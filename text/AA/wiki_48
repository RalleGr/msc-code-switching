<doc id="6066" url="https://en.wikipedia.org/wiki?curid=6066" title="Carl von Clausewitz">
Carl von Clausewitz

Carl Philipp Gottfried (or Gottlieb) von Clausewitz (; 1 June 1780 – 16 November 1831) was a Prussian general and military theorist who stressed the "moral" (meaning, in modern terms, psychological) and political aspects of war. His most notable work, "Vom Kriege" ("On War"), was unfinished at his death.
Clausewitz was a realist in many different senses and, while in some respects a romantic, also drew heavily on the rationalist ideas of the European Enlightenment.

Clausewitz's thinking is often described as Hegelian because of his dialectical method; but, although he was probably personally acquainted with Hegel, there remains debate as to whether or not Clausewitz was in fact influenced by him. He stressed the dialectical interaction of diverse factors, noting how unexpected developments unfolding under the "fog of war" (i.e., in the face of incomplete, dubious, and often completely erroneous information and high levels of fear, doubt, and excitement) call for rapid decisions by alert commanders. He saw history as a vital check on erudite abstractions that did not accord with experience. In contrast to the early work of Antoine-Henri Jomini, he argued that war could not be quantified or reduced to mapwork, geometry, and graphs. Clausewitz had many aphorisms, of which the most famous is "War is the continuation of politics by other means."

Clausewitz's Christian names are sometimes given in non-German sources as "Karl," "Carl Philipp Gottlieb," or "Carl Maria." He spelled his own given name with a "C" in order to identify with the classical Western tradition; writers who use "Karl" are often seeking to emphasize his German (rather than European) identity. "Carl Philipp Gottfried" appears on Clausewitz's tombstone. Nonetheless, sources such as military historian Peter Paret and "Encyclopædia Britannica" continue to use Gottlieb instead of Gottfried.

Clausewitz was born on 1 June 1780 in Burg bei Magdeburg in the Prussian Duchy of Magdeburg as the fourth and youngest son of a family that made claims to a noble status which Carl accepted. Clausewitz's family claimed descent from the Barons of Clausewitz in Upper Silesia, though scholars question the connection. His grandfather, the son of a Lutheran pastor, had been a professor of theology. Clausewitz's father, once a lieutenant in the army of Frederick the Great, King of Prussia, held a minor post in the Prussian internal-revenue service. Clausewitz entered the Prussian military service at the age of twelve as a lance-corporal, eventually attaining the rank of major general.

Clausewitz served in the Rhine Campaigns (1793–1794) including the Siege of Mainz, when the Prussian army invaded France during the French Revolution, and fought in the Napoleonic Wars from 1806 to 1815. He entered the "Kriegsakademie" (also cited as "The German War School", the "Military Academy in Berlin", and the "Prussian Military Academy," later the "War College") in Berlin in 1801 (aged 21), probably studied the writings of the philosophers Immanuel Kant and/or Fichte and Schleiermacher and won the regard of General Gerhard von Scharnhorst, the future first chief-of-staff of the newly reformed Prussian Army (appointed 1809). Clausewitz, Hermann von Boyen (1771–1848) and Karl von Grolman (1777–1843) were among Scharnhorst's primary allies in his efforts to reform the Prussian army between 1807 and 1814.

Clausewitz served during the Jena Campaign as aide-de-camp to Prince August. At the Battle of Jena-Auerstedt on 14 October 1806—when Napoleon invaded Prussia and defeated the massed Prussian-Saxon army commanded by Karl Wilhelm Ferdinand, Duke of Brunswick—he was captured, one of the 25,000 prisoners taken that day as the Prussian army disintegrated. He was 26. Clausewitz was held prisoner with his prince in France from 1807 to 1808. Returning to Prussia, he assisted in the reform of the Prussian army and state.
On 10 December 1810 he married the socially prominent Countess Marie von Brühl, whom he had first met in 1803. She was a member of the noble German von Brühl family originating in Thuringia. The couple moved in the highest circles, socialising with Berlin's political, literary, and intellectual élite. Marie was well-educated and politically well-connected—she played an important role in her husband's career progress and intellectual evolution. She also edited, published, and introduced his collected works.

Opposed to Prussia's enforced alliance with Napoleon I, Clausewitz left the Prussian army and served in the Imperial Russian Army from 1812 to 1813 during the Russian Campaign, taking part in the Battle of Borodino (1812). Like many Prussian officers serving in Russia, he joined the Russian-German Legion in 1813. In the service of the Russian Empire, Clausewitz helped negotiate the Convention of Tauroggen (1812), which prepared the way for the coalition of Prussia, Russia, and the United Kingdom that ultimately defeated Napoleon and his allies.

In 1815 the Russian-German Legion became integrated into the Prussian Army and Clausewitz re-entered Prussian service as a colonel. He was soon appointed chief-of-staff of Johann von Thielmann's III Corps. In that capacity he served at the Battle of Ligny and the Battle of Wavre during the Waterloo Campaign in 1815. An army led personally by Napoleon defeated the Prussians at Ligny (south of Mont-Saint-Jean and the village of Waterloo) on 16 June 1815, but they withdrew in good order. Napoleon's failure to destroy the Prussian forces led to his defeat a few days later at the Battle of Waterloo (18 June 1815), when the Prussian forces arrived on his right flank late in the afternoon to support the Anglo-Dutch-Belgian forces pressing his front. Napoleon had convinced his troops that the field grey uniforms were those of Marshal Grouchy's grenadiers. Clausewitz's unit fought heavily outnumbered at Wavre (18–19 June 1815), preventing large reinforcements from reaching Napoleon at Waterloo. After the war, Clausewitz served as the director of the "Kriegsakademie", where he served until 1830. In that year he returned to active duty with the army. Soon afterward, the outbreak of several revolutions around Europe and a crisis in Poland appeared to presage another major European war. Clausewitz was appointed chief of staff of the only army Prussia was able to mobilise in this emergency, which was sent to the Polish border. Its commander, Gneisenau, died of cholera (August 1831), and Clausewitz took command of the Prussian army's efforts to construct a "cordon sanitaire" to contain the great cholera outbreak (the first time cholera had appeared in modern heartland Europe, causing a continent-wide panic). Clausewitz himself died of the same disease shortly afterwards, on 17 November 1831.

His widow edited, published, and wrote the introduction to his "magnum opus" on the philosophy of war in 1832. (He had started working on the text in 1816, but had not completed it.) She wrote the preface for "On War" and by 1835 had published most of his collected works. She died in January 1836.

Clausewitz was a professional combat soldier who was involved in numerous military campaigns, but he is famous primarily as a military theorist interested in the examination of war, utilising the campaigns of Frederick the Great and Napoleon as frames of reference for his work. He wrote a careful, systematic, philosophical examination of war in all its aspects. The result was his principal book, "On War," a major work on the philosophy of war. It was unfinished when Clausewitz died and contains material written at different stages in his intellectual evolution, producing some significant contradictions between different sections. The sequence and precise character of that evolution is a source of much debate, as are exact meaning behind his seemingly contradictory claims (discussions pertinent to the tactical, operational and strategic levels of war are one example). Clausewitz constantly sought to revise the text, particularly between 1827 and his departure on his last field assignments, to include more material on "people's war" and forms of war other than high-intensity warfare between states, but relatively little of this material was included in the book. Soldiers before this time had written treatises on various military subjects, but none had undertaken a great philosophical examination of war on the scale of those written by Clausewitz and Leo Tolstoy, both of which were inspired by the events of the Napoleonic Era.

Clausewitz's work is still studied today, demonstrating its continued relevance. More than sixteen major English-language books that focused specifically on his work were published between 2005 and 2014, whereas his 19th-century rival Jomini faded from influence. The historian Lynn Montross said the outcome, "may be explained by the fact that Jomini produced a system of war, Clausewitz a philosophy. The one has been outdated by new weapons, the other still influences the strategy behind those weapons." Jomini did not attempt to define war but Clausewitz did, providing (and dialectically comparing) a number of definitions. The first is his dialectical thesis: "War is thus an act of force to compel our enemy to do our will." The second, often treated as Clausewitz's 'bottom line,' is in fact merely his dialectical antithesis: "War is merely the continuation of politics with other means." The synthesis of his dialectical examination of the nature of war is his famous "trinity," saying that war is "a fascinating trinity—composed of primordial violence, hatred, and enmity, which are to be regarded as a blind natural force; the play of chance and probability, within which the creative spirit is free to roam; and its element of subordination, as an instrument of policy, which makes it subject to pure reason." Christopher Bassford says the best shorthand for Clausewitz's trinity should be something like "violent emotion/chance/rational calculation." However, it is frequently presented as "people/army/government," a misunderstanding based on a later paragraph in the same chapter. This misrepresentation was popularised by U.S. Army Colonel Harry Summers' Vietnam-era interpretation, facilitated by weaknesses in the 1976 Howard/Paret translation.

The degree to which Clausewitz managed to revise his manuscript to reflect that synthesis is the subject of much debate. His final reference to war and "Politik", however, goes beyond his widely quoted antithesis: "War is simply the continuation of political intercourse with the addition of other means. We deliberately use the phrase 'with the addition of other means' because we also want to make it clear that war in itself does not suspend political intercourse or change it into something entirely different. In essentials that intercourse continues, irrespective of the means it employs. The main lines along which military events progress, and to which they are restricted, are political lines that continue throughout the war into the subsequent peace."

Clausewitz introduced systematic philosophical contemplation into Western military thinking, with powerful implications not only for historical and analytical writing but also for practical policy, military instruction, and operational planning. He relied on his own experiences, contemporary writings about Napoleon, and on deep historical research. His historiographical approach is evident in his first extended study, written when he was 25, of the Thirty Years War. He rejects the Enlightenment's view of the war as a chaotic muddle and instead explains its drawn-out operations by the economy and technology of the age, the social characteristics of the troops, and the commanders' politics and psychology. In "On War", Clausewitz sees all wars as the sum of decisions, actions, and reactions in an uncertain and dangerous context, and also as a socio-political phenomenon. He also stressed the complex nature of war, which encompasses both the socio-political and the operational and stresses the primacy of state policy.

The word "strategy" had only recently come into usage in modern Europe, and Clausewitz's definition is quite narrow: "the use of engagements for the object of war." Clausewitz conceived of war as a political, social, and military phenomenon which might — depending on circumstances — involve the entire population of a nation at war. In any case, Clausewitz saw military force as an instrument that states and other political actors use to pursue the ends of policy, in a dialectic between opposing wills, each with the aim of imposing his policies and will upon his enemy.

Clausewitz's emphasis on the inherent superiority of the defence suggests that habitual aggressors are likely to end up as failures. The inherent superiority of the defence obviously does not mean that the defender will always win, however: there are other asymmetries to be considered. He was interested in co-operation between the regular army and militia or partisan forces, or citizen soldiers, as one possible — sometimes the only — method of defence. In the circumstances of the Wars of the French Revolution and with Napoleon, which were energised by a rising spirit of nationalism, he emphasised the need for states to involve their entire populations in the conduct of war. This point is especially important, as these wars demonstrated that such energies could be of decisive importance and for a time led to a democratisation of the armed forces much as universal suffrage democratised politics.

While Clausewitz was intensely aware of the value of intelligence at all levels, he was also very sceptical of the accuracy of much military intelligence: "Many intelligence reports in war are contradictory; even more are false, and most are uncertain... In short, most intelligence is false." This circumstance is generally described as part of the fog of war. Such sceptical comments apply only to intelligence at the tactical and operational levels; at the strategic and political levels he constantly stressed the requirement for the best possible understanding of what today would be called strategic and political intelligence. His conclusions were influenced by his experiences in the Prussian Army, which was often in an intelligence fog due partly to the superior abilities of Napoleon's system but even more to the nature of war. Clausewitz acknowledges that friction creates enormous difficulties for the realisation of any plan, and the "fog of war" hinders commanders from knowing what is happening. It is precisely in the context of this challenge that he develops the concept of military genius, whose capabilities are seen above all in the execution of operations. 'Military genius' is not simply a matter of intellect, but a combination of qualities of intellect, experience, personality, and temperament (and there are many possible such combinations) that create a very highly developed mental aptitude for the waging of war.

Key ideas discussed in "On War" include:

Clausewitz used a dialectical method to construct his argument, leading to frequent misinterpretation of his ideas. British military theorist B. H. Liddell Hart contends that the enthusiastic acceptance by the Prussian military establishment – especially Moltke the Elder, a former student of his – of what they believed to be Clausewitz's ideas, and the subsequent widespread adoption of the Prussian military system worldwide, had a deleterious effect on military theory and practice, due to their egregious misinterpretation of his ideas:

As so often happens, Clausewitz's disciples carried his teaching to an extreme which their master had not intended... [Clausewitz's] theory of war was expounded in a way too abstract and involved for ordinary soldier-minds, essentially concrete, to follow the course of his argument – which often turned back from the direction in which it was apparently leading. Impressed yet befogged, they grasped at his vivid leading phrases, seeing only their surface meaning, and missing the deeper current of his thought.

As described by Christopher Bassford, then-professor of strategy at the National War College of the United States:

One of the main sources of confusion about Clausewitz's approach lies in his dialectical method of presentation. For example, Clausewitz's famous line that "War is a mere continuation of politics by other means," ("Der Krieg ist eine bloße Fortsetzung der Politik mit anderen Mitteln") while accurate as far as it goes, was not intended as a statement of fact. It is the antithesis in a dialectical argument whose thesis is the point – made earlier in the analysis – that "war is nothing but a duel [or wrestling match, a better translation of the German "Zweikampf"] on a larger scale." His synthesis, which resolves the deficiencies of these two bold statements, says that war is neither "nothing but" an act of brute force nor "merely" a rational act of politics or policy. This synthesis lies in his "fascinating trinity" [wunderliche Dreifaltigkeit]: a dynamic, inherently unstable interaction of the forces of violent emotion, chance, and rational calculation.

Another example of this confusion is the idea that Clausewitz was a proponent of total war as used in the Third Reich's propaganda in the 1940s. In fact, he never used the term "total war": rather, he discussed "absolute war," a concept which evolved into the much more abstract notion of "ideal war" discussed at the very beginning of "Vom Kriege"—the purely "logical" result of the forces underlying a "pure," Platonic "ideal" of war. In what he called a "logical fantasy," war cannot be waged in a limited way: the rules of competition will force participants to use all means at their disposal to achieve victory. But in the "real world", he said, such rigid logic is unrealistic and dangerous. As a practical matter, the military objectives in "real" war that support political objectives generally fall into two broad types: "war to achieve limited aims"; and war to "disarm" the enemy, "to render [him] politically helpless or militarily impotent." Thus the complete defeat of the enemy may not be necessary, desirable, or even possible.

In modern times the reconstruction of Clausewitzian theory has been a matter of much dispute. One analysis was that of Panagiotis Kondylis, a Greek writer and philosopher, who opposed the interpretations of Raymond Aron in "Penser la Guerre, Clausewitz", and other liberal writers. According to Aron, Clausewitz was one of the first writers to condemn the militarism of the Prussian general staff and its war-proneness, based on Clausewitz's argument that "war is a continuation of politics by other means." In "Theory of War," Kondylis claims that this is inconsistent with Clausewitzian thought. He claims that Clausewitz was morally indifferent to war (though this probably reflects a lack of familiarity with personal letters from Clausewitz, which demonstrate an acute awareness of war's tragic aspects) and that his advice regarding politics' dominance over the conduct of war has nothing to do with pacifist ideas. For Clausewitz, war is simply one unique means that is sometimes applied to the eternal quest for power, of "raison d'État" in an anarchic and unsafe world.

Other notable writers who have studied Clausewitz's texts and translated them into English are historians Peter Paret of the Institute for Advanced Study and Sir Michael Howard, and the philosopher, musician, and game theorist Anatol Rapoport. Howard and Paret edited the most widely used edition of "On War" (Princeton University Press, 1976/1984) and have produced comparative studies of Clausewitz and other theorists, such as Tolstoy. Bernard Brodie's "A Guide to the Reading of "On War"", in the 1976 Princeton translation, expressed his interpretations of the Prussian's theories and provided students with an influential synopsis of this vital work.

The British military historian John Keegan attacked Clausewitz's theory in his book "A History of Warfare". Keegan argued that Clausewitz assumed the existence of states, yet 'war antedates the state, diplomacy and strategy by many millennia.'

Clausewitz died without completing "On War", but despite this his ideas have been widely influential in military theory and have had a strong influence on German military thought specifically. Later Prussian and German generals, such as Helmuth Graf von Moltke, were clearly influenced by Clausewitz: Moltke's widely quoted statement that "No campaign plan survives first contact with the enemy" is a classic reflection of Clausewitz's insistence on the roles of chance, friction, "fog," uncertainty, and interactivity in war.

Clausewitz's influence spread to British thinking as well, though at first more as a historian and analyst than as a theorist. See for example Wellington's extended essay discussing Clausewitz's study of the Campaign of 1815—Wellington's only serious written discussion of the battle, which was widely discussed in 19th-century Britain. Clausewitz's broader thinking came to the fore following Britain's military embarrassments in the Boer War (1899–1902). One example of a heavy Clausewitzian influence in that era is Spenser Wilkinson, journalist, the first Chichele Professor of Military History at Oxford University, and perhaps the most prominent military analyst in Britain from c. 1885 until well into the interwar period. Another is naval historian Julian Corbett (1854–1922), whose work reflected a deep if idiosyncratic adherence to Clausewitz's concepts and frequently an emphasis on Clausewitz's ideas about 'limited war' and the inherent strengths of the defensive form of war. Corbett's practical strategic views were often in prominent public conflict with Wilkinson's – see, for example, Wilkinson's article "Strategy at Sea," "The Morning Post", 12 February 1912. Following the First World War, however, the influential British military commentator B. H. Liddell Hart in the 1920s erroneously attributed to him the doctrine of "total war" that during the First World War had been embraced by many European general staffs and emulated by the British. More recent scholars typically see that war as so confused in terms of political rationale that it in fact contradicts much of "On War." One of the most influential British Clausewitzians today is Colin S. Gray; historian Hew Strachan (like Wilkinson also the Chichele Professor of Military History at Oxford University, since 2001) has been an energetic proponent of the "study" of Clausewitz, but his own views on Clausewitz's ideas are somewhat ambivalent.

With some interesting exceptions (e.g., John McAuley Palmer, Robert M. Johnston, Hoffman Nickerson), Clausewitz had little influence on American military thought before 1945 other than via British writers, though Generals Eisenhower and Patton were avid readers. He did influence Karl Marx, Friedrich Engels, Vladimir Lenin, Leon Trotsky and Mao Zedong, and thus the Communist Soviet and Chinese traditions, as Lenin emphasised the inevitability of wars among capitalist states in the age of imperialism and presented the armed struggle of the working class as the only path toward the eventual elimination of war. Because Lenin was an admirer of Clausewitz and called him "one of the great military writers", his influence on the Red Army was immense. The Russian historian A.N. Mertsalov commented that "It was an irony of fate that the view in the USSR was that it was Lenin who shaped the attitude towards Clausewitz, and that Lenin's dictum that war is a continuation of politics is taken from the work of this [allegedly] anti-humanist anti-revolutionary." The American mathematician Anatol Rapoport wrote in 1968 that Clausewitz as interpreted by Lenin formed the basis of all Soviet military thinking since 1917, and quoted the remarks by Marshal V.D. Sokolovsky:

In describing the essence of war, Marxism-Leninism takes as its point of departure the premise that war is not an aim in itself, but rather a tool of politics. In his remarks on Clausewitz's "On War", Lenin stressed that "Politics is the reason, and war is only the tool, not the other way around. Consequently, it remains only to subordinate the military point of view to the political".

Henry A. Kissinger, however, described Lenin's approach as being that politics is a continuation of war by other means, thus turning Clausewitz's argument "on its head."

Rapoport argued that:

As for Lenin's approval of Clausewitz, it probably stems from his obsession with the struggle for power. The whole Marxist conception of history is that of successive struggles for power, primarily between social classes. This was constantly applied by Lenin in a variety of contexts. Thus the entire history of philosophy appears in Lenin's writings as a vast struggle between "idealism" and "materialism". The fate of the socialist movement was to be decided by a struggle between the revolutionists and the reformers. Clausewitz's acceptance of the struggle for power as the essence of international politics must have impressed Lenin as starkly realistic.

Clausewitz directly influenced Mao Zedong, who read "On War" in 1938 and organised a seminar on Clausewitz for the Party leadership in Yan'an. Thus the "Clausewitzian" content in many of Mao's writings is not merely a regurgitation of Lenin but reflects Mao's study.
The idea that war involves inherent "friction" that distorts, to a greater or lesser degree, all prior arrangements, has become common currency in fields such as business strategy and sport. The phrase "fog of war" derives from Clausewitz's stress on how confused warfare can seem while immersed within it. The term center of gravity, used in a military context derives from Clausewitz's usage, which he took from Newtonian mechanics. In U.S. military doctrine, "center of gravity" refers to the basis of an opponent's power at the operational, strategic, or political level, though this is only one aspect of Clausewitz's use of the term.

The deterrence strategy of the United States in the 1950s was closely inspired by President Dwight Eisenhower’s reading of Clausewitz as a young officer in the 1920s. Eisenhower was greatly impressed by Clausewitz’s example of a theoretical, idealised “absolute war” in "Vom Krieg" as a way of demonstrating how absurd it would be to attempt such a strategy in practice. For Eisenhower, the age of nuclear weapons had made what was for Clausewitz in the early 19th century only a theoretical vision an all too real possibility in the mid-20th century. From Eisenhower's viewpoint, the best deterrent to war was to show the world just how appalling and horrific a nuclear “absolute war” would be if it should ever occur, hence a series of much publicized nuclear tests in the Pacific, giving first priority in the defence budget to nuclear weapons and delivery systems over conventional weapons, and making repeated statements in public that the United States was able and willing at all times to use nuclear weapons. In this way through the massive retaliation doctrine and the closely related foreign policy concept of brinkmanship, Eisenhower hoped to hold out a creditable vision of Clausewitzian nuclear “absolute war” in order to deter the Soviet Union and/or China from ever risking a war or even conditions that might lead to a war with the United States.
After 1970, some theorists claimed that nuclear proliferation made Clausewitzian concepts obsolete after the 20th-century period in which they dominated the world. John E. Sheppard, Jr., argues that by developing nuclear weapons, state-based conventional armies simultaneously both perfected their original purpose, to destroy a mirror image of themselves, and made themselves obsolete. No two powers have used nuclear weapons against each other, instead using conventional means or proxy wars to settle disputes. If such a conflict did occur, presumably both combatants would be annihilated. Heavily influenced by the war in Vietnam and by antipathy to American strategist Henry Kissinger, the American biologist, musician, and game-theorist Anatol Rapoport argued in 1968 that a Clausewitzian view of war was not only obsolete in the age of nuclear weapons, but also highly dangerous as it promoted a "zero-sum paradigm" to international relations and a "dissolution of rationality" amongst decision-makers.

The end of the 20th century and the beginning of the 21st century have seen many instances of state armies attempting to suppress insurgencies, terrorism, and other forms of asymmetrical warfare. Clausewitz did not focus solely on wars between countries with well-defined armies. The era of the French Revolution and Napoleon was full of revolutions, rebellions, and violence by "non-state actors", such as the wars in the French Vendée and in Spain. Clausewitz wrote a series of “Lectures on Small War” and studied the rebellion in the Vendée (1793–1796) and the Tyrolean uprising of 1809. In his famous “Bekenntnisdenkschrift” of 1812, he called for a “Spanish war in Germany” and laid out a comprehensive guerrilla strategy to be waged against Napoleon. In "On War" he included a famous chapter on “The People in Arms.”

One prominent critic of Clausewitz is the Israeli military historian Martin van Creveld. In his book "The Transformation of War", Creveld argued that Clausewitz's famous "Trinity" of people, army, and government was an obsolete socio-political construct based on the state, which was rapidly passing from the scene as the key player in war, and that he (Creveld) had constructed a new "non-trinitarian" model for modern warfare. Creveld's work has had great influence. Daniel Moran replied, 'The most egregious misrepresentation of Clausewitz's famous metaphor must be that of Martin van Creveld, who has declared Clausewitz to be an apostle of Trinitarian War, by which he means, incomprehensibly, a war of 'state against state and army against army,' from which the influence of the people is entirely excluded." Christopher Bassford went further, noting that one need only "read" the paragraph in which Clausewitz defined his Trinity to see "that the words 'people,' 'army,' and 'government' appear nowhere at all in the list of the Trinity’s components... Creveld's and Keegan's assault on Clausewitz's Trinity is not only a classic 'blow into the air,' i.e., an assault on a position Clausewitz doesn't occupy. It is also a pointless attack on a concept that is quite useful in its own right. In any case, their failure to read the actual wording of the theory they so vociferously attack, and to grasp its deep relevance to the phenomena they describe, is hard to credit."

Some have gone further and suggested that Clausewitz's best-known aphorism, that war is a continuation of politics with other means, is not only irrelevant today but also inapplicable historically. For an opposing view see the sixteen essays presented in "Clausewitz in the Twenty-First Century" edited by Hew Strachan and Andreas Herberg-Rothe.

In military academies, schools, and universities worldwide, Clausewitz's literature is often mandatory reading.

Literature

Film

Video games

August Otto Rühle von Lilienstern – Prussian officer from whom Clausewitz allegedly took, without acknowledgement, several important ideas (including that about war as pursuing political aims) made famous in "On War". However, such ideas as Clausewitz and Lilienstern shared in common derived from a common influence, i.e., Scharnhorst, who was Clausewitz's "second father" and professional mentor.

Informational notes
Citations
Further reading




</doc>
<doc id="6068" url="https://en.wikipedia.org/wiki?curid=6068" title="Common Lisp">
Common Lisp

Common Lisp (CL) is a dialect of the Lisp programming language, published in ANSI standard document "ANSI INCITS 226-1994 (R2004)" (formerly "X3.226-1994 (R1999)"). The Common Lisp HyperSpec, a hyperlinked HTML version, has been derived from the ANSI Common Lisp standard.

The Common Lisp language was developed as a standardized and improved successor of Maclisp. By the early 1980s several groups were already at work on diverse successors to MacLisp: Lisp Machine Lisp (aka ZetaLisp), Spice Lisp, NIL and S-1 Lisp. Common Lisp sought to unify, standardise, and extend the features of these MacLisp dialects. Common Lisp is not an implementation, but rather a language specification. Several implementations of the Common Lisp standard are available, including free and open-source software and proprietary products.
Common Lisp is a general-purpose, multi-paradigm programming language. It supports a combination of procedural, functional, and object-oriented programming paradigms. As a dynamic programming language, it facilitates evolutionary and incremental software development, with iterative compilation into efficient run-time programs. This incremental development is often done interactively without interrupting the running application.

It also supports optional type annotation and casting, which can be added as necessary at the later profiling and optimization stages, to permit the compiler to generate more efficient code. For instance, codice_1 can hold an unboxed integer in a range supported by the hardware and implementation, permitting more efficient arithmetic than on big integers or arbitrary precision types. Similarly, the compiler can be told on a per-module or per-function basis which type of safety level is wanted, using "optimize" declarations.

Common Lisp includes CLOS, an object system that supports multimethods and method combinations. It is often implemented with a Metaobject Protocol.

Common Lisp is extensible through standard features such as "Lisp macros" (code transformations) and "reader macros" (input parsers for characters).

Common Lisp provides partial backwards compatibility with Maclisp and John McCarthy's original Lisp. This allows older Lisp software to be ported to Common Lisp.

Work on Common Lisp started in 1981 after an initiative by ARPA manager Bob Engelmore to develop a single community standard Lisp dialect. Much of the initial language design was done via electronic mail. In 1982, Guy L. Steele, Jr. gave the first overview of Common Lisp at the 1982 ACM Symposium on LISP and functional programming.

The first language documentation was published in 1984 as Common Lisp the Language (known as CLtL1), first edition. A second edition (known as CLtL2), published in 1990, incorporated many changes to the language, made during the ANSI Common Lisp standardization process: extended LOOP syntax, the Common Lisp Object System, the Condition System for error handling, an interface to the pretty printer and much more. But CLtL2 does not describe the final ANSI Common Lisp standard and thus is not a documentation of ANSI Common Lisp. The final ANSI Common Lisp standard then was published in 1994. Since then no update to the standard has been published. Various extensions and improvements to Common Lisp (examples are Unicode, Concurrency, CLOS-based IO) have been provided by implementations and libraries (many available via Quicklisp).

Common Lisp is a dialect of Lisp. It uses S-expressions to denote both code and data structure. Function calls, macro forms and special forms are written as lists, with the name of the operator first, as in these examples:

Common Lisp has many data types.

"Number" types include integers, ratios, floating-point numbers, and complex numbers. Common Lisp uses bignums to represent numerical values of arbitrary size and precision. The ratio type represents fractions exactly, a facility not available in many languages. Common Lisp automatically coerces numeric values among these types as appropriate.

The Common Lisp "character" type is not limited to ASCII characters. Most modern implementations allow Unicode characters.

The "symbol" type is common to Lisp languages, but largely unknown outside them. A symbol is a unique, named data object with several parts: name, value, function, property list, and package. Of these, "value cell" and "function cell" are the most important. Symbols in Lisp are often used similarly to identifiers in other languages: to hold the value of a variable; however there are many other uses. Normally, when a symbol is evaluated, its value is returned. Some symbols evaluate to themselves, for example, all symbols in the keyword package are self-evaluating. Boolean values in Common Lisp are represented by the self-evaluating symbols T and NIL. Common Lisp has namespaces for symbols, called 'packages'.

A number of functions are available for rounding scalar numeric values in various ways. The function codice_2 rounds the argument to the nearest integer, with halfway cases rounded to the even integer. The functions codice_3, codice_4, and codice_5 round towards zero, down, or up respectively. All these functions return the discarded fractional part as a secondary value. For example, codice_6 yields −3, 0.5; codice_7 yields −2, −0.5; codice_8 yields 2, 0.5; and codice_9 yields 4, −0.5.

"Sequence" types in Common Lisp include lists, vectors, bit-vectors, and strings. There are many operations that can work on any sequence type.

As in almost all other Lisp dialects, "lists" in Common Lisp are composed of "conses", sometimes called "cons cells" or "pairs". A cons is a data structure with two slots, called its "car" and "cdr". A list is a linked chain of conses or the empty list. Each cons's car refers to a member of the list (possibly another list). Each cons's cdr refers to the next cons—except for the last cons in a list, whose cdr refers to the codice_10 value. Conses can also easily be used to implement trees and other complex data structures; though it is usually advised to use structure or class instances instead. It is also possible to create circular data structures with conses.

Common Lisp supports multidimensional "arrays", and can dynamically resize "adjustable" arrays if required. Multidimensional arrays can be used for matrix mathematics. A "vector" is a one-dimensional array. Arrays can carry any type as members (even mixed types in the same array) or can be specialized to contain a specific type of members, as in a vector of bits. Usually, only a few types are supported. Many implementations can optimize array functions when the array used is type-specialized. Two type-specialized array types are standard: a "string" is a vector of characters, while a "bit-vector" is a vector of bits.

"Hash tables" store associations between data objects. Any object may be used as key or value. Hash tables are automatically resized as needed.

"Packages" are collections of symbols, used chiefly to separate the parts of a program into namespaces. A package may "export" some symbols, marking them as part of a public interface. Packages can use other packages.

"Structures", similar in use to C structs and Pascal records, represent arbitrary complex data structures with any number and type of fields (called "slots"). Structures allow single-inheritance.

"Classes" are similar to structures, but offer more dynamic features and multiple-inheritance. (See CLOS). Classes have been added late to Common Lisp and there is some conceptual overlap with structures. Objects created of classes are called "Instances". A special case is Generic Functions. Generic Functions are both functions and instances.

Common Lisp supports first-class functions. For instance, it is possible to write functions that take other functions as arguments or return functions as well. This makes it possible to describe very general operations.

The Common Lisp library relies heavily on such higher-order functions. For example, the codice_11 function takes a relational operator as an argument and key function as an optional keyword argument. This can be used not only to sort any type of data, but also to sort data structures according to a key.
The evaluation model for functions is very simple. When the evaluator encounters a form codice_12 then it presumes that the symbol named f is one of the following:


If f is the name of a function, then the arguments a1, a2, ..., an are evaluated in left-to-right order, and the function is found and invoked with those values supplied as parameters.

The macro codice_14 defines functions where a function definition gives the name of the function, the names of any arguments, and a function body:
Function definitions may include compiler directives, known as "declarations", which provide hints to the compiler about optimization settings or the data types of arguments. They may also include "documentation strings" (docstrings), which the Lisp system may use to provide interactive documentation:
Anonymous functions (function literals) are defined using codice_13 expressions, e.g. codice_16 for a function that squares its argument. Lisp programming style frequently uses higher-order functions for which it is useful to provide anonymous functions as arguments.

Local functions can be defined with codice_17 and codice_18.
There are several other operators related to the definition and manipulation of functions. For instance, a function may be compiled with the codice_19 operator. (Some Lisp systems run functions using an interpreter by default unless instructed to compile; others compile every function).

The macro codice_20 defines generic functions. Generic functions are a collection of methods.
The macro codice_21 defines methods.

Methods can specialize their parameters over CLOS "standard classes", "system classes", "structure classes" or individual objects. For many types, there are corresponding "system classes".

When a generic function is called, multiple-dispatch will determine the effective method to use.

Generic Functions are also a first class data type. There are many more features to Generic Functions and Methods than described above.

The namespace for function names is separate from the namespace for data variables. This is a key difference between Common Lisp and Scheme. For Common Lisp, operators that define names in the function namespace include codice_14, codice_17, codice_18, codice_21 and codice_20.

To pass a function by name as an argument to another function, one must use the codice_27 special operator, commonly abbreviated as codice_28. The first codice_11 example above refers to the function named by the symbol codice_30 in the function namespace, with the code codice_31. Conversely, to call a function passed in such a way, one would use the codice_32 operator on the argument.

Scheme's evaluation model is simpler: there is only one namespace, and all positions in the form are evaluated (in any order) – not just the arguments. Code written in one dialect is therefore sometimes confusing to programmers more experienced in the other. For instance, many Common Lisp programmers like to use descriptive variable names such as "list" or "string" which could cause problems in Scheme, as they would locally shadow function names.

Whether a separate namespace for functions is an advantage is a source of contention in the Lisp community. It is usually referred to as the "Lisp-1 vs. Lisp-2 debate". Lisp-1 refers to Scheme's model and Lisp-2 refers to Common Lisp's model. These names were coined in a 1988 paper by Richard P. Gabriel and Kent Pitman, which extensively compares the two approaches.

Common Lisp supports the concept of "multiple values", where any expression always has a single "primary value", but it might also have any number of "secondary values", which might be received and inspected by interested callers. This concept is distinct from returning a list value, as the secondary values are fully optional, and passed via a dedicated side channel. This means that callers may remain entirely unaware of the secondary values being there if they have no need for them, and it makes it convenient to use the mechanism for communicating information that is sometimes useful, but not always necessary. For example,




Multiple values are supported by a handful of standard forms, most common of which are the codice_35 special form for accessing secondary values and codice_36 for returning multiple values:

Other data types in Common Lisp include:


Like programs in many other programming languages, Common Lisp programs make use of names to refer to variables, functions, and many other kinds of entities. Named references are subject to scope.

The association between a name and the entity which the name refers to is called a binding.

Scope refers to the set of circumstances in which a name is determined to have a particular binding.

The circumstances which determine scope in Common Lisp include:


To understand what a symbol refers to, the Common Lisp programmer must know what kind of reference is being expressed, what kind of scope it uses if it is a variable reference (dynamic versus lexical scope), and also the run-time situation: in what environment is the reference resolved, where was the binding introduced into the environment, et cetera.

Some environments in Lisp are globally pervasive. For instance, if a new type is defined, it is known everywhere thereafter. References to that type look it up in this global environment.

One type of environment in Common Lisp is the dynamic environment. Bindings established in this environment have dynamic extent, which means that a binding is established at the start of the execution of some construct, such as a codice_51 block, and disappears when that construct finishes executing: its lifetime is tied to the dynamic activation and deactivation of a block. However, a dynamic binding is not just visible within that block; it is also visible to all functions invoked from that block. This type of visibility is known as indefinite scope. Bindings which exhibit dynamic extent (lifetime tied to the activation and deactivation of a block) and indefinite scope (visible to all functions which are called from that block) are said to have dynamic scope.

Common Lisp has support for dynamically scoped variables, which are also called special variables. Certain other kinds of bindings are necessarily dynamically scoped also, such as restarts and catch tags. Function bindings cannot be dynamically scoped using codice_17 (which only provides lexically scoped function bindings), but function objects (a first-level object in Common Lisp) can be assigned to dynamically scoped variables, bound using codice_51 in dynamic scope, then called using codice_32 or codice_57.

Dynamic scope is extremely useful because it adds referential clarity and discipline to global variables. Global variables are frowned upon in computer science as potential sources of error, because they can give rise to ad-hoc, covert channels of communication among modules that lead to unwanted, surprising interactions.

In Common Lisp, a special variable which has only a top-level binding behaves just like a global variable in other programming languages. A new value can be stored into it, and that value simply replaces what is in the top-level binding. Careless replacement of the value of a global variable is at the heart of bugs caused by the use of global variables. However, another way to work with a special variable is to give it a new, local binding within an expression. This is sometimes referred to as "rebinding" the variable. Binding a dynamically scoped variable temporarily creates a new memory location for that variable, and associates the name with that location. While that binding is in effect, all references to that variable refer to the new binding; the previous binding is hidden. When execution of the binding expression terminates, the temporary memory location is gone, and the old binding is revealed, with the original value intact. Of course, multiple dynamic bindings for the same variable can be nested.

In Common Lisp implementations which support multithreading, dynamic scopes are specific to each thread of execution. Thus special variables serve as an abstraction for thread local storage. If one thread rebinds a special variable, this rebinding has no effect on that variable in other threads. The value stored in a binding can only be retrieved by the thread which created that binding. If each thread binds some special variable codice_58, then codice_58 behaves like thread-local storage. Among threads which do not rebind codice_58, it behaves like an ordinary global: all of these threads refer to the same top-level binding of codice_58.

Dynamic variables can be used to extend the execution context with additional context information which is implicitly passed from function to function without having to appear as an extra function parameter. This is especially useful when the control transfer has to pass through layers of unrelated code, which simply cannot be extended with extra parameters to pass the additional data. A situation like this usually calls for a global variable. That global variable must be saved and restored, so that the scheme doesn't break under recursion: dynamic variable rebinding takes care of this. And that variable must be made thread-local (or else a big mutex must be used) so the scheme doesn't break under threads: dynamic scope implementations can take care of this also.

In the Common Lisp library, there are many standard special variables. For instance, all standard I/O streams are stored in the top-level bindings of well-known special variables. The standard output stream is stored in *standard-output*.

Suppose a function foo writes to standard output:
To capture its output in a character string, *standard-output* can be bound to a string stream and called:

Common Lisp supports lexical environments. Formally, the bindings in a lexical environment have lexical scope and may have either an indefinite extent or dynamic extent, depending on the type of namespace. Lexical scope means that visibility is physically restricted to the block in which the binding is established. References which are not textually (i.e. lexically) embedded in that block simply do not see that binding.

The tags in a TAGBODY have lexical scope. The expression (GO X) is erroneous if it is not embedded in a TAGBODY which contains a label X. However, the label bindings disappear when the TAGBODY terminates its execution, because they have dynamic extent. If that block of code is re-entered by the invocation of a lexical closure, it is invalid for the body of that closure to try to transfer control to a tag via GO:

When the TAGBODY is executed, it first evaluates the setf form which stores a function in the special variable *stashed*. Then the (go end-label) transfers control to end-label, skipping the code (print "Hello"). Since end-label is at the end of the tagbody, the tagbody terminates, yielding NIL. Suppose that the previously remembered function is now called:
This situation is erroneous. One implementation's response is an error condition containing the message, "GO: tagbody for tag SOME-LABEL has already been left". The function tried to evaluate (go some-label), which is lexically embedded in the tagbody, and resolves to the label. However, the tagbody isn't executing (its extent has ended), and so the control transfer cannot take place.

Local function bindings in Lisp have lexical scope, and variable bindings also have lexical scope by default. By contrast with GO labels, both of these have indefinite extent. When a lexical function or variable binding is established, that binding continues to exist for as long as references to it are possible, even after the construct which established that binding has terminated. References to lexical variables and functions after the termination of their establishing construct are possible thanks to lexical closures.

Lexical binding is the default binding mode for Common Lisp variables. For an individual symbol, it can be switched to dynamic scope, either by a local declaration, by a global declaration. The latter may occur implicitly through the use of a construct like DEFVAR or DEFPARAMETER. It is an important convention in Common Lisp programming that special (i.e. dynamically scoped) variables have names which begin and end with an asterisk sigil codice_62 in what is called the "earmuff convention". If adhered to, this convention effectively creates a separate namespace for special variables, so that variables intended to be lexical are not accidentally made special.

Lexical scope is useful for several reasons.

Firstly, references to variables and functions can be compiled to efficient machine code, because the run-time environment structure is relatively simple. In many cases it can be optimized to stack storage, so opening and closing lexical scopes has minimal overhead. Even in cases where full closures must be generated, access to the closure's environment is still efficient; typically each variable becomes an offset into a vector of bindings, and so a variable reference becomes a simple load or store instruction with a base-plus-offset addressing mode.

Secondly, lexical scope (combined with indefinite extent) gives rise to the lexical closure, which in turn creates a whole paradigm of programming centered around the use of functions being first-class objects, which is at the root of functional programming.

Thirdly, perhaps most importantly, even if lexical closures are not exploited, the use of lexical scope isolates program modules from unwanted interactions. Due to their restricted visibility, lexical variables are private. If one module A binds a lexical variable X, and calls another module B, references to X in B will not accidentally resolve to the X bound in A. B simply has no access to X. For situations in which disciplined interactions through a variable are desirable, Common Lisp provides special variables. Special variables allow for a module A to set up a binding for a variable X which is visible to another module B, called from A. Being able to do this is an advantage, and being able to prevent it from happening is also an advantage; consequently, Common Lisp supports both lexical and dynamic scope.

A "macro" in Lisp superficially resembles a function in usage. However, rather than representing an expression which is evaluated, it represents a transformation of the program source code. The macro gets the source it surrounds as arguments, binds them to its parameters and computes a new source form. This new form can also use a macro. The macro expansion is repeated until the new source form does not use a macro. The final computed form is the source code executed at runtime.

Typical uses of macros in Lisp:


Various standard Common Lisp features also need to be implemented as macros, such as:


Macros are defined by the "defmacro" macro. The special operator "macrolet" allows the definition of local (lexically scoped) macros. It is also possible to define macros for symbols using "define-symbol-macro" and "symbol-macrolet".

Paul Graham's book On Lisp describes the use of macros in Common Lisp in detail. Doug Hoyte's book Let Over Lambda extends the discussion on macros, claiming "Macros are the single greatest advantage that lisp has as a programming language and the single greatest advantage of any programming language." Hoyte provides several examples of iterative development of macros.

Macros allow Lisp programmers to create new syntactic forms in the language. One typical use is to create new control structures. The example macro provides an codice_73 looping construct. The syntax is:
The macro definition for "until":

"tagbody" is a primitive Common Lisp special operator which provides the ability to name tags and use the "go" form to jump to those tags. The backquote "`" provides a notation that provides code templates, where the value of forms preceded with a comma are filled in. Forms preceded with comma and at-sign are "spliced" in. The tagbody form tests the end condition. If the condition is true, it jumps to the end tag. Otherwise the provided body code is executed and then it jumps to the start tag.

An example form using above "until" macro:

The code can be expanded using the function "macroexpand-1". The expansion for above example looks like this:

(TAGBODY
During macro expansion the value of the variable "test" is "(= (random 10) 0)" and the value of the variable "body" is "((write-line "Hello"))". The body is a list of forms.

Symbols are usually automatically upcased. The expansion uses the TAGBODY with two labels. The symbols for these labels are computed by GENSYM and are not interned in any package. Two "go" forms use these tags to jump to. Since "tagbody" is a primitive operator in Common Lisp (and not a macro), it will not be expanded into something else. The expanded form uses the "when" macro, which also will be expanded. Fully expanding a source form is called "code walking".

In the fully expanded ("walked") form, the "when" form is replaced by the primitive "if":

(TAGBODY
All macros must be expanded before the source code containing them can be evaluated or compiled normally. Macros can be considered functions that accept and return S-expressions – similar to abstract syntax trees, but not limited to those. These functions are invoked before the evaluator or compiler to produce the final source code.
Macros are written in normal Common Lisp, and may use any Common Lisp (or third-party) operator available.

Common Lisp macros are capable of what is commonly called "variable capture", where symbols in the macro-expansion body coincide with those in the calling context, allowing the programmer to create macros wherein various symbols have special meaning. The term "variable capture" is somewhat misleading, because all namespaces are vulnerable to unwanted capture, including the operator and function namespace, the tagbody label namespace, catch tag, condition handler and restart namespaces.

"Variable capture" can introduce software defects. This happens in one of the following two ways:


The Scheme dialect of Lisp provides a macro-writing system which provides the referential transparency that eliminates both types of capture problem. This type of macro system is sometimes called "hygienic", in particular by its proponents (who regard macro systems which do not automatically solve this problem as unhygienic). 

In Common Lisp, macro hygiene is ensured one of two different ways.

One approach is to use gensyms: guaranteed-unique symbols which can be used in a macro-expansion without threat of capture. The use of gensyms in a macro definition is a manual chore, but macros can be written which simplify the instantiation and use of gensyms. Gensyms solve type 2 capture easily, but they are not applicable to type 1 capture in the same way, because the macro expansion cannot rename the interfering symbols in the surrounding code which capture its references. Gensyms could be used to provide stable aliases for the global symbols which the macro expansion needs. The macro expansion would use these secret aliases rather than the well-known names, so redefinition of the well-known names would have no ill effect on the macro.

Another approach is to use packages. A macro defined in its own package can simply use internal symbols in that package in its expansion. The use of packages deals with type 1 and type 2 capture.

However, packages don't solve the type 1 capture of references to standard Common Lisp functions and operators. The reason is that the use of packages to solve capture problems revolves around the use of private symbols (symbols in one package, which are not imported into, or otherwise made visible in other packages). Whereas the Common Lisp library symbols are external, and frequently imported into or made visible in user-defined packages.

The following is an example of unwanted capture in the operator namespace, occurring in the expansion of a macro:

The codice_73 macro will expand into a form which calls codice_75 which is intended to refer to the standard Common Lisp macro codice_75. However, in this context, codice_75 may have a completely different meaning, so codice_73 may not work properly.

Common Lisp solves the problem of the shadowing of standard operators and functions by forbidding their redefinition. Because it redefines the standard operator codice_75, the preceding is actually a fragment of non-conforming Common Lisp, which allows implementations to diagnose and reject it.

The "condition system" is responsible for exception handling in Common Lisp. It provides "conditions", "handler"s and "restart"s. "Condition"s are objects describing an exceptional situation (for example an error). If a "condition" is signaled, the Common Lisp system searches for a "handler" for this condition type and calls the handler. The "handler" can now search for restarts and use one of these restarts to automatically repair the current problem, using information such as the condition type and any relevant information provided as part of the condition object, and call the appropriate restart function.

These restarts, if unhandled by code, can be presented to users (as part of a user interface, that of a debugger for example), so that the user can select and invoke one of the available restarts. Since the condition handler is called in the context of the error (without unwinding the stack), full error recovery is possible in many cases, where other exception handling systems would have already terminated the current routine. The debugger itself can also be customized or replaced using the codice_80 dynamic variable. Code found within "unwind-protect" forms such as finalizers will also be executed as appropriate despite the exception.

In the following example (using Symbolics Genera) the user tries to open a file in a Lisp function "test" called from the Read-Eval-Print-LOOP (REPL), when the file does not exist. The Lisp system presents four restarts. The user selects the "Retry OPEN using a different pathname" restart and enters a different pathname (lispm-init.lisp instead of lispm-int.lisp). The user code does not contain any error handling code. The whole error handling and restart code is provided by the Lisp system, which can handle and repair the error without terminating the user code.
Command: (test ">zippy>lispm-int.lisp")

Error: The file was not found.

LMFS:OPEN-LOCAL-LMFS-1

s-A, <Resume>: Retry OPEN of lispm:>zippy>lispm-int.lisp.newest
s-B: Retry OPEN using a different pathname
s-C, <Abort>: Return to Lisp Top Level in a TELNET server
s-D: Restart process TELNET terminal

-> Retry OPEN using a different pathname
Use what pathname instead [default lispm:>zippy>lispm-int.lisp.newest]:

...the program continues

Common Lisp includes a toolkit for object-oriented programming, the Common Lisp Object System or CLOS, which is one of the most powerful object systems available in any language. For example, Peter Norvig explains how many Design Patterns are simpler to implement in a dynamic language with the features of CLOS (Multiple Inheritance, Mixins, Multimethods, Metaclasses, Method combinations, etc.).
Several extensions to Common Lisp for object-oriented programming have been proposed to be included into the ANSI Common Lisp standard, but eventually CLOS was adopted as the standard object-system for Common Lisp. CLOS is a dynamic object system with multiple dispatch and multiple inheritance, and differs radically from the OOP facilities found in static languages such as C++ or Java. As a dynamic object system, CLOS allows changes at runtime to generic functions and classes. Methods can be added and removed, classes can be added and redefined, objects can be updated for class changes and the class of objects can be changed.

CLOS has been integrated into ANSI Common Lisp. Generic functions can be used like normal functions and are a first-class data type. Every CLOS class is integrated into the Common Lisp type system. Many Common Lisp types have a corresponding class. There is more potential use of CLOS for Common Lisp. The specification does not say whether conditions are implemented with CLOS. Pathnames and streams could be implemented with CLOS. These further usage possibilities of CLOS for ANSI Common Lisp are not part of the standard. Actual Common Lisp implementations use CLOS for pathnames, streams, input–output, conditions, the implementation of CLOS itself and more.

A Lisp interpreter directly executes Lisp source code provided as Lisp objects (lists, symbols, numbers, ...) read from s-expressions. A Lisp compiler generates bytecode or machine code from Lisp source code. Common Lisp allows both individual Lisp functions to be compiled in memory and the compilation of whole files to externally stored compiled code ("fasl" files).

Several implementations of earlier Lisp dialects provided both an interpreter and a compiler. Unfortunately often the semantics were different. These earlier Lisps implemented lexical scoping in the compiler and dynamic scoping in the interpreter. Common Lisp requires that both the interpreter and compiler use lexical scoping by default. The Common Lisp standard describes both the semantics of the interpreter and a compiler. The compiler can be called using the function "compile" for individual functions and using the function "compile-file" for files. Common Lisp allows type declarations and provides ways to influence the compiler code generation policy. For the latter various optimization qualities can be given values between 0 (not important) and 3 (most important): "speed", "space", "safety", "debug" and "compilation-speed".

There is also a function to evaluate Lisp code: codice_81. codice_81 takes code as pre-parsed s-expressions and not, like in some other languages, as text strings. This way code can be constructed with the usual Lisp functions for constructing lists and symbols and then this code can be evaluated with the function codice_81. Several Common Lisp implementations (like Clozure CL and SBCL) are implementing codice_81 using their compiler. This way code is compiled, even though it is evaluated using the function codice_81.

The file compiler is invoked using the function "compile-file". The generated file with compiled code is called a "fasl" (from "fast load") file. These "fasl" files and also source code files can be loaded with the function "load" into a running Common Lisp system. Depending on the implementation, the file compiler generates byte-code (for example for the Java Virtual Machine), C language code (which then is compiled with a C compiler) or, directly, native code.

Common Lisp implementations can be used interactively, even though the code gets fully compiled. The idea of an Interpreted language thus does not apply for interactive Common Lisp.

The language makes a distinction between read-time, compile-time, load-time, and run-time, and allows user code to also make this distinction to perform the wanted type of processing at the wanted step.

Some special operators are provided to especially suit interactive development; for instance, codice_86 will only assign a value to its provided variable if it wasn't already bound, while codice_87 will always perform the assignment. This distinction is useful when interactively evaluating, compiling and loading code in a live image.

Some features are also provided to help writing compilers and interpreters. Symbols consist of first-level objects and are directly manipulable by user code. The codice_88 special operator allows to create lexical bindings programmatically, while packages are also manipulable. The Lisp compiler is available at runtime to compile files or individual functions. These make it easy to use Lisp as an intermediate compiler or interpreter for another language.

The following program calculates the smallest number of people in a room for whom the probability of unique birthdays is less than 50% (the birthday paradox, where for 1 person the probability is obviously 100%, for 2 it is 364/365, etc.). The answer is 23.

By convention, constants in Common Lisp are enclosed with + characters.

Calling the example function using the REPL (Read Eval Print Loop):

CL-USER > (birthday-paradox 1.0 1)
23

We define a class codice_89 and a method for displaying the name and age of a person.
Next we define a group of persons as a list of codice_89 objects.
Then we iterate over the sorted list.

(defparameter *group*

It prints the three names with descending age.

Bob (33)
Ash (23)
Chris (16)

Use of the LOOP macro is demonstrated:
Example use:
CL-USER > (power 2 200)
1606938044258990275541962092341162602522202993782792835301376
Compare with the built in exponentiation:
CL-USER > (= (expt 2 200) (power 2 200))
T

WITH-OPEN-FILE is a macro that opens a file and provides a stream. When the form is returning, the file is automatically closed. FUNCALL calls a function object. The LOOP collects all lines that match the predicate.
The function AVAILABLE-SHELLS calls above function LIST-MATCHING-LINES with a pathname and an anonymous function as the predicate. The predicate returns the pathname of a shell or NIL (if the string is not the filename of a shell).
Example results (on Mac OS X 10.6):
CL-USER > (available-shells)

Common Lisp is most frequently compared with, and contrasted to, Scheme—if only because they are the two most popular Lisp dialects. Scheme predates CL, and comes not only from the same Lisp tradition but from some of the same engineers—Guy L. Steele, with whom Gerald Jay Sussman designed Scheme, chaired the standards committee for Common Lisp.

Common Lisp is a general-purpose programming language, in contrast to Lisp variants such as Emacs Lisp and AutoLISP which are extension languages embedded in particular products (GNU Emacs and AutoCAD, respectively). Unlike many earlier Lisps, Common Lisp (like Scheme) uses lexical variable scope by default for both interpreted and compiled code.

Most of the Lisp systems whose designs contributed to Common Lisp—such as ZetaLisp and Franz Lisp—used dynamically scoped variables in their interpreters and lexically scoped variables in their compilers. Scheme introduced the sole use of lexically scoped variables to Lisp; an inspiration from ALGOL 68. CL supports dynamically scoped variables as well, but they must be explicitly declared as "special". There are no differences in scoping between ANSI CL interpreters and compilers.

Common Lisp is sometimes termed a "Lisp-2" and Scheme a "Lisp-1", referring to CL's use of separate namespaces for functions and variables. (In fact, CL has "many" namespaces, such as those for go tags, block names, and codice_72 keywords). There is a long-standing controversy between CL and Scheme advocates over the tradeoffs involved in multiple namespaces. In Scheme, it is (broadly) necessary to avoid giving variables names which clash with functions; Scheme functions frequently have arguments named codice_92, codice_93, or codice_94 so as not to conflict with the system function codice_95. However, in CL it is necessary to explicitly refer to the function namespace when passing a function as an argument—which is also a common occurrence, as in the codice_11 example above.

CL also differs from Scheme in its handling of boolean values. Scheme uses the special values #t and #f to represent truth and falsity. CL follows the older Lisp convention of using the symbols T and NIL, with NIL standing also for the empty list. In CL, "any" non-NIL value is treated as true by conditionals, such as codice_68, whereas in Scheme all non-#f values are treated as true. These conventions allow some operators in both languages to serve both as predicates (answering a boolean-valued question) and as returning a useful value for further computation, but in Scheme the value '() which is equivalent to NIL in Common Lisp evaluates to true in a boolean expression.

Lastly, the Scheme standards documents require tail-call optimization, which the CL standard does not. Most CL implementations do offer tail-call optimization, although often only when the programmer uses an optimization directive. Nonetheless, common CL coding style does not favor the ubiquitous use of recursion that Scheme style prefers—what a Scheme programmer would express with tail recursion, a CL user would usually express with an iterative expression in codice_75, codice_99, codice_72, or (more recently) with the codice_101 package.

See the Category .

Common Lisp is defined by a specification (like Ada and C) rather than by one implementation (like Perl). There are many implementations, and the standard details areas in which they may validly differ.

In addition, implementations tend to come with extensions, which provide functionality not covered in the standard:


Free and open-source software libraries have been created to support extensions to Common Lisp in a portable way, and are most notably found in the repositories of the Common-Lisp.net and CLOCC (Common Lisp Open Code Collection) projects.

Common Lisp implementations may use any mix of native code compilation, byte code compilation or interpretation. Common Lisp has been designed to support incremental compilers, file compilers and block compilers. Standard declarations to optimize compilation (such as function inlining or type specialization) are proposed in the language specification. Most Common Lisp implementations compile source code to native machine code. Some implementations can create (optimized) stand-alone applications. Others compile to interpreted bytecode, which is less efficient than native code, but eases binary-code portability. Some compilers compile Common Lisp code to C code. The misconception that Lisp is a purely interpreted language is most likely because Lisp environments provide an interactive prompt and that code is compiled one-by-one, in an incremental way. With Common Lisp incremental compilation is widely used.

Some Unix-based implementations (CLISP, SBCL) can be used as a scripting language; that is, invoked by the system transparently in the way that a Perl or Unix shell interpreter is.




See the Category .

Common Lisp is used to develop research applications (often in Artificial Intelligence), for rapid development of prototypes or for deployed applications.

Common Lisp is used in many commercial applications, including the Yahoo! Store web-commerce site, which originally involved Paul Graham and was later rewritten in C++ and Perl. Other notable examples include:


There also exist open-source applications written in Common Lisp, such as:


Since 2011, Zach Beane, with support of the Common Lisp Foundation, has maintained the Quicklisp library manager. It allows automatic download, installing, and loading of over 3600 libraries, all of which are required to work on more than just one implementation of Common Lisp and to have a license that allows their redistribution.

A chronological list of books published (or about to be published) about Common Lisp (the language) or about programming with Common Lisp (especially AI programming).



</doc>
<doc id="6069" url="https://en.wikipedia.org/wiki?curid=6069" title="Color code">
Color code

A color code or colour code is a system for displaying information by using different colors.

The earliest examples of color codes in use are for long distance communication by use of flags, as in semaphore communication. The United Kingdom adopted a color code scheme for such communication wherein red signified danger and white signified safety, with other colors having similar assignments of meaning.

As chemistry and other technologies advanced, it became expedient to use coloration as a signal for telling apart things that would otherwise be confusingly similar, such as wiring in electrical and electronic devices, and pharmaceutical pills.

The use of color codes has been extended to abstractions, such as the Homeland Security Advisory System color code in the United States. Similarly, hospital emergency codes often incorporate colors (such as the widely used "Code Blue" indicating a cardiac arrest), although they may also include numbers, and may not conform to a uniform standard.

Color codes do present some potential problems. On forms and signage, the use of color can distract from black and white text. They are often difficult for color blind and blind people to interpret, and even for those with normal color vision, use of many colors to code many variables can lead to use of confusingly similar colors.

Systems incorporating color-coding include:




</doc>
<doc id="6080" url="https://en.wikipedia.org/wiki?curid=6080" title="CGI">
CGI

CGI may refer to:






</doc>
<doc id="6082" url="https://en.wikipedia.org/wiki?curid=6082" title="Cortex">
Cortex

Cortex or cortical may refer to:






</doc>
<doc id="6084" url="https://en.wikipedia.org/wiki?curid=6084" title="Collection">
Collection

Collection or Collections may refer to:

Collection may also refer to:





</doc>
<doc id="6085" url="https://en.wikipedia.org/wiki?curid=6085" title="Cauchy sequence">
Cauchy sequence

In mathematics, a Cauchy sequence (; ), named after Augustin-Louis Cauchy, is a sequence whose elements become arbitrarily close to each other as the sequence progresses. More precisely, given any small positive distance, all but a finite number of elements of the sequence are less than that given distance from each other.

It is not sufficient for each term to become arbitrarily close to the term. For instance, in the sequence of square roots of natural numbers:
the consecutive terms become arbitrarily close to each other:
However, with growing values of the index , the terms become arbitrarily large, so for any index and distance , there exists an index big enough such that . (Actually, any suffices.) As a result, despite how far one goes, the remaining terms of the sequence never get close to , hence the sequence is not Cauchy.

The utility of Cauchy sequences lies in the fact that in a complete metric space (one where all such sequences are known to converge to a limit), the criterion for convergence depends only on the terms of the sequence itself, as opposed to the definition of convergence, which uses the limit value as well as the terms. This is often exploited in algorithms, both theoretical and applied, where an iterative process can be shown relatively easily to produce a Cauchy sequence, consisting of the iterates, thus fulfilling a logical condition, such as termination.

The notions above are not as unfamiliar as they might at first appear. The customary acceptance of the fact that any real number "x" has a decimal expansion is an implicit acknowledgment that a particular Cauchy sequence of rational numbers (whose terms are the successive truncations of the decimal expansion of "x") has the real limit "x". In some cases it may be difficult to describe "x" independently of such a limiting process involving rational numbers.

Generalizations of Cauchy sequences in more abstract uniform spaces exist in the form of Cauchy filters and Cauchy nets.

A sequence

of real numbers is called a Cauchy sequence if for every positive real number "ε", there is a positive integer "N" such that for all natural numbers "m", "n" > "N"

where the vertical bars denote the absolute value. In a similar way one can define Cauchy sequences of rational or complex numbers. Cauchy formulated such a condition by requiring formula_5 to be infinitesimal for every pair of infinite "m", "n".

If formula_6 is a sequence in the set formula_7, then a "modulus of Cauchy convergence" for the sequence is a function formula_8 from the set of natural numbers to itself, such that formula_9.

Any sequence with a modulus of Cauchy convergence is a Cauchy sequence. The existence of a modulus for a Cauchy sequence follows from the well-ordering property of the natural numbers (let formula_10 be the smallest possible formula_11 in the definition of Cauchy sequence, taking formula_12 to be formula_13). The existence of a modulus also follows from the principle of dependent choice, which is a weak form of the axiom of choice, and it also follows from an even weaker condition called AC. "Regular Cauchy sequences" are sequences with a given modulus of Cauchy convergence (usually formula_14 or formula_15). Any Cauchy sequence with a modulus of Cauchy convergence is equivalent to a regular Cauchy sequence; this can be proved without using any form of the axiom of choice.

Moduli of Cauchy convergence are used by constructive mathematicians who do not wish to use any form of choice. Using a modulus of Cauchy convergence can simplify both definitions and theorems in constructive analysis. Regular Cauchy sequences were used by Errett Bishop in his Foundations of Constructive Analysis, and by Douglas Bridges in a non-constructive textbook (). 

Since the definition of a Cauchy sequence only involves metric concepts, it is straightforward to generalize it to any metric space "X". 
To do so, the absolute value |"x" - "x"| is replaced by the distance "d"("x", "x") (where "d" denotes a metric) between "x" and "x".

Formally, given a metric space , a sequence

is Cauchy, if for every positive real number there is a positive integer such that for all positive integers , the distance

Roughly speaking, the terms of the sequence are getting closer and closer together in a way that suggests that the sequence ought to have a limit in "X". 
Nonetheless, such a limit does not always exist within "X": the property of a space that every Cauchy sequence converges in the space is called "completeness", and is detailed below.

A metric space ("X", "d") in which every Cauchy sequence converges to an element of "X" is called complete.

The real numbers are complete under the metric induced by the usual absolute value, and one of the standard constructions of the real numbers involves Cauchy sequences of rational numbers. In this construction, each equivalence class of Cauchy sequences of rational numbers with a certain tail behavior—that is, each class of sequences that get arbitrarily close to one another— is a real number.

A rather different type of example is afforded by a metric space "X" which has the discrete metric (where any two distinct points are at distance 1 from each other). Any Cauchy sequence of elements of "X" must be constant beyond some fixed point, and converges to the eventually repeating term.

The rational numbers Q are not complete (for the usual distance):
There are sequences of rationals that converge (in R) to irrational numbers; these are Cauchy sequences having no limit in Q. In fact, if a real number "x" is irrational, then the sequence ("x"), whose "n"-th term is the truncation to "n" decimal places of the decimal expansion of "x", gives a Cauchy sequence of rational numbers with irrational limit "x". Irrational numbers certainly exist in R, for example:


The open interval formula_21 in the set of real numbers with an ordinary distance in R is not a complete space: there is a sequence formula_22 in it, which is Cauchy (for arbitrarily small distance bound formula_23 all terms formula_24 of formula_25 fit in the formula_26 interval), however does not converge in formula_27 — its 'limit', number formula_28, does not belong to the space formula_27.


These last two properties, together with the Bolzano–Weierstrass theorem, yield one standard proof of the completeness of the real numbers, closely related to both the Bolzano–Weierstrass theorem and the Heine–Borel theorem. Every Cauchy sequence of real numbers is bounded, hence by Bolzano-Weierstrass has a convergent subsequence, hence is itself convergent. This proof of the completeness of the real numbers implicitly makes use of the least upper bound axiom. The alternative approach, mentioned above, of the real numbers as the completion of the rational numbers, makes the completeness of the real numbers tautological.

One of the standard illustrations of the advantage of being able to work with Cauchy sequences and make use of completeness is provided by consideration of the summation of an infinite series of real numbers
(or, more generally, of elements of any complete normed linear space, or Banach space). Such a series 
formula_30 is considered to be convergent if and only if the sequence of partial sums formula_31 is convergent, where 
formula_32. It is a routine matter 
to determine whether the sequence of partial sums is Cauchy or not,
since for positive integers "p" > "q", 

If formula_34 is a uniformly continuous map between the metric spaces "M" and "N" and ("x") is a Cauchy sequence in "M", then formula_35 is a Cauchy sequence in "N". If formula_36 and formula_37 are two Cauchy sequences in the rational, real or complex numbers, then the sum formula_38 and the product formula_39 are also Cauchy sequences.

There is also a concept of Cauchy sequence for a topological vector space formula_7: Pick a local base formula_41 for formula_7 about 0; then (formula_43) is a Cauchy sequence if for each member formula_44, there is some number formula_11 such that whenever 
formula_46 is an element of formula_47. If the topology of formula_7 is compatible with a translation-invariant metric formula_49, the two definitions agree.

Since the topological vector space definition of Cauchy sequence requires only that there be a continuous "subtraction" operation, it can just as well be stated in the context of a topological group: A sequence formula_50 in a topological group formula_51 is a Cauchy sequence if for every open neighbourhood formula_52 of the identity in formula_51 there exists some number formula_11 such that whenever formula_55 it follows that formula_56. As above, it is sufficient to check this for the neighbourhoods in any local base of the identity in formula_51.

As in the construction of the completion of a metric space, one can furthermore define the binary relation on Cauchy sequences in formula_51 that formula_50 and formula_60 are equivalent if for every open neighbourhood formula_52 of the identity in formula_51 there exists some number formula_11 such that whenever formula_55 it follows that formula_65. This relation is an equivalence relation: It is reflexive since the sequences are Cauchy sequences. It is symmetric since formula_66 which by continuity of the inverse is another open neighbourhood of the identity. It is transitive since formula_67 where formula_68 and formula_69 are open neighbourhoods of the identity such that formula_70; such pairs exist by the continuity of the group operation.

There is also a concept of Cauchy sequence in a group formula_51:
Let formula_72 be a decreasing sequence of normal subgroups of formula_51 of finite index.
Then a sequence formula_36 in formula_51 is said to be Cauchy (w.r.t. formula_76) if and only if for any formula_12 there is formula_11 such that formula_79.

Technically, this is the same thing as a topological group Cauchy sequence for a particular choice of topology on formula_51, namely that for which formula_76 is a local base.

The set formula_82 of such Cauchy sequences forms a group (for the componentwise product), and the set formula_83 of null sequences (s.th. formula_84) is a normal subgroup of formula_82. The factor group formula_86 is called the completion of formula_51 with respect to formula_76.

One can then show that this completion is isomorphic to the inverse limit of the sequence formula_89.

An example of this construction, familiar in number theory and algebraic geometry is the construction of the "p"-adic completion of the integers with respect to a prime "p". In this case, "G" is the integers under addition, and "H" is the additive subgroup consisting of integer multiples of "p".

If formula_76 is a cofinal sequence (i.e., any normal subgroup of finite index contains some formula_91), then this completion is canonical in the sense that it is isomorphic to the inverse limit of formula_92, where formula_76 varies over normal subgroups of finite index. For further details, see ch. I.10 in Lang's "Algebra".

A real sequence formula_94 has a natural hyperreal extension, defined for hypernatural values "H" of the index "n" in addition to the usual natural "n". The sequence is Cauchy if and only if for every infinite "H" and "K", the values formula_95 and formula_96 are infinitely close, or adequal, i.e. 
where "st" is the standard part function.

 introduced a notion of Cauchy completion of a category. Applied to Q (the category whose objects are rational numbers, and there is a morphism from "x" to "y" if and only if "x" ≤ "y"), this Cauchy completion yields R (again interpreted as a category using its natural ordering).




</doc>
<doc id="6088" url="https://en.wikipedia.org/wiki?curid=6088" title="Common Era">
Common Era

Common Era (CE) is one of the notation systems for the world's most widely used calendar era. BCE (Before the Common Era or Before the Current Era) is the era before CE. BCE and CE are alternatives to the Dionysian BC and AD system respectively. The Dionysian era distinguishes eras using BC ("before Christ") and AD (", "in [the] year of [the] Lord"). The two notation systems are numerically equivalent: " CE" and "AD " each describe the current year; "400 BCE" and "400 BC" are each the same year. Both notations refer to the Gregorian calendar (and its predecessor, the Julian calendar). The year-numbering system used by the Gregorian calendar is used throughout the world today, and is an international standard for civil calendars.

The expression has been traced back to 1615, when it first appeared in a book by Johannes Kepler as the Latin ", and to 1635 in English as "Vulgar Era". The term "Common Era" can be found in English as early as 1708, and became more widely used in the mid-19th century by Jewish religious scholars. In the later 20th century, the use of CE and BCE was popularized in academic and scientific publications as a culturally neutral term. It is also used by some authors and publishers who wish to emphasize sensitivity to non-Christians by not explicitly referencing Jesus as "Christ" and "Dominus" ("Lord") through use of the abbreviation "AD".

The year numbering system used with Common Era notation was devised by the Christian monk Dionysius Exiguus in the year 525 to replace the Era of Martyrs system, because he did not wish to continue the memory of a tyrant who persecuted Christians. He attempted to number years from an initial reference date ("epoch"), an event he referred to as the Incarnation of Jesus. Dionysius labeled the column of the table in which he introduced the new era as ""Anni Domini Nostri Jesu Christi"".

This way of numbering years became more widespread in Europe with its use by Bede in England in 731. Bede also introduced the practice of dating years before what he supposed was the year of birth of Jesus, and the practice of not using a year zero. In 1422, Portugal became the last Western European country to switch to the system begun by Dionysius.

The term "Common Era" is traced back in English to its appearance as "Vulgar Era" to distinguish dates on the Ecclesiastic calendar in popular use from dates of the regnal year, the year of reign of a sovereign, typically used in national law. (The word 'vulgar' originally meant 'of the ordinary people', with no derogatory associations.)

The first use of the Latin term "anno aerae nostrae vulgaris" discovered so far was in a 1615 book by Johannes Kepler. Kepler uses it again, as "ab Anno vulgaris aerae", in a 1616 table of ephemerides, and again, as "ab anno vulgaris aerae", in 1617. A 1635 English edition of that book has the title page in English – so far, the earliest-found use of "Vulgar Era" in English. A 1701 book edited by John LeClerc includes "Before Christ according to the Vulgar Æra, 6". A 1716 book in English by Dean Humphrey Prideaux says, "before the beginning of the vulgar æra, by which we now compute the years from his incarnation." A 1796 book uses the term "vulgar era of the nativity".

The first known use of "Christian Era" is as the Latin phrase "annus aerae christianae" on the title page of a 1584 theology book. In 1649, the Latin phrase "annus æræ Christianæ" appeared in the title of an English almanac. A 1652 ephemeris is the first instance found so far of the English use of "Christian Era".

The English phrase "common Era" appears at least as early as 1708, and in a 1715 book on astronomy it is used interchangeably with "Christian Era" and "Vulgar Era". A 1759 history book uses "common æra" in a generic sense, to refer to the common era of the Jews. The first use found so far of the phrase "before the common era" is in a 1770 work that also uses "common era" and "vulgar era" as synonyms, in a translation of a book originally written in German. The 1797 edition of the Encyclopædia Britannica uses the terms "vulgar era" and "common era" synonymously. In 1835, in his book "Living Oracles", Alexander Campbell, wrote: "The vulgar Era, or Anno Domini; the fourth year of Jesus Christ, the first of which was but eight days", and also refers to the "common era" as a synonym for "vulgar era" with "the fact that our Lord was born on the 4th year before the vulgar era, called Anno Domini, thus making (for example) the 42d year from his birth to correspond with the 38th of the common era..." The "Catholic Encyclopedia" (1909) in at least one article reports all three terms (Christian, Vulgar, Common Era) being commonly understood by the early 20th century.

The phrase "common era", in lower case, also appeared in the 19th century in a "generic" sense, not necessarily to refer to the Christian Era, but to any system of dates in common use throughout a civilization. Thus, "the common era of the Jews", "the common era of the Mahometans", "common era of the world", "the common era of the foundation of Rome". When it did refer to the Christian Era, it was sometimes qualified, e.g., "common era of the Incarnation", "common era of the Nativity", or "common era of the birth of Christ".

An adapted translation of "Common Era" into Latin as "Era Vulgaris" ("era" or, with a macron, "ēra" being an alternative form of "aera"; "aera" is the usual form) was adopted in the 20th century by some followers of Aleister Crowley, and thus the abbreviation "e.v." or "EV" may sometimes be seen as a replacement for AD.

Although Jews have their own Hebrew calendar, they often use the Gregorian calendar, without the AD prefix. As early as 1825, the abbreviation VE (for Vulgar Era) was in use among Jews to denote years in the Western calendar. As of 2005, Common Era notation has also been in use for Hebrew lessons for more than a century. In 1856, Rabbi and historian Morris Jacob Raphall used the abbreviations CE and BCE in his book "Post-Biblical History of The Jews". Jews have also used the term Current Era.

Some academics in the fields of theology, education, archaeology and history have adopted CE and BCE notation, although there is some disagreement. Several style guides now prefer or mandate its use.
The style guide for the Episcopal Diocese "Maryland Church News" says that BCE and CE should be used.

In the United States, the use of the BCE/CE notation in textbooks was reported in 2005 to be growing. Some publications have moved over to using it exclusively. For example, the 2007 World Almanac was the first edition to switch over to BCE/CE, ending a period of 138 years in which the traditional BC/AD dating notation was used. BCE/CE is used by the College Board in its history tests, and by the Norton Anthology of English Literature. Others have taken a different approach. The US-based History Channel uses BCE/CE notation in articles on non-Christian religious topics such as Jerusalem and Judaism.

In 2002, an advisory panel for the religious education syllabus for England and Wales recommended introducing BCE/CE dates to schools, and by 2018 some local education authorities were using them. In 2018, the National Trust said it would continue to use BC/AD as its house style. English Heritage explains its era policy thus: "It might seem strange to use a Christian calendar system when referring to British prehistory, but the BC/AD labels are widely used and understood." Some parts of the BBC use BCE/CE, but some presenters have said they will not. As at October 2019, the BBC News style guide has entries for AD and BC, but not for CE or BCE. 

In June 2006, in the United States, the Kentucky State School Board reversed its decision to use BCE and CE in the state's new Program of Studies, leaving education of students about these concepts a matter of discretion at the local level.

Also in 2011, media reports suggested that the BC/AD notation in Australian school textbooks would be replaced by BCE/CE notation. The story became national news and drew opposition from some politicians and church leaders. Weeks after the story broke, the Australian Curriculum, Assessment and Reporting Authority denied the rumour and stated that the BC/AD notation would remain, with CE and BCE as an optional suggested learning activity.

In 2013 the Canadian Museum of Civilization (now the Canadian Museum of History) in Ottawa, which had previously switched to BCE/CE, decided to change back to BC/AD in material intended for the public, while retaining BCE/CE in academic content.

The style guide for The Guardian says, under the entry for CE/BCE: "some people prefer CE (common era, current era, or Christian era) and BCE (before common era, etc) to AD and BC, which, however, remain our style".

The use of CE in Jewish scholarship was historically motivated by the desire to avoid the implicit "Our Lord" in the abbreviation "AD". Although other aspects of dating systems are based in Christian origins, AD is a direct reference to Jesus as Lord.

Proponents of the Common Era notation assert that the use of BCE/CE shows sensitivity to those who use the same year numbering system as the one that originated with and is currently used by Christians, but who are not themselves Christian.

Former United Nations Secretary-General Kofi Annan has argued:

[T]he Christian calendar no longer belongs exclusively to Christians. People of all faiths have taken to using it simply as a matter of convenience. There is so much interaction between people of different faiths and cultures – different civilizations, if you like – that some shared way of reckoning time is a necessity. And so the Christian Era has become the Common Era.

Adena K. Berkowitz, when arguing at the Supreme Court, opted to use BCE and CE because "Given the multicultural society that we live in, the traditional Jewish designations – B.C.E. and C.E. – cast a wider net of inclusion".

Some oppose the Common Era notation for explicitly religious reasons. Because the BC/AD notation is based on the traditional year of the conception or birth of Jesus, some Christians are offended by the removal of the reference to him in era notation. The Southern Baptist Convention supports retaining the BC/AD abbreviations. Roman Catholic priest and writer on interfaith issues Raimon Panikkar argued that the BCE/CE usage is the less inclusive option as, in his view, using the designation BCE/CE is a "return... to the most bigoted Christian colonialism" towards non-Christians, who do not necessarily consider the time period following the beginning of the calendar to be a "common era".

There are also secular concerns. In 1993 the English language expert Kenneth G. Wilson speculated in his style guide that "if we do end by casting aside the AD/BC convention, almost certainly some will argue that we ought to cast aside as well the conventional numbering system [that is, the method of numbering years] itself, given its Christian basis." The short lived French Republican Calendar, for example, began with the first year of the French First Republic and rejected the seven-day week (with its connections to the Book of Genesis) for a ten-day week.

According to a "Los Angeles Times" report, it was a student's use of BCE/CE notation, inspired by its use within Wikipedia, which prompted the teacher and politician Andrew Schlafly to found Conservapedia, a cultural conservative wiki. One of its "Conservapedia Commandments" is that users must always apply BC/AD notation, since its sponsors perceive BCE/CE notation to "deny the historical basis" of the dating system.

The abbreviation BCE, just as with BC, always follows the year number. Unlike AD, which traditionally precedes the year number, CE always follows the year number (if context requires that it be written at all). Thus, the current year is written as in both notations (or, if further clarity is needed, as CE, or as AD ), and the year that Socrates died is represented as 399 BCE (the same year that is represented by 399 BC in the BC/AD notation). The abbreviations are sometimes written with small capital letters, or with periods (e.g., "B.C.E." or "C.E."). The US-based Society of Biblical Literature style guide for academic texts on religion prefers BCE/CE to BC/AD.





</doc>
<doc id="6091" url="https://en.wikipedia.org/wiki?curid=6091" title="Charles Robert Malden">
Charles Robert Malden

Charles Robert Malden (9 August 1797 – 23 May 1855), was a nineteenth-century British naval officer, surveyor and educator. He is the discoverer of Malden Island in the central Pacific, which is named in his honour. He also founded Windlesham House School at Brighton, England.

Malden was born in Putney, Surrey, son of Jonas Malden, a surgeon. He entered British naval service at the age of 11 on 22 June 1809. He served nine years as a volunteer 1st class, midshipman, and shipmate, including one year in the English Channel and Bay of Biscay (1809), four years at the Cape of Good Hope and in the East Indies (1809–14), two and a half years on the North American and West Indian stations (1814–16), and a year and a half in the Mediterranean (1817–18). He was present at the capture of Mauritius and Java, and at the battles of Baltimore and New Orleans.

He passed the examination in the elements of mathematics and the theory of navigation at the Royal Naval Academy on 2–4 September 1816, and became a 1st Lieutenant on 1 September 1818. In eight years of active service as an officer, he served two and a half years in a surveying ship in the Mediterranean (1818–21), one and a half years in a surveying sloop in the English Channel and off the coast of Ireland (1823–24), and one and a half years as Surveyor of the frigate during a voyage (1824–26) to and from the Hawaiian Islands (then known as the "Sandwich islands").
In Hawaii he surveyed harbours which, he noted, were "said not to exist by Captains Cook and Vancouver." On the return voyage he discovered and explored uninhabited Malden Island in the central Pacific on 30 July 1825. After his return he left active service but remained at half pay. He served for several years as hydrographer to King William IV.

He married Frances Cole, daughter of Rev. William Hodgson Cole, rector of West Clandon and Vicar of Wonersh, near Guildford, Surrey, on 8 April 1828. Malden became the father of seven sons and a daughter.

From 1830-36 he took pupils for the Royal Navy at Ryde, Isle of Wight. He purchased the school of Henry Worsley at Newport, Isle of Wight, in December 1836, reopened it as a preparatory school on 20 February 1837, and moved it to Montpelier Road in Brighton in December 1837. He built the Windlesham House School at Brighton in 1844, and conducted the school until his death there in 1855.


</doc>
<doc id="6094" url="https://en.wikipedia.org/wiki?curid=6094" title="CPD">
CPD

CPD may refer to:







</doc>
<doc id="6095" url="https://en.wikipedia.org/wiki?curid=6095" title="Chechnya">
Chechnya

Chechnya (; ; , ), officially the Chechen Republic (; ; , ), is a federal subject (a republic) of the Russian Federation.

It is located in the North Caucasus, and within of the Caspian Sea. The capital of the republic is the city of Grozny. , the republic was reported to have a population of 1,268,989 people.

After the dissolution of the Soviet Union in 1991, the Chechen-Ingush ASSR was split into two parts: the Republic of Ingushetia and the Chechen Republic. The latter proclaimed the Chechen Republic of Ichkeria, which sought independence. Following the First Chechen War with Russia, Chechnya gained "de facto" independence as the Chechen Republic of Ichkeria. Russian federal control was restored during the Second Chechen War. Since then there has been a systematic reconstruction and rebuilding process, though sporadic fighting continued to take place in the mountains and southern regions until 2019.

According to Leonti Mroveli, the 11th-century Georgian chronicler, the word Caucasian is derived from the Vainakh ancestor Kavkas.
According to George Anchabadze of Ilia State University American linguist Johanna Nichols "has used language to connect the modern people of the Caucasus region to the ancient farmers of the Fertile Crescent" and her research suggests that "farmers of the region were proto-Nakh-Daghestanians." Nichols stated: "The Nakh–Dagestanian languages are the closest thing we have to a direct continuation of the cultural and linguistic community which gave rise to Western civilisation." Henry Harpending of the University of Utah supports her claims.

Traces of human settlement dating back to 40,000 BC were found near Lake Kezanoi. Cave paintings, artefacts, and other archaeological evidence indicates continuous habitation for some 8,000 years. People living in these settlements used tools, fire, animal skins as clothing.

The Caucasian Epipaleolithic and early Caucasian Neolithic era, saw the introduction of agriculture, irrigation, and the domestication of animals in the region. Settlements near Ali-Yurt and Magas, discovered in modern times, revealed tools made out of stone: stone axes, polished stones, stone knives, stones with holes drilled in them, clay dishes etc. Settlements made out of clay bricks were discovered in the plains. In the mountains there were settlements made from stone and surrounded by walls; some of them dated back to 8000 BC. This period also saw the invention of the wheel (3000 BC), horseback riding, metal works (copper, gold, silver, iron), dishes, armour, daggers, knives, arrow tips. The artefacts were found near Nasare-Cort, Muzhichi, Ja-E-Bortz (also known as Surkha-khi), Abbey-Gove (also known as Nazran or Nasare)

From 900–1200, the kingdom in the centre of the Caucasus was split into Alania and Noble Alania (Russian Царственные Аланы). The German scientist Peter Simon Pallas believed that Ingush people (Kist) were the direct descendants from Alania. In 1239, the Alania capital of Maghas was destroyed and Alan confederacy of the Northern Caucasian highlanders, nations, and tribes by Batu Khan (a Mongol leader and a grandson of Genghis Khan) "Magas was destroyed in the beginning of 1239 by the hordes of Batu Khan. Historically Magas was located at approximately the same place on which the new capital of Ingushetia is now built" – D.V.Zayats

In 1300–1400, there was frequent warfare between the Alans, Tamerlan, Tokhtamysh, culminating in the Battle of the Terek River. The Alan tribes built fortresses, castles, and defensive walls protecting the mountains from the invaders. Part of the lowland tribes were occupied by Mongols. The insurgency against Mongols began.

In 1991 the Jordanian historian Abdul-Ghani Khassan presented a photocopy from old Arabic scripts claiming that Alania was in Chechnya and Ingushetia, and the document from Alanian historian Azdin Vazzar (1395–1460) who claimed to be from Nokhcho (Chechen) tribe of Alania.

The 16th century saw the first Russian involvement in the Caucasus. 1558 Temryuk of Kabarda sent his emissaries to Moscow requesting help from Ivan the Terrible against the Vainakh tribes. Ivan the Terrible married Temryuk's daughter Maria Temryukovna. An alliance was formed to gain the ground in the central Caucasus for the expanding Tsardom of Russia against stubborn Vainakh defenders. Chechnya was a nation in the Northern Caucasus that fought against foreign rule continually since the 15th century. The Chechens converted over the next few centuries to Sunni Islam, as Islam was associated with resistance to Russian encroachment.

Peter I first sought to increase Russia's political influence in the Caucasus and the Caspian Sea at the expense of Safavid Persia when he launched the Russo-Persian War (1722–1723). Notable in Chechen history, this particular Russo-Persian War marked the first military encounter between Imperial Russia and the Vainakh. Russian forces succeeded in taking much of the Caucasian territories from Iran for several years.

As the Russians took control of the Caspian corridor and moved into Persian-ruled Dagestan, Peter's forces ran into mountain tribes. Peter sent a cavalry force to subdue them, but the Chechens routed them. In 1732, after Russia already ceded back most of the Caucasus to Persia, now led by Nader Shah, following the Treaty of Resht, Russian troops clashed again with Chechens in a village called Chechen-aul along the Argun River. The Russians were defeated again and withdrew, but this battle is responsible for the apocryphal story about how the Nokchi came to be known as "Chechens"-the people ostensibly named for the place the battle had taken place. The name Chechen was however already used since as early as 1692.

Under intermittent Persian rule since 1555, in 1783 the eastern Georgians of Kartl-Kakheti led by Erekle II and Russia signed the Treaty of Georgievsk. According to this treaty, Kartl-Kakheti received protection from Russia, and Georgia abjured any dependence on Iran. In order to increase its influence in the Caucasus and to secure communications with Kartli and other minority Christian regions of the Transcaucasia which it considered useful in its wars against Persia and Turkey, the Russian Empire began conquering the Northern Caucasus mountains. The Russian Empire used Christianity to justify its conquests, allowing Islam to spread widely because it positioned itself as the religion of liberation from tsardom, which viewed Nakh tribes as "bandits". The rebellion was led by Mansur Ushurma, a Chechen Naqshbandi (Sufi) sheikh—with wavering military support from other North Caucasian tribes. Mansur hoped to establish a Transcaucasus Islamic state under shari'a law. He was unable to fully achieve this because in the course of the war he was betrayed by the Ottomans, handed over to Russians, and executed in 1794.

Following the forced ceding of the current territories of Dagestan, most of Azerbaijan, and Georgia by Persia to Russia, following the Russo-Persian War (1804–1813) and its resultant Treaty of Gulistan, Russia significantly widened its foothold in the Caucasus at the expense of Persia. Another successful Caucasus war against Persia several years later, starting in 1826 and ending in 1828 with the Treaty of Turkmenchay, and a successful war against Ottoman Turkey in 1828, enabled Russia to use a much larger portion of its army in subduing the natives of the North Caucasus.

The resistance of the Nakh tribes never ended and was a fertile ground for a new Muslim-Avar commander, Imam Shamil, who fought against the Russians from 1834 to 1859 (see Murid War). In 1859, Shamil was captured by Russians at aul Gunib. Shamil left Boysangur Benoiski, a Chechen with one arm, one eye, and one leg, in charge of command at Gunib. Benoiski broke through the siege and continued to fight Russia for another two years until he was captured and killed by Russians. The Russian tsar hoped that by sparing the life of Shamil, the resistance in the North Caucasus would stop, but it did not. Russia began to use a colonisation tactic by destroying Nakh settlements and building Cossack defense lines in the lowlands. The Cossacks suffered defeat after defeat and were constantly attacked by mountaineers, who were robbing them of food and weaponry.

The tsarists' regime used a different approach at the end of the 1860s. They offered Chechens and Ingush to leave the Caucasus for the Ottoman Empire (see Muhajir (Caucasus)). It is estimated that about 80% of Chechens and Ingush left the Caucasus during the deportation. It weakened the resistance which went from open warfare to insurgent warfare. One of the notable Chechen resistance fighters at the end of the 19th century was a Chechen abrek Zelimkhan Gushmazukaev and his comrade-in-arms Ingush abrek Sulom-Beck Sagopshinski. Together they built up small units which constantly harassed Russian military convoys, government mints, and government post-service, mainly in Ingushetia and Chechnya. Ingush aul Kek was completely burned when the Ingush refused to hand over Zelimkhan. Zelimkhan was killed at the beginning of the 20th century. The war between Nakh tribes and Russia resurfaced during the times of the Russian Revolution, which saw the Nakh struggle against Anton Denikin and later against the Soviet Union.

On December 21, 1917, Ingushetia, Chechnya, and Dagestan declared independence from Russia and formed a single state: "United Mountain Dwellers of the North Caucasus" (also known as the Mountainous Republic of the Northern Caucasus) which was recognised by major world powers. The capital of the new state was moved to Temir-Khan-Shura (Dagestan). Tapa Tchermoeff, a prominent Chechen statesman, was elected the first prime minister of the state. The second prime minister elected was Vassan-Girey Dzhabagiev, an Ingush statesman, who also was the author of the constitution of the republic in 1917, and in 1920 he was re-elected for the third term. In 1921 the Russians attacked and occupied the country and forcefully absorbed it into the Soviet state. The Caucasian war for independence restarted, and the government went into exile.

During Soviet rule, Chechnya and Ingushetia were combined to form Checheno-Ingush Autonomous Soviet Socialist Republic. In the 1930s Chechnya was flooded with many Ukrainians fleeing the Holodomor. As a result, many of the Ukrainians settled in Chechen-Ingush ASSR permanently and survived the famine. 
Although over 50,000 Chechens and over 12,000 Ingush were fighting against Nazi Germany on the front line (including heroes of the USSR: Abukhadzhi Idrisov, Khanpasha Nuradilov, Movlid Visaitov), and although Nazi German troops were fought to a complete stop at two Chechen-Ingush ASSR cities Malgobek and Ordzhonikidze (renamed to Vladikavkaz) after capturing half of the Caucasus in less than a month; Chechens and Ingush were falsely accused as Nazi supporters and entire nations were deported during Operation Lentil to the Kazakh SSR (later Kazakhstan) in 1944 near the end of World War II where over 60% of Chechen and Ingush populations perished. American historian Norman Naimark writes: The deportation was supposedly justified by the materials prepared by notorious NKVD officer Bogdan Kobulov accusing Chechens and Ingush in a mass conspiracy preparing rebellion and providing assistance to the German forces. Many of the materials were later proved to be fabricated. Even distinguished Red Army officers who fought bravely against Germans (e.g. the commander of 255th Separate Chechen-Ingush regiment Movlid Visaitov, the first to contact American forces at Elbe river) were deported. There is a theory that the real reason why Chechens and Ingush were deported is the desire of Russia to attack Turkey, a non-communist country, as Chechens and Ingush could impede such plans. In 2004, the European Parliament recognised the deportation of Chechens and Ingush as an act of genocide.

The territory of the Chechen-Ingush Autonomous Soviet Socialist Republic was divided between Stavropol Krai (where Grozny Okrug was formed), the Dagestan ASSR, the North Ossetian ASSR, and the Georgian SSR.

The Chechens and Ingush were allowed to return to their land after 1956 during de-Stalinisation under Nikita Khrushchev when Chechen-Ingush Autonomous Soviet Socialist Republic was restored but both boundaries and ethnic composition of the territory significantly changed. There were many (predominantly Russian) migrants from other parts of the Soviet Union, who often settled in the abandoned family homes of Chechens and Ingushes. The republic lost its Prigorodny District which transferred to North Ossetian ASSR but gained predominantly Russian Naursky District and Shelkovskoy District that is considered the homeland for Terek Cossacks.

The Russification policies towards Chechens continued after 1956, with Russian language proficiency required in many aspects of life to provide Chechens better opportunities for advancement in the Soviet system.

On November 26, 1990, the Supreme Council of Chechen-Ingush ASSR adopted the "Declaration of State Sovereignty of the Chechen-Ingush Republic". This declaration was part of the reorganisation of the Soviet Union. This new treaty would have been signed August 22, 1991, which would have transformed 15 republic states into more than 80. The August 19–21, 1991 Soviet coup d'état attempt led to the abandonment of this reorganisation.

With the impending dissolution of the Soviet Union in 1991, an independence movement, the Chechen National Congress, was formed, led by ex-Soviet Air Force general and new Chechen President Dzhokhar Dudayev. It campaigned for the recognition of Chechnya as a separate nation. This movement was opposed by Boris Yeltsin's Russian Federation, which argued that Chechnya had not been an independent entity within the Soviet Union—as the Baltic, Central Asian, and other Caucasian States had—but was part of the Russian Soviet Federative Socialist Republic and hence did not have a right under the Soviet constitution to secede. It also argued that other republics of Russia, such as Tatarstan, would consider seceding from the Russian Federation if Chechnya were granted that right. Finally, it argued that Chechnya was a major hub in the oil infrastructure of Russia and hence its secession would hurt the country's economy and energy access.

In the ensuing decade, the territory was locked in an ongoing struggle between various factions, usually fighting unconventionally and forgoing the position held by the several successive Russian governments through the current administration.

The First Chechen War took place from 1994 to 1996, when Russian forces attempted to regain control over Chechnya, which had declared independence in November 1991. Despite overwhelming numerical superiority in men, weaponry, and air support, the Russian forces were unable to establish effective permanent control over the mountainous area due to numerous successful full-scale battles and insurgency raids. In three months, Russia lost more tanks (over 1,997 tanks) in Grozny than during the Battle of Berlin in 1945.
The Budyonnovsk hospital hostage crisis in 1995 shocked the Russian public and led to international condemnation of the Chechen rebels.

In April 1996 the first democratically elected president of Chechnya, Dzhokhar Dudayev, was killed by Russian forces using a booby trap bomb and a missile fired from a warplane after he was located by triangulating the position of a satellite phone he was using.

The widespread demoralisation of the Russian forces in the area and a successful offensive to re-take Grozny by Chechen rebel's forces led by Aslan Maskhadov prompted Russian President Boris Yeltsin to declare a ceasefire in 1996, and sign a peace treaty a year later that saw a withdrawal of Russian forces.

After the war, parliamentary and presidential elections took place in January 1997 in Chechnya and brought to power new President Aslan Maskhadov, chief of staff and prime minister in the Chechen coalition government, for a five-year term. Maskhadov sought to maintain Chechen sovereignty while pressing the Russian government to help rebuild the republic, whose formal economy and infrastructure were virtually destroyed. Russia continued to send money for the rehabilitation of the republic; it also provided pensions and funds for schools and hospitals. Most of these funds were taken by Chechen authorities and divided between favoured warlords. Nearly half a million people (40% of Chechnya's prewar population) had been internally displaced and lived in refugee camps or overcrowded villages. There was an economic downturn. Two Russian brigades were permanently stationed in Chechnya.

In lieu of the devastated economic structure, kidnapping emerged as the principal source of income countrywide, procuring over US$200 million during the three-year independence of the chaotic fledgling state, although victims were rarely killed. In 1998, 176 people were kidnapped, 90 of whom were released, according to official accounts. President Maskhadov started a major campaign against hostage-takers, and on October 25, 1998, Shadid Bargishev, Chechnya's top anti-kidnapping official, was killed in a remote-controlled car bombing. Bargishev's colleagues then insisted they would not be intimidated by the attack and would go ahead with their offensive. Political violence and religious extremism, blamed on "Wahhabism", was rife. In 1998, Grozny authorities declared a state of emergency. Tensions led to open clashes between the Chechen National Guard and Islamist militants, such as the July 1998 confrontation in Gudermes.

The War of Dagestan began on August 7, 1999, during which the Islamic International Brigade (IIPB) began an unsuccessful incursion into the neighbouring Russian republic of Dagestan in favour of the Shura of Dagestan which sought independence from Russia. In September, a series of apartment bombs that killed around 300 people in several Russian cities, including Moscow, were blamed on the Chechen separatists. Some journalists contested the official explanation, instead blaming the Russian Secret Service for blowing up the buildings to initiate a new military campaign against Chechnya. In response to the bombings, a prolonged air campaign of retaliatory strikes against the Ichkerian regime and a ground offensive that began in October 1999 marked the beginning of the Second Chechen War. Much better organised and planned than in the first Chechen War, the Russian armed forces took control of most regions. The Russian forces used brutal force, killing 60 Chechen civilians during a mop-up operation in Aldy, Chechnya on February 5, 2000. After the re-capture of Grozny in February 2000, the Ichkerian regime fell apart.

Chechen rebels continued to fight Russian troops and conduct terrorist attacks. In October 2002, 40–50 Chechen rebels seized a Moscow theatre and took about 900 civilians hostage. The crisis ended with 117 hostages and up to 50 rebels dead, mostly due to an unknown aerosol pumped into the building by Russian special forces to incapacitate the people inside.

In response to the increasing terrorism, Russia tightened its grip on Chechnya and expanded its anti-terrorist operations throughout the region. Russia installed a pro-Russian Chechen regime. In 2003, a referendum was held on a constitution that reintegrated Chechnya within Russia but provided limited autonomy. According to the Chechen government, the referendum passed with 95.5% of the votes and almost 80% turnout. The Economist was skeptical of the results, arguing that "few outside the Kremlin regard the referendum as fair".

In September 2004, separatist rebels occupied a school in the town of Beslan, North Ossetia, demanding recognition of the independence of Chechnya and a Russian withdrawal. 1,100 people (including 777 children) were taken hostage. The attack lasted three days, resulting in the deaths of over 331 people, including 186 children. After the 2004 school siege, Russian president Vladimir Putin announced sweeping security and political reforms, sealing borders in the Caucasus region and revealing plans to give the central government more power. He also vowed to take tougher action against domestic terrorism, including preemptive strikes against Chechen separatists. In 2005 and 2006, separatist leaders Aslan Maskhadov and Shamil Basayev were killed.

Since 2007, Chechnya has been governed by Ramzan Kadyrov. Kadyrov's rule has been characterised by high-level corruption, a poor human rights record, widespread use of torture, and a growing cult of personality. Allegations of Anti-gay purges in Chechnya were initially reported on 1 April 2017.

In April 2009, Russia ended its counter-terrorism operation and pulled out the bulk of its army. The insurgency in the North Caucasus continued even after this date. The Caucasus Emirate has fully adopted the tenets of a Salafist jihadist group through its strict adherence to the Sunni Hanbali obedience to the literal interpretation of the Quran and the Sunnah.

Situated in the eastern part of the North Caucasus, partially in Eastern Europe, Chechnya is surrounded on nearly all sides by Russian Federal territory. In the west, it borders North Ossetia and Ingushetia, in the north, Stavropol Krai, in the east, Dagestan, and to the south, Georgia. Its capital is Grozny.

Rivers:


The Chechen Republic is divided into 15 districts and 3 cities of republican significance.

There are no true districts of Chechnya, but many believe that the different dialects of the Chechen language define different districts. The main dialects are:
Grozny, also known as the Dzhokhar dialect, is the dialect of people who live in and in some towns around Grozny.
Naskhish, a dialect spoken to the northeast of Chechnya. The most notable difference in this dialect is the addition of the letters "ȯ", "ј" and "є"
Day, pronounced like the word 'die' is spoken in a small section of the south, around and in the town of Day.

There are other dialects which are believed to define districts, but because these areas are so isolated, not much research has been done on these areas.

According to the 2010 Census, the population of the republic is 1,268,989, up from 1,103,686 recorded in the 2002 Census. That number has been questioned by demographers, who think such population growth after two deadly wars is highly implausible.

As of the 2010 Census, Chechens at 1,206,551 make up 95.3% of the republic's population. Other groups include Russians (24,382, or 1.9%), Kumyks (12,221, or 1%), Ingush (1,296 or 0.1%) and a host of smaller groups, each accounting for less than 0.5% of the total population. The Armenian community, which used to number around 15,000 in Grozny alone, has dwindled to a few families. The Armenian church of Grozny was demolished in 1930. The birth rate was 25.41 in 2004. (25.7 in Achkhoi Martan, 19.8 in Groznyy, 17.5 in Kurchaloi, 28.3 in Urus Martan and 11.1 in Vedeno). According to the Chechen State Statistical Committee, Chechnya's population had grown to 1.205 million in January 2006.

At the end of the Soviet era, ethnic Russians (including Cossacks) comprised about 23% of the population (269,000 in 1989).

According to some Russian sources, from 1991 to 1994 tens of thousands of people of non-Chechen ethnicity (mostly Russians, Ukrainians, and Armenians) left the republic amidst reports of violence and discrimination against the non-Chechen population, as well as widespread lawlessness and ethnic cleansing under the government of Dzhokhar Dudayev. However, Russian economists Boris Lvin and Andrei Iliaronov believe emigration of the Russian-speaking population from Chechnya was no more intense than that from Kalmykia, Tuva and Sakha-Yakutia.

The languages used in the Republic are Chechen and Russian. Chechen belongs to the Vaynakh or North-central Caucasian language family, which also includes Ingush and Batsb. Some scholars place it in a wider North Caucasian languages.

Note: TFR 2009–12 source.

Islam is the predominant religion in Chechnya, practised by 95% of those polled in Grozny in 2010. Chechens are overwhelmingly adherents to the Shafi'i Madhhab of Sunni Islam, the republic having converted to Islam between the 16th and the 19th centuries. Due to historical importance, many Chechens are Sufis, of either the Qadiri or Naqshbandi orders. Most of the population follows either the Shafi'i or the Hanafi, schools of jurisprudence, fiqh. The Shafi'i school of jurisprudence has a long tradition among the Chechens, and thus it remains the most practised.

Following the end of the Soviet Union, there has been an Islamic revival in Chechnya, and in 2011 it was estimated that there were 465 mosques, including the Akhmad Kadyrov Mosque in Grozny accommodating 10,000 worshipers, as well 31 madrasas, including an Islamic university named Kunta-haji and a Centre of Islamic Medicine in Grozny which is the largest such institution in Europe.

On 19 January 2015, 12 days after the Charlie Hebdo shooting, a march took place in Grozny against the publication of caricatures of the prophet Mohammed. The Chechen Ministry of Interior reported that more than a million people participated, while according to the sources of Caucasian Knot the number was between 350,000 and 500,000.

The once-strong Russian minority in Chechnya, mostly Terek Cossacks and estimated as numbering approximately 25,000 in 2012, are predominantly Russian Orthodox, although presently only one church exists in Grozny. In August 2011, Archbishop Zosima of Vladikavkaz and Makhachkala performed the first mass baptism ceremony in the history of the Chechen Republic in the Terek River of Naursky District in which 35 citizens of Naursky and Shelkovsky districts were converted to Orthodoxy.

Since 1990, the Chechen Republic has had many legal, military, and civil conflicts involving separatist movements and pro-Russian authorities. Today, Chechnya is a relatively stable federal republic, although there is still some separatist movement activity. Its regional constitution entered into effect on April 2, 2003, after an all-Chechen referendum was held on March 23, 2003. Some Chechens were controlled by regional teips, or clans, despite the existence of pro- and anti-Russian political structures.

The former separatist religious leader (mufti) Akhmad Kadyrov, looked upon as a traitor by many separatists, was elected president with 83% of the vote in an internationally monitored election on October 5, 2003. Incidents of ballot stuffing and voter intimidation by Russian soldiers and the exclusion of separatist parties from the polls were subsequently reported by the Organisation for Security and Co-operation in Europe (OSCE) monitors. On May 9, 2004, Kadyrov was assassinated in Grozny football stadium by a landmine explosion that was planted beneath a VIP stage and detonated during a parade, and Sergey Abramov was appointed to the position of acting prime minister after the incident. However, since 2005 Ramzan Kadyrov (son of Akhmad Kadyrov) has been the caretaker prime minister, and in 2007 was appointed as the new president. Many allege he is the wealthiest and most powerful man in the republic, with control over a large private militia referred to as the "Kadyrovtsy". The militia, which began as his father's security force, has been accused of killings and kidnappings by human rights organisations such as Human Rights Watch.

In 2009, the US government financed American organization Freedom House included Chechnya in the "Worst of the Worst" list of most repressive societies in the world, together with Burma, North Korea, Tibet, and others.

In addition to the Russian regional government, there was a separatist Ichkeria government that was not recognized by any state (although members have been given political asylum in European and Arab countries, as well as the United States).

Ichkeria was a member of the Unrepresented Nations and Peoples Organisation between 1991 and 2010. Former president of Georgia Zviad Gamsakhurdia deposed in a military coup of 1991 and a participant of the Georgian Civil War, recognized the independence of the Chechen Republic of Ichkeria in 1993. Diplomatic relations with Ichkeria were also established by the partially recognized Islamic Emirate of Afghanistan under the Taliban government on January 16, 2000. This recognition ceased with the fall of the Taliban in 2001. However, despite Taliban recognition, there were no friendly relations between the Taliban and Ichkeria—Maskhadov rejected their recognition, stating that the Taliban were illegitimate. Ichkeria also received vocal support from the Baltic countries, a group of Ukrainian nationalists and Poland; Estonia once voted to recognize, but the act never was followed through due to pressure applied by both Russia and the EU.

The president of this government was Aslan Maskhadov, the Foreign Minister was Ilyas Akhmadov, who was the spokesman for Maskhadov. Aslan Maskhadov had been elected in an internationally monitored election in 1997 for 4 years, which took place after signing a peace agreement with Russia. In 2001 he issued a decree prolonging his office for one additional year; he was unable to participate in the 2003 presidential election since separatist parties were barred by the Russian government, and Maskhadov faced accusations of terrorist offences in Russia. Maskhadov left Grozny and moved to the separatist-controlled areas of the south at the onset of the Second Chechen War. Maskhadov was unable to influence a number of warlords who retain effective control over Chechen territory, and his power was diminished as a result. Russian forces killed Maskhadov on March 8, 2005, and the assassination of Maskhadov was widely criticised since it left no legitimate Chechen separatist leader with whom to conduct peace talks. Akhmed Zakayev, Deputy Prime Minister and a Foreign Minister under Maskhadov, was appointed shortly after the 1997 election and is currently living under asylum in England. He and others chose Abdul Khalim Saidullayev, a relatively unknown Islamic judge who was previously the host of an Islamic program on Chechen television, to replace Maskhadov following his death. On June 17, 2006, it was reported that Russian special forces killed Abdul Khalim Saidullayev in a raid in a Chechen town Argun.

The successor of Saidullayev became Doku Umarov. On October 31, 2007, Umarov abolished the Chechen Republic of Ichkeria and its presidency and in its place proclaimed the Caucasus Emirate with himself as its Emir. This change of status has been rejected by many Chechen politicians and military leaders who continue to support the existence of the republic.

The Internal Displacement Monitoring Centre reports that after hundreds of thousands of ethnic Russians and Chechens fled their homes following inter-ethnic and separatist conflicts in Chechnya in 1994 and 1999, more than 150,000 people still remain displaced in Russia today.

On September 1, 1997, Criminal Code reportedly being implemented in the Chechen Republic-Ichkeriya, Article 148 punishes "anal sexual intercourse between a man and a woman or a man and a man". For first- and second-time offenders, the punishment is caning. A third conviction leads to the death penalty, which can be carried out in a number of ways including stoning or beheading.

Human rights groups criticised the conduct of the 2005 parliamentary elections as unfairly influenced by the central Russian government and military.

In 2006 Human Rights Watch reported that pro-Russian Chechen forces under the command of Ramzan Kadyrov, as well as federal police personnel, used torture to get information about separatist forces. "If you are detained in Chechnya, you face a real and immediate risk of torture. And there is little chance that your torturer will be held accountable", said Holly Cartner, Director of the Europe and Central Asia division of the Human Rights Watch.

On February 1, 2009, "The New York Times" released extensive evidence to support allegations of consistent torture and executions under the Kadyrov government. The accusations were sparked by the assassination in Austria of a former Chechen rebel who had gained access to Kadyrov's inner circle, 27-year-old Umar Israilov.

On July 1, 2009, Amnesty International released a detailed report covering the human rights violations committed by the Russian Federation against Chechen citizens. Among the most prominent features was that those abused had no method of redress against assaults, ranging from kidnapping to torture, while those responsible were never held accountable. This led to the conclusion that Chechnya was being ruled without law, being run into further devastating destabilisation.
On March 10, 2011, Human Rights Watch reported that since Chechenisation, the government has pushed for enforced Islamic dress code. The president Ramzan Kadyrov is quoted as saying "I have the right to criticize my wife. She doesn't. With us [in Chechen society], a wife is a housewife. A woman should know her place. A woman should give her love to us [men]... She would be [man's] property. And the man is the owner. Here, if a woman does not behave properly, her husband, father, and brother are responsible. According to our tradition, if a woman fools around, her family members kill her... That's how it happens, a brother kills his sister or a husband kills his wife... As a president, I cannot allow for them to kill. So, let women not wear shorts...". He has also openly defended honour killings on several occasions.

On July 9, 2017, Russian newspaper Novaya Gazeta reported that a number of people were subject to an extrajudicial execution on the night of January 26, 2017. It published 27 names of the people known to be dead, but stressed that the list is "not all [of those killed]"; the newspaper asserted that 50 people may have been killed in the execution. Some of the dead were gay, but not all; the deaths appeared to have been triggered by the death of a policeman, and according to the author of the report, Elena Milashina, were executed for terrorism.

In 2017, it was reported by Novaya Gazeta and human rights groups that Chechen authorities had allegedly set up concentration camps, one of which is in Argun, where gay men are interrogated and subjected to physical violence.

On 11 January 2019, it was reported that another 'gay purge' had begun in the country in December 2018, with several gay men and women being detained. The Russian LGBT Network believes that around 40 people were detained and two killed.

During the war, the Chechen economy fell apart. In 1994, the separatists planned to introduce a new currency, but the change did not occur due to the re-taking of Chechnya by Russian troops in the Second Chechen War.

The economic situation in Chechnya has improved considerably since 2000. According to the "New York Times", major efforts to rebuild Grozny have been made, and improvements in the political situation have led some officials to consider setting up a tourism industry, though there are claims that construction workers are being irregularly paid and that poor people have been displaced.

Chechnya's unemployment was 67% in 2006 and fell to 21.5% in 2014.

Total revenue of the budget of Chechnya for 2017 was 59.2 billion rubles. Of these, 48.5 billion rubles were so-called "gratuitous receipts" from the federal budget of the Russian Federation.






</doc>
<doc id="6097" url="https://en.wikipedia.org/wiki?curid=6097" title="Canonization">
Canonization

Canonization is the declaration of a deceased person as an officially recognized saint, specifically, the official act of a Christian communion declaring a person worthy of public cult and entering his or her name in the canon, or authorized list, of that communion’s recognized saints.

Canonization is a papal declaration that the Catholic faithful may venerate a particular deceased member of the church. Popes began making such decrees in the tenth century. Up to that point, the local bishops governed the veneration of holy men and women within their own dioceses; and there may have been, for any particular saint, no formal decree at all. In subsequent centuries, the procedures became increasingly regularized and the popes began restricting to themselves the right to declare someone a Catholic saint. In contemporary usage, the term is understood to refer to the act by which any Christian church declares that a person who has died is a saint, upon which declaration the person is included in the list of recognized saints, called the "canon". 

The Roman Rite's Canon of the Mass contains only the names of martyrs, along with that of the Blessed Virgin Mary and, since 1962, that of Saint Joseph her spouse.

By the fourth century, however, "confessors"—people who had confessed their faith not by dying but by word and life—began to be venerated publicly. Examples of such people are Saint Hilarion and Saint Ephrem the Syrian in the East, and Saint Martin of Tours and Saint Hilary of Poitiers in the West. Their names were inserted in the diptychs, the lists of saints explicitly venerated in the liturgy, and their tombs were honoured in like manner as those of the martyrs. Since the witness of their lives was not as unequivocal as that of the martyrs, they were venerated publicly only with the approval by the local bishop. This process is often referred to as "local canonization".

This approval was required even for veneration of a reputed martyr. In his history of the Donatist heresy, Saint Optatus recounts that at Carthage a Catholic matron, named Lucilla, incurred the censures of the Church for having kissed the relics of a reputed martyr whose claims to martyrdom had not been juridically proved. And Saint Cyprian (died 258) recommended that the utmost diligence be observed in investigating the claims of those who were said to have died for the faith. All the circumstances accompanying the martyrdom were to be inquired into; the faith of those who suffered, and the motives that animated them were to be rigorously examined, in order to prevent the recognition of undeserving persons. Evidence was sought from the court records of the trials or from people who had been present at the trials.
Augustine of Hippo (died 430) tells of the procedure which was followed in his day for the recognition of a martyr. The bishop of the diocese in which the martyrdom took place set up a canonical process for conducting the inquiry with the utmost severity. The acts of the process were sent either to the metropolitan or primate, who carefully examined the cause, and, after consultation with the suffragan bishops, declared whether the deceased was worthy of the name of 'martyr' and public veneration.

Though not "canonizations" in the narrow sense, acts of formal recognition, such as the erection of an altar over the saint's tomb or transferring the saint's relics to a church, were preceded by formal inquiries into the sanctity of the person's life and the miracles attributed to that person's intercession.

Such acts of recognition of a saint were authoritative, in the strict sense, only for the diocese or ecclesiastical province for which they were issued, but with the spread of the fame of a saint, were often accepted elsewhere also.

In the Catholic Church, both Latin and constituent Eastern churches, the act of canonization is reserved to the Apostolic See and occurs at the conclusion of a long process requiring extensive proof that the candidate for canonization lived and died in such an exemplary and holy way that they are worthy to be recognized as a saint. The Church's official recognition of sanctity implies that the person is now in Heaven and that they may be publicly invoked and mentioned officially in the liturgy of the Church, including in the "Litany of the Saints".

In the Catholic Church, canonization is a decree that allows universal veneration of the saint in the liturgy. For permission to venerate merely locally, only beatification is needed.

For several centuries the Bishops, or in some places only the Primates and Patriarchs, could grant martyrs and confessors public ecclesiastical honor; such honor, however, was always decreed only for the local territory of which the grantors had jurisdiction. Only acceptance of the "cultus" by the Pope made the "cultus" universal, because he alone can rule the universal Catholic Church. Abuses, however, crept into this discipline, due as well to indiscretions of popular fervor as to the negligence of some bishops in inquiring into the lives of those whom they permitted to be honoured as saints.

In the Medieval West, the Apostolic See was asked to intervene in the question of canonizations so as to ensure more authoritative decisions. The canonization of Saint Udalric, Bishop of Augsburg by Pope John XV in 993 was the first undoubted example of papal canonization of a saint from outside of Rome being declared worthy of liturgical veneration for the entire church. Some historians maintain further that the first papal canonization was of St. Swibert by Pope Leo III in 804.

Thereafter, recourse to the judgment of the Pope occurred more frequently. Toward the end of the eleventh century the Popes began asserting their exclusive right to authorize the veneration of a saint against the older rights of bishops to do so for their dioceses and regions. Popes therefore decreed that the virtues and miracles of persons proposed for public veneration should be examined in councils, more specifically in general councils. Pope Urban II, Pope Calixtus II, and Pope Eugene III conformed to this discipline.

Hugh de Boves, Archbishop of Rouen, canonized Walter of Pontoise, or St. Gaultier, in 1153, the final saint in Western Europe to be canonized by an authority other than the Pope: "The last case of canonization by a metropolitan is said to have been that of St. Gaultier, or Gaucher, [A]bbot of Pontoise, by the Archbishop of Rouen. A decree of Pope Alexander III [in] 1170 gave the prerogative to the [P]ope thenceforth, so far as the Western Church was concerned." In a decretal of 1173, Pope Alexander III reprimanded some bishops for permitting veneration of a man who was merely killed while intoxicated, prohibited veneration of the man, and most significantly decreed that "you shall not therefore presume to honor him in the future; for, even if miracles were worked through him, it is not lawful for you to venerate him as a saint without the authority of the Catholic Church." Theologians disagree as to the full import of the decretal of Pope Alexander III: either a new law was instituted, in which case the Pope then for the first time reserved the right of beatification to himself, or an existing law was confirmed.

However, the procedure initiated by the decretal of Pope Alexander III was confirmed by a bull of Pope Innocent III issued on the occasion of the canonization of Cunigunde of Luxembourg in 1200. The bull of Pope Innocent III resulted in increasingly elaborate inquiries to the Apostolic See concerning canonizations. Because the decretal of Pope Alexander III did not end all controversy and some bishops did not obey it in so far as it regarded beatification, the right of which they had certainly possessed hitherto, Pope Urban VIII issued the Apostolic letter "Caelestis Hierusalem cives" of 5 July 1634 that exclusively reserved to the Apostolic See both its immemorial right of canonization and that of beatification. He further regulated both of these acts by issuing his "Decreta servanda in beatificatione et canonizatione Sanctorum" on 12 March 1642.

In his "De Servorum Dei beatificatione et de Beatorum canonizatione" of five volumes the eminent canonist Prospero Lambertini (1675–1758), who later became Pope Benedict XIV, elaborated on the procedural norms of Pope Urban VIII's Apostolic letter "Caelestis Hierusalem cives" of 1634 and "Decreta servanda in beatificatione et canonizatione Sanctorum" of 1642, and on the conventional practice of the time. His work published from 1734 to 1738 governed the proceedings until 1917. The article "Beatification and canonization process in 1914" describes the procedures followed until the promulgation of the "Codex" of 1917. The substance of "De Servorum Dei beatifιcatione et de Beatorum canonizatione" was incorporated into the "Codex Iuris Canonici" ("Code of Canon Law") of 1917, which governed until the promulgation of the revised "Codex Iuris Canonici" in 1983 by Pope John Paul II. Prior to promulgation of the revised "Codex" in 1983, Pope St. Paul VI initiated a simplification of the procedures.

The Apostolic constitution "Divinus Perfectionis Magister" of Pope John Paul II of 25 January 1983 and the norms issued by the Congregation for the Causes of Saints on 7 February 1983 to implement the constitution in dioceses, continued the simplification of the process initiated by Pope Paul VI. Contrary to popular belief, the reforms did not eliminate the office of the Promoter of the Faith (Latin: "Promotor Fidei"), popularly known as the Devil's advocate, whose office is to question the material presented in favor of canonization. The reforms were intended to reduce the adversarial nature of the process. In November 2012 Pope Benedict XVI appointed Monsignor Carmello Pellegrino as Promoter of the Faith.

Candidates for canonization undergo the following process:

The satisfaction of the applicable conditions permits beatification, which then bestows on the Venerable the title of "Blessed" (Latin: "Beatus" or "Beata"). A feast day will be designated, but its observance is ordinarily only permitted for the Blessed's home diocese, to specific locations associated with them, or to the churches or houses of the Blessed's religious order if they belonged to one. Parishes may not normally be named in honor of "beati".

Canonization is a statement of the Church that the person certainly enjoys the Beatific Vision of Heaven. The title of "Saint" (Latin: "Sanctus" or "Sancta") is then proper, reflecting that the Saint is a refulgence of the holiness ("sanctitas") of God himself, which alone comes from God's gift. The Saint is assigned a feast day which may be celebrated anywhere in the universal Church, although it is not necessarily added to the General Roman Calendar or local calendars as an "obligatory" feast; parish churches may be erected in her honor; and the faithful may freely celebrate and honor the Saint.

Although recognition of sainthood by the Pope does not directly concern a fact of Divine revelation, nonetheless it must be "definitively held" by the faithful as "infallible" pursuant to, at the least, the Universal Magisterium of the Church, because it is a truth related to revelation by historical necessity.

Regarding the Eastern Catholic Churches, individual "sui juris" churches have the right to "glorify" saints for their own jurisdictions, although this has rarely happened.

Popes have several times permitted to the universal Church, without executing the ordinary judicial process of canonization described above, the veneration as a saint, the ""cultus"" of one long venerated as such locally. This act of a pope is denominated "equipollent" or "equivalent canonization" and "confirmation of "cultus"". According to the rules Pope Benedict XIV ("regnat" 17 August 1740 – 3 May 1758) instituted, there are three conditions for an equipollent canonization: (1) existence of an ancient "cultus" of the person, (2) a general and constant attestation to the virtues or martyrdom of the person by credible historians, and (3) uninterrupted fame of the person as a worker of miracles.

As examples, prior to his pontificate, of this mode of canonization, Pope Benedict XIV himself enumerated the equipollent canonizations of Saints:

Later equipollent canonizations include those of Saints:

Pope Francis added Saints:

The Church of England, the Mother Church of the Anglican Communion, canonized Charles I as a saint, in the Convocations of Canterbury and York of 1660.

The General Conference of the United Methodist Church has formally declared individuals "martyrs", including Dietrich Bonhoeffer (in 2008) and Martin Luther King Jr. (in 2012).

The following terms are used for canonization by the autocephalous national Orthodox Churches: канонизация or прославление "glorification" (Russian Orthodox Church), კანონიზაცია "kanonizats’ia" (Georgian Orthodox Church), канонизација (Serbian Orthodox Church), "canonizare" (Romanian Orthodox Church), and Канонизация (Bulgarian Orthodox Church). The following terms are used for canonization by other autocephalous Orthodox Churches: αγιοκατάταξη (Katharevousa: ἁγιοκατάταξις) "agiokatataxi/agiokatataxis", "ranking among saints" (Ecumenical Patriarchate of Constantinople, Church of Cyprus, Church of Greece), "kanonizim" (Albanian Orthodox Church), "kanonizacja" (Polish Orthodox Church), and "kanonizace/kanonizácia" (Czech and Slovak Orthodox Church).

The Orthodox Church in America, an Eastern Orthodox Church partly recognized as autocephalous, uses the term "glorification" for granting official recognition to someone as a saint—see glorification.

Within the Armenian Apostolic Church, part of Oriental Orthodoxy, there had been discussions since the 1980s about canonizing the victims of the Armenian Genocide. On April 23, 2015, all of the victims of the genocide were canonized.

The Universal Life Church canonizes Saints for demonstrating three values:


A certificate is issued following a donation if the application for Sainthood is accepted and is then entered into the church's official records.




</doc>
<doc id="6099" url="https://en.wikipedia.org/wiki?curid=6099" title="Carboxylic acid">
Carboxylic acid

A carboxylic acid is an organic compound that contains a carboxyl group (C(=O)OH) attached to an R-group. The general formula of a carboxylic acid is R–COOH, with R referring to the alkyl group. Carboxylic acids occur widely. Important examples include the amino acids and fatty acids. Deprotonation of a carboxylic acid gives a carboxylate anion.

Carboxylic acids are commonly identified by their trivial names. They often have the suffix "-ic acid". IUPAC-recommended names also exist; in this system, carboxylic acids have an "-oic acid" suffix. For example, butyric acid (CHCOH) is butanoic acid by IUPAC guidelines. For nomenclature of complex molecules containing a carboxylic acid, the carboxyl can be considered position one of the parent chain even if there are other substituents, such as 3-chloropropanoic acid. Alternately, it can be named as a "carboxy" or "carboxylic acid" substituent on another parent structure, such as 2-carboxyfuran.

The carboxylate anion (R–COO or RCO) of a carboxylic acid is usually named with the suffix "-ate", in keeping with the general pattern of "-ic acid" and "-ate" for a conjugate acid and its conjugate base, respectively. For example, the conjugate base of acetic acid is acetate.

Carbonic acid, which occurs in bicarbonate buffer systems in nature, is not generally classed as one of the carboxylic acids, despite that it has a moiety that looks like a COOH group. 

Carboxylic acids are polar. Because they are both hydrogen-bond acceptors (the carbonyl –C=O) and hydrogen-bond donors (the hydroxyl –OH), they also participate in hydrogen bonding. Together, the hydroxyl and carbonyl group form the functional group carboxyl. Carboxylic acids usually exist as dimers in nonpolar media due to their tendency to "self-associate". Smaller carboxylic acids (1 to 5 carbons) are soluble in water, whereas bigger carboxylic acids have limited solubility due to the increasing hydrophobic nature of the alkyl chain. These longer chain acids tend to be soluble in less-polar solvents such as ethers and alcohols. Aqueous sodium hydroxide and carboxylic acids, even hydrophobic ones, react to yield water-soluble sodium salts. For example, enathic acid has a low solubility in water (0.2 g/L), but its sodium salt is very soluble in water.
Carboxylic acids tend to have higher boiling points than water, because of their greater surface areas and their tendency to form stabilised dimers through hydrogen bonds. For boiling to occur, either the dimer bonds must be broken or the entire dimer arrangement must be vaporised, increasing the enthalpy of vaporization requirements significantly.

Carboxylic acids are Brønsted–Lowry acids because they are proton (H) donors. They are the most common type of organic acid.

Carboxylic acids are typically weak acids, meaning that they only partially dissociate into HO cations and RCOO anions in neutral aqueous solution. For example, at room temperature, in a 1-molar solution of acetic acid, only 0.4% of the acid are dissociated. Electron-withdrawing substituents, such as -CF group, give stronger acids (the pKa of formic acid is 3.75 whereas trifluoroacetic acid, with a trifluoromethyl substituent, has a pK of 0.23). Electron-donating substituents give weaker acids (the pK of formic acid is 3.75 whereas acetic acid, with a methyl substituent, has a pK of 4.76)

Deprotonation of carboxylic acids gives carboxylate anions; these are resonance stabilized, because the negative charge is delocalized over the two oxygen atoms, increasing the stability of the anion. Each of the carbon–oxygen bonds in the carboxylate anion has a partial double-bond character. The carbonyl carbon's partial positive charge is also weakened by the -/ negative charges on the 2 oxygen atoms.

Carboxylic acids often have strong sour odours. Esters of carboxylic acids tend to have pleasant odours, and many are used in perfume.

Carboxylic acids are readily identified as such by infrared spectroscopy. They exhibit a sharp band associated with vibration of the C–O vibration bond ("ν") between 1680 and 1725 cm. A characteristic "ν" band appears as a broad peak in the 2500 to 3000 cm region. By H NMR spectrometry, the hydroxyl hydrogen appears in the 10–13 ppm region, although it is often either broadened or not observed owing to exchange with traces of water.

Many carboxylic acids are produced industrially on a large scale. They are also frequently found in nature. Esters of fatty acids are the main components of lipids and polyamides of aminocarboxylic acids are the main components of proteins.

Carboxylic acids are used in the production of polymers, pharmaceuticals, solvents, and food additives. Industrially important carboxylic acids include acetic acid (component of vinegar, precursor to solvents and coatings), acrylic and methacrylic acids (precursors to polymers, adhesives), adipic acid (polymers), citric acid (a flavor and preservative in food and beverages), ethylenediaminetetraacetic acid (chelating agent), fatty acids (coatings), maleic acid (polymers), propionic acid (food preservative), terephthalic acid (polymers). Important carboxylate salts are soaps.

In general, industrial routes to carboxylic acids differ from those used on a smaller scale because they require specialized equipment.


Preparative methods for small scale reactions for research or for production of fine chemicals often employ expensive consumable reagents.

Many reactions produce carboxylic acids but are used only in specific cases or are mainly of academic interest.

The most widely practiced reactions convert carboxylic acids into esters, amides, carboxylate salts, acid chlorides, and alcohols. Carboxylic acids react with bases to form carboxylate salts, in which the hydrogen of the hydroxyl (–OH) group is replaced with a metal cation. For example, acetic acid found in vinegar reacts with sodium bicarbonate (baking soda) to form sodium acetate, carbon dioxide, and water:

Carboxylic acids also react with alcohols to give esters. This process is widely used, e.g. in the production of polyesters. Likewise, carboxylic acids are converted into amides, but this conversion typically does not occur by direct reaction of the carboxylic acid and the amine. Instead esters are typical precursors to amides. The conversion of amino acids into peptides is a significant biochemical process that requires ATP.

The hydroxyl group on carboxylic acids may be replaced with a chlorine atom using thionyl chloride to give acyl chlorides. In nature, carboxylic acids are converted to thioesters.

Like esters, most of carboxylic acid can be reduced to alcohols by hydrogenation or using hydride or alkyl transferring agents (since they will deprotonate the acids instead without transfer) such as lithium aluminium hydride or Grignard reagents (organolithium compounds).

"N","N"-Dimethyl(chloromethylene)ammonium chloride (ClHC=N(CH)Cl) is a highly chemoselective agent for carboxylic acid reduction. It selectively activates the carboxylic acid to give the carboxymethyleneammonium salt, which can be reduced by a mild reductant like lithium tris("t"-butoxy)aluminum hydride to afford an aldehyde in a one pot procedure. This procedure is known to tolerate reactive carbonyl functionalities such as ketone as well as moderately reactive ester, olefin, nitrile, and halide moieties.


The carboxyl radical, •COOH, only exists briefly. The acid dissociation constant of COOH has been measured using electron paramagnetic resonance spectroscopy. The carboxyl group tends to dimerise to form oxalic acid.




</doc>
<doc id="6100" url="https://en.wikipedia.org/wiki?curid=6100" title="Chernobyl">
Chernobyl

Chernobyl (, ), also known as Chornobyl (), is a partially abandoned city in the Chernobyl Exclusion Zone, situated in the Ivankiv Raion of northern Kiev Oblast, Ukraine. Chernobyl is about north of Kiev, and southwest of the Belarusian city of Gomel. Before its evacuation, the city had about 14,000 residents, while around 1,000 people live in the city today.

First mentioned as a ducal hunting lodge in 1193, the city has changed hands multiple times over the course of history. Jews were introduced to the city in the 16th century, and a now-defunct monastery was established near the city in 1626. By the end of the 18th century, Chernobyl was a major centre of Hasidic Judaism under the Twersky Dynasty, who left Chernobyl after the city was subject to pogroms in the early 20th century. The Jewish community was later destroyed during the Holocaust. Chernobyl was chosen as the site of Ukraine's first nuclear power plant in 1972, located north of the city, which opened in 1977. Chernobyl was evacuated on 5 May 1986, 9 days after a catastrophic nuclear disaster at the plant, which was the largest nuclear disaster in history. Along with the residents of the nearby city of Pripyat, which was built as a home for the plant's workers, the population was relocated to the newly built city of Slavutych, and most have never returned.

The city was the administrative centre of Chernobyl Raion (district) from 1923. After the disaster, in 1988, the raion was dissolved and administration was transferred to the neighbouring Ivankiv Raion.

Although Chernobyl is primarily a ghost town today, a small number of people still live there, in houses marked with signs that read, "Owner of this house lives here", and a small number of animals live there as well. Workers on watch and administrative personnel of the Chernobyl Exclusion Zone are also stationed in the city. The city has two general stores and a hotel.

The city's name is the same as one of the Ukrainian names for "Artemisia vulgaris", mugwort or common wormwood, which is (or more commonly , 'common artemisia'). The name is inherited from or , a compound of + , the parts related to and , 'stalk', so named in distinction to the lighter-stemmed wormwood "A. absinthium".

The name in languages used nearby is:

The name in languages formerly used in the area is:

On the Ptolemy's world map there is the city of Azagarium which, according to "Dictionary of Ancient Geography" of Alexander Macbean (published in 1773 in London), is a town of Sarmatia Europaea on the Borysthenes, 36° East longitude and 50°40' latitude. The city is now supposed to be Czernobol, a town in Poland, in Red Russia, Palatinate of Kiow (see Kiev Voivodeship), not far from the Borystenes. On the map Azagarium is located on the right bank of Borystenes. It also was located just north of the city of Amadoca which was a capital of Amadocium situated between the lake (palus) of Amadoca (in the west) and the mountains (montes) of Amadoca (in the east).

Chernobyl was originally part of the land of Kievan Rus′. The first known mention of Chernobyl is from an 1193 charter, which describes it as a hunting-lodge of Knyaz Rurik Rostislavich. In the 13th century, it was a crown village of the Grand Duchy of Lithuania. The village was granted to Filon Kmita, a captain of the royal cavalry, as a fiefdom in 1566. The province where Chernobyl is located was transferred to the Kingdom of Poland in 1569, and was annexed by the Russian Empire in 1793.

Prior to the 20th century, Chernobyl was inhabited by Ukrainian peasants, some Polish people and a relatively large number of Jews.

Jews were brought to Chernobyl by Filon Kmita, during the Polish campaign of colonization. After 1596, the traditionally Eastern Orthodox Ukrainian peasantry of the district were forcibly converted, by Poland, to the Greek Catholic Uniate religion. Many of these converts returned to Eastern Orthodoxy after the Partitions of Poland.

In 1626, during the Counter-reformation, a Dominican church and monastery were founded by Lukasz Sapieha. A group of Old Catholics opposed the decrees of the Council of Trent. In 1832, following the failed Polish November Uprising, the Dominican monastery was sequestrated. The church of the Old Catholics was disbanded in 1852.

Until the end of the 19th century, Chernobyl was a privately owned city that belonged to the Chodkiewicz family. In 1896 they sold the city to the state, but until 1910 they owned a castle and a house in the city. 

In the second half of the 18th century, Chernobyl became a major centre of Hasidic Judaism. The Chernobyl Hasidic dynasty had been founded by Rabbi Menachem Nachum Twersky. The Jewish population suffered greatly from pogroms in October 1905 and in March–April 1919; many Jews were killed or robbed at the instigation of the Russian nationalist Black Hundreds. When the Twersky Dynasty left Chernobyl in 1920, it ceased to exist as a center of Hasidism.

Chernobyl had a population of 10,800 in 1898, including 7,200 Jews. Chernobyl was occupied in World War I by German forces.

Ukrainians and Bolsheviks fought over the city in the ensuing Civil War. In the Polish–Soviet War of 1919–20, Chernobyl was taken first by the Polish Army and then by cavalry of the Red Army. From 1921 onwards, it was officially incorporated into the Ukrainian SSR.

Between 1929 and 1933, Chernobyl suffered from killings during Stalin's collectivization campaign. It was also affected by the famine that resulted from Stalin's policies. The Polish and German community of Chernobyl was deported to Kazakhstan in 1936, during the Frontier Clearances.

During World War II, Chernobyl was occupied by the German Army from 25 August 1941 to 17 November 1943. The Jewish community was murdered during the Holocaust.

Twenty years later, the area was chosen as the site of the first nuclear power station to be built on Ukrainian soil. The Duga over-the-horizon radar array, several miles outside of Chernobyl, was the origin of the Russian Woodpecker; it was designed as part of an anti-ballistic missile early warning radar network.

With the dissolution of the Soviet Union in 1991, Chernobyl remained part of Ukraine.

On 26 April 1986, one of the reactors at the Chernobyl Nuclear Power Plant exploded after unsanctioned experiments on the reactor by plant operators were done improperly. The resulting loss of control was due to design flaws of the RBMK reactor, which made it unstable when operated at low power, and prone to thermal runaway where increases in temperature increase reactor power output.

Chernobyl city was evacuated 9 days after the disaster. The level of contamination with caesium-137 was around 555 kBq/m (surface ground deposition in 1986).

Later analyses concluded that, even with very conservative estimates, relocation of the city (or of any area below 1500 kBq/m) could not be justified on the grounds of radiological health.
This however does not account for the uncertainty in the first few days of the accident about further depositions and weather patterns.
Moreover, an earlier short-term evacuation could have averted more significant doses from short-lived isotope radiation (specifically iodine-131, which has a half-life of about eight days).
Estimates of health effects are a subject of some controversy, see Effects of the Chernobyl disaster.

In 1998, average caesium-137 doses from the accident (estimated at 1-2 mSv per year) did not exceed those from other sources of exposure. Current effective caesium-137 dose rates as of 2019 are 200-250 nSv/h, or roughly 1.7-2.2 mSv per year,
which is comparable to the worldwide average background radiation from natural sources.

The base of operations for the administration and monitoring of the Chernobyl Exclusion Zone was moved from Pripyat to Chernobyl. Chernobyl currently contains offices for the State Agency of Ukraine on the Exclusion Zone Management and accommodations for visitors. Apartment blocks have been repurposed as accommodations for employees of the State Agency. The length of time that workers may spend within the Chernobyl Exclusion Zone is restricted by regulations that have been implemented to limit radiation exposure. Today, visits are allowed to Chernobyl but limited by strict rules.

In 2003, the United Nations Development Programme launched a project, called the Chernobyl Recovery and Development Programme (CRDP), for the recovery of the affected areas. The main goal of the CRDP's activities is supporting the efforts of the Government of Ukraine to mitigate the long-term social, economic, and ecological consequences of the Chernobyl disaster.

The city has become overgrown and many types of animals live there. According to census information collected over an extended period of time, it is estimated that more mammals live there now than before the disaster.





</doc>
<doc id="6102" url="https://en.wikipedia.org/wiki?curid=6102" title="Cyan">
Cyan

Cyan (, ) is a greenish-blue color. It is evoked by light with a predominant wavelength of between 490 and 520 nm, between the wavelengths of green and blue.

In the subtractive color system, or CMYK color model, which can be overlaid to produce all colors in paint and color printing, cyan is one of the primary colors, along with magenta, yellow, and black. In the additive color system, or RGB color model, used to create all the colors on a computer or television display, cyan is made by mixing equal amounts of green and blue light. Cyan is the complement of red; it can be made by the removal of red from white light. Mixing red light and cyan light at the right intensity will make white light.

The web color cyan is synonymous with aqua. Other colors in the cyan color range are teal, turquoise, electric blue, aquamarine, and others described as blue-green.

Its name is derived from the Ancient Greek κύανος, transliterated "kyanos", meaning "dark blue, dark blue enamel, Lapis lazuli". It was formerly known as "cyan blue" or cyan-blue, and its first recorded use as a color name in English was in 1879. Further origins of the color name can be traced back to a dye produced from the cornflower ("Centaurea cyanus").

In most languages, 'cyan' is not a basic color term and it phenomenologically appears as a greenish vibrant hue of blue to most English speakers. Other English terms for this "borderline" hue region include "blue green", "aqua", and "turquoise".

The web color cyan shown at right is a secondary color in the RGB color model, which uses combinations of red, green and blue light to create all the colors on computer and television displays. In X11 colors, this color is called both cyan and aqua. In the HTML color list, this same color is called aqua.

The web colors are more vivid than the cyan used in the CMYK color system, and the web colors cannot be accurately reproduced on a printed page. To reproduce the web color cyan in inks, it is necessary to add some white ink to the printer's cyan below, so when it is reproduced in printing, it is not a primary subtractive color. It is called "aqua" (a name in use since 1598) because it is a color commonly associated with water, such as the appearance of the water at a tropical beach.

Cyan is also one of the common inks used in four-color printing, along with magenta, yellow, and black; this set of colors is referred to as CMYK. In printing, the cyan ink is sometimes known as printer's cyan, process cyan, or process blue.

While both the additive secondary and the subtractive primary are called "cyan", they can be substantially different from one another. Cyan printing ink is typically more saturated than the RGB secondary cyan, depending on what RGB color space and ink are considered. That is, process cyan is usually outside the RGB gamut, and there is no fixed conversion from CMYK primaries to RGB. Different formulations are used for printer's ink, so there can be variations in the printed color that is pure cyan ink. This is because real-world subtractive (unlike additive) color mixing does not consistently produce the same result when mixing apparently identical colors, since the specific frequencies filtered out to produce that color affect how it interacts with other colors. Phthalocyanine blue is one such commonly used pigment. A typical formulation of "process cyan" is shown in the color box at right.










</doc>
<doc id="6105" url="https://en.wikipedia.org/wiki?curid=6105" title="Conventional insulin therapy">
Conventional insulin therapy

Conventional insulin therapy is a therapeutic regimen for treatment of diabetes mellitus which contrasts with the newer intensive insulin therapy.

This older method (prior to the development home blood glucose monitoring) is still in use in a proportion of cases.

Conventional insulin therapy is characterized by:

The down side of this method is that it is difficult to achieve as good results of glycemic control as with intensive insulin therapy. The advantage is that, for diabetics with a regular lifestyle, the regime is less intrusive than the intensive therapy.


</doc>
<doc id="6109" url="https://en.wikipedia.org/wiki?curid=6109" title="Cream">
Cream

Cream is a dairy product composed of the higher-fat layer skimmed from the top of milk before homogenization. In un-homogenized milk, the fat, which is less dense, eventually rises to the top. In the industrial production of cream, this process is accelerated by using centrifuges called "separators". In many countries, it is sold in several grades depending on the total butterfat content. It can be dried to a powder for shipment to distant markets, and contains high levels of saturated fat.

Cream skimmed from milk may be called "sweet cream" to distinguish it from cream skimmed from whey, a by-product of cheese-making. Whey cream has a lower fat content and tastes more salty, tangy and "cheesy". In many countries, cream is usually sold partially fermented: sour cream, crème fraîche, and so on. Both forms have many culinary uses in sweet, bitter, salty and tangy dishes.

Cream produced by cattle (particularly Jersey cattle) grazing on natural pasture often contains some natural carotenoid pigments derived from the plants they eat; this gives it a slightly yellow tone, hence the name of the yellowish-white color: cream. This is also the origin of butter's yellow color. Cream from goat's milk, water buffalo milk, or from cows fed indoors on grain or grain-based pellets, is white.

Cream is used as an ingredient in many foods, including ice cream, many sauces, soups, stews, puddings, and some custard bases, and is also used for cakes. Whipped cream is served as a topping on ice cream sundaes, milkshakes, lassi, eggnog, sweet pies, strawberries, blueberries or peaches. Irish cream is an alcoholic liqueur which blends cream with whiskey, and often honey, wine, or coffee. Cream is also used in Indian curries such as masala dishes.

Cream (usually light/single cream or half and half) is often added to coffee in the US and Canada.

Both single and double cream (see Types for definitions) can be used in cooking. Double cream or full-fat crème fraîche are often used when cream is added to a hot sauce, to prevent any problem with it separating or "splitting". Double cream can be thinned with milk to make an approximation of single cream.

The French word "crème" denotes not only dairy cream, but also other thick liquids such as sweet and savory custards, which are normally made with milk, not cream.

Different grades of cream are distinguished by their fat content, whether they have been heat-treated, whipped, and so on. In many jurisdictions, there are regulations for each type.

The Australia New Zealand Food Standards Code – Standard 2.5.2 – Defines cream as a milk product comparatively rich in fat, in the form of an emulsion of fat-in-skim milk, which can be obtained by separation from milk. Cream must contain no less than 350 g/kg (35%) milk fat.

Manufacturers labels may distinguish between different fat contents, a general guideline is as follows:

Canadian cream definitions are similar to those used in the United States, except for "light cream", which is very low-fat cream, usually with 5 or 6 percent butterfat. Specific product characteristics are generally uniform throughout Canada, but names vary by both geographic and linguistic area and by manufacturer: "coffee cream" may be 10 or 18 percent cream and "half-and-half" ("crème légère") may be 3, 5, 6 or 10 percent, all depending on location and brand.

Regulations allow cream to contain acidity regulators and stabilizers. For whipping cream, allowed additives include skim milk powder (≤ 0.25%), glucose solids (≤ 0.1%), calcium sulphate (≤ 0.005%), and xanthan gum (≤ 0.02%). The content of milk fat in canned cream must be displayed as a percentage followed by "milk fat", "B.F", or "M.F".

In France, the use of the term "cream" for food products is defined by the decree 80-313 of April 23, 1980. It specifies the minimum rate of milk fat (12%) as well as the rules for pasteurisation or UHT sterilisation. The mention "crème fraîche" (fresh cream) can only be used for pasteurised creams conditioned on production site within 24h after pasteurisation. Even if food additives complying with French and European laws are allowed, usually, none will be found in plain "crèmes" and "crèmes fraîches" apart from lactic ferments (some low cost creams (or close to creams) can contain thickening agents, but rarely). Fat content is commonly shown as "XX% M.G." ("matière grasse").
Russia, as well as other EAC countries, legally separates cream into two classes: normal (10–34% butterfat) and heavy (35–58%), but the industry has pretty much standardized around the following types:
In Sweden, cream is usually sold as:

Mellangrädde (27%) is, nowadays, a less common variant. 
Gräddfil (usually 12 %) and Creme Fraiche (usually around 35 %) are two common sour cream products.

In Switzerland, the types of cream are legally defined as follows:

Sour cream and crème fraîche (German: Sauerrahm, Crème fraîche; French: crème acidulée, crème fraîche; Italian: panna acidula, crème fraîche) are defined as cream soured by bacterial cultures.

Thick cream (German: verdickter Rahm; French: crème épaissie; Italian: panna addensata) is defined as cream thickened using thickening agents.

In the United Kingdom, the types of cream are legally defined as follows:

In the United States, cream is usually sold as:

Most cream products sold in the United States at retail contain the minimum permissible fat content for their product type, e.g., "Half and half" almost always contains only 10.5% butterfat.<br> Not all grades are defined by all jurisdictions, and the exact fat content ranges vary. The above figures, except for "manufacturer's cream", are based on the Code of Federal Regulations, Title 21, Part 131

Cream may have thickening agents and stabilizers added. Thickeners include sodium alginate, carrageenan, gelatine, sodium bicarbonate, tetrasodium pyrophosphate, and alginic acid.

Other processing may be carried out. For example, cream has a tendency to produce oily globules (called "feathering") when added to coffee. The stability of the cream may be increased by increasing the non-fat solids content, which can be done by partial demineralisation and addition of sodium caseinate, although this is expensive.

 by churning cream to separate the butterfat and buttermilk. This can be done by hand or by machine.

Whipped cream is made by whisking or mixing air into cream with more than 30% fat, to turn the liquid cream into a soft solid. Nitrous oxide, from whipped-cream chargers may also be used to make whipped cream.

Sour cream, common in many countries including the U.S., Canada and Australia, is cream (12 to 16% or more milk fat) that has been subjected to a bacterial culture that produces lactic acid (0.5%+), which sours and thickens it.

Crème fraîche (28% milk fat) is slightly soured with bacterial culture, but not as sour or as thick as sour cream. Mexican crema (or cream espesa) is similar to crème fraîche.

Smetana is a heavy cream derived (15–40% milk fat) Central and Eastern European sweet or sour cream.

Rjome or rømme is Norwegian sour cream containing 35% milk fat, similar to Icelandic sýrður rjómi.

Clotted cream, common in the United Kingdom, is made through a process that starts by slowly heating whole milk to produce a very high-fat (55%) product. This is similar to Indian malai.

Reduced cream is a cream product used in New Zealand to make Kiwi dip.

Some non-edible substances are called creams due to their consistency: shoe cream is runny, unlike regular waxy shoe polish; hand/body 'creme' or "skin cream" is meant for moisturizing the skin.

Regulations in many jurisdictions restrict the use of the word "cream" for foods. Words such as "creme", "kreme", "creame", or "whipped topping" (e.g., Cool Whip) are often used for products which cannot legally be called cream, though in some jurisdictions even these spellings may be disallowed, for example under the doctrine of "idem sonans". Oreo and Hydrox cookies are a type of sandwich cookie in which two biscuits have a soft, sweet filling between them that is called "crème filling." In some cases, foods can be described as cream although they do not contain predominantly milk fats; for example in Britain "ice cream" does not have to be a dairy product (although it must be labelled "contains non-milk fat"), and salad cream is the customary name for a condiment that has been produced since the 1920s.

In other languages, cognates of "cream" are also sometimes used for non-food products, such as fogkrém (Hungarian for toothpaste), or Sonnencreme (German for suntan lotion).


Nutrition chart for heavy cream


</doc>
<doc id="6111" url="https://en.wikipedia.org/wiki?curid=6111" title="Chemical vapor deposition">
Chemical vapor deposition

Chemical vapor deposition (CVD) is a vacuum deposition method used to produce high quality, high-performance, solid materials. The process is often used in the semiconductor industry to produce thin films.

In typical CVD, the wafer (substrate) is exposed to one or more volatile precursors, which react and/or decompose on the substrate surface to produce the desired deposit. Frequently, volatile by-products are also produced, which are removed by gas flow through the reaction chamber.

Microfabrication processes widely use CVD to deposit materials in various forms, including: monocrystalline, polycrystalline, amorphous, and epitaxial. These materials include: silicon (dioxide, carbide, nitride, oxynitride), carbon (fiber, nanofibers, nanotubes, diamond and graphene), fluorocarbons, filaments, tungsten, titanium nitride and various high-k dielectrics.

CVD is practiced in a variety of formats. These processes generally differ in the means by which chemical reactions are initiated.

Most modern CVD is either LPCVD or UHVCVD.

CVD is commonly used to deposit conformal films and augment substrate surfaces in ways that more traditional surface modification techniques are not capable of. CVD is extremely useful in the process of atomic layer deposition at depositing extremely thin layers of material. A variety of applications for such films exist. Gallium arsenide is used in some integrated circuits (ICs) and photovoltaic devices. Amorphous polysilicon is used in photovoltaic devices. Certain carbides and nitrides confer wear-resistance. Polymerization by CVD, perhaps the most versatile of all applications, allows for super-thin coatings which possess some very desirable qualities, such as lubricity, hydrophobicity and weather-resistance to name a few. The CVD of metal-organic frameworks, a class of crystalline nanoporous materials, has recently been demonstrated. Recently scaled up as an integrated cleanroom process depositing large-area substrates, the applications for these films are anticipated in gas sensing and low-k dielectrics
CVD techniques are advantageous for membrane coatings as well, such as those in desalination or water treatment, as these coatings can be sufficiently uniform (conformal) and thin that they do not clog membrane pores.

Polycrystalline silicon is deposited from trichlorosilane (SiHCl) or silane (SiH), using the following reactions:

This reaction is usually performed in LPCVD systems, with either pure silane feedstock, or a solution of silane with 70–80% nitrogen. Temperatures between 600 and 650 °C and pressures between 25 and 150 Pa yield a growth rate between 10 and 20 nm per minute. An alternative process uses a hydrogen-based solution. The hydrogen reduces the growth rate, but the temperature is raised to 850 or even 1050 °C to compensate. Polysilicon may be grown directly with doping, if gases such as phosphine, arsine or diborane are added to the CVD chamber. Diborane increases the growth rate, but arsine and phosphine decrease it.

Silicon dioxide (usually called simply "oxide" in the semiconductor industry) may be deposited by several different processes. Common source gases include silane and oxygen, dichlorosilane (SiClH) and nitrous oxide (NO), or tetraethylorthosilicate (TEOS; Si(OCH)). The reactions are as follows:

The choice of source gas depends on the thermal stability of the substrate; for instance, aluminium is sensitive to high temperature. Silane deposits between 300 and 500 °C, dichlorosilane at around 900 °C, and TEOS between 650 and 750 °C, resulting in a layer of "low- temperature oxide" (LTO). However, silane produces a lower-quality oxide than the other methods (lower dielectric strength, for instance), and it deposits nonconformally. Any of these reactions may be used in LPCVD, but the silane reaction is also done in APCVD. CVD oxide invariably has lower quality than thermal oxide, but thermal oxidation can only be used in the earliest stages of IC manufacturing.

Oxide may also be grown with impurities (alloying or "doping"). This may have two purposes. During further process steps that occur at high temperature, the impurities may diffuse from the oxide into adjacent layers (most notably silicon) and dope them. Oxides containing 5–15% impurities by mass are often used for this purpose. In addition, silicon dioxide alloyed with phosphorus pentoxide ("P-glass") can be used to smooth out uneven surfaces. P-glass softens and reflows at temperatures above 1000 °C. This process requires a phosphorus concentration of at least 6%, but concentrations above 8% can corrode aluminium. Phosphorus is deposited from phosphine gas and oxygen:

Glasses containing both boron and phosphorus (borophosphosilicate glass, BPSG) undergo viscous flow at lower temperatures; around 850 °C is achievable with glasses containing around 5 weight % of both constituents, but stability in air can be difficult to achieve. Phosphorus oxide in high concentrations interacts with ambient moisture to produce phosphoric acid. Crystals of BPO can also precipitate from the flowing glass on cooling; these crystals are not readily etched in the standard reactive plasmas used to pattern oxides, and will result in circuit defects in integrated circuit manufacturing.

Besides these intentional impurities, CVD oxide may contain byproducts of the deposition. TEOS produces a relatively pure oxide, whereas silane introduces hydrogen impurities, and dichlorosilane introduces chlorine.

Lower temperature deposition of silicon dioxide and doped glasses from TEOS using ozone rather than oxygen has also been explored (350 to 500 °C). Ozone glasses have excellent conformality but tend to be hygroscopic – that is, they absorb water from the air due to the incorporation of silanol (Si-OH) in the glass. Infrared spectroscopy and mechanical strain as a function of temperature are valuable diagnostic tools for diagnosing such problems.

Silicon nitride is often used as an insulator and chemical barrier in manufacturing ICs. The following two reactions deposit silicon nitride from the gas phase:

Silicon nitride deposited by LPCVD contains up to 8% hydrogen. It also experiences strong tensile stress, which may crack films thicker than 200 nm. However, it has higher resistivity and dielectric strength than most insulators commonly available in microfabrication (10 Ω·cm and 10 MV/cm, respectively).

Another two reactions may be used in plasma to deposit SiNH:

These films have much less tensile stress, but worse electrical properties (resistivity 10 to 10 Ω·cm, and dielectric strength 1 to 5 MV/cm).

CVD for tungsten is achieved from tungsten hexafluoride (WF), which may be deposited in two ways:

Other metals, notably aluminium and copper, can be deposited by CVD. , commercially cost-effective CVD for copper did not exist, although volatile sources exist, such as Cu(hfac). Copper is typically deposited by electroplating. Aluminum can be deposited from triisobutylaluminium (TIBAL) and related organoaluminium compounds.

CVD for molybdenum, tantalum, titanium, nickel is widely used. These metals can form useful silicides when deposited onto silicon. Mo, Ta and Ti are deposited by LPCVD, from their pentachlorides. Nickel, molybdenum, and tungsten can be deposited at low temperatures from their carbonyl precursors. In general, for an arbitrary metal "M", the chloride deposition reaction is as follows:

whereas the carbonyl decomposition reaction can happen spontaneously under thermal treatment or acoustic cavitation and is as follows:

the decomposition of metal carbonyls is often violently precipitated by moisture or air, where oxygen reacts with the metal precursor to form metal or metal oxide along with carbon dioxide.

Niobium(V) oxide layers can be produced by the thermal decomposition of niobium(V) ethoxide with the loss of diethyl ether according to the equation:

Many variations of CVD can be utilized to synthesize graphene. Although many advancements have been made, the processes listed below are not commercially viable yet.

The most popular carbon source that is used to produce graphene is methane gas. One of the less popular choices is petroleum asphalt, notable for being inexpensive but more difficult to work with.

Although methane is the most popular carbon source, hydrogen is required during the preparation process to promote carbon deposition on the substrate. If the flow ratio of methane and hydrogen are not appropriate, it will cause undesirable results. During the growth of graphene, the role of methane is to provide a carbon source, the role of hydrogen is to provide H atoms to corrode amorphous C, and improve the quality of graphene. But excessive H atoms can also corrode graphene. As a result, the integrity of the crystal lattice is destroyed, and the quality of graphene is deteriorated. Therefore, by optimizing the flow rate of methane and hydrogen gases in the growth process, the quality of graphene can be improved.

The use of catalyst is viable in changing the physical process of graphene production. Notable examples include iron nanoparticles, nickel foam, and gallium vapor. These catalysts can either be used in situ during graphene buildup, or situated at some distance away at the deposition area. Some catalysts require another step to remove them from the sample material.

The direct growth of high-quality, large single-crystalline domains of graphene on a dielectric substrate is of vital importance for applications in electronics and optoelectronics. Combining the advantages of both catalytic CVD and the ultra-flat dielectric substrate, gaseous catalyst-assisted CVD paves the way for synthesizing high-quality graphene for device applications while avoiding the transfer process.
Physical conditions such as surrounding pressure, temperature, carrier gas, and chamber material play a big role in production of graphene.

Most systems use LPCVD with pressures ranging from 1 to 1500 Pa. However, some still use APCVD. Low pressures are used more commonly as they help prevent unwanted reactions and produce more uniform thickness of deposition on the substrate.

On the other hand, temperatures used range from 800–1050 °C. High temperatures translate to an increase of the rate of reaction. Caution has to be exercised as high temperatures do pose higher danger levels in addition to greater energy costs.
Hydrogen gas and inert gases such as argon are flowed into the system. These gases act as a carrier, enhancing surface reaction and improving reaction rate, thereby increasing deposition of graphene onto the substrate.
Standard quartz tubing and chambers are used in CVD of graphene. Quartz is chosen because it has a very high melting point and is chemically inert. In other words, quartz does not interfere with any physical or chemical reactions regardless of the conditions.
Raman spectroscopy, X-ray spectroscopy, transmission electron microscopy (TEM), and scanning electron microscopy (SEM) are used to examine and characterize the graphene samples.

Raman spectroscopy is used to characterize and identify the graphene particles; X-ray spectroscopy is used to characterize chemical states; TEM is used to provide fine details regarding the internal composition of graphene; SEM is used to examine the surface and topography.

Sometimes, atomic force microscopy (AFM) is used to measure local properties such as friction and magnetism.

Cold wall CVD technique can be used to study the underlying surface science involved in graphene nucleation and growth as it allows unprecedented control of process parameters like gas flow rates, temperature and pressure as demonstrated in a recent study. The study was carried out in a home-built vertical cold wall system utilizing resistive heating by passing direct current through the substrate. It provided conclusive insight into a typical surface-mediated nucleation and growth mechanism involved in two-dimensional materials grown using catalytic CVD under conditions sought out in the semiconductor industry.

In spite of graphene's exciting electronic and thermal properties, it is unsuitable as a transistor for future digital devices, due to the absence of a bandgap between the conduction and valence bands. This makes it impossible to switch between on and off states with respect to electron flow. Scaling things down, graphene nanoribbons of less than 10 nm in width do exhibit electronic bandgaps and are therefore potential candidates for digital devices. Precise control over their dimensions, and hence electronic properties, however, represents a challenging goal, and the ribbons typically possess rough edges that are detrimental to their performance.

CVD can be used to produce a synthetic diamond by creating the circumstances necessary for carbon atoms in a gas to settle on a substrate in crystalline form. CVD of diamonds has received much attention in the materials sciences because it allows many new applications that had previously been considered too expensive. CVD diamond growth typically occurs under low pressure (1–27 kPa; 0.145–3.926 psi; 7.5–203 Torr) and involves feeding varying amounts of gases into a chamber, energizing them and providing conditions for diamond growth on the substrate. The gases always include a carbon source, and typically include hydrogen as well, though the amounts used vary greatly depending on the type of diamond being grown. Energy sources include hot filament, microwave power, and arc discharges, among others. The energy source is intended to generate a plasma in which the gases are broken down and more complex chemistries occur. The actual chemical process for diamond growth is still under study and is complicated by the very wide variety of diamond growth processes used.

Using CVD, films of diamond can be grown over large areas of substrate with control over the properties of the diamond produced. In the past, when high pressure high temperature (HPHT) techniques were used to produce a diamond, the result was typically very small free standing diamonds of varying sizes. With CVD diamond growth areas of greater than fifteen centimeters (six inches) diameter have been achieved and much larger areas are likely to be successfully coated with diamond in the future. Improving this process is key to enabling several important applications.

The growth of diamond directly on a substrate allows the addition of many of diamond's important qualities to other materials. Since diamond has the highest thermal conductivity of any bulk material, layering diamond onto high heat producing electronics (such as optics and transistors) allows the diamond to be used as a heat sink. Diamond films are being grown on valve rings, cutting tools, and other objects that benefit from diamond's hardness and exceedingly low wear rate. In each case the diamond growth must be carefully done to achieve the necessary adhesion onto the substrate. Diamond's very high scratch resistance and thermal conductivity, combined with a lower coefficient of thermal expansion than Pyrex glass, a coefficient of friction close to that of Teflon (polytetrafluoroethylene) and strong lipophilicity would make it a nearly ideal non-stick coating for cookware if large substrate areas could be coated economically.

CVD growth allows one to control the properties of the diamond produced. In the area of diamond growth, the word "diamond" is used as a description of any material primarily made up of sp3-bonded carbon, and there are many different types of diamond included in this. By regulating the processing parameters—especially the gases introduced, but also including the pressure the system is operated under, the temperature of the diamond, and the method of generating plasma—many different materials that can be considered diamond can be made. Single crystal diamond can be made containing various dopants. Polycrystalline diamond consisting of grain sizes from several nanometers to several micrometers can be grown. Some polycrystalline diamond grains are surrounded by thin, non-diamond carbon, while others are not. These different factors affect the diamond's hardness, smoothness, conductivity, optical properties and more.

Commercially, mercury cadmium telluride is of continuing interest for detection of infrared radiation. Consisting of an alloy of CdTe and HgTe, this material can be prepared from the dimethyl derivatives of the respective elements.



</doc>
<doc id="6112" url="https://en.wikipedia.org/wiki?curid=6112" title="CN Tower">
CN Tower

The CN Tower () is a concrete communications and observation tower located in Downtown Toronto, Ontario, Canada. Built on the former Railway Lands, it was completed in 1976. Its name "CN" originally referred to Canadian National, the railway company that built the tower. Following the railway's decision to divest non-core freight railway assets prior to the company's privatization in 1995, it transferred the tower to the Canada Lands Company, a federal Crown corporation responsible for real estate development.

The CN Tower held the record for the world's tallest free-standing structure for 32 years until 2007 when it was surpassed by the Burj Khalifa, and was the world's tallest tower until 2009 when it was surpassed by the Canton Tower. It is now the ninth tallest free-standing structure in the world and remains the tallest free-standing structure on land in the Western Hemisphere. In 1995, the CN Tower was declared one of the modern Seven Wonders of the World by the American Society of Civil Engineers. It also belongs to the World Federation of Great Towers.

It is a signature icon of Toronto's skyline and attracts more than two million international visitors annually.

The original concept of the CN Tower originated in 1968 when the Canadian National Railway wanted to build a large TV and radio communication platform to serve the Toronto area, as well as demonstrate the strength of Canadian industry and CN in particular. These plans evolved over the next few years, and the project became official in 1972.

The tower would have been part of Metro Centre (see CityPlace), a large development south of Front Street on the Railway Lands, a large railway switching yard that was being made redundant by newer yards outside the city. Key project team members were NCK Engineering as structural engineer; John Andrews Architects; Webb, Zerafa, Menkes, Housden Architects; Foundation Building Construction; and Canron (Eastern Structural Division).

As Toronto grew rapidly during the late 1960s and early 1970s, multiple skyscrapers were constructed in the downtown core, most notably First Canadian Place. The reflective nature of the new buildings compromised the quality of broadcast signals necessitating new, higher antennas that were at least tall.

At the time, most data communications took place over point-to-point microwave links, whose dish antennae covered the roofs of large buildings. As each new skyscraper was added to the downtown, former line-of-sight links were no longer possible. CN intended to rent "hub" space for microwave links, visible from almost any building in the Toronto area.

The original plan for the tower envisioned a tripod consisting of three independent cylindrical "pillars" linked at various heights by structural bridges. Had it been built, this design would have been considerably shorter, with the metal antenna located roughly where the concrete section between the main level and the SkyPod lies today. As the design effort continued, it evolved into the current design with a single continuous hexagonal core to the SkyPod, with three support legs blended into the hexagon below the main level, forming a large Y-shape structure at the ground level.

The idea for the main level in its current form evolved around this time, but the Space Deck (later renamed SkyPod) was not part of the plans until some time later. One engineer in particular felt that visitors would feel the higher observation deck would be worth paying extra for, and the costs in terms of construction were not prohibitive. It was also some time around this point that it was realized that the tower could become the world's tallest structure, and plans were changed to incorporate subtle modifications throughout the structure to this end.

The CN Tower was built by Canada Cement Company (also known as the Cement Foundation Company of Canada at the time), a subsidiary of Sweden's Skanska, a global project-development and construction group.
Construction began on February 6, 1973, with massive excavations at the tower base for the foundation. By the time the foundation was complete, of earth and shale were removed to a depth of in the centre, and a base incorporating of concrete with of rebar and of steel cable had been built to a thickness of . This portion of the construction was fairly rapid, with only four months needed between the start and the foundation being ready for construction on top.

To create the main support pillar, workers constructed a hydraulically raised slipform at the base. This was a fairly unprecedented engineering feat on its own, consisting of a large metal platform that raised itself on jacks at about per day as the concrete below set. Concrete was poured Monday to Friday (and not continuously) by a small team of people until February 22, 1974, at which time it had already become the tallest structure in Canada, surpassing the recently built Inco Superstack in Sudbury, which was built using similar methods.

The tower contains of concrete, all of which was mixed on-site in order to ensure batch consistency. Through the pour, the vertical accuracy of the tower was maintained by comparing the slip form's location to massive plumb bobs hanging from it, observed by small telescopes from the ground. Over the height of the tower, it varies from true vertical accuracy by only .
In August 1974, construction of the main level commenced. Using 45 hydraulic jacks attached to cables strung from a temporary steel crown anchored to the top of the tower, twelve giant steel and wooden bracket forms were slowly raised, ultimately taking about a week to crawl up to their final position. These forms were used to create the brackets that support the main level, as well as a base for the construction of the main level itself. The Space Deck (currently named SkyPod) was built of concrete poured into a wooden frame attached to rebar at the lower level deck, and then reinforced with a large steel compression band around the outside.

The antenna was originally to be raised by crane as well, but during construction the Sikorsky S-64 Skycrane helicopter became available when the United States Army sold one to civilian operators. The helicopter, named "Olga", was first used to remove the crane, and then flew the antenna up in 36 sections.

The flights of the antenna pieces were a minor tourist attraction of their own, and the schedule was printed in the local newspapers. Use of the helicopter saved months of construction time, with this phase taking only three and a half weeks instead of the planned six months. The tower was topped-off on April 2, 1975, after 26 months of construction, officially capturing the height record from Moscow's Ostankino Tower, and bringing the total mass to .

Two years into the construction, plans for Metro Centre were scrapped, leaving the tower isolated on the Railway Lands in what was then a largely abandoned light-industrial space. This caused serious problems for tourists to access the tower. Ned Baldwin, project architect with John Andrews, wrote at the time that "All of the logic which dictated the design of the lower accommodation has been upset," and that "Under such ludicrous circumstances Canadian National would hardly have chosen this location to build."

The CN Tower opened to the public on June 26, 1976. The construction costs of approximately ($ in dollars) were repaid in fifteen years. Canadian National Railway sold the tower prior to taking the company private in 1995, when it decided to divest all operations not directly related to its core freight shipping businesses.

From the mid-1970s to the mid-1980s, the CN Tower was practically the only development along Front Street West; it was still possible to see Lake Ontario from the foot of the CN Tower due to the expansive parking lots and lack of development in the area at the time. As the area around the tower was developed, particularly with the completion of the Metro Toronto Convention Centre (north building) in 1984 and SkyDome in 1989 (renamed Rogers Centre in 2005), the former Railway Lands were redeveloped and the tower became the centre of a newly developing entertainment area. Access was greatly improved with the construction of the SkyWalk in 1989, which connected the tower and SkyDome to the nearby Union Station railway and subway station, and, in turn, to the city's PATH underground pedestrian system. By the mid-1990s, it was the centre of a thriving tourist district. The entire area continues to be an area of intense building, notably a boom in condominium construction in the first quarter of the 21st century, as well as the 2013 opening of the Ripley's Aquarium by the base of the tower.


The CN Tower consists of several substructures. The main portion of the tower is a hollow concrete hexagonal pillar containing the stairwells and power and plumbing connections. The tower's six elevators are located in the three inverted angles created by the Tower's hexagonal shape (two elevators per angle). Each of the three elevator shafts is lined with glass, allowing for views of the city as the glass-windowed elevators make their way through the tower. The stairwell was originally located in one of these angles (the one facing north), but was moved into the central hollow of the tower; the tower's new fifth and sixth elevators were placed in the hexagonal angle that once contained the stairwell. On top of the main concrete portion of the tower is a tall metal broadcast antenna, carrying television and radio signals. There are three visitor areas: the Glass Floor and Outdoor Observation Terrace, which are both located at an elevation of , the Indoor Lookout Level (formerly known as "Indoor Observation Level") located at , and the higher SkyPod (formerly known as "Space Deck") at , just below the metal antenna. The hexagonal shape is visible between the two areas; however, below the main deck, three large supporting legs give the tower the appearance of a large tripod.

The main deck level is seven storeys, some of which are open to the public. Below the public areas — at — is a large white donut-shaped radome containing the structure's UHF transmitters. The glass floor and outdoor observation deck are at . The glass floor has an area of and can withstand a pressure of . The floor's thermal glass units are thick, consisting of a pane of laminated glass, airspace and a pane of laminated glass. In 2008, one elevator was upgraded to add a glass floor panel, believed to have the highest vertical rise of any elevator equipped with this feature. The Horizons Cafe and the lookout level are at . The 360 Restaurant, a revolving restaurant that completes a full rotation once every 72 minutes, is at . When the tower first opened, it also featured a disco named Sparkles (at the Indoor Observation Level), billed as the highest disco and dance floor in the world.

The SkyPod was once the highest public observation deck in the world until it was surpassed by the Shanghai World Financial Center in 2008.

A metal staircase reaches the main deck level after 1,776 steps, and the SkyPod above after 2,579 steps; it is the tallest metal staircase on Earth. These stairs are intended for emergency use only and are not open to the public, except for twice per year for charity stair-climb events. The average climber takes approximately 30 minutes to climb to the base of the radome, but the fastest climb on record is 7 minutes and 52 seconds in 1989 by Brendan Keenoy, an Ontario Provincial Police officer. In 2002, Canadian Olympian and Paralympic champion Jeff Adams climbed the stairs of the tower in a specially designed wheelchair. The stairs were originally on one of the three sides of the tower (facing north), with a glass view, but these were later replaced with the third elevator pair and the stairs were moved to the inside of the core. Top climbs on the new, windowless stairwell used since around 2003 have generally been over ten minutes.

On August 1, 2011, the CN Tower opened the EdgeWalk, an amusement in which thrill-seekers can walk on and around the roof of the main pod of the tower at , which is directly above the 360 Restaurant. It is the world's highest full-circle, hands-free walk. Visitors are tethered to an overhead rail system and walk around the edge of the CN Tower's main pod above the 360 Restaurant on a metal floor. The attraction is closed throughout the winter and during periods of electrical storms and high winds.

One of the notable guests who visited EdgeWalk was Canadian comedian Rick Mercer as featured as the first episode of the ninth season of his CBC Television news satire show, "Rick Mercer Report". There, he was accompanied by Canadian pop singer Jann Arden. The episode aired on April 10, 2013.

A freezing rain storm on March 2, 2007, resulted in a layer of ice several centimetres thick forming on the side of the tower and other downtown buildings. The sun thawed the ice, and winds of up to blew some of it away from the structure. There were fears that cars and windows of nearby buildings would be smashed by large chunks of ice. In response, police closed some streets surrounding the tower. During morning rush hour on March 5 of the same year, police expanded the area of closed streets to include the Gardiner Expressway away from the tower as increased winds blew the ice farther away, as far north as King Street West, away, where a taxicab window was shattered. Subsequently, on March 6, 2007, the Gardiner Expressway reopened after winds abated.

On April 16, 2018, falling ice from the CN Tower punctured the roof of the nearby Rogers Centre, causing the Toronto Blue Jays to postpone the game that day to the following day as a doubleheader; this was the third doubleheader held at the Rogers Centre. On April 20, the CN Tower reopened.

In August 2000, a fire broke out at the Ostankino Tower in Moscow killing three people and causing extensive damage. The fire was blamed on poor maintenance and outdated equipment. The failure of the fire-suppression systems and the lack of proper equipment for firefighters allowed the fire to destroy most of the interior and spark fears the tower might even collapse.

The Ostankino Tower was completed nine years before the CN Tower and is only shorter. The parallels between the towers led to some concern that the CN Tower could be at risk of a similar tragedy. However, Canadian officials subsequently stated that it is "highly unlikely" that a similar disaster could occur at the CN Tower, as it has important safeguards that were not present in the Ostankino Tower. Specifically, officials cited:


Officials also noted that the CN Tower has an excellent safety record, although there was an electrical fire in the antennae on August 16, 2017 — the tower's first fire. Moreover, other supertall structures built between 1967 and 1976 — such as the Willis Tower (formerly the Sears Tower), the World Trade Center (until its destruction on September 11, 2001), the Fernsehturm Berlin, the Aon Center, 875 North Michigan Avenue (formerly the John Hancock Center), and First Canadian Place — also have excellent safety records, which suggests that the Ostankino Tower accident was a rare safety failure, and that the likelihood of similar events occurring at other supertall structures is extremely low.

The CN Tower was originally lit at night with incandescent lights, which were removed in 1997 because they were inefficient and expensive to repair. In June 2007, the tower was outfitted with 1,330 super-bright LED lights inside the elevator shafts, shooting over the main pod and upward to the top of the tower's mast to light the tower from dusk until 2 a.m. The official opening ceremony took place on June 28 before the Canada Day holiday weekend.

The tower changes its lighting scheme on holidays and to commemorate major events. After the 95th Grey Cup in Toronto, the tower was lit in green and white to represent the colours of the Grey Cup champion Saskatchewan Roughriders. From sundown on August 27, 2011, to sunrise the following day, the tower was lit in orange, the official colour of the New Democratic Party (NDP), to commemorate the death of federal NDP leader and leader of the official opposition Jack Layton. When former South African president Nelson Mandela died, the tower was lit in the colours of the South African flag. When former federal finance minister under Stephen Harper's Conservatives Jim Flaherty died, the tower was lit in green to reflect his Irish Canadian heritage. On the night of the attacks on Paris on November 13, 2015, the tower displayed the colours of the French flag.

Programmed from a desktop computer with a wireless network interface controller in Burlington, Ontario, the LEDs use less energy to light than the previous incandescent lights (10% less energy than the dimly lit version and 60% less than the brightly lit version). The estimated cost to use the LEDs is $1,000 per month.

During the spring and autumn bird migration seasons, the lights would be turned off to comply with the voluntary Fatal Light Awareness Program, which "encourages buildings to dim unnecessary exterior lighting to mitigate bird mortality during spring and summer migration."

The CN Tower is the tallest freestanding structure in the Western Hemisphere. As of 2013, there are only two other freestanding structures in the Western Hemisphere which exceed in height; the Willis Tower in Chicago, which stands at when measured to its pinnacle; and the topped-out One World Trade Center in New York City, which has a pinnacle height of , or approximately shorter than the CN Tower. Due to the symbolism of the number 1776 (the year of the signing of the United States Declaration of Independence), the height of One World Trade Center is unlikely to be increased. The proposed Chicago Spire was expected to exceed the height of the CN Tower, but its construction was halted early due to financial difficulties amid the Great Recession, and was eventually cancelled in 2010.

"Guinness World Records" has called the CN Tower "the world's tallest self-supporting tower" and "the world's tallest free-standing tower". Although Guinness did list this description of the CN Tower under the heading "tallest building" at least once, it has also listed it under "tallest tower", omitting it from its list of "tallest buildings." In 1996, Guinness changed the tower's classification to "World's Tallest Building and Freestanding Structure". Emporis and the Council on Tall Buildings and Urban Habitat both listed the CN Tower as the world's tallest free-standing structure on land, and specifically state that the CN Tower is not a true building, thereby awarding the title of world's tallest building to Taipei 101, which is shorter than the CN Tower. The issue of what was tallest became moot when Burj Khalifa, then under construction, exceeded the height of the CN Tower in 2007 (see below).

Although the CN Tower contains a restaurant, a gift shop and multiple observation levels, it does not have floors continuously from the ground, and therefore it is not considered a building by the Council on Tall Buildings and Urban Habitat (CTBUH) or Emporis. CTBUH defines a building as "a structure that is designed for residential, business, or manufacturing purposes. An essential characteristic of a building is that it has floors." The CN Tower and other similar structures—such as the Ostankino Tower in Moscow, Russia; the Oriental Pearl Tower in Shanghai, China; The Strat in Las Vegas, Nevada, United States; and the Eiffel Tower in Paris, France—are categorized as "towers", which are free-standing structures that may have observation decks and a few other habitable levels, but do not have floors from the ground up. The CN Tower was the tallest tower by this definition until 2010 (see below).

Taller than the CN Tower are numerous radio masts and towers, which are held in place by guy-wires, the tallest being the KVLY-TV mast in Blanchard, North Dakota in the United States at tall, leading to a distinction between these and "free-standing" structures. Additionally, the Petronius Platform stands above its base on the bottom of the Gulf of Mexico, but only the top of this oil and natural gas platform are above water, and the structure is thus partially supported by its buoyancy. Like the CN Tower, none of these taller structures are commonly considered buildings.

On September 12, 2007, Burj Khalifa, which is a hotel, residential and commercial building in Dubai, United Arab Emirates, and was formerly known as Burj Dubai before opening, passed the CN Tower's 553.33-metre height. The CN Tower held the record of tallest freestanding structure on land for over 30 years.

After Burj Khalifa had been formally recognized by the Guinness World Records as the world's tallest freestanding structure, Guinness re-certified CN Tower as the world's tallest freestanding tower. The tower definition used by Guinness was defined by the Council on Tall Buildings and Urban Habitat as 'a building in which less than 50% of the construction is usable floor space'. "Guinness World Records" editor-in-chief Craig Glenday announced that Burj Khalifa was not classified as a tower because it has too much usable floor space to be considered to be a tower. CN Tower still held world records for highest above ground wine cellar (in 360 Restaurant) at 351 metres, highest above ground restaurant at 346 metres (Horizons Restaurant), and tallest free-standing concrete tower during Guinness's recertification. The CN Tower was surpassed in 2009 by the Canton Tower in Guangzhou, China, which stands at tall, as the world's tallest tower; which in turn was surpassed by the Tokyo Skytree in 2011, which currently is the tallest tower at in height. The CN Tower, as of 2018, stands as the ninth-tallest free-standing structure on land, remains the tallest free-standing structure in the Western Hemisphere, and is the third-tallest tower.

Since the construction of the tower had been completed, it has gained the following world height records:

The CN Tower has been and continues to be used as a communications tower for a number of different media and by numerous companies.

There is no AM broadcasting on the CN Tower. The FM transmitters are situated in a 102-metre (334.6 ft) tall metal broadcast antenna, on top of the main concrete portion of the tower at an elevation above 446.5 metres (1,465 ft).


The CN Tower has been featured in numerous films, television shows, music recording covers, and video games. The tower also has its own official mascot, which resembles the tower itself.




</doc>
<doc id="6113" url="https://en.wikipedia.org/wiki?curid=6113" title="Chain rule">
Chain rule

In calculus, the chain rule is a formula to compute the derivative of a composite function. That is, if and are differentiable functions, then the chain rule expresses the derivative of their composite — the function which maps ' to formula_1— in terms of the derivatives of ' and " and the product of functions as follows:

Alternatively, by letting (equiv., for all "), one can also write the chain rule in Lagrange's notation, as follows:

The chain rule may also be rewritten in Leibniz's notation in the following way. If a variable ' depends on the variable ', which itself depends on the variable ' (i.e., ' and ' are dependent variables), then ', via the intermediate variable of ', depends on ' as well. In which case, the chain rule states that:

More precisely, to indicate the point each derivative is evaluated at, formula_5.

The versions of the chain rule in the Lagrange and the Leibniz notation are equivalent, in the sense that if formula_6 and formula_7, so that formula_8, then

and

Intuitively, the chain rule states that knowing the instantaneous rate of change of "z" relative to "y" and that of "y" relative to "x" allows one to calculate the instantaneous rate of change of "z" relative to "x". As put by George F. Simmons: "if a car travels twice as fast as a bicycle and the bicycle is four times as fast as a walking man, then the car travels 2 × 4 = 8 times as fast as the man."

In integration, the counterpart to the chain rule is the substitution rule.

The chain rule seems to have first been used by Gottfried Wilhelm Leibniz. He used it to calculate the derivative of formula_11 as the composite of the square root function and the function formula_12. He first mentioned it in a 1676 memoir (with a sign error in the calculation). The common notation of chain rule is due to Leibniz. Guillaume de l'Hôpital used the chain rule implicitly in his "Analyse des infiniment petits". The chain rule does not appear in any of Leonhard Euler's analysis books, even though they were written over a hundred years after Leibniz's discovery.

Suppose that a skydiver jumps from an aircraft. Assume that seconds after his jump, his height above sea level in meters is given by . One model for the atmospheric pressure at a height " is . These two equations can be differentiated and combined in various ways to produce the following data:

Here, the chain rule gives a method for computing in terms of and . While it is always possible to directly apply the definition of the derivative to compute the derivative of a composite function, this is usually very difficult. The utility of the chain rule is that it turns a complicated derivative into several easy derivatives.

The chain rule states that, under appropriate conditions,
In this example, this equals

In the statement of the chain rule, and play slightly different roles because is evaluated at formula_15, whereas is evaluated at ". This is necessary to make the units work out correctly.

For example, suppose that we want to compute the rate of change in atmospheric pressure ten seconds after the skydiver jumps. This is and has units of pascals per second. The factor in the chain rule is the velocity of the skydiver ten seconds after his jump, and it is expressed in meters per second. formula_16 is the change in pressure with respect to height at the height and is expressed in pascals per meter. The product of formula_16 and formula_18 therefore has the correct units of pascals per second.

Here, notice that it is not possible to evaluate " anywhere else. For instance, the 10 in the problem represents ten seconds, while the expression formula_19 would represent the change in pressure at a height of ten meters, which is not what we wanted. Similarly, while has a unit of meters per second, the expression would represent the change in pressure at a height of −98 meters, which is again not what we wanted. However, is 3020 meters above sea level, the height of the skydiver ten seconds after his jump, and this has the correct units for an input to .

The simplest form of the chain rule is for real-valued functions of one real variable. It states that if ' is a function that is differentiable at a point ' (i.e. the derivative exists) and ' is a function that is differentiable at , then the composite function is differentiable at ', and the derivative is

The rule is sometimes abbreviated as

If and , then this abbreviated form is written in Leibniz notation as:

The points where the derivatives are evaluated may also be stated explicitly:

Carrying the same reasoning further, given " functions formula_24 with the composite function formula_25, if each function formula_26 is differentiable at its immediate input, then the composite function is also differentiable by the repeated application of Chain Rule, where the derivative is (in Leibniz's notation):

It may be possible to apply the chain rule even when there are no formulas for the functions which are being differentiated. This can happen when the derivatives are measured directly. Suppose that a car is driving up a tall mountain. The car's speedometer measures its speed directly. If the grade is known, then the rate of ascent can be calculated using trigonometry. Suppose that the car is ascending at . Standard models for the Earth's atmosphere imply that the temperature drops about per kilometer ascended (called the lapse rate). To find the temperature drop per hour, we can apply the chain rule. Let the function be the altitude of the car at time , and let the function be the temperature kilometers above sea level. and are not known exactly: For example, the altitude where the car starts is not known and the temperature on the mountain is not known. However, their derivatives are known: is , and is . The chain rule states that the derivative of the composite function is the product of the derivative of and the derivative of . This is .

One of the reasons why this computation is possible is because is a constant function. A more accurate description of how the temperature near the car varies over time would require an accurate model of how the temperature varies at different altitudes. This model may not have a constant derivative. To compute the temperature change in such a model, it would be necessary to know and not just , because without knowing it is not possible to know where to evaluate .

The chain rule can be applied to composites of more than two functions. To take the derivative of a composite of more than two functions, notice that the composite of , , and ' (in that order) is the composite of with . The chain rule states that to compute the derivative of , it is sufficient to compute the derivative of ' and the derivative of . The derivative of "" can be calculated directly, and the derivative of can be calculated by applying the chain rule again.

For concreteness, consider the function
This can be decomposed as the composite of three functions:
Their derivatives are:

The chain rule states that the derivative of their composite at the point is:

In Leibniz notation, this is:
or for short,
The derivative function is therefore:

Another way of computing this derivative is to view the composite function as the composite of and "h". Applying the chain rule in this manner would yield:

This is the same as what was computed above. This should be expected because .

Sometimes, it is necessary to differentiate an arbitrarily long composition of the form formula_36. In this case, define
where formula_38 and formula_39 when formula_40. Then the chain rule takes the form
or, in the Lagrange notation,

The chain rule can be used to derive some well-known differentiation rules. For example, the quotient rule is a consequence of the chain rule and the product rule. To see this, write the function as the product . First apply the product rule:

To compute the derivative of , notice that it is the composite of with the reciprocal function, that is, the function that sends to . The derivative of the reciprocal function is formula_44. By applying the chain rule, the last expression becomes:

which is the usual formula for the quotient rule.

Suppose that has an inverse function. Call its inverse function so that we have . There is a formula for the derivative of in terms of the derivative of . To see this, note that ' and ' satisfy the formula

And because the functions formula_47 and are equal, their derivatives must be equal. The derivative of " is the constant function with value 1, and the derivative of formula_47 is determined by the chain rule. Therefore, we have that:

To express as a function of an independent variable ', we substitute formula_50 for ' wherever it appears. Then we can solve for .

For example, consider the function . It has an inverse . Because , the above formula says that

This formula is true whenever is differentiable and its inverse ' is also differentiable. This formula can fail when one of these conditions is not true. For example, consider . Its inverse is , which is not differentiable at zero. If we attempt to use the above formula to compute the derivative of ' at zero, then we must evaluate . Since and , we must evaluate 1/0, which is undefined. Therefore, the formula fails in this case. This is not surprising because " is not differentiable at zero.

Faà di Bruno's formula generalizes the chain rule to higher derivatives. Assuming that and , then the first few derivatives are:

One proof of the chain rule begins with the definition of the derivative:

Assume for the moment that formula_55 does not equal formula_56 for any near ". Then the previous expression is equal to the product of two factors:

If formula_58 oscillates near ', then it might happen that no matter how close one gets to ', there is always an even closer " such that formula_55 equals formula_56. For example, this happens for near the point . Whenever this happens, the above expression is undefined because it involves division by zero. To work around this, introduce a function "formula_61" as follows:

We will show that the difference quotient for is always equal to:

Whenever is not equal to , this is clear because the factors of cancel. When equals , then the difference quotient for is zero because equals , and the above product is zero because it equals times zero. So the above product is always equal to the difference quotient, and to show that the derivative of at exists and to determine its value, we need only show that the limit as goes to of the above product exists and determine its value.

To do this, recall that the limit of a product exists if the limits of its factors exist. When this happens, the limit of the product of these two factors will equal the product of the limits of the factors. The two factors are and . The latter is the difference quotient for at , and because ' is differentiable at ' by assumption, its limit as ' tends to ' exists and equals .

As for , notice that is defined wherever ' is. Furthermore, ' is differentiable at by assumption, so is continuous at , by definition of the derivative. The function ' is continuous at ' because it is differentiable at ', and therefore is continuous at '. So its limit as ' goes to ' exists and equals , which is .

This shows that the limits of both factors exist and that they equal and , respectively. Therefore, the derivative of at "a" exists and equals .

Another way of proving the chain rule is to measure the error in the linear approximation determined by the derivative. This proof has the advantage that it generalizes to several variables. It relies on the following equivalent definition of differentiability at a point: A function "g" is differentiable at "a" if there exists a real number "g"′("a") and a function "ε"("h") that tends to zero as "h" tends to zero, and furthermore
Here the left-hand side represents the true difference between the value of "g" at "a" and at , whereas the right-hand side represents the approximation determined by the derivative plus an error term.

In the situation of the chain rule, such a function "ε" exists because "g" is assumed to be differentiable at "a". Again by assumption, a similar function also exists for "f" at "g"("a"). Calling this function "η", we have
The above definition imposes no constraints on "η"(0), even though it is assumed that "η"("k") tends to zero as "k" tends to zero. If we set , then "η" is continuous at 0.

Proving the theorem requires studying the difference as "h" tends to zero. The first step is to substitute for using the definition of differentiability of "g" at "a":
The next step is to use the definition of differentiability of "f" at "g"("a"). This requires a term of the form for some "k". In the above equation, the correct "k" varies with "h". Set and the right hand side becomes . Applying the definition of the derivative gives:
To study the behavior of this expression as "h" tends to zero, expand "k". After regrouping the terms, the right-hand side becomes:
Because "ε"("h") and "η"("k") tend to zero as "h" tends to zero, the first two bracketed terms tend to zero as "h" tends to zero. Applying the same theorem on products of limits as in the first proof, the third bracketed term also tends zero. Because the above expression is equal to the difference , by the definition of the derivative is differentiable at "a" and its derivative is 

The role of "Q" in the first proof is played by "η" in this proof. They are related by the equation:
The need to define "Q" at "g"("a") is analogous to the need to define "η" at zero.

Constantin Carathéodory's alternative definition of the differentiability of a function can be used to give an elegant proof of the chain rule.

Under this definition, a function is differentiable at a point if and only if there is a function , continuous at and such that . There is at most one such function, and if is differentiable at then .

Given the assumptions of the chain rule and the fact that differentiable functions and compositions of continuous functions are continuous, we have that there exist functions , continuous at and , continuous at and such that,
and
Therefore,
but the function given by is continuous at , and we get, for this 
A similar approach works for continuously differentiable (vector-)functions of many variables. This method of factoring also allows a unified approach to stronger forms of differentiability, when the derivative is required to be Lipschitz continuous, Hölder continuous, etc. Differentiation itself can be viewed as the polynomial remainder theorem (the little Bézout theorem, or factor theorem), generalized to an appropriate class of functions. 

If formula_74 and formula_75 then choosing infinitesimal formula_76 we compute the corresponding formula_77 and then the corresponding formula_78, so that
and applying the standard part we obtain
which is the chain rule.

The generalization of the chain rule to multi-variable functions is rather technical. However, it is simpler to write in the case of functions of the form 

As this case occurs often in the study of functions of a single variable, it is worth describing it separately.

For writing the chain rule for a function of the form 
one needs the partial derivatives of with respect to its arguments. The usual notations for partial derivatives involve names for the arguments of the function. As these arguments are not named in the above formula, it is simpler and clearer to denote by 
the derivative of with respect to its th argument, and by 
the value of this derivative at .

With this notation, the chain rule is

If the function is addition, that is, if 
then formula_86 (the constant function 1). 
Thus, the chain rule gives 

For multiplication
the partials are formula_89 and formula_90 Thus, 

The case of exponentiation
is slightly more complicated, as 
and, as formula_94
It follows that 

The simplest way for writing the chain rule in the general case is to use the total derivative, which is a linear transformation that captures all directional derivatives in a single formula. Consider differentiable functions and , and a point in . Let denote the total derivative of at and denote the total derivative of at . These two derivatives are linear transformations and , respectively, so they can be composed. The chain rule for total derivatives is that their composite is the total derivative of at :
or for short,
The higher-dimensional chain rule can be proved using a technique similar to the second proof given above.

Because the total derivative is a linear transformation, the functions appearing in the formula can be rewritten as matrices. The matrix corresponding to a total derivative is called a Jacobian matrix, and the composite of two derivatives corresponds to the product of their Jacobian matrices. From this perspective the chain rule therefore says:
or for short,

That is, the Jacobian of a composite function is the product of the Jacobians of the composed functions (evaluated at the appropriate points).

The higher-dimensional chain rule is a generalization of the one-dimensional chain rule. If "k", "m", and "n" are 1, so that and , then the Jacobian matrices of "f" and "g" are . Specifically, they are:
The Jacobian of "f" ∘ "g" is the product of these matrices, so it is , as expected from the one-dimensional chain rule. In the language of linear transformations, "D"("g") is the function which scales a vector by a factor of "g"′("a") and "D"("f") is the function which scales a vector by a factor of "f"′("g"("a")). The chain rule says that the composite of these two linear transformations is the linear transformation , and therefore it is the function that scales a vector by "f"′("g"("a"))⋅"g"′("a").

Another way of writing the chain rule is used when "f" and "g" are expressed in terms of their components as and . In this case, the above rule for Jacobian matrices is usually written as:

The chain rule for total derivatives implies a chain rule for partial derivatives. Recall that when the total derivative exists, the partial derivative in the "i"th coordinate direction is found by multiplying the Jacobian matrix by the "i"th basis vector. By doing this to the formula above, we find:
Since the entries of the Jacobian matrix are partial derivatives, we may simplify the above formula to get:
More conceptually, this rule expresses the fact that a change in the "x" direction may change all of "g" through "g", and any of these changes may affect "f".

In the special case where , so that "f" is a real-valued function, then this formula simplifies even further:
This can be rewritten as a dot product. Recalling that , the partial derivative is also a vector, and the chain rule says that:

Given where and , determine the value of and using the chain rule.
and

Faà di Bruno's formula for higher-order derivatives of single-variable functions generalizes to the multivariable case. If is a function of as above, then the second derivative of is:

All extensions of calculus have a chain rule. In most of these, the formula remains the same, though the meaning of that formula may be vastly different.

One generalization is to manifolds. In this situation, the chain rule represents the fact that the derivative of is the composite of the derivative of "f" and the derivative of "g". This theorem is an immediate consequence of the higher dimensional chain rule given above, and it has exactly the same formula.

The chain rule is also valid for Fréchet derivatives in Banach spaces. The same formula holds as before. This case and the previous one admit a simultaneous generalization to Banach manifolds.

In abstract algebra, the derivative is interpreted as a morphism of modules of Kähler differentials. A ring homomorphism of commutative rings determines a morphism of Kähler differentials which sends an element "dr" to "d"("f"("r")), the exterior differential of "f"("r"). The formula holds in this context as well.

The common feature of these examples is that they are expressions of the idea that the derivative is part of a functor. A functor is an operation on spaces and functions between them. It associates to each space a new space and to each function between two spaces a new function between the corresponding new spaces. In each of the above cases, the functor sends each space to its tangent bundle and it sends each function to its derivative. For example, in the manifold case, the derivative sends a "C"-manifold to a "C"-manifold (its tangent bundle) and a "C"-function to its total derivative. There is one requirement for this to be a functor, namely that the derivative of a composite must be the composite of the derivatives. This is exactly the formula .

There are also chain rules in stochastic calculus. One of these, Itō's lemma, expresses the composite of an Itō process (or more generally a semimartingale) "dX" with a twice-differentiable function "f". In Itō's lemma, the derivative of the composite function depends not only on "dX" and the derivative of "f" but also on the second derivative of "f". The dependence on the second derivative is a consequence of the non-zero quadratic variation of the stochastic process, which broadly speaking means that the process can move up and down in a very rough way. This variant of the chain rule is not an example of a functor because the two functions being composed are of different types.




</doc>
<doc id="6115" url="https://en.wikipedia.org/wiki?curid=6115" title="P versus NP problem">
P versus NP problem

The P versus NP problem is a major unsolved problem in computer science. It asks whether every problem whose solution can be quickly verified can also be solved quickly.

It is one of the seven Millennium Prize Problems selected by the Clay Mathematics Institute, each of which carries a US$1,000,000 prize for the first correct solution.

The informal term "quickly", used above, means the existence of an algorithm solving the task that runs in polynomial time, such that the time to complete the task varies as a polynomial function on the size of the input to the algorithm (as opposed to, say, exponential time). The general class of questions for which some algorithm can provide an answer in polynomial time is called "class P" or just "P". For some questions, there is no known way to find an answer quickly, but if one is provided with information showing what the answer is, it is possible to verify the answer quickly. The class of questions for which an answer can be "verified" in polynomial time is called NP, which stands for "nondeterministic polynomial time".

An answer to the P = NP question would determine whether problems that can be verified in polynomial time can also be solved in polynomial time. If it turned out that P ≠ NP, which is widely believed, it would mean that there are problems in NP that are harder to compute than to verify: they could not be solved in polynomial time, but the answer could be verified in polynomial time.

Aside from being an important problem in computational theory, a proof either way would have profound implications for mathematics, cryptography, algorithm research, artificial intelligence, game theory, multimedia processing, philosophy, economics and many other fields.

Consider Sudoku, a game where the player is given a partially filled-in grid of numbers and attempts to complete the grid following certain rules. Given an incomplete Sudoku grid, of any size, is there at least one legal solution? Any proposed solution is easily verified, and the time to check a solution grows slowly (polynomially) as the grid gets bigger. However, all known algorithms for finding solutions take, for difficult examples, time that grows exponentially as the grid gets bigger. So, Sudoku is in NP (quickly checkable) but does not seem to be in P (quickly solvable). Thousands of other problems seem similar, in that they are fast to check but slow to solve. Researchers have shown that many of the problems in NP have the extra property that a fast solution to any one of them could be used to build a quick solution to any other problem in NP, a property called NP-completeness. Decades of searching have not yielded a fast solution to any of these problems, so most scientists suspect that none of these problems can be solved quickly. This, however, has never been proven.

The precise statement of the P versus NP problem was introduced in 1971 by Stephen Cook in his seminal paper "The complexity of theorem proving procedures" (and independently by Leonid Levin in 1973) and is considered by many to be the most important open problem in computer science.

Although the P versus NP problem was formally defined in 1971, there were previous inklings of the problems involved, the difficulty of proof, and the potential consequences. In 1955, mathematician John Nash wrote a letter to the NSA, where he speculated that cracking a sufficiently complex code would require time exponential in the length of the key. If proved (and Nash was suitably skeptical) this would imply what is now called P ≠ NP, since a proposed key can easily be verified in polynomial time. Another mention of the underlying problem occurred in a 1956 letter written by Kurt Gödel to John von Neumann. Gödel asked whether theorem-proving (now known to be co-NP-complete) could be solved in quadratic or linear time, and pointed out one of the most important consequences—that if so, then the discovery of mathematical proofs could be automated.

The relation between the complexity classes P and NP is studied in computational complexity theory, the part of the theory of computation dealing with the resources required during computation to solve a given problem. The most common resources are time (how many steps it takes to solve a problem) and space (how much memory it takes to solve a problem).

In such analysis, a model of the computer for which time must be analyzed is required. Typically such models assume that the computer is "deterministic" (given the computer's present state and any inputs, there is only one possible action that the computer might take) and "sequential" (it performs actions one after the other).

In this theory, the class P consists of all those "decision problems" (defined below) that can be solved on a deterministic sequential machine in an amount of time that is polynomial in the size of the input; the class NP consists of all those decision problems whose positive solutions can be verified in polynomial time given the right information, or equivalently, whose solution can be found in polynomial time on a non-deterministic machine. Clearly, P ⊆ NP. Arguably the biggest open question in theoretical computer science concerns the relationship between those two classes:

Since 2002, William Gasarch has conducted three polls of researchers concerning this and related questions. Confidence that P ≠ NP has been increasing — in 2019, 88% believed P ≠ NP, as opposed to 83% in 2012 and 61% in 2002. When restricted to experts, the 2019 answers became 99% believe P ≠ NP.

To attack the P = NP question, the concept of NP-completeness is very useful. NP-complete problems are a set of problems to each of which any other NP-problem can be reduced in polynomial time and whose solution may still be verified in polynomial time. That is, any NP problem can be transformed into any of the NP-complete problems. Informally, an NP-complete problem is an NP problem that is at least as "tough" as any other problem in NP.

NP-hard problems are those at least as hard as NP problems, i.e., all NP problems can be reduced (in polynomial time) to them. NP-hard problems need not be in NP, i.e., they need not have solutions verifiable in polynomial time.

For instance, the Boolean satisfiability problem is NP-complete by the Cook–Levin theorem, so "any" instance of "any" problem in NP can be transformed mechanically into an instance of the Boolean satisfiability problem in polynomial time. The Boolean satisfiability problem is one of many such NP-complete problems. If any NP-complete problem is in P, then it would follow that P = NP. However, many important problems have been shown to be NP-complete, and no fast algorithm for any of them is known.

Based on the definition alone it is not obvious that NP-complete problems exist; however, a trivial and contrived NP-complete problem can be formulated as follows: given a description of a Turing machine "M" guaranteed to halt in polynomial time, does there exist a polynomial-size input that "M" will accept? It is in NP because (given an input) it is simple to check whether "M" accepts the input by simulating "M"; it is NP-complete because the verifier for any particular instance of a problem in NP can be encoded as a polynomial-time machine "M" that takes the solution to be verified as input. Then the question of whether the instance is a yes or no instance is determined by whether a valid input exists.

The first natural problem proven to be NP-complete was the Boolean satisfiability problem, also known as SAT. As noted above, this is the Cook–Levin theorem; its proof that satisfiability is NP-complete contains technical details about Turing machines as they relate to the definition of NP. However, after this problem was proved to be NP-complete, proof by reduction provided a simpler way to show that many other problems are also NP-complete, including the game Sudoku discussed earlier. In this case, the proof shows that a solution of Sudoku in polynomial time could also be used to complete Latin squares in polynomial time. This in turn gives a solution to the problem of partitioning tri-partite graphs into triangles, which could then be used to find solutions for the special case of SAT known as 3-SAT, which then provides a solution for general Boolean satisfiability. So a polynomial time solution to Sudoku leads, by a series of mechanical transformations, to a polynomial time solution of satisfiability, which in turn can be used to solve any other NP-problem in polynomial time. Using transformations like this, a vast class of seemingly unrelated problems are all reducible to one another, and are in a sense "the same problem".

Although it is unknown whether P = NP, problems outside of P are known. Just as the class P is defined in terms of polynomial running time, the class EXPTIME is the set of all decision problems that have "exponential" running time. In other words, any problem in EXPTIME is solvable by a deterministic Turing machine in O(2) time, where "p"("n") is a polynomial function of "n". A decision problem is EXPTIME-complete if it is in EXPTIME, and every problem in EXPTIME has a polynomial-time many-one reduction to it. A number of problems are known to be EXPTIME-complete. Because it can be shown that P ≠ EXPTIME, these problems are outside P, and so require more than polynomial time. In fact, by the time hierarchy theorem, they cannot be solved in significantly less than exponential time. Examples include finding a perfect strategy for chess positions on an "N" × "N" board and similar problems for other board games.

The problem of deciding the truth of a statement in Presburger arithmetic requires even more time. Fischer and Rabin proved in 1974 that every algorithm that decides the truth of Presburger statements of length "n" has a runtime of at least formula_1 for some constant "c". Hence, the problem is known to need more than exponential run time. Even more difficult are the undecidable problems, such as the halting problem. They cannot be completely solved by any algorithm, in the sense that for any particular algorithm there is at least one input for which that algorithm will not produce the right answer; it will either produce the wrong answer, finish without giving a conclusive answer, or otherwise run forever without producing any answer at all.

It is also possible to consider questions other than decision problems. One such class, consisting of counting problems, is called #P: whereas an NP problem asks "Are there any solutions?", the corresponding #P problem asks "How many solutions are there?" Clearly, a #P problem must be at least as hard as the corresponding NP problem, since a count of solutions immediately tells if at least one solution exists, if the count is greater than zero. Surprisingly, some #P problems that are believed to be difficult correspond to easy (for example linear-time) P problems. For these problems, it is very easy to tell whether solutions exist, but thought to be very hard to tell how many. Many of these problems are #P-complete, and hence among the hardest problems in #P, since a polynomial time solution to any of them would allow a polynomial time solution to all other #P problems.

In 1975, Richard E. Ladner showed that if P ≠ NP then there exist problems in NP that are neither in P nor NP-complete. Such problems are called NP-intermediate problems. The graph isomorphism problem, the discrete logarithm problem and the integer factorization problem are examples of problems believed to be NP-intermediate. They are some of the very few NP problems not known to be in P or to be NP-complete.

The graph isomorphism problem is the computational problem of determining whether two finite graphs are isomorphic. An important unsolved problem in complexity theory is whether the graph isomorphism problem is in P, NP-complete, or NP-intermediate. The answer is not known, but it is believed that the problem is at least not NP-complete. If graph isomorphism is NP-complete, the polynomial time hierarchy collapses to its second level. Since it is widely believed that the polynomial hierarchy does not collapse to any finite level, it is believed that graph isomorphism is not NP-complete. The best algorithm for this problem, due to László Babai and Eugene Luks, has run time 2 for graphs with "n" vertices.

The integer factorization problem is the computational problem of determining the prime factorization of a given integer. Phrased as a decision problem, it is the problem of deciding whether the input has a factor less than "k". No efficient integer factorization algorithm is known, and this fact forms the basis of several modern cryptographic systems, such as the RSA algorithm. The integer factorization problem is in NP and in co-NP (and even in UP and co-UP). If the problem is NP-complete, the polynomial time hierarchy will collapse to its first level (i.e., NP = co-NP). The best known algorithm for integer factorization is the general number field sieve, which takes expected time

to factor an "n"-bit integer. However, the best known quantum algorithm for this problem, Shor's algorithm, does run in polynomial time, although this does not indicate where the problem lies with respect to non-quantum complexity classes.

All of the above discussion has assumed that P means "easy" and "not in P" means "hard", an assumption known as "Cobham's thesis". It is a common and reasonably accurate assumption in complexity theory; however, it has some caveats.

First, it is not always true in practice. A theoretical polynomial algorithm may have extremely large constant factors or exponents thus rendering it impractical. For example, the problem of deciding whether a graph "G" contains "H" as a minor, where "H" is fixed, can be solved in a running time of "O"("n"), where "n" is the number of vertices in "G". However, the big O notation hides a constant that depends superexponentially on "H". The constant is greater than formula_3 (using Knuth's up-arrow notation), and where "h" is the number of vertices in "H".

On the other hand, even if a problem is shown to be NP-complete, and even if P ≠ NP, there may still be effective approaches to tackling the problem in practice. There are algorithms for many NP-complete problems, such as the knapsack problem, the traveling salesman problem and the Boolean satisfiability problem, that can solve to optimality many real-world instances in reasonable time. The empirical average-case complexity (time vs. problem size) of such algorithms can be surprisingly low. An example is the simplex algorithm in linear programming, which works surprisingly well in practice; despite having exponential worst-case time complexity it runs on par with the best known polynomial-time algorithms.

Finally, there are types of computations which do not conform to the Turing machine model on which P and NP are defined, such as quantum computation and randomized algorithms.

According to polls, most computer scientists believe that P ≠ NP. A key reason for this belief is that after decades of studying these problems no one has been able to find a polynomial-time algorithm for any of more than 3000 important known NP-complete problems (see List of NP-complete problems). These algorithms were sought long before the concept of NP-completeness was even defined (Karp's 21 NP-complete problems, among the first found, were all well-known existing problems at the time they were shown to be NP-complete). Furthermore, the result P = NP would imply many other startling results that are currently believed to be false, such as NP = co-NP and P = PH.

It is also intuitively argued that the existence of problems that are hard to solve but for which the solutions are easy to verify matches real-world experience.
On the other hand, some researchers believe that there is overconfidence in believing P ≠ NP and that researchers should explore proofs of P = NP as well. For example, in 2002 these statements were made:

One of the reasons the problem attracts so much attention is the consequences of the answer. Either direction of resolution would advance theory enormously, and perhaps have huge practical consequences as well.

A proof that P = NP could have stunning practical consequences if the proof leads to efficient methods for solving some of the important problems in NP. It is also possible that a proof would not lead directly to efficient methods, perhaps if the proof is non-constructive, or the size of the bounding polynomial is too big to be efficient in practice. The consequences, both positive and negative, arise since various NP-complete problems are fundamental in many fields.

Cryptography, for example, relies on certain problems being difficult. A constructive and efficient solution to an NP-complete problem such as 3-SAT would break most existing cryptosystems including:
These would need to be modified or replaced by information-theoretically secure solutions not inherently based on P-NP inequivalence.

On the other hand, there are enormous positive consequences that would follow from rendering tractable many currently mathematically intractable problems. For instance, many problems in operations research are NP-complete, such as some types of integer programming and the travelling salesman problem. Efficient solutions to these problems would have enormous implications for logistics. Many other important problems, such as some problems in protein structure prediction, are also NP-complete; if these problems were efficiently solvable, it could spur considerable advances in life sciences and biotechnology.

But such changes may pale in significance compared to the revolution an efficient method for solving NP-complete problems would cause in mathematics itself. Gödel, in his early thoughts on computational complexity, noted that a mechanical method that could solve any problem would revolutionize mathematics:

Similarly, Stephen Cook says

Research mathematicians spend their careers trying to prove theorems, and some proofs have taken decades or even centuries to find after problems have been stated—for instance, Fermat's Last Theorem took over three centuries to prove. A method that is guaranteed to find proofs to theorems, should one exist of a "reasonable" size, would essentially end this struggle.

Donald Knuth has stated that he has come to believe that P = NP, but is reserved about the impact of a possible proof:
A proof that showed that P ≠ NP would lack the practical computational benefits of a proof that P = NP, but would nevertheless represent a very significant advance in computational complexity theory and provide guidance for future research. It would allow one to show in a formal way that many common problems cannot be solved efficiently, so that the attention of researchers can be focused on partial solutions or solutions to other problems. Due to widespread belief in P ≠ NP, much of this focusing of research has already taken place.

Also P ≠ NP still leaves open the average-case complexity of hard problems in NP. For example, it is possible that SAT requires exponential time in the worst case, but that almost all randomly selected instances of it are efficiently solvable. Russell Impagliazzo has described five hypothetical "worlds" that could result from different possible resolutions to the average-case complexity question. These range from "Algorithmica", where P = NP and problems like SAT can be solved efficiently in all instances, to "Cryptomania", where P ≠ NP and generating hard instances of problems outside P is easy, with three intermediate possibilities reflecting different possible distributions of difficulty over instances of NP-hard problems. The "world" where P ≠ NP but all problems in NP are tractable in the average case is called "Heuristica" in the paper. A Princeton University workshop in 2009 studied the status of the five worlds.

Although the P = NP problem itself remains open despite a million-dollar prize and a huge amount of dedicated research, efforts to solve the problem have led to several new techniques. In particular, some of the most fruitful research related to the P = NP problem has been in showing that existing proof techniques are not powerful enough to answer the question, thus suggesting that novel technical approaches are required.

As additional evidence for the difficulty of the problem, essentially all known proof techniques in computational complexity theory fall into one of the following classifications, each of which is known to be insufficient to prove that P ≠ NP:
These barriers are another reason why NP-complete problems are useful: if a polynomial-time algorithm can be demonstrated for an NP-complete problem, this would solve the P = NP problem in a way not excluded by the above results.

These barriers have also led some computer scientists to suggest that the P versus NP problem may be independent of standard axiom systems like ZFC (cannot be proved or disproved within them). The interpretation of an independence result could be that either no polynomial-time algorithm exists for any NP-complete problem, and such a proof cannot be constructed in (e.g.) ZFC, or that polynomial-time algorithms for NP-complete problems may exist, but it is impossible to prove in ZFC that such algorithms are correct. However, if it can be shown, using techniques of the sort that are currently known to be applicable, that the problem cannot be decided even with much weaker assumptions extending the Peano axioms (PA) for integer arithmetic, then there would necessarily exist nearly-polynomial-time algorithms for every problem in NP. Therefore, if one believes (as most complexity theorists do) that not all problems in NP have efficient algorithms, it would follow that proofs of independence using those techniques cannot be possible. Additionally, this result implies that proving independence from PA or ZFC using currently known techniques is no easier than proving the existence of efficient algorithms for all problems in NP.

While the P versus NP problem is generally considered unsolved, many amateur and some professional researchers have claimed solutions. Gerhard J. Woeginger maintains a list that, as of 2018, contains 62 purported proofs of P = NP, 50 proofs of P ≠ NP, 2 proofs the problem is unprovable, and one proof that it is undecidable. Some attempts at resolving P versus NP have received brief media attention, though these attempts have since been refuted.

The P = NP problem can be restated in terms of expressible certain classes of logical statements, as a result of work in descriptive complexity.

Consider all languages of finite structures with a fixed signature including a linear order relation. Then, all such languages in P can be expressed in first-order logic with the addition of a suitable least fixed-point combinator. Effectively, this, in combination with the order, allows the definition of recursive functions. As long as the signature contains at least one predicate or function in addition to the distinguished order relation, so that the amount of space taken to store such finite structures is actually polynomial in the number of elements in the structure, this precisely characterizes P.

Similarly, NP is the set of languages expressible in existential second-order logic—that is, second-order logic restricted to exclude universal quantification over relations, functions, and subsets. The languages in the polynomial hierarchy, PH, correspond to all of second-order logic. Thus, the question "is P a proper subset of NP" can be reformulated as "is existential second-order logic able to describe languages (of finite linearly ordered structures with nontrivial signature) that first-order logic with least fixed point cannot?". The word "existential" can even be dropped from the previous characterization, since P = NP if and only if P = PH (as the former would establish that NP = co-NP, which in turn implies that NP = PH).

No algorithm for any NP-complete problem is known to run in polynomial time. However, there are algorithms known for NP-complete problems with the property that if P = NP, then the algorithm runs in polynomial time on accepting instances (although with enormous constants, making the algorithm impractical). However, these algorithms do not qualify as polynomial time because their running time on rejecting instances are not polynomial. The following algorithm, due to Levin (without any citation), is such an example below. It correctly accepts the NP-complete language SUBSET-SUM. It runs in polynomial time on inputs that are in SUBSET-SUM if and only if P = NP:

If, and only if, P = NP, then this is a polynomial-time algorithm accepting an NP-complete language. "Accepting" means it gives "yes" answers in polynomial time, but is allowed to run forever when the answer is "no" (also known as a "semi-algorithm").

This algorithm is enormously impractical, even if P = NP. If the shortest program that can solve SUBSET-SUM in polynomial time is "b" bits long, the above algorithm will try at least other programs first.

Conceptually speaking, a "decision problem" is a problem that takes as input some string "w" over an alphabet Σ, and outputs "yes" or "no". If there is an algorithm (say a Turing machine, or a computer program with unbounded memory) that can produce the correct answer for any input string of length "n" in at most "cn" steps, where "k" and "c" are constants independent of the input string, then we say that the problem can be solved in "polynomial time" and we place it in the class P. Formally, P is defined as the set of all languages that can be decided by a deterministic polynomial-time Turing machine. That is,
where
and a deterministic polynomial-time Turing machine is a deterministic Turing machine "M" that satisfies the following two conditions:


NP can be defined similarly using nondeterministic Turing machines (the traditional way). However, a modern approach to define NP is to use the concept of "certificate" and "verifier". Formally, NP is defined as the set of languages over a finite alphabet that have a verifier that runs in polynomial time, where the notion of "verifier" is defined as follows.

Let "L" be a language over a finite alphabet, Σ.

"L" ∈ NP if, and only if, there exists a binary relation formula_10 and a positive integer "k" such that the following two conditions are satisfied:


A Turing machine that decides "L" is called a "verifier" for "L" and a "y" such that ("x", "y") ∈ "R" is called a "certificate of membership" of "x" in "L".

In general, a verifier does not have to be polynomial-time. However, for "L" to be in NP, there must be a verifier that runs in polynomial time.

Let
Clearly, the question of whether a given "x" is a composite is equivalent to the question of whether "x" is a member of COMPOSITE. It can be shown that COMPOSITE ∈ NP by verifying that it satisfies the above definition (if we identify natural numbers with their binary representations).

COMPOSITE also happens to be in P, a fact demonstrated by the invention of the AKS primality test.

There are many equivalent ways of describing NP-completeness.

Let "L" be a language over a finite alphabet Σ.

"L" is NP-complete if, and only if, the following two conditions are satisfied:


Alternatively, if "L" ∈ NP, and there is another NP-complete problem that can be polynomial-time reduced to "L", then "L" is NP-complete. This is a common way of proving some new problem is NP-complete.

The film "Travelling Salesman", by director Timothy Lanzone, is the story of four mathematicians hired by the US government to solve the P versus NP problem.

In the sixth episode of "The Simpsons" seventh season "Treehouse of Horror VI", the equation P=NP is seen shortly after Homer accidentally stumbles into the "third dimension".

In the second episode of season 2 of "Elementary", "Solve for X" revolves around Sherlock and Watson investigating the murders of mathematicians who were attempting to solve P versus NP.





</doc>
<doc id="6117" url="https://en.wikipedia.org/wiki?curid=6117" title="Charles Sanders Peirce">
Charles Sanders Peirce

Charles Sanders Peirce ( ; September 10, 1839 – April 19, 1914) was an American philosopher, logician, mathematician, and scientist who is sometimes known as "the father of pragmatism". He was educated as a chemist and employed as a scientist for thirty years. Today he is appreciated largely for his contributions to logic, mathematics, philosophy, scientific methodology, and semiotics, and for his founding of pragmatism.

An innovator in mathematics, statistics, philosophy, research methodology, and various sciences, Peirce considered himself, first and foremost, a logician. He made major contributions to logic, but logic for him encompassed much of that which is now called epistemology and philosophy of science. He saw logic as the formal branch of semiotics, of which he is a founder, which foreshadowed the debate among logical positivists and proponents of philosophy of language that dominated 20th-century Western philosophy. Additionally, he defined the concept of abductive reasoning, as well as rigorously formulated mathematical induction and deductive reasoning. As early as 1886 he saw that logical operations could be carried out by electrical switching circuits. The same idea was used decades later to produce digital computers.

In 1934, the philosopher Paul Weiss called Peirce "the most original and versatile of American philosophers and America's greatest logician". "Webster's Biographical Dictionary" said in 1943 that Peirce was "now regarded as the most original thinker and greatest logician of his time".

Peirce was born at 3 Phillips Place in Cambridge, Massachusetts. He was the son of Sarah Hunt Mills and Benjamin Peirce, himself a professor of astronomy and mathematics at Harvard University and perhaps the first serious research mathematician in America. At age 12, Charles read his older brother's copy of Richard Whately's "Elements of Logic", then the leading English-language text on the subject. So began his lifelong fascination with logic and reasoning. He went on to earn a Bachelor of Arts degree and a Master of Arts degree (1862) from Harvard. In 1863 the Lawrence Scientific School awarded him a Bachelor of Science degree, Harvard's first "summa cum laude" chemistry degree. His academic record was otherwise undistinguished. At Harvard, he began lifelong friendships with Francis Ellingwood Abbot, Chauncey Wright, and William James. One of his Harvard instructors, Charles William Eliot, formed an unfavorable opinion of Peirce. This proved fateful, because Eliot, while President of Harvard (1869–1909—a period encompassing nearly all of Peirce's working life), repeatedly vetoed Peirce's employment at the university.

Peirce suffered from his late-teens onward from a nervous condition then known as "facial neuralgia", which would today be diagnosed as trigeminal neuralgia. His biographer, Joseph Brent, says that when in the throes of its pain "he was, at first, almost stupefied, and then aloof, cold, depressed, extremely suspicious, impatient of the slightest crossing, and subject to violent outbursts of temper". Its consequences may have led to the social isolation of his later life.

Between 1859 and 1891, Peirce was intermittently employed in various scientific capacities by the United States Coast Survey and its successor, the United States Coast and Geodetic Survey, where he enjoyed his highly influential father's protection until the latter's death in 1880. That employment exempted Peirce from having to take part in the American Civil War; it would have been very awkward for him to do so, as the Boston Brahmin Peirces sympathized with the Confederacy. At the Survey, he worked mainly in geodesy and gravimetry, refining the use of pendulums to determine small local variations in the Earth's gravity. He was elected a resident fellow of the American Academy of Arts and Sciences in January 1867. The Survey sent him to Europe five times, first in 1871 as part of a group sent to observe a solar eclipse. There, he sought out Augustus De Morgan, William Stanley Jevons, and William Kingdon Clifford, British mathematicians and logicians whose turn of mind resembled his own. From 1869 to 1872, he was employed as an assistant in Harvard's astronomical observatory, doing important work on determining the brightness of stars and the shape of the Milky Way. On April 20, 1877 he was elected a member of the National Academy of Sciences. Also in 1877, he proposed measuring the meter as so many wavelengths of light of a certain frequency, the kind of definition employed from 1960 to 1983.

During the 1880s, Peirce's indifference to bureaucratic detail waxed while his Survey work's quality and timeliness waned. Peirce took years to write reports that he should have completed in months. Meanwhile, he wrote entries, ultimately thousands, during 1883–1909 on philosophy, logic, science, and other subjects for the encyclopedic "Century Dictionary". In 1885, an investigation by the Allison Commission exonerated Peirce, but led to the dismissal of Superintendent Julius Hilgard and several other Coast Survey employees for misuse of public funds. In 1891, Peirce resigned from the Coast Survey at Superintendent Thomas Corwin Mendenhall's request.

In 1879, Peirce was appointed lecturer in logic at Johns Hopkins University, which had strong departments in areas that interested him, such as philosophy (Royce and Dewey completed their Ph.D.s at Hopkins), psychology (taught by G. Stanley Hall and studied by Joseph Jastrow, who coauthored a landmark empirical study with Peirce), and mathematics (taught by J. J. Sylvester, who came to admire Peirce's work on mathematics and logic). His "Studies in Logic by Members of the Johns Hopkins University" (1883) contained works by himself and Allan Marquand, Christine Ladd, Benjamin Ives Gilman, and Oscar Howard Mitchell, several of whom were his graduate students. Peirce's nontenured position at Hopkins was the only academic appointment he ever held.

Brent documents something Peirce never suspected, namely that his efforts to obtain academic employment, grants, and scientific respectability were repeatedly frustrated by the covert opposition of a major Canadian-American scientist of the day, Simon Newcomb. Peirce's efforts may also have been hampered by what Brent characterizes as "his difficult personality". In contrast, Keith Devlin believes that Peirce's work was too far ahead of his time to be appreciated by the academic establishment of the day and that this played a large role in his inability to obtain a tenured position.

Peirce's personal life undoubtedly worked against his professional success. After his first wife, Harriet Melusina Fay ("Zina"), left him in 1875, Peirce, while still legally married, became involved with Juliette, whose last name, given variously as Froissy and Pourtalai, and nationality (she spoke French) remains uncertain. When his divorce from Zina became final in 1883, he married Juliette. That year, Newcomb pointed out to a Johns Hopkins trustee that Peirce, while a Hopkins employee, had lived and traveled with a woman to whom he was not married; the ensuing scandal led to his dismissal in January 1884. Over the years Peirce sought academic employment at various universities without success. He had no children by either marriage.

In 1887 Peirce spent part of his inheritance from his parents to buy of rural land near Milford, Pennsylvania, which never yielded an economic return. There he had an 1854 farmhouse remodeled to his design. The Peirces named the property "Arisbe". There they lived with few interruptions for the rest of their lives, Charles writing prolifically, much of it unpublished to this day (see Works). Living beyond their means soon led to grave financial and legal difficulties. He spent much of his last two decades unable to afford heat in winter and subsisting on old bread donated by the local baker. Unable to afford new stationery, he wrote on the verso side of old manuscripts. An outstanding warrant for assault and unpaid debts led to his being a fugitive in New York City for a while. Several people, including his brother James Mills Peirce and his neighbors, relatives of Gifford Pinchot, settled his debts and paid his property taxes and mortgage.

Peirce did some scientific and engineering consulting and wrote much for meager pay, mainly encyclopedic dictionary entries, and reviews for "The Nation" (with whose editor, Wendell Phillips Garrison, he became friendly). He did translations for the Smithsonian Institution, at its director Samuel Langley's instigation. Peirce also did substantial mathematical calculations for Langley's research on powered flight. Hoping to make money, Peirce tried inventing. He began but did not complete several books. In 1888, President Grover Cleveland appointed him to the Assay Commission.

From 1890 on, he had a friend and admirer in Judge Francis C. Russell of Chicago, who introduced Peirce to editor Paul Carus and owner Edward C. Hegeler of the pioneering American philosophy journal "The Monist", which eventually published at least 14 articles by Peirce. He wrote many texts in James Mark Baldwin's "Dictionary of Philosophy and Psychology" (1901–1905); half of those credited to him appear to have been written actually by Christine Ladd-Franklin under his supervision. He applied in 1902 to the newly formed Carnegie Institution for a grant to write a systematic book describing his life's work. The application was doomed; his nemesis, Newcomb, served on the Carnegie Institution executive committee, and its president had been president of Johns Hopkins at the time of Peirce's dismissal.

The one who did the most to help Peirce in these desperate times was his old friend William James, dedicating his "Will to Believe" (1897) to Peirce, and arranging for Peirce to be paid to give two series of lectures at or near Harvard (1898 and 1903). Most important, each year from 1907 until James's death in 1910, James wrote to his friends in the Boston intelligentsia to request financial aid for Peirce; the fund continued even after James died. Peirce reciprocated by designating James's eldest son as his heir should Juliette predecease him. It has been believed that this was also why Peirce used "Santiago" ("St. James" in English) as a middle name, but he appeared in print as early as 1890 as Charles Santiago Peirce. (See Charles Santiago Sanders Peirce for discussion and references).

Peirce died destitute in Milford, Pennsylvania, twenty years before his widow. Juliette Peirce kept the urn with Peirce's ashes at Arisbe. In 1934, Pennsylvania Governor Gifford Pinchot arranged for Juliette's burial on Milford Cemetery. The urn with Peirce's ashes was interred with Juliette.

Peirce grew up in a home where white supremacy was taken for granted, and Southern slavery was considered natural.

Until the outbreak of the Civil War his father described himself as a secessionist, but after the outbreak of the war, this stopped and he became a Union partisan, providing donations to the Sanitary Commission, the leading Northern war charity. No members of the Peirce family volunteered or enlisted. Peirce shared his father's views and liked to use the following syllogism to illustrate the unreliability of traditional forms of logic (see also: ):

<poem>
All Men are equal in their political rights.
Negroes are Men.
Therefore, negroes are equal in political rights to whites.
</poem>

Bertrand Russell (1959) wrote "Beyond doubt [...] he was one of the most original minds of the later nineteenth century and certainly the greatest American thinker ever". Russell and Whitehead's "Principia Mathematica", published from 1910 to 1913, does not mention Peirce (Peirce's work was not widely known until later). A. N. Whitehead, while reading some of Peirce's unpublished manuscripts soon after arriving at Harvard in 1924, was struck by how Peirce had anticipated his own "process" thinking. (On Peirce and process metaphysics, see Lowe 1964). Karl Popper viewed Peirce as "one of the greatest philosophers of all times". Yet Peirce's achievements were not immediately recognized. His imposing contemporaries William James and Josiah Royce admired him and Cassius Jackson Keyser, at Columbia and C. K. Ogden, wrote about Peirce with respect but to no immediate effect.

The first scholar to give Peirce his considered professional attention was Royce's student Morris Raphael Cohen, the editor of an anthology of Peirce's writings entitled "Chance, Love, and Logic" (1923), and the author of the first bibliography of Peirce's scattered writings. John Dewey, studied under Peirce at Johns Hopkins. From 1916 onward, Dewey's writings repeatedly mention Peirce with deference. His 1938 "Logic: The Theory of Inquiry" is much influenced by Peirce. The publication of the first six volumes of "Collected Papers" (1931–1935), the most important event to date in Peirce studies and one that Cohen made possible by raising the needed funds, did not prompt an outpouring of secondary studies. The editors of those volumes, Charles Hartshorne and Paul Weiss, did not become Peirce specialists. Early landmarks of the secondary literature include the monographs by Buchler (1939), Feibleman (1946), and Goudge (1950), the 1941 PhD thesis by Arthur W. Burks (who went on to edit volumes 7 and 8), and the studies edited by Wiener and Young (1952). The Charles S. Peirce Society was founded in 1946. Its "Transactions", an academic quarterly specializing in Peirce's pragmatism and American philosophy has appeared since 1965. (See Phillips 2014, 62 for discussion of Peirce and Dewey relative to transactionalism).

In 1949, while doing unrelated archival work, the historian of mathematics Carolyn Eisele (1902–2000) chanced on an autograph letter by Peirce. So began her forty years of research on Peirce, “the mathematician and scientist,” culminating in Eisele (1976, 1979, 1985). Beginning around 1960, the philosopher and historian of ideas Max Fisch (1900–1995) emerged as an authority on Peirce (Fisch, 1986). He includes many of his relevant articles in a survey (Fisch 1986: 422–48) of the impact of Peirce's thought through 1983.

Peirce has gained an international following, marked by university research centers devoted to Peirce studies and pragmatism in Brazil (CeneP/CIEP), Finland (HPRC and ), Germany (Wirth's group, Hoffman's and Otte's group, and Deuser's and Härle's group), France (L'I.R.S.C.E.), Spain (GEP), and Italy (CSP). His writings have been translated into several languages, including German, French, Finnish, Spanish, and Swedish. Since 1950, there have been French, Italian, Spanish, British, and Brazilian Peirce scholars of note. For many years, the North American philosophy department most devoted to Peirce was the University of Toronto, thanks in part to the leadership of Thomas Goudge and David Savan. In recent years, U.S. Peirce scholars have clustered at Indiana University – Purdue University Indianapolis, home of the Peirce Edition Project (PEP) –, and Pennsylvania State University.

In recent years, Peirce's trichotomy of signs is exploited by a growing number of practitioners for marketing and design tasks.

Peirce's reputation rests largely on academic papers published in American scientific and scholarly journals such as "Proceedings of the American Academy of Arts and Sciences", the "Journal of Speculative Philosophy", "The Monist", "Popular Science Monthly", the "American Journal of Mathematics", "Memoirs of the National Academy of Sciences", "The Nation", and others. See Articles by Peirce, published in his lifetime for an extensive list with links to them online. The only full-length book (neither extract nor pamphlet) that Peirce authored and saw published in his lifetime was "Photometric Researches" (1878), a 181-page monograph on the applications of spectrographic methods to astronomy. While at Johns Hopkins, he edited "Studies in Logic" (1883), containing chapters by himself and his graduate students. Besides lectures during his years (1879–1884) as lecturer in Logic at Johns Hopkins, he gave at least nine series of lectures, many now published; see Lectures by Peirce.

After Peirce's death, Harvard University obtained from Peirce's widow the papers found in his study, but did not microfilm them until 1964. Only after Richard Robin (1967) catalogued this "Nachlass" did it become clear that Peirce had left approximately 1,650 unpublished manuscripts, totaling over 100,000 pages, mostly still unpublished except on microfilm. On the vicissitudes of Peirce's papers, see Houser (1989). Reportedly the papers remain in unsatisfactory condition.

The first published anthology of Peirce's articles was the one-volume "Chance, Love and Logic: Philosophical Essays", edited by Morris Raphael Cohen, 1923, still in print. Other one-volume anthologies were published in 1940, 1957, 1958, 1972, 1994, and 2009, most still in print. The main posthumous editions of Peirce's works in their long trek to light, often multi-volume, and some still in print, have included:

1931–1958: "Collected Papers of Charles Sanders Peirce" (CP), 8 volumes, includes many published works, along with a selection of previously unpublished work and a smattering of his correspondence. This long-time standard edition drawn from Peirce's work from the 1860s to 1913 remains the most comprehensive survey of his prolific output from 1893 to 1913. It is organized thematically, but texts (including lecture series) are often split up across volumes, while texts from various stages in Peirce's development are often combined, requiring frequent visits to editors' notes. Edited (1–6) by Charles Hartshorne and Paul Weiss and (7–8) by Arthur Burks, in print and online.

1975–1987: "Charles Sanders Peirce: Contributions to" The Nation, 4 volumes, includes Peirce's more than 300 reviews and articles published 1869–1908 in "The Nation". Edited by Kenneth Laine Ketner and James Edward Cook, online.

1976: "The New Elements of Mathematics by Charles S. Peirce", 4 volumes in 5, included many previously unpublished Peirce manuscripts on mathematical subjects, along with Peirce's important published mathematical articles. Edited by Carolyn Eisele, back in print.

1977: "Semiotic and Significs: The Correspondence between C. S. Peirce and Victoria Lady Welby" (2nd edition 2001), included Peirce's entire correspondence (1903–1912) with Victoria, Lady Welby. Peirce's other published correspondence is largely limited to the 14 letters included in volume 8 of the "Collected Papers", and the 20-odd pre-1890 items included so far in the "Writings". Edited by Charles S. Hardwick with James Cook, out of print.

1982–now: "Writings of Charles S. Peirce, A Chronological Edition" (W), Volumes 1–6 & 8, of a projected 30. The limited coverage, and defective editing and organization, of the "Collected Papers" led Max Fisch and others in the 1970s to found the Peirce Edition Project (PEP), whose mission is to prepare a more complete critical chronological edition. Only seven volumes have appeared to date, but they cover the period from 1859 to 1892, when Peirce carried out much of his best-known work. "Writings of Charles S. Peirce", 8 was published in November 2010; and work continues on "Writings of Charles S. Peirce", 7, 9, and 11. In print and online.

1985: "Historical Perspectives on Peirce's Logic of Science: A History of Science", 2 volumes. Auspitz has said, "The extent of Peirce's immersion in the science of his day is evident in his reviews in the "Nation" [...] and in his papers, grant applications, and publishers' prospectuses in the history and practice of science", referring latterly to "Historical Perspectives". Edited by Carolyn Eisele, back in print.

1992: "Reasoning and the Logic of Things" collects in one place Peirce's 1898 series of lectures invited by William James. Edited by Kenneth Laine Ketner, with commentary by Hilary Putnam, in print.

1992–1998: "The Essential Peirce" (EP), 2 volumes, is an important recent sampler of Peirce's philosophical writings. Edited (1) by Nathan Hauser and Christian Kloesel and (2) by "Peirce Edition Project" editors, in print.

1997: "Pragmatism as a Principle and Method of Right Thinking" collects Peirce's 1903 Harvard "Lectures on Pragmatism" in a study edition, including drafts, of Peirce's lecture manuscripts, which had been previously published in abridged form; the lectures now also appear in "The Essential Peirce", 2. Edited by Patricia Ann Turisi, in print.

2010: "Philosophy of Mathematics: Selected Writings" collects important writings by Peirce on the subject, many not previously in print. Edited by Matthew E. Moore, in print.

Peirce's most important work in pure mathematics was in logical and foundational areas. He also worked on linear algebra, matrices, various geometries, topology and Listing numbers, Bell numbers, graphs, the four-color problem, and the nature of continuity.

He worked on applied mathematics in economics, engineering, and map projections (such as the Peirce quincuncial projection), and was especially active in probability and statistics.


Peirce made a number of striking discoveries in formal logic and foundational mathematics, nearly all of which came to be appreciated only long after he died:

In 1860 he suggested a cardinal arithmetic for infinite numbers, years before any work by Georg Cantor (who completed his dissertation in 1867) and without access to Bernard Bolzano's 1851 (posthumous) "Paradoxien des Unendlichen".

In 1880–1881 he showed how Boolean algebra could be done via a repeated sufficient single binary operation (logical NOR), anticipating Henry M. Sheffer by 33 years. (See also De Morgan's Laws.)

In 1881 he set out the axiomatization of natural number arithmetic, a few years before Richard Dedekind and Giuseppe Peano. In the same paper Peirce gave, years before Dedekind, the first purely cardinal definition of a finite set in the sense now known as "Dedekind-finite", and implied by the same stroke an important formal definition of an infinite set (Dedekind-infinite), as a set that can be put into a one-to-one correspondence with one of its proper subsets.

In 1885 he distinguished between first-order and second-order quantification. In the same paper he set out what can be read as the first (primitive) axiomatic set theory, anticipating Zermelo by about two decades (Brady 2000, pp. 132–33).

In 1886, he saw that Boolean calculations could be carried out via electrical switches, anticipating Claude Shannon by more than 50 years. 
By the later 1890s he was devising existential graphs, a diagrammatic notation for the predicate calculus. Based on them are John F. Sowa's conceptual graphs and Sun-Joo Shin's diagrammatic reasoning.


Peirce wrote drafts for an introductory textbook, with the working title "The New Elements of Mathematics", that presented mathematics from an original standpoint. Those drafts and many other of his previously unpublished mathematical manuscripts finally appeared in "The New Elements of Mathematics by Charles S. Peirce" (1976), edited by mathematician Carolyn Eisele.


Peirce agreed with Auguste Comte in regarding mathematics as more basic than philosophy and the special sciences (of nature and mind). Peirce classified mathematics into three subareas: (1) mathematics of logic, (2) discrete series, and (3) pseudo-continua (as he called them, including the real numbers) and continua. Influenced by his father Benjamin, Peirce argued that mathematics studies purely hypothetical objects and is not just the science of quantity but is more broadly the science which draws necessary conclusions; that mathematics aids logic, not vice versa; and that logic itself is part of philosophy and is the science "about" drawing conclusions necessary and otherwise.

 Beginning with his first paper on the "Logic of Relatives" (1870), Peirce extended the theory of relations that Augustus De Morgan had just recently awakened from its Cinderella slumbers. Much of the mathematics of relations now taken for granted was "borrowed" from Peirce, not always with all due credit; on that and on how the young Bertrand Russell, especially his "Principles of Mathematics" and "Principia Mathematica", did not do Peirce justice, see Anellis (1995). In 1918 the logician C. I. Lewis wrote, "The contributions of C.S. Peirce to symbolic logic are more numerous and varied than those of any other writer—at least in the nineteenth century." Beginning in 1940, Alfred Tarski and his students rediscovered aspects of Peirce's larger vision of relational logic, developing the perspective of relation algebra.

Relational logic gained applications. In mathematics, it influenced the abstract analysis of E. H. Moore and the lattice theory of Garrett Birkhoff. In computer science, the relational model for databases was developed with Peircean ideas in work of Edgar F. Codd, who was a doctoral student of Arthur W. Burks, a Peirce scholar. In economics, relational logic was used by Frank P. Ramsey, John von Neumann, and Paul Samuelson to study preferences and utility and by Kenneth J. Arrow in "Social Choice and Individual Values", following Arrow's association with Tarski at City College of New York.

On Peirce and his contemporaries Ernst Schröder and Gottlob Frege, Hilary Putnam (1982) documented that Frege's work on the logic of quantifiers had little influence on his contemporaries, although it was published four years before the work of Peirce and his student Oscar Howard Mitchell. Putnam found that mathematicians and logicians learned about the logic of quantifiers through the independent work of Peirce and Mitchell, particularly through Peirce's "On the Algebra of Logic: A Contribution to the Philosophy of Notation" (1885), published in the premier American mathematical journal of the day, and cited by Peano and Schröder, among others, who ignored Frege. They also adopted and modified Peirce's notations, typographical variants of those now used. Peirce apparently was ignorant of Frege's work, despite their overlapping achievements in logic, philosophy of language, and the foundations of mathematics.

Peirce's work on formal logic had admirers besides Ernst Schröder:

A philosophy of logic, grounded in his categories and semiotic, can be extracted from Peirce's writings and, along with Peirce's logical work more generally, is exposited and defended in Hilary Putnam (1982); the Introduction in Nathan Houser "et al." (1997); and Randall Dipert's chapter in Cheryl Misak (2004).

Continuity and synechism are central in Peirce's philosophy: "I did not at first suppose that it was, as I gradually came to find it, the master-Key of philosophy".

From a mathematical point of view, he embraced infinitesimals and worked long on the mathematics of continua. He long held that the real numbers constitute a pseudo-continuum; that a true continuum is the real subject matter of "analysis situs" (topology); and that a true continuum of instants exceeds—and within any lapse of time has room for—any Aleph number (any infinite "multitude" as he called it) of instants.

In 1908 Peirce wrote that he found that a true continuum might have or lack such room. Jérôme Havenel (2008): "It is on 26 May 1908, that Peirce finally gave up his idea that in every continuum there is room for whatever collection of any multitude. From now on, there are different kinds of continua, which have different properties."

Peirce held that science achieves statistical probabilities, not certainties, and that spontaneity (absolute chance) is real (see Tychism on his view). Most of his statistical writings promote the frequency interpretation of probability (objective ratios of cases), and many of his writings express skepticism about (and criticize the use of) probability when such models are not based on objective randomization. Though Peirce was largely a frequentist, his possible world semantics introduced the "propensity" theory of probability before Karl Popper. Peirce (sometimes with Joseph Jastrow) investigated the probability judgments of experimental subjects, "perhaps the very first" elicitation and estimation of subjective probabilities in experimental psychology and (what came to be called) Bayesian statistics.

Peirce was one of the founders of statistics. He formulated modern statistics in "Illustrations of the Logic of Science" (1877–1878) and "A Theory of Probable Inference" (1883). With a repeated measures design, Charles Sanders Peirce and Joseph Jastrow introduced blinded, controlled randomized experiments in 1884 (Hacking 1990:205) (before Ronald A. Fisher). He invented optimal design for experiments on gravity, in which he "corrected the means". He used correlation and smoothing. Peirce extended the work on outliers by Benjamin Peirce, his father. He introduced terms "confidence" and "likelihood" (before Jerzy Neyman and Fisher). (See Stephen Stigler's historical books and Ian Hacking 1990.)

Peirce was a working scientist for 30 years, and arguably was a professional philosopher only during the five years he lectured at Johns Hopkins. He learned philosophy mainly by reading, each day, a few pages of Immanuel Kant's "Critique of Pure Reason", in the original German, while a Harvard undergraduate. His writings bear on a wide array of disciplines, including mathematics, logic, philosophy, statistics, astronomy, metrology, geodesy, experimental psychology, economics, linguistics, and the history and philosophy of science. This work has enjoyed renewed interest and approval, a revival inspired not only by his anticipations of recent scientific developments but also by his demonstration of how philosophy can be applied effectively to human problems.

Peirce's philosophy includes (see below in related sections) a pervasive three-category system: belief that truth is immutable and is both independent from actual opinion (fallibilism) and discoverable (no radical skepticism), logic as formal semiotic on signs, on arguments, and on inquiry's ways—including philosophical pragmatism (which he founded), critical common-sensism, and scientific method—and, in metaphysics: Scholastic realism, e.g. John Duns Scotus, belief in God, freedom, and at least an attenuated immortality, objective idealism, and belief in the reality of continuity and of absolute chance, mechanical necessity, and creative love. In his work, fallibilism and pragmatism may seem to work somewhat like skepticism and positivism, respectively, in others' work. However, for Peirce, fallibilism is balanced by an anti-skepticism and is a basis for belief in the reality of absolute chance and of continuity, and pragmatism commits one to anti-nominalist belief in the reality of the general (CP 5.453–57).

For Peirce, First Philosophy, which he also called cenoscopy, is less basic than mathematics and more basic than the special sciences (of nature and mind). It studies positive phenomena in general, phenomena available to any person at any waking moment, and does not settle questions by resorting to special experiences. He divided such philosophy into (1) phenomenology (which he also called phaneroscopy or categorics), (2) normative sciences (esthetics, ethics, and logic), and (3) metaphysics; his views on them are discussed in order below.

On May 14, 1867, the 27-year-old Peirce presented a paper entitled "On a New List of Categories" to the American Academy of Arts and Sciences, which published it the following year. The paper outlined a theory of predication, involving three universal categories that Peirce developed in response to reading Aristotle, Immanuel Kant, and G. W. F. Hegel, categories that Peirce applied throughout his work for the rest of his life. Peirce scholars generally regard the "New List" as foundational or breaking the ground for Peirce's "architectonic", his blueprint for a pragmatic philosophy. In the categories one will discern, concentrated, the pattern that one finds formed by the three grades of clearness in "" (1878 paper foundational to pragmatism), and in numerous other trichotomies in his work.

"On a New List of Categories" is cast as a Kantian deduction; it is short but dense and difficult to summarize. The following table is compiled from that and later works. In 1893, Peirce restated most of it for a less advanced audience. 

Peirce did not write extensively in aesthetics and ethics, but came by 1902 to hold that aesthetics, ethics, and logic, in that order, comprise the normative sciences. He characterized aesthetics as the study of the good (grasped as the admirable), and thus of the ends governing all conduct and thought.

Peirce regarded logic "per se" as a division of philosophy, as a normative science based on esthetics and ethics, as more basic than metaphysics, and as "the art of devising methods of research". More generally, as inference, "logic is rooted in the social principle", since inference depends on a standpoint that, in a sense, is unlimited. Peirce called (with no sense of deprecation) "mathematics of logic" much of the kind of thing which, in current research and applications, is called simply "logic". He was productive in both (philosophical) logic and logic's mathematics, which were connected deeply in his work and thought.

Peirce argued that logic is formal semiotic, the formal study of signs in the broadest sense, not only signs that are artificial, linguistic, or symbolic, but also signs that are semblances or are indexical such as reactions. Peirce held that "all this universe is perfused with signs, if it is not composed exclusively of signs", along with their representational and inferential relations. He argued that, since all thought takes time, all thought is in signs and sign processes ("semiosis") such as the inquiry process. He divided logic into: (1) speculative grammar, or stechiology, on how signs can be meaningful and, in relation to that, what kinds of signs there are, how they combine, and how some embody or incorporate others; (2) logical critic, or logic proper, on the modes of inference; and (3) speculative or universal rhetoric, or methodeutic, the philosophical theory of inquiry, including pragmatism.

In his "F.R.L." [First Rule of Logic] (1899), Peirce states that the first, and "in one sense, the sole", rule of reason is that, "to learn, one needs to desire to learn" and desire it without resting satisfied with that which one is inclined to think. So, the first rule is, "to wonder". Peirce proceeds to a critical theme in research practices and the shaping of theories:
Do not block the way of inquiry.
Peirce adds, that method and economy are best in research but no outright sin inheres in trying any theory in the sense that the investigation via its trial adoption can proceed unimpeded and undiscouraged, and that "the one unpardonable offence" is a philosophical barricade against truth's advance, an offense to which "metaphysicians in all ages have shown themselves the most addicted". Peirce in many writings holds that logic precedes metaphysics (ontological, religious, and physical).

Peirce goes on to list four common barriers to inquiry: (1) Assertion of absolute certainty; (2) maintaining that something is absolutely unknowable; (3) maintaining that something is absolutely inexplicable because absolutely basic or ultimate; (4) holding that perfect exactitude is possible, especially such as to quite preclude unusual and anomalous phenomena. To refuse absolute theoretical certainty is the heart of "fallibilism", which Peirce unfolds into refusals to set up any of the listed barriers. Peirce elsewhere argues (1897) that logic's presupposition of fallibilism leads at length to the view that chance and continuity are very real (tychism and synechism).

The First Rule of Logic pertains to the mind's presuppositions in undertaking reason and logic; presuppositions, for instance, that truth and the real do not depend on yours or my opinion of them but do depend on representational relation and consist in the destined end in investigation taken far enough (see below). He describes such ideas as, collectively, hopes which, in particular cases, one is unable seriously to doubt.

 In three articles in 1868–1869, Peirce rejected mere verbal or hyperbolic doubt and first or ultimate principles, and argued that we have (as he numbered them):
(The above sense of the term "intuition" is almost Kant's, said Peirce. It differs from the current looser sense that encompasses instinctive or anyway half-conscious inference.)

Peirce argued that those incapacities imply the reality of the general and of the continuous, the validity of the modes of reasoning, and the falsity of philosophical Cartesianism (see below).

Peirce rejected the conception (usually ascribed to Kant) of the unknowable thing-in-itself and later said that to "dismiss make-believes" is a prerequisite for pragmatism.

Peirce sought, through his wide-ranging studies through the decades, formal philosophical ways to articulate thought's processes, and also to explain the workings of science. These inextricably entangled questions of a dynamics of inquiry rooted in nature and nurture led him to develop his semiotic with very broadened conceptions of signs and inference, and, as its culmination, a theory of inquiry for the task of saying 'how science works' and devising research methods. This would be logic by the medieval definition taught for centuries: art of arts, science of sciences, having the way to the principles of all methods. Influences radiate from points on parallel lines of inquiry in Aristotle's work, in such "loci" as: the basic terminology of psychology in "On the Soul"; the founding description of sign relations in "On Interpretation"; and the differentiation of inference into three modes that are commonly translated into English as "abduction", "deduction", and "induction", in the "Prior Analytics", as well as inference by analogy (called "paradeigma" by Aristotle), which Peirce regarded as involving the other three modes.

Peirce began writing on semiotic in the 1860s, around the time when he devised his system of three categories. He called it both "semiotic" and "semeiotic". Both are current in singular and plural. He based it on the conception of a triadic sign relation, and defined "semiosis" as "action, or influence, which is, or involves, a cooperation of "three" subjects, such as a sign, its object, and its interpretant, this tri-relative influence not being in any way resolvable into actions between pairs". As to signs in thought, Peirce emphasized the reverse: "To say, therefore, that thought cannot happen in an instant, but requires a time, is but another way of saying that every thought must be interpreted in another, or that all thought is in signs."

Peirce held that all thought is in signs, issuing in and from interpretation, where "sign" is the word for the broadest variety of conceivable semblances, diagrams, metaphors, symptoms, signals, designations, symbols, texts, even mental concepts and ideas, all as determinations of a mind or "quasi-mind", that which at least functions like a mind, as in the work of crystals or bees—the focus is on sign action in general rather than on psychology, linguistics, or social studies (fields which he also pursued).

Inquiry is a kind of inference process, a manner of thinking and semiosis. Global divisions of ways for phenomena to stand as signs, and the subsumption of inquiry and thinking within inference as a sign process, enable the study of inquiry on semiotics' three levels:


Peirce uses examples often from common experience, but defines and discusses such things as assertion and interpretation in terms of philosophical logic. In a formal vein, Peirce said:

Peirce's theory of signs is known to be one of the most complex semiotic theories due to its generalistic claim. Anything is a sign—not absolutely as itself, but instead in some relation or other. The "sign relation" is the key. It defines three roles encompassing (1) the sign, (2) the sign's subject matter, called its "object", and (3) the sign's meaning or ramification as formed into a kind of effect called its "interpretant" (a further sign, for example a translation). It is an irreducible "triadic relation", according to Peirce. The roles are distinct even when the things that fill those roles are not. The roles are but three; a sign of an object leads to one or more interpretants, and, as signs, they lead to further interpretants.

"Extension × intension = information." Two traditional approaches to sign relation, necessary though insufficient, are the way of "extension" (a sign's objects, also called breadth, denotation, or application) and the way of "intension" (the objects' characteristics, qualities, attributes referenced by the sign, also called depth, comprehension, significance, or connotation). Peirce adds a third, the way of "information", including change of information, to integrate the other two approaches into a unified whole. For example, because of the equation above, if a term's total amount of information stays the same, then the more that the term 'intends' or signifies about objects, the fewer are the objects to which the term 'extends' or applies.

"Determination." A sign depends on its object in such a way as to represent its object—the object enables and, in a sense, determines the sign. A physically causal sense of this stands out when a sign consists in an indicative reaction. The interpretant depends likewise on both the sign and the object—an object determines a sign to determine an interpretant. But this determination is not a succession of dyadic events, like a row of toppling dominoes; sign determination is triadic. For example, an interpretant does not merely represent something which represented an object; instead an interpretant represents something "as" a sign representing the object. The object (be it a quality or fact or law or even fictional) determines the sign to an interpretant through one's collateral experience with the object, in which the object is found or from which it is recalled, as when a sign consists in a chance semblance of an absent object. Peirce used the word "determine" not in a strictly deterministic sense, but in a sense of "specializes", "bestimmt", involving variable amount, like an influence. Peirce came to define representation and interpretation in terms of (triadic) determination. The object determines the sign to determine another sign—the interpretant—to be related to the object "as the sign is related to the object", hence the interpretant, fulfilling its function as sign of the object, determines a further interpretant sign. The process is logically structured to perpetuate itself, and is definitive of sign, object, and interpretant in general.

Peirce held there are exactly three basic elements in semiosis (sign action):
Some of the understanding needed by the mind depends on familiarity with the object. To know what a given sign denotes, the mind needs some experience of that sign's object, experience outside of, and collateral to, that sign or sign system. In that context Peirce speaks of collateral experience, collateral observation, collateral acquaintance, all in much the same terms.

Among Peirce's many sign typologies, three stand out, interlocked. The first typology depends on the sign itself, the second on how the sign stands for its denoted object, and the third on how the sign stands for its object to its interpretant. Also, each of the three typologies is a three-way division, a trichotomy, via Peirce's three phenomenological categories: (1) quality of feeling, (2) reaction, resistance, and (3) representation, mediation.

I. "Qualisign, sinsign, legisign" (also called" tone, token, type," and also called "potisign, actisign, famisign"): This typology classifies every sign according to the sign's own phenomenological category—the qualisign is a quality, a possibility, a "First"; the sinsign is a reaction or resistance, a singular object, an actual event or fact, a "Second"; and the legisign is a habit, a rule, a representational relation, a "Third".

II. "Icon, index, symbol": This typology, the best known one, classifies every sign according to the category of the sign's way of denoting its object—the icon (also called semblance or likeness) by a quality of its own, the index by factual connection to its object, and the symbol by a habit or rule for its interpretant.

III. "Rheme, dicisign, argument" (also called "sumisign, dicisign, suadisign," also "seme, pheme, delome," and regarded as very broadened versions of the traditional "term, proposition, argument"): This typology classifies every sign according to the category which the interpretant attributes to the sign's way of denoting its object—the rheme, for example a term, is a sign interpreted to represent its object in respect of quality; the dicisign, for example a proposition, is a sign interpreted to represent its object in respect of fact; and the argument is a sign interpreted to represent its object in respect of habit or law. This is the culminating typology of the three, where the sign is understood as a structural element of inference.

Every sign belongs to one class or another within (I) "and" within (II) "and" within (III). Thus each of the three typologies is a three-valued parameter for every sign. The three parameters are not independent of each other; many co-classifications are absent, for reasons pertaining to the lack of either habit-taking or singular reaction in a quality, and the lack of habit-taking in a singular reaction. The result is not 27 but instead ten classes of signs fully specified at this level of analysis.

Borrowing a brace of concepts from Aristotle, Peirce examined three basic modes of inference—"abduction", "deduction", and "induction"—in his "critique of arguments" or "logic proper". Peirce also called abduction "retroduction", "presumption", and, earliest of all, "hypothesis". He characterized it as guessing and as inference to an explanatory hypothesis. He sometimes expounded the modes of inference by transformations of the categorical syllogism Barbara (AAA), for example in "Deduction, Induction, and Hypothesis" (1878). He does this by rearranging the "rule" (Barbara's major premise), the "case" (Barbara's minor premise), and the "result" (Barbara's conclusion):

Deduction.

"Rule:" All the beans from this bag are white. <br>
"Case:" These beans are beans from this bag. <br>
formula_1 "Result:" These beans are white.

Induction.

"Case:" These beans are [randomly selected] from this bag. <br>
"Result:" These beans are white. <br>
formula_1 "Rule:" All the beans from this bag are white.

Hypothesis (Abduction).

"Rule:" All the beans from this bag are white. <br>
"Result:" These beans [oddly] are white. <br>
formula_1 "Case:" These beans are from this bag.
Peirce 1883 in "A Theory of Probable Inference" ("Studies in Logic") equated hypothetical inference with the induction of characters of objects (as he had done in effect before). Eventually dissatisfied, by 1900 he distinguished them once and for all and also wrote that he now took the syllogistic forms and the doctrine of logical extension and comprehension as being less basic than he had thought. In 1903 he presented the following logical form for abductive inference:

The logical form does not also cover induction, since induction neither depends on surprise nor proposes a new idea for its conclusion. Induction seeks facts to test a hypothesis; abduction seeks a hypothesis to account for facts. "Deduction proves that something "must" be; Induction shows that something "actually is" operative; Abduction merely suggests that something "may be"." Peirce did not remain quite convinced that one logical form covers all abduction. In his methodeutic or theory of inquiry (see below), he portrayed abduction as an economic initiative to further inference and study, and portrayed all three modes as clarified by their coordination in essential roles in inquiry: hypothetical explanation, deductive prediction, inductive testing.

 Peirce's recipe for pragmatic thinking, which he called "pragmatism" and, later, "pragmaticism", is recapitulated in several versions of the so-called "pragmatic maxim". Here is one of his more emphatic reiterations of it:

As a movement, pragmatism began in the early 1870s in discussions among Peirce, William James, and others in the Metaphysical Club. James among others regarded some articles by Peirce such as "" (1877) and especially "" (1878) as foundational to pragmatism. Peirce (CP 5.11–12), like James ("", 1907), saw pragmatism as embodying familiar attitudes, in philosophy and elsewhere, elaborated into a new deliberate method for fruitful thinking about problems. Peirce differed from James and the early John Dewey, in some of their tangential enthusiasms, in being decidedly more rationalistic and realistic, in several senses of those terms, throughout the preponderance of his own philosophical moods.

In 1905 Peirce coined the new name pragmaticism "for the precise purpose of expressing the original definition", saying that "all went happily" with James's and F.C.S. Schiller's variant uses of the old name "pragmatism" and that he coined the new name because of the old name's growing use in "literary journals, where it gets abused". Yet he cited as causes, in a 1906 manuscript, his differences with James and Schiller and, in a 1908 publication, his differences with James as well as literary author Giovanni Papini's declaration of pragmatism's indefinability. Peirce in any case regarded his views that truth is immutable and infinity is real, as being opposed by the other pragmatists, but he remained allied with them on other issues.

Pragmatism begins with the idea that belief is that on which one is prepared to act. Peirce's pragmatism is a method of clarification of conceptions of objects. It equates any conception of an object to a conception of that object's effects to a general extent of the effects' conceivable implications for informed practice. It is a method of sorting out conceptual confusions occasioned, for example, by distinctions that make (sometimes needed) formal yet not practical differences. He formulated both pragmatism and statistical principles as aspects of scientific logic, in his "Illustrations of the Logic of Science" series of articles. In the second one, "", Peirce discussed three grades of clearness of conception:

By way of example of how to clarify conceptions, he addressed conceptions about truth and the real as questions of the presuppositions of reasoning in general. In clearness's second grade (the "nominal" grade), he defined truth as a sign's correspondence to its object, and the real as the object of such correspondence, such that truth and the real are independent of that which you or I or any actual, definite community of inquirers think. After that needful but confined step, next in clearness's third grade (the pragmatic, practice-oriented grade) he defined truth as that opinion which "would" be reached, sooner or later but still inevitably, by research taken far enough, such that the real does depend on that ideal final opinion—a dependence to which he appeals in theoretical arguments elsewhere, for instance for the long-run validity of the rule of induction. Peirce argued that even to argue against the independence and discoverability of truth and the real is to presuppose that there is, about that very question under argument, a truth with just such independence and discoverability.

Peirce said that a conception's meaning consists in "all general modes of rational conduct" implied by "acceptance" of the conception—that is, if one were to accept, first of all, the conception as true, then what could one conceive to be consequent general modes of rational conduct by all who accept the conception as true?—the whole of such consequent general modes is the whole meaning. His pragmatism does not equate a conception's meaning, its intellectual purport, with the conceived benefit or cost of the conception itself, like a meme (or, say, propaganda), outside the perspective of its being true, nor, since a conception is general, is its meaning equated with any definite set of actual consequences or upshots corroborating or undermining the conception or its worth. His pragmatism also bears no resemblance to "vulgar" pragmatism, which misleadingly connotes a ruthless and Machiavellian search for mercenary or political advantage. Instead the pragmatic maxim is the heart of his pragmatism as a method of experimentational mental reflection arriving at conceptions in terms of conceivable confirmatory and disconfirmatory circumstances—a method hospitable to the formation of explanatory hypotheses, and conducive to the use and improvement of verification.

Peirce's pragmatism, as method and theory of definitions and conceptual clearness, is part of his theory of inquiry, which he variously called speculative, general, formal or universal rhetoric or simply methodeutic. He applied his pragmatism as a method throughout his work.

Critical common-sensism, treated by Peirce as a consequence of his pragmatism, is his combination of Thomas Reid's common-sense philosophy with a fallibilism that recognizes that propositions of our more or less vague common sense now indubitable may later come into question, for example because of transformations of our world through science. It includes efforts to work up in tests genuine doubts for a core group of common indubitables that vary slowly if at all.

In "" (1877), Peirce described inquiry in general not as the pursuit of truth "per se" but as the struggle to move from irritating, inhibitory doubt born of surprise, disagreement, and the like, and to reach a secure belief, belief being that on which one is prepared to act. That let Peirce frame scientific inquiry as part of a broader spectrum and as spurred, like inquiry generally, by actual doubt, not mere verbal, quarrelsome, or hyperbolic doubt, which he held to be fruitless. Peirce sketched four methods of settling opinion, ordered from least to most successful:

Peirce held that, in practical affairs, slow and stumbling ratiocination is often dangerously inferior to instinct and traditional sentiment, and that the scientific method is best suited to theoretical research, which in turn should not be trammeled by the other methods and practical ends; reason's "first rule" is that, in order to learn, one must desire to learn and, as a corollary, must not block the way of inquiry. Scientific method excels over the others finally by being deliberately designed to arrive—eventually—at the most secure beliefs, upon which the most successful practices can be based. Starting from the idea that people seek not truth "per se" but instead to subdue irritating, inhibitory doubt, Peirce showed how, through the struggle, some can come to submit to truth for the sake of belief's integrity, seek as truth the guidance of potential conduct correctly to its given goal, and wed themselves to the scientific method.

Insofar as clarification by pragmatic reflection suits explanatory hypotheses and fosters predictions and testing, pragmatism points beyond the usual duo of foundational alternatives: deduction from self-evident truths, or "rationalism"; and induction from experiential phenomena, or "empiricism".

Based on his critique of three modes of argument and different from either foundationalism or coherentism, Peirce's approach seeks to justify claims by a three-phase dynamic of inquiry:


Thereby, Peirce devised an approach to inquiry far more solid than the flatter image of inductive generalization "simpliciter", which is a mere re-labeling of phenomenological patterns. Peirce's pragmatism was the first time the scientific method was proposed as an epistemology for philosophical questions.

A theory that succeeds better than its rivals in predicting and controlling our world is said to be nearer the truth. This is an operational notion of truth used by scientists.

Peirce extracted the pragmatic model or theory of inquiry from its raw materials in classical logic and refined it in parallel with the early development of symbolic logic to address problems about the nature of scientific reasoning.

Abduction, deduction, and induction make incomplete sense in isolation from one another but comprise a cycle understandable as a whole insofar as they collaborate toward the common end of inquiry. In the pragmatic way of thinking about conceivable practical implications, every thing has a purpose, and, as possible, its purpose should first be denoted. Abduction hypothesizes an explanation for deduction to clarify into implications to be tested so that induction can evaluate the hypothesis, in the struggle to move from troublesome uncertainty to more secure belief. No matter how traditional and needful it is to study the modes of inference in abstraction from one another, the integrity of inquiry strongly limits the effective modularity of its principal components.

Peirce's outline of the scientific method in §III–IV of "A Neglected Argument" is summarized below (except as otherwise noted). There he also reviewed plausibility and inductive precision (issues of critique of arguments).

1. Abductive (or retroductive) phase. Guessing, inference to explanatory hypotheses for selection of those best worth trying. From abduction, Peirce distinguishes induction as inferring, on the basis of tests, the proportion of truth in the hypothesis. Every inquiry, whether into ideas, brute facts, or norms and laws, arises from surprising observations in one or more of those realms (and for example at any stage of an inquiry already underway). All explanatory content of theories comes from abduction, which guesses a new or outside idea so as to account in a simple, economical way for a surprising or complicated phenomenon. The modicum of success in our guesses far exceeds that of random luck, and seems born of attunement to nature by developed or inherent instincts, especially insofar as best guesses are optimally plausible and simple in the sense of the "facile and natural", as by Galileo's natural light of reason and as distinct from "logical simplicity". Abduction is the most fertile but least secure mode of inference. Its general rationale is inductive: it succeeds often enough and it has no substitute in expediting us toward new truths. In 1903, Peirce called pragmatism "the logic of abduction". Coordinative method leads from abducting a plausible hypothesis to judging it for its testability and for how its trial would economize inquiry itself. The hypothesis, being insecure, needs to have practical implications leading at least to mental tests and, in science, lending themselves to scientific tests. A simple but unlikely guess, if not costly to test for falsity, may belong first in line for testing. A guess is intrinsically worth testing if it has plausibility or reasoned objective probability, while subjective likelihood, though reasoned, can be misleadingly seductive. Guesses can be selected for trial strategically, for their caution (for which Peirce gave as example the game of Twenty Questions), breadth, or incomplexity. One can discover only that which would be revealed through their sufficient experience anyway, and so the point is to expedite it; economy of research demands the leap, so to speak, of abduction and governs its art.

2. Deductive phase. Two stages:

3. Inductive phase. Evaluation of the hypothesis, inferring from observational or experimental tests of its deduced consequences. The long-run validity of the rule of induction is deducible from the principle (presuppositional to reasoning in general) that the real "is only the object of the final opinion to which sufficient investigation would lead"; in other words, anything excluding such a process would never be real. Induction involving the ongoing accumulation of evidence follows "a method which, sufficiently persisted in", will "diminish the error below any predesignate degree". Three stages:

Peirce drew on the methodological implications of the four incapacities—no genuine introspection, no intuition in the sense of non-inferential cognition, no thought but in signs, and no conception of the absolutely incognizable—to attack philosophical Cartesianism, of which he said that:

1. "It teaches that philosophy must begin in universal doubt" – when, instead, we start with preconceptions, "prejudices [...] which it does not occur to us "can" be questioned", though we may find reason to question them later. "Let us not pretend to doubt in philosophy what we do not doubt in our hearts."

2. "It teaches that the ultimate test of certainty is...in the individual consciousness" – when, instead, in science a theory stays on probation till agreement is reached, then it has no actual doubters left. No lone individual can reasonably hope to fulfill philosophy's multi-generational dream. When "candid and disciplined minds" continue to disagree on a theoretical issue, even the theory's author should feel doubts about it.

3. It trusts to "a single thread of inference depending often upon inconspicuous premisses" – when, instead, philosophy should, "like the successful sciences", proceed only from tangible, scrutinizable premisses and trust not to any one argument but instead to "the multitude and variety of its arguments" as forming, not a chain at least as weak as its weakest link, but "a cable whose fibers", soever "slender, are sufficiently numerous and intimately connected".

4. It renders many facts "absolutely inexplicable, unless to say that 'God makes them so' is to be regarded as an explanation" – when, instead, philosophy should avoid being "unidealistic", misbelieving that something real can defy or evade all possible ideas, and supposing, inevitably, "some absolutely inexplicable, unanalyzable ultimate", which explanatory surmise explains nothing and so is inadmissible.

Peirce divided metaphysics into (1) ontology or general metaphysics, (2) psychical or religious metaphysics, and (3) physical metaphysics.

Ontology. Peirce was a Scholastic Realist, declaring for the reality of generals as early as 1868. Regarding modalities (possibility, necessity, etc.), he came in later years to regard himself as having wavered earlier as to just how positively real the modalities are. In his 1897 "The Logic of Relatives" he wrote: Peirce retained, as useful for some purposes, the definitions in terms of information states, but insisted that the pragmaticist is committed to a strong modal realism by conceiving of objects in terms of predictive general conditional propositions about how they "would" behave under certain circumstances.

Psychical or religious metaphysics. Peirce believed in God, and characterized such belief as founded in an instinct explorable in musing over the worlds of ideas, brute facts, and evolving habits—and it is a belief in God not as an "actual" or "existent" being (in Peirce's sense of those words), but all the same as a "real" being. In "" (1908), Peirce sketches, for God's reality, an argument to a hypothesis of God as the Necessary Being, a hypothesis which he describes in terms of how it would tend to develop and become compelling in musement and inquiry by a normal person who is led, by the hypothesis, to consider as being purposed the features of the worlds of ideas, brute facts, and evolving habits (for example scientific progress), such that the thought of such purposefulness will "stand or fall with the hypothesis"; meanwhile, according to Peirce, the hypothesis, in supposing an "infinitely incomprehensible" being, starts off at odds with its own nature as a purportively true conception, and so, no matter how much the hypothesis grows, it both (A) inevitably regards itself as partly true, partly vague, and as continuing to define itself without limit, and (B) inevitably has God appearing likewise vague but growing, though God as the Necessary Being is not vague or growing; but the hypothesis will hold it to be "more" false to say the opposite, that God is purposeless. Peirce also argued that the will is free and (see Synechism) that there is at least an attenuated kind of immortality.

Physical metaphysics. Peirce held the view, which he called objective idealism, that "matter is effete mind, inveterate habits becoming physical laws". Peirce asserted the reality of (1) absolute chance (his tychist view), (2) mechanical necessity (anancist view), and (3) that which he called the law of love (agapist view), echoing his categories Firstness, Secondness, and Thirdness, respectively. He held that fortuitous variation (which he also called "sporting"), mechanical necessity, and creative love are the three modes of evolution (modes called "tychasm", "anancasm", and "agapasm") of the cosmos and its parts. He found his conception of agapasm embodied in Lamarckian evolution; the overall idea in any case is that of evolution tending toward an end or goal, and it could also be the evolution of a mind or a society; it is the kind of evolution which manifests workings of mind in some general sense. He said that overall he was a synechist, holding with reality of continuity, especially of space, time, and law.

Peirce outlined two fields, "Cenoscopy" and "Science of Review", both of which he called philosophy. Both included philosophy about science. In 1903 he arranged them, from more to less theoretically basic, thus:


Peirce placed, within Science of Review, the work and theory of classifying the sciences (including mathematics and philosophy). His classifications, on which he worked for many years, draw on argument and wide knowledge, and are of interest both as a map for navigating his philosophy and as an accomplished polymath's survey of research in his time.

Contemporaries associated with Peirce



</doc>
<doc id="6118" url="https://en.wikipedia.org/wiki?curid=6118" title="Carnot heat engine">
Carnot heat engine

A Carnot heat engine is a theoretical engine that operates on the Carnot cycle. The basic model for this engine was developed by Nicolas Léonard Sadi Carnot in 1824. The Carnot engine model was graphically expanded by Benoît Paul Émile Clapeyron in 1834 and mathematically explored by Rudolf Clausius in 1857, work that led to the fundamental thermodynamic concept of entropy.

Every thermodynamic system exists in a particular state. A thermodynamic cycle occurs when a system is taken through a series of different states, and finally returned to its initial state. In the process of going through this cycle, the system may perform work on its surroundings, thereby acting as a heat engine.

A heat engine acts by transferring energy from a warm region to a cool region of space and, in the process, converting some of that energy to mechanical work. The cycle may also be reversed. The system may be worked upon by an external force, and in the process, it can transfer thermal energy from a cooler system to a warmer one, thereby acting as a refrigerator or heat pump rather than a heat engine.

In the adjacent diagram, from Carnot's 1824 work, "Reflections on the Motive Power of Fire", there are "two bodies "A" and "B", kept each at a constant temperature, that of "A" being higher than that of "B". These two bodies to which we can give, or from which we can remove the heat without causing their temperatures to vary, exercise the functions of two unlimited reservoirs of caloric. We will call the first the furnace and the second the refrigerator.” Carnot then explains how we can obtain motive power, i.e., “work”, by carrying a certain quantity of heat from body "A" to body "B".
It also acts as a cooler and hence can also act as a Refrigerator.

The previous image shows the original piston-and-cylinder diagram used by Carnot in discussing his ideal engines. The figure at right shows a block diagram of a generic heat engine, such as the Carnot engine. In the diagram, the “working body” (system), a term introduced by Clausius in 1850, can be any fluid or vapor body through which heat "Q" can be introduced or transmitted to produce work. Carnot had postulated that the fluid body could be any substance capable of expansion, such as vapor of water, vapor of alcohol, vapor of mercury, a permanent gas, or air, etc. Although, in these early years, engines came in a number of configurations, typically "Q" was supplied by a boiler, wherein water was boiled over a furnace; "Q" was typically supplied by a stream of cold flowing water in the form of a condenser located on a separate part of the engine. The output work, "W", represents the movement of the piston as it is used to turn a crank-arm, which in turn was typically used to power a pulley so as to lift water out of flooded salt mines. Carnot defined work as “weight lifted through a height”.

The Carnot cycle when acting as a heat engine consists of the following steps:


Carnot's theorem is a formal statement of this fact: "No engine operating between two heat reservoirs can be more efficient than a Carnot engine operating between the same reservoirs."

Explanation 
This maximum efficiency formula_3 is defined as above:

A corollary to Carnot's theorem states that: All reversible engines operating between the same heat reservoirs are equally efficient.

It is easily shown that the efficiency is maximum when the entire cyclic process is a reversible process. This means the total entropy of the net system (the entropies of the hot furnace, the "working fluid" of the Heat engine, and the cold sink) remains constant when the "working fluid" completes one cycle and returns to its original state. (In the general case, the total entropy of this combined system would increase in a general irreversible process).

Since the "working fluid" comes back to the same state after one cycle, and entropy of the system is a state function; the change in entropy of the "working fluid" system is 0. Thus, it implies that the total entropy change of the furnace and sink is zero, for the process to be reversible and the efficiency of the engine to be maximum. This derivation is carried out in the next section.

The coefficient of performance (COP) of the heat engine is the reciprocal of its efficiency.

For a real heat engine, the total thermodynamic process is generally irreversible. The working fluid is brought back to its initial state after one cycle, and thus the change of entropy of the fluid system is 0, but the sum of the entropy changes in the hot and cold reservoir in this one cyclical process is greater than 0.

The internal energy of the fluid is also a state variable, so its total change in one cycle is 0. So the total work done by the system , is equal to the heat put into the system formula_4 minus the heat taken out formula_8.

For real engines, sections 1 and 3 of the Carnot Cycle; in which heat is absorbed by the "working fluid" from the hot reservoir, and released by it to the cold reservoir, respectively; no longer remain ideally reversible, and there is a temperature differential between the temperature of the reservoir and the temperature of the fluid while heat exchange takes place.

During heat transfer from the hot reservoir at formula_9 to the fluid, the fluid would have a slightly lower temperature than formula_9, and the process for the fluid may not necessarily remain isothermal. 
Let formula_11 be the total entropy change of the fluid in the process of intake of heat. 

where the temperature of the fluid is always slightly lesser than formula_9, in this process.

So, one would get 

Similarly, at the time of heat injection from the fluid to the cold reservoir one would have, for the magnitude of total entropy change formula_13 of the fluid in the process of expelling heat:

where, during this process of transfer of heat to the cold reservoir, the temperature of the fluid is always slightly greater than formula_14.

We have only considered the magnitude of the entropy change here. Since the total change of entropy of the fluid system for the cyclic process is 0, we must have

The previous three equations combine to give:

Equations () and () combine to give 

Hence,

where formula_15 is the efficiency of the real engine, and formula_3 is the efficiency of the Carnot engine working between the same two reservoirs at the temperatures formula_9 and formula_14. For the Carnot engine, the entire process is 'reversible', and Equation () is an equality.

Hence, the efficiency of the real engine is always less than the ideal Carnot engine.

Equation () signifies that the total entropy of the total system (the two reservoirs + fluid) increases for the real engine, because the entropy gain of the cold reservoir as formula_19 flows into it at the fixed temperature formula_14, is greater than the entropy loss of the hot reservoir as formula_21 leaves it at its fixed temperature formula_9. The inequality in Equation () is essentially the statement of the Clausius theorem.

According to the second theorem, "The efficiency of the Carnot engine is independent of the nature of the working substance".



</doc>
<doc id="6119" url="https://en.wikipedia.org/wiki?curid=6119" title="Context-sensitive">
Context-sensitive

Context-sensitive is an adjective meaning "depending on context" or "depending on circumstances". It may refer to:



</doc>
<doc id="6121" url="https://en.wikipedia.org/wiki?curid=6121" title="Central America">
Central America

Central America (, , "Centroamérica" ) is sometimes defined as a subregion of the Americas. This region is bordered by Mexico to the north, Colombia to the southeast, the Caribbean Sea to the east and the Pacific Ocean to the west and south. Central America consists of seven countries: El Salvador, Costa Rica, Belize, Guatemala, Honduras, Nicaragua and Panama. The combined population of Central America is estimated at 44.53 million (2016).

Central America is a part of the Mesoamerican biodiversity hotspot, which extends from northern Guatemala to central Panama. Due to the presence of several active geologic faults and the Central America Volcanic Arc, there is a great deal of seismic activity in the region, such as volcanic eruptions and earthquakes, which has resulted in death, injury and property damage.

In the Pre-Columbian era, Central America was inhabited by the indigenous peoples of Mesoamerica to the north and west and the Isthmo-Colombian peoples to the south and east. Following the Spanish expedition of Christopher Columbus' voyages to the Americas, Spain began to colonize the Americas. From 1609 to 1821, the majority of Central American territories (except for what would become Belize and Panama, and including the modern Mexican state of Chiapas) were governed by the viceroyalty of New Spain from Mexico City as the Captaincy General of Guatemala. On 24 August 1821, Spanish Viceroy Juan de O'Donojú signed the Treaty of Córdoba, which established New Spain's independence from Spain. On 15 September 1821, the Act of Independence of Central America was enacted to announce Central America's separation from the Spanish Empire and provide for the establishment of a new Central American state. Some of New Spain's provinces in the Central American region (i.e. what would become Guatemala, Honduras, El Salvador, Nicaragua and Costa Rica) were annexed to the First Mexican Empire; however, in 1823 they seceded from Mexico to form the Federal Republic of Central America until 1838.

In 1838, Nicaragua, Honduras, Costa Rica and Guatemala became the first of Central America's seven states to become independent autonomous countries, followed by El Salvador in 1841, Panama in 1903 and Belize in 1981. Despite the dissolution of the Federal Republic of Central America, there is anecdotal evidence that demonstrates that Salvadorans, Panamanians, Costa Ricans, Guatemalans, Hondurans and Nicaraguans continue to maintain a Central American identity . For instance, Central Americans sometimes refer to their nations as if they were provinces of a Central American state. It is not unusual to write "C.A." after the country's name in formal and informal contexts. Governments in the region sometimes reinforce this sense of belonging to Central America in its citizens . Belizeans are usually identified as culturally West Indian rather than Central American.

"Central America" may mean different things to various people, based upon different contexts:

In the Pre-Columbian era, the northern areas of Central America were inhabited by the indigenous peoples of Mesoamerica. Most notable among these were the Mayans, who had built numerous cities throughout the region, and the Aztecs, who had created a vast empire. The pre-Columbian cultures of eastern El Salvador, eastern Honduras, Caribbean Nicaragua, most of Costa Rica and Panama were predominantly speakers of the Chibchan languages at the time of European contact and are considered by some culturally different and grouped in the Isthmo-Colombian Area.

Following the Spanish expedition of Christopher Columbus's voyages to the Americas, the Spanish sent many expeditions to the region, and they began their conquest of Maya territory in 1523. Soon after the conquest of the Aztec Empire, Spanish conquistador Pedro de Alvarado commenced the conquest of northern Central America for the Spanish Empire. Beginning with his arrival in Soconusco in 1523, Alvarado's forces systematically conquered and subjugated most of the major Maya kingdoms, including the K'iche', Tz'utujil, Pipil, and the Kaqchikel. By 1528, the conquest of Guatemala was nearly complete, with only the Petén Basin remaining outside the Spanish sphere of influence. The last independent Maya kingdoms – the Kowoj and the Itza people – were finally defeated in 1697, as part of the Spanish conquest of Petén.

In 1538, Spain established the Real Audiencia of Panama, which had jurisdiction over all land from the Strait of Magellan to the Gulf of Fonseca. This entity was dissolved in 1543, and most of the territory within Central America then fell under the jurisdiction of the "Audiencia Real de Guatemala". This area included the current territories of Costa Rica, El Salvador, Guatemala, Honduras, Nicaragua, and the Mexican state of Chiapas, but excluded the lands that would become Belize and Panama. The president of the Audiencia, which had its seat in Antigua Guatemala, was the governor of the entire area. In 1609 the area became a captaincy general and the governor was also granted the title of captain general. The Captaincy General of Guatemala encompassed most of Central America, with the exception of present-day Belize and Panama.

The Captaincy General of Guatemala lasted for more than two centuries, but began to fray after a rebellion in 1811 which began in the intendancy of San Salvador. The Captaincy General formally ended on 15 September 1821, with the signing of the Act of Independence of Central America. Mexican independence was achieved at virtually the same time with the signing of the Treaty of Córdoba and the Declaration of Independence of the Mexican Empire, and the entire region was finally independent from Spanish authority by 28 September 1821.

From its independence from Spain in 1821 until 1823, the former Captaincy General remained intact as part of the short-lived First Mexican Empire. When the Emperor of Mexico abdicated on 19 March 1823, Central America again became independent. On 1 July 1823, the Congress of Central America peacefully seceded from Mexico and declared absolute independence from all foreign nations, and the region formed the Federal Republic of Central America.

The Federal Republic of Central America was a representative democracy with its capital at Guatemala City. This union consisted of the provinces of Costa Rica, El Salvador, Guatemala, Honduras, Los Altos, Mosquito Coast, and Nicaragua. The lowlands of southwest Chiapas, including Soconusco, initially belonged to the Republic until 1824, when Mexico annexed most of Chiapas and began its claims to Soconusco. The Republic lasted from 1823 to 1838, when it disintegrated as a result of civil wars.

The territory that now makes up Belize was heavily contested in a dispute that continued for decades after Guatemala achieved independence (see History of Belize (1506–1862). Spain, and later Guatemala, considered this land a Guatemalan department. In 1862, Britain formally declared it a British colony and named it British Honduras. It became independent as Belize in 1981.

Panama, situated in the southernmost part of Central America on the Isthmus of Panama, has for most of its history been culturally and politically linked to South America. Panama was part of the Province of Tierra Firme from 1510 until 1538 when it came under the jurisdiction of the newly formed "Audiencia Real de Panama". Beginning in 1543, Panama was administered as part of the Viceroyalty of Peru, along with all other Spanish possessions in South America. Panama remained as part of the Viceroyalty of Peru until 1739, when it was transferred to the Viceroyalty of New Granada, the capital of which was located at Santa Fé de Bogotá. Panama remained as part of the Viceroyalty of New Granada until the disestablishment of that viceroyalty in 1819. A series of military and political struggles took place from that time until 1822, the result of which produced the republic of Gran Colombia. After the dissolution of Gran Colombia in 1830, Panama became part of a successor state, the Republic of New Granada. From 1855 until 1886, Panama existed as Panama State, first within the Republic of New Granada, then within the Granadine Confederation, and finally within the United States of Colombia. The United States of Colombia was replaced by the Republic of Colombia in 1886. As part of the Republic of Colombia, Panama State was abolished and it became the Isthmus Department. Despite the many political reorganizations, Colombia was still deeply plagued by conflict, which eventually led to the secession of Panama on 3 November 1903. Only after that time did some begin to regard Panama as a North or Central American entity.

By the 1930s the United Fruit Company owned of land in Central America and the Caribbean and was the single largest land owner in Guatemala. Such holdings gave it great power over the governments of small countries. That was one of the factors that led to the coining of the phrase banana republic.

After more than two hundred years of social unrest, violent conflict, and revolution, Central America today remains in a period of political transformation. Poverty, social injustice, and violence are still widespread. Nicaragua is the second poorest country in the western hemisphere (only Haiti is poorer).

Central America is a tapering isthmus running from the southern extent of Mexico to the northwestern portion of South America. The Pacific Ocean lies to the southwest, the Caribbean Sea lies to the northeast, and the Gulf of Mexico lies to the north. Some physiographists define the Isthmus of Tehuantepec as the northern geographic border of Central America, while others use the northwestern borders of Belize and Guatemala. From there, the Central American land mass extends southeastward to the Atrato River, where it connects to the Pacific Lowlands in northwestern South America.

Of the many mountain ranges within Central America, the longest are the Sierra Madre de Chiapas, the Cordillera Isabelia and the Cordillera de Talamanca. At , Volcán Tajumulco is the highest peak in Central America. Other high points of Central America are as listed in the table below:

Between the mountain ranges lie fertile valleys that are suitable for the raising of livestock and for the production of coffee, tobacco, beans and other crops. Most of the population of Honduras, Costa Rica and Guatemala lives in valleys.

Trade winds have a significant effect upon the climate of Central America. Temperatures in Central America are highest just prior to the summer wet season, and are lowest during the winter dry season, when trade winds contribute to a cooler climate. The highest temperatures occur in April, due to higher levels of sunlight, lower cloud cover and a decrease in trade winds.

Central America is part of the Mesoamerican biodiversity hotspot, boasting 7% of the world's biodiversity. The Pacific Flyway is a major north–south flyway for migratory birds in the Americas, extending from Alaska to Tierra del Fuego. Due to the funnel-like shape of its land mass, migratory birds can be seen in very high concentrations in Central America, especially in the spring and autumn. As a bridge between North America and South America, Central America has many species from the Nearctic and the Neotropical realms. However the southern countries (Costa Rica and Panama) of the region have more biodiversity than the northern countries (Guatemala and Belize), meanwhile the central countries (Honduras, Nicaragua and El Salvador) have the least biodiversity. The table below shows recent statistics:

Over 300 species of the region's flora and fauna are threatened, 107 of which are classified as critically endangered. The underlying problems are deforestation, which is estimated by FAO at 1.2% per year in Central America and Mexico combined, fragmentation of rainforests and the fact that 80% of the vegetation in Central America has already been converted to agriculture.

Efforts to protect fauna and flora in the region are made by creating ecoregions and nature reserves. 36% of Belize's land territory falls under some form of official protected status, giving Belize one of the most extensive systems of terrestrial protected areas in the Americas. In addition, 13% of Belize's marine territory are also protected. A large coral reef extends from Mexico to Honduras: the Mesoamerican Barrier Reef System. The Belize Barrier Reef is part of this. The Belize Barrier Reef is home to a large diversity of plants and animals, and is one of the most diverse ecosystems of the world. It is home to 70 hard coral species, 36 soft coral species, 500 species of fish and hundreds of invertebrate species.
So far only about 10% of the species in the Belize barrier reef have been discovered.

From 2001 to 2010, of forest were lost in the region. In 2010 Belize had 63% of remaining forest cover, Costa Rica 46%, Panama 45%, Honduras 41%, Guatemala 37%, Nicaragua 29%, and El Salvador 21%. Most of the loss occurred in the moist forest biome, with . Woody vegetation loss was partially set off by a gain in the coniferous forest biome with , and a gain in the dry forest biome at . Mangroves and deserts contributed only 1% to the loss in forest vegetation. The bulk of the deforestation was located at the Caribbean slopes of Nicaragua with a loss of of forest in the period from 2001 to 2010. The most significant regrowth of of forest was seen in the coniferous woody vegetation of Honduras.

The Central American pine-oak forests ecoregion, in the tropical and subtropical coniferous forests biome, is found in Central America and southern Mexico. The Central American pine-oak forests occupy an area of , extending along the mountainous spine of Central America, extending from the Sierra Madre de Chiapas in Mexico's Chiapas state through the highlands of Guatemala, El Salvador, and Honduras to central Nicaragua. The pine-oak forests lie between elevation, and are surrounded at lower elevations by tropical moist forests and tropical dry forests. Higher elevations above are usually covered with Central American montane forests. The Central American pine-oak forests are composed of many species characteristic of temperate North America including oak, pine, fir, and cypress.

Laurel forest is the most common type of Central American temperate evergreen cloud forest, found in almost all Central American countries, normally more than above sea level. Tree species include evergreen oaks, members of the laurel family, and species of "Weinmannia", "Drimys", and "Magnolia". The cloud forest of Sierra de las Minas, Guatemala, is the largest in Central America. In some areas of southeastern Honduras there are cloud forests, the largest located near the border with Nicaragua. In Nicaragua, cloud forests are situated near the border with Honduras, but many were cleared to grow coffee. There are still some temperate evergreen hills in the north. The only cloud forest in the Pacific coastal zone of Central America is on the Mombacho volcano in Nicaragua. In Costa Rica, there are laurel forests in the Cordillera de Tilarán and Volcán Arenal, called Monteverde, also in the Cordillera de Talamanca.

The Central American montane forests are an ecoregion of the tropical and subtropical moist broadleaf forests biome, as defined by the World Wildlife Fund. These forests are of the moist deciduous and the semi-evergreen seasonal subtype of tropical and subtropical moist broadleaf forests and receive high overall rainfall with a warm summer wet season and a cooler winter dry season. Central American montane forests consist of forest patches located at altitudes ranging from , on the summits and slopes of the highest mountains in Central America ranging from Southern Mexico, through Guatemala, El Salvador, and Honduras, to northern Nicaragua. The entire ecoregion covers an area of and has a temperate climate with relatively high precipitation levels.

Ecoregions are not only established to protect the forests themselves but also because they are habitats for an incomparably rich and often endemic fauna. Almost half of the bird population of the Talamancan montane forests in Costa Rica and Panama are endemic to this region. Several birds are listed as threatened, most notably the resplendent quetzal (Pharomacrus mocinno), three-wattled bellbird (Procnias tricarunculata), bare-necked umbrellabird (Cephalopterus glabricollis), and black guan (Chamaepetes unicolor). Many of the amphibians are endemic and depend on the existence of forest. The golden toad that once inhabited a small region in the Monteverde Reserve, which is part of the Talamancan montane forests, has not been seen alive since 1989 and is listed as extinct by IUCN. The exact causes for its extinction are unknown. Global warming may have played a role, because the development of that frog is typical for this area may have been compromised. Seven small mammals are endemic to the Costa Rica-Chiriqui highlands within the Talamancan montane forest region. Jaguars, cougars, spider monkeys, as well as tapirs, and anteaters live in the woods of Central America. The Central American red brocket is a brocket deer found in Central America's tropical forest.

Central America is geologically very active, with volcanic eruptions and earthquakes occurring frequently, and tsunamis occurring occasionally. Many thousands of people have died as a result of these natural disasters.

Most of Central America rests atop the Caribbean Plate. This tectonic plate converges with the Cocos, Nazca, and North American plates to form the Middle America Trench, a major subduction zone. The Middle America Trench is situated some off the Pacific coast of Central America and runs roughly parallel to it. Many large earthquakes have occurred as a result of seismic activity at the Middle America Trench. For example, subduction of the Cocos Plate beneath the North American Plate at the Middle America Trench is believed to have caused the 1985 Mexico City earthquake that killed as many as 40,000 people. Seismic activity at the Middle America Trench is also responsible for earthquakes in 1902, 1942, 1956, 1982, 1992, 2001, 2007, 2012, 2014, and many other earthquakes throughout Central America.

The Middle America Trench is not the only source of seismic activity in Central America. The Motagua Fault is an onshore continuation of the Cayman Trough which forms part of the tectonic boundary between the North American Plate and the Caribbean Plate. This transform fault cuts right across Guatemala and then continues offshore until it merges with the Middle America Trench along the Pacific coast of Mexico, near Acapulco. Seismic activity at the Motagua Fault has been responsible for earthquakes in 1717, 1773, 1902, 1976, 1980, and 2009.

Another onshore continuation of the Cayman Trough is the Chixoy-Polochic Fault, which runs parallel to, and roughly to the north, of the Motagua Fault. Though less active than the Motagua Fault, seismic activity at the Chixoy-Polochic Fault is still thought to be capable of producing very large earthquakes, such as the 1816 earthquake of Guatemala.

Managua, the capital of Nicaragua, was devastated by earthquakes in 1931 and 1972.

Volcanic eruptions are also common in Central America. In 1968 the Arenal Volcano, in Costa Rica, erupted killing 87 people as the 3 villages of Tabacon, Pueblo Nuevo and San Luis were buried under pyroclastic flows and debris. Fertile soils from weathered volcanic lava have made it possible to sustain dense populations in the agriculturally productive highland areas.

The population of Central America is estimated at 47,448,333 as of . With an area of , it has a population density of . Human Development Index values are from the estimates for 2017.

The official language majority in all Central American countries is Spanish, except in Belize, where the official language is English. Mayan languages constitute a language family consisting of about 26 related languages. Guatemala formally recognized 21 of these in 1996. Xinca and Garifuna are also present in Central America.

This region of the continent is very rich in terms of ethnic groups. The majority of the population is mestizo, with sizable Mayan and African descendent populations present, including Xinca and Garifuna minorities. The immigration of Arabs, Jews, Chinese, Europeans and others brought additional groups to the area.

The predominant religion in Central America is Christianity (95.6%). Beginning with the Spanish colonization of Central America in the 16th century, Roman Catholicism became the most popular religion in the region until the first half of the 20th century. Since the 1960s, there has been an increase in other Christian groups, particularly Protestantism, as well as other religious organizations, and individuals identifying themselves as having no religion.



Central America is currently undergoing a process of political, economic and cultural transformation that started in 1907 with the creation of the Central American Court of Justice.

In 1951 the integration process continued with the signature of the San Salvador Treaty, which created the ODECA, the Organization of Central American States. However, the unity of the ODECA was limited by conflicts between several member states.

In 1991, the integration agenda was further advanced by the creation of the Central American Integration System ("Sistema para la Integración Centroamericana", or SICA). SICA provides a clear legal basis to avoid disputes between the member states. SICA membership includes the 7 nations of Central America plus the Dominican Republic, a state that is traditionally considered part of the Caribbean.

On 6 December 2008, SICA announced an agreement to pursue a common currency and common passport for the member nations. No timeline for implementation was discussed.

Central America already has several supranational institutions such as the Central American Parliament, the Central American Bank for Economic Integration and the Central American Common Market.

On 22 July 2011, President Mauricio Funes of El Salvador became the first president "pro tempore" to SICA. El Salvador also became the headquarters of SICA with the inauguration of a new building.

Until recently, all Central American countries have maintained diplomatic relations with Taiwan instead of China. President Óscar Arias of Costa Rica, however, established diplomatic relations with China in 2007, severing formal diplomatic ties with Taiwan. After breaking off relations with the Republic of China in 2017, Panama established diplomatic relations with the People's Republic of China. In August 2018, El Salvador also severed ties with Taiwan to formally start recognizing the People's Republic of China as sole China, a move many considered lacked transparency due to its abruptness and reports of the Chinese government's desires to invest in the department of La Union while also promising to fund the ruling party's reelection campaign. President of El Salvador, Nayib Bukele, broke diplomatic relations with Taiwan and establish better ones with China.

The Central American Parliament (also known as PARLACEN) is a political and parliamentary body of SICA. The parliament started around 1980, and its primary goal was to resolve conflicts in Nicaragua, Guatemala, and El Salvador. Although the group was disbanded in 1986, ideas of unity of Central Americans still remained, so a treaty was signed in 1987 to create the Central American Parliament and other political bodies. Its original members were Guatemala, El Salvador, Nicaragua and Honduras. The parliament is the political organ of Central America, and is part of SICA. New members have since then joined including Panama and the Dominican Republic.

Costa Rica is not a member State of the Central American Parliament and its adhesion remains as a very unpopular topic at all levels of the Costa Rican society due to existing strong political criticism towards the regional parliament, since it is regarded by Costa Ricans as a menace to democratic accountability and effectiveness of integration efforts. Excessively high salaries for its members, legal immunity of jurisdiction from any member State, corruption, lack of a binding nature and effectiveness of the regional parliament's decisions, high operative costs and immediate membership of Central American Presidents once they leave their office and presidential terms, are the most common reasons invoked by Costa Ricans against the Central American Parliament.

Signed in 2004, the Central American Free Trade Agreement (CAFTA) is an agreement between the United States, Costa Rica, El Salvador, Guatemala, Honduras, Nicaragua, and the Dominican Republic. The treaty is aimed at promoting free trade among its members.

Guatemala has the largest economy in the region. Its main exports are coffee, sugar, bananas, petroleum, clothing, and cardamom. Of its 10.29 billion dollar annual exports, 40.2% go to the United States, 11.1% to neighboring El Salvador, 8% to Honduras, 5.5% to Mexico, 4.7% to Nicaragua, and 4.3% to Costa Rica.

The region is particularly attractive for companies (especially clothing companies) because of its geographical proximity to the[United States], very low wages and considerable tax advantages. In addition, the decline in the prices of coffee and other export products and the structural adjustment measures promoted by the international financial institutions have partly ruined agriculture, favouring the emergence of maquiladoras. This sector accounts for 42 per cent of total exports from El Salvador, 55 per cent from Guatemala, and 65 per cent from Honduras. However, its contribution to the economies of these countries is disputed; raw materials are imported, jobs are precarious and low-paid, and tax exemptions weaken public finances.

They are also criticised for the working conditions of employees: insults and physical violence, abusive dismissals (especially of pregnant workers), working hours, non-payment of overtime. According to Lucrecia Bautista, coordinator of the"maquilas" sector of the audit firm Coverco,"labour law regulations are regularly violated in maquilas and there is no political will to enforce their application. In the case of infringements, the labour inspectorate shows remarkable leniency. It is a question of not discouraging investors. "Trade unionists are subject to pressure, and sometimes to kidnapping or murder. In some cases, business leaders have used the services of the maras. Finally, black lists containing the names of trade unionists or political activists are circulating in employers' circles.

Economic growth in Central America is projected to slow slightly in 2014–15, as country-specific domestic factors offset the positive effects from stronger economic activity in the United States.

Tourism in Belize has grown considerably in more recent times, and it is now the second largest industry in the nation. Belizean Prime Minister Dean Barrow has stated his intention to use tourism to combat poverty throughout the country. The growth in tourism has positively affected the agricultural, commercial, and finance industries, as well as the construction industry. The results for Belize's tourism-driven economy have been significant, with the nation welcoming almost one million tourists in a calendar year for the first time in its history in 2012. Belize is also the only country in Central America with English as its official language, making this country a comfortable destination for English-speaking tourists.

Costa Rica is the most visited nation in Central America. Tourism in Costa Rica is one of the fastest growing economic sectors of the country, having become the largest source of foreign revenue by 1995. Since 1999, tourism has earned more foreign exchange than bananas, pineapples and coffee exports combined. The tourism boom began in 1987, with the number of visitors up from 329,000 in 1988, through 1.03 million in 1999, to a historical record of 2.43 million foreign visitors and $1.92-billion in revenue in 2013. In 2012 tourism contributed with 12.5% of the country's GDP and it was responsible for 11.7% of direct and indirect employment.

Tourism in Nicaragua has grown considerably recently, and it is now the second largest industry in the nation. Nicaraguan President Daniel Ortega has stated his intention to use tourism to combat poverty throughout the country. The growth in tourism has positively affected the agricultural, commercial, and finance industries, as well as the construction industry. The results for Nicaragua's tourism-driven economy have been significant, with the nation welcoming one million tourists in a calendar year for the first time in its history in 2010.

The Inter-American Highway is the Central American section of the Pan-American Highway, and spans between Nuevo Laredo, Mexico, and Panama City, Panama. Because of the break in the highway known as the Darién Gap, it is not possible to cross between Central America and South America in an automobile.




</doc>
<doc id="6122" url="https://en.wikipedia.org/wiki?curid=6122" title="Continuous function">
Continuous function

In mathematics, a continuous function is a function that does not have any abrupt changes in value, known as discontinuities. More precisely, sufficiently small changes in the input of a continuous function result in arbitrarily small changes in its output. If not continuous, a function is said to be "discontinuous". Up until the 19th century, mathematicians largely relied on intuitive notions of continuity, during which attempts such as the epsilon–delta definition were made to formalize it. 

Continuity of functions is one of the core concepts of topology, which is treated in full generality below. The introductory portion of this article focuses on the special case where the inputs and outputs of functions are real numbers. A stronger form of continuity is uniform continuity. In addition, this article discusses the definition for the more general case of functions between two metric spaces. In order theory, especially in domain theory, one considers a notion of continuity known as Scott continuity. Other forms of continuity do exist but they are not discussed in this article.

As an example, the function denoting the height of a growing flower at time would be considered continuous. In contrast, the function denoting the amount of money in a bank account at time would be considered discontinuous, since it "jumps" at each point in time when money is deposited or withdrawn.

A form of the epsilon–delta definition of continuity was first given by Bernard Bolzano in 1817. Augustin-Louis Cauchy defined continuity of formula_1 as follows: an infinitely small increment formula_2 of the independent variable "x" always produces an infinitely small change formula_3 of the dependent variable "y" (see e.g. "Cours d'Analyse", p. 34). Cauchy defined infinitely small quantities in terms of variable quantities, and his definition of continuity closely parallels the infinitesimal definition used today (see microcontinuity). The formal definition and the distinction between pointwise continuity and uniform continuity were first given by Bolzano in the 1830s but the work wasn't published until the 1930s. Like Bolzano, Karl Weierstrass denied continuity of a function at a point "c" unless it was defined at and on both sides of "c", but Édouard Goursat allowed the function to be defined only at and on one side of "c", and Camille Jordan allowed it even if the function was defined only at "c". All three of those nonequivalent definitions of pointwise continuity are still in use. Eduard Heine provided the first published definition of uniform continuity in 1872, but based these ideas on lectures given by Peter Gustav Lejeune Dirichlet in 1854.

A real function, that is a function from real numbers to real numbers can be represented by a graph in the Cartesian plane; such a function is continuous if, roughly speaking, the graph is a single unbroken curve whose domain is the entire real line. A more mathematically rigorous definition is given below.

A rigorous definition of continuity of real functions is usually given in a first course in calculus in terms of the idea of a limit. First, a function with variable is said to be continuous "at the point" on the real line, if the limit of , as approaches that point , is equal to the value ; and second, the "function (as a whole)" is said to be "continuous", if it is continuous at every point. A function is said to be "discontinuous" (or to have a "discontinuity") at some point when it is not continuous there. These points themselves are also addressed as "discontinuities".

There are several different definitions of continuity of a function. Sometimes a function is said to be continuous if it is continuous at every point in its domain. In this case, the function , with the domain of all real ,  any integer, is continuous. Sometimes an exception is made for boundaries of the domain. For example, the graph of the function , with the domain of all non-negative reals, has a "left-hand" endpoint. In this case only the limit from the "right" is required to equal the value of the function. Under this definition "f" is continuous at the boundary and so for all non-negative arguments. The most common and restrictive definition is that a function is continuous if it is continuous at all real numbers. In this case, the previous two examples are not continuous, but every polynomial function is continuous, as are the sine, cosine, and exponential functions. Care should be exercised in using the word "continuous", so that it is clear from the context which meaning of the word is intended.

Using mathematical notation, there are several ways to define continuous functions in each of the three senses mentioned above.

Let

This subset formula_5 is the domain of "f". Some possible choices include 

In case of the domain formula_14 being defined as an open interval, formula_15 and formula_16 are not boundaries in the above sense, and the values of formula_17 and formula_18 do not matter for continuity on formula_14.

The function "f" is "continuous at some point" "c" of its domain if the limit of "f"("x"), as "x" approaches "c" through the domain of "f", exists and is equal to "f"("c"). In mathematical notation, this is written as
In detail this means three conditions: first, "f" has to be defined at "c" (guaranteed by the requirement that "c" is in the domain of "f"). Second, the limit on the left hand side of that equation has to exist. Third, the value of this limit must equal "f"("c").

A neighborhood of a point "c" is a set that contains, at least, all points within some fixed distance of "c". Intuitively, a function is continuous at a point "c" if the range of "f" over the neighborhood of "c" shrinks to a single point "f"("c") as the width of the neighborhood around "c" shrinks to zero. More precisely, a function "f" is continuous at a point "c" of its domain if, for any neighborhood formula_21 there is a neighborhood formula_22 in its domain such that formula_23 whenever formula_24

This definition only requires that the domain and the codomain are topological spaces and is thus the most general definition. It follows from this definition that a function "f" is automatically continuous at every isolated point of its domain. As a specific example, every real valued function on the set of integers is continuous.

One can instead require that for any sequence formula_25 of points in the domain which converges to "c", the corresponding sequence formula_26 converges to "f"("c"). In mathematical notation, formula_27

Explicitly including the definition of the limit of a function, we obtain a self-contained definition:
Given a function "f" : "D" → "R" as above and an element "x" of the domain "D", "f" is said to be continuous at the point "x" when the following holds: For any number "ε" > 0, however small, there exists some number "δ" > 0 such that for all "x" in the domain of "f" with "x" − "δ" < "x" < "x" + "δ", the value of "f"("x") satisfies

Alternatively written, continuity of "f" : "D" → "R" at "x" ∈ "D" means that for every "ε" > 0 there exists a "δ" > 0 such that for all "x" ∈ "D" :

More intuitively, we can say that if we want to get all the "f"("x") values to stay in some small neighborhood around "f"("x"), we simply need to choose a small enough neighborhood for the "x" values around "x". If we can do that no matter how small the "f"("x") neighborhood is, then "f" is continuous at "x".

In modern terms, this is generalized by the definition of continuity of a function with respect to a basis for the topology, here the metric topology.

Weierstrass had required that the interval "x" − "δ" < "x" < "x" + "δ" be entirely within the domain "D", but Jordan removed that restriction.

In proofs and numerical analysis we often need to know how fast limits are converging, or in other words, control of the remainder. We can formalise this to a definition of continuity. 
A function formula_30 is called a control function if

A function "f" : "D" → "R" is "C"-continuous at "x" if 

A function is continuous in "x" if it is "C"-continuous for some control function "C".

This approach leads naturally to refining the notion of continuity by restricting the set of admissible control functions. For a given set of control functions formula_34 a function is formula_34-continuous if it is formula_36-continuous for some formula_37. For example, the Lipschitz and Hölder continuous functions of exponent α below are defined by the set of control functions 
respectively 

Continuity can also be defined in terms of oscillation: a function "f" is continuous at a point "x" if and only if its oscillation at that point is zero; in symbols, formula_41 A benefit of this definition is that it "quantifies" discontinuity: the oscillation gives how "much" the function is discontinuous at a point.

This definition is useful in descriptive set theory to study the set of discontinuities and continuous points – the continuous points are the intersection of the sets where the oscillation is less than "ε" (hence a G set) – and gives a very quick proof of one direction of the Lebesgue integrability condition.

The oscillation is equivalent to the "ε"-"δ" definition by a simple re-arrangement, and by using a limit (lim sup, lim inf) to define oscillation: if (at a given point) for a given "ε" there is no "δ" that satisfies the "ε"-"δ" definition, then the oscillation is at least "ε", and conversely if for every "ε" there is a desired "δ," the oscillation is 0. The oscillation definition can be naturally generalized to maps from a topological space to a metric space.

Cauchy defined continuity of a function in the following intuitive terms: an infinitesimal change in the independent variable corresponds to an infinitesimal change of the dependent variable (see "Cours d'analyse", page 34). Non-standard analysis is a way of making this mathematically rigorous. The real line is augmented by the addition of infinite and infinitesimal numbers to form the hyperreal numbers. In nonstandard analysis, continuity can be defined as follows.

(see microcontinuity). In other words, an infinitesimal increment of the independent variable always produces to an infinitesimal change of the dependent variable, giving a modern expression to Augustin-Louis Cauchy's definition of continuity.

Checking the continuity of a given function can be simplified by checking one of the above defining properties for the building blocks of the given function. It is straightforward to show that the sum of two functions, continuous on some domain, is also continuous on this domain. Given

then the "sum of continuous functions"
is continuous in formula_14.

The same holds for the "product of continuous functions,"
is continuous in formula_14.

Combining the above preservations of continuity and the continuity of constant functions and of the identity function formula_51 one arrives at the continuity of all polynomial functions such as
(pictured on the right).

In the same way it can be shown that the "reciprocal of a continuous function" 
is continuous in formula_56.

This implies that, excluding the roots of formula_57, the "quotient of continuous functions" 
is also continuous on formula_62.

For example, the function (pictured)

is defined for all real numbers and is continuous at every such point. Thus it is a continuous function. The question of continuity at does not arise, since is not in the domain of "y". There is no continuous function "F": R → R that agrees with "y"("x") for all .

Since the function sine is continuous on all reals, the sinc function "G"("x") = sin "x"/"x", is defined and continuous for all real "x" ≠ 0. However, unlike the previous example, "G" "can" be extended to a continuous function on "all" real numbers, by "defining" the value "G"(0) to be 1, which is the limit of "G"("x"), when "x" approaches 0, i.e.,

Thus, by setting

the sinc-function becomes a continuous function on all real numbers. The term "removable singularity" is used in such cases, when (re)defining values of a function to coincide with the appropriate limits make a function continuous at specific points.

A more involved construction of continuous functions is the function composition. Given two continuous functions
their composition, denoted as
formula_67, and defined by formula_68 is continuous.

This construction allows stating, for example, that

An example of a discontinuous function is the Heaviside step function formula_71, defined by

Pick for instance formula_73. Then there is no around formula_74, i.e. no open interval formula_75 with formula_76 that will force all the formula_77 values to be within the of formula_78, i.e. within formula_79. Intuitively we can think of this type of discontinuity as a sudden jump in function values.

Similarly, the signum or sign function
is discontinuous at formula_74 but continuous everywhere else. Yet another example: the function
is continuous everywhere apart from formula_74.
Besides plausible continuities and discontinuities like above, there are also functions with a behavior, often coined pathological, for example, Thomae's function,
is continuous at all irrational numbers and discontinuous at all rational numbers. In a similar vein, Dirichlet's function, the indicator function for the set of rational numbers,
is nowhere continuous.

Let formula_86 be a function that is continuous at a point formula_87 and formula_88 be a value such formula_89 Then formula_90 throughout some neighbourhood of formula_91

"Proof:" By the definition of continuity, take formula_92 , then there exists formula_93 such that 
Suppose there is a point in the neighbourhood formula_95 for which formula_96 then we have the contradiction

The intermediate value theorem is an existence theorem, based on the real number property of completeness, and states:

For example, if a child grows from 1 m to 1.5 m between the ages of two and six years, then, at some time between two and six years of age, the child's height must have been 1.25 m.

As a consequence, if "f" is continuous on ["a", "b"] and "f"("a") and "f"("b") differ in sign, then, at some point "c" in ["a", "b"], "f"("c") must equal zero.

The extreme value theorem states that if a function "f" is defined on a closed interval ["a","b"] (or any closed and bounded set) and is continuous there, then the function attains its maximum, i.e. there exists "c" ∈ ["a","b"] with "f"("c") ≥ "f"("x") for all "x" ∈ ["a","b"]. The same is true of the minimum of "f". These statements are not, in general, true if the function is defined on an open interval ("a","b") (or any set that is not both closed and bounded), as, for example, the continuous function "f"("x") = 1/"x", defined on the open interval (0,1), does not attain a maximum, being unbounded above.

Every differentiable function
is continuous, as can be shown. The converse does not hold: for example, the absolute value function
is everywhere continuous. However, it is not differentiable at "x" = 0 (but is so everywhere else). Weierstrass's function is also everywhere continuous but nowhere differentiable.

The derivative "f′"("x") of a differentiable function "f"("x") need not be continuous. If "f′"("x") is continuous, "f"("x") is said to be continuously differentiable. The set of such functions is denoted "C"(). More generally, the set of functions
(from an open interval (or open subset of R) Ω to the reals) such that "f" is "n" times differentiable and such that the "n"-th derivative of "f" is continuous is denoted "C"(Ω). See differentiability class. In the field of computer graphics, properties related (but not identical) to "C", "C", "C" are sometimes called "G" (continuity of position), "G" (continuity of tangency), and "G" (continuity of curvature); see Smoothness of curves and surfaces.

Every continuous function
is integrable (for example in the sense of the Riemann integral). The converse does not hold, as the (integrable, but discontinuous) sign function shows.

Given a sequence
of functions such that the limit
exists for all "x" in "D", the resulting function "f"("x") is referred to as the pointwise limit of the sequence of functions ("f"). The pointwise limit function need not be continuous, even if all functions "f" are continuous, as the animation at the right shows. However, "f" is continuous if all functions "f" are continuous and the sequence converges uniformly, by the uniform convergence theorem. This theorem can be used to show that the exponential functions, logarithms, square root function, and trigonometric functions are continuous.

Discontinuous functions may be discontinuous in a restricted way, giving rise to the concept of directional continuity (or right and left continuous functions) and semi-continuity. Roughly speaking, a function is "right-continuous" if no jump occurs when the limit point is approached from the right. Formally, "f" is said to be right-continuous at the point "c" if the following holds: For any number "ε" > 0 however small, there exists some number "δ" > 0 such that for all "x" in the domain with , the value of "f"("x") will satisfy

This is the same condition as for continuous functions, except that it is required to hold for "x" strictly larger than "c" only. Requiring it instead for all "x" with yields the notion of "left-continuous" functions. A function is continuous if and only if it is both right-continuous and left-continuous.

A function "f" is "lower semi-continuous" if, roughly, any jumps that might occur only go down, but not up. That is, for any "ε" > 0, there exists some number "δ" > 0 such that for all "x" in the domain with , the value of "f"("x") satisfies
The reverse condition is "upper semi-continuity".

The concept of continuous real-valued functions can be generalized to functions between metric spaces. A metric space is a set "X" equipped with a function (called metric) "d", that can be thought of as a measurement of the distance of any two elements in "X". Formally, the metric is a function
that satisfies a number of requirements, notably the triangle inequality. Given two metric spaces ("X", d) and ("Y", d) and a function
then "f" is continuous at the point "c" in "X" (with respect to the given metrics) if for any positive real number ε, there exists a positive real number δ such that all "x" in "X" satisfying d("x", "c") < δ will also satisfy d("f"("x"), "f"("c")) < ε. As in the case of real functions above, this is equivalent to the condition that for every sequence ("x") in "X" with limit lim "x" = "c", we have lim "f"("x") = "f"("c"). The latter condition can be weakened as follows: "f" is continuous at the point "c" if and only if for every convergent sequence ("x") in "X" with limit "c", the sequence ("f"("x")) is a Cauchy sequence, and "c" is in the domain of "f".

The set of points at which a function between metric spaces is continuous is a G set – this follows from the ε-δ definition of continuity.

This notion of continuity is applied, for example, in functional analysis. A key statement in this area says that a linear operator
between normed vector spaces "V" and "W" (which are vector spaces equipped with a compatible norm, denoted ||"x"||)
is continuous if and only if it is bounded, that is, there is a constant "K" such that
for all "x" in "V".

The concept of continuity for functions between metric spaces can be strengthened in various ways by limiting the way δ depends on ε and "c" in the definition above. Intuitively, a function "f" as above is uniformly continuous if the δ does
not depend on the point "c". More precisely, it is required that for every real number "ε" > 0 there exists "δ" > 0 such that for every "c", "b" ∈ "X" with "d"("b", "c") < "δ", we have that "d"("f"("b"), "f"("c")) < "ε". Thus, any uniformly continuous function is continuous. The converse does not hold in general, but holds when the domain space "X" is compact. Uniformly continuous maps can be defined in the more general situation of uniform spaces.

A function is Hölder continuous with exponent α (a real number) if there is a constant "K" such that for all "b" and "c" in "X", the inequality
holds. Any Hölder continuous function is uniformly continuous. The particular case is referred to as Lipschitz continuity. That is, a function is Lipschitz continuous if there is a constant "K" such that the inequality
holds for any "b", "c" in "X". The Lipschitz condition occurs, for example, in the Picard–Lindelöf theorem concerning the solutions of ordinary differential equations.

Another, more abstract, notion of continuity is continuity of functions between topological spaces in which there generally is no formal notion of distance, as there is in the case of metric spaces. A topological space is a set "X" together with a topology on "X", which is a set of subsets of "X" satisfying a few requirements with respect to their unions and intersections that generalize the properties of the open balls in metric spaces while still allowing to talk about the neighbourhoods of a given point. The elements of a topology are called open subsets of "X" (with respect to the topology).

A function
between two topological spaces "X" and "Y" is continuous if for every open set "V" ⊆ "Y", the inverse image
is an open subset of "X". That is, "f" is a function between the sets "X" and "Y" (not on the elements of the topology "T"), but the continuity of "f" depends on the topologies used on "X" and "Y".

This is equivalent to the condition that the preimages of the closed sets (which are the complements of the open subsets) in "Y" are closed in "X".

An extreme example: if a set "X" is given the discrete topology (in which every subset is open), all functions
to any topological space "T" are continuous. On the other hand, if "X" is equipped with the indiscrete topology (in which the only open subsets are the empty set and "X") and the space "T" set is at least T, then the only continuous functions are the constant functions. Conversely, any function whose range is indiscrete is continuous.

The translation in the language of neighborhoods of the (ε, δ)-definition of continuity leads to the following definition of the continuity at a point:
This definition is equivalent to the same statement with neighborhoods restricted to open neighborhoods and can be restated in several ways by using preimages rather than images.

Also, as every set that contains a neighborhood is also a neighborhood, and formula_115 is the largest subset of such that , this definition may be simplified into:
As an open set is a set that is a neighborhood of all its points, a function formula_116 is continuous at every point of if and only if it is a continuous function.

If "X" and "Y" are metric spaces, it is equivalent to consider the neighborhood system of open balls centered at "x" and "f"("x") instead of all neighborhoods. This gives back the above δ-ε definition of continuity in the context of metric spaces. In general topological spaces, there is no notion of nearness or distance. If however the target space is a Hausdorff space, it is still true that "f" is continuous at "a" if and only if the limit of "f" as "x" approaches "a" is "f"("a"). At an isolated point, every function is continuous.

Several equivalent definitions for a topological structure exist and thus there are several equivalent ways to define a continuous function.

In several contexts, the topology of a space is conveniently specified in terms of limit points. In many instances, this is accomplished by specifying when a point is the limit of a sequence, but for some spaces that are too large in some sense, one specifies also when a point is the limit of more general sets of points indexed by a directed set, known as nets. A function is (Heine-)continuous only if it takes limits of sequences to limits of sequences. In the former case, preservation of limits is also sufficient; in the latter, a function may preserve all limits of sequences yet still fail to be continuous, and preservation of nets is a necessary and sufficient condition.

In detail, a function "f": "X" → "Y" is sequentially continuous if whenever a sequence ("x") in "X" converges to a limit "x", the sequence ("f"("x")) converges to "f"("x"). Thus sequentially continuous functions "preserve sequential limits". Every continuous function is sequentially continuous. If "X" is a first-countable space and countable choice holds, then the converse also holds: any function preserving sequential limits is continuous. In particular, if "X" is a metric space, sequential continuity and continuity are equivalent. For non first-countable spaces, sequential continuity might be strictly weaker than continuity. (The spaces for which the two properties are equivalent are called sequential spaces.) This motivates the consideration of nets instead of sequences in general topological spaces. Continuous functions preserve limits of nets, and in fact this property characterizes continuous functions.

Instead of specifying the open subsets of a topological space, the topology can also be determined by a closure operator (denoted cl) which assigns to any subset "A" ⊆ "X" its closure, or an interior operator (denoted int), which assigns to any subset "A" of "X" its interior. In these terms, a function
between topological spaces is continuous in the sense above if and only if for all subsets "A" of "X"
That is to say, given any element "x" of "X" that is in the closure of any subset "A", "f"("x") belongs to the closure of "f"("A"). This is equivalent to the requirement that for all subsets "A"<nowiki>'</nowiki> of "X"<nowiki>'</nowiki>
Moreover,
is continuous if and only if
for any subset "A"' of "Y".

If "f": "X" → "Y" and "g": "Y" → "Z" are continuous, then so is the composition "g" ∘ "f": "X" → "Z". If "f": "X" → "Y" is continuous and

The possible topologies on a fixed set "X" are partially ordered: a topology τ is said to be coarser than another topology τ (notation: τ ⊆ τ) if every open subset with respect to τ is also open with respect to τ. Then, the identity map
is continuous if and only if τ ⊆ τ (see also comparison of topologies). More generally, a continuous function
stays continuous if the topology τ is replaced by a coarser topology and/or τ is replaced by a finer topology.

Symmetric to the concept of a continuous map is an open map, for which "images" of open sets are open. In fact, if an open map "f" has an inverse function, that inverse is continuous, and if a continuous map "g" has an inverse, that inverse is open. Given a bijective function "f" between two topological spaces, the inverse function "f" need not be continuous. A bijective continuous function with continuous inverse function is called a "homeomorphism".

If a continuous bijection has as its domain a compact space and its codomain is Hausdorff, then it is a homeomorphism.

Given a function
where "X" is a topological space and "S" is a set (without a specified topology), the final topology on "S" is defined by letting the open sets of "S" be those subsets "A" of "S" for which "f"("A") is open in "X". If "S" has an existing topology, "f" is continuous with respect to this topology if and only if the existing topology is coarser than the final topology on "S". Thus the final topology can be characterized as the finest topology on "S" that makes "f" continuous. If "f" is surjective, this topology is canonically identified with the quotient topology under the equivalence relation defined by "f".

Dually, for a function "f" from a set "S" to a topological space "X", the initial topology on "S" is defined by designating as an open set every subset "A" of "S" such that formula_124 for some open subset "U" of "X". If "S" has an existing topology, "f" is continuous with respect to this topology if and only if the existing topology is finer than the initial topology on "S". Thus the initial topology can be characterized as the coarsest topology on "S" that makes "f" continuous. If "f" is injective, this topology is canonically identified with the subspace topology of "S", viewed as a subset of "X".

A topology on a set "S" is uniquely determined by the class of all continuous functions formula_125 into all topological spaces "X". Dually, a similar idea can be applied to maps formula_126

Various other mathematical domains use the concept of continuity in different, but related meanings. For example, in order theory, an order-preserving function "f": "X" → "Y" between particular types of partially ordered sets "X" and "Y" is continuous if for each directed subset "A" of "X", we have sup("f"("A")) = "f"(sup("A")). Here sup is the supremum with respect to the orderings in "X" and "Y", respectively. This notion of continuity is the same as topological continuity when the partially ordered sets are given the Scott topology.

In category theory, a functor
between two categories is called "continuous", if it commutes with small limits. That is to say,
for any small (i.e., indexed by a set "I", as opposed to a class) diagram of objects in formula_129.

A "continuity space" is a generalization of metric spaces and posets, which uses the concept of quantales, and that can be used to unify the notions of metric spaces and domains.



</doc>
<doc id="6123" url="https://en.wikipedia.org/wiki?curid=6123" title="Curl (mathematics)">
Curl (mathematics)

In vector calculus, the curl is a vector operator that describes the infinitesimal rotation of a vector field in three-dimensional Euclidean space. At every point in the field, the curl of that point is represented by a vector. The attributes of this vector (length and direction) characterize the rotation at that point.

The direction of the curl is the axis of rotation, as determined by the right-hand rule, and the magnitude of the curl is the magnitude of rotation. If the vector field represents the flow velocity of a moving fluid, then the curl is the circulation density of the fluid. A vector field whose curl is zero is called irrotational. The curl is a form of differentiation for vector fields. The corresponding form of the fundamental theorem of calculus is Stokes' theorem, which relates the surface integral of the curl of a vector field to the line integral of the vector field around the boundary curve.

The alternative terminology "rotation" or "rotational" and alternative notations and are often used (the former especially in many European countries, the latter, using the del (or nabla) operator and the cross product, is more used in other countries) for .

Unlike the gradient and divergence, curl does not generalize as simply to other dimensions; some generalizations are possible, but only in three dimensions is the geometrically defined curl of a vector field again a vector field. This is a phenomenon similar to the 3-dimensional cross product, and the connection is reflected in the notation for the curl.

The name "curl" was first suggested by James Clerk Maxwell in 1871 but the concept was apparently first used in the construction of an optical field theory by James MacCullagh in 1839.

The curl of a vector field , denoted by , or , or , at a point is defined in terms of its projection onto various lines through the point. If formula_1 is any unit vector, the projection of the curl of onto formula_1 is defined to be the limiting value of a closed line integral in a plane orthogonal to formula_1 divided by the area enclosed, as the path of integration is contracted around the point.

The curl operator maps continuously differentiable functions to continuous functions , and in particular, it maps functions in to functions in . 

Implicitly, curl is defined:

where is a line integral along the boundary of the area in question, and is the magnitude of the area. This equation defines the projection of the curl of onto formula_1, where formula_1 is the normal vector to the surface bounded by ; and is defined via the right-hand rule (see diagram).

The above formula means that the curl of a vector field is defined as the infinitesimal area density of the "circulation" of that field. To this definition fit naturally 

The equation for each component can be obtained by exchanging each occurrence of a subscript 1, 2, 3 in cyclic permutation: 1 → 2, 2 → 3, and 3 → 1 (where the subscripts represent the relevant indices).

If are the Cartesian coordinates and are the orthogonal coordinates, then 
is the length of the coordinate vector corresponding to . The remaining two components of curl result from cyclic permutation of indices: 3,1,2 → 1,2,3 → 2,3,1.

Suppose the vector field describes the velocity field of a fluid flow (such as a large tank of liquid or gas) and a small ball is located within the fluid or gas (the centre of the ball being fixed at a certain point). If the ball has a rough surface, the fluid flowing past it will make it rotate. The rotation axis (oriented according to the right hand rule) points in the direction of the curl of the field at the centre of the ball, and the angular speed of the rotation is half the magnitude of the curl at this point.

The curl of the vector at any point is given by the rotation of an infinitesimal area in the "xy"-plane (for "z"-axis component of the curl), "zx"-plane (for "y"-axis component of the curl) and "yz"-plane (for "x"-axis component of the curl vector). This can be clearly seen in the examples below.

In practice, the above definition is rarely used because in virtually all cases, the curl operator can be applied using some set of curvilinear coordinates, for which simpler representations have been derived.

The notation has its origins in the similarities to the 3-dimensional cross product, and it is useful as a mnemonic in Cartesian coordinates if is taken as a vector differential operator del. Such notation involving operators is common in physics and algebra.

Expanded in 3-dimensional Cartesian coordinates (see "Del in cylindrical and spherical coordinates" for spherical and cylindrical coordinate representations), is, for composed of :

where , , and are the unit vectors for the -, -, and -axes, respectively. This expands as follows:

Although expressed in terms of coordinates, the result is invariant under proper rotations of the coordinate axes but the result inverts under reflection.

In a general coordinate system, the curl is given by

where denotes the Levi-Civita tensor and the covariant derivative, the metric tensor is used to lower the index on , and the Einstein summation convention implies that repeated indices are summed over. In Cartesian coordinate system, the covariant derivative reduces to the partial derivative. Equivalently,

where are the coordinate vector fields. Equivalently, using the exterior derivative, the curl can be expressed as:

Here and are the musical isomorphisms, and is the Hodge star operator. This formula shows how to calculate the curl of in any coordinate system, and how to extend the curl to any oriented three-dimensional Riemannian manifold. Since this depends on a choice of orientation, curl is a chiral operation. In other words, if the orientation is reversed, then the direction of the curl is also reversed.

Take the vector field:

For clarity, this can be decomposed as follows:

Its corresponding plot:

Upon visual inspection, the field can be described as "rotating". If the vectors of the field were to represent a linear force acting on objects present at that point, and an object were to be placed inside the field, the object would start to rotate clockwise around itself. This is true regardless of where the object is placed.

Calculating the curl:

The resulting vector field describing the curl would be uniformly going in the negative direction. The results of this equation align with what could have been predicted using the right-hand rule using a right-handed coordinate system. Being a uniform vector field, the object described before would have the same rotational intensity regardless of where it was placed.

The plot describing the curl of :

Take the vector field:

Its corresponding plot:

Upon initial inspection, curl existing in this graph would not be obvious. However, taking the object in the previous example, and placing it anywhere on the line , the force exerted on the right side would be slightly greater than the force exerted on the left, causing it to rotate clockwise. Using the right-hand rule, it can be predicted that the resulting curl would be straight in the negative direction. Inversely, if placed on , the object would rotate counterclockwise and the right-hand rule would result in a positive direction.

Calculating the curl:

As predicted, the curl points in the negative direction when is positive and vice versa. In this field, the intensity of rotation would be greater as the object moves away from the plane .

The plot describing the curl of :


In general curvilinear coordinates (not only in Cartesian coordinates), the curl of a cross product of vector fields and can be shown to be

Interchanging the vector field and operator, we arrive at the cross product of a vector field with curl of a vector field:

where is the Feynman subscript notation, which considers only the variation due to the vector field (i.e., in this case, is treated as being constant in space).

Another example is the curl of a curl of a vector field. It can be shown that in general coordinates

and this identity defines the vector Laplacian of , symbolized as .

The curl of the gradient of "any" scalar field is always the zero vector field

which follows from the antisymmetry in the definition of the curl, and the symmetry of second derivatives.

If is a scalar valued function and is a vector field, then

The vector calculus operations of grad, curl, and div are most easily generalized in the context of differential forms, which involves a number of steps. In short, they correspond to the derivatives of 0-forms, 1-forms, and 2-forms, respectively. The geometric interpretation of curl as rotation corresponds to identifying bivectors (2-vectors) in 3 dimensions with the special orthogonal Lie algebra of infinitesimal rotations (in coordinates, skew-symmetric 3 × 3 matrices), while representing rotations by vectors corresponds to identifying 1-vectors (equivalently, 2-vectors) and , these all being 3-dimensional spaces.

In 3 dimensions, a differential 0-form is simply a function ; a differential 1-form is the following expression:
a differential 2-form is the formal sum:
and a differential 3-form is defined by a single term:

The exterior derivative of a -form in is defined as the -form from above—and in if, e.g.,

then the exterior derivative leads to

The exterior derivative of a 1-form is therefore a 2-form, and that of a 2-form is a 3-form. On the other hand, because of the interchangeability of mixed derivatives, e.g. because of

the twofold application of the exterior derivative leads to 0.

Thus, denoting the space of -forms by and the exterior derivative by one gets a sequence:

Here is the space of sections of the exterior algebra vector bundle over ℝ, whose dimension is the binomial coefficient ; note that for or . Writing only dimensions, one obtains a row of Pascal's triangle:

the 1-dimensional fibers correspond to scalar fields, and the 3-dimensional fibers to vector fields, as described below. Modulo suitable identifications, the three nontrivial occurrences of the exterior derivative correspond to grad, curl, and div.

Differential forms and the differential can be defined on any Euclidean space, or indeed any manifold, without any notion of a Riemannian metric. On a Riemannian manifold, or more generally pseudo-Riemannian manifold, -forms can be identified with -vector fields (-forms are -covector fields, and a pseudo-Riemannian metric gives an isomorphism between vectors and covectors), and on an "oriented" vector space with a nondegenerate form (an isomorphism between vectors and covectors), there is an isomorphism between -vectors and -vectors; in particular on (the tangent space of) an oriented pseudo-Riemannian manifold. Thus on an oriented pseudo-Riemannian manifold, one can interchange -forms, -vector fields, -forms, and -vector fields; this is known as Hodge duality. Concretely, on this is given by:

Thus, identifying 0-forms and 3-forms with scalar fields, and 1-forms and 2-forms with vector fields:

On the other hand, the fact that corresponds to the identities
for any scalar field , and
for any vector field .

Grad and div generalize to all oriented pseudo-Riemannian manifolds, with the same geometric interpretation, because the spaces of 0-forms and -forms is always (fiberwise) 1-dimensional and can be identified with scalar fields, while the spaces of 1-forms and -forms are always fiberwise -dimensional and can be identified with vector fields.

Curl does not generalize in this way to 4 or more dimensions (or down to 2 or fewer dimensions); in 4 dimensions the dimensions are

so the curl of a 1-vector field (fiberwise 4-dimensional) is a "2-vector field", which is fiberwise 6-dimensional, one has

which yields a sum of six independent terms, and cannot be identified with a 1-vector field. Nor can one meaningfully go from a 1-vector field to a 2-vector field to a 3-vector field (4 → 6 → 4), as taking the differential twice yields zero (). Thus there is no curl function from vector fields to vector fields in other dimensions arising in this way.

However, one can define a curl of a vector field as a "2-vector field" in general, as described below.

2-vectors correspond to the exterior power ; in the presence of an inner product, in coordinates these are the skew-symmetric matrices, which are geometrically considered as the special orthogonal Lie algebra of infinitesimal rotations. This has dimensions, and allows one to interpret the differential of a 1-vector field as its infinitesimal rotations. Only in 3 dimensions (or trivially in 0 dimensions) does , which is the most elegant and common case. In 2 dimensions the curl of a vector field is not a vector field but a function, as 2-dimensional rotations are given by an angle (a scalar – an orientation is required to choose whether one counts clockwise or counterclockwise rotations as positive); this is not the div, but is rather perpendicular to it. In 3 dimensions the curl of a vector field is a vector field as is familiar (in 1 and 0 dimensions the curl of a vector field is 0, because there are no non-trivial 2-vectors), while in 4 dimensions the curl of a vector field is, geometrically, at each point an element of the 6-dimensional Lie algebra .

The curl of a 3-dimensional vector field which only depends on 2 coordinates (say and ) is simply a vertical vector field (in the direction) whose magnitude is the curl of the 2-dimensional vector field, as in the examples on this page.

Considering curl as a 2-vector field (an antisymmetric 2-tensor) has been used to generalize vector calculus and associated physics to higher dimensions.

In case the divergence of a vector field V is zero, then there exist vector fields W such that curl(W) = V.

If W is one vector field with curl(W) = V, then adding any gradient vector field grad(f) to W will result in another vector field W + grad(f) such that curl(W + grad(f)) = V as well. This can be summarized by saying that the inverse curl of a three-dimensional vector field can be obtained up to an integration constant and an unknown irrotational field with the Biot–Savart law.





</doc>
<doc id="6125" url="https://en.wikipedia.org/wiki?curid=6125" title="Carl Friedrich Gauss">
Carl Friedrich Gauss

Johann Carl Friedrich Gauss (; ; ; 30 April 177723 February 1855) was a German mathematician and physicist who made significant contributions to many fields in mathematics and science. Sometimes referred to as the "Princeps mathematicorum" () and "the greatest mathematician since antiquity", Gauss had an exceptional influence in many fields of mathematics and science, and is ranked among history's most influential mathematicians.

Johann Carl Friedrich Gauss was born on 30 April 1777 in Brunswick (Braunschweig), in the Duchy of Brunswick-Wolfenbüttel (now part of Lower Saxony, Germany), to poor, working-class parents. His mother was illiterate and never recorded the date of his birth, remembering only that he had been born on a Wednesday, eight days before the Feast of the Ascension (which occurs 39 days after Easter). Gauss later solved this puzzle about his birthdate in the context of finding the date of Easter, deriving methods to compute the date in both past and future years. He was christened and confirmed in a church near the school he attended as a child.

Gauss was a child prodigy. In his memorial on Gauss, Wolfgang Sartorius von Waltershausen says that when Gauss was barely three years old he corrected a math error his father made; and that when he was seven, he confidently solved an arithmetic series problem (commonly said to be ) faster than anyone else in his class of 100 students. Many versions of this story have been retold since that time with various details regarding what the series was – the most frequent being the classical problem of adding all the integers from 1 to 100. There are many other anecdotes about his precocity while a toddler, and he made his first groundbreaking mathematical discoveries while still a teenager. He completed his magnum opus, "Disquisitiones Arithmeticae", in 1798, at the age of 21—though it was not published until 1801. This work was fundamental in consolidating number theory as a discipline and has shaped the field to the present day.

Gauss's intellectual abilities attracted the attention of the Duke of Brunswick, who sent him to the Collegium Carolinum (now Braunschweig University of Technology), which he attended from 1792 to 1795, and to the University of Göttingen from 1795 to 1798.
While at university, Gauss independently rediscovered several important theorems. His breakthrough occurred in 1796 when he showed that a regular polygon can be constructed by compass and straightedge if the number of its sides is the product of distinct Fermat primes and a power of 2. This was a major discovery in an important field of mathematics; construction problems had occupied mathematicians since the days of the Ancient Greeks, and the discovery ultimately led Gauss to choose mathematics instead of philology as a career.
Gauss was so pleased with this result that he requested that a regular heptadecagon be inscribed on his tombstone. The stonemason declined, stating that the difficult construction would essentially look like a circle.

The year 1796 was productive for both Gauss and number theory. He discovered a construction of the heptadecagon on 30 March. He further advanced modular arithmetic, greatly simplifying manipulations in number theory. On 8 April he became the first to prove the quadratic reciprocity law. This remarkably general law allows mathematicians to determine the solvability of any quadratic equation in modular arithmetic. The prime number theorem, conjectured on 31 May, gives a good understanding of how the prime numbers are distributed among the integers.

Gauss also discovered that every positive integer is representable as a sum of at most three triangular numbers on 10 July and then jotted down in his diary the note: "ΕΥΡΗΚΑ! . On 1 October he published a result on the number of solutions of polynomials with coefficients in finite fields, which 150 years later led to the Weil conjectures.

Gauss remained mentally active into his old age, even while suffering from gout and general unhappiness. For example, at the age of 62, he taught himself Russian.

In 1840, Gauss published his influential "Dioptrische Untersuchungen", in which he gave the first systematic analysis on the formation of images under a paraxial approximation (Gaussian optics). Among his results, Gauss showed that under a paraxial approximation an optical system can be characterized by its cardinal points and he derived the Gaussian lens formula.

In 1845, he became an associated member of the Royal Institute of the Netherlands; when that became the Royal Netherlands Academy of Arts and Sciences in 1851, he joined as a foreign member.

In 1854, Gauss selected the topic for Bernhard Riemann's inaugural lecture "Über die Hypothesen, welche der Geometrie zu Grunde liegen" ("About the hypotheses that underlie Geometry"). On the way home from Riemann's lecture, Weber reported that Gauss was full of praise and excitement.

On 23 February 1855, Gauss died of a heart attack in Göttingen (then Kingdom of Hanover and now Lower Saxony); he is interred in the Albani Cemetery there. Two people gave eulogies at his funeral: Gauss's son-in-law Heinrich Ewald, and Wolfgang Sartorius von Waltershausen, who was Gauss's close friend and biographer. Gauss's brain was preserved and was studied by Rudolf Wagner, who found its mass to be slightly above average, at 1,492 grams, and the cerebral area equal to 219,588 square millimeters (340.362 square inches). Highly developed convolutions were also found, which in the early 20th century were suggested as the explanation of his genius.

Gauss was a Lutheran Protestant, a member of the St. Albans Evangelical Lutheran church in Göttingen. Potential evidence that Gauss believed in God comes from his response after solving a problem that had previously defeated him: "Finally, two days ago, I succeeded—not on account of my hard efforts, but by the grace of the Lord." One of his biographers, G. Waldo Dunnington, described Gauss's religious views as follows:
For him science was the means of exposing the immortal nucleus of the human soul. In the days of his full strength, it furnished him recreation and, by the prospects which it opened up to him, gave consolation. Toward the end of his life, it brought him confidence. Gauss's God was not a cold and distant figment of metaphysics, nor a distorted caricature of embittered theology. To man is not vouchsafed that fullness of knowledge which would warrant his arrogantly holding that his blurred vision is the full light and that there can be none other which might report the truth as does his. For Gauss, not he who mumbles his creed, but he who lives it, is accepted. He believed that a life worthily spent here on earth is the best, the only, preparation for heaven. Religion is not a question of literature, but of life. God's revelation is continuous, not contained in tablets of stone or sacred parchment. A book is inspired when it inspires. The unshakeable idea of personal continuance after death, the firm belief in a last regulator of things, in an eternal, just, omniscient, omnipotent God, formed the basis of his religious life, which harmonized completely with his scientific research.

Apart from his correspondence, there are not many known details about Gauss's personal creed. Many biographers of Gauss disagree about his religious stance, with Bühler and others considering him a deist with very unorthodox views, while Dunnington (though admitting that Gauss did not believe literally in all Christian dogmas and that it is unknown what he believed on most doctrinal and confessional questions) points out that he was, at least, a nominal Lutheran.

In connection to this, there is a record of a conversation between Rudolf Wagner and Gauss, in which they discussed William Whewell's book "Of the Plurality of Worlds". In this work, Whewell had discarded the possibility of existing life in other planets, on the basis of theological arguments, but this was a position with which both Wagner and Gauss disagreed. Later Wagner explained that he did not fully believe in the Bible, though he confessed that he "envied" those who were able to easily believe. This later led them to discuss the topic of faith, and in some other religious remarks, Gauss said that he had been more influenced by theologians like Lutheran minister Paul Gerhardt than by Moses. Other religious influences included Wilhelm Braubach, Johann Peter Süssmilch, and the New Testament. Two religious works which Gauss read frequently were Braubach's "Seelenlehre" (Giessen, 1843) and Süssmilch's "Gottliche" (Ordnung gerettet A756); he also devoted considerable time to the New Testament in the original Greek.

Dunnington further elaborates on Gauss's religious views by writing: Gauss's religious consciousness was based on an insatiable thirst for truth and a deep feeling of justice extending to intellectual as well as material goods. He conceived spiritual life in the whole universe as a great system of law penetrated by eternal truth, and from this source he gained the firm confidence that death does not end all.

Gauss declared he firmly believed in the afterlife, and saw spirituality as something essentially important for human beings. He was quoted stating: ""The world would be nonsense, the whole creation an absurdity without immortality,"" and for this statement he was severely criticized by the atheist Eugen Dühring who judged him as a narrow superstitious man.

Though he was not a church-goer, Gauss strongly upheld religious tolerance, believing "that one is not justified in disturbing another's religious belief, in which they find consolation for earthly sorrows in time of trouble." When his son Eugene announced that he wanted to become a Christian missionary, Gauss approved of this, saying that regardless of the problems within religious organizations, missionary work was "a highly honorable" task.

On 9 October 1805, Gauss married Johanna Osthoff (1780–1809), and had two sons and a daughter with her. Johanna died on 11 October 1809, and her most recent child, Louis, died the following year. Gauss plunged into a depression from which he never fully recovered. He then married Minna Waldeck (1788–1831) on 4 August 1810, and had three more children. Gauss was never quite the same without his first wife, and he, just like his father, grew to dominate his children. Minna Waldeck died on 12 September 1831.

Gauss had six children. With Johanna (1780–1809), his children were Joseph (1806–1873), Wilhelmina (1808–1846) and Louis (1809–1810). With Minna Waldeck he also had three children: Eugene (1811–1896), Wilhelm (1813–1879) and Therese (1816–1864). Eugene shared a good measure of Gauss's talent in languages and computation. After his second wife's death in 1831 Therese took over the household and cared for Gauss for the rest of his life. His mother lived in his house from 1817 until her death in 1839.

Gauss eventually had conflicts with his sons. He did not want any of his sons to enter mathematics or science for "fear of lowering the family name", as he believed none of them would surpass his own achievements. Gauss wanted Eugene to become a lawyer, but Eugene wanted to study languages. They had an argument over a party Eugene held, for which Gauss refused to pay. The son left in anger and, in about 1832, emigrated to the United States. While working for the American Fur Company in the Midwest, he learned the Sioux language. Later, he moved to Missouri and became a successful businessman. Wilhelm also moved to America in 1837 and settled in Missouri, starting as a farmer and later becoming wealthy in the shoe business in St. Louis. It took many years for Eugene's success to counteract his reputation among Gauss's friends and colleagues. See also on 3 September 1912.

Gauss was an ardent perfectionist and a hard worker. He was never a prolific writer, refusing to publish work which he did not consider complete and above criticism. This was in keeping with his personal motto "pauca sed matura" ("few, but ripe"). His personal diaries indicate that he had made several important mathematical discoveries years or decades before his contemporaries published them. Scottish-American mathematician and writer Eric Temple Bell said that if Gauss had published all of his discoveries in a timely manner, he would have advanced mathematics by fifty years.

Though he did take in a few students, Gauss was known to dislike teaching. It is said that he attended only a single scientific conference, which was in Berlin in 1828. However, several of his students became influential mathematicians, among them Richard Dedekind and Bernhard Riemann.

On Gauss's recommendation, Friedrich Bessel was awarded an honorary doctor degree from Göttingen in March 1811. Around that time, the two men engaged in a correspondence. However, when they met in person in 1825, they quarrelled; the details are unknown.

Before she died, Sophie Germain was recommended by Gauss to receive an honorary degree; she never received it.

Gauss usually declined to present the intuition behind his often very elegant proofs—he preferred them to appear "out of thin air" and erased all traces of how he discovered them. This is justified, if unsatisfactorily, by Gauss in his "Disquisitiones Arithmeticae", where he states that all analysis (i.e., the paths one traveled to reach the solution of a problem) must be suppressed for sake of brevity.

Gauss supported the monarchy and opposed Napoleon, whom he saw as an outgrowth of revolution.

Gauss summarized his views on the pursuit of knowledge in a letter to Farkas Bolyai dated 2 September 1808 as follows:It is not knowledge, but the act of learning, not possession but the act of getting there, which grants the greatest enjoyment. When I have clarified and exhausted a subject, then I turn away from it, in order to go into darkness again. The never-satisfied man is so strange; if he has completed a structure, then it is not in order to dwell in it peacefully, but in order to begin another. I imagine the world conqueror must feel thus, who, after one kingdom is scarcely conquered, stretches out his arms for others.

In his 1799 doctorate in absentia, "A new proof of the theorem that every integral rational algebraic function of one variable can be resolved into real factors of the first or second degree", Gauss proved the fundamental theorem of algebra which states that every non-constant single-variable polynomial with complex coefficients has at least one complex root. Mathematicians including Jean le Rond d'Alembert had produced false proofs before him, and Gauss's dissertation contains a critique of d'Alembert's work. Ironically, by today's standard, Gauss's own attempt is not acceptable, owing to the implicit use of the Jordan curve theorem. However, he subsequently produced three other proofs, the last one in 1849 being generally rigorous. His attempts clarified the concept of complex numbers considerably along the way.

Gauss also made important contributions to number theory with his 1801 book "Disquisitiones Arithmeticae" (Latin, Arithmetical Investigations), which, among other things, introduced the triple bar symbol for congruence and used it in a clean presentation of modular arithmetic, contained the first two proofs of the law of quadratic reciprocity, developed the theories of binary and ternary quadratic forms, stated the class number problem for them, and showed that a regular heptadecagon (17-sided polygon) can be constructed with straightedge and compass. It appears that Gauss already knew the class number formula in 1801.

In addition, he proved the following conjectured theorems:

He also

On 1 January 1801, Italian astronomer Giuseppe Piazzi discovered the dwarf planet Ceres. Piazzi could only track Ceres for somewhat more than a month, following it for three degrees across the night sky. Then it disappeared temporarily behind the glare of the Sun. Several months later, when Ceres should have reappeared, Piazzi could not locate it: the mathematical tools of the time were not able to extrapolate a position from such a scant amount of data—three degrees represent less than 1% of the total orbit. Gauss heard about the problem and tackled it. After three months of intense work, he predicted a position for Ceres in December 1801—just about a year after its first sighting—and this turned out to be accurate within a half-degree when it was rediscovered by Franz Xaver von Zach on 31 December at Gotha, and one day later by Heinrich Olbers in Bremen. This confirmation eventually led to the the classification of Ceres as minor-planet designation 1 Ceres: the first asteroid (now dwarf planet) ever discovered.

Gauss's method involved determining a conic section in space, given one focus (the Sun) and the conic's intersection with three given lines (lines of sight from the Earth, which is itself moving on an ellipse, to the planet) and given the time it takes the planet to traverse the arcs determined by these lines (from which the lengths of the arcs can be calculated by Kepler's Second Law). This problem leads to an equation of the eighth degree, of which one solution, the Earth's orbit, is known. The solution sought is then separated from the remaining six based on physical conditions. In this work, Gauss used comprehensive approximation methods which he created for that purpose.

One such method was the fast Fourier transform. While this method is attributed to a 1965 paper by James Cooley and John Tukey, Gauss developed it as a trigonometric interpolation method. His paper, "Theoria Interpolationis Methodo Nova Tractata", was only published posthumously in Volume 3 of his collected works. This paper predates the first presentation by Joseph Fourier on the subject in 1807.

Zach noted that "without the intelligent work and calculations of Doctor Gauss we might not have found Ceres again". Though Gauss had up to that point been financially supported by his stipend from the Duke, he doubted the security of this arrangement, and also did not believe pure mathematics to be important enough to deserve support. Thus he sought a position in astronomy, and in 1807 was appointed Professor of Astronomy and Director of the astronomical observatory in Göttingen, a post he held for the remainder of his life.
The discovery of Ceres led Gauss to his work on a theory of the motion of planetoids disturbed by large planets, eventually published in 1809 as "Theoria motus corporum coelestium in sectionibus conicis solem ambientum" (Theory of motion of the celestial bodies moving in conic sections around the Sun). In the process, he so streamlined the cumbersome mathematics of 18th-century orbital prediction that his work remains a cornerstone of astronomical computation. It introduced the Gaussian gravitational constant, and contained an influential treatment of the method of least squares, a procedure used in all sciences to this day to minimize the impact of measurement error.

Gauss proved the method under the assumption of normally distributed errors (see Gauss–Markov theorem; see also Gaussian). The method had been described earlier by Adrien-Marie Legendre in 1805, but Gauss claimed that he had been using it since 1794 or 1795. In the history of statistics, this disagreement is called the "priority dispute over the discovery of the method of least squares."

In 1818 Gauss, putting his calculation skills to practical use, carried out a geodetic survey of the Kingdom of Hanover, linking up with previous Danish surveys. To aid the survey, Gauss invented the heliotrope, an instrument that uses a mirror to reflect sunlight over great distances, to measure positions.

Gauss also claimed to have discovered the possibility of non-Euclidean geometries but never published it. This discovery was a major paradigm shift in mathematics, as it freed mathematicians from the mistaken belief that Euclid's axioms were the only way to make geometry consistent and non-contradictory.

Research on these geometries led to, among other things, Einstein's theory of general relativity, which describes the universe as non-Euclidean. His friend Farkas Wolfgang Bolyai with whom Gauss had sworn "brotherhood and the banner of truth" as a student, had tried in vain for many years to prove the parallel postulate from Euclid's other axioms of geometry.

Bolyai's son, János Bolyai, discovered non-Euclidean geometry in 1829; his work was published in 1832. After seeing it, Gauss wrote to Farkas Bolyai: "To praise it would amount to praising myself. For the entire content of the work ... coincides almost exactly with my own meditations which have occupied my mind for the past thirty or thirty-five years." This unproved statement put a strain on his relationship with Bolyai who thought that Gauss was "stealing" his idea.

Letters from Gauss years before 1829 reveal him obscurely discussing the problem of parallel lines. Waldo Dunnington, a biographer of Gauss, argues in "Gauss, Titan of Science" (1955) that Gauss was in fact in full possession of non-Euclidean geometry long before it was published by Bolyai, but that he refused to publish any of it because of his fear of controversy.

The geodetic survey of Hanover, which required Gauss to spend summers traveling on horseback for a decade, fueled Gauss's interest in differential geometry and topology, fields of mathematics dealing with curves and surfaces. Among other things, he came up with the notion of Gaussian curvature.
This led in 1828 to an important theorem, the Theorema Egregium ("remarkable theorem"), establishing an important property of the notion of curvature. Informally, the theorem says that the curvature of a surface can be determined entirely by measuring angles and distances on the surface.

That is, curvature does not depend on how the surface might be embedded in 3-dimensional space or 2-dimensional space.

In 1821, he was made a foreign member of the Royal Swedish Academy of Sciences. Gauss was elected a Foreign Honorary Member of the American Academy of Arts and Sciences in 1822.

In 1831, Gauss developed a fruitful collaboration with the physics professor Wilhelm Weber, leading to new knowledge in magnetism (including finding a representation for the unit of magnetism in terms of mass, charge, and time) and the discovery of Kirchhoff's circuit laws in electricity. It was during this time that he formulated his namesake law. They constructed the first electromechanical telegraph in 1833, which connected the observatory with the institute for physics in Göttingen. Gauss ordered a magnetic observatory to be built in the garden of the observatory, and with Weber founded the "Magnetischer Verein" ("magnetic association"), which supported measurements of Earth's magnetic field in many regions of the world. He developed a method of measuring the horizontal intensity of the magnetic field which was in use well into the second half of the 20th century, and worked out the mathematical theory for separating the inner and outer (magnetospheric) sources of Earth's magnetic field.

The British mathematician Henry John Stephen Smith (1826–1883) gave the following appraisal of Gauss:
There are several stories of his early genius. According to one, his gifts became very apparent at the age of three when he corrected, mentally and without fault in his calculations, an error his father had made on paper while calculating finances.

Another story has it that in primary school after the young Gauss misbehaved, his teacher, J.G. Büttner, gave him a task: add a list of integers in arithmetic progression; as the story is most often told, these were the numbers from 1 to 100. The young Gauss reputedly produced the correct answer within seconds, to the astonishment of his teacher and his assistant Martin Bartels.

Gauss's presumed method was to realize that pairwise addition of terms from opposite ends of the list yielded identical intermediate sums: 1 + 100 = 101, 2 + 99 = 101, 3 + 98 = 101, and so on, for a total sum of 50 × 101 = 5050.
However, the details of the story are at best uncertain (see for discussion of the original Wolfgang Sartorius von Waltershausen source and the changes in other versions); some authors, such as Joseph Rotman in his book "A first course in Abstract Algebra", question whether it ever happened.

He referred to mathematics as "the queen of sciences" and supposedly once espoused a belief in the necessity of immediately understanding Euler's identity as a benchmark pursuant to becoming a first-class mathematician.

From 1989 through 2001, Gauss's portrait, a normal distribution curve and some prominent Göttingen buildings were featured on the German ten-mark banknote. The reverse featured the approach for Hanover. Germany has also issued three postage stamps honoring Gauss. One (no. 725) appeared in 1955 on the hundredth anniversary of his death; two others, nos. 1246 and 1811, in 1977, the 200th anniversary of his birth.

Daniel Kehlmann's 2005 novel "Die Vermessung der Welt", translated into English as "Measuring the World" (2006), explores Gauss's life and work through a lens of historical fiction, contrasting them with those of the German explorer Alexander von Humboldt. A film version directed by Detlev Buck was released in 2012.

In 2007 a bust of Gauss was placed in the Walhalla temple.

The numerous things named in honor of Gauss include:

In 1929 the Polish mathematician Marian Rejewski, who helped to solve the German Enigma cipher machine in December 1932, began studying actuarial statistics at Göttingen. At the request of his Poznań University professor, Zdzisław Krygowski, on arriving at Göttingen Rejewski laid flowers on Gauss's grave.

On 30 April 2018, Google honoured Gauss in his would-be 241st birthday with a Google Doodle showcased in Europe, Russia, Israel, Japan, Taiwan, parts of Southern and Central America and the United States.

Carl Friedrich Gauss, who also introduced the so-called Gaussian logarithms, sometimes gets confused with (1829–1915), a German geologist, who also published some well-known logarithm tables used up into the early 1980s.





</doc>
<doc id="6130" url="https://en.wikipedia.org/wiki?curid=6130" title="Cornish language">
Cornish language

Cornish (Standard Written Form: ' or '; ) is a Southwestern Brittonic language of the Celtic language family. It is a revived language that became extinct as a first language in Cornwall in the late 18th century. A revival began in the early 20th century. Some have expressed the opinion that the language is an important part of Cornish identity, culture and heritage. Cornish is currently recognised under the European Charter for Regional or Minority Languages. It has a growing number of second language speakers. A few parents are inspired to create new first language speakers, by teaching their children the language from birth.

Along with Welsh and Breton, Cornish is descended directly from the Common Brittonic language spoken throughout much of Great Britain before the English language came to dominate. It was the main language of Cornwall for centuries until it was pushed westwards by English, maintaining close links with its sister language Breton, with which it was mutually intelligible until well into the Middle Ages. Cornish continued to function as a common community language in parts of Cornwall until the mid 18th century. There is some evidence of knowledge of the language persisting into the 19th century, possibly almost overlapping the beginning of revival efforts.

A process to revive the language was begun in the early 20th century, with a number of orthographical systems still in use, although an attempt was made to impose a Standard Written Form in 2008. In 2010, UNESCO announced that its former classification of the language as "extinct" was "no longer accurate". Since the revival of the language, some Cornish textbooks and works of literature have been published, and an increasing number of people are studying the language. Recent developments include Cornish music, independent films and children's books. A small number of people in Cornwall have been brought up to be bilingual native speakers, and the language is taught in schools. The first Cornish language day care opened in 2010.

Cornish is one of the Brittonic languages, which constitute a branch of the Insular Celtic section of the Celtic language family. Brittonic also includes Welsh, Breton and the Cumbric language; the latter of which is extinct. Scottish Gaelic, Irish and Manx are part of the separate Goidelic branch of Insular Celtic.

Joseph Loth viewed Cornish and Breton as being two dialects of the same language, claiming that "Middle Cornish is without doubt closer to Breton as a whole than the modern Breton dialect of Quiberon ["Kiberen"] is to that of Saint-Pol-de-Léon ["Kastell-Paol"]."

Cornish evolved from the Common Brittonic spoken throughout Britain south of the Firth of Forth during the British Iron Age and Roman period. As a result of westward Anglo-Saxon expansion, the Britons of the southwest were separated from those in modern-day Wales and Cumbria. Some scholars have proposed that this split took place after the Battle of Deorham in about 577. The western dialects eventually evolved into modern Welsh and the now extinct Cumbric, while Southwestern Brittonic developed into Cornish and Breton, the latter as a result of emigration to parts of the continent, known as Brittany over the following centuries.

The area controlled by the southwestern Britons was progressively reduced by the expansion of Wessex over the next few centuries. During the Old Cornish period (800–1200), the Cornish-speaking area was largely coterminous with modern-day Cornwall, after the Saxons had taken over Devon in their south-westward advance, which probably was facilitated by a second migration wave to Brittany that resulted in the partial depopulation of Devon. The earliest written record of the Cornish language comes from this period; a 9th-century gloss in a Latin manuscript of ' by Boethius, which used the words '. The phrase means "it [the mind] hated the gloomy places". A much more substantial survival from Old Cornish is a Cornish-Latin glossary (the Vocabularium Cornicum or Cottonian Vocabulary) containing translations of around 940 entries, of which 503 are definitely Cornish, 305 could be either Cornish or Welsh, 38 are Welsh or show certain features of Welsh, and 94 are 'not Brittonic', or of unknown origin, according to a study by Oliver Padel. The manuscript was widely thought to be in Old Welsh until the 18th century when it was identified as Cornish. At this time there was still little difference between Welsh and Cornish, and even fewer differences between Cornish and Breton, with some scholars arguing that the terms "Old Cornish" and "Old Breton" are merely geographical terms for the same language.

The Cornish language continued to flourish well through the Middle Cornish period (1200–1600), reaching a peak of about 39,000 speakers in the 13th century, after which the number started to decline. This period provided the bulk of traditional Cornish literature, which was used to reconstruct the language during its revival. Most important is the "Ordinalia", a cycle of three mystery plays, "Origo Mundi", "Passio Christi" and "Resurrexio Domini". Together these provide about 20,000 lines of text. Various plays were written by the canons of Glasney College, intended to educate the Cornish people about the Bible and the Celtic saints. From this period also are the plays ' and the recently discovered '.

In the reign of Henry VIII, an account was given by Andrew Boorde in his 1542 "Boke of the Introduction of Knowledge". He states, ""

When Parliament passed the Act of Uniformity 1549, people in many areas of Cornwall did not speak or understand English. The intention of the Act was to replace worship in Latin with worship in English, which was known by the lawmakers not to be universally spoken throughout England. Instead of merely banning Latin, the Act was framed so as to enforce English. The Prayer Book Rebellion, which may also have been influenced by the retaliation of the English after the failed Cornish Rebellion of 1497, broke out, and was ruthlessly suppressed: over 4,000 people who protested against the imposition of an English prayer book were massacred by Edward VI's army. Their leaders were executed and the people suffered numerous reprisals.

The rebels' document claimed they wanted a return to the old religious services and ended, "We the Cornishmen (whereof certain of us understand no English) utterly refuse this new English [altered spelling]." Edward Seymour, Duke of Somerset, replied to the Cornishmen, inquiring as to why they should be offended by services in English when they had them in Latin, which they also did not understand.
Through many factors, including loss of life and the spread of English, the Prayer Book Rebellion proved a turning-point for the Cornish language. Peter Berresford Ellis cites the years 1550–1650 as a century of immense damage for the language, and its decline can be traced to this period. In 1680, William Scawen wrote an essay describing 16 reasons for the decline of Cornish, among them the lack of a distinctive Cornish alphabet, the loss of contact between Cornwall and Brittany, the cessation of the miracle plays, loss of records in the Civil War, lack of a Cornish Bible, and immigration to Cornwall.

By the middle of the 17th century, the language had retreated to Penwith and Kerrier, and transmission of the language to new generations had almost entirely ceased. In his "Survey of Cornwall", published in 1602, Richard Carew writes:[M]ost of the inhabitants can speak no word of Cornish, but very few are ignorant of the English; and yet some so affect their own, as to a stranger they will not speak it; for if meeting them by chance, you inquire the way, or any such matter, your answer shall be, "," "I [will] speak no Saxonage."
The Late Cornish period from 1578 to about 1800 has fewer sources of information on the language but they are more varied in nature. Written sources from this period are often spelled following English spelling conventions since the majority of writers of the time had had no exposure to Middle Cornish texts or the Cornish orthography within them, although after 1700 some writers began to adopt the orthography used by Edward Lhuyd in his Archaeologia Britannica, for example using the circumflex to denote long vowels. In 1776, William Bodinar, who had learnt Cornish from fishermen, wrote a letter in Cornish which was probably the last prose in the language. However, the last verse was the "Cranken Rhyme", written in the late 19th century by John Davey of Boswednack.

The traditional view that Dolly Pentreath (1692-1777) was the last native speaker of Cornish has been challenged, and in the 18th and 19th centuries, there was academic interest in the language and in attempting to find the last speaker of Cornish. The search for the last speaker is hampered by a lack of transcriptions or audio recordings, so that it is impossible to tell, from this distance, whether the language these people were reported to be speaking was Cornish, or English with a heavy Cornish substratum, nor what their level of fluency was. Nevertheless this academic interest, along with the beginning of the Celtic Revival in the late 19th century, provided the groundwork for a Cornish language revival movement.

Notwithstanding the uncertainty over who was the last speaker of Cornish, there is no certainty that any native speaker of the language lived beyond the 18th century, and researchers have posited the following numbers for the prevalence of the language between 1050 and 1800.

In 1904, the Celtic language scholar and Cornish cultural activist Henry Jenner published "A Handbook of the Cornish Language". The publication of this book is often considered to be the point at which the revival movement started.

The revival focused on reconstructing and standardising the language, including coining new words for modern concepts, and creating educational material in order to teach Cornish to others. In 1929 Robert Morton Nance published his Unified Cornish system, based on the Middle Cornish literature while extending the attested vocabulary with forms based on Celtic roots also found in Breton and Welsh, publishing a dictionary in 1938. Nance's work became the basis of revived Cornish for most of the 20th century. However, as the revival grew in strength and focus shifted from written to spoken Cornish, Nance's stiff, archaic formulation of the language seemed less suitable for a spoken revival, and academic research into the traditional literature proved that the Unified system lacked some phonological distinctions.

In the 1980s, in response to dissatisfaction with Unified Cornish, Ken George published a new system, ("Common Cornish"). Like Unified Cornish, it retained a Middle Cornish base but implemented an orthography that aspired to be as phonemic as possible. It was subsequently adopted by the Cornish Language Board as well as by many Cornish speakers, but came under fierce criticism for a variety of reasons by Jon Mills and Nicholas Williams, as well as those who found its orthography too different from traditional Cornish spelling conventions. Also during this period, Richard Gendall created his Modern Cornish system (also known as "Revived Late Cornish"), which used Late Cornish as a basis, and Nicholas Williams published a revised version of Unified; however neither of these systems gained the popularity of Unified or Kemmyn.

The revival entered a period of factionalism and public disputes, with each orthography attempting to push the others aside. By the time that Cornish was recognised by the UK government under the European Charter for Regional or Minority Languages in 2002, it had become recognised that the existence of multiple orthographies was unsustainable with regards to using the language in education and public life, as none had achieved a wide consensus. A process of unification was set about which resulted in the creation of the public-body Cornish Language Partnership in 2005 and agreement on a Standard Written Form in 2008. In 2010 a new milestone was reached when UNESCO altered its classification of Cornish, stating that its previous label of "extinct" was no longer accurate.

Speakers of Cornish reside primarily in Cornwall, which has a population of 563,600 (2017 estimate). There are also some speakers living outside Cornwall, particularly in the countries of the Cornish diaspora, as well as other Celtic nations. Estimates of the number of Cornish speakers vary according to the definition of being a speaker, and is difficult to accurately determine due to the individualised nature of language take-up. Nevertheless, there is recognition that the number of Cornish speakers is growing. From before the 1980s to the end of the 20th century there was a sixfold increased in the number of speakers to around 300. One figure for the mean number of people who know a few basic words, such as knowing that "Kernow" means "Cornwall", was 300,000; the same survey gave the figure of people able to have simple conversations at 3,000.

The Cornish Language Strategy project commissioned research to provide quantitative and qualitative evidence for the number of Cornish speakers: due to the success of the revival project it was estimated that 2,000 people were fluent (surveyed in spring 2008), an increase from the estimated 300 people who spoke Cornish fluently suggested in a study by Kenneth MacKinnon in 2000.<ref name="BBC BBC/British Council"></ref>

Jenefer Lowe of the Cornish Language Partnership said in an interview with the BBC in 2010 that there were around 300 fluent speakers. Councillor and Bard Bert Biscoe in a statement to Western Morning News in 2014 said there were "several hundred fluent speakers. Cornwall Council estimated in 2015 that there were 300–400 fluent speakers who used the language regularly, with 5,000 people having a basic conversational ability in the language.

A report on the 2011 Census published in 2013 by the Office for National Statistics placed the number of speakers at somewhere from 325 to 625 speakers. In 2017 the ONS released a freedom of information request based on the 2011 Census which placed the number of speakers at 557 people in England and Wales declared Cornish to be their main language, 464 of whom lived in Cornwall.

A study which appeared in 2018 established the number of people in Cornwall with at least minimal skills in Cornish, such as the use of some words and phrases, to be more than 3,000, including around 500 estimated to be fluent.

The Institute of Cornish Studies at the University of Exeter is working with the Cornish Language Partnership to study the Cornish language revival of the 20th Century, including the growth in number of speakers.

Cornish has had no official status but in 2002, it was named as a regional or minority language under the European Charter for Regional or Minority Languages. As an EU member state, the UK government recognised that charter. The Cornish Language Partnership promotes and develops the language in Cornwall.

Cornwall Council's policy is to support the language, in line with the European Charter. A motion was passed in November 2009 in which the council promoted the inclusion of Cornish, as appropriate and where possible, in council publications and on signs. This plan has drawn some criticism.

In October 2015, Cornwall Council announced that staff would be encouraged to use "basic words and phrases" in Cornish when dealing with the public.
In 2014 the Cornish people were recognised by the UK Government as a national minority under the Framework Convention for the Protection of National Minorities. The FCNM provides certain rights and protections to a national minority with regard to their minority language.

UNESCO's "Atlas of World Languages" classifies Cornish as "critically endangered." UNESCO has said that a previous classification of "extinct", which came under fierce criticism from Cornish speakers, "does not reflect the current situation for Cornish".

In 2016, British government funding for the Cornish language ceased, and responsibility transferred to Cornwall Council.

The phonology of modern Cornish is based on a number of sources. The work of the linguist Edward Lhuyd, who visited Cornwall in 1700 to record the language, has provided a major source of input. Analysis of the traditional literature has also been used, as the Middle Cornish plays were often written in rhyming verse, and Late Cornish texts were written phonetically following English spelling conventions.

The grammar of Cornish shares with other Celtic languages a number of features which, while not unique, are unusual in an Indo-European context. The grammatical features most unfamiliar to English speakers of the language are the initial consonant mutations, the verb–subject–object word order, inflected prepositions, fronting of emphasised syntactic elements, and the use of two different forms for "to be". Cornish nouns belong to one of two grammatical genders, masculine and feminine, but are not inflected for case. Cornish has a variety of different endings to indicate the plural, and some nouns have a third collective form. Verbs are conjugated for tense and mood, which can be indicated either by inflection of the main verb, or by the use of auxiliary verbs. In Cornish vocabulary, a large number of the lexical items are language and culture specific. Examples of these include the Cornish word ', which means "mine waste" and the word ', which means "to mend fishing nets". ' and ' are different types of pastry cakes. ' is culture specific when referring to "a traditional Cornish dance get-together", while ' is a specific kind of ceremonial dance that takes place in Cornwall.

In contrast, Cornish translates the English noun, "book", as ' (= Welsh '), but "" can actually be translated into English as "book" or "volume" because it can be considered one in a set of books.

As in other Celtic languages, Cornish lacks a number of verbs that are commonly found in other languages. This includes modals and psych-verbs; examples "have", "like", "hate", "prefer", "must"/"have to", "make"/"compel to". These functions are instead fulfilled by periphrastic constructions involving a verb and various prepositional phrases.


The Celtic Congress and Celtic League are groups that advocate cooperation amongst the Celtic Nations in order to protect and promote Celtic languages and cultures, thus working in the interests of the Cornish language.

There have been films such as "", some televised, made entirely, or significantly, in the language. Some businesses use Cornish names.

According to sociolinguist Kenneth MacKinnon, Jenner wrote "There has never been a time when there has been no person in Cornwall without a knowledge of the Cornish language."

Cornish has significantly and durably affected Cornwall's place-names, as well as in Cornish surnames, and knowledge of the language helps the understanding of these ancient meanings. Cornish names are adopted for children, pets, houses and boats.

There is Cornish literature, including spoken poetry and song, as well as traditional Cornish chants historically performed in marketplaces during religious holidays and public festivals and gatherings.

There are periodicals solely in the language such as the monthly ', ', and "". BBC Radio Cornwall has a news broadcast in Cornish, and sometimes has other programmes and features for learners and enthusiasts. Local newspapers such as the "Western Morning News" have articles in Cornish, and newspapers such as "The Packet", "The West Briton" and "The Cornishman" have also been known to have Cornish features. There is an online radio service in Cornish called , publishing a one-hour podcast each week, based on a magazine format. It includes music in Cornish as well as interviews and features.

The language has financial sponsorship from sources, including the Millennium Commission. A number of language organisations exist in Cornwall: (Our Language), the Cornish sub-group of the European Bureau for Lesser-Used Languages, , (the Cornish Language Board) and (the Cornish Language Fellowship). There are ceremonies, some ancient, some modern, which use the language or are entirely in the language.

Though estimations of the number of Cornish speakers vary, the speakers of Cornish today are thought to be around five hundred. Currently, Cornish is spoken by its speakers at home, outside the home, in the workplace, and at ritual ceremonies. Cornish is also being used in the arts. Revived Cornish is constructed on historical Cornish, so that the Cornish language develops. English language has had some effect in this development. Regardless of having "no concrete purpose during the twentieth century," the number of Cornish speakers has gradually increased.

The Celtic Congress and Celtic League are groups that advocate cooperation amongst the Celtic Nations in order to protect and promote Celtic languages and cultures, thus working in the interests of the Cornish language. Cornish has significantly and durably affected Cornwall's place-names, as well as in Cornish surnames, and knowledge of the language helps the understanding of these ancient meanings. Cornish names are adopted for children, pets, houses and boats. There are periodicals solely in the language such as the monthly "An Gannas", "An Gowsva", and "An Garrick". BBC Radio Cornwall has a news broadcast in Cornish, and sometimes has other programmes and features for learners and enthusiasts. Local newspapers such as the "Western Morning News" have articles in Cornish, and newspapers such as "The Packet", "The West Briton" and "The Cornishman" have also been known to have Cornish features. The language has financial sponsorship from sources, including the Millennium Commission. A number of language organisations exist in Cornwall: Agan Tavas (Our Language), the Cornish sub-group of the European Bureau for Lesser-Used Languages, Gorsedh Kernow, Kesva an Taves Kernewek (the Cornish Language Board) and Kowethas an Yeth Kernewek (the Cornish Language Fellowship).

Cornwall has had cultural events associated with the language, including the international Celtic Media Festival, hosted in St Ives in 1997. The Old Cornwall Society has promoted the use of the language at events and meetings. Two examples of ceremonies that are performed in both the English and Cornish languages are Crying the Neck and the annual mid-summer bonfires.

Cornish is taught in some schools; it was previously taught at degree level at the University of Wales, though the only existing course in the language at University level is as part of a course in Cornish Studies at the University of Exeter. In March 2008, a course in the language was started as part of the Celtic Studies curriculum at the University of Vienna, Austria.
The University of Cambridge offers courses in Cornish through its John Trim Resources Centre, which is part of its Language Centre. In addition, the Department of Anglo-Saxon, Norse and Celtic (which is part of the faculty of English), also carries out research into the Cornish language.

In 2015 a university level course aiming to encourage and support practitioners working with young children to introduce the Cornish language into their settings was launched. The "Cornish Language Practice Project (Early Years)" is a level 4 course approved by Plymouth University and run at Cornwall College. The course is not a Cornish language course, but students will be assessed on their ability to use the Cornish language constructively in their work with young children. The course will cover such topics as "Understanding Bilingualism", "Creating Resources" and "Integrating Language and Play", but the focus of the language provision will be on Cornish. A non-accredited specialist Cornish language course has been developed to run alongside the level 4 course for those who prefer tutor support to learn the language or develop their skills further for use with young children.

Cornwall's first Cornish language crèche, "", was established in 2010 at Cornwall College, Camborne. The nursery teaches children aged between two and five years alongside their parents to ensure the language is also spoken in the home.

A number of dictionaries are available in the different orthographies (a dictionary in the Standard Written Form has yet to be published), including ' by Ken George, ' by Nicholas Williams and "A Practical Dictionary of Modern Cornish" by Richard Gendall. Course books include the three-part ' series, ', ' and ', as well as the more recent ' and '.

Classes and conversation groups for adults are available at several locations in Cornwall, as well as in London, Cardiff and Bristol.

William Scawen produced a manuscript on the declining Cornish language that continually evolved until he died in 1689, aged 89. He was one of the first to realise the language was dying out and wrote detailed manuscripts which he started working on when he was 78. The only version that was ever published was a short first draft, but the final version, which he worked on until his death, is a few hundred pages long. At the same time a group of scholars, led by John Keigwin (nephew of William Scawen), of Mousehole, tried to preserve and further the Cornish language, and chose to consciously write in Cornish. One of their number, Nicholas Boson, tells how he had formerly been discouraged from using Cornish to servants by his mother. This group left behind a large number of translations of parts of the Bible, proverbs and songs. They were contacted by the Welsh linguist Edward Lhuyd who came to Cornwall to study the language.

Early Modern Cornish was the subject of a study published by Lhuyd in 1707, and differs from the medieval language in having a considerably simpler structure and grammar. Such differences included sound changes and more frequent use of auxiliary verbs. The medieval language also possessed two additional tenses for expressing past events and an extended set of possessive suffixes.

John Whitaker, the Manchester-born rector of Ruan Lanihorne, studied the decline of the Cornish language. In his 1804 work "the Ancient Cathedral of Cornwall" he concluded that: "[T]he English Liturgy, was not desired by the Cornish, but forced upon them by the tyranny of England, at a time when the English language was yet unknown in Cornwall. This act of tyranny was at once gross barbarity to the Cornish people, and a death blow to the Cornish language."

Robert Williams published the first comprehensive Cornish dictionary in 1865, the "Lexicon Cornu-Britannicum". As a result of the discovery of additional ancient Cornish manuscripts, 2000 new words were added to the vocabulary by Whitley Stokes in "A Cornish Glossary". William C. Borlase published "Proverbs and Rhymes in Cornish" in 1866 while "A Glossary of Cornish Names" was produced by John Bannister in the same year. Frederick Jago published his "English–Cornish Dictionary" in 1882.

In 2002, the Cornish language gained new recognition because of the European Charter for Regional and Minority Languages. Conversely, along with government provision was the governmental basis of "New Public Management," measuring quantifiable results as means of determining effectiveness. This put enormous pressure on finding a single orthography that could be used in unison. The revival of Cornish required extensive rebuilding. The Cornish orthographies that were reconstructed may be considered versions of Cornish because they are not traditional sociolinguistic variations. In the middle-to-late twentieth century, the debate over Cornish orthographies angered more people because several language groups received public funding. This caused other groups to sense favouritism as playing a role in the debate.

A governmental policymaking structure called New Public Management (NPM) has helped the Cornish language by managing public life of the Cornish language and people. In 2007, the Cornish Language Partnership MAGA represents separate divisions of government and their purpose is to further enhance the Cornish Language Developmental Plan. MAGA established an "Ad-Hoc Group," which resulted in three orthographies being presented. The relations for the Ad-Hoc Group were to obtain consensus among the three orthographies, and then develop a "single written form." The end result was creating a new form of Cornish, which had to be natural for both new learners and skilled speakers.

In 1981, the Breton library ' edited ' (Passion of our lord), a 15th-century Cornish poem. The first complete translation of the Bible into Cornish, translated from English, was published in 2011. Another Bible translation project translating from original languages is underway. The New Testament and Psalms were posted on-line on YouVersion (Bible.com) and Bibles.org in July 2014 by the Bible Society.

A few small publishers produce books in Cornish which are stocked in some local bookshops, as well as in Cornish branches of Waterstones and WH Smiths, although publications are becoming increasingly available on the Internet. Printed copies of these may also be found from Amazon. The Truro Waterstones hosts the annual "" literary awards, established by to recognise publications relating to Cornwall or in the Cornish language. In recent years, a number of Cornish translations of literature have been published, including "Alice's Adventures in Wonderland" (2009), "Around the World in Eighty Days" (2009), "Treasure Island" (2010), "The Railway Children" (2012), "Hound of the Baskervilles" (2012), "The War of the Worlds" (2012), "The Wind in the Willows" (2013), "Three Men in a Boat" (2013), "Alice in Wonderland and Through the Looking-Glass" (2014), and "A Christmas Carol" (which won the 2012 award for Cornish Language books), as well as original Cornish literature such as ' ("The Lyonesse Stone") by Craig Weatherhill. Literature aimed at children is also available, such as ' ("Where's Spot?"), ' ("The Beast of Bodmin Moor"), three "Topsy and Tim" titles, two "Tintin" titles and ' ("Briallen and the Alien"), which won the 2015 award for Cornish Language books for children. In 2014 "", Nicholas Williams' translation of J.R.R. Tolkien's "The Hobbit" was published.

An Gannas is a monthly magazine published entirely in the Cornish language. Members contribute articles on various subjects. The magazine is produced by Graham Sandercock who has been its editor since 1976.

In 1983 BBC Radio Cornwall started broadcasting around two minutes of Cornish every week. In 1987, however, they gave over 15 minutes of airtime on Sunday mornings for a programme called ' ("Holdall"), presented by John King, running until the early 1990s. It was eventually replaced with a five-minute news bulletin called ' ("The News"). The bulletin was presented every Sunday evening for many years by Rod Lyon, then Elizabeth Stewart, and currently a team presents in rotation. Pirate FM ran short bulletins on Saturday lunchtimes from 1998 to 1999. In 2006, Matthew Clarke who had presented the Pirate FM bulletin, launched a web-streamed news bulletin called ' ("Weekly News"), which in 2008 was merged into a new weekly magazine podcast ' (RanG).

Cornish television shows have included a 1982 series by Westward Television each episode containing a three-minute lesson in Cornish. ', an eight episode series produced by Television South West and broadcast between June and July 1984, later on S4C from May to July 1985, and as a schools programme in 1986. Also by Television South West were two bilingual programmes on Cornish Culture called '
In 2016 Kelly's Ice Cream of Bodmin introduced a light hearted television commercial in the Cornish language and this has been repeated in 2017.

The first episode from the third season of the US television program Deadwood features a conversation between miners in the Cornish language, including a toast of shots using "sláinte", a term also common in the Irish language. One of the miners is then shot by thugs working for businessman George Hearst and justifies the murder by saying, "He come at me with his foreign gibberish."

English composer Peter Warlock wrote a Christmas carol in Cornish (setting words by Henry Jenner). The Cornish electronic musician Aphex Twin has used Cornish names for track titles, most notably on his "DrukQs" album.

Several traditional Cornish folk songs have been collected and can be sung to various tunes. These include "An Awhesyth", "Bro Goth agan Tasow", and "Delkiow Sivy".

In 2018, the singer Gwenno Saunders released an album in Cornish, entitled "Le Kov", saying: "I speak Cornish with my son: if you’re comfortable expressing yourself in a language, you want to share it."

The Cornish language has influenced the toponomy of Cornwall, and has historically been used in surnames for the Cornish people. Long before the agreement of the Standard Written Form of Cornish in the 21st century, Late Cornish orthography in the Early Modern period usually followed Welsh to English transliteration, phonetically rendering C for K, I for Y, U for W, and Z for S. This meant that place-names were adopted into English with spellings such as "Porthcurno" and "Penzance"; they are written "Porth Kernow" and "Pen Sans" in the Standard Written Form of Cornish, agreed upon in 2008. Likewise, words such as Enys ("island") can be found spelled as "Ince" as at Ince Castle. These apparent mistransliterations can however reveal an insight into how names and places were actually pronounced, explaining, for example, how anglicised Launceston is still pronounced "Lann-zan" from Cornish "Lann Stefan" (though with emphasis on the first element, the result of accent shift in English, and a consonant change s > z which again would have occurred in English in this alternative English form of the name).

The following tables present some examples of Cornish place-names and surnames, and their anglicised versions:

From the Universal Declaration of Human Rights:

From ", the Cornish anthem:






</doc>
<doc id="6132" url="https://en.wikipedia.org/wiki?curid=6132" title="Complexity theory">
Complexity theory

Complexity theory (or complexity science) is the study of complexity and of complex systems. It may also refer to:



</doc>
<doc id="6134" url="https://en.wikipedia.org/wiki?curid=6134" title="Charybdis">
Charybdis

Charybdis (; Ancient Greek: Χάρυβδις, , "Kharubdis") is a sea monster in Greek mythology. Subsequent scholarship has suggested that it was based on a whirlpool in the Strait of Messina.

The sea monster Charybdis was believed to live under a small rock on one side of a narrow channel. Opposite her was Scylla, another sea monster, that lived inside a much larger rock. The sides of the strait were within an arrow-shot of each other, and sailors attempting to avoid one of them would come in reach of the other. To be "between Scylla and Charybdis" therefore means to be presented with two opposite dangers, the task being to find a route that avoids both. Three times a day, Charybdis swallowed a huge amount of water, before belching it back out again, creating large whirlpools capable of dragging a ship underwater. In some variations of the story, Charybdis was simply a large whirlpool instead of a sea monster.

The theoretical size of Charybdis remains unknown, yet in order to consume Greek ships the whirlpool can be estimated to about 23 meters (75 ft) across. Through the descriptions of Greek mythical chroniclers and Greek historians such as Thucydides, modern scholars generally agree that Charybdis was said to have been located in the Strait of Messina, off the coast of Sicily and opposite a rock on the mainland identified with Scylla. Were Charybdis to be located in the Strait of Messina, it would in fact have the size to accommodate the whirlpool. A whirlpool does exist there, caused by currents meeting, but it is dangerous only to small craft in extreme conditions.

A later myth makes Charybdis the daughter of Poseidon and Gaia and living as a loyal servant to her father.

Charybdis aided her father Poseidon in his feud with her paternal uncle Zeus and, as such, helped him engulf lands and islands in water. Zeus, angry over the land she stole from him, captured and chained her to the sea-bed. Charybdis was then cursed by the god and transformed into a hideous bladder of a monster, with flippers for arms and legs, and an uncontrollable thirst for the sea. As such, she drank the water from the sea thrice a day to quench it, which created whirlpools. She lingered on a rock with Scylla facing her directly on another rock, making a strait.

 Odysseus faced both Charybdis and Scylla while rowing through a narrow channel. He ordered his men to avoid Charybdis, thus forcing them to pass near Scylla, which resulted in the deaths of six of his men. Later, stranded on a raft, Odysseus was swept back through the strait and passed near Charybdis. His raft was sucked into her maw, but he survived by clinging to a fig tree growing on a rock over her lair. On the next outflow of water, when his raft was expelled, Odysseus recovered it and paddled away safely.

The Argonauts were able to avoid both dangers because Hera ordered the Nereid nymph Thetis, Achilles' mother, to guide them through the perilous passage.

In the "Aeneid" the Trojans are warned by Helenus of Scylla and Charybdis, and are advised to avoid them by sailing around Pachynus point (Cape Passero) rather than risk the Straits . Later however they find themselves passing Etna, and have to row for their lives to escape Charybdis.

Aristotle mentions in his "Meteorologica" that Aesop once teased a ferryman by telling him a myth concerning Charybdis. With one gulp of the sea, she brought the mountains to view; islands appeared after the next. The third is yet to come and will dry the sea altogether, thus depriving the ferryman of his livelihood.



</doc>
<doc id="6136" url="https://en.wikipedia.org/wiki?curid=6136" title="Carbon monoxide">
Carbon monoxide

Carbon monoxide (CO) is a colorless, odorless, and tasteless flammable gas that is slightly less dense than air. It is toxic to animals that use hemoglobin as an oxygen carrier (both invertebrate and vertebrate) when encountered in concentrations above about 35 ppm, although it is also produced in normal animal metabolism in low quantities, and is thought to have some normal biological functions. In the atmosphere, it is spatially variable and short-lived, having a role in the formation of ground-level ozone.
Carbon monoxide consists of one carbon atom and one oxygen atom, connected by a triple bond that consists of a net two pi bonds and one sigma bond. It is the simplest oxocarbon and is isoelectronic with other triply-bonded diatomic species possessing 10 valence electrons, including the cyanide anion, the nitrosonium cation, boron monofluoride and molecular nitrogen. In coordination complexes the carbon monoxide ligand is called carbonyl.

Aristotle (384–322 BC) first recorded that burning coals produced toxic fumes. An ancient method of execution was to shut the criminal in a bathing room with smoldering coals. What was not known was the mechanism of death. Greek physician Galen (129–199 AD) speculated that there was a change in the composition of the air that caused harm when inhaled. In 1776, the French chemist produced CO by heating zinc oxide with coke, but mistakenly concluded that the gaseous product was hydrogen, as it burned with a blue flame. The gas was identified as a compound containing carbon and oxygen by the Scottish chemist William Cruickshank in 1800. Its toxic properties on dogs were thoroughly investigated by Claude Bernard around 1846.

During World War II, a gas mixture including carbon monoxide was used to keep motor vehicles running in parts of the world where gasoline and diesel fuel were scarce. External (with a few exceptions) charcoal or wood gas generators were fitted, and the mixture of atmospheric nitrogen, hydrogen, carbon monoxide, and small amounts of other gases produced by gasification was piped to a gas mixer. The gas mixture produced by this process is known as wood gas. Carbon monoxide was also used on a large scale during the Holocaust at some Nazi German extermination camps, the most notable by gas vans in Chełmno, and in the Action T4 "euthanasia" program.

Carbon monoxide is produced from the partial oxidation of carbon-containing compounds; it forms when there is not enough oxygen to produce carbon dioxide (CO), such as when operating a stove or an internal combustion engine in an enclosed space. In the presence of oxygen, including atmospheric concentrations, carbon monoxide burns with a blue flame, producing carbon dioxide. Coal gas, which was widely used before the 1960s for domestic lighting, cooking, and heating, had carbon monoxide as a significant fuel constituent. Some processes in modern technology, such as iron smelting, still produce carbon monoxide as a byproduct. A large quantity of CO byproduct is formed during the oxidative processes for the production of chemicals. For this reason, the process off-gases have to be purified. On the other hand, considerable research efforts are made in order to optimize the process conditions, develop catalyst with improved selectivity and to understand the reaction pathways leading to the target product and side products.

Worldwide, the largest source of carbon monoxide is natural in origin, due to photochemical reactions in the troposphere that generate about 5*10^12 kilograms per year. Other natural sources of CO include volcanoes, forest fires, other forms of combustion, and carbon monoxide-releasing molecules.

In biology, carbon monoxide is naturally produced by the action of heme oxygenase 1 and 2 on the heme from hemoglobin breakdown. This process produces a certain amount of carboxyhemoglobin in normal persons, even if they do not breathe any carbon monoxide. Following the first report that carbon monoxide is a normal neurotransmitter in 1993, as well as one of three gases that naturally modulate inflammatory responses in the body (the other two being nitric oxide and hydrogen sulfide), carbon monoxide has received a great deal of clinical attention as a biological regulator. In many tissues, all three gases are known to act as anti-inflammatories, vasodilators, and promoters of neovascular growth. Clinical trials of small amounts of carbon monoxide as a drug are ongoing. Too much carbon monoxide causes carbon monoxide poisoning.

Some deep-diving marine mammal species are known to contain concentrations of carbon monoxide in their blood that resembles levels seen in chronic cigarette smokers . It is believed these elevated levels of CO will increase the animals' hemoglobin-oxygen affinity, which can help the animals more efficiently deliver oxygen during the events of severe hypoxemia they routinely encounter during long duration dives. Further, these levels of CO could help the animals with the prevention of injuries associated ischemia/reperfusion events associated with the physiological dive response .

Carbon monoxide has a molar mass of 28.0, which, according to the ideal gas law, makes it slightly less dense than air, whose average molar mass is 28.8.

The bond length between the carbon atom and the oxygen atom is 112.8 pm. This bond length is consistent with a triple bond, as in molecular nitrogen (N), which has a similar bond length (109.76 pm) and nearly the same molecular mass. Carbon–oxygen double bonds are significantly longer, 120.8 pm in formaldehyde, for example. The boiling point (82 K) and melting point (68 K) are very similar to those of N (77 K and 63 K, respectively). The bond-dissociation energy of 1072 kJ/mol is stronger than that of N (942 kJ/mol) and represents the strongest chemical bond known.

The ground electronic state of carbon monoxide is a singlet state since there are no unpaired electrons.

Carbon and oxygen together have a total of 10 electrons in the valence shell. Following the octet rule for both carbon and oxygen, the two atoms form a triple bond, with six shared electrons in three bonding molecular orbitals, rather than the usual double bond found in organic carbonyl compounds. Since four of the shared electrons come from the oxygen atom and only two from carbon, one bonding orbital is occupied by two electrons from oxygen, forming a dative or dipolar bond. This causes a C←O polarization of the molecule, with a small negative charge on carbon and a small positive charge on oxygen. The other two bonding orbitals are each occupied by one electron from carbon and one from oxygen, forming (polar) covalent bonds with a reverse C→O polarization, since oxygen is more electronegative than carbon. In the free carbon monoxide molecule, a net negative charge δ remains at the carbon end and the molecule has a small dipole moment of 0.122 D.

The molecule is therefore asymmetric: oxygen has more electron density than carbon, and is also slightly positively charged compared to carbon being negative. By contrast, the isoelectronic dinitrogen molecule has no dipole moment.

Carbon monoxide has a computed fractional bond order of 2.6, indicating that the "third" bond is important but constitutes somewhat less than a full bond. Thus, in valence bond terms, C≡O is the most important structure, while :C=O is non-octet, but has a neutral formal charge on each atom and represents the second most important resonance contributor. Because of the lone pair and divalence of carbon in this resonance structure, carbon monoxide is often considered to be an extraordinarily stabilized carbene. Isocyanides are compounds in which the O is replaced by an NR (R = alkyl or aryl) group and have a similar bonding scheme.

If carbon monoxide acts as a ligand, the polarity of the dipole may reverse with a net negative charge on the oxygen end, depending on the structure of the coordination complex.
See also the section ""Coordination chemistry"" below.

Theoretical and experimental studies show that, despite the greater electronegativity of oxygen, the dipole moment points from the more-negative carbon end to the more-positive oxygen end. The three bonds are in fact polar covalent bonds that are strongly polarized. The calculated polarization toward the oxygen atom is 71% for the σ-bond and 77% for both π-bonds.

The oxidation state of carbon in carbon monoxide is +2 in each of these structures. It is calculated by counting all the bonding electrons as belonging to the more electronegative oxygen. Only the two non-bonding electrons on carbon are assigned to carbon. In this count, carbon then has only two valence electrons in the molecule compared to four in the free atom.

Carbon monoxide poisoning is the most common type of fatal air poisoning in many countries. Carbon monoxide is colorless, odorless, and tasteless, but highly toxic. It combines with hemoglobin to produce carboxyhemoglobin, by binding to the site in hemoglobin that normally carries oxygen, leaving it ineffective for delivering oxygen to bodily tissues. Concentrations as low as 667 ppm may cause up to 50% of the body's hemoglobin to convert to carboxyhemoglobin. A level of 50% carboxyhemoglobin may result in seizure, coma, and fatality. In the United States, the OSHA limits long-term workplace exposure levels above 50 ppm.

The most common symptoms of carbon monoxide poisoning may resemble other types of poisonings and infections, including symptoms such as headache, nausea, vomiting, dizziness, fatigue, and a feeling of weakness. Affected families often believe they are victims of food poisoning. Infants may be irritable and feed poorly. Neurological signs include confusion, disorientation, visual disturbance, syncope (fainting), and seizures.

Some descriptions of carbon monoxide poisoning include retinal hemorrhages, and an abnormal cherry-red blood hue. In most clinical diagnoses these signs are seldom noticed. One difficulty with the usefulness of this cherry-red effect is that it corrects, or masks, what would otherwise be an unhealthy appearance, since the chief effect of removing deoxygenated hemoglobin is to make an asphyxiated person appear more normal, or a dead person appear more lifelike, similar to the effect of red colorants in embalming fluid. The "false" or unphysiologic red-coloring effect in anoxic CO-poisoned tissue is related to the meat-coloring commercial use of carbon monoxide, discussed below.

Carbon monoxide also binds to other molecules such as myoglobin and mitochondrial cytochrome oxidase. Exposures to carbon monoxide may cause significant damage to the heart and central nervous system, especially to the globus pallidus, often with long-term chronic pathological conditions. Carbon monoxide may have severe adverse effects on the fetus of a pregnant woman.

Carbon monoxide is produced naturally by the human body as a signaling molecule. Thus, carbon monoxide may have a physiological role in the body, such as a neurotransmitter or a blood vessel relaxant. Because of carbon monoxide's role in the body, abnormalities in its metabolism have been linked to a variety of diseases, including neurodegenerations, hypertension, heart failure, and pathological inflammation. Relative to inflammation, carbon monoxide has been shown to inhibit the movement of leukocytes to inflamed tissues, stimulate leukocyte phagocytosis of bacteria, and reduce the production of pro-inflammatory cytokines by leukocytes. In animal model studies, furthermore, carbon monoxide reduced the severity of experimentally induced bacterial sepsis, pancreatitis, hepatic ischemia/reperfusion injury, colitis, osteoarthritis, lung injury, lung transplantation rejection, and neuropathic pain while promoting skin wound healing. These actions are similar to those of Specialized pro-resolving mediators which act to dampen, reverse, and repair the tissue damage due to diverse inflammation responses. Indeed, carbon monoxide can act additively with one of these mediators (Resolvin D1) to limit inflammatory responses. The studies implicate carbon monoxide as a physiological contributor to limiting inflammation and suggest that its delivery by inhalation or carbon monoxide-forming drugs may be therapeutically useful for controlling pathological inflammatory responses. 
CO functions as an endogenous signaling molecule, modulates functions of the cardiovascular system, inhibits blood platelet aggregation and adhesion, suppresses, reverses, and repairs the damage caused by inflammatory responses.
It may play a role as potential therapeutic agent.

Carbon monoxide is a nutrient for methanogenic archaea, which reduce it to methane using hydrogen. This is the theme for the emerging field of bioorganometallic chemistry. Extremophile micro-organisms can, thus, utilize carbon monoxide in such locations as the thermal vents of volcanoes.

Some microbes can convert carbon monoxide to carbon dioxide to yield energy.

In bacteria, carbon monoxide is produced via the reduction of carbon dioxide by the enzyme carbon monoxide dehydrogenase, an Fe-Ni-S-containing protein.

CooA is a carbon monoxide sensor protein. The scope of its biological role is still unknown; it may be part of a signaling pathway in bacteria and archaea. Its occurrence in mammals is not established.

Carbon monoxide occurs in various natural and artificial environments. Typical concentrations in parts per million are as follows:

Carbon monoxide (CO) is present in small amounts (about 80 ppb) in the Earth's atmosphere. About half of the carbon monoxide in Earth's atmosphere is from the burning of fossil fuels and biomass (such as forest and bushfires). Most of the rest comes from chemical reactions with organic compounds emitted by human activities and plants. Small amounts are also emitted from the ocean, and from geological activity because carbon monoxide occurs dissolved in molten volcanic rock at high pressures in the Earth's mantle. Because natural sources of carbon monoxide are so variable from year to year, it is difficult to accurately measure natural emissions of the gas.

Carbon monoxide has an indirect effect on radiative forcing by elevating concentrations of direct greenhouse gases, including methane and tropospheric ozone. CO can react chemically with other atmospheric constituents (primarily the hydroxyl radical, OH) that would otherwise destroy methane. Through natural processes in the atmosphere, it is oxidized to carbon dioxide and ozone. Carbon monoxide is short-lived in the atmosphere (with an average lifetime of about one to two months), and spatially variable in concentration.

In the atmosphere of Venus carbon monoxide occurs as a result of the photodissociation of carbon dioxide by electromagnetic radiation of wavelengths shorter than 169 nm.

Due to its long lifetime in the mid-troposphere, carbon monoxide is also used as tracer for pollutant plumes.

Carbon monoxide is a temporary atmospheric pollutant in some urban areas, chiefly from the exhaust of internal combustion engines (including vehicles, portable and back-up generators, lawn mowers, power washers, etc.), but also from incomplete combustion of various other fuels (including wood, coal, charcoal, oil, paraffin, propane, natural gas, and trash).

Large CO pollution events can be observed from space over cities.

Carbon monoxide is, along with aldehydes, part of the series of cycles of chemical reactions that form photochemical smog. It reacts with hydroxyl radical (OH) to produce a radical intermediate HOCO, which transfers rapidly its radical hydrogen to O to form peroxy radical (HO) and carbon dioxide (CO). Peroxy radical subsequently reacts with nitrogen oxide (NO) to form nitrogen dioxide (NO) and hydroxyl radical. NO gives O(P) via photolysis, thereby forming O following reaction with O.
Since hydroxyl radical is formed during the formation of NO, the balance of the sequence of chemical reactions starting with carbon monoxide and leading to the formation of ozone is:

Although the creation of NO is the critical step leading to low level ozone formation, it also increases this ozone in another, somewhat mutually exclusive way, by reducing the quantity of NO that is available to react with ozone.

In closed environments, the concentration of carbon monoxide can easily rise to lethal levels. On average, 170 people in the United States die every year from carbon monoxide produced by non-automotive consumer products. According to the Florida Department of Health, "every year more than 500 Americans die from accidental exposure to carbon monoxide and thousands more across the U.S. require emergency medical care for non-fatal carbon monoxide poisoning" These products include malfunctioning fuel-burning appliances such as furnaces, ranges, water heaters, and gas and kerosene room heaters; engine-powered equipment such as portable generators; fireplaces; and charcoal that is burned in homes and other enclosed areas. The American Association of Poison Control Centers (AAPCC) reported 15,769 cases of carbon monoxide poisoning resulting in 39 deaths in 2007. In 2005, the CPSC reported 94 generator-related carbon monoxide poisoning deaths. Forty-seven of these deaths were known to have occurred during power outages due to severe weather, including Hurricane Katrina. Still others die from carbon monoxide produced by non-consumer products, such as cars left running in attached garages. The Centers for Disease Control and Prevention estimates that several thousand people go to hospital emergency rooms every year to be treated for carbon monoxide poisoning.

Carbon monoxide is produced in heme catabolism and thus is present in blood. Normal circulating levels in the blood are 0% to 3% saturation, i.e. the ratio of the amount of carboxyhaemoglobin present to the total circulating haemoglobin, and are higher in smokers. Some deep-diving marine mammal species are known to maintain carboxyhemoglobin levels between 5-10% . Carbon monoxide levels cannot be assessed through a physical exam. Laboratory testing requires a blood sample (arterial or venous) and laboratory analysis on a CO-Oximeter. Additionally, a noninvasive carboxyhemoglobin (SpCO) test method from Pulse CO-Oximetry exists and has been validated compared to invasive methods.

A carbon monoxide sensor protein, CooA, has been characterized in bacteria.

Beyond Earth, carbon monoxide is the second-most common molecule in the interstellar medium, after molecular hydrogen. Because of its asymmetry, this polar molecule produces far brighter spectral lines than the hydrogen molecule, making CO much easier to detect. Interstellar CO was first detected with radio telescopes in 1970. It is now the most commonly used tracer of molecular gas in general in the interstellar medium of galaxies, as molecular hydrogen can only be detected using ultraviolet light, which requires space telescopes. Carbon monoxide observations provide much of the information about the molecular clouds in which most stars form.

Beta Pictoris, the second brightest star in the constellation Pictor, shows an excess of infrared emission compared to normal stars of its type, which is caused by large quantities of dust and gas (including carbon monoxide) near the star.

Solid carbon monoxide is a component of comets. Halley's Comet is about 15% carbon monoxide. It has also been identified spectroscopy on the surface of Neptune's moon Triton. At room temperature and at atmospheric pressure carbon monoxide is actually only metastable (see Boudouard reaction) and the same is true at low temperatures where CO and are solid, but nevertheless it can exist for billions of years in comets. There is very little CO in the atmosphere of Pluto, which seems to have been formed from comets. This may be because there is (or was) liquid water inside Pluto. Carbon monoxide can react with water to form carbon dioxide and hydrogen:

This is called the water-gas shift reaction when occurring in the gas phase, but it can also take place (very slowly) in aqueous solution.
If the hydrogen partial pressure is high enough (for instance in an underground sea), formic acid will be formed:

These reactions can take place in a few million years even at temperatures such as found on Pluto.

Miners refer to carbon monoxide as "white damp" or the "silent killer". It can be found in confined areas of poor ventilation in both surface mines and underground mines. The most common sources of carbon monoxide in mining operations are the internal combustion engine and explosives, however in coal mines carbon monoxide can also be found due to the low temperature oxidation of coal.

Many methods have been developed for carbon monoxide's production.

A major industrial source of CO is producer gas, a mixture containing mostly carbon monoxide and nitrogen, formed by combustion of carbon in air at high temperature when there is an excess of carbon. In an oven, air is passed through a bed of coke. The initially produced CO equilibrates with the remaining hot carbon to give CO. The reaction of CO with carbon to give CO is described as the Boudouard reaction. Above 800 °C, CO is the predominant product:

Another source is "water gas", a mixture of hydrogen and carbon monoxide produced via the endothermic reaction of steam and carbon:

Other similar "synthesis gases" can be obtained from natural gas and other fuels.

Carbon monoxide can also be produced by high-temperature electrolysis of carbon dioxide with solid oxide electrolyzer cells: One method, developed at DTU Energy uses a cerium oxide catalyst and does not have any issues of fouling of the catalyst

Carbon monoxide is also a byproduct of the reduction of metal oxide ores with carbon, shown in a simplified form as follows:

Carbon monoxide is also produced by the direct oxidation of carbon in a limited supply of oxygen or air.

Since CO is a gas, the reduction process can be driven by heating, exploiting the positive (favorable) entropy of reaction. The Ellingham diagram shows that CO formation is favored over CO in high temperatures.

Carbon monoxide is conveniently produced in the laboratory by the dehydration of formic acid or oxalic acid, for example with concentrated sulfuric acid. Another method is heating an intimate mixture of powdered zinc metal and calcium carbonate, which releases CO and leaves behind zinc oxide and calcium oxide:

Silver nitrate and iodoform also afford carbon monoxide:

Finally, metal oxalate salts release CO upon heating, leaving a carbonate as byproduct:

Most metals form coordination complexes containing covalently attached carbon monoxide. Only metals in lower oxidation states will complex with carbon monoxide ligands. This is because there must be sufficient electron density to facilitate back-donation from the metal d-orbital, to the π* molecular orbital from CO. The lone pair on the carbon atom in CO, also donates electron density to the d on the metal to form a sigma bond. This electron donation is also exhibited with the cis effect, or the labilization of CO ligands in the cis position. Nickel carbonyl, for example, forms by the direct combination of carbon monoxide and nickel metal:
For this reason, nickel in any tubing or part must not come into prolonged contact with carbon monoxide. Nickel carbonyl decomposes readily back to Ni and CO upon contact with hot surfaces, and this method is used for the industrial purification of nickel in the Mond process.

In nickel carbonyl and other carbonyls, the electron pair on the carbon interacts with the metal; the carbon monoxide donates the electron pair to the metal. In these situations, carbon monoxide is called the carbonyl ligand. One of the most important metal carbonyls is iron pentacarbonyl, Fe(CO):

Many metal-CO complexes are prepared by decarbonylation of organic solvents, not from CO. For instance, iridium trichloride and triphenylphosphine react in boiling 2-methoxyethanol or DMF to afford IrCl(CO)(PPh).

Metal carbonyls in coordination chemistry are usually studied using infrared spectroscopy.

In the presence of strong acids and water, carbon monoxide reacts with alkenes to form carboxylic acids in a process known as the Koch–Haaf reaction. In the Gattermann–Koch reaction, arenes are converted to benzaldehyde derivatives in the presence of AlCl and HCl. Organolithium compounds (e.g. butyl lithium) react with carbon monoxide, but these reactions have little scientific use.

Although CO reacts with carbocations and carbanions, it is relatively nonreactive toward organic compounds without the intervention of metal catalysts.

With main group reagents, CO undergoes several noteworthy reactions. Chlorination of CO is the industrial route to the important compound phosgene. With borane CO forms the adduct HBCO, which is isoelectronic with the acetylium cation [HCCO]. CO reacts with sodium to give products resulting from C-C coupling such as sodium acetylenediolate 2·. It reacts with molten potassium to give a mixture of an organometallic compound, potassium acetylenediolate 2·, potassium benzenehexolate 6 , and potassium rhodizonate 2·.

The compounds cyclohexanehexone or triquinoyl (CO) and cyclopentanepentone or leuconic acid (CO), which so far have been obtained only in trace amounts, can be regarded as polymers of carbon monoxide.

At pressures of over 5 gigapascals, carbon monoxide converts into a solid polymer of carbon and oxygen. This is metastable at atmospheric pressure but is a powerful explosive.

Carbon monoxide is an industrial gas that has many applications in bulk chemicals manufacturing. Large quantities of aldehydes are produced by the hydroformylation reaction of alkenes, carbon monoxide, and H. Hydroformylation is coupled to the Shell higher olefin process to give precursors to detergents.

Phosgene, useful for preparing isocyanates, polycarbonates, and polyurethanes, is produced by passing purified carbon monoxide and chlorine gas through a bed of porous activated carbon, which serves as a catalyst. World production of this compound was estimated to be 2.74 million tonnes in 1989.
Methanol is produced by the hydrogenation of carbon monoxide. In a related reaction, the hydrogenation of carbon monoxide is coupled to C-C bond formation, as in the Fischer-Tropsch process where carbon monoxide is hydrogenated to liquid hydrocarbon fuels. This technology allows coal or biomass to be converted to diesel.

In the Cativa process, carbon monoxide and methanol react in the presence of a homogeneous Iridium catalyst and hydroiodic acid to give acetic acid. This process is responsible for most of the industrial production of acetic acid.

An industrial scale use for pure carbon monoxide is purifying nickel in the Mond process.

Carbon monoxide can also be used in the water-gas shift reaction to produce hydrogen.

Carbon monoxide is used in modified atmosphere packaging systems in the US, mainly with fresh meat products such as beef, pork, and fish to keep them looking fresh. The carbon monoxide combines with myoglobin to form carboxymyoglobin, a bright-cherry-red pigment. Carboxymyoglobin is more stable than the oxygenated form of myoglobin, oxymyoglobin, which can become oxidized to the brown pigment metmyoglobin. This stable red color can persist much longer than in normally packaged meat. Typical levels of carbon monoxide used in the facilities that use this process are between 0.4% to 0.5%.

The technology was first given "generally recognized as safe" (GRAS) status by the U.S. Food and Drug Administration (FDA) in 2002 for use as a secondary packaging system, and does not require labeling. In 2004, the FDA approved CO as primary packaging method, declaring that CO does not mask spoilage odor. Despite this ruling, the process remains controversial for fears that it masks spoilage. In 2007, a bill was introduced to the United States House of Representatives to label modified atmosphere carbon monoxide packaging as a color additive, but the bill died in subcommittee. The process is banned in many other countries, including Japan, Singapore, and the European Union.

In biology, carbon monoxide is naturally produced by the action of heme oxygenase 1 and 2 on the heme from hemoglobin breakdown. This process produces a certain amount of carboxyhemoglobin in normal persons, even if they do not breathe any carbon monoxide.

Following the first report that carbon monoxide is a normal neurotransmitter in 1993, as well as one of three gases that naturally modulate inflammatory responses in the body (the other two being nitric oxide and hydrogen sulfide), carbon monoxide has received a great deal of clinical attention as a biological regulator. In many tissues, all three gases are known to act as anti-inflammatories, vasodilators, and encouragers of neovascular growth. However, the issues are complex, as neovascular growth is not always beneficial, since it plays a role in tumor growth, and also the damage from "wet" macular degeneration, a disease for which smoking (a major source of carbon monoxide in the blood, several times more than natural production) increases the risk from 4 to 6 times.

There is a theory that, in some nerve cell synapses, when long-term memories are being laid down, the receiving cell makes carbon monoxide, which back-transmits to the transmitting cell, telling it to transmit more readily in future. Some such nerve cells have been shown to contain guanylate cyclase, an enzyme that is activated by carbon monoxide.

Studies involving carbon monoxide have been conducted in many laboratories throughout the world for its anti-inflammatory and cytoprotective properties. These properties have potential to be used to prevent the development of a series of pathological conditions including ischemia reperfusion injury, transplant rejection, atherosclerosis, severe sepsis, severe malaria, or autoimmunity. Clinical tests involving humans have been performed, however the results have not yet been released.

Carbon monoxide is a strong reductive agent, and whilst not known, it has been used in pyrometallurgy to reduce metals from ores since ancient times. Carbon monoxide strips oxygen off metal oxides, reducing them to pure metal in high temperatures, forming carbon dioxide in the process. Carbon monoxide is not usually supplied as is, in gaseous phase, in the reactor, but rather it is formed in high temperature in presence of oxygen-carrying ore, carboniferous agent such as coke and high temperature. The blast furnace process is a typical example of a process of reduction of metal from ore with carbon monoxide.

Carbon monoxide has also been used as a lasing medium in high-powered infrared lasers.

Carbon monoxide has been proposed for use as a fuel on Mars. Carbon monoxide/oxygen engines have been suggested for early surface transportation use as both carbon monoxide and oxygen can be straightforwardly produced from the atmosphere of Mars by zirconia electrolysis, without using any Martian water resources to obtain hydrogen, which would be needed to make methane or any hydrogen-based fuel. Likewise, blast furnace gas collected at the top of blast furnace, still contains some 10% to 30% of carbon monoxide, and is used as fuel on Cowper stoves and on Siemens-Martin furnaces on open hearth steelmaking.




</doc>
<doc id="6138" url="https://en.wikipedia.org/wiki?curid=6138" title="Conjecture">
Conjecture

In mathematics, a conjecture is a conclusion or a proposition which is suspected to be true due to preliminary supporting evidence, but for which no proof or disproof has yet been found. Some conjectures, such as the Riemann hypothesis (still a conjecture) or Fermat's Last Theorem (a conjecture until proven in 1995 by Andrew Wiles), have shaped much of mathematical history as new areas of mathematics are developed in order to prove them.

In number theory, Fermat's Last Theorem (sometimes called Fermat's conjecture, especially in older texts) states that no three positive integers formula_1, "formula_2", and "formula_3" can satisfy the equation "formula_4" for any integer value of "formula_5" greater than two.

This theorem was first conjectured by Pierre de Fermat in 1637 in the margin of a copy of "Arithmetica", where he claimed that he had a proof that was too large to fit in the margin. The first successful proof was released in 1994 by Andrew Wiles, and formally published in 1995, after 358 years of effort by mathematicians. The unsolved problem stimulated the development of algebraic number theory in the 19th century, and the proof of the modularity theorem in the 20th century. It is among the most notable theorems in the history of mathematics, and prior to its proof it was in the "Guinness Book of World Records" for "most difficult mathematical problems".

In mathematics, the four color theorem, or the four color map theorem, states that given any separation of a plane into contiguous regions, producing a figure called a "map", no more than four colors are required to color the regions of the map—so that no two adjacent regions have the same color. Two regions are called "adjacent" if they share a common boundary that is not a corner, where corners are the points shared by three or more regions. For example, in the map of the United States of America, Utah and Arizona are adjacent, but Utah and New Mexico, which only share a point that also belongs to Arizona and Colorado, are not.

Möbius mentioned the problem in his lectures as early as 1840. The conjecture was first proposed on October 23, 1852 when Francis Guthrie, while trying to color the map of countries of England, noticed that only four different colors were needed. The five color theorem, which has a short elementary proof, states that five colors suffice to color a map and was proven in the late 19th century; however, proving that four colors suffice turned out to be significantly harder. A number of false proofs and false counterexamples have appeared since the first statement of the four color theorem in 1852.

The four color theorem was ultimately proven in 1976 by Kenneth Appel and Wolfgang Haken. It was the first major theorem to be proved using a computer. Appel and Haken's approach started by showing that there is a particular set of 1,936 maps, each of which cannot be part of a smallest-sized counterexample to the four color theorem (i.e., if they did appear, one could make a smaller counter-example). Appel and Haken used a special-purpose computer program to confirm that each of these maps had this property. Additionally, any map that could potentially be a counterexample must have a portion that looks like one of these 1,936 maps. Showing this with hundreds of pages of hand analysis, Appel and Haken concluded that no smallest counterexample exists because any must contain, yet do not contain, one of these 1,936 maps. This contradiction means there are no counterexamples at all and that the theorem is therefore true. Initially, their proof was not accepted by mathematicians at all because the computer-assisted proof was infeasible for a human to check by hand. However, the proof has since then gained wider acceptance, although doubts still remain.

The Hauptvermutung (German for main conjecture) of geometric topology is the conjecture that any two triangulations of a triangulable space have a common refinement, a single triangulation that is a subdivision of both of them. It was originally formulated in 1908, by Steinitz and Tietze.

This conjecture is now known to be false. The non-manifold version was disproved by John Milnor in 1961 using Reidemeister torsion.

The manifold version is true in dimensions . The cases were proved by Tibor Radó and Edwin E. Moise in the 1920s and 1950s, respectively.

In mathematics, the Weil conjectures were some highly influential proposals by on the generating functions (known as local zeta-functions) derived from counting the number of points on algebraic varieties over finite fields.

A variety "V" over a finite field with "q" elements has a finite number of rational points, as well as points over every finite field with "q" elements containing that field. The generating function has coefficients derived from the numbers "N" of points over the (essentially unique) field with "q" elements.

Weil conjectured that such "zeta-functions" should be rational functions, should satisfy a form of functional equation, and should have their zeroes in restricted places. The last two parts were quite consciously modeled on the Riemann zeta function and Riemann hypothesis. The rationality was proved by , the functional equation by , and the analogue of the Riemann hypothesis was proved by 

In mathematics, the Poincaré conjecture is a theorem about the characterization of the 3-sphere, which is the hypersphere that bounds the unit ball in four-dimensional space. The conjecture states that: An equivalent form of the conjecture involves a coarser form of equivalence than homeomorphism called homotopy equivalence: if a 3-manifold is "homotopy equivalent" to the 3-sphere, then it is necessarily "homeomorphic" to it.

Originally conjectured by Henri Poincaré, the theorem concerns a space that locally looks like ordinary three-dimensional space but is connected, finite in size, and lacks any boundary (a closed 3-manifold). The Poincaré conjecture claims that if such a space has the additional property that each loop in the space can be continuously tightened to a point, then it is necessarily a three-dimensional sphere. An analogous result has been known in higher dimensions for some time.

After nearly a century of effort by mathematicians, Grigori Perelman presented a proof of the conjecture in three papers made available in 2002 and 2003 on arXiv. The proof followed on from the program of Richard S. Hamilton to use the Ricci flow to attempt to solve the problem. Hamilton later introduced a modification of the standard Ricci flow, called "Ricci flow with surgery" to systematically excise singular regions as they develop, in a controlled way, but was unable to prove this method "converged" in three dimensions. Perelman completed this portion of the proof. Several teams of mathematicians have verified that Perelman's proof is correct.

The Poincaré conjecture, before being proven, was one of the most important open questions in topology.

In mathematics, the Riemann hypothesis, proposed by , is a conjecture that the non-trivial zeros of the Riemann zeta function all have real part 1/2. The name is also used for some closely related analogues, such as the Riemann hypothesis for curves over finite fields.

The Riemann hypothesis implies results about the distribution of prime numbers. Along with suitable generalizations, some mathematicians consider it the most important unresolved problem in pure mathematics. The Riemann hypothesis, along with the Goldbach conjecture, is part of Hilbert's eighth problem in David Hilbert's list of 23 unsolved problems; it is also one of the Clay Mathematics Institute Millennium Prize Problems.

The P versus NP problem is a major unsolved problem in computer science. Informally, it asks whether every problem whose solution can be quickly verified by a computer can also be quickly solved by a computer; it is widely conjectured that the answer is no. It was essentially first mentioned in a 1956 letter written by Kurt Gödel to John von Neumann. Gödel asked whether a certain NP-complete problem could be solved in quadratic or linear time. The precise statement of the P=NP problem was introduced in 1971 by Stephen Cook in his seminal paper "The complexity of theorem proving procedures" and is considered by many to be the most important open problem in the field. It is one of the seven Millennium Prize Problems selected by the Clay Mathematics Institute to carry a US$1,000,000 prize for the first correct solution.


Formal mathematics is based on "provable" truth. In mathematics, any number of cases supporting a conjecture, no matter how large, is insufficient for establishing the conjecture's veracity, since a single counterexample could immediately bring down the conjecture. Mathematical journals sometimes publish the minor results of research teams having extended the search for a counterexample farther than previously done. For instance, the Collatz conjecture, which concerns whether or not certain sequences of integers terminate, has been tested for all integers up to 1.2 × 10 (over a trillion). However, the failure to find a counterexample after extensive search does not constitute a proof that no counterexample exists, nor that the conjecture is true—because the conjecture might be false but with a very large minimal counterexample.

Instead, a conjecture is considered proven only when it has been shown that it is logically impossible for it to be false. There are various methods of doing so; see methods of mathematical proof for more details.

One method of proof, applicable when there are only a finite number of cases that could lead to counterexamples, is known as "brute force": in this approach, all possible cases are considered and shown not to give counterexamples. In some occasions, the number of cases is quite large, in which case a brute-force proof may require as a practical matter the use of a computer algorithm to check all the cases. For example, the validity of the 1976 and 1997 brute-force proofs of the four color theorem by computer was initially doubted, but was eventually confirmed in 2005 by theorem-proving software.

When a conjecture has been proven, it is no longer a conjecture but a theorem. Many important theorems were once conjectures, such as the Geometrization theorem (which resolved the Poincaré conjecture), Fermat's Last Theorem, and others.

Conjectures disproven through counterexample are sometimes referred to as "false conjectures" (cf. the Pólya conjecture and Euler's sum of powers conjecture). In the case of the latter, the first counterexample found for the n=4 case involved numbers in the millions, although it has been subsequently found that the minimal counterexample is actually smaller.

Not every conjecture ends up being proven true or false. The continuum hypothesis, which tries to ascertain the relative cardinality of certain infinite sets, was eventually shown to be independent from the generally accepted set of Zermelo–Fraenkel axioms of set theory. It is therefore possible to adopt this statement, or its negation, as a new axiom in a consistent manner (much as Euclid's parallel postulate can be taken either as true or false in an axiomatic system for geometry).

In this case, if a proof uses this statement, researchers will often look for a new proof that "doesn't" require the hypothesis (in the same way that it is desirable that statements in Euclidean geometry be proved using only the axioms of neutral geometry, i.e. without the parallel postulate). The one major exception to this in practice is the axiom of choice, as the majority of researchers usually do not worry whether a result requires it—unless they are studying this axiom in particular.

Sometimes, a conjecture is called a "hypothesis" when it is used frequently and repeatedly as an assumption in proofs of other results. For example, the Riemann hypothesis is a conjecture from number theory that — amongst other things — makes predictions about the distribution of prime numbers. Few number theorists doubt that the Riemann hypothesis is true. In fact, in anticipation of its eventual proof, some have even proceeded to develop further proofs which are contingent on the truth of this conjecture. These are called "conditional proofs": the conjectures assumed appear in the hypotheses of the theorem, for the time being.

These "proofs", however, would fall apart if it turned out that the hypothesis was false, so there is considerable interest in verifying the truth or falsity of conjectures of this type.

Karl Popper pioneered the use of the term "conjecture" in scientific philosophy. Conjecture is related to hypothesis, which in science refers to a testable conjecture.




</doc>
<doc id="6139" url="https://en.wikipedia.org/wiki?curid=6139" title="Christoph Ludwig Agricola">
Christoph Ludwig Agricola

Christoph Ludwig Agricola (November 5, 1667 – August 8, 1719) was a German landscape painter and etcher. He was born and died at Regensburg (Ratisbon).

Christoph Ludwig Agricola was born on 5 November 1667 at Regensburg in Germany. He trained, as many painters of the period did, by studying nature. 

He spent a great part of his life in travel, visiting England, the Netherlands and France, and residing for a considerable period at Naples, where he may have been influenced by Poussin. He also stayed for some years circa 1712 in Venice, where he painted many works for the patron Zaccaria Sagredo. 

He died in Regensburg in 1719. 

Although he primarily worked in gouache and oils, documentary sources reveal that he also produced a small number of etchings. He was a good draughtsman, used warm lighting and exhibited a warm, masterly brushstroke. 

His numerous landscapes, chiefly cabinet pictures, are remarkable for fidelity to nature, and especially for their skilful representation of varied phases of climate, especially nocturnal scenes and weather anomalies such as thunderstorms. In composition his style shows the influence of Nicolas Poussin, while in light and colour he imitates Claude Lorrain. His work often displays the idealistic scenes associated with his former mentor, Poussin. His compositions include ruins of ancient buildings in the foreground, but his favourite figure for the foreground was men dressed in Oriental attire. He also produced a series of etchings of birds. 

His pictures can be found in Dresden, Braunschweig, Vienna, Florence, Naples and many other towns of both Germany and Italy.

He probably tutored the artist, Johann Theile, and had an enormous influence on him. Art historians have also noted that the work of the landscape painter, Christian Johann Bendeler (1699-1728), was also influenced by Agricola. 


</doc>
<doc id="6140" url="https://en.wikipedia.org/wiki?curid=6140" title="Claudius">
Claudius

Claudius ( ; Tiberius Claudius Caesar Augustus Germanicus; 1 August 10 BC – 13 October AD 54) was Roman emperor from AD 41 to 54. Born Tiberius Claudius Drusus to Nero Claudius Drusus and Antonia Minor at Lugdunum in Roman Gaul, where his father was stationed as a military legate, he was the first Roman emperor to be born outside Italy. Nonetheless, Claudius was an Italic of Sabine origins and a member of the Julio-Claudian dynasty. Because he was afflicted with a limp and slight deafness due to sickness at a young age, his family ostracized him and excluded him from public office until his consulship, shared with his nephew Caligula in 37.

Claudius' infirmity probably saved him from the fate of many other nobles during the purges of Tiberius' and Caligula's reigns; potential enemies did not see him as a serious threat. His survival led to his being declared emperor by the Praetorian Guard after Caligula's assassination, at which point he was the last male of his family. Despite his lack of experience, Claudius proved to be an able and efficient administrator. He expanded the imperial bureaucracy to include freedmen, and helped to restore the empire's finances after the excess of Caligula's reign. He was also an ambitious builder, constructing many new roads, aqueducts, and canals across the Empire. During his reign the Empire started its successful conquest of Britain.

Having a personal interest in law, he presided at public trials, and issued up to twenty edicts a day. He was seen as vulnerable throughout his reign, particularly by elements of the nobility. Claudius was constantly forced to shore up his position; this resulted in the deaths of many senators. These events damaged his reputation among the ancient writers, though more recent historians have revised this opinion. Many authors contend that he was murdered by his own wife, Agrippina the Younger. After his death at the age of 63, his grand-nephew and legally adopted step-son Nero succeeded him as emperor. His 13-year reign (slightly longer than Nero's) would not be surpassed by any successors until that of Domitian, who reigned for 15 years.

He was a descendant of the Octavii Rufi (through Gaius Octavius), Julii Caesares (through Julia Minor and Julia (Mark Antony's mother)), and the Claudii Nerones (through Nero Claudius Drusus). He was a step-grandson (through his father Drusus) and great-nephew (through his mother Antonia Minor) of Augustus. Tiberius was his father's brother. Through his brother Germanicus, Claudius was an uncle of Caligula and a great uncle of Nero. Through his mother, Antonia Minor, he was also a grandson of Mark Antony and Octavia Minor.

Claudius was born on 1 August 10 BC at Lugdunum (modern Lyon, France). He had two older siblings, Germanicus and Livilla. His mother, Antonia, may have had two other children who died young.

His maternal grandparents were Mark Antony and Octavia Minor, Augustus' sister, and he was therefore the great-great grandnephew of Gaius Julius Caesar. His paternal grandparents were Livia, Augustus' third wife, and Tiberius Claudius Nero. During his reign, Claudius revived the rumor that his father Drusus was actually the illegitimate son of Augustus, to give the appearance that Augustus was Claudius' paternal grandfather.

In 9 BC, his father Drusus unexpectedly died on campaign in Germania, possibly from illness. Claudius was then left to be raised by his mother, who never remarried. When Claudius' disability became evident, the relationship with his family turned sour. Antonia referred to him as a monster, and used him as a standard for stupidity. She seems to have passed her son off to his grandmother Livia for a number of years.

Livia was a little kinder, but nevertheless often sent him short, angry letters of reproof. He was put under the care of a "former mule-driver" to keep him disciplined, under the logic that his condition was due to laziness and a lack of will-power. However, by the time he reached his teenage years his symptoms apparently waned and his family took some notice of his scholarly interests.

In AD 7, Livy was hired to tutor him in history, with the assistance of Sulpicius Flavus. He spent a lot of his time with the latter and the philosopher Athenodorus. Augustus, according to a letter, was surprised at the clarity of Claudius' oratory. Expectations about his future began to increase.

His work as a budding historian damaged his prospects for advancement in public life. According to Vincent Scramuzza and others, Claudius began work on a history of the Civil Wars that was either too truthful or too critical of Octavian—then reigning as Augustus Caesar. In either case, it was far too early for such an account, and may have only served to remind Augustus that Claudius was Antony's descendant. His mother and grandmother quickly put a stop to it, and this may have convinced them that Claudius was not fit for public office. He could not be trusted to toe the existing party line.

When he returned to the narrative later in life, Claudius skipped over the wars of the Second Triumvirate altogether. But the damage was done, and his family pushed him into the background. When the Arch of Pavia was erected to honor the Imperial clan in 8 AD, Claudius' name (now Tiberius Claudius Nero Germanicus after his elevation to paterfamilias of Claudii Nerones on the adoption of his brother) was inscribed on the edge—past the deceased princes, Gaius and Lucius, and Germanicus' children. There is some speculation that the inscription was added by Claudius himself decades later, and that he originally did not appear at all.

When Augustus died in AD 14, Claudius—then aged 23—appealed to his uncle Tiberius to allow him to begin the "cursus honorum". Tiberius, the new Emperor, responded by granting Claudius consular ornaments. Claudius requested office once more and was snubbed. Since the new Emperor was no more generous than the old, Claudius gave up hope of public office and retired to a scholarly, private life.

Despite the disdain of the Imperial family, it seems that from very early on the general public respected Claudius. At Augustus' death, the "equites", or knights, chose Claudius to head their delegation. When his house burned down, the Senate demanded it be rebuilt at public expense. They also requested that Claudius be allowed to debate in the Senate. Tiberius turned down both motions, but the sentiment remained.

During the period immediately after the death of Tiberius' son, Drusus, Claudius was pushed by some quarters as a potential heir. This again suggests the political nature of his exclusion from public life. However, as this was also the period during which the power and terror of the commander of the Praetorian Guard, Sejanus, was at its peak, Claudius chose to downplay this possibility.

After the death of Tiberius, the new emperor Caligula (the son of Claudius' brother Germanicus) recognized Claudius to be of some use. He appointed Claudius his co-consul in 37 in order to emphasize the memory of Caligula's deceased father Germanicus. Despite this, Caligula relentlessly tormented his uncle: playing practical jokes, charging him enormous sums of money, humiliating him before the Senate, and the like. According to Cassius Dio Claudius became very sickly and thin by the end of Caligula's reign, most likely due to stress. A possible surviving portrait of Claudius from this period may support this.

On 24 January 41, Caligula was assassinated in a broad-based conspiracy involving the Praetorian commander Cassius Chaerea and several senators. There is no evidence that Claudius had a direct hand in the assassination, although it has been argued that he knew about the plot—particularly since he left the scene of the crime shortly before his nephew was murdered. However, after the deaths of Caligula's wife and daughter, it became apparent that Cassius intended to go beyond the terms of the conspiracy and wipe out the Imperial family.
In the chaos following the murder, Claudius witnessed the German guard cut down several uninvolved noblemen, including many of his friends. He fled to the palace to hide. According to tradition, a Praetorian named Gratus found him hiding behind a curtain and suddenly declared him "princeps". A section of the guard may have planned in advance to seek out Claudius, perhaps with his approval. They reassured him that they were not one of the battalions looking for revenge. He was spirited away to the Praetorian camp and put under their protection.

The Senate quickly met and began debating a change of government, but this eventually devolved into an argument over which of them would be the new "princeps". When they heard of the Praetorians' claim, they demanded that Claudius be delivered to them for approval, but he refused, sensing the danger that would come with complying. Some historians, particularly Josephus, claim that Claudius was directed in his actions by the Judaean King Herod Agrippa. However, an earlier version of events by the same ancient author downplays Agrippa's role so it remains uncertain. Eventually the Senate was forced to give in and, in return, Claudius pardoned nearly all the assassins.

Claudius took several steps to legitimize his rule against potential usurpers, most of them emphasizing his place within the Julio-Claudian family. He adopted the name "Caesar" as a cognomen, as the name still carried great weight with the populace. In order to do so, he dropped the cognomen "Nero" which he had adopted as "paterfamilias" of the Claudii Nerones when his brother Germanicus was adopted out. As Pharaoh of Egypt, Claudius adopted the royal titulary "Tiberios Klaudios, Autokrator Heqaheqau Meryasetptah, Kanakht Djediakhshuemakhet" ("Tiberius Claudius, Emperor and ruler of rulers, beloved of Isis and Ptah, the strong bull of the stable moon on the horizon").

While Claudius had never been formally adopted either by Augustus or his successors, he was nevertheless the grandson of Augustus' sister Octavia, and so he felt that he had the right of family. He also adopted the name "Augustus" as the two previous emperors had done at their accessions. He kept the honorific "Germanicus" to display the connection with his heroic brother. He deified his paternal grandmother Livia to highlight her position as wife of the divine Augustus. Claudius frequently used the term "filius Drusi" (son of Drusus) in his titles, in order to remind the people of his legendary father and lay claim to his reputation.

Since Claudius was the first Emperor proclaimed on the initiative of the Praetorian Guard instead of the Senate, his repute suffered at the hands of commentators (such as Seneca). Moreover, he was the first Emperor who resorted to bribery as a means to secure army loyalty and rewarded the soldiers of the Praetorian Guard that had elevated him with 15,000 sesterces. Tiberius and Augustus had both left gifts to the army and guard in their wills, and upon Caligula's death the same would have been expected, even if no will existed. Claudius remained grateful to the guard, however, issuing coins with tributes to the Praetorians in the early part of his reign.

Pliny the Elder noted, according to the 1938 Loeb Classical Library translation by Harris Rackham, "... many people do not allow any gems in a signet-ring, and seal with the gold itself; this was a fashion invented when Claudius Cæsar was emperor."

Claudius restored the status of the peaceful Imperial Roman provinces of Macedonia and Achaea as senatorial provinces.

Under Claudius, the Empire underwent its first major expansion since the reign of Augustus. The provinces of Thrace, Noricum, Lycia, and Judea were annexed (or put under direct rule) under various circumstances during his term. The annexation of Mauretania, begun under Caligula, was completed after the defeat of rebel forces, and the official division of the former client kingdom into two Imperial provinces. The most far-reaching conquest was that of Britannia.
In 43, Claudius sent Aulus Plautius with four legions to Britain ("Britannia") after an appeal from an ousted tribal ally. Britain was an attractive target for Rome because of its material wealth – mines and slaves – as well as being a haven for Gallic rebels. Claudius himself traveled to the island after the completion of initial offensives, bringing with him reinforcements and elephants. The Roman "colonia" of "Colonia Claudia Victricensis" was established as the provincial capital of the newly established province of Britannia at Camulodunum, where a large Temple was dedicated in his honour.

He left after 16 days, but remained in the provinces for some time. The Senate granted him a triumph for his efforts. Only members of the Imperial family were allowed such honours, but Claudius subsequently lifted this restriction for some of his conquering generals. He was granted the honorific "Britannicus" but only accepted it on behalf of his son, never using the title himself. When the British general Caractacus was captured in 50, Claudius granted him clemency. Caractacus lived out his days on land provided by the Roman state, an unusual end for an enemy commander.

Claudius conducted a census in 48 that found 5,984,072 Roman citizens (adult males with Roman citizenship; women, children, slaves, and free adult males without Roman citizenship were not counted), an increase of around a million since the census conducted at Augustus' death. He had helped increase this number through the foundation of Roman colonies that were granted blanket citizenship. These colonies were often made out of existing communities, especially those with elites who could rally the populace to the Roman cause. Several colonies were placed in new provinces or on the border of the Empire to secure Roman holdings as quickly as possible.

Claudius personally judged many of the legal cases tried during his reign. Ancient historians have many complaints about this, stating that his judgments were variable and sometimes did not follow the law. He was also easily swayed. Nevertheless, Claudius paid detailed attention to the operation of the judicial system.

He extended the summer court session, as well as the winter term, by shortening the traditional breaks. Claudius also made a law requiring plaintiffs to remain in the city while their cases were pending, as defendants had previously been required to do. These measures had the effect of clearing out the docket. The minimum age for jurors was also raised to 25 in order to ensure a more experienced jury pool.

Claudius also settled disputes in the provinces. He freed the island of Rhodes from Roman rule for their good faith and exempted Ilium (Troy) from taxes. Early in his reign, the Greeks and Jews of Alexandria sent him two embassies at once after riots broke out between the two communities. This resulted in the famous "Letter to the Alexandrians", which reaffirmed Jewish rights in the city but also forbade them to move in more families en masse. According to Josephus, he then reaffirmed the rights and freedoms of all the Jews in the Empire.

One of Claudius's investigators discovered that many old Roman citizens based in the city of Tridentum (modern Trento) were not in fact citizens. The Emperor issued a declaration, contained in the "Tabula clesiana", that they would be considered to hold citizenship from then on, since to strip them of their status would cause major problems. However, in individual cases, Claudius punished false assumption of citizenship harshly, making it a capital offense. Similarly, any freedmen found to be laying false claim to membership of the Roman equestrian order were sold back into slavery.

Numerous edicts were issued throughout Claudius' reign. These were on a number of topics, everything from medical advice to moral judgments. A famous medical example is one promoting yew juice as a cure for snakebite. Suetonius wrote that he is even said to have thought of an edict allowing public flatulence for good health. One of the more famous edicts concerned the status of sick slaves. Masters had been abandoning ailing slaves at the temple of Aesculapius on Tiber Island to die instead of providing them with medical assistance and care, and then reclaiming them if they lived. Claudius ruled that slaves who were thus abandoned and recovered after such treatment would be free. Furthermore, masters who chose to kill slaves rather than take care of them were liable to be charged with murder.

Claudius embarked on many public works throughout his reign, both in the capital and in the provinces. He built two aqueducts, the Aqua Claudia, begun by Caligula, and the Anio Novus. These entered the city in 52 and met at the Porta Maggiore. He also restored a third, the Aqua Virgo.
He paid special attention to transportation. Throughout Italy and the provinces he built roads and canals. Among these was a large canal leading from the Rhine to the sea, as well as a road from Italy to Germany – both begun by his father, Drusus. Closer to Rome, he built a navigable canal on the Tiber, leading to Portus, his new port just north of Ostia. This port was constructed in a semicircle with two moles and a lighthouse at its mouth. The construction also had the effect of reducing flooding in Rome.

The port at Ostia was part of Claudius' solution to the constant grain shortages that occurred in winter, after the Roman shipping season. The other part of his solution was to insure the ships of grain merchants who were willing to risk travelling to Egypt in the off-season. He also granted their sailors special privileges, including citizenship and exemption from the Lex Papia Poppaea, a law that regulated marriage. In addition, he repealed the taxes that Caligula had instituted on food, and further reduced taxes on communities suffering drought or famine.

The last part of Claudius' plan was to increase the amount of arable land in Italy. This was to be achieved by draining the Fucine lake, which would have the added benefit of making the nearby river navigable year-round. A tunnel was dug through the lake bed, but the plan was a failure. The tunnel was crooked and not large enough to carry the water, which caused it to back up when opened. The resultant flood washed out a large gladiatorial exhibition held to commemorate the opening, causing Claudius to run for his life along with the other spectators. The draining of the lake continued to present a problem well into the Middle Ages. It was finally achieved by the Prince Torlonia in the 19th century, producing over of new arable land. He expanded the Claudian tunnel to three times its original size.

Because of the circumstances of his accession, Claudius took great pains to please the Senate. During regular sessions, the Emperor sat among the Senate body, speaking in turn. When introducing a law, he sat on a bench between the consuls in his position as holder of the power of Tribune (the Emperor could not officially serve as a Tribune of the Plebes as he was a Patrician, but it was a power taken by previous rulers). He refused to accept all his predecessors' titles (including Imperator) at the beginning of his reign, preferring to earn them in due course. He allowed the Senate to issue its own bronze coinage for the first time since Augustus. He also put the Imperial provinces of Macedonia and Achaea back under Senate control.

Claudius set about remodeling the Senate into a more efficient, representative body. He chided the senators about their reluctance to debate bills introduced by himself, as noted in the fragments of a surviving speech:

In 47 he assumed the office of "censor" with Lucius Vitellius, which had been allowed to lapse for some time. He struck the names of many senators and "equites" who no longer met qualifications, but showed respect by allowing them to resign in advance. At the same time, he sought to admit eligible men from the provinces. The Lyon Tablet preserves his speech on the admittance of Gallic senators, in which he addresses the Senate with reverence but also with criticism for their disdain of these men. He even jokes about how the Senate had admitted members from beyond Gallia Narbonensis (Lyons, France), i.e. himself. He also increased the number of Patricians by adding new families to the dwindling number of noble lines. Here he followed the precedent of Lucius Junius Brutus and Julius Caesar.

Nevertheless, many in the Senate remained hostile to Claudius, and many plots were made on his life. This hostility carried over into the historical accounts. As a result, Claudius reduced the Senate's power for the sake of efficiency. The administration of Ostia was turned over to an Imperial Procurator after construction of the port. Administration of many of the empire's financial concerns was turned over to Imperial appointees and freedmen. This led to further resentment and suggestions that these same freedmen were ruling the Emperor.

Several coup attempts were made during Claudius' reign, resulting in the deaths of many senators. Appius Silanus was executed early in Claudius' reign under questionable circumstances. Shortly after, a large rebellion was undertaken by the Senator Vinicianus and Scribonianus, the governor of Dalmatia, and gained quite a few senatorial supporters. It ultimately failed because of the reluctance of Scribonianus' troops, which led to the suicide of the main conspirators.

Many other senators tried different conspiracies and were condemned. Claudius' son-in-law Pompeius Magnus was executed for his part in a conspiracy with his father Crassus Frugi. Another plot involved the consulars Lusiius Saturninus, Cornelius Lupus, and Pompeius Pedo.

In 46, Asinius Gallus, the grandson of Asinius Pollio, and Titus Statilius Taurus Corvinus were exiled for a plot hatched with several of Claudius' own freedmen. Valerius Asiaticus was executed without public trial for unknown reasons. The ancient sources say the charge was adultery, and that Claudius was tricked into issuing the punishment. However, Claudius singles out Asiaticus for special damnation in his speech on the Gauls, which dates over a year later, suggesting that the charge must have been much more serious.

Asiaticus had been a claimant to the throne in the chaos following Caligula's death and a co-consul with the Titus Statilius Taurus Corvinus mentioned above. Most of these conspiracies took place before Claudius' term as Censor, and may have induced him to review the Senatorial rolls. The conspiracy of Gaius Silius in the year after his Censorship, 48, is detailed in book 11 of Tacitus Annal. This section of Tacitus history narrates the alleged conspiracy of Claudius' third wife, Messalina. Suetonius states that a total of 35 senators and 300 knights were executed for offenses during Claudius' reign. Needless to say, the responses to these conspiracies could not have helped Senate–emperor relations.

Claudius was hardly the first emperor to use freedmen to help with the day-to-day running of the Empire. He was, however, forced to increase their role as the powers of the "princeps" became more centralized and the burden larger. This was partly due to the ongoing hostility of the Senate, as mentioned above, but also due to his respect for the senators. Claudius did not want free-born magistrates to have to serve under him, as if they were not peers.

The secretariat was divided into bureaus, with each being placed under the leadership of one freedman. Narcissus was the secretary of correspondence. Pallas became the secretary of the treasury. Callistus became secretary of justice. There was a fourth bureau for miscellaneous issues, which was put under Polybius until his execution for treason. The freedmen could also officially speak for the Emperor, as when Narcissus addressed the troops in Claudius' stead before the conquest of Britain.

Since these were important positions, the senators were aghast at their being placed in the hands of former slaves. If freedmen had total control of money, letters, and law, it seemed it would not be hard for them to manipulate the Emperor. This is exactly the accusation put forth by the ancient sources. However, these same sources admit that the freedmen were loyal to Claudius.

He was similarly appreciative of them and gave them due credit for policies where he had used their advice. However, if they showed treasonous inclinations, the Emperor did punish them with just force, as in the case of Polybius and Pallas' brother, Felix. There is no evidence that the character of Claudius' policies and edicts changed with the rise and fall of the various freedmen, suggesting that he was firmly in control throughout.

Regardless of the extent of their political power, the freedmen did manage to amass wealth through their positions. Pliny the Elder notes that several of them were richer than Crassus, the richest man of the Republican era.

Claudius, as the author of a treatise on Augustus' religious reforms, felt himself in a good position to institute some of his own. He had strong opinions about the proper form for state religion. He refused the request of Alexandrian Greeks to dedicate a temple to his divinity, saying that only gods may choose new gods. He restored lost days to festivals and got rid of many extraneous celebrations added by Caligula. He re-instituted old observances and archaic language.

Claudius was concerned with the spread of eastern mysteries within the city and searched for more Roman replacements. He emphasized the Eleusinian mysteries which had been practiced by so many during the Republic. He expelled foreign astrologers, and at the same time rehabilitated the old Roman soothsayers (known as haruspices) as a replacement. He was especially hard on Druidism, because of its incompatibility with the Roman state religion and its proselytizing activities.

Claudius forbade proselytizing in any religion, even in those regions where he allowed natives to worship freely.

It is also reported that at one time he expelled the Jews from Rome, probably because the Jews within the city caused continuous disturbances at the instigation of Chrestus.

According to Suetonius, Claudius was extraordinarily fond of games. He is said to have risen with the crowd after gladiatorial matches and given unrestrained praise to the fighters. Claudius also presided over many new and original events. Soon after coming into power, Claudius instituted games to be held in honor of his father on the latter's birthday. Annual games were also held in honour of his accession, and took place at the Praetorian camp where Claudius had first been proclaimed Emperor.

Claudius organised a performance of the Secular Games, marking the 800th anniversary of the founding of Rome. Augustus had performed the same games less than a century prior. Augustus' excuse was that the interval for the games was 110 years, not 100, but his date actually did not qualify under either reasoning. Claudius also presented naval battles to mark the attempted draining of the Fucine Lake, as well as many other public games and shows.

At Ostia, in front of a crowd of spectators, Claudius fought a killer whale which was trapped in the harbour. The event was witnessed by Pliny the Elder:

Claudius also restored and adorned many public venues in Rome. At the Circus Maximus, the turning posts and starting stalls were replaced in marble and embellished, and an embankment was probably added to prevent flooding of the track. Claudius also reinforced or extended the seating rules that reserved front seating at the Circus for senators. Claudius rebuilt Pompey's Theatre after it had been destroyed by fire, organising special fights at the re-dedication which he observed from a special platform in the orchestra box.

Suetonius and the other ancient authors accused Claudius of being dominated by women and wives, and of being a womanizer.

Claudius married four times, after two failed betrothals. The first betrothal was to his distant cousin Aemilia Lepida, but was broken for political reasons. The second was to Livia Medullina Camilla, which ended with Medullina's sudden death on their wedding day.

Plautia Urgulanilla was the granddaughter of Livia's confidant Urgulania. During their marriage she gave birth to a son, Claudius Drusus. Drusus died of asphyxiation in his early teens, shortly after becoming engaged to Junilla, the daughter of Sejanus.

Claudius later divorced Urgulanilla for adultery and on suspicion of murdering her sister-in-law Apronia. When Urgulanilla gave birth after the divorce, Claudius repudiated the baby girl, Claudia, as the father was allegedly one of his own freedmen. This action made him later the target of criticism by his enemies.
Soon after (possibly in 28), Claudius married Aelia Paetina, a relative of Sejanus, if not Sejanus's adoptive sister. During their marriage, Claudius and Paetina had a daughter, Claudia Antonia. He later divorced her after the marriage became a political liability, although Leon (1948) suggests it may have been due to emotional and mental abuse by Paetina.

Some years after divorcing Aelia Paetina, in 38 or early 39, Claudius married Valeria Messalina, who was his first cousin once removed and closely allied with Caligula's circle. Shortly thereafter, she gave birth to a daughter, Claudia Octavia. A son, first named Tiberius Claudius Germanicus, and later known as Britannicus, was born just after Claudius' accession.

This marriage ended in tragedy. The ancient historians allege that Messalina was a nymphomaniac who was regularly unfaithful to Claudius—Tacitus states she went so far as to compete with a prostitute to see who could have the most sexual partners in a night—and manipulated his policies in order to amass wealth. In 48, Messalina married her lover Gaius Silius in a public ceremony while Claudius was at Ostia.

Sources disagree as to whether or not she divorced the Emperor first, and whether the intention was to usurp the throne. Under Roman law, the spouse needed to be informed that he or she had been divorced before a new marriage could take place; the sources state that Claudius was in total ignorance until after the marriage. Scramuzza, in his biography, suggests that Silius may have convinced Messalina that Claudius was doomed, and the union was her only hope of retaining rank and protecting her children. The historian Tacitus suggests that Claudius's ongoing term as Censor may have prevented him from noticing the affair before it reached such a critical point. Whatever the case, the result was the execution of Silius, Messalina, and most of her circle.

Claudius did marry once more. The ancient sources tell that his freedmen put forward three candidates, Caligula's third wife Lollia Paulina, Claudius's divorced second wife Aelia Paetina and Claudius's niece Agrippina the Younger. According to Suetonius, Agrippina won out through her feminine wiles.
The truth is probably more political. The attempted coup d'état by Silius and Messalina had probably made Claudius realize the weakness of his position as a member of the Claudian but not the Julian family. This weakness was compounded by the fact that he did not yet have an obvious adult heir, Britannicus being just a boy.

Agrippina was one of the few remaining descendants of Augustus, and her son Lucius Domitius Ahenobarbus (the future Emperor Nero) was one of the last males of the Imperial family. Coup attempts could rally around the pair and Agrippina was already showing such ambition. It has been suggested that the Senate may have pushed for the marriage, to end the feud between the Julian and Claudian branches. This feud dated back to Agrippina's mother's actions against Tiberius after the death of her husband Germanicus (Claudius's brother), actions which Tiberius had gladly punished. In any case, Claudius accepted Agrippina and later adopted the newly mature Nero as his son.

Nero was married to Claudius' daughter Octavia, made joint heir with the underage Britannicus, and promoted; Augustus had similarly named his grandson Postumus Agrippa and his stepson Tiberius as joint heirs, and Tiberius had named Caligula joint heir with his grandson Tiberius Gemellus. Adoption of adults or near adults was an old tradition in Rome, when a suitable natural adult heir was unavailable as was the case during Britannicus' minority. Claudius may have previously looked to adopt one of his sons-in-law to protect his own reign.

Faustus Cornelius Sulla Felix, who was married to Claudius's daughter Claudia Antonia, was only descended from Octavia and Antony on one side – not close enough to the Imperial family to prevent doubts (although that did not stop others from making him the object of a coup attempt against Nero a few years later). Besides which, he was the half-brother of Valeria Messalina and at this time those wounds were still fresh. Nero was more popular with the general public as the grandson of Germanicus and the direct descendant of Augustus.

The historian Suetonius describes the physical manifestations of Claudius' affliction in relatively good detail. His knees were weak and gave way under him and his head shook. He stammered and his speech was confused. He slobbered and his nose ran when he was excited. The Stoic Seneca states in his "Apocolocyntosis" that Claudius' voice belonged to no land animal, and that his hands were weak as well.

However, he showed no physical deformity, as Suetonius notes that when calm and seated he was a tall, well-built figure of "dignitas". When angered or stressed, his symptoms became worse. Historians agree that this condition improved upon his accession to the throne. Claudius himself claimed that he had exaggerated his ailments to save his life.

Modern assessments of his health have changed several times in the past century. Prior to World War II, infantile paralysis (or polio) was widely accepted as the cause. This is the diagnosis used in Robert Graves' Claudius novels, first published in the 1930s. Polio does not explain many of the described symptoms, however, and a more recent theory implicates cerebral palsy as the cause, as outlined by Ernestine Leon. Tourette syndrome has also been considered a possibility.

As a person, ancient historians described Claudius as generous and lowbrow, a man who sometimes lunched with the plebeians. They also paint him as bloodthirsty and cruel, overly fond of gladiatorial combat and executions, and very quick to anger; Claudius himself acknowledged the latter trait, and apologized publicly for his temper. According to the ancient historians he was also overly trusting, and easily manipulated by his wives and freedmen. But at the same time they portray him as paranoid and apathetic, dull and easily confused.

Claudius' extant works present a different view, painting a picture of an intelligent, scholarly, well-read, and conscientious administrator with an eye to detail and justice. Thus, Claudius becomes an enigma. Since the discovery of his "Letter to the Alexandrians" in the last century, much work has been done to rehabilitate Claudius and determine where the truth lies.

Claudius wrote copiously throughout his life. Arnaldo Momigliano states that during the reign of Tiberius – which covers the peak of Claudius' literary career – it became impolitic to speak of republican Rome. The trend among the young historians was to either write about the new empire or obscure antiquarian subjects. Claudius was the rare scholar who covered both.

Besides the history of Augustus' reign that caused him so much grief, his major works included "Tyrrhenica", a twenty-book Etruscan history, and "Carchedonica", an eight-volume history of Carthage, as well as an Etruscan dictionary. He also wrote a book on dice-playing. Despite the general avoidance of the Republican era, he penned a defense of Cicero against the charges of Asinius Gallus. Modern historians have used this to determine the nature of his politics and of the aborted chapters of his civil war history.
He proposed a reform of the Latin alphabet by the addition of three new letters. He officially instituted the change during his censorship but they did not survive his reign. Claudius also tried to revive the old custom of putting dots between successive words (Classical Latin was written with no spacing). Finally, he wrote an eight-volume autobiography that Suetonius describes as lacking in taste. Claudius (like most of the members of his dynasty) harshly criticized his predecessors and relatives in surviving speeches.

None of the works survive but live on as sources for the surviving histories of the Julio-Claudian dynasty. Suetonius quotes Claudius' autobiography once and must have used it as a source numerous times. Tacitus uses Claudius' arguments for the orthographical innovations mentioned above and may have used him for some of the more antiquarian passages in his annals. Claudius is the source for numerous passages of Pliny's "Natural History".

The influence of historical study on Claudius is obvious. In his speech on Gallic senators, he uses a version of the founding of Rome identical to that of Livy, his tutor in adolescence. The speech is meticulous in details, a common mark of all his extant works, and he goes into long digressions on related matters. This indicates a deep knowledge of a variety of historical subjects that he could not help but share. Many of the public works instituted in his reign were based on plans first suggested by Julius Caesar. Levick believes this emulation of Caesar may have spread to all aspects of his policies.

His censorship seems to have been based on those of his ancestors, particularly Appius Claudius Caecus, and he used the office to put into place many policies based on those of Republican times. This is when many of his religious reforms took effect, and his building efforts greatly increased during his tenure. In fact, his assumption of the office of Censor may have been motivated by a desire to see his academic labors bear fruit. For example, he believed (as most Romans did) that Caecus had used the censorship to introduce the letter "R" and so used his own term to introduce his new letters.

The consensus of ancient historians was that Claudius was murdered by poison—possibly contained in mushrooms or on a feather—and died in the early hours of 13 October 54.

Nearly all implicate his final wife, Agrippina, as the instigator. Agrippina and Claudius had become more combative in the months leading up to his death. This carried on to the point where Claudius openly lamented his bad wives, and began to comment on Britannicus' approaching manhood with an eye towards restoring his status within the imperial family. Agrippina had motive in ensuring the succession of Nero before Britannicus could gain power.

Some implicate either his taster Halotus, his doctor Xenophon, or the infamous poisoner Locusta as the administrator of the fatal substance. Some say he died after prolonged suffering following a single dose at dinner, and some have him recovering only to be poisoned again. Among contemporary sources, Seneca the Younger ascribed the emperor's death to natural causes, while Josephus only spoke of rumors on his poisoning.

Some historians have cast doubt on whether Claudius was murdered or merely succumbed to illness or old age. Evidences against his murder include his old age, his serious illnesses in his last years, his unhealthy lifestyle and the fact that his taster Halotus continued to serve in the same position under Nero. On the other hand, some modern scholars claim the near universality of the accusations in ancient texts lends credence to the crime. Claudius' ashes were interred in the Mausoleum of Augustus on 24 October 54, after a funeral similar to that of his great-uncle Augustus 40 years earlier.

Already, while alive, he received the widespread private worship of a living "princeps" and was worshipped in Britannia in his own temple in Camulodunum.

Claudius was deified by Nero and the Senate almost immediately.

Agrippina had sent away Narcissus shortly before Claudius' death, and now murdered the freedman. The last act of this secretary of letters was to burn all of Claudius' correspondence—most likely so it could not be used against him and others in an already hostile new regime. Thus Claudius' private words about his own policies and motives were lost to history. Just as Claudius had criticized his predecessors in official edicts (see below), Nero often criticized the deceased Emperor and many of Claudius' laws and edicts were disregarded under the reasoning that he was too stupid and senile to have meant them.

Seneca's Apocolocyntosis mocks the deification of Claudius and reinforces the view of Claudius as an unpleasant fool; this remained the official view for the duration of Nero's reign. Eventually Nero stopped referring to his deified adoptive father at all, and realigned with his birth family. Claudius' temple was left unfinished after only some of the foundation had been laid down. Eventually the site was overtaken by Nero's Golden House.

The Flavians, who had risen to prominence under Claudius, took a different tack. They were in a position where they needed to shore up their legitimacy, but also justify the fall of the Julio-Claudians. They reached back to Claudius in contrast with Nero, to show that they were good associated with good. Commemorative coins were issued of Claudius and his son Britannicus, who had been a friend of the Emperor Titus (Titus was born in 39, Britannicus was born in 41). When Nero's Golden House was burned, the Temple of Claudius was finally completed on the Caelian Hill.

However, as the Flavians became established, they needed to emphasize their own credentials more, and their references to Claudius ceased. Instead, he was lumped with the other emperors of the fallen dynasty. His state cult in Rome probably continued until the abolition of all such cults of dead Emperors by Maximinus Thrax in 237–238. The "Feriale Duranum", probably identical to the festival calendars of every regular army unit, assigns him a sacrifice of a steer on his birthday, the Kalends of August. And such commemoration (and consequent feasting) probably continued until the Christianization and disintegration of the army in the late 4th century.

The main ancient historians Tacitus, Suetonius, and Cassius Dio all wrote after the last of the Flavians had gone. All three were senators or "equites". They took the side of the Senate in most conflicts with the Princeps, invariably viewing him as being in the wrong. This resulted in biases, both conscious and unconscious. Suetonius lost access to the official archives shortly after beginning his work. He was forced to rely on second-hand accounts when it came to Claudius (with the exception of Augustus' letters, which had been gathered earlier). Suetonius painted Claudius as a ridiculous figure, belittling many of his acts and attributing the objectively good works to his retinue.

Tacitus wrote a narrative for his fellow senators and fitted each of the emperors into a simple mold of his choosing. He wrote of Claudius as a passive pawn and an idiot in affairs relating to the palace and often in public life. During his censorship of 47–48 Tacitus allows the reader a glimpse of a Claudius who is more statesmanlike (XI.23–25), but it is a mere glimpse. Tacitus is usually held to have 'hidden' his use of Claudius' writings and to have omitted Claudius' character from his works. Even his version of Claudius' Lyons tablet speech is edited to be devoid of the Emperor's personality. Dio was less biased, but seems to have used Suetonius and Tacitus as sources. Thus the conception of Claudius as the weak fool, controlled by those he supposedly ruled, was preserved for the ages.

As time passed, Claudius was mostly forgotten outside of the historians' accounts. His books were lost first, as their antiquarian subjects became unfashionable. In the 2nd century, Pertinax, who shared his birthday, became emperor, overshadowing commemoration of Claudius.


In literature, Claudius and his contemporaries appear in the historical novel "The Roman" by Mika Waltari. Canadian-born science fiction writer A. E. van Vogt reimagined Robert Graves' Claudius story, in his two novels, "Empire of the Atom" and "The Wizard of Linn".

The historical novel "Chariot of the Soul" by Linda Proud features Claudius as host and mentor of the young Togidubnus, son of King Verica of the Atrebates, during his ten-year stay in Rome. When Togidubnus returns to Britain in advance of the Roman army, it is with a mission given to him by Claudius.





</doc>
<doc id="6141" url="https://en.wikipedia.org/wiki?curid=6141" title="Cardinal">
Cardinal

Cardinal or The Cardinal may refer to:
















</doc>
<doc id="6172" url="https://en.wikipedia.org/wiki?curid=6172" title="Cantor set">
Cantor set

In mathematics, the Cantor set is a set of points lying on a single line segment that has a number of remarkable and deep properties. It was discovered in 1874 by Henry John Stephen Smith and introduced by German mathematician Georg Cantor in 1883.

Through consideration of this set, Cantor and others helped lay the foundations of modern point-set topology. Although Cantor himself defined the set in a general, abstract way, the most common modern construction is the Cantor ternary set, built by removing the middle third of a line segment and then repeating the process with the remaining shorter segments. Cantor himself mentioned the ternary construction only in passing, as an example of a more general idea, that of a perfect set that is nowhere dense.

The Cantor ternary set formula_1 is created by iteratively deleting the "open" middle third from a set of line segments. One starts by deleting the open middle third (, ) from the interval [0, 1], leaving two line segments: [0, ] ∪ [, 1]. Next, the open middle third of each of these remaining segments is deleted, leaving four line segments: [0, ] ∪ [, ] ∪ [, ] ∪ [, 1]. This process is continued ad infinitum, where the "n"th set is

The Cantor ternary set contains all points in the interval [0, 1] that are not deleted at any step in this infinite process:

The first six steps of this process are illustrated below.

Using the idea of self-similar transformations, formula_4 and formula_5 the explicit closed formulas for the Cantor set are
where every middle third is removed as the open interval formula_7 from the closed interval formula_8 surrounding it, or
where the middle third formula_10 of the foregoing closed interval formula_11 is removed by intersecting with formula_12

This process of removing middle thirds is a simple example of a finite subdivision rule. The Cantor ternary set is an example of a fractal string.

In arithmetical terms, the Cantor set consists of all real numbers of the unit interval formula_13 that do not require the digit 1 in order to be expressed as a ternary (base 3) fraction. As the above diagram illustrates, each point in the Cantor set is uniquely located by a path through an infinitely deep binary tree, where the path turns left or right at each level according to which side of a deleted segment the point lies on. Representing each left turn with 0 and each right turn with 2 yields the ternary fraction for a point. Replacing the "2" digits in these fractions with "1" digits produces a surjective (and not injective) mapping between the Cantor set and the set of binary fractions in the interval [0,1].

Since the Cantor set is defined as the set of points not excluded, the proportion (i.e., measure) of the unit interval remaining can be found by total length removed. This total is the geometric progression

So that the proportion left is 1 – 1 = 0.

This calculation suggests that the Cantor set cannot contain any interval of non-zero length. It may seem surprising that there should be anything left—after all, the sum of the lengths of the removed intervals is equal to the length of the original interval. However, a closer look at the process reveals that there must be something left, since removing the "middle third" of each interval involved removing open sets (sets that do not include their endpoints). So removing the line segment (⁄, ⁄) from the original interval [0, 1] leaves behind the points ⁄ and ⁄. Subsequent steps do not remove these (or other) endpoints, since the intervals removed are always internal to the intervals remaining. So the Cantor set is not empty, and in fact contains an uncountably infinite number of points (as follows from the above description in terms of paths in an infinite binary tree).

It may appear that "only" the endpoints of the construction segments are left, but that is not the case either. The number ⁄, for example, has the unique ternary form 0.020202... = . It is in the bottom third, and the top third of that third, and the bottom third of that top third, and so on. Since it is never in one of the middle segments, it is never removed. Yet it is also not an endpoint of any middle segment, because it is not a multiple of any power of 1/3.
All endpoints of segments are "terminating" ternary fractions and are contained in the set
which is a countably infinite set.
As to cardinality, almost all elements of the Cantor set are not endpoints of intervals,
and the whole Cantor set is not countable.

It can be shown that there are as many points left behind in this process as there were to begin with, and that therefore, the Cantor set is uncountable. To see this, we show that there is a function "f" from the Cantor set formula_1 to the closed interval [0,1] that is surjective (i.e. "f" maps from formula_1 onto [0,1]) so that the cardinality of formula_1 is no less than that of [0,1]. Since formula_1 is a subset of [0,1], its cardinality is also no greater, so the two cardinalities must in fact be equal, by the Cantor–Bernstein–Schröder theorem.

To construct this function, consider the points in the [0, 1] interval in terms of base 3 (or ternary) notation. 
Recall that the proper ternary fractions, more precisely: the elements of formula_20, admit more than one representation in this notation, as for example ⁄, that can be written as 0.1 = , but also as 0.0222... = , and ⁄, that can be written as 0.2 = but also as 0.1222... = .
When we remove the middle third, this contains the numbers with ternary numerals of the form 0.1xxxxx... where xxxxx... is strictly between 00000... and 22222... So the numbers remaining after the first step consist of

This can be summarized by saying that those numbers with a ternary representation such that the first digit after the radix point is not 1 are the ones remaining after the first step.

The second step removes numbers of the form 0.01xxxx... and 0.21xxxx..., and (with appropriate care for the endpoints) it can be concluded that the remaining numbers are those with a ternary numeral where neither of the first "two" digits is 1.

Continuing in this way, for a number not to be excluded at step "n", it must have a ternary representation whose "n"th digit is not 1. For a number to be in the Cantor set, it must not be excluded at any step, it must admit a numeral representation consisting entirely of 0s and 2s.

It is worth emphasizing that numbers like 1, ⁄ = 0.1 and ⁄ = 0.21 are in the Cantor set, as they have ternary numerals consisting entirely of 0s and 2s: 1 = 0.222... = , ⁄ = 0.0222... = and ⁄ = 0.20222... = .
All the latter numbers are “endpoints”, and these examples are right limit points of formula_1. The same is true for the left limit points of formula_1, e. g. ⁄ = 0.1222... = = and ⁄ = 0.21222... = = . All these endpoints are "proper ternary" fractions (elements of formula_23) of the form ⁄, where denominator "q" is a power of 3 when the fraction is in its irreducible form. The ternary representation of these fractions terminates (i. e. is finite) or — recall from above that proper ternary fractions each have 2 representations — is infinite and “ends” in either infinitely many recurring 0s or infinitely many recurring 2s. Such a fraction is a left limit point of formula_1 if its ternary representation contains no 1's and “ends” in infinitely many recurring 0s. Similarly, a proper ternary fraction is a right limit point of formula_1 if it again its ternary expansion contains no 1's and “ends” in infinitely many recurring 2s.

This set of endpoints is dense in formula_1 (but not dense in [0, 1]) and makes up a countably infinite set. The numbers in formula_1 which are "not" endpoints also have only 0s and 2s in their ternary representation, but they cannot end in an infinite repetition of the digit 0, nor of the digit 2, because then it would be an endpoint.

The function from formula_1 to [0,1] is defined by taking the ternary numerals that do consist entirely of 0s and 2s, replacing all the 2s by 1s, and interpreting the sequence as a binary representation of a real number. In a formula,

For any number "y" in [0,1], its binary representation can be translated into a ternary representation of a number "x" in formula_1 by replacing all the 1s by 2s. With this, "f"("x") = "y" so that "y" is in the range of "f". For instance if "y" = ⁄ = 0.100110011001... = , we write "x" = = 0.200220022002... = ⁄. Consequently, "f" is surjective. However, "f" is "not" injective — the values for which "f"("x") coincides are those at opposing ends of one of the "middle thirds" removed. For instance, take
so
Thus there are as many points in the Cantor set as there are in the interval [0, 1] (which has the uncountable cardinality However, the set of endpoints of the removed intervals is countable, so there must be uncountably many numbers in the Cantor set which are not interval endpoints. As noted above, one example of such a number is ⁄, which can be written as 0.020202... = in ternary notation. In fact, given any formula_35, there exist formula_36 such that formula_37. This was first demonstrated by Steinhaus in 1917, who proved, via a geometric argument, the equivalent assertion that formula_38 for every formula_35. Since this construction provides an injection from formula_40 to formula_41, we have formula_42 as an immediate corollary. Assuming that formula_43 for any infinite set formula_44 (a statement shown to be equivalent to the axiom of choice by Tarski), this provides another demonstration that formula_45.

The Cantor set contains as many points as the interval from which it is taken, yet itself contains no interval of nonzero length. The irrational numbers have the same property, but the Cantor set has the additional property of being closed, so it is not even dense in any interval, unlike the irrational numbers which are dense in every interval.

It has been conjectured that all algebraic irrational numbers are normal. Since members of the Cantor set are not normal, this would imply that all members of the Cantor set are either rational or transcendental.

The Cantor set is the prototype of a fractal. It is self-similar, because it is equal to two copies of itself, if each copy is shrunk by a factor of 3 and translated. More precisely, the Cantor set is equal to the union of two functions, the left and right self-similarity transformations of itself, formula_46 and formula_47, which leave the Cantor set invariant up to homeomorphism: formula_48

Repeated iteration of formula_49 and formula_50 can be visualized as an infinite binary tree. That is, at each node of the tree, one may consider the subtree to the left or to the right. Taking the set formula_51 together with function composition forms a monoid, the dyadic monoid.

The automorphisms of the binary tree are its hyperbolic rotations, and are given by the modular group. Thus, the Cantor set is a homogeneous space in the sense that for any two points formula_52 and formula_53 in the Cantor set formula_1, there exists a homeomorphism formula_55 with formula_56. An explicit construction of formula_57 can be described more easily if we see the Cantor set as a product space of countably many copies of the discrete space formula_58. Then the map formula_59 defined by formula_60 is an involutive homeomorphism exchanging formula_52 and formula_53.

It has been found that some form of conservation law is always responsible behind scaling and self-similarity. In the case of Cantor set it can be seen that the formula_63th moment (where formula_64 is the fractal dimension) of all the surviving intervals at any stage of the construction process is equal to constant which is equal to one in the case of Cantor set 
. We know that there are formula_65 intervals of size formula_66
present in the system at the formula_67th step of its construction. Then if we label the surviving intervals
as formula_68 then the formula_63th moment is formula_70 since formula_71.

The Hausdorff dimension of the Cantor set is equal to ln(2)/ln(3) ≈ 0.631.

Although "the" Cantor set typically refers to the original, middle-thirds Cantor described above, topologists often talk about "a" Cantor set, which means any topological space that is homeomorphic (topologically equivalent) to it.

As the above summation argument shows, the Cantor set is uncountable but has Lebesgue measure 0. Since the Cantor set is the complement of a union of open sets, it itself is a closed subset of the reals, and therefore a complete metric space. Since it is also totally bounded, the Heine–Borel theorem says that it must be compact.

For any point in the Cantor set and any arbitrarily small neighborhood of the point, there is some other number with a ternary numeral of only 0s and 2s, as well as numbers whose ternary numerals contain 1s. Hence, every point in the Cantor set is an accumulation point (also called a cluster point or limit point) of the Cantor set, but none is an interior point. A closed set in which every point is an accumulation point is also called a perfect set in topology, while a closed subset of the interval with no interior points is nowhere dense in the interval.

Every point of the Cantor set is also an accumulation point of the complement of the Cantor set.

For any two points in the Cantor set, there will be some ternary digit where they differ — one will have 0 and the other 2. By splitting the Cantor set into "halves" depending on the value of this digit, one obtains a partition of the Cantor set into two closed sets that separate the original two points. In the relative topology on the Cantor set, the points have been separated by a clopen set. Consequently, the Cantor set is totally disconnected. As a compact totally disconnected Hausdorff space, the Cantor set is an example of a Stone space.

As a topological space, the Cantor set is naturally homeomorphic to the product of countably many copies of the space formula_72, where each copy carries the discrete topology. This is the space of all sequences in two digits 

which can also be identified with the set of 2-adic integers. The basis for the open sets of the product topology are cylinder sets; the homeomorphism maps these to the subspace topology that the Cantor set inherits from the natural topology on the real number line. This characterization of the Cantor space as a product of compact spaces gives a second proof that Cantor space is compact, via Tychonoff's theorem.

From the above characterization, the Cantor set is homeomorphic to the p-adic integers, and, if one point is removed from it, to the p-adic numbers.

The Cantor set is a subset of the reals, which are a metric space with respect to the ordinary distance metric; therefore the Cantor set itself is a metric space, by using that same metric. Alternatively, one can use the p-adic metric on formula_74: given two sequences formula_75, the distance between them is formula_76, where formula_77 is the smallest index such that formula_78; if there is no such index, then the two sequences are the same, and one defines the distance to be zero. These two metrics generate the same topology on the Cantor set.

We have seen above that the Cantor set is a totally disconnected perfect compact metric space. Indeed, in a sense it is the only one: every nonempty totally disconnected perfect compact metric space is homeomorphic to the Cantor set. See Cantor space for more on spaces homeomorphic to the Cantor set.

The Cantor set is sometimes regarded as "universal" in the category of compact metric spaces, since any compact metric space is a continuous image of the Cantor set; however this construction is not unique and so the Cantor set is not universal in the precise categorical sense. The "universal" property has important applications in functional analysis, where it is sometimes known as the "representation theorem for compact metric spaces".

For any integer "q" ≥ 2, the topology on the group G=Z (the countable direct sum) is discrete. Although the Pontrjagin dual Γ is also Z, the topology of Γ is compact. One can see that Γ is totally disconnected and perfect - thus it is homeomorphic to the Cantor set. It is easiest to write out the homeomorphism explicitly in the case "q"=2. (See Rudin 1962 p 40.)

The geometric mean of the Cantor set is approximately 0.274974.

The Cantor set can be seen as the compact group of binary sequences, and as such, it is endowed with a natural Haar measure. When normalized so that the measure of the set is 1, it is a model of an infinite sequence of coin tosses. Furthermore, one can show that the usual Lebesgue measure on the interval is an image of the Haar measure on the Cantor set, while the natural injection into the ternary set is a canonical example of a singular measure. It can also be shown that the Haar measure is an image of any probability, making the Cantor set a universal probability space in some ways.

In Lebesgue measure theory, the Cantor set is an example of a set which is uncountable and has zero measure.

If we define a Cantor number as a member of the Cantor set, then

The Cantor set is a meager set (or a set of first category) as a subset of [0,1] (although not as a subset of itself, since it is a Baire space). The Cantor set thus demonstrates that notions of "size" in terms of cardinality, measure, and (Baire) category need not coincide. Like the set formula_79, the Cantor set formula_1 is "small" in the sense that it is a null set (a set of measure zero) and it is a meager subset of [0,1]. However, unlike formula_79, which is countable and has a "small" cardinality, formula_82, the cardinality of formula_1 is the same as that of [0,1], the continuum formula_84, and is "large" in the sense of cardinality. In fact, it is also possible to construct a subset of [0,1] that is meager but of positive measure and a subset that is non-meager but of measure zero: By taking the countable union of "fat" Cantor sets formula_85 of measure formula_86 (see Smith–Volterra–Cantor set below for the construction), we obtain a set formula_87which has a positive measure (equal to 1) but is meager in [0,1], since each formula_85 is nowhere dense. Then consider the set formula_89. Since formula_90, formula_91 cannot be meager, but since formula_92, formula_91 must have measure zero.

Instead of repeatedly removing the middle third of every piece as in the Cantor set, we could also keep removing any other fixed percentage (other than 0% and 100%) from the middle. In the case where the middle ⁄ of the interval is removed, we get a remarkably accessible case — the set consists of all numbers in [0,1] that can be written as a decimal consisting entirely of 0s and 9s. If a fixed percentage is removed at each stage, then the limiting set will have measure zero, since the length of the remainder formula_94 as formula_95 for any "f" such that formula_96.

On the other hand, "fat Cantor sets" of positive measure can be generated by removal of smaller fractions of the middle of the segment in each iteration. Thus, one can construct sets homeomorphic to the Cantor set that have positive Lebesgue measure while still being nowhere dense. If an interval of length formula_97 (formula_98) is removed from the middle of each segment at the "n"th iteration, then the total length removed is formula_99, and the limiting set will have a Lebesgue measure of formula_100. Thus, in a sense, the middle-thirds Cantor set is a limiting case with formula_101. If formula_102, then the remainder will have positive measure with formula_103. The case formula_104 is known as the Smith–Volterra–Cantor set, which has a Lebesgue measure of formula_105.

One can modify the construction of the Cantor set by dividing randomly instead of equally. Besides, to incorporate time we can divide only one of the available intervals at each step instead of dividing all the available intervals. In the case of stochastic triadic Cantor set the resulting process can be described by the following rate equation

and for the stochastic dyadic Cantor set

where formula_108 is the number of intervals of size between formula_52 and formula_110. In the case of triadic Cantor set the fractal dimension is formula_111 which is 
less than its deterministic counterpart formula_112. In the case of stochastic dyadic Cantor set
the fractal dimension is formula_113 which is again less than that of its deterministic counterpart formula_114. In the case of stochastic dyadic Cantor set the solution for formula_115 exhibits dynamic scaling as its solution in the long-time limit is formula_116 where the fractal dimension of the stochastic dyadic Cantor set formula_117. In either case, like triadic Cantor set, the formula_63th moment (formula_119) of stochastic triadic and dyadic Cantor set too are conserved quantities.

Cantor dust is a multi-dimensional version of the Cantor set. It can be formed by taking a finite Cartesian product of the Cantor set with itself, making it a Cantor space. Like the Cantor set, Cantor dust has zero measure.

A different 2D analogue of the Cantor set is the Sierpinski carpet, where a square is divided up into nine smaller squares, and the middle one removed. The remaining squares are then further divided into nine each and the middle removed, and so on ad infinitum. One 3D analogue of this is the Menger sponge.

Christopher Domas presented a interactive binary visualization tool based on cantor dust at Black hat USA 2012.

Cantor himself defined the set in a general, abstract way, and mentioned the ternary construction only in passing, as an example of a more general idea, that of a perfect set that is nowhere dense. The original paper provides several different constructions of the abstract concept.

This set would have been considered abstract at the time when Cantor devised it. Cantor himself was led to it by practical concerns about the set of points where a trigonometric series might fail to converge. The discovery did much to set him on the course for developing an abstract, general theory of infinite sets.




</doc>
<doc id="6173" url="https://en.wikipedia.org/wiki?curid=6173" title="Cardinal number">
Cardinal number

In mathematics, cardinal numbers, or cardinals for short, are a generalization of the natural numbers used to measure the cardinality (size) of sets. The cardinality of a finite set is a natural number: the number of elements in the set. The "transfinite" cardinal numbers describe the sizes of infinite sets.

Cardinality is defined in terms of bijective functions. Two sets have the same cardinality if, and only if, there is a one-to-one correspondence (bijection) between the elements of the two sets. In the case of finite sets, this agrees with the intuitive notion of size. In the case of infinite sets, the behavior is more complex. A fundamental theorem due to Georg Cantor shows that it is possible for infinite sets to have different cardinalities, and in particular the cardinality of the set of real numbers is greater than the cardinality of the set of natural numbers. It is also possible for a proper subset of an infinite set to have the same cardinality as the original set, something that cannot happen with proper subsets of finite sets.

There is a transfinite sequence of cardinal numbers:
This sequence starts with the natural numbers including zero (finite cardinals), which are followed by the aleph numbers (infinite cardinals of well-ordered sets). The aleph numbers are indexed by ordinal numbers. Under the assumption of the axiom of choice, this transfinite sequence includes every cardinal number. If one rejects that axiom, the situation is more complicated, with additional infinite cardinals that are not alephs.

Cardinality is studied for its own sake as part of set theory. It is also a tool used in branches of mathematics including model theory, combinatorics, abstract algebra, and mathematical analysis. In category theory, the cardinal numbers form a skeleton of the category of sets.

The notion of cardinality, as now understood, was formulated by Georg Cantor, the originator of set theory, in 1874–1884. Cardinality can be used to compare an aspect of finite sets; e.g. the sets {1,2,3} and {4,5,6} are not "equal", but have the "same cardinality", namely three (this is established by the existence of a bijection, i.e. a one-to-one correspondence, between the two sets; e.g. {1→4, 2→5, 3→6}).

Cantor applied his concept of bijection to infinite sets; e.g. the set of natural numbers N = {0, 1, 2, 3, ...}. Thus, all sets having a bijection with N he called denumerable (countably infinite) sets and they all have the same cardinal number. This cardinal number is called formula_2, aleph-null. He called the cardinal numbers of these infinite sets transfinite cardinal numbers.

Cantor proved that any unbounded subset of N has the same cardinality as N, even though this might appear to run contrary to intuition. He also proved that the set of all ordered pairs of natural numbers is denumerable; this implies that the set of all rational numbers is also denumerable, since every rational can be represented by a pair of integers. He later proved that the set of all real algebraic numbers is also denumerable. Each real algebraic number "z" may be encoded as a finite sequence of integers which are the coefficients in the polynomial equation of which it is a solution, i.e. the ordered n-tuple ("a", "a", ..., "a"), "a" ∈ Z together with a pair of rationals ("b", "b") such that "z" is the unique root of the polynomial with coefficients ("a", "a", ..., "a") that lies in the interval ("b", "b").

In his 1874 paper "On a Property of the Collection of All Real Algebraic Numbers", Cantor proved that there exist higher-order cardinal numbers by showing that the set of real numbers has cardinality greater than that of N. His proof used an argument with nested intervals, but in an 1891 paper he proved the same result using his ingenious but simpler diagonal argument. The new cardinal number of the set of real numbers is called the cardinality of the continuum and Cantor used the symbol formula_3 for it.

Cantor also developed a large portion of the general theory of cardinal numbers; he proved that there is a smallest transfinite cardinal number (formula_2, aleph-null), and that for every cardinal number there is a next-larger cardinal

His continuum hypothesis is the proposition that formula_3 is the same as formula_7. This hypothesis has been found to be independent of the standard axioms of mathematical set theory; it can neither be proved nor disproved from the standard assumptions.

In informal use, a cardinal number is what is normally referred to as a "counting number", provided that 0 is included: 0, 1, 2, ... They may be identified with the natural numbers beginning with 0. The counting numbers are exactly what can be defined formally as the finite cardinal numbers. Infinite cardinals only occur in higher-level mathematics and logic.

More formally, a non-zero number can be used for two purposes: to describe the size of a set, or to describe the position of an element in a sequence. For finite sets and sequences it is easy to see that these two notions coincide, since for every number describing a position in a sequence we can construct a set which has exactly the right size, e.g. 3 describes the position of 'c' in the sequence <'a','b','c','d'...>, and we can construct the set {a,b,c} which has 3 elements. However, when dealing with infinite sets it is essential to distinguish between the two — the two notions are in fact different for infinite sets. Considering the position aspect leads to ordinal numbers, while the size aspect is generalized by the cardinal numbers described here.

The intuition behind the formal definition of cardinal is the construction of a notion of the relative size or "bigness" of a set without reference to the kind of members which it has. For finite sets this is easy; one simply counts the number of elements a set has. In order to compare the sizes of larger sets, it is necessary to appeal to more subtle notions.

A set "Y" is at least as big as a set "X" if there is an injective mapping from the elements of "X" to the elements of "Y". An injective mapping identifies each element of the set "X" with a unique element of the set "Y". This is most easily understood by an example; suppose we have the sets "X" = {1,2,3} and "Y" = {a,b,c,d}, then using this notion of size we would observe that there is a mapping:
which is injective, and hence conclude that "Y" has cardinality greater than or equal to "X". The element d has no element mapping to it, but this is permitted as we only require an injective mapping, and not necessarily an injective and onto mapping. The advantage of this notion is that it can be extended to infinite sets.

We can then extend this to an equality-style relation. Two sets "X" and "Y" are said to have the same "cardinality" if there exists a bijection between "X" and "Y". By the Schroeder–Bernstein theorem, this is equivalent to there being "both" an injective mapping from "X" to "Y" "and" an injective mapping from "Y" to "X". We then write |"X"| = |"Y"|. The cardinal number of "X" itself is often defined as the least ordinal "a" with |"a"| = |"X"|. This is called the von Neumann cardinal assignment; for this definition to make sense, it must be proved that every set has the same cardinality as "some" ordinal; this statement is the well-ordering principle. It is however possible to discuss the relative cardinality of sets without explicitly assigning names to objects.

The classic example used is that of the infinite hotel paradox, also called Hilbert's paradox of the Grand Hotel. Supposing there is an innkeeper at a hotel with an infinite number of rooms. The hotel is full, and then a new guest arrives. It is possible to fit the extra guest in by asking the guest who was in room 1 to move to room 2, the guest in room 2 to move to room 3, and so on, leaving room 1 vacant. We can explicitly write a segment of this mapping:
In this way we can see that the set {1,2,3...} has the same cardinality as the set {2,3,4...} since a bijection between the first and the second has been shown. This motivates the definition of an infinite set being any set which has a proper subset of the same cardinality; in this case {2,3,4...} is a proper subset of {1,2,3...}.

When considering these large objects, we might also want to see if the notion of counting order coincides with that of cardinal defined above for these infinite sets. It happens that it does not; by considering the above example we can see that if some object "one greater than infinity" exists, then it must have the same cardinality as the infinite set we started out with. It is possible to use a different formal notion for number, called ordinals, based on the ideas of counting and considering each number in turn, and we discover that the notions of cardinality and ordinality are divergent once we move out of the finite numbers.

It can be proved that the cardinality of the real numbers is greater than that of the natural numbers just described. This can be visualized using Cantor's diagonal argument;
classic questions of cardinality (for instance the continuum hypothesis) are concerned with discovering whether there is some cardinal between some pair of other infinite cardinals. In more recent times mathematicians have been describing the properties of larger and larger cardinals.

Since cardinality is such a common concept in mathematics, a variety of names are in use. Sameness of cardinality is sometimes referred to as "equipotence", "equipollence", or "equinumerosity". It is thus said that two sets with the same cardinality are, respectively, "equipotent", "equipollent", or "equinumerous".

Formally, assuming the axiom of choice, the cardinality of a set "X" is the least ordinal number α such that there is a bijection between "X" and α. This definition is known as the von Neumann cardinal assignment. If the axiom of choice is not assumed we need to do something different. The oldest definition of the cardinality of a set "X" (implicit in Cantor and explicit in Frege and Principia Mathematica) is as the class ["X"] of all sets that are equinumerous with "X". This does not work in ZFC or other related systems of axiomatic set theory because if "X" is non-empty, this collection is too large to be a set. In fact, for "X" ≠ ∅ there is an injection from the universe into ["X"] by mapping a set "m" to {"m"} × "X" and so by the axiom of limitation of size, ["X"] is a proper class. The definition does work however in type theory and in New Foundations and related systems. However, if we restrict from this class to those equinumerous with "X" that have the least rank, then it will work (this is a trick due to Dana Scott: it works because the collection of objects with any given rank is a set).

Formally, the order among cardinal numbers is defined as follows: |"X"| ≤ |"Y"| means that there exists an injective function from "X" to "Y". The Cantor–Bernstein–Schroeder theorem states that if |"X"| ≤ |"Y"| and |"Y"| ≤ |"X"| then |"X"| = |"Y"|. The axiom of choice is equivalent to the statement that given two sets "X" and "Y", either |"X"| ≤ |"Y"| or |"Y"| ≤ |"X"|.

A set "X" is Dedekind-infinite if there exists a proper subset "Y" of "X" with |"X"| = |"Y"|, and Dedekind-finite if such a subset doesn't exist. The finite cardinals are just the natural numbers, i.e., a set "X" is finite if and only if |"X"| = |"n"| = "n" for some natural number "n". Any other set is infinite. Assuming the axiom of choice, it can be proved that the Dedekind notions correspond to the standard ones. It can also be proved that the cardinal formula_2 (aleph null or aleph-0, where aleph is the first letter in the Hebrew alphabet, represented formula_9) of the set of natural numbers is the smallest infinite cardinal, i.e. that any infinite set has a subset of cardinality formula_10 The next larger cardinal is denoted by formula_7 and so on. For every ordinal α there is a cardinal number formula_12 and this list exhausts all infinite cardinal numbers.

We can define arithmetic operations on cardinal numbers that generalize the ordinary operations for natural numbers. It can be shown that for finite cardinals these operations coincide with the usual operations for natural numbers. Furthermore, these operations share many properties with ordinary arithmetic.

If the axiom of choice holds, then every cardinal κ has a successor κ > κ, and there are no cardinals between κ and its successor. (Without the axiom of choice, using Hartogs' theorem, it can be shown that, for any cardinal number κ, there is a minimal cardinal κ, such that formula_13) For finite cardinals, the successor is simply κ + 1. For infinite cardinals, the successor cardinal differs from the successor ordinal.

If "X" and "Y" are disjoint, addition is given by the union of "X" and "Y". If the two sets are not already disjoint, then they can be replaced by disjoint sets of the same cardinality, e.g., replace "X" by "X"×{0} and "Y" by "Y"×{1}.

Zero is an additive identity "κ" + 0 = 0 + "κ" = "κ".

Addition is associative ("κ" + "μ") + "ν" = "κ" + ("μ" + "ν").

Addition is commutative "κ" + "μ" = "μ" + "κ".

Addition is non-decreasing in both arguments:

Assuming the axiom of choice, addition of infinite cardinal numbers is easy. If either κ or μ is infinite, then

Assuming the axiom of choice and, given an infinite cardinal σ and a cardinal μ, there exists a cardinal κ such that μ + κ = σ if and only if μ ≤ σ. It will be unique (and equal to σ) if and only if μ < σ.

The product of cardinals comes from the cartesian product.

"κ"·0 = 0·"κ" = 0.

"κ"·"μ" = 0 → ("κ" = 0 or "μ" = 0).

One is a multiplicative identity "κ"·1 = 1·"κ" = "κ".

Multiplication is associative ("κ"·"μ")·"ν" = "κ"·("μ"·"ν").

Multiplication is commutative "κ"·"μ" = "μ"·"κ".

Multiplication is non-decreasing in both arguments:
"κ" ≤ "μ" → ("κ"·"ν" ≤ "μ"·"ν" and "ν"·"κ" ≤ "ν"·"μ").

Multiplication distributes over addition:
"κ"·("μ" + "ν") = "κ"·"μ" + "κ"·"ν" and
("μ" + "ν")·"κ" = "μ"·"κ" + "ν"·"κ".

Assuming the axiom of choice, multiplication of infinite cardinal numbers is also easy. If either "κ" or "μ" is infinite and both are non-zero, then

Assuming the axiom of choice and, given an infinite cardinal "π" and a non-zero cardinal μ, there exists a cardinal κ such that μ · κ = "π" if and only if μ ≤ "π". It will be unique (and equal to "π") if and only if μ < "π".

Exponentiation is given by
where "X" is the set of all functions from "Y" to "X".

Exponentiation is non-decreasing in both arguments:

2 is the cardinality of the power set of the set "X" and Cantor's diagonal argument shows that 2 > |"X"| for any set "X". This proves that no largest cardinal exists (because for any cardinal "κ", we can always find a larger cardinal 2). In fact, the class of cardinals is a proper class. (This proof fails in some set theories, notably New Foundations.)

All the remaining propositions in this section assume the axiom of choice:

If 2 ≤ κ and 1 ≤ μ and at least one of them is infinite, then:

Using König's theorem, one can prove κ < κ and κ < cf(2) for any infinite cardinal κ, where cf(κ) is the cofinality of κ.

Assuming the axiom of choice and, given an infinite cardinal κ and a finite cardinal μ greater than 0, the cardinal ν satisfying formula_20 will be κ.

Assuming the axiom of choice and, given an infinite cardinal κ and a finite cardinal μ greater than 1, there may or may not be a cardinal λ satisfying formula_21. However, if such a cardinal exists, it is infinite and less than κ, and any finite cardinality ν greater than 1 will also satisfy formula_22.

The logarithm of an infinite cardinal number κ is defined as the least cardinal number μ such that κ ≤ 2. Logarithms of infinite cardinals are useful in some fields of mathematics, for example in the study of cardinal invariants of topological spaces, though they lack some of the properties that logarithms of positive real numbers possess.

The continuum hypothesis (CH) states that there are no cardinals strictly between formula_2 and formula_24 The latter cardinal number is also often denoted by formula_3; it is the cardinality of the continuum (the set of real numbers). In this case formula_26 The generalized continuum hypothesis (GCH) states that for every infinite set "X", there are no cardinals strictly between | "X" | and 2. The continuum hypothesis is independent of the usual axioms of set theory, the Zermelo-Fraenkel axioms together with the axiom of choice (ZFC).

Notes
Bibliography



</doc>
<doc id="6174" url="https://en.wikipedia.org/wiki?curid=6174" title="Cardinality">
Cardinality

In mathematics, the cardinality of a set is a measure of the "number of elements" of the set. For example, the set formula_1 contains 3 elements, and therefore formula_2 has a cardinality of 3. Beginning in the late 19th century, this concept was generalized to infinite sets, which allows one to distinguish between the different types of infinity, and to perform arithmetic on them. There are two approaches to cardinality: one which compares sets directly using bijections and injections, and another which uses cardinal numbers.
The cardinality of a set is also called its size, when no confusion with other notions of size is possible.

The cardinality of a set formula_2 is usually denoted formula_4, with a vertical bar on each side; this is the same notation as absolute value, and the meaning depends on context. The cardinality of a set formula_2 may alternatively be denoted by formula_6, formula_2, formula_8, or formula_9.

While the cardinality of a finite set is just the number of its elements, extending the notion to infinite sets usually starts with defining the notion of comparison of arbitrary sets (some of which are possibly infinite).

If ≤ and ≤ , then = (a fact known as Schröder–Bernstein theorem). The axiom of choice is equivalent to the statement that ≤ or ≤ for every "A", "B".

In the above section, "cardinality" of a set was defined functionally. In other words, it was not defined as a specific object itself. However, such an object can be defined as follows.

The relation of having the same cardinality is called equinumerosity, and this is an equivalence relation on the class of all sets. The equivalence class of a set "A" under this relation, then, consists of all those sets which have the same cardinality as "A". There are two ways to define the "cardinality of a set":


Assuming the axiom of choice, the cardinalities of the infinite sets are denoted
For each ordinal formula_11, formula_12 is the least cardinal number greater than formula_13.

The cardinality of the natural numbers is denoted aleph-null (formula_14), while the cardinality of the real numbers is denoted by "formula_15" (a lowercase fraktur script "c"), and is also referred to as the cardinality of the continuum. Cantor showed, using the diagonal argument, that formula_16. We can show that formula_17, this also being the cardinality of the set of all subsets of the natural numbers. 

The continuum hypothesis says that formula_18, i.e. formula_19 is the smallest cardinal number bigger than formula_14, i.e. there is no set whose cardinality is strictly between that of the integers and that of the real numbers. The continuum hypothesis is independent of ZFC, a standard axiomatization of set theory; that is, it is impossible to prove the continuum hypothesis or its negation from ZFC—provided that ZFC is consistent). For more detail, see § Cardinality of the continuum below.

If the axiom of choice holds, the law of trichotomy holds for cardinality. Thus we can make the following definitions:


Our intuition gained from finite sets breaks down when dealing with infinite sets. In the late nineteenth century Georg Cantor, Gottlob Frege, Richard Dedekind and others rejected the view that the whole cannot be the same size as the part. One example of this is Hilbert's paradox of the Grand Hotel.
Indeed, Dedekind defined an infinite set as one that can be placed into a one-to-one correspondence with a strict subset (that is, having the same size in Cantor's sense); this notion of infinity is called Dedekind infinite. Cantor introduced the cardinal numbers, and showed—according to his bijection-based definition of size—that some infinite sets are greater than others. The smallest infinite cardinality is that of the natural numbers (formula_14).

One of Cantor's most important results was that the cardinality of the continuum (formula_24) is greater than that of the natural numbers (formula_14); that is, there are more real numbers R than natural numbers N. Namely, Cantor showed that formula_26 (see Beth one) satisfies:

The continuum hypothesis states that there is no cardinal number between the cardinality of the reals and the cardinality of the natural numbers, that is,

However, this hypothesis can neither be proved nor disproved within the widely accepted ZFC axiomatic set theory, if ZFC is consistent.

Cardinal arithmetic can be used to show not only that the number of points in a real number line is equal to the number of points in any segment of that line, but that this is equal to the number of points on a plane and, indeed, in any finite-dimensional space. These results are highly counterintuitive, because they imply that there exist proper subsets and proper supersets of an infinite set "S" that have the same size as "S", although "S" contains elements that do not belong to its subsets, and the supersets of "S" contain elements that are not included in it.

The first of these results is apparent by considering, for instance, the tangent function, which provides a one-to-one correspondence between the interval (−½π, ½π) and R (see also Hilbert's paradox of the Grand Hotel).

The second result was first demonstrated by Cantor in 1878, but it became more apparent in 1890, when Giuseppe Peano introduced the space-filling curves, curved lines that twist and turn enough to fill the whole of any square, or cube, or hypercube, or finite-dimensional space. These curves are not a direct proof that a line has the same number of points as a finite-dimensional space, but they can be used to obtain such a proof.

Cantor also showed that sets with cardinality strictly greater than formula_15 exist (see his generalized diagonal argument and theorem). They include, for instance:

Both have cardinality

The cardinal equalities formula_31 formula_32 and formula_33 can be demonstrated using cardinal arithmetic:


If "A" and "B" are disjoint sets, then

From this, one can show that in general, the cardinalities of unions and intersections are related by the following equation:



</doc>
<doc id="6176" url="https://en.wikipedia.org/wiki?curid=6176" title="Cecil B. DeMille">
Cecil B. DeMille

Cecil Blount DeMille (; August 12, 1881January 21, 1959) was an American filmmaker. Between 1914 and 1958, he made a total of 70 features, both silent and sound films. He is acknowledged as a founding father of the American cinema and the most commercially successful producer-director in film history. His films were distinguished by their epic scale and by his cinematic showmanship. His silent films included social dramas, comedies, Westerns, farces, morality plays, and historical pageants.

DeMille was born in Ashfield, Massachusetts, and grew up in New York City. He began his career as a stage actor in 1900. He later moved to writing and directing stage productions, some with Jesse Lasky, who was then a vaudeville producer. DeMille's first film, "The Squaw Man" (1914), was also the first full-length feature film shot in Hollywood. Its interracial love story made it commercially successful and it first publicized Hollywood as the home of the U.S. film industry. The continued success of his productions led to the founding of Paramount Pictures with Lasky and Adolph Zukor. His first biblical epic, "The Ten Commandments" (1923), was both a critical and commercial success; it held the Paramount revenue record for twenty-five years.

DeMille directed "The King of Kings" (1927), a biography of Jesus, which gained approval for its sensitivity and reached more than 800 million viewers. "The Sign of the Cross" (1932) is said to be the first sound film to integrate all aspects of cinematic technique. "Cleopatra" (1934) was his first film to be nominated for the Academy Award for Best Picture. After more than thirty years in film production, DeMille reached a pinnacle in his career with "Samson and Delilah" (1949), a biblical epic which became the highest-grossing film of 1950. Along with biblical and historical narratives, he also directed films oriented toward "neo-naturalism", which tried to portray the laws of man fighting the forces of nature.

He received his first nomination for the Academy Award for Best Director for his circus drama "The Greatest Show on Earth" (1952), which won both the Academy Award for Best Picture and the Golden Globe Award for Best Motion Picture – Drama. His last and best known film, "The Ten Commandments" (1956), also a Best Picture Academy Award nominee, is currently the eighth-highest-grossing film of all time, adjusted for inflation. In addition to his Best Picture Awards, he received an Academy Honorary Award for his film contributions, the Palme d'Or (posthumously) for "Union Pacific" (1939), a DGA Award for Lifetime Achievement, and the Irving G. Thalberg Memorial Award. He was the first recipient of the Golden Globe Cecil B. DeMille Award, which was named in his honor. DeMille's reputation as a filmmaker has grown over time and his work has influenced many other films and directors.

Cecil Blount DeMille was born on August 12, 1881, in a boarding house on Main Street in Ashfield, Massachusetts, where his parents had been vacationing for the summer. On September 1, 1881, the family returned with newborn DeMille to their flat in New York. DeMille was named after his grandmothers Cecelia Wolff and Margarete Blount. He was the second of three children of Henry Churchill de Mille (September 4, 1853 – February 10, 1893) and his wife Matilda Beatrice deMille (née Samuel; January 30, 1853 – October 8, 1923), known as Beatrice. His brother, William C. DeMille, was born on July 25, 1878. Henry deMille, whose ancestors were of Dutch-Belgian descent, was a North Carolina-born dramatist, actor, and lay reader in the Episcopal Church. DeMille's father was also an English teacher at Columbia College (now Columbia University). He worked as a playwright, administrator, and faculty member during the early years of the American Academy of Dramatic Arts, established in New York City in 1884.

Henry deMille frequently collaborated with David Belasco when playwriting. Their most well known collaborations include "The Wife", "Lord Chumley", "The Charity Ball", and "Men and Women". DeMille's mother Beatrice, a literary agent and scriptwriter, whose parents were both of German-Jewish heritage, married Henry deMille July 1, 1876, despite her parents' dissent due to their differing religions. She emigrated from England with her parents in 1871 when she was 18, and they settled in Brooklyn. Beatrice grew up in a middle-class English household. DeMille's parents met as members of a music and literary society in New York. Henry was a tall, red-headed student. Beatrice was intelligent, educated, forthright, and strong-willed. When they married, Beatrice converted to Episcopalianism.

DeMille was a brave and confident child. He gained his love of theater while watching his father and Belasco rehearse their plays and a lasting memory for DeMille was a lunch with his father and actor Edwin Booth. As a child, DeMille created an alter-ego called "Champion Driver", a Robin Hood-like character, evidence of his creativity and imagination. The family lived in Washington, North Carolina, until Henry built a three-story Victorian-style house for his family in Pompton Lakes, New Jersey; they named this estate "Pamlico". John Philip Sousa was a friend of the family and DeMille recalled throwing mud balls in the air so neighbor Annie Oakley could practice her shooting. DeMille's sister Agnes was born on April 23, 1891; his mother nearly did not survive the birth. Agnes would die on February 11, 1894, at the age of three from spinal meningitis. DeMille's parents operated a private school in town and attended Christ Episcopal Church. DeMille recalled that this church was the place where he visualized the story of his 1923 version of "The Ten Commandments".

On January 8, 1893, at the age of forty, Henry de Mille died suddenly from typhoid fever, leaving Beatrice with three children. To provide for her family, she opened the Henry C. DeMille School for Girls in her home in February 1893. The aim of the school was to teach young women to properly understand and fulfill the women's duty to herself, her home, and her country. Before Henry deMille's death, Beatrice had "enthusiastically supported" her husband's theatrical aspirations. She later became the second female play broker on Broadway. On Henry DeMille's deathbed, he told his wife that he did not want his sons to become playwrights due to its uncertainty and disappointment as a career. In order to cultivate DeMille's education and life skills, DeMille's mother sent him to Pennsylvania Military College (now Widener University) in Chester, Pennsylvania, at the age of fifteen. He fled school to join the Spanish–American War, but failed to meet the age requirement. DeMille was a neat, intelligent, athletic, and determined adolescent. At the military college, even though his grades were average, he reportedly excelled in personal conduct. DeMille (Class of 1900) attended and graduated from the American Academy of Dramatic Arts, where he attended for free due to his father's service to the Academy. His graduation performance was the play "The Arcady Trail". In the audience was Charles Frohman who would cast DeMille in his play "Hearts are Trumps", DeMille's Broadway debut.

Cecil B. DeMille began his career as an actor on the stage in the theatrical company of Charles Frohman in 1900. He debuted as an actor on February 21, 1900, in the play "Hearts Are Trumps" at New York's Garden Theater. In 1901, DeMille starred in productions of "A Repentance", "To Have and to Hold", and "Are You a Mason?" At the age of twenty-one, Cecil B. DeMille married Constance Adams on August 16, 1902 at Adams's father's home in East Orange, New Jersey. The wedding party was small and Beatrice deMille's family was not in attendance. It was suggested by Simon Louvish that this was to conceal DeMille's Jewish heritage. Adams was 29 years old at the time of their marriage, eight years older than DeMille. They had met in a theater in Washington D.C. while they were both acting in "Hearts Are Trumps".

Their age difference led to their sexual incompatibility; according to DeMille, Adams was too "pure" to "feel such violent and evil passions". DeMille had more violent sexual preferences and fetishes than his wife and Adams allowed DeMille to have several long term mistresses during their marriage as an outlet for his particular sexual kinks, while maintaining an outward appearance of a faithful marriage. Adams did not want to have sexual relations with DeMille, but did not mind his affairs because she felt that sex and love were unrelated; she knew that she was the sole Mrs. DeMille. One of DeMille's affairs was with his screenwriter Jeanie MacPherson. Despite his reputation for extramarital affairs, DeMille did not like to have affairs with his stars, as he believed it would cause him to lose control as a director. He related a story that he maintained his self-control when Gloria Swanson sat on his lap, refusing to touch her.

In 1902, he played a small part in "Hamlet". Publicists wrote that he became an actor in order to learn how direct and produce, but DeMille admitted that he became an actor in order to pay the bills. From 1904 to 1905, DeMille attempted to make a living as a stock theatre actor with his wife Constance. DeMille made a 1905 reprise in "Hamlet" as Osric. His brother William was establishing himself as a playwright and sometimes invited him to collaborate. DeMille and William collaborated on "The Genius", "The Royal Mounted", and "After Five". However, none of these were very successful; William deMille was most successful when he worked alone. DeMille and his brother at times worked with the legendary impresario David Belasco, who had been a friend and collaborator of their father. DeMille would later adapt Belasco's "The Girl of the Golden West" and "Rose of the Rancho", and "The Warrens of Virginia" into films. DeMille was credited with creating the premise of Belasco's "The Return of Peter Grimm". "The Return of Peter Grimm" sparked controversy; however, because Belasco had taken DeMille's unnamed screenplay, changed the characters and named it "The Return of Peter Grimm", producing and presenting it as his own work. DeMille was credited in small print as "based on an idea by Cecil DeMille". The play was successful and DeMille was distraught that his childhood idol had plagiarized his work.

DeMille performed on stage with actors whom he would later direct in films: Charlotte Walker, Mary Pickford, and Pedro de Cordoba. DeMille also produced and directed plays. His 1905 performance in "The Prince Chap" as the Earl of Huntington was well received by audiences. DeMille wrote a few of his own plays in-between stage performances, but his playwriting was not as successful. His first play was "The Pretender-A Play in a Prologue and 4 Acts" set in the seventeenth century Russia. Another unperformed play he wrote was "Son of the Winds", a mythological Native American story. Life was difficult for DeMille and his wife as traveling actors; however, traveling allowed him to experience part of the United States he had not yet seen. DeMille sometimes worked with the director E.H. Sothern, who influenced DeMille's later perfectionism in his work. In 1907, due to a scandal with one of Beatrice's students, Evelyn Nesbit, the Henry deMille School lost students. The school closed and Beatrice filed for bankruptcy. DeMille wrote another play originally called "Sergeant Devil May Care" which was renamed "The Royal Mounted". He also toured with the Standard Opera Company, but there are few records to indicate DeMille's singing ability. DeMille had a daughter, Cecilia, on November 5, 1908, who would be his only biological child. In the 1910s, DeMille began directing and producing other writer's plays.

DeMille was poor and struggled to find work. Consequently, his mother hired him for her agency The DeMille Play Company and taught him how to be an agent and a playwright. Eventually, he became manager of the agency and later, a junior partner with his mother. In 1911, DeMille became acquainted with vaudeville producer Jesse Lasky when Lasky was searching for a writer for his new musical. He initially sought out William deMille. William had been a successful playwright, but DeMille was suffering from the failure of his plays "The Royal Mounted" and "The Genius". However, Beatrice introduced Lasky to DeMille instead. The collaboration of DeMille and Lasky produced a successful musical called "California" which opened in New York in January 1912. Another DeMille-Lasky production that opened in January 1912 was "The Antique Girl". DeMille found success in the spring of 1913 producing "Reckless Age" by Lee Wilson, a play about a high society girl wrongly accused of manslaughter starring Frederick Burton and Sydney Shields. However, changes in the theater rendered DeMille's melodramas obsolete before they were produced, and true theatrical success eluded him. He produced many flops. Having become disinterested in working in theatre, DeMille's passion for film was ignited when he watched the 1912 French film "Les Amours de la reine Élisabeth".

Desiring a change of scene, Cecil B. DeMille, Jesse Lasky, Sam Goldfish (later Samuel Goldwyn), and a group of East Coast businessmen created the Jesse L. Lasky Feature Play Company in 1913 over which DeMille became director-general. Lasky and DeMille were said to have sketched out the organization of the company on the back of a restaurant menu. As director-general, DeMille's job was to make the films. In addition to directing, DeMille was the supervisor and consultant for the first year of films made by the Lasky Feature Play Company. Sometimes, he directed scenes for other directors at the Feature Play Company in order to release films on time. Moreover, when he was busy directing other films, he would co-author other Lasky Company scripts as well as create screen adaptations that others directed.

The Lasky Play Company sought out William DeMille to join the company, but he rejected the offer because he did not believe there was any promise in a film career. When William found out that DeMille had begun working in the motion picture industry, he wrote DeMille a letter, disappointed that he was willing "to throw away [his] future" when he was "born and raised in the finest traditions of the theater". The Lasky Company wanted to attract high-class audiences to their films so they began producing films from literary works. The Lasky Company bought the rights to the play "The Squaw Man" by Edwin Milton Royle and cast Dustin Farnum in the lead role. They offered Farnum a choice to have a quarter stock in the company (similar to William deMille) or $250 per week as salary. Farnum chose $250 per week. Already $15,000 in debt to Royle for the screenplay of "The Squaw Man", Lasky's relatives bought the $5,000 stock to save the Lasky Company from bankruptcy. With no knowledge of filmmaking, DeMille was introduced to observe the process at film studios. He was eventually introduced to Oscar Apfel, a stage director turned movie director.

On December 12, 1913, DeMille, his cast, and crew boarded a Southern Pacific train bound for Flagstaff via New Orleans. His tentative plan was to shoot a film in Arizona, but he felt that Arizona did not typify the Western look they were searching for. They also learned that other filmmakers were successfully shooting in Los Angeles, even in winter. He continued to Los Angeles. Once there, he chose not to shoot in Edendale, where many studios were, but in Hollywood. DeMille rented a barn to function as their film studio. Filming began on December 29, 1913, and lasted three weeks. Apfel filmed most of "The Squaw Man" due to DeMille's inexperience; however, DeMille learned quickly and was particularly adept at impromptu screenwriting as necessary. He made his first film run sixty minutes, as long as a short play. "The Squaw Man" (1914), co-directed by Oscar Apfel, was a sensation and it established the Lasky Company. This was the first feature-length film made in Hollywood. There were problems; however, with the perforation of the film stock and it was discovered the DeMille had brought a cheap British film projector. DeMille would later need to be sure to punch in sixty-five holes per foot instead of the industry-standard sixty-four. This was also the first American feature film; however, only by release date, as D. W. Griffith's "Judith of Bethulia" was filmed earlier than "The Squaw Man", but released later. Additionally, this was the only film in which DeMille shared director's credit with Oscar C. Apfel.

"The Squaw Man" was a success, which led to the eventual founding of Paramount Pictures and Hollywood becoming the "film capital of the world". The film grossed over ten times its budget after its New York premiere in February 1914. DeMille's next project was to aid Oscar Apfel and directing "Brewster's Millions", which was wildly successful. In December 1914, Constance Adams brought home John DeMille, a fifteen-month-old, whom the couple legally adopted three years later. Biographer Scott Eyman suggested that this may have been a result of Adams's recent miscarriage.

Cecil B. DeMille's second film credited exclusively to him was "The Virginian". This is earliest of DeMille's films available in a quality, color-tinted video format. However, this version is actually a 1918 re-release. The first few years of the Lasky Company were spent in making films nonstop, literally writing the language of film. DeMille himself directed twenty films by 1915. The most successful films during the beginning of the Lasky Company were "Brewster's Millions" (co-directed by DeMille), "Rose of the Rancho", and "The Ghost Breaker". DeMille adapted Belasco's dramatic lighting techniques to film technology, mimicking moonlight with U.S. cinema's first attempts at "motivated lighting" in "The Warrens of Virginia". This was the first of few film collaborations with his brother William. They struggled to adapt the play from the stage to the set. After the film was shown, viewers complained that the shadows and lighting prevented the audience from seeing the actors' full faces, complaining that they would only pay half price. However, Sam Goldwyn realized that if they called it "Rembrandt" lighting, the audience would pay double the price. Additionally, because of DeMille's cordiality after the "Peter Grimm" incident, DeMille was able to rekindle his partnership with Belasco. He adapted several of Belasco's screenplays into film.

DeMille's most successful film was "The Cheat"; DeMille's direction in the film was acclaimed. In 1916, exhausted from three years of nonstop filmmaking, DeMille purchased land in the Angeles National Forest for a ranch which would become his getaway. He called this place, "Paradise", declaring it a wildlife sanctuary; no shooting of animals was allowed besides snakes. His wife did not like Paradise, so DeMille often brought his mistresses there with him including actress Julia Faye. In addition to his Paradise, DeMille purchased a yacht in 1921 which he called "The Seaward".

While filming "The Captive" in 1915, an extra, Bob Fleming, died on set when another extra failed to heed to DeMille's orders to unload all guns for rehearsal. DeMille instructed the guilty man to leave town and would never reveal his name. Lasky and DeMille maintained the widow Fleming on the payroll; however, according to leading actor House Peters Sr. DeMille refused to stop production for the funeral of Fleming. Peters claimed that he encouraged the cast to attend the funeral with him anyway since DeMille would not be able to shoot the film without him. On July 19, 1916, the Jesse Lasky Feature Play Company merged with Adolph Zukor's Famous Players Film Company, becoming Famous Players-Lasky. Zukor became president with Lasky as the vice president. DeMille was maintained as director-general and Goldwyn became chairman of the board. Goldwyn was later fired from Famous Players-Lasky due to frequent clashes with Lasky, DeMille, and finally Zukor. While on a European vacation in 1921, DeMille contracted rheumatic fever in Paris. He was confined to bed and unable to eat. His poor physical condition upon his return home affected the production of his 1922 film "Manslaughter". According to Richard Birchard, DeMille's weakened state during production may have led to the film being received as uncharacteristically substandard.

During World War I, the Famous Players-Lasky organized a military company underneath the National Guard called the "Home Guard" made up of film studio employees with DeMille as captain. Eventually, the Guard was promoted to a battalion and recruited soldiers from other film studios. They took time off weekly from film production to practice military drills. Additionally, during the war, DeMille volunteered for the Justice Department's Intelligence Office, investigating friends, neighbors, and others he came in contact with in connection with the Famous Players-Lasky. He volunteered for the Intelligence Office during World War II as well. Although DeMille considered enlisting in World War I, he stayed in the United States and made films. However, he did take a few months to set up a movie theater for the French front. Famous Players-Lasky donated the films. DeMille and Adams adopted Katherine Lester in 1920 whom Adams had found in the orphanage over which she was the director. In 1922, the couple adopted Richard deMille.

Film started becoming more sophisticated and the subsequent films of the Lasky company were criticized for primitive and unrealistic set design. Consequently, Beatrice deMille introduced the Famous Players-Lasky to Wilfred Buckland, who DeMille had known from his time at the American Academy of Dramatic Arts, and he became DeMille's art director. William deMille reluctantly became a story editor. William deMille would later convert from theater to Hollywood and would spend the rest of his career as a film director. Throughout his career, DeMille would frequently remake his own films. In his first instance, in 1917, he remade "The Squaw Man" (1918), only waiting four years from the 1914 original. Despite its quick turnaround, the film was fairly successful. However, DeMille's second remake at MGM in 1931 would be a failure.

After five years and thirty hit films, DeMille became the American film industry's most successful director. In the silent era, he was renowned for "Male and Female" (1919), "Manslaughter" (1922), "The Volga Boatman" (1926), and "The Godless Girl" (1928). DeMille's trademark scenes included bathtubs, lion attacks, and Roman orgies. A number of his films featured scenes in two-color Technicolor. In 1923, DeMille released a modern melodrama "The Ten Commandments" which was a significant change from his previous stint of irreligious films. The film was produced on a large budget of $600,000, the most expensive production at Paramount. This concerned the executives at Paramount; however, the film turned out to be the studio's highest-grossing film. It held the Paramount record for twenty-five years until DeMille broke the record again himself.
In the early 1920s, scandal surrounded Paramount. Several Paramount contractees were accused of rape, murder, and drug addiction. Outcry intensified from religious groups and the media were appalled by immorality in the film industry on and off screen. A censorship board called the Hays Code was established. DeMille's depiction of on screen immorality came under fire, likely due to the scandalous film "The Affairs of Anatol". Furthermore, DeMille argued with Zukor over his extravagant and over-budget production costs. Consequently, DeMille left Paramount in 1924 despite having helped establish it. Instead, he joined the Producers Distributing Corporation.
His first film from his new production company, DeMille Pictures Corporation, was "The Road to Yesterday" in 1925. He directed and produced four films on his own, working with Producers Distributing Corporation because he found front office supervision too restricting. Aside from "The King of Kings" (which was said to be DeMille's favorite film), none of DeMille's films away from Paramount were successful. "The Kings of Kings" established DeMille as "master of the grandiose and of biblical sagas". The most successful Christian film of the silent era. DeMille calculated that the film had been viewed over 800 million times around the world. After the release of DeMille's "The Godless Girl", silent films in America became obsolete and DeMille was forced to shoot a shoddy final reel with the new sound production technique. Although this final reel looked so different from the previous eleven reels that it appeared to be from another movie, according to Simon Louvish, the film is one of DeMille's strangest and most "DeMillean" film.

The immense popularity of DeMille's silent films enabled him to branch out into other areas. The Roaring Twenties were the boom years and DeMille took full advantage, opening the Mercury Aviation Company, one of America's first commercial airlines. He was also a real estate speculator, an underwriter of political campaigns, and vice president of Bank of America. He was additionally vice president of the Commercial National Trust and Savings Bank in Los Angeles where he approved loans for other filmmakers. In 1916, DeMille purchased a mansion in Hollywood. Charlie Chaplin lived next door for a time, and after he moved, DeMille purchased the other house and combined the estates.

When "talking pictures" were invented in 1928, Cecil B. DeMille made a successful transition, offering his own innovations to the painful process; he devised a microphone boom and a soundproof camera blimp. He also popularized the camera crane. His first three sound films were produced at Metro-Goldwyn-Mayer. These three films, "Dynamite", "Madame Satan", and his 1931 remake of "The Squaw Man" were both critically and financially unsuccessful. He had completely adapted to the production of sound film besides despite the film's poor dialogue. After his contract ended at MGM, he left, but no production studios would hire him. He attempted to create a guild of a half a dozen directors with the same creative desires called the Director's Guild. However, the idea failed due to lack of funding and commitment. Moreover, DeMille was audited by the Internal Revenue Service due to issues with his production company. This was, according to DeMille, the lowest point of his career. DeMille traveled abroad to find employment until he was offered a deal at Paramount.

In 1932, DeMille returned to Paramount at the request of Lasky, bringing with him his own production unit. His first film back at Paramount, "The Sign of the Cross", was also his first success since leaving Paramount besides "The King of Kings". DeMille's return was approved by Zukor under the condition that DeMille not exceed his production budget of $650,000 for "The Sign of the Cross". Produced in eight weeks without exceeding budget, the film was financially successful. "The Sign of the Cross" was the first film to integrate all cinematic techniques. The film was considered a "masterpiece" and surpassed the quality of other sound films of the time. DeMille followed this epic uncharacteristically with two dramas released in 1933 and 1934. "This Day and Age" and "Four Frightened People" were box office disappointments, though "Four Frightened People" received good reviews. DeMille would stick to his large-budget spectaculars for the rest of his career.

Cecil B. DeMille was a conservative Republican activist. He became more conservative as he aged, until he became a "pillar of California's political right-wing". However, he lived two different lives. On the one hand, DeMille lived a life of strong Christian ethics, as exemplified through his wife and children. On the other hand, DeMille's private life, which included mistresses and adultery, conflicted with the Episcopalian integrity he portrayed. Additionally, he frequently contradicted his staunchly conservative viewpoints. His film "The Volga Boatman" gave a sympathetic portrayal of the Russian Revolution and he was fascinated by a trip to the Soviet Union in the 1930s. More in line with his conservative views, he was known as anti-union and worked to prevent unionizing of film production studios. However, according to DeMille himself, he was not anti-union and belonged to a few unions himself. He said he was rather against union leaders such as Walter Reuther and Harry Bridges whom he compared to dictators. He supported Herbert Hoover and in 1928 made his largest campaign donation to Hoover. However, in a contradiction, DeMille liked Franklin D. Roosevelt, finding him charismatic, tenacious, and intelligent. He agreed with Roosevelt's abhorrence of Prohibition. DeMille lent Roosevelt a car for his campaign for the 1932 United States presidential election and voted for him. However, he would never again vote for a Democratic candidate in a presidential election.

From June 1, 1936, until January 22, 1945, Cecil B. DeMille hosted and directed "Lux Radio Theater", a weekly digest of current feature films. Broadcast on the Columbia Broadcasting System (CBS) from 1935 to 1954, the Lux Radio show was one of the most popular weekly shows in the history of radio. While DeMille was host, the show had forty million weekly listeners, gaining DeMille an annual salary of $100,000. From 1936 to 1945, he produced, hosted, and directed all shows with the occasional exception of a guest director. He resigned from the Lux Radio Show because he refused to pay a dollar to the American Federation of Radio Artists (AFRA) because he did not believe that any organization had the right to "levy a compulsory assessment upon any member." Consequently, he had to resign from the radio show.

DeMille sued the union for reinstatement but lost. He then appealed to the California Supreme Court and lost again. When the AFRA expanded to television, DeMille was banned from television appearances. Consequently, he formed the DeMille Foundation for Political Freedom in order to campaign for the right to work. He began presenting speeches across the United States for the next few years. DeMille's primary criticism was of closed shops, but later included criticism of communism and unions in general. The United States Supreme Court declined to review his case. Despite his loss, DeMille continued to lobby for the Taft–Hartley Act, which passed. This prohibited denying anyone the right to work if they refuse to pay a political assessment, however, the law did not apply retroactively. Consequently, DeMille's television and radio appearance ban lasted for the remainder of his life, though he was permitted to appear on radio or television to publicize a movie. William Keighley was his replacement. DeMille would never again work on radio. 

In 1939, DeMille's "Union Pacific" was successful through DeMille's collaboration with the Union Pacific Railroad. The Union Pacific gave DeMille access to historical data, early period trains, and expert crews, adding to the authenticity of the film. During pre-production of "Union Pacific", DeMille was dealing with his first serious health issue. In March 1938, He underwent a major emergency prostatectomy. He suffered from a post-surgery infection from which he nearly did not recover, citing streptomycin as his saving grace. The surgery caused him to suffer from sexual dysfunction for the rest of his life, according to some family members. Following his surgery and the success of "Union Pacific", in 1940, DeMille first used three-strip Technicolor in "North West Mounted Police". DeMille wanted to film in Canada; however, due to budget constraints, the film was instead shot in Oregon and Hollywood. Critics were impressed with the visuals but found the scripts dull, calling it DeMille's "poorest Western". Despite the criticism, it was Paramount's highest-grossing film of the year. Audiences liked its highly saturated color, so DeMille made no further black-and-white features. DeMille was anti-communist and abandoned a project in 1940 to film Ernest Hemingway's "For Whom the Bell Tolls" due to its communist themes despite the fact he had already paid $100,000 for the rights to the novel. He was so eager to produce the film, that he hadn't yet read the novel. He claimed he abandoned the project in order to complete a different project, but in reality, it was to preserve his reputation and avoid appearing reactionary. While concurrently filmmaking, he served in World War II at the age of sixty as his neighborhood air-raid warden.

In 1942, DeMille worked with Jeanie MacPherson and brother William deMille in order to produce a film called "Queen of Queens" which was intended to be about Mary, mother of Jesus. After reading the screenplay, Daniel A. Lord warned DeMille that Catholics would find the film too irreverent, while non-Catholics would have considered the film Catholic propaganda. Consequently, the film was never made. Jeanie MacPherson would work as a scriptwriter for many of DeMille's films. In 1938, DeMille supervised the compilation of film "Land of Liberty" to represent the contribution of the American film industry to the 1939 New York World's Fair. DeMille used clips from his own films in "Land of Liberty". Though the film was not high-grossing, it was well-received and DeMille was asked to shorten its running time to allow for more showings per day. MGM distributed the film in 1941 and donated profits to World War II relief charities.

In 1942, DeMille released Paramount's most successful film, "Reap the Wild Wind". It was produced with a large budget and contained many special effects including an electronically operated giant squid. After working on "Reap the Wild Wind", in 1944, he was the master of ceremonies at the massive rally organized by David O. Selznick in the Los Angeles Coliseum in support of the Dewey–Bricker ticket as well as Governor Earl Warren of California. DeMille's subsequent film "Unconquered" (1947) had the longest running time (146 minutes), longest filming schedule (102 days) and largest budget of $5 million. The sets and effects were so realistic that 30 extras needed to be hospitalized due to a scene with fireballs and flaming arrows. It was commercially very successful.

DeMille's next film, "Samson and Delilah" in 1949, became Paramount's highest-grossing film up to that time. A Biblical epic with sex, it was a characteristically DeMille film. Again, 1952's "The Greatest Show on Earth" became Paramount's highest-grossing film to that point. Furthermore, DeMille's film won the Academy Award for Best Picture and the Academy Award for Best Story. The film began production in 1949, Ringling Brothers-Barnum and Bailey were paid $250,000 for use of the title and facilities. DeMille toured with the circus while helping write the script. Noisy and bright, it was not well-liked by critics, but was a favorite among audiences. DeMille signed a contract with Prentice Hall publishers in August 1953 to publish an autobiography. DeMille would reminisce into a voice recorder, the recording would be transcribed, and the information would be organized in the biography based on the topic. Art Arthur also interviewed people for the autobiography. DeMille did not like the first draft of the biography, saying that he thought the person portrayed in the biography was an "SOB"; he said it made him sound too egotistical. Besides filmmaking and finishing his autobiography, DeMille was involved in other projects. In the early 1950s, DeMille was recruited by Allen Dulles and Frank Wisner to serve on the board of the anti-communist National Committee for a Free Europe, the public face of the organization that oversaw the Radio Free Europe service. In 1954, Secretary of the Air Force Harold E. Talbott asked DeMille for help in designing the cadet uniforms at the newly established United States Air Force Academy. DeMille's designs, most notably his design of the distinctive cadet parade uniform, won praise from Air Force and Academy leadership, were ultimately adopted, and are still worn by cadets.

In 1952, DeMille sought approval for a lavish remake of his 1923 silent film "The Ten Commandments". He went before the Paramount board of directors, which was mostly Jewish-American. The members rejected his proposal, even though his last two films, "Samson and Delilah" and "The Greatest Show on Earth", had been record-breaking hits. Adolph Zukor convinced the board to change their minds on the grounds of morality. DeMille did not have an exact budget proposal for the project, and it promised to be the most costly in U.S. film history. Still, the members unanimously approved it. "The Ten Commandments", released in 1956, was DeMille's final film. It was the longest (3 hours, 39 minutes) and most expensive ($13 million) film in Paramount history. Production of "The Ten Commandments" began in October 1954. The Exodus scene was filmed on-site in Egypt with the use of four Technicolor-VistaVision camera filming 12,000 people. They continued filming in 1955 in Paris and Hollywood on 30 different sound stages. They were even required to expand to RKO sound studios for filming. Post-production lasted a year and the film premiered in Salt Lake City. Nominated for an Academy Award for Best Picture, it grossed over $80 million, which surpassed the gross of "The Greatest Show on Earth" and every other film in history, except for "Gone with the Wind". A unique practice at the time, DeMille offered ten percent of his profit to the crew.

On November 7, 1954, while in Egypt filming the Exodus sequence for "The Ten Commandments", DeMille (who was seventy-three) climbed a ladder to the top of the massive Per Rameses set and suffered a serious heart attack. Despite the urging of his associate producer, DeMille wanted to return to the set right away. DeMille developed a plan with his doctor to allow him to continue directing while reducing his physical stress. Although DeMille completed the film, his health was diminished by several more heart attacks. His daughter Cecilia took over as director as DeMille sat behind the camera with Loyal Griggs as the cinematographer. This film would be his last. 

Due to his frequent heart attacks, DeMille asked his son-in-law, actor Anthony Quinn, to direct a remake of his 1938 film "The Buccaneer". DeMille served as executive producer, overseeing producer Henry Wilcoxon. Despite a cast led by Charlton Heston and Yul Brynner, the 1958 film "The Buccaneer" was a disappointment. DeMille attended the Santa Barbara premiere of "The Buccaneer" in December 1958. DeMille was unable to attend the Los Angeles premiere of "The Buccaneer". In the months before his death, DeMille was researching a film biography of Robert Baden-Powell, the founder of the Scout Movement. DeMille asked David Niven to star in the film, but it was never made. DeMille also was planning a film about the space race as well as another biblical epic about the Book of Revelation. DeMille's autobiography was mostly completed by the time DeMille died and was published in November 1959.

 Cecil B. DeMille suffered a series of heart attacks from June 1958 to January 1959, and died on January 21, 1959, following an attack. DeMille's funeral was held on January 23 at St. Stephen's Episcopal Church. He was entombed at the Hollywood Memorial Cemetery (now known as Hollywood Forever). After his death, notable news outlets such as "The New York Times", "Los Angeles Times", and "The Guardian" honored DeMille as "pioneer of movies", "the greatest creator and showman of our industry", and "the founder of Hollywood". DeMille left his multi-million dollar estate in Los Feliz, Los Angeles in Laughlin Park to his daughter Cecilia because his wife had dementia and was unable to care for an estate. She would die one year later. His personal will drew a line between Cecilia and his three adopted children, with Cecilia receiving a majority of DeMille's inheritance and estate. The other three children were surprised by this, as DeMille did not treat the children differently in life. Cecilia lived in the house for many years but auctioned the house in the late 1980s.

DeMille believed his first influences to be his parents, Henry and Beatrice DeMille. His playwright father introduced him to the theater at a young age. Henry was heavily influenced by the work of Charles Kingsley whose ideas trickled down to DeMille. DeMille noted that his mother had a "high sense of the dramatic" and was determined to continue the artistic legacy of her husband after he died. Beatrice became a play broker and author's agent, influencing DeMille's early life and career. DeMille's father worked with David Belasco theatrical producer, impresario, and playwright. Belasco was known for adding realistic elements in his plays such as real flowers, food, and aromas that could transport his audiences into the scenes. While working in theatre, DeMille used real fruit trees in his play "California" as influenced by Belasco. Similar to Belasco, DeMille's theatre was revolved around entertainment, rather than artistry. Generally, Belasco's influence of DeMille's career can be seen in DeMille's showmanship and narration. E.H. Sothern's early influence on DeMille's work can be seen in DeMille's perfectionism. DeMille recalled that one of the most influential plays he saw was "Hamlet", directed by Sothern.

DeMille's filmmaking process always began with extensive research. Next, he would work with writers to develop the story that he was envisioning. Then, he would help writers construct a script. Finally, he would leave the script with artists and allow them to create artistic depictions and renderings of each scene. Plot and dialogue was not a strong point of DeMille's films. Consequently, he focused his efforts on his films' visuals. He worked with visual technicians, editors, art directors, costume designers, cinematographers, and set carpenters in order to perfect the visual aspects of his films. With his editor, Anne Bauchens, DeMille used editing techniques to allow the visual images to bring the plot to climax rather than dialogue. DeMille had large and frequent office conferences to discuss and examine all aspects of the working film including story-boards, props, and special effects.

DeMille rarely gave direction to actors; he preferred to "office-direct" where he would work with actors in his office, going over characters and reading through scripts. Any problems on the set were often fixed by writers in the office rather than on the set. DeMille did not believe a large movie set was the place to discuss minor character or line issues. DeMille was particularly adept at directing and managing large crowds in his films. Martin Scorsese recalled that DeMille had the skill to maintain control of not only the lead actors in a frame but the many extras in the frame as well. DeMille was adept at directing "thousands of extras", and many of his pictures include spectacular set pieces: the toppling of the pagan temple in "Samson and Delilah"; train wrecks in "The Road to Yesterday", "Union Pacific" and "The Greatest Show on Earth"; the destruction of an airship in "Madam Satan"; and the parting of the Red Sea in both versions of "The Ten Commandments".

DeMille experimented in his early films with photographic light and shade which created dramatic shadows instead of glare. His specific use of lighting, influenced by his mentor David Belasco, was for the purpose of creating "striking images" and heightening "dramatic situations". DeMille was unique in using this technique. In addition to his use of volatile and abrupt film editing, his lighting and composition were innovative for the time period as filmmakers were primarily concerned with a clear, realistic image. Another important aspect of DeMille's editing technique was to put the film away for a week or two after an initial edit in order to re-edit the picture with a fresh mind. This allowed for the rapid production of his films in the early years of the Lasky Company. The cuts were sometimes rough, but the movies were always interesting.

DeMille often edited in a manner that favored psychological space rather than physical space through his cuts. In this way, the characters' thoughts and desires are the visual focus rather than the circumstances regarding the physical scene. As DeMille's career progressed, he increasingly relied on artist Dan Sayre Groesbeck's concept, costume, and storyboard art. Groesbeck's art was circulated on set to give actors and crew members a better understanding of DeMille's vision. His art was even shown at Paramount meetings when pitching new films. DeMille adored the art of Groesbeck, even hanging it above his fireplace, but film staff found it difficult to convert his art into three-dimensional sets. As DeMille continued to rely on Groesbeck, the nervous energy of his early films transformed into more steady compositions of his later films. While visually appealing, this made the films appear more old-fashioned.

Composer Elmer Bernstein described DeMille as, "sparing no effort", when filmmaking. Bernstein recalled that DeMille would scream, yell, or flatter, whatever it took to achieve the perfection he required in his films. DeMille was painstakingly attentive to details on set and was as critical of himself as he was of his crew. Costume designer Dorothy Jenkins, who worked with DeMille on "The Ten Commandments" (1956), described that DeMille was skilled in humiliating people. Jenkins admitted that she received quality training from DeMille, but that it was necessary to become a perfectionist on a DeMille set to avoid being fired. DeMille had an authoritarian persona on set; he required absolute attention from the cast and crew. He had a band of assistants who catered to his needs. He would speak to the entire set, sometimes enormous with countless numbers of crew members and extras, via a microphone to maintain control of the set. He was disliked by many inside and outside of the film industry due to his cold and controlling reputation.

DeMille was known for autocratic behavior on the set, singling out and berating extras who were not paying attention. A number of these displays were thought to be staged, however, as an exercise in discipline. He despised actors who were unwilling to take physical risks, especially when he had first demonstrated that the required stunt would not harm them. This occurred with Victor Mature in "Samson and Delilah". Mature refused to wrestle Jackie the Lion, even though DeMille had just tussled with the lion, proving that he was tame. DeMille told the actor that he was "one hundred percent yellow". Paulette Goddard's refusal to risk personal injury in a scene involving fire in "Unconquered" cost her DeMille's favor and a role in "The Greatest Show on Earth". DeMille did receive help in his films, notably from Alvin Wyckoff who shot forty-three of DeMille's films; brother William deMille who would occasionally serve as his screenwriter; and Jeanie Macpherson, who served as DeMille's exclusive screenwriter for fifteen years; and Eddie Salven, DeMille's favorite assistant director.

DeMille made stars of unknown actors: Gloria Swanson, Bebe Daniels, Rod La Rocque, William Boyd, Claudette Colbert, and Charlton Heston. He also cast established stars such as Gary Cooper, Robert Preston, Paulette Goddard and Fredric March in multiple pictures. DeMille displayed a loyalty to his performers, casting them repeatedly including: Henry Wilcoxon, Julia Faye, Joseph Schildkraut, Ian Keith, Charles Bickford, Theodore Roberts, Akim Tamiroff and William Boyd. DeMille was credited by actor Edward G. Robinson with saving his career following his eclipse in the Hollywood blacklist.

Cecil B. DeMille's film production career evolved from critically significant silent films to financially significant sounds films. He began his career with reserved yet brilliant melodramas. From there, DeMille's style developed into marital comedies with outrageously melodramatic plots. In order to attract a high-class audience, DeMille based many of his early films on stage melodramas, novels, and short stories. He began the production of epics earlier in his career until they began to solidify his career in the 1920s. By 1930, DeMille had perfected his film style of mass-interest spectacle films with Western, Roman, or Biblical themes. DeMille was often criticized for making his spectacles too colorful and for being too occupied with entertaining the audience rather than accessing the artistic and auteur possibilities that film could provide. However, others interpreted DeMille's work as visually impressive, thrilling, and nostalgic. Along the same lines, critics of DeMille often qualify him by his later spectacles and fail to consider several decades of ingenuity and energy that defined him during his generation. Throughout his career, he did not alter his films to better adhere to contemporary or popular styles. Actor Charlton Heston admitted DeMille was, "terribly unfashionable" and Sidney Lumet called Demille, "the cheap version of D.W. Griffith," adding that DeMille, "[didn't have]...an original thought in his head," though Heston added that DeMille was much more than that.

According to Scott Eyman, DeMille's films were at the same time masculine and feminine due to his thematic adventurousness and his eye for the extravagant. DeMille's distinctive style can be seen through camera and lighting effects as early as "The Squaw Man" with the use of daydream images; moonlight and sunset on a mountain; and side-lighting through a tent flap. In the early age of cinema, DeMille differentiated the Lasky Company from other production companies due to the use of dramatic, low-key lighting they called "Lasky lighting" and marketed as "Rembrandt lighting" to appeal to the public. DeMille achieved international recognition for his unique use of lighting and color tint in his film "The Cheat". DeMille's 1956 version of "The Ten Commandments", according to director Martin Scorsese, is renowned for its level of production and the care and detail that went into creating the film. He stated that "The Ten Commandments" was the final culmination of DeMille's style.

DeMille was interested in art and his favorite artist was Gustave Doré; DeMille based some of his most well-known scenes on the work of Doré. DeMille was the first director to connect art to filmmaking; he created the title of "art director" on the film set. DeMille was also known for his use of special effects without the use of digital technology. Notably, DeMille had cinematographer John P. Fulton create the parting of the Red Sea scene in his 1956 film "The Ten Commandments", which was one of the most expensive special effects in film history, and has been called by Steven Spielberg "the greatest special effect in film history". The actual parting of the sea was created by releasing 360,000 gallons of water into a huge water tank split by a U-shaped trough, overlaying it with film of a giant waterfall that was built on the Paramount backlot, and playing the clip backwards.

Aside from his Biblical and historical epics which are concerned with how man relates to God, some of DeMille's films contained themes of "neo-naturalism" which portray the conflict between the laws of man and the laws of nature. Although he is known for his later "spectacular" films, his early films are held in high regard by critics and film historians. DeMille discovered the possibilities of the "bathroom" or "boudoir" in film without being "vulgar" or "cheap". DeMille's films "Male and Female", "Why Change Your Wife?", and "The Affairs of Anatol" can be retrospectively described as high camp and are categorized as "early DeMille films" due to their particular style of production and costume and set design. However, his earlier films "The Captive", "Kindling", "Carmen", and "The Whispering Chorus" are more serious films. It is difficult to typify DeMille's films into one specific genre. His first three films were Westerns, and he filmed many Westerns throughout his career. However, throughout his career, he filmed comedies, periodic and contemporary romances, dramas, fantasies, propaganda, Biblical spectacles, musical comedies, suspense, and war films. At least one DeMille film can represent each film genre. DeMille produced the majority of his films before the 1930s, and by the time sound films were invented, film critics saw DeMille as antiquated, with his best filmmaking years behind him.

DeMille's film contained a number of similar themes throughout his career. However, the films of his silent era were often thematically different than the films of his sound era. His silent era films often included the "battle of the sexes" theme due to the era of women's suffrage and the enlarging role of women in society. Moreover, before his religious-themed films, many of his silent era films revolved around "husband-and-wife-divorce-and-remarry satires", considerably more adult-themed. According to Simon Louvish, these films reflected DeMille's inner thoughts and opinions about marriage and human sexuality. Religion was a theme that DeMille returned to throughout his career. Of his seventy films, five revolved around stories of the Bible and the New Testament; however many others, while not direct retellings of Biblical stories, had themes of faith and religious fanaticism in films such as "The Crusades" and "The Road to Yesterday". Western and frontier American were also themes that DeMille returned to throughout his career. His first several films were westerns and he produced a chain of westerns during the sound era. Instead of portraying the danger and anarchy of the West, he portrayed the opportunity and redemption found in Western America. Another common theme in DeMille's films is the reversal of fortune and the portrayal of the rich and the poor, including the war of the classes and man versus society conflicts such as in "The Golden Chance" and "The Cheat". In relation to his own interests and sexual preferences, sadomasochism was a minor theme present in some of his films. Another minor characteristic of DeMille's films include train crashes which can be found in several of his films.

Known as the father of the Hollywood motion picture industry, Cecil B. DeMille made 70 films including several box-office hits. DeMille is one of the more commercially successful film directors in history with his films before the release of "The Ten Commandments" estimated to have grossed $650 million worldwide. Adjusted for inflation, DeMille's remake of "The Ten Commandments" is the eighth highest-grossing film in the world.

According to Sam Goldwyn, critics did not like DeMille's films, but the audiences did and "they have the final word". Similarly, scholar David Blanke, argued that DeMille had lost the respect of his colleagues and film critics by his late film career. However, his final films maintained that DeMille was still respected by his audiences. Five of DeMille's film were the highest-grossing films at the year of their release, with only Spielberg topping him with six of his films as the highest-grossing films of the year. DeMille's highest-grossing films include: "The Sign of the Cross" (1932), "Unconquered" (1947), "Samson and Delilah" (1949), "The Greatest Show on Earth" (1952), and "The Ten Commandments" (1956). Director Ridley Scott has been called "the Cecil B. DeMille of the digital era" due to his classical and medieval epics.

Despite his box-office success, awards, and artistic achievements, DeMille has been dismissed and ignored by critics both during his life and posthumously. He consistently was criticized for producing shallow films without talent or artistic care. Compared to other directors, few film scholars have taken the time to academically analyze his films and style. During the French New Wave, critics began to categorize certain filmmakers as auteurs such as Howard Hawks, John Ford, and Raoul Walsh. DeMille was left off the list, determined to be too unsophisticated and antiquated to be considered an auteur. However, Simon Louvish wrote "he was the complete master and auteur of his films" and Anton Kozlovic called him the "unsung American auteur". Andrew Sarris, a leading proponent of the auteur theory, ranked DeMille highly as an auteur in the "Far Side of Paradise", just below the "Pantheon". Sarris added that despite the influence of styles of contemporary directors throughout his career, DeMille's style remained unchanged. Robert Birchard wrote one could argue auteurship of DeMille on the basis that DeMille's thematic and visual style remained consistent throughout his career. However, Birchard acknowledged that Sarris's point was more likely that DeMille's style was behind the development of film as an art form. Meanwhile, Sumiko Higashi sees DeMille as "not only a figure who was shaped and influenced by the forces of his era but as a filmmaker who left his own signature on the culture industry." The critic Camille Paglia has called "The Ten Commandments" one of the ten greatest films of all time.

DeMille was one of the first directors to become a celebrity in his own right. He cultivated the image of the omnipotent director, complete with megaphone, riding crop, and jodhpurs. He was known for his unique, working wardrobe which included riding boots, riding pants, and soft, open necked shirts. Joseph Henabery recalled that DeMille looked like "a king on a throne surrounded by his court" while directing films on a camera platform.

DeMille was respected by his peers, yet his individual films were sometimes criticized. "Directorially, I think his pictures were the most horrible things I've ever seen in my life", said director William Wellman. "But he put on pictures that made a fortune. In that respect, he was better than any of us", Wellman added. Producer David O. Selznick wrote: "There has appeared only one Cecil B. DeMille. He is one of the most extraordinarily able showmen of modern times. However much I may dislike some of his pictures, it would be very silly of me, as a producer of commercial motion pictures, to demean for an instant his unparalleled skill as a maker of mass entertainment." Salvador Dalí wrote that DeMille, Walt Disney and the Marx Brothers were "the three great American Surrealists". DeMille appeared as himself in numerous films, including the MGM comedy "Free and Easy". He often appeared in his coming-attraction trailers and narrated many of his later films, even stepping on screen to introduce "The Ten Commandments". DeMille was immortalized in Billy Wilder's "Sunset Boulevard" when Gloria Swanson spoke the line: "All right, Mr. DeMille. I'm ready for my close-up." DeMille plays himself in the film. DeMille's reputation had a renaissance in the 2010s.

As a filmmaker, DeMille was the aesthetic inspiration of many directors and films due to his early influence during the crucial development of the film industry. DeMille's early silent comedies influenced the comedies of Ernst Lubitsch and Charlie Chaplin's "A Woman of Paris". Additionally, DeMille's epics such as "The Crusades" influenced Sergei Eisenstein's "Alexander Nevsky". Moreover, DeMille's epics inspired directors such as Howard Hawks, Nicholas Ray, Joseph L. Mankiewicz, and George Stevens to try producing epics. Cecil B. DeMille has influenced the work of several well-known directors. Alfred Hitchcock cited DeMille's 1921 film "Forbidden Fruit" as an influence of his work and one of his top ten favorite films. DeMille has influenced the careers of many modern directors. Martin Scorsese cited "Unconquered", "Samson and Delilah", and "The Greatest Show on Earth" as DeMille films that have imparted lasting memories on him. Scorsese said he had viewed "The Ten Commandments" forty or fifty times. Famed director Steven Spielberg stated that DeMille's "The Greatest Show on Earth" was one of the films that influenced him to become a filmmaker. Furthermore, DeMille influenced about half of Spielberg's films, including "War of the Worlds". "The Ten Commandments" inspired DreamWorks Animation's later film about Moses, "The Prince of Egypt". As one of the establishing members of the Paramount Pictures and co-founder of Hollywood, DeMille had a role in the development of the film industry. Consequently, the name "DeMille" has become synonymous with filmmaking.

Publicly Episcopalian, DeMille drew on his Christian and Jewish heritage to convey a message of tolerance. DeMille received more than a dozen awards from Jewish religious and cultural groups, including B'nai B'rith. However, not everyone received DeMille's religious films favorably. DeMille was accused of antisemitism after the release of "The King of Kings", and director John Ford despised DeMille for what he saw as "hollow" biblical epics meant to promote DeMille's reputation during the politically turbulent 1950s. In response to the claims, DeMille donated some of the profits from "The King of Kings" to charity. In the 2012 "Sight & Sound" poll, both DeMille's "Samson and Delilah" and 1923 version of "The Ten Commandments" received votes, but did not make the top 100 films. Although many of DeMille's films are available on DVD and Blu-ray release, only 20 of his silent films are commercially available on DVD 

The original Lasky-DeMille Barn in which "The Squaw Man" was filmed was converted into a museum named the "Hollywood Heritage Museum". It opened on December 13, 1985 and features some of DeMille's personal artifacts. The Lasky-DeMille Barn was dedicated as a California historical landmark in a ceremony on December 27, 1956; DeMille was the keynote speaker. and was listed on the National Register of Historic Places in 2014. The Dunes Center in Guadalupe, California contains an exhibition of artifacts uncovered in the desert near Guadalupe from DeMille's set of his 1923 version of "The Ten Commandments", known as the "Lost City of Cecil B. DeMille". Donated by the Cecil B. DeMille Foundation in 2004, the moving image collection of Cecil B. DeMille is held at the Academy Film Archive and includes home movies, outtakes, and never-before-seen test footage.

In summer 2019, The Friends of the Pompton Lakes Library hosted a Cecil B DeMille film festival to celebrate DeMille's achievements and connection to Pompton Lakes. They screened four of his films at Christ Church, where DeMille and his family attended church when they lived there. Two schools have been named after him: Cecil B. DeMille Middle School, in Long Beach, California, which was closed and demolished in 2010 to make way for a new high school; and Cecil B. DeMille Elementary School in Midway City, California. The former film building at Chapman University in Orange, California, is named in honor of DeMille. During the Apollo 11 mission, Buzz Aldrin refers to himself in one instance as "Cecil B. DeAldrin", as a humorous nod to DeMille. The title of the 2000 John Waters film "Cecil B. Demented" alludes to DeMille.

DeMille's legacy is maintained by his granddaughter Cecilia DeMille Presley who serves as the president of the Cecil B. DeMille Foundation, which strives to support higher education, child welfare, and film in Southern California. In 1963, the Cecil B. DeMille Foundation donated the "Paradise" ranch to the Hathaway Foundation, which cares for emotionally disturbed and abused children. A large collection of DeMille's materials including scripts, storyboards, and films resides at Brigham Young University in L. Tom Perry Special Collections.

Cecil B. DeMille received many awards and honors, especially later in his career. The American Academy of Dramatic Arts honored DeMille with an Alumni Achievement Award in 1958. In 1957, DeMille gave the commencement address for the graduation ceremony of Brigham Young University wherein he received an honorary Doctorate of Letter degree. Additionally, in 1958, he received an honorary Doctorate of Law degree from Temple University. From the film industry, DeMille received the Irving G. Thalberg Memorial Award at the Academy Awards in 1953, and a Lifetime Achievement Award from the Directors Guild of America Award the same year. In the same ceremony, DeMille received a nomination from Directors Guild of America Award for Outstanding Directorial Achievement in Motion Pictures for "The Greatest Show on Earth". In 1952, DeMille was awarded the first Cecil B. DeMille Award at the Golden Globes. An annual award, the Golden Globe's Cecil B. DeMille Award recognizes lifetime achievement in the film industry. For his contribution to the motion picture and radio industry, DeMille has two stars on the Hollywood Walk of Fame. The first, for radio contributions, is located at 6240 Hollywood Blvd. The second star is located at 1725 Vine Street.

DeMille received two Academy Awards: an Honorary Award for "37 years of brilliant showmanship" in 1950 and a Best Picture award in 1953 for "The Greatest Show on Earth". DeMille received a Golden Globe Award for Best Director and was additionally nominated for the Best Director category at the 1953 Academy Awards for the same film. He was further nominated in the Best Picture category for "The Ten Commandments" at the 1957 Academy Awards. DeMille's "Union Pacific" received a Palme d'Or in retrospect at the 2002 Cannes Film Festival.

Two of DeMille's films have been selected for preservation in the National Film Registry by the United States Library of Congress: "The Cheat" (1915) and "The Ten Commandments" (1956).

Cecil B. DeMille made 70 features. Fifty-two of his features are silent films. The first 24 of his silent films were made in the first three years of his career (1913-1916). Eight of his films were "epics" with five of those classified as "Biblical". Seven of DeMille's films including "The Arab", "The Wild Goose Chase", "Chimmie Fadden", "The Dream Girl", "The Devil-Stone", "We Can't Have Everything", and "The Squaw Man" (1918) were destroyed due to nitrate decomposition and are considered lost. "The Ten Commandments" is broadcast every Saturday at Passover in the United States on the ABC Television Network.

Filmography obtained from "Fifty Hollywood Directors".

Silent films

Sound films
These films represent those which DeMille produced or assisted in directing, credited or uncredited.

DeMille frequently made cameos as himself in other Paramount films. Additionally, he often starred in prologues and special trailers that he created for his films, having an opportunity to personally address the audience.





</doc>
<doc id="6181" url="https://en.wikipedia.org/wiki?curid=6181" title="Chinese Islamic cuisine">
Chinese Islamic cuisine

Cuisine of Chinese Muslims (, Dungan: Чыңжән цаы or , Dungan: Ҳуэйзў цаы) is the cuisine of the Hui (ethnic Chinese Muslims) and other Muslims living in China such as Bonan, Dongxiang, Salar and Uyghurs as well as Dungans of Central Asia.
Due to the large Muslim population in Western China, many Chinese restaurants cater to or are run by, Muslims. Northern Chinese Islamic cuisine originated in China proper. It is heavily influenced by Beijing cuisine, with nearly all cooking methods identical and differs only in material due to religious restrictions. As a result, northern Islamic cuisine is often included in home Beijing cuisine though seldom in east coast restaurants.

During the Yuan dynasty, halal and kosher methods of slaughtering animals and preparing food was banned and forbidden by the Mongol emperors, starting with Genghis Khan who banned Muslims and Jews from slaughtering their animals their own way and made them follow the Mongol method.
Among all the [subject] alien peoples only the Hui-hui say “we do not eat Mongol food”. [Cinggis Qa’an replied:] “By the aid of heaven we have pacified you; you are our slaves. Yet you do not eat our food or drink. How can this be right?” He thereupon made them eat. “If you slaughter sheep, you will be considered guilty of a crime.” He issued a regulation to that effect ... [In 1279/1280 under Qubilai] all the Muslims say: “if someone else slaughters [the animal] we do not eat”. Because the poor people are upset by this, from now on, Musuluman [Muslim] Huihui and Zhuhu [Jewish] Huihui, no matter who kills [the animal] will eat [it] and must cease slaughtering sheep themselves, and cease the rite of circumcision.
Traditionally, there is a distinction between Northern and Southern Chinese Islamic cuisine despite both using lamb and mutton. Northern Chinese Islamic cuisine relies heavily on beef, but rarely ducks, geese, shrimp or seafood, while southern Islamic cuisine is the reverse. The reason for this difference is due to availability of the ingredients. Oxen have been long used for farming and Chinese governments have frequently strictly prohibited the slaughter of oxen for food. However, due to the geographic proximity of the northern part of China to minority-dominated regions that were not subjected to such restrictions, beef could be easily purchased and transported to Northern China. At the same time, ducks, geese and shrimp are rare in comparison to Southern China due to the arid climate of Northern China.

A Chinese Islamic restaurant () can be similar to a Mandarin restaurant with the exception that there is no pork on the menu and is primarily noodle/soup based.

In most major eastern cities in China, there are very limited Islamic/Halal restaurants, which are typically run by migrants from Western China (e.g., Uyghurs). They primarily offer inexpensive noodle soups only. These restaurants are typically decorated with Islamic motifs such as pictures of Islamic rugs and Arabic writing.

Another difference is that lamb and mutton dishes are more commonly available than in other Chinese restaurants, due to the greater prevalence of these meats in the cuisine of Western Chinese regions. (Refer to image 1.)

Other Muslim ethnic minorities like the Bonan, Dongxiang, Salar and Tibetan Muslims have their own cuisines as well. Dongxiang people operate their own restaurants serving their cuisine.

Many cafeterias (canteens) at Chinese universities have separate sections or dining areas for Muslim students (Hui or Western Chinese minorities), typically labeled "qingzhen." Student ID cards sometimes indicate whether a student is Muslim and will allow access to these dining areas or will allow access on special occasions such as the Eid feast following Ramadan.

Several Hui restaurants serving Chinese Islamic cuisine exist in Los Angeles. San Francisco, despite its huge number of Chinese restaurants, appears to have only one whose cuisine would qualify as halal.

Many Chinese Hui Muslims who moved from Yunnan to Burma (Myanmar) are known as Panthays operate restaurants and stalls serving Chinese Islamic cuisine such as noodles. Chinese Hui Muslims from Yunnan who moved to Thailand are known as Chin Haw and they also own restaurants and stalls serving Chinese Islamic food.
In Central Asia, Dungan people, descendants of Hui, operate restaurants serving Chinese Islamic cuisine which is respectively referred to as "Dungan cuisine" there. They cater to Chinese businessmen. Chopsticks are used by Dungans. The cuisine of the Dungan resembles northwestern Chinese cuisine.

Most Chinese regard Hui halal food as cleaner than food made by non-Muslims so their restaurants are popular in China. Hui who migrated to Northeast China (Manchuria) after the Chuang Guandong opened many new inns and restaurants to cater to travelers, which were regarded as clean.

The Hui who migrated to Taiwan operate Qingzhen restaurants and stalls serving Chinese Islamic cuisine in Taipei and other big cities.

The Thai Department of Export Promotion claims that "China's halal food producers are small-scale entrepreneurs whose products have little value added and lack branding and technology to push their goods to international standards" to encourage Thai private sector halal producers to market their products in China.

A 1903 started franchise which serves Muslim food is Dong Lai Shun in Hankou.

400 meters have to be kept as a distance from each restaurant serving beef noodles to another of its type if they belong to Hui Muslims, since Hui have a pact between each other in Ningxia, Gansu and Shaanxi.

Halal restaurants are checked up upon by clerics from mosques.

Halal food manufacture has been sanctioned by the government of the Ningxia Autonomous Region.

Lamian (, Dungan: Ламян) is a Chinese dish of hand-made noodles, usually served in a beef or mutton-flavored soup (湯麪, даңмян, tāngmiàn), but sometimes stir-fried (炒麪, Чаомян, chǎomiàn) and served with a tomato-based sauce. Literally, 拉, ла (lā) means to pull or stretch, while 麪, мян (miàn) means noodle. The hand-making process involves taking a lump of dough and repeatedly stretching it to produce a single very long noodle.

Words that begin with L are not native to Turkic — läghmän is a loanword as stated by Uyghur linguist Abdlikim: It is of Chinese derivation and not originally Uyghur.

Beef noodle soup is a noodle soup dish composed of stewed beef, beef broth, vegetables and wheat noodles. It exists in various forms throughout East and Southeast Asia. It was created by the Hui people during the Tang dynasty of China.

In the west, this food may be served in a small portion as a soup. In China, a large bowl of it is often taken as a whole meal with or without any side dish.

Chuanr (Chinese: 串儿, Dungan: Чўанр, Pinyin: chuànr (shortened from "chuan er"), ""kebab""), originating in the Xinjiang (新疆) province of China and in recent years has been disseminated throughout the rest of that country, most notably in Beijing. It is a product of the Chinese Islamic cuisine of the Uyghur (维吾尔) people and other Chinese Muslims. Yang rou chuan or lamb kebabs, is particularly popular.

Suan cai is a traditional fermented vegetable dish, similar to Korean kimchi and German sauerkraut, used in a variety of ways. It consists of pickled Chinese cabbage. Suan cai is a unique form of pao cai due to the material used and the method of production. Although "suan cai" is not exclusive to Chinese Islamic cuisine, it is used in Chinese Islamic cuisine to top off noodle soups, especially beef noodle soup.

"Nang" (Chinese: 馕, Dungan: Нәң) is a type of round unleavened bread, topped with sesame. It is similar to South and Central Asia naan.



</doc>
<doc id="6182" url="https://en.wikipedia.org/wiki?curid=6182" title="Cantonese cuisine">
Cantonese cuisine

Cantonese cuisine or more accurately, Guangdong cuisine (), also known as Yue cuisine () refers to the cuisine of the Guangdong province of China (particularly the provincial capital, Guangzhou, and the surrounding regions in the Pearl River Delta, including Hong Kong and Macau). "Cantonese" specifically refers to only Guangzhou or the language known as Cantonese associated with it, but people generally refer to "Cantonese cuisine" to all the cooking styles of the speakers of Yue Chinese languages from within Guangdong. The Teochew cuisine and Hakka cuisine of Guangdong are considered their own styles, as is neighboring Guangxi's cuisine despite also being considered culturally Cantonese. It is one of the Eight Culinary Traditions of Chinese cuisine. Its prominence outside China is due to the large number of Cantonese emigrants. Chefs trained in Cantonese cuisine are highly sought after throughout China. Until the late 20th century, most Chinese restaurants in the West served largely Cantonese dishes.

Guangzhou (Canton) City, the provincial capital of Guangdong and the center of Cantonese culture, has long been a trading hub and many imported foods and ingredients are used in Cantonese cuisine. Besides pork, beef and chicken, Cantonese cuisine incorporates almost all edible meats, including offal, chicken feet, duck's tongue, frog legs, snakes and snails. However, lamb and goat are less commonly used than in the cuisines of northern or western China. Many cooking methods are used, with steaming and stir frying being the most favoured due to their convenience and rapidity. Other techniques include shallow frying, double steaming, braising and deep frying.

For a lot of traditional Cantonese cooks, the flavours of a dish should be well balanced and not greasy. Apart from that, spices should be used in modest amounts to avoid overwhelming the flavours of the primary ingredients, and these ingredients in turn should be at the peak of their freshness and quality. There is no widespread use of fresh herbs in Cantonese cooking, in contrast with their liberal use in other cuisines such as Sichuanese, Vietnamese, Lao, Thai and European. Garlic chives and coriander leaves are notable exceptions, although the former are often used as a vegetable and the latter are usually used as mere garnish in most dishes.

In Cantonese cuisine, a number of ingredients such as sugar, salt, soy sauce, rice wine, cornstarch, vinegar, scallion and sesame oil, suffice to enhance flavour, although garlic is heavily used in some dishes, especially those in which internal organs, such as entrails, may emit unpleasant odours. Ginger, chili peppers, five-spice powder, powdered black pepper, star anise and a few other spices are also used, but often sparingly.

Although Cantonese cooks pay much attention to the freshness of their primary ingredients, Cantonese cuisine also uses a long list of preserved food items to add flavour to a dish. This may be influenced by Hakka cuisine, since the Hakkas were once a dominant group occupying imperial Hong Kong and other southern territories.

Some items gain very intense flavours during the drying/preservation/oxidation process and some foods are preserved to increase their shelf life. Some chefs combine both dried and fresh varieties of the same items in a dish. Dried items are usually soaked in water to rehydrate before cooking. These ingredients are generally not served "a la carte", but rather with vegetables or other Cantonese dishes.

A number of dishes have been part of Cantonese cuisine since the earliest territorial establishments of Guangdong. While many of these are on the menus of typical Cantonese restaurants, some simpler ones are more commonly found in Cantonese homes. Home-made Cantonese dishes are usually served with plain white rice.

There are a small number of deep-fried dishes in Cantonese cuisine, which can often be found as street food. They have been extensively documented in colonial Hong Kong records of the 19th and 20th centuries. A few are synonymous with Cantonese breakfast and lunch, even though these are also part of other cuisines.

Old fire soup, or "lou fo tong" (), is a clear broth prepared by simmering meat and other ingredients over a low heat for several hours. Chinese herbs are often used as ingredients. There are basically two ways to make old fire soup – put ingredients and water in the pot and heat it directly on fire, which is called "bou tong" (); or put the ingredients in a small stew pot, and put it in a bigger pot filled with water, then heat the bigger pot on fire directly, which is called "dun tong" (). The latter way can keep the most original taste of the soup.

Soup chain stores or delivery outlets in cities with significant Cantonese populations, such as Hong Kong, serve this dish due to the long preparation time required of slow-simmered soup.

Due to Guangdong's location along the South China Sea coast, fresh seafood is prominent in Cantonese cuisine, and many Cantonese restaurants keep aquariums or seafood tanks on the premises. In Cantonese cuisine, as in cuisines from other parts of Asia, if seafood has a repugnant odour, strong spices and marinating juices are added; the freshest seafood is odourless and, in Cantonese culinary arts, is best cooked by steaming. For instance, in some recipes, only a small amount of soy sauce, ginger and spring onion is added to steamed fish. In Cantonese cuisine, the light seasoning is used only to bring out the natural sweetness of the seafood. As a rule of thumb, the spiciness of a dish is usually inversely proportionate to the freshness of the ingredients.

Noodles are served either in soup broth or fried. These are available as home-cooked meals, on dim sum side menus, or as street food at dai pai dongs, where they can be served with a variety of toppings such as fish balls, beef balls, or fish slices.

"Siu mei" () is essentially the Chinese rotisserie style of cooking. Unlike most other Cantonese dishes, "siu mei" solely consists of meat, with no vegetables.

Lou mei () is the name given to dishes made from internal organs, entrails and other left-over parts of animals. It is widely available in southern Chinese regions.

All Cantonese-style cooked meats, including siu mei, lou mei and preserved meat can be classified as siu laap (). "Siu laap" also includes dishes such as:

A typical dish may consist of offal and half an order of multiple varieties of roasted meat. The majority of siu laap is white meat.

Little pot rice () are dishes cooked and served in a flat-bottomed pot (as opposed to a round-bottomed wok). Usually this is a saucepan or braising pan (see clay pot cooking). Such dishes are cooked by covering and steaming, making the rice and ingredients very hot and soft. Usually the ingredients are layered on top of the rice with little or no mixing in between. Many standard combinations exist.

A number of dishes are traditionally served in Cantonese restaurants only at dinner time. Dim sum restaurants stop serving bamboo-basket dishes after the yum cha period (equivalent to afternoon tea) and begin offering an entirely different menu in the evening. Some dishes are standard while others are regional. Some are customised for special purposes such as Chinese marriages or banquets. Salt and pepper dishes are one of the few spicy dishes.

After the evening meal, most Cantonese restaurants offer "tong sui" (), a sweet soup. Many varieties of "tong sui" are also found in other Chinese cuisines. Some desserts are traditional, while others are recent innovations. The more expensive restaurants usually offer their specialty desserts. Sugar water is the general name of dessert in Guangdong province. It is cooked by adding water and sugar to some other cooking ingredients. It is said that Huazhou sugar water is the famous and popular one in Guangdong. There is a saying that Chinese sugar water is in Guangdong, and Cantonese sugar water in Huazhou. And the booming of Huazhou sugar water stores prove it.

Certain Cantonese delicacies consist of parts taken from rare or endangered animals, which raises controversy over animal rights and environmental issues. This is often due to alleged health benefits of certain animal products. For example, the continued spreading of the idea that shark cartilage can cure cancer has led to decreased shark populations even though scientific research has found no evidence to support the credibility of shark cartilage as a cancer cure.




</doc>
<doc id="6183" url="https://en.wikipedia.org/wiki?curid=6183" title="Teochew cuisine">
Teochew cuisine

Teochew cuisine, also known as Chiuchow cuisine, Chaozhou cuisine or Chaoshan cuisine, originated from the Chaoshan region in the eastern part of China's Guangdong Province, which includes the cities of Chaozhou, Shantou and Jieyang. Teochew cuisine bears more similarities to that of Fujian cuisine, particularly Southern Min cuisine, due to the similarity of Chaoshan's and Fujian's culture, language, and their geographic proximity to each other. However, Teochew cuisine is also influenced by Cantonese cuisine in its style and technique.

Teochew cuisine is well known for its seafood and vegetarian dishes. Its use of flavouring is much less heavy-handed than most other Chinese cuisines and depends much on the freshness and quality of the ingredients for taste and flavour. As a delicate cuisine, oil is not often used in large quantities and there is a relatively heavy emphasis on poaching, steaming and braising, as well as the common Chinese method of stir-frying. Teochew cuisine is also known for serving congee (; or "mue"), in addition to steamed rice or noodles with meals. The Teochew "" is rather different from the Cantonese counterpart, being very watery with the rice sitting loosely at the bottom of the bowl, while the Cantonese dish is more a thin gruel.

Authentic Teochew restaurants serve very strong oolong tea called Tieguanyin in very tiny cups before and after the meal. Presented as "gongfu" tea, the tea has a thickly bittersweet taste, colloquially known as "gam gam" ().

A condiment that is popular in Fujian and Taiwanese cuisine and commonly associated with cuisine of certain Teochew groups is shacha sauce (). It is made from soybean oil, garlic, shallots, chilies, brill fish and dried shrimp. The paste has a savoury and slightly spicy taste. As an ingredient, it has multiple uses: as a base for soups, as a rub for barbecued meats, as a seasoning for stir-fried dishes, or as a component for dipping sauces.

In addition to soy sauce (widely used in all Chinese cuisines), the Teochew diaspora in Southeast Asia use fish sauce in their cooking. It is used as a flavouring agent in soups and sometimes as a dipping sauce, as in Vietnamese spring rolls.

Teochew chefs often use a special stock called superior broth (). This stock remains on the stove and is continuously replenished. Portrayed in popular media, some Hong Kong chefs allegedly use the same superior broth that is preserved for decades. This stock can as well be seen on Chaozhou TV's cooking programmes.

There is a notable feast in Teochew cuisine called "" (). A myriad of dishes are often served, which include shark fin soup, bird's nest soup, lobster, steamed fish, roasted suckling pig and braised goose.

Teochew chefs take pride in their skills of vegetable carving, and carved vegetables are used as garnishes on cold dishes and on the banquet table.

Teochew cuisine is also known for a late night meal known as "meh siao" () or "daa laang" () among the Cantonese. Teochew people enjoy eating out close to midnight in restaurants or at roadside food stalls. Some dai pai dong-like eateries stay open till dawn.

Unlike the typical menu selections of many other Chinese cuisines, Teochew restaurant menus often have a dessert section.

Many people of Chaoshan origin, also known as Teochiu or Teochew people, have settled in Hong Kong and places in Southeast Asia like Malaysia, Singapore, Cambodia and Thailand. Influences they bring can be noted in Singaporean cuisine and that of other settlements. A large number of Teochew people have also settled in Taiwan, evident in Taiwanese cuisine. Other notable Teochew diaspora communities are in Vietnam, Cambodia and France. A popular noodle soup in both Vietnam and Cambodia, known as hu tieu, originated from the Teochew. There is also a large diaspora of Teochew people (most were from Southeast Asia) in the United States - particularly in California. There is a Teochew Chinese Association in Paris called L'Amicale des Teochews en France.




</doc>
<doc id="6184" url="https://en.wikipedia.org/wiki?curid=6184" title="Co-NP">
Co-NP

In computational complexity theory, co-NP is a complexity class. A decision problem is a member of co-NP if and only if its complement is in the complexity class NP. The class can be defined as follows: a decision problem is in co-NP precisely if for any "no"-instance "x" there is a "certificate" which a polynomial-time algorithm can use to verify that "x" is a "no"-instance, and for any "yes"-instance there is no such certificate.

Equivalently, co-NP is the set of decision problems where there exists a polynomial "p(n)" and a polynomial-time bounded non-deterministic Turing machine such that for every instance "x", "x" is a yes instance if and only if: for every possible certificate "c" of length bounded by "p(n)", the Turing machine accepts the pair ("x", "c").

The complement of any problem in NP is a problem in co-NP. An example of an NP-complete problem is the circuit satisfiability problem: given a Boolean circuit, is there a possible input for which the circuit outputs true? The complementary problem asks: "given a Boolean circuit, do all possible inputs to the circuit output false?". This is in co-NP because a polynomial-time certificate of a "no"-instance is a set of inputs which make the output true.

An example of a problem that is known to belong to both NP and co-NP (but not known to be in P) is integer factorization: given positive integers "m" and "n", determine if "m" has a factor less than "n" and greater than one. Membership in NP is clear; if "m" does have such a factor then the factor itself is a certificate. Membership in co-NP is also straightforward: one can just list the prime factors of "m", all greater or equal to n, which the verifier can confirm to be valid by multiplication and the AKS primality test. It is presently not known whether there is a polynomial-time algorithm for factorization, equivalently that integer factorization is in P, and hence this example is interesting as one of the most natural problems known to be in NP and co-NP but not known to be in P.

A problem "L" is co-NP-complete if and only if "L" is in co-NP and for any problem in co-NP, there exists a polynomial-time reduction from that problem to "L". An example such problem is that of determining if a formula in propositional logic is a tautology: that is, if the formula evaluates to true under every possible assignment to its variables.

P, the class of polynomial time solvable problems, is a subset of both NP and co-NP. P is thought to be a strict subset in both cases (and demonstrably cannot be strict in one case and not strict in the other).

NP and co-NP are also thought to be unequal. If so, then no NP-complete problem can be in co-NP and no co-NP-complete problem can be in NP. This can be shown as follows. Suppose there exists an NP-complete problem that is in co-NP. Since all problems in NP can be reduced to , it follows that for every problem in NP we can construct a non-deterministic Turing machine that decides its complement in polynomial time, i.e., NP ⊆ co-NP. From this it follows that the set of complements of the problems in NP is a subset of the set of complements of the problems in co-NP, i.e., co-NP ⊆ NP. Thus co-NP = NP. The proof that no co-NP-complete problem can be in NP if NP ≠ co-NP is symmetrical.


</doc>
<doc id="6185" url="https://en.wikipedia.org/wiki?curid=6185" title="Chuck Yeager">
Chuck Yeager

Charles Elwood Yeager (; born February 13, 1923) is a former United States Air Force officer, flying ace, and record-setting test pilot. In 1947, he became the first pilot in history confirmed to have exceeded the speed of sound in level flight.

Yeager's career began in World War II as a private in the United States Army Air Forces in 1941. After serving as an aircraft mechanic, in September 1942 he entered enlisted pilot training and upon graduation was promoted to the rank of flight officer (the World War II USAAF equivalent to warrant officer), later achieving most of his aerial victories as a P-51 fighter pilot on the Western Front, where he shot down over 11 enemy aircraft.

After the war, Yeager became a test pilot of many types of aircraft, including experimental rocket-powered aircraft. As the first human to officially break the sound barrier, on October 14, 1947, he flew the experimental Bell X-1 at Mach 1 and an altitude of , for which he won both the Collier and Mackay trophies in 1948. He then went on to break several other speed and altitude records.

Yeager later commanded fighter squadrons and wings in Germany, as well as in Southeast Asia during the Vietnam War. In recognition of the outstanding performance ratings of those units, he was promoted to brigadier general in 1969, retiring on March 1, 1975. Yeager's three war active duty flying career spans more than 30 years and has taken him to many parts of the world, including the Soviet Union during the height of the Cold War.

Yeager was born February 13, 1923, to farming parents Susie Mae ("née" Sizemore; 1898–1987) and Albert Hal Yeager (1896–1963) in Myra, West Virginia. When he was five, his family moved to Hamlin, West Virginia. He attended Hamlin High School, where he played basketball and football, receiving his best grades in geometry and typing. He graduated from high school in June 1941. Yeager had two brothers, Roy and Hal Jr., and two sisters, Doris Ann (accidentally killed at age two by six-year-old Roy playing with a shotgun) and Pansy Lee. His first experience with the military was as a teen at the Citizens Military Training Camp at Fort Benjamin Harrison, Indianapolis, Indiana, during the summers of 1939 and 1940. On February 26, 1945, Yeager married Glennis Dickhouse, and the couple had four children. Glennis died in 1990.

The name "Yeager" () is an Anglicized form of the German name "Jäger" or "Jaeger" (German: "hunter"). He is the cousin of former baseball catcher Steve Yeager.

Yeager enlisted as a private in the U.S. Army Air Forces (USAAF) on September 12, 1941, and became an aircraft mechanic at George Air Force Base, Victorville, California. At enlistment, Yeager was not eligible for flight training because of his age and educational background, but the entry of the U.S. into World War II less than three months later prompted the USAAF to alter its recruiting standards. Having unusually sharp vision (a visual acuity rated 20/10), which once enabled him to shoot a deer at , Yeager displayed natural talent as a pilot and was accepted for flight training.

At the time of his flight training acceptance, he was a crew chief on an AT-11. He received his pilot wings and a promotion to flight officer at Luke Field, Arizona, where he graduated from Class 43C on March 10, 1943. Assigned to the 357th Fighter Group at Tonopah, Nevada, he initially trained as a fighter pilot, flying Bell P-39 Airacobras (being grounded for seven days for clipping a farmer's tree during a training flight), and shipped overseas with the group on November 23, 1943.
Stationed in the United Kingdom at RAF Leiston, Yeager flew P-51 Mustangs in combat with the 363d Fighter Squadron. He named his aircraft "Glamorous Glen" after his girlfriend, Glennis Faye Dickhouse, who became his wife in February 1945. Yeager had gained one victory before he was shot down over France in his first aircraft (P-51B-5-NA s/n 43-6763) on March 5, 1944 during his eighth mission. He escaped to Spain on March 30 with the help of the "Maquis" (French Resistance) and returned to England on May 15, 1944. During his stay with the "Maquis", Yeager assisted the guerrillas in duties that did not involve direct combat; he helped construct bombs for the group, a skill that he had learned from his father. He was awarded the Bronze Star for helping a B-24 navigator, "Pat" Patterson, who was shot in the knee during the escape attempt, to cross the Pyrenees. Yeager cut off the tendon by which Patterson's leg was hanging below the knee, then tied off the leg with a spare shirt made of parachute silk.

Despite a regulation prohibiting "evaders" (escaped pilots) from flying over enemy territory again, the purpose of which was to prevent a second capture from compromising resistance groups, Yeager was reinstated to flying combat. He had joined another evader, fellow P-51 pilot 1st Lt Fred Glover, in speaking directly to the Supreme Allied Commander, General Dwight D. Eisenhower, on June 12, 1944. With Glover pleading their case, they argued that because the Allies had invaded France and the "Maquis" were by then openly fighting the Nazis alongside Allied troops, if Yeager or Glover were shot down again, there was little about those who had previously helped them evade capture that could be revealed to the enemy.

Eisenhower, after gaining permission from the War Department to decide the requests, concurred with Yeager and Glover. Yeager later credited his postwar success in the Air Force to this decision, saying that his test pilot career followed naturally from his having been a decorated combat pilot, along with having been an aircraft mechanic before attending pilot school. In part, because of his maintenance background, he also frequently served as a maintenance officer in his flying units.

Yeager demonstrated outstanding flying skills and combat leadership. On October 12, 1944, he became the first pilot in his group to make "ace in a day," downing five enemy aircraft in a single mission. Two of these kills were scored without firing a single shot: when he flew into firing position against a Messerschmitt Bf 109, the pilot of the aircraft panicked, breaking to starboard and colliding with his wingman. Yeager said both pilots bailed out. He finished the war with 11.5 official victories, including one of the first air-to-air victories over a jet fighter, a German Messerschmitt Me 262 that he shot down as it was on final approach for landing.

In his 1986 memoirs, Yeager recalled with disgust that "atrocities were committed by both sides", and he said he went on a mission with orders from the Eighth Air Force to "strafe anything that moved." During the mission briefing, he whispered to Major Donald H. Bochkay, "If we are going to do things like this, we sure as hell better make sure we are on the winning side." Yeager said, "I'm certainly not proud of that particular strafing mission against civilians. But it is there, on the record and in my memory." He has also expressed bitterness at his treatment in England during WWII, describing the British as "arrogant" and "nasty".

Yeager was commissioned a second lieutenant while at Leiston, and was promoted to captain before the end of his tour. He flew his 61st and final mission on January 15, 1945 and returned to the United States in early February. As an evader, he received his choice of assignments and, because his new wife was pregnant, chose Wright Field to be near his home in West Virginia. His high number of flight hours and maintenance experience qualified him to become a functional test pilot of repaired aircraft, which brought him under the command of Colonel Albert Boyd, head of the Aeronautical Systems Flight Test Division.

Yeager remained in the Air Force after the war, becoming a test pilot at Muroc Army Air Field (now Edwards Air Force Base), following graduation from Air Materiel Command Flight Performance School (Class 46C). After Bell Aircraft test pilot Chalmers "Slick" Goodlin demanded $150,000 (over $1.7 million in 2020 dollars) to break the sound "barrier," the USAAF selected Yeager to fly the rocket-powered Bell XS-1 in a NACA program to research high-speed flight.

Such was the difficulty in this task that the answer to many of the inherent challenges was along the lines of "Yeager better have paid-up insurance." Two nights before the scheduled date for the flight, Yeager broke two ribs when he fell from a horse. He was worried that the injury would remove him from the mission and reported that he went to a civilian doctor in nearby Rosamond, who taped his ribs. Yeager told only his wife, as well as friend and fellow project pilot Jack Ridley, about the accident. On the day of the flight, Yeager was in such pain that he could not seal the X-1's hatch by himself. Ridley rigged up a device, using the end of a broom handle as an extra lever, to allow Yeager to seal the hatch.

Yeager broke the sound barrier on October 14, 1947, flying the X-1 "Glamorous Glennis" at Mach 1.05 at an altitude of . over the Rogers Dry Lake in the Mojave Desert. The success of the mission was not announced to the public until June 1948. Yeager was awarded the Mackay Trophy and the Collier Trophy in 1948 for his mach-transcending flight, and the Harmon International Trophy in 1954. The X-1 he flew that day was later put on permanent display at the Smithsonian Institution's National Air and Space Museum.

Yeager went on to break many other speed and altitude records. He was also one of the first American pilots to fly a MiG-15, after its pilot, No Kum-sok, defected to South Korea. Returning to Muroc, during the latter half of 1953, Yeager was involved with the USAF team that was working on the X-1A, an aircraft designed to surpass Mach 2 in level flight. That year, he flew a chase aircraft for the civilian pilot Jackie Cochran as she became the first woman to fly faster than sound.

On November 20, 1953, the U.S. Navy program involving the D-558-II Skyrocket and its pilot, Scott Crossfield, became the first team to reach twice the speed of sound. After they were bested, Ridley and Yeager decided to beat rival Crossfield's speed record in a series of test flights that they dubbed "Operation NACA Weep." Not only did they beat Crossfield by setting a new record at Mach 2.44 on December 12, 1953, but they did it in time to spoil a celebration planned for the 50th anniversary of flight in which Crossfield was to be called "the fastest man alive."

The new record flight, however, did not entirely go to plan, since shortly after reaching Mach 2.44, Yeager lost control of the X-1A at about due to inertia coupling, a phenomenon largely unknown at the time. With the aircraft simultaneously rolling, pitching, and yawing out of control, Yeager dropped in less than a minute before regaining control at around . He then managed to land without further incident. For this achievement, Yeager was awarded the Distinguished Service Medal (DSM) in 1954.

Yeager was foremost a fighter pilot and held several squadron and wing commands. From May 1955 to July 1957, he commanded the F-86H Sabre-equipped 417th Fighter-Bomber Squadron (50th Fighter-Bomber Wing) at Hahn AB, West Germany, and Toul-Rosieres Air Base, France; and from 1957 to 1960 the F-100D Super Sabre-equipped 1st Fighter Day Squadron (later, while still under Yeager's command, re-designated the 306th Tactical Fighter Squadron) at George Air Force Base, California, and Morón Air Base, Spain.

Now a full colonel in 1962, after completion of a year's studies at the Air War College, Yeager became the first commandant of the USAF Aerospace Research Pilot School, which produced astronauts for NASA and the USAF, after its redesignation from the USAF Flight Test Pilot School. (Yeager himself had only a high school education, so he was not eligible to become an astronaut like those he trained.) Between December 1963 and January 1964, Yeager completed five flights in the NASA M2-F1 lifting body. An accident during a December 1963 test flight in one of the school's NF-104s eventually put an end to his record attempts.

In 1966, Yeager took command of the 405th Tactical Fighter Wing at Clark Air Base, the Philippines, whose squadrons were deployed on rotational temporary duty (TDY) in South Vietnam and elsewhere in Southeast Asia. There he accrued another 414 hours of combat time in 127 missions, mostly in a Martin B-57 Canberra light bomber. In February 1968, Yeager was assigned command of the 4th Tactical Fighter Wing at Seymour Johnson Air Force Base, North Carolina, and led the McDonnell Douglas F-4 Phantom II wing in South Korea during the "Pueblo" crisis.

On June 22, 1969, Yeager was promoted to brigadier general and was assigned in July as the vice-commander of the Seventeenth Air Force.

From 1971 to 1973, at the behest of Ambassador Joe Farland, Yeager was assigned to Pakistan to advise the Pakistan Air Force. In one of the numerous raids carried out by Indian pilots against Pakistani airfields, Yeager's plane was destroyed while it was parked at Islamabad airport. Edward C. Ingraham, a U.S diplomat who had served as political counselor to Ambassador Farland in Islamabad recalled this incident in the "Washington Monthly" of October 1985: "After Yeager's Beechcraft was destroyed during an Indian air raid, he raged to his colleagues that the Indian pilot had been specifically instructed by Indira Gandhi to blast his plane. 'It was,' he later wrote, 'the Indian way of giving Uncle Sam the finger.'" After having his twin-engined Beechcraft liaison aircraft destroyed in an Indian air raid on the Chaklala Airbase, he was incensed and demanded U.S. retaliation.

On March 1, 1975, following assignments in Germany and Pakistan, Yeager retired from the Air Force at Norton Air Force Base, California, after serving over 33 years on active duty, although he continued to occasionally fly for the USAF and NASA as a consulting test pilot at Edwards AFB.

Yeager made a cameo appearance in the movie "The Right Stuff" (1983). He played "Fred," a bartender at "Pancho's Place", which was most appropriate, as Yeager said, "if all the hours were ever totaled, I reckon I spent more time at her place than in a cockpit over those years." His own role in the movie was played by Sam Shepard.

For several years in the 1980s, Yeager was connected to General Motors, publicizing AC Delco, the company's automotive parts division. In 1986 he was invited to drive the Chevrolet Corvette pace car for the 70th running of the Indianapolis 500. In 1988, Yeager was again invited to drive the pace car, this time at the wheel of an Oldsmobile Cutlass Supreme. In 1986, President Reagan appointed Yeager to the Rogers Commission that investigated the explosion of the Space Shuttle "Challenger".

In the late 1980s and early 1990s, Yeager set several light general aircraft performance records for speed, range, and endurance. Most notable were flights conducted on behalf of Piper Aircraft. On one such flight, Yeager performed an emergency landing as a result of fuel exhaustion. On another, he piloted Piper's turboprop Cheyenne 400LS to a time-to-height record: FL350 (35,000 feet) in 16 minutes, exceeding the climb performance of a Boeing 737 at gross weight.

During this time Yeager also served as a technical adviser for three Electronic Arts flight simulator video games. The games include "Chuck Yeager's Advanced Flight Trainer", "Chuck Yeager's Advanced Flight Trainer 2.0", and "Chuck Yeager's Air Combat". The game manuals featured quotes and anecdotes from Yeager, and were well received by players. Missions featured several of Yeager's accomplishments and let players attempt to top his records. "Chuck Yeager's Advanced Flight Trainer" was Electronic Art's top selling game for 1987.

In 2009, Yeager participated in the documentary "The Legend of Pancho Barnes and the Happy Bottom Riding Club", a profile of his friend Pancho Barnes. The documentary was screened at film festivals, aired on public television in the United States and won an Emmy Award.

Yeager is fully retired from military test flying, after having maintained that status for three decades after his official retirement from the Air Force. On October 14, 1997, on the 50th anniversary of his historic flight past Mach 1, he flew a new "Glamorous Glennis III", an F-15D Eagle, past Mach 1. The chase plane for the flight was an F-16 Fighting Falcon piloted by Bob Hoover, a longtime test, fighter and aerobatic pilot who had been Yeager's wingman for the first supersonic flight. This was supposed to be Yeager's last official flight with the U.S. Air Force. However he was called back into flying with the USAF in 2000 and continued to do so until the end of 2012. At the end of his speech to the crowd in 1997, Yeager concluded, "All that I am ... I owe to the Air Force." Later that month, he was the recipient of the Tony Jannus Award for his achievements.

On October 14, 2012, on the 65th anniversary of breaking the sound barrier, Yeager did it again at the age of 89, flying as co-pilot in a McDonnell Douglas F-15 Eagle piloted by Captain David Vincent out of Nellis Air Force Base.

In 1973, Yeager was inducted into the National Aviation Hall of Fame, arguably aviation's highest honor. In 1974, Yeager received the Golden Plate Award of the American Academy of Achievement. In December 1975, the U.S. Congress awarded Yeager a silver medal "equivalent to a noncombat Medal of Honor ... for contributing immeasurably to aerospace science by risking his life in piloting the X-1 research airplane faster than the speed of sound on October 14, 1947." President Gerald Ford presented the medal to Yeager in a ceremony at the White House on December 8, 1976.

Yeager, who never attended college and was often modest about his background, is considered by many, including "Flying Magazine", the California Hall of Fame, the State of West Virginia, National Aviation Hall of Fame, a few U.S. presidents, and the United States Army Air Force, to be one of the greatest pilots of all time. Despite his lack of higher education, he has been honored in his home state. Marshall University has named its highest academic scholarship, the Society of Yeager Scholars, in his honor. Yeager was also the chairman of Experimental Aircraft Association's Young Eagle Program from 1994–2004, and has been named the program's chairman emeritus.

In 1966, Yeager was inducted into the International Air & Space Hall of Fame. He was inducted into the International Space Hall of Fame in 1981. He was inducted into the Aerospace Walk of Honor 1990 inaugural class.

Yeager Airport in Charleston, West Virginia, is named in his honor. The Interstate 64/Interstate 77 bridge over the Kanawha River in Charleston is named in his honor. He also flew directly under the Kanahwa Bridge and West Virginia named it to the Chuck E. Yeager Bridge. On October 19, 2006, the state of West Virginia also honored Yeager with a marker along Corridor G (part of US Highway 119) in his home Lincoln County, and also renamed part of the highway the "Yeager Highway".

Yeager is an honorary board member of the humanitarian organization Wings of Hope. On August 25, 2009, Governor Arnold Schwarzenegger and Maria Shriver announced that Yeager would be one of 13 California Hall of Fame inductees in The California Museum's yearlong exhibit. The induction ceremony was on December 1, 2009 in Sacramento, California. "Flying Magazine" ranked Yeager number 5 on its 2013 list of The 51 Heroes of Aviation; he is the highest-ranked living person on the list.

The Civil Air Patrol, the volunteer auxiliary of the USAF, awards the Charles E. "Chuck" Yeager Award to its Senior Members as part of its Aerospace Education program. 

Yeager named his plane after his wife Glennis as a good-luck charm; "You're my good-luck charm, hon. Any airplane I name after you always brings me home." Yeager and Glennis moved to Grass Valley, California, after his retirement from the Air Force in 1975. The couple prospered because of Yeager's best-selling autobiography, speaking engagements and commercial ventures. Glennis Yeager died of ovarian cancer in 1990. They had four children (Susan, Don, Mickey and Sharon).

In 2000, Yeager met actress Victoria Scott D'Angelo on a hiking trail in Nevada County. The pair started dating shortly thereafter, and married in August 2003. Subsequent to the commencement of their relationship, a bitter dispute arose between Yeager, his children and D'Angelo. The children contended that D'Angelo, 35 years Yeager's junior, had married him for his fortune. Yeager and D'Angelo both denied the charge. Litigation ensued, in which his children accused D'Angelo of "undue influence" on Yeager, and Yeager accused his children of diverting millions of dollars from his assets. In August 2008, the California Court of Appeal ruled for Yeager, finding that his daughter Susan had breached her duty as trustee.




</doc>
<doc id="6186" url="https://en.wikipedia.org/wiki?curid=6186" title="Cajun cuisine">
Cajun cuisine

Cajun cuisine (, ), () is a style of cooking named for the French-speaking Acadian people deported by the British from Acadia in Canada, incorporating West African, French and Spanish cooking techniques, in region of Louisiana. Cajun cuisine is sometimes referred to as a 'rustic cuisine', meaning that it is based on locally available ingredients and preparation is relatively simple.

An authentic Cajun meal is usually a three-pot affair, with one pot dedicated to the main dish, one dedicated to steamed rice, special made sausages, or some seafood dish, and the third containing whatever vegetable is plentiful or available. Crawfish, shrimp, and andouille sausage are staple meats used in a variety of dishes.

The aromatic vegetables green bell pepper (), onion, and celery are called the trinity by Cajun chefs in Cajun and Louisiana Creole cuisines. Roughly diced and combined in cooking, the method is similar to the use of the "mirepoix" in traditional French cuisine which blends roughly diced carrot, onion, and celery. Characteristic aromatics for the Creole version may also include parsley, bay leaf, green onions, dried cayenne pepper, and dried black pepper.

Acadians were forcibly deported by the British in 1755 in what was called "le Grand Dérangement", eventually settling in Southern Louisiana. Due to the extreme change in climate, Acadians were unable to cook their original dishes. Soon, their former culinary traditions were lost, and so, these other meals developed to become what is now considered classic Cajun cuisine traditions (not to be confused with the more modern concept associated with Prudhomme's style). Up through the 20th century, the meals were not elaborate but instead, rather basic. The public's false perception of "Cajun" cuisine was based on Prudhomme's style of Cajun cooking, which was spicy, flavorful, and not true to the classic form of the cuisine. Cajun and Creole label have been mistaken to be the same, but the origins of Creole cooking began in New Orleans, and Cajun cooking came 40 years after the establishment of New Orleans.
Today, most restaurants serve dishes that consist of Cajun styles, which Paul Prudhomme dubbed "Louisiana cooking". In home-cooking, these individual styles are still kept separate. However, there are fewer and fewer people cooking the classic Cajun dishes that would have been eaten by the original settlers.


Deep-frying of turkeys or oven-roasted turduckens entered southern Louisiana cuisine more recently. Also, blackening of fish or chicken and barbecuing of shrimp in the shell are excluded because they were not prepared in traditional Cajun cuisine. Blackening was actually an invention by chef Paul Prudhomme in the 1970s, becoming associated with Cajun cooking, and presented as such by him, but is not a true historical or traditional Cajun cooking process.

The following is a partial list of ingredients used in Cajun cuisine and some of the staple ingredients of the Acadian food culture.


Cajun foodways include many ways of preserving meat, some of which are waning due to the availability of refrigeration and mass-produced meat at the grocer. Smoking of meats remains a fairly common practice, but once-common preparations such as turkey or duck confit (preserved in poultry fat, with spices) are now seen even by Acadians as quaint rarities.

Game (and hunting) are still uniformly popular in Acadiana.

The recent increase of catfish farming in the Mississippi Delta has brought about an increase in its usage in Cajun cuisine in the place of the more traditional wild-caught trout (the saltwater species) and red fish.

Thyme, sage, mint, marjoram, savory, and basil are considered sweet herbs. In Colonial times a herbes de Provence would be several sweet herbs tied up in a muslin.



Boudin is a type of sausage made from pork, pork liver, rice, garlic, green onions and other spices. It is widely available by the link or pound from butcher shops. Boudin is typically stuffed in a natural casing and has a softer consistency than other, better-known sausage varieties. It is usually served with side dishes such as rice dressing, maque choux or bread. Boudin balls are commonly served in southern Louisiana restaurants and are made by taking the boudin out of the case and frying it in spherical form.

Gumbo - High on the list of favorites of Cajun cooking are the soups called gumbos. Contrary to non-Cajun or Continental beliefs, gumbo does not mean simply "everything in the pot". Gumbo exemplifies the influence of French, Spanish, African and Native American food cultures on Cajun cuisine. The name originally meant "okra", a word brought to the region from western Africa. Okra which can be one of the principal ingredients in gumbo recipes is used as a thickening agent and for its distinct vegetable flavor. Many claim that Gumbo is a "Cajun" dish, but Gumbo was established long before the Acadian arrival. Its early existence came via the early French Creole culture In New Orleans, Louisiana, where French, Spanish and Africans frequented and also influenced by later waves of Italian, German and Irish settlers.

A filé gumbo is thickened with dried sassafras leaves after the stew has finished cooking, a practice borrowed from the Choctaw Indians. The backbone of a gumbo is roux of which there are two variations: Cajun, a golden brown roux, and Creole, a dark roux, which is made of flour, toasted until well-browned, and fat or oil. The classic gumbo is made with chicken and the Cajun sausage called andouille, pronounced {ahn-doo-wee}, but the ingredients vary according to what is available.

Jambalaya - Another classic Cajun dish is jambalaya. The only certain thing that can be said about a jambalaya is that it contains rice, some sort of meat (such as chicken or beef), seafood (such as shrimp or crawfish) or almost anything else. Usually, however, one will find green peppers, onions, celery, tomatoes and hot chili peppers. Anything else is optional. This is also a great pre-Acadian dish, established by the Spanish in Louisiana.

Rice and gravy - Rice and gravy dishes are a staple of Cajun cuisine and is usually a brown gravy based on pan drippings, which are deglazed and simmered with extra seasonings and served over steamed or boiled rice. The dish is traditionally made from cheaper cuts of meat and cooked in a cast iron pot, typically for an extended time period in order to let the tough cuts of meat become tender. Beef, pork, chicken or any of a large variety of game meats are used for its preparation. Popular local varieties include hamburger steak, smothered rabbit, turkey necks, and chicken fricassee.

The crawfish boil is a celebratory event where Cajuns boil crawfish, potatoes, onions and corn in large pots over propane cookers. Lemons and small muslin bags containing a mixture of bay leaves, mustard seeds, cayenne pepper, and other spices, commonly known as "crab boil" or "crawfish boil" are added to the water for seasoning. The results are then dumped onto large, newspaper-draped tables and in some areas covered in Creole/Cajun spice blends, such as REX, Zatarain's, Louisiana Fish Fry, or Tony Chachere's. Also, cocktail sauce, mayonnaise, and hot sauce are sometimes used. The seafood is scooped onto large trays or plates and eaten by hand. During times when crawfish are not abundant, shrimp and crabs are prepared and served in the same manner.

Attendees are encouraged to "suck the head" of a crawfish by separating the head from the abdomen of the crustacean and sucking out the fat and juices from the head.

Often, newcomers to the crawfish boil or those unfamiliar with the traditions are jokingly warned "not to eat the dead ones." This comes from the common belief that when live crawfish are boiled, their tails curl beneath themselves, but when dead crawfish are boiled, their tails are straight and limp.
Seafood boils with crabs and shrimp are also popular.

The traditional Cajun outdoor food event hosted by a farmer in the rural areas of the Acadiana. Family and friends of the farmer gather to socialize, play games, dance, drink, and have a copious meal consisting of hog and other dishes. Men have the task of slaughtering a hog, cutting it into usable parts, and cooking the main pork dishes while women have the task of making boudin.
Similar to a family , the is a food event that revolves around pork but does not need to be hosted by a farmer. Traditionally, a suckling pig was purchased for the event, but in modern , adult pigs are used. Unlike the family , a hog is not butchered by the hosts and there are generally not as many guests or activities. The host and male guests have the task of roasting the pig (see pig roast) while female guests bring side dishes.

The traditional Cajun Mardi Gras (see: "Courir de Mardi Gras") is a Mardi Gras celebration in rural Cajun Parishes. The tradition originated in the 18th century with the Cajuns of Louisiana, but it was abandoned in the early 20th century because of unwelcome violence associated with the event. In the early 1950s the tradition was revived in Mamou in Evangeline Parish.

The event revolves around male maskers on horseback who ride into the countryside to collect food ingredients for the party later on. They entertain householders with Cajun music, dancing, and festive antics in return for the ingredients. The preferred ingredient is a live chicken in which the householder throws the chicken to allow the maskers to chase it down (symbolizing a hunt), but other ingredients include rice, sausage, vegetables, or frozen chicken. Unlike other Cajun events, men take no part in cooking the main course for the party, and women prepare the chicken and ingredients for the gumbo. Once the festivities begin, the Cajun community members eat and dance to Cajun music until midnight after which is the beginning of Lent.



Three popular local dishes in Acadiana are noted in the Hank Williams song "Jambalaya", namely "Jambalaya and-a crawfish pie and filé gumbo".



</doc>
<doc id="6187" url="https://en.wikipedia.org/wiki?curid=6187" title="Cologne">
Cologne

Cologne ( ; ; ; , usually shortened to ) is the largest city of Germany's most populous federal state of North Rhine-Westphalia and the fourth-most populous city in Germany. With slightly over a million inhabitants (1.09 million) within its city boundaries, Cologne is the largest city on the Rhine and also the most populous city both of the Rhine-Ruhr Metropolitan Region, which is Germany's largest and one of Europe's major metropolitan areas, and of the Rhineland. Centered on the left bank of the Rhine, Cologne is about southeast of North Rhine-Westphalia's capital of Düsseldorf and northwest of Bonn. It is the largest city in the Central Franconian and Ripuarian dialect areas.

The city's Cologne Cathedral ("Kölner Dom") is the seat of the Catholic Archbishop of Cologne. There are many institutions of higher education in the city, most notably the University of Cologne ("Universität zu Köln"), one of Europe's oldest and largest universities, the Technical University of Cologne ("Technische Hochschule Köln"), Germany's largest university of applied sciences, and the German Sport University Cologne ("Deutsche Sporthochschule Köln"), Germany's only sport university. Cologne Bonn Airport ("Flughafen Köln/Bonn") is Germany's seventh-largest airport and lies in the southeast of the city. The main airport for the Rhine-Ruhr region is Düsseldorf Airport.

Cologne was founded and established in Ubii territory in the 1st century AD as the Roman "Colonia Claudia Ara Agrippinensium", the first word of which is the origin of its name. An alternative Latin name of the settlement is "Augusta Ubiorum", after the Ubii. "Cologne", the French version of the city's name, has become standard in English as well. Cologne functioned as the capital of the Roman province of "Germania Inferior" and as the headquarters of the Roman military in the region until occupied by the Franks in 462. During the Middle Ages the city flourished as being located on one of the most important major trade routes between east and western Europe. Cologne was one of the leading members of the Hanseatic League and one of the largest cities north of the Alps in medieval and Renaissance times. Prior to World War II, the city had undergone several occupations by the French and also by the British (1918–1926). Cologne was one of the most heavily bombed cities in Germany during World War II, with the Royal Air Force (RAF) dropping of bombs on the city. The bombing reduced the population by 95%, mainly due to evacuation, and destroyed almost the entire city centre. With the intention of restoring as many historic landmarks as possible, the postwar rebuilding has resulted in a very mixed and unique cityscape.

Cologne is a major cultural centre for the Rhineland; it hosts more than 30 museums and hundreds of galleries. Exhibitions range from local ancient Roman archeological sites to contemporary graphics and sculpture. The Cologne Trade Fair hosts a number of trade shows such as Art Cologne, imm Cologne, Gamescom, and the Photokina.

The first urban settlement on the grounds of modern-day Cologne was "Oppidum Ubiorum", founded in 38 BC by the Ubii, a Cisrhenian Germanic tribe. In 50 AD, the Romans founded "Colonia Claudia Ara Agrippinensium" (Cologne) on the river Rhine and the city became the provincial capital of Germania Inferior in 85 AD. Considerable Roman remains can be found in present-day Cologne, especially near the wharf area, where a 1,900-year-old Roman boat was discovered in late 2007. From 260 to 271, Cologne was the capital of the Gallic Empire under Postumus, Marius, and Victorinus. In 310, under emperor Constantine I, a bridge was built over the Rhine at Cologne. Roman imperial governors resided in the city and it became one of the most important trade and production centres in the Roman Empire north of the Alps. Cologne is shown on the 4th century Peutinger Map.

Maternus, who was elected as bishop in 313, was the first known bishop of Cologne. The city was the capital of a Roman province until it was occupied by the Ripuarian Franks in 462. Parts of the original Roman sewers are preserved underneath the city, with the new sewerage system having opened in 1890.

Early medieval Cologne was part of Austrasia within the Frankish Empire. In 716, Charles Martel commanded an army for the first time and suffered the only defeat of his life when Chilperic II, King of Neustria, invaded Austrasia and the city fell to him in the Battle of Cologne. Charles fled to the Eifel mountains, rallied supporters and took the city back that same year after defeating Chilperic in the Battle of Amblève. Cologne had been the seat of a bishop since the Roman period; under Charlemagne, in 795, bishop Hildebold was promoted to archbishop. In the 843 Treaty of Verdun Cologne fell into the dominion of Lothair I's Middle Francia—later called Lotharingia (Lower Lorraine).

In 953, the archbishops of Cologne first gained noteworthy secular power when bishop Bruno was appointed as duke by his brother Otto I, King of Germany. In order to weaken the secular nobility, who threatened his power, Otto endowed Bruno and his archiepiscopal successors with the prerogatives of secular princes, thus establishing the Electorate of Cologne, formed by the temporal possessions of the archbishopric and included in the end a strip of territory along the left Bank of the Rhine east of Jülich, as well as the Duchy of Westphalia on the other side of the Rhine, beyond Berg and Mark. By the end of the 12th century, the Archbishop of Cologne was one of the seven electors of the Holy Roman Emperor. Besides being prince elector, he was Arch-chancellor of Italy as well, technically from 1238 and permanently from 1263 until 1803.

Following the Battle of Worringen in 1288, Cologne gained its independence from the archbishops and became a Free City. Archbishop Sigfried II von Westerburg was forced to reside in Bonn. The archbishop nevertheless preserved the right of capital punishment. Thus the municipal council (though in strict political opposition towards the archbishop) depended upon him in all matters concerning criminal justice. This included torture, the sentence for which was only allowed to be handed down by the episcopal judge known as the "Greve". This legal situation lasted until the French conquest of Cologne.

Besides its economic and political significance Cologne also became an important centre of medieval pilgrimage, when Cologne's archbishop, Rainald of Dassel, gave the relics of the Three Wise Men to Cologne's cathedral in 1164 (after they, in fact, had been taken from Milan). Besides the three magi Cologne preserves the relics of Saint Ursula and Albertus Magnus.

Cologne's location on the river Rhine placed it at the intersection of the major trade routes between east and west as well as the main south–north Western Europe trade route, Northern Italy to Flanders. The intersection of these trade routes were the basis of Cologne's growth. By 1300 the city population was 50,000–55,000. Cologne was a member of the Hanseatic League in 1475, when Frederick III confirmed the city's imperial immediacy.

The economic structures of medieval and early modern Cologne were characterised by the city's status as a major harbour and transport hub on the Rhine. Craftsmanship was organised by self-administering guilds, some of which were exclusive to women.

As a free imperial city, Cologne was a self-ruling state within the Holy Roman Empire, an imperial estate with seat and vote at the Imperial Diet, and as such had the right (and obligation) to contribute to the defense of the Empire and maintain its own military force. As they wore a red uniform, these troops were known as the "Rote Funken" (red sparks). These soldiers were part of the Army of the Holy Roman Empire ("Reichskontingent") and fought in the wars of the 17th and 18th century, including the wars against revolutionary France, when the small force was almost completely wiped out in combat. The tradition of these troops is preserved as a military persiflage by Cologne's most outstanding carnival society, the "Rote Funken".

The Free Imperial City of Cologne must not be confused with the Electorate of Cologne which was a state of its own within the Holy Roman Empire. Since the second half of the 16th century the majority of archbishops were drawn from the Bavaria Wittelsbach dynasty. Due to the free status of Cologne, the archbishops were usually not allowed to enter the city. Thus they took up residence in Bonn and later in Brühl on the Rhine. As members of an influential and powerful family, and supported by their outstanding status as electors, the archbishops of Cologne repeatedly challenged and threatened the free status of Cologne during the 17th and 18th centuries, resulting in complicated affairs, which were handled by diplomatic means and propaganda as well as by the supreme courts of the Holy Roman Empire.

Cologne lost its status as a free city during the French period. According to the Peace Treaty of Lunéville (1801) all the territories of the Holy Roman Empire on the left bank of the Rhine were officially incorporated into the French Republic (which had already occupied Cologne in 1794). Thus this region later became part of Napoleon's Empire. Cologne was part of the French Département Roer (named after the river Roer, German: Rur) with Aachen (French: Aix-la-Chapelle) as its capital. The French modernised public life, for example by introducing the Napoleonic code and removing the old elites from power. The Napoleonic code remained in use on the left bank of the Rhine until 1900, when a unified civil code (the "Bürgerliches Gesetzbuch") was introduced in the German Empire. In 1815 at the Congress of Vienna, Cologne was made part of the Kingdom of Prussia, first in the Jülich-Cleves-Berg province and then the Rhine province.

The permanent tensions between the Roman Catholic Rhineland and the overwhelmingly Protestant Prussian state repeatedly escalated with Cologne being in the focus of the conflict. In 1837 the archbishop of Cologne, Clemens August von Droste-Vischering, was arrested and imprisoned for two years after a dispute over the legal status of marriages between Protestants and Roman Catholics ("Mischehenstreit"). In 1874, during the Kulturkampf, Archbishop Paul Melchers was imprisoned before taking asylum in the Netherlands. These conflicts alienated the Catholic population from Berlin and contributed to a deeply felt anti-Prussian resentment, which was still significant after World War II, when the former mayor of Cologne, Konrad Adenauer, became the first West German chancellor.

During the 19th and 20th centuries, Cologne absorbed numerous surrounding towns, and by World War I had already grown to 700,000 inhabitants. Industrialisation changed the city and spurred its growth. Vehicle and engine manufacturing was especially successful, though the heavy industry was less ubiquitous than in the Ruhr area. The cathedral, started in 1248 but abandoned around 1560, was eventually finished in 1880 not just as a place of worship but also as a German national monument celebrating the newly founded German empire and the continuity of the German nation since the Middle Ages. Some of this urban growth occurred at the expense of the city's historic heritage with much being demolished (for example, the city walls or the area around the cathedral) and sometimes replaced by contemporary buildings.

Cologne was designated as one of the Fortresses of the German Confederation. It was turned into a heavily armed fortress (opposing the French and Belgian fortresses of Verdun and Liège) with two fortified belts surrounding the city, the remains of which can be seen to this day. The military demands on what became Germany's largest fortress presented a significant obstacle to urban development, with forts, bunkers, and wide defensive dugouts completely encircling the city and preventing expansion; this resulted in a very densely built-up area within the city itself.

During World War I Cologne was the target of several minor air raids but suffered no significant damage. Cologne was occupied by the British Army of the Rhine until 1926, under the terms of the Armistice and the subsequent Versailles Peace Treaty.
In contrast with the harsh behaviour of the French occupation troops in Germany, the British forces were more lenient to the local population. Konrad Adenauer, the mayor of Cologne from 1917 until 1933 and later a West German chancellor, acknowledged the political impact of this approach, especially since Britain had opposed French demands for a permanent Allied occupation of the entire Rhineland.

As part of the demilitarisation of the Rhineland, the city's fortifications had to be dismantled. This was an opportunity to create two green belts ("Grüngürtel") around the city by converting the fortifications and their fields of fire into large public parks. This was not completed until 1933. In 1919 the University of Cologne, closed by the French in 1798, was reopened. This was considered to be a replacement for the loss of the University of Strasbourg on the west bank of the Rhine, which reverted to France with the rest of Alsace. Cologne prospered during the Weimar Republic (1919–33), and progress was made especially in public governance, city planning, housing and social affairs. Social housing projects were considered exemplary and were copied by other German cities. Cologne competed to host the Olympics, and a modern sports stadium was erected at Müngersdorf. When the British occupation ended, the prohibition of civil aviation was lifted and Cologne Butzweilerhof Airport soon became a hub for national and international air traffic, second in Germany only to Berlin Tempelhof Airport.

The democratic parties lost the local elections in Cologne in March 1933 to the Nazi Party and other right wing parties. The Nazis then arrested the Communist and Social Democrats members of the city assembly, and Mayor Adenauer was dismissed. Compared to some other major cities, however, the Nazis never gained decisive support in Cologne. (Significantly, the number of votes cast for the Nazi Party in Reichstag elections had always been the national average.) By 1939 the population had risen to 772,221 inhabitants.

During World War II, Cologne was a Military Area Command Headquarters ("Militärbereichshauptkommandoquartier") for the Military District ("Wehrkreis") VI of Münster. Cologne was under the command of Lieutenant-General Freiherr Roeder von Diersburg, who was responsible for military operations in Bonn, Siegburg, Aachen, Jülich, Düren, and Monschau. Cologne was home to the 211th Infantry Regiment and the 26th Artillery Regiment.

The Allies dropped 44,923.2 tons of bombs on the city during World War II, destroying 61% of its built up area. During the Bombing of Cologne in World War II, Cologne endured 262 air raids by the Western Allies, which caused approximately 20,000 civilian casualties and almost completely wiped out the central part of the city. During the night of 31 May 1942, Cologne was the target of "Operation Millennium", the first 1,000 bomber raid by the Royal Air Force in World War II. 1,046 heavy bombers attacked their target with 1,455 tons of explosives, approximately two-thirds of which were incendiary. This raid lasted about 75 minutes, destroyed of built-up area (61%), killed 486 civilians and made 59,000 people homeless. The devastation was recorded by Hermann Claasen from 1942 until the end of the war, and presented in his exhibition and book of 1947 "Singing in the furnace. Cologne - Remains of an old city"

Cologne was taken by the American First Army in early March 1945. By the end of the war, the population of Cologne had been reduced by 95 percent. This loss was mainly caused by a massive evacuation of the people to more rural areas. The same happened in many other German cities in the last two years of war. By the end of 1945, however, the population had already recovered to approximately 450,000.
By the end of the war, essentially all of Cologne's pre-war Jewish population of 11,000 had been deported or killed by the Nazis. The six synagogues of the city were destroyed. The synagogue on Roonstraße was rebuilt in 1959.

Despite Cologne's status as the largest city in the region, nearby Düsseldorf was chosen as the political capital of the federated state of North Rhine-Westphalia. With Bonn being chosen as the provisional federal capital ("provisorische Bundeshauptstadt") and seat of the government of the Federal Republic of Germany (then informally West Germany), Cologne benefited by being sandwiched between two important political centres. The city became–and still is–home to a number of federal agencies and organizations. After reunification in 1990, Berlin was made the capital of Germany.

In 1945 architect and urban planner Rudolf Schwarz called Cologne the "world's greatest heap of rubble". Schwarz designed the master plan for reconstruction in 1947, which included the construction of several new thoroughfares through the city centre, especially the "Nord-Süd-Fahrt" ("North-South-Drive"). The master plan took into consideration the fact that even shortly after the war a large increase in automobile traffic could be anticipated. Plans for new roads had already, to a certain degree, evolved under the Nazi administration, but the actual construction became easier when most of the city centre was in ruins.

The destruction of 95% of the city centre, including the famous Twelve Romanesque churches such as St. Gereon, Great St. Martin, St. Maria im Kapitol and several other monuments in World War II, meant a tremendous loss of cultural treasures. The rebuilding of those churches and other landmarks such as the Gürzenich event hall was not undisputed among leading architects and art historians at that time, but in most cases, civil intention prevailed. The reconstruction lasted until the 1990s, when the Romanesque church of St. Kunibert was finished.

In 1959, the city's population reached pre-war numbers again. It then grew steadily, exceeding 1 million for about one year from 1975. It remained just below that until mid-2010, when it exceeded 1 million again.

In the 1980s and 1990s Cologne's economy prospered for two main reasons. The first was the growth in the number of media companies, both in the private and public sectors; they are especially catered for in the newly developed Media Park, which creates a strong visual focal point in Cologne's city centre and includes the "KölnTurm", one of Cologne's most prominent high-rise buildings. The second was the permanent improvement of the diverse traffic infrastructure, which made Cologne one of the most easily accessible metropolitan areas in Central Europe.

Due to the economic success of the Cologne Trade Fair, the city arranged a large extension to the fair site in 2005. At the same time the original buildings, which date back to the 1920s, were rented out to RTL, Germany's largest private broadcaster, as their new corporate headquarters.

Cologne was the focus of the 2015-16 New Year's Eve sexual assaults in Germany, with over 500 women reporting that they were sexually assaulted by persons of African and Arab appearance.

The metropolitan area encompasses over , extending around a central point that lies at 50° 56' 33 latitude and 6° 57' 32 longitude. The city's highest point is above sea level (the Monte Troodelöh) and its lowest point is above sea level (the Worringer Bruch). The city of Cologne lies within the larger area of the Cologne Lowland, a cone-shaped area of the central Rhineland that lies between Bonn, Aachen and Düsseldorf.

Cologne is divided into 9 boroughs ("Stadtbezirke") and 85 districts ("Stadtteile"):

Located in the Rhine-Ruhr area, Cologne is one of the warmest cities in Germany. It has a temperate–oceanic climate (Köppen: "Cfb") with cool winters and warm summers. It is also one of the cloudiest cities in Germany, with just 1812 hours of sun a year. Its average annual temperature is : during the day and at night. In January, the mean temperature is , while the mean temperature in August is . The record high temperature of 40C (104F) happened on 25 July 2019 during the July 2019 European heat wave in which Cologne saw three consecutive days over 38C (100F). Temperatures can vary significantly over the course of a month with warmer and colder weather. Precipitation is spread evenly throughout the year with a light peak in summer due to showers and thunderstorms.

Cologne is regularly affected by flooding from the Rhine and is considered the most flood-prone European city. A city agency ("Stadtentwässerungsbetriebe Köln", "Cologne Urban Drainage Operations") manages an extensive flood control system which includes both permanent and mobile flood walls, protection from rising waters for buildings close to the river banks, monitoring and forecasting systems, pumping stations and programmes to create or protect floodplains, and river embankments. The system was redesigned after a 1993 flood, which resulted in heavy damage.

In the Roman Empire the city was large and rich with a population of 40,000 in 100–200 AD. The city was home to around 20,000 people in 1000 AD, growing to 50,000 in 1200 AD. The Rhineland metropolis still had 50,000 residents in 1300 AD.

Cologne is the fourth-largest city in Germany after Berlin, Hamburg and Munich. As of 31 December 2016, there were 1,080,701 people registered as living in Cologne in an area of . The population density was . The metropolitan area of the Cologne Bonn Region is home to 3,573,500 living on . It is part of the polycentric megacity region Rhine-Ruhr with a population of over 11,000,000 people.

There were 546,498 women and 522,694 men in Cologne. For every 1,000 males, there were 1,046 females. In 2015, there were 11,337 births in Cologne (of which 34.53% were to unmarried women); 7,704 marriages and 2,203 divorces, and 9,629 deaths. In the city, the population was spread out, with 15.6% under the age of 18, and 17.6% were 65 years of age or older. 163 people in Cologne were over the age of 100.

According to the Statistical Office of the City of Cologne, the number of people with a migrant background is at 36.7% (393,7936). 2,537 people acquired German citizenship in 2015.
In 2015, there were 557,090 households, of which 18.3% had children under the age of 18; 50.6% of all households were made up of singles. 8.7% of all households were single-parent households. The average household size was 1.87.

Cologne residents with a foreign citizenship as of 31 December 2015 is as follows:

Colognian or Kölsch () (natively "Kölsch Platt") is a small set of very closely related dialects, or variants, of the Ripuarian Central German group of languages. These dialects are spoken in the area covered by the Archdiocese and former Electorate of Cologne reaching from Neuss in the north to just south of Bonn, west to Düren and east to Olpe in the North-West of Germany. Kölsch is one of the very few city dialects in Germany, which also include the dialect spoken in Berlin, for example.

As of 2015, 35.5% of the population belonged to the Catholic Church, the largest religious body, and 15.5% to the Evangelical Church. Irenaeus of Lyons claimed that Christianity was brought to Cologne by Roman soldiers and traders at an unknown early date. It is known that in the early second century it was a bishop's seat. The first historical Bishop of Cologne was Saint Maternus. Thomas Aquinas studied in Cologne in 1244 under Albertus Magnus. Cologne is the seat of the Roman Catholic Archdiocese of Cologne.

According to the 2011 census, 2.1% of the population was Eastern Orthodox, 0.5% was member of an Evangelical Free Church and 4.2% belonged to further religious communities officially recognized by the federal state of North Rhine-Westphalia (such as Jehovah's Witnesses).

There are several mosques, including the Cologne Central Mosque run by the Turkish-Islamic Union for Religious Affairs. In 2011, about 11.2% of the population was Muslim.

Cologne also has one of the oldest and largest Jewish communities in Germany. In 2011, 0.3% of Cologne's population was Jewish.

The city's administration is headed by the mayor and the three deputy mayors.

The long tradition of a free imperial city, which long dominated an exclusively Catholic population and the age-old conflict between the church and the bourgeoisie (and within it between the patricians and craftsmen) have created its own political climate in Cologne. Various interest groups often form networks beyond party boundaries. The resulting web of relationships, with political, economic, and cultural links with each other in a system of mutual favours, obligations and dependencies, is called the 'Cologne coterie'. This has often led to an unusual proportional distribution in the city government and degenerated at times into corruption: in 1999, a "waste scandal" over kickbacks and illegal campaign contributions came to light, which led not only to the imprisonment of the entrepreneur Hellmut Trienekens, but also to the downfall of almost the entire leadership of the ruling Social Democrats.

The Lord Mayor of Cologne is Henriette Reker. She received 52.66% of the vote at the municipal election on 17 October 2015 and was appointed on 15 December 2015.

City Councillors are elected for a five-year term and the Mayor has a six-year term.

The inner city of Cologne was completely destroyed during World War II. The reconstruction of the city followed the style of the 1950s, while respecting the old layout and naming of the streets. Thus, the city today is characterized by simple and modest post-war buildings, with a few interspersed pre-war buildings which were reconstructed due to their historical importance. Some buildings of the "Wiederaufbauzeit" (era of reconstruction), for example, the opera house by Wilhelm Riphahn, are nowadays regarded as classics of modern architecture. Nevertheless, the uncompromising style of the Cologne Opera house and other modern buildings has remained controversial.

Green areas account for over a quarter of Cologne, which is approximately of public green space for every inhabitant.

The presence of animals in Cologne is generally limited to insects, small rodents, and several species of birds. Pigeons are the most often seen animals in Cologne, although the number of birds is augmented each year by a growing population of feral exotics, most visibly parrots such as the rose-ringed parakeet. The sheltered climate in southeast Northrhine-Westphalia allows these birds to survive through the winter, and in some cases, they are displacing native species. The plumage of Cologne's green parrots is highly visible even from a distance, and contrasts starkly with the otherwise muted colours of the cityscape.

Cologne had 5.8 million overnight stays booked and 3.35 million arrivals in 2016. The city also has the most pubs per capita in Germany. The city has 70 clubs, "countless" bars, restaurants, and pubs.

The Cologne City Hall ("Kölner Rathaus"), founded in the 12th century, is the oldest city hall in Germany still in use. The Renaissance-style loggia and tower were added in the 15th century. Other famous buildings include the Gürzenich, Haus Saaleck and the Overstolzenhaus.

Of the twelve medieval city gates that once existed, only the Eigelsteintorburg at Ebertplatz, the Hahnentor at Rudolfplatz and the Severinstorburg at Chlodwigplatz still stand today.


Several bridges cross the Rhine in Cologne. They are (from south to north): the Cologne Rodenkirchen Bridge, South Bridge (railway), Severin Bridge, Deutz Bridge, Hohenzollern Bridge (railway), Zoo Bridge ("Zoobrücke") and Cologne Mülheim Bridge. In particular the iron tied arch Hohenzollern Bridge ("Hohenzollernbrücke") is a dominant landmark along the river embankment. A Rhine crossing of a special kind is provided by the Cologne Cable Car (German: "Kölner Seilbahn"), a cableway that runs across the Rhine between the Cologne Zoological Garden in Riehl and the Rheinpark in Deutz.

Cologne's tallest structure is the Colonius telecommunication tower at . The observation deck has been closed since 1992. A selection of the tallest buildings in Cologne is listed below. Other tall structures include the Hansahochhaus (designed by architect Jacob Koerfer and completed in 1925—it was at one time Europe's tallest office building), the Kranhaus buildings at Rheinauhafen, and the Messeturm Köln ("trade fair tower").

Cologne has several museums. The famous Roman-Germanic Museum features art and architecture from the city's distant past; the Museum Ludwig houses one of the most important collections of modern art in Europe, including a Picasso collection matched only by the museums in Barcelona and Paris. The Museum Schnütgen of religious art is partly housed in St. Cecilia, one of Cologne's Twelve Romanesque churches.
Many art galleries in Cologne enjoy a worldwide reputation like e.g. Galerie Karsten Greve, one of the leading galleries for postwar and contemporary art.

Several orchestras are active in the city, among them the Gürzenich Orchestra, which is also the orchestra of the Cologne Opera and the WDR Symphony Orchestra Cologne ("German State Radio Orchestra"), both based at the Cologne Philharmonic Orchestra Building (Kölner Philharmonie). Other orchestras are the Musica Antiqua Köln and the WDR Rundfunkorchester Köln, and several choirs, including the WDR Rundfunkchor Köln. Cologne was also an important hotbed for electronic music in the 1950s (Studio für elektronische Musik, Karlheinz Stockhausen) and again from the 1990s onward. The public radio and TV station WDR was involved in promoting musical movements such as Krautrock in the 1970s; the influential Can was formed there in 1968. There are several centres of nightlife, among them the "Kwartier Latäng" (the student quarter around the Zülpicher Straße) and the nightclub-studded areas around Hohenzollernring, Friesenplatz and Rudolfplatz.

The large annual literary festival Lit. Cologne features regional and international authors. The main literary figure connected with Cologne is the writer Heinrich Böll, winner of the Nobel Prize for Literature.

Cologne is well known for its beer, called Kölsch. Kölsch is also the name of the local dialect. This has led to the common joke of Kölsch being the only language one can drink.

Cologne is also famous for Eau de Cologne (German: "Kölnisch Wasser"; lit: "Water of Cologne"), a perfume created by Italian expatriate Johann Maria Farina at the beginning of the 18th century. During the 18th century, this perfume became increasingly popular, was exported all over Europe by the Farina family and "Farina" became a household name for "Eau de Cologne". In 1803 Wilhelm Mülhens entered into a contract with an unrelated person from Italy named Carlo Francesco Farina who granted him the right to use his family name and Mühlens opened a small factory at Cologne's Glockengasse. In later years, and after various court battles, his grandson Ferdinand Mülhens was forced to abandon the name "Farina" for the company and their product. He decided to use the house number given to the factory at Glockengasse during the French occupation in the early 19th century, 4711. Today, original Eau de Cologne is still produced in Cologne by both the Farina family, currently in the eighth generation, and by Mäurer & Wirtz who bought the 4711 brand in 2006.

The Cologne carnival is one of the largest street festivals in Europe. In Cologne, the carnival season officially starts on 11 November at 11 minutes past 11 a.m. with the proclamation of the new Carnival Season, and continues until Ash Wednesday. However, the so-called "Tolle Tage" (crazy days) do not start until "Weiberfastnacht" (Women's Carnival) or, in dialect, "Wieverfastelovend", the Thursday before Ash Wednesday, which is the beginning of the street carnival. Zülpicher Strasse and its surroundings, Neumarkt square, Heumarkt and all bars and pubs in the city are crowded with people in costumes dancing and drinking in the streets. Hundreds of thousands of visitors flock to Cologne during this time. Generally, around a million people celebrate in the streets on the Thursday before Ash Wednesday.

Cologne and Düsseldorf have a "fierce regional rivalry", which includes carnival parades, football, and beer. People in Cologne prefer Kölsch while people in Düsseldorf prefer Altbier ("Alt"). Waiters and patrons will "scorn" and make a "mockery" of people who order Alt beer in Cologne or Kölsch in Düsseldorf. The rivalry has been described as a "love–hate relationship".


The city was home to the internationally famous Ringfest, and now to the C/o pop festival.<ref name="C/o pop"> </ref>

In addition, Cologne enjoys a thriving Christmas Market ("Weihnachtsmarkt") presence with several locations in the city.

As the largest city in the Rhine-Ruhr metropolitan region, Cologne benefits from a large market structure. In competition with Düsseldorf, the economy of Cologne is primarily based on insurance and media industries, while the city is also an important cultural and research centre and home to a number of corporate headquarters.

Among the largest media companies based in Cologne are Westdeutscher Rundfunk, RTL Television (with subsidiaries), n-tv, Deutschlandradio, Brainpool TV and publishing houses like J. P. Bachem, Taschen, Tandem Verlag, and M. DuMont Schauberg. Several clusters of media, arts and communications agencies, TV production studios, and state agencies work partly with private and government-funded cultural institutions. Among the insurance companies based in Cologne are Central, DEVK, DKV, Generali Deutschland, Gen Re, Gothaer, HDI Gerling and national headquarters of AXA Insurance, Mitsui Sumitomo Insurance Group and Zurich Financial Services.

The German flag carrier Lufthansa and its subsidiary Lufthansa CityLine have their main corporate headquarters in Cologne. The largest employer in Cologne is Ford Europe, which has its European headquarters and a factory in Niehl (Ford-Werke GmbH). Toyota Motorsport GmbH (TMG), Toyota's official motorsports team, responsible for Toyota rally cars, and then Formula One cars, has its headquarters and workshops in Cologne. Other large companies based in Cologne include the REWE Group, TÜV Rheinland, Deutz AG and a number of Kölsch breweries. Cologne has the country's highest density of pubs per capita. The largest three Kölsch breweries are Reissdorf, Gaffel, and Früh.

Historically, Cologne has always been an important trade city, with land, air, and sea connections. The city has five Rhine ports, the second largest inland port in Germany and one of the largest in Europe. Cologne-Bonn Airport is the second largest freight terminal in Germany. Today, the Cologne trade fair ("Koelnmesse") ranks as a major European trade fair location with over 50 trade fairs and other large cultural and sports events. In 2008 Cologne had 4.31 million overnight stays booked and 2.38 million arrivals. Cologne's largest daily newspaper is the "Kölner Stadt-Anzeiger".

Cologne shows a significant increase in startup companies, especially when considering digital business.

Cologne has also become the first German city with a population of more than a million people to declare climate emergency.

Road building had been a major issue in the 1920s under the leadership of mayor Konrad Adenauer. The first German limited-access road was constructed after 1929 between Cologne and Bonn. Today, this is the Bundesautobahn 555. In 1965, Cologne became the first German city to be fully encircled by a motorway ring road. Roughly at the same time, a city centre bypass ("Stadtautobahn") was planned, but only partially put into effect, due to opposition by environmental groups. The completed section became "Bundesstraße ("Federal Road") B 55a", which begins at the "Zoobrücke" ("Zoo Bridge") and meets with A 4 and A 3 at the interchange Cologne East. Nevertheless, it is referred to as "Stadtautobahn" by most locals. In contrast to this, the "Nord-Süd-Fahrt" ("North-South-Drive") was actually completed, a new four/six-lane city centre through-route, which had already been anticipated by planners such as Fritz Schumacher in the 1920s. The last section south of "Ebertplatz" was completed in 1972.

In 2005, the first stretch of an eight-lane motorway in North Rhine-Westphalia was opened to traffic on Bundesautobahn 3, part of the eastern section of the Cologne Beltway between the interchanges Cologne East and Heumar.

Compared to other German cities, Cologne has a traffic layout that is not very bicycle-friendly. It has repeatedly ranked among the worst in an independent evaluation conducted by the Allgemeiner Deutscher Fahrrad-Club. In 2014 it ranked 36th out of 39 German cities with a population greater than 200,000.

Cologne has a railway service with Deutsche Bahn InterCity and ICE-trains stopping at "Köln Hauptbahnhof" (Cologne Main Station), "Köln Messe/Deutz" and "Cologne/Bonn Airport". ICE and TGV Thalys high-speed trains link Cologne with Amsterdam, Brussels (in 1h47, 9 departures/day) and Paris (in 3h14, 6 departures/day). There are frequent ICE trains to other German cities, including Frankfurt am Main and Berlin. ICE Trains to London via the Channel Tunnel were planned for 2013.

The Cologne Stadtbahn operated by Kölner Verkehrsbetriebe (KVB) is an extensive light rail system that is partially underground and serves Cologne and a number of neighbouring cities. It evolved from the tram system. Nearby Bonn is linked by both the Stadtbahn and main line railway trains, and occasional recreational boats on the Rhine. Düsseldorf is also linked by S-Bahn trains, which are operated by Deutsche Bahn.

The Rhine-Ruhr S-Bahn has 5 lines which cross Cologne.The S13/S19 runs 24/7 between Cologne Hbf and Cologne/Bonn airport.

There are also frequent buses covering most of the city and surrounding suburbs, and Eurolines coaches to London via Brussels.

"Häfen und Güterverkehr Köln" (Ports and Goods traffic Cologne, HGK) is one of the largest operators of inland ports in Germany. Ports include Köln-Deutz, Köln-Godorf, and Köln-Niehl I and II.

Cologne's international airport is Cologne/Bonn Airport (CGN). It is also called Konrad Adenauer Airport after Germany's first post-war Chancellor Konrad Adenauer, who was born in the city and was mayor of Cologne from 1917 until 1933. The airport is shared with the neighbouring city of Bonn. Cologne is headquarters to the European Aviation Safety Agency (EASA).

Cologne is home to numerous universities and colleges, and host to some 72,000 students. Its oldest university, the University of Cologne (founded in 1388) is the largest university in Germany, as the Cologne University of Applied Sciences is the largest university of Applied Sciences in the country. The Cologne University of Music and Dance is the largest conservatory in Europe. Foreigners can have German lessons in the VHS (Adult Education Centre).
Within Germany, Cologne is known as an important media centre. Several radio and television stations, including Westdeutscher Rundfunk (WDR), RTL and VOX, have their headquarters in the city. Film and TV production is also important. The city is "Germany's capital of TV crime stories". A third of all German TV productions are made in the Cologne region. Furthermore, the city hosts the Cologne Comedy Festival, which is considered to be the largest comedy festival in mainland Europe.

Cologne hosts 1. FC Köln, who play in the 1. Bundesliga. They play their home matches in RheinEnergieStadion which also hosted 5 matches of the 2006 FIFA World Cup. The International Olympic Committee and Internationale Vereinigung Sport- und Freizeiteinrichtungen e.V. gave RheinEnergieStadion a bronze medal for "being one of the best sporting venues in the world". Cologne also hosts FC Viktoria Köln 1904 and SC Fortuna Köln, who play in the Regionalliga West (fourth division) and the 3. Liga (third division) respectively.

The city is also home of the ice hockey team Kölner Haie, in the highest ice hockey league in Germany, the Deutsche Eishockey Liga. They are based at Lanxess Arena.

Several horse races per year are held at Cologne-Weidenpesch Racecourse since 1897, the annual Cologne Marathon was started in 1997. Besides, Cologne has a long tradition in rowing, being home of some of Germany's oldest regatta courses and boat clubs, such as the Kölner Rudergesellschaft 1891 in the district Rodenkirchen.

Japanese automotive manufacturer Toyota have their major motorsport facility known by the name Toyota Motorsport GmbH. Which is located in Marsdorf suburb, and is responsible for Toyota's major motorsport development and operations, which in the past included the FIA Formula One World Championship, the FIA World Rally Championship and the Le Mans Series. Currently they are working on Toyota's team (Toyota Gazoo Racing) which competes in the FIA World Endurance Championship.

Cologne is considered "the secret golf capital of Germany". The first golf club in North Rhine-Westphalia was founded in Cologne in 1906. The city offers the most options and top events in Germany.

The city has hosted several athletic events which includes the 2005 FIFA Confederations Cup, 2006 FIFA World Cup, 2007 World Men's Handball Championship, 2010 and 2017 Ice Hockey World Championships and 2010 Gay Games.

Since 2014, the city has hosted ESL One Cologne, one of the biggest CS GO tournaments held annually in July/August at Lanxess Arena.

Notable people, whose roots can be found in Cologne:

Cologne is twinned with:




</doc>
<doc id="6188" url="https://en.wikipedia.org/wiki?curid=6188" title="Buddhist cuisine">
Buddhist cuisine

Buddhist cuisine is an Asian cuisine that is followed by monks and many believers from areas historically influenced by Mahayana Buddhism. It is vegetarian or vegan, and it is based on the Dharmic concept of ahimsa (non-violence). Vegetarianism is common in other Dharmic faiths such as Hinduism, Jainism and Sikhism, as well as East Asian religions like Taoism. While monks and a minority of believers are vegetarian year-round, many believers follow the Buddhist vegetarian diet for celebrations.

The origin of "Buddhist food" as a distinct sub-style of cuisine is tied to monasteries, where one member of the community would have the duty of being the head cook and supplying meals that paid respect to the strictures of Buddhist precepts. Temples that were open to visitors from the general public might also serve meals to them and a few temples effectively run functioning restaurants on the premises. In Japan, this practice is generally known as , and served at many temples, especially in Kyoto. A more recent version, more Chinese in style, is prepared by the Ōbaku school of zen, and known as ; this is served at the head temple of Manpuku-ji, as well as various subtemples. In modern times, commercial restaurants have also latched on to the style, catering both to practicing and non-practicing lay people.

Most of the dishes considered to be uniquely Buddhist are vegetarian, but not all Buddhist traditions require vegetarianism of lay followers or clergy. Vegetarian eating is primarily associated with the East Asian tradition in China, Vietnam, Japan, and Korea where it is commonly practiced by clergy and may be observed by laity on holidays or as a devotional practice.

In the Mahayana tradition, several sutras of the Mahayana canon contain explicit prohibitions against consuming meat, including sections of the Lankavatara Sutra and Surangama Sutra. The monastic community in Chinese Buddhism, Vietnamese Buddhism and most of Korean Buddhism strictly adhere to vegetarianism.Japanese Buddhist sects generally believe that Buddha ate meat. All Japanese Kamakura sects of Buddhism (Zen, Nichiren, Jodo) have relaxed Mahayana vinaya, and as a consequence, vegetarianism is optional. 

Theravada Monks and nuns traditionally feed themselves by gathering alms, and generally must eat whatever foods are given to them, including meat. The exception to this alms rule is when monks and nuns have seen, heard or known that animal(s) have been specifically killed to feed the alms-seeker, in which case consumption of such meat would be karmically negative, as well as meat from certain animals, such as dogs and snakes, that were regarded as impure in ancient India. The same restriction is also followed by some lay Buddhists and is known as the consumption of "triply clean meat" (三净肉). The Pali Sutras also describe the Buddha as refusing a suggestion by his student Devadatta to mandate vegetarianism in the monastic precepts.

Tibetan Buddhism has long accepted that the practical difficulties in obtaining vegetables and grains within most of Tibet make it impossible to insist upon vegetarianism; however, many leading Tibetan Buddhist teachers agree upon the great worth of practicing vegetarianism whenever and wherever possible.

Both Mahayana and Theravada Buddhists consider that one may practice vegetarianism as part of cultivating Bodhisattvas's paramita.

In addition to the ban on garlic practically all Mahayana monastics in China, Korea, Vietnam and Japan specifically avoid eating strong-smelling plants, traditionally asafoetida, shallot, mountain leek and Allium chinense, which together with garlic are referred to as "wǔ hūn" (五葷, or 'Five Acrid and Strong-smelling Vegetables') or "wǔ xīn" (五辛 or 'Five Spices') as they tend to excite senses. This is based on teachings found in the Brahamajala Sutra, the Surangama Sutra and the Lankavatara Sutra (chapter eight). In modern times this rule is often interpreted to include other vegetables of the onion genus, as well as coriander. The origin of this additional restriction is from the Indic region and can still be found among some believers of Hinduism and Jainism. Some Taoists also have this additional restriction but the list of restricted plants differs from the Buddhist list.
The food that a strict Buddhist takes, if not a vegetarian, is also specific. For many Chinese Buddhists beef and the consumption of large animals and exotic species is avoided. Then there would be the aforementioned "triply clean meat" rule. One restriction on food that is not known to many is the abstinence from eating animal innards and organs. This is known as "xiàshui" (下水), not to be confused with the term for sewage.

Alcohol and other drugs are also avoided by many Buddhists because of their effects on the mind and "mindfulness". It is part of the Five Precepts which dictate that one is not to consume "addictive materials". The definition of "addictive" depends on each individual but most Buddhists consider alcohol, tobacco and drugs other than medicine to be addictive. Although caffeine is now also known to be addictive, caffeinated drinks and especially tea are not included under this restriction; tea in particular is considered to be healthful and beneficial and its mild stimulant effect desirable. There are many legends about tea. Among meditators it is considered to keep the person alert and awake without overexcitement.

In theory and practice, many regional styles of cooking may be adopted to be "Buddhist" as long as the cook, with the above restrictions in mind, prepares the food, generally in simple preparations, with expert attention to its quality, wholesomeness and flavor. Often working on a tight budget, the monastery cook would have to make the most of whatever ingredients were available.

In "Tenzo kyokun" ("Instructions for the Zen Cook"), Soto Zen founder Eihei Dogen wrote the following about the Zen attitude toward food:

In preparing food, it is essential to be sincere and to respect each ingredient regardless of how coarse or fine it is. (...) A rich buttery soup is not better as such than a broth of wild herbs. In handling and preparing wild herbs, do so as you would the ingredients for a rich feast, wholeheartedly, sincerely, clearly. When you serve the monastic assembly, they and you should taste only the flavour of the Ocean of Reality, the Ocean of unobscured Awake Awareness, not whether or not the soup is creamy or made only of wild herbs. In nourishing the seeds of living in the Way, rich food and wild grass are not separate.""

Following its dominant status in most parts of East Asia where Buddhism is most practiced, rice features heavily as a staple in the Buddhist meal, especially in the form of rice porridge or congee as the usual morning meal. Noodles and other grains may often be served as well. Vegetables of all sorts are generally either stir-fried or cooked in vegetarian broth with seasonings and may be eaten with various sauces. Traditionally eggs and dairy are not permitted. Seasonings will be informed by whatever is common in the local region; for example, soy sauce and vegan dashi figure strongly in Japanese monastery food while curry and Tương (as a vegetarian replacement for fish sauce) may be prominent in Southeast Asia. Sweets and desserts are not often consumed, but are permitted in moderation and may be served at special occasions such as in the context of a tea ceremony in the Zen tradition.

Buddhist vegetarian chefs have become extremely creative in imitating meat using prepared wheat gluten, also known as seitan, kao fu (烤麸) or wheat meat, soy (such as tofu or tempeh), agar, konnyaku and other plant products. Some of their recipes are the oldest and most-refined meat analogues in the world. Soy and wheat gluten are very versatile materials, because they can be manufactured into various shapes and textures, and they absorb flavorings (including, but not limited to, meat-like flavorings), while having very little flavor of their own. With the proper seasonings, they can mimic various kinds of meat quite closely.

Some of these Buddhist vegetarian chefs are in the many monasteries and temples which serve allium-free and mock-meat (also known as 'meat analogues') dishes to the monks and visitors (including non-Buddhists who often stay for a few hours or days, to Buddhists who are not monks, but staying overnight for anywhere up to weeks or months). Many Buddhist restaurants also serve vegetarian, vegan, non-alcoholic or allium-free dishes.

Some Buddhists eat vegetarian on the 1st and 15th of the lunar calendar (lenten days), on Chinese New Year eve, and on saint and ancestral holy days. To cater to this type of customer, as well as full-time vegetarians, the menu of a Buddhist vegetarian restaurant usually shows no difference from a typical Chinese or East Asian restaurant, except that in recipes originally made to contain meat, a soy chicken substitute might be served instead.

According to cookbooks published in English, formal monastery meals in the Zen tradition generally follow a pattern of "three bowls" in descending size. The first and largest bowl is a grain-based dish such as rice, noodles or congee; the second contains the protein dish which is often some form of stew or soup; the third and smallest bowl is a vegetable dish or a salad.




</doc>
<doc id="6191" url="https://en.wikipedia.org/wiki?curid=6191" title="Charles V">
Charles V

Charles V may refer to:




</doc>
<doc id="6193" url="https://en.wikipedia.org/wiki?curid=6193" title="Constantin von Tischendorf">
Constantin von Tischendorf

Lobegott Friedrich Constantin (von) Tischendorf (18 January 1815 – 7 December 1874) was a world-leading biblical scholar in his time. In 1844, he discovered the world's oldest and most complete Bible, dated to around the mid-4th century and called Codex Sinaiticus, after the St. Catherine's Monastery at Mt. Sinai, where Tischendorf discovered it. Tischendorf was made an Honorary Doctor by Oxford University on 16 March 1865, and an Honorary Doctor by Cambridge University on 9 March 1865 following this find of the century. While a student gaining his academic degree in the 1840s, he earned international recognition when he deciphered the "Codex Ephraemi Rescriptus", a 5th-century Greek manuscript of the New Testament. 

Tischendorf was born in Lengenfeld, Saxony, near Plauen, the son of a physician. Beginning in 1834, he spent his scholarly career at the University of Leipzig where he was mainly influenced by JGB Winer, and he began to take special interest in New Testament criticism. Winer's influence gave him the desire to use the oldest manuscripts in order to compile the text of the New Testament as close to the original as possible. In 1838 he took the degree of Doctor of Philosophy, then became master at a school near Leipzig.

After a journey through southern Germany and Switzerland, and a visit to Strassburg, he returned to Leipzig, and set to work upon a critical study of the New Testament text. 

In 1840 he qualified as university lecturer in theology with a dissertation on the recensions of the New Testament text, the main part of which reappeared the following year in the prolegomena to his first edition of the Greek New Testament. His critical apparatus included variant readings from earlier scholars, Elsevier, Georg Christian Knapp, Johann Martin Augustin Scholz, and as recent as Karl Lachmann, whereby his research was emboldened to depart from the received text as used in churches. These early textual studies convinced him of the absolute necessity of new and more exact collations of manuscripts. 

From October 1840 until January 1843 he was in Paris, busy with the treasures of the Bibliothèque Nationale, eking out his scanty means by making collations for other scholars, and producing for the publisher, Firmin Didot, several editions of the Greek New Testament – one of them exhibiting the form of the text corresponding most closely to the Vulgate. His second edition retracted the more precarious readings of the first, and included a statement of critical principles that is a landmark for evolving critical studies of Biblical texts.

A great triumph of these laborious months was the decipherment of the palimpsest "Codex Ephraemi Syri Rescriptus", of which the New Testament part was printed before he left Paris, and the Old Testament in 1845. His success in dealing with a manuscript that, having been over-written with other works of Ephrem the Syrian, had been mostly illegible to earlier collators, made him more well known, and gained support for more extended critical expeditions. He now became "professor extraordinarius" at Leipzig, and where he was married in 1845. He also began to publish "Reise in den Orient", an account of his travels in the east (in 2 vols., 1845–46, translated as "Travels in the East" in 1847). Even though he was an expert in reading the text of a palimpsest (this is a document where the original writing has been removed and new writing added), he was not able to identify the value or meaning of the "Archimedes Palimpsest", a torn leaf of which he held and after his death was sold to the Cambridge University Library.

From Paris, he had paid short visits to the Netherlands (1841) and England (1842). In 1843 he visited Italy, and after a stay of thirteen months, went on to Egypt, Sinai, and the Levant, returning via Vienna and Munich.

In 1844 Tischendorf travelled the first time to Saint Catherine's Monastery at the foot of Mount Sinai in Egypt, where he found a portion of what would later be hailed as the oldest complete known Bible. Of the many pages which were contained in an old wicker basket (the kind that the monastery hauled in its visitors as customary in unsafe territories) he was given 43 pages containing a part of the Old Testament as a present. He donated those 43 pages to King Frederick Augustus II of Saxony (reigned 1836–1854), to honour him and to recognise his patronage as the funder of Tischenforf's journey. (Tischendorf held a position as Theological Professor at Leipzig University, also under the patronage of Frederick Augustus II.) Leipzig University put two of the leaves on display in 2011.
Tischendorf reported in his 1865 book "Wann Wurden Unsere Evangelen Verfasst", translated to English in 1866 as "When Were Our Gospels Written" in the section "The Discovery of the Sinaitic Manuscript" that he found, in a trash basket, forty-three sheets of parchment of an ancient copy of the Greek Old Testament, reporting that the monks were using the trash to start fires. And Tischendorf, horrified, asked if he could have them. He deposited them at the University of Leipzig, under the title of the "Codex Friderico-Augustanus", a name given in honour of his patron, Frederick Augustus II of Saxony, king of Saxony. The fragments were published in 1846, although Tischendorf kept the place of discovery a secret.

Many have expressed skepticism at the historical accuracy of this report of saving a 1500-year-old parchment from the flames. J. Rendel Harris referred to the story as a "myth". The Tischendorf Lesebuch (see References) quotes that the Librarian Kyrillos mentioned to Tischendorf that the contents of the basket had already twice been submitted to the fire. The contents of the baskets were damaged scriptures, the third filling apparently, so cited by Tischendorf himself.[see Tischendorf Lesebuch, Tischendorf's own account]. 
In 1853 Tischendorf made a second trip to the Syrian monastery but made no new discoveries. He returned a third time in January 1859 under the patronage of Tsar Alexander II of Russia with the active aid of the Russian government to find more of the "Codex Frederico-Augustanus" or similar ancient Biblical texts. On February 4, the last day of his visit, he was shown a text which he recognized as significant – the "Codex Sinaiticus" – a Greek manuscript of the complete New Testament and parts of the Old Testament dating to the 4th century.

Tischendorf persuaded the monks to present the manuscript to Tsar Alexander II of Russia, at the cost of the Tsar it was published in 1862 (in four folio volumes). Those ignorant of the details of his discovery of the "Codex Sinaiticus" accused Tischendorf of buying manuscripts from ignorant monastery librarians at low prices. Indeed, he was never rich, but he staunchly defended the rights of the monks at Saint Catherine's Monastery when he persuaded them eventually to send the manuscript to the Tsar. This took approximately 10 years because the abbot of St Catherines had to be re-elected and confirmed in office in Cairo and in Jerusalem, and during those 10 years no one in the monastery had the authority to hand over any documents. However the documents were handed over in due course following a signed and sealed letter to the Tsar Alexander II (Schenkungsurkunde). Even so, the monks of Mt. Sinai still display a receipt-letter from Tischendorf promising to return the manuscript to them in the case that the donation can not be done. This token-letter had to be destroyed, following the late issue of a "Schenkungsurkunde". This donation act regulated the Codex exchange with the Tsar, against 9000 Rubels and Rumanian estate protection. The Tsar was seen as the protector of Greek-Orthodox Christians. Thought lost since the Russian revolution, the document (Schenkungsurkunde) has now resurfaced in St Petersburg 2003, and has also been long before commented upon by other scholars like Kurt Aland. The monastery has disputed the existence of the gift certificate (Schenkungsurkunde) since the British Library was named as the new owner of the Codex. Now following the late find of the gift certificate by the National Russian Library the existence cannot be disputed in earnest. In 1869 the Tsar awarded Tischendorf the style of "von" Tischendorf as a Russian noble. 327 facsimile editions of the Codex were printed in Leipzig for the Tsar (instead of a salary for the three-year work of Tischendorf the Tsar gave him 100 copies for reselling) in order to celebrate the 1000th anniversary of the traditional foundation of the Rus' state in 862 with the publication of this most amazing find. Supporting the production of the facsimile, all made with special print characters for each of the 4 scribes of the Codex Sinaiticus, was shift work and contributed to Tischendorf's early demise due to exhausting work for months also during nights. Thus the Codex found its way to the Imperial Library at St. Petersburg.

When the 4-volume luxury edition of the Sinai Bible was completed in 1862, C. Tischendorf presented the original ancient manuscript to Emperor Alexander II. Meanwhile, the question of transferring the manuscript to the full possession of the Russian Sovereign remained unresolved for some years. In 1869, the new Archbishop of Sinai, Callistratus, and the monastic community, signed the official certificate presenting the manuscript to the Tsar. The Russian Government, in turn, bestowed the Monastery with 9000 rubles and decorated the Archbishop and some of the brethren with orders. In 1933 the Soviet Government sold the Codex Sinaiticus for 100,000 pounds to the British Museum in London, England. The official certificate with signatures in Russian/ French/ Greek sections has been refound in St Petersburg.

In the winter of 1849 the first edition of his great work now titled "Novum Testamentum Graece. Ad antiquos testes recensuit. Apparatum criticum multis modis" appeared (translated as "Greek New Testament. The ancient witnesses reviewed. Preparations critical in many ways"), containing canons of criticism, adding examples of their application that are applicable to students today:

Basic rule: "The text is only to be sought from ancient evidence, and especially from Greek manuscripts, but without neglecting the testimonies of versions and fathers."
These were partly the result of the tireless travels he had begun in 1839 in search of unread manuscripts of the New Testament, "to clear up in this way," he wrote, "the history of the sacred text, and to recover if possible the genuine apostolic text which is the foundation of our faith."

In 1850 appeared his edition of the "Codex Amiatinus" (in 1854 corrected) and of the Septuagint version of the Old Testament (7th ed., 1887); in 1852, amongst other works, his edition of the "Codex Claromontanus".

Meanwhile, also in 1859, he had been made "professor ordinarius" of theology and of Biblical paleography, this latter professorship being specially created for him; and another book of travel, "Aus dem heiligen Lande", appeared in 1862. Tischendorf's Eastern journeys were rich enough in other discoveries to merit the highest praise.

Besides his fame as a scholar, he was a friend of both Robert Schumann, with whom he corresponded, and Felix Mendelssohn, who dedicated a song to him. His text critical colleague Samuel Prideaux Tregelles wrote warmly of their mutual interest in textual scholarship. His personal library, purchased after his death, eventually came to the University of Glasgow, where a commemorative exhibition of books from his library was held in 1974 and can be accessed by the public.

He died in Leipzig.

The "Codex Sinaiticus" contains a 4th-century manuscript of New Testament texts. Two other Bibles of similar age exist, though they are less complete: Codex Vaticanus in the Vatican Library and Codex Alexandrinus, currently owned by the British Library. The Codex Sinaiticus is deemed by some to be the most important surviving New Testament manuscript, as no older manuscript is as nearly complete as the Codex. The codex can be viewed in the British Library in London, or as a digitized version on the Internet.

Throughout his life Tischendorf sought old biblical manuscripts, as he saw it as his task to give theology a Greek New Testament which was based on the oldest possible scriptures. He intended to be as close as possible to the original sources. Tischendorf's greatest discovery was in the monastery of Saint Catherine on the Sinai Peninsula, which he visited in May 1844, and again in 1853 and 1859 (as Russian envoy).

In 1862 Tischendorf published the text of the Codex Sinaiticus for the 1000th Anniversary of the Russian Monarchy in both an illustrious four-volume facsimile edition and in a less costly text edition, to enable all scholars to have access to the Codex.

Tischendorf pursued a constant course of editorial labours, mainly on the New Testament, until he was broken down by overwork in 1873. His motive, as explained in a publication on Tischendorf's Letter by Prof. Christfried Boettrich (Leibzig University, Prof. of Theology), was to prove scientifically that the words of the Bible were trustfully transmitted over centuries.

His "magnum opus" was the "Critical Edition of the New Testament."

The great edition, of which the text and apparatus appeared in 1869 and 1872, was called by himself "editio viii"; but this number is raised to twenty or twenty-one, if mere reprints from stereotype plates and the minor editions of his great critical texts are included; posthumous prints bring the total to forty-one. Four main recensions of Tischendorf's text may be distinguished, dating respectively from his editions of 1841, 1849, 1859 (ed. vii), and 1869–72 (ed. viii). The edition of 1849 may be regarded as historically the most important, from the mass of new critical material it used; that of 1859 is distinguished from Tischendorf's other editions by coming nearer to the received text; in the eighth edition, the testimony of the Sinaitic manuscript received great (probably too great) weight. The readings of the Vatican manuscript were given with more exactness and certainty than had been possible in the earlier editions, and the editor had also the advantage of using the published labours of his colleague and friend Samuel Prideaux Tregelles.

Of relatively lesser importance was Tischendorf's work on the Greek Old Testament. His edition of the Roman text, with the variants of the Alexandrian manuscript, the "Codex Ephraemi", and the "Friderico-Augustanus", was of service when it appeared in 1850, but, being stereotyped, was not greatly improved in subsequent issues. Its imperfections, even within the limited field it covers, may be judged by the aid of Eberhard Nestle's appendix to the 6th issue (1880).

Besides this may be mentioned editions of the New Testament apocrypha, "De Evangeliorum apocryphorum origine et usu" (1851); "Acta Apostolorum apocrypha" (1851); "Evangelia apocrypha" (1853; 2nd ed., 1876); "Apocalypses apocryphae" (1866), and various minor writings, partly of an apologetic character, such as "Wann wurden unsere Evangelien verfasst?" ("When Were Our Gospels Written?"; 1865; 4th ed., 1866, digitized by Google and available for e-readers), "Haben wir den echten Schrifttext der Evangelisten und Apostel?" (1873), and "Synopsis evangelica" (7th ed., 1898).













</doc>
<doc id="6195" url="https://en.wikipedia.org/wiki?curid=6195" title="Calvin Coolidge">
Calvin Coolidge

Calvin Coolidge (born John Calvin Coolidge Jr.; ; July 4, 1872 – January 5, 1933) was an American politician and lawyer who served as the 30th president of the United States from 1923 to 1929. A Republican lawyer from New England, born in Vermont, Coolidge worked his way up the ladder of Massachusetts state politics, eventually becoming governor of Massachusetts. His response to the Boston Police Strike of 1919 thrust him into the national spotlight and gave him a reputation as a man of decisive action. The next year, he was elected the 29th vice president of the United States, and he succeeded to the presidency upon the sudden death of Warren G. Harding in 1923. Elected in his own right in 1924, he gained a reputation as a small-government conservative and also as a man who said very little and had a rather dry sense of humor.

Coolidge restored public confidence in the White House after the scandals of his predecessor's administration, and left office with considerable popularity. As a Coolidge biographer wrote: "He embodied the spirit and hopes of the middle class, could interpret their longings and express their opinions. That he did represent the genius of the average is the most convincing proof of his strength".

Scholars have ranked Coolidge in the lower half of those presidents that they have assessed. He is praised by advocates of smaller government and laissez-faire economics, while supporters of an active central government generally view him less favorably, although most praise his stalwart support of racial equality.

John Calvin Coolidge Jr. was born on July 4, 1872 in Plymouth Notch, Windsor County, Vermont, the only US president to be born on Independence Day. He was the elder of the two children of John Calvin Coolidge Sr. (1845–1926) and Victoria Josephine Moor (1846–1885). Although named for his father, John, from early childhood Coolidge was addressed by his middle name, Calvin. His middle name was selected in honor of John Calvin, considered a founder of the Congregational church in which Coolidge was raised and remained active throughout his life.

Coolidge Senior engaged in many occupations and developed a statewide reputation as a prosperous farmer, storekeeper, and public servant. He held various local offices, including justice of the peace and tax collector and served in the Vermont House of Representatives as well as the Vermont Senate. Coolidge's mother was the daughter of a Plymouth Notch farmer. She was chronically ill and died, perhaps from tuberculosis, when Coolidge was twelve years old. His younger sister, Abigail Grace Coolidge (1875–1890), died at the age of 15, probably of appendicitis, when Coolidge was 18. Coolidge's father married a Plymouth schoolteacher in 1891, and lived to the age of 80.

Coolidge's family had deep roots in New England; his earliest American ancestor, John Coolidge, emigrated from Cottenham, Cambridgeshire, England, around 1630 and settled in Watertown, Massachusetts. Coolidge's great-great-grandfather, also named John Coolidge, was an American military officer in the Revolutionary War and one of the first selectmen of the town of Plymouth. His grandfather Calvin Galusha Coolidge served in the Vermont House of Representatives. Coolidge was also a descendant of Samuel Appleton, who settled in Ipswich and led the Massachusetts Bay Colony during King Philip's War.

Coolidge attended Black River Academy and then St. Johnsbury Academy, before enrolling at Amherst College, where he distinguished himself in the debating class. As a senior, he joined the fraternity Phi Gamma Delta and graduated "cum laude". While at Amherst, Coolidge was profoundly influenced by philosophy professor Charles Edward Garman, a Congregational mystic, with a neo-Hegelian philosophy.

Coolidge explained Garman's ethics forty years later:
[T]here is a standard of righteousness that might does not make right, that the end does not justify the means, and that expediency as a working principle is bound to fail. The only hope of perfecting human relationships is in accordance with the law of service under which men are not so solicitous about what they shall get as they are about what they shall give. Yet people are entitled to the rewards of their industry. What they earn is theirs, no matter how small or how great. But the possession of property carries the obligation to use it in a larger service...

At his father's urging after graduation, Coolidge moved to Northampton, Massachusetts to become a lawyer. To avoid the cost of law school, Coolidge followed the common practice of apprenticing with a local law firm, Hammond & Field, and reading law with them. John C. Hammond and Henry P. Field, both Amherst graduates, introduced Coolidge to law practice in the county seat of Hampshire County, Massachusetts. In 1897, Coolidge was admitted to the Massachusetts bar, becoming a country lawyer. With his savings and a small inheritance from his grandfather, Coolidge opened his own law office in Northampton in 1898. He practiced commercial law, believing that he served his clients best by staying out of court. As his reputation as a hard-working and diligent attorney grew, local banks and other businesses began to retain his services.

In 1903, Coolidge met Grace Anna Goodhue, a University of Vermont graduate and teacher at Northampton's Clarke School for the Deaf. They married on October 4, 1905 at 2:30 p.m. in a small ceremony which took place in the parlor of Grace's family's house, having overcome his future mother-in-law's objections to the marriage. The newlyweds went on a honeymoon trip to Montreal, originally planned for two weeks but cut short by a week at Coolidge's request. After 25 years he wrote of Grace, "for almost a quarter of a century she has borne with my infirmities and I have rejoiced in her graces".

The Coolidges had two sons: John (September 7, 1906 – May 31, 2000) and Calvin Jr. (April 13, 1908 – July 7, 1924). Calvin Jr. died at age 16 from blood poisoning. On June 30, 1924 Calvin Jr. had played tennis with his brother on the White House tennis courts without putting on socks and developed a blister on one of his toes. The blister subsequently degenerated into sepsis and Calvin Jr. died a little over a week later. The President never forgave himself for Calvin Jr's death. His eldest John said it "hurt [Coolidge] terribly." John became a railroad executive, helped to start the Coolidge Foundation, and was instrumental in creating the President Calvin Coolidge State Historic Site.

Coolidge was frugal, and when it came to securing a home, he insisted upon renting. He and his wife attended Northampton's Edwards Congregational Church before and after his presidency.

The Republican Party was dominant in New England at the time, and Coolidge followed the example of Hammond and Field by becoming active in local politics. In 1896, Coolidge campaigned for Republican presidential candidate William McKinley, and the next year he was selected to be a member of the Republican City Committee. In 1898, he won election to the City Council of Northampton, placing second in a ward where the top three candidates were elected. The position offered no salary but provided Coolidge invaluable political experience. In 1899, he declined renomination, running instead for City Solicitor, a position elected by the City Council. He was elected for a one-year term in 1900, and reelected in 1901. This position gave Coolidge more experience as a lawyer and paid a salary of $600 (). In 1902, the city council selected a Democrat for city solicitor, and Coolidge returned to private practice. Soon thereafter, however, the clerk of courts for the county died, and Coolidge was chosen to replace him. The position paid well, but it barred him from practicing law, so he remained at the job for only one-year. In 1904, Coolidge suffered his sole defeat at the ballot box, losing an election to the Northampton school board. When told that some of his neighbors voted against him because he had no children in the schools he would govern, the recently married Coolidge replied, "Might give me time!"

In 1906, the local Republican committee nominated Coolidge for election to the Massachusetts House of Representatives. He won a close victory over the incumbent Democrat, and reported to Boston for the 1907 session of the Massachusetts General Court. In his freshman term, Coolidge served on minor committees and, although he usually voted with the party, was known as a Progressive Republican, voting in favor of such measures as women's suffrage and the direct election of Senators. While in Boston, Coolidge became an ally, and then a liegeman, of then US Senator Winthrop Murray Crane who controlled the western faction of the Massachusetts Republican Party; Crane's party rival in the east of the commonwealth was US Senator Henry Cabot Lodge. Coolidge forged another key strategic alliance with Guy Currier, who had served in both state houses and had the social distinction, wealth, personal charm and broad circle of friends which Coolidge lacked, and which would have a lasting impact on his political career. In 1907, he was elected to a second term, and in the 1908 session Coolidge was more outspoken, though not in a leadership position.
Instead of vying for another term in the State House, Coolidge returned home to his growing family and ran for mayor of Northampton when the incumbent Democrat retired. He was well liked in the town, and defeated his challenger by a vote of 1,597 to 1,409. During his first term (1910 to 1911), he increased teachers' salaries and retired some of the city's debt while still managing to effect a slight tax decrease. He was renominated in 1911, and defeated the same opponent by a slightly larger margin.

In 1911, the State Senator for the Hampshire County area retired and successfully encouraged Coolidge to run for his seat for the 1912 session; Coolidge defeated his Democratic opponent by a large margin. At the start of that term, he became chairman of a committee to arbitrate the "Bread and Roses" strike by the workers of the American Woolen Company in Lawrence, Massachusetts. After two tense months, the company agreed to the workers' demands, in a settlement proposed by the committee. A major issue affecting Massachusetts Republicans that year was the party split between the progressive wing, which favored Theodore Roosevelt, and the conservative wing, which favored William Howard Taft. Although he favored some progressive measures, Coolidge refused to leave the Republican party. When the new Progressive Party declined to run a candidate in his state senate district, Coolidge won reelection against his Democratic opponent by an increased margin.

In the 1913 session, Coolidge enjoyed renowned success in arduously navigating to passage the Western Trolley Act, which connected Northampton with a dozen similar industrial communities in western Massachusetts. Coolidge intended to retire after his second term as was the custom, but when the President of the State Senate, Levi H. Greenwood, considered running for Lieutenant Governor, Coolidge decided to run again for the Senate in the hopes of being elected as its presiding officer. Although Greenwood later decided to run for reelection to the Senate, he was defeated primarily due to his opposition to women's suffrage; Coolidge was in favor of the women's vote, won his own re-election and with Crane's help, assumed the presidency of a closely divided Senate. After his election in January 1914, Coolidge delivered a published and frequently quoted speech entitled "Have Faith in Massachusetts", which summarized his philosophy of government.

Coolidge's speech was well received, and he attracted some admirers on its account; towards the end of the term, many of them were proposing his name for nomination to lieutenant governor. After winning reelection to the Senate by an increased margin in the 1914 elections, Coolidge was reelected unanimously to be President of the Senate. Coolidge's supporters, led by fellow Amherst alumnus Frank Stearns, encouraged him again to run for lieutenant governor. Stearns, an executive with the Boston department store R. H. Stearns, became another key ally, and began a publicity campaign on Coolidge's behalf before he announced his candidacy at the end of the 1915 legislative session.

Coolidge entered the primary election for lieutenant governor and was nominated to run alongside gubernatorial candidate Samuel W. McCall. Coolidge was the leading vote-getter in the Republican primary, and balanced the Republican ticket by adding a western presence to McCall's eastern base of support. McCall and Coolidge won the 1915 election to their respective one-year terms, with Coolidge defeating his opponent by more than 50,000 votes.

In Massachusetts, the lieutenant governor does not preside over the state Senate, as is the case in many other states; nevertheless, as lieutenant governor, Coolidge was a deputy governor functioning as administrative inspector and was a member of the governor's council. He was also chairman of the finance committee and the pardons committee. As a full-time elected official, Coolidge discontinued his law practice in 1916, though his family continued to live in Northampton. McCall and Coolidge were both reelected in 1916 and again in 1917. When McCall decided that he would not stand for a fourth term, Coolidge announced his intention to run for governor.

Coolidge was unopposed for the Republican nomination for Governor of Massachusetts in 1918. He and his running mate, Channing Cox, a Boston lawyer and Speaker of the Massachusetts House of Representatives, ran on the previous administration's record: fiscal conservatism, a vague opposition to Prohibition, support for women's suffrage, and support for American involvement in World War I. The issue of the war proved divisive, especially among Irish and German Americans. Coolidge was elected by a margin of 16,773 votes over his opponent, Richard H. Long, in the smallest margin of victory of any of his statewide campaigns.

In 1919, in reaction to a plan of the policemen of the Boston Police Department to register with a union, Police Commissioner Edwin U. Curtis announced that such an act would not be tolerated. In August of that year, the American Federation of Labor issued a charter to the Boston Police Union. Curtis declared the union's leaders were guilty of insubordination and would be relieved of duty, but indicated he would cancel their suspension if the union was dissolved by September 4. The mayor of Boston, Andrew Peters, convinced Curtis to delay his action for a few days, but with no results, and Curtis suspended the union leaders on September 8. The following day, about three-quarters of the policemen in Boston went on strike. Coolidge, tacitly but fully in support of Curtis' position, closely monitored the situation but initially deferred to the local authorities. He anticipated that only a resulting measure of lawlessness could sufficiently prompt the public to understand and appreciate the controlling principle – that a policeman does not strike. That night and the next, there was sporadic violence and rioting in the unruly city. Peters, concerned about sympathy strikes by the firemen and others, called up some units of the Massachusetts National Guard stationed in the Boston area pursuant to an old and obscure legal authority, and relieved Curtis of duty.

Coolidge, sensing the severity of circumstances were then in need of his intervention, conferred with Crane's operative, William Butler, and then acted. He called up more units of the National Guard, restored Curtis to office, and took personal control of the police force. Curtis proclaimed that all of the strikers were fired from their jobs, and Coolidge called for a new police force to be recruited.
That night Coolidge received a telegram from AFL leader Samuel Gompers. "Whatever disorder has occurred", Gompers wrote, "is due to Curtis's order in which the right of the policemen has been denied…" Coolidge publicly answered Gompers's telegram, denying any justification whatsoever for the strike – and his response launched him into the national consciousness. Newspapers across the nation picked up on Coolidge's statement and he became the newest hero to opponents of the strike. In the midst of the First Red Scare, many Americans were terrified of the spread of communist revolution, like those that had taken place in Russia, Hungary, and Germany. While Coolidge had lost some friends among organized labor, conservatives across the nation had seen a rising star. Although he usually acted with deliberation, the Boston police strike gave him a national reputation as a decisive leader, and as a strict enforcer of law and order.

Coolidge and Cox were renominated for their respective offices in 1919. By this time Coolidge's supporters (especially Stearns) had publicized his actions in the Police Strike around the state and the nation and some of Coolidge's speeches were published in book form. He faced the same opponent as in 1918, Richard Long, but this time Coolidge defeated him by 125,101 votes, more than seven times his margin of victory from a year earlier. His actions in the police strike, combined with the massive electoral victory, led to suggestions that Coolidge run for president in 1920.

By the time Coolidge was inaugurated on January 2, 1919, the First World War had ended, and Coolidge pushed the legislature to give a $100 bonus () to Massachusetts veterans. He also signed a bill reducing the work week for women and children from fifty-four hours to forty-eight, saying, "We must humanize the industry, or the system will break down." He signed into law a budget that kept the tax rates the same, while trimming $4 million from expenditures, thus allowing the state to retire some of its debt.

Coolidge also wielded the veto pen as governor. His most publicized veto prevented an increase in legislators' pay by 50%. Although Coolidge was personally opposed to Prohibition, he vetoed a bill in May 1920 that would have allowed the sale of beer or wine of 2.75% alcohol or less, in Massachusetts in violation of the Eighteenth Amendment to the United States Constitution. "Opinions and instructions do not outmatch the Constitution," he said in his veto message. "Against it, they are void."

At the 1920 Republican National Convention, most of the delegates were selected by state party caucuses, not primaries. As such, the field was divided among many local favorites. Coolidge was one such candidate, and while he placed as high as sixth in the voting, the powerful party bosses running the convention, primarily the party's US Senators, never considered him seriously. After ten ballots, the bosses and then the delegates settled on Senator Warren G. Harding of Ohio as their nominee for president. When the time came to select a vice presidential nominee, the bosses also made and announced their decision on whom they wanted – Sen. Irvine Lenroot of Wisconsin – and then prematurely departed after his name was put forth, relying on the rank and file to confirm their decision. A delegate from Oregon, Wallace McCamant, having read "Have Faith in Massachusetts", proposed Coolidge for vice president instead. The suggestion caught on quickly with the masses starving for an act of independence from the absent bosses, and Coolidge was unexpectedly nominated.

The Democrats nominated another Ohioan, James M. Cox, for president and the Assistant Secretary of the Navy, Franklin D. Roosevelt, for vice president. The question of the United States joining the League of Nations was a major issue in the campaign, as was the unfinished legacy of Progressivism. Harding ran a "front-porch" campaign from his home in Marion, Ohio, but Coolidge took to the campaign trail in the Upper South, New York, and New England – his audiences carefully limited to those familiar with Coolidge and those placing a premium upon concise and short speeches. On November 2, 1920, Harding and Coolidge were victorious in a landslide, winning more than 60 percent of the popular vote, including every state outside the South. They also won in Tennessee, the first time a Republican ticket had won a Southern state since Reconstruction.

The US vice-presidency did not carry many official duties, but Coolidge was invited by President Harding to attend cabinet meetings, making him the first vice president to do so. He gave a number of unremarkable speeches around the country.

As the US vice president, Coolidge and his vivacious wife Grace were invited to quite a few parties, where the legend of "Silent Cal" was born. It is from this time that most of the jokes and anecdotes involving Coolidge originate, such as Coolidge being "silent in five languages". Although Coolidge was known to be a skilled and effective public speaker, in private he was a man of few words and was commonly referred to as "Silent Cal". An apocryphal story has it that a person seated next to him at a dinner, said to him, "I made a bet today that I could get more than two words out of you." He replied, "You lose." However, on April 22, 1923, Coolidge himself said that the "You lose" quotation never occurred. The story about it was related by Frank B. Noyes, President of the Associated Press, to their membership at their annual luncheon at the Waldorf Astoria Hotel, when toasting and introducing Coolidge, who was the invited speaker. After the introduction and before his prepared remarks, Coolidge said to the membership, "Your President [referring to Noyes] has given you a perfect example of one of those rumors now current in Washington which is without any foundation." Dorothy Parker, upon learning that Coolidge had died, reportedly remarked, "How can they tell?" Coolidge often seemed uncomfortable among fashionable Washington society; when asked why he continued to attend so many of their dinner parties, he replied, "Got to eat somewhere." Alice Roosevelt Longworth, a leading Republican wit, underscored Coolidge's silence and his dour personality: "When he wished he were elsewhere, he pursed his lips, folded his arms, and said nothing. He looked then precisely as though he had been weaned on a pickle."

As president, Coolidge's reputation as a quiet man continued. "The words of a President have an enormous weight," he would later write, "and ought not to be used indiscriminately." Coolidge was aware of his stiff reputation; indeed, he cultivated it. "I think the American people want a solemn ass as a President," he once told Ethel Barrymore, "and I think I will go along with them." Some historians suggest that Coolidge's image was created deliberately as a campaign tactic, while others believe his withdrawn and quiet behavior to be natural, deepening after the death of his son in 1924.

On August 2, 1923, President Harding died unexpectedly from a heart attack in San Francisco while on a speaking tour of the western United States. Vice President Coolidge was in Vermont visiting his family home, which had neither electricity nor a telephone, when he received word by messenger of Harding's death. The vice president dressed, said a prayer, and came downstairs to greet the reporters who had assembled. His father, a notary public and justice of the peace, administered the oath of office in the family's parlor by the light of a kerosene lamp at 2:47 a.m. on August 3, 1923; and Coolidge then returned to bed as president.

Coolidge returned to Washington the next day, and was sworn in again by Justice Adolph A. Hoehling Jr. of the Supreme Court of the District of Columbia, to forestall any questions about the authority of a state official to administer a federal oath. This second oath-taking remained a secret until it was revealed by Harry M. Daugherty in 1932, and confirmed by Hoehling. When Hoehling confirmed Daugherty's story, he indicated that Daugherty, then serving as United States Attorney General, asked him to administer the oath without fanfare at the Willard Hotel. According to Hoehling, he did not question Daugherty's reason for requesting a second oath-taking but assumed it was to resolve any doubt about whether the first swearing-in was valid.
The nation initially did not know what to make of Coolidge, who had maintained a low profile in the Harding administration; many had even expected him to be replaced on the ballot in 1924. Coolidge believed that those of Harding's men under suspicion were entitled to every presumption of innocence, taking a methodical approach to the scandals, principally the Teapot Dome scandal, while others clamored for rapid punishment of those they presumed guilty. Coolidge thought the Senate investigations of the scandals would suffice; this was affirmed by the resulting resignations of those involved. He personally intervened in demanding the resignation of Attorney General Harry M. Daugherty after he refused to cooperate with the congressional probe. He then set about to confirm that no loose ends remained in the administration, arranging for a full briefing on the wrongdoing. Harry A. Slattery reviewed the facts with him, Harlan F. Stone analyzed the legal aspects for him and Senator William E. Borah assessed and presented the political factors.

Coolidge addressed Congress when it reconvened on December 6, 1923, giving a speech that supported many of Harding's policies, including Harding's formal budgeting process, the enforcement of immigration restrictions and arbitration of coal strikes ongoing in Pennsylvania. Coolidge's speech was the first presidential speech to be broadcast over the radio. The Washington Naval Treaty was proclaimed just one month into Coolidge's term, and was generally well received in the country. In May 1924, the World War I veterans' World War Adjusted Compensation Act or "Bonus Bill" was passed over his veto. Coolidge signed the Immigration Act later that year, which was aimed at restricting southern and eastern European immigration, but appended a signing statement expressing his unhappiness with the bill's specific exclusion of Japanese immigrants. Just before the Republican Convention began, Coolidge signed into law the Revenue Act of 1924, which reduced the top marginal tax rate from 58% to 46%, as well as personal income tax rates across the board, increased the estate tax and bolstered it with a new gift tax.

On June 2, 1924, Coolidge signed the act granting citizenship to all Native Americans born in the United States. By that time, two-thirds of the people were already citizens, having gained it through marriage, military service (veterans of World War I were granted citizenship in 1919), or the land allotments that had earlier taken place.

The Republican Convention was held on June 10–12, 1924, in Cleveland, Ohio; Coolidge was nominated on the first ballot. The convention nominated Frank Lowden of Illinois for vice president on the second ballot, but he declined; former Brigadier General Charles G. Dawes was nominated on the third ballot and accepted.

The Democrats held their convention the next month in New York City. The convention soon deadlocked, and after 103 ballots, the delegates finally agreed on a compromise candidate, John W. Davis, with Charles W. Bryan nominated for vice president. The Democrats' hopes were buoyed when Robert M. La Follette, a Republican senator from Wisconsin, split from the GOP to form a new Progressive Party. Many believed that the split in the Republican party, like the one in 1912, would allow a Democrat to win the presidency.

After the conventions and the death of his younger son Calvin, Coolidge became withdrawn; he later said that "when he [the son] died, the power and glory of the Presidency went with him." Even as he mourned, Coolidge ran his standard campaign, not mentioning his opponents by name or maligning them, and delivering speeches on his theory of government, including several that were broadcast over the radio. It was the most subdued campaign since 1896, partly because of Coolidge's grief, but also because of his naturally non-confrontational style. The other candidates campaigned in a more modern fashion, but despite the split in the Republican party, the results were similar to those of 1920. Coolidge and Dawes won every state outside the South except Wisconsin, La Follette's home state. Coolidge won the election with 382 electoral votes and the popular vote by 2.5 million over his opponents' combined total.

During Coolidge's presidency, the United States experienced a period of rapid economic growth known as the "Roaring Twenties." He left the administration's industrial policy in the hands of his activist Secretary of Commerce, Herbert Hoover, who energetically used government auspices to promote business efficiency and develop airlines and radio. Coolidge disdained regulation and demonstrated this by appointing commissioners to the Federal Trade Commission and the Interstate Commerce Commission who did little to restrict the activities of businesses under their jurisdiction. The regulatory state under Coolidge was, as one biographer described it, "thin to the point of invisibility."

Historian Robert Sobel offers some context of Coolidge's laissez-faire ideology, based on the prevailing understanding of federalism during his presidency: "As Governor of Massachusetts, Coolidge supported wages and hours legislation, opposed child labor, imposed economic controls during World War I, favored safety measures in factories, and even worker representation on corporate boards. Did he support these measures while president? No, because in the 1920s, such matters were considered the responsibilities of state and local governments."

Coolidge adopted the taxation policies of his Secretary of the Treasury, Andrew Mellon, who advocated "scientific taxation" — the notion that lowering taxes will increase, rather than decrease, government receipts. Congress agreed, and tax rates were reduced in Coolidge's term. In addition to federal tax cuts, Coolidge proposed reductions in federal expenditures and retiring of the federal debt. Coolidge's ideas were shared by the Republicans in Congress, and in 1924, Congress passed the Revenue Act of 1924, which reduced income tax rates and eliminated all income taxation for some two million people. They reduced taxes again by passing the Revenue Acts of 1926 and 1928, all the while continuing to keep spending down so as to reduce the overall federal debt. By 1927, only the wealthiest 2% of taxpayers paid any federal income tax. Federal spending remained flat during Coolidge's administration, allowing one-fourth of the federal debt to be retired in total. State and local governments saw considerable growth, however, surpassing the federal budget in 1927. By 1929, after Coolidge's series of tax rate reductions had cut the tax rate to 24 percent on those making over $100,000, the federal government collected more than a billion dollars in income taxes, of which 65 percent was collected from those making over $100,000. In 1921, when the tax rate on people making over $100,000 a year was 73 percent, the federal government collected a little over $700 million in income taxes, of which 30 percent was paid by those making over $100,000.

Perhaps the most contentious issue of Coolidge's presidency was relief for farmers. Some in Congress proposed a bill designed to fight falling agricultural prices by allowing the federal government to purchase crops to sell abroad at lower prices. Agriculture Secretary Henry C. Wallace and other administration officials favored the bill when it was introduced in 1924, but rising prices convinced many in Congress that the bill was unnecessary, and it was defeated just before the elections that year. In 1926, with farm prices falling once more, Senator Charles L. McNary and Representative Gilbert N. Haugen—both Republicans—proposed the McNary–Haugen Farm Relief Bill. The bill proposed a federal farm board that would purchase surplus production in high-yield years and hold it (when feasible) for later sale or sell it abroad. Coolidge opposed McNary-Haugen, declaring that agriculture must stand "on an independent business basis," and said that "government control cannot be divorced from political control." Instead of manipulating prices, he favored instead Herbert Hoover's proposal to increase profitability by modernizing agriculture. Secretary Mellon wrote a letter denouncing the McNary-Haugen measure as unsound and likely to cause inflation, and it was defeated.

After McNary-Haugen's defeat, Coolidge supported a less radical measure, the Curtis-Crisp Act, which would have created a federal board to lend money to farm co-operatives in times of surplus; the bill did not pass. In February 1927, Congress took up the McNary-Haugen bill again, this time narrowly passing it, and Coolidge vetoed it. In his veto message, he expressed the belief that the bill would do nothing to help farmers, benefiting only exporters and expanding the federal bureaucracy. Congress did not override the veto, but it passed the bill again in May 1928 by an increased majority; again, Coolidge vetoed it. "Farmers never have made much money," said Coolidge, the Vermont farmer's son. "I do not believe we can do much about it."

Coolidge has often been criticized for his actions during the Great Mississippi Flood of 1927, the worst natural disaster to hit the Gulf Coast until Hurricane Katrina in 2005. Although he did eventually name Secretary Hoover to a commission in charge of flood relief, scholars argue that Coolidge overall showed a lack of interest in federal flood control. Coolidge did not believe that personally visiting the region after the floods would accomplish anything, and that it would be seen as mere political grandstanding. He also did not want to incur the federal spending that flood control would require; he believed property owners should bear much of the cost. On the other hand, Congress wanted a bill that would place the federal government completely in charge of flood mitigation. When Congress passed a compromise measure in 1928, Coolidge declined to take credit for it and signed the bill in private on May 15.

According to one biographer, Coolidge was "devoid of racial prejudice," but rarely took the lead on civil rights. Coolidge disliked the Ku Klux Klan and no Klansman is known to have received an appointment from him. In the 1924 presidential election his opponents (Robert La Follette and John Davis), and his running mate Charles Dawes, often attacked the Klan but Coolidge avoided the subject.

Coolidge spoke in favor of the civil rights of African-Americans, saying in his first State of the Union address that their rights were "just as sacred as those of any other citizen" under the U.S. Constitution and that it was a "public and a private duty to protect those rights."

Coolidge repeatedly called for laws to make lynching a federal crime (it was already a state crime, though not always enforced). Congress refused to pass any such legislation. On June 2, 1924, Coolidge signed the Indian Citizenship Act, which granted U.S. citizenship to all American Indians living on reservations. (Those off reservations had long been citizens.) On June 6, 1924, Coolidge delivered a commencement address at historically black, non-segregated Howard University, in which he thanked and commended African-Americans for their rapid advances in education and their contributions to US society over the years, as well as their eagerness to render their services as soldiers in the World War, all while being faced with discrimination and prejudices at home.

In a speech in October 1924, Coolidge stressed tolerance of differences as an American value and thanked immigrants for their contributions to U.S. society, saying that they have "contributed much to making our country what it is." He stated that although the diversity of peoples was a detrimental source of conflict and tension in Europe, it was peculiar for the United States that it was a "harmonious" benefit for the country. Coolidge further stated the United States should assist and help immigrants who come to the country and urged immigrants to reject "race hatreds" and "prejudices".

Coolidge was neither well versed in nor very interested in world affairs. His focus was directed mainly at American business, especially pertaining to trade, and "Maintaining the Status Quo." Although not an isolationist, he was reluctant to enter into foreign alliances. While Coolidge believed strongly in a non-interventionist foreign policy, he did believe that America was exceptional.

Coolidge considered the 1920 Republican victory as a rejection of the Wilsonian position that the United States should join the League of Nations. While not completely opposed to the idea, Coolidge believed the League, as then constituted, did not serve American interests, and he did not advocate U.S. membership. He spoke in favor of the United States joining the Permanent Court of International Justice (World Court), provided that the nation would not be bound by advisory decisions. In 1926, the Senate eventually approved joining the Court (with reservations). The League of Nations accepted the reservations, but it suggested some modifications of its own. The Senate failed to act and so the United States did not join the World Court.

Coolidge authorized the Dawes Plan, a financial plan by Charles Dawes, to provide Germany partial relief from its reparations obligations from World War I. The plan initially provided stimulus for the German economy. Additionally, Coolidge attempted to pursue further curbs on naval strength following the early successes of Harding's Washington Naval Conference by sponsoring the Geneva Naval Conference in 1927, which failed owing to a French and Italian boycott and ultimate failure of Great Britain and the United States to agree on cruiser tonnages. As a result, the conference was a failure and Congress eventually authorized for increased American naval spending in 1928. The Kellogg–Briand Pact of 1928, named for Coolidge's Secretary of State, Frank B. Kellogg, and French foreign minister Aristide Briand, was also a key peacekeeping initiative. The treaty, ratified in 1929, committed signatories—the United States, the United Kingdom, France, Germany, Italy, and Japan—to "renounce war, as an instrument of national policy in their relations with one another." The treaty did not achieve its intended result—the outlawry of war—but it did provide the founding principle for international law after World War II. Coolidge also continued the previous administration's policy of withholding recognition of the Soviet Union.

Efforts were made to normalize ties with post-Revolution Mexico. Coolidge recognized Mexico's new governments under Álvaro Obregón and Plutarco Elías Calles, and continued American support for the elected Mexican government against the National League for the Defense of Religious Liberty during the Cristero War, lifting the arms embargo on that country; he also appointed Dwight Morrow as Ambassador to Mexico with the successful objective to avoid further American conflict with Mexico.

Coolidge's administration would see continuity in the occupation of Nicaragua and Haiti, and an end to the occupation of the Dominican Republic in 1924 as a result of withdrawal agreements finalized during Harding's administration. In 1925, Coolidge ordered the withdrawal of Marines stationed in Nicaragua following perceived stability after the 1924 Nicaraguan general election, but redeployed them there in January 1927 following failed attempts to peacefully resolve the rapid deterioration of political stability and avert the ensuing Constitutionalist War; Henry L. Stimson was later sent by Coolidge to mediate a peace deal that would end the civil war and extend American military presence in Nicaragua beyond Coolidge's term in office.

To extend an olive branch to Latin American leaders embittered over America's interventionist policies in Central America and the Caribbean, Coolidge led the U.S. delegation to the Sixth International Conference of American States, January 15–17, 1928, in Havana, Cuba, the only international trip Coolidge made during his presidency. He would be the last sitting American president to visit Cuba until Barack Obama in 2016.

For Canada, Coolidge authorized the St. Lawrence Seaway, a system of locks and canals that would provide large vessels passage between the Atlantic Ocean and the Great Lakes.

Although a few of Harding's cabinet appointees were scandal-tarred, Coolidge initially retained all of them, out of an ardent conviction that as successor to a deceased elected president he was obligated to retain Harding's counselors and policies until the next election. He kept Harding's able speechwriter Judson T. Welliver; Stuart Crawford replaced Welliver in November 1925. Coolidge appointed C. Bascom Slemp, a Virginia Congressman and experienced federal politician, to work jointly with Edward T. Clark, a Massachusetts Republican organizer whom he retained from his vice-presidential staff, as Secretaries to the President (a position equivalent to the modern White House Chief of Staff).

Perhaps the most powerful person in Coolidge's Cabinet was Secretary of the Treasury Andrew Mellon, who controlled the administration's financial policies and was regarded by many, including House Minority Leader John Nance Garner, as more powerful than Coolidge himself. Secretary of Commerce Herbert Hoover also held a prominent place in Coolidge's Cabinet, in part because Coolidge found value in Hoover's ability to win positive publicity with his pro-business proposals. Secretary of State Charles Evans Hughes directed Coolidge's foreign policy until he resigned in 1925 following Coolidge's re-election. He was replaced by Frank B. Kellogg, who had previously served as a Senator and as the ambassador to Great Britain. Coolidge made two other appointments following his re-election, with William M. Jardine taking the position of Secretary of Agriculture and John G. Sargent becoming Attorney General. Coolidge did not have a vice president during his first term, but Charles Dawes became vice president during Coolidge's second term, and Dawes and Coolidge clashed over farm policy and other issues.

Coolidge appointed one justice to the Supreme Court of the United States, Harlan F. Stone in 1925. Stone was Coolidge's fellow Amherst alumnus, a Wall Street lawyer and conservative Republican. Stone was serving as dean of Columbia Law School when Coolidge appointed him to be attorney general in 1924 to restore the reputation tarnished by Harding's Attorney General, Harry M. Daugherty. It does not appear that Coolidge considered appointing anyone other than Stone, although Stone himself had urged Coolidge to appoint Benjamin N. Cardozo. Stone proved to be a firm believer in judicial restraint and was regarded as one of the court's three liberal justices who would often vote to uphold New Deal legislation. President Franklin D. Roosevelt later appointed Stone to be chief justice.

Coolidge nominated 17 judges to the United States Courts of Appeals and 61 judges to the United States district courts. He appointed judges to various specialty courts as well, including Genevieve R. Cline, who became the first woman named to the federal judiciary when Coolidge placed her on the United States Customs Court in 1928. Coolidge also signed the Judiciary Act of 1925 into law, allowing the Supreme Court more discretion over its workload.

In the summer of 1927, Coolidge vacationed in the Black Hills of South Dakota, where he engaged in horseback riding and fly fishing and attended rodeos. He made Custer State Park his "summer White House." While on vacation, Coolidge surprisingly issued a terse statement that he would not seek a second full term as president: "I do not choose to run for President in 1928." After allowing the reporters to take that in, Coolidge elaborated. "If I take another term, I will be in the White House till 1933 … Ten years in Washington is longer than any other man has had it—too long!" In his memoirs, Coolidge explained his decision not to run: "The Presidential office takes a heavy toll of those who occupy it and those who are dear to them. While we should not refuse to spend and be spent in the service of our country, it is hazardous to attempt what we feel is beyond our strength to accomplish." After leaving office, he and Grace returned to Northampton, where he wrote his memoirs. The Republicans retained the White House in 1928 with a landslide by Herbert Hoover. Coolidge had been reluctant to endorse Hoover as his successor; on one occasion he remarked that "for six years that man has given me unsolicited advice—all of it bad." Even so, Coolidge had no desire to split the party by publicly opposing the nomination of the popular commerce secretary.

After his presidency, Coolidge retired to a modest rented house on residential Massasoit Street in Northampton before moving to a more spacious home, "The Beeches." He kept a Hacker runabout boat on the Connecticut River and was often observed on the water by local boating enthusiasts. During this period, he also served as chairman of the Non-Partisan Railroad Commission, an entity created by several banks and corporations to survey the country's long-term transportation needs and make recommendations for improvements. He was an honorary president of the American Foundation for the Blind, a director of New York Life Insurance Company, president of the American Antiquarian Society, and a trustee of Amherst College.

Coolidge published his autobiography in 1929 and wrote a syndicated newspaper column, "Calvin Coolidge Says," from 1930 to 1931. Faced with looming defeat in the 1932 presidential election, some Republicans spoke of rejecting Herbert Hoover as their party's nominee, and instead drafting Coolidge to run, but the former president made it clear that he was not interested in running again, and that he would publicly repudiate any effort to draft him, should it come about. Hoover was renominated, and Coolidge made several radio addresses in support of him. Hoover then lost the general election to Coolidge's 1920 vice presidential Democratic opponent Franklin D. Roosevelt in a landslide.
Coolidge died suddenly from coronary thrombosis at "The Beeches," at 12:45 p.m., January 5, 1933. Shortly before his death, Coolidge confided to an old friend: "I feel I no longer fit in with these times." Coolidge is buried in Plymouth Notch Cemetery, Plymouth Notch, Vermont. The nearby family home is maintained as one of the original buildings on the Calvin Coolidge Homestead District site. The State of Vermont dedicated a new visitors' center nearby to mark Coolidge's 100th birthday on July 4, 1972.

Despite his reputation as a quiet and even reclusive politician, Coolidge made use of the new medium of radio and made radio history several times while president. He made himself available to reporters, giving 520 press conferences, meeting with reporters more regularly than any president before or since. Coolidge's second inauguration was the first presidential inauguration broadcast on radio. On December 6, 1923, his speech to Congress was broadcast on radio, the first presidential radio address. Coolidge signed the Radio Act of 1927, which assigned regulation of radio to the newly created Federal Radio Commission. On August 11, 1924, Theodore W. Case, using the Phonofilm sound-on-film process he developed for Lee de Forest, filmed Coolidge on the White House lawn, making "Silent Cal" the first president to appear in a sound film. The title of the DeForest film was "President Coolidge, Taken on the White House Grounds". When Charles Lindbergh arrived in Washington on a U.S. Navy ship after his celebrated 1927 trans-Atlantic flight, President Coolidge welcomed him back to the U.S. and presented him with the Congressional Medal of Honor; the event was captured on film.






</doc>
<doc id="6198" url="https://en.wikipedia.org/wiki?curid=6198" title="Convention on Biological Diversity">
Convention on Biological Diversity

The Convention on Biological Diversity (CBD), known informally as the Biodiversity Convention, is a multilateral treaty. The Convention has three main goals including: the conservation of biological diversity (or biodiversity); the sustainable use of its components; and the fair and equitable sharing of benefits arising from genetic resources.

In other words, its objective is to develop national strategies for the conservation and sustainable use of biological diversity. It is often seen as the key document regarding sustainable development. The Convention was opened for signature at the Earth Summit in Rio de Janeiro on 5 June 1992 and entered into force on 29 December 1993. CBD has two supplementary agreements - Cartagena Protocol and Nagoya Protocol.

The Cartagena Protocol on Biosafety to the Convention on Biological Diversity is an international treaty governing the movements of living modified organisms (LMOs) resulting from modern biotechnology from one country to another. It was adopted on 29 January 2000 as a supplementary agreement to the Convention on Biological Diversity and entered into force on 11 September 2003.

The Nagoya Protocol on Access to Genetic Resources and the Fair and Equitable Sharing of Benefits Arising from their Utilization (ABS) to the Convention on Biological Diversity is a supplementary agreement to the Convention on Biological Diversity. It provides a transparent legal framework for the effective implementation of one of the three objectives of the CBD: the fair and equitable sharing of benefits arising out of the utilization of genetic resources. 
The Nagoya Protocol on ABS was adopted on 29 October 2010 in Nagoya, Japan and entered into force on 12 October 2014, 90 days after the deposit of the fiftieth instrument of ratification. Its objective is the fair and equitable sharing of benefits arising from the utilization of genetic resources, thereby contributing to the conservation and sustainable use of biodiversity.

The notion of an international convention on bio-diversity was conceived at a United Nations Environment Programme (UNEP) Ad Hoc Working Group of Experts on Biological Diversity in November 1988. The subsequent year, the Ad Hoc Working Group of Technical and Legal Experts was established for the drafting of a legal text which addressed the conservation and sustainable use of biological diversity, as well as the sharing of benefits arising from their utilization with sovereign states and local communities.
In 1991, an intergovernmental negotiating committee was established, tasked with finalizing the convention's text.

A Conference for the Adoption of the Agreed Text of the Convention on Biological Diversity was held in Nairobi, Kenya, in 1992, and its conclusions were distilled in the Nairobi Final Act. The Convention's text was opened for signature on 5 June 1992 at the United Nations Conference on Environment and Development (the Rio "Earth Summit"). By its closing date, 4 June 1993, the convention had received 168 signatures. It entered into force on 29 December 1993.

The convention recognized for the first time in international law that the conservation of biodiversity is "a common concern of humankind" and is an integral part of the development process. The agreement covers all ecosystems, species, and genetic resources. It links traditional conservation efforts to the economic goal of using biological resources sustainably. It sets principles for the fair and equitable sharing of the benefits arising from the use of genetic resources, notably those destined for commercial use. It also covers the rapidly expanding field of biotechnology through its Cartagena Protocol on Biosafety, addressing technology development and transfer, benefit-sharing and biosafety issues. Importantly, the Convention is legally binding; countries that join it ('Parties') are obliged to implement its provisions.

The convention reminds decision-makers that natural resources are not infinite and sets out a philosophy of sustainable use. While past conservation efforts were aimed at protecting particular species and habitats, the Convention recognizes that ecosystems, species and genes must be used for the benefit of humans. However, this should be done in a way and at a rate that does not lead to the long-term decline of biological diversity.

The convention also offers decision-makers guidance based on the precautionary principle which demands that where there is a threat of significant reduction or loss of biological diversity, lack of full scientific certainty should not be used as a reason for postponing measures to avoid or minimize such a threat. The Convention acknowledges that substantial investments are required to conserve biological diversity. It argues, however, that conservation will bring us significant environmental, economic and social benefits in return.

The Convention on Biological Diversity of 2010 banned some forms of geoengineering.

Some of the many issues dealt with under the convention include:


The Cartagena Protocol on Biosafety of the Convention, also known as the Biosafety Protocol, was adopted in January 2000. The Biosafety Protocol seeks to protect biological diversity from the potential risks posed by living modified organisms resulting from modern biotechnology.

The Biosafety Protocol makes clear that products from new technologies must be based on the precautionary principle and allow developing nations to balance public health against economic benefits. It will for example let countries ban imports of a genetically modified organism if they feel there is not enough scientific evidence the product is safe and requires exporters to label shipments containing genetically modified commodities such as corn or cotton.

The required number of 50 instruments of ratification/accession/approval/acceptance by countries was reached in May 2003. In accordance with the provisions of its Article 37, the Protocol entered into force on 11 September 2003.

In April 2002, the parties of the UN CBD adopted the recommendations of the Gran Canaria Declaration Calling for a Global Plant Conservation Strategy, and adopted a 16-point plan aiming to slow the rate of plant extinctions around the world by 2010.

As of 2016, the Convention has 196 parties, which includes 195 states and the European Union. All UN member states—with the exception of the United States—have ratified the treaty. Non-UN member states that have ratified are the Cook Islands, Niue, and the State of Palestine. The Holy See and the states with limited recognition are non-parties. The US has signed but not ratified the treaty, and has not announced plans to ratify it.

The European Union created the Cartagena Protocol to enhance biosafety regulation and propagate the 'precautionary principle' over the 'sound science principle' defended by the United States. Whereas the impact of the Cartagena Protocol on domestic regulations has been substantial, its impact on international trade law remains uncertain. In 2006, The World Trade Organization (WTO) ruled that the European Union violated international trade law between 1999 and 2003 by imposing a moratorium on the approval of genetically modified organisms (GMO) imports. Disappointing the United States, the panel nevertheless ‘‘decided not to decide’’ by not invalidating the stringent European biosafety regulations.

Conference of the Parties:
The convention's governing body is the Conference of the Parties (COP), consisting of all governments (and regional economic integration organizations) that have ratified the treaty. This ultimate authority reviews progress under the Convention, identifies new priorities, and sets work plans for members. The COP can also make amendments to the Convention, create expert advisory bodies, review progress reports by member nations, and collaborate with other international organizations and agreements.

The Conference of the Parties (COP) uses expertise and support from several other bodies that are established by the Convention. In addition to committees or mechanisms established on an ad hoc basis, the main organs are:

Secretariat:
The CBD Secretariat, based in Montreal, Quebec, Canada, operates under UNEP, the United Nations Environment Programme. Its main functions are to organize meetings, draft documents, assist member governments in the implementation of the programme of work, coordinate with other international organizations, and collect and disseminate information.

Subsidiary Body for Scientific, Technical and Technological Advice (SBSTTA): The SBSTTA is a committee composed of experts from member governments competent in relevant fields. It plays a key role in making recommendations to the COP on scientific and technical issues. The next two meetings of the SBSTTA will be 25–29 November 2019 in Montreal, Canada (SBSTTA-23), and 18–23 May 2020 in Montreal, Canada (SBSTTA-24). The current chair of the SBSTTA Bureau is Mr. Hesiquio Benitez Diaz of Mexico.

Subsidiary Body on Implementation (SBI): In 2014, the Conference of the Parties to the Convention on Biological Diversity established the Subsidiary Body on Implementation (SBI) to replace the Ad Hoc Open-ended Working Group on Review of Implementation of the Convention. The four functions and core areas of work of SBI are: (a) review of progress in implementation; (b) strategic actions to enhance implementation; (c) strengthening means of implementation; and (d) operations of the convention and the Protocols. The first meeting of the SBI was held on 2–6 May 2016 and the second meeting was held on 9–13 July 2018, both in Montreal, Canada. The third meeting of the SBI will be held on 25–29 May 2020 in Montreal, Canada. The Bureau of the Conference of the Parties serves as the Bureau of the SBI. The current chair of the SBI is Ms. Charlotta Sörqvist of Sweden.

"National Biodiversity Strategies and Action Plans (NBSAPs) are the principal instruments for implementing the Convention at the national level (Article 6). The Convention requires countries to prepare a national biodiversity strategy (or equivalent instrument) and to ensure that this strategy is mainstreamed into the planning and activities of all those sectors whose activities can have an impact (positive and negative) on biodiversity. To date [2012-02-01], 173 Parties have developed NBSAPs in line with Article 6."

For example, the United Kingdom, New Zealand and Tanzania have carried out elaborate responses to conserve individual species and specific habitats. The United States of America, a signatory who has not yet ratified the treaty, has produced one of the most thorough implementation programs through species Recovery Programs and other mechanisms long in place in the US for species conservation.

Singapore has also established a detailed "National Biodiversity Strategy and Action Plan". The "National Biodiversity Centre" of Singapore represents Singapore in the Convention for Biological Diversity.

In accordance with Article 26 of the Convention, Parties prepare national reports on the status of implementation of the Convention.

The current acting executive secretary is Elizabeth Maruma Mrema, who took up this post on 1 December 2019.

The previous executive secretaries were:

Cristiana Pașca Palmer (2017-2019), Braulio Ferreira de Souza Dias (2012-2017), Ahmed Djoghlaf (2006-2012), Hamdallah Zedan (1998-2005), Calestous Juma (1995-1998), and Angela Cropper (1993-1995).

The Nagoya Protocol on Access to Genetic Resources and the Fair and Equitable Sharing of Benefits Arising from their Utilization to the Convention on Biological Diversity is a supplementary agreement to the Convention on Biological Diversity. It provides a transparent legal framework for the effective implementation of one of the three objectives of the CBD: the fair and equitable sharing of benefits arising out of the utilization of genetic resources. The Protocol was adopted on 29 October 2010 in Nagoya, Aichi Province, Japan, and entered into force on 12 October 2014. Its objective is the fair and equitable sharing of benefits arising from the utilization of genetic resources, thereby contributing to the conservation and sustainable use of biodiversity.

The first ordinary meeting of the parties to the convention took place in November and December 1994, in Nassau, Bahamas.

The second ordinary meeting of the parties to the convention took place in November 1995, in Jakarta, Indonesia.

The third ordinary meeting of the parties to the convention took place in November 1996, in Buenos Aires, Argentina.

The fourth ordinary meeting of the parties to the convention took place in May 1998, in Bratislava, Slovakia.

The First Extraordinary Meeting of the Conference of the Parties took place in February 1999, in Cartagena, Colombia.

The fifth ordinary meeting of the parties to the convention took place in May 2000, in Nairobi, Kenya.

The sixth ordinary meeting of the parties to the convention took place in April 2002, in The Hague, Netherlands.

The seventh ordinary meeting of the parties to the convention took place in February 2004, in Kuala Lumpur, Malaysia.

The eighth ordinary meeting of the parties to the convention took place in March 2006, in Curitiba, Brazil.

The ninth ordinary meeting of the parties to the convention took place in May 2008, in Bonn, Germany.

The tenth ordinary meeting of the parties to the convention took place in October 2010, in Nagoya, Japan.

Leading up to the Conference of the Parties (COP 11) meeting on biodiversity in Hyderabad, India 2012, preparations for a World Wide Views on Biodiversity has begun, involving old and new partners and building on the experiences from the World Wide Views on Global Warming.

Under the theme, "Biodiversity for Sustainable Development," thousands of representatives of governments, NGOs, indigenous peoples, scientists and the private sector gathered in Pyeongchang, Republic of Korea in October 2014 for the 12th meeting of the Conference of the Parties to the Convention on Biological Diversity (COP 12).

From 6–17 October 2014, Parties discussed the implementation of the Strategic Plan for Biodiversity 2011-2020 and its Aichi Biodiversity Targets, which are to be achieved by the end of this decade. The results of Global Biodiversity Outlook 4, the flagship assessment report of the CBD informed the discussions.

The conference gave a mid-term evaluation to the UN Decade on Biodiversity (2011-2020) initiative, which aims to promote the conservation and sustainable use of nature.
At the end of the meeting, the meeting adopted the "Pyeongchang Road Map," which addresses ways to achieve biodiversity through technology cooperation, funding and strengthening the capacity of developing countries.

The thirteenth ordinary meeting of the parties to the convention took place between 2 and 17 December 2016 in Cancun, Mexico.

The fourteenth ordinary meeting of the parties to the convention took place on 17–29 November 2018, in 
Sharm El-Sheikh, Egypt. The 2018 UN Biodiversity Conference closed on 29 November 2018 with broad international agreement on reversing the global destruction of nature and biodiversity loss threatening all forms of life on Earth. Parties adopted the Voluntary Guidelines for the design and effective implementation of ecosystem-based approaches to climate change adaptation and disaster risk reduction. Governments also agreed to accelerate action to achieve the Aichi Biodiversity Targets, agreed in 2010, from now until 2020. Work to achieve these targets will take place at the global, regional, national and subnational levels.

2010 was the International Year of Biodiversity and the Secretariat of the CBD was its focal point. Following a recommendation of CBD signatories during COP 10 at Nagoya in October 2010, the UN, on 22 December 2010, declared 2011 to 2020 as the United Nations Decade on Biodiversity.

There have been criticisms against CBD that the Convention has been weakened in implementation due to the resistance of Western countries to the implementation of the pro-South provisions of the Convention. CBD is also regarded as a case of a hard treaty gone soft in the implementation trajectory. The argument to enforce the treaty as a legally binding multilateral instrument with the Conference of Parties reviewing the infractions and non-compliance is also gaining strength.

Although the convention explicitly states that all forms of life are covered by its provisions, examination of reports and of national biodiversity strategies and action plans submitted by participating countries shows that in practice this is not happening. The fifth report of the European Union, for example, makes frequent reference to animals (particularly fish) and plants, but does not mention bacteria, fungi or protists at all. The International Society for Fungal Conservation has assessed more than 100 of these CBD documents for their coverage of fungi using defined criteria to place each in one of six categories. No documents were assessed as good or adequate, less than 10% as nearly adequate or poor, and the rest as deficient, seriously deficient or totally deficient.

Scientists working with biodiversity and medical research are expressing fears that the Nagoya Protocol is counterproductive, and will hamper disease prevention and conservation efforts, and that the threat of imprisonment of scientists will have a chilling effect on research. Non-commercial researchers and institutions such as natural history museums fear maintaining biological reference collections and exchanging material between institutions will become difficult, and medical researchers have expressed alarm at plans to expand the protocol to make it illegal to publicly share genetic information, e.g. via GenBank.

William Y. Brown from Brookings institutions has mentioned that the Convention on Biological Diversity should include the preservation of intact genomes and viable cells for every known species and for new species as they are discovered.


"This article is partly based on the relevant entry in the CIA World Factbook, edition."

There are indeed several comprehensive publications on the subject, the given reference covers only one small aspect



</doc>
<doc id="6199" url="https://en.wikipedia.org/wiki?curid=6199" title="Convention on Fishing and Conservation of the Living Resources of the High Seas">
Convention on Fishing and Conservation of the Living Resources of the High Seas

The Convention on Fishing and Conservation of Living Resources of the High Seas is an agreement that was designed to solve through international cooperation the problems involved in the conservation of living resources of the high seas, considering that because of the development of modern technology some of these resources are in danger of being overexploited. The convention opened for signature on 29 April 1958 and entered into force on 20 March 1966.

"Parties" – (39): Australia, Belgium, Bosnia and Herzegovina, Burkina Faso, Cambodia, Colombia, Republic of the Congo, Denmark, Dominican Republic, Fiji, Finland, France, Haiti, Jamaica, Kenya, Lesotho, Madagascar, Malawi, Malaysia, Mauritius, Mexico, Montenegro, Netherlands, Nigeria, Portugal, Senegal, Serbia, Sierra Leone, Solomon Islands, South Africa, Spain, Switzerland, Thailand, Tonga, Trinidad and Tobago, Uganda, United Kingdom, United States, Venezuela.

"Countries that have signed, but not yet ratified" – (21): Afghanistan, Argentina, Bolivia, Canada, Costa Rica, Cuba, Ghana, Iceland, Indonesia, Iran, Ireland, Israel, Lebanon, Liberia, Nepal, New Zealand, Pakistan, Panama, Sri Lanka, Tunisia, Uruguay.





</doc>
<doc id="6200" url="https://en.wikipedia.org/wiki?curid=6200" title="Convention on Long-Range Transboundary Air Pollution">
Convention on Long-Range Transboundary Air Pollution

The Convention on Long-Range Transboundary Air Pollution, often abbreviated as Air Convention or CLRTAP, is intended to protect the human environment against air pollution and to gradually reduce and prevent air pollution, including long-range transboundary air pollution. It is implemented by the European Monitoring and Evaluation Programme (EMEP), directed by the United Nations Economic Commission for Europe (UNECE).

The convention opened for signature on entered into force on .

The Convention, which now has 51 Parties, identifies the Executive Secretary of the United Nations Economic Commission for Europe (UNECE) as its secretariat. The current parties to the Convention are shown on the map.

The Convention is implemented by the European Monitoring and Evaluation Programme (EMEP) (short for "Co-operative Programme for Monitoring and Evaluation of the Long-range Transmission of Air Pollutants in Europe"). Results of the EMEP programme are published on the EMEP website, www.emep.int.

Since 1979 the Convention on Long-range Transboundary Air Pollution has addressed some of the major environmental problems of the UNECE region through scientific collaboration and policy negotiation. The Convention has been extended by eight protocols that identify specific measures to be taken by Parties to cut their emissions of air pollutants:


The aim of the Convention is that Parties shall endeavour to limit and, as far as possible, gradually reduce and prevent air pollution including long-range transboundary air pollution. Parties develop policies and strategies to combat the discharge of air pollutants through exchanges of information, consultation, research and monitoring.

The Parties meet annually at sessions of the Executive Body to review ongoing work and plan future activities including a workplan for the coming year. The three main subsidiary bodies - the Working Group on Effects, the Steering Body to EMEP and the Working Group on Strategies and Review - as well as the Convention's Implementation Committee, report to the Executive Body each year.

Currently, the Convention's priority activities include review and possible revision of its most recent protocols, implementation of the Convention and its protocols across the entire UNECE region (with special focus on Eastern Europe, the Caucasus and Central Asia and South-East Europe) and sharing its knowledge and information with other regions of the world.




</doc>
<doc id="6201" url="https://en.wikipedia.org/wiki?curid=6201" title="CITES">
CITES

CITES (the Convention on International Trade in Endangered Species of Wild Fauna and Flora, also known as the Washington Convention) is a multilateral treaty to protect endangered plants and animals. It was drafted as a result of a resolution adopted in 1963 at a meeting of members of the International Union for Conservation of Nature (IUCN). The convention was opened for signature in 1973 and CITES entered into force on 1 July 1975. 

Its aim is to ensure that international trade in specimens of wild animals and plants does not threaten the survival of the species in the wild, and it accords varying degrees of protection to more than 35,000 species of animals and plants. In order to ensure that the General Agreement on Tariffs and Trade (GATT) was not violated, the Secretariat of GATT was consulted during the drafting process.

, Secretary-General of the CITES Secretariat is Ivonne Higuero.

CITES is one of the largest and oldest conservation and sustainable use agreements in existence. Participation is voluntary, and countries that have agreed to be bound by the Convention are known as Parties. Although CITES is legally binding on the Parties, it does not take the place of national laws. Rather it provides a framework respected by each Party, which must adopt their own domestic legislation to implement CITES at the national level. Often, domestic legislation is either non-existent (especially in Parties that have not ratified it), or with penalties with the gravity of the crime and insufficient deterrents to wildlife traders. As of 2002, 50% of Parties lacked one or more of the four major requirements for a Party: designation of Management and Scientific Authorities; laws prohibiting the trade in violation of CITES; penalties for such trade; laws providing for the confiscation of specimens.

Funding for the activities of the Secretariat and Conference of the Parties (CoP) meetings comes from a Trust Fund derived from Party contributions. Trust Fund money is not available to Parties to improve implementation or compliance. These activities, and all those outside Secretariat activities (training, species specific programmes such as Monitoring the Illegal Killing of Elephants - MIKE) must find external funding, mostly from donor countries and regional organizations such as the European Union.

Although the Convention itself does not provide for arbitration or dispute in the case of noncompliance, 36 years of CITES in practice has resulted in several strategies to deal with infractions by Parties. The Secretariat, when informed of an infraction by a Party, will notify all other parties. The Secretariat will give the Party time to respond to the allegations and may provide technical assistance to prevent further infractions. Other actions the Convention itself does not provide for but that derive from subsequent COP resolutions may be taken against the offending Party. These include:
Bilateral sanctions have been imposed on the basis of national legislation (e.g. the USA used certification under the Pelly Amendment to get Japan to revoke its reservation to hawksbill turtle products in 1991, thus reducing the volume of its exports).

Infractions may include negligence with respect to permit issuing, excessive trade, lax enforcement, and failing to produce annual reports (the most common).

Originally, CITES addressed depletion resulting from demand for luxury goods such as furs in Western countries, but with the rising wealth of Asia, particularly in China, the focus changed to products demanded there, particularly those used for luxury goods such as ivory or shark fins or for superstitious purposes such as rhinoceros horn. As of 2013 the demand was massive and had expanded to include thousands of species previously considered unremarkable and in no danger of extinction such as manta rays or pangolins.

The text of the Convention was finalized at a meeting of representatives of 80 countries in Washington, D.C., United States, on 3 March 1973. It was then open for signature until 31 December 1974. It entered into force after the 10th ratification by a signatory country, on 1 July 1975. Countries that signed the Convention become Parties by ratifying, accepting or approving it. By the end of 2003, all signatory countries had become Parties. States that were not signatories may become Parties by acceding to the Convention. As of October 2016, the Convention has 183 parties, including 182 states and the European Union.

The CITES Convention includes provisions and rules for trade with non-Parties. All member states of the United Nations are party to the treaty, with the exception of Andorra, Democratic People's Republic of Korea, Federated States of Micronesia, Haiti, Kiribati, Marshall Islands, Nauru, South Sudan, East Timor, Turkmenistan, and Tuvalu. UN observer the Holy See is also not a member. The Faroe Islands, an autonomous country in the Kingdom of Denmark, is also treated as a non-Party to CITES (both the Danish mainland and Greenland are part of CITES).

An amendment to the text of the Convention, known as the Gaborone Amendment allows regional economic integration organizations (REIO), such as the European Union, to have the status of a member state and to be a Party to the Convention. The REIO can vote at CITES meetings with the number of votes representing the number of members in the REIO, but it does not have an additional vote.

In accordance with Article XVII, paragraph 3, of the CITES Convention, the Gaborone Amendment entered into force on 29 November 2013, 60 days after 54 (two-thirds) of the 80 States that were party to CITES on 30 April 1983 deposited their instrument of acceptance of the amendment. At that time it entered into force only for those States that had accepted the amendment. The amended text of the Convention will apply automatically to any State that becomes a Party after 29 November 2013. For States that became party to the Convention before that date and have not accepted the amendment, it will enter into force 60 days after they accept it.

CITES works by subjecting international trade in specimens of selected species to certain controls. All import, export, re-export and introduction from the sea of species covered by the Convention has to be authorized through a licensing system. According to Article IX of the Convention, Management and Scientific Authorities, each Party to the Convention must designate one or more Management Authorities in charge of administering that licensing system and one or more Scientific Authorities to advise them on the effects of trade on the status of CITES-listed species.

Roughly 5,000 species of animals and 29,000 species of plants are protected by CITES against over-exploitation through international trade. Each protected species or population is included in one of three lists, called appendices (explained below). The Appendix that lists a species or population reflects the extent of the threat to it and the controls that apply to the trade.

Species may be split-listed meaning that some populations of a species are on one Appendix, while some are on another. Some people argue that this is risky as specimens from a more protected population could be 'laundered' through the borders of a Party whose population is not as strictly protected. The African bush elephant ("Loxodonta africana") is currently split-listed, with all populations except those of Botswana, Namibia, South Africa and Zimbabwe listed in Appendix I. Those of Botswana, Namibia, South Africa and Zimbabwe are listed in Appendix II. Listing the species over the whole of its range would prevent such 'laundering' but also restricts trade in wildlife products by range states with good management practices. There are also species that have only some populations listed in an Appendix. One example is the pronghorn ("Antilocapra americana"), a ruminant native to North America. Its Mexican population is listed in Appendix I, but its U.S. and Canadian populations are not listed (though certain U.S. populations in Arizona are nonetheless protected under the Endangered Species Act).

Species are proposed for inclusion in or deletion from the Appendices at meetings of the Conference of the Parties (CoP), which are held approximately once every three years, the most recent of which was CoP (CoP 17) in Johannesburg, South Africa from 24 September to 5 October 2016 at the Sandton Convention Center.

Species in the Appendices may be proposed for addition, change of Appendix, or de-listing (i.e., deletion) by any Party, whether or not it is a range State and changes may be made despite objections by range States if there is sufficient (2/3 majority) support for the listing. These discussions are usually among the most contentious at CoP meetings.

There has been increasing willingness within the Parties to allow for trade in products from well-managed populations. For instance, sales of the South African white rhino have generated revenues that helped pay for protection. Listing the species on Appendix I increased the price of rhino horn (which fueled more poaching), but the species survived wherever there was adequate on-the-ground protection. Thus field protection may be the primary mechanism that saved the population, but it is likely that field protection would not have been increased without CITES protection.

Appendix I, about 1200 species, are species that are threatened with extinction and are or may be affected by trade. Commercial trade in wild-caught specimens of these species is illegal (permitted only in exceptional licensed circumstances). Captive-bred animals or cultivated plants of Appendix I species are considered Appendix II specimens, with concomitant requirements (see below and Article VII). The Scientific Authority of the exporting country must make a non-detriment finding, assuring that export of the individuals will not adversely affect the wild population. Any trade in these species requires export and import permits. The Management Authority of the exporting state is expected to check that an import permit has been secured and that the importing state is able to care for the specimen adequately. 

Notable animal species listed in Appendix I include the red panda ("Ailurus fulgens"), western gorilla ("Gorilla gorilla"), the chimpanzee species ("Pan spp."), tigers ("Panthera tigris" subspecies), Asiatic lion ("Panthera leo persica"), leopards ("Panthera pardus"), jaguar ("Panthera onca"), cheetah ("Acinonyx jubatus"), Asian elephant ("Elephas maximus"), some populations of African bush elephant ("Loxodonta africana"), the dugong and manatees (Sirenia), and all rhinoceros species (except some Southern African subspecies populations).

Appendix II, about 21,000 species, are species that are not necessarily threatened with extinction, but may become so unless trade in specimens of such species is subject to strict regulation in order to avoid utilization incompatible with the survival of the species in the wild. In addition, Appendix II can include species similar in appearance to species already listed in the Appendices. International trade in specimens of Appendix II species may be authorized by the granting of an export permit or re-export certificate. In practice, many hundreds of thousands of Appendix II animals are traded annually. No import permit is necessary for these species under CITES, although some Parties do require import permits as part of their stricter domestic measures. A non-detriment finding and export permit are required by the exporting Party.

In addition, Article VII of CITES states that specimens of animals listed in Appendix I that are bred in captivity for commercial purposes are treated as Appendix II. The same applies for specimens of Appendix I plants artificially propagated for commercial purposes.

Examples of species listed on Appendix II are the great white shark ("Carcharodon carcharias"), the American black bear ("Ursus americanus"), Hartmann's mountain zebra ("Equus zebra hartmannae"), green iguana ("Iguana iguana"), queen conch ("Strombus gigas"), Emperor scorpion ("Pandinus imperator"), Mertens' water monitor ("Varanus mertensi"), bigleaf mahogany ("Swietenia macrophylla") and lignum vitae "ironwood" ("Guaiacum officinale").

Appendix III, about 170 species, are species that are listed after one member country has asked other CITES Parties for assistance in controlling trade in a species. The species are not necessarily threatened with extinction globally. In all member countries, trade in these species is only permitted with an appropriate export permit and a certificate of origin from the state of the member country who has listed the species.

Examples of species listed on Appendix III and the countries that listed them are the two-toed sloth ("Choloepus hoffmanni") by Costa Rica, sitatunga ("Tragelaphus spekii") by Ghana, African civet ("Civettictis civetta") by Botswana, and alligator snapping turtle ("Macrochelys temminckii") by the USA.

European Union uses Annex'es A, B, C and D instead of Appendixes 1, 2 and 3.
Annexes A, B and C are stricter versions of 1, 2 and 3 and contain more species that are protected under EU Internal Legislation.
Annex D, which doesn't have equivalent in CITES, is "monitoring list". It contains species, which import levels are monitored to determine the level of trade and any potential thread to species caused by trade. 

Amendments to the Convention must be supported by a two-thirds majority who are "present and voting" and can be made during an extraordinary meeting of the COP if one-third of the Parties are interested in such a meeting. The Gaborone Amendment (1983) allows regional economic blocs to accede to the treaty. Reservations (Article XXIII) can be made by any Party with respect to any species, which considerably weakens the treaty (see Reservations entered by Parties CITES for current reservations). Trade with non-Party states is allowed, although permits and certificates are recommended to be issued by exporters and sought by importers.

Notable reservations include those by Iceland, Japan and Norway on various baleen whale species and those on Falconiformes by Saudi Arabia.

General limitations about the structure and philosophy of CITES include: by design and intent it focuses on trade at the species level and does not address habitat loss, ecosystem approaches to conservation, or poverty; it seeks to prevent unsustainable use rather than promote sustainable use (which generally conflicts with the Convention on Biological Diversity), although this has been changing (see Nile crocodile, African elephant, South African white rhino case studies in Hutton and Dickinson 2000). It does not explicitly address market demand. In fact, CITES listings have been demonstrated to increase financial speculation in certain markets for high value species. Funding does not provide for increased on-the-ground enforcement (it must apply for bilateral aid for most projects of this nature).

By design, CITES regulates and monitors trade in the manner of a "negative list" such that trade in all species is permitted and unregulated "unless" the species in question appears on the Appendices or looks very much like one of those taxa. Then and only then, trade is regulated or constrained. Because the remit of the Convention covers millions of species of plants and animals, and tens of thousands of these taxa are potentially of economic value, in practice this negative list approach effectively forces CITES signatories to expend limited resources on just a select few, leaving many species to be traded with neither constraint nor review. For example, recently several bird classified as threatened with extinction appeared in the legal wild bird trade because the CITES process never considered their status. If a "positive list" approach were taken, only species evaluated and approved for the positive list would be permitted in trade, thus lightening the review burden for member states and the Secretariat, and also preventing inadvertent legal trade threats to poorly known species.

Specific weaknesses in the text include: it does not stipulate guidelines for the 'non-detriment' finding required of national Scientific Authorities; non-detriment findings require copious amounts of information; the 'household effects' clause is often not rigid enough/specific enough to prevent CITES violations by means of this Article (VII); non-reporting from Parties means Secretariat monitoring is incomplete; and it has no capacity to address domestic trade in listed species.

During the coronavirus pandemic in 2020 CEO Ivonne Higuero noted that wildlife trade not only helps to destroy habitats, but these habitats create a safety barrier for humans that can prevent pathogens from animals passing themselves on to people.

Suggestions for improvement in the operation of CITES include: more regular missions by the Secretariat (not reserved just for high-profile species); improvement of national legislation and enforcement; better reporting by Parties (and the consolidation of information from all sources-NGOs, TRAFFIC, the wildlife trade monitoring network and Parties); more emphasis on enforcement-including a technical committee enforcement officer; the development of CITES Action Plans (akin to Biodiversity Action Plans related to the Convention on Biological Diversity) including: designation of Scientific/Management Authorities and national enforcement strategies; incentives for reporting and timelines for both Action Plans and reporting. CITES would benefit from access to Global Environment Facility (GEF), funds-although this is difficult given the GEFs more ecosystem approach-or other more regular funds. Development of a future mechanism similar to that of the Montreal Protocol (developed nations contribute to a fund for developing nations) could allow more funds for non-Secretariat activities.

On 15 July 2008, the Committee of Environmental Insecticides that oversees the administration of the convention between meetings of all the Parties granted China and Japan permission to import elephant ivory from four African government stockpiles, the ivory being sold at a single auction in each country. The amounts to be sold comprise approximately 44 tons from Botswana, 9 tons from Namibia, 51 tons from South Africa, and 4 tons from Zimbabwe. The Chinese government in 2003 acknowledged that it had lost track of 121 tons of ivory between 1991 and 2002.

From 2005 – 2009 the legal trade corresponded with these numbers
In the 1990s the annual trade of legal animal products was $160 billion annually. In 2009 the estimated value almost doubled to $300 billion.

Additional information about the documented trade can be extracted through queries on the CITES website.

The Conference of the Parties (CoP) is held once every three years. The last Conference of the Parties (CoP 18) was held in Geneva, Switzerland, 17-28 August 2019 and the one before it (CoP 17) was held in Johannesburg, South Africa, 2016. The next one (CoP 19) will be in San Jose, Cost Rica in 2022. The location of the next CoP is chosen at the close of each CoP by a secret ballot vote.

The CITES Committees (Animals Committee, Plants Committee and Standing Committee) hold meetings during each year that does not have a CoP, while the Standing committee meets also in years with a CoP. The Committee meetings take place in Geneva, Switzerland (where the Secretariat of the CITES Convention is located), unless another country offers to host the meeting. The Secretariat is administered by UNEP. The Animals and Plants Committees have sometimes held joint meetings. The previous joint meeting was held in March 2012 in Dublin, Ireland, and the latest one was held in Veracruz, Mexico in May 2014.

A current list of upcoming meetings appears on the CITES calendar.







</doc>
<doc id="6203" url="https://en.wikipedia.org/wiki?curid=6203" title="Environmental Modification Convention">
Environmental Modification Convention

The Environmental Modification Convention (ENMOD), formally the Convention on the Prohibition of Military or Any Other Hostile Use of Environmental Modification Techniques is an international treaty prohibiting the military or other hostile use of environmental modification techniques having widespread, long-lasting or severe effects. It opened for signature on 18 May 1977 in Geneva and entered into force on 5 October 1978.

The Convention bans weather warfare, which is the use of weather modification techniques for the purposes of inducing damage or destruction. The Convention on Biological Diversity of 2010 would also ban some forms of weather modification or geoengineering.

Many states do not regard this as a complete ban on the use of herbicides in warfare, such as Agent Orange, but it does require case-by-case consideration.

The Convention was signed by 48 states; 16 of the signatories have not ratified. As of January 2018, the Convention has 78 state parties.

The problem of artificial modification of the environment for military or other hostile purposes was brought to the international agenda in the early 1970s. Following the US decision of July 1972 to renounce the use of climate modification techniques for hostile purposes, the 1973 resolution by the US Senate calling for an international agreement "prohibiting the use of any environmental or geophysical modification activity as a weapon of war", and an in-depth review by the Department of Defense of the military aspects of weather and other environmental modification techniques, US decided to seek agreement with the Soviet Union to explore the possibilities of an international agreement.

In July 1974, US and USSR agreed to hold bilateral discussions on measures to overcome the danger of the use of environmental modification techniques for military purposes and three subsequent rounds of discussions in 1974 and 1975. In August 1975, US and USSR tabled identical draft texts of a convention at the Conference of the Committee on Disarmament (CCD), Conference on Disarmament, where intensive negotiations resulted in a modified text and understandings regarding four articles of this Convention in 1976.

The Convention was approved by Resolution 31/72 of the General Assembly of the United Nations on 10 December 1976, by 96 to 8 votes with 30 abstentions.

Environmental Modification Technique includes any technique for changing – through the deliberate manipulation of natural processes – the dynamics, composition or structure of the earth, including its biota, lithosphere, hydrosphere and atmosphere, or of outer space.

The Convention contains ten articles and one Annex on the Consultative Committee of Experts. Integral part of the Convention are also the Understandings relating to articles I, II, III and VIII. These Understandings are not incorporated into the Convention but are part of the negotiating record and were included in the report transmitted by the Conference of the Committee on Disarmament to the United Nations General Assembly in September 1976 Report of the Conference of the Committee on Disarmament, Volume I, General Assembly Official records: Thirty-first session, Supplement No. 27 (A/31/27), New York, United Nations, 1976, pp. 91–92.




</doc>
<doc id="6205" url="https://en.wikipedia.org/wiki?curid=6205" title="Chaitin's constant">
Chaitin's constant

In the computer science subfield of algorithmic information theory, a Chaitin constant (Chaitin omega number) or halting probability is a real number that, informally speaking, represents the probability that a randomly constructed program will halt. These numbers are formed from a construction due to Gregory Chaitin.

Although there are infinitely many halting probabilities, one for each method of encoding programs, it is common to use the letter Ω to refer to them as if there were only one. Because Ω depends on the program encoding used, it is sometimes called Chaitin's construction instead of Chaitin's constant when not referring to any specific encoding.

Each halting probability is a normal and transcendental real number that is not computable, which means that there is no algorithm to compute its digits. Indeed, each halting probability is Martin-Löf random, meaning there is not even any algorithm which can reliably guess its digits.

The definition of a halting probability relies on the existence of a prefix-free universal computable function. Such a function, intuitively, represents a programming language with the property that no valid program can be obtained as a proper extension of another valid program.

Suppose that "F" is a partial function that takes one argument, a finite binary string, and possibly returns a single binary string as output. The function "F" is called computable if there is a Turing machine that computes it (in the sense that for any finite binary strings "x" and "y," "F(x) = y" if and only if the Turing machine halts with "y" on its tape when given the input "x").

The function "F" is called universal if the following property holds: for every computable function "f" of a single variable there is a string "w" such that for all "x", "F"("w" "x") = "f"("x"); here "w" "x" represents the concatenation of the two strings "w" and "x". This means that "F" can be used to simulate any computable function of one variable. Informally, "w" represents a "script" for the computable function "f", and "F" represents an "interpreter" that parses the script as a prefix of its input and then executes it on the remainder of input.

The domain of "F" is the set of all inputs "p" on which it is defined. For "F" that are universal, such a "p" can generally be seen both as the concatenation of a program part and a data part, and as a single program for the function "F".

The function "F" is called prefix-free if there are no two elements "p", "p′" in its domain such that "p′" is a proper extension of "p". This can be rephrased as: the domain of "F" is a prefix-free code (instantaneous code) on the set of finite binary strings. A simple way to enforce prefix-free-ness is to use machines whose means of input is a binary stream from which bits can be read one at a time. There is no end-of-stream marker; the end of input is determined by when the universal machine decides to stop reading more bits. Here, the difference between the two notions of program mentioned in the last paragraph becomes clear; one is easily recognized by some grammar, while the other requires arbitrary computation to recognize.

The domain of any universal computable function is a computably enumerable set but never a computable set. The domain is always Turing equivalent to the halting problem.

Let "P" be the domain of a prefix-free universal computable function "F". The constant Ω is then defined as
where formula_2 denotes the length of a string "p". This is an infinite sum which has one summand for every "p" in the domain of "F". The requirement that the domain be prefix-free, together with Kraft's inequality, ensures that this sum converges to a real number between 0 and 1. If "F" is clear from context then Ω may be denoted simply Ω, although different prefix-free universal computable functions lead to different values of Ω.

Knowing the first "N" bits of Ω, one could calculate the halting problem for all programs of a size up to "N". Let the program "p" for which the halting problem is to be solved be "N" bits long. In dovetailing fashion, all programs of all lengths are run, until enough have halted to jointly contribute enough probability to match these first "N" bits. If the program "p" hasn't halted yet, then it never will, since its contribution to the halting probability would affect the first "N" bits. Thus, the halting problem would be solved for "p".

Because many outstanding problems in number theory, such as Goldbach's conjecture, are equivalent to solving the halting problem for special programs (which would basically search for counter-examples and halt if one is found), knowing enough bits of Chaitin's constant would also imply knowing the answer to these problems. But as the halting problem is not generally solvable, and therefore calculating any but the first few bits of Chaitin's constant is not possible, this just reduces hard problems to impossible ones, much like trying to build an oracle machine for the halting problem would be.

The Cantor space is the collection of all infinite sequences of 0s and 1s. A halting probability can be interpreted as the measure of a certain subset of Cantor space under the usual probability measure on Cantor space. It is from this interpretation that halting probabilities take their name.

The probability measure on Cantor space, sometimes called the fair-coin measure, is defined so that for any binary string "x" the set of sequences that begin with "x" has measure 2. This implies that for each natural number "n", the set of sequences "f" in Cantor space such that "f"("n") = 1 has measure 1/2, and the set of sequences whose "n"th element is 0 also has measure 1/2.

Let "F" be a prefix-free universal computable function. The domain "P" of "F" consists of an infinite set of binary strings
Each of these strings "p" determines a subset "S" of Cantor space; the set "S" contains all sequences in cantor space that begin with "p". These sets are disjoint because "P" is a prefix-free set. The sum
represents the measure of the set 

In this way, Ω represents the probability that a randomly selected infinite sequence of 0s and 1s begins with a bit string (of some finite length) that is in the domain of "F". It is for this reason that Ω is called a halting probability.

Each Chaitin constant Ω has the following properties:


Not every set that is Turing equivalent to the halting problem is a halting probability. A finer equivalence relation, Solovay equivalence, can be used to characterize the halting probabilities among the left-c.e. reals. One can show that a real number in [0,1] is a Chaitin constant (i.e. the halting probability of some prefix-free universal computable function) if and only if it is left-c.e. and algorithmically random. Ω is among the few definable algorithmically random numbers and is the best-known algorithmically random number, but it is not at all typical of all algorithmically random numbers.

A real number is called computable if there is an algorithm which, given "n", returns the first "n" digits of the number. This is equivalent to the existence of a program that enumerates the digits of the real number.

No halting probability is computable. The proof of this fact relies on an algorithm which, given the first "n" digits of Ω, solves Turing's halting problem for programs of length up to "n". Since the halting problem is undecidable, Ω cannot be computed.

The algorithm proceeds as follows. Given the first "n" digits of Ω and a "k" ≤ "n", the algorithm enumerates the domain of "F" until enough elements of the domain have been found so that the probability they represent is within 2 of Ω. After this point, no additional program of length "k" can be in the domain, because each of these would add 2 to the measure, which is impossible. Thus the set of strings of length "k" in the domain is exactly the set of such strings already enumerated.

A real number is random if the binary sequence representing the real number is an algorithmically random sequence. 
Calude, Hertling, Khoussainov, and Wang showed
that a recursively enumerable real number is an algorithmically random sequence if and only if it is a Chaitin's Ω number.

For each specific consistent effectively represented axiomatic system for the natural numbers, such as Peano arithmetic, there exists a constant "N" such that no bit of Ω after the "N"th can be proven to be 1 or 0 within that system. The constant "N" depends on how the formal system is effectively represented, and thus does not directly reflect the complexity of the axiomatic system. This incompleteness result is similar to Gödel's incompleteness theorem in that it shows that no consistent formal theory for arithmetic can be complete.

As mentioned above, the first n bits of Gregory Chaitin's constant Ω are random or incompressible in the sense that we cannot compute them by a halting algorithm with fewer than n-O(1) bits. However, consider the short but never halting algorithm which systematically lists and runs all possible programs; whenever one of them halts its probability gets added to the output (initialized by zero). After finite time the first n bits of the output will never change any more (it does not matter that this time itself is not computable by a halting program). So there is a short non-halting algorithm whose output converges (after finite time) onto the first n bits of Ω. In other words, the enumerable first n bits of Ω are highly compressible in the sense that they are limit-computable by a very short algorithm; they are not random with respect to the set of enumerating algorithms. Jürgen Schmidhuber (2000) constructed a limit-computable "Super Ω" which in a sense is much more random than the original limit-computable Ω, as one cannot significantly compress the Super Ω by any enumerating non-halting algorithm.

For an alternative "Super Ω", the universality probability of a prefix-free Universal Turing Machine (UTM) namely, the probability that it remains universal even when every input of it (as a binary string) is prefixed by a random binary string can be seen as the non-halting probability of a machine with oracle the third iteration of the halting problem (i.e., formula_7using Turing Jump notation).





</doc>
<doc id="6206" url="https://en.wikipedia.org/wiki?curid=6206" title="Computable number">
Computable number

In mathematics, computable numbers are the real numbers that can be computed to within any desired precision by a finite, terminating algorithm. They are also known as the recursive numbers, effective numbers (vanDerHoeven) or the computable reals or recursive reals.

Equivalent definitions can be given using μ-recursive functions, Turing machines, or λ-calculus as the formal representation of algorithms. The computable numbers form a real closed field and can be used in the place of real numbers for many, but not all, mathematical purposes.

In the following, Marvin Minsky defines the numbers to be computed in a manner similar to those defined by Alan Turing in 1936; i.e., as "sequences of digits interpreted as decimal fractions" between 0 and 1:

The key notions in the definition are (1) that some "n" is specified at the start, (2) for any "n" the computation only takes a finite number of steps, after which the machine produces the desired output and terminates.

An alternate form of (2) – the machine successively prints all n of the digits on its tape, halting after printing the n – emphasizes Minsky's observation: (3) That by use of a Turing machine, a "finite" definition – in the form of the machine's table – is being used to define what is a potentially-"infinite" string of decimal digits.

This is however not the modern definition which only requires the result be accurate to within any given accuracy. The informal definition above is subject to a rounding problem called the table-maker's dilemma whereas the modern definition is not.

A real number "a" is computable if it can be approximated by some computable function formula_1 in the following manner: given any positive integer "n", the function produces an integer "f"("n") such that:

There are two similar definitions that are equivalent:

There is another equivalent definition of computable numbers via computable Dedekind cuts. A computable Dedekind cut is a computable function formula_8 which when provided with a rational number formula_9 as input returns formula_10 or formula_11, satisfying the following conditions:
An example is given by a program "D" that defines the cube root of 3. Assuming formula_15 this is defined by:

A real number is computable if and only if there is a computable Dedekind cut "D" corresponding to it. The function "D" is unique for each computable number (although of course two different programs may provide the same function).

A complex number is called computable if its real and imaginary parts are computable.

Assigning a Gödel number to each Turing machine definition produces a subset formula_18 of the natural numbers corresponding to the computable numbers and identifies a surjection from formula_18 to the computable numbers. There are only countably many Turing machines, showing that the computable numbers are subcountable. The set formula_18 of these Gödel numbers, however, is not computably enumerable (and consequently, neither are subsets of formula_18 that are defined in terms of it). This is because there is no algorithm to determine which Gödel numbers correspond to Turing machines that produce computable reals. In order to produce a computable real, a Turing machine must compute a total function, but the corresponding decision problem is in Turing degree 0′′. Consequently, there is no surjective computable function from the natural numbers to the computable reals, and Cantor's diagonal argument cannot be used constructively to demonstrate uncountably many of them.

While the set of real numbers is uncountable, the set of computable numbers is classically countable and thus almost all real numbers are not computable. Here, for any given computable number formula_22 the well ordering principle provides that there is a minimal element in formula_18 which corresponds to formula_24, and therefore there exists a subset consisting of the minimal elements, on which the map is a bijection. The inverse of this bijection is an injection into the natural numbers of the computable numbers, proving that they are countable. But, again, this subset is not computable, even though the computable reals are themselves ordered.

The arithmetical operations on computable numbers are themselves computable in the sense that whenever real numbers "a" and "b" are computable then the following real numbers are also computable: "a + b", "a - b", "ab", and "a/b" if "b" is nonzero.
These operations are actually "uniformly computable"; for example, there is a Turing machine which on input ("A","B",formula_25) produces output "r", where "A" is the description of a Turing machine approximating "a", "B" is the description of a Turing machine approximating "b", and "r" is an formula_25 approximation of "a"+"b".

The fact that computable real numbers form a field was first proved by Henry Gordon Rice in 1954 (Rice 1954).

Computable reals however do not form a computable field, because the definition of a computable field requires effective equality.

The order relation on the computable numbers is not computable. Let "A" be the description of a Turing machine approximating the number formula_6. Then there is no Turing machine which on input "A" outputs "YES" if formula_28 and "NO" if formula_29 To see why, suppose the machine described by "A" keeps outputting 0 as formula_25 approximations. It is not clear how long to wait before deciding that the machine will "never" output an approximation which forces "a" to be positive. Thus the machine will eventually have to guess that the number will equal 0, in order to produce an output; the sequence may later become different from 0. This idea can be used to show that the machine is incorrect on some sequences if it computes a total function. A similar problem occurs when the computable reals are represented as Dedekind cuts. The same holds for the equality relation : the equality test is not computable.

While the full order relation is not computable, the restriction of it to pairs of unequal numbers is computable. That is, there is a program that takes as input two Turing machines "A" and "B" approximating numbers "a" and "b", where "a" ≠ "b", and outputs whether formula_31 or formula_32 It is sufficient to use "ε"-approximations where formula_33 so by taking increasingly small ε (approaching 0), one eventually can decide whether formula_31 or formula_32

The computable real numbers do not share all the properties of the real numbers used in analysis. For example, the least upper bound of a bounded increasing computable sequence of computable real numbers need not be a computable real number (Bridges and Richman, 1987:58). A sequence with this property is known as a Specker sequence, as the first construction is due to E. Specker (1949). Despite the existence of counterexamples such as these, parts of calculus and real analysis can be developed in the field of computable numbers, leading to the study of computable analysis.

Every computable number is definable, but not vice versa. There are many definable, noncomputable real numbers, including:
Both of these examples in fact define an infinite set of definable, uncomputable numbers, one for each Universal Turing machine.
A real number is computable if and only if the set of natural numbers it represents (when written in binary and viewed as a characteristic function) is computable.

Every computable number is arithmetical.

The set of computable real numbers (as well as every countable, densely ordered subset of computable reals without ends) is order-isomorphic to the set of rational numbers.

Turing's original paper defined computable numbers as follows:

Turing was aware that this definition is equivalent to the formula_25-approximation definition given above. The argument proceeds as follows: if a number is computable in the Turing sense, then it is also computable in the formula_25 sense: if formula_41, then the first "n" digits of the decimal expansion for "a" provide an formula_25 approximation of "a". For the converse, we pick an formula_25 computable real number "a" and generate increasingly precise approximations until the "n"th digit after the decimal point is certain. This always generates a decimal expansion equal to "a" but it may improperly end in an infinite sequence of 9's in which case it must have a finite (and thus computable) proper decimal expansion.

Unless certain topological properties of the real numbers are relevant it is often more convenient to deal with elements of formula_44 (total 0,1 valued functions) instead of reals numbers in formula_45. The members of formula_44 can be identified with binary decimal expansions but since the decimal expansions formula_47 and formula_48 denote the same real number the interval formula_45 can only be bijectively (and homeomorphically under the subset topology) identified with the subset of formula_44 not ending in all 1's.

Note that this property of decimal expansions means it's impossible to effectively identify computable real numbers defined in terms of a decimal expansion and those defined in the formula_25 approximation sense. Hirst has shown there is no algorithm which takes as input the description of a Turing machine which produces formula_25 approximations for the computable number "a", and produces as output a Turing machine which enumerates the digits of "a" in the sense of Turing's definition (see Hirst 2007). Similarly it means that the arithmetic operations on the computable reals are not effective on their decimal representations as when adding decimal numbers, in order to produce one digit it may be necessary to look arbitrarily far to the right to determine if there is a carry to the current location. This lack of uniformity is one reason that the contemporary definition of computable numbers uses formula_25 approximations rather than decimal expansions.

However, from a computational or measure theoretic perspective the two structures formula_44 and formula_45 are essentially identical, and computability theorists often refer to members of formula_44 as reals. While formula_45 formula_44 is totally disconnected, for questions about formula_59 classes or randomness it's much less messy to work in formula_44.

Elements of formula_61 are sometimes called reals as well and though containing a homeomorphic image of formula_62 formula_61 in addition to being totally disconnected isn't even locally compact. This leads to genuine differences in the computational properties. For instance the formula_64 satisfying formula_65 with formula_66 quantifier free must be computable while the unique formula_67 satisfying a universal formula can be arbitrarily high in the hyperarithmetic hierarchy.

The computable numbers include the specific real numbers which appear in practice, including all real algebraic numbers, as well as "e", "π", and many other transcendental numbers. Though the computable reals exhaust those reals we can calculate or approximate, the assumption that all reals are computable leads to substantially different conclusions about the real numbers. The question naturally arises of whether it is possible to dispose of the full set of reals and use computable numbers for all of mathematics. This idea is appealing from a constructivist point of view, and has been pursued by what Bishop and Richman call the "Russian school" of constructive mathematics.

To actually develop analysis over computable numbers, some care must be taken. For example, if one uses the classical definition of a sequence, the set of computable numbers is not closed under the basic operation of taking the supremum of a bounded sequence (for example, consider a Specker sequence, see the section above). This difficulty is addressed by considering only sequences which have a computable modulus of convergence. The resulting mathematical theory is called computable analysis.

There are some computer packages that work with computable real numbers, representing the real numbers as programs computing approximations. One example is the RealLib package (Lambov 2015).




</doc>
<doc id="6207" url="https://en.wikipedia.org/wiki?curid=6207" title="Electric current">
Electric current

An electric current is the rate of flow of electric charge past a point or region. An electric current is said to exist when there is a net flow of electric charge through a region. Electric charge is carried by charged particles, so an electric current is a flow of charged particles. The moving particles are called charge carriers, which may be one of several types of particles, depending on the conductor. In electric circuits the charge carriers are often electrons moving through a wire. In an electrolyte the charge carriers are ions, while in an ionized gas (plasma), both ions and electrons are used.

The SI unit of electric current is the ampere, or "amp", which is the flow of electric charge across a surface at the rate of one coulomb per second. The ampere (symbol: A) is an SI base unit Electric current is measured using a device called an ammeter.

Electric currents cause Joule heating, which creates light in incandescent light bulbs. They also create magnetic fields, which are used in motors, generators, inductors, and transformers.

The conventional symbol for current is , which originates from the French phrase "intensité du courant", (current intensity). Current intensity is often referred to simply as "current". The symbol was used by André-Marie Ampère, after whom the unit of electric current is named, in formulating Ampère's force law (1820). The notation travelled from France to Great Britain, where it became standard, although at least one journal did not change from using to until 1896.

In a conductive material, the moving charged particles that constitute the electric current are called charge carriers. In metals, which make up the wires and other conductors in most electrical circuits, the positively charged atomic nuclei of the atoms are held in a fixed position, and the negatively charged electrons are the charge carriers, free to move about in the metal. In other materials, notably the semiconductors, the charge carriers can be positive "or" negative, depending on the dopant used. Positive and negative charge carriers may even be present at the same time, as happens in an electrolyte in an electrochemical cell.

A flow of positive charges gives the same electric current, and has the same effect in a circuit, as an equal flow of negative charges in the opposite direction. Since current can be the flow of either positive or negative charges, or both, a convention is needed for the direction of current that is independent of the type of charge carriers. The direction of "conventional current" is arbitrarily defined as the direction in which positive charges flow. Negatively charged carriers, such as the electrons (the charge carriers in metal wires and many other electronic circuit components), therefore flow in the opposite direction of conventional current flow in an electrical circuit.

As current in a wire or circuit element can flow in both directions, the direction representing positive current must be specified, usually by an arrow on the circuit schematic diagram. This is called the "reference direction" of the current. When analyzing electrical circuits, the actual direction of current through a specific circuit element is usually unknown until the analysis is completed. Consequently, the reference directions of currents are often assigned arbitrarily. When the circuit is solved, a negative value for the current implies the actual direction of current through that circuit element is opposite that of the chosen reference direction.

Ohm's law states that the current through a conductor between two points is directly proportional to the potential difference across the two points. Introducing the constant of proportionality, the resistance, one arrives at the usual mathematical equation that describes this relationship:

where "I" is the current through the conductor in units of amperes, "V" is the potential difference measured "across" the conductor in units of volts, and "R" is the resistance of the conductor in units of ohms. More specifically, Ohm's law states that the "R" in this relation is constant, independent of the current.

In alternating current (AC) systems, the movement of electric charge periodically reverses direction. AC is the form of electric power most commonly delivered to businesses and residences. The usual waveform of an AC power circuit is a sine wave, though certain applications use alternative waveforms, such as triangular or square waves. Audio and radio signals carried on electrical wires are also examples of alternating current. An important goal in these applications is recovery of information encoded (or "modulated") onto the AC signal.

In contrast, direct current (DC) refers to a system in which the movement of electric charge in only one direction (sometimes called unidirectional flow). Direct current is produced by sources such as batteries, thermocouples, solar cells, and commutator-type electric machines of the dynamo type. Alternating current can also be converted to direct current through use of a rectifier. Direct current may flow in a conductor such as a wire, but can also flow through semiconductors, insulators, or even through a vacuum as in electron or ion beams. An old name for direct current was "galvanic current".

Natural observable examples of electrical current include lightning, static electric discharge, and the solar wind, the source of the polar auroras.

Man-made occurrences of electric current include the flow of conduction electrons in metal wires such as the overhead power lines that deliver electrical energy across long distances and the smaller wires within electrical and electronic equipment. Eddy currents are electric currents that occur in conductors exposed to changing magnetic fields. Similarly, electric currents occur, particularly in the surface, of conductors exposed to electromagnetic waves. When oscillating electric currents flow at the correct voltages within radio antennas, radio waves are generated.

In electronics, other forms of electric current include the flow of electrons through resistors or through the vacuum in a vacuum tube, the flow of ions inside a battery or a neuron, and the flow of holes within metals and semiconductors.

Current can be measured using an ammeter.

Electric current can be directly measured with a galvanometer, but this method involves breaking the electrical circuit, which is sometimes inconvenient. 

Current can also be measured without breaking the circuit by detecting the magnetic field associated with the current. 
Devices, at the circuit level, use various techniques to measure current:

Joule heating, also known as "ohmic heating" and "resistive heating", is the process of power dissipation by which the passage of an electric current through a conductor increases the internal energy of the conductor, converting thermodynamic work into heat. The phenomenon was first studied by James Prescott Joule in 1841. Joule immersed a length of wire in a fixed mass of water and measured the temperature rise due to a known current through the wire for a 30 minute period. By varying the current and the length of the wire he deduced that the heat produced was proportional to the square of the current multiplied by the electrical resistance of the wire.

This relationship is known as Joule's Law. The SI unit of energy was subsequently named the joule and given the symbol "J". The commonly known SI unit of power, the watt (symbol: W), is equivalent to one joule per second.

In an electromagnet a coil of wires behaves like a magnet when an electric current flows through it. When the current is switched off, the coil loses its magnetism immediately.

Electric current produces a magnetic field. The magnetic field can be visualized as a pattern of circular field lines surrounding the wire that persists as long as there is current.

Magnetic fields can also be used to make electric currents. When a changing magnetic field is applied to a conductor, an electromotive force (EMF) is induced, which starts an electric current, when there is a suitable path.

When an electric current flows in a suitably shaped conductor at radio frequencies, radio waves can be generated. These travel at the speed of light and can cause electric currents in distant conductors.

In metallic solids, electric charge flows by means of electrons, from lower to higher electrical potential. In other media, any stream of charged objects (ions, for example) may constitute an electric current. To provide a definition of current independent of the type of charge carriers, "conventional current" is defined as moving in the same direction as the positive charge flow. So, in metals where the charge carriers (electrons) are negative, conventional current is in the opposite direction to the overall electron movement. In conductors where the charge carriers are positive, conventional current is in the same direction as the charge carriers.

In a vacuum, a beam of ions or electrons may be formed. In other conductive materials, the electric current is due to the flow of both positively and negatively charged particles at the same time. In still others, the current is entirely due to positive charge flow. For example, the electric currents in electrolytes are flows of positively and negatively charged ions. In a common lead-acid electrochemical cell, electric currents are composed of positive hydronium ions flowing in one direction, and negative sulfate ions flowing in the other. Electric currents in sparks or plasma are flows of electrons as well as positive and negative ions. In ice and in certain solid electrolytes, the electric current is entirely composed of flowing ions.

In a metal, some of the outer electrons in each atom are not bound to the individual atom as they are in insulating materials, but are free to move within the metal lattice. These conduction electrons can serve as charge carriers, carrying a current. Metals are particularly conductive because there are many of these free electrons, typically one per atom in the lattice. With no external electric field applied, these electrons move about randomly due to thermal energy but, on average, there is zero net current within the metal. At room temperature, the average speed of these random motions is 10 metres per second. Given a surface through which a metal wire passes, electrons move in both directions across the surface at an equal rate. As George Gamow wrote in his popular science book, "One, Two, Three...Infinity" (1947), "The metallic substances differ from all other materials by the fact that the outer shells of their atoms are bound rather loosely, and often let one of their electrons go free. Thus the interior of a metal is filled up with a large number of unattached electrons that travel aimlessly around like a crowd of displaced persons. When a metal wire is subjected to electric force applied on its opposite ends, these free electrons rush in the direction of the force, thus forming what we call an electric current."

When a metal wire is connected across the two terminals of a DC voltage source such as a battery, the source places an electric field across the conductor. The moment contact is made, the free electrons of the conductor are forced to drift toward the positive terminal under the influence of this field. The free electrons are therefore the charge carrier in a typical solid conductor.

For a steady flow of charge through a surface, the current "I" (in amperes) can be calculated with the following equation:
where "Q" is the electric charge transferred through the surface over a time "t". If "Q" and "t" are measured in coulombs and seconds respectively, "I" is in amperes.

More generally, electric current can be represented as the rate at which charge flows through a given surface as:

Electric currents in electrolytes are flows of electrically charged particles (ions). For example, if an electric field is placed across a solution of Na and Cl (and conditions are right) the sodium ions move towards the negative electrode (cathode), while the chloride ions move towards the positive electrode (anode). Reactions take place at both electrode surfaces, neutralizing each ion.

Water-ice and certain solid electrolytes called proton conductors contain positive hydrogen ions ("protons") that are mobile. In these materials, electric currents are composed of moving protons, as opposed to the moving electrons in metals.

In certain electrolyte mixtures, brightly coloured ions are the moving electric charges. The slow progress of the colour makes the current visible.

In air and other ordinary gases below the breakdown field, the dominant source of electrical conduction is via relatively few mobile ions produced by radioactive gases, ultraviolet light, or cosmic rays. Since the electrical conductivity is low, gases are dielectrics or insulators. However, once the applied electric field approaches the breakdown value, free electrons become sufficiently accelerated by the electric field to create additional free electrons by colliding, and ionizing, neutral gas atoms or molecules in a process called avalanche breakdown. The breakdown process forms a plasma that contains enough mobile electrons and positive ions to make it an electrical conductor. In the process, it forms a light emitting conductive path, such as a spark, arc or lightning.

Plasma is the state of matter where some of the electrons in a gas are stripped or "ionized" from their molecules or atoms. A plasma can be formed by high temperature, or by application of a high electric or alternating magnetic field as noted above. Due to their lower mass, the electrons in a plasma accelerate more quickly in response to an electric field than the heavier positive ions, and hence carry the bulk of the current. The free ions recombine to create new chemical compounds (for example, breaking atmospheric oxygen into single oxygen [O → 2O], which then recombine creating ozone [O]).

Since a "perfect vacuum" contains no charged particles, it normally behaves as a perfect insulator. However, metal electrode surfaces can cause a region of the vacuum to become conductive by injecting free electrons or ions through either field electron emission or thermionic emission. Thermionic emission occurs when the thermal energy exceeds the metal's work function, while field electron emission occurs when the electric field at the surface of the metal is high enough to cause tunneling, which results in the ejection of free electrons from the metal into the vacuum. Externally heated electrodes are often used to generate an electron cloud as in the filament or indirectly heated cathode of vacuum tubes. Cold electrodes can also spontaneously produce electron clouds via thermionic emission when small incandescent regions (called "cathode spots" or "anode spots") are formed. These are incandescent regions of the electrode surface that are created by a localized high current. These regions may be initiated by field electron emission, but are then sustained by localized thermionic emission once a vacuum arc forms. These small electron-emitting regions can form quite rapidly, even explosively, on a metal surface subjected to a high electrical field. Vacuum tubes and sprytrons are some of the electronic switching and amplifying devices based on vacuum conductivity.

Superconductivity is a phenomenon of exactly zero electrical resistance and expulsion of magnetic fields occurring in certain materials when cooled below a characteristic critical temperature. It was discovered by Heike Kamerlingh Onnes on April 8, 1911 in Leiden. Like ferromagnetism and atomic spectral lines, superconductivity is a quantum mechanical phenomenon. It is characterized by the Meissner effect, the complete ejection of magnetic field lines from the interior of the superconductor as it transitions into the superconducting state. The occurrence of the Meissner effect indicates that superconductivity cannot be understood simply as the idealization of "perfect conductivity" in classical physics.

In a semiconductor it is sometimes useful to think of the current as due to the flow of positive "holes" (the mobile positive charge carriers that are places where the semiconductor crystal is missing a valence electron). This is the case in a p-type semiconductor. A semiconductor has electrical conductivity intermediate in magnitude between that of a conductor and an insulator. This means a conductivity roughly in the range of 10 to 10 siemens per centimeter (S⋅cm).

In the classic crystalline semiconductors, electrons can have energies only within certain bands (i.e. ranges of levels of energy). Energetically, these bands are located between the energy of the ground state, the state in which electrons are tightly bound to the atomic nuclei of the material, and the free electron energy, the latter describing the energy required for an electron to escape entirely from the material. The energy bands each correspond to many discrete quantum states of the electrons, and most of the states with low energy (closer to the nucleus) are occupied, up to a particular band called the "valence band". Semiconductors and insulators are distinguished from metals because the valence band in any given metal is nearly filled with electrons under usual operating conditions, while very few (semiconductor) or virtually none (insulator) of them are available in the "conduction band", the band immediately above the valence band.

The ease of exciting electrons in the semiconductor from the valence band to the conduction band depends on the band gap between the bands. The size of this energy band gap serves as an arbitrary dividing line (roughly 4 eV) between semiconductors and insulators.

With covalent bonds, an electron moves by hopping to a neighboring bond. The Pauli exclusion principle requires that the electron be lifted into the higher anti-bonding state of that bond. For delocalized states, for example in one dimensionthat is in a nanowire, for every energy there is a state with electrons flowing in one direction and another state with the electrons flowing in the other. For a net current to flow, more states for one direction than for the other direction must be occupied. For this to occur, energy is required, as in the semiconductor the next higher states lie above the band gap. Often this is stated as: full bands do not contribute to the electrical conductivity. However, as a semiconductor's temperature rises above absolute zero, there is more energy in the semiconductor to spend on lattice vibration and on exciting electrons into the conduction band. The current-carrying electrons in the conduction band are known as "free electrons", though they are often simply called "electrons" if that is clear in context.

Current density is the rate at which charge passes through a chosen unit area. It is defined as a vector whose magnitude is the current per unit cross-sectional area. As discussed in Reference direction, the direction is arbitrary. Conventionally, if the moving charges are positive, then the current density has the same sign as the velocity of the charges. For negative charges, the sign of the current density is opposite to the velocity of the charges. In SI units, current density (symbol: j) is expressed in the SI base units of amperes per square metre.

In linear materials such as metals, and under low frequencies, the current density across the conductor surface is uniform. In such conditions, Ohm's law states that the current is directly proportional to the potential difference between two ends (across) of that metal (ideal) resistor (or other ohmic device):

where formula_6 is the current, measured in amperes; formula_7 is the potential difference, measured in volts; and formula_8 is the resistance, measured in ohms. For alternating currents, especially at higher frequencies, skin effect causes the current to spread unevenly across the conductor cross-section, with higher density near the surface, thus increasing the apparent resistance.

The mobile charged particles within a conductor move constantly in random directions, like the particles of a gas. (More accurately, a Fermi gas.) To create a net flow of charge, the particles must also move together with an average drift rate. Electrons are the charge carriers in most metals and they follow an erratic path, bouncing from atom to atom, but generally drifting in the opposite direction of the electric field. The speed they drift at can be calculated from the equation:
where
Typically, electric charges in solids flow slowly. For example, in a copper wire of cross-section 0.5 mm, carrying a current of 5 A, the drift velocity of the electrons is on the order of a millimetre per second. To take a different example, in the near-vacuum inside a cathode ray tube, the electrons travel in near-straight lines at about a tenth of the speed of light.

Any accelerating electric charge, and therefore any changing electric current, gives rise to an electromagnetic wave that propagates at very high speed outside the surface of the conductor. This speed is usually a significant fraction of the speed of light, as can be deduced from Maxwell's equations, and is therefore many times faster than the drift velocity of the electrons. For example, in AC power lines, the waves of electromagnetic energy propagate through the space between the wires, moving from a source to a distant load, even though the electrons in the wires only move back and forth over a tiny distance.

The ratio of the speed of the electromagnetic wave to the speed of light in free space is called the velocity factor, and depends on the electromagnetic properties of the conductor and the insulating materials surrounding it, and on their shape and size.

The magnitudes (not the natures) of these three velocities can be illustrated by an analogy with the three similar velocities associated with gases. (See also hydraulic analogy.)


</doc>
<doc id="6208" url="https://en.wikipedia.org/wiki?curid=6208" title="Charles Ancillon">
Charles Ancillon

Charles Ancillon (28 July 16595 July 1715) was a French jurist and diplomat.

Ancillon was born in Metz into a distinguished family of Huguenots. His father, David Ancillon (1617–1692), was obliged to leave France on the revocation of the Edict of Nantes, and became pastor of the French Protestant community in Berlin.

Ancillon studied law at Marburg, Geneva and Paris, where he was called to the bar. At the request of the Huguenots at Metz, he pleaded its cause at the court of King Louis XIV, urging that it should be excepted in the revocation of the Edict of Nantes, but his efforts were unsuccessful, and he joined his father in Berlin. He was at once appointed by Elector Frederick III ""juge et directeur de colonie de Berlin"." Before this, he had published several works on the revocation of the Edict of Nantes and its consequences, but his literary capacity was mediocre, his style stiff and cold, and it was his personal character rather than his reputation as a writer that earned him the confidence of the elector.

In 1687 Ancillon was appointed head of the so-called "Academie des nobles," the principal educational establishment of the state; later on, as councillor of embassy, he took part in the negotiations which led to the assumption of the title of "King in Prussia" by the elector. In 1699 he succeeded Samuel Pufendorf as historiographer to the elector, and the same year replaced his uncle Joseph Ancillon as judge of all the French refugees in the Margraviate of Brandenburg.

Ancillon is mainly remembered for what he did for education in Brandenburg-Prussia, and the share he took, in co-operation with Gottfried Leibniz, in founding the Academy of Berlin. Of his fairly numerous works the one of the most value is the ""Histoire de l'etablissement des Francais refugies dans les etats de Brandebourg"" published in Berlin in 1690.



</doc>
<doc id="6210" url="https://en.wikipedia.org/wiki?curid=6210" title="Clark Ashton Smith">
Clark Ashton Smith

Clark Ashton Smith (January 13, 1893 – August 14, 1961) was an American writer and artist. He achieved early local recognition, largely through the enthusiasm of George Sterling, for traditional verse in the vein of Swinburne. As a poet, Smith is grouped with the West Coast Romantics alongside Joaquin Miller, Sterling, and Nora May French and remembered as "The Last of the Great Romantics" and "The Bard of Auburn". Smith's work was praised by his contemporaries. H. P. Lovecraft stated that "in sheer daemonic strangeness and fertility of conception, Clark Ashton Smith is perhaps unexcelled", and Ray Bradbury said that Smith "filled my mind with incredible worlds, impossibly beautiful cities, and still more fantastic creatures".

Smith was one of "the big three of "Weird Tales", with Robert E. Howard and H. P. Lovecraft", but some readers objected to his morbidness and violation of pulp traditions. The fantasy critic L. Sprague de Camp said of him that "nobody since Poe has so loved a well-rotted corpse." Smith was a member of the Lovecraft circle and his literary friendship with Lovecraft lasted from 1922 until Lovecraft's death in 1937. His work is marked by an extraordinarily rich and ornate vocabulary, a cosmic perspective and a vein of sardonic and sometimes ribald humor.

Of his writing style, Smith stated: "My own conscious ideal has been to delude the reader into accepting an impossibility, or series of impossibilities, by means of a sort of verbal black magic, in the achievement of which I make use of prose-rhythm, metaphor, simile, tone-color, counter-point, and other stylistic resources, like a sort of incantation."

Smith was born January 13, 1893, in Long Valley, California, of English and New England parentage. He spent most of his life in the small town of Auburn, California, living in a cabin built by his parents, Fanny and Timeus Smith. Smith professed to hate the town's provincialism but rarely left it until he married late in life. 

His formal education was limited: he suffered from psychological disorders including intense agoraphobia, and although he was accepted to high school after attending eight years of grammar school, his parents decided it was better for him to be taught at home. An insatiable reader with an extraordinary eidetic memory, Smith appeared to retain most or all of whatever he read. After leaving formal education, he embarked upon a self-directed course of literature, including "Robinson Crusoe", "Gulliver's Travels", the fairy tales of Hans Christian Andersen and Madame d'Aulnoy, the "Arabian Nights" and the poems of Edgar Allan Poe. He read the entire unabridged 13th edition of Webster's Dictionary word for word, studying not only the definitions of the words but also their etymology.

The other main course in Smith's self-education was to read the complete 11th edition of the "Encyclopædia Britannica" at least twice. Smith later taught himself French and Spanish to translate verse out of those languages, including works by Gérard de Nerval, Paul Verlaine, and all but 6 of Charles Baudelaire's 157 poems in "The Flowers of Evil".

His first literary efforts, at the age of 11, took the form of fairy tales and imitations of the Arabian Nights. Later, he wrote long adventure novels dealing with Oriental life. By 14 he had already written a short adventure novel called "The Black Diamonds" which was lost for years until published in 2002. Another juvenile novel was written in his teenaged years—"The Sword of Zagan" (unpublished until 2004). Like "The Black Diamonds", it uses a medieval, "Arabian Nights"-like setting, and the "Arabian Nights", like the fairy tales of the Brothers Grimm and the works of Edgar Allan Poe, are known to have strongly influenced Smith's early writing, as did William Beckford's "Vathek".

At age 17, he sold several tales to "The Black Cat", a magazine which specialized in unusual tales. He also published some tales in the "Overland Monthly" in this brief foray into fiction which preceded his poetic career.

However, it was primarily poetry that motivated the young Smith and he confined his efforts to poetry for more than a decade. In his later youth, Smith made the acquaintance of the San Francisco poet George Sterling through a member of the local Auburn Monday Night Club, where he read several of his poems with considerable success. On a month-long visit to Sterling in Carmel, California, Smith was introduced by Sterling to the poetry of Baudelaire.

He became Sterling's protégé and Sterling helped him to publish his first volume of poems, "The Star-Treader and Other Poems", at the age of 19. Smith received international acclaim for the collection. "The Star-Treader" was received very favorably by American critics, one of whom named Smith "the Keats of the Pacific". Smith briefly moved among the circle that included Ambrose Bierce and Jack London, but his early fame soon faded away.

A little later, Smith's health broke down and for eight years his literary production was intermittent, though he produced his best poetry during this period. A small volume, "Odes and Sonnets", was brought out in 1918. Smith came into contact with literary figures who would later form part of H.P. Lovecraft's circle of correspondents; Smith knew them far earlier than Lovecraft. These figures include poet Samuel Loveman and bookman George Kirk. It was Smith who in fact later introduced Donald Wandrei to Lovecraft. For this reason, it has been suggested that Lovecraft might as well be referred to as a member of a "Smith" circle as Smith was a member of a Lovecraft one.

In 1920 Smith composed a celebrated long poem in blank verse, "The Hashish Eater, or The Apocalypse of Evil" which was published in "Ebony and Crystal" (1922). This was followed by a fan letter from H. P. Lovecraft, which was the beginning of 15 years of friendship and correspondence. With studied playfulness, Smith and Lovecraft borrowed each other's coinages of place names and the names of strange gods for their stories, though so different is Smith's treatment of the Lovecraft theme that it has been dubbed the "Clark Ashton Smythos."

In 1925 Smith published "Sandalwood", which was partly funded by a gift of $50 from Donald Wandrei. He wrote little fiction in this period with the exception of some imaginative vignettes or prose poems. Smith was poor for most of his life and often did hard manual jobs such as fruit picking and woodcutting to support himself and his parents. He was an able cook and made many kinds of wine. He also did well digging, typing and journalism, as well as contributing a column to "The Auburn Journal" and sometimes worked as its night editor.

One of Smith's artistic patrons and frequent correspondents was San Francisco businessman Albert M. Bender.

At the beginning of the Depression in 1929, with his aged parents' health weakening, Smith resumed fiction writing and turned out more than a hundred short stories between 1929 and 1934, nearly all of which can be classed as weird horror or science fiction. Like Lovecraft, he drew upon the nightmares that had plagued him during youthful spells of sickness. Brian Stableford has written that the stories written during this brief phase of hectic productivity "constitute one of the most remarkable oeuvres in imaginative literature".

He published at his own expense a volume containing six of his best stories, "The Double Shadow and Other Fantasies", in an edition of 1000 copies printed by the "Auburn Journal". The theme of much of his work is egotism and its supernatural punishment; his weird fiction is generally macabre in subject matter, gloatingly preoccupied with images of death, decay and abnormality.

Most of Smith's weird fiction falls into four series set variously in Hyperborea, Poseidonis, Averoigne and Zothique. Hyperborea, which is a lost continent of the Miocene period, and Poseidonis, which is a remnant of Atlantis, are much the same, with a magical culture characterized by bizarreness, cruelty, death and postmortem horrors. Averoigne is Smith's version of pre-modern France, comparable to James Branch Cabell's Poictesme. Zothique exists millions of years in the future. It is "the last continent of earth, when the sun is dim and tarnished". These tales have been compared to the "Dying Earth" sequence of Jack Vance.

In 1933 Smith began corresponding with Robert E. Howard, the Texan creator of Conan the Barbarian. From 1933 to 1936, Smith, Howard and Lovecraft were the leaders of the Weird Tales school of fiction and corresponded frequently, although they never met. The writer of oriental fantasies E. Hoffmann Price is the only man known to have met all three in the flesh.

Critic Steve Behrends has suggested that the frequent theme of 'loss' in Smith's fiction (many of his characters attempt to recapture a long-vanished youth, early love, or picturesque past) may reflect Smith's own feeling that his career had suffered a "fall from grace":

In September 1935, Smith's mother Fanny died. Smith spent the next two years nursing his father through his last illness. Timeus died in December 1937. Aged 44, Smith now virtually ceased writing fiction. He had been severely affected by several tragedies occurring in a short period of time: Robert E. Howard's death by suicide (1936), Lovecraft's death from cancer (1937) and the deaths of his parents, which left him exhausted. As a result, he withdrew from the scene, marking the end of "Weird Tales"' Golden Age. He began sculpting and resumed the writing of poetry. However, Smith was visited by many writers at his cabin, including Fritz Leiber, Rah Hoffman, Francis T. Laney and others.

In 1942, three years after August Derleth founded Arkham House for the purpose of preserving the work of H.P. Lovecraft, Derleth published the first of several major collections of Smith's fiction, "Out of Space and Time" (1942). This was followed by "Lost Worlds" (1944). The books sold slowly, went out of print and became costly rarities. Derleth published five more volumes of Smith's prose and two of his verse, and at his death in 1971 had a large volume of Smith's poems in press.

In 1953, Smith suffered a coronary attack. Aged 61, he married Carol(yn) Jones Dorman on November 10, 1954. Dorman had much experience in Hollywood and radio public relations. After honeymooning at the Smith cabin, they moved to Pacific Grove, California, where he set up a household including her three children. (Carol had been married before). For several years he alternated between the house on Indian Ridge and their house in Pacific Grove. Smith having sold most of his father's tract, in 1957 the old house burned – the Smiths believed by arson, others said by accident.

Smith now reluctantly did gardening for other residents at Pacific Grove, and grew a goatee. He spent much time shopping and walking near the seafront but despite Derleth's badgering, resisted the writing of more fiction. In 1961 he suffered a series of strokes and in August 1961 he quietly died in his sleep, aged 68. After Smith's death, Carol remarried (becoming Carolyn Wakefield) and subsequently died of cancer.

The poet's ashes were buried beside, or beneath, a boulder to the immediate west of where his childhood home (destroyed by fire in 1957) stood; some were also scattered in a stand of blue oaks near the boulder. There was no marker. Plaques recognizing Smith have been erected at the Auburn Placer County Library in 1985 and in Bicentennial Park in Auburn in 2003.

Bookseller Roy A. Squires was appointed Smith's "west coast executor", with Jack L. Chalker as his "east coast executor". Squires published many letterpress editions of individual Smith poems.

Smith's literary estate is represented by his stepson, Prof William Dorman, director of CASiana Literary Enterprises. Arkham House owns the copyright to many Smith stories, though some are now in the public domain.

For 'posthumous collaborations' of Smith (stories completed by Lin Carter), see the entry on Lin Carter.

While Smith was always an artist who worked in several very different media, it is possible to identify three distinct periods in which one form of art had precedence over the others.

Smith published most of his volumes of poetry in this period, including the aforementioned "The Star-Treader and Other Poems", as well as "Odes and Sonnets" (1918), "Ebony and Crystal" (1922) and "Sandalwood" (1925). His long poem "The Hashish-Eater; Or, the Apocalypse of Evil" was written in 1920.

Smith wrote most of his weird fiction and Cthulhu Mythos stories, partially inspired by H. P. Lovecraft. Creatures of his invention include Aforgomon, Rlim-Shaikorth, Mordiggian, Tsathoggua, the wizard Eibon, and various others. In an homage to his friend, Lovecraft referred in "The Whisperer in Darkness" and "The Battle That Ended the Century" (written in collaboration with R. H. Barlow) to an Atlantean high-priest, "Klarkash-Ton".

Smith's weird stories form several cycles, called after the lands in which they are set: Averoigne, Hyperborea, Mars, Poseidonis, Zothique. To some extent Smith was influenced in his vision of such lost worlds by the teachings of Theosophy and the writings of Helena Blavatsky. Stories set in Zothique belong to the Dying Earth subgenre. Amongst Smith's science fiction tales are stories set on Mars and the invented planet of Xiccarph.

His short stories originally appeared in the magazines "Weird Tales", "Strange Tales", "Astounding Stories", "Stirring Science Stories" and "Wonder Stories".

Clark Ashton Smith was the third member of the great triumvirate of "Weird Tales", with Lovecraft and Robert E. Howard.

Many of Smith's stories were published in six hardcover volumes by August Derleth under his Arkham House imprint. For a full bibliography to 1978, see Sidney-Fryer, "Emperor of Dreams" (cited below). S.T. Joshi is working with other scholars to produce an updated bibliography of Smith's work.

A selection of Smith's best-known tales includes:

By this time his interest in writing fiction began to lessen and he turned to creating sculptures from soft rock such as soapstone. Smith also made hundreds of fantastic paintings and drawings.














Scholars S.T. Joshi and David E. Schultz are preparing various volumes of Smith's letters to such of his individual correspondents as Donald Wandrei, Robert H. Barlow, and August Derleth.







</doc>
<doc id="6211" url="https://en.wikipedia.org/wiki?curid=6211" title="Context-sensitive grammar">
Context-sensitive grammar

A context-sensitive grammar (CSG) is a formal grammar in which the left-hand sides and right-hand sides of any production rules may be surrounded by a context of terminal and nonterminal symbols. Context-sensitive grammars are more general than context-free grammars, in the sense that there are languages that can be described by CSG but not by context-free grammars. Context-sensitive grammars are less general (in the same sense) than unrestricted grammars. Thus, CSG are positioned between context-free and unrestricted grammars in the Chomsky hierarchy.

A formal language that can be described by a context-sensitive grammar, or, equivalently, by a noncontracting grammar or a linear bounded automaton, is called a context-sensitive language. Some textbooks actually define CSGs as non-contracting, although this is not how Noam Chomsky defined them in 1959. This choice of definition makes no difference in terms of the languages generated (i.e. the two definitions are weakly equivalent), but it does make a difference in terms of what grammars are structurally considered context-sensitive; the latter issue was analyzed by Chomsky in 1963.

Chomsky introduced context-sensitive grammars as a way to describe the syntax of natural language where it is often the case that a word may or may not be appropriate in a certain place depending on the context. Walter Savitch has criticized the terminology "context-sensitive" as misleading and proposed "non-erasing" as better explaining the distinction between a CSG and an unrestricted grammar.

Although it is well known that certain features of languages (e.g. cross-serial dependency) are not context-free, it is an open question how much of CSG's expressive power is needed to capture the context sensitivity found in natural languages. Subsequent research in this area has focused on the more computationally tractable mildly context-sensitive languages. The syntaxes of some visual programming languages can be described by context-sensitive graph grammars.

A formal grammar "G" = ("N", Σ, "P", "S"), where "N" is a set of nonterminal symbols, Σ is a set of terminal symbols, "P" is a set of production rules, and "S" is the start symbol, is context-sensitive if all rules in "P" are of the form
where "A" ∈ "N", α,β ∈ ("N"∪Σ) and γ ∈ ("N"∪Σ).

A string "u" ∈ ("N"∪Σ) directly yields, or directly derives to, a string "v" ∈ ("N"∪Σ), denoted as "u" ⇒ "v", if "u" can be written as "l"α"A"β"r", and "v" can be written as "l"αγβ"r", for some production rule (α"A"β→αγβ) ∈ "P", and some context strings "l", "r" ∈ ("N"∪Σ).
More generally, "u" is said to yield, or derive to, "v", denoted as "u" ⇒ "v", if "u" = "u" ⇒ ... ⇒ "u" = "v" for some "n"≥0 and some strings "u", ..., "u" ("N"∪Σ). That is, the relation (⇒) is the reflexive transitive closure of the relation (⇒).

The language of the grammar "G" is the set of all terminal symbol strings derivable from its start symbol, formally: "L"("G") = { "w" ∈ Σ: "S" ⇒ "w" }.
Derivations that do not end in a string composed of terminal symbols only are possible, but don't contribute to "L"("G").

The only difference between this definition of Chomsky and that of unrestricted grammars is that γ can be empty in the unrestricted case.

Some definitions of a context-sensitive grammar only require that for any production rule of the form u → v, the length of u shall be less than or equal to the length of v. This seemingly weaker requirement is in fact weakly equivalent, see Noncontracting grammar#Transforming into context-sensitive grammar.

In addition, a rule of the form
where λ represents the empty string and "S" does not appear on the right-hand side of any rule is permitted. The addition of the empty string allows the statement that the context sensitive languages are a proper superset of the context-free languages, rather than having to make the weaker statement that all context-free grammars with no →λ productions are also context sensitive grammars.

The name "context-sensitive" is explained by the α and β that form the context of "A" and determine whether "A" can be replaced with γ or not. This is different from a context-free grammar where the context of a nonterminal is not taken into consideration. Indeed, every production of a context-free grammar is of the form "V" → "w" where "V" is a "single" nonterminal symbol, and "w" is a string of terminals and/or nonterminals; "w" can be empty.

If the possibility of adding the empty string to a language is added to the strings recognized by the noncontracting grammars (which can never include the empty string) then the languages in these two definitions are identical.

The left-context- and right-context-sensitive grammars are defined by restricting the rules to just the form α"A" → αγ and to just "A"β → γβ, respectively. The languages generated by these grammars are also the full class of context-sensitive languages. The equivalence was established by Penttonen normal form.

The following context-sensitive grammar, with start symbol "S", generates the canonical non-context-free language { "a""b""c" : "n" ≥ 1 } :

Rules 1 and 2 allow for blowing-up "S" to "a""BC"("BC"); rules 3 to 6 allow for successively exchanging each "CB" to "BC" (four rules are needed for that since a rule "CB" → "BC" wouldn't fit into the scheme α"A"β → αγβ); rules 7–10 allow replacing a non-terminals "B" and "C" with its corresponding terminals "b" and "c" respectively, provided it is in the right place.
A generation chain for "" is:

More complicated grammars formula_1can be used to parse { "a""b""c""d": "n" ≥ 1 }, and other languages with even more letters. Here we show a simpler approach using non-contracting grammars:
Start with a kernel of regular productions generating the sentential forms
formula_2 and then include the non contracting productions
formula_3,
formula_4,
formula_5,
formula_6,
formula_7,
formula_8,
formula_9,
formula_10,
formula_11,
formula_12.

A non contracting grammar (for which there is an equivalent formula_1) for the language formula_14 is defined by
formula_15
and
formula_16,
formula_17, formula_18, formula_19, formula_20, formula_21, formula_22.

With these definitions, a derivation for formula_23 is:
formula_24.

A noncontracting grammar for the language { "a" : i ≥ 1 } is constructed in Example 9.5 (p. 224) of (Hopcroft, Ullman, 1979):


Every context-sensitive grammar which does not generate the empty string can be transformed into a weakly equivalent one in Kuroda normal form. "Weakly equivalent" here means that the two grammars generate the same language. The normal form will not in general be context-sensitive, but will be a noncontracting grammar.

The Kuroda normal form is an actual normal form for non-contracting grammars.

A formal language can be described by a context-sensitive grammar if and only if it is accepted by some linear bounded automaton (LBA). In some textbooks this result is attributed solely to Landweber and Kuroda. Others call it the Myhill–Landweber–Kuroda theorem. (Myhill introduced the concept of deterministic LBA in 1960. Peter S. Landweber published in 1963 that the language accepted by a deterministic LBA is context sensitive. Kuroda introduced the notion of non-deterministic LBA and the equivalence between LBA and CSGs in 1964.)

Context-sensitive languages are closed under complement. This 1988 result is known as the Immerman–Szelepcsényi theorem.
Moreover, they are closed under union, intersection, concatenation, substitution, inverse homomorphism, and Kleene plus.

Every recursively enumerable language "L" can be written as "h"("L") for some context-sensitive language "L" and some string homomorphism "h".

The decision problem that asks whether a certain string "s" belongs to the language of a given context-sensitive grammar "G", is PSPACE-complete. Moreover, there are context-sensitive grammars whose languages are PSPACE-complete. In other words, there is a context-sensitive grammar "G" such that deciding whether a certain string "s" belongs to the language of "G" is PSPACE-complete (so "G" is fixed and only "s" is part of the input of the problem).

The emptiness problem for context-sensitive grammars (given a context-sensitive grammar "G", is "L"("G")=∅ ?) is undecidable.

Savitch has proven the following theoretical result, on which he bases his criticism of CSGs as basis for natural language: for any recursively enumerable set "R", there exists a context-sensitive language/grammar "G" which can be used as a sort of proxy to test membership in "R" in the following way: given a string "s", "s" is in "R" if and only if there exists a positive integer "n" for which "sc" is in G, where "c" is an arbitrary symbol not part of "R".

It has been shown that nearly all natural languages may in general be characterized by context-sensitive grammars, but the whole class of CSG's seems to be much bigger than natural languages. Worse yet, since the aforementioned decision problem for CSG's is PSPACE-complete, that makes them totally unworkable for practical use, as a polynomial-time algorithm for a PSPACE-complete problem would imply P=NP.

It was proven that some natural languages are not context-free, based on identifying so-called cross-serial dependencies and unbounded scrambling phenomena. However this does not necessarily imply that all the class CSG is necessary to capture "context sensitivity" in the colloquial sense of these terms in natural languages. For example, the strictly weaker (than CSG) linear context-free rewriting systems (LCFRS) can account for the phenomenon of cross-serial dependencies; one can write a LCFRS grammar for {"abcd" | "n" ≥ 1} for example.

Ongoing research on computational linguistics has focused on formulating other classes of languages that are "mildly context-sensitive" whose decision problems are feasible, such as tree-adjoining grammars, combinatory categorial grammars, coupled context-free languages, and linear context-free rewriting systems. The languages generated by these formalisms properly lie between the context-free and context-sensitive languages.

More recently, the class PTIME has been identified with range concatenation grammars, which are now considered to be the most expressive of the mild-context sensitive languages.




</doc>
<doc id="6212" url="https://en.wikipedia.org/wiki?curid=6212" title="Context-sensitive language">
Context-sensitive language

In formal language theory, a context-sensitive language is a language that can be defined by a context-sensitive grammar (and equivalently by a noncontracting grammar). Context-sensitive is one of the four types of grammars in the Chomsky hierarchy.

Computationally, a context-sensitive language is equivalent to a linear bounded nondeterministic Turing machine, also called a linear bounded automaton. That is a non-deterministic Turing machine with a tape of only formula_1 cells, where formula_2 is the size of the input and formula_3 is a constant associated with the machine. This means that every formal language that can be decided by such a machine is a context-sensitive language, and every context-sensitive language can be decided by such a machine.

This set of languages is also known as NLINSPACE or NSPACE("O"("n")), because they can be accepted using linear space on a non-deterministic Turing machine. The class LINSPACE (or DSPACE("O"("n"))) is defined the same, except using a deterministic Turing machine. Clearly LINSPACE is a subset of NLINSPACE, but it is not known whether LINSPACE=NLINSPACE.

One of the simplest context-sensitive but not context-free languages is formula_4: the language of all strings consisting of occurrences of the symbol "a", then "b"'s, then "c"'s (abc, , , etc.). A superset of this language, called the Bach language, is defined as the set of all strings where "a", "b" and "c" (or any other set of three symbols) occurs equally often (, , etc.) and is also context-sensitive.

Similarly:
formula_5 is another context-sensitive language; the corresponding context-sensitive grammar can be easily projected starting with two context-free grammars generating sentential forms in the formats
formula_6
and
formula_7
and then supplementing them with a permutation production like 
formula_8, a new starting symbol and standard syntactic sugar.
formula_9 is another context-sensitive language (the "3" in the name of this language is intended to mean a ternary alphabet); that is, the "product" operation defines a context-sensitive language (but the "sum" defines only a context-free language as the grammar formula_10 and formula_11 shows). Because of the commutative property of the product, the most intuitive grammar for formula_12 is ambiguous. This problem can be avoided considering a somehow more restrictive definition of the language, e.g. formula_13. This can be specialized to 
formula_14 and, from this, to formula_15, formula_16, etc.
formula_17 is a context-sensitive language. The corresponding context-sensitive grammar can be obtained as a generalization of the context-sensitive grammars for formula_18, formula_19, etc.
formula_20 is a context-sensitive language.
formula_21 is a context-sensitive language (the "2" in the name of this language is intended to mean a binary alphabet). This was proved by Hartmanis using pumping lemmas for regular and context-free languages over a binary alphabet and, after that, sketching a linear bounded multitape automaton accepting formula_22.
formula_23 is a context-sensitive language (the "1" in the name of this language is intended to mean an unary alphabet). This was credited by A. Salomaa to Matti Soittola by means of a linear bounded automaton over an unary alphabet (pages 213-214, exercise 6.8) and also to Marti Penttonen by means of a context-sensitive grammar also over an unary alphabet (See: Formal Languages by A. Salomaa, page 14, Example 2.5).
An example of recursive language that is not context-sensitive is any recursive language whose decision is an EXPSPACE-hard problem, say, the set of pairs of equivalent regular expressions with exponentiation.





</doc>
<doc id="6216" url="https://en.wikipedia.org/wiki?curid=6216" title="Chinese room">
Chinese room

The Chinese room argument holds that a digital computer executing a program cannot be shown to have a "mind", "understanding" or "consciousness", regardless of how intelligently or human-like the program may make the computer behave. The argument was first presented by philosopher John Searle in his paper, "Minds, Brains, and Programs", published in "Behavioral and Brain Sciences" in 1980. It has been widely discussed in the years since. The centerpiece of the argument is a thought experiment known as the "Chinese room".

The argument is directed against the philosophical positions of functionalism and computationalism, which hold that the mind may be viewed as an information-processing system operating on formal symbols, and that simulation of a given mental state is sufficient for its presence. Specifically, the argument is intended to refute a position Searle calls strong AI: "The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds."

Although it was originally presented in reaction to the statements of artificial intelligence (AI) researchers, it is not an argument against the goals of mainstream AI research, because it does not limit the amount of intelligence a machine can display. The argument applies only to digital computers running programs and does not apply to machines in general.

Searle's thought experiment begins with this hypothetical premise: suppose that artificial intelligence research has succeeded in constructing a computer that behaves as if it understands Chinese. It takes Chinese characters as input and, by following the instructions of a computer program, produces other Chinese characters, which it presents as output. Suppose, says Searle, that this computer performs its task so convincingly that it comfortably passes the Turing test: it convinces a human Chinese speaker that the program is itself a live Chinese speaker. To all of the questions that the person asks, it makes appropriate responses, such that any Chinese speaker would be convinced that they are talking to another Chinese-speaking human being.

The question Searle wants to answer is this: does the machine "literally" "understand" Chinese? Or is it merely "simulating" the ability to understand Chinese? Searle calls the first position "strong AI" and the latter "weak AI".

Searle then supposes that he is in a closed room and is receiving questions in Chinese. While he cannot understand Chinese, he has a large collection of Chinese phrasebooks in the room, with questions and matching answers. When he receives a question, he need only to look up the same sequence of characters in one of the books and respond with the indicated answer, even though he does not understand the question nor the answer. If the computer had passed the Turing test this way, it follows, says Searle, that he would do so as well, simply by running the program manually.

Searle asserts that there is no essential difference between the roles of the computer and himself in the experiment. Each simply follows a program, step-by-step, producing a behavior which is then interpreted by the user as demonstrating intelligent conversation. However, Searle himself would not be able to understand the conversation. ("I don't speak a word of Chinese," he points out.) Therefore, he argues, it follows that the computer would not be able to understand the conversation either.

Searle argues that, without "understanding" (or "intentionality"), we cannot describe what the machine is doing as "thinking" and, since it does not think, it does not have a "mind" in anything like the normal sense of the word. Therefore, he concludes that the "strong AI" hypothesis is false.

Gottfried Leibniz made a similar argument in 1714 against mechanism (the position that the mind is a machine and nothing more). Leibniz used the thought experiment of expanding the brain until it was the size of a mill. Leibniz found it difficult to imagine that a "mind" capable of "perception" could be constructed using only mechanical processes. In the 1961 short story "The Game" by Anatoly Dneprov, a stadium of people act as switches and memory cells implementing a program to translate a sentence of Portuguese, a language that none of them knows. In 1974, Lawrence Davis imagined duplicating the brain using telephone lines and offices staffed by people, and in 1978 Ned Block envisioned the entire population of China involved in such a brain simulation. This thought experiment is called the China brain, also the "Chinese Nation" or the "Chinese Gym".

The Chinese Room Argument was introduced in Searle's 1980 paper "Minds, Brains, and Programs", published in "Behavioral and Brain Sciences". It eventually became the journal's "most influential target article", generating an enormous number of commentaries and responses in the ensuing decades, and Searle has continued to defend and refine the argument in many papers, popular articles and books. David Cole writes that "the Chinese Room argument has probably been the most widely discussed philosophical argument in cognitive science to appear in the past 25 years".

Most of the discussion consists of attempts to refute it. "The overwhelming majority", notes "BBS" editor Stevan Harnad, "still think that the Chinese Room Argument is dead wrong". The sheer volume of the literature that has grown up around it inspired Pat Hayes to comment that the field of cognitive science ought to be redefined as "the ongoing research program of showing Searle's Chinese Room Argument to be false".

Searle's argument has become "something of a classic in cognitive science", according to Harnad. Varol Akman agrees, and has described the original paper as "an exemplar of philosophical clarity and purity".

Although the Chinese Room argument was originally presented in reaction to the statements of artificial intelligence researchers, philosophers have come to consider it as an important part of the philosophy of mind. It is a challenge to functionalism and the computational theory of mind, and is related to such questions as the mind–body problem, the problem of other minds, the symbol-grounding problem, and the hard problem of consciousness.

Searle identified a philosophical position he calls "strong AI":

The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds.

The definition depends on the distinction between "simulating" a mind and "actually having" a mind. Searle writes that "according to Strong AI, the correct simulation really is a mind. According to Weak AI, the correct simulation is a model of the mind."

The claim is implicit in some of the statements of early AI researchers and analysts. For example, in 1955, AI founder Herbert A. Simon declared that "there are now in the world machines that think, that learn and create"(Simon, together with Allen Newell and Cliff Shaw, had just completed the first "AI" program, the Logic Theorist), and claimed that they had "solved the venerable mind–body problem, explaining how a system composed of matter can have the properties of mind." John Haugeland wrote that "AI wants only the genuine article: "machines with minds", in the full and literal sense. This is not science fiction, but real science, based on a theoretical conception as deep as it is daring: namely, we are, at root, "computers ourselves"."

Searle also ascribes the following claims to advocates of strong AI:

In more recent presentations of the Chinese room argument, Searle has identified "strong AI" as "computer functionalism" (a term he attributes to Daniel Dennett). Functionalism is a position in modern philosophy of mind that holds that we can define mental phenomena (such as beliefs, desires, and perceptions) by describing their functions in relation to each other and to the outside world. Because a computer program can accurately represent functional relationships as relationships between symbols, a computer can have mental phenomena if it runs the right program, according to functionalism.

Stevan Harnad argues that Searle's depictions of strong AI can be reformulated as "recognizable tenets of "computationalism", a position (unlike "strong AI") that is actually held by many thinkers, and hence one worth refuting." Computationalism is the position in the philosophy of mind which argues that the mind can be accurately described as an information-processing system.

Each of the following, according to Harnad, is a "tenet" of computationalism:

Searle holds a philosophical position he calls "biological naturalism": that consciousness and understanding require specific biological machinery that are found in brains. He writes "brains cause minds" and that "actual human mental phenomena [are] dependent on actual physical–chemical properties of actual human brains". Searle argues that this machinery (known to neuroscience as the "neural correlates of consciousness") must have some causal powers that permit the human experience of consciousness. Searle's belief in the existence of these powers has been criticized.

Searle does not disagree with the notion that machines can have consciousness and understanding, because, as he writes, "we are precisely such machines". Searle holds that the brain is, in fact, a machine, but that the brain gives rise to consciousness and understanding using machinery that is non-computational. If neuroscience is able to isolate the mechanical process that gives rise to consciousness, then Searle grants that it may be possible to create machines that have consciousness and understanding. However, without the specific machinery required, Searle does not believe that consciousness can occur.

Biological naturalism implies that one cannot determine if the experience of consciousness is occurring merely by examining how a system functions, because the specific machinery of the brain is essential. Thus, biological naturalism is directly opposed to both behaviorism and functionalism (including "computer functionalism" or "strong AI"). Biological naturalism is similar to identity theory (the position that mental states are "identical to" or "composed of" neurological events); however, Searle has specific technical objections to identity theory. Searle's biological naturalism and strong AI are both opposed to Cartesian dualism, the classical idea that the brain and mind are made of different "substances". Indeed, Searle accuses strong AI of dualism, writing that "strong AI only makes sense given the dualistic assumption that, where the mind is concerned, the brain doesn't matter."

Searle's original presentation emphasized "understanding"—that is, mental states with what philosophers call "intentionality"—and did not directly address other closely related ideas such as "consciousness". However, in more recent presentations Searle has included consciousness as the real target of the argument.

David Chalmers writes "it is fairly clear that consciousness is at the root of the matter" of the Chinese room.

Colin McGinn argues that the Chinese room provides strong evidence that the hard problem of consciousness is fundamentally insoluble. The argument, to be clear, is not about whether a machine can be conscious, but about whether it (or anything else for that matter) can be shown to be conscious. It is plain that any other method of probing the occupant of a Chinese room has the same difficulties in principle as exchanging questions and answers in Chinese. It is simply not possible to divine whether a conscious agency or some clever simulation inhabits the room.

Searle argues that this is only true for an observer "outside" of the room. The whole point of the thought experiment is to put someone "inside" the room, where they can directly observe the operations of consciousness. Searle claims that from his vantage point within the room there is nothing he can see that could imaginably give rise to consciousness, other than himself, and clearly he does not have a mind that can speak Chinese.

Patrick Hew used the Chinese Room argument to deduce requirements from military command and control systems if they are to preserve a commander's moral agency. He drew an analogy between a commander in their command center and the person in the Chinese Room, and analyzed it under a reading of Aristotle’s notions of "compulsory" and "ignorance". Information could be "down converted" from meaning to symbols, and manipulated symbolically, but moral agency could be undermined if there was inadequate 'up conversion' into meaning. Hew cited examples from the USS "Vincennes" incident.

The Chinese room argument is primarily an argument in the philosophy of mind, and both major computer scientists and artificial intelligence researchers consider it irrelevant to their fields. However, several concepts developed by computer scientists are essential to understanding the argument, including symbol processing, Turing machines, Turing completeness, and the Turing test.

Searle's arguments are not usually considered an issue for AI research. Stuart Russell and Peter Norvig observe that most AI researchers "don't care about the strong AI hypothesis—as long as the program works, they don't care whether you call it a simulation of intelligence or real intelligence." The primary mission of artificial intelligence research is only to create useful systems that "act" intelligently, and it does not matter if the intelligence is "merely" a simulation.

Searle does not disagree that AI research can create machines that are capable of highly intelligent behavior. The Chinese room argument leaves open the possibility that a digital machine could be built that "acts" more intelligently than a person, but does not have a mind or intentionality in the same way that brains do.

Searle's "strong AI" should not be confused with "strong AI" as defined by Ray Kurzweil and other futurists, who use the term to describe machine intelligence that rivals or exceeds human intelligence. Kurzweil is concerned primarily with the "amount" of intelligence displayed by the machine, whereas Searle's argument sets no limit on this. Searle argues that even a super-intelligent machine would not necessarily have a mind and consciousness.

The Chinese room implements a version of the Turing test. Alan Turing introduced the test in 1950 to help answer the question "can machines think?" In the standard version, a human judge engages in a natural language conversation with a human and a machine designed to generate performance indistinguishable from that of a human being. All participants are separated from one another. If the judge cannot reliably tell the machine from the human, the machine is said to have passed the test.

Turing then considered each possible objection to the proposal "machines can think", and found that there are simple, obvious answers if the question is de-mystified in this way. He did not, however, intend for the test to measure for the presence of "consciousness" or "understanding". He did not believe this was relevant to the issues that he was addressing. He wrote:
To Searle, as a philosopher investigating in the nature of mind and consciousness, these are the relevant mysteries. The Chinese room is designed to show that the Turing test is insufficient to detect the presence of consciousness, even if the room can behave or function as a conscious mind would.

The Chinese room (and all modern computers) manipulate physical objects in order to carry out calculations and do simulations. AI researchers Allen Newell and Herbert A. Simon called this kind of machine a physical symbol system. It is also equivalent to the formal systems used in the field of mathematical logic.

Searle emphasizes the fact that this kind of symbol manipulation is syntactic (borrowing a term from the study of grammar). The computer manipulates the symbols using a form of syntax rules, without any knowledge of the symbol's semantics (that is, their meaning).

Newell and Simon had conjectured that a physical symbol system (such as a digital computer) had all the necessary machinery for "general intelligent action", or, as it is known today, artificial general intelligence. They framed this as a philosophical position, the physical symbol system hypothesis: "A physical symbol system has the necessary and sufficient means for general intelligent action." The Chinese room argument does not refute this, because it is framed in terms of "intelligent action", i.e. the external behavior of the machine, rather than the presence or absence of understanding, consciousness and mind.

The Chinese room has a design analogous to that of a modern computer. It has a Von Neumann architecture, which consists of a program (the book of instructions), some memory (the papers and file cabinets), a CPU which follows the instructions (the man), and a means to write symbols in memory (the pencil and eraser). A machine with this design is known in theoretical computer science as "Turing complete", because it has the necessary machinery to carry out any computation that a Turing machine can do, and therefore it is capable of doing a step-by-step simulation of any other digital machine, given enough memory and time. Alan Turing writes, "all digital computers are in a sense equivalent." The widely accepted Church–Turing thesis holds that any function computable by an effective procedure is computable by a Turing machine.

The Turing completeness of the Chinese room implies that it can do whatever any other digital computer can do (albeit much, much more slowly). Thus, if the Chinese room does not or can not contain a Chinese-speaking mind, then no other digital computer can contain a mind. Some replies to Searle begin by arguing that the room, as described, cannot have a Chinese-speaking mind. Arguments of this form, according to Stevan Harnad, are "no refutation (but rather an affirmation)" of the Chinese room argument, because these arguments actually imply that "no" digital computers can have a mind.

There are some critics, such as Hanoch Ben-Yami, who argue that the Chinese room cannot simulate all the abilities of a digital computer, such as being able to determine the current time.

Searle has produced a more formal version of the argument of which the Chinese Room forms a part. He presented the first version in 1984. The version given below is from 1990. The only part of the argument which should be controversial is A3 and it is this point which the Chinese room thought experiment is intended to prove.

He begins with three axioms:

Searle posits that these lead directly to this conclusion:

This much of the argument is intended to show that artificial intelligence can never produce a machine with a mind by writing programs that manipulate symbols. The remainder of the argument addresses a different issue. Is the human brain running a program? In other words, is the computational theory of mind correct? He begins with an axiom that is intended to express the basic modern scientific consensus about brains and minds:

Searle claims that we can derive "immediately" and "trivially" that:

And from this he derives the further conclusions:

Replies to Searle's argument may be classified according to what they claim to show:

Some of the arguments (robot and brain simulation, for example) fall into multiple categories.

These replies attempt to answer the question: since the man in the room doesn't speak Chinese, "where" is the "mind" that does? These replies address the key ontological issues of mind vs. body and simulation vs. reality. All of the replies that identify the mind in the room are versions of "the system reply".

Searle notes that (in this simple version of the reply) the "system" is nothing more than a collection of ordinary physical objects; it grants the power of understanding and consciousness to "the conjunction of that person and bits of paper" without making any effort to explain how this pile of objects has become a conscious, thinking being. Searle argues that no reasonable person should be satisfied with the reply, unless they are "under the grip of an ideology;" In order for this reply to be remotely plausible, one must take it for granted that consciousness can be the product of an information processing "system", and does not require anything resembling the actual biology of the brain.

Searle then responds by simplifying this list of physical objects: he asks what happens if the man memorizes the rules and keeps track of everything in his head? Then the whole system consists of just one object: the man himself. Searle argues that if the man doesn't understand Chinese then the system doesn't understand Chinese either because now "the system" and "the man" both describe exactly the same object.

Critics of Searle's response argue that the program has allowed the man to have two minds in one head. If we assume a "mind" is a form of information processing, then the theory of computation can account for two computations occurring at once, namely (1) the computation for universal programmability (which is the function instantiated by the person and note-taking materials "independently" from any particular program contents) and (2) the computation of the Turing machine that is described by the program (which is instantiated by everything "including" the specific program). The theory of computation thus formally explains the open possibility that the second computation in the Chinese Room could entail a human-equivalent semantic understanding of the Chinese inputs. The focus belongs on the program's Turing machine rather than on the person's. However, from Searle's perspective, this argument is circular. The question at issue is whether consciousness is a form of information processing, and this reply requires that we make that assumption.

More sophisticated versions of the systems reply try to identify more precisely what "the system" is and they differ in exactly how they describe it. According to these replies, the "mind that speaks Chinese" could be such things as: the "software", a "program", a "running program", a simulation of the "neural correlates of consciousness", the "functional system", a "simulated mind", an "emergent property", or "a virtual mind" (Marvin Minsky's version of the systems reply, described below).

Searle responds that such a mind is, at best, a simulation, and writes: "No one supposes that computer simulations of a five-alarm fire will burn the neighborhood down or that a computer simulation of a rainstorm will leave us all drenched." Nicholas Fearn responds that, for some things, simulation is as good as the real thing. "When we call up the pocket calculator function on a desktop computer, the image of a pocket calculator appears on the screen. We don't complain that 'it isn't "really" a calculator', because the physical attributes of the device do not matter." The question is, is the human mind like the pocket calculator, essentially composed of information? Or is the mind like the rainstorm, something other than a computer, and not realizable in full by a computer simulation? (The issue of simulation is also discussed in the article synthetic intelligence.)

These replies provide an explanation of exactly who it is that understands Chinese. If there is something "besides" the man in the room that can understand Chinese, Searle can't argue that (1) the man doesn't understand Chinese, therefore (2) nothing in the room understands Chinese. This, according to those who make this reply, shows that Searle's argument fails to prove that "strong AI" is false.

However, the thought experiment is not intended to be a "reductio ad absurdum," but rather an example that requires explanation. Searle is not asserting that the situation is impossible, but rather that it is difficult or impossible to explain how this system can have subjective conscious experience. The system reply succeeds in showing that it is "not impossible" but fails to show how the system would have consciousness; the replies, by themselves, provide no evidence that the system (or the virtual mind) understands Chinese, other than the hypothetical premise that it passes the Turing Test. As Searle writes "the systems reply simply begs the question by insisting that the system must understand Chinese."

As far as the person in the room is concerned, the symbols are just meaningless "squiggles." But if the Chinese room really "understands" what it is saying, then the symbols must get their meaning from somewhere. These arguments attempt to connect the symbols to the things they symbolize. These replies address Searle's concerns about intentionality, symbol grounding and syntax vs. semantics.

To each of these suggestions, Searle's response is the same: no matter how much knowledge is written into the program and no matter how the program is connected to the world, he is still in the room manipulating symbols according to rules. His actions are syntactic and this can never explain to him what the symbols stand for. Searle writes "syntax is insufficient for semantics."

However, for those who accept that Searle's actions simulate a mind, separate from his own, the important question is not what the symbols mean "to Searle", what is important is what they mean "to the virtual mind." While Searle is trapped in the room, the virtual mind is not: it is connected to the outside world through the Chinese speakers it speaks to, through the programmers who gave it world knowledge, and through the cameras and other sensors that roboticists can supply.

These arguments are all versions of the systems reply that identify a particular "kind" of system as being important; they identify some special technology that would create conscious understanding in a machine. (Note that the "robot" and "commonsense knowledge" replies above also specify a certain kind of system as being important.)

These arguments (and the robot or commonsense knowledge replies) identify some special technology that would help create conscious understanding in a machine. They may be interpreted in two ways: either they claim (1) this technology is required for consciousness, the Chinese room does not or cannot implement this technology, and therefore the Chinese room cannot pass the Turing test or (even if it did) it would not have conscious understanding. Or they may be claiming that (2) it is easier to see that the Chinese room has a mind if we visualize this technology as being used to create it.

In the first case, where features like a robot body or a connectionist architecture are required, Searle claims that strong AI (as he understands it) has been abandoned. The Chinese room has all the elements of a Turing complete machine, and thus is capable of simulating any digital computation whatsoever. If Searle's room can't pass the Turing test then there is no other digital technology that could pass the Turing test. If Searle's room "could" pass the Turing test, but still does not have a mind, then the Turing test is not sufficient to determine if the room has a "mind". Either way, it denies one or the other of the positions Searle thinks of as "strong AI", proving his argument.

The brain arguments in particular deny strong AI if they assume that there is no simpler way to describe the mind than to create a program that is just as mysterious as the brain was. He writes "I thought the whole idea of strong AI was that we don't need to know how the brain works to know how the mind works." If computation does not provide an "explanation" of the human mind, then strong AI has failed, according to Searle.

Other critics hold that the room as Searle described it does, in fact, have a mind, however they argue that it is difficult to see—Searle's description is correct, but "misleading." By redesigning the room more realistically they hope to make this more obvious. In this case, these arguments are being used as appeals to intuition (see next section).

In fact, the room can just as easily be redesigned to "weaken" our intuitions. Ned Block's Blockhead argument suggests that the program could, in theory, be rewritten into a simple lookup table of rules of the form "if the user writes "S", reply with "P" and goto X". At least in principle, any program can be rewritten (or "refactored") into this form, even a brain simulation. In the blockhead scenario, the entire mental state is hidden in the letter X, which represents a memory address—a number associated with the next rule. It is hard to visualize that an instant of one's conscious experience can be captured in a single large number, yet this is exactly what "strong AI" claims. On the other hand, such a lookup table would be ridiculously large (to the point of being physically impossible), and the states could therefore be "extremely" specific.

Searle argues that however the program is written or however the machine is connected to the world, the mind is being "simulated" by a simple step-by-step digital machine (or machines). These machines are always just like the man in the room: they understand nothing and don't speak Chinese. They are merely manipulating symbols without knowing what they mean. Searle writes: "I can have any formal program you like, but I still understand nothing."

The following arguments (and the intuitive interpretations of the arguments above) do not directly explain how a Chinese speaking mind could exist in Searle's room, or how the symbols he manipulates could become meaningful. However, by raising doubts about Searle's intuitions they support other positions, such as the system and robot replies. These arguments, if accepted, prevent Searle from claiming that his conclusion is obvious by undermining the intuitions that his certainty requires.

Several critics believe that Searle's argument relies entirely on intuitions. Ned Block writes "Searle's argument depends for its force on intuitions that certain entities do not think." Daniel Dennett describes the Chinese room argument as a misleading "intuition pump" and writes "Searle's thought experiment depends, illicitly, on your imagining too simple a case, an irrelevant case, and drawing the 'obvious' conclusion from it."

Some of the arguments above also function as appeals to intuition, especially those that are intended to make it seem more plausible that the Chinese room contains a mind, which can include the robot, commonsense knowledge, brain simulation and connectionist replies. Several of the replies above also address the specific issue of complexity. The connectionist reply emphasizes that a working artificial intelligence system would have to be as complex and as interconnected as the human brain. The commonsense knowledge reply emphasizes that any program that passed a Turing test would have to be "an extraordinarily supple, sophisticated, and multilayered system, brimming with 'world knowledge' and meta-knowledge and meta-meta-knowledge", as Daniel Dennett explains.

An especially vivid version of the speed and complexity reply is from Paul and Patricia Churchland. They propose this analogous thought experiment:

Stevan Harnad is critical of speed and complexity replies when they stray beyond addressing our intuitions. He writes "Some have made a cult of speed and timing, holding that, when accelerated to the right speed, the computational may make a phase transition into the mental. It should be clear that is not a counterargument but merely an "ad hoc" speculation (as is the view that it is all just a matter of ratcheting up to the right degree of 'complexity.')"

Searle argues that his critics are also relying on intuitions, however his opponents' intuitions have no empirical basis. He writes that, in order to consider the "system reply" as remotely plausible, a person must be "under the grip of an ideology". The system reply only makes sense (to Searle) if one assumes that any "system" can have consciousness, just by virtue of being a system with the right behavior and functional parts. This assumption, he argues, is not tenable given our experience of consciousness.

Several replies argue that Searle's argument is irrelevant because his assumptions about the mind and consciousness are faulty. Searle believes that human beings directly experience their consciousness, intentionality and the nature of the mind every day, and that this experience of consciousness is not open to question. He writes that we must "presuppose the reality and knowability of the mental." These replies question whether Searle is justified in using his own experience of consciousness to determine that it is more than mechanical symbol processing. In particular, the other minds reply argues that we cannot use our experience of consciousness to answer questions about other minds (even the mind of a computer), and the epiphenomena reply argues that Searle's consciousness does not "exist" in the sense that Searle thinks it does.


Nils Nilsson writes "If a program behaves "as if" it were multiplying, most of us would say that it is, in fact, multiplying. For all I know, Searle may only be behaving "as if" he were thinking deeply about these matters. But, even though I disagree with him, his simulation is pretty good, so I'm willing to credit him with real thought."

Alan Turing anticipated Searle's line of argument (which he called "The Argument from Consciousness") in 1950 and makes the other minds reply. He noted that people never consider the problem of other minds when dealing with each other. He writes that "instead of arguing continually over this point it is usual to have the polite convention that everyone thinks." The Turing test simply extends this "polite convention" to machines. He doesn't intend to solve the problem of other minds (for machines or people) and he doesn't think we need to.


Stuart Russell and Peter Norvig argue that, if we accept Searle's description of intentionality, consciousness and the mind, we are forced to accept that consciousness is epiphenomenal: that it "casts no shadow", that it is undetectable in the outside world. They argue that Searle must be mistaken about the "knowability of the mental", and in his belief that there are "causal properties" in our neurons that give rise to the mind. They point out that, by Searle's own description, these causal properties can't be detected by anyone outside the mind, otherwise the Chinese Room couldn't pass the Turing test—the people outside would be able to tell there wasn't a Chinese speaker in the room by detecting their causal properties. Since they can't detect causal properties, they can't detect the existence of the mental. In short, Searle's "causal properties" and consciousness itself is undetectable, and anything that cannot be detected either does not exist or does not matter.

Daniel Dennett provides this extension to the "epiphenomena" argument.

Searle disagrees with this analysis and argues that "the study of the mind starts with such facts as that humans have beliefs, while thermostats, telephones, and adding machines don't ... what we wanted to know is what distinguishes the mind from thermostats and livers." He takes it as obvious that we can detect the presence of consciousness and dismisses these replies as being off the point.


The Chinese room argument is a central concept in Peter Watts's novels "Blindsight" and (to a lesser extent) "Echopraxia". It is also a central theme in the video game "Virtue's Last Reward", and ties into the game's narrative. In Season 4 of the American crime drama "Numb3rs" there is a brief reference to the Chinese room.

The Chinese Room is also the name of a British independent video game development studio best known for working on experimental first-person games, such as "Everybody's Gone to the Rapture", or "Dear Esther".

In the 2016 video game The Turing Test, the Chinese Room thought experiment is explained to the player by an AI.






</doc>
<doc id="6217" url="https://en.wikipedia.org/wiki?curid=6217" title="Charon (disambiguation)">
Charon (disambiguation)

Charon, in Greek mythology, is the ferryman who carried the souls of the dead to the underworld.

Charon may also refer to:








</doc>
<doc id="6220" url="https://en.wikipedia.org/wiki?curid=6220" title="Circle">
Circle

A circle is a shape consisting of all points in a plane that are a given distance from a given point, the centre; equivalently it is the curve traced out by a point that moves in a plane so that its distance from a given point is constant. The distance between any point of the circle and the centre is called the radius. This article is about circles in Euclidean geometry, and, in particular, the Euclidean plane, except where otherwise noted.

Specifically, a circle is a simple closed curve that divides the plane into two regions: an interior and an exterior. In everyday use, the term "circle" may be used interchangeably to refer to either the boundary of the figure, or to the whole figure including its interior; in strict technical usage, the circle is only the boundary and the whole figure is called a disc.

A circle may also be defined as a special kind of ellipse in which the two foci are coincident and the eccentricity is 0, or the two-dimensional shape enclosing the most area per unit perimeter squared, using calculus of variations.
In the field of topology, a circle isn't limited to the geometric concept, but to all of its homeomorphisms. Two topological circles are equivalent if one can be transformed into the other via a deformation of R upon itself (known as an ambient isotopy).

All of the specified regions may be considered as "open", that is, not containing their boundaries, or as "closed", including their respective boundaries.

The word "circle" derives from the Greek κίρκος/κύκλος ("kirkos/kuklos"), itself a metathesis of the Homeric Greek κρίκος ("krikos"), meaning "hoop" or "ring". The origins of the words "circus" and "circuit" are closely related.
The circle has been known since before the beginning of recorded history. Natural circles would have been observed, such as the Moon, Sun, and a short plant stalk blowing in the wind on sand, which forms a circle shape in the sand. The circle is the basis for the wheel, which, with related inventions such as gears, makes much of modern machinery possible. In mathematics, the study of the circle has helped inspire the development of geometry, astronomy and calculus.

Early science, particularly geometry and astrology and astronomy, was connected to the divine for most medieval scholars, and many believed that there was something intrinsically "divine" or "perfect" that could be found in circles.

Some highlights in the history of the circle are:


The ratio of a circle's circumference to its diameter is (pi), an irrational constant approximately equal to 3.141592654. Thus the circumference "C" is related to the radius "r" and diameter "d" by:

As proved by Archimedes, in his Measurement of a Circle, the area enclosed by a circle is equal to that of a triangle whose base has the length of the circle's circumference and whose height equals the circle's radius, which comes to multiplied by the radius squared:

Equivalently, denoting diameter by "d",

that is, approximately 79% of the circumscribing square (whose side is of length "d").

The circle is the plane curve enclosing the maximum area for a given arc length. This relates the circle to a problem in the calculus of variations, namely the isoperimetric inequality.

Equation of a circle<br>
In an "x"–"y" Cartesian coordinate system, the circle with centre coordinates ("a", "b") and radius "r" is the set of all points ("x", "y") such that

This equation, known as the Equation of the Circle, follows from the Pythagorean theorem applied to any point on the circle: as shown in the adjacent diagram, the radius is the hypotenuse of a right-angled triangle whose other sides are of length |"x" − "a"| and |"y" − "b"|. If the circle is centred at the origin (0, 0), then the equation simplifies to

Parametric form <br>
The equation can be written in parametric form using the trigonometric functions sine and cosine as
where "t" is a parametric variable in the range 0 to 2, interpreted geometrically as the angle that the ray from ("a", "b") to ("x", "y") makes with the positive "x"-axis.

An alternative parametrisation of the circle is:

In this parameterisation, the ratio of "t" to "r" can be interpreted geometrically as the stereographic projection of the line passing through the centre parallel to the "x"-axis (see Tangent half-angle substitution). However, this parameterisation works only if "t" is made to range not only through all reals but also to a point at infinity; otherwise, the leftmost point of the circle would be omitted.

3-point-form <br>
The equation of the circle determined by three points formula_10 not on a line is obtained by a conversion of the "3-point-form of a circle's equation"

Homogeneous form<br>
In homogeneous coordinates, each conic section with the equation of a circle has the form

It can be proven that a conic section is a circle exactly when it contains (when extended to the complex projective plane) the points "I"(1: "i": 0) and "J"(1: −"i": 0). These points are called the circular points at infinity.

In polar coordinates, the equation of a circle is:

where "a" is the radius of the circle, formula_14 is the polar coordinate of a generic point on the circle, and formula_15 is the polar coordinate of the centre of the circle (i.e., "r" is the distance from the origin to the centre of the circle, and "φ" is the anticlockwise angle from the positive "x"-axis to the line connecting the origin to the centre of the circle). For a circle centred on the origin, i.e. "r" = 0, this reduces to simply . When , or when the origin lies on the circle, the equation becomes

In the general case, the equation can be solved for "r", giving
Note that without the ± sign, the equation would in some cases describe only half a circle.

In the complex plane, a circle with a centre at "c" and radius "r" has the equation:

In parametric form, this can be written:

The slightly generalised equation

for real "p", "q" and complex "g" is sometimes called a generalised circle. This becomes the above equation for a circle with formula_21, since formula_22. Not all generalised circles are actually circles: a generalised circle is either a (true) circle or a line.

The tangent line through a point "P" on the circle is perpendicular to the diameter passing through "P". If and the circle has centre ("a", "b") and radius "r", then the tangent line is perpendicular to the line from ("a", "b") to ("x", "y"), so it has the form . Evaluating at ("x", "y") determines the value of "c" and the result is that the equation of the tangent is
or

If then the slope of this line is

This can also be found using implicit differentiation.

When the centre of the circle is at the origin then the equation of the tangent line becomes
and its slope is





An inscribed angle (examples are the blue and green angles in the figure) is exactly half the corresponding central angle (red). Hence, all inscribed angles that subtend the same arc (pink) are equal. Angles inscribed on the arc (brown) are supplementary. In particular, every inscribed angle that subtends a diameter is a right angle (since the central angle is 180 degrees).


Another proof of this result, which relies only on two chord properties given above, is as follows. Given a chord of length "y" and with sagitta of length "x", since the sagitta intersects the midpoint of the chord, we know it is part of a diameter of the circle. Since the diameter is twice the radius, the "missing" part of the diameter is () in length. Using the fact that one part of one chord times the other part is equal to the same product taken along a chord intersecting the first chord, we find that (. Solving for "r", we find the required result.

There are many compass-and-straightedge constructions resulting in circles.

The simplest and most basic is the construction given the centre of the circle and a point on the circle. Place the fixed leg of the compass on the centre point, the movable leg on the point on the circle and rotate the compass.



Apollonius of Perga showed that a circle may also be defined as the set of points in a plane having a constant "ratio" (other than 1) of distances to two fixed foci, "A" and "B". (The set of points where the distances are equal is the perpendicular bisector of segment "AB", a line.) That circle is sometimes said to be drawn "about" two points.

The proof is in two parts. First, one must prove that, given two foci "A" and "B" and a ratio of distances, any point "P" satisfying the ratio of distances must fall on a particular circle. Let "C" be another point, also satisfying the ratio and lying on segment "AB". By the angle bisector theorem the line segment "PC" will bisect the interior angle "APB", since the segments are similar:

Analogously, a line segment "PD" through some point "D" on "AB" extended bisects the corresponding exterior angle "BPQ" where "Q" is on "AP" extended. Since the interior and exterior angles sum to 180 degrees, the angle "CPD" is exactly 90 degrees, i.e., a right angle. The set of points "P" such that angle "CPD" is a right angle forms a circle, of which "CD" is a diameter.

Second, see for a proof that every point on the indicated circle satisfies the given ratio.

A closely related property of circles involves the geometry of the cross-ratio of points in the complex plane. If "A", "B", and "C" are as above, then the circle of Apollonius for these three points is the collection of points "P" for which the absolute value of the cross-ratio is equal to one:

Stated another way, "P" is a point on the circle of Apollonius if and only if the cross-ratio ["A","B";"C","P"] is on the unit circle in the complex plane.

If "C" is the midpoint of the segment "AB", then the collection of points "P" satisfying the Apollonius condition

is not a circle, but rather a line.

Thus, if "A", "B", and "C" are given distinct points in the plane, then the locus of points "P" satisfying the above equation is called a "generalised circle." It may either be a true circle or a line. In this sense a line is a generalised circle of infinite radius.

In every triangle a unique circle, called the incircle, can be inscribed such that it is tangent to each of the three sides of the triangle.

About every triangle a unique circle, called the circumcircle, can be circumscribed such that it goes through each of the triangle's three vertices.

A tangential polygon, such as a tangential quadrilateral, is any convex polygon within which a circle can be inscribed that is tangent to each side of the polygon. Every regular polygon and every triangle is a tangential polygon.

A cyclic polygon is any convex polygon about which a circle can be circumscribed, passing through each vertex. A well-studied example is the cyclic quadrilateral. Every regular polygon and every triangle is a cyclic polygon. A polygon that is both cyclic and tangential is called a bicentric polygon.

A hypocycloid is a curve that is inscribed in a given circle by tracing a fixed point on a smaller circle that rolls within and tangent to the given circle.

The circle can be viewed as a limiting case of each of various other figures:

Defining a circle as the set of points with a fixed distance from a point, different shapes can be considered circles under different definitions of distance. In "p"-norm, distance is determined by
In Euclidean geometry, "p" = 2, giving the familiar

In taxicab geometry, "p" = 1. Taxicab circles are squares with sides oriented at a 45° angle to the coordinate axes. While each side would have length formula_38 using a Euclidean metric, where "r" is the circle's radius, its length in taxicab geometry is 2"r". Thus, a circle's circumference is 8"r". Thus, the value of a geometric analog to formula_39 is 4 in this geometry. The formula for the unit circle in taxicab geometry is formula_40 in Cartesian coordinates and

in polar coordinates.

A circle of radius 1 (using this distance) is the von Neumann neighborhood of its center.

A circle of radius "r" for the Chebyshev distance (L metric) on a plane is also a square with side length 2"r" parallel to the coordinate axes, so planar Chebyshev distance can be viewed as equivalent by rotation and scaling to planar taxicab distance. However, this equivalence between L and L metrics does not generalize to higher dimensions.

Squaring the circle is the problem, proposed by ancient geometers, of constructing a square with the same area as a given circle by using only a finite number of steps with compass and straightedge.

In 1882, the task was proven to be impossible, as a consequence of the Lindemann–Weierstrass theorem, which proves that pi () is a transcendental number, rather than an algebraic irrational number; that is, it is not the root of any polynomial with rational coefficients.

From the time of the earliest known civilisations – such as the Assyrians and ancient Egyptians, those in the Indus Valley and along the Yellow River in China, and the Western civilisations of ancient Greece and Rome during classical Antiquity – the circle has been used directly or indirectly in visual art to convey the artist’s message and to express certain ideas.
However, differences in worldview (beliefs and culture) had a great impact on artists’ perceptions. While some emphasised the circle’s perimeter to demonstrate their democratic manifestation, others focused on its centre to symbolise the concept of cosmic unity. In mystical doctrines, the circle mainly symbolises the infinite and cyclical nature of existence, but in religious traditions it represents heavenly bodies and divine spirits.
The circle signifies many sacred and spiritual concepts, including unity, infinity, wholeness, the universe, divinity, balance, stability and perfection, among others. Such concepts have been conveyed in cultures worldwide through the use of symbols, for example, a compass, a halo, the vesica piscis and its derivatives (fish, eye, aureole, mandorla, etc.), the ouroboros, the Dharma wheel, a rainbow, mandalas, rose windows and so forth. 












</doc>
