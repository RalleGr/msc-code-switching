<doc id="8468" url="https://en.wikipedia.org/wiki?curid=8468" title="Determinant">
Determinant

In linear algebra, the determinant is a scalar value that can be computed from the elements of a square matrix and encodes certain properties of the linear transformation described by the matrix. The determinant of a matrix is denoted , , or . Geometrically, it can be viewed as the volume scaling factor of the linear transformation described by the matrix. This is also the signed volume of the -dimensional parallelepiped spanned by the column or row vectors of the matrix. The determinant is positive or negative according to whether the linear transformation preserves or reverses the orientation of a real vector space.

In the case of a matrix the determinant may be defined as

Similarly, for a 3 × 3 matrix "A", its determinant is

Each determinant of a matrix in this equation is called a minor of the matrix . This procedure can be extended to give a recursive definition for the determinant of an matrix, the "Laplace expansion".

Determinants occur throughout mathematics. For example, a matrix is often used to represent the coefficients in a system of linear equations, and the determinant can be used to solve those equations, although other methods of solution are much more computationally efficient. In linear algebra, a matrix (with entries in a field) is singular (not invertible) if and only if its determinant is zero. This leads to the use of determinants in defining the characteristic polynomial of a matrix, whose roots are the eigenvalues. In analytic geometry, determinants express the signed -dimensional volumes of -dimensional parallelepipeds. This leads to the use of determinants in calculus, the Jacobian determinant in the change of variables rule for integrals of functions of several variables. Determinants appear frequently in algebraic identities such as the Vandermonde identity.

Determinants possess many algebraic properties. One of them is multiplicativity, namely that the determinant of a product of matrices is equal to the product of determinants. Special types of matrices have special determinants; for example, the determinant of an orthogonal matrix is always plus or minus one, and the determinant of a complex Hermitian matrix is always real.

If an real matrix "A" is written in terms of its column vectors formula_3 then 

This means that formula_5 maps the unit "n"-cube to the "n"-dimensional parallelotope defined by the vectors formula_6 the region formula_7

The determinant gives the signed "n"-dimensional volume of this parallelotope, formula_8 and hence describes more generally the "n"-dimensional volume scaling factor of the linear transformation produced by "A". (The sign shows whether the transformation preserves or reverses orientation.) In particular, if the determinant is zero, then this parallelotope has volume zero and is not fully "n"-dimensional, which indicates that the dimension of the image of "A" is less than "n". This means that "A" produces a linear transformation which is neither onto nor one-to-one, and so is not invertible.

There are various equivalent ways to define the determinant of a square matrix "A", i.e. one with the same number of rows and columns. Perhaps the simplest way to express the determinant is by considering the elements in the top row and the respective minors; starting at the left, multiply the element by the minor, then subtract the product of the next element and its minor, and alternate adding and subtracting such products until all elements in the top row have been exhausted. For example, here is the result for a 4 × 4 matrix:
Another way to define the determinant is expressed in terms of the columns of the matrix. If we write an matrix "A" in terms of its column vectors

where the formula_11 are vectors of size "n", then the determinant of "A" is defined so that

where "b" and "c" are scalars, "v" is any vector of size "n" and "I" is the identity matrix of size "n". These equations say that the determinant is a linear function of each column, that interchanging adjacent columns reverses the sign of the determinant, and that the determinant of the identity matrix is 1. These properties mean that the determinant is an alternating multilinear function of the columns that maps the identity matrix to the underlying unit scalar. These suffice to uniquely calculate the determinant of any square matrix. Provided the underlying scalars form a field (more generally, a commutative ring with unity), the definition below shows that such a function exists, and it can be shown to be unique.

Equivalently, the determinant can be expressed as a sum of products of entries of the matrix where each product has "n" terms and the coefficient of each product is −1 or 1 or 0 according to a given rule: it is a polynomial expression of the matrix entries. This expression grows rapidly with the size of the matrix (an matrix contributes "n"! terms), so it will first be given explicitly for the case of matrices and matrices, followed by the rule for arbitrary size matrices, which subsumes these two cases.

Assume "A" is a square matrix with "n" rows and "n" columns, so that it can be written as

The entries can be numbers or expressions (as happens when the determinant is used to define a characteristic polynomial); the definition of the determinant depends only on the fact that they can be added and multiplied together in a commutative manner.

The determinant of "A" is denoted by det("A"), or it can be denoted directly in terms of the matrix entries by writing enclosing bars instead of brackets:

The Leibniz formula for the determinant of a matrix is

If the matrix entries are real numbers, the matrix can be used to represent two linear maps: one that maps the standard basis vectors to the rows of , and one that maps them to the columns of . In either case, the images of the basis vectors form a parallelogram that represents the image of the unit square under the mapping. The parallelogram defined by the rows of the above matrix is the one with vertices at and as shown in the accompanying diagram.

The absolute value of is the area of the parallelogram, and thus represents the scale factor by which areas are transformed by . (The parallelogram formed by the columns of is in general a different parallelogram, but since the determinant is symmetric with respect to rows and columns, the area will be the same.)

The absolute value of the determinant together with the sign becomes the "oriented area" of the parallelogram. The oriented area is the same as the usual area, except that it is negative when the angle from the first to the second vector defining the parallelogram turns in a clockwise direction (which is opposite to the direction one would get for the identity matrix).

To show that is the signed area, one may consider a matrix containing two vectors and representing the parallelogram's sides. The signed area can be expressed as for the angle "θ" between the vectors, which is simply base times height, the length of one vector times the perpendicular component of the other. Due to the sine this already is the signed area, yet it may be expressed more conveniently using the cosine of the complementary angle to a perpendicular vector, e.g. so that which can be determined by the pattern of the scalar product to be equal to 

Thus the determinant gives the scaling factor and the orientation induced by the mapping represented by "A". When the determinant is equal to one, the linear mapping defined by the matrix is equi-areal and orientation-preserving.

The object known as the "bivector" is related to these ideas. In 2D, it can be interpreted as an "oriented plane segment" formed by imagining two vectors each with origin and coordinates and The bivector magnitude (denoted by is the "signed area", which is also the determinant 

The Laplace formula for the determinant of a matrix is

this can be expanded out to give the Leibniz formula.

The Leibniz formula for the determinant of a matrix:

The rule of Sarrus is a mnemonic for the matrix determinant: the sum of the products of three diagonal north-west to south-east lines of matrix elements, minus the sum of the products of three diagonal south-west to north-east lines of elements, when the copies of the first two columns of the matrix are written beside it as in the illustration: 
formula_19

formula_20
This scheme for calculating the determinant of a matrix does not carry over into higher dimensions.

The determinant of a matrix of arbitrary size can be defined by the Leibniz formula or the Laplace formula.

The Leibniz formula for the determinant of an matrix "A" is

Here the sum is computed over all permutations "σ" of the set A permutation is a function that reorders this set of integers. The value in the "i"th position after the reordering "σ" is denoted by "σ". For example, for , the original sequence 1, 2, 3 might be reordered to , with , , and . The set of all such permutations (also known as the symmetric group on "n" elements) is denoted by S. For each permutation "σ", sgn("σ") denotes the signature of "σ", a value that is +1 whenever the reordering given by σ can be achieved by successively interchanging two entries an even number of times, and −1 whenever it can be achieved by an odd number of such interchanges.

In any of the formula_22 summands, the term

is notation for the product of the entries at positions , where "i" ranges from 1 to "n":

For example, the determinant of a matrix "A" () is

It is sometimes useful to extend the Leibniz formula to a summation in which not only permutations, but all sequences of "n" indices in the range occur, ensuring that the contribution of a sequence will be zero unless it denotes a permutation. Thus the totally antisymmetric Levi-Civita symbol formula_26 extends the signature of a permutation, by setting formula_27 for any permutation "σ" of "n", and formula_28 when no permutation "σ" exists such that formula_29 for formula_30 (or equivalently, whenever some pair of indices are equal). The determinant for an matrix can then be expressed using an "n"-fold summation as

or using two epsilon symbols as

where now each "i" and each "j" should be summed over .

However, through the use of tensor notation and the suppression of the summation symbol (Einstein's summation convention) we can obtain a much more compact expression of the determinant of the second order system of formula_33 dimensions, formula_34;

where formula_36 and formula_37 represent 'e-systems' that take on the values 0, +1 and −1 given the number of permutations of formula_38 and formula_39. More specifically, formula_37 is equal to 0 when there is a repeated index in formula_38; +1 when an even number of permutations of formula_38 is present; −1 when an odd number of permutations of formula_38 is present. The number of indices present in the e-systems is equal to formula_44 and thus can be generalized in this manner.

The determinant has many properties. Some basic properties of determinants are


This can be deduced from some of the properties below, but it follows most easily directly from the Leibniz formula (or from the Laplace expansion), in which the identity permutation is the only one that gives a non-zero contribution.

A number of additional properties relate to the effects on the determinant of changing particular rows or columns:

Property 5 says that the determinant on matrices is homogeneous of degree "n". These properties can be used to facilitate the computation of determinants by simplifying the matrix to the point where the determinant can be determined immediately. Specifically, for matrices with coefficients in a field, properties 13 and 14 can be used to transform any matrix into a triangular matrix, whose determinant is given by property 7; this is essentially the method of Gaussian elimination.

For example, the determinant of

can be computed using the following matrices:

Here, "B" is obtained from "A" by adding −1/2×the first row to the second, so that . "C" is obtained from "B" by adding the first to the third row, so that . Finally, "D" is obtained from "C" by exchanging the second and third row, so that . The determinant of the (upper) triangular matrix "D" is the product of its entries on the main diagonal: . Therefore, .

The following identity holds for a Schur complement of a square matrix:

The Schur complement arises as the result of performing a block Gaussian elimination by multiplying the matrix "M" from the right with a "block lower triangular" matrix

Here "I" denotes the "p"×"p" identity matrix. After multiplication with the matrix "L", the Schur complement appears in the upper "p"×"p" block. The product matrix is

That is, we have effected a Gaussian decomposition

The first and last matrices on the RHS have determinant unity, so we have

This is Schur's determinant identity.

The determinant of a matrix product of square matrices equals the product of their determinants:

Thus the determinant is a "multiplicative map". This property is a consequence of the characterization given above of the determinant as the unique "n"-linear alternating function of the columns with value 1 on the identity matrix, since the function that maps can easily be seen to be "n"-linear and alternating in the columns of "M", and takes the value det("A") at the identity. The formula can be generalized to (square) products of rectangular matrices, giving the Cauchy–Binet formula, which also provides an independent proof of the multiplicative property.

The determinant det("A") of a matrix "A" is non-zero if and only if "A" is invertible or, yet another equivalent statement, if its rank equals the size of the matrix. If so, the determinant of the inverse matrix is given by

In particular, products and inverses of matrices with determinant one still have this property. Thus, the set of such matrices (of fixed size "n") form a group known as the special linear group. More generally, the word "special" indicates the subgroup of another matrix group of matrices of determinant one. Examples include the special orthogonal group (which if "n" is 2 or 3 consists of all rotation matrices), and the special unitary group.

Laplace expansion expresses the determinant of a matrix in terms of its minors. The minor is defined to be the determinant of the -matrix that results from by removing the th row and the th column. The expression is known as a cofactor. For every , one has the equality
which is called the "Laplace expansion along the th row". Similarly, the "Laplace expansion along the th column" is the equality
For example, the Laplace expansion of the matrix

along the second column ( and the sum runs over ) is given by,

Laplace expansion can be used iteratively for computing determinants, but this is efficient for small matrices and sparse matrices only, since for general matrices this requires to compute an exponential number of determinants, even if care is taken to compute each minor only once.
The adjugate matrix adj("A") is the transpose of the matrix of the cofactors, that is,

For every matrix, one has

Thus the adjugate matrix can be used for expressing the inverse of a nonsingular matrix: 

Sylvester's determinant theorem states that for "A", an matrix, and "B", an matrix (so that "A" and "B" have dimensions allowing them to be multiplied in either order forming a square matrix):

where "I" and "I" are the and identity matrices, respectively.

From this general result several consequences follow.

Let be an arbitrary matrix of complex numbers with eigenvalues formula_85. (Here it is understood that an eigenvalue with algebraic multiplicity occurs times in this list.) Then the determinant of is the product of all eigenvalues,
The product of all non-zero eigenvalues is referred to as pseudo-determinant.

Conversely, determinants can be used to find the eigenvalues of the matrix : they are the solutions of the characteristic equation
where "I" is the identity matrix of the same dimension as and is a (scalar) number which solves the equation (there are no more than solutions, where is the dimension of ).

A Hermitian matrix is positive definite if all its eigenvalues are positive. Sylvester's criterion asserts that this is equivalent to the determinants of the submatrices

being positive, for all between 1 and .

The trace tr("A") is by definition the sum of the diagonal entries of and also equals the sum of the eigenvalues. Thus, for complex matrices ,

or, for real matrices ,

Here exp() denotes the matrix exponential of , because every eigenvalue of corresponds to the eigenvalue exp() of exp(). In particular, given any logarithm of , that is, any matrix satisfying

the determinant of is given by

For example, for , , and , respectively,

cf. Cayley-Hamilton theorem. Such expressions are deducible from combinatorial arguments, Newton's identities, or the Faddeev–LeVerrier algorithm. That is, for generic , the signed constant term of the characteristic polynomial, determined recursively from

In the general case, this may also be obtained from

where the sum is taken over the set of all integers "k" ≥ 0 satisfying the equation

The formula can be expressed in terms of the complete exponential Bell polynomial of "n" arguments "s" = −("l" – 1)! tr("A") as

This formula can also be used to find the determinant of a matrix with multidimensional indices and . The product and trace of such matrices are defined in a natural way as

An important arbitrary dimension identity can be obtained from the Mercator series expansion of the logarithm when the expansion converges. If every eigenvalue of "A" is less than 1 in absolute value,

where is the identity matrix. More generally, if 

is expanded as a formal power series in then all coefficients of for are zero and the remaining polynomial is .

For a positive definite matrix , the trace operator gives the following tight lower and upper bounds on the log determinant

with equality if and only if . This relationship can be derived via the formula for the KL-divergence between two multivariate normal distributions.

Also,

These inequalities can be proved by bringing the matrix "A" to the diagonal form. As such, they represent the well-known fact that the harmonic mean is less than the geometric mean, which is less than the arithmetic mean, which is, in turn, less than the root mean square.

For a matrix equation

the solution is given by Cramer's rule:
where "A" is the matrix formed by replacing the "i"th column of "A" by the column vector "b". This follows immediately by column expansion of the determinant, i.e.
where the vectors formula_11 are the columns of "A". The rule is also implied by the identity

It has recently been shown that Cramer's rule can be implemented in O("n") time, which is comparable to more common methods of solving systems of linear equations, such as LU, QR, or singular value decomposition.

Suppose "A", "B", "C", and "D" are matrices of dimension , , , and , respectively. Then

This can be seen from the Leibniz formula for determinants, or from a decomposition like (for the former case)

When "A" is invertible, one has

as can be seen by employing the decomposition

When "D" is invertible, a similar identity with formula_112 factored out can be derived analogously, that is,

When the blocks are square matrices of the same order further formulas hold. For example, if "C" and "D" commute (i.e., ), then the following formula comparable to the determinant of a matrix holds:

Generally, if all pairs of matrices of the block matrix commute, then the determinant of the block matrix is equal to the determinant of the matrix obtained by computing the determinant of the block matrix considering its entries as the entries of a matrix. As the previous formula shows, for "p" = 2, this criterion is sufficient, but not necessary.

When "A" = "D" and "B" = "C", the blocks are square matrices of the same order and the following formula holds (even if "A" and "B" do not commute)

When "D" is a 1×1 matrix, "B" is a column vector, and "C" is a row vector then

Let formula_117 be a scalar complex number. If a block matrix is square, its characteristic polynomial can be factored with

It can be seen, e.g. using the Leibniz formula, that the determinant of real (or analogously for complex) square matrices is a polynomial function from to R, and so it is everywhere differentiable. Its derivative can be expressed using Jacobi's formula:

where adj("A") denotes the adjugate of "A". In particular, if "A" is invertible, we have

Expressed in terms of the entries of "A", these are

Yet another equivalent formulation is

using big O notation. The special case where formula_123, the identity matrix, yields

This identity is used in describing the tangent space of certain matrix Lie groups.

If the matrix A is written as formula_125 where a, b, c are column vectors of length 3, then the gradient over one of the three vectors may be written as the cross product of the other two:

The above identities concerning the determinant of products and inverses of matrices imply that similar matrices have the same determinant: two matrices "A" and "B" are similar, if there exists an invertible matrix "X" such that . Indeed, repeatedly applying the above identities yields

The determinant is therefore also called a similarity invariant. The determinant of a linear transformation
for some finite-dimensional vector space "V" is defined to be the determinant of the matrix describing it, with respect to an arbitrary choice of basis in "V". By the similarity invariance, this determinant is independent of the choice of the basis for "V" and therefore only depends on the endomorphism "T".

The determinant of a linear transformation of an "n"-dimensional vector space "V" can be formulated in a coordinate-free manner by considering the "n"th exterior power Λ"V" of "V". "T" induces a linear map

As Λ"V" is one-dimensional, the map ΛT is given by multiplying with some scalar. This scalar coincides with the determinant of "T", that is to say

This definition agrees with the more concrete coordinate-dependent definition. In particular, for a square formula_131 matrix "A" whose columns are formula_132, its determinant satisfies formula_133, where formula_134 is the standard basis of formula_135. This follows from the characterization of the determinant given above. For example, switching two columns changes the sign of the determinant; likewise, permuting the vectors in the exterior product to , say, also changes its sign.

For this reason, the highest non-zero exterior power Λ("V") is sometimes also called the determinant of "V" and similarly for more involved objects such as vector bundles or chain complexes of vector spaces. Minors of a matrix can also be cast in this setting, by considering lower alternating forms Λ"V" with .

The determinant can also be characterized as the unique function
from the set of all matrices with entries in a field "K" to that field satisfying the following three properties: first, "D" is an "n"-linear function: considering all but one column of "A" fixed, the determinant is linear in the remaining column, that is
for any column vectors "v", ..., "v", and "w" and any scalars (elements of "K") "a" and "b". Second, "D" is an alternating function: for any matrix "A" with two identical columns, . Finally, , where "I" is the identity matrix.

This fact also implies that every other "n"-linear alternating function satisfies

This definition can also be extended where "K" is a commutative ring "R", in which case a matrix is invertible if and only if its determinant is an invertible element in "R". For example, a matrix "A" with entries in Z, the integers, is invertible (in the sense that there exists an inverse matrix with integer entries) if the determinant is +1 or −1. Such a matrix is called unimodular.

The determinant defines a mapping
between the group of invertible matrices with entries in "R" and the multiplicative group of units in "R". Since it respects the multiplication in both groups, this map is a group homomorphism. Secondly, given a ring homomorphism , there is a map given by replacing all entries in "R" by their images under "f". The determinant respects these maps, i.e., given a matrix with entries in "R", the identity
holds. In other words, the following diagram commutes:

For example, the determinant of the complex conjugate of a complex matrix (which is also the determinant of its conjugate transpose) is the complex conjugate of its determinant, and for integer matrices: the reduction modulo "m" of the determinant of such a matrix is equal to the determinant of the matrix reduced modulo "m" (the latter determinant being computed using modular arithmetic). In the language of category theory, the determinant is a natural transformation between the two functors GL and (⋅) (see also Natural transformation#Determinant). Adding yet another layer of abstraction, this is captured by saying that the determinant is a morphism of algebraic groups, from the general linear group to the multiplicative group,

For matrices with an infinite number of rows and columns, the above definitions of the determinant do not carry over directly. For example, in the Leibniz formula, an infinite sum (all of whose terms are infinite products) would have to be calculated. Functional analysis provides different extensions of the determinant for such infinite-dimensional situations, which however only work for particular kinds of operators.

The Fredholm determinant defines the determinant for operators known as trace class operators by an appropriate generalization of the formula

Another infinite-dimensional notion of determinant is the functional determinant.

For operators in a finite factor, one may define a positive real-valued determinant called the Fuglede−Kadison determinant using the canonical trace. In fact, corresponding to every tracial state on a von Neumann algebra there is a notion of Fuglede−Kadison determinant.

For square matrices with entries in a non-commutative ring, there are various difficulties in defining determinants analogously to that for commutative rings. A meaning can be given to the Leibniz formula provided that the order for the product is specified, and similarly for other definitions of the determinant, but non-commutativity then leads to the loss of many fundamental properties of the determinant, such as the multiplicative property or the fact that the determinant is unchanged under transposition of the matrix. Over non-commutative rings, there is no reasonable notion of a multilinear form (existence of a nonzero with a regular element of "R" as value on some pair of arguments implies that "R" is commutative). Nevertheless, various notions of non-commutative determinant have been formulated that preserve some of the properties of determinants, notably quasideterminants and the Dieudonné determinant. For some classes of matrices with non-commutative elements, one can define the determinant and prove linear algebra theorems that are very similar to their commutative analogs. Examples include the "q"-determinant on quantum groups, the Capelli determinant on Capelli matrices, and the Berezinian on supermatrices. Manin matrices form the class closest to matrices with commutative elements.

Determinants of matrices in superrings (that is, Z-graded rings) are known as Berezinians or superdeterminants.

The permanent of a matrix is defined as the determinant, except that the factors sgn("σ") occurring in Leibniz's rule are omitted. The immanant generalizes both by introducing a character of the symmetric group S in Leibniz's rule.

Determinants are mainly used as a theoretical tool. They are rarely calculated explicitly in numerical linear algebra, where for applications like checking invertibility and finding eigenvalues the determinant has largely been supplanted by other techniques. Computational geometry, however, does frequently use calculations related to determinants.

Naive methods of implementing an algorithm to compute the determinant include using the Leibniz formula or Laplace's formula. Both these approaches are extremely inefficient for large matrices, though, since the number of required operations grows very quickly: it is of order "n"! ("n" factorial) for an matrix "M". For example, Leibniz's formula requires calculating "n"! products. Therefore, more involved techniques have been developed for calculating determinants.

Given a matrix "A", some methods compute its determinant by writing "A" as a product of matrices whose determinants can be more easily computed. Such techniques are referred to as decomposition methods. Examples include the LU decomposition, the QR decomposition or the Cholesky decomposition (for positive definite matrices). These methods are of order O("n"), which is a significant improvement over O("n"!)

The LU decomposition expresses "A" in terms of a lower triangular matrix "L", an upper triangular matrix "U" and a permutation matrix "P":
The determinants of "L" and "U" can be quickly calculated, since they are the products of the respective diagonal entries. The determinant of "P" is just the sign formula_144 of the corresponding permutation (which is +1 for an even number of permutations and is −1 for an odd number of permutations). The determinant of "A" is then

(See determinant identities.) Moreover, the decomposition can be chosen such that "L" is a unitriangular matrix and therefore has determinant 1, in which case the formula further simplifies to

If the determinant of "A" and the inverse of "A" have already been computed, the matrix determinant lemma allows rapid calculation of the determinant of , where "u" and "v" are column vectors.

Since the definition of the determinant does not need divisions, a question arises: do fast algorithms exist that do not need divisions? This is especially interesting for matrices over rings. Indeed, algorithms with run-time proportional to "n" exist. An algorithm of Mahajan and Vinay, and Berkowitz is based on closed ordered walks (short "clow"). It computes more products than the determinant definition requires, but some of these products cancel and the sum of these products can be computed more efficiently. The final algorithm looks very much like an iterated product of triangular matrices.

If two matrices of order "n" can be multiplied in time "M"("n"), where for some , then the determinant can be computed in time O("M"("n")). This means, for example, that an O("n") algorithm exists based on the Coppersmith–Winograd algorithm.

Charles Dodgson (i.e. Lewis Carroll of "Alice's Adventures in Wonderland" fame) invented a method for computing determinants called Dodgson condensation. Unfortunately this interesting method does not always work in its original form.

Algorithms can also be assessed according to their bit complexity, i.e., how many bits of accuracy are needed to store intermediate values occurring in the computation. For example, the Gaussian elimination (or LU decomposition) method is of order O("n"), but the bit length of intermediate values can become exponentially long. The Bareiss Algorithm, on the other hand, is an exact-division method based on Sylvester's identity is also of order "n", but the bit complexity is roughly the bit size of the original entries in the matrix times "n".

Historically, determinants were used long before matrices: A determinant was originally defined as a property of a system of linear equations. 
The determinant "determines" whether the system has a unique solution (which occurs precisely if the determinant is non-zero). 
In this sense, determinants were first used in the Chinese mathematics textbook "The Nine Chapters on the Mathematical Art" (九章算術, Chinese scholars, around the 3rd century BCE). 
In Europe, determinants were considered by Cardano at the end of the 16th century and larger ones by Leibniz.

In Japan, Seki Takakazu is credited with the discovery of the resultant and the determinant (at first in 1683, the complete version no later than 1710). 
In Europe, Cramer (1750) added to the theory, treating the subject in relation to sets of equations. 
The recurrence law was first announced by Bézout (1764).

It was Vandermonde (1771) who first recognized determinants as independent functions. Laplace (1772) gave the general method of expanding a determinant in terms of its complementary minors: Vandermonde had already given a special case. Immediately following, Lagrange (1773) treated determinants of the second and third order and applied it to questions of elimination theory; he proved many special cases of general identities.

Gauss (1801) made the next advance. Like Lagrange, he made much use of determinants in the theory of numbers. He introduced the word determinant (Laplace had used "resultant"), though not in the present signification, but rather as applied to the discriminant of a quantic. Gauss also arrived at the notion of reciprocal (inverse) determinants, and came very near the multiplication theorem.

The next contributor of importance is Binet (1811, 1812), who formally stated the theorem relating to the product of two matrices of "m" columns and "n" rows, which for the special case of reduces to the multiplication theorem. On the same day (November 30, 1812) that Binet presented his paper to the Academy, Cauchy also presented one on the subject. (See Cauchy–Binet formula.) In this he used the word determinant in its present sense, summarized and simplified what was then known on the subject, improved the notation, and gave the multiplication theorem with a proof more satisfactory than Binet's. With him begins the theory in its generality.

The next important figure was Jacobi (from 1827). He early used the functional determinant which Sylvester later called the Jacobian, and in his memoirs in "Crelle's Journal" for 1841 he specially treats this subject, as well as the class of alternating functions which Sylvester has called "alternants". About the time of Jacobi's last memoirs, Sylvester (1839) and Cayley began their work.

The study of special forms of determinants has been the natural result of the completion of the general theory. Axisymmetric determinants have been studied by Lebesgue, Hesse, and Sylvester; persymmetric determinants by Sylvester and Hankel; circulants by Catalan, Spottiswoode, Glaisher, and Scott; skew determinants and Pfaffians, in connection with the theory of orthogonal transformation, by Cayley; continuants by Sylvester; Wronskians (so called by Muir) by Christoffel and Frobenius; compound determinants by Sylvester, Reiss, and Picquet; Jacobians and Hessians by Sylvester; and symmetric gauche determinants by Trudi. Of the textbooks on the subject Spottiswoode's was the first. In America, Hanus (1886), Weld (1893), and Muir/Metzler (1933) published treatises.

As mentioned above, the determinant of a matrix (with real or complex entries, say) is zero if and only if the column vectors (or the row vectors) of the matrix are linearly dependent. Thus, determinants can be used to characterize linearly dependent vectors. For example, given two linearly independent vectors "v", "v" in R, a third vector "v" lies in the plane spanned by the former two vectors exactly if the determinant of the matrix consisting of the three vectors is zero. The same idea is also used in the theory of differential equations: given "n" functions "f"("x"), ..., "f"("x") (supposed to be times differentiable), the Wronskian is defined to be

It is non-zero (for some "x") in a specified interval if and only if the given functions and all their derivatives up to order "n"−1 are linearly independent. If it can be shown that the Wronskian is zero everywhere on an interval then, in the case of analytic functions, this implies the given functions are linearly dependent. See the Wronskian and linear independence.

The determinant can be thought of as assigning a number to every sequence of "n" vectors in R, by using the square matrix whose columns are the given vectors. For instance, an orthogonal matrix with entries in R represents an orthonormal basis in Euclidean space. The determinant of such a matrix determines whether the orientation of the basis is consistent with or opposite to the orientation of the standard basis. If the determinant is +1, the basis has the same orientation. If it is −1, the basis has the opposite orientation.

More generally, if the determinant of "A" is positive, "A" represents an orientation-preserving linear transformation (if "A" is an orthogonal or matrix, this is a rotation), while if it is negative, "A" switches the orientation of the basis.

As pointed out above, the absolute value of the determinant of real vectors is equal to the volume of the parallelepiped spanned by those vectors. As a consequence, if is the linear map represented by the matrix "A", and "S" is any measurable subset of R, then the volume of "f"("S") is given by times the volume of "S". More generally, if the linear map is represented by the matrix "A", then the "n"-dimensional volume of "f"("S") is given by:

By calculating the volume of the tetrahedron bounded by four points, they can be used to identify skew lines. The volume of any tetrahedron, given its vertices a, b, c, and d, is , or any other combination of pairs of vertices that would form a spanning tree over the vertices.

For a general differentiable function, much of the above carries over by considering the Jacobian matrix of "f". For

the Jacobian matrix is the matrix whose entries are given by

Its determinant, the Jacobian determinant, appears in the higher-dimensional version of integration by substitution: for suitable functions "f" and an open subset "U" of R (the domain of "f"), the integral over "f"("U") of some other function is given by

The Jacobian also occurs in the inverse function theorem.

The third order Vandermonde determinant is
In general, the "n"th-order Vandermonde determinant is

where the right-hand side is the continued product of all the differences that can be formed from the pairs of numbers taken from "x", "x", ..., "x", with the order of the differences taken in the reversed order of the suffixes that are involved.

Second order

Third order

where "ω" and "ω" are the complex cube roots of 1. In general, the "n"th-order circulant determinant is

where "ω" is an "n"th root of 1.




</doc>
<doc id="8470" url="https://en.wikipedia.org/wiki?curid=8470" title="David Ricardo">
David Ricardo

David Ricardo (18 April 1772 – 11 September 1823) was a British political economist, one of the most influential of the classical economists along with Thomas Malthus, Adam Smith and James Mill.

Born in London, England, Ricardo was the third surviving of the 17 children of Abigail Delvalle (1753–1801) and her husband Abraham Israel Ricardo (1733?–1812). His family were Sephardic Jews of Portuguese origin who had recently relocated from the Dutch Republic. His father was a successful stockbroker and Ricardo began working with him at the age of 14. At the age of 21 Ricardo eloped with a Quaker, Priscilla Anne Wilkinson, and, against his father's wishes, converted to Unitarianism. This religious difference resulted in estrangement from his family, and he was led to adopt a position of independence. His father disowned him and his mother apparently never spoke to him again.

Following this estrangement he went into business for himself with the support of Lubbocks and Forster, an eminent banking house. He made the bulk of his fortune as a result of speculation on the outcome of the Battle of Waterloo. "The Sunday Times" reported in Ricardo's obituary, published on 14 September 1823, that during the Battle Ricardo "netted upwards of a million sterling", a huge sum at the time. He immediately retired, his position on the floor no longer tenable, and subsequently purchased Gatcombe Park, an estate in Gloucestershire, and retired to the country. He was appointed High Sheriff of Gloucestershire for 1818–19.

In August 1818 he bought Lord Portarlington's seat in Parliament for £4,000, as part of the terms of a loan of £25,000. His record in Parliament was that of an earnest reformer. He held the seat until his death five years later.

Ricardo was a close friend of James Mill. Other notable friends included Jeremy Bentham and Thomas Malthus, with whom Ricardo had a considerable debate (in correspondence) over such things as the role of landowners in a society. He also was a member of Malthus' Political Economy Club, and a member of the King of Clubs. He was one of the original members of The Geological Society. His youngest sister was author Sarah Ricardo-Porter (e.g., "Conversations in Arithmetic").

As MP for Portarlington, he voted with the opposition in support of the liberal movements in Naples, 21 February, and Sicily, 21 June, and for inquiry into the administration of justice in Tobago, 6 June. He divided for repeal of the Blasphemous and Seditious Libels Act, 8 May, inquiry into the Peterloo massacre, 16 May, and abolition of the death penalty for forgery, 25 May 4 June 1821.

He adamantly supported the implementation of free trade. He voted against renewal of the sugar duties, 9 Feb, and objected to the higher duty on East as opposed to West Indian produce, 4 May 1821. He opposed the timber duties. He voted silently for parliamentary reform, 25 Apr and 3 June, and spoke in its favour at the Westminster anniversary reform dinner, 23 May 1822. He again voted for criminal law reform, 4 June.

His friend John Louis Mallett commented: " … he meets you upon every subject that he has studied with a mind made up, and opinions in the nature of mathematical truths. He spoke of parliamentary reform and ballot as a man who would bring such things about, and destroy the existing system tomorrow, if it were in his power, and without the slightest doubt on the result … It is this very quality of the man’s mind, his entire disregard of experience and practice, which makes me doubtful of his opinions on political economy."

Ten years after retiring and four years after entering Parliament, Ricardo died from an infection of the middle ear that spread into his brain and induced septicaemia. He was 51.

He and his wife Priscilla had eight children together including Osman Ricardo (1795–1881; MP for Worcester 1847–1865), David Ricardo (1803–1864, MP for Stroud 1832–1833) and Mortimer Ricardo, who served as an officer in the Life Guards and was a deputy lieutenant for Oxfordshire.

Ricardo is buried in an ornate grave in the churchyard of Saint Nicholas in Hardenhuish, now a suburb of Chippenham, Wiltshire. At the time of his death his assets were estimated at between £675,000–£775,000.

He wrote his first economics article at 37, firstly in "The Morning Chronicle" advocating reduction in the note-issuing of the Bank of England and then publishing "The High Price of Bullion, a Proof of the Depreciation of Bank Notes" in 1810.

He was also an abolitionist, speaking at a meeting of the Court of the East India Company in March 1823, where he said he regarded slavery as a stain on the character of the nation.

Ricardo's most famous work is his "Principles of Political Economy and Taxation" (1817). He advanced a labour theory of value:

The value of a commodity, or the quantity of any other commodity for which it will exchange, depends on the relative quantity of labour which is necessary for its production, and not on the greater or less compensation which is paid for that labour.

Ricardo's note to Section VI:

Mr. Malthus appears to think that it is a part of my doctrine, that the cost and value of a thing be the same;—it is, if he means by cost, "cost of production" including profit.

Ricardo contributed to the development of theories of rent, wages, and profits. He defined rent as "the difference between the produce obtained by the employment of two equal quantities of capital and labour." Ricardo believed that the process of economic development, which increased land use and eventually led to the cultivation of poorer land, principally benefited landowners. According to Ricardo, such premium over "real social value" that is reaped due to ownership constitutes value to an individual but is at best a paper monetary return to "society". The portion of such purely individual benefit that accrues to scarce resources Ricardo labels "rent".

In his "Theory of Profit", Ricardo stated that as real wages increase, real profits decrease because the revenue from the sale of manufactured goods is split between profits and wages. He said in his "Essay on Profits", "Profits depend on high or low wages, wages on the price of necessaries, and the price of necessaries chiefly on the price of food."

Between 1500 and 1750 most economists advocated Mercantilism which promoted the idea of international trade for the purpose of earning bullion by running a trade surplus with other countries. Ricardo challenged the idea that the purpose of trade was merely to accumulate gold or silver. With "comparative advantage" Ricardo argued in favour of industry specialisation and free trade. He suggested that industry specialization combined with free international trade always produces positive results. This theory expanded on the concept of absolute advantage.

Ricardo suggested that there is mutual national benefit from trade even if one country is more competitive in every area than its trading counterpart and that a nation should concentrate resources only in industries where it has a comparative advantage, that is in those industries in which it has the greatest competitive edge. Ricardo suggested that national industries which were, in fact, profitable and internationally competitive should be jettisoned in favour of the most competitive industries, the assumption being that subsequent economic growth would more than offset any economic dislocation which would result from closing profitable and competitive national industries.

Ricardo attempted to prove theoretically that international trade is always beneficial. Paul Samuelson called the numbers used in Ricardo's example dealing with trade between England and Portugal the "four magic numbers". "In spite of the fact that the Portuguese could produce both cloth and wine with less amount of labour, Ricardo suggested that both countries would benefit from trade with each other".

As for recent extensions of Ricardian models, see Ricardian trade theory extensions.

Ricardo's theory of international trade was reformulated by John Stuart Mill. The term "comparative advantage" was started by J. S. Mill and his contemporaries.

John Stuart Mill started a neoclassical turn of international trade theory, i.e. his formulation was inherited by Alfred Marshall and others and contributed to the resurrection of anti-Ricardian concept of law of supply and demand and induce the arrival neoclassical theory of value.

Ricardo's four magic numbers has long been interpreted as comparison of two ratios of labour input coefficients. This interpretation is now considered as erroneous. This point was first made by Roy J. Ruffin in 2002 and examined and explained in detail in Andrea Maneschi in 2004. This is now known as "new interpretation" but it has been mentioned by P. Sraffa in 1930 and by Kenzo Yukizawa in 1974. The new interpretation affords totally new reading of Ricardo's "Principles of Political Economy and Taxation" with regards to trade theory.

Like Adam Smith, Ricardo was an opponent of protectionism for national economies, especially for agriculture. He believed that the British "Corn Laws" – imposing tariffs on agricultural products – ensured that less-productive domestic land would be cultivated and rents would be driven up . Thus, profits would be directed toward landlords and away from the emerging industrial capitalists. Ricardo believed landlords tended to squander their wealth on luxuries, rather than invest. He believed the Corn Laws were leading to the stagnation of the British economy. In 1846, his nephew John Lewis Ricardo, MP for Stoke-upon-Trent, advocated free trade and the repeal of the Corn Laws.

Modern empirical analysis of the Corn Laws yields mixed results. Parliament repealed the Corn Laws in 1846.

Ricardo was concerned about the impact of technological change on labour in the short-term. In 1821, he wrote that he had become "convinced that the substitution of machinery for human labour, is often very injurious to the interests of the class of labourers," and that "the opinion entertained by the labouring class, that the employment of machinery is frequently detrimental to their interests, is not founded on prejudice and error, but is conformable to the correct principles of political economy."

Ricardo himself was the first to recognize that comparative advantage is a domain-specific theory, meaning that it applies only when certain conditions are met. Ricardo noted that the theory applies only in situations where capital is immobile. Regarding his famous example, he wrote:"it would undoubtedly be advantageous to the capitalists [and consumers] of England… [that] the wine and cloth should both be made in Portugal [and that] the capital and labour of England employed in making cloth should be removed to Portugal for that purpose."Ricardo recognized that applying his theory in situations where capital was mobile would result in offshoring, and thereby economic decline and job loss. To correct for this, he argued that (i) "most men of property [will be] satisfied with a low rate of profits in their own country, rather than seek[ing] a more advantageous employment for their wealth in foreign nations," and (ii) that capital was functionally immobile.

Ricardo's argument in favour of free trade has also been attacked by those who believe trade restriction can be necessary for the economic development of a nation. Utsa Patnaik claims that Ricardian theory of international trade contains a logical fallacy. Ricardo assumed that in both countries two goods are producible and actually are produced, but developed and underdeveloped countries often trade those goods which are not producible in their own country. In these cases, one cannot define which country has comparative advantage.

Critics also argue that Ricardo's theory of comparative advantage is flawed in that it assumes production is continuous and absolute. In the real world, events outside the realm of human control (e.g. natural disasters) can disrupt production. In this case, specialisation could cripple a country that depends on imports from foreign, naturally disrupted countries. For example, if an industrially based country trades its manufactured goods with an agrarian country in exchange for agricultural products, a natural disaster in the agricultural country (e.g. drought) may cause the industrially based country to starve.

As Joan Robinson pointed out, following the opening of free trade with England, Portugal endured centuries of economic underdevelopment: "the imposition of free trade on Portugal killed off a promising textile industry and left her with a slow-growing export market for wine, while for England, exports of cotton cloth led to accumulation, mechanisation and the whole spiralling growth of the industrial revolution". Robinson argued that Ricardo's example required that economies be in static equilibrium positions with full employment and that there could not be a trade deficit or a trade surplus. These conditions, she wrote, were not relevant to the real world. She also argued that Ricardo's math did not take into account that some countries may be at different levels of development and that this raised the prospect of 'unequal exchange' which might hamper a country's development, as we saw in the case of Portugal.

The development economist Ha-Joon Chang challenges the argument that free trade benefits every country:
Another idea associated with Ricardo is Ricardian equivalence, an argument suggesting that in some circumstances a government's choice of how to pay for its spending ("i.e.," whether to use tax revenue or issue debt and run a deficit) might have no effect on the economy. This is due to the fact the public saves its excess money to pay for expected future tax increases that will be used to pay off the debt. Ricardo notes that the proposition is theoretically implied in the presence of intertemporal optimisation by rational tax-payers: but that since tax-payers do not act so rationally, the proposition fails to be true in practice. Thus, while the proposition bears his name, he does not seem to have believed it. Economist Robert Barro is responsible for its modern prominence.

David Ricardo's ideas had a tremendous influence on later developments in economics. US economists rank Ricardo as the second most influential economic thinker, behind Adam Smith, prior to the twentieth century.

Ricardo became the theoretical father of classical political economy. However, Schumpeter coined an expression "Ricardian vice", which indicates that rigorous logic does not provide a good economic theory. This criticism applies also to most neoclassical theories, which make heavy use of mathematics, but are, according to him, theoretically unsound, because the conclusion being drawn does not logically follow from the theories used to defend it.

Ricardo's writings fascinated a number of early socialists in the 1820s, who thought his value theory had radical implications. They argued that, in view of labour theory of value, labour produces the entire product, and the profits capitalists get are a result of exploitations of workers. These include Thomas Hodgskin, William Thompson, John Francis Bray, and Percy Ravenstone.

Georgists believe that rent, in the sense that Ricardo used, belongs to the community as a whole. Henry George was greatly influenced by Ricardo, and often cited him, including in his most famous work, "Progress and Poverty" from 1879. In the preface to the fourth edition he wrote: "What I have done in this book, if I have correctly solved the great problem I have sought to investigate, is, to unite the truth perceived by the school of Smith and Ricardo to the truth perceived by the school of Proudhon and Lasalle; to show that laissez faire (in its full true meaning) opens the way to a realization of the noble dreams of socialism; to identify social law with moral law, and to disprove ideas which in the minds of many cloud grand and elevating perceptions."

After the rise of the 'neoclassical' school, Ricardo's influence declined temporarily. It was Piero Sraffa, the editor of the Collected Works of David Ricardo and the author of seminal "Production of Commodities by Means of Commodities", who resurrected Ricardo as the originator of another strand of economic thought, which was effaced with the arrival of the neoclassical school. The new interpretation of Ricardo and Sraffa's criticism against the marginal theory of value gave rise to a new school, now named neo-Ricardian or Sraffian school. Major contributors to this school include Luigi Pasinetti (1930–), Pierangelo Garegnani (1930–2011), Ian Steedman (1941–), Geoffrey Harcourt (1931–), Heinz Kurz (1946–), Neri Salvadori (1951–), Pier Paolo Saviotti (–) among others. See also Neo-Ricardianism. The Neo-Ricardian school is sometimes seen to be a component of Post-Keynesian economics.

Inspired by Piero Sraffa, a new strand of trade theory emerged and was named neo-Ricardian trade theory. The main contributors include Ian Steedman and Stanley Metcalfe. They have criticised neoclassical international trade theory, namely the Heckscher–Ohlin model on the basis that the notion of capital as primary factor has no method of measuring it before the determination of profit rate (thus trapped in a logical vicious circle). This was a second round of the Cambridge capital controversy, this time in the field of international trade. Depoortère and Ravix judge that neo-Ricardian contribution failed without giving effective impact on neoclassical trade theory, because it could not offer "a genuine alternative approach from a classical point of view."

Several distinctive groups have sprung out of the neo-Ricardian school. One is the evolutionary growth theory, developed notably by Luigi Pasinetti, J.S. Metcalfe, Pier Paolo Saviotti, and Koen Frenken and others.

Pasinetti argued that the demand for any commodity came to stagnate and frequently decline, demand saturation occurs. Introduction of new commodities (goods and services) is necessary to avoid economic stagnation.

Ricardo's idea was even expanded to the case of continuum of goods by Dornbusch, Fischer, and Samuelson This formulation is employed for example by Matsuyama and others.

Ricardian trade theory ordinarily assumes that the labour is the unique input. This is a deficiency as intermediate goods occupies now a great part of international trade. The situation changed after the appearance of 's work of 2007. He has succeeded to incorporate traded input goods in his model.

Yeats found that 30% of world trade in manufacturing is intermediate inputs. Bardhan and Jafee found that intermediate inputs occupy 37 to 38% in the imports to the US for the years from 1992 to 1997, whereas the percentage of intrafirm trade grew from 43% in 1992 to 52% in 1997.

Chris Edward includes Emmanuel's unequal exchange theory among variations of neo-Ricardian trade theory. Arghiri Emmanuel argued that the Third World is poor because of the international exploitation of labour.

The unequal exchange theory of trade has been influential to the (new) dependency theory.

Ricardo's publications included:

His works and writings were collected in 




</doc>
<doc id="8471" url="https://en.wikipedia.org/wiki?curid=8471" title="Delphinus">
Delphinus

Delphinus (Pronounced or ) is a small constellation in the Northern Celestial Hemisphere, close to the celestial equator. Its name is the Latin version for the Greek word for dolphin (). It is one of the 48 constellations listed by the 2nd century astronomer Ptolemy, and remains one of the 88 modern constellations recognized by the International Astronomical Union. It is one of the smaller constellations, ranked 69th in size. Delphinus' five brightest stars form a distinctive asterism symbolizing a dolphin with four stars representing the body and one the tail. It is bordered (clockwise from north) by Vulpecula, Sagitta, Aquila, Aquarius, Equuleus and Pegasus.

Delphinus is a faint constellation with only two stars brighter than an apparent magnitude of 4, Beta Delphini (Rotanev) at magnitude 3.6 and Alpha Delphini with a magnitude of 3.8.

Delphinus is associated with two stories from Greek mythology.

According to the first Greek god Poseidon wanted to marry Amphitrite, a beautiful nereid. However, wanting to protect her virginity, she fled to the Atlas mountains. Her suitor then sent out several searchers, among them a certain Delphinus. Delphinus accidentally stumbled upon her and was able to persuade Amphitrite to accept Poseidon's wooing. Out of gratitude the god placed the image of a dolphin among the stars.

The second story tells of the Greek poet Arion of Lesbos (7th century BC), who was saved by a dolphin. He was a court musician at the palace of Periander, ruler of Corinth. Arion had amassed a fortune during his travels to Sicily and Italy. On his way home from Tarentum his wealth caused the crew of his ship to conspire against him. Threatened with death, Arion asked to be granted a last wish which the crew granted: he wanted to sing a dirge. This he did, and while doing so, flung himself into the sea. There, he was rescued by a dolphin which had been charmed by Arion's music. The dolphin carried Arion to the coast of Greece and left.

In Chinese astronomy, the stars of Delphinus are located within "the Black Tortoise of the North" (北方玄武, "Běi Fāng Xuán Wǔ").

In Polynesia, two cultures recognized Delphinus as a constellation. In Pukapuka, it was called "Te Toloa" and in the Tuamotus, it was called "Te Uru-o-tiki".

Delphinus is bordered by Vulpecula to the north, Sagitta to the northeast, Aquila to the east and southeast, Aquarius to the southwest, Equuleus to the west and Pegasus to the east. Covering 188.5 square degrees, corresponding to 0.457% of the sky, it ranks 69th of the 88 constellations in size. The three-letter abbreviation for the constellation, as adopted by the IAU in 1922, is "Del". The official constellation boundaries, as set by Eugène Delporte in 1930, are defined by a polygon of 14 segments. In the equatorial coordinate system, the right ascension coordinates of these borders lie between and , while the declination coordinates are between and . The whole constellation is visible to observers north of latitude 69°S.

Delphinus has two stars above fourth (apparent) magnitude; its brightest star is of magnitude 3.6. The main asterism in Delphinus is Job's Coffin, nearly a 45°-apex lozenge diamond of the four brightest stars: Alpha, Beta, Gamma, and Delta Delphini. Delphinus is in a rich Milky Way star field. Alpha and Beta Delphini have 19th century names Sualocin and Rotanev, read backwards: Nicolaus Venator, the Latinized name of a Palermo Observatory director, Niccolò Cacciatore (d. 1841).

Alpha Delphini is a blue-white hued main sequence star of magnitude 3.8, 241 light-years from Earth.

Beta Delphini, called Rotanev. The gap between its close binary stars is visible from large amateur telescopes. To the unaided eye, it appears to be a white star of magnitude 3.6. It has a period of 27 years and is 97 light-years from Earth.

Gamma Delphini is a celebrated binary star among amateur astronomers. The primary is orange-gold of magnitude 4.3; the secondary is a light yellow star of magnitude 5.1. The pair form a true binary with an estimated orbital period of over 3,000 years. 125 light-years away, the two components are visible in a small amateur telescope. The secondary, also described as green, is 10 arcseconds from the primary. Struve 2725, called the "Ghost Double", is a pair that appears similar but dimmer. Its components of magnitudes 7.6 and 8.4 are separated by 6 arcseconds and are 15 arcminutes from Gamma Delphini itself.

Delta Delphini is a type A7 IIIp star of magnitude 4.43.

Epsilon Delphini, Deneb Dulfim (lit. "tail [of the] Dolphin"), or Aldulfin, is a star of stellar class B6 III and magnitude 4, at 330 ly.

Zeta Delphini, blue-white main-sequence star of magnitude 4.6, was in 2014 discovered to have a brown dwarf orbiting around it. Zeta Delphini B has a mass of 50±15 .

In Delphinus, in extremes of distance, Gliese 795 is the closest known star at 54.95 ly and rapidly moves east over a period of centuries (863±3 arcseconds per year); whereas the giant of blue colour, W Delphini is at 2203.81 ly at 9.76 magnitude. Its brightness ranges from a magnitude of 12.3 to a magnitude of 9.7 over its variable period as it is a Beta Persei star-type semi-detached system. Other variable stars of large amateur telescopic visibility include R Delphini, a Mira-type variable star with a period of 285.5 days. Its magnitude ranges between a maximum 7.6 and a minimum 13.8.
Rho Aquilae at magnitude 4.94 is at about 150 light years. Due to its proper motion it has been in the (round-figure parameter) bounds of the constellation since 1992.

HR Delphini was a nova that brightened to magnitude 3.5 in December 1967. It took an unusually long time for the nova to reach peek brightness which indicate that it barely satisfied the conditions for a thermonuclear runaway. Another nova by the name V339 Delphini was detected in 2013; it peaked at magnitude 4.3 and was the first nova observed to produce lithium.

Musica, also known by its Flamsteed designation 18 Delphini, is one of the five stars with known planets located in Delphinus. Arion, the planet, is a very dense and massive planet with a mass at least 10.3 times greater than Jupiter. Arion was part of the first NameExoWorlds contest where the public got the opportunity to suggest names for exoplanets and their host stars.

Its rich Milky Way star field means many modestly deep-sky objects. NGC 6891 is a planetary nebula of magnitude 10.5; another is NGC 6905 or the Blue Flash nebula. NGC 6934 is a globular cluster of magnitude 9.75. At a distance of about 185,000 light-years, the globular cluster NGC 7006 is at the outer reaches of the galaxy. It is also fairly dim at magnitude 11.5.





</doc>
<doc id="8472" url="https://en.wikipedia.org/wiki?curid=8472" title="Disk storage">
Disk storage

Disk storage (also sometimes called drive storage) is a general category of storage mechanisms where data is recorded by various electronic, magnetic, optical, or mechanical changes to a surface layer of one or more rotating disks. A disk drive is a device implementing such a storage mechanism. Notable types are the hard disk drive (HDD) containing a non-removable disk, the floppy disk drive (FDD) and its removable floppy disk, and various optical disc drives (ODD) and associated optical disc media.

(The spelling disk and disc are used interchangeably except where trademarks preclude one usage, e.g. the Compact Disc logo. The choice of a particular form is frequently historical, as in IBM's usage of the "disk" form beginning in 1956 with the "IBM 350 disk storage unit").

Audio information was originally recorded by analog methods (see Sound recording and reproduction). Similarly the first video disc used an analog recording method. In the music industry, analog recording has been mostly replaced by digital optical technology where the data is recorded in a digital format with optical information.

The first commercial digital disk storage device was the IBM 350 which shipped in 1956 as a part of the IBM 305 RAMAC computing system. The random-access, low-density storage of disks was developed to complement the already used sequential-access, high-density storage provided by tape drives using magnetic tape. Vigorous innovation in disk storage technology, coupled with less vigorous innovation in tape storage, has reduced the difference in acquisition cost per terabyte between disk storage and tape storage; however, the total cost of ownership of data on disk including power and management remains larger than that of tape.

Disk storage is now used in both computer storage and consumer electronic storage, e.g., audio CDs and video discs (VCD, standard DVD and Blu-ray).

Data on modern disks is stored in fixed length blocks, usually called sectors and varying in length from a few hundred to many thousands of bytes. Gross disk drive capacity is simply the number of disk surfaces times the number of blocks/surface times the number of bytes/block. In certain legacy IBM CKD drives the data was stored on magnetic disks with variable length blocks, called records; record length could vary on and between disks. Capacity decreased as record length decreased due to the necessary gaps between blocks.

Digital disk drives are block storage devices. Each disk is divided into logical blocks (collection of sectors). Blocks are addressed using their logical block addresses (LBA). Read from or writing to disk happens at the granularity of blocks.

Originally the disk capacity was quite low and has been improved in one of several ways. Improvements in mechanical design and manufacture allowed smaller and more precise heads, meaning that more tracks could be stored on each of the disks. Advancements in data compression methods permitted more information to be stored in each of the individual sectors.

The drive stores data onto cylinders, heads, and sectors. The sectors unit is the smallest size of data to be stored in a hard disk drive and each file will have many sectors units assigned to it. The smallest entity in a CD is called a frame, which consists of 33 bytes and contains six complete 16-bit stereo samples (two bytes × two channels × six samples = 24 bytes). The other nine bytes consist of eight CIRC error-correction bytes and one subcode byte used for control and display.

The information is sent from the computer processor to the BIOS into a chip controlling the data transfer. This is then sent out to the hard drive via a multi-wire connector. Once the data is received onto the circuit board of the drive, they are translated and compressed into a format that the individual drive can use to store onto the disk itself. The data is then passed to a chip on the circuit board that controls the access to the drive. The drive is divided into sectors of data stored onto one of the sides of one of the internal disks. An HDD with two disks internally will typically store data on all four surfaces.

The hardware on the drive tells the actuator arm where it is to go for the relevant track and the compressed information is then sent down to the head which changes the physical properties, optically or magnetically for example, of each byte on the drive, thus storing the information. A file is not stored in a linear manner, rather, it is held in the best way for quickest retrieval.

Mechanically there are two different motions occurring inside the drive. One is the rotation of the disks inside the device. The other is the side-to-side motion of the head across the disk as it moves between tracks.

There are two types of disk rotation methods:

Track positioning also follows two different methods across disk storage devices. Storage devices focused on holding computer data, e.g., HDDs, FDDs, Iomega zip drives, use concentric tracks to store data. During a sequential read or write operation, after the drive accesses all the sectors in a track it repositions the head(s) to the next track. This will cause a momentary delay in the flow of data between the device and the computer. In contrast, optical audio and video discs use a single spiral track that starts at the inner most point on the disc and flows continuously to the outer edge. When reading or writing data there is no need to stop the flow of data to switch tracks. This is similar to vinyl records except vinyl records started at the outer edge and spiraled in toward the center.

The disk drive interface is the mechanism/protocol of communication between the rest of the system and the disk drive itself. Storage devices intended for desktop and mobile computers typically use ATA (PATA) and SATA interfaces. Enterprise systems and high-end storage devices will typically use SCSI, SAS, and FC interfaces in addition to some use of SATA.





</doc>
<doc id="8474" url="https://en.wikipedia.org/wiki?curid=8474" title="Arthur Wellesley, 1st Duke of Wellington">
Arthur Wellesley, 1st Duke of Wellington

Arthur Wellesley, 1st Duke of Wellington (1 May 1769 – 14 September 1852) was an Anglo-Irish soldier and Tory statesman who was one of the leading military and political figures of 19th-century Britain, serving twice as prime minister. He ended the Napoleonic Wars when he defeated Napoleon at the Battle of Waterloo in 1815.

Wellesley was born in Dublin into the Protestant Ascendancy in Ireland. He was commissioned as an ensign in the British Army in 1787, serving in Ireland as aide-de-camp to two successive lords lieutenant of Ireland. He was also elected as a member of Parliament in the Irish House of Commons. He was a colonel by 1796 and saw action in the Netherlands and in India, where he fought in the Fourth Anglo-Mysore War at the Battle of Seringapatam. He was appointed governor of Seringapatam and Mysore in 1799 and, as a newly appointed major-general, won a decisive victory over the Maratha Confederacy at the Battle of Assaye in 1803.

Wellesley rose to prominence as a general during the Peninsular campaign of the Napoleonic Wars, and was promoted to the rank of field marshal after leading the allied forces to victory against the French Empire at the Battle of Vitoria in 1813. Following Napoleon's exile in 1814, he served as the ambassador to France and was granted a dukedom. During the Hundred Days in 1815, he commanded the allied army which, together with a Prussian Army under Blücher, defeated Napoleon at Waterloo. Wellington's battle record is exemplary; he ultimately participated in some 60 battles during the course of his military career.

Wellington is famous for his adaptive defensive style of warfare, resulting in several victories against numerically superior forces while minimising his own losses. He is regarded as one of the greatest defensive commanders of all time, and many of his tactics and battle plans are still studied in military academies around the world. After the end of his active military career, he returned to politics. He was twice British prime minister as a member of the Tory party from 1828 to 1830 and for a little less than a month in 1834. He oversaw the passage of the Roman Catholic Relief Act 1829, but opposed the Reform Act 1832. He continued as one of the leading figures in the House of Lords until his retirement and remained Commander-in-Chief of the British Army until his death.
Wellesley was born into an aristocratic Anglo-Irish family in Ireland as The Hon. Arthur Wesley, the third of five surviving sons (fourth otherwise) of Anne and Garret Wesley, 1st Earl of Mornington. His mother was the eldest daughter of Arthur Hill-Trevor, 1st Viscount Dungannon, after whom Wellesley was named. As such, he belonged to the Protestant Ascendancy. His biographers mostly follow the same contemporary newspaper evidence in saying that he was born on 1 May 1769, the day before he was baptised. His birthplace is uncertain. He was most likely born at his parents' townhouse, 24 Upper Merrion Street, Dublin, now the Merrion Hotel. But his mother Anne, Countess of Mornington, recalled in 1815 that he had been born at 6 Merrion Street, Dublin. Other places have been put forward as the location of his birth, including Mornington House (the house next door on Upper Merrion), as his father had asserted; the Dublin packet boat; and the mansion in the family estate of Athy (consumed in the fires of 1916), as the Duke apparently put on his 1851 census return.

He spent most of his childhood at his family's two homes, the first a large house in Dublin and the second Dangan Castle, north of Summerhill on the Trim Road (now the R158) in County Meath. In 1781, Arthur's father died and his eldest brother Richard inherited his father's earldom.

He went to the diocesan school in Trim when at Dangan, Mr Whyte's Academy when in Dublin, and Brown's School in Chelsea when in London. He then enrolled at Eton College, where he studied from 1781 to 1784. His loneliness there caused him to hate it, and makes it highly unlikely that he actually said "The Battle of Waterloo was won on the playing fields of Eton", a quotation which is often attributed to him. Moreover, Eton had no playing fields at the time. In 1785, a lack of success at Eton, combined with a shortage of family funds due to his father's death, forced the young Wellesley and his mother to move to Brussels. Until his early twenties, Arthur showed little sign of distinction and his mother grew increasingly concerned at his idleness, stating, "I don't know what I shall do with my awkward son Arthur."

A year later, Arthur enrolled in the French Royal Academy of Equitation in Angers, where he progressed significantly, becoming a good horseman and learning French, which later proved very useful. Upon returning to England in late 1786, he astonished his mother with his improvement.

Despite his new promise, he had yet to find a job and his family was still short of money, so upon the advice of his mother, his brother Richard asked his friend the Duke of Rutland (then Lord Lieutenant of Ireland) to consider Arthur for a commission in the Army. Soon afterward, on 7 March 1787, he was gazetted ensign in the 73rd Regiment of Foot. In October, with the assistance of his brother, he was assigned as "aide-de-camp", on ten shillings a day (twice his pay as an ensign), to the new Lord Lieutenant of Ireland, Lord Buckingham. He was also transferred to the new 76th Regiment forming in Ireland and on Christmas Day, 1787, was promoted lieutenant. During his time in Dublin his duties were mainly social; attending balls, entertaining guests and providing advice to Buckingham. While in Ireland, he overextended himself in borrowing due to his occasional gambling, but in his defence stated that "I have often known what it was to be in want of money, but I have never got helplessly into debt".

On 23 January 1788, he transferred into the 41st Regiment of Foot, then again on 25 June 1789, still a lieutenant, he transferred to the 12th (Prince of Wales's) Regiment of (Light) Dragoons and, according to military historian Richard Holmes, he also dipped a reluctant toe into politics. Shortly before the general election of 1789, he went to the rotten borough of Trim to speak against the granting of the title "Freeman" of Dublin to the parliamentary leader of the Irish Patriot Party, Henry Grattan. Succeeding, he was later nominated and duly elected as a Member of Parliament (MP) for Trim in the Irish House of Commons. Because of the limited suffrage at the time, he sat in a parliament where at least two-thirds of the members owed their election to the landowners of fewer than a hundred boroughs. Wellesley continued to serve at Dublin Castle, voting with the government in the Irish parliament over the next two years. He became a captain on 30 January 1791, and was transferred to the 58th Regiment of Foot.

On 31 October, he transferred to the 18th Light Dragoons and it was during this period that he grew increasingly attracted to Kitty Pakenham, the daughter of Edward Pakenham, 2nd Baron Longford. She was described as being full of 'gaiety and charm'. In 1793, he sought her hand, but was turned down by her brother Thomas, Earl of Longford, who considered Wellesley to be a young man, in debt, with very poor prospects. An aspiring amateur musician, Wellesley, devastated by the rejection, burnt his violins in anger, and resolved to pursue a military career in earnest. He became a major by purchase in the 33rd Regiment in 1793. A few months later, in September, his brother lent him more money and with it he purchased a lieutenant-colonelcy in the 33rd.

In 1793, the Duke of York was sent to Flanders in command of the British contingent of an allied force destined for the invasion of France. In June 1794, Wellesley with the 33rd regiment set sail from Cork bound for Ostend as part of an expedition bringing reinforcements for the army in Flanders. They arrived too late and joined the Duke of York as he was pulling back towards the Netherlands. On 15 September 1794, at the Battle of Boxtel, east of Breda, Wellington, in temporary command of his brigade, had his first experience of battle. During General Abercromby's withdrawal in the face of superior French forces, the 33rd held off enemy cavalry, allowing neighbouring units to retreat safely. During the extremely harsh winter that followed, Wellesley and his regiment formed part of an allied force holding the defence line along the Waal River. The 33rd, along with the rest of the army, suffered heavy losses from sickness and exposure. Wellesley's health was also affected by the damp environment. Though the campaign was to end disastrously, with the British army driven out of the United Provinces into Germany, Wellesley was to learn several valuable lessons, including the use of steady lines of infantry against advancing columns and of the merits of supporting sea-power. He understood that the failure of the campaign was due in part to the faults of the leaders and the poor organisation at headquarters. He remarked later of his time in the Netherlands that "At least I learned what not to do, and that is always a valuable lesson".

Returning to England in March 1795, he was returned as a member of parliament for Trim for a second time. He hoped to be given the position of secretary of war in the new Irish government but the new lord-lieutenant, Lord Camden, was only able to offer him the post of Surveyor-General of the Ordnance. Declining the post, he returned to his regiment, now at Southampton preparing to set sail for the West Indies. After seven weeks at sea, a storm forced the fleet back to Poole. The 33rd was given time to recuperate and a few months later, Whitehall decided to send the regiment to India. Wellesley was promoted full colonel by seniority on 3 May 1796 and a few weeks later set sail for Calcutta with his regiment.

Arriving in Calcutta in February 1797 he spent several months there, before being sent on a brief expedition to the Philippines, where he established a list of new hygiene precautions for his men to deal with the unfamiliar climate. Returning in November to India, he learnt that his elder brother Richard, now known as Lord Mornington, had been appointed as the new Governor-General of India.

In 1798, he changed the spelling of his surname to "Wellesley"; up to this time he was still known as Wesley, which his eldest brother considered the ancient and proper spelling.

As part of the campaign to extend the rule of the British East India Company, the Fourth Anglo-Mysore War broke out in 1798 against the Sultan of Mysore, Tipu Sultan. Arthur's brother Richard ordered that an armed force be sent to capture Seringapatam and defeat Tipu. Under the command of General Harris, some 24,000 troops were dispatched to Madras (to join an equal force being sent from Bombay in the west). Arthur and the 33rd sailed to join them in August.

After extensive and careful logistic preparation (which would become one of Wellesley's main attributes) the 33rd left with the main force in December and travelled across of jungle from Madras to Mysore. On account of his brother, during the journey, Wellesley was given an additional command, that of chief advisor to the Nizam of Hyderabad's army (sent to accompany the British force). This position was to cause friction among many of the senior officers (some of whom were senior to Wellesley). Much of this friction was put to rest after the Battle of Mallavelly, some from Seringapatam, in which Harris's army attacked a large part of the sultan's army. During the battle, Wellesley led his men, in a line of battle of two ranks, against the enemy to a gentle ridge and gave the order to fire. After an extensive repetition of volleys, followed by a bayonet charge, the 33rd, in conjunction with the rest of Harris's force, forced Tipu's infantry to retreat.

Immediately after their arrival at Seringapatam on 5 April 1799, the Battle of Seringapatam began and Wellesley was ordered to lead a night attack on the village of Sultanpettah, adjacent to the fortress to clear the way for the artillery. Because of the enemy's strong defensive preparations, and the darkness, with the resulting confusion, the attack failed with 25 casualties. Wellesley suffered a minor injury to his knee from a spent musket-ball. Although they would re-attack successfully the next day, after time to scout ahead the enemy's positions, the affair affected Wellesley. He resolved "never to attack an enemy who is preparing and strongly posted, and whose posts have not been reconnoitered by daylight".

Lewin Bentham Bowring gives this alternative account:

A few weeks later, after extensive artillery bombardment, a breach was opened in the main walls of the fortress of Seringapatam. An attack led by Major-General Baird secured the fortress. Wellesley secured the rear of the advance, posting guards at the breach and then stationed his regiment at the main palace. After hearing news of the death of the Tipu Sultan, Wellesley was the first at the scene to confirm his death, checking his pulse. Over the coming day, Wellesley grew increasingly concerned over the lack of discipline among his men, who drank and pillaged the fortress and city. To restore order, several soldiers were flogged and four hanged.

After battle and the resulting end of the war, the main force under General Harris left Seringapatam and Wellesley, aged 30, stayed behind to command the area as the new Governor of Seringapatam and Mysore. While in India, Wellesley was ill for a considerable time, first with severe diarrhoea from the water and then with fever, followed by a serious skin infection caused by trichophyton.

Wellesley was in charge of raising an Anglo-Indian expeditionary force in Trincomali in early 1801 for the capture of Batavia and Mauritius from the French. However, on the eve of its departure, orders arrived from England that it was to be sent to Egypt to co-operate with Sir Ralph Abercromby in the expulsion of the French from Egypt. Wellesley had been appointed second in command to Baird, but owing to ill-health did not accompany the expedition on 9 April 1801. This turned out fortunately for Wellesley, since the very vessel on which he was to have sailed foundered with all hands in the Red Sea.

He was promoted to brigadier-general on 17 July 1801. He took residence within the Sultan's summer palace and reformed the tax and justice systems in his province to maintain order and prevent bribery. He also hunted down the mercenary and self-proclaimed 'King' Dhoondiah Waugh, who had escaped from prison in Seringapatam during the battle.

In 1800, whilst serving as Governor of Mysore, Wellesley was tasked with putting down an insurgency led by Dhoondiah Waugh, formerly a Patan trooper for Tipu Sultan. After the fall of Seringapatam he became a powerful brigand, raiding villages along the Maratha–Mysore border region. Despite initial setbacks, the East India Company having pursued and destroyed his forces once already, forcing him into retreat in August 1799, he raised a sizeable force composed of disbanded Mysore soldiers, captured small outposts and forts in Mysore, and was receiving the support of several Maratha "killedars" opposed to British occupation. This drew the attention of the British administration, who were beginning to recognise him as more than just a bandit, as his raids, expansion and threats to destabilise British authority suddenly increased in 1800. The death of Tipu Sultan had created a power vacuum and Waugh was seeking to fill it.

Given independent command of a combined East India Company and British Army force, Wellesley ventured north to confront Waugh in June 1800, with an army of 8,000 infantry and cavalry, having learned that Waugh's forces numbered over 50,000, although the majority (around 30,000) were irregular light cavalry and unlikely to pose a serious threat to British infantry and artillery.

Throughout June–August 1800, Wellesley advanced through Waugh's territory, his troops escalading forts in turn and capturing each one with "trifling loss". The forts generally offered little resistance due to their poor construction and design. Wellesley did not have sufficient troops to garrison each fort, and had to clear the surrounding area of insurgents before advancing to the next fort. On 31 July, he had "taken and destroyed Dhoondiah's baggage and six guns, and driven into the Malpoorba (where they were drowned) about five thousand people". Dhoondiah continued to retreat, but his forces were rapidly deserting, he had no infantry and due to the monsoon weather flooding river crossings he could no longer outpace the British advance. On 10 September, at the Battle of Conaghul, Wellesley personally led a charge of 1,400 British dragoons and Indian cavalry, in single line with no reserve, against Dhoondiah and his remaining 5,000 cavalry. Dhoondiah was killed during the clash, his body was discovered and taken to the British camp tied to a cannon. With this victory Wellesley's campaign was concluded, and British authority had been restored.

Wellesley, with command of four regiments, had defeated Dhoondiah's larger rebel force, along with Dhoondiah himself, who was killed in the final battle. Wellesley then paid for the future upkeep of Dhoondiah's orphaned son.

In September 1802, Wellesley learnt that he had been promoted to the rank of major-general. He had been gazetted on 29 April 1802, but the news took several months to reach him by sea. He remained at Mysore until November when he was sent to command an army in the Second Anglo-Maratha War.

When he determined that a long defensive war would ruin his army, Wellesley decided to act boldly to defeat the numerically larger force of the Maratha Empire. With the logistic assembly of his army complete (24,000 men in total) he gave the order to break camp and attack the nearest Maratha fort on 8 August 1803. The fort surrendered on 12 August after an infantry attack had exploited an artillery-made breach in the wall. With the fort now in British control Wellesley was able to extend control southwards to the river Godavari.

Splitting his army into two forces, to pursue and locate the main Marathas army, (the second force, commanded by Colonel Stevenson was far smaller) Wellesley was preparing to rejoin his forces on 24 September. His intelligence, however, reported the location of the Marathas' main army, between two rivers near Assaye. If he waited for the arrival of his second force, the Marathas would be able to mount a retreat, so Wellesley decided to launch an attack immediately.

On 23 September, Wellesley led his forces over a ford in the river Kaitna and the Battle of Assaye commenced. After crossing the ford the infantry was reorganised into several lines and advanced against the Maratha infantry. Wellesley ordered his cavalry to exploit the flank of the Maratha army just near the village. During the battle Wellesley himself came under fire; two of his horses were shot from under him and he had to mount a third. At a crucial moment, Wellesley regrouped his forces and ordered Colonel Maxwell (later killed in the attack) to attack the eastern end of the Maratha position while Wellesley himself directed a renewed infantry attack against the centre.

An officer in the attack wrote of the importance of Wellesley's personal leadership: "The General was in the thick of the action the whole time ... I never saw a man so cool and collected as he was ... though I can assure you, 'til our troops got the order to advance the fate of the day seemed doubtful ..." With some 6,000 Marathas killed or wounded, the enemy was routed, though Wellesley's force was in no condition to pursue. British casualties were heavy: the British losses were counted as 409 soldiers being killed out of which 164 were Europeans and the remaining 245 were Indian; a further 1,622 British soldiers were wounded and 26 soldiers were reported missing (the British casualty figures were taken from Wellesley's own despatch). Wellesley was troubled by the loss of men and remarked that he hoped "I should not like to see again such loss as I sustained on 23 September, even if attended by such gain". Years later, however, he remarked that Assaye, and not Waterloo, was the best battle he ever fought.

Despite the damage done to the Maratha army, the battle did not end the war. A few months later in November, Wellesley attacked a larger force near Argaum, leading his army to victory again, with an astonishing 5,000 enemy dead at the cost of only 361 British casualties. A further successful attack at the fortress at Gawilghur, combined with the victory of General Lake at Delhi forced the Maratha to sign a peace settlement at Anjangaon (not concluded until a year later) called the Treaty of Surji-Anjangaon.

Military historian Richard Holmes remarked that Wellesley's experiences in India had an important influence on his personality and military tactics, teaching him much about military matters that would prove vital to his success in the Peninsular War. These included a strong sense of discipline through drill and order, the use of diplomacy to gain allies, and the vital necessity for a secure supply line. He also established a high regard for the acquisition of intelligence through scouts and spies. His personal tastes also developed, including dressing himself in white trousers, a dark tunic, with Hessian boots and black cocked hat (that later became synonymous as his style).

Wellesley had grown tired of his time in India, remarking "I have served as long in India as any man ought who can serve anywhere else". In June 1804 he applied for permission to return home and as a reward for his service in India he was made a Knight of the Bath in September. While in India, Wellesley had amassed a fortune of £42,000 (considerable at the time), consisting mainly of prize money from his campaign. When his brother's term as Governor-General of India ended in March 1805, the brothers returned together to England on HMS "Howe". Arthur, coincidentally, stopped on his voyage at the little island of Saint Helena and stayed in the same building to which Napoleon I would later be exiled.

In September 1805, Major-General Wellesley was newly returned from his campaigns in India and was not yet particularly well known to the public. He reported to the office of the Secretary for War to request a new assignment. In the waiting room, he met Vice-Admiral Horatio Nelson, already a legendary figure after his victories at the Nile and Copenhagen, who was briefly in England after months chasing the French Toulon fleet to the West Indies and back. Some 30 years later, Wellington recalled a conversation that Nelson began with him which Wellesley found "almost all on his side in a style so vain and silly as to surprise and almost disgust me". Nelson left the room to inquire who the young general was and, on his return, switched to a very different tone, discussing the war, the state of the colonies, and the geopolitical situation as between equals. On this second discussion, Wellington recalled, "I don't know that I ever had a conversation that interested me more". This was the only time that the two men met; Nelson was killed at his great victory at Trafalgar just seven weeks later.

Wellesley then served in the abortive Anglo-Russian expedition to north Germany in 1805, taking a brigade to Elbe.

He then took a period of extended leave from the army and was elected as a Tory member of the British parliament for Rye in January 1806. A year later, he was elected MP for Newport on the Isle of Wight and was then appointed to serve as Chief Secretary for Ireland, under the Duke of Richmond. At the same time, he was made a privy counsellor. While in Ireland, he gave a verbal promise that the remaining Penal Laws would be enforced with great moderation, perhaps an indication of his later willingness to support Catholic Emancipation.

Wellesley was in Ireland in May 1807 when he heard of the British expedition to Denmark. He decided to go, while maintaining his political appointments and was appointed to command an infantry brigade in the Second Battle of Copenhagen which took place in August. He fought at the Køge, during which the men under his command took 1,500 prisoners, with Wellesley later present during the surrender.

By 30 September, he had returned to England and was raised to the rank of lieutenant general on 25 April 1808. In June 1808 he accepted the command of an expedition of 9,000 men. Preparing to sail for an attack on the Spanish colonies in South America (to assist the Latin American patriot Francisco de Miranda) his force was instead ordered to sail for Portugal, to take part in the Peninsular Campaign and rendezvous with 5,000 troops from Gibraltar.

Ready for battle, Wellesley left Cork on 12 July 1808 to participate in the war against French forces in the Iberian Peninsula, with his skills as a commander tested and developed. According to the historian Robin Neillands, "Wellesley had by now acquired the experience on which his later successes were founded. He knew about command from the ground up, about the importance of logistics, about campaigning in a hostile environment. He enjoyed political influence and realised the need to maintain support at home. Above all, he had gained a clear idea of how, by setting attainable objectives and relying on his own force and abilities, a campaign could be fought and won."

Wellesley defeated the French at the Battle of Roliça and the Battle of Vimeiro in 1808 but was superseded in command immediately after the latter battle. General Dalrymple then signed the controversial Convention of Sintra, which stipulated that the Royal Navy transport the French army out of Lisbon with all their loot, and insisted on the association of the only available government minister, Wellesley.
Dalrymple and Wellesley were recalled to Britain to face a Court of Enquiry. Wellesley had agreed to sign the preliminary armistice, but had not signed the convention, and was cleared.

Meanwhile, Napoleon himself entered Spain with his veteran troops to put down the revolt; the new commander of the British forces in the Peninsula, Sir John Moore, died during the Battle of Corunna in January 1809.

Although overall the land war with France was not going well from a British perspective, the Peninsula was the one theatre where they, with the Portuguese, had provided strong resistance against France and her allies. This contrasted with the disastrous Walcheren expedition, which was typical of the mismanaged British operations of the time. Wellesley submitted a memorandum to Lord Castlereagh on the defence of Portugal. He stressed its mountainous frontiers and advocated Lisbon as the main base because the Royal Navy could help to defend it. Castlereagh and the cabinet approved the memo and appointed him head of all British forces in Portugal.

Wellesley arrived in Lisbon on 22 April 1809 on board HMS "Surveillante", after narrowly escaping shipwreck. Reinforced, he took to the offensive. In the Second Battle of Porto he crossed the Douro river in a daylight "coup de main", and routed Marshal Soult's French troops in Porto.

With Portugal secured, Wellesley advanced into Spain to unite with General Cuesta's forces. The combined allied force prepared for an assault on Marshal Victor's I Corps at Talavera, 23 July. Cuesta, however, was reluctant to agree, and was only persuaded to advance on the following day. The delay allowed the French to withdraw, but Cuesta sent his army headlong after Victor, and found himself faced by almost the entire French army in New Castile—Victor had been reinforced by the Toledo and Madrid garrisons. The Spanish retreated precipitously, necessitating the advance of two British divisions to cover their retreat.

The next day, 27 July, at the Battle of Talavera the French advanced in three columns and were repulsed several times throughout the day by Wellesley, but at a heavy cost to the British force. In the aftermath Marshal Soult's army was discovered to be advancing south, threatening to cut Wellesley off from Portugal. Wellesley moved east on 3 August to block it, leaving 1,500 wounded in the care of the Spanish, intending to confront Soult before finding out that the French were in fact 30,000 strong. The British commander sent the Light Brigade on a dash to hold the bridge over the Tagus at Almaraz. With communications and supply from Lisbon secured for now, Wellesley considered joining with Cuesta again but found out that his Spanish ally had abandoned the British wounded to the French and was thoroughly uncooperative, promising and then refusing to supply the British forces, aggravating Wellesley and causing considerable friction between the British and their Spanish allies. The lack of supplies, coupled with the threat of French reinforcement (including the possible inclusion of Napoleon himself) in the spring, led to the British deciding to retreat into Portugal.

Following his victory at Talavera, Wellesley was elevated to the Peerage of the United Kingdom on 26 August 1809 as Viscount Wellington of Talavera and of Wellington, in the County of Somerset, with the subsidiary title of Baron Douro of Wellesley.

In 1810, a newly enlarged French army under Marshal André Masséna invaded Portugal. British opinion both at home and in the army was negative and there were suggestions that they must evacuate Portugal. Instead, Lord Wellington first slowed the French down at Buçaco; he then prevented them from taking the Lisbon Peninsula by the construction of his massive earthworks, the Lines of Torres Vedras, which had been assembled in complete secrecy and had flanks guarded by the Royal Navy. The baffled and starving French invasion forces retreated after six months. Wellington's pursuit was frustrated by a series of reverses inflicted by Marshal Ney in a much-lauded rear guard campaign.

In 1811, Masséna returned toward Portugal to relieve Almeida; Wellington narrowly checked the French at the Battle of Fuentes de Onoro. Simultaneously, his subordinate, Viscount Beresford, fought Soult's 'Army of the South' to a mutual bloody standstill at the Battle of Albuera in May. Wellington was promoted to full general on 31 July for his services. The French abandoned Almeida, slipping away from British pursuit, but retained the twin Spanish fortresses of Ciudad Rodrigo and Badajoz, the 'Keys' guarding the roads through the mountain passes into Portugal.

In 1812, Wellington finally captured Ciudad Rodrigo by a rapid movement as the French went into winter quarters, storming it before they could react. He then moved south quickly, besieged the fortress of Badajoz for a month and captured it during one bloody night. On viewing the aftermath of the Storming of Badajoz, Wellington lost his composure and cried at the sight of the bloody carnage in the breaches.

His army now was a veteran British force reinforced by units of the retrained Portuguese army. Campaigning in Spain, he routed the French at the Battle of Salamanca, taking advantage of a minor French mispositioning. The victory liberated the Spanish capital of Madrid. As a reward, he was created Earl of Wellington, in the county of Somerset on 22 February 1812, and then Marquess of Wellington, in the said county on 18 August 1812, and given command of all Allied armies in Spain.

Wellington attempted to take the vital fortress of Burgos, which linked Madrid to France. But failure, due in part to a lack of siege guns, forced him into a headlong retreat with the loss of over 2,000 casualties.

The French abandoned Andalusia, and combined the troops of Soult and Marmont. Thus combined, the French outnumbered the British, putting the British forces in a precarious position. Wellington withdrew his army and, joined with the smaller corps commanded by Rowland Hill, began to retreat to Portugal. Marshal Soult declined to attack.

In 1813, Wellington led a new offensive, this time against the French line of communications. He struck through the hills north of Burgos, the Tras os Montes, and switched his supply line from Portugal to Santander on Spain's north coast; this led to the French abandoning Madrid and Burgos. Continuing to outflank the French lines, Wellington caught up with and smashed the army of King Joseph Bonaparte in the Battle of Vitoria, for which he was promoted to field marshal on 21 June. He personally led a column against the French centre, while other columns commanded by Sir Thomas Graham, Rowland Hill and the Earl of Dalhousie looped around the French right and left (this battle became the subject of Beethoven's orchestral piece, the "Wellington's Victory" (Opus 91). The British troops broke ranks to loot the abandoned French wagons instead of pursuing the beaten foe. This gross abandonment of discipline caused an enraged Wellington to write in a famous dispatch to Earl Bathurst, "We have in the service the scum of the earth as common soldiers".

Although later, when his temper had cooled, he extended his comment to praise the men under his command saying that though many of the men were, "the scum of the earth; it is really wonderful that we should have made them to the fine fellows they are".

After taking the small fortresses of Pamplona, Wellington invested San Sebastián but was frustrated by the obstinate French garrison, losing 693 dead and 316 captured in a failed assault and suspending the siege at the end of July. Soult's relief attempt was blocked by the Spanish Army of Galicia at San Marcial, allowing the Allies to consolidate their position and tighten the ring around the city, which fell in September after a second spirited defence. Wellington then forced Soult's demoralised and battered army into a fighting retreat into France, punctuated by battles at the Pyrenees, Bidassoa and Nivelle. Wellington invaded southern France, winning at the Nive and Orthez. Wellington's final battle against his rival Soult occurred at Toulouse, where the Allied divisions were badly mauled storming the French redoubts, losing some 4,600 men. Despite this momentary victory, news arrived of Napoleon's defeat and abdication and Soult, seeing no reason to continue the fighting, agreed on a ceasefire with Wellington, allowing Soult to evacuate the city.

Hailed as the conquering hero by the British, on 3 May 1814 Wellington was made Duke of Wellington, in the county of Somerset, together with the subsidiary title of Marquess Douro, in the said County.

He received some recognition during his lifetime (the title of "Duque de Ciudad Rodrigo" and "Grandee of Spain") and the Spanish King Ferdinand VII allowed him to keep part of the works of art from the Royal Collection which he had recovered from the French. His equestrian portrait features prominently in the Monument to the Battle of Vitoria, in present-day Vitoria-Gasteiz.

His popularity in Britain was due to his image and his appearance as well as to his military triumphs. His victory fitted well with the passion and intensity of the Romantic movement, with its emphasis on individuality. His personal style influenced the fashions on Britain at the time: his tall, lean figure and his plumed black hat and grand yet classic uniform and white trousers became very popular.

In late 1814, the Prime Minister wanted him to take command in Canada and with the assignment of winning the War of 1812 against the United States. Wellesley replied that he would go to America, but he believed that he was needed more in Europe. He stated:

He was appointed Ambassador to France, then took Lord Castlereagh's place as first plenipotentiary to the Congress of Vienna, where he strongly advocated allowing France to keep its place in the European balance of power. On 2 January 1815 the title of his Knighthood of the Bath was converted to Knight Grand Cross upon the expansion of that order.

On 26 February 1815, Napoleon escaped from Elba and returned to France. He regained control of the country by May and faced a renewed alliance against him. Wellington left Vienna for what became known as the Waterloo Campaign. He arrived in the Netherlands to take command of the British-German army and their allied Dutch, all stationed alongside the Prussian forces of Generalfeldmarschall Gebhard Leberecht von Blücher.

Napoleon's strategy was to isolate the Allied and Prussian armies and annihilate each one separately before the Austrians and Russians arrived. In doing so the vast superiority in numbers of the Coalition would be greatly diminished. He would then seek the possibility of peace with Austria and Russia.

The French invaded the Netherlands, with Napoleon defeating the Prussians at Ligny, and Marshal Ney engaging indecisively with Wellington at the Battle of Quatre Bras. The Prussians retreated 18 miles north to Wavre whilst Wellington's Anglo-Allied army withdrew 15 miles north to a site he had noted the previous year as favourable for a battle: the north ridge of a shallow valley on the Brussels road, just south of the small town of Waterloo. On 17 June there was torrential rain, which severely hampered movement and had a considerable effect the next day, 18 June, when the Battle of Waterloo was fought. This was the first time Wellington had encountered Napoleon; he commanded an Anglo-Dutch-German army that consisted of approximately 73,000 troops, 26,000 of whom were British. Approximately 30 percent of that 26,000 were Irish.

The Battle of Waterloo commenced with a diversionary attack on Hougoumont by a division of French soldiers. After a barrage of 80 cannons, the first French infantry attack was launched by Comte D'Erlon's I Corps. D'Erlon's troops advanced through the Allied centre, resulting in Allied troops in front of the ridge retreating in disorder through the main position. D'Erlon's corps stormed the most fortified Allied position, La Haye Sainte, but failed to take it. An Allied division under Thomas Picton met the remainder of D'Erlon's corps head to head, engaging them in an infantry duel in which Picton fell. During this struggle Lord Uxbridge launched two of his cavalry brigades at the enemy, catching the French infantry off guard, driving them to the bottom of the slope, and capturing two French Imperial Eagles. The charge, however, over-reached itself, and the British cavalry, crushed by fresh French horsemen hurled at them by Napoleon, were driven back, suffering tremendous losses.

A little before 16:00, Marshal Ney noted an apparent exodus from Wellington's centre. He mistook the movement of casualties to the rear for the beginnings of a retreat, and sought to exploit it. Ney at this time had few infantry reserves left, as most of the infantry had been committed either to the futile Hougoumont attack or to the defence of the French right. Ney therefore tried to break Wellington's centre with a cavalry charge alone.

At about 16:30, the first Prussian corps arrived. Commanded by Freiherr von Bülow, IV Corps arrived as the French cavalry attack was in full spate. Bülow sent the 15th Brigade to link up with Wellington's left flank in the Frichermont–La Haie area while the brigade's horse artillery battery and additional brigade artillery deployed to its left in support. Napoleon sent Lobau's corps to intercept the rest of Bülow's IV Corps proceeding to Plancenoit. The 15th Brigade sent Lobau's corps into retreat to the Plancenoit area. Von Hiller's 16th Brigade also pushed forward with six battalions against Plancenoit. Napoleon had dispatched all eight battalions of the Young Guard to reinforce Lobau, who was now seriously pressed by the enemy. Napoleon's Young Guard counter-attacked and, after very hard fighting, secured Plancenoit, but were themselves counter-attacked and driven out. Napoleon then resorted to sending two battalions of the Middle and Old Guard into Plancenoit and after ferocious fighting they recaptured the village.
The French cavalry attacked the British infantry squares many times, each at a heavy cost to the French but with few British casualties. Ney himself was displaced from his horse four times. Eventually, it became obvious, even to Ney, that cavalry alone were achieving little. Belatedly, he organised a combined-arms attack, using Bachelu's division and Tissot's regiment of Foy's division from Reille's II Corps plus those French cavalry that remained in a fit state to fight. This assault was directed along much the same route as the previous heavy cavalry attacks.
Meanwhile, at approximately the same time as Ney's combined-arms assault on the centre-right of Wellington's line, Napoleon ordered Ney to capture La Haye Sainte at whatever the cost. Ney accomplished this with what was left of D'Erlon's corps soon after 18:00. Ney then moved horse artillery up towards Wellington's centre and began to destroy the infantry squares at short-range with canister. This all but destroyed the 27th (Inniskilling) Regiment, and the 30th and 73rd Regiments suffered such heavy losses that they had to combine to form a viable square. Wellington's centre was now on the verge of collapse and wide open to an attack from the French. Luckily for Wellington, Pirch I's and Zieten's corps of the Prussian Army were now at hand. Zieten's corps permitted the two fresh cavalry brigades of Vivian and Vandeleur on Wellington's extreme left to be moved and posted behind the depleted centre. Pirch I Corps then proceeded to support Bülow and together they regained possession of Plancenoit, and once more the Charleroi road was swept by Prussian round shot. The value of this reinforcement at this particular moment can hardly be overestimated.
The French army now fiercely attacked the Coalition all along the line with the culminating point being reached when Napoleon sent forward the Imperial Guard at 19:30. The attack of the Imperial Guards was mounted by five battalions of the Middle Guard, and not by the Grenadiers or Chasseurs of the Old Guard. Marching through a hail of canister and skirmisher fire and severely outnumbered, the 3,000 or so Middle Guardsmen advanced to the west of La Haye Sainte and proceeded to separate into three distinct attack forces. One, consisting of two battalions of Grenadiers, defeated the Coalition's first line and marched on. Chassé's relatively fresh Dutch division was sent against them and Allied artillery fired into the victorious Grenadiers' flank. This still could not stop the Guard's advance, so Chassé ordered his first brigade to charge the outnumbered French, who faltered and broke.

Further to the west, 1,500 British Foot Guards under Maitland were lying down to protect themselves from the French artillery. As two battalions of Chasseurs approached, the second prong of the Imperial Guard's attack, Maitland's guardsmen rose and devastated them with point-blank volleys. The Chasseurs deployed to counter-attack but began to waver. A bayonet charge by the Foot Guards then broke them. The third prong, a fresh Chasseur battalion, now came up in support. The British guardsmen retreated with these Chasseurs in pursuit, but the latter were halted as the 52nd Light Infantry wheeled in line onto their flank and poured a devastating fire into them and then charged. Under this onslaught, they too broke.

The last of the Guard retreated headlong. A ripple of panic passed through the French lines as the astounding news spread: ""La Garde recule. Sauve qui peut!"" ("The Guard retreats. Save yourself if you can!"). Wellington then stood up in Copenhagen's stirrups, and waved his hat in the air to signal an advance of the Allied line just as the Prussians were overrunning the French positions to the east. What remained of the French army then abandoned the field in disorder. Wellington and Blücher met at the inn of La Belle Alliance, on the north–south road which bisected the battlefield, and it was agreed that the Prussians should pursue the retreating French army back to France. The Treaty of Paris was signed on 20 November 1815.

After the victory, the Duke supported proposals that a medal be awarded to all British soldiers who participated in the Waterloo campaign, and on 28 June 1815 he wrote to the Duke of York suggesting: ... the expediency of giving to the non-commissioned officers and soldiers engaged in the Battle of Waterloo a medal. I am convinced it would have the best effect in the army, and if the battle should settle our concerns, they will well deserve it.The Waterloo Medal was duly authorised and distributed to all ranks in 1816.

Much historical discussion has been made about Napoleon's decision to send 33,000 troops under Marshal Grouchy to intercept the Prussians, but—having defeated Blücher at Ligny on 16 June and forced the Allies to retreat in divergent directions—Napoleon may have been strategically astute in a judgement that he would have been unable to beat the combined Allied forces on one battlefield. Wellington's comparable strategic gamble was to leave 17,000 troops and artillery, mostly Dutch, away at Halle, north-west of Mont-Saint-Jean, in case of a French advance up the Mons-Hal-Brussels road.
The campaign led to numerous other controversies, especially concerning the Prussians. For example: Were Wellington's troop dispositions prior to Napoleon's invasion of the Netherlands sound? Did Wellington somehow mislead or betray Blücher by promising, then failing, to come directly to Blücher's aid at Ligny? Who deserved the lion's share of credit for the victory—Wellington or the Prussians? These and other such issues concerning Blücher's, Wellington's, and Napoleon's decisions during the campaign were the subject of a major strategic-level study by the famous Prussian political-military theorist Carl von Clausewitz, "Feldzug von 1815: Strategische Uebersicht des Feldzugs von 1815", English title: "The Campaign of 1815: Strategic Overview of the Campaign". Written c.1827, this study was Clausewitz's last such work and is widely considered to be the best example of Clausewitz's mature theories concerning such analyses. It attracted the attention of Wellington's staff, who prompted the Duke to write his only published essay on the campaign (other than his immediate, official after-action report, "The Waterloo Dispatch"), his 1842 "Memorandum on the Battle of Waterloo". While Wellington disputed Clausewitz on several points, the Prussian writer largely absolved Wellington of accusations levelled against him by nationalistic German axe-grinders. This exchange with Clausewitz was quite famous in Britain in the 19th century (it was heavily discussed in, for example, Chesney's "Waterloo Lectures" (1868).) It seems, however, to have been systematically ignored by British historians writing since 1914, which is odd considering that it was one of only two discussions of the battle that Wellington wrote. The explanation, unfortunately, is probably that it drew too much attention to the decisive German role in Wellington's victory—which Wellington himself was perfectly happy to acknowledge, but which became an awkward subject given Anglo-German hostilities in the 20th century.

Wellington entered politics again when he was appointed Master-General of the Ordnance in the Tory government of Lord Liverpool on 26 December 1818. He also became Governor of Plymouth on 9 October 1819. He was appointed Commander-in-Chief of the British Army on 22 January 1827 and Constable of the Tower of London on 5 February 1827.

Along with Robert Peel, Wellington became an increasingly influential member of the Tory party, and in 1828 he resigned as Commander-in-Chief and became Prime Minister.

During his first seven months as prime minister, he chose not to live in the official residence at 10 Downing Street, finding it too small. He moved in only because his own home, Apsley House, required extensive renovations. During this time he was largely instrumental in the foundation of King's College London. On 20 January 1829 Wellington was appointed Lord Warden of the Cinque Ports.

His term was marked by Catholic emancipation: the granting of almost full civil rights to Catholics in Great Britain and Ireland. The change was prompted by the landslide by-election win of Daniel O'Connell, an Irish Catholic proponent of emancipation, who was elected despite not being legally allowed to sit in Parliament. In the House of Lords, facing stiff opposition, Wellington spoke for Catholic Emancipation, and according to some sources, gave one of the best speeches of his career. He was born in Ireland and so had some understanding of the grievances of the Catholic communities there; as Chief Secretary, he had given an undertaking that the remaining Penal Laws would only be enforced as "mildly" as possible. In 1811 Catholic soldiers were given freedom of worship and 18 years later the Catholic Relief Act 1829 was passed with a majority of 105. Many Tories voted against the Act, and it passed only with the help of the Whigs. Wellington had threatened to resign as Prime Minister if the King (George IV) did not give his Royal Assent.

The Earl of Winchilsea accused the Duke of "an insidious design for the infringement of our liberties and the introduction of Popery into every department of the State". Wellington responded by immediately challenging Winchilsea to a duel. On 21 March 1829, Wellington and Winchilsea met on Battersea fields. When the time came to fire, the Duke took aim and Winchilsea kept his arm down. The Duke fired wide to the right. Accounts differ as to whether he missed on purpose, an act known in dueling as a "delope". Wellington claimed he did. However, he was noted for his poor aim and reports more sympathetic to Winchilsea claimed he had aimed to kill. Winchilsea discharged his pistol into the air, a plan he and his second had almost certainly decided upon before the duel. Honour was saved and Winchilsea wrote Wellington an apology.

The nickname "Iron Duke" originates from this period, when he experienced a high degree of personal and political unpopularity. Its repeated use in "Freeman's Journal" throughout June 1830 appears to bear reference to his resolute political will, with taints of disapproval from its Irish editors. During this time, Wellington was greeted by a hostile reaction from the crowds at the opening of the Liverpool and Manchester Railway.

Wellington's government fell in 1830. In the summer and autumn of that year, a wave of riots swept the country. The Whigs had been out of power for most years since the 1770s, and saw political reform in response to the unrest as the key to their return. Wellington stuck to the Tory policy of no reform and no expansion of suffrage, and as a result, lost a vote of no confidence on 15 November 1830.

The Whigs introduced the first Reform Bill while Wellington and the Tories worked to prevent its passage. The Whigs could not get the bill past its second reading in the British House of Commons, and the bill failed. An election followed in direct response and the Whigs were returned with a landslide majority. A second Reform Act was introduced and passed in the House of Commons but was defeated in the Tory-controlled House of Lords. Another wave of near insurrection swept the country. Wellington's residence at Apsley House was targeted by a mob of demonstrators on 27 April 1831 and again on 12 October, leaving his windows smashed. Iron shutters were installed in June 1832 to prevent further damage by crowds angry over rejection of the Reform Bill, which he strongly opposed. The Whig Government fell in 1832 and Wellington was unable to form a Tory Government partly because of a run on the Bank of England. This left King William IV no choice but to restore Earl Grey to the premiership. Eventually, the bill passed the House of Lords after the King threatened to fill that House with newly created Whig peers if it were not. Wellington was never reconciled to the change; when Parliament first met after the first election under the widened franchise, Wellington is reported to have said "I never saw so many shocking bad hats in my life".

Wellington opposed the Jewish Civil Disabilities Repeal Bill, and he stated in Parliament on 1 August 1833 that England "is a Christian country and a Christian legislature, and that the effect of this measure would be to remove that peculiar character." The Bill was defeated 104 votes to 54.

Wellington was gradually superseded as leader of the Tories by Robert Peel, while the party evolved into the Conservatives. When the Tories were returned to power in 1834, Wellington declined to become Prime Minister because he thought membership in Commons had become essential. The king reluctantly approved Peel, who was in Italy. So for three weeks in November and December 1834, Wellington acted as interim leader, taking the responsibilities of Prime Minister and most of the other ministries. In Peel's first cabinet (1834–1835), Wellington became Foreign Secretary, while in the second (1841–1846) he was a Minister without Portfolio and Leader of the House of Lords. Wellington was also re-appointed Commander-in-Chief of the British Army on 15 August 1842 following the resignation of Lord Hill.

Wellington served as the leader of the Conservative party in the House of Lords, 1828–1846. Some historians have belittled him as a befuddled reactionary, but a consensus in the late 20th century depicts him as a shrewd operator who hid his cleverness behind the facade of a poorly informed old soldier. Wellington worked to transform the Lords from unstinting support of the Crown to an active player in political maneuvering, with a commitment to the landed aristocracy. He used his London residence as a venue for intimate dinners and private consultations, together with extensive correspondence that kept him in close touch with party leaders in the Commons, and the main persona in the Lords. He gave public rhetorical support to Ultra-Tory anti-reform positions, but then deftly changed positions toward the party's center, especially when Peel needed support from the upper house. Wellington's success was based on the 44 Elected peers from Scotland and Ireland, whose election he controlled.

Wellesley married Kitty Pakenham in Dublin on 10 April 1806. They had two children: Arthur was born in 1807 and Charles was born in 1808. The marriage proved unsatisfactory and the two spent years apart, while Wellesley was campaigning and afterward. Kitty grew depressed, and Wellesley pursued other sexual and romantic partners. The couple largely lived apart, with Kitty spending most of her time at their country home, Stratfield Saye House and Wellesley at their London home, Apsley House. Kitty's brother Edward Pakenham served under Wellesley throughout the Peninsular War, and Wellesley's regard for him helped to smooth his relations with Kitty, until Pakenham's death at the Battle of New Orleans in 1815.

Wellington retired from political life in 1846, although he remained Commander-in-Chief, and returned briefly to the spotlight in 1848 when he helped organise a military force to protect London during that year of European revolution.

The Conservative Party had split over the Repeal of the Corn Laws in 1846, with Wellington and most of the former Cabinet still supporting Peel, but most of the MPs led by Lord Derby supporting a protectionist stance. Early in 1852 Wellington, by then very deaf, gave Derby's first government its nickname by shouting "Who? Who?" as the list of inexperienced Cabinet Ministers was read out in the House of Lords.

He became Chief Ranger and Keeper of Hyde Park and St. James's Park on 31 August 1850. He was also colonel of the 33rd Regiment of Foot from 1 February 1806 and colonel of the Grenadier Guards from 22 January 1827.

Kitty died of cancer in 1831; despite their generally unhappy relations, which had led to an effective separation, Wellington was said to have been greatly saddened by her death, his one comfort being that after "half a lifetime together, they had come to understand each other at the end". He had found consolation for his unhappy marriage in his warm friendship with the diarist Harriet Arbuthnot, wife of his colleague Charles Arbuthnot. Harriet's death in the cholera epidemic of 1834 was almost as great a blow to Wellington as it was to her husband. The two widowers spent their last years together at Apsley House.

Wellington died at Walmer Castle in Deal on 14 September 1852. This was his residence as Lord Warden of the Cinque Ports. Walmer Castle was said to have been his favourite residence. He was found to be unwell on that morning and was aided from his military campaign bed (the same one he used throughout his historic military career) and seated in his chair where he died. His death was recorded as being due to the after-effects of a stroke culminating in a series of seizures. He was aged 83.

Although in life he hated travelling by rail (after witnessing the death of William Huskisson, one of the first railway accident casualties), his body was then taken by train to London, where he was given a state funeral – one of only a handful of British subjects to be honoured in that way (other examples are Lord Nelson and Sir Winston Churchill). The funeral took place on 18 November 1852. Before the funeral, the Duke's body lay in state at the Royal Hospital, Chelsea. Members of the royal family, including Queen Victoria, the Prince Consort, the Prince of Wales, and the Princess Royal, visited to pay their respects. When viewing opened to the public, crowds thronged to visit and several people were killed in the crush.

At his funeral there was hardly any space to stand because of the number of people attending, and the effusive praise given him in Tennyson's "Ode on the Death of the Duke of Wellington" attests to his stature at the time of his death. He was buried in a sarcophagus of luxulyanite in St Paul's Cathedral next to Lord Nelson. A bronze memorial was sculpted by Alfred Stevens, and features two intricate supports: "Truth tearing the tongue out of the mouth of False-hood", and "Valour trampling Cowardice underfoot". Stevens did not live to see it placed in its home under one of the great arches of the cathedral.

Wellington's casket was decorated with banners which were made for his funeral procession. Originally, there was one from Prussia, which was removed during the First World War and never reinstated. In the procession, the "Great Banner" was carried by General Sir James Charles Chatterton of the 4th Dragoon Guards on the orders of Queen Victoria.

Most of the book "A Biographical Sketch of the Military and Political Career of the Late Duke of Wellington" by Weymouth newspaper proprietor Joseph Drew is a detailed contemporary account of his death, lying in state and funeral.

After his death, Irish and English newspapers disputed whether Wellington had been born an Irishman or an Englishman. In 2002, he was number 15 in the BBC's poll of the 100 Greatest Britons.

Owing to its links with Wellington, as the former commanding officer and colonel of the regiment, the title "33rd (The Duke of Wellington's) Regiment" was granted to the 33rd Regiment of Foot, on 18 June 1853 (the 38th anniversary of the Battle of Waterloo) by Queen Victoria. Wellington's battle record is exemplary; he participated in some 60 battles during the course of his military career.

Wellington always rose early; he "couldn't bear to lie awake in bed", even if the army was not on the march. Even when he returned to civilian life after 1815, he slept in a camp bed, reflecting his lack of regard for creature comforts; it remains on display in Walmer Castle. General Miguel de Álava complained that Wellington said so often that the army would march "at daybreak" and dine on "cold meat", that he began to dread those two phrases. While on campaign, he seldom ate anything between breakfast and dinner. During the retreat to Portugal in 1811, he subsisted on "cold meat and bread", to the despair of his staff who dined with him. He was, however, renowned for the quality of the wine that he drank and served, often drinking a bottle with his dinner (not a great quantity by the standards of his day).

He rarely showed emotion in public, and often appeared condescending to those less competent or less well-born than himself (which was nearly everyone). However, Álava was a witness to an incident just before the Battle of Salamanca. Wellington was eating a chicken leg while observing the manoeuvres of the French army through a spyglass. He spotted an overextension in the French left flank, and realised that he could launch a successful attack there. He threw the drumstick in the air and shouted ""Les français sont perdus!"" ("The French are lost!"). After the Battle of Toulouse, an aide brought him the news of Napoleon's abdication, and Wellington broke into an impromptu flamenco dance, spinning around on his heels and clicking his fingers.
Military historian Charles Dalton recorded that, after a hard-fought battle in Spain, a young officer made the comment, "I am going to dine with Wellington tonight", which was overheard by the Duke as he rode by. "Give me at least the prefix of Mr. before my name," Wellington said. "My Lord," replied the officer, "we do not speak of Mr. Caesar or Mr. Alexander, so why should I speak of Mr. Wellington?"

His stern countenance and iron-handed discipline were renowned; he was said to disapprove of soldiers cheering as "too nearly an expression of opinion." Nevertheless, Wellington cared for his men; he refused to pursue the French after the battles of Porto and Salamanca, foreseeing an inevitable cost to his army in chasing a diminished enemy through rough terrain. The only time that he ever showed grief in public was after the storming of Badajoz; he cried at the sight of the British dead in the breaches. In this context, his famous dispatch after the Battle of Vitoria, calling them the "scum of the earth," can be seen to be fuelled as much by disappointment at their breaking ranks as by anger. He expressed his grief openly the night after Waterloo before his personal physician, and later with his family; unwilling to be congratulated for his victory, he broke down in tears, his fighting spirit diminished by the high cost of the battle and great personal loss.

Wellington's soldier servant, a gruff German called Beckerman, and his long-serving valet, James Kendall, who served him for 25 years and was with him when he died, were both devoted to him. (A story that he never spoke to his servants and preferred instead to write his orders on a note pad on his dressing table in fact probably refers to his son, the 2nd Duke. It was recorded by the 3rd Duke's niece, Viva Seton Montgomerie (1879-1959), as being an anecdote she heard from an old retainer, Charles Holman who was said greatly to resemble Napoleon. Holman is recorded as a servant of the Dukes of Wellington from 1871 to 1905).

Following an incident when, as Master-General of the Ordnance he had been close to a large explosion, Wellington began to experience deafness and other ear-related problems. In 1822, he had an operation to improve the hearing of the left ear. The result, however, was that he became permanently deaf on that side. It is claimed that he was "never quite well afterwards".

Wellington had a "vigorous sexual appetite" and many amorous liaisons during his marriage to Kitty. He enjoyed the company of intellectual and attractive women for many decades, particularly after the Battle of Waterloo and his subsequent ambassadorial position in Paris. The British press lampooned this side of the national hero. In 1824, one liaison came back to haunt him, when Wellington received a letter from a publisher offering to refrain from issuing an edition of the rather racy memoirs of one of his mistresses Harriette Wilson, in exchange for financial consideration. It is said that the Duke promptly returned the letter, after scrawling across it, "Publish and be damned". However, Hibbert notes in his biography that the letter can be found among the Duke's papers, with nothing written on it. It is certain that Wellington "did" reply, and the tone of a further letter from the publisher, quoted by Longford, suggests that he had refused in the strongest language to submit to blackmail.

He was also a remarkably practical man who spoke concisely. In 1851, it was discovered that there were a great many sparrows flying about in the Crystal Palace just before the Great Exhibition was to open. His advice to Queen Victoria was "Sparrowhawks, ma'am".

Wellington has often been portrayed as a defensive general, even though many, perhaps most, of his battles were offensive (Argaum, Assaye, Oporto, Salamanca, Vitoria, Toulouse). However, for most of the Peninsular War, where he earned his fame, his army lacked the numbers for a strategically offensive posture.


This commonly used nickname originally related to his consistent political resolve rather than to any particular incident. In various cases its editorial use appears to be disparaging. It is likely that its use became more widespread after an incident in 1832 in which he installed metal shutters to prevent rioters breaking windows at Apsley House. The term may have been made increasingly popular by "Punch" cartoons published in 1844–45.

Wellington had various other nicknames:

In addition:






</doc>
<doc id="8476" url="https://en.wikipedia.org/wiki?curid=8476" title="Disk operating system">
Disk operating system

A disk operating system (abbreviated DOS) is a computer operating system that resides on and can use a disk storage device, such as a floppy disk, hard disk drive, or optical disc. A disk operating system must provide a file system for organizing, reading, and writing files on the storage disk. Strictly speaking, this definition does not apply to current generations of operating systems, such as versions of Microsoft Windows in use, and is more appropriately used only for older generations of operating systems.

Disk operating systems were available for mainframes, minicomputers, microprocessors and home computers and were usually loaded from the disks themselves as part of the boot process.

In the early days of computers, there were no disk drives, floppy disks or modern flash storage devices. Early storage devices such as delay lines, core memories, punched cards, punched tape, magnetic tape, and magnetic drums were used instead. And in the early days of microcomputers and home computers, paper tape or audio cassette tape (see Kansas City standard) or nothing were used instead. In the latter case, program and data entry was done at front panel switches directly into memory or through a computer terminal / keyboard, sometimes controlled by a BASIC interpreter in ROM; when power was turned off any information was lost.

In the early 1960s, as disk drives became larger and more affordable, various mainframe and minicomputer vendors began introducing disk operating systems and modifying existing operating systems to exploit disks.

Both hard disks and floppy disk drives require software to manage rapid access to block storage of sequential and other data. For most microcomputers, a disk drive of any kind was an optional peripheral; systems could be used with a tape drive or booted without a storage device at all. The disk operating system component of the operating system was only needed when a disk drive was used.

By the time IBM announced the System/360 mainframes, the concept of a disk operating system was well established. Although IBM did offer Basic Programming Support (BPS/360) and TOS/360 for small systems, they were out of the mainstream and most customers used either DOS/360 or OS/360.

Most home and personal computers of the late 1970s and 1980s used a disk operating system, most often with "DOS" in the name and simply referred to as "DOS" within their respective communities: CBM DOS for Commodore 8-bit systems, Atari DOS for the Atari 8-bit family, TRS-DOS for the TRS-80, and Apple DOS for the Apple II, and MS-DOS for IBM PC compatibles.

Usually, a disk operating system was loaded from a disk. Among the exceptions were Commodore, whose DOS resided on ROM chips in the disk drives. The Lt. Kernal hard disk subsystem for the Commodore 64 and Commodore 128 models stored its DOS on the disk, as is the case with modern systems, and loaded the DOS into RAM at boot time; the British BBC Micro's optional Disc Filing System, DFS, offered as a kit with a disk controller chip, a ROM chip, and a handful of logic chips, to be installed inside the computer.


Some disk operating systems were the operating systems for the entire computer system.



</doc>
<doc id="8477" url="https://en.wikipedia.org/wiki?curid=8477" title="Dual">
Dual

Dual or Duals may refer to:





</doc>
<doc id="8478" url="https://en.wikipedia.org/wiki?curid=8478" title="Doublespeak">
Doublespeak

Doublespeak is language that deliberately obscures, disguises, distorts, or reverses the meaning of words. Doublespeak may take the form of euphemisms (e.g. "downsizing" for layoffs and "servicing the target" for bombing), in which case it is primarily meant to make the truth sound more palatable. It may also refer to intentional ambiguity in language or to actual inversions of meaning. In such cases, doublespeak disguises the nature of the truth. Doublespeak is most closely associated with political language. The word is comparable to George Orwell's Newspeak and Doublethink as used in his book "Nineteen Eighty-Four", though the term Doublespeak does not appear there.
The term "doublespeak" originates in George Orwell's book "1984" (Nineteen Eighty-Four). Although the term is not used in the book, it is a close relative of two of the book's central concepts, "doublethink" and "Newspeak". Another variant, "doubletalk", also referring to deliberately ambiguous speech, did exist at the time Orwell wrote his book, but the usage of "doublespeak", as well as of "doubletalk", in the sense emphasizing ambiguity clearly postdates the publication of "Nineteen Eighty-Four". Parallels have also been drawn between doublespeak and Orwell's classic essay "Politics and the English Language", which discusses the distortion of language for political purposes. In it he observes that political language serves to distort and obfuscate reality. Orwell's description of political speech is extremely similar to the contemporary definition of doublespeak:
The writer Edward S. Herman cited what he saw as examples of doublespeak and doublethink in modern society. Herman describes in his book "Beyond Hypocrisy" the principal characteristics of doublespeak:
Terrence P. Moran of the US National Council of Teachers of English has compared the use of doublespeak in the mass media to a set of laboratory experiments conducted on rats. In the experiment, a sample of rats was first deprived of food, before one group was fed sugar and water and the other group a saccharin solution. Both groups exhibited behavior indicating that their hunger was satisfied, but rats in the second group (which were fed saccharin solution) died of malnutrition. Moran parallels doublespeak's effects on the social masses to the second group of rats upon whom an illusionary effect was created. He also highlights the structural nature of doublespeak, and notes that the mass media and other social institutions employ an active, downward-aimed approach in managing the opinions of society at large: Doublespeak also has close connections with some contemporary theories. Edward S. Herman and Noam Chomsky comment in their book "" that Orwellian doublespeak is an important component of the manipulation of the English language in American media, through a process called "dichotomization," a component of media propaganda involving "deeply embedded double standards in the reporting of news." For example, the use of state funds by the poor and financially needy is commonly referred to as "social welfare" or "handouts," which the "coddled" poor "take advantage of." These terms, however, are not as often applied to other beneficiaries of government spending such as military spending.

The National Council of Teachers of English (NCTE) Committee on Public Doublespeak was formed in 1971, in the midst of the Watergate scandal. It was at a point when there was widespread skepticism about the degree of truth which characterized relationships between the public and the worlds of politics, the military, and business. NCTE passed two resolutions. One called for the Council to find means to study dishonest and inhumane uses of language and literature by advertisers, to bring offenses to public attention, and to propose classroom techniques for preparing children to cope with commercial propaganda. The other called for the Council to find means to study the relationships between language and public policy and to track, publicize, and combat semantic distortion by public officials, candidates for office, political commentators, and all others whose language is transmitted through the mass media. The two resolutions were accomplished by forming NCTE's Committee on Public Doublespeak, a body which has made significant contributions in describing the need for reform where clarity in communication has been deliberately distorted.

Hugh Rank helped form the Doublespeak committee in 1971 and was its first chairman. Under his editorship, the committee produced a book called "Language and Public Policy" (1974), with the aim of informing readers of the extensive scope of doublespeak being used to deliberately mislead and deceive the audience. He highlighted the deliberate public misuses of language and provided strategies for countering doublespeak by focusing on educating people in the English language so as to help them identify when doublespeak is being put into play. He was also the founder of the Intensify/Downplay pattern that has been widely used to identify instances of doublespeak being used.

Daniel Dieterich served as the second chairman of the Doublespeak committee after Hugh Rank in 1975. He served as editor of its second publication, "Teaching about Doublespeak" (1976), which carried forward the Committee's charge to inform teachers of ways of teaching students how to recognize and combat language designed to mislead and misinform.

William D. Lutz has served as the third chairman of the Doublespeak Committee since 1975. In 1989, both his own book "Doublespeak" and, under his editorship, the committee's third book, "Beyond Nineteen Eighty-Four", were published. "Beyond Nineteen Eighty-Four" consists of 220 pages and eighteen articles contributed by long-time Committee members and others whose bodies of work have contributed to public understanding about language, as well as a bibliography of 103 sources on doublespeak. Lutz was also the former editor of the now defunct "Quarterly Review of Doublespeak", which examined the use of vocabulary by public officials to obscure the underlying meaning of what they tell the public. Lutz is one of the main contributors to the committee as well as promoting the term "doublespeak" to a mass audience to inform them of its deceptive qualities. He mentions:

A. M. Tibbetts is one of the main critics of the NCTE, claiming that "the Committee's very approach to the misuse of language and what it calls 'doublespeak' may in the long run limit its usefulness". According to him, the "Committee's use of Orwell is both confused and confusing". The NCTE's publications resonate with George Orwell's name, and allusions to him abound in statements on doublespeak; for example, the committee quoted Orwell's remark that "language is often used as an instrument of social control" in "Language and Public Policy". Tibbetts argues that such a relation between NCTE and Orwell's work is contradictory because "the Committee's attitude towards language is liberal, even radical" while "Orwell's attitude was conservative, even reactionary". He also criticizes the Committee's "continual attack" against linguistic "purism".

Whereas in the early days of the practice it was considered wrong to construct words to disguise meaning, this is now an established practice. There is a thriving industry in constructing words without explicit meaning but with particular connotations for new products or companies. Doublespeak is also employed in the field of politics.

Advertisers can use doublespeak to mask their commercial intent from users, as users' defenses against advertising become more entrenched. Some are attempting to counter this technique with a number of systems offering diverse views and information to highlight the manipulative and dishonest methods that advertisers employ.

According to Jacques Ellul, "the aim is not to even modify people’s ideas on a given subject, rather, it is to achieve conformity in the way that people act." He demonstrates this view by offering an example from drug advertising. Use of doublespeak in advertisements resulted in aspirin production rates rising by almost 50 percent from over 23 million pounds in 1960 to over 35 million pounds in 1970.

Charles Weingartner, one of the founding members of the NCTE committee on Public Doublespeak mentioned: "people do not know enough about the subject (the reality) to recognize that the language being used conceals, distorts, misleads. Teachers of English should teach our students that words are not things, but verbal tokens or signs of things that should finally be carried back to the things that they stand for to be verified."

According to William Lutz: "Only by teaching respect and love for the language can teachers of English instill in students the sense of outrage they should experience when they encounter doublespeak." "Only by using language well will we come to appreciate the perversion inherent in doublespeak."
This pattern was formulated by Hugh Rank and is a simple tool designed to teach some basic patterns of persuasion used in political propaganda and commercial advertising. The function of the intensify/downplay pattern is not to dictate what should be discussed but to encourage coherent thought and systematic organization. The pattern works in two ways: intensifying and downplaying. All people intensify and this is done via repetition, association and composition. Downplaying is commonly done via omission, diversion and confusion as they communicate in words, gestures, numbers, et cetera. Individuals can better cope with organized persuasion by recognizing the common ways whereby communication is intensified or downplayed, so as to counter doublespeak.

Doublespeak is often used by politicians for the advancement of their agenda. The Doublespeak Award is an "ironic tribute to public speakers who have perpetuated language that is grossly deceptive, evasive, euphemistic, confusing, or self-centered." It has been issued by the National Council of Teachers of English (NCTE) since 1974. The recipients of the Doublespeak Award are usually politicians, national administration or departments. An example of this is the United States Department of Defense, which won the award three times in 1991, 1993, and 2001. For the 1991 award, the United States Department of Defense "swept the first six places in the Doublespeak top ten" for using euphemisms like "servicing the target" (bombing) and "force packages" (warplanes). Among the other phrases in contention were "difficult exercise in labor relations", meaning a strike, and "meaningful downturn in aggregate output", an attempt to avoid saying the word "recession".

Doublespeak, particularly when exaggerated, can be used as a device in satirical comedy and social commentary to ironically parody political or bureaucratic establishments intent on obfuscation or prevarication. The television series "Yes Minister" is notable for its use of this device. Oscar Wilde was an early proponent of this device and a significant influence on Orwell.




</doc>
<doc id="8481" url="https://en.wikipedia.org/wiki?curid=8481" title="Dressed to Kill (1980 film)">
Dressed to Kill (1980 film)

Dressed to Kill is a 1980 American neo-noir slasher film written and directed by Brian De Palma. Starring Michael Caine, Angie Dickinson, Nancy Allen, and Keith Gordon, the film depicts the events leading up to the murder of a New York City housewife (Dickinson) before following a prostitute (Allen) who witnesses the crime. It contains several direct references to Alfred Hitchcock's 1960 film "Psycho", such as a man dressing as a woman to commit murders, significant shower scenes, and the murder of the female lead early in the picture.

Released in the summer of 1980, "Dressed to Kill" was a box office hit in the United States, grossing over $30 million. It received largely favorable reviews, and critic David Denby of "New York Magazine" proclaimed it "the first great American movie of the '80s." Angie Dickinson won the Saturn Award for Best Actress for her performance. Nancy Allen received both a Golden Globe Award nomination for New Star of the Year, as well as an inaugural first-year Golden Raspberry Award for Worst Actress (a distinction that she shared in 1980 with Neil Diamond who also received both a Golden Globe nomination for Best Actor in "The Jazz Singer" and "won" the Worst Actor Razzie Award for the same role). Caine also stood out for his double role of the healing, reserved psychiatrist and the psychiatrist's murdering, gender-role conflicted alter ego.

Kate Miller is a sexually frustrated housewife who is in therapy with New York City psychiatrist Dr. Robert Elliott. During an appointment, Kate attempts to seduce him, but Elliott rejects her advances. Kate goes to the Metropolitan Museum of Art where she has an unexpected flirtation with a mysterious stranger. Kate and the stranger stalk each other through the museum until they finally wind up outside, where Kate joins him in a taxi. They go to his apartment and have sex.

Hours later, Kate awakens and decides to discreetly leave while the man, Warren Lockman, is asleep. Kate sits at his desk to leave him a note and finds a document indicating that Warren has contracted a sexually transmitted disease. Shocked, she leaves the apartment. In her haste, she forgets her wedding ring on the nightstand, and she returns to retrieve it. The elevator doors open on the figure of a tall, blond woman in dark sunglasses wielding a straight razor. Kate is violently stabbed to death in the elevator. A high-priced call girl, Liz Blake, happens upon the body. She catches a glimpse of the killer in the elevator's convex mirror, and subsequently becomes both the prime suspect and the killer's next target.

Dr. Elliott receives a bizarre message on his answering machine from "Bobbi", a transgender patient. Bobbi taunts the psychiatrist for breaking off their therapy sessions, apparently because Elliott refuses to sign the necessary papers for Bobbi to get sex reassignment surgery. Elliott tries to convince Dr. Levy, the patient's new doctor, that Bobbi is a danger to herself and others.

Police Detective Marino is skeptical about Liz's story, partly because of her profession, so Liz joins forces with Kate's revenge-minded son Peter to find the killer. Peter, an inventor, uses a series of homemade listening devices and time-lapse cameras to track patients leaving Elliott's office. They catch Bobbi on camera, and soon Liz is being stalked by a tall blonde in sunglasses. Several attempts are subsequently made on Liz's life. One, in the New York City Subway, is thwarted by Peter, who sprays Bobbi with homemade Mace.

Liz and Peter scheme to learn Bobbi's birth name by getting inside Dr. Elliott's office. Liz baits the therapist by stripping to lingerie and coming on to him, distracting him long enough to make a brief exit and leaf through his appointment book. Peter is watching through the window when a blonde pulls him away. When Liz returns, a blonde with a razor confronts her; the blonde outside shoots and wounds the blonde inside, the wig falls off, and it is Dr. Elliott, revealing that he is also Bobbi. The blonde who shot Bobbi is actually a female police officer, revealing herself to be the blonde who has been trailing Liz.

Elliott is arrested and placed in an insane asylum. Dr. Levy explains later to Liz that Elliott wanted to be a woman, but his male side would not allow him to go through with the operation. Whenever a woman sexually aroused Elliott, Bobbi, representing the unstable, female side of the doctor's personality, became threatened to the point that it finally became murderous. When Dr. Levy realized this through his last conversation with Elliott, he called the police on the spot, who then, with his help, did their duty.

In a final sequence, Elliott escapes from the asylum and slashes Liz's throat in a bloody act of vengeance. She wakes up screaming, Peter rushing to her side, realizing that it was
just a nightmare. 

The nude body in the opening scene, taking place in a shower, was not that of Angie Dickinson, but of 1977 "Penthouse" Pet of the Year model Victoria Lynn Johnson. De Palma originally wanted Norwegian actress Liv Ullmann to play Kate Miller, but she declined because of the violence. The role then went to Angie Dickinson. Sean Connery was offered the role of Robert Elliot and was enthusiastic about it, but declined on account of previous commitments. Connery later worked with De Palma on the 1987 Oscar-winning adaptation of "The Untouchables". De Palma called the elevator killing the best murder scene he has ever done.

"Dressed to Kill" premiered in Los Angeles and New York City on July 25, 1980. The film grossed $3,416,000 in its opening weekend from 591 theatres and improved its gross the following weekend with $3,640,000 from 596 theatres. It grossed a total of $31.9 million at the U.S. box office, and was the 21st highest-grossing film of the year.

"Dressed to Kill" currently holds an 81% "fresh" rating on Rotten Tomatoes based on 48 reviews, with an average rating of 6.63/10. The consensus states, "With arresting visuals and an engrossingly lurid mystery, "Dressed to Kill" stylishly encapsulates writer-director Brian De Palma's signature strengths."

Roger Ebert awarded the film three stars out of four, stating "the museum sequence is brilliant" and adding: ""Dressed to Kill" is an exercise in style, not narrative; it would rather look and feel like a thriller than make sense, but DePalma has so much fun with the conventions of the thriller that we forgive him and go along." Gene Siskel also gave it three stars out of four, writing that there were scenes "that are as exciting and as stylish as any ever put on film. Unfortunately, a good chunk of the film is a whodunit, and its mystery is so easy to solve that we merely end up watching the film's visual pyrotechnics at a distance, never getting all that involved." Vincent Canby of "The New York Times]" called the film "witty, romantic," and "very funny, which helps to defuse the effect of the graphically photographed violence. In addition, the film is, in its own inside-out way, peculiarly moral." His review added that "The performers are excellent, especially Miss Dickinson." "Variety" declared "Despite some major structural weaknesses, the cannily manipulated combination of mystery, gore and kinky sex adds up to a slick commercial package that stands to draw some rich blood money." David Denby of "New York Magazine" proclaimed the film "the first great American movie of the '80s."

Sheila Benson of the "Los Angeles Times" wrote "The brilliance of "Dressed to Kill" is apparent within seconds of its opening gliding shot; it is a sustained work of terror—elegant, sensual, erotic, bloody, a directorial tour de force." Pauline Kael of "The New Yorker" stated of De Palma that "his timing is so great that when he wants you to feel something he gets you every time. His thriller technique, constantly refined, has become insidious, jewelled. It's hardly possible to find a point at which you could tear yourself away from this picture." Gary Arnold of "The Washington Post" wrote, "This elegant new murder thriller promises to revive the lagging summer box office and enhance De Palma's reputation as the most exciting and distinctive manipulator of suspense since Alfred Hitchcock." In his movie guide, Leonard Maltin gave the film 3 1/2 stars out of four, calling it a "High-tension melodrama", and stating "De Palma works on viewers' emotions, not logic, and maintains a fever pitch from start to finish." He also praised Pino Donaggio's "chilling music score."

John Simon of the "National Review", after taking note of the two-page advertisements full of superlatives in "The New York Times", wrote "What "Dressed to Kill" dispenses liberally, however, is sophomoric soft-core pornography, vulgar manipulation of the emotions for mere sensation, salacious but inept dialogue that is a cross between comic-strip Freudianism and sniggering double entendres, and a plot line so full of holes to be at best a dotted line".

Two versions of the film exist in North America, an R-rated version and an unrated version. The unrated version is around 30 seconds longer and shows more pubic hair in the shower scene, more blood in the elevator scene (including a close-up shot of the killer slitting Kate's throat), and more explicit dialogue from Liz during the scene in Elliott's office. These scenes were trimmed when the MPAA originally gave the film an X rating.

The film is currently owned by Metro-Goldwyn-Mayer (successor to Orion Pictures, who bought Filmways and American International Pictures in 1982). The film saw a 1984 VHS release by Warner Home Video, and later another VHS release by Goodtimes under licence from Orion. In 2002, MGM released the film on DVD, including special features. In 2010, MGM released both R-rated and unrated versions on DVD and Blu-ray. The Criterion Collection released a deluxe Blu-ray edition of the film on September 8, 2015.




</doc>
<doc id="8483" url="https://en.wikipedia.org/wiki?curid=8483" title="Diesel cycle">
Diesel cycle

The Diesel cycle is a combustion process of a reciprocating internal combustion engine. In it, fuel is ignited by heat generated during the compression of air in the combustion chamber, into which fuel is then injected. This is in contrast to igniting the fuel-air mixture with a spark plug as in the Otto cycle (four-stroke/petrol) engine. Diesel engines are used in aircraft, automobiles, power generation, diesel-electric locomotives, and both surface ships and submarines.

The Diesel cycle is assumed to have constant pressure during the initial part of the combustion phase (formula_1 to formula_2 in the diagram, below). This is an idealized mathematical model: real physical diesels do have an increase in pressure during this period, but it is less pronounced than in the Otto cycle. In contrast, the idealized Otto cycle of a gasoline engine approximates a constant volume process during that phase.

The image shows a p-V diagram for the ideal Diesel cycle; where formula_3 is pressure and V the volume or formula_4 the specific volume if the process is placed on a unit mass basis. The "idealized" Diesel cycle assumes an ideal gas and ignores combustion chemistry, exhaust- and recharge procedures and simply follows four distinct processes:


The Diesel engine is a heat engine: it converts heat into work. During the bottom isentropic processes (blue), energy is transferred into the system in the form of work formula_5, but by definition (isentropic) no energy is transferred into or out of the system in the form of heat. During the constant pressure (red, isobaric) process, energy enters the system as heat formula_6. During the top isentropic processes (yellow), energy is transferred out of the system in the form of formula_7, but by definition (isentropic) no energy is transferred into or out of the system in the form of heat. During the constant volume (green, isochoric) process, some of energy flows out of the system as heat through the right depressurizing process formula_8. The work that leaves the system is equal to the work that enters the system plus the difference between the heat added to the system and the heat that leaves the system; in other words, net gain of work is equal to the difference between the heat added to the system and the heat that leaves the system.


The net work produced is also represented by the area enclosed by the cycle on the P-V diagram. The net work is produced per cycle and is also called the useful work, as it can be turned to other useful types of energy and propel a vehicle (kinetic energy) or produce electrical energy. The summation of many such cycles per unit of time is called the developed power. The formula_7 is also called the gross work, some of which is used in the next cycle of the engine to compress the next charge of air

The maximum thermal efficiency of a Diesel cycle is dependent on the compression ratio and the cut-off ratio. It has the following formula under cold air standard analysis: 

formula_16

where

The cut-off ratio can be expressed in terms of temperature as shown below:

formula_26 can be approximated to the flame temperature of the fuel used. The flame temperature can be approximated to the adiabatic flame temperature of the fuel with corresponding air-to-fuel ratio and compression pressure, formula_27.
formula_28 can be approximated to the inlet air temperature.

This formula only gives the ideal thermal efficiency. The actual thermal efficiency will be significantly lower due to heat and friction losses. The formula is more complex than the Otto cycle (petrol/gasoline engine) relation that has the following formula:

formula_29

The additional complexity for the Diesel formula comes around since the heat addition is at constant pressure and the heat rejection is at constant volume. The Otto cycle by comparison has both the heat addition and rejection at constant volume.

Comparing the two formulae it can be seen that for a given compression ratio (), the "ideal" Otto cycle will be more efficient. However, a "real" diesel engine will be more efficient overall since it will have the ability to operate at higher compression ratios. If a petrol engine were to have the same compression ratio, then knocking (self-ignition) would occur and this would severely reduce the efficiency, whereas in a diesel engine, the self ignition is the desired behavior. Additionally, both of these cycles are only idealizations, and the actual behavior does not divide as clearly or sharply. Furthermore, the ideal Otto cycle formula stated above does not include throttling losses, which do not apply to diesel engines.

Diesel engines have the lowest specific fuel consumption of any large internal combustion engine employing a single cycle, 0.26 lb/hp·h (0.16 kg/kWh) for very large marine engines (combined cycle power plants are more efficient, but employ two engines rather than one). Two-stroke diesels with high pressure forced induction, particularly turbocharging, make up a large percentage of the very largest diesel engines.

In North America, diesel engines are primarily used in large trucks, where the low-stress, high-efficiency cycle leads to much longer engine life and lower operational costs. These advantages also make the diesel engine ideal for use in the heavy-haul railroad and earthmoving environments.

Many model airplanes use very simple "glow" and "diesel" engines. Glow engines use glow plugs. "Diesel" model airplane engines have variable compression ratios. Both types depend on special fuels.

Some 19th-century or earlier experimental engines used external flames, exposed by valves, for ignition, but this becomes less attractive with increasing compression. (It was the research of Nicolas Léonard Sadi Carnot that established the thermodynamic value of compression.) A historical implication of this is that the diesel engine could have been invented without the aid of electricity.



</doc>
<doc id="8484" url="https://en.wikipedia.org/wiki?curid=8484" title="Deus Ex (video game)">
Deus Ex (video game)

Deus Ex is a 2000 action role-playing video game developed by Ion Storm and published by Eidos Interactive. Set in a cyberpunk-themed dystopian world in the year 2052, the game follows JC Denton, an agent of the fictional agency United Nations Anti-Terrorist Coalition (UNATCO), who is given superhuman abilities by nanotechnology, as he sets out to combat hostile forces in a world ravaged by inequality and a deadly plague. His missions entangle him in a conspiracy that brings him into conflict with the Triads, Majestic 12, and the Illuminati.

"Deus Ex"s gameplay combines elements of the first-person shooter with stealth elements, adventure, and role-playing genres, allowing for its tasks and missions to be completed in a variety of ways, which in turn lead to differing outcomes. Presented from the first-person perspective, the player can customize Denton's various abilities such as weapon skills or lockpicking, increasing his effectiveness in these areas; this opens up different avenues of exploration and methods of interacting with or manipulating other characters. The player can complete side missions away from the primary storyline by moving freely around the available areas, which can reward the player with experience points to upgrade abilities and alternative ways to tackle main missions.

Powered by the Unreal Engine, the game was released for Microsoft Windows in June 2000, with a Mac OS port following the next month. A modified version of the game was released for the PlayStation 2 in 2002. In the years following its release, "Deus Ex" has received additional improvements and content from its fan community.

The game received critical acclaim, including being named "Best PC Game of All Time" in "PC Gamer"s "Top 100 PC Games" in 2011 and a poll carried out by the UK gaming magazine "PC Zone". It received several Game of the Year awards, drawing praise for its pioneering designs in player choice and multiple narrative paths. It has sold more than 1 million copies, as of April 23, 2009. The game led to a series, which includes the sequel "" (2003), and three prequels: "" (2011), "" (2013), and "" (2016).

"Deus Ex" incorporates elements from four video game genres: role-playing, first-person shooter, adventure, and "immersive simulation," the last of which being a game where "nothing reminds you that you're just playing a game." For example, the game uses a first-person camera during gameplay and includes exploration and character interaction as primary features.

The player assumes the role of JC Denton, a nanotech-augmented operative of the United Nations Anti-Terrorist Coalition (UNATCO). This nanotechnology is a central gameplay mechanism and allows players to perform superhuman feats.

As the player accomplishes objectives, the player character is rewarded with "skill points." Skill points are used to enhance a character's abilities in eleven different areas, and were designed to provide players with a way to customize their characters; a player might create a combat-focused character by increasing proficiency with pistols or rifles, while a more furtive character can be created by focusing on lock picking and computer hacking abilities. There are four different levels of proficiency in each skill, with the skill point cost increasing for each successive level.

Weapons may be customized through "weapon modifications," which can be found or purchased throughout the game. The player might add scopes, silencers, or laser sights; increase the weapon's range, accuracy, or magazine size; or decrease its recoil and reload time; as appropriate to the weapon type.

Players are further encouraged to customize their characters through nano-augmentations—cybernetic devices that grant characters superhuman powers. While the game contains eighteen different nano-augmentations, the player can install a maximum of nine, as each must be used on a certain part of the body: one in the arms, legs, eyes, and head; two underneath the skin; and three in the torso. This forces the player to choose carefully between the benefits offered by each augmentation. For example, the arm augmentation requires the player to decide between boosting their character's skill in hand-to-hand combat or his ability to lift heavy objects.

Interaction with non-player characters (NPCs) was a significant design focus. When the player interacts with a non-player character, the game will enter a cutscene-like conversation mode where the player advances the conversation by selecting from a list of dialogue options. The player's choices often have a substantial effect on both gameplay and plot, as non-player characters will react in different ways depending on the selected answer (e.g., rudeness makes them less likely to assist the player).

"Deus Ex" features combat similar to first-person shooters, with real-time action, a first-person perspective, and reflex-based gameplay. As the player will often encounter enemies in groups, combat often tends toward a tactical approach, including the use of cover, strafing, and "hit-and-run." A "USA Today" reviewer found, "At the easiest difficulty setting, your character is puréed again and again by an onslaught of human and robotic terrorists until you learn the value of stealth." However, through the game's role-playing systems, it is possible to develop a character's skills and augmentations to create a tank-like combat specialist with the ability to deal and absorb large amounts of damage. Non-player characters will praise or criticize the main character depending on the use of force, incorporating a moral element into the gameplay.

"Deus Ex" features a head-up display crosshair, whose size dynamically shows where shots will fall based on movement, aim, and the weapon in use; the reticle expands while the player is moving or shifting their aim, and slowly shrinks to its original size while no actions are taken. How quickly the reticle shrinks depends on the character's proficiency with the equipped weapon the number of accuracy modifications added to the weapon, and the level of the "Targeting" nano-augmentation.

"Deus Ex" features twenty-four weapons, ranging from crowbars, electroshock weapons, and riot baton, to laser-guided anti-tank rockets and assault rifles; both lethal and non-lethal weapons are available. The player can also make use of several weapons of opportunity, such as fire extinguishers.

Gameplay in "Deus Ex" emphasizes player choice. Objectives can be completed in numerous ways, including stealth, sniping, heavy frontal assault, dialogue, or engineering and computer hacking. This level of freedom requires that levels, characters, and puzzles be designed with significant redundancy, as a single play-through of the game will miss large sections of dialogue, areas, and other content. In some missions, the player is encouraged to avoid using deadly force, and specific aspects of the story may change depending on how violent or non-violent the player chooses to be. The game is also unusual in that two of its boss villains can be killed off early in the game, or left alive to be defeated later, and this too affects how other characters interact with the player.

Because of its design focus on player choice, "Deus Ex" has been compared with "System Shock", a game that inspired its design. Together, these factors give the game a high degree of replayability, as the player will have vastly different experiences, depending on which methods they use to accomplish objectives.

"Deus Ex" was designed as a single-player game, and the initial releases of the Windows and Macintosh versions of the game did not include multiplayer functionality. Support for multiplayer modes was later incorporated through patches. The component consists of three game modes: deathmatch, basic team deathmatch, and advanced team deathmatch. Five maps, based on levels from the single-player portion of the game, were included with the original multiplayer patch, but many user-created maps exist. The PlayStation 2 release of "Deus Ex" does not offer a multiplayer mode. In April 2014 it was announced that GameSpy would cease their masterserver services, also affecting "Deus Ex". A community-made patch for the multiplayer mode has been created as a response to this.

"Deus Ex" takes place in an unspecified near future in an alternate history where real-world conspiracy theories are true. These include speculations regarding black helicopters, vaccinations, and FEMA, as well as Area 51, the ECHELON network, Men in Black, chupacabras (in the form of "greasels"), and grey aliens. Mysterious groups such as Majestic 12, the Illuminati, the Knights Templar, the Bilderberg Group, and the Trilateral Commission also either play a central part in the plot or are alluded to during the course of the game.

The plot of "Deus Ex" depicts a society on a slow spiral into chaos. There is a massive division between the rich and the poor, not only socially, but in some cities physically. A lethal pandemic, known as the "Gray Death", ravages the world's population, especially within the United States, and has no cure. A synthetic vaccine, "Ambrosia", manufactured by the company VersaLife, nullifies the effects of the virus but is in critically short supply. Because of its scarcity, Ambrosia is available only to those deemed "vital to the social order", and finds its way primarily to government officials, military personnel, the rich and influential, scientists, and the intellectual elite. With no hope for the common people of the world, riots occur worldwide, and some terrorist organizations have formed with the professed intent of assisting the downtrodden, among them the National Secessionist Forces (NSF) of the U.S. and a French group known as Silhouette.

To combat these threats to the world order, the United Nations has expanded its influence around the globe to form the United Nations Anti-Terrorist Coalition (UNATCO). It is headquartered near New York City in a bunker beneath Liberty Island, placed there after a terrorist strike on the Statue of Liberty.

The main character of "Deus Ex" is UNATCO agent JC Denton (voiced by Jay Franke), one of the first in a new line of agents physically altered with advanced nanotechnology to gain superhuman abilities, alongside his brother Paul (also voiced by Jay Franke), who joined UNATCO to avenge his parents' deaths at the hands of Majestic 12. His UNATCO colleagues include the mechanically-augmented and ruthlessly efficient field agents Gunther Hermann and Anna Navarre; Quartermaster General Sam Carter, and the bureaucratic UNATCO chief Joseph Manderley. UNATCO communications tech Alex Jacobson's character model and name are based on Warren Spector's nephew, Alec Jacobson.

JC's missions bring him into contact with various characters, including NSF leader Juan Lebedev, hacker and scientist Tracer Tong, nano-tech expert Gary Savage, Nicolette DuClare (daughter of an Illuminati member), former Illuminati leader Morgan Everett, the Artificial Intelligences (AI) Daedalus and Icarus, and Bob Page, owner of VersaLife and leader of Majestic 12, a clandestine organization that has usurped the infrastructure of the Illuminati, allowing him to control the world for his own ends.

After completing his training, UNATCO agent JC Denton takes several missions given by Director Joseph Manderley to track down members of the National Secessionist Forces (NSF) and their stolen shipments of the "Ambrosia" vaccine, the treatment for the "Gray Death" virus. Through these missions, JC is reunited with his brother, Paul, who is also nano-augmented. JC tracks the Ambrosia shipment to a private terminal at LaGuardia Airport. Paul meets JC outside the plane and explains that he has defected from UNATCO and is working with the NSF after learning that the Gray Death is a human-made virus, with UNATCO using its power to make sure only the elite receive the vaccine.

JC returns to UNATCO headquarters and is told by Manderley that both he and Paul have been outfitted with a 24-hour kill switch and that Paul's has been activated due to his betrayal. Manderley orders JC to fly to Hong Kong to eliminate Tracer Tong, a hacker whom Paul has contact with, and who can disable the kill switches. Instead, JC returns to Paul's apartment to find Paul hiding inside. Paul further explains his defection and encourages JC to also defect by sending out a distress call to alert the NSF's allies. Upon doing so, JC becomes a wanted man by UNATCO, and his kill switch is activated by Federal Emergency Management Agency (FEMA) Director Walton Simons. JC is unable to escape UNATCO forces, and both he and Paul (provided he survived the raid on the apartment) are taken to a secret prison below UNATCO headquarters. An entity named "Daedalus" contacts JC and informs him that the prison is part of Majestic 12, and arranges for him and Paul to escape. The two flee to Hong Kong to meet with Tong, who deactivates their kill switches. Tong requests that JC infiltrate the VersaLife building. Doing so, JC discovers that the corporation is the source for the Gray Death, and he can steal the plans for the virus and destroy the "universal constructor" (UC) that produces it.

Analysis of the virus shows that it was manufactured by the Illuminati, prompting Tong to send JC to Paris to try to make contact with the organization and obtain their help fighting Majestic 12. JC meets with Illuminati leader Morgan Everett and learns that the Gray Death virus was intended to be used for augmentation technology, but Majestic 12, led by trillionaire businessman and former Illuminatus Bob Page, was able to steal and repurpose it into its viral form. Everett recognizes that without VersaLife's universal constructor, Majestic 12 can no longer create the virus, and will likely target Vandenberg Air Force Base, where X-51, a group of former Area 51 scientists, have built another one. After aiding the base personnel in repelling a Majestic 12 attack, JC meets X-51 leader Gary Savage, who reveals that Daedalus is an artificial intelligence (AI) borne out of the ECHELON program. Everett attempts to gain control over Majestic 12's communications network by releasing Daedalus onto the U.S. military networks, but Page counters by releasing his own AI, Icarus, which merges with Daedalus to form a new AI, Helios, with the ability to control all global communications. After this, Savage enlists JC's help in procuring schematics for reconstructing components for the UC that were damaged during Majestic 12's raid of Vandenberg. JC finds the schematics and electronically transmits them to Savage. Page intercepts the transmission and launches a nuclear missile at Vandenberg to ensure that Area 51 (now Majestic 12's headquarters) will be the only location in the world with an operational UC. However, JC can reprogram the missile to strike Area 51. JC travels there himself to confront Page.

When JC locates him, Page reveals that he seeks to merge with Helios and gain full control over all nanotechnology. JC is contacted by Tong, Everett, and the Helios AI simultaneously. All three factions ask for his help in defeating Page while furthering their own objectives, and JC is forced to choose between them. Tong seeks to plunge the world into a Dark Age by destroying the global communications hub and preventing anyone from taking control of the world. Everett offers Denton the chance to bring the Illuminati back to power by killing Bob Page and using the technology of Area 51 to rule the world with an invisible hand. Helios wishes to merge with Denton and rule the world as a benevolent dictator with infinite knowledge and reason. The player's decision determines the course of the future and brings the game to a close.

After Looking Glass Technologies and Origin Systems released "" in January 1993, producer Warren Spector began to plan "Troubleshooter", the game that would become "Deus Ex". In his 1994 proposal, he described the concept as ""Underworld"-style first-person action" in a real-world setting with "big-budget, nonstop action". After Spector and his team were laid off from Looking Glass, John Romero of Ion Storm offered him the chance to make his "dream game" without any restrictions.

Preproduction for "Deus Ex" began around August 1997 and lasted roughly six months. The game's working title was "Shooter: Majestic Revelations", and it was scheduled for release on Christmas 1998. The team developed the setting before the game mechanics. Noticing his wife's fascination with "The X-Files", Spector connected the "real world, millennial weirdness, [and] conspiracy" topics on his mind and decided to make a game about them that would appeal to a broad audience. The "Shooter" design document cast the player as an augmented agent working against an elite cabal in the "dangerous and chaotic" 2050s. It cited "Half-Life", "Fallout", "", and "GoldenEye 007" as game design influences, and used the stories and settings of "", "The Manchurian Candidate", "Robocop", "The X-Files", and "Men in Black" as reference points. The team designed a skill system that featured "special powers" derived from nanotechnological augmentation and avoided the inclusion of die rolling and skills that required micromanagement. Spector also cited Konami's 1995 role-playing video game "Suikoden" as an inspiration, stating that the limited choices in "Suikoden" inspired him to expand on the idea with more meaningful choices in "Deux Ex".

In early 1998, the "Deus Ex" team grew to 20 people, and the game entered a 28-month production phase. The development team consisted of three programmers, six designers, seven artists, a writer, an associate producer, a "tech", and Spector. Two writers and four testers were hired as contractors. Chris Norden was the lead programmer and assistant director, Harvey Smith the lead designer, Jay Lee the lead artist, and Sheldon Pacotti the lead writer. Close friends of the team who understood the intentions behind the game were invited to playtest and give feedback. The wide range of input led to debates in the office and changes to the game. Spector later concluded that the team was "blinded by promises of complete creative freedom", and by their belief that the game would have no budget, marketing, or time restraints. By mid-1998, the game's title had become "Deus Ex", derived from the Latin literary device "deus ex machina" ("god from the machine"), in which a plot is resolved by an unpredictable intervention.

Spector felt that the best aspects of "Deus Ex"s development were the "high-level vision" and length of preproduction, flexibility within the project, testable "proto-missions", and the Unreal Engine license. The team's pitfalls included the management structure, unrealistic goals, underestimating risks with artificial intelligence, their handling of proto-missions, and weakened morale from bad press. "Deus Ex" was released on June 23, 2000, and published by Eidos Interactive for Microsoft Windows. The team planned third-party ports for Mac OS 9 and Linux.

The original 1997 design document for "Deus Ex" privileges character development over all other features. The game was designed to be "genre-busting": in parts simulation, role-playing, first-person shooter, and adventure. The team wanted players to consider "who they wanted to be" in the game, and for that to alter how they behaved in the game. In this way, the game world was "deeply simulated", or realistic and believable enough that the player would solve problems in creative, emergent ways without noticing distinct puzzles. However, the simulation ultimately failed to maintain the desired level of openness, and they had to brute force "skill", "action", and "character interaction" paths through each level. Playtesting also revealed that their idea of a role-playing game based on the real world was more interesting in theory than in reality, as certain aspects of the real world, such as hotels and office buildings, were not compelling in a game.

One of the things that Spector wanted to achieve in Deus Ex was to make JC Denton a cipher for the player, to create a better immersion and gameplay experience. He did not want the character to force any emotion, so that whatever feelings the player may be experiencing come from themselves rather than from JC Denton. To do this, Spector instructed voice actor Jay Anthony Franke to record his dialogue without any emotion but in a monotone voice, which is unusual for a voice acting role.

Once coded, the team's game systems did not work as intended. The early tests of the conversation system and user interface were flawed. The team also found augmentations and skills to be less interesting than they had seemed in the design document. In response, Harvey Smith substantially revised the augmentations and skills. Production milestones served as wake-up calls for the game's direction. A May 1998 milestone that called for a functional demo revealed that the size of the game's maps caused frame rate issues, which was one of the first signs that maps needed to be cut. A year later, the team reached a milestone for finished game systems, which led to better estimates for their future mission work and the reduction of the 500-page design document to 270 pages. Spector recalled Smith's mantra on this point: "less is more". 

One of the team's biggest blind spots was the AI programming for NPCs. Spector wrote that they considered it in preproduction, but that they did not figure out how to handle it until "relatively late in development". This led to wasted time when the team had to discard their old AI code. The team built atop their game engine's shooter-based AI instead of writing new code that would allow characters to exhibit convincing emotions. As a result, NPC behavior was variable until the very end of development. Spector felt that the team's "sin" was their inconsistent display of a trustable "human AI".

 The game was developed on systems including dual-processor Pentium Pro 200s and Athlon 800s with eight and nine gigabyte hard drives, some using SCSI. The team used "more than 100 video cards" throughout development. "Deus Ex" was built using Visual Studio, Lightwave, and Lotus Notes. They also made a custom dialogue editor, ConEdit. The team used UnrealEd atop the Unreal game engine for map design, which Spector wrote was "superior to anything else available". Their trust in UnrealScript led them to code "special-cases" for their immediate mission needs instead of more generalized multi-case code. Even as concerned team members expressed misgivings, the team only addressed this later in the project. To Spector, this was a lesson to always prefer "general solutions" over "special casing", such that the toolset works predictably.

They waited to license a game engine until after preproduction, expecting the benefits of licensing to be more time for the content and gameplay, which Spector reported to be the case. They chose the Unreal engine, as it did 80% of what they needed from an engine and was more economical than building from scratch. Their small programming team allowed for a larger design group. The programmers also found the engine accommodating, though it took about nine months to acclimate to the software. Spector felt that they would have understood the code better had they built it themselves, instead of "treating the engine as a black box" and coding conservatively. He acknowledged that this precipitated into the Direct3D issues in their final release, which slipped through their quality assurance testing. Spector also noted that the artificial intelligence, pathfinding, and sound propagation were designed for shooters and should have been rewritten from scratch instead of relying on the engine. He thought the licensed engine worked well enough that he expected to use the same for the game's sequel "" and "Thief 3". He added that developers should not attempt to force their technology to perform in ways it was not intended, and should find a balance between perfection and pragmatism.

The soundtrack of "Deus Ex", composed by Alexander Brandon (primary contributor, including main theme), Dan Gardopée ("Naval Base" and "Vandenberg"), Michiel van den Bos ("UNATCO", "Lebedev's Airfield", "Airfield Action", "DuClare Chateau", plus minor contribution to some of Brandon's tracks), and Reeves Gabrels ("NYC Bar"), was praised by critics for complementing the gritty atmosphere predominant throughout the game with melodious and ambient music incorporated from a number of genres, including techno, jazz, and classical. The music sports a basic dynamic element, similar to the iMUSE system used in early 1990s LucasArts games; during play, the music will change to a different iteration of the currently playing song based on the player's actions, such as when the player starts a conversation, engages in combat, or transitions to the next level. All the music in the game is tracked - Gabrels' contribution, "NYC Bar", was converted to a module by Brandon.

"Deus Ex" has been re-released in several iterations since its original publication and has also been the basis of several mods developed by its fan community.

The "Deus Ex: Game of the Year Edition", which was released on May 8, 2001, contains the latest game updates and a software development kit, a separate soundtrack CD, and a page from a fictional newspaper featured prominently in "Deus Ex" titled "The Midnight Sun", which recounts recent events in the game's world. However, later releases of said version do not include the soundtrack CD and contain a PDF version of the newspaper on the game's disc.

The Mac OS version of the game, released a month after the Windows version, was shipped with the same capabilities and can also be patched to enable multiplayer support. However, publisher Aspyr Media did not release any subsequent editions of the game or any additional patches. As such, the game is only supported in Mac OS 9 and the "Classic" environment in Mac OS X, neither of which are compatible with Intel-based Macs. The Windows version will run on Intel-based Macs using Crossover, Boot Camp, or other software to enable a compatible version of Windows to run on a Mac.

A PlayStation 2 port of the game, retitled "Deus Ex: The Conspiracy" outside of Europe, was released on March 26, 2002. Along with motion-captured character animations and pre-rendered introductory and ending cinematics that replaced the original versions, it features a simplified interface with optional auto-aim. There are many minor changes in level design, some to balance gameplay, but most to accommodate loading transition areas, due to the memory limitations of the PlayStation 2. The PlayStation 2 version was re-released in Europe on the PlayStation 3 as a PlayStation 2 Classic on May 16, 2012.

Loki Games worked on a Linux version of the game, but the company went out of business before releasing it. The OpenGL layer they wrote for the port, however, was sent out to Windows gamers through an online patch.

Though their quality assurance did not see major Direct3D issues, players noted "dramatic slowdowns" immediately following the launch, and the team did not understand the "black box" of the Unreal engine well enough to make it do exactly what they needed. Spector characterized "Deus Ex" reviews into two categories based on how they begin with either how "Warren Spector makes games all by himself" or that ""Deus Ex" couldn't possibly have been made by Ion Storm". He has said that the game won over 30 "best of" awards in 2001, and concluded that their final game was not perfect, but that they were much closer for having tried to "do things right or not at all".

"Deus Ex" was built on the Unreal Engine, which already had an active community of modders. In September 2000, Eidos Interactive and Ion Storm announced in a press release that they would be releasing the software development kit (SDK), which included all the tools used to create the original game. Several team members, as well as project director Warren Spector, stated that they were "really looking forward to seeing what [the community] does with our tools". The kit was released on September 22, 2000, and soon gathered community interest, followed by the release of tutorials, small mods, up to announcements of large mods and conversions. While Ion Storm did not hugely alter the engine's rendering and core functionality, they introduced role-playing elements.

In 2009, a fan-made mod called "The Nameless Mod" ("TNM") was released by Off Topic Productions. The game's protagonist is a user of an Internet forum, with digital places represented as physical locations. The mod offers roughly the same amount of gameplay as Deus Ex and adds several new features to the game, with a more open world structure than "Deus Ex" and new weapons such as the player character's fists. The mod was developed over seven years and has thousands of lines of recorded dialogue and two different parallel story arcs. Upon its release, "TNM" earned a 9/10 overall from "PC PowerPlay" magazine. In Mod DB's 2009 Mod of the Year awards, "The Nameless Mod" won the Editor's Choice award for Best Singleplayer Mod.

In 2015, during the 15th anniversary of the game's release, Square Enix (who had acquired Eidos earlier) endorsed a free fan-created mod, "Deus Ex: Revision" which was released through Steam. The mod, created by Caustic Creative, is a graphical overhaul of the original game, adding in support for newer versions of DirectX, improving the textures and the soundtrack from the original game, and adding in more world-building aesthetics.

According to "Computer Gaming World"s Stefan Janicki, "Deus Ex" had "sold well in North America" by early 2001. In the United States, it debuted at #6 on PC Data's sales chart for the week ending June 24, at an average retail price of $40. It fell to eighth place in its second week but rose again to position 6 in its third. It proceeded to place in the top 10 rankings for August 6–12 and the week ending September 2 and to secure 10th place overall for the months of July and August. "Deus Ex" achieved sales of 138,840 copies and revenues of $5 million in the United States by the end of 2000, according to PC Data. The firm tracked another 91,013 copies sold in the country during 2001.

The game was a larger hit in Europe; Janicki called it a "blockbuster" for the region, which broke a trend of weak sales for 3D games. He wrote, "[I]n Europe—particularly in England—the action/RPG dominated the charts all summer, despite competition from heavyweights like "Diablo II" and "The Sims"." In the German-speaking market, "PC Player" reported sales over 70,000 units for "Deus Ex" by early 2001. It debuted at #3 in the region for July 2000 and held the position in August, before dropping to #10, #12 and #27 over the following three months. In the United Kingdom, "Deus Ex" reached #1 on the sales charts during August and spent three months in the top 10. It received a "Silver" award from the Entertainment and Leisure Software Publishers Association (ELSPA) in February 2002, indicating lifetime sales of at least 100,000 units in the United Kingdom. The ELSPA later raised it to "Gold" status, for 200,000 sales.

In April 2009, Square-Enix revealed that "Deus Ex" had surpassed 1 million sales globally, but was outsold by "".

"Deus Ex" received critical acclaim, attaining a score of 90 out of 100 from 28 critics on Metacritic. Thierry Nguyen from "Computer Gaming World" said that the game "delivers moments of brilliance, idiocy, ingenuity, and frustration". "Computer Games Magazine" praised the title for its deep gameplay and its use of multiple solutions to situations in the game. Similarly, "Edge" highlighted the game's freedom of choice, saying that "Deus Ex" "never tells you what to do. Goals are set, but alter according to your decisions." "Eurogamer"s Rob Fahey lauded the game, writing, "Moody and atmospheric, compelling and addictive, this is first person gaming in grown-up form, and it truly is magnificent."

Former GameSpot reviewer Greg Kasavin, though awarding the game a score of 8.2 of 10, was disappointed by the security and lockpicking mechanics. "Such instances are essentially noninteractive", he wrote. "You simply stand there and spend a particular quantity of electronic picks or modules until the door opens or the security goes down." Kasavin made similar complaints about the hacking interface, noting that "Even with basic hacking skills, you'll still be able to bypass the encryption and password protection ... by pressing the 'hack' button and waiting a few seconds".

The game's graphics and voice acting were also met with muted enthusiasm. Kasavin complained of "Deus Ex"s relatively sub-par graphics, blaming them on the game's "incessantly dark industrial environments". GamePro reviewer Chris Patterson took the time to note that despite being "solid acoustically", "Deus Ex" had moments of weakness. He poked fun at JC's "Joe Friday, 'just the facts', deadpan", and the "truly cheesy accents" of minor characters in Hong Kong and New York City. IGN called the graphics "blocky", adding that "the animation is stiff, and the dithering is just plain awful in some spots", referring to the limited capabilities of the Unreal Engine used to design the game. The website, later on, stated that "overall Deus Ex certainly looks better than your average game".

Reviewers and players also complained about the size of "Deus Ex"s save files. An Adrenaline Vault reviewer noted that "Playing through the entire adventure, [he] accumulated over 250 MB of save game data, with the average file coming in at over 15 MB."

Jeff Lundrigan reviewed the PC version of the game for "Next Generation", rating it five stars out of five, and stated that "This is hands-down one of the best PC games ever made. Stop reading and go get yours now."

The game developed a strong cult following, leading to a core modding and playing community that remained active over 15 years after its release. In an interview with IGN in June 2015, game director Warren Spector said he never expected "Deus Ex" to sell many copies, but he did expect it to become a cult classic among a smaller, active community, and he continues to receive fan mail from players to date regarding their experiences and thoughts about "Deus Ex".

"Deus Ex" received over 30 "best of" awards in 2001, from outlets such as IGN, GameSpy, "PC Gamer", "Computer Gaming World", and The Adrenaline Vault. It won "Excellence in Game Design" and "Game Innovation Spotlight" at the 2001 Game Developers Choice Awards, and it was nominated for "Game of the Year". At the Interactive Achievement Awards, it won in the "Computer Innovation" and "Computer Action/Adventure" categories and received nominations for "Sound Design", "PC Role-Playing", and "Game of the Year" in both the PC and overall categories. The British Academy of Film and Television Arts named it "PC Game of the Year". The game also collected several "Best Story" accolades, including first prize in Gamasutra's 2006 "Quantum Leap" awards for storytelling in a video game.

Since its release, "Deus Ex" has appeared in several "Greatest Games of All Time" lists and Hall of Fame features. It was included in IGN's "100 Greatest Games of All Time" (#40, #21 and #34 in 2003, 2005 and 2007, respectively), "Top 25 Modern PC Games" (4th place in 2010) and "Top 25 PC Games of All Time" (#20 and #21 in 2007 and 2009 respectively) lists. GameSpy featured the game in its "Top 50 Games of All Time" (18th place in 2001) and "25 Most Memorable Games of the Past 5 Years" (15th place in 2004) lists, and in the site's "Hall of Fame". "PC Gamer" placed "Deus Ex" on its "Top 100 PC Games of All Time" (#2, #2, #1 by staff and #4 by readers in 2007, 2008, 2010 and 2010 respectively) and "50 Best Games of All Time" (#10 and #27 in 2001 and 2005) lists, and it was awarded 1st place in "PC Zone"s "101 Best PC Games Ever" feature. It was also included in Yahoo! UK Video Games' "100 Greatest Computer Games of All Time" (28th place) list, and in "Edge"s "The 100 Best Videogames" (29th place in 2007) and "100 Best Games to Play Today" (57th place in 2009) lists. "Deus Ex" was named the second-best game of the 2000s by Gamasutra. In 2012, "Time" named it one of the 100 greatest video games of all time, and G4tv ranked it as the 53rd best game of all time for its "complex and well-crafted story that was really the start of players making choices that genuinely affect the outcome". 1UP.com listed it as one of the most important games of all time, calling its influence "too massive to properly gauge".

A film adaptation based on the game was initially announced in May 2002 by Columbia Pictures. The film was being produced by Laura Ziskin, along with Greg Pruss attached with writing the screenplay. Peter Schlessel, president of the production for Columbia Pictures, and Paul Baldwin, president of marketing for Eidos Interactive, stated that they were confident in that the adaptation would be a successful development for both the studios and the franchise. In March 2003, during an interview with Greg Pruss, he informed IGN that the character of JC Denton would be "a little bit filthier than he was in the game". He further stated that the script was shaping up to be darker in tone than the original game. Although a release date was scheduled for 2006, the film did not get past the scripting stage.

In 2012, CBS films revived the project, buying the rights and commissioning a film inspired by the "Deux Ex" series; its direct inspiration was the 2011 game "". C. Robert Cargill and Scott Derrickson wee to write the screenplay, and Derrickson will direct the film.

A sequel to the game titled "", was released in the United States on December 2, 2003, and then in Europe in early 2004 for both the PC and the Xbox game console. A second sequel, titled "Deus Ex: Clan Wars", was initially conceived as a multiplayer-focused third game for the series. After the commercial performance and public reception of "Deus Ex: Invisible War" failed to meet expectations, the decision was made to set the game in a separate universe, and "Deus Ex: Clan Wars" was eventually published under the title "Project: Snowblind".

On March 29, 2007, Valve announced "Deus Ex" and its sequel would be available for purchase from their Steam service. Among the games announced are several other Eidos franchise titles, including "" and "Tomb Raider".

Eidos Montréal produced a prequel to "Deus Ex" called "". This was confirmed on November 26, 2007, when Eidos Montréal posted a teaser trailer for the title on their website. The game was released on August 23, 2011, for the PC, PlayStation 3, and Xbox 360 platforms and received critical acclaim.

On April 7, 2015, Eidos announced a sequel to "Deus Ex: Human Revolution" and second prequel to "Deus Ex" titled "". It was released on August 23, 2016.




</doc>
<doc id="8485" url="https://en.wikipedia.org/wiki?curid=8485" title="Diego Maradona">
Diego Maradona

Diego Armando Maradona (, born 30 October 1960) is an Argentine football manager and retired professional footballer. He is currently the coach of Argentine Primera División club Gimnasia de La Plata. He is widely regarded as one of the greatest football players of all time. He was one of the two joint winners of the FIFA Player of the 20th Century award. Maradona's vision, passing, ball control and dribbling skills were combined with his small stature (), which gave him a low center of gravity allowing him to maneuver better than most other football players; he would often dribble past multiple opposing players on a run. His presence and leadership on the field had a great effect on his team's general performance, while he would often be singled out by the opposition. In addition to his creative abilities, he also possessed an eye for goal and was known to be a free kick specialist. A precocious talent, Maradona was given the nickname ""El Pibe de Oro"" ("The Golden Boy"), a name that stuck with him throughout his career.

An advanced playmaker who operated in the classic number 10 position, Maradona was the first player in football history to set the world record transfer fee twice, first when he transferred to Barcelona for a then world record £5 million, and second, when he transferred to Napoli for another record fee £6.9 million. He played for Argentinos Juniors, Boca Juniors, Barcelona, Napoli, Sevilla and Newell's Old Boys during his club career, and is most famous for his time at Napoli and Barcelona where he won numerous accolades.

In his international career with Argentina, he earned 91 caps and scored 34 goals. Maradona played in four FIFA World Cups, including the 1986 World Cup in Mexico where he captained Argentina and led them to victory over West Germany in the final, and won the Golden Ball as the tournament's best player. In the 1986 World Cup quarter final, he scored both goals in a 2–1 victory over England that entered football history for two different reasons. The first goal was an unpenalized handling foul known as the "Hand of God", while the second goal followed a dribble past five England players, voted "Goal of the Century" by FIFA.com voters in 2002.

Maradona became coach of Argentina in November 2008. He was in charge of the team at the 2010 World Cup in South Africa before leaving at the end of the tournament. He coached Dubai-based club Al Wasl in the UAE Pro-League for the 2011–12 season. In 2017, Maradona became the coach of Fujairah before leaving at the end of the season. In May 2018, Maradona was announced as the new chairman of Belarusian club Dynamo Brest. He arrived in Brest and was presented by the club to start his duties in July. From September 2018 to June 2019, Maradona was coach of Mexican club Dorados.

Diego Armando Maradona was born on 30 October 1960, at the Policlínico (Polyclinic) Evita Hospital in Lanús, Buenos Aires Province, but raised in Villa Fiorito, a shantytown on the southern outskirts of Buenos Aires, Argentina, to a poor family that had moved from Corrientes Province. He was the first son after four daughters. He has two younger brothers, Hugo ("el Turco") and Raúl (Lalo), both of whom were also professional football players. 
His parents were Diego Maradona "Chitoro" (d. 2015) and Dalma Salvadora Franco 'Doña Tota' (1930–2011). They were both born and brought up in the town of Esquina in the north-east province of Corrientes Province, living only two hundred metres from each other on the banks of the Corriente River. In 1950, they left Esquina and settled in Buenos Aires. At age eight, Maradona was spotted by a talent scout while he was playing in his neighbourhood club Estrella Roja. He became a staple of "Los Cebollitas" (The Little Onions), the junior team of Buenos Aires's Argentinos Juniors. As a 12-year-old ball boy, he amused spectators by showing his wizardry with the ball during the halftime intermissions of first division games. He named Brazilian playmaker Rivelino and Manchester United winger George Best among his inspirations growing up.

On 20 October 1976, Maradona made his professional debut for Argentinos Juniors, 10 days before his 16th birthday, vs. Talleres de Córdoba. He entered to the pitch wearing the number 16 jersey, and became the youngest player in the history of Argentine Primera División. Few minutes after debuting, Maradona kicked the ball through Juan Domingo Cabrera's legs, making a nutmeg that would become legendary. After the game, Maradona said, "That day I felt I had held the sky in my hands." Thirty years later, Cabrera remembered Maradona's debut: "I was on the right side of the field and went to press him, but he didn't give me a chance. He made the nutmeg and when I turned around, he was far away from me". Maradona scored his first goal in the Primera División against Marplatense team San Lorenzo on 14 November 1976, two weeks after turning 16.
Maradona spent five years at Argentinos Juniors, from 1976 to 1981, scoring 115 goals in 167 appearances before his US$ 4 million transfer to Boca Juniors. Maradona received offers to join other clubs, including River Plate who offered to make him the club's best paid player. Nevertheless, Maradona expressed his will to be transferred to Boca Juniors, the team he always wanted to play for.

Maradona signed a contract with Boca Juniors on 20 February 1981. He made his debut two days later against Talleres de Córdoba, scoring twice in the club's 4–1 win. On 10 April, Maradona played his first "Superclásico" against River Plate at La Bombonera stadium. Boca defeated River 3–0 with Maradona scoring a goal after dribbling past Alberto Tarantini and Fillol. Despite the distrustful relationship between Maradona and Boca Juniors manager, Silvio Marzolini, Boca had a successful season, winning the league title after securing a point against Racing Club. That would be the only title won by Maradona in the Argentine domestic league.

After the 1982 World Cup, in June, Maradona was transferred to Barcelona in Spain for a then world record fee of £5 million ($7.6 million). In 1983, under coach César Luis Menotti, Barcelona and Maradona won the Copa del Rey (Spain's annual national cup competition), beating Real Madrid, and the Spanish Super Cup, beating Athletic Bilbao. On 26 June 1983, Barcelona defeated Real Madrid on the road in one of the world's biggest club games, "El Clásico", a match where Maradona scored and became the first Barcelona player to be applauded by archrival Real Madrid fans. Maradona dribbled past Madrid goalkeeper Agustín, and as he approached the empty goal, he stopped just as Madrid defender Juan José came sliding in a desperate attempt to block the shot and ended up crashing into the post, before Maradona slotted the ball into the net. The manner of the goal led to many inside the stadium start applauding; only Ronaldinho (in November 2005) and Andrés Iniesta (in November 2015) have since been granted such an ovation as Barcelona players from Madrid fans at the Santiago Bernabéu. Due to illness and injury as well as controversial incidents on the field, Maradona had a difficult tenure in Barcelona. First a bout of hepatitis, then a broken ankle in a La Liga game at the Camp Nou in September 1983 caused by an ill-timed tackle by Athletic Bilbao's Andoni Goikoetxea, threatened to jeopardize Maradona's career, but with treatment and therapy, it was possible for him to return to the pitch after a three-month recovery period.
The end of the 1983–84 season included a violent and chaotic fight Maradona was directly involved in at the 1984 Copa del Rey final at the Santiago Bernabéu in Madrid against Athletic Bilbao. After receiving another rough tackle by Goikoetxea which wounded his leg, being taunted with xenophobic, racist insults related to his father's Native American ancestry throughout the match by Bilbao fans, and being provoked by Bilbao's Miguel Sola at full time as Barcelona lost 1–0, Maradona snapped. He aggressively got up, stood inches from Sola's face and the two exchanged words. This started a chain reaction of emotional reactions from both teams. Using expletives, Sola mimicked a gesture from the crowd towards Maradona by using a xenophobic term. Maradona then headbutted Sola, elbowed another Bilbao player in the face and kneed another player in the head, knocking him out cold. The Bilbao squad surrounded Maradona to exact some retribution with Goikoetxea connecting with a high kick to his chest, before the rest of the Barcelona squad joined in to help Maradona. From this point, Barcelona and Bilbao players brawled on the field with Maradona in the centre of the action, kicking and punching anyone in a Bilbao shirt.

The mass brawl was played out in front of the Spanish King Juan Carlos and an audience of 100,000 fans inside the stadium, and more than half of Spain watching on television. After fans began throwing solid objects on the field at the players, coaches and even photographers, sixty people were injured, with the incident effectively sealing Maradona's transfer out of the club in what was his last game in a Barcelona shirt. One Barcelona executive stated, "When I saw those scenes of Maradona fighting and the chaos that followed I realized we couldn't go any further with him." Maradona got into frequent disputes with FC Barcelona executives, particularly club president Josep Lluís Núñez, culminating with a demand to be transferred out of Camp Nou in 1984. During his two injury-hit seasons at Barcelona, Maradona scored 38 goals in 58 games. Maradona transferred to Napoli in Italy's Serie A for another world record fee, £6.9 million ($10.48M).

Maradona arrived in Naples and was presented to the world media as a Napoli player on 5 July 1984, where he was welcomed by 75,000 fans at his presentation at the Stadio San Paolo. Sports writer David Goldblatt commented, "They [the fans] were convinced that the saviour had arrived." A local newspaper stated that despite the lack of a "mayor, houses, schools, buses, employment and sanitation, none of this matters because we have Maradona". Prior to Maradona's arrival, Italian football was dominated by teams from the north and centre of the country, such as A.C. Milan, Juventus, Inter Milan and Roma, and no team in the south of the Italian Peninsula had ever won a league title.

At Napoli, Maradona reached the peak of his professional career: he soon inherited the captain's armband from Napoli veteran defender Giuseppe Bruscolotti and quickly became an adored star among the club's fans; in his time there he elevated the team to the most successful era in its history. Maradona played for Napoli at a period when north–south tensions in Italy were at a peak due to a variety of issues, notably the economic differences between the two. Led by Maradona, Napoli won their first ever Serie A Italian Championship in 1986–87. Goldblatt wrote, "The celebrations were tumultuous. A rolling series of impromptu street parties and festivities broke out contagiously across the city in a round-the-clock carnival which ran for over a week. The world was turned upside down. The Neapolitans held mock funerals for Juventus and Milan, burning their coffins, their death notices announcing 'May 1987, the other Italy has been defeated. A new empire is born.'" Murals of Maradona were painted on the city's ancient buildings, and newborn children were named in his honor. The following season, the team's prolific attacking trio, formed by Maradona, Bruno Giordano and Careca, was later dubbed the "Ma-Gi-Ca" ("magical") front-line.

Napoli would win their second league title in 1989–90, and finish runners up in the league twice, in 1987–88 and 1988–89. Other honors during the Maradona era at Napoli included the Coppa Italia in 1987, (as well as a second place finish in the Coppa Italia in 1989), the UEFA Cup in 1989 and the Italian Supercup in 1990. During the 1989 UEFA Cup Final against Stuttgart, Maradona scored from a penalty in a 2–1 home victory in the first leg, later assisting Careca's match–winning goal, while in the second leg on 17 May – a 3–3 away draw –, he assisted Ciro Ferrara's goal with a header. Despite primarily playing in a creative role as an attacking midfielder, Maradona was the top scorer in Serie A in 1987–88, with 15 goals, and was the all-time leading goalscorer for Napoli, with 115 goals, until his record was broken by Marek Hamšík in 2017. When asked who was the toughest player he ever faced, A.C. Milan central defender Franco Baresi stated, that it was Maradona, a view shared by his Milan teammate Paolo Maldini, who viewed Maradona and Ronaldo as the best players he ever faced, stating in 2008, "The best ever I played against was Maradona."

While Maradona was successful on the field during his time in Italy, his personal problems increased. His cocaine use continued, and he received US$70,000 in fines from his club for missing games and practices, ostensibly because of "stress". He faced a scandal there regarding an illegitimate son, and he was also the object of some suspicion over an alleged friendship with the Camorra. Later on, in honour of Maradona and his achievements during his career at Napoli, the number 10 jersey of Napoli was officially retired.

After serving a 15-month ban for failing a drug test for cocaine, Maradona left Napoli in disgrace in 1992. Despite interest from Real Madrid and Marseille, he signed for Sevilla, where he stayed for one year. In 1993, he played for Newell's Old Boys and in 1995 returned to Boca Juniors for a two-year stint. Maradona also appeared for Tottenham Hotspur in a testimonial match for Osvaldo Ardiles against Internazionale, shortly before the 1986 World Cup. Maradona was himself given a testimonial match in November 2001, played between an all-star World XI and the Argentina national team.

During his time with the Argentina national team, Maradona scored 34 goals in 91 appearances. He made his full international debut at age 16, against Hungary, on 27 February 1977. Maradona was left off the Argentine squad for the 1978 World Cup on home soil by coach César Luis Menotti who felt he was too young at age 17. At age 18, Maradona played the 1979 FIFA World Youth Championship in Japan and emerged as the star of the tournament, shining in Argentina's 3–1 final win over the Soviet Union. On 2 June 1979, Maradona scored his first senior international goal in a 3–1 win against Scotland at Hampden Park. He went on to play for Argentina in two 1979 Copa América ties during August 1979, a 2–1 loss against Brazil and a 3–0 win over Bolivia in which he scored his side's third goal.

Speaking thirty years later on the impact of Maradona's performances in 1979, FIFA President Sepp Blatter stated, "Everyone has an opinion on Diego Armando Maradona, and that’s been the case since his playing days. My most vivid recollection is of this incredibly gifted kid at the second FIFA U-20 World Cup in Japan in 1979. He left everyone open-mouthed every time he got on the ball." Maradona and his compatriot Lionel Messi are the only players to win the Golden Ball at both the FIFA U-20 World Cup and FIFA World Cup. Maradona did so in 1979 and 1986, which Messi emulated in 2005 and 2014.

Maradona played his first World Cup tournament in 1982 in his new country of residence, Spain. Argentina played Belgium in the opening game of the 1982 Cup at the Camp Nou in Barcelona. The Catalan crowd was eager to see their new world-record signing Maradona in action, but he did not perform to expectations, as Argentina, the defending champions, lost 1–0. Although the team convincingly beat both Hungary and El Salvador in Alicante to progress to the second round, there were internal tensions within the team, with the younger, less experienced players at odds with the older, more experienced players. In a team that also included such players as Mario Kempes, Osvaldo Ardiles, Ramón Díaz, Daniel Bertoni, Alberto Tarantini, Ubaldo Fillol and Daniel Passarella, the Argentine side was defeated in the second round by Brazil and by eventual winners Italy. The Italian match is renowned for Maradona being aggressively man-marked by Claudio Gentile, as Italy beat Argentina at the Sarrià Stadium in Barcelona, 2–1.

Maradona played in all five matches without being substituted, scoring twice against Hungary. He was fouled repeatedly in all five games and particularly in the last one against Brazil at the Sarrià, a game that was blighted by poor officiating and violent fouls. With Argentina already down 3–0 to Brazil, Maradona's temper eventually got the better of him and he was sent off with five minutes remaining for a serious retaliatory foul against Batista.

Maradona captained the Argentine national team to victory in the 1986 World Cup in Mexico, winning the final in Mexico City against West Germany. Throughout the tournament, Maradona asserted his dominance and was the most dynamic player of the tournament. He played every minute of every Argentina game, scoring five goals and making five assists, three of those in the opening match against South Korea at the Olimpico Universitario Stadium in Mexico City. His first goal of the tournament came against Italy in the second group game in Puebla. Argentina eliminated Uruguay in the first knockout round in Puebla, setting up a match against England at the Azteca Stadium, also in Mexico City. After scoring two contrasting goals in the 2–1 quarter-final win against England, his legend was cemented. The majesty of his second goal and the notoriety of his first led to the French newspaper "L'Equipe" describing Maradona as "half-angel, half-devil". This match was played with the background of the Falklands War between Argentina and the United Kingdom. Replays showed that the first goal was scored by striking the ball with his hand. Maradona was coyly evasive, describing it as "a little with the head of Maradona and a little with the hand of God". It became known as the "Hand of God". Ultimately, on 22 August 2005, Maradona acknowledged on his television show that he had hit the ball with his hand purposely, and no contact with his head was made, and that he immediately knew the goal was illegitimate. This became known as an international fiasco in World Cup history. The goal stood, much to the wrath of the English players.

Maradona's second goal, just four minutes after the hotly disputed hand-goal, was later voted by FIFA as the greatest goal in the history of the World Cup. He received the ball in his own half, swivelled around and with 11 touches ran more than half the length of the field, dribbling past five English outfield players (Peter Beardsley, Steve Hodge, Peter Reid, Terry Butcher and Terry Fenwick) before he left goalkeeper Peter Shilton on his backside with a feint, and slotted the ball into the net. This goal was voted "Goal of the Century" in a 2002 online poll conducted by FIFA. A 2002 Channel 4 poll in the UK saw his performance ranked number 6 in the list of the 100 Greatest Sporting Moments.
Maradona followed this with two more goals in a semi-final match against Belgium at the Azteca, including another virtuoso dribbling display for the second goal. In the final match, West Germany attempted to contain him by double-marking, but he nevertheless found the space past the West German player Lothar Matthäus to give the final pass to Jorge Burruchaga for the winning goal. Argentina beat West Germany 3–2 in front of 115,000 fans at the Azteca with Maradona lifting the World Cup as captain.

During the course of the tournament, Maradona attempted or created more than half of Argentina's shots, attempted a tournament best 90 dribbles – some three times more than any other player – and was fouled a record 53 times, winning his team twice as many free kicks as any player. Maradona scored or assisted 10 of Argentina's 14 goals (71%), including the assist for the winning goal in the final, ensuring that he would be remembered as one of the greatest names in football history. By the end of the World Cup, Maradona went on to win the Golden Ball as the best player of the tournament by unanimous vote and was widely regarded to have won the World Cup virtually single-handedly, something that he later stated he did not entirely agree with. Zinedine Zidane, watching the 1986 World Cup as a 14-year-old, stated Maradona "was on another level". In a tribute to him, Azteca Stadium authorities built a statue of him scoring the "Goal of the Century" and placed it at the entrance of the stadium.

Regarding Mardona's performance at the 1986 World Cup in Mexico, in 2014, Roger Bennett of "ESPN FC" described it as "the most virtuoso performance a World Cup has ever witnessed," while Kevin Baxter of the "Los Angeles Times" called it "one of the greatest individual performances in tournament history," with Steven Goff of "The Washington Post" instead dubbing his performance as "one of the finest in tournament annals." In 2002, Russell Thomas of "The Guardian" described Maradona's second goal against England in the 1986 World Cup quarter-finals as "arguably the greatest individual goal ever." In a 2009 article for "CBC Sports", John Molinaro described the goal as "the greatest ever scored in the tournament – and, maybe, in soccer." In a 2018 article for "Sportsnet", he added: "No other player, not even Pel[é] in 1958 nor Paolo Rossi in 1982, had dominated a single competition the way Maradona did in Mexico." He also went on to say of Maradona's performance: "The brilliant Argentine artist single-handedly delivered his country its second World Cup." Regarding his two memorable goals against England in the quarter-finals, he commented: "Yes, it was Maradona’s hand, and not God’s, that was responsible for the first goal against England. But while the 'Hand of God' goal remains one of the most contentious moments in World Cup history, there can be no disputing that his second goal against England ranks as the greatest ever scored in the tournament. It transcended mere sports—his goal was pure art."

Maradona captained Argentina again in the 1990 World Cup in Italy to yet another World Cup final. An ankle injury affected his overall performance, and he was much less dominant than four years earlier. After losing their opening game to Cameroon at the San Siro in Milan, Argentina were almost eliminated in the first round, only qualifying in third position from their group. In the round of 16 match against Brazil in Turin, Claudio Caniggia scored the only goal after being set up by Maradona.

In the quarter-final, Argentina faced Yugoslavia in Florence; the match ended 0–0 after 120 minutes, with Argentina advancing in a penalty shootout even though Maradona's kick, a weak shot to the goalkeeper's right, was saved. The semi-final against the host nation Italy at Maradona's club stadium in Naples, the Stadio San Paolo, was also resolved on penalties after a 1–1 draw. This time, however, Maradona was successful with his effort, daringly rolling the ball into the net with an almost exact replica of his unsuccessful kick in the previous round. At the final in Rome, Argentina lost 1–0 to West Germany, the only goal being a penalty by Andreas Brehme in the 85th minute after a controversial foul on Rudi Völler.

At the 1994 World Cup in the United States, Maradona played in only two games (both at the Foxboro Stadium near Boston), scoring one goal against Greece, before being sent home after failing a drug test for ephedrine doping. After scoring against Greece, Maradona had one of the most infamous World Cup goal celebrations as he ran towards one of the sideline cameras shouting with a distorted face and bulging eyes. This turned out to be Maradona's last international goal for Argentina in what was his last appearance for his country.

In his autobiography, Maradona argued that the test result was due to his personal trainer giving him the power drink Rip Fuel. His claim was that the U.S. version, unlike the Argentine one, contained the chemical and that, having run out of his Argentine dosage, his trainer unwittingly bought the U.S. formula. FIFA expelled him from USA '94, and Argentina were subsequently eliminated in the second round by Romania in Los Angeles. Maradona has also separately claimed that he had an agreement with FIFA, on which the organization reneged, to allow him to use the drug for weight loss before the competition in order to be able to play. His failed drugs test at the 1994 World Cup signaled the end of his international career, which had lasted 17 years and yielded 34 goals from 91 games, as well as one winner's medal and one runners-up medal in the World Cup.

Described as a "classic number 10" in the media, Maradona was a traditional playmaker who usually played in a free role, either as an attacking midfielder behind the forwards, or as a second striker in a front–two, although he was also deployed as an offensive–minded central midfielder in a 4–4–2 formation on occasion. Maradona was renowned for his dribbling ability, vision, close ball control, passing and creativity, and is considered one of the most skillful players in the sport. He had a compact physique, and with his strong legs, low center of gravity, and resulting balance, he could withstand physical pressure well while running with the ball, despite his small stature, while his acceleration, quick feet, and agility, combined with his dribbling skills and close control at speed, allowed him to change direction quickly, making him difficult for opponents to defend against. He is regarded by several pundits and football figures as one of the greatest dribblers in the history of the game; former Dutch player Johan Cruyff saw similarities between Maradona and Lionel Messi with the ball seemingly attached to their body when dribbling. His physical strengths were illustrated by his two goals against Belgium in the 1986 World Cup. Although he was known for his penchant for undertaking individual runs with the ball, he was also a strategist and an intelligent team player, with excellent spatial awareness, as well as being highly technical with the ball. He could manage himself effectively in limited spaces, and would attract defenders only to quickly dash out of the melee (as in the second 1986-goal against England), or give an assist to a free teammate. Being short, but strong, he could hold the ball long enough with a defender on his back to wait for a teammate making a run or to find a gap for a quick shot. He showed leadership qualities on the field and captained Argentina in their World Cup campaigns of 1986, 1990 and 1994. While he was primarily a creative playmaker, Maradona was also known for his finishing and goalscoring ability. Former Milan manager Arrigo Sacchi also praised Maradona for his defensive work–rate off the ball in a 2010 interview with "Il Corriere dello Sport".
The team leader on and off the field – he would speak up on a range of issues on behalf of the players – Maradona's ability as a player and his overpowering personality had a major positive effect on his team, with his 1986 World Cup teammate Jorge Valdano stating: "Maradona was a technical leader: a guy who resolved all difficulties that may come up on the pitch. Firstly, he was in charge of making the miracles happen, that's something that gives team-mates a lot of confidence. Secondly, the scope of his celebrity was such that he absorbed all the pressures on behalf of his team-mates. What I mean is: one slept soundly the night before a game not just because you knew you were playing next to Diego and Diego did things no other player in the world could do, but also because unconsciously we knew that if it was the case that we lost then Maradona would shoulder more of the burden, would be blamed more, than the rest of us. That was the kind of influence he exercised on the team." Lauding the "charisma" of Maradona, another of his Argentina teammates, prolific striker Gabriel Batistuta, stated, "Diego could command a stadium, have everyone watch him. I played with him and I can tell you how technically decisive he was for the team". Napoli's former president – Corrado Ferlaino – commented on Maradona's leadership qualities during his time with the club in 2008, describing him as "a coach on the pitch."
One of Maradona's trademark moves was dribbling full-speed on the right wing, and on reaching the opponent's goal line, delivering accurate passes to his teammates. Another trademark was the "rabona", a reverse-cross pass shot behind the leg that holds all the weight. This maneuver led to several assists, such as the cross for Ramón Díaz's header against Switzerland in 1980. He was also a dangerous free kick and penalty kick taker, who was renowned for his ability to bend the ball from corners and direct set pieces. Regarded as one of he best dead–ball specialists of all time, his free kick technique, which often saw him raise his knee at a high angle when striking the ball, thus enabling him to lift it high over the wall, allowed him to score free kicks even from close range, within 22 to 17 yards (20 to 16 metres) from the goal, or even just outside the penalty area. His style of taking free kicks influenced several other specialists, including Gianfranco Zola, Andrea Pirlo, and Lionel Messi.
Maradona was famous for his cunning personality. Inherent within his nickname "El Pibe de Oro" ("Golden Boy") is a sense of mischief, with "pibe" being an anti-establishment rogue, street smart and full of guile. Some critics view his controversial "Hand of God" goal at the 1986 World Cup as a clever maneuver, with one of the opposition players, Glenn Hoddle, admitting that Maradona had disguised it by flicking his head at the same time as palming the ball. The goal itself has been viewed as an embodiment of the Buenos Aires shanty town Maradona was brought up in and its concept of "viveza criolla" — "native cunning". While critical of the illegitimate first goal, England striker Gary Lineker conceded, "When Diego scored that second goal against us, I felt like applauding. I'd never felt like that before, but it's true... and not just because it was such an important game. It was impossible to score such a beautiful goal. He's the greatest player of all time, by a long way. A genuine phenomenon." Maradona used his hand in the 1990 World Cup, again without punishment, and this time on his own goal line, to prevent the Soviet Union from scoring. A number of publications have referred to Maradona as the Artful Dodger, the urchin pickpocket from Charles Dickens' "Oliver Twist".

Maradona was dominantly left-footed, often using his left foot even when the ball was positioned more suitably for a right-footed connection. His first goal against Belgium in the 1986 World Cup semi-final is a worthy indicator of such; he had run into the inside right channel to receive a pass but let the ball travel across to his left foot, requiring more technical ability. During his run past several England players in the previous round for the "Goal of the Century" he did not use his right foot once, despite spending the whole movement on the right-hand side of the pitch. In the 1990 World Cup second round tie against Brazil, he did use his right foot to set up the winning goal for Claudio Caniggia due to two Brazilian markers forcing him into a position that made use of his left foot less practical.

Regarded as the best player of his generation, as well as one of the greatest players of all time by several pundits, players, and managers, and by some as the best player ever, Maradona is renowned as one of the most skilful players in the history of football, as well as being considered one of the greatest dribblers and free kick takers in the history of the sport. Considered to be a precocious talent in his youth, in addition to his playing ability, Maradona also drew praise from his former manager Menotti for his dedication, determination, and the work-ethic he demonstrated in order to improve the technical aspect of his game in training, despite his natural gifts, with the manager noting: "I'm always cautious about using the word 'genius'. I find it hard to apply that even to Mozart. The beauty of Diego's game has a hereditary element – his natural ease with the ball – but it also owes a lot to his ability to learn: a lot of those brushstrokes, those strokes of 'genius', are in fact a product of his hard work. Diego worked very hard to be the best." Maradona's former Napoli manager – Ottavio Bianchi – also praised his discipline in training, commenting: "Diego is different to the one that they depict. When you got him on his own he was a very good kid. It was beautiful to watch him and coach him. They all speak of the fact that he did not train, but it was not true because Diego was the last person to leave the pitch, it was necessary to send him away because otherwise he would stay for hours to invent free kicks." However, although, as Bianchi noted, Maradona was known for making "great plays" and doing "unimaginable" and "incredible things" with the ball during training sessions, and would even go through periods of rigorous exercise, he was equally known for his limited work-rate in training without the ball, and even gained a degree of infamy during his time in Italy for missing training sessions with Napoli, while he often trained independently instead of with his team.

In a 2019 documentary film on his life, Maradona confessed that his weekly regime consisted of "playing a game on Sunday, going out until Wednesday, then hitting the gym on Thursday." Regarding his inconsistent training regimen, the film's director, Asif Kapadia, commented in 2020: "He had a metabolism. He would look so incredibly out of shape, but then he’d train like crazy and sweat it off by the time matchday came along. His body shape just didn’t look like a footballer, but then he had this ability and this balance. He had a way of being, and that idea of talking to him honestly about how a typical week transpired was pretty amazing." He also revealed that Maradona was ahead of his time in the fact that he had a personal fitness coach – Fernando Signorini – who trained him in a variety of areas, in addition to looking after his physical conditioning, adding: "While he [Maradona] was in a football team he had his own regime. How many players would do that? How many players would even know to think like that? 'I’m different to anyone else so I need to train at what I’m good at and what I’m weak at.' Signorini is very well read and very intelligent. He would literally say, 'This is the way I’m going to train you, read this book.' He would help him psychologically, talk to him about philosophy, and things like that." Moreover, Maradona was notorious for his poor diet and extreme lifestyle off the pitch, including his use of illicit drugs and alcohol abuse, which along with personal issues, his metabolism, medication that he was prescribed, and periods of inactivity due to injuries and suspensions, led to his significant weight–gain and physical decline as his career progressed; his lack of dispcipline and difficulties in his turbulent personal life are thought by some in the sport to have negatively impacted his performances and longevity in the later years of his playing career.

A controversial footballing figure, while he earned critical acclaim from players, pundits, and managers over his playing style, he also drew criticism in the media for his temper and confrontational behaviour, both on and off the pitch. However, in 2005, Paolo Maldini, described Maradona both as the greatest player he ever faced, and also as the most honest, stating: "He was a model of good behaviour on the pitch – he was respectful of everyone, from the great players down to the ordinary team member. He was always getting kicked around and he never complained – not like some of today's strikers." His former defensive club and international teammate, Baresi, stated when he was asked who was his greatest opponent: "Maradona; when he was on form, there was almost no way of stopping him," while fellow former Italy defender Giuseppe Bergomi described Maradona as the greatest player of all time in 2018.

In 1999, Maradona was placed second behind Pelé' by "World Soccer" in the magazine's list of the "100 Greatest Players of the 20th Century." Along with Pelé, Maradona was one of the two joint winners of the "FIFA Player of the Century" award in 2000, and also placed fifth in "IFFHS' Century Elections." In a 2014 FIFA poll, Maradona was voted the second-greatest number 10 of all-time, behind only Pelé, and later that year, was ranked second in "The Guardian"'s list of the 100 greatest World Cup players of all-time, ahead of the 2014 World Cup in Brazil, once again behind Pelé. In 2017, "FourFourTwo" ranked him in first place in their list of "100 greatest players," while in 2018, he was ranked in first place by the same magazine in their list of the "Greatest Football Players in World Cup History"; in March 2020, he was also ranked first by Jack Gallagher of "90min.com" in their list of "Top 50 Greatest Players of All Time." In May 2020, "Sky Sports" ranked him as the best player ever never to have won the Champions League or European Cup.

Hounded for years by the press, Maradona once fired a compressed-air rifle at reporters who he claimed were invading his privacy. This quote from former teammate Jorge Valdano summarizes the feelings of many:
In 1990, the Konex Foundation from Argentina granted him the Diamond Konex Award, one of the most prestigious culture awards in Argentina, as the most important personality in Sports in the last decade in his country. In 2000, Maradona published his autobiography "Yo Soy El Diego" ("I am "The Diego""), which became a bestseller in Argentina. Two years later, Maradona donated the Cuban royalties of his book to "the Cuban people and Fidel".

In 2000, he won FIFA Player of the Century award which was to be decided by votes on their official website, their official magazine and a grand jury. Maradona won the Internet-based poll, garnering 53.6% of the votes against 18.53% for Pelé. In spite of this, and shortly before the ceremony, FIFA added a second award and appointed a "Football Family" committee composed of football journalists that also gave to Pelé the title of best player of the century to make it a draw. Maradona also came fifth in the vote of the IFFHS (International Federation of Football History and Statistics). In 2001, the Argentine Football Association (AFA) asked FIFA for authorization to retire the jersey number 10 for Maradona. FIFA did not grant the request, even though Argentine officials have maintained that FIFA hinted that it would.

Maradona has topped a number of fan polls, including a 2002 FIFA poll in which his second goal against England was chosen as the best goal ever scored in a World Cup; he also won the most votes in a poll to determine the All-Time Ultimate World Cup Team. On 22 March 2010, Maradona was chosen number 1 in The Greatest 10 World Cup players of all time by the London-based newspaper "The Times". Argentinos Juniors named its stadium after Maradona on 26 December 2003. In 2003, Maradona was employed by the Libyan footballer Al-Saadi Gaddafi, the third son of Colonel Muammar Gaddafi, as a "technical consultant", while Al-Saadi was playing for the Italian club, Perugia, which was playing in Serie A at the time.

On 22 June 2005, it was announced that Maradona would return to former club Boca Juniors as a sports vice president in charge of managing the First Division roster (after a disappointing 2004–05 season, which coincided with Boca's centenary). His contract began 1 August 2005, and one of his first recommendations proved to be very effective: advising the club to hire Alfio Basile as the new coach. With Maradona fostering a close relationship with the players, Boca won the 2005 Apertura, the 2006 Clausura, the 2005 Copa Sudamericana and the 2005 Recopa Sudamericana.

On 15 August 2005, Maradona made his debut as host of a talk-variety show on Argentine television, La Noche del 10 ("The Night of the no. 10"). His main guest on opening night was Pelé; the two had a friendly chat, showing no signs of past differences. However, the show also included a cartoon villain with a clear physical resemblance to Pelé. In subsequent evenings, he led the ratings on all occasions but one. Most guests were drawn from the worlds of football and show business, including Ronaldo and Zinedine Zidane, but also included interviews with other notable friends and personalities such as Cuban leader Fidel Castro and boxers Roberto Durán and Mike Tyson. Maradona gave each of his guests a signed Argentina jersey, which Tyson wore when he arrived in Brazil, Argentina's biggest rivals. In November 2005, however, Maradona rejected an offer to work with Argentina's national football team.

In May 2006, Maradona agreed to take part in UK's Soccer Aid (a program to raise money for Unicef). In September 2006, Maradona, in his famous blue and white number 10, was the captain for Argentina in a three-day World Cup of Indoor Football tournament in Spain. On 26 August 2006, it was announced that Maradona was quitting his position in the club Boca Juniors because of disagreements with the AFA, who selected Alfio Basile to be the new coach of the Argentina national team. In 2008, award-winning Serbian filmmaker Emir Kusturica made a documentary about Maradona's life, entitled "Maradona".

On 1 September 2014, Maradona, along with many current and former footballing stars, took part in the "Match for Peace", which was played at the Stadio Olimpico in Rome, with the proceeds being donated entirely to charity. Maradona set up a goal for Roberto Baggio during the first half of the match, with a chipped through-ball over the defence with the outside of his left foot. Unusually, both Baggio and Maradona wore the number 10 shirt, despite playing on the same team. On 17 August 2015, Maradona visited Ali Bin Nasser, the Tunisian referee of the Argentina–England quarter-final match at the 1986 World Cup where Maradona scored his Hand of God, and paid tribute to him by giving him a signed Argentine jersey.

Maradona began his managerial career alongside former Argentinos Juniors midfield teammate Carlos Fren. The pair led Mandiyú of Corrientes in 1994 and Racing Club in 1995, with little success. In May 2011 he became manager of Dubai club Al Wasl FC in the United Arab Emirates. Maradona was sacked on 10 July 2012. In August 2013, Maradona moved on to become mental coach at Argentine club Deportivo Riestra. Maradona departed this role in 2017 to become the head coach of Fujairah, in the UAE second division, before leaving at the end of the season upon failure to secure promotion at the club. In September 2018 he was appointed manager of Mexican second division side Dorados. He made his debut with Dorados on 17 September 2018 with a 4–1 victory over Cafetaleros de Tapachula. On 13 June 2019, after Dorados failed to clinch promotion to the Mexican top flight, Maradona's lawyer announced that he would be stepping down from the role, citing health reasons.

On 5 September 2019, Maradona was unveiled as the new head coach of Gimnasia de La Plata, signing a contract until the end of the season. After two months in charge he left the club on 19 November. However, two days later, Maradona rejoined the club as manager saying that "we finally achieved political unity in the club". Maradona insisted that Gabriel Pellegrino remain club President if he were to stay with Gimnisia de La Plata. However it was still not clear if Pellegrino, who declined to run for re-election, would stay on as club President. Originally scheduled to be held on 23 November 2019, the election was delayed 15 days. On 15 December 2019, Pellegrino, who was encouraged by Maradona to seek re-election, was re-elected to a three-year term. Despite having a bad record during the 2019–20 season, Gimnasia renewed Maradona's contract on 3 June 2020 through the 2020–21 season.

After the resignation of Argentina national team coach Alfio Basile in 2008, Maradona immediately proposed his candidacy for the vacant role. According to several press sources, his major challengers included Diego Simeone, Carlos Bianchi, Miguel Ángel Russo and Sergio Batista. On 29 October 2008, AFA chairman Julio Grondona confirmed that Maradona would be the head coach of the national team. On 19 November 2008, Maradona managed Argentina for the first time when they played against Scotland at Hampden Park in Glasgow, which Argentina won 1–0.
After winning his first three matches in charge of the national team, he oversaw a 6–1 defeat to Bolivia, equalling the team's worst ever margin of defeat. With two matches remaining in the qualification tournament for the 2010 World Cup, Argentina was in fifth place and faced the possibility of failing to qualify, but victory in the last two matches secured qualification for the finals. After Argentina's qualification, Maradona used abusive language at the live post-game press conference, telling members of the media to "suck it and keep on sucking it". FIFA responded with a two-month ban on all footballing activity, which expired on 15 January 2010, and a CHF 25,000 fine, with a warning as to his future conduct. The friendly match scheduled to take place at home to the Czech Republic on 15 December, during the period of the ban, was cancelled. The only match Argentina played during Maradona's ban was a friendly away to Catalonia, which they lost 4–2.

At the World Cup finals in June 2010, Argentina started by winning 1–0 against Nigeria, followed by a 4–1 victory over South Korea on the strength of a Gonzalo Higuaín hat-trick. In the final match of the group stage, Argentina won 2–0 against Greece to win the group and advance to a second round, meeting Mexico. After defeating Mexico 3–1, however, Argentina was routed by Germany 4–0 in the quarter-finals to go out of the competition. Argentina was ranked fifth in the tournament. After the defeat to Germany, Maradona admitted that he was considering his future as Argentina coach, stating, "I may leave tomorrow." On 15 July 2010, the AFA said that he would be offered a new four-year deal that would keep him in charge through to the summer of 2014 when Brazil stages the World Cup. On 27 July, however, the AFA announced that its board had unanimously decided not to renew his contract, different to 1978 World Cup winning captain and 1986 teammate, Daniel Passarella. Afterwards, on 29 July, Maradona claimed that AFA president Julio Grondona and director of national teams (as well as his former Argentine national team and Sevilla coach) Carlos Bilardo had "lied to", "betrayed" and effectively sacked him from the role. He said, "They wanted me to continue, but seven of my staff should not go on, if he told me that, it meant he did not want me to keep working."

Born to a Roman Catholic family, his parents are Diego Maradona Senior and Dalma Salvadora Franco. Maradona married long-time fiancée Claudia Villafañe on 7 November 1984 in Buenos Aires, and they had two daughters, Dalma Nerea (born 2 April 1987) and Gianinna Dinorah (born 16 May 1989), by whom he became a grandfather in 2009.

Maradona and Villafañe divorced in 2004. Daughter Dalma has since asserted that the divorce was the best solution for all, as her parents remained on friendly terms. They travelled together to Naples for a series of homages in June 2005 and were seen together on other occasions, including the Argentina games during 2006 World Cup.

During the divorce proceedings, Maradona admitted he is the father of Diego Sinagra (born in Naples on 20 September 1986). The Italian courts had already ruled so in 1993, after Maradona refused to undergo DNA tests to prove or disprove his paternity. Diego Junior met Maradona for the first time in May 2003 after tricking his way onto a golf course in Italy where Maradona was playing. Sinagra is now a footballer playing in Italy. After the divorce, Claudia embarked on a career as a theatre producer, and Dalma was seeking an acting career; she had expressed her desire to attend the Actor's Studio in Los Angeles.

Maradona's relationship with his immediate family was a close one, and in a 1990 interview with "Sports Illustrated" he showed phone bills where he had spent a minimum of 15,000 US dollars per month calling his parents and siblings. Maradona's mother, Dalma, died on 19 November 2011. He was in Dubai at the time, and desperately tried to fly back in time to see her, but was too late. She was 81 years old. His father, "Don" Diego, died on 25 June 2015 at age 87.

Maradona's great-nephew, Hernán, is a professional footballer.

From the mid-1980s until 2004, Maradona was addicted to cocaine. He allegedly began using the drug in Barcelona in 1983. By the time he was playing for Napoli, he had a regular addiction, which began to interfere with his ability to play football. In the midst of his drug-crisis in 1991 Maradona was asked by journalists if the hit song "Mi enfermedad" (lit. My Disease) was dedicated to him.

Maradona has a tendency to put on weight and suffered increasingly from obesity, at one point weighing . He was obese from the end of his playing career until undergoing gastric bypass surgery in a clinic in Cartagena de Indias, Colombia, on 6 March 2005. His surgeon said that Maradona would follow a liquid diet for three months in order to return his normal weight. When Maradona resumed public appearances shortly thereafter, he displayed a notably thinner figure. On 29 March 2007, Maradona was readmitted to a hospital in Buenos Aires. He was treated for hepatitis and effects of alcohol abuse and was released on 11 April, but readmitted two days later. In the following days, there were constant rumors about his health, including three false claims of his death within a month. After transfer to a psychiatric clinic specialising in alcohol-related problems, he was discharged on 7 May. On 8 May 2007, Maradona appeared on Argentine television and stated that he had quit drinking and had not used drugs in two-and-a-half years. In January 2019, Maradona underwent surgery after a hernia caused internal bleeding in his stomach.

Having previously been vocal in his support of neoliberal Argentine President Carlos Menem and his Harvard University-educated economist Domingo Cavallo, Maradona has shown sympathy to left-wing ideologies. He became friends with Cuban leader Fidel Castro while receiving treatment on the island, with Castro stating, "Diego is a great friend and very noble, too. There's also no question he’s a wonderful athlete and has maintained a friendship with Cuba to no material gain of his own." He has a portrait of Castro tattooed on his left leg and one of Fidel's second in command, fellow Argentine Che Guevara on his right arm. In his autobiography, "El Diego", he dedicated the book to various people, including Castro. He wrote, "To Fidel Castro and, through him, all the Cuban people."
Maradona was also a supporter of former Venezuelan President Hugo Chávez. In 2005, he came to Venezuela to meet Chávez, who received him in the Miraflores Palace. After this meeting, Maradona claimed that he had come with the aim of meeting a "great man" (""un grande"" in Spanish), but he had met instead a gigantic man (""un gigante"" in Spanish, meaning he was more than great). "I believe in Chávez, I am Chavista. Everything Fidel does, everything Chávez does, for me is the best." Maradona was the guest of honor of Chávez at the opening game of the 2007 Copa América held in Venezuela.

Maradona has declared his opposition to what he identifies as imperialism, notably during the 2005 Summit of the Americas in Mar del Plata, Argentina. There he protested George W. Bush's presence in Argentina, wearing a T-shirt labeled "" (with the "s" in "Bush" being replaced with a swastika) and referring to Bush as "human garbage". In August 2007, Maradona went further, making an appearance on Chávez's weekly television show "Alo Presidente" and saying, "I hate everything that comes from the United States. I hate it with all my strength." In December 2008, however, Maradona had adopted a more pro-US attitude when he expressed admiration for Bush's successor, President-elect Barack Obama, and held great expectations for him.
With his poor shanty town upbringing, Maradona has cultivated a man of the people persona. During a meeting with Pope John Paul II at the Vatican in 1987, they clashed on the issue of wealth disparity, with Maradona stating, "I argued with him because I was in the Vatican and I saw all these golden ceilings and afterwards I heard the Pope say the Church was worried about the welfare of poor kids. Sell your ceiling then amigo, do something!" In September 2014, Maradona met with Pope Francis in Rome, crediting Francis for inspiring him to return to religion after many years; he stated, "We should all imitate Pope Francis. If each one of us gives something to someone else, no one in the world would be starving."

In December 2007, Maradona presented a signed shirt with a message of support to the people of Iran: it is displayed in the Iranian Ministry of Foreign Affairs' museum. In April 2013, Maradona visited the tomb of Hugo Chávez and urged Venezuelans to elect the late leader's designated successor, Nicolás Maduro, to continue the socialist leader's legacy; "Continue the struggle," Maradona said on television. Maradona attended Maduro's final campaign rally in Caracas, signing footballs and kicking them to the crowd, and presented Maduro with an Argentina jersey. Having visited Chávez's tomb with Maradona, Maduro said, "Speaking with Diego was very emotional because comandante Chávez also loved him very much." Maradona participated and danced at the electoral campaign rally during the 2018 presidential elections in Venezuela. During the 2019 Venezuelan presidential crisis, the Mexican Football Federation fined him for violating their code of ethics and dedicating a team victory to Nicolás Maduro.

In October 2015, Maradona thanked Queen Elizabeth II and the Houses of Parliament in London for giving him the chance to provide "true justice" as head of an organisation designed to help young children. In a video released on his official Facebook page, Maradona confirmed he would accept their nomination for him to become Latin American director for the non-governmental organisation Football for Unity.

Maradona habitually refers to himself in the third person as "Maradona" and "El Diego".

In March 2009, Italian officials announced that Maradona still owed the Italian government €37 million in local taxes; €23.5 million of which was accrued interest on his original debt. They reported that thus far, Maradona had paid only €42,000, two luxury watches and a set of earrings.

The American newspaper "The Houston Chronicle" wrote about Maradona:
In Argentina, Maradona is considered a sports hero. On the idolatry that exists in Argentina, former teammate Jorge Valdano said, "At the time that Maradona retired from active football, left traumatized Argentina. Maradona was more than just a great footballer. It was a special compensation factor for a country that in a few years lived several military dictatorships and social frustrations of all kinds". Valdano added that "Maradona offered to the Argentines a way out of their collective frustration, and that's why people love him. There is a divine figure."

Ever since 1986, it is common for Argentines abroad to hear Maradona's name as a token of recognition, even in remote places. The Tartan Army sing a version of the Hokey Cokey in honour of the Hand of God goal against England. In Argentina, Maradona is often talked about in terms reserved for legends. In the Argentine film "El Hijo de la Novia" ("Son of the Bride"), somebody who impersonates a Catholic priest says to a bar patron, "They idolized him and then crucified him." When a friend scolds him for taking the prank too far, the fake priest retorts, "But I was talking about Maradona." He is the subject of the film "El Camino de San Diego", though he himself only appears in archive footage.

Maradona was included in many cameos in the Argentine comic book El Cazador de Aventuras. After the closing of it, the authors started a new short-lived comic book titled "El Die", using Maradona as the main character. Maradona has had several online Flash games that are entirely dedicated to his legacy. In Rosario, Argentina, locals organized the parody religion of the "Church of Maradona". The organization reformulates many elements from Christian tradition, such as Christmas or prayers, reflecting instead details from Maradona. It had 200 founding members, and tens of thousands more have become members via the church's official web site.

Many Argentine artists performed songs in tribute to Diego, such as "La Mano de Dios" by El Potro Rodrigo, "Maradona" by Andrés Calamaro, "Para siempre Diego" (Diego forever) by Los Ratones Paranoicos, "Francotirador" (Sniper) by Attaque 77, "Maradona blues" by Charly García, "Santa Maradona" (Saint Maradona) by Mano Negra, "La Vida Tombola" by Manu Chao, among others. There are also films, such as: "Maradona, La Mano de Dios" (Maradona, the Hand of God), "El Camino de San Diego" (Saint Diego's Road), "Amando a Maradona" (Loving Maradona), "Maradona by Kusturica".

By 1982, Maradona had become one of the biggest sports stars in the world and had endorsements with many companies, including Puma and Coca-Cola, earning him an additional $1.5 million per year on top of his club salary. In 1982, he featured in a World Cup commercial for Coca-Cola, and a Japanese commercial for Puma. In 2010 he appeared in a commercial for French fashion house Louis Vuitton, indulging in a game of table football with fellow World Cup winners Pelé and Zinedine Zidane. Maradona features in the music video to the 2010 World Cup song "Waka Waka" by Shakira, with footage shown of him celebrating Argentina winning the 1986 World Cup.

A 2006 television commercial for Brazilian soft drink Guaraná Antarctica portrayed Maradona as a member of the Brazil national team, including wearing the yellow jersey and singing the Brazilian national anthem with Brazilian players Ronaldo and Kaká. Later on in the commercial he wakes up realizing it was a nightmare after having drunk too much of the drink. This generated some controversy in the Argentine media after its release (although the commercial was not supposed to air on the Argentine market, fans could see it online). Maradona replied that he has no problem in wearing the Brazilian national squad jersey despite Argentina and Brazil having a tense rivalry in football, but that he would refuse to wear the shirt of River Plate, Boca Juniors' traditional rival. There is a documented phenomenon of Brazilians being named in honour of Maradona, an example being footballer Diego Costa.

In 2017, Maradona featured as a legendary player in the football video games "FIFA 18" and "Pro Evolution Soccer 2018". In 2019, a documentary film titled "Diego Maradona" was released by Academy Award and BAFTA Award winning filmmaker Asif Kapadia, director of "Amy" (on singer Amy Winehouse) and "Senna" (on motor racing driver Ayrton Senna). Kapadia states, "Maradona is the third part of a trilogy about child geniuses and fame." He added, "I was fascinated by his journey, wherever he went there were moments of incredible brilliance and drama. He was a leader, taking his teams to the very top, but also many lows in his career. He was always the little guy fighting against the system... and he was willing to do anything, to use all of his cunning and intelligence to win."



Boca Juniors

Barcelona

Napoli

Argentina Youth

Argentina






</doc>
<doc id="8487" url="https://en.wikipedia.org/wiki?curid=8487" title="David Brewster">
David Brewster

Sir David Brewster (11 December 178110 February 1868) was a British scientist, inventor, author, and academic administrator. In science he is principally remembered for his experimental work in physical optics, mostly concerned with the study of the polarization of light and including the discovery of Brewster's angle. He studied the birefringence of crystals under compression and discovered photoelasticity, thereby creating the field of optical mineralogy. For this work, William Whewell dubbed him the "father of modern experimental optics" and "the Johannes Kepler of optics."

A pioneer in photography, Brewster invented an improved stereoscope, which he called "lenticular stereoscope" and which became the first portable 3D-viewing device. He also invented the binocular camera, two types of polarimeters, the polyzonal lens, the lighthouse illuminator, and the kaleidoscope.

Brewster was a Presbyterian and walked arm in arm with his brother on the Disruption procession which formed the Free Church of Scotland. As a historian of science, Brewster focused on the life and work of his hero, Isaac Newton. Brewster published a detailed biography of Newton in 1831 and later became the first scientific historian to examine many of the papers in Newton's "Nachlass". Brewster also wrote numerous works of popular science, and was one of the founders of the British Science Association, of which he was elected President in 1849. He became the public face of higher education in Scotland, serving as Principal of the University of St Andrews (1837–59) and later of the University of Edinburgh (1859–68). Brewster also edited the 18-volume "Edinburgh Encyclopædia".

David Brewster was born in the Canongate in Jedburgh, Roxburghshire, to Margaret Key (1753–1790) and James Brewster (c. 1735–1815), the rector of Jedburgh Grammar School and a teacher of high reputation. David was the third of six children, two daughters and four sons: James (1777–1847), minister at Craig, Ferryden; David; George (1784–1855), minister at Scoonie, Fife; and Patrick (1788–1859), minister at the abbey church, Paisley.

At the age of 12, David was sent to the University of Edinburgh (graduating MA in 1800), being intended for the clergy. He was licensed a minister of the Church of Scotland, and preached around Edinburgh on several occasions. He had already shown a strong inclination for natural science, and this had been fostered by his intimacy with a "self-taught philosopher, astronomer and mathematician", as Sir Walter Scott called him, of great local fame, James Veitch of Inchbonny, a man who was particularly skilful in making telescopes.

He is buried in the grounds of Melrose Abbey in the Scottish Borders.

Though Brewster duly finished his theological studies and was licensed to preach, his other interests distracted him from the duties of his profession. In 1799 fellow-student Henry Brougham persuaded him to study the diffraction of light. The results of his investigations were communicated from time to time in papers to the "Philosophical Transactions" of London and other scientific journals. The fact that other scientists – notably Étienne-Louis Malus and Augustin Fresnel – were pursuing the same investigations contemporaneously in France does not invalidate Brewster's claim to independent discovery, even though in one or two cases the priority must be assigned to others. A lesser-known classmate of his, Thomas Dick, also went on to become a popular astronomical writer.

The most important subjects of his inquiries can be enumerated under the following five headings:

In this line of investigation, the prime importance belongs to the discovery of

These discoveries were promptly recognised. As early as 1807 the degree of LL.D. was conferred upon Brewster by Marischal College, Aberdeen; in 1815 he was elected a Fellow of the Royal Society of London, and received the Copley Medal; in 1818 he received the Rumford Medal of the society; and in 1816 the French Institute awarded him one-half of the prize of three thousand francs for the two most important discoveries in physical science made in Europe during the two preceding years. In 1821, he was made a foreign member of the Royal Swedish Academy of Sciences, and in 1822 a Foreign Honorary Member of the American Academy of Arts and Sciences.
Among the non-scientific public, his fame spread more effectually by his invention in about 1815 of the kaleidoscope, for which there was a great demand in both the United Kingdom, France, and the United States. As a reflection of this fame, Brewster portrait was later printed in some cigar boxes. Brewster chose renowned achromatic lens developer Philip Carpenter as the sole manufacturer of the kaleidoscope in 1817. Although Brewster patented the kaleidoscope in 1817 (GB 4136), a copy of the prototype was shown to London opticians and copied before the patent was granted. As a consequence, the kaleidoscope became produced in large numbers, but yielded no direct financial benefits to Brewster. It proved to be a massive success with two hundred thousand kaleidoscopes sold in London and Paris in just three months.
An instrument of more significance, the stereoscope, which – though of much later date (1849) – along with the kaleidoscope did more than anything else to popularise his name, was not as has often been asserted the invention of Brewster. Sir Charles Wheatstone discovered its principle and applied it as early as 1838 to the construction of a cumbersome but effective instrument, in which the binocular pictures were made to combine by means of mirrors. A dogged rival of Wheatstone's, Brewster was unwilling to credit him with the invention, however, and proposed that the true author of the stereoscope was a Mr. Elliot, a "Teacher of Mathematics" from Edinburgh, who, according to Brewster, had conceived of the principles as early as 1823 and had constructed a lensless and mirrorless prototype in 1839, through which one could view drawn landscape transparencies, since photography had yet to be invented. Brewster's personal contribution was the suggestion to use prisms for uniting the dissimilar pictures; and accordingly the lenticular stereoscope may fairly be said to be his invention.

A much more valuable and practical result of Brewster's optical researches was the improvement of the British lighthouse system. Although Fresnel, who had also the satisfaction of being the first to put it into operation, perfected the dioptric apparatus independently, Brewster was active earlier in the field than Fresnel, describing the dioptric apparatus in 1812. Brewster pressed its adoption on those in authority at least as early as 1820, two years before Fresnel suggested it, and it was finally introduced into lighthouses mainly through Brewster's persistent efforts.

Although Brewster's own discoveries were important, they were not his only service to science. He began writing in 1799 as a regular contributor to the "Edinburgh Magazine", of which he acted as editor at the age of twenty. In 1807, he undertook the editorship of the newly projected "Edinburgh Encyclopædia", of which the first part appeared in 1808, and the last not until 1830. The work was strongest in the scientific department, and many of its most valuable articles were from the pen of the editor. At a later period he was one of the leading contributors to the "Encyclopædia Britannica" (seventh and eighth editions) writing, among others, the articles on electricity, hydrodynamics, magnetism, microscope, optics, stereoscope, and voltaic electricity. He was elected a member of the American Antiquarian Society in 1816.

In 1819 Brewster undertook further editorial work by establishing, in conjunction with Robert Jameson (1774–1854), the "Edinburgh Philosophical Journal", which took the place of the "Edinburgh Magazine". The first ten volumes (1819–1824) were published under the joint editorship of Brewster and Jameson, the remaining four volumes (1825–1826) being edited by Jameson alone. After parting company with Jameson, Brewster started the "Edinburgh Journal of Science" in 1824, 16 volumes of which appeared under his editorship during the years 1824–1832, with very many articles from his own pen.

He contributed around three hundred papers to the transactions of various learned societies, and few of his contemporaries wrote as much for the various reviews. In the "North British Review" alone, seventy-five articles of his appeared. A list of his larger separate works will be found below. Special mention, however, must be made of the most important of them all: his biography of Sir Isaac Newton. In 1831 he published the "Life of Sir Isaac Newton", a short popular account of the philosopher's life, in "Murray's Family Library", followed by an 1832 American edition in Harper's Family Library; but it was not until 1855 that he was able to issue the much fuller "Memoirs of the Life, Writings and Discoveries of Sir Isaac Newton", a work which embodied the results of more than 20 years' investigation of original manuscripts and other available sources.

Brewster's position as editor brought him into frequent contact with the most eminent scientific men, and he was naturally among the first to recognise the benefit that would accrue from regular communication among those in the field of science. In a review of Charles Babbage's book "Decline of Science in England" in "John Murray's Quarterly Review", he suggested the creation of "an association of our nobility, clergy, gentry and philosophers". This was taken up by various "Declinarians" and found speedy realisation in the British Association for the Advancement of Science. Its first meeting was held at York in 1831; and Brewster, along with Babbage and Sir John Herschel, had the chief part in shaping its constitution.

In the same year in which the British Association held its first meeting, Brewster received the honour of knighthood and the decoration of the Royal Guelphic Order. In 1838, he was appointed principal of the united colleges of St Salvator and St Leonard, University of St Andrews. In 1849, he acted as president of the British Association and was elected one of the eight foreign associates of the Institute of France in succession to J. J. Berzelius; and ten years later, he accepted the office of principal of the University of Edinburgh, the duties of which he discharged until within a few months of his death. In 1855, the government of France made him an Officier de la Légion d'honneur.

He was a close friend of William Henry Fox Talbot, inventor of the calotype process, who sent Brewster early examples of his work. It was Brewster who suggested Talbot only patent his process in England, initiating the development of early photography in Scotland and eventually allowing for the formation of the first photographic society in the world, the Edinburgh Calotype Club, in 1843. Brewster was a prominent member of the club until its dissolution sometime in the mid-1850s; however, his interest in photography continued, and he was elected the first President of the Photographic Society of Scotland when it was founded in 1856.

Of a high-strung and nervous temperament, Brewster was somewhat irritable in matters of controversy; but he was repeatedly subjected to serious provocation. He was a man of highly honourable and fervently religious character. In estimating his place among scientific discoverers, the chief thing to be borne in mind is that his genius was not characteristically mathematical. His method was empirical, and the laws that he established were generally the result of repeated experiment. To the ultimate explanation of the phenomena with which he dealt he contributed nothing, and it is noteworthy although he did not maintain to the end of his life the corpuscular theory he never explicitly adopted the wave theory of light. Few would dispute the verdict of James David Forbes, an editor of the eighth edition of the "Encyclopædia Britannica": "His scientific glory is different in kind from that of Young and Fresnel; but the discoverer of the law of polarization of biaxial crystals, of optical mineralogy, and of double refraction by compression, will always occupy a foremost rank in the intellectual history of the age." In addition to the various works of Brewster already mentioned, the following may be added: "Notes and Introduction to Carlyle's translation of Legendre's Elements of Geometry" (1824); "Treatise on Optics" (1831); " Letters on Natural Magic", addressed to Sir Walter Scott (1832) "The Martyrs of Science, or the Lives of Galileo, Tycho Brahe, and Kepler" (1841); "More Worlds than One" (1854).

In his "Treatise" he demonstrated that vegetal colors were related with the absorption spectra and he described for the first time the red fluorescence of chlorophyll.

As well as his many scientific works and biographies of notable scientists, Brewster also wrote "The History of Free Masonry, Drawn from Authentic Sources of Information; with an Account of the Grand Lodge of Scotland, from Its Institution in 1736, to the Present Time", published in 1804, when he was only 23. The work was commissioned by Alexander Lawrie, publisher to the Grand Lodge of Scotland, to whom the work has been, frequently, mis-attributed. Given that the book bears Lawrie's name and not Brewster's this is understandable. The book became one of the standard works on early Scottish freemasonry although it has been largely superseded by later works. There is no evidence that Brewster was a Freemason at the time he wrote the book, nor any that he became one later.

Brewster's Christian beliefs stirred him to respond against the idea of the transmutation of species and the theory of evolution. His opinion was that "science and religion must be one since each dealt with Truth, which had only one and the same Author." In 1845 he wrote a highly critical review of the evolutionist work "Vestiges of the Natural History of Creation", in the "North British Review". which he considered to be an insult to Christian revelation and a dangerous example of materialism.

In 1862, he responded to Darwin's "On the Origin of Species" and published the article "" in "Good Words". He stated that Darwin's book combined both "interesting facts and idle fancies" which made up a "dangerous and degrading speculation". He accepted adaptive changes, but he strongly opposed Darwin's statement about the "primordial form", which he considered an offensive idea to "both the naturalist and the Christian."

Brewster married twice. His first wife, Juliet Macpherson (c. 1776–1850), was a daughter of James Macpherson (1736–1796), a probable translator of Ossian poems. They married on 31 July 1810 in Edinburgh and had four sons and a daughter:

Brewster married a second time in Nice, on 26 (or 27) March 1857, to Jane Kirk Purnell (b. 1827), the second daughter of Thomas Purnell of Scarborough. Lady Brewster famously fainted at the Oxford evolution debate of 30 June 1860. Brewster died in 1868, and was buried at Melrose Abbey, next to his first wife and second son. The physics building at Heriot-Watt University is named in his honour.

A bust of Brewster is in the Hall of Heroes of the National Wallace Monument in Stirling.

Brewster's views on the possibility of evolution of intelligence on other planets, contrasted with the opinion of William Whewell, are cited in the novel "Barchester Towers".

He appears as a minor antagonist in the 2015 video game "Assassin's Creed Syndicate" as a scientist working for the game's opposing faction. He is assassinated by one of the protagonists, Evie Frye.

A street within the Kings Buildings complex (science buildings linked to Edinburgh University) was named in his memory in 2015.





 


</doc>
<doc id="8488" url="https://en.wikipedia.org/wiki?curid=8488" title="Dual-tone multi-frequency signaling">
Dual-tone multi-frequency signaling

Dual-tone multi-frequency signaling (DTMF) is a telecommunication signaling system using the voice-frequency band over telephone lines between telephone equipment and other communications devices and switching centers. DTMF was first developed in the Bell System in the United States, and became known under the trademark Touch-Tone for use in push-button telephones supplied to telephone customers, starting in 1963. DTMF is standardized as ITU-T Recommendation Q.23. It is also known in the UK as "MF4".

The Touch-Tone system using a telephone keypad gradually replaced the use of rotary dial and has become the industry standard for landline and mobile service. Other multi-frequency systems are used for internal signaling within the telephone network.

Prior to the development of DTMF, telephone numbers were dialed by users with a loop-disconnect (LD) signaling, more commonly known as pulse dialing (dial pulse, DP) in the U.S. It functions by interrupting the current in the local loop between the telephone exchange and the calling party's telephone at a precise rate with a switch in the telephone that is operated by the rotary dial as it spins back to its rest position after having been rotated to each desired number. The exchange equipment responds to the dial pulses either directly by operating relays, or by storing the number in a digit register recording the dialed number. The physical distance for which this type of dialing was possible was restricted by electrical distortions and was possible only on direct metallic links between end points of a line. Placing calls over longer distances required either operator assistance or provision of special subscriber trunk dialing equipment. Operators used an earlier type of multi-frequency signaling.

Multi-frequency signaling (MF) is a group of signaling methods that use a mixture of two pure tone (pure sine wave) sounds. Various MF signaling protocols were devised by the Bell System and CCITT. The earliest of these were for in-band signaling between switching centers, where long-distance telephone operators used a 16-digit keypad to input the next portion of the destination telephone number in order to contact the next downstream long-distance telephone operator. This semi-automated signaling and switching proved successful in both speed and cost effectiveness. Based on this prior success with using MF by specialists to establish long-distance telephone calls, dual-tone multi-frequency signaling was developed for end-user signaling without the assistance of operators.

The DTMF system uses a set of eight audio frequencies transmitted in pairs to represent 16 signals, represented by the ten digits, the letters A to D, and the symbols "#" and "*". As the signals are audible tones in the voice frequency range, they can be transmitted through electrical repeaters and amplifiers, and over radio and microwave links, thus eliminating the need for intermediate operators on long-distance circuits.

AT&T described the product as "a method for pushbutton signaling from customer stations using the voice transmission path." In order to prevent consumer telephones from interfering with the MF-based routing and switching between telephone switching centers, DTMF frequencies differ from all of the pre-existing MF signaling protocols between switching centers: MF/R1, R2, CCS4, CCS5, and others that were later replaced by SS7 digital signaling. DTMF was known throughout the Bell System by the trademark "Touch-Tone". The term was first used by AT&T in commerce on July 5, 1960, and was introduced to the public on November 18, 1963, when the first push-button telephone was made available to the public. As a parent company of Bell Systems, AT&T held the trademark from September 4, 1962, to March 13, 1984. It is standardized by ITU-T Recommendation Q.23. In the UK, it is also known as MF4.

Other vendors of compatible telephone equipment called the Touch-Tone feature "tone dialing" or "DTMF", or used their other trade names such as "Digitone" by Northern Electric Company in Canada.

As a method of in-band signaling, DTMF signals were also used by cable television broadcasters as cue tones to indicate the start and stop times of local commercial insertion points during station breaks for the benefit of cable companies. Until out-of-band signaling equipment was developed in the 1990s, fast, unacknowledged DTMF tone sequences could be heard during the commercial breaks of cable channels in the United States and elsewhere. Previously, terrestrial television stations used DTMF tones to control remote transmitters. In IP telephony, DTMF signals can also be delivered as either in-band or out-of-band tones, or even as a part of signaling protocols, as long as both endpoints agree on a common approach to adopt.

The engineers had envisioned telephones being used to access computers and automated response systems. They consulted with companies to determine the requirements. This led to the addition of the number sign<nowiki> (#, "pound" or "diamond" in this context, "hash", "square" or "gate" in the UK, and "</nowiki>octothorpe<nowiki>" by the original engineers) and </nowiki>asterisk or "star" (*) keys as well as a group of keys for menu selection: A, B, C and D. In the end, the lettered keys were dropped from most phones, and it was many years before the two symbol keys became widely used for vertical service codes such as *67 in the United States of America and Canada to suppress caller ID.

Public payphones that accept credit cards use these additional codes to send the information from the magnetic strip.

The AUTOVON telephone system of the United States Armed Forces used these signals to assert certain privilege and priority levels when placing telephone calls. Precedence is still a feature of military telephone networks, but using number combinations. For example, entering 93 before a number is a priority call.

Present-day uses of the signals "A", "B", "C" and "D" are rare in telephone networks, and are exclusive to network control. For example, key "A" is used in some networks for cycling through a list of carriers. The signals are used in radio phone patch and repeater operations to allow, among other uses, control of the repeater while connected to an active telephone line.

The signals *, #, A, B, C and D are still widely used worldwide by amateur radio operators and commercial two-way radio systems for equipment control, repeater control, remote-base operations and some telephone communications systems.

DTMF signaling tones can also be heard at the start or end of some VHS (Video Home System) cassette tapes. Information on the master version of the video tape is encoded in the DTMF tone. The encoded tone provides information to automatic duplication machines, such as format, duration and volume levels, in order to replicate the original video as closely as possible.

DTMF tones are used in some caller ID systems to transfer the caller ID information, but in the United States the Bell 202 modulated frequency-shift keying (FSK) signaling is used to transfer the data.

The DTMF telephone keypad is laid out as a matrix of push buttons in which each row represents the low frequency component and each column represents the high frequency component of the DTMF signal. The commonly used keypad has four rows and three columns, but a fourth column is present for some applications. Pressing a key sends a combination of the row and column frequencies. For example, the "1" key produces a superimposition of a 697 Hz low tone and a 1209 Hz high tone. Initial pushbutton designs employed levers, enabling each button to activate one row and one column contact. The tones are decoded by the switching center to determine the keys pressed by the user.

DTMF was originally decoded by tuned filter banks. By the end of the 20th century, digital signal processing became the predominant technology for decoding. DTMF decoding algorithms typically use the Goertzel algorithm. As DTMF signaling is often transmitted in-band with voice or other audio signals present simultaneously, the DTMF signal definition includes strict limits for timing (minimum duration and interdigit spacing), frequency deviations, harmonics, and amplitude relation of the two components with respect to each other ("twist").

National telephone systems define other tones, outside the DTMF specification, that indicate the status of lines, equipment, or the result of calls, and for control of equipment for troubleshooting or service purposes. Such call-progress tones are often also composed of multiple frequencies and are standardized in each country. The Bell System defined them in the Precise Tone Plan. Bell's Multi-frequency signaling was exploited by blue box devices.




</doc>
<doc id="8489" url="https://en.wikipedia.org/wiki?curid=8489" title="Deuterocanonical books">
Deuterocanonical books

The deuterocanonical books (from the Greek meaning "belonging to the second canon") are books and passages considered by the Catholic Church, the Eastern Orthodox Church, the Oriental Orthodox Churches and the Assyrian Church of the East to be canonical books of the Old Testament but which are considered non-canonical by Protestant denominations. They date from the period 300 BC–AD 100 approximately (mostly from 200 BC–AD 70, i.e. before the definite separation of the Church from Judaism). While the New Testament never quotes from or ascribes canonical authority to these books, some say there is a correspondence of thought, while others see texts from these books being paraphrased, referred or alluded to many times in the New Testament, particularly in the Pauline Epistles depending in large measure on what is counted as a reference.

Though there is no scholarly consensus as to when the Hebrew Bible canon was fixed, some scholars hold that the Hebrew canon was established well before the first century AD – even as early as the fourth century BC, or by the Hasmonean dynasty (140–40 BC). The Hebrew canon does not include the seven deuterocanonical books and this formed the basis for their exclusion from the Protestant Old Testament. 

The Septuagint translation of the Hebrew Bible into Greek, which the early church used as its Old Testament, included all of the deuterocanonical books. The term distinguished these books both from those that were termed protocanonical books, which were the books of the Hebrew canon; and from the apocryphal books, which were those books of Jewish origin that were known sometimes to have been read in church as scripture but which were considered not to be canonical.

The Council of Rome (AD 382) defined a list of books of Scripture presented as having been made canonical. It included most of the deuterocanonical books.

Since the 16th century, most Protestant Churches have accepted only works in the Masoretic Text of the Hebrew Bible as canonical books of the Old Testament, and hence classify all deuterocanonical texts (of whichever definition) with the Apocrypha.

The deuterocanonical books of the Old Testament are:

"Canonical by the Catholic Church and the Orthodox Church:"
"Canonical only by the Orthodox Church:"

Deuterocanonical is a term coined in 1566 by the theologian Sixtus of Siena, who had converted to Catholicism from Judaism, to describe scriptural texts considered canonical by the Catholic Church, but which recognition was considered "secondary". For Sixtus, this term included portions of both Old and New Testaments (Sixtus considers the final chapter of the Gospel of Mark as 'deuterocanonical'); and he also applies the term to the Book of Esther from the canon of the Hebrew Bible. The term was then taken up by other writers to apply specifically to those books of the Old Testament which had been recognised as canonical by the Councils of Rome (AD 382) of Hippo (AD 393), Carthage (AD 397 and AD 419), Council of Florence (AD 1442) and Council of Trent (AD 1546), but which were not in the Hebrew canon.

Forms of the term "deuterocanonical" were adopted after the 16th century by the Eastern Orthodox Church to denote canonical books of the Septuagint not in the Hebrew Bible (a wider selection than that adopted by the Council of Trent), and also by the Ethiopian Orthodox Tewahedo Church to apply to works believed to be of Jewish origin translated in the Old Testament of the Ethiopic Bible; a wider selection still.

The acceptance of some of these books among early Christians was widespread, though not universal, and surviving Bibles from the early Church always include, with varying degrees of recognition, books now called "deuterocanonical". Some say that their canonicity seems not to have been doubted in the Church until it was challenged by Jews after AD 100, sometimes postulating a hypothetical Council of Jamnia. Regional councils in the West published official canons that included these books as early as the 4th and 5th centuries.

The "Catholic Encyclopedia" states that:

Meanwhile, "the protocanonical books of the Old Testament correspond with those of the Bible of the Hebrews, and the Old Testament as received by Protestants. The deuterocanonical (deuteros, "second") are those whose Scriptural character was contested in some quarters, but which long ago gained a secure footing in the Bible of the Catholic Church, though those of the Old Testament are classed by Protestants as the "Apocrypha". These consist of seven books: Tobias, Judith, Baruch, Ecclesiasticus, Wisdom, First and Second Machabees; also certain additions to Esther and Daniel."

Fragments of three deuterocanonical books ("Sirach", "Tobit", and "Letter of Jeremiah") have been found among the Dead Sea Scrolls found at Qumran, in addition to several partial copies of "I Enoch" and "Jubilees" from the Ethiopic deuterocanon, and Psalm 151 from the Eastern Orthodox Church deuterocanon.

"Sirach", whose Hebrew text was already known from the Cairo Geniza, has been found in two scrolls (2QSir or 2Q18, 11QPs_a or 11Q5) in Hebrew. Another Hebrew scroll of "Sirach" has been found in Masada (MasSir). Five fragments from the "Book of Tobit" have been found in Qumran written in Aramaic and in one written in Hebrew (papyri 4Q, nos. 196–200). The "Letter of Jeremiah" (or "Baruch" chapter 6) has been found in cave 7 (papyrus 7Q2) in Greek. It has been theorized by recent scholars that the Qumran library (of approximately 1,100 manuscripts found in the eleven caves at Qumran) was not entirely produced at Qumran, but may have included part of the library of the Jerusalem Temple, that may have been hidden in the caves for safekeeping at the time the Temple was destroyed by Romans in AD 70.

Deuterocanonical and Apocryphal books included in the Septuagint
The large majority of Old Testament references in the New Testament are taken from the Koine Greek Septuagint (LXX), editions of which include the deuterocanonical books, as well as apocrypha – both of which are called collectively "anagignoskomena" (""Readable," namely worthy of reading"). No two Septuagint codices contain the same apocrypha, and the three earliest manuscripts of the LXX show uncertainty as to which books constitute the complete list of biblical books. Codex Vaticanus (B) lacks any of the books of Maccabees, while Codex Sinaiticus (Aleph) omits Baruch and the letter of Jeremiah, but includes 1 and 4 Maccabees. Codex Alexandrinus includes the Psalms of Solomon and Maccabees 1–4. All three codices include Psalm 151 in addition to the canonical 150 Psalms; and all three codices include Greek Esdras as 'Esdras A', with the canonical Ezra–Nehemiah counted as 'Esdras B'.

Greek Psalm manuscripts from the fifth century contain three New Testament "psalms": the Magnificat, the Benedictus, the Nunc dimittis from Luke's birth narrative, and the conclusion of the hymn that begins with the "Gloria in Excelsis". Beckwith states that manuscripts of anything like the capacity of Codex Alexandrinus were not used in the first centuries of the Christian era, and believes that the comprehensive codices of the Septuagint, which start appearing in the fourth century AD, are all of Christian origin.

Some deuterocanonicals appear to have been written originally in Hebrew, but the original text has long been lost. Archaeological finds discovered both Psalm 151 and the Book of Tobit in Hebrew among the Dead Sea Scrolls. The Septuagint was widely accepted and used by Greek-speaking Jews in the 1st century, even in the region of Roman Judea, and therefore naturally became the text most widely used by early Christians, who were predominantly Greek speaking.

In the New Testament, Hebrews 11:35 is understood by some as referring to an event that was recorded in one of the deuterocanonical books, 2 Maccabees. For instance, the author of Hebrews references oral tradition which spoke of an Old Testament prophet who was sawn in half in Hebrews 11:37, two verses after the 2nd Maccabees reference. Other New Testament authors such as Paul also reference or quote period literature which was familiar to the audience but that was not included in the deuterocanonical or the protocanonical Old Testament books.

The Jewish historian Josephus (c. AD 94) speaks of there being 22 books in the canon of the Hebrew Bible, reported also by the Christian bishop Athanasius.

Origen of Alexandria (c. AD 240) also records 22 canonical books of the Hebrew Bible cited by Eusebius; among them are the Epistle of Jeremiah and the Maccabees as canonical books.

In the 7th century Latin document the Muratorian fragment, which some scholars actually believe to be a copy of an earlier AD 170 Greek original, the book of the Wisdom of Solomon is counted by the church.

Eusebius wrote in his "Church History" (c. AD 324) that Bishop Melito of Sardis in the 2nd century AD considered the deuterocanonical Wisdom of Solomon as part of the Old Testament and that it was considered canonical by Jews and Christians. On the other hand, the contrary claim has been made: "In the catalogue of Melito, presented by Eusebius, after Proverbs, the word Wisdom occurs, which nearly all commentators have been of opinion is only another name for the same book, and not the name of the book now called 'The Wisdom of Solomon'."

Cyril of Jerusalem (c. AD 350) in his "Catechetical Lectures" cites as canonical books "Jeremiah one, including Baruch and Lamentations and the Epistle (of Jeremiah)".

In Athanasius's canonical books list (AD 367) the Book of Baruch and the Letter of Jeremiah are included and Esther is omitted. At the same time, he mentioned that certain other books, including four deuterocanonical books (the Wisdom of Solomon, the Wisdom of Sirach, Judith and Tobit), the book of Esther and also the Didache and The Shepherd of Hermas, while not being part of the Canon, "were appointed by the Fathers to be read". He excluded what he called "apocryphal writings" entirely.

Epiphanius of Salamis (c. AD 385) mentions that "there are 27 books given the Jews by God, but they are counted as 22, however, like the letters of their Hebrew alphabet, because ten books are doubled and reckoned as five". He wrote in his "Panarion" that Jews had in their books the deuterocanonical Epistle of Jeremiah and Baruch, both combined with Jeremiah and Lamentations in only one book. While Wisdom of Sirach and the Wisdom of Solomon were books of disputed canonicity.

Augustine (c. AD 397) writes in his book "On Christian Doctrine (Book II Chapter 8)" that two books of Maccabees, Tobias, Judith, Wisdom of Solomon and Ecclesiasticus are canonical books.

According to the monk Rufinus of Aquileia (c. AD 400) the deuterocanonical books were not called canonical but ecclesiastical books. In this category Rufinus includes the Wisdom of Solomon, Sirach, Judith, Tobit and two books of Maccabees. Rufinus makes no mention of Baruch or the Epistle of Jeremiah.

Pope Innocent I (AD 405) sent a letter to the bishop of Toulouse citing deuterocanonical books as a part of the Old Testament Canon.

In later copyings of the canons of the Council of Laodicea (from AD 364) a canon list became appended to Canon 59, likely before the mid fifth century, which affirmed that Jeremiah, and Baruch, the Lamentations, and the Epistle (of Jeremiah) were canonical, while excluding the other deuterocanonical books.

According to Decretum Gelasianum, which is a work written by an anonymous scholar between 519 and 553, the Council of Rome (AD 382) cites a list of books of Scripture presented as having been made canonical. This list mentions all the deuterocanonical books except Baruch and the Letter of Jeremiah as a part of the Old Testament Canon.

The Synod of Hippo (in AD 393), followed by the Council of Carthage (397) and the Council of Carthage (419), may be the first councils that explicitly accepted the first canon which includes a selection of books that did not appear in the Hebrew Bible; the councils were under significant influence of Augustine of Hippo, who regarded the canon as already closed. Canon XXIV from the Synod of Hippo records the Scriptures which are considered canonical; the Old Testament books as follows:

On 28 August 397, the Council of Carthage (AD 397) confirmed the canon issued at Hippo; the recurrence of the Old Testament part is stated:
The Council of Carthage (AD 419) in its canon 24 lists the deuterocanonical books except Baruch and the Epistle of Jeremiah as Canonical Scripture.

The Apostolic Canons approved by the Eastern Council in Trullo in AD 692 (not recognized by the Catholic Church) states as venerable and sacred the first three books of Maccabees and Wisdom of Sirach.

The Roman Catholic Council of Florence (AD 1442) promulgated a list of the books of the Bible, including the books of Judith, Esther, Wisdom, Ecclesiasticus, Baruch and two books of the Maccabees as Canonical books.

The Roman Catholic Council of Trent (AD 1546) adopted an understanding of the canons of these previous councils as corresponding to its own list of deuterocanonical books.

Jerome in one of his Vulgate prologues describes a canon which excludes the deuterocanonical books. In these prologues, Jerome mentions all of the deuterocanonical and apocryphal works by name as being apocryphal or "not in the canon" except for "Prayer of Manasses" and "Baruch". He mentions "Baruch" by name in his "Prologue to Jeremiah" and notes that it is neither read nor held among the Hebrews, but does not explicitly call it apocryphal or "not in the canon". The inferior status to which the deuterocanonical books were relegated by authorities like Jerome is seen by some as being due to a rigid conception of canonicity, one demanding that a book, to be entitled to this supreme dignity, must be received by all, must have the sanction of Jewish antiquity, and must moreover be adapted not only to edification, but also to the "confirmation of the doctrine of the Church".

J. N. D. Kelly states that "Jerome, conscious of the difficulty of arguing with Jews on the basis of books they spurned and anyhow regarding the Hebrew original as authoritative, was adamant that anything not found in it was 'to be classed among the apocrypha', not in the canon; later he grudgingly conceded that the Church read some of these books for edification, but not to support doctrine."

Eventually however, Jerome's Vulgate did include the deuterocanonical books as well as apocrypha. Jerome referenced and quoted from some as scripture despite describing them as "not in the canon". Michael Barber asserts that, although Jerome was once suspicious of the apocrypha, he later viewed them as Scripture. Barber argues that this is clear from Jerome's epistles; he cites Jerome's letter to Eustochium, in which Jerome quotes Sirach 13:2. Elsewhere Jerome apparently also refers to Baruch, the Story of Susannah and Wisdom as scripture. Henry Barker states that Jerome quotes the Apocrypha with marked respect, and even as "Scripture", giving them an ecclesiastical if not a canonical position and use. Luther also wrote introductions to the books of the Apocrypha, and occasionally quoted from some to support an argument.

In his prologue to Judith, without using the word canon, Jerome mentioned that Judith was held to be scriptural by the First Council of Nicaea.

In his reply to Rufinus, Jerome affirmed that he was consistent with the choice of the church regarding which version of the deuterocanonical portions of Daniel to use, which the Jews of his day did not include:

Thus Jerome acknowledged the principle by which the canon would be settled – the judgment of the Church (at least the local churches in this case) rather than his own judgment or the judgment of Jews; though concerning translation of Daniel to Greek, he wondered why one should use the version of a translator whom he regarded as a heretic and judaizer (Theodotion).

The Vulgate is also important as the touchstone of the canon concerning which parts of books are canonical. When the Council of Trent listed the books included in the canon, it qualified the books as being "entire with all their parts, as they have been used to be read in the Catholic Church, and as they are contained in the old Latin vulgate edition". This decree was clarified somewhat by Pope Pius XI on 2 June 1927, who allowed that the Comma Johanneum was open to dispute, and it was further explicated by Pope Pius XII's "Divino afflante Spiritu".

The Council of Trent also promulgated the Vulgate Bible as the official Latin version of the Bible for the Roman Catholic Church.

Deuterocanonical and Apocryphal books included in the Latin Vulgate

Philip Schaff says that "the Council of Hippo in 393, and the third (according to another reckoning the sixth) Council of Carthage in 397, under the influence of Augustine, who attended both, fixed the catholic canon of the Holy Scriptures, including the Apocrypha of the Old Testament, ...This decision of the transmarine church, however, was subject to ratification; and the concurrence of the Roman see it received when Innocent I and Gelasius I (AD 414) repeated the same index of biblical books." Schaff says that this canon remained undisturbed till the sixteenth century, and was sanctioned by the Council of Trent at its fourth session, although as the "Catholic Encyclopedia" reports, "in the Latin Church, all through the Middle Ages we find evidence of hesitation about the character of the deuterocanonicals. ... Few are found to unequivocally acknowledge their canonicity," but that the countless manuscript copies of the Vulgate produced by these ages, with a slight, probably accidental, exception, uniformly embrace the complete Roman Catholic Old Testament. Subsequent research qualifies this latter statement, in that a distinct tradition of large format pandect bibles has been identified as having been promoted by the 11th and 12th century reforming Papacy for presentation to monasteries in Italy; and now commonly termed 'Atlantic Bibles' on account of their very great size. While not all these bibles present a consistent reformed Vulgate text, they generally exclude the deuterocanonical books.

Exceptions to this narrative are Baruch and the Letter of Jeremiah, which appear in the Greek canon lists of the Council of Laodicea, Athanasius (AD 367), Cyril of Jerusalem (c. AD 350), and Epiphanius of Salamis (c. AD 385) but are not separately listed as canonical in the Latin accounts of the Canons of Laodicea or any other Western synods and councils, nor are specified as canonical by Innocent I and Gelasius I, nor are present in any complete Vulgate Bibles earlier than the 9th century; and even after that date, do not become common in the Vulgate Old Testament until the 13th century. In the Old Latin version of the Bible, these two works appear to have been incorporated into the Book of Jeremiah, and Latin Fathers of the 4th century and earlier always cite their texts as being from that book. However, when Jerome translated Jeremiah afresh from the Hebrew text, which is considerably longer than the Greek Septuagint text and with chapters in a different order, he steadfastly refused to incorporate either Baruch or the Letter of Jeremiah from the Greek. As the Vulgate Bible supplanted the Old Latin in Western church use in subsequent centuries, so Baruch and the letter of Jeremiah are no longer treated as canonical in the works of Fathers who favoured the Vulgate, Gregory the Great, Isidore of Seville and Bede. In the 9th century these two works were reintroduced into the Vulgate Bibles produced under the influence of Theodulf of Orleans, originally as additional chapters to the Vulgate book of Jeremiah. Subsequently, and especially in the Paris Bibles of the 13th century, they are found together as a single, combined book after Lamentations.

For the Roman Catholic Church Greek Esdras is apocryphal, while the Orthodox Church considers it as canonical. The canonical status of this book in the Western church is less easy to track, as references to Esdras in canon lists may refer either to this book, or to Greek Ezra–Nehemiah, or both. In the surviving Greek pandect Bibles of the 4th and 5th centuries, Greek Esdras always stands as 'Esdras A' while the Greek translation of the whole of canonical Ezra–Nehemiah stands as 'Esdras B'; and the same is found in the surviving witness of the Old Latin Bible. When Latin fathers of the early church cite quotations from the biblical 'Book of Ezra' it is overwhelmingly 'First Ezra/Esdras A' to which they refer, as in Augustine 'City of God' 18:36. Citations of the 'Nehemiah' sections of Old Latin Second Ezra/'Esdras B' are much rarer; and no Old Latin citations from the 'Ezra' sections of Second Ezra/'Esdras B' are known before Bede in the 8th century. In Jerome's Vulgate Bible however, there is only one Book of Ezra, translating Hebrew Ezra–Nehemiah but corresponding to Greek Esdras B; Esdras A is stated by Jerome to be a variant version, "(exemplaria varietas)" of the same Hebrew original. In the prologue to Ezra Jerome states that 3 Esdras (Greek Esdras) and 4 Esdras are apocryphal. 

From the 9th century, occasional Latin Vulgate manuscripts are found in which Jerome's single Ezra text is split to form the separate books of Ezra and Nehemiah; and in the Paris Bibles of the 13th century this split has become universal, with Esdras A being reintroduced as '3 Esdras' and Latin Esdras being added as '4 Esdras'. At the Council of Trent neither '3 Esdras' nor '4 Esdras' were accepted as canonical books, but were eventually printed in the section of 'Apocrypha' in the Sixto-Clementine Vulgate, along with the Prayer of Manasses.

The Council of Trent in 1546 stated the list of books included in the canon as it had been set out in the Council of Florence. In respect to the deuterocanonical books this list conformed with the canon lists of Western synods of the late 4th century, other than including Baruch with the Letter of Jeremiah as a separate book, and in excluding Greek Esdras. While the majority at Trent supported this decision there were participants in the minority who disagreed with accepting any other than the protocanonical books in the canon. Among the minority, at Trent, were Cardinals Seripando and Cajetan, the latter an opponent of Luther at Augsburg.

Outside the Roman Catholic Church, the term deuterocanonical is sometimes used, by way of analogy, to describe books that Eastern Orthodoxy and Oriental Orthodoxy included in the Old Testament that are not part of the Jewish Tanakh, nor the Protestant Old Testament. Among Orthodox, the term is understood to mean that they were compiled separately from the primary canon, as explained in 2 Esdras, where Esdras is instructed to keep certain books separate and hidden.

The Eastern Orthodox Churches have traditionally included all the books of the Septuagint in their Old Testaments. The Greeks use the word "" (Ἀναγιγνωσκόμενα "readable, worthy to be read") to describe the books of the Greek Septuagint that are not present in the Hebrew Bible. When E. Orthodox theologians use the term "deuterocanonical", it is important to note that the meaning is not identical to the Roman Catholic usage. In E. Orthodox Christianity, deuterocanonical means that a book is part of the corpus of the Old Testament (i.e. is read during the services) but has secondary authority. In other words, deutero (second) applies to authority or witnessing power, whereas in Roman Catholicism, deutero applies to chronology (the fact that these books were confirmed later), not to authority.

The Eastern Orthodox canon includes the deuterocanonical books accepted by Roman Catholics plus Psalm 151, the Prayer of Manasseh, 3 Maccabees and 1 Esdras (also included in the Clementine Vulgate), while Baruch is divided from the Epistle of Jeremiah, making a total of 49 Old Testament books in contrast with the Protestant 39-book canon.

Like the Roman Catholic deuterocanonical books, these texts are integrated with the rest of the Old Testament, not printed in a separate section.

Other texts printed in Orthodox Bibles are included as an appendix, which is not the same in all churches; the appendix contains 4 Maccabees in Greek-language bibles, while it contains 2 Esdras in Slavonic-language and Russian-language bibles.

In the Ethiopic Bible used by the Ethiopian Orthodox Church (an Oriental Orthodox Church), those books of the Old Testament that are still counted as canonical, but which are not agreed upon by all other Churches, are often set in a separate section titled ""Deeyutrokanoneekal"" (ዲዩትሮካኖኒካል), which is the same word as "Deuterocanonical". The Ethiopian Orthodox Deuterocanon, in addition to the standard set listed above, and with the books of Esdras and "Prayer of Minasse", also includes some books that are still held canonical by only the Ethiopian Church, including Enoch or "Henok" (I Enoch), "Kufale" (Jubilees) and 1, 2 and 3 Meqabyan (which are sometimes wrongly confused with the "Books of Maccabees").

There is a great deal of overlap between the Apocrypha section of the original 1611 King James Bible and the Catholic deuterocanon, but the two are distinct. The Apocrypha section of the original 1611 King James Bible includes, in addition to the deuterocanonical books, the following three books, which were not included in the list of the canonical books by the Council of Trent:

These books make up the Apocrypha section of the Clementine Vulgate: 3 Esdras (a.k.a. 1 Esdras); 4 Esdras (a.k.a. 2 Esdras); and the Prayer of Manasseh, where they are specifically described as "outside of the series of the canon". The 1609 Douai Bible includes them in an appendix, but they have not been included in English Catholic Bibles since the Challoner revision of the Douai Bible in 1750. They are found, along with the deuterocanonical books, in the Apocrypha section of certain Protestant Bibles (some versions of the King James, for example).

Using the word apocrypha (Greek: "hidden away") to describe texts, although not necessarily pejorative, implies to some people that the writings in question should not be included in the canon of the Bible. This classification commingles them with certain non-canonical gospels and New Testament apocrypha. "The Society of Biblical Literature" recommends the use of the term "deuterocanonical books" instead of "Apocrypha" in academic writing.

The Thirty-nine Articles of Religion of the Church of England lists the deuterocanonical books as suitable to be read for "example of life and instruction of manners, but yet doth not apply them to establish any doctrine". The early lectionaries of the Anglican Church (as included in the Book of Common Prayer of 1662) included the deuterocanonical books amongst the cycle of readings, and passages from them were used regularly in services (such as the Kyrie Pantokrator and the Benedicite).

Readings from the deuterocanonical books are now included in most, if not all, of the modern lectionaries in the Anglican Communion, based on the Revised Common Lectionary (in turn based on the post-conciliar Roman Catholic lectionary), though alternative readings from protocanonical books are also provided.

Luther did not accept deuterocanonical books in his Old Testament, terming them "Apocrypha, that is, books which are not considered equal to the Holy Scriptures, but are useful and good to read."

The first Methodist liturgical book, "The Sunday Service of the Methodists", employs verses from the biblical apocrypha, such as in the Eucharistic liturgy.

The Revised Common Lectionary, in use by most mainline Protestants including Methodists and Moravians, lists readings from the biblical apocrypha in the liturgical kalendar, although alternate Old Testament scripture lessons are provided.

The Westminster Confession of Faith, a Calvinist document that serves as a systematic summary of doctrine for the Church of Scotland and other Presbyterian Churches worldwide, recognizes only the sixty-six books of the Protestant canon as authentic Scripture. Chapter 1, Article 3 of the Confession reads: "The books commonly called Apocrypha, not being of divine inspiration, are no part of the Canon of Scripture; and therefore are of no authority in the Church of God, nor to be any otherwise approved, or made use of, than other human writings."

The Belgic Confession, used in Reformed churches, devotes a section (Article 6) to "the difference between the canonical and apocryphal books" and says of them: "All which the Church may read and take instruction from, so far as they agree with the canonical books; but they are far from having such power and efficacy as that we may from their testimony confirm any point of faith or of the Christian religion; much less to detract from the authority of the other sacred books."

Judaism excludes these books. It is commonly said that Judaism officially excluded the deuterocanonicals and the additional Greek texts listed here from their Scripture in the Council of Jamnia (c. AD 70–90 ), but this claim is disputed.

The term "deuterocanonical" is sometimes used to describe the canonical antilegomena, those books of the New Testament which, like the deuterocanonicals of the Old Testament, were not universally accepted by the early Church. These books may be called the "New Testament deuterocanonicals", which are now included in the 27 books of the New Testament recognized by almost all Christians. The deuterocanonicals of the New Testament are as follows:

Luther made an attempt to remove the books of Hebrews, James, Jude and Revelation from the canon (notably, he perceived them to go against the doctrines of "sola gratia" and "sola fide"), but this was not generally accepted among his followers. However, these books are ordered last in the German-language Luther Bible to this day.





</doc>
<doc id="8490" url="https://en.wikipedia.org/wiki?curid=8490" title="Discus throw">
Discus throw

The discus throw (), also known as disc throw, is a track and field event in which an athlete throws a heavy disc—called a discus—in an attempt to mark a farther distance than their competitors. It is an ancient sport, as demonstrated by the fifth-century-BC Myron statue "Discobolus". Although not part of the modern pentathlon, it was one of the events of the ancient Greek pentathlon, which can be dated back to at least to 708 BC, and it is part of the modern decathlon.

The sport of throwing the discus traces back to it being an event in the original Olympic Games of Ancient Greece. The discus as a sport was resurrected in Magdeburg, Germany, by Christian Georg Kohlrausch and his students in the 1870s. Organized Men's competition was resumed in the late 19th century, and has been a part of the modern Summer Olympic Games since the first modern competition, the 1896 Summer Olympics. Images of discus throwers figured prominently in advertising for early modern Games, such as fundraising stamps for the 1896 games, the main posters for the 1920 and 1948 Summer Olympics. Today the sport of discus is a routine part of modern track-and-field meets at all levels, and retains a particularly iconic place in the Olympic Games.

The first modern athlete to throw the discus while rotating the whole body was František Janda-Suk from Bohemia (the present Czech Republic). He invented this technique when studying the position of the famous statue of Discobolus. After only one year of developing the technique he earned a silver medal in the 1900 Olympics.

Women's competition began in the first decades of the 20th century. Following competition at national and regional levels it was added to the Olympic program for the 1928 games.

The event consists of throwing a lenticular disc of a certain weight or size depending on the competitor. Men and women throw different sized discus with varying sizes of weights depending on age. The weight of the discus is either governed by the World Athletics for international or USA Track & Field for the United States.

The typical discus has sides made of plastic, wood, fiberglass, carbon fiber or metal with a metal rim and a metal core to attain the weight. The rim must be smooth, with no roughness or finger holds. A discus with more weight in the rim produces greater angular momentum for any given spin rate, and thus more stability, although it is more difficult to throw. However, a higher rim weight, if thrown correctly, can lead to a farther throw. In some competitions, a solid rubber discus is used (see in the United States).

To make a throw, the competitor starts in a circle of diameter, which is recessed in a concrete pad by . The thrower typically takes an initial stance facing away from the direction of the throw. He then spins anticlockwise (for right-handers) around one and a half times through the circle to build momentum, then releases his throw. The discus must land within a 34.92-degree sector. The rules of competition for discus are virtually identical to those of shot put, except that the circle is larger, a stop board is not used and there are no form rules concerning how the discus is to be thrown.

The basic motion is a fore-handed sidearm movement. The discus is spun off the index finger or the middle finger of the throwing hand. In flight the disc spins clockwise when viewed from above for a right-handed thrower, and anticlockwise for a left-handed thrower. As well as achieving maximum momentum in the discus on throwing, the discus' distance is also determined by the trajectory the thrower imparts, as well as the aerodynamic behavior of the discus. Generally, throws into a moderate headwind achieve the maximum distance. Also, a faster-spinning discus imparts greater gyroscopic stability. The technique of discus throwing is quite difficult to master and needs much experience to perfect, thus most top throwers are 30 years old or more.

The discus technique can be broken down into phases. The purpose is to transfer from the back to the front of the throwing circle while turning through one and a half circles. The speed of delivery is high, and speed is built up during the throw (slow to fast). Correct technique involves the buildup of torque so that maximum force can be applied to the discus on delivery.

Initially, the thrower takes up their position in the throwing circle, distributing their body weight evenly over both feet, which are roughly shoulder width apart. They crouch in order to adopt a more efficient posture to start from whilst also isometrically preloading their muscles; this will allow them to start faster and achieve a more powerful throw. They then begin the wind-up, which sets the tone for the entire throw; the rhythm of the wind-up and throw is very important.

Focusing on rhythm can bring about the consistency to get in the right positions that many throwers lack. Executing a sound discus throw with solid technique requires perfect balance. This is due to the throw being a linear movement combined with a one and a half rotation and an implement at the end of one arm. Thus, a good discus thrower needs to maintain balance within the circle.

For a right handed thrower, the next stage is to move the weight over the left foot. From this position the right foot is raised, and the athlete 'runs' across the circle. There are various techniques for this stage where the leg swings out to a small or great extent, some athletes turn on their left heel (e.g. Ilke Wylluda) but turning on the ball of the foot is far more common.

The aim is to land in the 'power position', the right foot should be in the center and the heel should not touch the ground at any point. The left foot should land very quickly after the right. Weight should be mostly over the back foot with as much torque as possible in the body—so the right arm is high and far back. This is very hard to achieve.

The critical stage is the delivery of the discus, from this 'power position' the hips drive through hard, and will be facing the direction of the throw on delivery. Athletes employ various techniques to control the end-point and recover from the throw, such as fixing feet (to pretty much stop dead), or an active reverse spinning onto the left foot (e.g. Virgilijus Alekna).

Sports scientist Richard Ganslen researched the "Aerodynamics of the Discus", reporting the discus will stall at an angle of 29°.

The discus throw has been the subject of a number of well-known ancient Greek statues and Roman copies such as the Discobolus and Discophoros. The discus throw also appears repeatedly in ancient Greek mythology, featured as a means of manslaughter in the cases of Hyacinth, Crocus, Phocus, and Acrisius, and as a named event in the funeral games of Patroclus.

Discus throwers have been selected as a main motif in numerous collectors' coins. One of the recent samples is the €10 Greek Discus commemorative coin, minted in 2003 to commemorate the 2004 Summer Olympics. On the obverse of the coin a modern athlete is seen in the foreground in a half-turned position, while in the background an ancient discus thrower has been captured in a lively bending motion, with the discus high above his head, creating a vivid representation of the sport.

Under US high school rules, if a discus hits the surrounding safety cage and is deflected into the sector, it is ruled a foul. In contrast, under International, WMA, NCAA and USATF rules, it is ruled a legal throw. Additionally, under US high school rules, distances thrown are rounded down to the nearest whole inch, rather than the nearest centimeter.

US high school rules allow the use of a solid rubber discus; it is cheaper and easier to learn to throw (due to its more equal distribution of weight, as opposed to the heavy rim weight of the metal rim/core discus), but less durable. However, there are a vast variety of metal discuses to choose from. The weight is not always distributed into the rim of metal discuses as there are four categories that the discs are sold in; center weighted, low spin, high spin, and very high spin. Center weighted discs carry 50-60% of their weight in the rims and are intended for beginner throwers just as rubber discs are.



At the 2019 Diamond League Meeting in Doha, Qatar, Daniel Ståhl became the first man to produce six throws beyond 69.50 in a single competition.






</doc>
<doc id="8492" url="https://en.wikipedia.org/wiki?curid=8492" title="Discrete mathematics">
Discrete mathematics

Discrete mathematics is the study of mathematical structures that are fundamentally discrete rather than continuous. In contrast to real numbers that have the property of varying "smoothly", the objects studied in discrete mathematics – such as integers, graphs, and statements in logic – do not vary smoothly in this way, but have distinct, separated values. Discrete mathematics therefore excludes topics in "continuous mathematics" such as calculus or Euclidean geometry. Discrete objects can often be enumerated by integers. More formally, discrete mathematics has been characterized as the branch of mathematics dealing with countable sets (finite sets or sets with the same cardinality as the natural numbers). However, there is no exact definition of the term "discrete mathematics." Indeed, discrete mathematics is described less by what is included than by what is excluded: continuously varying quantities and related notions.

The set of objects studied in discrete mathematics can be finite or infinite. The term finite mathematics is sometimes applied to parts of the field of discrete mathematics that deals with finite sets, particularly those areas relevant to business.

Research in discrete mathematics increased in the latter half of the twentieth century partly due to the development of digital computers which operate in discrete steps and store data in discrete bits. Concepts and notations from discrete mathematics are useful in studying and describing objects and problems in branches of computer science, such as computer algorithms, programming languages, cryptography, automated theorem proving, and software development. Conversely, computer implementations are significant in applying ideas from discrete mathematics to real-world problems, such as in operations research.

Although the main objects of study in discrete mathematics are discrete objects, analytic methods from continuous mathematics are often employed as well.

In university curricula, "Discrete Mathematics" appeared in the 1980s, initially as a computer science support course; its contents were somewhat haphazard at the time. The curriculum has thereafter developed in conjunction with efforts by ACM and MAA into a course that is basically intended to develop mathematical maturity in first-year students; therefore it is nowadays a prerequisite for mathematics majors in some universities as well. Some high-school-level discrete mathematics textbooks have appeared as well. At this level, discrete mathematics is sometimes seen as a preparatory course, not unlike precalculus in this respect.

The Fulkerson Prize is awarded for outstanding papers in discrete mathematics.

The history of discrete mathematics has involved a number of challenging problems which have focused attention within areas of the field. In graph theory, much research was motivated by attempts to prove the four color theorem, first stated in 1852, but not proved until 1976 (by Kenneth Appel and Wolfgang Haken, using substantial computer assistance).

In logic, the second problem on David Hilbert's list of open problems presented in 1900 was to prove that the axioms of arithmetic are consistent. Gödel's second incompleteness theorem, proved in 1931, showed that this was not possible – at least not within arithmetic itself. Hilbert's tenth problem was to determine whether a given polynomial Diophantine equation with integer coefficients has an integer solution. In 1970, Yuri Matiyasevich proved that this could not be done.

The need to break German codes in World War II led to advances in cryptography and theoretical computer science, with the first programmable digital electronic computer being developed at England's Bletchley Park with the guidance of Alan Turing and his seminal work, On Computable Numbers. At the same time, military requirements motivated advances in operations research. The Cold War meant that cryptography remained important, with fundamental advances such as public-key cryptography being developed in the following decades. Operations research remained important as a tool in business and project management, with the critical path method being developed in the 1950s. The telecommunication industry has also motivated advances in discrete mathematics, particularly in graph theory and information theory. Formal verification of statements in logic has been necessary for software development of safety-critical systems, and advances in automated theorem proving have been driven by this need.

Computational geometry has been an important part of the computer graphics incorporated into modern video games and computer-aided design tools.

Several fields of discrete mathematics, particularly theoretical computer science, graph theory, and combinatorics, are important in addressing the challenging bioinformatics problems associated with understanding the tree of life.

Currently, one of the most famous open problems in theoretical computer science is the P = NP problem, which involves the relationship between the complexity classes P and NP. The Clay Mathematics Institute has offered a $1 million USD prize for the first correct proof, along with prizes for six other mathematical problems.

Theoretical computer science includes areas of discrete mathematics relevant to computing. It draws heavily on graph theory and mathematical logic. Included within theoretical computer science is the study of algorithms and data structures. Computability studies what can be computed in principle, and has close ties to logic, while complexity studies the time, space, and other resources taken by computations. Automata theory and formal language theory are closely related to computability. Petri nets and process algebras are used to model computer systems, and methods from discrete mathematics are used in analyzing VLSI electronic circuits. Computational geometry applies algorithms to geometrical problems, while computer image analysis applies them to representations of images. Theoretical computer science also includes the study of various continuous computational topics.

Information theory involves the quantification of information. Closely related is coding theory which is used to design efficient and reliable data transmission and storage methods. Information theory also includes continuous topics such as: analog signals, analog coding, analog encryption.

Logic is the study of the principles of valid reasoning and inference, as well as of consistency, soundness, and completeness. For example, in most systems of logic (but not in intuitionistic logic) Peirce's law ((("P"→"Q")→"P")→"P") is a theorem. For classical logic, it can be easily verified with a truth table. The study of mathematical proof is particularly important in logic, and has applications to automated theorem proving and formal verification of software.

Logical formulas are discrete structures, as are proofs, which form finite trees or, more generally, directed acyclic graph structures (with each inference step combining one or more premise branches to give a single conclusion). The truth values of logical formulas usually form a finite set, generally restricted to two values: "true" and "false", but logic can also be continuous-valued, e.g., fuzzy logic. Concepts such as infinite proof trees or infinite derivation trees have also been studied, e.g. infinitary logic.

Set theory is the branch of mathematics that studies sets, which are collections of objects, such as {blue, white, red} or the (infinite) set of all prime numbers. Partially ordered sets and sets with other relations have applications in several areas.

In discrete mathematics, countable sets (including finite sets) are the main focus. The beginning of set theory as a branch of mathematics is usually marked by Georg Cantor's work distinguishing between different kinds of infinite set, motivated by the study of trigonometric series, and further development of the theory of infinite sets is outside the scope of discrete mathematics. Indeed, contemporary work in descriptive set theory makes extensive use of traditional continuous mathematics.

Combinatorics studies the way in which discrete structures can be combined or arranged.
Enumerative combinatorics concentrates on counting the number of certain combinatorial objects - e.g. the twelvefold way provides a unified framework for counting permutations, combinations and partitions.
Analytic combinatorics concerns the enumeration (i.e., determining the number) of combinatorial structures using tools from complex analysis and probability theory. In contrast with enumerative combinatorics which uses explicit combinatorial formulae and generating functions to describe the results, analytic combinatorics aims at obtaining asymptotic formulae.
Design theory is a study of combinatorial designs, which are collections of subsets with certain intersection properties.
Partition theory studies various enumeration and asymptotic problems related to integer partitions, and is closely related to q-series, special functions and orthogonal polynomials. Originally a part of number theory and analysis, partition theory is now considered a part of combinatorics or an independent field.
Order theory is the study of partially ordered sets, both finite and infinite.

Graph theory, the study of graphs and networks, is often considered part of combinatorics, but has grown large enough and distinct enough, with its own kind of problems, to be regarded as a subject in its own right. Graphs are one of the prime objects of study in discrete mathematics. They are among the most ubiquitous models of both natural and human-made structures. They can model many types of relations and process dynamics in physical, biological and social systems. In computer science, they can represent networks of communication, data organization, computational devices, the flow of computation, etc. In mathematics, they are useful in geometry and certain parts of topology, e.g. knot theory. Algebraic graph theory has close links with group theory. There are also continuous graphs; however, for the most part, research in graph theory falls within the domain of discrete mathematics.

Discrete probability theory deals with events that occur in countable sample spaces. For example, count observations such as the numbers of birds in flocks comprise only natural number values {0, 1, 2, ...}. On the other hand, continuous observations such as the weights of birds comprise real number values and would typically be modeled by a continuous probability distribution such as the normal. Discrete probability distributions can be used to approximate continuous ones and vice versa. For highly constrained situations such as throwing dice or experiments with decks of cards, calculating the probability of events is basically enumerative combinatorics.

Number theory is concerned with the properties of numbers in general, particularly integers. It has applications to cryptography and cryptanalysis, particularly with regard to modular arithmetic, diophantine equations, linear and quadratic congruences, prime numbers and primality testing. Other discrete aspects of number theory include geometry of numbers. In analytic number theory, techniques from continuous mathematics are also used. Topics that go beyond discrete objects include transcendental numbers, diophantine approximation, p-adic analysis and function fields.

Algebraic structures occur as both discrete examples and continuous examples. Discrete algebras include: boolean algebra used in logic gates and programming; relational algebra used in databases; discrete and finite versions of groups, rings and fields are important in algebraic coding theory; discrete semigroups and monoids appear in the theory of formal languages.

A function defined on an interval of the integers is usually called a sequence. A sequence could be a finite sequence from a data source or an infinite sequence from a discrete dynamical system. Such a discrete function could be defined explicitly by a list (if its domain is finite), or by a formula for its general term, or it could be given implicitly by a recurrence relation or difference equation. Difference equations are similar to differential equations, but replace differentiation by taking the difference between adjacent terms; they can be used to approximate differential equations or (more often) studied in their own right. Many questions and methods concerning differential equations have counterparts for difference equations. For instance, where there are integral transforms in harmonic analysis for studying continuous functions or analogue signals, there are discrete transforms for discrete functions or digital signals. As well as the discrete metric there are more general discrete or finite metric spaces and finite topological spaces.

Discrete geometry and combinatorial geometry are about combinatorial properties of "discrete collections" of geometrical objects. A long-standing topic in discrete geometry is tiling of the plane. Computational geometry applies algorithms to geometrical problems.

Although topology is the field of mathematics that formalizes and generalizes the intuitive notion of "continuous deformation" of objects, it gives rise to many discrete topics; this can be attributed in part to the focus on topological invariants, which themselves usually take discrete values.
See combinatorial topology, topological graph theory, topological combinatorics, computational topology, discrete topological space, finite topological space, topology (chemistry).

Operations research provides techniques for solving practical problems in engineering, business, and other fields — problems such as allocating resources to maximize profit, and scheduling project activities to minimize risk. Operations research techniques include linear programming and other areas of optimization, queuing theory, scheduling theory, and network theory. Operations research also includes continuous topics such as continuous-time Markov process, continuous-time martingales, process optimization, and continuous and hybrid control theory.

Decision theory is concerned with identifying the values, uncertainties and other issues relevant in a given decision, its rationality, and the resulting optimal decision.

Utility theory is about measures of the relative economic satisfaction from, or desirability of, consumption of various goods and services.

Social choice theory is about voting. A more puzzle-based approach to voting is ballot theory.

Game theory deals with situations where success depends on the choices of others, which makes choosing the best course of action more complex. There are even continuous games, see differential game. Topics include auction theory and fair division.

Discretization concerns the process of transferring continuous models and equations into discrete counterparts, often for the purposes of making calculations easier by using approximations. Numerical analysis provides an important example.

There are many concepts in continuous mathematics which have discrete versions, such as discrete calculus, discrete probability distributions, discrete Fourier transforms, discrete geometry, discrete logarithms, discrete differential geometry, discrete exterior calculus, discrete Morse theory, difference equations, discrete dynamical systems, and discrete vector measures.

In applied mathematics, discrete modelling is the discrete analogue of continuous modelling. In discrete modelling, discrete formulae are fit to data. A common method in this form of modelling is to use recurrence relation.

In algebraic geometry, the concept of a curve can be extended to discrete geometries by taking the spectra of polynomial rings over finite fields to be models of the affine spaces over that field, and letting subvarieties or spectra of other rings provide the curves that lie in that space. Although the space in which the curves appear has a finite number of points, the curves are not so much sets of points as analogues of curves in continuous settings. For example, every point of the form formula_1 for formula_2 a field can be studied either as formula_3, a point, or as the spectrum formula_4 of the local ring at (x-c), a point together with a neighborhood around it. Algebraic varieties also have a well-defined notion of tangent space called the Zariski tangent space, making many features of calculus applicable even in finite settings.

The time scale calculus is a unification of the theory of difference equations with that of differential equations, which has applications to fields requiring simultaneous modelling of discrete and continuous data. Another way of modeling such a situation is the notion of hybrid dynamical systems.





</doc>
<doc id="8494" url="https://en.wikipedia.org/wiki?curid=8494" title="DDT">
DDT

Dichlorodiphenyltrichloroethane, commonly known as DDT, is a colorless, tasteless, and almost odorless crystalline chemical compound, an organochlorine. Originally developed as an insecticide, it became infamous for its environmental impacts. DDT was first synthesized in 1874 by the Austrian chemist Othmar Zeidler. DDT's insecticidal action was discovered by the Swiss chemist Paul Hermann Müller in 1939. DDT was used in the second half of World War II to control malaria and typhus among civilians and troops. Müller was awarded the Nobel Prize in Physiology or Medicine in 1948 "for his discovery of the high efficiency of DDT as a contact poison against several arthropods".

By October 1945, DDT was available for public sale in the United States. Although it was promoted by government and industry for use as an agricultural and household pesticide, there were also concerns about its use from the beginning. Opposition to DDT was focused by the 1962 publication of Rachel Carson's book "Silent Spring". It talked about environmental impacts that correlated with widespread use of DDT in agriculture in the United States, and it questioned the logic of broadcasting potentially dangerous chemicals into the environment with little prior investigation of their environmental and health effects. The book cited claims that DDT and other pesticides caused cancer and that their agricultural use was a threat to wildlife, particularly birds. Although Carson never directly called for an outright ban on the use of DDT, its publication was a seminal event for the environmental movement and resulted in a large public outcry that eventually led, in 1972, to a ban on DDT's agricultural use in the United States. A worldwide ban on agricultural use was formalized under the Stockholm Convention on Persistent Organic Pollutants, but its limited and still-controversial use in disease vector control continues, because of its effectiveness in reducing malarial infections, balanced by environmental and other health concerns.

Along with the passage of the Endangered Species Act, the United States ban on DDT is a major factor in the comeback of the bald eagle (the national bird of the United States) and the peregrine falcon from near-extinction in the contiguous United States.

DDT is similar in structure to the insecticide methoxychlor and the acaricide dicofol. It is highly hydrophobic and nearly insoluble in water but has good solubility in most organic solvents, fats and oils. DDT does not occur naturally and is synthesised by consecutive Friedel–Crafts reactions between chloral () and two equivalents of chlorobenzene (), in the presence of an acidic catalyst. DDT has been marketed under trade names including Anofex, Cezarex, Chlorophenothane, Dicophane, Dinocide, Gesarol, Guesapon, Guesarol, Gyron, Ixodex, Neocid, Neocidol and Zerdane; INN is clofenotane.

Commercial DDT is a mixture of several closely–related compounds. Due to the nature of the chemical reaction used to synthesize DDT, several combinations of "ortho" and "para" arene substitution patterns are formed. The major component (77%) is the desired "p","p" isomer. The "o","p" isomeric impurity is also present in significant amounts (15%). Dichlorodiphenyldichloroethylene (DDE) and dichlorodiphenyldichloroethane (DDD) make up the balance of impurities in commercial samples. DDE and DDD are also the major metabolites and environmental breakdown products. DDT, DDE and DDD are sometimes referred to collectively as DDX.

DDT has been formulated in multiple forms, including solutions in xylene or petroleum distillates, emulsifiable concentrates, water-wettable powders, granules, aerosols, smoke candles and charges for vaporizers and lotions.

From 1950 to 1980, DDT was extensively used in agriculture – more than 40,000 tonnes each year worldwide – and it has been estimated that a total of 1.8 million tonnes have been produced globally since the 1940s. In the United States, it was manufactured by some 15 companies, including Monsanto, Ciba, Montrose Chemical Company, Pennwalt, and Velsicol Chemical Corporation. Production peaked in 1963 at 82,000 tonnes per year. More than 600,000 tonnes (1.35 billion pounds) were applied in the US before the 1972 ban. Usage peaked in 1959 at about 36,000 tonnes.

In 2009, 3,314 tonnes were produced for malaria control and visceral leishmaniasis. India is the only country still manufacturing DDT, and is the largest consumer.<ref name="DDTBP.1/2"></ref> China ceased production in 2007.

In insects, DDT opens sodium ion channels in neurons, causing them to fire spontaneously, which leads to spasms and eventual death. Insects with certain mutations in their sodium channel gene are resistant to DDT and similar insecticides. DDT resistance is also conferred by up-regulation of genes expressing cytochrome P450 in some insect species, as greater quantities of some enzymes of this group accelerate the toxin's metabolism into inactive metabolites. (The same enzyme family is up-regulated in mammals too, e.g., in response to ethanol consumption.) Genomic studies in the model genetic organism "Drosophila melanogaster" revealed that high level DDT resistance is polygenic, involving multiple resistance mechanisms.

DDT was first synthesized in 1874 by Othmar Zeidler under the supervision of Adolf von Baeyer. It was further described in 1929 in a dissertation by W. Bausch and in two subsequent publications in 1930. The insecticide properties of "multiple chlorinated aliphatic or fat-aromatic alcohols with at least one trichloromethane group" were described in a patent in 1934 by Wolfgang von Leuthold. DDT's insecticidal properties were not, however, discovered until 1939 by the Swiss scientist Paul Hermann Müller, who was awarded the 1948 Nobel Prize in Physiology and Medicine for his efforts.

DDT is the best-known of several chlorine-containing pesticides used in the 1940s and 1950s. With pyrethrum in short supply, DDT was used extensively during World War II by the Allies to control the insect vectors of typhus – nearly eliminating the disease in many parts of Europe. In the South Pacific, it was sprayed aerially for malaria and dengue fever control with spectacular effects. While DDT's chemical and insecticidal properties were important factors in these victories, advances in application equipment coupled with competent organization and sufficient manpower were also crucial to the success of these programs.

In 1945, DDT was made available to farmers as an agricultural insecticide and played a role in the temporary elimination of malaria in Europe and North America.

In 1955, the World Health Organization commenced a program to eradicate malaria in countries with low to moderate transmission rates worldwide, relying largely on DDT for mosquito control and rapid diagnosis and treatment to reduce transmission. The program eliminated the disease in "North America, Europe, the former Soviet Union", and in "Taiwan, much of the Caribbean, the Balkans, parts of northern Africa, the northern region of Australia, and a large swath of the South Pacific" and dramatically reduced mortality in Sri Lanka and India.

However, failure to sustain the program, increasing mosquito tolerance to DDT, and increasing parasite tolerance led to a resurgence. In many areas early successes partially or completely reversed, and in some cases rates of transmission increased. The program succeeded in eliminating malaria only in areas with "high socio-economic status, well-organized healthcare systems, and relatively less intensive or seasonal malaria transmission".

DDT was less effective in tropical regions due to the continuous life cycle of mosquitoes and poor infrastructure. It was not applied at all in sub-Saharan Africa due to these perceived difficulties. Mortality rates in that area never declined to the same dramatic extent, and now constitute the bulk of malarial deaths worldwide, especially following the disease's resurgence as a result of resistance to drug treatments and the spread of the deadly malarial variant caused by "Plasmodium falciparum". Eradication was abandoned in 1969 and attention instead focused on controlling and treating the disease. Spraying programs (especially using DDT) were curtailed due to concerns over safety and environmental effects, as well as problems in administrative, managerial and financial implementation. Efforts shifted from spraying to the use of bednets impregnated with insecticides and other interventions.

By October 1945, DDT was available for public sale in the United States, used both as an agricultural pesticide and as a household insecticide. Although its use was promoted by government and the agricultural industry, US scientists such as FDA pharmacologist Herbert O. Calvery expressed concern over possible hazards associated with DDT as early as 1944. In 1947, Dr. Bradbury Robinson, a physician and nutritionist practicing in St. Louis, Michigan, warned of the dangers of using the pesticide DDT in agriculture. DDT had been researched and manufactured in St. Louis by the Michigan Chemical Corporation, later purchased by Velsicol Chemical Corporation, and had become an important part of the local economy. Citing research performed by Michigan State University in 1946, Robinson, a past president of the local Conservation Club, opined that: ... perhaps the greatest danger from D.D.T. is that its extensive use in farm areas is most likely to upset the natural balances, not only killing beneficial insects in great number but by bringing about the death of fish, birds, and other forms of wild life either by their feeding on insects killed by D.D.T. or directly by ingesting the poison.

As its production and use increased, public response was mixed. At the same time that DDT was hailed as part of the "world of tomorrow," concerns were expressed about its potential to kill harmless and beneficial insects (particularly pollinators), birds, fish, and eventually humans. The issue of toxicity was complicated, partly because DDT's effects varied from species to species, and partly because consecutive exposures could accumulate, causing damage comparable to large doses. A number of states attempted to regulate DDT. In the 1950s the federal government began tightening regulations governing its use. These events received little attention. Women like Dorothy Colson and Mamie Ella Plyler of Claxton, Georgia gathered evidence about DDT's effects and wrote to the Georgia Department of Public Health, the National Health Council in New York City, and other organizations.

In 1957 "The New York Times" reported an unsuccessful struggle to restrict DDT use in Nassau County, New York, and the issue came to the attention of the popular naturalist-author Rachel Carson. William Shawn, editor of "The New Yorker", urged her to write a piece on the subject, which developed into her 1962 book "Silent Spring". The book argued that pesticides, including DDT, were poisoning both wildlife and the environment and were endangering human health. "Silent Spring" was a best seller, and public reaction to it launched the modern environmental movement in the United States. The year after it appeared, President John F. Kennedy ordered his Science Advisory Committee to investigate Carson's claims. The committee's report "add[ed] up to a fairly thorough-going vindication of Rachel Carson’s Silent Spring thesis," in the words of the journal "Science", and recommended a phaseout of "persistent toxic pesticides". In 1965, the U.S. military removed DDT from the military supply system due in part to the development of resistance by body lice to DDT; it was replaced by lindane.

DDT became a prime target of the growing anti-chemical and anti-pesticide movements, and in 1967 a group of scientists and lawyers founded the Environmental Defense Fund (EDF) with the specific goal of enacting a ban on DDT. Victor Yannacone, Charles Wurster, Art Cooley and others in the group had all witnessed bird kills or declines in bird populations and suspected that DDT was the cause. In their campaign against the chemical, the EDF petitioned the government for a ban and filed lawsuits. Around this time, toxicologist David Peakall was measuring DDE levels in the eggs of peregrine falcons and California condors and finding that increased levels corresponded with thinner shells.

In response to an EDF suit, the U.S. District Court of Appeals in 1971 ordered the EPA to begin the de-registration procedure for DDT. After an initial six-month review process, William Ruckelshaus, the Agency's first Administrator rejected an immediate suspension of DDT's registration, citing studies from the EPA's internal staff stating that DDT was not an imminent danger. However, these findings were criticized, as they were performed mostly by economic entomologists inherited from the United States Department of Agriculture, who many environmentalists felt were biased towards agribusiness and understated concerns about human health and wildlife. The decision thus created controversy.

The EPA held seven months of hearings in 1971–1972, with scientists giving evidence for and against DDT. In the summer of 1972, Ruckelshaus announced the cancellation of most uses of DDT – exempting public health uses under some conditions. Again, this caused controversy. Immediately after the announcement, both the EDF and the DDT manufacturers filed suit against EPA. Many in the agricultural community were concerned that food production would be severely impacted, while proponents of pesticides warned of increased breakouts of insect-borne diseases and questioned the accuracy of giving animals high amounts of pesticides for cancer potential. Industry sought to overturn the ban, while the EDF wanted a comprehensive ban. The cases were consolidated, and in 1973 the United States Court of Appeals for the District of Columbia Circuit ruled that the EPA had acted properly in banning DDT. During the late 1970s, the EPA also began banning organochlorines, pesticides that were chemically similar to DDT. These included aldrin, dieldrin, chlordane, heptachlor, texaphene, and mirex.

Some uses of DDT continued under the public health exemption. For example, in June 1979, the California Department of Health Services was permitted to use DDT to suppress flea vectors of bubonic plague. DDT continued to be produced in the United States for foreign markets until 1985, when over 300 tons were exported.

In the 1970s and 1980s, agricultural use was banned in most developed countries, beginning with Hungary in 1968, followed by Norway and Sweden in 1970, West Germany and the United States in 1972, but not in the United Kingdom until 1984. By 1991, total bans, including for disease control, were in place in at least 26 countries; for example, Cuba in 1970, the US in the 1980s, Singapore in 1984, Chile in 1985, and the Republic of Korea in 1986.

The Stockholm Convention on Persistent Organic Pollutants, which took effect in 2004, put a global ban on several persistent organic pollutants, and restricted DDT use to vector control. The Convention was ratified by more than 170 countries. Recognizing that total elimination in many malaria-prone countries is currently unfeasible absent affordable/effective alternatives, the convention exempts public health use within World Health Organization (WHO) guidelines from the ban. Resolution 60.18 of the World Health Assembly commits WHO to the Stockholm Convention's aim of reducing and ultimately eliminating DDT. Malaria Foundation International states, "The outcome of the treaty is arguably better than the status quo going into the negotiations. For the first time, there is now an insecticide which is restricted to vector control only, meaning that the selection of resistant mosquitoes will be slower than before."

Despite the worldwide ban, agricultural use continued in India, North Korea, and possibly elsewhere.<ref name="DDTBP.1/2"></ref> As of 2013, an estimated 3,000 to 4,000 tons of DDT were produced for disease vector control, including 2786 tons in India. DDT is applied to the inside walls of homes to kill or repel mosquitoes. This intervention, called indoor residual spraying (IRS), greatly reduces environmental damage. It also reduces the incidence of DDT resistance. For comparison, treating of cotton during a typical U.S. growing season requires the same amount of chemical to treat roughly 1,700 homes.

DDT is a persistent organic pollutant that is readily adsorbed to soils and sediments, which can act both as sinks and as long-term sources of exposure affecting organisms. Depending on conditions, its soil half-life can range from 22 days to 30 years. Routes of loss and degradation include runoff, volatilization, photolysis and aerobic and anaerobic biodegradation. Due to hydrophobic properties, in aquatic ecosystems DDT and its metabolites are absorbed by aquatic organisms and adsorbed on suspended particles, leaving little DDT dissolved in the water (however, its half-life in aquatic environments is listed by the National Pesticide Information Center as 150 years). Its breakdown products and metabolites, DDE and DDD, are also persistent and have similar chemical and physical properties. DDT and its breakdown products are transported from warmer areas to the Arctic by the phenomenon of global distillation, where they then accumulate in the region's food web.

Medical researchers in 1974 found a measurable and significant difference in the presence of DDT in human milk between mothers who lived in New Brunswick and mothers who lived in Nova Scotia, "possibly because of the wider use of insecticide sprays in the past".

Because of its lipophilic properties, DDT can bioaccumulate, especially in predatory birds. DDT is toxic to a wide range of living organisms, including marine animals such as crayfish, daphnids, sea shrimp and many species of fish. DDT, DDE and DDD magnify through the food chain, with apex predators such as raptor birds concentrating more chemicals than other animals in the same environment. They are stored mainly in body fat. DDT and DDE are resistant to metabolism; in humans, their half-lives are 6 and up to 10 years, respectively. In the United States, these chemicals were detected in almost all human blood samples tested by the Centers for Disease Control in 2005, though their levels have sharply declined since most uses were banned. Estimated dietary intake has declined, although FDA food tests commonly detect it.

Despite being banned for many years, in 2018 research showed that DDT residues are still present in European soils and Spanish rivers.

The chemical and its breakdown products DDE and DDD caused eggshell thinning and population declines in multiple North American and European bird of prey species. DDE-related eggshell thinning is considered a major reason for the decline of the bald eagle, brown pelican, peregrine falcon and osprey. However, birds vary in their sensitivity to these chemicals, with birds of prey, waterfowl and song birds being more susceptible than chickens and related species. Even in 2010, California condors that feed on sea lions at Big Sur that in turn feed in the Palos Verdes Shelf area of the Montrose Chemical Superfund site exhibited continued thin-shell problems, though DDT's role in the decline of the California condor is disputed.

The biological thinning mechanism is not entirely understood, but DDE appears to be more potent than DDT, and strong evidence indicates that "p","p"-DDE inhibits calcium ATPase in the membrane of the shell gland and reduces the transport of calcium carbonate from blood into the eggshell gland. This results in a dose-dependent thickness reduction. Other evidence indicates that o,p'-DDT disrupts female reproductive tract development, later impairing eggshell quality. Multiple mechanisms may be at work, or different mechanisms may operate in different species.

DDT is an endocrine disruptor. It is considered likely to be a human carcinogen although the majority of studies suggest it is not directly genotoxic. DDE acts as a weak androgen receptor antagonist, but not as an estrogen. "p","p"-DDT, DDT's main component, has little or no androgenic or estrogenic activity. The minor component "o","p"-DDT has weak estrogenic activity.

DDT is classified as "moderately toxic" by the US National Toxicology Program (NTP) and "moderately hazardous" by WHO, based on the rat oral of 113 mg/kg. Indirect exposure is considered relatively non-toxic for humans.

Primarily through the tendency for DDT to build up in areas of the body with high lipid content, chronic exposure can affect reproductive capabilities and the embryo or fetus.

In 2015, the International Agency for Research on Cancer classified DDT as Group 2A "probably carcinogenic to humans". Previous assessments by the U.S. National Toxicology Program classified it as "reasonably anticipated to be a carcinogen" and by the EPA classified DDT, DDE and DDD as class B2 "probable" carcinogens; these evaluations were based mainly on animal studies. 

A 2005 Lancet review stated that occupational DDT exposure was associated with increased pancreatic cancer risk in 2 case control studies, but another study showed no DDE dose-effect association. Results regarding a possible association with liver cancer and biliary tract cancer are conflicting: workers who did not have direct occupational DDT contact showed increased risk. White men had an increased risk, but not white women or black men. Results about an association with multiple myeloma, prostate and testicular cancer, endometrial cancer and colorectal cancer have been inconclusive or generally do not support an association. A 2017 review of liver cancer studies concluded that "organochlorine pesticides, including DDT, may increase hepatocellular carcinoma risk".

A 2009 review, whose co-authors included persons engaged in DDT-related litigation, reached broadly similar conclusions, with an equivocal association with testicular cancer. Case–control studies did not support an association with leukemia or lymphoma.

The question of whether DDT or DDE are risk factors in breast cancer has not been conclusively answered. Several meta analyses of observational studies have concluded that there is no overall relationship between DDT exposure and breast cancer risk. The United States Institute of Medicine reviewed data on the association of breast cancer with DDT exposure in 2012 and concluded that a causative relationship could neither be proven nor disproven.

A 2007 case–control study using archived blood samples found that breast cancer risk was increased 5-fold among women who were born prior to 1931 and who had high serum DDT levels in 1963. Reasoning that DDT use became widespread in 1945 and peaked around 1950, they concluded that the ages of 14–20 were a critical period in which DDT exposure leads to increased risk. This study, which suggests a connection between DDT exposure and breast cancer that would not be picked up by most studies, has received variable commentary in third party reviews. One review suggested that "previous studies that measured exposure in older women may have missed the critical period". The National Toxicology Program notes that while the majority of studies have not found a relationship between DDT exposure and breast cancer that positive associations have been seen in a "few studies among women with higher levels of exposure and among certain subgroups of women".

A 2015 case control study identified a link (odds ratio 3.4) between "in-utero" exposure (as estimated from archived maternal blood samples) and breast cancer diagnosis in daughters. The findings "support classification of DDT as an endocrine disruptor, a predictor of breast cancer, and a marker of high risk".

Malaria remains the primary public health challenge in many countries. In 2015, there were 214 million cases of malaria worldwide resulting in an estimated 438,000 deaths, 90% of which occurred in Africa. DDT is one of many tools to fight the disease. Its use in this context has been called everything from a "miracle weapon [that is] like Kryptonite to the mosquitoes", to "toxic colonialism".

Before DDT, eliminating mosquito breeding grounds by drainage or poisoning with Paris green or pyrethrum was sometimes successful. In parts of the world with rising living standards, the elimination of malaria was often a collateral benefit of the introduction of window screens and improved sanitation. A variety of usually simultaneous interventions represents best practice. These include antimalarial drugs to prevent or treat infection; improvements in public health infrastructure to diagnose, sequester and treat infected individuals; bednets and other methods intended to keep mosquitoes from biting humans; and vector control strategies such as larvaciding with insecticides, ecological controls such as draining mosquito breeding grounds or introducing fish to eat larvae and indoor residual spraying (IRS) with insecticides, possibly including DDT. IRS involves the treatment of interior walls and ceilings with insecticides. It is particularly effective against mosquitoes, since many species rest on an indoor wall before or after feeding. DDT is one of 12 WHO–approved IRS insecticides.

The WHO's anti-malaria campaign of the 1950s and 1960s relied heavily on DDT and the results were promising, though temporary in developing countries. Experts tie malarial resurgence to multiple factors, including poor leadership, management and funding of malaria control programs; poverty; civil unrest; and increased irrigation. The evolution of resistance to first-generation drugs (e.g. chloroquine) and to insecticides exacerbated the situation. Resistance was largely fueled by unrestricted agricultural use. Resistance and the harm both to humans and the environment led many governments to curtail DDT use in vector control and agriculture. In 2006 WHO reversed a longstanding policy against DDT by recommending that it be used as an indoor pesticide in regions where malaria is a major problem.

Once the mainstay of anti-malaria campaigns, as of 2008 only 12 countries used DDT, including India and some southern African states, though the number was expected to rise.

When it was introduced in World War II, DDT was effective in reducing malaria morbidity and mortality. WHO's anti-malaria campaign, which consisted mostly of spraying DDT and rapid treatment and diagnosis to break the transmission cycle, was initially successful as well. For example, in Sri Lanka, the program reduced cases from about one million per year before spraying to just 18 in 1963 and 29 in 1964. Thereafter the program was halted to save money and malaria rebounded to 600,000 cases in 1968 and the first quarter of 1969. The country resumed DDT vector control but the mosquitoes had evolved resistance in the interim, presumably because of continued agricultural use. The program switched to malathion, but despite initial successes, malaria continued its resurgence into the 1980s.

DDT remains on WHO's list of insecticides recommended for IRS. After the appointment of Arata Kochi as head of its anti-malaria division, WHO's policy shifted from recommending IRS only in areas of seasonal or episodic transmission of malaria, to advocating it in areas of continuous, intense transmission. WHO reaffirmed its commitment to phasing out DDT, aiming "to achieve a 30% cut in the application of DDT world-wide by 2014 and its total phase-out by the early 2020s if not sooner" while simultaneously combating malaria. WHO plans to implement alternatives to DDT to achieve this goal.

South Africa continues to use DDT under WHO guidelines. In 1996, the country switched to alternative insecticides and malaria incidence increased dramatically. Returning to DDT and introducing new drugs brought malaria back under control. Malaria cases increased in South America after countries in that continent stopped using DDT. Research data showed a strong negative relationship between DDT residual house sprayings and malaria. In a research from 1993 to 1995, Ecuador increased its use of DDT and achieved a 61% reduction in malaria rates, while each of the other countries that gradually decreased its DDT use had large increases.

In some areas resistance reduced DDT's effectiveness. WHO guidelines require that absence of resistance must be confirmed before using the chemical. Resistance is largely due to agricultural use, in much greater quantities than required for disease prevention.

Resistance was noted early in spray campaigns. Paul Russell, former head of the Allied Anti-Malaria campaign, observed in 1956 that "resistance has appeared after six or seven years". Resistance has been detected in Sri Lanka, Pakistan, Turkey and Central America and it has largely been replaced by organophosphate or carbamate insecticides, e.g. malathion or bendiocarb.

In many parts of India, DDT is ineffective. Agricultural uses were banned in 1989 and its anti-malarial use has been declining. Urban use ended. One study concluded that "DDT is still a viable insecticide in indoor residual spraying owing to its effectivity in well supervised spray operation and high excito-repellency factor."

Studies of malaria-vector mosquitoes in KwaZulu-Natal Province, South Africa found susceptibility to 4% DDT (WHO's susceptibility standard), in 63% of the samples, compared to the average of 87% in the same species caught in the open. The authors concluded that "Finding DDT resistance in the vector "An. arabiensis", close to the area where we previously reported pyrethroid-resistance in the vector "An. funestus" Giles, indicates an urgent need to develop a strategy of insecticide resistance management for the malaria control programmes of southern Africa."

DDT can still be effective against resistant mosquitoes and the avoidance of DDT-sprayed walls by mosquitoes is an additional benefit of the chemical. For example, a 2007 study reported that resistant mosquitoes avoided treated huts. The researchers argued that DDT was the best pesticide for use in IRS (even though it did not afford the most protection from mosquitoes out of the three test chemicals) because the other pesticides worked primarily by killing or irritating mosquitoes – encouraging the development of resistance. Others argue that the avoidance behavior slows eradication. Unlike other insecticides such as pyrethroids, DDT requires long exposure to accumulate a lethal dose; however its irritant property shortens contact periods. "For these reasons, when comparisons have been made, better malaria control has generally been achieved with pyrethroids than with DDT." In India outdoor sleeping and night duties are common, implying that "the excito-repellent effect of DDT, often reported useful in other countries, actually promotes outdoor transmission".

IRS is effective if at least 80% of homes and barns in a residential area are sprayed. Lower coverage rates can jeopardize program effectiveness. Many residents resist DDT spraying, objecting to the lingering smell, stains on walls, and the potential exacerbation of problems with other insect pests. Pyrethroid insecticides (e.g. deltamethrin and lambda-cyhalothrin) can overcome some of these issues, increasing participation.

A 1994 study found that South Africans living in sprayed homes have levels that are several orders of magnitude greater than others. Breast milk from South African mothers contains high levels of DDT and DDE. It is unclear to what extent these levels arise from home spraying vs food residues. Evidence indicates that these levels are associated with infant neurological abnormalities.

Most studies of DDT's human health effects have been conducted in developed countries where DDT is not used and exposure is relatively low.

Illegal diversion to agriculture is also a concern as it is difficult to prevent and its subsequent use on crops is uncontrolled. For example, DDT use is widespread in Indian agriculture, particularly mango production and is reportedly used by librarians to protect books. Other examples include Ethiopia, where DDT intended for malaria control is reportedly used in coffee production, and Ghana where it is used for fishing. The residues in crops at levels unacceptable for export have been an important factor in bans in several tropical countries. Adding to this problem is a lack of skilled personnel and management.

A few people and groups have argued that limitations on DDT use for public health purposes have caused unnecessary morbidity and mortality from vector-borne diseases, with some claims of malaria deaths ranging as high as the hundreds of thousands and millions. Robert Gwadz of the US National Institutes of Health said in 2007, "The ban on DDT may have killed 20 million children." These arguments were rejected as "outrageous" by former WHO scientist Socrates Litsios. May Berenbaum, University of Illinois entomologist, says, "to blame environmentalists who oppose DDT for more deaths than Hitler is worse than irresponsible". More recently, Michael Palmer, a professor of chemistry at the University of Waterloo, has pointed out that DDT is still used to prevent malaria, that its declining use is primarily due to increases in manufacturing costs, and that in Africa, efforts to control malaria have been regional or local, not comprehensive.
Criticisms of a DDT "ban" often specifically reference the 1972 United States ban (with the erroneous implication that this constituted a worldwide ban and prohibited use of DDT in vector control). Reference is often made to "Silent Spring", even though Carson never pushed for a DDT ban. John Quiggin and Tim Lambert wrote, "the most striking feature of the claim against Carson is the ease with which it can be refuted".

Investigative journalist Adam Sarvana and others characterize these notions as "myths" promoted principally by Roger Bate of the pro-DDT advocacy group Africa Fighting Malaria (AFM).

Organophosphate and carbamate insecticides, e.g. malathion and bendiocarb, respectively, are more expensive than DDT per kilogram and are applied at roughly the same dosage. Pyrethroids such as deltamethrin are also more expensive than DDT, but are applied more sparingly (0.02–0.3 g/m vs 1–2 g/m), so the net cost per house per treatment is about the same. DDT has one of the longest residual efficacy periods of any IRS insecticide, lasting 6 to 12 months. Pyrethroids will remain active for only 4 to 6 months, and organophosphates and carbamates remain active for 2 to 6 months. In many malaria-endemic countries, malaria transmission occurs year-round, meaning that the high expense conducting a spray campaign (including hiring spray operators, procuring insecticides, and conducting pre-spray outreach campaigns to encourage people to be home and to accept the intervention) will need to occur multiple times per year for these shorter lasting insecticides.

In 2019, the related compound difluorodiphenyltrichloroethane (DFDT) was described as a potentially more effective and therefore potentially safer alternative to DDT.

Before DDT, malaria was successfully eliminated or curtailed in several tropical areas by removing or poisoning mosquito breeding grounds and larva habitats, for example by eliminating standing water. These methods have seen little application in Africa for more than half a century. According to CDC, such methods are not practical in Africa because ""Anopheles gambiae", one of the primary vectors of malaria in Africa, breeds in numerous small pools of water that form due to rainfall ... It is difficult, if not impossible, to predict when and where the breeding sites will form, and to find and treat them before the adults emerge."

The relative effectiveness of IRS versus other malaria control techniques (e.g. bednets or prompt access to anti-malarial drugs) varies and is dependent on local conditions.

A WHO study released in January 2008 found that mass distribution of insecticide-treated mosquito nets and artemisinin–based drugs cut malaria deaths in half in malaria-burdened Rwanda and Ethiopia. IRS with DDT did not play an important role in mortality reduction in these countries.

Vietnam has enjoyed declining malaria cases and a 97% mortality reduction after switching in 1991 from a poorly funded DDT-based campaign to a program based on prompt treatment, bednets and pyrethroid group insecticides.

In Mexico, effective and affordable chemical and non-chemical strategies were so successful that the Mexican DDT manufacturing plant ceased production due to lack of demand.

A review of fourteen studies in sub-Saharan Africa, covering insecticide-treated nets, residual spraying, chemoprophylaxis for children, chemoprophylaxis or intermittent treatment for pregnant women, a hypothetical vaccine and changing front–line drug treatment, found decision making limited by the lack of information on the costs and effects of many interventions, the small number of cost-effectiveness analyses, the lack of evidence on the costs and effects of packages of measures and the problems in generalizing or comparing studies that relate to specific settings and use different methodologies and outcome measures. The two cost-effectiveness estimates of DDT residual spraying examined were not found to provide an accurate estimate of the cost-effectiveness of DDT spraying; the resulting estimates may not be good predictors of cost-effectiveness in current programs.

However, a study in Thailand found the cost per malaria case prevented of DDT spraying (US$1.87) to be 21% greater than the cost per case prevented of lambda-cyhalothrin–treated nets (US$1.54), casting some doubt on the assumption that DDT was the most cost-effective measure. The director of Mexico's malaria control program found similar results, declaring that it was 25% cheaper for Mexico to spray a house with synthetic pyrethroids than with DDT. However, another study in South Africa found generally lower costs for DDT spraying than for impregnated nets.

A more comprehensive approach to measuring cost-effectiveness or efficacy of malarial control would not only measure the cost in dollars, as well as the number of people saved, but would also consider ecological damage and negative human health impacts. One preliminary study found that it is likely that the detriment to human health approaches or exceeds the beneficial reductions in malarial cases, except perhaps in epidemics. It is similar to the earlier study regarding estimated theoretical infant mortality caused by DDT and subject to the criticism also mentioned earlier.

A study in the Solomon Islands found that "although impregnated bed nets cannot entirely replace DDT spraying without substantial increase in incidence, their use permits reduced DDT spraying".

A comparison of four successful programs against malaria in Brazil, India, Eritrea and Vietnam does not endorse any single strategy but instead states, "Common success factors included conducive country conditions, a targeted technical approach using a package of effective tools, data-driven decision-making, active leadership at all levels of government, involvement of communities, decentralized implementation and control of finances, skilled technical and managerial capacity at national and sub-national levels, hands-on technical and programmatic support from partner agencies, and sufficient and flexible financing."

DDT resistant mosquitoes may be susceptible to pyrethroids in some countries. However, pyrethroid resistance in "Anopheles" mosquitoes is on the rise with resistant mosquitoes found in multiple countries.



Artifacts








</doc>
<doc id="8495" url="https://en.wikipedia.org/wiki?curid=8495" title="Data set">
Data set

A data set (or dataset) is a collection of data. In the case of tabular data, a data set corresponds to one or more database tables, where every column of a table represents a particular variable, and each row corresponds to a given record of the data set in question. The data set lists values for each of the variables, such as height and weight of an object, for each member of the data set. Each value is known as a datum. Data sets can also consist of a collection of documents or files.

In the open data discipline, data set is the unit to measure the information released in a public open data repository. The European Open Data portal aggregates more than half a million data sets. In this field other definitions have been proposed, but currently there is not an official one. Some other issues (real-time data sources, non-relational data sets, etc.) increases the difficulty to reach a consensus about it.

Several characteristics define a data set's structure and properties. These include the number and types of the attributes or variables, and various statistical measures applicable to them, such as standard deviation and kurtosis.

The values may be numbers, such as real numbers or integers, for example representing a person's height in centimeters, but may also be nominal data (i.e., not consisting of numerical values), for example representing a person's ethnicity. More generally, values may be of any of the kinds described as a level of measurement. For each variable, the values are normally all of the same kind. However, there may also be "missing values", which must be indicated in some way.

In statistics, data sets usually come from actual observations obtained by sampling a statistical population, and each row corresponds to the observations on one element of that population. Data sets may further be generated by algorithms for the purpose of testing certain kinds of software. Some modern statistical analysis software such as SPSS still present their data in the classical data set fashion. If data is missing or suspicious an imputation method may be used to complete a data set.

Several classic data sets have been used extensively in the statistical literature:




</doc>
<doc id="8496" url="https://en.wikipedia.org/wiki?curid=8496" title="DMA">
DMA

DMA may refer to:











</doc>
<doc id="8498" url="https://en.wikipedia.org/wiki?curid=8498" title="Diagnostic and Statistical Manual of Mental Disorders">
Diagnostic and Statistical Manual of Mental Disorders

The Diagnostic and Statistical Manual of Mental Disorders (DSM; latest edition: DSM-5, publ. 2013) is a publication by the American Psychiatric Association (APA) for the classification of mental disorders using a common language and standard criteria.

It is used by clinicians, researchers, psychiatric drug regulation agencies, health insurance companies, pharmaceutical companies, the legal system, and policy makers.

The DSM evolved from systems for collecting census and psychiatric hospital statistics, as well as from a United States Army manual. Revisions since its first publication in 1952 have incrementally added to the total number of mental disorders, while removing those no longer considered to be mental disorders.

Recent editions of the DSM have received praise for standardizing psychiatric diagnosis grounded in empirical evidence, as opposed to the theory-bound nosology used in DSM-III. However, it has also generated controversy and criticism, including ongoing questions concerning the reliability and validity of many diagnoses; the use of arbitrary dividing lines between mental illness and "normality"; possible cultural bias; and the medicalization of human distress.

An alternate, widely-used classification publication is the "International Classification of Diseases" (ICD) is produced by the World Health Organization (WHO). The ICD has broader scope than the DSM, covering overall health as well as mental health; of the ICD specifically covers mental and behavioural disorders. Moreover, while the DSM is the most popular diagnostic system for mental disorders in the US, the ICD is used more widely in Europe and other parts of the world, giving it a far larger reach than the DSM. 

The DSM-IV-TR (4th. ed.) contains specific codes allowing comparisons between the DSM and the ICD manuals, which may not systematically match because revisions are not simultaneously coordinated. Though recent editions of the DSM and ICD have become more similar due to collaborative agreements, each one contains information absent from the other.

Mental health professionals use the manual to determine and help communicate a patient's diagnosis after an evaluation. Hospitals, clinics, and insurance companies in the United States may require a DSM diagnosis for all patients. Health-care researchers use the DSM to categorize patients for research purposes.

An international survey of psychiatrists in sixty-six countries compared the use of the ICD-10 and DSM-IV. It found the former was more often used for clinical diagnosis while the latter was more valued for research.

DSM-5, and the abbreviations for all previous editions, are registered trademarks owned by the American Psychiatric Association.

The initial impetus for developing a classification of mental disorders in the United States was the need to collect statistical information. The first official attempt was the 1840 census, which used a single category: "idiocy/insanity". Three years later, the American Statistical Association made an official protest to the U.S. House of Representatives, stating that "the most glaring and remarkable errors are found in the statements respecting nosology, prevalence of insanity, blindness, deafness, and dumbness, among the people of this nation", pointing out that in many towns African-Americans were all marked as insane, and calling the statistics essentially useless.

The Association of Medical Superintendents of American Institutions for the Insane was formed in 1844; it has since changed its name twice before the new millennium: in 1892 to the American Medico-Psychological Association, and in 1921 to the present American Psychiatric Association (APA).

Edward Jarvis and later Francis Amasa Walker helped expand the census, from two volumes in 1870 to twenty-five volumes in 1880. Frederick H. Wines was appointed to write a 582-page volume, published in 1888, called "Report on the Defective, Dependent, and Delinquent Classes of the Population of the United States, As Returned at the Tenth Census (June 1, 1880)".

Wines used seven categories of mental illness, which were also adopted by the American Medico-Psychological Association: dementia, dipsomania (uncontrollable craving for alcohol), epilepsy, mania, melancholia, monomania, and paresis.

In 1917, together with the National Commission on Mental Hygiene (now Mental Health America), the American Medico-Psychological Association developed a new guide for mental hospitals called the "Statistical Manual for the Use of Institutions for the Insane". This guide included twenty-two diagnoses and would be revised several times by the Association and its successor, the American Psychiatric Association (APA), over the years. Along with the New York Academy of Medicine, the APA provided the psychiatric nomenclature subsection of the U.S. general medical guide, the "Standard Classified Nomenclature of Disease", referred to as the "Standard".

World War II saw the large-scale involvement of U.S. psychiatrists in the selection, processing, assessment, and treatment of soldiers. This moved the focus away from mental institutions and traditional clinical perspectives. Under the direction of James Forrestal, a committee headed by psychiatrist Brigadier General William C. Menninger, with the assistance of the Mental Hospital Service, developed a new classification scheme called Medical 203, which was issued in 1943 as a War Department Technical Bulletin under the auspices of the Office of the Surgeon General. The foreword to the DSM-I states the United States Navy had itself made some minor revisions but "the Army established a much more sweeping revision, abandoning the basic outline of the Standard and attempting to express present-day concepts of mental disturbance. This nomenclature eventually was adopted by all the armed forces, and "assorted modifications of the Armed Forces nomenclature [were] introduced into many clinics and hospitals by psychiatrists returning from military duty." The Veterans Administration also adopted a slightly modified version of Medical 203.

In 1949, the World Health Organization published the sixth revision of the International Statistical Classification of Diseases (ICD), which included a section on mental disorders for the first time. The foreword to DSM-1 states this "categorized mental disorders in rubrics similar to those of the Armed Forces nomenclature".

An APA Committee, on Nomenclature and Statistics, was empowered to develop a version of Medical 203 specifically for use in the United States, to standardize the diverse and confused usage of different documents. In 1950, the APA committee undertook a review and consultation. It circulated an adaptation of Medical 203, the "Standard"s nomenclature, and the VA system's modifications of the "Standard" to approximately 10% of APA members: 46% of whom replied, with 93% approving the changes. After some further revisions (resulting in its being called DSM-I), the "Diagnostic and Statistical Manual of Mental Disorders" was approved in 1951 and published in 1952. The structure and conceptual framework were the same as in Medical 203, and many passages of text were identical. The manual was 130 pages long and listed 106 mental disorders. These included several categories of "personality disturbance", generally distinguished from "neurosis" (nervousness, egodystonic).

In 1952, the APA listed homosexuality in the DSM as a sociopathic personality disturbance. "", a large-scale 1962 study of homosexuality by Irving Bieber and other authors, was used to justify inclusion of the disorder as a supposed pathological hidden fear of the opposite sex caused by traumatic parent–child relationships. This view was influential in the medical profession. In 1956, however, the psychologist Evelyn Hooker performed a study comparing the happiness and well-adjusted nature of self-identified homosexual men with heterosexual men and found no difference. Her study stunned the medical community and made her a heroine to many gay men and lesbians, but homosexuality remained in the DSM until May 1974.

In the 1960s, there were many challenges to the concept of mental illness itself. These challenges came from psychiatrists like Thomas Szasz, who argued mental illness was a myth used to disguise moral conflicts; from sociologists such as Erving Goffman, who said mental illness was another example of how society labels and controls non-conformists; from behavioural psychologists who challenged psychiatry's fundamental reliance on unobservable phenomena; and from gay rights activists who criticised the APA's listing of homosexuality as a mental disorder. A study published in "Science", the Rosenhan experiment, received much publicity and was viewed as an attack on the efficacy of psychiatric diagnosis.

The APA was closely involved in the next significant revision of the mental disorder section of the ICD (version 8 in 1968). It decided to go ahead with a revision of the DSM, which was published in 1968. DSM-II was similar to DSM-I, listed 182 disorders, and was 134 pages long. The term "reaction" was dropped, but the term "neurosis" was retained. Both the DSM-I and the DSM-II reflected the predominant psychodynamic psychiatry, although both manuals also included biological perspectives and concepts from Kraepelin's system of classification. Symptoms were not specified in detail for specific disorders. Many were seen as reflections of broad underlying conflicts or maladaptive reactions to life problems that were rooted in a distinction between neurosis and psychosis (roughly, anxiety/depression broadly in touch with reality, as opposed to hallucinations or delusions disconnected from reality). Sociological and biological knowledge was incorporated, under a model that did not emphasize a clear boundary between normality and abnormality. The idea that personality disorders did not involve emotional distress was discarded.

An influential 1974 paper by Robert Spitzer and Joseph L. Fleiss demonstrated that the second edition of the DSM (DSM-II) was an unreliable diagnostic tool. Spitzer and Fleiss found that different practitioners using the DSM-II rarely agreed when diagnosing patients with similar problems. In reviewing previous studies of eighteen major diagnostic categories, Spitzer and Fleiss concluded that "there are no diagnostic categories for which reliability is uniformly high. Reliability appears to be only satisfactory for three categories: mental deficiency, organic brain syndrome (but not its subtypes), and alcoholism. The level of reliability is no better than fair for psychosis and schizophrenia and is poor for the remaining categories".

As described by Ronald Bayer, a psychiatrist and gay rights activist, specific protests by gay rights activists against the APA began in 1970, when the organization held its convention in San Francisco. The activists disrupted the conference by interrupting speakers and shouting down and ridiculing psychiatrists who viewed homosexuality as a mental disorder. In 1971, gay rights activist Frank Kameny worked with the Gay Liberation Front collective to demonstrate at the APA's convention. At the 1971 conference, Kameny grabbed the microphone and yelled: "Psychiatry is the enemy incarnate. Psychiatry has waged a relentless war of extermination against us. You may take this as a declaration of war against you."

This gay activism occurred in the context of a broader anti-psychiatry movement that had come to the fore in the 1960s and was challenging the legitimacy of psychiatric diagnosis. Anti-psychiatry activists protested at the same APA conventions, with some shared slogans and intellectual foundations as gay activists.

Taking into account data from researchers such as Alfred Kinsey and Evelyn Hooker, the sixth printing of the DSM-II, in 1974, no longer listed homosexuality as a category of disorder. After a vote by the APA trustees in 1973, and confirmed by the wider APA membership in 1974, the diagnosis was replaced with the category of "sexual orientation disturbance".

In 1974, the decision to create a new revision of the DSM was made, and Robert Spitzer was selected as chairman of the task force. The initial impetus was to make the DSM nomenclature consistent with that of the International Classification of Diseases (ICD). The revision took on a far wider mandate under the influence and control of Spitzer and his chosen committee members. One added goal was to improve the uniformity and validity of psychiatric diagnosis in the wake of a number of critiques, including the famous Rosenhan experiment. There was also felt a need to standardize diagnostic practices within the United States and with other countries, after research showed that psychiatric diagnoses differed between Europe and the United States. The establishment of consistent criteria was an attempt to facilitate the pharmaceutical regulatory process.

The criteria adopted for many of the mental disorders were taken from the Research Diagnostic Criteria (RDC) and Feighner Criteria, which had just been developed by a group of research-orientated psychiatrists based primarily at Washington University in St. Louis and the New York State Psychiatric Institute. Other criteria, and potential new categories of disorder, were established by consensus during meetings of the committee chaired by Spitzer. A key aim was to base categorization on colloquial English (which would be easier to use by federal administrative offices), rather than by assumption of cause, although its categorical approach still assumed each particular pattern of symptoms in a category reflected a particular underlying pathology (an approach described as "neo-Kraepelinian"). The psychodynamic or physiologic view was abandoned, in favor of a regulatory or legislative model. A new "multiaxial" system attempted to yield a picture more amenable to a statistical population census, rather than a simple diagnosis. Spitzer argued "mental disorders are a subset of medical disorders", but the task force decided on this statement for the DSM: "Each of the mental disorders is conceptualized as a clinically significant behavioral or psychological syndrome." Personality disorders were placed on axis II along with mental retardation.

The first draft of DSM-III was ready within a year. It introduced many new categories of disorder, while deleting or changing others. A number of unpublished documents discussing and justifying the changes have recently come to light. Field trials sponsored by the U.S. National Institute of Mental Health (NIMH) were conducted between 1977 and 1979 to test the reliability of the new diagnoses. A controversy emerged regarding deletion of the concept of neurosis, a mainstream of psychoanalytic theory and therapy but seen as vague and unscientific by the DSM task force. Faced with enormous political opposition, DSM-III was in serious danger of not being approved by the APA Board of Trustees unless "neurosis" was included in some form; a political compromise reinserted the term in parentheses after the word "disorder" in some cases. Additionally, the diagnosis of ego-dystonic homosexuality replaced the DSM-II category of "sexual orientation disturbance".

Finally published in 1980, DSM-III listed 265 diagnostic categories and was 494 pages long. It rapidly came into widespread international use and has been termed a revolution, or transformation, in psychiatry.

When DSM-III was published, the developers made extensive claims about the reliability of the radically new diagnostic system they had devised, which relied on data from special field trials. However, according to a 1994 article by Stuart A. Kirk:

Twenty years after the reliability problem became the central focus of DSM-III, there is still not a single multi-site study showing that DSM (any version) is routinely used with high reliably by regular mental health clinicians. Nor is there any credible evidence that any version of the manual has greatly increased its reliability beyond the previous version. There are important methodological problems that limit the generalisability of most reliability studies. Each reliability study is constrained by the training and supervision of the interviewers, their motivation and commitment to diagnostic accuracy, their prior skill, the homogeneity of the clinical setting in regard to patient mix and base rates, and the methodological rigor achieved by the investigator ...

In 1987, DSM-III-R was published as a revision of the DSM-III, under the direction of Spitzer. Categories were renamed and reorganized, with significant changes in criteria. Six categories were deleted while others were added. Controversial diagnoses, such as pre-menstrual dysphoric disorder and masochistic personality disorder, were considered and discarded. "Ego-dystonic homosexuality" was also removed and was largely subsumed under "sexual disorder not otherwise specified", which could include "persistent and marked distress about one's sexual orientation." Altogether, the DSM-III-R contained 292 diagnoses and was 567 pages long. Further efforts were made for the diagnoses to be purely descriptive, although the introductory text stated for at least some disorders, "particularly the Personality Disorders, the criteria require much more inference on the part of the observer" [p. xxiii].

In 1994, DSM-IV was published, listing 410 disorders in 886 pages. The task force was chaired by Allen Frances and was overseen by a steering committee of twenty-seven people, including four psychologists. The steering committee created thirteen work groups of five to sixteen members, each work group having about twenty advisers in addition. The work groups conducted a three-step process: first, each group conducted an extensive literature review of their diagnoses; then, they requested data from researchers, conducting analyses to determine which criteria required change, with instructions to be conservative; finally, they conducted multicenter field trials relating diagnoses to clinical practice. A major change from previous versions was the inclusion of a clinical-significance criterion to almost half of all the categories, which required symptoms causing "clinically significant distress or impairment in social, occupational, or other important areas of functioning". Some personality-disorder diagnoses were deleted or moved to the appendix.

A "text revision" of DSM-IV, known as DSM-IV-TR, was published in 2000. The diagnostic categories and the vast majority of the specific criteria for diagnosis were unchanged. The text sections giving extra information on each diagnosis were updated, as were some of the diagnostic codes, to maintain consistency with the ICD. The DSM-IV-TR was organized into a five-part axial system. The first axis incorporated clinical disorders. The second axis covered personality disorders and intellectual disabilities. The remaining axes covered medical, psychosocial, environmental, and childhood factors functionally necessary to provide diagnostic criteria for health care assessments.

The DSM-IV-TR characterizes a mental disorder as "a clinically significant behavioral or psychological syndrome or pattern that occurs in an individual [which] is associated with present distress... or disability... or with a significant increased risk of suffering." It also notes "no definition adequately specifies precise boundaries for the concept of 'mental disorder'... different situations call for different definitions." It states "there is no assumption that each category of mental disorder is a completely discrete entity with absolute boundaries dividing it from other mental disorders or from no mental disorder."

The DSM-IV is a categorical classification system. The categories are prototypes, and a patient with a close approximation to the prototype is said to have that disorder. DSM-IV states, "there is no assumption each category of mental disorder is a completely discrete entity with absolute boundaries" but isolated, low-grade, and non-criterion (unlisted for a given disorder) symptoms are not given importance. Qualifiers are sometimes used: for example, to specify mild, moderate, or severe forms of a disorder. For nearly half the disorders, symptoms must be sufficient to cause "clinically significant distress or impairment in social, occupational, or other important areas of functioning", although DSM-IV-TR removed the distress criterion from tic disorders and several of the paraphilias due to their egosyntonic nature. Each category of disorder has a numeric code taken from the ICD coding system, used for health service (including insurance) administrative purposes.

With the advent of the DSM-5 in 2013, the APA eliminated the longstanding multi-axial system for mental disorders. Previously, the DSM-IV organized each psychiatric diagnosis into five dimensions (axes) that related to different aspects of disorder or disability:

Mental/Psychiatric/Behavioral/Learning conditions include, but are not limited to: depression, anxiety disorders, bipolar disorder, ADHD, autism spectrum disorders, anorexia nervosa, bulimia nervosa, and schizophrenia.

Personality Disorders include, but are not limited to: paranoid personality disorder, schizoid personality disorder, schizotypal personality disorder, borderline personality disorder, antisocial personality disorder, narcissistic personality disorder, histrionic personality disorder, avoidant personality disorder, dependent personality disorder, obsessive-compulsive personality disorder, and organic intellectual disabilities.

Common medical/physical conditions or diseases that may result in or exacerbate some of the aforementioned mental/psychiatric conditions, or that may be aggravated by the aforementioned conditions include, but are not limited to: brain injuries, terminal diseases, pregnancy, cancer, epilepsy, idiopathic physiological conditions and virtually any other conditions, ailments or injuries which may affect the patient's mental health.

Many biopsychosocial assessments incorporate multiple factors that adversely affect the patient's, client's, or subject's overall well-being and homeostasis.

Typical psychosocial influences that are usually listed as having negative impact on life, mentality, and health include, but are not limited to: environmental factors of dysfunction such as those experienced within home, school, and work; social factors such as issues with drug use (not diagnosed), enabling friends and conflicts with coworkers; family complications such as divorce, social service involvement, and court ordered placements; various stressors such as recent accident, natural disaster, and other traumatic occurrences (e.g. assault, death, abuse); financial problems such as bankruptcy, job loss, and debts; and service needs such as lack of medical insurance, inability to find adequate treatment, and inaccessibility to necessary state and federal programs.

The DSM-IV does not specifically cite its sources, but there are four volumes of "sourcebooks" intended to be APA's documentation of the guideline development process and supporting evidence, including literature reviews, data analyses, and field trials. The sourcebooks have been said to provide important insights into the character and quality of the decisions that led to the production of DSM-IV, and the scientific credibility of contemporary psychiatric classification.

The fifth edition of the Diagnostic and Statistical Manual of Mental Disorders (DSM), the DSM-5, was approved by the Board of Trustees of the APA on December 1, 2012. Published on May 18, 2013, the DSM-5 contains extensively revised diagnoses and, in some cases, broadens diagnostic definitions while narrowing definitions in other cases. The DSM-5 is the first major edition of the manual in twenty years.

A significant change in the fifth edition is the deletion of the subtypes of schizophrenia: paranoid, disorganized, catatonic, undifferentiated, and residual. The deletion of the subsets of autistic spectrum disorder—namely, Asperger's syndrome, classic autism, Rett syndrome, childhood disintegrative disorder and pervasive developmental disorder not otherwise specified—was also implemented, with specifiers regarding intensity: mild, moderate, and severe.

Severity is based on social communication impairments and restricted, repetitive patterns of behaviour, with three levels:


During the revision process, the APA website periodically listed several sections of the DSM-5 for review and discussion.

Beginning with the fifth edition, it is intended that subsequent revisions will be added more often, to keep up with research in the field. It is notable that DSM-5 uses Arabic rather than Roman numerals. Beginning with DSM-5, the APA will use decimals to identify incremental updates (e.g., DSM-5.1, DSM-5.2) and whole numbers for new editions (e.g., DSM-5, DSM-6), similar to the scheme used for software versioning.

Allsopp et al. (2019) describe the entire construct of psychiatric diagnoses as scientifically meaningless because of its unsupportable premise of mental distresses being "caused" by whatever (putative) disorder(s) being set in contrast to hypothesized-yet-subjective notions about what should be thought normal.

The revisions of the DSM from the 3rd Edition forward have been mainly concerned with diagnostic reliability—the degree to which different diagnosticians agree on a diagnosis. Henrik Walter argued that psychiatry as a science can only advance if diagnosis is reliable. If clinicians and researchers frequently disagree about the diagnosis of a patient, then research into the causes and effective treatments of those disorders cannot advance. Hence, diagnostic reliability was a major concern of DSM-III. When the diagnostic reliability problem was thought to be solved, subsequent editions of the DSM were concerned mainly with "tweaking" the diagnostic criteria. Unfortunately, neither the issue of reliability or validity was settled.

In 2013, shortly before the publication of DSM-5, the director of the National Institute of Mental Health (NIMH), Thomas R. Insel, declared that the agency would no longer fund research projects that relied exclusively on DSM diagnostic criteria, due to its lack of validity. Insel questioned the validity of the DSM classification scheme because "diagnoses are based on a consensus about clusters of clinical symptoms" as opposed to "collecting the genetic, imaging, physiologic, and cognitive data to see how all the data – not just the symptoms – cluster and how these clusters relate to treatment response."

Field trials of DSM-5 brought the debate of reliability back into the limelight, as the diagnoses of some disorders showed poor reliability. For example, a diagnosis of major depressive disorder, a common mental illness, had a poor reliability kappa statistic of 0.28, indicating that clinicians frequently disagreed on diagnosing this disorder in the same patients. The most reliable diagnosis was major neurocognitive disorder, with a kappa of 0.78.

By design, the DSM is primarily concerned with the signs and symptoms of mental disorders, rather than the underlying causes. It claims to collect them together based on statistical or clinical patterns. As such, it has been compared to a naturalist's field guide to birds, with similar advantages and disadvantages. The lack of a causative or explanatory basis, however, is not specific to the DSM, but rather reflects a general lack of pathophysiological understanding of psychiatric disorders. As DSM-III chief architect Robert Spitzer and DSM-IV editor Michael First outlined in 2005, "little progress has been made toward understanding the pathophysiological processes and cause of mental disorders. If anything, the research has shown the situation is even more complex than initially imagined, and we believe not enough is known to structure the classification of psychiatric disorders according to etiology."

"The DSM's focus on superficial symptoms is claimed to be largely a result of necessity (assuming such a manual is necessary at all), since there is no agreement on a more explanatory classification system. Reviewers note, however, that this approach is undermining research, including in genetics, because it results in the grouping of individuals who have very little in common except superficial criteria as per a DSM or ICD-based diagnosis (Fadul, 2014, p.143)."

Despite the lack of consensus on underlying causation, advocates for specific psychopathological paradigms have nonetheless faulted the current diagnostic scheme for not incorporating evidence-based models or findings from other areas of science. A recent example is evolutionary psychologists' criticism that the DSM does not differentiate between genuine cognitive malfunctions and those induced by psychological adaptations, a key distinction within evolutionary psychology but one that is widely challenged within general psychology. Another example is the strong operationalist viewpoint, which contends that reliance on operational definitions, as purported by the DSM, necessitates that intuitive concepts like depression be replaced by specific measurable concepts before they are scientifically meaningful. One critic states of psychologists that "Instead of replacing 'metaphysical' terms such as 'desire' and 'purpose', they used it to legitimize them by giving them operational definitions...the initial, quite radical operationalist ideas eventually came to serve as little more than a 'reassurance fetish' (Koch 1992) for mainstream methodological practice."

A 2013 review published in the "European Archives of Psychiatry and Clinical Neuroscience" states "that psychiatry targets the phenomena of consciousness, which, unlike somatic symptoms and signs, cannot be grasped on the analogy with material thing-like objects." As an example of the problem of the superficial characterization of psychiatric signs and symptoms, the authors gave the example of a patient saying they "feel depressed, sad, or down," showing that such a statement could indicate various underlying experiences: "not only depressed mood but also, for instance, irritation, anger, loss of meaning, varieties of fatigue, ambivalence, ruminations of different kinds, hyper-reflectivity, thought pressure, psychological anxiety, varieties of depersonalization, and even voices with negative content, and so forth." The structured interview comes with a "danger of over confidence in the face value of the answers, as if a simple 'yes' or 'no' truly confirmed or denied the diagnostic criterion at issue." The authors gave an example: A patient who was being administered the Structured Clinical Interview for the DSM-IV Axis I Disorders denied thought insertion, but during a "conversational, phenomenological interview", a semi-structured interview tailored to the patient, the same patient admitted to experiencing thought insertion, along with a delusional elaboration. The authors suggested 2 reasons for this discrepancy: either the patient did not "recognize his own experience in the rather blunt, implicitly either/or formulation of the structured-interview question", or the experience did not "fully articulate itself" until the patient started talking about his experiences.

Dr. Allen Frances, an outspoken critic of DSM-5, states that "normality is an endangered species," because of "fad diagnoses" and an "epidemic" of over-diagnosing, and suggests that the "DSM-5 threatens to provoke several more [epidemics]." Some researchers state that changes in diagnostic criteria, following each published version of the DSM, reduce thresholds for a diagnosis, which results in increases in prevalence rates for ADHD and autism spectrum disorder. Bruchmüller, et al. (2012) suggest that as a factor that may lead to overdiagnosis are situations when the clinical judgment of the diagnostician regarding a diagnosis (ADHD) is affected by heuristics.

Despite caveats in the introduction to the DSM, it has long been argued that its system of classification makes unjustified categorical distinctions between disorders and uses arbitrary cut-offs between normal and abnormal. A 2009 psychiatric review noted that attempts to demonstrate natural boundaries between related DSM syndromes, or between a common DSM syndrome and normality, have failed. Some argue that rather than a categorical approach, a fully dimensional, spectrum or complaint-oriented approach would better reflect the evidence.

In addition, it is argued that the current approach based on exceeding a threshold of symptoms does not adequately take into account the context in which a person is living, and to what extent there is internal disorder of an individual versus a psychological response to adverse situations. The DSM does include a step ("Axis IV") for outlining "Psychosocial and environmental factors contributing to the disorder" once someone is diagnosed with that particular disorder.

Because an individual's degree of impairment is often not correlated with symptom counts and can stem from various individual and social factors, the DSM's standard of distress or disability can often produce false positives. On the other hand, individuals who do not meet symptom counts may nevertheless experience comparable distress or disability in their life.

Psychiatrists have argued that published diagnostic standards rely on an exaggerated interpretation of neurophysiological findings and so understate the scientific importance of social-psychological variables. Advocating a more culturally sensitive approach to psychology, critics such as Carl Bell and Marcello Maviglia contend that researchers and service-providers often discount the cultural and ethnic diversity of individuals. In addition, current diagnostic guidelines have been criticized as having a fundamentally Euro-American outlook. Although these guidelines have been widely implemented, opponents argue that even when a diagnostic criterion-set is accepted across different cultures, it does not necessarily indicate that the underlying constructs have any validity within those cultures; even reliable application can only demonstrate consistency, not legitimacy. Cross-cultural psychiatrist Arthur Kleinman contends that Western bias is ironically illustrated in the introduction of cultural factors to the DSM-IV: the fact that disorders or concepts from non-Western or non-mainstream cultures are described as "culture-bound", whereas standard psychiatric diagnoses are given no cultural qualification whatsoever, is to Kleinman revelatory of an underlying assumption that Western cultural phenomena are universal. Other cross-cultural critics largely share Kleinman's negative view toward the culture-bound syndrome, common responses included both disappointment over the large number of documented non-Western mental disorders still left out, and frustration that even those included were often misinterpreted or misrepresented.

Mainstream psychiatrists have also been dissatisfied with these new culture-bound diagnoses, although not for the same reasons. Robert Spitzer, a lead architect of DSM-III, has held the opinion that the addition of cultural formulations was an attempt to placate cultural critics, and that they lack any scientific motivation or support. Spitzer also posits that the new culture-bound diagnoses are rarely used in practice, maintaining that the standard diagnoses apply regardless of the culture involved. In general, the mainstream psychiatric opinion remains that if a diagnostic category is valid, cross-cultural factors are either irrelevant or are only significant to specific symptom presentations. One result of this dissatisfaction was the development of the Azibo Nosology by Daudi Ajani Ya Azibo, as an alternative to the DSM in treating patients of the African diaspora.

Historically, the DSM tended to avoid issues involving religion; the DSM-5 relaxed this attitude somewhat.

There was extensive analysis and comment on DSM-IV (published in 1994) in the years leading up to the 2013 publication of DSM-5. It was alleged that the way the categories of DSM-IV were structured, as well as the substantial expansion of the number of categories within it, represented increasing medicalization of human nature, very possibly attributable to disease mongering by psychiatrists and pharmaceutical companies, the power and influence of the latter having grown dramatically in recent decades. In 2005, then APA President Steven Sharfstein released a statement in which he conceded that psychiatrists had "allowed the biopsychosocial model to become the bio-bio-bio model". It was reported that of the authors who selected and defined the DSM-IV psychiatric disorders, roughly half had financial relationships with the pharmaceutical industry during the period 1989–2004, raising the prospect of a direct conflict of interest. The same article concluded that the connections between panel members and the drug companies were particularly strong involving those diagnoses where drugs are the first line of treatment, such as schizophrenia and mood disorders, where 100% of the panel members had financial ties with the pharmaceutical industry.

William Glasser referred to DSM-IV as having "phony diagnostic categories", arguing that "it was developed to help psychiatrists – to help them make money". A 2012 article in The New York Times commented sharply that DSM-IV (then in its 18th year), through copyrights held closely by the APA, had earned the Association over $100 million.

However, although the number of identified diagnoses had increased by more than 300% (from 106 in DSM-I to 365 in DSM-IV-TR), psychiatrists such as Zimmerman and Spitzer argued that this almost entirely represented greater specification of the forms of pathology, thereby allowing better grouping of similar patients.

A client is a person who accesses psychiatric services and may have been given a diagnosis from the DSM, while a survivor self-identifies as a person who has endured a psychiatric intervention and the mental health system (which may have involved involuntary commitment and involuntary treatment). A term adopted by many users of psychiatric services is "consumer". This term was chosen to eliminate the "patient" label and restore the person to an active role as a user or consumer of services. Some individuals are relieved to find that they have a recognized condition that they can apply a name to and this has led to many people self-diagnosing. Others, however, question the accuracy of the diagnosis, or feel they have been given a "label" that invites social stigma and discrimination (the terms "mentalism" and "sanism" have been used to describe such discriminatory treatment).

Diagnoses can become internalized and affect an individual's self-identity, and some psychotherapists have found that the healing process can be inhibited and symptoms can worsen as a result. Some members of the psychiatric survivors movement (more broadly the consumer/survivor/ex-patient movement) actively campaign against their diagnoses, or the assumed implications, or against the DSM system in general. Additionally, it has been noted that the DSM often uses definitions and terminology that are inconsistent with a recovery model, and such content can erroneously imply excess psychopathology (e.g. multiple "comorbid" diagnoses) or chronicity.

Psychiatrist Allen Frances has been critical of proposed revisions to the DSM-5. In a 2012 "New York Times" editorial, Frances warned that if this DSM version is issued unamended by the APA, "it will medicalize normality and result in a glut of unnecessary and harmful drug prescription."

In a December 2012, blog post on "Psychology Today", Frances provides his "list of DSM 5's ten most potentially harmful changes:"

A group of 25 psychiatrists and researchers, among whom were Frances and Thomas Szasz, have published debates on what they see as the six most essential questions in psychiatric diagnosis:

In 2011, psychologist Brent Robbins co-authored a national letter for the Society for Humanistic Psychology that has brought thousands into the public debate about the DSM. Over 15,000 individuals and mental health professionals have signed a petition in support of the letter. Thirteen other APA divisions have endorsed the petition. Robbins has noted that under the new guidelines, certain responses to grief could be labeled as pathological disorders, instead of being recognized as being normal human experiences.




</doc>
<doc id="8500" url="https://en.wikipedia.org/wiki?curid=8500" title="Dar es Salaam">
Dar es Salaam

Dar es-Salaam (; from ) is the largest city and former capital of Tanzania. It is the largest city in East Africa and the seventh-largest in Africa, with a population of 12,798,650. On the Swahili coast, Dar es-Salaam is an important economic centre and one of the fastest growing cities in the world.

Until 1974, Dar es-Salaam served as Tanzania's capital city, at which point the capital city began to move to Dodoma, by order of president Julius Nyerere, which was officially completed in 1996. In 2018, it remains a focus of central government bureaucracy, although this is in the process of fully moving to Dodoma. It is Tanzania's most prominent city in arts, fashion, media, music, film and television and is a leading financial centre. The city is the leading arrival and departure point for most tourists who visit Tanzania, including the national parks for safaris and the islands of Unguja and Pemba.

It is the capital of the co-extensive Dar es-Salaam Region, which is one of Tanzania's 31 administrative regions and consists of five districts: Kinondoni in the north, Ilala in the centre, Ubungo and Temeke in the south and Kigamboni in the east across the Kurasini estuary.

In the 19th century, Mzizima (Swahili for "healthy town") was a coastal fishing village on the periphery of Indian Ocean trade routes. In 1865 or 1866, Sultan Majid bin Said of Zanzibar began building a new city very close to Mzizima and named it Dar es Salaam. The name is commonly translated as "abode/home of peace", based on the Arabic "dar" ("house"), and the Arabic "es salaam" ("of peace"). Dar es Salaam fell into decline after Majid's death in 1870, but was revived in 1887 when the German East Africa Company established a station there. The town's growth was facilitated by its role as the administrative and commercial centre of German East Africa and industrial expansion resulting from the construction of the Central Railway Line in the early 1900s.

German East Africa was captured by the British during World War I and became Tanganyika with Dar es Salaam remaining the administrative and commercial centre. Under British indirect rule, separate European (e.g., Oyster Bay) and African (e.g., Kariakoo and Ilala) areas developed at a distance from the city centre. The city's population also included a large number of workers from British India, many of whom came to take advantage of the trade and commercial opportunities presented to them. After World War II, Dar es Salaam experienced a period of rapid growth.

Political developments, including the formation and growth of the Tanganyika African National Union, led to Tanganyika attaining independence from colonial rule in December 1961. Dar es Salaam continued to serve as its capital, even when in 1964 Tanganyika and People's Republic of Zanzibar merged to form Tanzania. In 1973, however, provisions were made to relocate the capital to Dodoma, a more centrally located city in the interior. The relocation process has not yet been completed, and Dar es Salaam remains Tanzania's primary city. Journalist John Gunther noted that, in "November, 1953, several hippopotamuses entered Dar es Salaam from a creek near the airport, and terrorized the African quarter of the town."

In 1967, the Tanzanian government declared the "Ujamaa policy", which set Tanzania into a socialist path. The move slowed down the potential growth of the city as the government encouraged people not to move in cities but stay in Ujamaa socialist villages. However, by the 1980s the Ujamaa policy proved to be a failure in combating increasing poverty and hunger that Tanzania faced, and delayed the development that it needed. This led to the 1980s liberalization policy that virtually ended socialism and its proponents within Tanzania's government.

Until the late 1990s, Dar es-Salaam was not put into the same category as Africa's leading cities like Nairobi, Johannesburg, Lagos, or Addis Ababa. The 2000s became the turning point when the city experienced one of Africa's fastest urbanization rates. Businesses were opened and prospered, growth expanded in the construction sector with new multi-story buildings, bridges and roads, Tanzanian banks headquartered in the city began to be run with better regulation, the Dar es Salaam Stock Exchange expanded and the Dar es Salaam harbour continued to be the most important in Tanzania. The port is prominent for entrepot trade with landlocked countries such as Rwanda, Burundi, and Zambia, as well as with eastern Democratic Republic of Congo. The CBD skyline hosts tall buildings, among them the 35-floor PSPF Tower, finished in 2015, and the Tanzania Ports Authority (TPA) Tower, the tallest building in Tanzania, completed in 2016.

Dar es Salaam is located at 6°48' South, 39°17' East (−6.8000, 39.2833), on a natural harbour on the coast of East Africa, with sandy beaches in some areas.

The region of Dar es Salaam is divided into five districts.

Dar es Salaam Region is divided into five administrative districts. All five are governed as municipal councils, and so all of the city's suburbs or wards are affiliated with them. The regional commissioner is Aboubakar Kunenge.

Kinondoni is the most populated amongst the districts, with half of the city's population residing within it. It is also home to high-income suburbs. These include:


Ilala is the administrative district of Dar es Salaam where almost all government offices and ministries are housed. The Central Business District (locally called "Posta") is located in this district. It is the transportation hub of the city, as the Julius Nyerere International Airport, Central Railway Station and Tazara Railway Station are all within the district boundaries. The residential areas are mainly middle to high-income, and some of these are:

Temeke is the industrial district of the city, where the manufacturing centers (heavy and light industry) are located. The Port of Dar es Salaam, which is the largest in the country, is found east of Temeke.

Temeke is believed to have the largest concentration of low-income residents due to industry. Port officials, military and police officers live there.


The Ubungo terminal serves as a transportation link to most large Dar es Salaam urban nodes. The narrow-gauge commuter rail runs from there to the city centre, with ten level crossings along the route.


Due to close proximity to the equator and the warm Indian Ocean, the city experiences tropical climatic conditions, typified by hot and humid weather throughout much of the year. It has a tropical wet and dry climate (Köppen: Aw). Annual rainfall is approximately , and in a normal year there are two rainy seasons: "the long rains" in April and May and "the short rains" in November and December.

"In 1949 the town became a municipality...[with] four honourable nominated Town Councillors who elected a Mayor." "Until June 1996, Dar es Salaam was managed by the Dar es Salaam City Council...the highest policy-making body in the city." As of 2017, Paul Makonda serves as the commissioner of Dar es Salaam Region.

As any growing city, Dar es-Salaam is the city in Tanzania to which villagers flock for better opportunities. Westerners and Asians are also settling in Dar es-Salaam, and the movement of foreigners has put a good workload on the relevant government body for developing better policies to accommodate the growing and the diverse population of the Dar es-Salaam together with its suburbs.

Dar es-Salaam is the most populous city in Tanzania. With a population increase of 5.6 percent per year from 2002 to 2012, it is the third-fastest-growing city in Africa, after Bamako and Lagos, and the ninth-fastest-growing in the world. The metro population is expected to reach 5.12 million by 2020 and predicted to be as high as 76 million by the year 2100, making it the third largest city in the world (after Lagos and Kinshasa).

According to the 2012 national census, the region had a population of 4,364,541, which was much higher than the pre-census projection of 3,270,255. For 2002–2012, the region's 5.6 percent average annual population growth rate was the highest in the country. It was also the most densely populated region with 3,133 people per square kilometer.

The sprawling suburbs furthest from the city centre are generally populated by Tanzanians of African descent, with the exception of Oyster Bay, where there is a large population of foreign expatriates. The edges of Dar es Salaam are spreading rapidly, severely taxing the transportation network. and raising the prospect of future urban overcrowding.

Dar es Salaam is Tanzania's most important city for both business and government. The city contains high concentrations of trade and other services and manufacturing compared to other parts of Tanzania, which has about 80 percent of its population in rural areas. Downtown includes small businesses, many of which are run by traders and proprietors whose families originated from the Middle East and the Indian sub-continent—areas of the world with which the settlements of the Tanzanian coast have had long-standing trading relations.

The Dar es Salaam Central Business District is the largest in Tanzania and comprises the Kisutu, Kivukoni, Upanga and Kariakoo areas. The downtown area is located in the Ilala district. Kivukoni is home to the Tanzania central bank, The Bank of Tanzania, the Dar es Salaam Stock Exchange and the city's important Magogoni fish market. Kisutu has businesses and offices and is the location of Dar es Salaam central railway station, the PSPF Towers and the TPA tower.

Dar es Salaam has had a major construction development. The PSPF Twin Towers, with 35 stories, is the second tallest building in the city and the country. Dar es Salaam has major infrastructural challenges, including an outdated transport system and occasional power rationing.
The Dar es Salaam Stock Exchange (DSE) is the country's first and most important stock exchange market.

Dar es Salaam hosts the Mlimani City shopping mall also there is City Mall around Kisutu area, Quality Center Mall, GSM Pugu Shopping Mall, GSM Msasani Mall as well Dar Free Market Mall.

Dar es Salaam, on a natural harbour on the Indian Ocean, is one of the hubs of the Tanzanian transportation system as the main railways and several highways originate in or near the city to provide convenient transportation for commuters.

The most common form of transport in Dar es Salaam are the public buses, called "dala dala", which are often found at the major bus terminals of Makumbusho and Ubungo. Since the introduction of motorcycle transit business known as "Bodaboda", most of the people prefer this type of transportation, which allows them to get into the city faster compared to the minibuses which face a lot of traffic. Other types of transport include motorcycles and bajaj.

The government has been introducing a bus rapid transport or metro bus system under the Dar es Salaam bus rapid transit meaning 'mwendo kasi' in Kiswahili. The metro buses are managed by UDART a partnership company between UDA (Usafiri Dar es Salaam) and the government.

The bus rapid transit system Phase 1 is completed and already in operation by the Dar es Salaam Rapid Transit Agency, a government-private sector entity, and began operation on 10 May 2016. It is branded as UDA-RT (Usafiri Dar es Salaam Rapid Transit). The first section runs between Kimara in the northwest to Kivukoni on the northern headland of the harbour. Phase 1 was funded by the World Bank, African Development Bank and the Tanzanian government.

The city has the country's busiest port: The port is located on the west of the Indian Ocean, Kurasini creek south east of Dar es Salaam's central business District. The Port of Dar es Salaam handles 90% of the country's cargo.

Due to huge influx of cargo and the slow pace of expansion a new cargo port northwest of Dar es Salaam is proposed at Bagamoyo.

MV Kigamboni ferries run between south east of Kivukoni and north west of Kigamboni in Dar es Salaam.

Travel to urban and sub-urban parts of Dar es Salaam is provided by the Dar es Salaam commuter rail.

Tanzania Railways operates the Central Line from Dar es Salaam to Kigoma.

The city also hosts the head office of Tanzania Zambia Railways Authority (TAZARA) built in the late 1960s to early 1970s. The main terminal is located west of Dar es Salaam's central business district in north Yombo Vituka along Nelson Mandela road. The TAZARA Railway connects Dar es Salaam to Zambia.

Tanzania Standard Gauge Railway is a new railway station which is under construction. It will link the country to Rwanda and Uganda, Burundi and Congo.

The Julius Nyerere International Airport is the principal airport serving the country with three operating terminals; Terminal Three at Kipawa in Ilala Municipality. The airport is located west of Dar es Salaam's central business district.

Dar es-Salaam (and specifically the area of Oyster Bay) is home to the brightly coloured and tourist-oriented Tingatinga painting style. The Nyumba ya sanaa ("House of Art") is a cultural centre, workshop and shop dedicated to Tanzanian art, showcasing and promoting Tanzanian craftmanship. Prominent Tanzanian sculptor George Lilanga has donated some of his works to the centre, including decorations of the building's main entrance.

The music scene in Dar es Salaam is divided between several styles. The longest standing style is live dance music (muziki wa dansi), played by bands such as DDC Mlimani Park Orchestra and Malaika Musical Band. Taarab which was traditionally strong in Zanzibar has also found a niche. However, it remains small compared both to dance music and "Bongo Flava", a broad category that represents the Tanzanian take on hip hop and R&B, which has quickly become the most popular locally produced music. Traditional music, which locally is used to refer to tribal music is still performed but typically only on family oriented occasions such as weddings.

This rap scene is also present.

In the 1970s, the Ministry of National Youth Culture aimed to create a national culture, which stressed the importance of music. Dar es Salaam became the music center in Tanzania, with the local radio showcasing new bands and dominating the music and cultural scene. With this ujamaa, or family, mentality governing culture and music a unified people's culture was created, leading to the rise of hip hop music. Throughout the years, the radio in Dar es Salaam has played a major role in the dissemination of music because many people don't have television and cassettes are used over CDs.

Dar es Salaam has two of the five museums comprising the National Museum of Tanzania consortium, namely the National Museum proper and the Makumbusho Cultural Centre & Village Museum. The National Museum is dedicated to the history of Tanzania; most notably, it exhibits some of the bones of "Paranthropus boisei" that were among the findings of Louis Leakey at Olduvai. The Makumbusho Cultural Centre & Village Museum, located in the outskirts of the city on the road to Bagamoyo, showcases traditional huts from 16 different Tanzanian ethnic groups. There are also examples of traditional cultivations, and traditional music and dance shows are held daily. In 2016, there was a breakthrough discovery in Northern Tanzania by a scientist, from the University of Dar es Salaam, of footprints thought to be of a hominid that predates Homo sapiens.

Close to the National Museum are also the botanical gardens, with tropical plants and trees.

There are beaches on the Msasani peninsula north of Dar es Salaam and in Kigamboni to the south. Trips to the nearby islands of the Dar es Salaam Marine Reserve are a popular daytrip from the city and a spot for snorkeling, swimming and sunbathing. Bongoyo Island can be reached by boat from the Msasani Slipway.

Among the places of worship, they are predominantly Christian churches and temples : Roman Catholic Archdiocese of Dar es Salaam (Catholic Church), Anglican Church of Tanzania (Anglican Communion), Evangelical Lutheran Church in Tanzania (Lutheran World Federation), Baptist Convention of Tanzania (Baptist World Alliance), Assemblies of God. There are also Muslim mosques.

Dar es-Salaam is the sports center of Tanzania. Dar es-Salaam hosts the second largest stadium in East and Central Africa (National Stadium), which can accommodate up to 60,000 people.
The National Stadium hosts Dar es Salaam's Young Africans Sports Club, Simba Sports Club, Azam F.C. and other Tanzanian football clubs, and international matches. There is a proposal to build a new stadium in Dodoma, much bigger in capacity than the present one in Dar es Salaam by the government as a donation from the Moroccan Kingdom.

Apart from the National Stadium, Dar es Salaam is home to the Uhuru Stadium (used mainly for local tournaments and political gatherings), Karume Memorial Stadium (the home of the Tanzania Football Federation). The stadium is situated west of Kurasini.

The Gymkhana Golf Courses located north west of the Kivukoni area (between the city centre looking on to the shores of the Indian Ocean in the east and Barack Obama Drive), also has tennis courts, squash courts, and a fitness club. Outside of the metropolitan districts, there is the Lugalo Military Golf Course (located in the Lugalo Military Barracks).

Dar es Salaam's Mama Africa school, founded in 2003, is known for training some of Africa's finest acrobats.

Dar es Salaam's Union Sports Club hosts a single indoor squash court with a referees' viewing gallery within the club grounds. The club has a yearly squash tournament during the Muslim month of Ramadhan.

Dar es Salaam's Union Sports Club hosts a single darts room. The club has a yearly darts tournament during the Muslim month of ramadhan.

Dar es Salaam's Union Sports Club hosts a single room for table tennis. The club has a yearly table tennis tournament during the Muslim month of Ramadhan.

Dar es Salaam's Union Sports Club hosts an under-the-sky outdoor scrabble tournament within the club grounds once a year during the Muslim month of Ramadhan.

Dar es Salaam hosts numerous outdoor swimming clubs; people also swim in the Indian Ocean.

Newspapers in Dar es Salaam are often sold by people prowling through stationary traffic at road intersections. English-language ones, with online presences, include "The Citizen" and "The Guardian" and the Kiswahili dailies, "Tanzania Daima" and "Mwananchi". "Business Times" is the only financial and economic newspaper in the city. It was established in 1988 and became the first private newspaper in Tanzania. "Business Times" owns "Majira", another Kiswahili newspaper.

Dar es Salaam is home to ITV, Sibuka, Channel Ten Television Station formerly known as Dar es Salaam Television (DTV) and Azam TV, a subscription-based service from the Azam group of companies.

Ayo TV, a television station, is also based in Ubungo, Dar es Salaam, as is the Tanzania Broadcasting Corporation.

Installation of a trans-Indian Ocean backbone cable in 2009 has, in theory, made Internet access much more readily available in Dar in particular and in East Africa in general. However, roll-out to end-users is slow, partly because of spotty telephone line coverage at the moment provided by the Tanzania Telecommunications Company Limited, partly due to the substantial prices and long contracts demanded for purchase of bandwidth for small ISPs. Mobile-telephone access to the Internet via 3G and 3.75G is still relatively expensive. 4G is making its way through major cities and towns with plans to go countrywide in the advanced planning stages.

Internet cafés are found in the city centre and free wifi hotspots in various government and non government institutions as well as public transport.

The expressed aim of the SEACOM cable is to enable East Africa to develop economically through increased online trading.

Dar es Salaam's first radio station began operation in the early 1950s "with little more equipment than a microphone and a blanket hung over a wall..." This project was overseen by Edward Twining.

Dar es Salaam is the educational centre of Tanzania. The city is home to several institutions of higher learning.

The city has some of the best schools in Tanzania such as Shaaban Robert Secondary School, Al Muntazir School, Aga Khan Primary School, Aga Khan Mzizima Secondary School, Loyola School, Indian School Dar Es Salaam, International School of Tanganyika, and St. Constantine's International School.

Below is a list of notable people who lived in Dar es Salaam:


Dar es Salaam is twinned with:



</doc>
<doc id="8501" url="https://en.wikipedia.org/wiki?curid=8501" title="Distributed computing">
Distributed computing

Distributed computing is a field of computer science that studies distributed systems. A "distributed system" is a system whose components are located on different networked computers, which communicate and coordinate their actions by passing messages to one another. The components interact with one another in order to achieve a common goal. Three significant characteristics of distributed systems are: concurrency of components, lack of a global clock, and independent failure of components. Examples of distributed systems vary from SOA-based systems to massively multiplayer online games to peer-to-peer applications.

A computer program that runs within a distributed system is called a distributed program (and distributed programming is the process of writing such programs). There are many different types of implementations for the message passing mechanism, including pure HTTP, RPC-like connectors and message queues.

"Distributed computing" also refers to the use of distributed systems to solve computational problems. In "distributed computing", a problem is divided into many tasks, each of which is solved by one or more computers, which communicate with each other via message passing.

The word "distributed" in terms such as "distributed system", "distributed programming", and "distributed algorithm" originally referred to computer networks where individual computers were physically distributed within some geographical area. The terms are nowadays used in a much wider sense, even referring to autonomous processes that run on the same physical computer and interact with each other by message passing.

While there is no single definition of a distributed system, the following defining properties are commonly used as:

A distributed system may have a common goal, such as solving a large computational problem; the user then perceives the collection of autonomous processors as a unit. Alternatively, each computer may have its own user with individual needs, and the purpose of the distributed system is to coordinate the use of shared resources or provide communication services to the users.

Other typical properties of distributed systems include the following:

Distributed systems are groups of networked computers which share a common goal for their work.
The terms "concurrent computing", "parallel computing", and "distributed computing" have much overlap, and no clear distinction exists between them. The same system may be characterized both as "parallel" and "distributed"; the processors in a typical distributed system run concurrently in parallel. Parallel computing may be seen as a particular tightly coupled form of distributed computing, and distributed computing may be seen as a loosely coupled form of parallel computing. Nevertheless, it is possible to roughly classify concurrent systems as "parallel" or "distributed" using the following criteria:
The figure on the right illustrates the difference between distributed and parallel systems. Figure (a) is a schematic view of a typical distributed system; the system is represented as a network topology in which each node is a computer and each line connecting the nodes is a communication link. Figure (b) shows the same distributed system in more detail: each computer has its own local memory, and information can be exchanged only by passing messages from one node to another by using the available communication links. Figure (c) shows a parallel system in which each processor has a direct access to a shared memory.

The situation is further complicated by the traditional uses of the terms parallel and distributed "algorithm" that do not quite match the above definitions of parallel and distributed "systems" (see below for more detailed discussion). Nevertheless, as a rule of thumb, high-performance parallel computation in a shared-memory multiprocessor uses parallel algorithms while the coordination of a large-scale distributed system uses distributed algorithms.

The use of concurrent processes which communicate through message-passing has its roots in operating system architectures studied in the 1960s. The first widespread distributed systems were local-area networks such as Ethernet, which was invented in the 1970s.

ARPANET, the predecessor of the Internet, was introduced in the late 1960s, and ARPANET e-mail was invented in the early 1970s. E-mail became the most successful application of ARPANET, and it is probably the earliest example of a large-scale distributed application. In addition to ARPANET (and its successor, the Internet), other early worldwide computer networks included Usenet and FidoNet from the 1980s, both of which were used to support distributed discussion systems.

The study of distributed computing became its own branch of computer science in the late 1970s and early 1980s. The first conference in the field, Symposium on Principles of Distributed Computing (PODC), dates back to 1982, and its counterpart International Symposium on Distributed Computing (DISC) was first held in Ottawa in 1985 as the International Workshop on Distributed Algorithms on Graphs.

Various hardware and software architectures are used for distributed computing. At a lower level, it is necessary to interconnect multiple CPUs with some sort of network, regardless of whether that network is printed onto a circuit board or made up of loosely coupled devices and cables. At a higher level, it is necessary to interconnect processes running on those CPUs with some sort of communication system.

Distributed programming typically falls into one of several basic architectures: client–server, three-tier, "n"-tier, or peer-to-peer; or categories: loose coupling, or tight coupling.


Another basic aspect of distributed computing architecture is the method of communicating and coordinating work among concurrent processes. Through various message passing protocols, processes may communicate directly with one another, typically in a master/slave relationship. Alternatively, a "database-centric" architecture can enable distributed computing to be done without any form of direct inter-process communication, by utilizing a shared database. Database-centric architecture in particular provides relational processing analytics in a schematic architecture allowing for live environment relay. This enables distributed computing functions both within and beyond the parameters of a networked database.

Reasons for using distributed systems and distributed computing may include:

Examples of distributed systems and applications of distributed computing include the following:

Many tasks that we would like to automate by using a computer are of question–answer type: we would like to ask a question and the computer should produce an answer. In theoretical computer science, such tasks are called computational problems. Formally, a computational problem consists of "instances" together with a "solution" for each instance. Instances are questions that we can ask, and solutions are desired answers to these questions.

Theoretical computer science seeks to understand which computational problems can be solved by using a computer (computability theory) and how efficiently (computational complexity theory). Traditionally, it is said that a problem can be solved by using a computer if we can design an algorithm that produces a correct solution for any given instance. Such an algorithm can be implemented as a computer program that runs on a general-purpose computer: the program reads a problem instance from input, performs some computation, and produces the solution as output. Formalisms such as random access machines or universal Turing machines can be used as abstract models of a sequential general-purpose computer executing such an algorithm.

The field of concurrent and distributed computing studies similar questions in the case of either multiple computers, or a computer that executes a network of interacting processes: which computational problems can be solved in such a network and how efficiently? However, it is not at all obvious what is meant by "solving a problem" in the case of a concurrent or distributed system: for example, what is the task of the algorithm designer, and what is the concurrent or distributed equivalent of a sequential general-purpose computer?

The discussion below focuses on the case of multiple computers, although many of the issues are the same for concurrent processes running on a single computer.

Three viewpoints are commonly used:


In the case of distributed algorithms, computational problems are typically related to graphs. Often the graph that describes the structure of the computer network "is" the problem instance. This is illustrated in the following example.

Consider the computational problem of finding a coloring of a given graph "G". Different fields might take the following approaches:

While the field of parallel algorithms has a different focus than the field of distributed algorithms, there is much interaction between the two fields. For example, the Cole–Vishkin algorithm for graph coloring was originally presented as a parallel algorithm, but the same technique can also be used directly as a distributed algorithm.

Moreover, a parallel algorithm can be implemented either in a parallel system (using shared memory) or in a distributed system (using message passing). The traditional boundary between parallel and distributed algorithms (choose a suitable network vs. run in any given network) does not lie in the same place as the boundary between parallel and distributed systems (shared memory vs. message passing).

In parallel algorithms, yet another resource in addition to time and space is the number of computers. Indeed, often there is a trade-off between the running time and the number of computers: the problem can be solved faster if there are more computers running in parallel (see speedup). If a decision problem can be solved in polylogarithmic time by using a polynomial number of processors, then the problem is said to be in the class NC. The class NC can be defined equally well by using the PRAM formalism or Boolean circuits—PRAM machines can simulate Boolean circuits efficiently and vice versa.

In the analysis of distributed algorithms, more attention is usually paid on communication operations than computational steps. Perhaps the simplest model of distributed computing is a synchronous system where all nodes operate in a lockstep fashion. This model is commonly known as the LOCAL model. During each "communication round", all nodes in parallel (1) receive the latest messages from their neighbours, (2) perform arbitrary local computation, and (3) send new messages to their neighbors. In such systems, a central complexity measure is the number of synchronous communication rounds required to complete the task.

This complexity measure is closely related to the diameter of the network. Let "D" be the diameter of the network. On the one hand, any computable problem can be solved trivially in a synchronous distributed system in approximately 2"D" communication rounds: simply gather all information in one location ("D" rounds), solve the problem, and inform each node about the solution ("D" rounds).

On the other hand, if the running time of the algorithm is much smaller than "D" communication rounds, then the nodes in the network must produce their output without having the possibility to obtain information about distant parts of the network. In other words, the nodes must make globally consistent decisions based on information that is available in their "local D-neighbourhood". Many distributed algorithms are known with the running time much smaller than "D" rounds, and understanding which problems can be solved by such algorithms is one of the central research questions of the field. Typically an algorithm which solves a problem in polylogarithmic time in the network size is considered efficient in this model.

Another commonly used measure is the total number of bits transmitted in the network (cf. communication complexity). The features of this concept are typically captured with the CONGEST(B) model, which similarly defined as the LOCAL model but where single messages can only contain B bits.

Traditional computational problems take the perspective that the user asks a question, a computer (or a distributed system) processes the question, then produces an answer and stops. However, there are also problems where the system is required not to stop, including the dining philosophers problem and other similar mutual exclusion problems. In these problems, the distributed system is supposed to continuously coordinate the use of shared resources so that no conflicts or deadlocks occur.

There are also fundamental challenges that are unique to distributed computing, for example those related to "fault-tolerance". Examples of related problems include consensus problems, Byzantine fault tolerance, and self-stabilisation.

Much research is also focused on understanding the "asynchronous" nature of distributed systems:
"Coordinator election" (or "leader election") is the process of designating a single process as the organizer of some task distributed among several computers (nodes). Before the task is begun, all network nodes are either unaware which node will serve as the "coordinator" (or leader) of the task, or unable to communicate with the current coordinator. After a coordinator election algorithm has been run, however, each node throughout the network recognizes a particular, unique node as the task coordinator.

The network nodes communicate among themselves in order to decide which of them will get into the "coordinator" state. For that, they need some method in order to break the symmetry among them. For example, if each node has unique and comparable identities, then the nodes can compare their identities, and decide that the node with the highest identity is the coordinator.

The definition of this problem is often attributed to LeLann, who formalized it as a method to create a new token in a token ring network in which the token has been lost.

Coordinator election algorithms are designed to be economical in terms of total bytes transmitted, and time. The algorithm suggested by Gallager, Humblet, and Spira for general undirected graphs has had a strong impact on the design of distributed algorithms in general, and won the Dijkstra Prize for an influential paper in distributed computing.

Many other algorithms were suggested for different kind of network graphs, such as undirected rings, unidirectional rings, complete graphs, grids, directed Euler graphs, and others. A general method that decouples the issue of the graph family from the design of the coordinator election algorithm was suggested by Korach, Kutten, and Moran.

In order to perform coordination, distributed systems employ the concept of coordinators. The coordinator election problem is to choose a process from among a group of processes on different processors in a distributed system to act as the central coordinator. Several central coordinator election algorithms exist.

So far the focus has been on "designing" a distributed system that solves a given problem. A complementary research problem is "studying" the properties of a given distributed system.

The halting problem is an analogous example from the field of centralised computation: we are given a computer program and the task is to decide whether it halts or runs forever. The halting problem is undecidable in the general case, and naturally understanding the behaviour of a computer network is at least as hard as understanding the behaviour of one computer.

However, there are many interesting special cases that are decidable. In particular, it is possible to reason about the behaviour of a network of finite-state machines. One example is telling whether a given network of interacting (asynchronous and non-deterministic) finite-state machines can reach a deadlock. This problem is PSPACE-complete, i.e., it is decidable, but not likely that there is an efficient (centralised, parallel or distributed) algorithm that solves the problem in the case of large networks.







</doc>
<doc id="8504" url="https://en.wikipedia.org/wiki?curid=8504" title="Dublin">
Dublin

Dublin (, ; ) is the capital and largest city of Ireland. Situated on a bay on the east coast, at the mouth of the River Liffey, it lies within the province of Leinster. It is bordered on the south by the Dublin Mountains, a part of the Wicklow Mountains range. It has an urban area population of 1,173,179, while the population of the Dublin Region (formerly County Dublin) was 1,347,359. The population of the Greater Dublin Area was 1,904,806 per the 2016 census.

There is archaeological debate regarding precisely where Dublin was established by the Gaels in or before the 7th century AD. Later expanded as a Viking settlement, the Kingdom of Dublin, the city became Ireland's principal settlement following the Norman invasion. The city expanded rapidly from the 17th century and was briefly the second largest city in the British Empire before the Acts of Union in 1800. Following the partition of Ireland in 1922, Dublin became the capital of the Irish Free State, later renamed Ireland. 

Dublin is a historical and contemporary centre for education, the arts, administration and industry. the city was listed by the Globalization and World Cities Research Network (GaWC) as a global city, with a ranking of "Alpha −", which places it amongst the top thirty cities in the world.

The name "Dublin" derives from the Irish word "Dubhlinn", early Classical Irish /, from (, , ) meaning "black, dark", and () "pool", referring to a dark tidal pool. This tidal pool was located where the River Poddle entered the Liffey, on the site of the castle gardens at the rear of Dublin Castle. In Modern Irish the name is "Duibhlinn", and Irish rhymes from County Dublin show that in Dublin Leinster Irish it was pronounced "Duílinn" . The original pronunciation is preserved in the names for the city in other languages such as Old English , Old Norse , modern Icelandic and modern Manx as well as Welsh and Breton . Other localities in Ireland also bear the name "Duibhlinn", variously anglicised as Devlin, Divlin and Difflin. Historically, scribes using the Gaelic script wrote "bh" with a dot over the "b", rendering Duḃlinn or Duiḃlinn. Those without knowledge of Irish omitted the dot, spelling the name as "Dublin". Variations on the name are also found in traditionally Gaelic-speaking areas of Scotland (Gàidhealtachd, cognate with Irish Gaeltacht), such as "An Linne Dhubh" ("the black pool"), which is part of Loch Linnhe.

It is now thought that the Viking settlement was preceded by a Christian ecclesiastical settlement known as "Duibhlinn", from which "Dyflin" took its name. Beginning in the 9th and 10th century, there were two settlements where the modern city stands. The Viking settlement of about 841, "Dyflin", and a Gaelic settlement, Áth Cliath ("ford of hurdles") further up river, at the present day Father Mathew Bridge (also known as Dublin Bridge), at the bottom of Church Street. ', meaning "town of the hurdled ford", is the common name for the city in modern Irish. ' is a place name referring to a fording point of the River Liffey near Father Mathew Bridge. "" was an early Christian monastery, believed to have been in the area of Aungier Street, currently occupied by Whitefriar Street Carmelite Church. There are other towns of the same name, such as "Àth Cliath" in East Ayrshire, Scotland, which is anglicised as Hurlford.

The area of Dublin Bay has been inhabited by humans since prehistoric times, but the writings of Ptolemy (the Greco-Roman astronomer and cartographer) in about AD 140 provide possibly the earliest reference to a settlement there. He called it "Eblana polis" ().

Dublin celebrated its 'official' millennium in 1988, meaning the Irish government recognised 988 as the year in which the city was settled and that this first settlement would later become the city of Dublin.
It is now thought the Viking settlement of about 841 was preceded by a Christian ecclesiastical settlement known as "Duibhlinn", from which "Dyflin" took its name. Beginning in the 9th and 10th century, there were two settlements which later became the modern Dublin. The subsequent Scandinavian settlement centred on the River Poddle, a tributary of the Liffey in an area now known as Wood Quay. The Dubhlinn was a pool on the lowest stretch of the Poddle, used to moor ships. This pool was finally fully infilled during the early 18th century, as the city grew. The Dubhlinn lay where the Castle Garden is now located, opposite the Chester Beatty Library within Dublin Castle. "Táin Bó Cuailgne" ("The Cattle Raid of Cooley") refers to "Dublind rissa ratter Áth Cliath", meaning "Dublin, which is called Ath Cliath".

Dublin was established as a Viking settlement in the 10th century and, despite a number of attacks by the native Irish, it remained largely under Viking control until the Norman invasion of Ireland was launched from Wales in 1169. It was upon the death of Muirchertach Mac Lochlainn in early 1166 that Ruaidrí Ua Conchobair, King of Connacht, proceeded to Dublin and was inaugurated "King of Ireland" without opposition.

According to some historians, part of the city's early economic growth is attributed to a trade in slaves. Slavery in Ireland and Dublin reached its pinnacle in the 9th and 10th centuries. Prisoners from slave raids and kidnappings, which captured men, women and children, brought revenue to the Gaelic Irish Sea raiders, as well as to the Vikings who had initiated the practice. The victims came from Wales, England, Normandy and beyond.

The King of Leinster, Diarmait Mac Murchada, after his exile by Ruaidhrí, enlisted the help of Strongbow, the Earl of Pembroke, to conquer Dublin. Following Mac Murrough's death, Strongbow declared himself King of Leinster after gaining control of the city. In response to Strongbow's successful invasion, King Henry II of England affirmed his ultimate sovereignty by mounting a larger invasion in 1171 and pronounced himself Lord of Ireland. Around this time, the "county of the City of Dublin" was established along with certain liberties adjacent to the city proper. This continued down to 1840 when the barony of Dublin City was separated from the barony of Dublin. Since 2001, both baronies have been redesignated as the "City of Dublin".
Dublin Castle, which became the centre of Anglo-Norman power in Ireland, was founded in 1204 as a major defensive work on the orders of King John of England. Following the appointment of the first Lord Mayor of Dublin in 1229, the city expanded and had a population of 8,000 by the end of the 13th century. Dublin prospered as a trade centre, despite an attempt by King Robert I of Scotland to capture the city in 1317. It remained a relatively small walled medieval town during the 14th century and was under constant threat from the surrounding native clans. In 1348, the Black Death, a lethal plague which had ravaged Europe, took hold in Dublin and killed thousands over the following decade.

Dublin was the heart of the area known as the Pale, a narrow strip of English settlement along the eastern seaboard, under the control of the English Crown. The Tudor conquest of Ireland in the 16th century spelt a new era for Dublin, with the city enjoying a renewed prominence as the centre of administrative rule in an Ireland where English control and settlement had become much more extensive. Determined to make Dublin a Protestant city, Queen Elizabeth I of England established Trinity College in 1592 as a solely Protestant university and ordered that the Catholic St. Patrick's and Christ Church cathedrals be converted to the Protestant church.

The city had a population of 21,000 in 1640 before a plague in 1649–51 wiped out almost half of the inhabitants. However, the city prospered again soon after as a result of the wool and linen trade with England, reaching a population of over 50,000 in 1700.

As the city continued to prosper during the 18th century, Georgian Dublin became, for a short period, the second largest city of the British Empire and the fifth largest city in Europe, with the population exceeding 130,000. The vast majority of Dublin's most notable architecture dates from this period – the Four Courts, the Custom House, Temple Bar and Grafton Street are some of the few remaining areas that were not affected by the wave of Georgian reconstruction and maintained their medieval character.

Dublin grew even more dramatically during the 18th century, with the construction of many new districts and buildings, such as Merrion Square, Parliament House and the Royal Exchange. The Wide Streets Commission was established in 1757 at the request of Dublin Corporation to govern architectural standards on the layout of streets, bridges and buildings. In 1759, the Guinness brewery was founded; and would eventually grow to become the largest brewery in the world and the largest employer in Dublin.

Dublin suffered a period of political and economic decline during the 19th century following the Acts of Union 1800, under which the seat of government was transferred to the Westminster Parliament in London. The city played no major role in the Industrial Revolution, but remained the centre of administration and a transport hub for most of the island. Ireland had no significant sources of coal, the fuel of the time, and Dublin was not a centre of ship manufacturing, the other main driver of industrial development in Britain and Ireland. Belfast developed faster than Dublin during this period on a mixture of international trade, factory-based linen cloth production and shipbuilding.
The Easter Rising of 1916, the Irish War of Independence, and the subsequent Irish Civil War resulted in a significant amount of physical destruction in central Dublin. The Government of the Irish Free State rebuilt the city centre and located the new parliament, the Oireachtas, in Leinster House. Since the beginning of Norman rule in the 12th century, the city has functioned as the capital in varying geopolitical entities: Lordship of Ireland (1171–1541), Kingdom of Ireland (1541–1800), as part of the United Kingdom of Great Britain and Ireland (1801–1922), and the Irish Republic (1919–1922). Following the partition of Ireland in 1922, it became the capital of the Irish Free State (1922–1937) and now is the capital of Ireland. One of the memorials to commemorate that time is the Garden of Remembrance.

Dublin was also a victim of the Northern Irish Troubles, although during this 30-year conflict, violence mainly occurred within Northern Ireland. However, the Provisional IRA drew some support from within the Republic, including from Dublin. A Loyalist paramilitary group, the Ulster Volunteer Force, bombed the city during this time – notably in an atrocity known as the Dublin and Monaghan bombings in which 34 people died, mainly in central Dublin.

Since 1997, the landscape of Dublin has changed. The city was at the forefront of Ireland's economic expansion during the Celtic Tiger period, with private sector and state development of housing, transport and business. Following an economic decline during the Great Recession, Dublin has rebounded and has close to full employment, but has a significant problem with housing supply in both the city and surrounds.

From 1842, the boundaries of the city were comprehended by the baronies of Dublin City and the Barony of Dublin. In 1930, the boundaries were extended by the Local Government (Dublin) Act. Later, in 1953, the boundaries were again extended by the Local Government Provisional Order Confirmation Act.

Dublin City Council is a unicameral assembly of 63 members elected every five years from Local Election Areas. It is presided over by the Lord Mayor, who is elected for a yearly term and resides in Dublin's Mansion House. Council meetings occur at Dublin City Hall, while most of its administrative activities are based in the Civic Offices on Wood Quay. The party or coalition of parties with the majority of seats assigns committee members, introduces policies, and proposes the Lord Mayor. The Council passes an annual budget for spending on areas such as housing, traffic management, refuse, drainage, and planning. The Dublin City Manager is responsible for implementing City Council decisions but also has considerable executive power.

As the capital city, Dublin is the seat of the national parliament of Ireland, the Oireachtas. It is composed of the President of Ireland, Seanad Éireann as the upper house, and Dáil Éireann as the lower house. The President resides in Áras an Uachtaráin in Phoenix Park, while both houses of the Oireachtas meet in Leinster House, a former ducal palace on Kildare Street. It has been the home of the Irish parliament since the creation of the Irish Free State in 1922. The old Irish Houses of Parliament of the Kingdom of Ireland are located in College Green.

Government Buildings house the Department of the Taoiseach, the Council Chamber, the Department of Finance and the Office of the Attorney General. It consists of a main building (completed 1911) with two wings (completed 1921). It was designed by Thomas Manley Dean and Sir Aston Webb as the Royal College of Science. The First Dáil originally met in the Mansion House in 1919. The Irish Free State government took over the two wings of the building to serve as a temporary home for some ministries, while the central building became the College of Technology until 1989. Although both it and Leinster House were intended to be temporary locations, they became the permanent homes of parliament from then on.

For elections to Dáil Éireann, the city is divided into five constituencies: Dublin Central (3 seats), Dublin Bay North (5 seats), Dublin North-West (3 seats), Dublin South-Central (4 seats) and Dublin Bay South (4 seats). Nineteen TD's are elected in total.

In the 2016 general election the Dublin city area elected 6 Fine Gael, 4 Sinn Féin, 2 Fianna Fáil, 2 Independents 4 Change, 2 Independents, 1 People Before Profit, 1 Green Party and 1 Social Democrats TDs.

Dublin is situated at the mouth of the River Liffey and encompasses a land area of approximately in east-central Ireland. It is bordered by the Dublin Mountains, a low mountain range and sub range of the Wicklow Mountains, to the south and surrounded by flat farmland to the north and west.

The River Liffey divides the city in two, between the Northside and the Southside. The Liffey bends at Leixlip from a northeasterly route to a predominantly eastward direction, and this point also marks the transition to urban development from more agricultural land usage.

Two secondary rivers further divide the city  – the River Tolka, running southeast into Dublin Bay, and the River Dodder running northeast to near the mouth of the Liffey, and these and the Liffey have multiple tributaries. A number of lesser rivers and streams also flow to the sea.

Two canals – the Grand Canal on the southside and the Royal Canal on the northside – ring the inner city on their way from the west and the River Shannon.

A north–south division once, to some extent, traditionally existed, with the River Liffey as the divider. The South side was generally seen as being more affluent and genteel than the North side. There have also been some social divisions evident between the coastal suburbs in the east of the city, and the newer developments further to the west.

In some tourism and real-estate marketing contexts, inner Dublin is sometimes divided into a number of "quarters" or districts. These include, the 'Medieval Quarter' (in the area of Dublin Castle, Christ Church and St Patrick's Cathedral and the old city walls), the 'Georgian Quarter' (including the area around St Stephen's Green, Trinity College, and Merrion Square), the 'Docklands Quarter' (around the Dublin Docklands and Silicon Docks), the 'Cultural Quarter' (around Temple Bar), and 'Creative Quarter' (between South William Street and George's Street).

Similar to much of the rest of northwestern Europe, Dublin experiences a maritime climate ("Cfb") with mild-warm summers, cool winters, and a lack of temperature extremes. The average maximum January temperature is , while the average maximum July temperature is . On average, the sunniest months are May and June, while the wettest month is October with of rain, and the driest month is February with . Rainfall is evenly distributed throughout the year.

Dublin's sheltered location on the east coast makes it the driest place in Ireland, receiving only about half the rainfall of the west coast. Ringsend in the south of the city records the lowest rainfall in the country, with an average annual precipitation of , with the average annual precipitation in the city centre being . The main precipitation in winter is rain; however snow showers do occur between November and March. Hail is more common than snow. The city experiences long summer days and short winter days. Strong Atlantic winds are most common in autumn. These winds can affect Dublin, but due to its easterly location, it is least affected compared to other parts of the country. However, in winter, easterly winds render the city colder and more prone to snow showers.

In the 20th century, smog and air-pollution were an issue in the city, precipitating a ban on bituminous fuels across Dublin. The ban was implemented in 1990 to address black smoke concentrations, that had been linked to cardiovascular and respiratory deaths in residents. Since the ban, non-trauma death rates, respiratory death rates and cardiovascular death rates have declined – by an estimated 350 deaths annually.

Dublin has many landmarks and monuments dating back hundreds of years. One of the oldest is Dublin Castle, which was first founded as a major defensive work on the orders of England's King John in 1204, shortly after the Norman invasion of Ireland in 1169, when it was commanded that a castle be built with strong walls and good ditches for the defence of the city, the administration of justice, and the protection of the King's treasure. Largely complete by 1230, the castle was of typical Norman courtyard design, with a central square without a keep, bounded on all sides by tall defensive walls and protected at each corner by a circular tower. Sited to the south-east of Norman Dublin, the castle formed one corner of the outer perimeter of the city, using the River Poddle as a natural means of defence.
One of Dublin's newest monuments is the Spire of Dublin, officially entitled the "Monument of Light." It is a conical spire made of stainless steel, located on O'Connell Street where it meets Henry Street and North Earl Street. It replaces Nelson's Pillar and is intended to mark Dublin's place in the 21st century. The spire was designed by Ian Ritchie Architects, who sought an "Elegant and dynamic simplicity bridging art and technology". The base of the monument is lit and the top is illuminated to provide a beacon in the night sky across the city.

The Old Library of Trinity College, Dublin, holding the Book of Kells, is one of the city's most visited sites. The Book of Kells is an illustrated manuscript created by Irish monks circa 800 AD. The Ha'penny Bridge, an iron footbridge over the River Liffey, is one of the most photographed sights in Dublin and is considered to be one of Dublin's most iconic landmarks.

Other landmarks and monuments include Christ Church Cathedral and St Patrick's Cathedral, the Mansion House, the Molly Malone statue, the complex of buildings around Leinster House, including part of the National Museum of Ireland and the National Library of Ireland, The Custom House and Áras an Uachtaráin. Other sights include the Anna Livia monument. The Poolbeg Towers are also landmark features of Dublin, and visible from various spots around the city.

There are many green-spaces around the city, and Dublin City Council manages over of parks. Public parks include the Phoenix Park, Herbert Park, St Stephen's Green, Saint Anne's Park and Bull Island. The Phoenix Park is about west of the city centre, north of the River Liffey. Its perimeter wall encloses , making it one of the largest walled city parks in Europe. It includes large areas of grassland and tree-lined avenues, and since the 17th century has been home to a herd of wild fallow deer. The residence of the President of Ireland (Áras an Uachtaráin), which was built in 1751, is located in the park. The park is also home to Dublin Zoo, Ashtown Castle, and the official residence of the United States Ambassador. Music concerts are also sometimes held in the park.

St Stephen's Green is adjacent to one of Dublin's main shopping streets, Grafton Street, and to a shopping centre named for it, while on its surrounding streets are the offices of a number of public bodies.

Saint Anne's Park is a public park and recreational facility, shared between Raheny and Clontarf, both suburbs on the Northside. The park, the second largest municipal park in Dublin, is part of a former estate assembled by members of the Guinness family, beginning with Benjamin Lee Guinness in 1835 (the largest municipal park is nearby (North) Bull Island, also shared between Clontarf and Raheny), featuring a 5 km beach.

 The Dublin region is the economic centre of Ireland, and was at the forefront of the country's economic expansion during the Celtic Tiger period. In 2009, Dublin was listed as the fourth richest city in the world by purchasing power and 10th richest by personal income. According to "Mercer's 2011 Worldwide Cost of Living Survey", Dublin is the 13th most expensive city in the European Union (down from 10th in 2010) and the 58th most expensive place to live in the world (down from 42nd in 2010). , approximately 874,400 people were employed in the Greater Dublin Area. Around 60% of people who are employed in Ireland's financial, ICT, and professional sectors are located in this area.

A number of Dublin's traditional industries, such as food processing, textile manufacturing, brewing, and distilling have gradually declined, although Guinness has been brewed at the St. James's Gate Brewery since 1759. Economic improvements in the 1990s attracted a number of global pharmaceutical, information and communications technology companies to the city and Greater Dublin Area. Companies such as Microsoft, Google, Amazon, eBay, PayPal, Yahoo!, Facebook, Twitter, Accenture and Pfizer now have European headquarters and/or operational bases in the city, with several located in enterprise clusters like the Digital Hub and Silicon Docks. The presence of these companies has driven economic expansion in the city and led to Dublin sometimes being referred to as the "Tech Capital of Europe".

Financial services have also become important to the city since the establishment of Dublin's International Financial Services Centre in 1987. More than 500 operations are approved to trade under the IFSC programme. The centre is host to half of the world's top 50 banks and to half of the top 20 insurance companies. Many international firms have established major headquarters in the city, such as Citibank. The Irish Stock Exchange (ISEQ), Internet Neutral Exchange (INEX) and Irish Enterprise Exchange (IEX) are also located in Dublin. Dublin has been positioned as one of the main cities vying to host Financial Services companies hoping to retain access to the Eurozone after Brexit. The Celtic Tiger also led to a temporary boom in construction, with large redevelopment projects in the Dublin Docklands and Spencer Dock. Completed projects include the Convention Centre, the 3Arena, and the Bord Gáis Energy Theatre.

In the second quarter of 2018, Dublin touched its lowest unemployment rate in a decade, when it fell down to 5.7% as reported by the Dublin Economic Monitor.

The road network in Ireland is primarily focused on Dublin. The M50 motorway, a semi-ring road which runs around the south, west and north of the city, connects important national primary routes to the rest of the country. In 2008, the West-Link toll bridge was replaced by the eFlow barrier-free tolling system, with a three-tiered charge system based on electronic tags and car pre-registration.

The first phase of a proposed eastern bypass for the city is the Dublin Port Tunnel, which officially opened in 2006 to mainly cater for heavy vehicles. The tunnel connects Dublin Port and the M1 motorway close to Dublin Airport. The city is also surrounded by an inner and outer orbital route. The inner orbital route runs approximately around the heart of the Georgian city and the outer orbital route runs primarily along the natural circle formed by Dublin's two canals, the Grand Canal and the Royal Canal, as well as the North and South Circular Roads.

The 2016 TomTom Traffic Index ranked Dublin the 15th most congested city in the world and the 7th most congested in Europe.

Dublin is served by a network of nearly 200 bus routes which cover the city and suburbs. The majority of these are provided by Dublin Bus, with a modest number having been transferred to Go Ahead Ireland in 2018, but a number of smaller companies also operate. Fares are generally calculated on a stage system based on distance travelled. There are several different levels of fares, which apply on most services. A "Real Time Passenger Information" system was introduced at Dublin Bus bus stops in 2012. Electronically displayed signs relay information about the time of the next buses arrival based on its GPS determined position. The National Transport Authority is responsible for integration of bus and rail services in Dublin and has been involved in introducing a pre-paid smart card, called a Leap card, which can be used on all of Dublin's public transport services.

The 2011 Census showed that 5.9 percent of commuters in Dublin cycled. A 2013 report by Dublin City Council on traffic flows crossing the canals in and out of the city found that just under 10% of all traffic was made up of cyclists, representing an increase of 14.1% over 2012 and an 87.2% increase over 2006 levels and is attributed to measures, such as, the Dublinbikes bike rental scheme, the provision of cycle lanes, public awareness campaigns to promote cycling and the introduction of the 30 km/h city centre speed limit.

Dublin City Council began installing cycle lanes and tracks throughout the city in the 1990s, and the city had over of specific on- and off-road tracks for cyclists. In 2011, the city was ranked 9th of major world cities on the "Copenhagenize Index of Bicycle-Friendly Cities". The same index showed a fall to 15th in 2015, and Dublin was outside the top 20 in 2017.
Dublinbikes is a self-service bicycle rental scheme which has been in operation in Dublin since 2009. Sponsored by JCDecaux and Just Eat, the scheme consists of hundreds of unisex bicycles stationed at 44 terminals throughout the city centre. Users must make a subscription for either an annual Long Term Hire Card or purchase a three-day ticket. , Dublinbikes had over 66,000 long-term subscribers making over 2 million journeys per year.

Heuston and Connolly stations are the two main railway termini in Dublin. Operated by Iarnród Éireann, the Dublin Suburban Rail network consists of five railway lines serving the Greater Dublin Area and commuter towns such as Drogheda and Dundalk in County Louth, Gorey in County Wexford, and extending as far as Portlaoise and once a day, Newry. One of the five lines is the electrified Dublin Area Rapid Transit (DART) line, which runs primarily along the coast of Dublin, comprising 31 stations, from Malahide and Howth southwards as far as Greystones in County Wicklow. Commuter rail operates on the other four lines using Irish Rail diesel multiple units. In 2013, passengers for DART and Dublin Suburban lines were 16 million and 11.7 million, respectively (around 75% of all Irish Rail passengers).

Dublin once had an extensive system of trams but this was largely phased out by 1949. A new light rail system, often described as a tram system, the Luas, was launched in 2004, and is run by Transdev Ireland (under contract from Transport Infrastructure Ireland), carrying over 34 million passengers annually. The network consists of two interconnecting lines; the Red Line links the Docklands and city centre with the south-western suburbs of Tallaght and Saggart, while the Green Line connects northern inner city suburbs and the main city centre with suburbs to the south of the city including Sandyford and Brides Glen. Together these lines comprise a total 67 stations and of track. Construction of a 6 km extension to the Green Line, bringing it into the north of the city, commenced in June 2013 and was opened for passenger travel on 9 December 2017.

A metro service is proposed under the name of Metrolink, and planned to run from Dublin's northside to Sandyford via Dublin Airport and St. Stephen's Green, with construction projected to start after 2021.

Dublin Connolly is connected by bus to Dublin Port and ferries run by Irish Ferries and Stena Line to Holyhead for connecting trains on the North Wales Coast Line to Chester, Crewe and London Euston. Dublin Connolly to Dublin Port can be reached via Amiens Street, Dublin into Store Street or by Luas via Busáras where Dublin Bus operates services to the Ferry Terminal.

Dublin Airport (owned and operated by DAA) is located north of Dublin city, near Swords in the administrative county of Fingal. The headquarters of Ireland's flag carrier Aer Lingus and regional airlines Stobart Air and CityJet are located there, and those of low-cost carrier Ryanair nearby. The airport offers a short and medium haul network, domestic services to regional airports in Ireland, and long-haul services to the United States, Canada, the Middle East and Hong Kong. Dublin Airport is the 11th busiest in the European Union, and by far the busiest airport on the island of Ireland.

In 2014, Dublin Airport was the 18th busiest airport in Europe, serving over 21 million passengers. By 2016 this increased to 27.9 million passengers passing through the airport, establishing an all-time record supported by growth in both short- and long-haul networks. In 2015 and 2016, transatlantic traffic grew, with 158 summer flights a week to North America, making it the sixth largest European hub for that route over the year. Transatlantic traffic was also the fastest-growing segment of the market for the airport in 2016, in which a 16% increase from 2015 brought the yearly number of passengers travelling between Dublin and North America to 2.9 million.

From 2010 to 2016, Dublin Airport saw an increase of nearly 9.5 million passengers in its annual traffic, as the number of commercial aircraft movements has similarly followed a growth trend from 163,703 in 2013 to 191,233 in 2015.

Dublin is also served by Weston Airport and other small facilities, by a range of helicopter operators, and the military and some State services use Casement Aerodrome nearby.

Dublin is the largest centre of education in Ireland, and is home to four universities and a number of other higher education institutions. It was the European Capital of Science in 2012.

The University of Dublin is the oldest university in Ireland, dating from the 16th century, and is located in the city centre. Its sole constituent college, Trinity College (TCD), was established by Royal Charter in 1592 under Elizabeth I. It was closed to Roman Catholics until 1793, and the Catholic hierarchy then banned Roman Catholics from attending until 1970. It is situated in the city centre, on College Green, and has over 18,000 students.

The National University of Ireland (NUI) has its seat in Dublin, which is also the location of the associated "constituent university" of University College Dublin (UCD), which has over 30,000 students. Founded in 1854, it is now the largest university in Ireland. UCD's main campus is at Belfield, about from the city centre, in the southeastern suburbs.

As of 2019, Dublin's principal, and Ireland's largest, institution for technological education and research, Dublin Institute of Technology (DIT), with origins in 1887, has merged with two major suburban third level institutions, Institute of Technology, Tallaght and Institute of Technology, Blanchardstown, to form Technological University Dublin, Ireland's second largest university by student population. The new university offers a wide range of courses in areas include engineering, architecture, the sciences, health, journalism, digital media, hospitality, business, art and design, music and the humanities programmes, and has three long-term campuses, at Grangegorman, Tallaght and Blanchardstown.

Dublin City University (DCU), formerly the National Institute for Higher Education (NIHE) Dublin, offers courses in business, engineering, science, communication courses, languages and primary education. It has around 16,000 students, and its main campus is located about from the city centre, in the northern suburbs. Aside from the main Glasnevin Campus, the Drumcondra campus includes the former St Patrick's College of Education, now also hosting students from the nearby Mater Dei Institute and students from the Church of Ireland College of Education.

The Royal College of Surgeons in Ireland (RCSI) conducts a medical school which is a recognised college of the NUI, and is situated at St. Stephen's Green in the city centre; there are also large medical schools within UCD and Trinity College. The National College of Art and Design (NCAD) provides education and research in art, design and media. The National College of Ireland (NCI) is also based in Dublin, as well as the Economic and Social Research Institute, a social science research institute, on Sir John Rogerson's Quay, and the Dublin Institute for Advanced Studies.

Dublin is also home to the Royal Irish Academy, membership of which is considered Ireland's highest academic honour.

The Institute of International and European Affairs is also in Dublin. Dublin Business School (DBS) is Ireland's largest private third level institution with over 9,000 students located on Aungier Street, and Griffith College Dublin has its main facility in Portobello. There are also smaller specialised colleges, including The Gaiety School of Acting and the New Media Technology College.

The Irish public administration and management training centre has its base in Dublin, the Institute of Public Administration provides a range of undergraduate and post graduate awards via the National University of Ireland and in some instances, Queen's University Belfast.

The suburban town of Dún Laoghaire is home to the Dún Laoghaire Institute of Art, Design and Technology (IADT), which supports training and research in art, design, business, psychology and media technology.

The City of Dublin is the area administered by Dublin City Council, but the term "Dublin" is also used to refer to the contiguous urban area which includes parts of the adjacent local authority areas of Dún Laoghaire–Rathdown, Fingal and South Dublin. Together, the four areas form the traditional County Dublin. This area is sometimes known as the Dublin Region. The population of the administrative area controlled by the City Council was 554,554 in the 2016 census, while the population of the urban area was 1,173,179. The County Dublin population was 1,273,069 and that of the Greater Dublin Area 1,904,806. The area's population is expanding rapidly, and it is estimated by the Central Statistics Office that it will reach 2.1 million by 2020.

After World War Two, Italians were by far the largest immigrant group in both Dublin and Ireland and became synonymous with the catering and restaurant landscape. Since the late 1990s, Dublin has experienced a significant level of net immigration, with the greatest numbers coming from the European Union, especially the United Kingdom, Poland and Lithuania. There is also immigration from outside Europe, including from Brazil, India, the Philippines, China and Nigeria. Dublin is home to a greater proportion of newer arrivals than any other part of the country. Sixty percent of Ireland's Asian population lives in Dublin. Over 15% of Dublin's population was foreign-born in 2006.

The capital attracts the largest proportion of non-Catholic migrants from other countries. Increased secularisation in Ireland has prompted a drop in regular Catholic church attendance in Dublin from over 90 percent in the mid-1970s down to 14 percent according to a 2011 survey.

According to the 2016 census, the population of Dublin was 86.2% white (including 862,381 white Irish [86.2%], 132,846 other white [13.2%] and 5,092 [0.5%] white Irish traveller), 2% black (23,892), and 4.6% Asian (46,626). Additionally, 2.7% (27,412) are from other ethnic or cultural background, while 4.9% (49,092) did not state their ethnicity. In terms of religion, 68.2% identified as Catholic, 12.7% as other stated religions, with 19.1% having no religion or no religion stated.

, there were 1,367 families within the Dublin region living in homeless accommodation or other emergency housing.

Dublin has a significant literary history, and produced many literary figures, including Nobel laureates William Butler Yeats, George Bernard Shaw and Samuel Beckett. Other influential writers and playwrights include Oscar Wilde, Jonathan Swift and the creator of Dracula, Bram Stoker. It is also the location of key and notable works of James Joyce, including "Ulysses", which is set in Dublin and includes much topical detail. "Dubliners" is a collection of short stories by Joyce about incidents and typical characters of the city during the early 20th century. Other renowned writers include J. M. Synge, Seán O'Casey, Brendan Behan, Maeve Binchy, John Banville and Roddy Doyle. Ireland's biggest libraries and literary museums are found in Dublin, including the National Print Museum of Ireland and National Library of Ireland. In July 2010, Dublin was named as a UNESCO City of Literature, joining Edinburgh, Melbourne and Iowa City with the permanent title.

There are several theatres within the city centre, and various well-known actors have emerged from the Dublin theatrical scene, including Noel Purcell, Michael Gambon, Brendan Gleeson, Stephen Rea, Colin Farrell, Colm Meaney and Gabriel Byrne. The best known theatres include the Gaiety, Abbey, Olympia, Gate, and Grand Canal. The Gaiety specialises in musical and operatic productions, and also opens its doors after the evening theatre production to host a variety of live music, dancing, and films. The Abbey was founded in 1904 by a group that included Yeats with the aim of promoting indigenous literary talent. It went on to provide a breakthrough for some of the city's most famous writers, such as Synge, Yeats himself and George Bernard Shaw. The Gate was founded in 1928 to promote European and American Avant Garde works. The Grand Canal Theatre is a newer 2,111 capacity theatre which opened in 2010 in the Grand Canal Dock area.

Apart from being the focus of the country's literature and theatre, Dublin is also the focal point for much of Irish art and the Irish artistic scene. The Book of Kells, a world-famous manuscript produced by Celtic monks in AD 800 and an example of Insular art, is on display in Trinity College. The Chester Beatty Library houses a collection of manuscripts, miniature paintings, prints, drawings, rare books and decorative arts assembled by American mining millionaire (and honorary Irish citizen) Sir Alfred Chester Beatty (1875–1968). The collections date from 2700 BC onwards and are drawn from Asia, the Middle East, North Africa and Europe.
In addition public art galleries are found across the city and are free to visit, including the Irish Museum of Modern Art, the National Gallery, the Hugh Lane Municipal Gallery, the Douglas Hyde Gallery, the Project Arts Centre and the exhibition space of the Royal Hibernian Academy. Private galleries in Dublin include Green on Red Gallery, Kerlin Gallery, Kevin Kavanagh Gallery and Mother's Tankstation.

Three branches of the National Museum of Ireland are located in Dublin: Archaeology in Kildare Street, Decorative Arts and History in Collins Barracks and Natural History in Merrion Street. The same area is also home to a number of smaller museums such as Number 29 on Fitzwilliam Street and the Little Museum of Dublin on St. Stephen's Green. Dublin is home to the National College of Art and Design, which dates from 1746, and Dublin Institute of Design, founded in 1991. Dublinia is a living history attraction showcasing the Viking and Medieval history of the city.

Dublin has long had an 'underground' arts scene, with Temple Bar hosting artists in the 1980s, and spaces such as the Project Arts Centre acting as a hub for collectives and new exhibitions. "The Guardian" noted that Dublin's independent and underground arts flourished during the economic recession of c.2010. Dublin also has many dramatic, musical and operatic companies, including Festival Productions, Lyric Opera Productions, the Pioneers' Musical & Dramatic Society, the Glasnevin Musical Society, Third Day Chorale, Second Age Theatre Company, Opera Theatre Company and Opera Ireland.

Dublin was shortlisted to be World Design Capital 2014. Taoiseach Enda Kenny was quoted to say that Dublin "would be an ideal candidate to host the World Design Capital in 2014".

Dublin has a vibrant nightlife and is reputedly one of Europe's most youthful cities, with an estimate of 50% of citizens being younger than 25. There are many pubs across the city centre, with the area around St. Stephen's Green and Grafton Street, especially Harcourt Street, Camden Street, Wexford Street and Leeson Street, the location of many nightclubs and pubs.

The best known area for nightlife is Temple Bar, south of the River Liffey. The area has become popular among tourists, including stag and hen parties from Britain. It was developed as Dublin's cultural quarter and does retain this spirit as a centre for small arts productions, photographic and artists' studios, and in the form of street performers and small music venues; however, it has been criticised as overpriced, false and dirty by Lonely Planet. The areas around Leeson Street, Harcourt Street, South William Street and Camden/George's Street are popular nightlife spots for locals.

Live music is played on streets and at venues throughout Dublin, and the city has produced several musicians and groups of international success, including The Dubliners, Thin Lizzy, The Boomtown Rats, U2, The Script, Sinéad O'Connor, Boyzone, Kodaline and Westlife. Dublin has several mid-range venues that host live music throughout the week, including Whelans and Vicar Street. The 3Arena venue in the Dublin Docklands plays host to visiting global performers.

Dublin city centre is a popular shopping destination for both locals and tourists. The city has numerous shopping districts, particularly around Grafton Street and Henry Street. The city centre is also the location of large department stores, including Arnotts, Brown Thomas and (prior to its 2015 closure) Clerys.

While the city has seen the loss of some traditional market sites, Moore Street remains one of the city's oldest trading districts. There has also been some growth in local farmers' markets and other markets. In 2007, Dublin Food Co-op relocated to a warehouse in The Liberties area, where it is home to market and community events. Suburban Dublin has several modern retail centres, including Dundrum Town Centre, Blanchardstown Centre, the Square in Tallaght, Liffey Valley Shopping Centre in Clondalkin, Omni Shopping Centre in Santry, Nutgrove Shopping Centre in Rathfarnham, and Swords Pavilions in Swords.

Dublin is the centre of both media and communications in Ireland, with many newspapers, radio stations, television stations and telephone companies based there. RTÉ is Ireland's national state broadcaster, and is based in Donnybrook. Fair City is RTÉ's soap opera, located in the fictional Dublin suburb of "Carraigstown".

Virgin Media Television, eir Sport, MTV Ireland and Sky News are also based in the city. The headquarters of An Post and telecommunications companies such as Eir, as well as mobile operators Vodafone and 3 are all located there. Dublin is also the headquarters of national newspapers such as "The Irish Times" and "Irish Independent", as well as local newspapers such as "The Evening Herald".

As well as being home to RTÉ Radio, Dublin also hosts the national radio networks Today FM and Newstalk, and local stations. Commercial radio stations based in the city include 4fm (94.9 MHz), Dublin's 98FM (98.1 MHz), Radio Nova 100FM (100.3 MHz), Q102 (102.2 MHz), SPIN 1038 (103.8 MHz), FM104 (104.4 MHz), Sunshine 106.8 (106.8 MHz). There are also numerous community and special interest stations, including Dublin City FM (103.2 MHz), Dublin South FM (93.9 MHz), Liffey Sound FM (96.4 MHz), Near FM (90.3 MHz), and Raidió Na Life (106.4 MHz).

Croke Park is the largest sport stadium in Ireland. The headquarters of the Gaelic Athletic Association, it has a capacity of 82,300. It is the third-largest stadium in Europe after Nou Camp in Barcelona and Wembley Stadium in London. It hosts the premier Gaelic football and hurling games, international rules football and irregularly other sporting and non-sporting events including concerts. Muhammad Ali fought there in 1972 and it played host to the opening and closing ceremonies of the 2003 Special Olympics. It also has conference and banqueting facilities. There is a GAA Museum there and tours of the stadium are offered, including a rooftop walk of the stadium. During the redevelopment of Lansdowne Road, Croke Park played host to the Irish Rugby Union Team and Republic of Ireland national football team as well as hosting the Heineken Cup rugby 2008–09 semi-final between Munster and Leinster which set a world record attendance for a club rugby match. The Dublin GAA team plays most of their home league hurling games at Parnell Park.

I.R.F.U. Stadium Lansdowne Road was laid out in 1874. This was the venue for home games of both the Irish Rugby Union Team and the Republic of Ireland national football team. A joint venture between the Irish Rugby Football Union, the FAI and the Government, saw it redeveloped into a new state-of-the-art 50,000 seat Aviva Stadium, which opened in May 2010. Aviva Stadium hosted the 2011 UEFA Europa League Final. Rugby union team Leinster Rugby play their competitive home games in the RDS Arena & the Aviva Stadium while Donnybrook Stadium hosts their friendlies and A games, Ireland A and Women, Leinster Schools and Youths and the home club games of All Ireland League clubs Old Wesley and Bective Rangers. County Dublin is home for 13 of the senior rugby union clubs in Ireland including 5 of the 10 sides in the top division 1A.

County Dublin is home to six League of Ireland association football (soccer) clubs; Bohemians F.C., Shamrock Rovers, St Patrick's Athletic, University College Dublin, Shelbourne and Cabinteely. The first Irish side to reach the group stages of a European competition (2011–12 UEFA Europa League group stage) are Shamrock Rovers, who play at Tallaght Stadium in South Dublin. Bohemian F.C play at Dalymount Park, the oldest football stadium in the country, and home ground for the Ireland football team from 1904 to the 1970s. St Patrick's Athletic play at Richmond Park; University College Dublin at the UCD Bowl in Dún Laoghaire–Rathdown; and Shelbourne at Tolka Park. Tolka Park, Dalymount Park, UCD Bowl and Tallaght Stadium, along with the Carlisle Grounds in Bray, hosted all Group 3 games in the intermediary round of the 2011 UEFA Regions' Cup.

Dublin has two ODI cricket grounds in Castle Avenue and Malahide Cricket Club Ground. The Castle Avenue hosted its first One Day International match on 21 May 1999 as part of the 1999 Cricket World Cup when Bangladesh played against the West Indies. College Park has Test status and played host to Ireland's first Test cricket match, a women's match against Pakistan in 2000. The men's Irish cricket team also played their first Test match against Pakistan at Malahide Cricket Club Ground during 2018. Leinster Lightning play their home inter-provincial matches in Dublin at College Park.

The Dublin Marathon has been run since 1980 at the end of October. The Women's Mini Marathon has been run since 1983 on the first Monday in June, which is also a bank holiday in Ireland. It is said to be the largest all female event of its kind in the world. The Great Ireland Run takes place in Dublin's Phoenix Park in mid-April.

The Dublin area hosts greyhound racing at Shelbourne Park and horse racing at Leopardstown. The Dublin Horse Show takes place at the RDS, which hosted the Show Jumping World Championships in 1982. The national boxing arena is located in The National Stadium on the South Circular Road. The National Basketball Arena is located in Tallaght, is the home of the Irish basketball team, the venue for the basketball league finals, and has also hosted boxing and wrestling events. The National Aquatic Centre in Blanchardstown is Ireland's largest indoor water leisure facility. There are also Gaelic Handball, hockey and athletics stadia, most notably Morton Stadium in Santry, which held the athletics events of the 2003 Special Olympics.

As of the 2018 Michelin Guide, five Dublin restaurants shared six Michelin stars – including Restaurant Patrick Guilbaud with two. Irish-born Kevin Thornton was awarded two Michelin stars in 2001 – though his restaurant, Thornton's, closed in 2016. The Dublin Institute of Technology commenced a bachelor's degree in culinary skills in 1999.

Historically, Irish coffee houses and cafes were associated with those working in media. Since the beginning of the 21st century, with the growth of apartment living in the city, Dublin's cafés attracted younger patrons looking for an informal gathering place and an ad hoc office. Cafés became more popular in the city, and Irish-owned coffee chains like Java Republic, Insomnia, and O'Brien's Sandwich Bars now compete internationally. In 2008, Irish barista Stephen Morrissey won the title of World Barista Champion.

There are 12,950 students in the Dublin region attending 34 gaelscoileanna (Irish-language primary schools) and 10 gaelcholáistí (Irish-language secondary schools). Two Irish language radio stations Raidió Na Life and RTÉ Raidió na Gaeltachta have studios in the city, and the online and DAB station Raidió Rí-Rá broadcasts from studios in the city. A number of Irish language agencies are also located in the capital. Conradh na Gaeilge offers language classes, has a book shop and is a meeting place for different groups. The closest Gaeltacht to Dublin is the County Meath Gaeltacht of Ráth Cairn and Baile Ghib which is away.

Dublin city council has an International Relations Unit, established in 2007. It works on hosting of international delegations, staff exchanges, international promotion of the city, twinning and partnerships, work with multi-city organisations such as Eurocities, economic partnerships and advice to other Council units. 

Dublin is twinned with four places:
The city also has "friendship" or "co-operation agreements" with a number of other cities: Moscow (2009−) and St Petersburg (2010−) in Russia and Guadalajara in Mexico (2013−), and has previously proposed an agreement with Rio de Janeiro also. Previous agreements have included those with Mexico City (2014−2018), Tbilisi in Georgia (2014−2017) and Wuhan in China (2016−2019).





</doc>
<doc id="8506" url="https://en.wikipedia.org/wiki?curid=8506" title="DirectX">
DirectX

Microsoft DirectX is a collection of application programming interfaces (APIs) for handling tasks related to multimedia, especially game programming and video, on Microsoft platforms. Originally, the names of these APIs all began with "Direct", such as Direct3D, DirectDraw, DirectMusic, DirectPlay, DirectSound, and so forth. The name "DirectX" was coined as a shorthand term for all of these APIs (the "X" standing in for the particular API names) and soon became the name of the collection. When Microsoft later set out to develop a gaming console, the "X" was used as the basis of the name Xbox to indicate that the console was based on DirectX technology. The "X" initial has been carried forward in the naming of APIs designed for the Xbox such as XInput and the Cross-platform Audio Creation Tool (XACT), while the DirectX pattern has been continued for Windows APIs such as Direct2D and DirectWrite.

Direct3D (the 3D graphics API within DirectX) is widely used in the development of video games for Microsoft Windows and the Xbox line of consoles. Direct3D is also used by other software applications for visualization and graphics tasks such as CAD/CAM engineering. As Direct3D is the most widely publicized component of DirectX, it is common to see the names "DirectX" and "Direct3D" used interchangeably.

The DirectX software development kit (SDK) consists of runtime libraries in redistributable binary form, along with accompanying documentation and headers for use in coding. Originally, the runtimes were only installed by games or explicitly by the user. Windows 95 did not launch with DirectX, but DirectX was included with Windows 95 OEM Service Release 2. Windows 98 and Windows NT 4.0 both shipped with DirectX, as has every version of Windows released since. The SDK is available as a free download. While the runtimes are proprietary, closed-source software, source code is provided for most of the SDK samples. Starting with the release of Windows 8 Developer Preview, DirectX SDK has been integrated into Windows SDK.

In late 1994, Microsoft was ready to release Windows 95, its next operating system. An important factor in the value consumers would place on it was the programs that would be able to run on it. Three Microsoft employees—Craig Eisler, Alex St. John, and Eric Engstrom—were concerned because programmers tended to see Microsoft's previous operating system, MS-DOS, as a better platform for game programming, meaning few games would be developed for Windows 95 and the operating system would not be as much of a success. This was compounded by negative reception surrounding the Windows port of the video game "The Lion King". The game used WinG, which crashed on Compaq Presarios that came shipped with it following a partnership between Compaq and Disney, as the Cirrus Logic display drivers used by the Presarios were not thoroughly tested with the API.

DOS allowed direct access to video cards, keyboards, mice, sound devices, and all other parts of the system, while Windows 95—with its protected memory model—restricted access to all of these, working on a much more standardized model. Microsoft needed a quick solution for programmers; the operating system was only months away from being released. Eisler (development lead), St. John, and Engstrom (program manager) worked together to fix this problem, with a solution that they eventually named DirectX.

The first version of DirectX was released in September 1995 as the Windows Games SDK. It was the Win32 replacement for the DCI and WinG APIs for Windows 3.1. DirectX allowed all versions of Microsoft Windows, starting with Windows 95, to incorporate high-performance multimedia. Eisler wrote about the frenzy to build DirectX 1 through 5 in his blog.

DirectX 2.0 became a component of Windows itself with the releases of Windows 95 OSR2 and Windows NT 4.0 in mid-1996. Since Windows 95 was itself still new and few games had been released for it, Microsoft engaged in heavy promotion of DirectX to developers who were generally distrustful of Microsoft's ability to build a gaming platform in Windows. Alex St. John, the evangelist for DirectX, staged an elaborate event at the 1996 Computer Game Developers Conference which game developer Jay Barnson described as a Roman theme, including real lions, togas, and something resembling an indoor carnival. It was at this event that Microsoft first introduced Direct3D and DirectPlay, and demonstrated multiplayer "MechWarrior 2" being played over the Internet.

The DirectX team faced the challenging task of testing each DirectX release against an array of computer hardware and software. A variety of different graphics cards, audio cards, motherboards, CPUs, input devices, games, and other multimedia applications were tested with each beta and final release. The DirectX team also built and distributed tests that allowed the hardware industry to confirm that new hardware designs and driver releases would be compatible with DirectX.

Prior to DirectX, Microsoft had included OpenGL on their Windows NT platform. At the time, OpenGL required "high-end" hardware and was focused on engineering and CAD uses. Direct3D was intended to be a Microsoft controlled alternative to OpenGL, focused initially on game use. As 3D gaming grew, OpenGL developed to include better support for programming techniques for interactive multimedia applications like games, giving developers choice between using OpenGL or Direct3D as the 3D graphics API for their applications. At that point a "battle" began between supporters of the cross-platform OpenGL and the Windows-only Direct3D. Incidentally, OpenGL was supported at Microsoft by the DirectX team. If a developer chose to use OpenGL 3D graphics API, the other APIs of DirectX are often combined with OpenGL in computer games because OpenGL does not include all of DirectX's functionality (such as sound or joystick support).

In a console-specific version, DirectX was used as a basis for Microsoft's Xbox, Xbox 360 and Xbox One console API. The API was developed jointly between Microsoft and Nvidia, which developed the custom graphics hardware used by the original Xbox. The Xbox API was similar to DirectX version 8.1, but is non-updateable like other console technologies. The Xbox was code named DirectXbox, but this was shortened to Xbox for its commercial name.

In 2002, Microsoft released DirectX 9 with support for the use of much longer shader programs than before with pixel and vertex shader version 2.0. Microsoft has continued to update the DirectX suite since then, introducing Shader Model 3.0 in DirectX 9.0c, released in August 2004.

As of April 2005, DirectShow was removed from DirectX and moved to the Microsoft Platform SDK instead.

DirectX has been confirmed to be present in Microsoft's Windows Phone 8.

Real-time raytracing was announced as DXR in 2018.

The original logo resembled a deformed radiation warning symbol. Controversially, the original name for the DirectX project was the "Manhattan Project", a reference to the US nuclear weapons initiative. Alex St. John, head of Microsoft DirectX evangelism at the time, claims that the connotation of the ultimate outcome of the Manhattan Project (the nuclear bombing of Japan) is intentional, and that DirectX and its sister project, the Xbox (which shares a similar logo), were meant to displace Japanese videogame-makers from their dominance of the video game industry. However, Microsoft publicly denies this account, instead claiming that the logo is merely an artistic design.

DirectX is composed of multiple APIs:


Microsoft has deprecated the following components:

DirectX functionality is provided in the form of COM-style objects and interfaces. Additionally, while not DirectX components themselves, managed objects have been built on top of some parts of DirectX, such as Managed Direct3D and the XNA graphics library on top of Direct3D 9.

Microsoft distributes debugging tool for DirectX called "PIX". 

DirectX 9 was released in 2002 for Windows 98 and XP, and currently is supported by all subsequent versions. Microsoft continues to make changes in DirectX 9.0c, causing support to be dropped for some of the aforementioned operating systems. As of January 2007, Windows 2000 or XP is required. This also introduced Shader Model 2.0 containing Pixel Shader 2.0 and Vertex Shader 2.0. Windows XP SP2 and newer include DirectX 9.0c, but may require a newer DirectX runtime redistributable installation for DirectX 9.0c applications compiled with the February 2005 DirectX 9.0 SDK or newer.

A major update to DirectX API, DirectX 10 ships with and is only available with Windows Vista and later; previous versions of Windows such as Windows XP are not able to run DirectX 10-exclusive applications. Rather, programs that are run on a Windows XP system with DirectX 10 hardware simply resort to the DirectX 9.0c code path, the latest available for Windows XP computers.

Changes for DirectX 10 were extensive. Many former parts of DirectX API were deprecated in the latest DirectX SDK and are preserved for compatibility only: DirectInput was deprecated in favor of XInput, DirectSound was deprecated in favor of the Cross-platform Audio Creation Tool system (XACT) and additionally lost support for hardware accelerated audio, since the Vista audio stack renders sound in software on the CPU. The DirectPlay DPLAY.DLL was also removed and was replaced with dplayx.dll; games that rely on this DLL must duplicate it and rename it to dplay.dll.

In order to achieve backwards compatibility, DirectX in Windows Vista contains several versions of Direct3D:
Direct3D 10.1 is an incremental update of Direct3D 10.0 which shipped with, and required, Windows Vista Service Pack 1. This release mainly sets a few more image quality standards for graphics vendors, while giving developers more control over image quality. It also adds support for cube map arrays, separate blend modes per-MRT, coverage mask export from a pixel shader, ability to run pixel shader per sample, access to multi-sampled depth buffers and requires that the video card supports Shader Model 4.1 or higher and 32-bit floating-point operations. Direct3D 10.1 still fully supports Direct3D 10 hardware, but in order to utilize all of the new features, updated hardware is required.

Microsoft unveiled DirectX 11 at the Gamefest 08 event in Seattle, with the major scheduled features including GPGPU support (DirectCompute), and Direct3D 11 with tessellation support and improved multi-threading support to assist video game developers in developing games that better utilize multi-core processors. Direct3D 11 runs on Windows Vista, Windows 7, Windows 8 and Windows 10. Parts of the new API such as multi-threaded resource handling can be supported on Direct3D 9/10/10.1-class hardware. Hardware tessellation and Shader Model 5.0 require Direct3D 11 supporting hardware. Microsoft has since released the Direct3D 11 Technical Preview. Direct3D 11 is a strict superset of Direct3D 10.1 — all hardware and API features of version 10.1 are retained, and new features are added only when necessary for exposing new functionality. This helps to keep backwards compatibility with previous versions of DirectX.

Microsoft released the Final Platform Update for Windows Vista on October 27, 2009, which was 5 days after the initial release of Windows 7 (launched with Direct3D 11 as a base standard).

Since then, four updates for DirectX 11 were released:

DirectX 12 was announced by Microsoft at GDC on March 20, 2014, and was officially launched alongside Windows 10 on July 29, 2015.

The primary feature highlight for the new release of DirectX was the introduction of advanced low-level programming APIs for Direct3D 12 which can reduce driver overhead. Developers are now able to implement their own command lists and buffers to the GPU, allowing for more efficient resource utilization through parallel computation. Lead developer Max McMullen stated that the main goal of Direct3D 12 is to achieve "console-level efficiency on phone, tablet and PC". The release of Direct3D 12 comes alongside other initiatives for low-overhead graphics APIs including AMD's Mantle for AMD graphics cards, Apple's Metal for iOS and macOS and Khronos Group's cross-platform Vulkan.

Multiadapter support will feature in DirectX 12 allowing developers to utilize multiple GPUs on a system simultaneously; multi-GPU support was previously dependent on vendor implementations such as AMD CrossFireX or NVIDIA SLI.

DirectX 12 is supported on all Fermi and later Nvidia GPUs, on AMD's GCN-based chips and on Intel's Haswell and later processors' graphics units.

At SIGGRAPH 2014, Intel released a demo showing a computer generated asteroid field, in which DirectX 12 was claimed to be 50–70% more efficient than DirectX 11 in rendering speed and CPU power consumption.

"Ashes of the Singularity" was the first publicly available game to utilize DirectX 12. Testing by "Ars Technica" in August 2015 revealed slight performance regressions in DirectX 12 over DirectX 11 mode for the Nvidia GeForce 980 Ti, whereas the AMD Radeon R9 290x achieved consistent performance improvements of up to 70% under DirectX 12, and in some scenarios the AMD outperformed the more powerful Nvidia under DirectX 12. The performance discrepancies may be due to poor Nvidia driver optimizations for DirectX 12, or even hardware limitations of the card which was optimized for DirectX 11 serial execution, however the exact cause remains unclear.

DirectX 12 APIs are also featured on the Xbox, however the DirectX 12 code is not directly portable between PC and Xbox One due to inherent differences between the two platforms. The performance improvements of DirectX 12 on the Xbox are not as substantial as on the PC.

In March 2018, DirectX Raytracing (DXR) was announced, capable of real-time ray-tracing on supported hardware, and the DXR API was added in the Windows 10 October 2018 update.

In 2019 Microsoft announced the arrival of DirectX 12 to Windows 7 but only as plug-in for certain game titles.

Microsoft revealed DirectX 12 Ultimate in March 2020. DirectX 12 Ultimate will unify common library on both Windows 10 computers and on the Xbox Series X and other fourth-generation Xbox consoles. Among new features in Ultimate includes DirectX Raytracing 1.1, Variable Rate Shading which gives programmers control over the level of detail of shading depending on design choices, Mesh Shaders, and Sampler Feedback.

The version number as reported by Microsoft's DxDiag tool (version 4.09.0000.0900 and higher) use the x.xx.xxxx.xxxx format for version numbers. However, the DirectX and Windows XP MSDN page claims that the registry always has been in the x.xx.xx.xxxx format. Therefore, when the above table lists a version as '4.09.00.0904' Microsoft's DxDiag tool may have it as '4.09.0000.0904'.

Various releases of Windows have included and supported various versions of DirectX, allowing newer versions of the operating system to continue running applications designed for earlier versions of DirectX until those versions can be gradually phased out in favor of newer APIs, drivers, and hardware.

APIs such as Direct3D and DirectSound need to interact with hardware, and they do this through a device driver. Hardware manufacturers have to write these drivers for a particular DirectX version's device driver interface (or DDI), and test each individual piece of hardware to make them DirectX compatible. Some hardware devices have only DirectX compatible drivers (in other words, one must install DirectX in order to use that hardware). Early versions of DirectX included an up-to-date library of all of the DirectX compatible drivers currently available. This practice was stopped however, in favor of the web-based Windows Update driver-update system, which allowed users to download only the drivers relevant to their hardware, rather than the entire library.

Prior to DirectX 10, DirectX runtime was designed to be "backward compatible" with older drivers, meaning that newer versions of the APIs were designed to interoperate with older drivers written against a previous version's DDI. The application programmer had to query the available hardware capabilities using a complex system of "cap bits" each tied to a particular hardware feature. Direct3D 7 and earlier would work on any version of the DDI, Direct3D 8 requires a minimum DDI level of 6 and Direct3D 9 requires a minimum DDI level of 7.
However, the Direct3D 10 runtime in Windows Vista cannot run on older hardware drivers due to the significantly updated DDI, which requires a unified feature set and abandons the use of "cap bits".

Direct3D 10.1 introduces "feature levels" 10_0 and 10_1, which allow use of only the hardware features defined in the specified version of Direct3D API. Direct3D 11 adds level 11_0 and "10 Level 9" - a subset of the Direct3D 10 API designed to run on Direct3D 9 hardware, which has three feature levels (9_1, 9_2 and 9_3) grouped by common capabilities of "low", "med" and "high-end" video cards; the runtime directly uses Direct3D 9 DDI provided in all WDDM drivers. Feature level 11_1 has been introduced with Direct3D 11.1.

In 2002, Microsoft released a version of DirectX compatible with the Microsoft .NET Framework, thus allowing programmers to take advantage of DirectX functionality from within .NET applications using compatible languages such as managed C++ or the use of the C# programming language. This API was known as "Managed DirectX" (or MDX for short), and claimed to operate at 98% of performance of the underlying native DirectX APIs. In December 2005, February 2006, April 2006, and August 2006, Microsoft released successive updates to this library, culminating in a beta version called Managed DirectX 2.0. While Managed DirectX 2.0 consolidated functionality that had previously been scattered over multiple assemblies into a single assembly, thus simplifying dependencies on it for software developers, development on this version has subsequently been discontinued, and it is no longer supported. The Managed DirectX 2.0 library expired on October 5, 2006.

During the GDC 2006, Microsoft presented the XNA Framework, a new managed version of DirectX (similar but not identical to Managed DirectX) that is intended to assist development of games by making it easier to integrate DirectX, HLSL and other tools in one package. It also supports the execution of managed code on the Xbox 360. The XNA Game Studio Express RTM was made available on December 11, 2006, as a free download for Windows XP. Unlike the DirectX runtime, Managed DirectX, XNA Framework or the Xbox 360 APIs (XInput, XACT etc.) have not shipped as part of Windows. Developers are expected to redistribute the runtime components along with their games or applications.

No Microsoft product including the latest XNA releases provides DirectX 10 support for the .NET Framework.

The other approach for DirectX in managed languages is to use third-party libraries like:


There are alternatives to the DirectX family of APIs, with OpenGL, its successor Vulkan, Metal and Mantle having the most features comparable to Direct3D. Examples of other APIs include SDL, Allegro, OpenMAX, OpenML, OpenAL, OpenCL, FMOD, SFML etc. Many of these libraries are cross-platform or have open codebases. There are also alternative implementations that aim to provide the same API, such as the one in Wine. Furthermore, the developers of ReactOS are trying to reimplement DirectX under the name "ReactX".




</doc>
<doc id="8508" url="https://en.wikipedia.org/wiki?curid=8508" title="Slalom skiing">
Slalom skiing

Slalom is an alpine skiing and alpine snowboarding discipline, involving skiing between poles or gates. These are spaced more closely than those in giant slalom, super giant slalom and downhill, necessitating quicker and shorter turns. Internationally, the sport is contested at the FIS Alpine World Ski Championships, and at the Olympic Winter Games.

The term may also refer to waterskiing on one ski. 

The term slalom comes from the Morgedal/Seljord (a Norwegian dialect) word "slalåm": "sla", meaning slightly inclining hillside, and "låm", meaning track after skis. The inventors of modern skiing classified their trails according to their difficulty. "Slalåm" was a trail used in Telemark by boys and girls not yet able to try themselves on the more challenging runs. "Ufsilåm" was a trail with one obstacle ("ufse") like a jump, a fence, a difficult turn, a gorge, a cliff (often more than high) and more. "Uvyrdslåm" was a trail with several obstacles. A Norwegian military downhill competition in 1767 included racing downhill among trees "without falling or breaking skis". Sondre Norheim and other skiers from Telemark practiced "uvyrdslåm" or "disrespectful/reckless downhill" where they raced downhill in difficult and untested terrain (i.e., off piste). The 1866 "ski race" in Oslo was a combined cross-country, jumping and slalom competition. In the slalom participants were allowed use poles for braking and steering, and they were given points for style (appropriate skier posture). During the late 1800s Norwegian skiers participated in all branches (jumping, slalom, and cross-country) often with the same pair of skis. Slalom and variants of slalom were often referred to as hill races. Around 1900 hill races are abandoned in the Oslo championships at Huseby and Holmenkollen. Mathias Zdarsky's development of the Lilienfeld binding helped change hill races into a specialty of the Alps region.

The rules for the modern slalom were developed by Arnold Lunn in 1922 for the British National Ski Championships, and adopted for alpine skiing at the 1936 Winter Olympics. Under these rules gates were marked by pairs of flags rather than single ones, were arranged so that the racers had to use a variety of turn lengths to negotiate them, and scoring was on the basis of time alone, rather than on both time and style.

A course is constructed by laying out a series of gates, formed by alternating pairs of red and blue poles. The skier must pass between the two poles forming the gate, with the tips of both skis and the skier's feet passing between the poles. A course has 55 to 75 gates for men and 40 to 60 for women. The vertical drop for a men's course is and slightly less for women. The gates are arranged in a variety of configurations to challenge the competitor.

Because the offsets are relatively small in slalom, ski racers take a fairly direct line and often knock the poles out of the way as they pass, which is known as blocking. (The main blocking technique in modern slalom is cross-blocking, in which the skier takes such a tight line and angulates so strongly that he or she is able to block the gate with the outside hand.) Racers employ a variety of protective equipment, including shin pads, hand guards, helmets and face guards.

Traditionally, bamboo poles were used for gates, the rigidity of which forced skiers to maneuver their entire body around each gate. In the early 1980s, rigid poles were replaced by hard plastic poles, hinged at the base. The hinged gates require, according to FIS rules, only that the skis and boots of the skier go around each gate.

The new gates allow a more direct path down a slalom course through the process of cross-blocking or shinning the gates. Cross-blocking is a technique in which the legs go around the gate with the upper body inclined toward, or even across, the gate; in this case the racer's outside pole and shinguards hit the gate, knocking it down and out of the way. Cross-blocking is done by pushing the gate down with the arms, hands, or shins. By 1989, most of the top technical skiers in the world had adopted the cross-block technique.

With the innovation of shaped skis around the turn of the 21st century, equipment used for slalom in international competition changed drastically. World Cup skiers commonly skied on slalom skis at a length of in the 1980s and 1990s but by the 2002 Olympic Winter Games in Salt Lake City, the majority of competitors were using skis measuring or less.

The downside of the shorter skis was that athletes found that recoveries were more difficult with a smaller platform underfoot. Out of concern for the safety of athletes, the FIS began to set minimum ski lengths for international slalom competition. The minimum was initially set at for men and for women, but was increased to for men and for women for the 2003–2004 season.
The equipment minimums and maximums imposed by the International Ski Federation (FIS) have created a backlash from skiers, suppliers, and fans. The main objection is that the federation is regressing the equipment, and hence the sport, by two decades. 
American Bode Miller hastened the shift to the shorter, more radical sidecut skis when he achieved unexpected success after becoming the first Junior Olympic athlete to adopt the equipment in giant slalom and super-G in 1996. A few years later, the technology was adapted to slalom skis as well.

In the following table men's slalom World Cup podiums in the World Cup since first season in 1967.


</doc>
<doc id="8518" url="https://en.wikipedia.org/wiki?curid=8518" title="Dachshund">
Dachshund

The dachshund ( or ) (German: "badger dog"), also known as the wiener dog, badger dog, or sausage dog, is a short-legged, long-bodied, hound-type dog breed. They may be smooth-haired, wire-haired, or long-haired.

The standard sized dachshund was developed to scent, chase, and flush out badgers and other burrow-dwelling animals, while the miniature dachshund was bred to hunt small animals such as rabbits and mice. In the Western United States, they have also been used to track wounded deer and hunt prairie dogs.

Dachshunds also participate in conformation shows, field trials and many other events organized through pure-bred dog organizations such as the American Kennel Club (AKC). According to the AKC, the dachshund is ranked 12th in popularity among dog breeds in the United States in 2018.

The name "dachshund" is of German origin and literally means "badger dog," from "Dachs" ("European badger") and "Hund" ("hound, dog"). The German word is pronounced . The pronunciation varies in English: variations of the first and second syllables include , and , , . It may be mispronounced as "hound" by some English speakers. Although "dachshund" is a German word, in modern German they are more commonly known by the short name "Dackel" or "Teckel". 

Because of their long, narrow build, they are often nicknamed wiener dog or sausage dog.

While classified in the hound group or scent hound group in the United States and Great Britain, the breed has its own group in the countries which belong to the Fédération Cynologique Internationale (World Canine Federation). Many dachshunds, especially the wire-haired subtype, may exhibit behavior and appearance that are similar to that of the terrier group of dogs. An argument can be made for the scent (or hound) group classification because the breed was developed to use scent to trail and hunt animals, and probably descended from the Saint Hubert Hound like many modern scent hound breeds such as bloodhounds and Basset Hounds; but with the persistent personality and love for digging that probably developed from the terrier, it can also be argued that they could belong in the terrier, or "earth dog", group.

A typical dachshund is long-bodied and muscular with short stubby legs. Its front paws are disproportionately large, being paddle-shaped and particularly suitable for digging. Its skin is loose enough not to tear while tunneling in tight burrows to chase prey. The dachshund has a deep chest which provides appropriate lung capacity for stamina when hunting. Its snout is long. According to the AKC standards for the breed, "scars from honorable wounds shall not be considered a fault" because the dachshund is a hunting dog. 

There are three dachshund coat varieties: smooth coat (short hair), long-haired, and wire-haired. Longhaired dachshunds have a silky coat and short featherings on legs and ears. Wire-haired dachshunds are the least common coat variety in the United States (although it is the most common in Germany) and the most recent coat to appear in breeding standards.
Dachshunds have a wide variety of colors and patterns, the most common one being red. Their base coloration can be single-colored (either red or cream), tan pointed (black and tan, chocolate and tan, blue and tan, or isabella and tan), and in wire-haired dogs, a color referred to as wildboar. Patterns such as dapple (merle), sable, brindle and piebald also can occur on any of the base colors. Dachshunds in the same litter may be born in different coat colors depending on the genetic makeup of the parents. 

The dominant color in the breed is red, followed by black and tan. Tan pointed dogs have tan (or cream) markings over the eyes, ears, paws, and tail. The reds range from coppers to deep rusts, with or without somewhat common black hairs peppered along the back, face and ear edges, lending much character and an almost burnished appearance; this is referred to among breeders and enthusiasts as an "overlay" or "sabling". Sabling should not be confused with a more unusual coat color referred to as sable. At a distance, a sable dachshund looks somewhat like a black and tan dog. Upon closer examination, however, one can observe that along the top of the dog's body, each hair is actually banded with red at the base near the skin transitioning to mostly black along the length of the strand. An additional striking coat marking is the brindle pattern. "Brindle" refers to dark stripes over a solid background—usually red. If a dachshund is brindled on a dark coat and has tan points, it will have brindling on the tan points only. Even one single, lone stripe of brindle is a brindle. If a dachshund has one single spot of dapple, it is a dapple.

The Dachshund Club of America (DCA) and the American Kennel Club (AKC) consider both the piebald pattern and the double dapple (double merle) pattern to be nonstandard. However, both types continue to be shown and sometimes even win in the conformation ring.

Dogs that are double-dappled have the merle pattern of a dapple, but with distinct white patches that occur when the dapple gene expresses itself twice in the same area of the coat. The DCA excluded the wording "double-dapple" from the standard in 2007 and now strictly uses the wording "dapple" as the double dapple gene is commonly responsible for blindness and deafness.

Dachshunds come in three sizes: standard, miniature, and "kaninchen" (German for "rabbit"). Although the standard and miniature sizes are recognized almost universally, the rabbit size is not recognized by clubs in the United States and the United Kingdom. The rabbit size is recognized by the Fédération Cynologique Internationale (World Canine Federation) (FCI), which contain kennel clubs from 83 countries all over the world. An increasingly common size for family pets falls between the miniature and the standard size; these are frequently referred to as "tweenies," which is not an official classification.

A full-grown standard dachshund averages to , while the miniature variety normally weighs less than . The kaninchen weighs to . According to kennel club standards, the miniature (and kaninchen, where recognized) differs from the full-size only by size and weight, thus offspring from miniature parents must never weigh more than the miniature standard to be considered a miniature as well. While many kennel club size divisions use weight for classification, such as the American Kennel Club, other kennel club standards determine the difference between the miniature and standard by chest circumference; some kennel clubs, such as in Germany, even measure chest circumference in addition to height and weight.

H. L. Mencken said that "A dachshund is a half-dog high and a dog-and-a-half long," although they have been referred to as "two dogs long". This characteristic has led them to be quite a recognizable breed, and they are featured in many jokes and cartoons, particularly "The Far Side" by Gary Larson.

Light-colored dachshunds can sport amber, light brown, or green eyes; however, kennel club standards state that the darker the eye color, the better. Dapple and double dapple dachshunds can have multi-coloured “wall” eyes with fully blue, partially blue or patched irises due to the effect of the dapple gene on eye pigmentation expression. “Wall” eye is permissible according to DCA standards but undesirable by AKC standards. Piebald-patterned dachshunds will never have blue in their eyes, unless the dapple pattern is present.

Dachshunds are playful, but as hunting dogs can be quite stubborn, and are known for their propensity for chasing small animals, birds, and tennis balls with great determination and ferocity. Many dachshunds are stubborn, making them a challenge to train.

Dachshunds can be aggressive to strangers and other dogs. Despite this, they are rated in the intelligence of dogs as an average working dog with a persistent ability to follow trained commands 50% of the time or more. They rank 49th in Stanley Coren's "Intelligence of Dogs", being of average working and obedience intelligence.
They can have a loud bark. Some bark quite a lot and may need training to stop, while others will not bark much at all. Dachshunds are known for their devotion and loyalty to their owners, though they can be standoffish towards strangers. If left alone too frequently, some dachshunds are prone to separation anxiety and may chew objects in the house to relieve stress.

Dachshunds are burrowers by nature and are likely to burrow in blankets and other items around the house, when bored or tired.

Dachshunds can be difficult to housebreak, and patience and consistency are often needed in this endeavor.

According to the American Kennel Club's breed standards, "the dachshund is clever, lively and courageous to the point of rashness, persevering in above and below ground work, with all the senses well-developed. Any display of shyness is a serious fault." Their temperament and body language give the impression that they do not know or care about their relatively small size. Like many small hunting dogs, they will challenge a larger dog. Indulged dachshunds may become snappy or extremely obstinate.

Many dachshunds do not like unfamiliar people, and many will growl or bark at them. Although the dachshund is generally an energetic dog, some are sedate. This dog's behavior is such that it is not the dog for everyone. A bored, untrained dachshund will become destructive. If raised improperly and not socialized at a young age, dachshunds can become aggressive or fearful. They require a caring, loving owner who understands their need for entertainment and exercise.

Dachshunds may not be the best pets for small children. Like any dog, dachshunds need a proper introduction at a young age. Well-trained dachshunds and well-behaved children usually get along fine. Otherwise, they may be aggressive and bite an unfamiliar child, especially one that moves quickly around them or teases them. However, many dachshunds are very tolerant and loyal to children within their family, but these children should be mindful of the vulnerability of the breed's back.

A 2008 University of Pennsylvania study of 6,000 dog owners who were interviewed indicated that dogs of smaller breeds were more likely to be "genetically predisposed towards aggressive behaviour". Dachshunds were rated the most aggressive, with 20% having bitten strangers, as well as high rates of attacks on other dogs and their owners. The study noted that attacks by small dogs were unlikely to cause serious injuries and because of this were probably under-reported.

The breed is prone to spinal problems, especially intervertebral disk disease (IVDD), due in part to an extremely long spinal column and short rib cage. The risk of injury may be worsened by obesity, jumping, rough handling, or intense exercise, which place greater strain on the vertebrae. About 20–25% of dachshunds will develop IVDD. Dachshunds with a number of calcified intervertebral discs at a young age have a higher risk of developing disc disease in later life. In addition, studies have shown that development of calcified discs is highly heritable in the breed. An appropriate screening programme for IVDD has been identified by Finnish researchers and a UK IVDD screening programme has been developed for breeders with the aim to reduce prevalence of spinal problems. 

Treatment consists of combinations of crate confinement and courses of anti-inflammatory medications (steroids and non-steroidal anti-inflammatory drugs like carprofen and meloxicam), or chronic pain medications, like tramadol. Serious cases may require surgery to remove the troublesome disk contents. A dog may need the aid of a cart to get around if paralysis occurs.

A minimally invasive procedure called "percutaneous laser disk ablation" has been developed at the Oklahoma State University Veterinary Hospital. Originally, the procedure was used in clinical trials only on dachshunds that had suffered previous back incidents. Since dachshunds are prone to back issues, the goal is to expand this treatment to dogs in a normal population.

In addition to back problems, the breed is prone to patellar luxation where the kneecap can become dislodged. Dachshunds may also be affected by osteogenesis imperfecta (brittle bone disease). The condition seems to be mainly limited to wire-haired Dachshunds, with 17% being carriers. A genetic test is available to allow breeders to avoid breeding carriers to carriers. In such pairings, each puppy will have a 25% chance of being affected.

In some double dapples, there are varying degrees of vision and hearing loss, including reduced or absent eyes. Not all double dapples have problems with their eyes and/or ears, which may include degrees of hearing loss, full deafness, malformed ears, congenital eye defects, reduced or absent eyes, partial or full blindness, or varying degrees of both vision and hearing problems; but heightened problems can occur due to the genetic process in which two dapple genes cross, particularly in certain breeding lines. Dapple genes, which are dominant genes, are considered "dilution" genes, meaning whatever color the dog would have originally carried is lightened, or diluted, randomly; two dominant "dilution" genes can cancel each other out, or "cross", removing all color and producing a white recessive gene, essentially a white mutation. When occurring genetically within the eyes or ears, this white mutation can be detrimental to development, causing hearing or vision problems.

Other dachshund health problems include hereditary epilepsy, granulomatous meningoencephalitis, dental issues, Cushing's syndrome, thyroid and autoimmune problems, various allergies and atopies, and various eye conditions including cataracts, glaucoma, progressive retinal atrophy, corneal ulcers, nonucerative corneal disease, sudden acquired retinal degeneration, and cherry eye. Dachshunds are also 2.5 times more likely than other breeds of dogs to develop patent ductus arteriosus, a congenital heart defect. Dilute color dogs (Blue, Isabella, and Cream) are very susceptible to color dilution alopecia, a skin disorder that can result in hair loss and extreme sensitivity to sun. Since the occurrence and severity of these health problems is largely hereditary, breeders are working to eliminate these.

Factors influencing the litter size of puppies and the proportion of stillborn puppies per litter were analyzed in normally sized German dachshunds. The records analyzed contained data on 42,855 litters. It was found that as the inbreeding coefficient increased, litter size decreased and the percentage of stillborn puppies increased, thus indicating inbreeding depression. It was also found that young and older dams had smaller litter sizes and more stillborn puppies than middle-aged dams.

The dachshund is a creation of German breeders and includes elements of German, French, and English hounds and terriers. Dachshunds have been kept by royal courts all over Europe, including that of Queen Victoria, who was particularly enamored of the breed.

The first verifiable references to the dachshund, originally named the "Dachs Kriecher" ("badger crawler") or "Dachs Krieger" ("badger warrior"), came from books written in the early 18th century. Prior to that, there exist references to "badger dogs" and "hole dogs", but these likely refer to purposes rather than to specific breeds. The original German dachshunds were larger than the modern full-size variety, weighing between , and originally came in straight-legged and crook-legged varieties (the modern dachshund is descended from the latter). Though the breed is famous for its use in exterminating badgers and badger-baiting, dachshunds were also commonly used for rabbit and fox hunting, for locating wounded deer, and in packs were known to hunt game as large as wild boar and as fierce as the wolverine.

There are huge differences of opinion as to when dachshunds were specifically bred for their purpose of badger hunting, as the American Kennel Club states the dachshund was bred in the 15th century, while the Dachshund Club of America states that foresters bred the dogs in the 18th or 19th century.

Double-dapple dachshunds, which are prone to eye disease, blindness, or hearing problems, are generally believed to have been introduced to the United States between 1879 and 1885.

The flap-down ears and famous curved tail of the dachshund have deliberately been bred into the dog. In the case of the ears, this is to keep grass seeds, dirt, and other matter from entering the ear canal. The curved tail is dual-purposed: to be seen more easily in long grass and, in the case of burrowing dachshunds, to help haul the dog out if it becomes stuck in a burrow.
The smooth-haired dachshund, the oldest style, may be a cross between the German Shorthaired Pointer, a Pinscher, and a Bracke (a type of bloodhound), or to have been produced by crossing a short Bruno Jura Hound with a pinscher. Others believe it was a cross from a miniature French pointer and a pinscher; others claim that it was developed from the St. Hubert Hound, also a bloodhound, in the 18th century, and still others believe that they were descended from Basset Hounds, based upon their scent abilities and general appearance. Dachshunds can track a scent that is more than a week old.

The exact origins of the dachshund are therefore unknown. According to William Loeffler, from " The American Book of the Dog (1891)", in the chapter on dachshunds: "The origin of the Dachshund is in doubt, our best authorities disagreeing as to the beginning of the breed." What can be agreed on, however, is that the smooth dachshund gave rise to both the long-haired and the wire-haired varieties.

There are two theories about how the standard long-haired dachshund came about. One theory is that smooth dachshunds would occasionally produce puppies which had slightly longer hair than their parents. By selectively breeding these animals, breeders eventually produced a dog which consistently produced long-haired offspring, and the long-haired dachshund was born. Another theory is that the standard long-haired dachshund was developed by breeding smooth dachshunds with various land and water spaniels. The long-haired dachshund may be a cross among any of the small dog breeds in the spaniel group, including the German Stoeberhund, and the smooth dachshund.

The wire-haired dachshund, the last to develop, was bred in the late 19th century. There is a possibility the wire-haired dachshund was a cross between the smooth dachshund and various hard-coated terriers and wire-haired pinschers, such as the Schnauzer, the Dandie Dinmont Terrier, the German Wirehaired Pointer, or perhaps the Scottish Terrier.

Dachshunds have traditionally been viewed as a symbol of Germany. Political cartoonists commonly used the image of the dachshund to ridicule Germany. During World War I, the dachshunds' popularity in the United States plummeted because of this association. As a result, they were often called "liberty hounds" by their owners similar to "liberty cabbage" becoming a term for sauerkraut mostly in North America. The stigma of the association was revived to a lesser extent during World War II, though it was comparatively short-lived. Kaiser Wilhelm II and German Field Marshal Erwin Rommel were known for keeping dachshunds.

Due to the association of the breed with Germany, as well as its particular popularity among dog keepers in Munich back then, the dachshund was chosen to be the first official mascot for the 1972 Summer Olympics in Munich, with the name Waldi.

Some people train and enter their dachshunds to compete in dachshund races, such as the Wiener Nationals. Several races across the United States routinely draw several thousand attendees, including races in Germantown, Tennessee; Bossier City, Louisiana; Buda, Texas; Davis, California; Phoenix, Arizona; Los Alamitos, California; Findlay, Ohio; Milwaukee, Wisconsin; Oklahoma City, Oklahoma; Kansas City, Kansas; Palo Alto, California; and Shakopee, Minnesota. There is also an annual dachshund run in Kennywood, located in Pittsburgh, Pennsylvania, called the Wiener 100, in Huntington, West Virginia called the Dachshund Dash and in Lovettsville, Virginia as part of the town's annual Oktoberfest celebration.

Despite the popularity of these events, the Dachshund Club of America opposes "wiener racing", as many greyhound tracks use the events to draw large crowds to their facilities. The DCA is also worried about potential injuries to dogs, due to their predisposition to back injuries. Another favorite sport is earthdog trials, in which dachshunds enter tunnels with dead ends and obstacles attempting to locate either an artificial bait or live but caged (and thus protected) rats.

In Germany, dachshunds are widely called "Dackel" (both singular and plural). Among hunters, they are mainly referred to as "Teckel". There are kennels which specialize in breeding hunting dachshunds, the so-called "jagdliche Leistungszucht" ("hunting-related performance breed") or "Gebrauchshundezucht" ("working dog breed"), as opposed to breeding family dogs. Therefore, it is sometimes incorrectly believed that "Teckel" is either a name for the hunting breed or a mark for passing the test for a trained hunting dog (called "VGP", "Verband-Gebrauchsprüfung") in Germany.

Dachshunds are one of the most popular dogs in the United States, ranking 13th in the 2016 AKC registration statistics. They are popular with urban and apartment dwellers, ranking among the top 10 most popular breeds in 76 of 190 major US cities surveyed by the AKC.
One will find varying degrees of organized local dachshund clubs in most major American cities, including New York, New Orleans, Portland, Los Angeles, and Chicago.





</doc>
<doc id="8519" url="https://en.wikipedia.org/wiki?curid=8519" title="Data structure">
Data structure

In computer science, a data structure is a data organization, management, and storage format that enables efficient access and modification. More precisely, a data structure is a collection of data values, the relationships among them, and the functions or operations that can be applied to the data.

Data structures serve as the basis for abstract data types (ADT). The ADT defines the logical form of the data type. The data structure implements the physical form of the data type.

Different types of data structures are suited to different kinds of applications, and some are highly specialized to specific tasks. For example, relational databases commonly use B-tree indexes for data retrieval, while compiler implementations usually use hash tables to look up identifiers.

Data structures provide a means to manage large amounts of data efficiently for uses such as large databases and internet indexing services. Usually, efficient data structures are key to designing efficient algorithms. Some formal design methods and programming languages emphasize data structures, rather than algorithms, as the key organizing factor in software design. Data structures can be used to organize the storage and retrieval of information stored in both main memory and secondary memory.

Data structures are generally based on the ability of a computer to fetch and store data at any place in its memory, specified by a pointer—a bit string, representing a memory address, that can be itself stored in memory and manipulated by the program. Thus, the array and record data structures are based on computing the addresses of data items with arithmetic operations, while the linked data structures are based on storing addresses of data items within the structure itself. 

The implementation of a data structure usually requires writing a set of procedures that create and manipulate instances of that structure. The efficiency of a data structure cannot be analyzed separately from those operations. This observation motivates the theoretical concept of an abstract data type, a data structure that is defined indirectly by the operations that may be performed on it, and the mathematical properties of those operations (including their space and time cost).

There are numerous types of data structures, generally built upon simpler primitive data types:

In addition, "graphs" and "binary trees" are other commonly used data structures.

Most assembly languages and some low-level languages, such as BCPL (Basic Combined Programming Language), lack built-in support for data structures. On the other hand, many high-level programming languages and some higher-level assembly languages, such as MASM, have special syntax or other built-in support for certain data structures, such as records and arrays. For example, the C (a direct descendant of BCPL) and Pascal languages support structs and records, respectively, in addition to vectors (one-dimensional arrays) and multi-dimensional arrays.

Most programming languages feature some sort of library mechanism that allows data structure implementations to be reused by different programs. Modern languages usually come with standard libraries that implement the most common data structures. Examples are the C++ Standard Template Library, the Java Collections Framework, and the Microsoft .NET Framework.

Modern languages also generally support modular programming, the separation between the interface of a library module and its implementation. Some provide opaque data types that allow clients to hide implementation details. Object-oriented programming languages, such as C++, Java, and Smalltalk, typically use classes for this purpose.

Many known data structures have concurrent versions which allow multiple computing threads to access a single concrete instance of a data structure simultaneously.





</doc>
<doc id="8520" url="https://en.wikipedia.org/wiki?curid=8520" title="Dmitri Shostakovich">
Dmitri Shostakovich

Dmitri Dmitriyevich Shostakovich (, ; (9 August 1975) was a Russian composer and pianist. He is regarded as one of the major composers of the 20th century, with a unique harmonic language and a historic importance due to his years of work under Stalin.
Shostakovich achieved fame in the Soviet Union under the patronage of Soviet chief of staff Mikhail Tukhachevsky, but later had a complex and difficult relationship with the government. Nevertheless, he received accolades and state awards and served in the Supreme Soviet of the RSFSR (1947) and the Supreme Soviet of the Soviet Union (from 1962 until his death).
A polystylist, Shostakovich developed a hybrid voice, combining a variety of different musical techniques into his works. His music is characterized by sharp contrasts, elements of the grotesque, and ambivalent tonality; he was also heavily influenced by the neoclassical style pioneered by Igor Stravinsky, and (especially in his symphonies) by the late Romanticism of Gustav Mahler.
Shostakovich's orchestral works include 15 symphonies and six concerti. His chamber output includes 15 string quartets, a piano quintet, two piano trios, and two pieces for string octet. His solo piano works include two sonatas, an early set of preludes, and a later set of 24 preludes and fugues. Other works include three operas, several song cycles, ballets, and a substantial quantity of film music; especially well known is the "Waltz No. 2" from the "Suite for Variety Orchestra", as well as the suite of music extracted from "The Gadfly".

Born at Podolskaya Street in Saint Petersburg, Russia, Shostakovich was the second of three children of Dmitri Boleslavovich Shostakovich and Sofiya Vasilievna Kokoulina. Shostakovich's paternal grandfather, originally surnamed Szostakowicz, was of Polish Roman Catholic descent (his family roots trace to the region of the town of Vileyka in today's Belarus), but his immediate forebears came from Siberia. A Polish revolutionary in the January Uprising of 1863–4, Bolesław Szostakowicz was exiled to Narym (near Tomsk) in 1866 in the crackdown that followed Dmitri Karakozov's assassination attempt on Tsar Alexander II. When his term of exile ended, Szostakowicz decided to remain in Siberia. He eventually became a successful banker in Irkutsk and raised a large family. His son Dmitri Boleslavovich Shostakovich, the composer's father, was born in exile in Narim in 1875 and studied physics and mathematics at Saint Petersburg University, graduating in 1899. He then went to work as an engineer under Dmitri Mendeleev at the Bureau of Weights and Measures in Saint Petersburg. In 1903 he married another Siberian transplant to the capital, Sofiya Vasilievna Kokoulina, one of six children born to a Russian Siberian native.

Their son, Dmitri Dmitriyevich Shostakovich, displayed significant musical talent after he began piano lessons with his mother at the age of nine. On several occasions he displayed a remarkable ability to remember what his mother had played at the previous lesson, and would get "caught in the act" of playing the previous lesson's music while pretending to read different music placed in front of him. In 1918 he wrote a funeral march in memory of two leaders of the Kadet party murdered by Bolshevik sailors.

In 1919, at age 13, Shostakovich was admitted to the Petrograd Conservatory, then headed by Alexander Glazunov, who monitored his progress closely and promoted him. Shostakovich studied piano with Leonid Nikolayev after a year in the class of Elena Rozanova, composition with Maximilian Steinberg, and counterpoint and fugue with Nikolay Sokolov, with whom he became friends. He also attended Alexander Ossovsky's music history classes. Steinberg tried to guide Shostakovich on the path of the great Russian composers, but was disappointed to see him 'wasting' his talent and imitating Igor Stravinsky and Sergei Prokofiev. Shostakovich also suffered for his perceived lack of political zeal, and initially failed his exam in Marxist methodology in 1926. His first major musical achievement was the First Symphony (premiered 1926), written as his graduation piece at the age of 19. This work brought him to the attention of Mikhail Tukhachevsky, who helped Shostakovich find accommodation and work in Moscow, and sent a driver around in "a very stylish automobile" to take him to a concert.

After graduation, Shostakovich initially embarked on a dual career as concert pianist and composer, but his dry playing style was often unappreciated (his American biographer, Laurel Fay, comments on his "emotional restraint" and "riveting rhythmic drive"). He won an "honorable mention" at the First International Chopin Piano Competition in Warsaw in 1927 and attributed the disappointing result to suffering from appendicitis and the jury being all Polish. He had his appendix removed in April 1927. After the competition Shostakovich met the conductor Bruno Walter, who was so impressed by the composer's First Symphony that he conducted it at its Berlin premiere later that year. Leopold Stokowski was equally impressed and gave the work its U.S. premiere the following year in Philadelphia. Stokowski also made the work's first recording.

Shostakovich concentrated on composition thereafter and soon limited his performances primarily to his own works. In 1927 he wrote his Second Symphony (subtitled "To October"), a patriotic piece with a pro-Soviet choral finale. Owing to its experimental nature, as with the subsequent Third Symphony, it was not critically acclaimed with the enthusiasm given to the First.

1927 also marked the beginning of Shostakovich's relationship with Ivan Sollertinsky, who remained his closest friend until the latter's death in 1944. Sollertinsky introduced the composer to Mahler's music, which had a strong influence on Shostakovich from the Fourth Symphony onward.

While writing the Second Symphony, Shostakovich also began work on his satirical opera "The Nose", based on the story by Nikolai Gogol. In June 1929, against the composer's wishes, the opera was given a concert performance; it was ferociously attacked by the Russian Association of Proletarian Musicians (RAPM). Its stage premiere on 18 January 1930 opened to generally poor reviews and widespread incomprehension among musicians.

In the late 1920s and early 1930s, Shostakovich worked at TRAM, a proletarian youth theatre. Although he did little work in this post, it shielded him from ideological attack. Much of this period was spent writing his opera "Lady Macbeth of the Mtsensk District", which was first performed in 1934. It was immediately successful, on both popular and official levels. It was described as "the result of the general success of Socialist construction, of the correct policy of the Party", and as an opera that "could have been written only by a Soviet composer brought up in the best tradition of Soviet culture".

Shostakovich married his first wife, Nina Varzar, in 1932. Difficulties led to a divorce in 1935, but the couple soon remarried when Nina became pregnant with their first child, Galina.

On 17 January 1936, Joseph Stalin paid a rare visit to the opera for a performance of a new work, "Quiet Flows the Don", based on the novel by Mikhail Sholokhov, by the little-known composer Ivan Dzerzhinsky, who was called to Stalin's box at the end of the performance and told that his work had "considerable ideological-political value". On 26 January, Stalin revisited the opera, accompanied by Vyacheslav Molotov, Andrei Zhdanov and Anastas Mikoyan, to hear "Lady Macbeth of the Mtsensk District". He and his entourage left without speaking to anyone. Shostakovich had been forewarned by a friend that he should postpone a planned concert tour in Arkhangelsk in order to be present at that particular performance. Eyewitness accounts testify that Shostakovich was "white as a sheet" when he went to take his bow after the third act. In letters to Sollertinsky, Shostakovich recounted the horror with which he watched as Stalin shuddered every time the brass and percussion played too loudly. Equally horrifying was the way Stalin and his companions laughed at the lovemaking scene between Sergei and Katerina. The next day, Shostakovich left for Arkhangelsk, and was there when he heard on 28 January that "Pravda" had published a tirade titled "Muddle Instead of Music", complaining that the opera was a "deliberately dissonant, muddled stream of sounds...[that] quacks, hoots, pants and gasps." This was the signal for a nationwide campaign, during which even Soviet music critics who had praised the opera were forced to recant in print, saying they "failed to detect the shortcomings of "Lady Macbeth" as pointed out by "Pravda"". There was resistance from those who admired Shostakovich, including Sollertinsky, who turned up at a composers' meeting in Leningrad called to denounce the opera and praised it instead. Two other speakers supported him. When Shostakovich returned to Leningrad, he had a telephone call from the commander of the Leningrad Military District, who had been asked by Marshal Mikhail Tukhachevsky to make sure that he was all right. When the writer Isaac Babel was under arrest four years later, he told his interrogators that "it was common ground for us to proclaim the genius of the slighted Shostakovich."

On 6 February, Shostakovich was again attacked in "Pravda", this time for his light comic ballet "The Limpid Stream", which was denounced because "it jangles and expresses nothing" and did not give an accurate picture of peasant life on a collective farm. Fearful that he was about to be arrested, Shostakovich secured an appointment with the Chairman of the USSR State Committee on Culture, Platon Kerzhentsev, who reported to Stalin and Molotov that he had instructed the composer to "reject formalist errors and in his art attain something that could be understood by the broad masses", and that Shostakovich had admitted being in the wrong and had asked for a meeting with Stalin, which was not granted.

As a result of this campaign, commissions began to fall off, and Shostakovich's income fell by about three-quarters. His Fourth Symphony was due to receive its premiere on 11 December 1936, but he withdrew it from the public, possibly because it was banned, and the symphony was not performed until 1961. "Lady Macbeth of the Mtsensk District" was also suppressed. A bowdlerised version was eventually performed under a new title, "Katerina Izmailova", on 8 January 1963. The anti-Shostakovich campaign also served as a signal to artists working in other fields, including art, architecture, the theatre and cinema, with the writer Mikhail Bulgakov, the director Sergei Eisenstein, and the theatre director Vsevolod Meyerhold among the prominent targets. More widely, 1936 marked the beginning of the Great Terror, in which many of the composer's friends and relatives were imprisoned or killed. These included Tukhachevsky (shot months after his arrest); his brother-in-law Vsevolod Frederiks (a distinguished physicist, who was eventually released but died before he got home); his close friend Nikolai Zhilyayev (a musicologist who had taught Tukhachevsky; shot shortly after his arrest); his mother-in-law, the astronomer Sofiya Mikhaylovna Varzar (sent to a camp in Karaganda); his friend the Marxist writer Galina Serebryakova (20 years in camps); his uncle Maxim Kostrykin (died); and his colleagues Boris Kornilov and Adrian Piotrovsky (executed). His only consolation in this period was the birth of his daughter Galina in 1936; his son Maxim was born two years later.

The publication of the "Pravda" editorials coincided with the composition of Shostakovich's Fourth Symphony. The work marked a great shift in style, owing to the substantial influence of Mahler and a number of Western-style elements. The symphony gave Shostakovich compositional trouble, as he attempted to reform his style into a new idiom. He was well into the work when the "Pravda" article appeared. He continued to compose the symphony and planned a premiere at the end of 1936. Rehearsals began that December, but after a number of rehearsals, for reasons still debated today, decided to withdraw the symphony from the public. A number of his friends and colleagues, such as Isaak Glikman, have suggested that it was an official ban that Shostakovich was persuaded to present as a voluntary withdrawal. Whatever the case, it seems possible that this action saved the composer's life: during this time Shostakovich feared for himself and his family. Yet he did not repudiate the work; it retained its designation as his Fourth Symphony. A piano reduction was published in 1946, and the work was finally premiered in 1961, well after Stalin's death.

During 1936 and 1937, in order to maintain as low a profile as possible between the Fourth and Fifth symphonies, Shostakovich mainly composed film music, a genre favored by Stalin and lacking in dangerous personal expression.

The composer's response to his denunciation was the Fifth Symphony of 1937, which was musically more conservative than his earlier works. Premiered on 21 November 1937 in Leningrad, it was a phenomenal success. The Fifth brought many to tears and welling emotions. Later, Shostakovich's purported memoir, "Testimony", stated: "I'll never believe that a man who understood nothing could feel the Fifth Symphony. Of course they understood, they understood what was happening around them and they understood what the Fifth was about."

The success put Shostakovich in good standing once again. Music critics and the authorities alike, including those who had earlier accused him of formalism, claimed that he had learned from his mistakes and become a true Soviet artist. In a newspaper article published under Shostakovich's name, the Fifth was characterized as "A Soviet artist's creative response to just criticism." The composer Dmitry Kabalevsky, who had been among those who disassociated themselves from Shostakovich when the "Pravda" article was published, praised the Fifth and congratulated Shostakovich for "not having given in to the seductive temptations of his previous 'erroneous' ways."

It was also at this time that Shostakovich composed the first of his string quartets. His chamber works allowed him to experiment and express ideas that would have been unacceptable in his more public symphonies. In September 1937 he began to teach composition at the Leningrad Conservatory, which provided some financial security.

In 1939, before Soviet forces attempted to invade Finland, the Party Secretary of Leningrad Andrei Zhdanov commissioned a celebratory piece from Shostakovich, the "Suite on Finnish Themes", to be performed as the marching bands of the Red Army paraded through Helsinki. The Winter War was a bitter experience for the Red Army, the parade never happened, and Shostakovich never laid claim to the authorship of this work. It was not performed until 2001. After the outbreak of war between the Soviet Union and Germany in 1941, Shostakovich initially remained in Leningrad. He tried to enlist in the military but was turned away because of his poor eyesight. To compensate, he became a volunteer for the Leningrad Conservatory's firefighter brigade and delivered a radio broadcast to the Soviet people "". The photograph for which he posed was published in newspapers throughout the country.

His most famous wartime contribution was the Seventh Symphony. The composer wrote the first three movements in Leningrad and completed the work in Kuibyshev (now Samara), where he and his family had been evacuated. It remains unclear whether Shostakovich really conceived the idea of the symphony with the siege of Leningrad in mind. It was officially claimed as a representation of the people of Leningrad's brave resistance to the German invaders and an authentic piece of patriotic art at a time when morale needed boosting. The symphony was first premiered by the Bolshoi Theatre orchestra in Kuibyshev and was soon performed abroad in London and the United States. It was subsequently performed for broadcast in Leningrad while the city was still under siege. The orchestra had only 14 musicians left, so the conductor Karl Eliasberg had to recruit anyone who could play an instrument to perform.

The family moved to Moscow in spring 1943. At the time of the Eighth Symphony's premiere, the tide had turned for the Red Army. As a consequence, the public, and most importantly the authorities, wanted another triumphant piece from the composer. Instead, they got the Eighth Symphony, perhaps the ultimate in sombre and violent expression in Shostakovich's output. In order to preserve Shostakovich's image (a vital bridge to the people of the Union and to the West), the government assigned the name "Stalingrad" to the symphony, giving it the appearance of mourning of the dead in the bloody Battle of Stalingrad. But the piece did not escape criticism. Its composer is reported to have said: "When the Eighth was performed, it was openly declared counter-revolutionary and anti-Soviet. They said, 'Why did Shostakovich write an optimistic symphony at the beginning of the war and a tragic one now? At the beginning, we were retreating and now we're attacking, destroying the Fascists. And Shostakovich is acting tragic, that means he's on the side of the fascists.'" The work was unofficially but effectively banned until 1956.

The Ninth Symphony (1945), in contrast, was much lighter in tone. Gavriil Popov wrote that it was "splendid in its joie de vivre, gaiety, brilliance, and pungency!" But by 1946 it too was the subject of criticism. Israel Nestyev asked whether it was the right time for "a light and amusing interlude between Shostakovich's significant creations, a temporary rejection of great, serious problems for the sake of playful, filigree-trimmed trifles." The "New York World-Telegram" of 27 July 1946 was similarly dismissive: "The Russian composer should not have expressed his feelings about the defeat of Nazism in such a childish manner". Shostakovich continued to compose chamber music, notably his Second Piano Trio (Op. 67), dedicated to the memory of Sollertinsky, with a bittersweet, Jewish-themed "totentanz" finale. In 1947, the composer was made a deputy to the Supreme Soviet of the RSFSR.

In 1948, Shostakovich, along with many other composers, was again denounced for formalism in the Zhdanov decree. Andrei Zhdanov, Chairman of the RSFSR Supreme Soviet, accused the composers (including Sergei Prokofiev and Aram Khachaturian) of writing inappropriate and formalist music. This was part of an ongoing anti-formalism campaign intended to root out all Western compositional influence as well as any perceived "non-Russian" output. The conference resulted in the publication of the Central Committee's Decree "On V. Muradeli’s opera "The Great Friendship"," which targeted all Soviet composers and demanded that they write only "proletarian" music, or music for the masses. The accused composers, including Shostakovich, were summoned to make public apologies in front of the committee. Most of Shostakovich's works were banned, and his family had privileges withdrawn. Yuri Lyubimov says that at this time "he waited for his arrest at night out on the landing by the lift, so that at least his family wouldn't be disturbed."

The decree's consequences for composers were harsh. Shostakovich was among those dismissed from the Conservatory altogether. For him, the loss of money was perhaps the largest blow. Others still in the Conservatory experienced an atmosphere thick with suspicion. No one wanted his work to be understood as formalist, so many resorted to accusing their colleagues of writing or performing anti-proletarian music.

In the next few years, Shostakovich composed three categories of work: film music to pay the rent, official works aimed at securing official rehabilitation, and serious works "for the desk drawer". The latter included the Violin Concerto No. 1 and the song cycle "From Jewish Folk Poetry". The cycle was written at a time when the postwar anti-Semitic campaign was already under way, with widespread arrests, including that of Dobrushin and Yiditsky, the compilers of the book from which Shostakovich took his texts.

The restrictions on Shostakovich's music and living arrangements were eased in 1949, when Stalin decided that the Soviets needed to send artistic representatives to the Cultural and Scientific Congress for World Peace in New York City, and that Shostakovich should be among them. For Shostakovich, it was a humiliating experience, culminating in a New York press conference where he was expected to read a prepared speech. Nicolas Nabokov, who was present in the audience, witnessed Shostakovich starting to read "in a nervous and shaky voice" before he had to break off "and the speech was continued in English by a suave radio baritone". Fully aware that Shostakovich was not free to speak his mind, Nabokov publicly asked him whether he supported the then recent denunciation of Stravinsky's music in the Soviet Union. A great admirer of Stravinsky who had been influenced by his music, Shostakovich had no alternative but to answer in the affirmative. Nabokov did not hesitate to write that this demonstrated that Shostakovich was "not a free man, but an obedient tool of his government." Shostakovich never forgave Nabokov for this public humiliation. That same year he was obliged to compose the cantata "Song of the Forests", which praised Stalin as the "great gardener".

Stalin's death in 1953 was the biggest step toward Shostakovich's rehabilitation as a creative artist, which was marked by his Tenth Symphony. It features a number of musical quotations and codes (notably the DSCH and Elmira motifs, Elmira Nazirova being a pianist and composer who had studied under Shostakovich in the year before his dismissal from the Moscow Conservatory), the meaning of which is still debated, while the savage second movement, according to "Testimony", is intended as a musical portrait of Stalin. The Tenth ranks alongside the Fifth and Seventh as one of Shostakovich's most popular works. 1953 also saw a stream of premieres of the "desk drawer" works.

During the forties and fifties, Shostakovich had close relationships with two of his pupils, Galina Ustvolskaya and Elmira Nazirova. In the background to all this remained Shostakovich's first, open marriage to Nina Varzar until her death in 1954. He taught Ustvolskaya from 1939 to 1941 and then from 1947 to 1948. The nature of their relationship is far from clear: Mstislav Rostropovich described it as "tender". Ustvolskaya rejected a proposal of marriage from him after Nina's death. Shostakovich's daughter, Galina, recalled her father consulting her and Maxim about the possibility of Ustvolskaya becoming their stepmother. Ustvolskaya's friend Viktor Suslin said that she had been "deeply disappointed" in Shostakovich by the time of her graduation in 1947 [source?]. The relationship with Nazirova seems to have been one-sided, expressed largely in his letters to her, and can be dated to around 1953 to 1956. He married his second wife, Komsomol activist Margarita Kainova, in 1956; the couple proved ill-matched, and divorced five years later.

In 1954, Shostakovich wrote the Festive Overture, opus 96; it was used as the theme music for the 1980 Summer Olympics. (His '"Theme from the film "Pirogov", Opus 76a: Finale" was played as the cauldron was lit at the 2004 Summer Olympics in Athens, Greece.)

In 1959, Shostakovich appeared on stage in Moscow at the end of a concert performance of his Fifth Symphony, congratulating Leonard Bernstein and the New York Philharmonic Orchestra for their performance (part of a concert tour of the Soviet Union). Later that year, Bernstein and the Philharmonic recorded the symphony in Boston for Columbia Records.

The year 1960 marked another turning point in Shostakovich's life: he joined the Communist Party. The government wanted to appoint him General Secretary of the Composers' Union, but in order to hold that position he was required to attain Party membership. It was understood that Nikita Khrushchev, the First Secretary of the Communist Party from 1953 to 1964, was looking for support from the intelligentsia's leading ranks in an effort to create a better relationship with the Soviet Union's artists. This event has variously been interpreted as a show of commitment, a mark of cowardice, the result of political pressure, or his free decision. On the one hand, the apparat was undoubtedly less repressive than it had been before Stalin's death. On the other, his son recalled that the event reduced Shostakovich to tears, and that he later told his wife Irina that he had been blackmailed. Lev Lebedinsky has said that the composer was suicidal. From 1962, he served as a delegate in the Supreme Soviet of the USSR. Once he joined the Party, several articles he did not write denouncing individualism in music were published under his name in "Pravda". By joining the party, Shostakovich also committed himself to finally writing the homage to Lenin that he had promised before. His Twelfth Symphony, which portrays the Bolshevik Revolution and was completed in 1961, was dedicated to Lenin and called "The Year 1917." Around this time, his health began to deteriorate.

Shostakovich's musical response to these personal crises was the Eighth String Quartet, composed in only three days. He subtitled the piece "To the victims of fascism and war", ostensibly in memory of the Dresden fire bombing that took place in 1945. Yet like the Tenth Symphony, the quartet incorporates quotations from several of his past works and his musical monogram. Shostakovich confessed to his friend Isaak Glikman, "I started thinking that if some day I die, nobody is likely to write a work in memory of me, so I had better write one myself." Several of Shostakovich's colleagues, including Natalya Vovsi-Mikhoels and the cellist Valentin Berlinsky, were also aware of the Eighth Quartet's biographical intent. Peter J. Rabinowitz has also pointed to covert references to Richard Strauss's "Metamorphosen" in it.

In 1962 Shostakovich married for the third time, to Irina Supinskaya. In a letter to Glikman, he wrote, "her only defect is that she is 27 years old. In all other respects she is splendid: clever, cheerful, straightforward and very likeable." According to Galina Vishnevskaya, who knew the Shostakoviches well, this marriage was a very happy one: "It was with her that Dmitri Dmitriyevich finally came to know domestic peace... Surely, she prolonged his life by several years." In November he made his only venture into conducting, conducting a couple of his own works in Gorky; otherwise he declined to conduct, citing nerves and ill health.

That year saw Shostakovich again turn to the subject of anti-Semitism in his Thirteenth Symphony (subtitled "Babi Yar"). The symphony sets a number of poems by Yevgeny Yevtushenko, the first of which commemorates a massacre of Ukrainian Jews during the Second World War. Opinions are divided as to how great a risk this was: the poem had been published in Soviet media, and was not banned, but remained controversial. After the symphony's premiere, Yevtushenko was forced to add a stanza to his poem that said that Russians and Ukrainians had died alongside the Jews at Babi Yar.

In 1965 Shostakovich raised his voice in defence of poet Joseph Brodsky, who was sentenced to five years of exile and hard labor. Shostakovich co-signed protests with Yevtushenko, fellow Soviet artists Kornei Chukovsky, Anna Akhmatova, Samuil Marshak, and the French philosopher Jean-Paul Sartre. After the protests the sentence was commuted, and Brodsky returned to Leningrad.

In 1964 Shostakovich composed the music for the Russian film "Hamlet", which was favourably reviewed by "The New York Times": "But the lack of this aural stimulation—of Shakespeare's eloquent words—is recompensed in some measure by a splendid and stirring musical score by Dmitri Shostakovich. This has great dignity and depth, and at times an appropriate wildness or becoming levity".

In later life, Shostakovich suffered from chronic ill health, but he resisted giving up cigarettes and vodka. Beginning in 1958 he suffered from a debilitating condition that particularly affected his right hand, eventually forcing him to give up piano playing; in 1965 it was diagnosed as poliomyelitis. He also suffered heart attacks the following year and again in 1971, and several falls in which he broke both his legs; in 1967 he wrote in a letter: "Target achieved so far: 75% (right leg broken, left leg broken, right hand defective). All I need to do now is wreck the left hand and then 100% of my extremities will be out of order."

A preoccupation with his own mortality permeates Shostakovich's later works, such as the later quartets and the Fourteenth Symphony of 1969 (a song cycle based on a number of poems on the theme of death). This piece also finds Shostakovich at his most extreme with musical language, with 12-tone themes and dense polyphony throughout. He dedicated the Fourteenth to his close friend Benjamin Britten, who conducted its Western premiere at the 1970 Aldeburgh Festival. The Fifteenth Symphony of 1971 is, by contrast, melodic and retrospective in nature, quoting Wagner, Rossini and the composer's own Fourth Symphony.

Shostakovich died of lung cancer on 9 August 1975. A civic funeral was held; he was interred in Novodevichy Cemetery, Moscow. Even before his death he had been commemorated with the naming of the Shostakovich Peninsula on Alexander Island, Antarctica., Despite suffering from Motor Neurone Disease (or ALS) from as early as the 1960s, Shostakovich insisted upon writing all his own correspondence and music himself, even when his right hand was virtually unusable.
He was survived by his third wife, Irina; his daughter, Galina; and his son, Maxim, a pianist and conductor who was the dedicatee and first performer of some of his father's works. Shostakovich himself left behind several recordings of his own piano works; other noted interpreters of his music include Emil Gilels, Mstislav Rostropovich, Tatiana Nikolayeva, Maria Yudina, David Oistrakh, and members of the Beethoven Quartet.

His last work was his Viola Sonata, which was first performed officially on 1 October 1975.

Shostakovich's musical influence on later composers outside the former Soviet Union has been relatively slight, although Alfred Schnittke took up his eclecticism and his contrasts between the dynamic and the static, and some of André Previn's music shows clear links to Shostakovich's style of orchestration. His influence can also be seen in some Nordic composers, such as Lars-Erik Larsson. Many of his Russian contemporaries, and his pupils at the Leningrad Conservatory were strongly influenced by his style (including German Okunev, Sergei Slonimsky, and Boris Tishchenko, whose 5th Symphony of 1978 is dedicated to Shostakovich's memory). Shostakovich's conservative idiom has grown increasingly popular with audiences both within and outside Russia, as the avant-garde has declined in influence and debate about his political views has developed.

Shostakovich's works are broadly tonal and in the Romantic tradition, but with elements of atonality and chromaticism. In some of his later works (e.g., the Twelfth Quartet), he made use of tone rows. His output is dominated by his cycles of symphonies and string quartets, each totaling 15. The symphonies are distributed fairly evenly throughout his career, while the quartets are concentrated towards the latter part. Among the most popular are the Fifth and Seventh Symphonies and the Eighth and Fifteenth Quartets. Other works include the operas "Lady Macbeth of Mtsensk", "The Nose" and the unfinished "The Gamblers," based on the comedy by Gogol; six concertos (two each for piano, violin and cello); two piano trios; and a large quantity of film music.

Shostakovich's music shows the influence of many of the composers he most admired: Bach in his fugues and passacaglias; Beethoven in the late quartets; Mahler in the symphonies; and Berg in his use of musical codes and quotations. Among Russian composers, he particularly admired Modest Mussorgsky, whose operas "Boris Godunov" and "Khovanshchina" he reorchestrated; Mussorgsky's influence is most prominent in the wintry scenes of "Lady Macbeth" and the Eleventh Symphony, as well as in satirical works such as "Rayok". Prokofiev's influence is most apparent in the earlier piano works, such as the first sonata and first concerto. The influence of Russian church and folk music is evident in his works for unaccompanied choir of the 1950s.

Shostakovich's relationship with Stravinsky was profoundly ambivalent; as he wrote to Glikman, "Stravinsky the composer I worship. Stravinsky the thinker I despise." He was particularly enamoured of the "Symphony of Psalms", presenting a copy of his own piano version of it to Stravinsky when the latter visited the USSR in 1962. (The meeting of the two composers was not very successful; observers commented on Shostakovich's extreme nervousness and Stravinsky's "cruelty" to him.)

Many commentators have noted the disjunction between the experimental works before the 1936 denunciation and the more conservative ones that followed; the composer told Flora Litvinova, "without 'Party guidance' ... I would have displayed more brilliance, used more sarcasm, I could have revealed my ideas openly instead of having to resort to camouflage." Articles Shostakovich published in 1934 and 1935 cited Berg, Schoenberg, Krenek, Hindemith, "and especially Stravinsky" among his influences. Key works of the earlier period are the First Symphony, which combined the academicism of the conservatory with his progressive inclinations; "The Nose" ("The most uncompromisingly modernist of all his stage-works"); "Lady Macbeth", which precipitated the denunciation; and the Fourth Symphony, described in Grove's Dictionary as "a colossal synthesis of Shostakovich's musical development to date". The Fourth was also the first piece in which Mahler's influence came to the fore, prefiguring the route Shostakovich took to secure his rehabilitation, while he himself admitted that the preceding two were his least successful.

In the years after 1936, Shostakovich's symphonic works were outwardly musically conservative, regardless of any subversive political content. During this time he turned increasingly to chamber works, a field that allowed him to explore different and often darker ideas without scrutiny. While his chamber works were largely tonal, they gave Shostakovich an outlet for sombre reflection not welcomed in his more public works. This is most apparent in the late chamber works, which portray what Grove's Dictionary calls "world of purgatorial numbness"; in some of these he included tone rows, although he treated these as melodic themes rather than serially. Vocal works are also a prominent feature of his late output, setting texts often concerned with love, death and art.

Even before the Stalinist anti-Semitic campaigns in the late 1940s and early 1950s, Shostakovich showed an interest in Jewish themes. He was intrigued by Jewish music's "ability to build a jolly melody on sad intonations". Examples of works that included Jewish themes are the Fourth String Quartet (1949), the First Violin Concerto (1948), and the "Four Monologues on Pushkin Poems" (1952), as well as the Piano Trio in E minor (1944). He was further inspired to write with Jewish themes when he examined Moisei Beregovski's 1944 thesis on Jewish folk music.

In 1948, Shostakovich acquired a book of Jewish folk songs, from which he composed the song cycle "From Jewish Folk Poetry". He initially wrote eight songs meant to represent the hardships of being Jewish in the Soviet Union. To disguise this, he added three more meant to demonstrate the great life Jews had under the Soviet regime. Despite his efforts to hide the real meaning in the work, the Union of Composers refused to approve his music in 1949 under the pressure of the anti-Semitism that gripped the country. "From Jewish Folk Poetry" could not be performed until after Stalin's death in March 1953, along with all the other works that were forbidden.

Throughout his compositions, Shostakovich demonstrated a controlled use of musical quotation. This stylistic choice had been common among earlier composers, but Shostakovich developed it into a defining characteristic of his music. Rather than quoting other composers, Shostakovich preferred to quote himself. Musicologists such as Sofia Moshevich, Ian McDonald, and Stephen Harris have connected his works through their quotations.

One example is the main theme of Katerina's aria, "Seryozha, khoroshiy moy", from the fourth act of "Lady Macbeth of the Mtsensk District". It accompanies Katerina as she reunites with her lover Sergei. The aria's beauty comes as a breath of fresh air in the intense, overbearing tone of the scene. This goes well with the dialogue, as Katerina visits her lover in prison. The theme is made tragic when Sergei betrays her and finds a new lover upon blaming Katerina for his incarceration.

More than 25 years later, Shostakovich quoted this theme in his eighth string quartet. In the midst of this quartet's oppressive and somber themes, the only light and cheerful moment is when the cello introduces the Seryozha theme about three minutes into the fourth movement. The quotation uses Katerina's hope amid misery as a means to demonstrate the hope of those oppressed by fascists.

This theme emerges once again in his 14th string quartet. As in the eighth, the cello introduces the theme, but for an entirely different purpose. The last in Shostakovich's "quartet of quartets", the fourteenth serves to honor the cellist of the Beethoven String Quartet, Sergei Shirinsky. Rather than reflecting the original theme's intentions, the quotation serves as a dedication to Shirinsky.

In 2004, the musicologist Olga Digonskaya discovered a trove of Shostakovich manuscripts at the Glinka State Central Museum of Musical Culture in Moscow. In a cardboard file were some "300 pages of musical sketches, pieces and scores" in Shostakovich's hand. "A composer friend bribed Shostakovich's housemaid to regularly deliver the contents of Shostakovich's office waste bin to him, instead of taking it to the garbage. Some of those cast-offs eventually found their way into the Glinka. ... The Glinka archive 'contained a huge number of pieces and compositions which were completely unknown or could be traced quite indirectly,' Digonskaya said."

Among these were Shostakovich's piano and vocal sketches for a prologue to an opera, "Orango" (1932). They were orchestrated by the British composer Gerard McBurney and premiered in December 2011 by the Los Angeles Philharmonic.

According to McBurney, opinion is divided on whether Shostakovich's music is "of visionary power and originality, as some maintain, or, as others think, derivative, trashy, empty and second-hand". William Walton, his British contemporary, described him as "the greatest composer of the 20th century". Musicologist David Fanning concludes in Grove's Dictionary that "Amid the conflicting pressures of official requirements, the mass suffering of his fellow countrymen, and his personal ideals of humanitarian and public service, he succeeded in forging a musical language of colossal emotional power."

Some modern composers have been critical. Pierre Boulez dismissed Shostakovich's music as "the second, or even third of Mahler". The Romanian composer and Webern disciple Philip Gershkovich called Shostakovich "a hack in a trance". A related complaint is that Shostakovich's style is vulgar and strident: Stravinsky wrote of "Lady Macbeth": "brutally hammering ... and monotonous". English composer and musicologist Robin Holloway described his music as "battleship-grey in melody and harmony, factory-functional in structure; in content all rhetoric and coercion."

In the 1980s, the Finnish conductor and composer Esa-Pekka Salonen was critical of Shostakovich and refused to conduct his music. For instance, he said in 1987:
Shostakovich is in many ways a polar counter-force for Stravinsky. [...] When I have said that the 7th symphony of Shostakovich is a dull and unpleasant composition, people have responded: "Yes, yes, but think of the background of that symphony." Such an attitude does no good to anyone.

Salonen has since performed and recorded several of Shostakovich's works, including the Piano Concertos Nos. 1 and 2 (1999), the Violin Concerto No. 1 (2010), the Prologue to "Orango" and the Symphony No. 4 (2012).

It is certainly true that Shostakovich borrows extensively from the material and styles both of earlier composers and of popular music; the vulgarity of "low" music is a notable influence on this "greatest of eclectics". McBurney traces this to the avant-garde artistic circles of the early Soviet period in which Shostakovich moved early in his career, and argues that these borrowings were a deliberate technique to allow him to create "patterns of contrast, repetition, exaggeration" that gave his music large-scale structure.

Shostakovich was in many ways an obsessive man: according to his daughter he was "obsessed with cleanliness". He synchronised the clocks in his apartment and regularly sent himself cards to test how well the postal service was working. Elizabeth Wilson's "Shostakovich: A Life Remembered" indexes 26 references to his nervousness. Mikhail Druskin remembers that even as a young man the composer was "fragile and nervously agile". Yuri Lyubimov comments, "The fact that he was more vulnerable and receptive than other people was no doubt an important feature of his genius." In later life, Krzysztof Meyer recalled, "his face was a bag of tics and grimaces."

In Shostakovich's lighter moods, sport was one of his main recreations, although he preferred spectating or umpiring to participating (he was a qualified football referee). His favourite football club was Zenit Leningrad (now Zenit Saint Petersburg), which he would watch regularly. He also enjoyed card games, particularly patience.

Shostakovich was fond of satirical writers such as Gogol, Chekhov and Mikhail Zoshchenko. Zoshchenko's influence in particular is evident in his letters, which include wry parodies of Soviet officialese. Zoshchenko noted the contradictions in the composer's character: "he is ... frail, fragile, withdrawn, an infinitely direct, pure child ... [but also] hard, acid, extremely intelligent, strong perhaps, despotic and not altogether good-natured (although cerebrally good-natured)."

Shostakovich was diffident by nature: Flora Litvinova has said he was "completely incapable of saying 'No' to anybody." This meant he was easily persuaded to sign official statements, including a denunciation of Andrei Sakharov in 1973. His widow later told Helsingin Sanomat that his name was included without his permission. But he was willing to try to help constituents in his capacities as chairman of the Composers' Union and Deputy to the Supreme Soviet. Oleg Prokofiev said, "he tried to help so many people that ... less and less attention was paid to his pleas." When asked if he believed in God, Shostakovich said "No, and I am very sorry about it."

Shostakovich's response to official criticism and whether he used music as a kind of covert dissidence is a matter of dispute. He outwardly conformed to government policies and positions, reading speeches and putting his name to articles expressing the government line. But it is evident he disliked many aspects of the regime, as confirmed by his family, his letters to Isaak Glikman, and the satirical cantata "Rayok", which ridiculed the "anti-formalist" campaign and was kept hidden until after his death. He was a close friend of Marshal of the Soviet Union Mikhail Tukhachevsky, who was executed in 1937 during the Great Purge.

It is also uncertain to what extent Shostakovich expressed his opposition to the state in his music. The revisionist view was put forth by Solomon Volkov in the 1979 book "Testimony", which claimed to be Shostakovich's memoirs dictated to Volkov. The book alleged that many of the composer's works contained coded anti-government messages, placing Shostakovich in a tradition of Russian artists outwitting censorship that goes back at least to Alexander Pushkin. He incorporated many quotations and motifs in his work, most notably his musical signature DSCH. His longtime musical collaborator Yevgeny Mravinsky said, "Shostakovich very often explained his intentions with very specific images and connotations."

The revisionist perspective has subsequently been supported by his children, Maxim and Galina, although Maxim said in 1981 that Volkov's book was not his father's work. Volkov has further argued, both in "Testimony" and in "Shostakovich and Stalin", that Shostakovich adopted the role of the "yurodivy" or holy fool in his relations with the government. Other prominent revisionists are Ian MacDonald, whose book "The New Shostakovich" put forward further revisionist interpretations of his music, and Elizabeth Wilson, whose "Shostakovich: A Life Remembered" provides testimony from many of the composer's acquaintances.

Musicians and scholars including Laurel Fay and Richard Taruskin contest the authenticity and debate the significance of "Testimony", alleging that Volkov compiled it from a combination of recycled articles, gossip, and possibly some information directly from the composer. Fay documents these allegations in her 2002 article 'Volkov's "Testimony" reconsidered', showing that the only pages of the original "Testimony" manuscript that Shostakovich had signed and verified are word-for-word reproductions of earlier interviews he gave, none of which are controversial. Against this, Allan B. Ho and Dmitry Feofanov have pointed out that at least two of the signed pages contain controversial material: for instance, "on the first page of chapter 3, where [Shostakovich] notes that the plaque that reads 'In this house lived [Vsevolod] Meyerhold' should also say 'And in this house his wife was brutally murdered'."

In May 1958, during a visit to Paris, Shostakovich recorded his two piano concertos with André Cluytens, as well as some short piano works. These were issued by EMI on an LP, reissued by Seraphim Records on LP, and eventually digitally remastered and released on CD. Shostakovich recorded the two concertos in stereo in Moscow for Melodiya. Shostakovich also played the piano solos in recordings of the Cello Sonata, Op. 40 with cellist Daniil Shafran and also with Mstislav Rostropovich; the Violin Sonata, Op. 134, with violinist David Oistrakh; and the Piano Trio, Op. 67 with violinist David Oistrakh and cellist Miloš Sádlo. There is also a short sound film of Shostakovich as soloist in a 1930s concert performance of the closing moments of his first piano concerto. A colour film of Shostakovich supervising one of his operas, from his last year, was also made. A major achievement was EMI's recording of the original, unexpurgated opera "Lady Macbeth of Mtsensk". There was at least one recording of the cleaned-up version, "Katerina Ismailova", that Shostakovich had made to satisfy Soviet censorship. But when conductor Mstislav Rostropovich and his wife, soprano Galina Vishnevskaya were finally allowed to emigrate to the West, the composer begged them to record the full original score, which they did in April 1978. It features Vishnevskaya as Katerina, Nicolai Gedda as Sergei, Dimiter Petkov as Boris Ismailov and a brilliant supporting cast under Rostropovich's direction.

Belgium: Member of the Royal Academy of Science, Letters and Fine Arts of Belgium (1960)

Denmark: Léonie Sonning Music Prize (1973)

Finland: Wihuri Sibelius Prize (1958)

Soviet Union:

United Kingdom: Gold Medal of the Royal Philharmonic Society (1966)





</doc>
<doc id="8521" url="https://en.wikipedia.org/wiki?curid=8521" title="Doom (1993 video game)">
Doom (1993 video game)

Doom is a 1993 first-person shooter (FPS) game developed by id Software for MS-DOS. Players assume the role of a space marine, popularly known as Doomguy, fighting his way through hordes of invading demons from Hell. The first episode, comprising nine levels, was distributed freely as shareware and played by an estimated 15–20 million people within two years; the full game, with two further episodes, was sold via mail order. An updated version with an additional episode and more difficult levels, "Ultimate Doom", was released in 1995 and sold at retail.

Along with its predecessor "Wolfenstein 3D", "Doom" helped define the FPS genre and inspired numerous similar games, known as "Doom" clones. It is one of the most significant games in video game history, frequently cited as one of the greatest games of all time. It pioneered online distribution and technologies including 3D graphics, networked multiplayer gaming, and support for custom modifications via packaged files (WADs). Its graphic violence and hellish imagery also made it a subject of controversy.

"Doom" has been ported to numerous platforms. The "Doom" franchise continued with "Doom II: Hell on Earth" (1994) and expansion packs including "Master Levels for Doom II" (1995). The source code was released in 1997, inspiring further adaptations. Id returned to the franchise with "Doom 3" (2004), a horror-focused retelling using the id Tech 4 engine, followed by a 2005 "Doom" film. A new series, returning to the fast-paced action of the originals, began with the 2016 reboot "Doom", followed in 2020 by "Doom Eternal".

"Doom" is a first-person shooter presented with early 3D graphics. The player controls an unnamed space marine—later termed the Doomguy—through a series of levels set in military bases on the moons of Mars and in Hell. To finish a level, the player must traverse through the area to reach a marked exit room. Levels are grouped together into named episodes, with the final level focusing on a boss fight with a particularly difficult enemy. While the levels are presented in a 3D perspective, the enemies and objects are instead 2D sprites presented from several set viewing angles, a technique sometimes referred to as 2.5D graphics. Levels are often labyrinthine, and a full screen automap is available which shows the areas explored to that point.

While traversing the levels, the player must fight a variety of enemies, including demons and possessed undead humans, while managing supplies of ammunition, health, and armor. Enemies often appear in large groups, and the game features five difficulty levels which increase the quantity and damage done by enemies, with enemies respawning upon death and moving faster than normal on the hardest difficulty setting. The monsters have very simple behavior, consisting of either moving toward their opponent, or attacking by throwing fireballs, biting, and clawing. They will fight each other if one monster is accidentally harmed by another, though most monsters are not harmed by other monsters of the same kind. Levels can also include pits of toxic waste, ceilings that lower and crush anything below them, and locked doors which require a keycard, skull-shaped key device, or a remote switch to be opened. The player can find weapons and ammunition placed in the levels or can collect them from dead enemies; weapons include a pistol, a chainsaw, a plasma rifle, and the BFG 9000, among others. The levels also feature power-ups such as items that give health or armor points, increase the player character's maximum ammunition or health, fill out the automap, give partial invisibility, or allow the player to survive in toxic waste. There are also items which apply time-limited effects such as invulnerability or a berserker status.

In addition to the main single-player game mode, "Doom" features two multiplayer modes playable over a local network: "cooperative", in which two to four players team up to play through the main game, and "deathmatch", in which two to four players play against each other. Online multiplayer was later made available a year after launch through the DWANGO service. "Doom" also contains cheat codes that allow the player to be invulnerable, obtain every weapon, be able to instantly kill every monster in a particular level, and several other abilities.

"Doom" is divided into three episodes: "Knee-Deep in the Dead", "The Shores of Hell", and "Inferno". A fourth episode, "Thy Flesh Consumed", was added in an expanded version of the game, "The Ultimate Doom". The game itself contains very few plot elements, with the minimal story instead given in the instruction manual and short text segues between episodes.

In the future, the player character (an unnamed space marine) has been punitively posted to Mars after assaulting a superior officer, who ordered his unit to fire on civilians. The space marines act as security for the Union Aerospace Corporation's radioactive waste facilities, which are used by the military to perform secret experiments with teleportation by creating gateways between the two moons of Mars, Phobos and Deimos. Three years later, Deimos disappears entirely and "something fraggin' evil" starts pouring out of the teleporter gateways, killing or possessing all personnel. The Martian marine unit is dispatched to investigate, with the player character left to guard the perimeter with only a pistol while the rest of the group proceeds inside the base and is killed. Being unable to pilot the shuttle off of Phobos by himself, he realizes that the only way to escape is to go inside and fight his way through the complexes of the moon base. 

As the last man standing, the player character fights through the onslaught of demonic enemies to keep them from attacking Earth. In "Knee-Deep in the Dead", he fights through the high-tech military bases, power plants, computer centers and geological anomalies on Phobos. It ends with the player character entering the teleporter leading to Deimos, only to be overwhelmed by monsters. In "The Shores of Hell" he fights through installations on Deimos, similar to those on Phobos, but warped and distorted from the demon invasion and interwoven with beastly architecture. After defeating the titanic Cyberdemon, the marine discovers the vanished moon is floating above Hell. "Inferno" begins after the marine climbs off Deimos to the surface. The marine fights his way through Hell and defeats the Spider Mastermind that planned the invasion. A hidden doorway back to Earth opens for the hero, who has "proven too tough for Hell to contain". However, a burning city and a rabbit's head impaled on a stake (named in "The Ultimate Doom" as the marine's pet rabbit, Daisy) show that the demons have invaded Earth. In "Thy Flesh Consumed", the marine fights the demons on Earth through a variety of disconnected high-tech bases and demonic temples, though ultimately the forces of Hell prevail in the invasion of Earth, setting the stage for "Doom II: Hell on Earth".

In May 1992, id Software released "Wolfenstein 3D", later called the "grandfather of 3D shooters", specifically first-person shooters, because it established the fast-paced action and technical prowess commonly expected in the genre and greatly increased the genre's popularity. Immediately following its release most of the id Software team began work on a set of episodes for the game, titled "Spear of Destiny", while id co-founder and lead programmer John Carmack instead focused on technology research for the company's next game. Following the release of "Spear of Destiny" in September 1992, the team began to plan their next title. They wanted to create another 3D game using a new engine Carmack was developing, but were largely tired of "Wolfenstein". They initially considered making another game in the "Commander Keen" series, as proposed by co-founder and lead designer Tom Hall, but decided that the platforming gameplay of the series was a poor fit for Carmack's fast-paced 3D engines. Additionally, the other two co-founders of id, designer John Romero and lead artist Adrian Carmack, wanted to create something in a darker style than the "Keen" games. John Carmack then came up with his own concept: a game about using technology to fight demons, inspired by the "Dungeons & Dragons" campaigns the team played, combining the styles of "Evil Dead II" and "Aliens". The concept originally had a working title of "Green and Pissed", but Carmack soon renamed the proposed game ""Doom"" after a line in the film "The Color of Money": "'What's in the case?' / 'In here? Doom.'"

The team agreed to pursue the "Doom" concept, and development began in November 1992. The initial development team was composed of five people: programmers John Carmack and Romero, artists Adrian Carmack and Kevin Cloud, and designer Hall. They moved offices to a dark office building, which they named "Suite 666", and drew inspiration from the noises coming from the dentist's office next door. They also decided to cut ties with Apogee Software, their previous publisher, and to instead self-publish "Doom".

Early in development, rifts in the team began to appear. At the end of November, Hall delivered a design document, which he named the "Doom Bible", that described the plot, backstory, and design goals for the project. His design was a science fiction horror concept wherein scientists on the Moon open a portal from which aliens emerge. Over a series of levels the player discovers that the aliens are demons while hell steadily infects the level design over the course of the game. John Carmack not only disliked the idea but dismissed the idea of having a story at all: "Story in a game is like story in a porn movie; it's expected to be there, but it's not that important." Rather than a deep story, he wanted to focus on the technological innovations of the game, dropping the levels and episodes of "Wolfenstein" in favor of a fast, continuous world. Tom disliked the idea, but the rest of the team sided with Carmack. Hall spent the next few weeks reworking the "Doom Bible" to work with Carmack's technological ideas. Hall was forced to rework it again in December, however, after the team decided that they were unable to create a single, seamless world with the hardware limitations of the time, which contradicted much of the document.

At the start of 1993, id put out a press release, touting Hall's story about fighting off demons while "knee-deep in the dead". The press release proclaimed the new game features that John Carmack had created, as well as other features, including multiplayer gaming features, that had not yet even been designed. Early versions of the game were built to match the "Doom Bible"; a "pre-alpha" version of the first level included Hall's introductory base scene. Initial versions of the game also retain "arcade" elements present in "Wolfenstein 3D", like score points and score items, but those were removed early in development as they were out of tone. Other elements, such as a complex user interface, an inventory system, a secondary shield protection, and lives were modified and slowly removed over the course of development.
Soon, however, the "Doom Bible" as a whole was rejected: Romero wanted a game even "more brutal and fast" than "Wolfenstein", which did not leave room for the character-driven plot Hall had created. Additionally, the team believed it emphasized realism over entertaining gameplay, and they did not see the need for a design document at all. Some ideas were retained, but the story was dropped and most of the game design was removed. By early 1993, levels were being created for the game and a demo was produced. John Carmack and Romero, however, disliked Hall's military base-inspired level design. Romero especially believed that the boxy, flat level designs were uninspiring, too similar to "Wolfenstein", and did not show off the engine's capabilities. He began to create his own, more abstract levels for the game, which the rest of the team saw as a great improvement.

Hall was upset with the reception to his designs and how little impact he was having as the lead designer. He was also upset with how much he was having to fight with John Carmack in order to get what he saw as obvious gameplay improvements, such as flying enemies, and began to spend less time at work. In July the other founders of id fired Hall, who went to work for Apogee. He was replaced in September, ten weeks before the game was released, by game designer Sandy Petersen. The team also added a third programmer, Dave Taylor. Petersen and Romero designed the rest of "Doom"s levels with different aims: the team believed that Petersen's designs were more technically interesting and varied, while Romero's were more aesthetically interesting. In late 1993, after the multiplayer component was coded, the development team began playing four-player multiplayer games matches, which Romero termed "deathmatch". According to Romero, the game's deathmatch mode was inspired by fighting games such as "", "Fatal Fury", and "Art of Fighting".

"Doom" was programmed largely in the ANSI C programming language, with a few elements done in assembly language. Development was done on NeXT computers running the NeXTSTEP operating system. The data used by the game engine, including both level designs and graphics files, are all stored in WAD files, short for "Where's All the Data". This allows for any part of the game's design to be easily changed without needing to adjust the engine code. Carmack designed this system specifically to enable fans to be able to easily modify the game; he had been impressed by the modifications made by fans of "Wolfenstein 3D", and wanted to support that with an easily swappable file structure along with releasing the map editor online.

Unlike "Wolfenstein", which had flat levels with walls at right angles, the "Doom" engine allows for walls and floors at any angle or height, though two traversable areas cannot be on top of each other. The lighting system was based on adjusting the color palette of surfaces directly: rather than calculating how light traveled from light sources to surfaces using ray tracing, the game calculates the "light level" of a small section of a level based on its distance from light sources. It then modifies the color palette of that section's surface textures to mimic how dark it would look. This same system is used to cause far away surfaces to look darker than close ones. Romero came up with new ways to use Carmack's lighting engine such as strobe lights. He also programmed engine features such as switches and movable stairs and platforms. After Romero's level designs started to cause problems with the engine, Carmack began to use binary space partitioning to quickly select the portion of a level that the player could see at a given time. Taylor, along with programming other features into the game, added cheat codes; some, such as 'idspispopd', were based on ideas their fans had come up with while eagerly awaiting the game.
Adrian Carmack was the lead artist for "Doom", with Kevin Cloud as an additional artist. They designed the monsters to be "nightmarish"; their intent was to have graphics that were realistic and dark as opposed to staged or rendered, so a mixed media approach was taken to the artwork. The artists sculpted models of some of the enemies, and took pictures of them in stop motion from five to eight different angles so that they could be rotated realistically in-game; the images were then digitized and converted to 2D characters with a program written by John Carmack. Adrian Carmack made clay models for a few demons, and had Gregor Punchatz build latex and metal sculptures of the others. The weapons were toys, with parts combined from different toys to make more guns. They scanned themselves as well, using Cloud's arm as the model for the player character's arm holding a gun, and Adrian's snakeskin boots and wounded knee for in-game textures.

As with "Wolfenstein 3D", id hired composer Bobby Prince to create the music and sound effects. Romero directed Prince to make the music in techno and metal styles; many tracks were directly inspired by songs by metal bands such as Alice in Chains and Pantera. Prince believed that ambient music would be more appropriate, and produced numerous tracks in both styles in the hopes of convincing the team; Romero put both styles in the game. Prince did not make music for specific levels, as they were composed before the levels were completed; instead, Romero assigned each track to each level late in development. Prince created the sound effects based on short descriptions or concept art of a monster or weapon, and adjusted them to match the completed animations. The monster sounds were created from animal noises, and Prince designed all the sounds to be distinct on the limited sound hardware of the time, even when many sounds were playing at once. He also designed the sound effects to play on different frequencies from those used for the MIDI music, so they would clearly cut through the music.

Because id planned to self-publish, as "Doom" neared completion they had to set up the systems to sell it. Jay Wilbur, who had been brought on as CEO and sole member of the business team, planned the marketing and distribution of "Doom". He believed that the mainstream press was uninterested in the game, and as id would make the most money off of copies they sold directly to customers—up to 85 percent of the planned price—he decided to leverage the shareware market as much as possible, buying only a single ad in any gaming magazine. Instead, he reached out directly to software retailers, offering them copies of the first "Doom" episode for free, allowing them to charge any price for it, in order to spur customer interest in buying the full game directly from id.

"Doom"s original release date was the third quarter of 1993, which the team did not meet. By December 1993, the team was working non-stop on the game, with several employees sleeping at the office; programmer Dave Taylor claimed that working on the game gave him such a rush that he would pass out from the intensity. Id began receiving calls from people interested in the game or angry that it had missed its planned release date, as hype for the game had been building online. At midnight on December 10, 1993, after working for 30 straight hours, the development team at id uploaded the first episode of the game to the internet, letting interested players distribute it for them. So many users were connected to the first network that they planned to upload the game to—the University of Wisconsin–Madison FTP network—that even after the network administrator increased the number of connections while on the phone with Wilbur, id was unable to connect, forcing them to kick all other users off to allow id to upload the game. When the upload finished thirty minutes later, 10,000 people attempted to download the game at once, crashing the university's network.

Within hours of "Doom"s release, university networks were banning "Doom" multiplayer games, as a rush of players overwhelmed their systems. After being alerted by network administrators the morning after release that the game's deathmatch network connection setup was crippling some computer networks, John Carmack quickly released a patch to change it, though many administrators had to implement "Doom"-specific rules to keep their networks from crashing due to the overwhelming traffic. 

In late 1995, "Doom" was estimated to be installed on more computers worldwide than Microsoft's new operating system, Windows 95, even with Microsoft's million-dollar advertising campaigns. Microsoft hired id Software to port Doom to Windows with the WinG API, and Microsoft CEO Bill Gates briefly considered buying the company. Microsoft developed a Windows 95 port of "Doom" to promote Windows as a gaming platform. The development team was led by Gabe Newell, who later founded the game company Valve. One Windows 95 promotional video had Gates digitally superimposed into the game.

In 1995, an expanded version of the game, titled "The Ultimate Doom", was released, containing a fourth episode.

Numerous ports of the game have been released by other companies. An unofficial port of "Doom" to Linux was released by id programmer Dave Taylor in 1994; it was hosted by id but not supported or made official. Official ports of "Doom" were released for Sega 32X, Atari Jaguar, and Mac OS in 1994, SNES and PlayStation in 1995, 3DO in 1996, Sega Saturn in 1997, Acorn Risc PC in 1998, Game Boy Advance in 2001, Xbox 360 in 2006, iOS in 2009, and Nintendo Switch in 2019. Notable exceptions in the list of official ports, as well as Linux, are AmigaOS and Symbian. Some of these were bestsellers even many years after the initial release. "Doom" has additionally been ported unofficially to numerous platforms; so many ports exist, including for esoteric devices such as smart thermostats and oscilloscopes, that variations on "It runs "Doom"" or "Can it run "Doom"?" are long-running phrases and memes.

The ability for others to create custom levels and otherwise modify the game using WAD files turned out to be a popular aspect of "Doom". Gaining the first large mod-making community, "Doom" affected the culture surrounding first-person shooters, and also the industry. Several future professional game designers started their careers making "Doom" WADs as a hobby, among them Tim Willits, who later became the lead designer at id Software.

The first level editors appeared in early 1994, and additional tools have been created that allow most aspects of the game to be edited. Although the majority of WADs contain one or several custom levels mostly in the style of the original game, others implement new monsters and other resources, and heavily alter the gameplay; several popular movies, television series, other video games and other brands from popular culture have been turned into "Doom" WADs by fans, including "Aliens", "Star Wars", "The Simpsons", "South Park", "Sailor Moon", "Dragon Ball Z", "Pokémon", "Beavis and Butt-head", "Batman", and "Sonic the Hedgehog". Some works, like the "Theme Doom Patch", combined enemies from several films, such as "Aliens", "Predator", and "The Terminator". Some add-on files were also made that changed the sounds made by the various characters and weapons.

Around 1994 and 1995, WADs were primarily distributed online over bulletin board systems or sold in collections on compact discs in computer shops, sometimes bundled with editing guide books. FTP servers became the primary method in later years. A few WADs have been released commercially, including the "Master Levels for Doom II", which was released in 1995 along with "Maximum Doom", a CD containing 1,830 WADs that had been downloaded from the Internet. Several thousand WADs have been created in total: the "idgames" FTP archive contains over 18,000 files, and this represents only a fraction of the complete output of "Doom" fans. Third-party programs were also written to handle the loading of various WADs, since the game is a DOS game and all commands had to be entered on the command line to run. A typical launcher would allow the player to select which files to load from a menu, making it much easier to start. In 1995, WizardWorks released the "D!Zone" pack featuring hundreds of levels for "Doom" and "Doom II". "D!Zone" was reviewed in "Dragon" by Jay & Dee; Jay gave the pack 1 out of 5 stars, while Dee gave the pack 1½ stars.

In 2016, Romero published two new "Doom" levels - E1M4b (""Phobos Mission Control"") and E1M8b (""Tech Gone Bad""). In 2018, for the 25th anniversary of DOOM, Romero announced an unofficial 5th Episodic pack of 9 levels. The 5th episode is titled "Sigil". The music for the 5th episode is composed entirely by Buckethead.

"Doom" became a problem at workplaces, both occupying the time of employees and clogging computer networks. Intel, Lotus Development, and Carnegie Mellon University were among many organizations reported to form policies specifically disallowing "Doom"-playing during work hours. At the Microsoft campus, "Doom" was by one account equal to a "religious phenomenon". Doom was #1 on "Computer Gaming World"s "Playing Lately?" survey for February 1994. One reader said that "No other game even compares to the addictiveness of NetDoom with four devious players! ... The only game I've stayed up 72+ straight hours to play", while another reported that "Linking four people together for a game of Doom is the quickest way to destroy a productive, boring evening of work".
Although Petersen said "Doom" was "nothing more than the computer equivalent of Whack-A-Mole", "Doom" received critical acclaim and was widely praised in the gaming press, broadly considered to be one of the most important and influential titles in gaming history. Upon release, "GamesMaster" gave it a 90% rating. "Dragon" gave it five stars, praising the improvements over "Wolfenstein 3D", the "fast-moving arcade shoot 'em up" gameplay, and network play. "Computer and Video Games" gave the game a 93% rating, praising its atmosphere and stating that "the level of texture-mapped detail and the sense of scale is awe inspiring", but criticized the occasionally repetitive gameplay and considered the violence excessive. A common criticism of "Doom" was that it was not a true 3D game, since the game engine did not allow corridors and rooms to be stacked on top of one another (room-over-room), and instead relied on graphical trickery to make it appear that the player character and enemies were moving along differing elevations.

"Computer Gaming World" stated in February 1994 that "Wolfenstein 3D" fans should "look forward to a delight of insomnia", and "Since networking is supported, bring along a friend to share in the visceral delights". A longer review in March 1994 said that "Doom" "was worth the wait ... a wonderfully involved and engaging game", and its technology "a new benchmark" for the gaming industry. The reviewer praised the "simply "dazzling"" graphics", and reported that "DeathMatches may be the most intense gaming experience available today". While criticizing the "ho-hum endgame" with a too-easy end boss, he concluded that "Doom" "is a virtuoso performance".

"Edge" criticized the "fairly simple" gameplay but praised the graphics and levels. The review concluded: "You’lI be longing for something new in this game. If only you could talk to these creatures, then perhaps you could try and make friends with them, form alliances... Now, that would be interesting." The sentiment attracted widespread mockery, and "if only you could talk to these creatures" became a running joke in gamer culture; however, a 2016 piece in the "International Business Times" defended the review as anticipating the dialogue systems of games such as "Skyrim", "Mass Effect" and "Undertale".

In 1994, "PC Gamer UK" named "Doom" the third best computer game of all time. The editors wrote, "Although it's only been around for a couple of months, "Doom" has already done more to establish the PC's arcade clout than any other title in gaming history." In 1994 "Computer Gaming World" named "Doom" Game of the Year.

In 1995, "Next Generation" said it was "The most talked about PC game ever – and with good reason. Running on a 486 machine (essential for maximum effect), "Doom" took PC graphics to a totally new level of speed, detail, and realism, and provided a genuinely scary degree of immersion in the gameworld."

In 1996, "Computer Gaming World" named it the fifth best video game of all time, and the third most-innovative game.

In 1998, "PC Gamer" declared it the 34th-best computer game ever released, and the editors called it "Probably the most imitated game of all time, "Doom" continued what "Wolfenstein 3D" began and elevated the fledgling 3D-shooter genre to blockbuster status".

In 2001, "Doom" was voted the number one game of all time in a poll among over 100 game developers and journalists conducted by GameSpy.

In 2003, IGN ranked it as the 44th top video game of all time and also called it ""the" breakthrough game of 1993", adding: "Its arsenal of powerful guns (namely the shotgun and BFG), intense level of gore and perfect balance of adrenaline-soaked action and exploration kept this gamer riveted for years." "PC Gamer" proclaimed "Doom" the most influential game of all time in its ten-year anniversary issue in April 2004.

In 2004, readers of "Retro Gamer" voted "Doom" as the ninth top retro game, with the editors commenting: "Only a handful of games can claim that they've changed the gaming world, and "Doom" is perhaps the most qualified of them all." In 2005, IGN ranked it as the 39th top game.

On March 12, 2007, "The New York Times" reported that "Doom" was named to a list of the ten most important video games of all time, the so-called game canon. The Library of Congress took up this video game preservation proposal and began with the games from this list.

In 2009, GameTrailers ranked "Doom" as the number one "breakthrough PC game". That year "Game Informer" put "Doom" sixth on the magazine's list of the top 200 games of all time, stating that it gave "the genre the kick start it needed to rule the gaming landscape two decades later." "Game Informer" staff also put it sixth on their 2001 list of the 100 best games ever. IGN included "Doom" at 2nd place in the "Top 100 Video Game Shooters of all Time", just behind "Half-Life", citing the game's "feel of running and gunning", memorable weapons and enemies, pure and simple fun and its spreading on nearly every gaming platform in existence.

In 2012, "Time" named it one of the 100 greatest video games of all time as "it established the look and feel of later shooters as surely as Xerox PARC established the rules of the virtual desktop," adding that "its impact also owes a lot to the gonzo horror sensibility of its designers, including John Romero, who showed a bracing lack of restraint in their deployment of gore and Satanic iconography." Including "Doom" on the list of the greatest games of all time, GameSpot wrote that "despite its numerous appearances in other formats and on other media, longtime fans will forever remember the original 1993 release of "Doom" as the beginning of a true revolution in action gaming."

The game has been ported to numerous console gaming platforms both domestically and abroad where it maintained its popularity, receiving generally favorable critical reception.

With the release of "Doom", id Software quickly found itself making $100,000 daily. Sandy Petersen later remarked that the game "sold a couple of hundred thousand copies during its first year or so", as piracy kept its initial sales from rising higher. Experts estimate that the game sold approximately 2-3 million physical copies from its release through 1999. According to PC Data, which tracked sales in the United States, the "Doom" shareware edition sold 1.15 million copies by September 1999. The "Ultimate Doom" SKU reached sales of 787,397 units by that date. At the time, PC Data ranked them as the country's eighth- and 20th-best-selling computer games since January 1993. In addition to its sales, the game's status as shareware dramatically increased its market penetration. "PC Zone"s David McCandless wrote that the game was played by "an estimated six million people across the globe", while other sources estimate that 10–20 million people played "Doom" within 24 months of its launch.

"Doom" was notorious for its high levels of graphic violence and satanic imagery, which generated controversy from a broad range of groups. "Doom" for the Genesis 32X was one of the first video games to be given an M for Mature rating from the Entertainment Software Rating Board due to its violent gore and nature. Yahoo! Games listed it as one of the top ten most controversial games of all time. It was criticized by religious organizations for its diabolic undertones and was dubbed a "mass murder simulator" by critic and Killology Research Group founder David Grossman. "Doom" prompted fears that the then-emerging virtual reality technology could be used to simulate extremely realistic killing.

The game again sparked controversy in the United States when it was found that Eric Harris and Dylan Klebold, who committed the Columbine High School massacre on April 20, 1999, were avid players of the game. While planning for the massacre, Harris said in his journal that the killing would be "like playing "Doom"", and "it'll be like the LA riots, the Oklahoma bombing, World War II, Vietnam, "Duke Nukem" and "Doom" all mixed together", and that his shotgun was "straight out of the game". A rumor spread afterwards that Harris had designed a "Doom" level that looked like the high school, populated with representations of Harris's classmates and teachers, and that he practiced for the shootings by playing the level over and over. Although Harris did design custom "Doom" levels (which later became known as the 'Harris levels'), none have been found to be based on Columbine High School.

In the earliest release versions, the level E1M4: Command Control contained a swastika-shaped structure, which was put in as a homage to "Wolfenstein 3D". The swastika was removed in later versions; according to Romero, the change was done out of respect after id Software received a complaint from a military veteran.

"Doom" has appeared in several forms in addition to video games, including a "Doom" comic book, four novels by Dafydd Ab Hugh and Brad Linaweaver (loosely based on events and locations in the games), a and a live-action film starring Karl Urban and The Rock released in 2005. The game's development and impact on popular culture is also the subject of the book "Masters of Doom: How Two Guys Created an Empire and Transformed Pop Culture" by David Kushner.

The "Doom" series remained dormant between 1997 and 2000, when "Doom 3" was finally announced. A retelling of the original "Doom" using entirely new graphics technology and a slower paced survival horror approach, "Doom 3" was hyped to provide as large a leap in realism and interactivity as the original game and helped renew interest in the franchise when it was released in 2004, under the id Tech 4 game engine.

The series again remained dormant for 10 years until a remake, simply titled "Doom" and running on the new id Tech 6, was announced with a beta access to players that had pre-ordered "". The game held its closed alpha multiplayer testing in October 2015, as closed and open beta access ran during March to April 2016. Returning to the series' roots in fast-paced action and minimal storytelling, the full game eventually released worldwide on May 13, 2016. The project initially started as "Doom 4" in May 2008, set to be a remake of "Doom II: Hell on Earth" and ditching the survival horror aspect of "Doom 3". Development completely restarted as id's Tim Willits remarked that "Doom 4" was "lacking the personality of the long-running shooter franchise".

"Doom" was influential and dozens of new first-person shooter titles appeared following "Doom" release, and they were often referred to as ""Doom" clones" rather than "first-person shooters". The term ""Doom" clone" was used to describe the style of gameplay in "Doom"-style games. While the term was initially popular, it was, after 1996, gradually replaced by "first-person shooter", and the phrase "first-person shooter" had firmly superseded ""Doom" clone" around 1998. Some of these were certainly "clones", hastily assembled and quickly forgotten, while others explored new grounds of the genre and were highly acclaimed. Many of the games closely imitated features in "Doom" such as the selection of weapons and cheat codes. "Doom" principal rivals were Apogee's "Rise of the Triad" and Looking Glass Studios' "System Shock". The popularity of "Star Wars"-themed WADs is rumored to have been the factor that prompted LucasArts to create their first-person shooter "Dark Forces".

The "Doom" game engine was licensed by id Software to several other companies, who released their own games using the technology, including "Heretic", "", "Strife: Quest for the Sigil", and "Hacx: Twitch 'n Kill". A "Doom"-based game called "Chex Quest" was released in 1996 by Ralston Foods as a promotion to increase cereal sales, and the United States Marine Corps released "Marine Doom".

When 3D Realms released "Duke Nukem 3D" in 1996, a tongue-in-cheek science fiction shooter based on Ken Silverman's technologically similar "Build" engine, id Software had nearly finished developing "Quake", its next-generation game, which mirrored "Doom"s success for much of the remainder of the 1990s and reduced interest in its predecessor (Wolfenstein 3D).

In addition to the thrilling nature of the single-player game, the deathmatch mode was an important factor in the game's popularity. "Doom" was not the first first-person shooter with a deathmatch mode; "Maze War", an FPS released in 1974, was running multiplayer deathmatch over ethernet on Xerox computers by 1977. The widespread distribution of PC systems and the violence in "Doom" made deathmatching particularly attractive. Two-player multiplayer was possible over a phone line by using a modem, or by linking two PCs with a null-modem cable. Because of its widespread distribution, "Doom" hence became the game that introduced deathmatching to a large audience and was also the first game to use the term "deathmatch".

Although the popularity of the "Doom" games dropped with the release of more modern first-person shooters, the game still retains a strong fan base that continues to this day by playing competitively and creating WADs, and "Doom"-related news is still tracked at multiple websites such as Doomworld. Interest in "Doom" was renewed in 1997, when the source code for the "Doom" engine was released (it was also placed under the GNU General Public License on October 3, 1999). Fans then began porting the game to various operating systems, even to previously unsupported platforms such as the Dreamcast. As for the PC, over 50 different "Doom" source ports have been developed. New features such as OpenGL rendering and scripting allow WADs to alter the gameplay more radically.

Devoted players have spent years creating speedruns for "Doom", competing for the quickest completion times and sharing knowledge about routes through the levels and how to exploit bugs in the "Doom" engine for shortcuts. Achievements include the completion of both "Doom" and "Doom II" on the "Ultra-Violence" difficulty setting in less than 30 minutes each. In addition, a few players have also managed to complete "Doom II" in a single run on the difficulty setting "Nightmare!", on which monsters are more aggressive, launch faster projectiles (or, in the case of the Pinky Demon, simply move faster), and respawn roughly 30 seconds after they have been killed (level designer John Romero characterized the idea of such a run as "[just having to be] impossible"). Movies of most of these runs are available from the COMPET-N website.

Online co-op and deathmatch play are still continued on fan created services.




</doc>
<doc id="8522" url="https://en.wikipedia.org/wiki?curid=8522" title="Denver">
Denver

Denver (), officially the City and County of Denver, is the capital and most populous municipality of the U.S. state of Colorado. Denver is located in the South Platte River Valley on the western edge of the High Plains just east of the Front Range of the Rocky Mountains. With an estimated population of 727,211 in 2019, Denver is the 19th-most populous city in the United States, the fifth-most populous state capitol, and the most populous city located in the Mountain states. The metropolitan area surrounding Denver represents a majority of the population and economic activity in the Front Range region, an area within which an estimated 85% of Colorado's population lives. The Denver downtown district is immediately east of the confluence of Cherry Creek with the South Platte River, approximately east of the foothills of the Rocky Mountains. Denver is named after James W. Denver, a governor of the Kansas Territory. It is nicknamed the "Mile High City" because its official elevation is exactly one mile () above sea level. The 105th meridian west of Greenwich, the longitudinal reference for the Mountain Time Zone, passes directly through Denver Union Station.
Denver is ranked as a Beta world city by the Globalization and World Cities Research Network. The 10-county Denver-Aurora-Lakewood, CO Metropolitan Statistical Area had an estimated 2018 population of 2,932,415 and was the 19th most populous U.S. metropolitan statistical area. The 12-city Denver-Aurora, CO Combined Statistical Area had an estimated 2018 population of 3,572,798 and was the 15th most populous U.S. metropolitan area. Denver was the most populous city of the 18-county Front Range Urban Corridor, an oblong urban region stretching across two states with an estimated 2018 population of 4,976,781. Denver is the most populous city within a radius and the second-most populous city in the Mountain West after Phoenix, Arizona. In 2016, Denver was named the best place to live in the United States by "U.S. News & World Report".

In the summer of 1858, during the Pike's Peak Gold Rush, a group of gold prospectors from Lawrence, Kansas established Montana City as a mining town on the banks of the South Platte River in what was then western Kansas Territory. This was the first historical settlement in what was later to become the city of Denver. The site faded quickly, however, and by the summer of 1859 it was abandoned in favor of Auraria (named after the gold-mining town of Auraria, Georgia) and St. Charles City.

On November 22, 1858, General William Larimer and Captain Jonathan Cox, Esquire, both land speculators from eastern Kansas Territory, placed cottonwood logs to stake a claim on the bluff overlooking the confluence of the South Platte River and Cherry Creek, across the creek from the existing mining settlement of Auraria, and on the site of the existing townsite of St. Charles. Larimer named the townsite Denver City to curry favor with Kansas Territorial Governor James W. Denver. Larimer hoped the town's name would help it be selected as the county seat of Arapaho County but, unbeknownst to him, Governor Denver had already resigned from office. The location was accessible to existing trails and was across the South Platte River from the site of seasonal encampments of the Cheyenne and Arapaho. The site of these first towns is now occupied by Confluence Park near downtown Denver.

Larimer, along with associates in the St. Charles City Land Company, sold parcels in the town to merchants and miners, with the intention of creating a major city that would cater to new immigrants. Denver City was a frontier town, with an economy based on servicing local miners with gambling, saloons, livestock and goods trading. In the early years, land parcels were often traded for grubstakes or gambled away by miners in Auraria. In May 1859, Denver City residents donated 53 lots to the Leavenworth & Pike's Peak Express in order to secure the region's first overland wagon route. Offering daily service for "passengers, mail, freight, and gold", the Express reached Denver on a trail that trimmed westward travel time from twelve days to six. In 1863, Western Union furthered Denver's dominance of the region by choosing the city for its regional terminus.

The Colorado Territory was created on February 28, 1861, Arapahoe County was formed on November 1, 1861, and Denver City was incorporated on November 7, 1861. Denver City served as the Arapahoe County Seat from 1861 until consolidation in 1902. In 1867, Denver City became the acting territorial capital, and in 1881 was chosen as the permanent state capital in a statewide ballot. With its newfound importance, Denver City shortened its name to Denver. On August 1, 1876, Colorado was admitted to the Union.
Although by the close of the 1860s, Denver residents could look with pride at their success establishing a vibrant supply and service center, the decision to route the nation's first transcontinental railroad through Cheyenne, rather than Denver, threatened the prosperity of the young town. The transcontinental railroad passed a daunting 100 miles away, but citizens mobilized to build a railroad to connect Denver to it. Spearheaded by visionary leaders including Territorial Governor John Evans, David Moffat, and Walter Cheesman, fundraising began. Within three days, $300,000 had been raised, and citizens were optimistic. Fundraising stalled before enough was raised, forcing these visionary leaders to take control of the debt-ridden railroad. Despite challenges, on June 24, 1870, citizens cheered as the Denver Pacific completed the link to the transcontinental railroad, ushering in a new age of prosperity for Denver.

Finally linked to the rest of the nation by rail, Denver prospered as a service and supply center. The young city grew during these years, attracting millionaires with their mansions, as well as a mixture of crime and poverty of a rapidly growing city. Denver citizens were proud when the rich chose Denver and were thrilled when Horace Tabor, the Leadville mining millionaire, built an impressive business block at 16th and Larimer, as well as the elegant Tabor Grand Opera House. Luxurious hotels, including the much-loved Brown Palace Hotel, soon followed, as well as splendid homes for millionaires, such as the Croke, Patterson, Campbell Mansion at 11th and Pennsylvania and the now-demolished Moffat Mansion at 8th and Grant. Intent on transforming Denver into one of the world's great cities, leaders wooed industry and attracted laborers to work in these factories.

Soon, in addition to the elite and a large middle class, Denver had a growing population of immigrant German, Italian, and Chinese laborers, soon followed by African Americans from the Deep South and Hispanic workers. The influx of the new residents strained available housing. In addition, the Silver Crash of 1893 unsettled political, social, and economic balances. Competition among the different ethnic groups was often expressed as bigotry, and social tensions gave rise to the Red Scare. Americans were suspicious of immigrants who were sometimes allied with socialist and labor union causes. After World War I, a revival of the Ku Klux Klan attracted white native-born Americans who were anxious about the many changes in society. Unlike the earlier organization that was active in the rural South, KKK chapters developed in urban areas of the Midwest and West, including Denver, and into Idaho and Oregon. Corruption and crime also developed in Denver.
Between 1880 and 1895 the city underwent a huge rise in corruption, as crime bosses, such as Soapy Smith, worked side by side with elected officials and the police to control elections, gambling, and bunco gangs. The city also suffered a depression in 1893 after the crash of silver prices. In 1887, the precursor to the international charity United Way was formed in Denver by local religious leaders, who raised funds and coordinated various charities to help Denver's poor. By 1890, Denver had grown to be the second-largest city west of Omaha, Nebraska. In 1900, whites represented 96.8% of Denver's population. The African American and Hispanic populations increased with migrations of the 20th century. Many African Americans first came as workers on the railroad, which had a terminus in Denver, and began to settle there.

Between the 1880s and 1930s, Denver's floriculture industry developed and thrived. This period became known locally as the Carnation Gold Rush.

A bill proposing a state constitutional amendment to allow home rule for Denver and other municipalities was introduced in the legislature in 1901 and passed. The measure called for a statewide referendum, which voters approved in 1902. On December 1 that year Governor James Orman proclaimed the amendment part of the state's fundamental law. The City and County of Denver came into being on that date and was separated from Arapahoe and Adams Counties.

Early in the 20th century, Denver, like many other cities, was home to a pioneering Brass Era car company. The Colburn Automobile Company made cars copied from one of its contemporaries, Renault.

From 1953 to 1989, the Rocky Flats Plant, a DOE nuclear weapon facility that was about 15 miles from Denver, produced fissile plutonium "pits" for nuclear warheads. A major fire at the facility in 1957, as well as leakage from nuclear waste stored at the site between 1958 and 1968, resulted in the contamination of some parts of Denver, to varying degrees, with plutonium-239, a harmful radioactive substance with a half-life of 24,200 years. A 1981 study by the Jefferson County health director, Dr. Carl Johnson linked the contamination to an increase in birth defects and cancer incidence in central Denver and nearer Rocky Flats. Later studies confirmed many of his findings. Plutonium contamination was still present outside the former plant site . It presents risks to building the envisioned Jefferson Parkway, which would complete Denver's automotive beltway.
In 1970, Denver was selected to host the 1976 Winter Olympics to coincide with Colorado's centennial celebration, but in November 1972, Colorado voters struck down ballot initiatives allocating public funds to pay for the high costs of the games. They were moved to Innsbruck, Austria. The notoriety of becoming the only city ever to decline to host an Olympiad after being selected has made subsequent bids difficult. The movement against hosting the games was based largely on environmental issues and was led by State Representative Richard Lamm. He was subsequently elected to three terms (1975–87) as Colorado governor. Denver explored a potential bid for the 2022 Winter Olympics, but no bid was submitted.

In 2010, Denver adopted a comprehensive update of its zoning code. The new zoning was developed to guide development as envisioned in adopted plans such as Blueprint Denver, Transit Oriented Development Strategic Plan, Greenprint Denver, and the Strategic Transportation Plan.

Denver has hosted the Democratic National Convention twice, in 1908 and again in 2008. It promoted the city on the national, political, and socioeconomic stage. On August 10–15, 1993, Denver hosted the Catholic Church's 6th World Youth Day, which was attended by an estimated 500,000, making it the largest gathering in Colorado history.

Denver has been known historically as the "Queen City of the Plains" and the "Queen City of the West", because of its important role in the agricultural industry of the High Plains region in eastern Colorado and along the foothills of the Colorado Front Range. Several U.S. Navy ships have been named in honor of the city.

Denver is in the center of the Front Range Urban Corridor, between the Rocky Mountains to the west and the High Plains to the east. Denver's topography consists of plains in the city center with hilly areas to the north, west and south. According to the United States Census Bureau the city has a total area of , of which is land and (1.1%) is water. The City and County of Denver is surrounded by only three other counties: Adams County to the north and east, Arapahoe County to the south and east, and Jefferson County to the west.

Although Denver's nickname is the "Mile-High City" because its official elevation is one mile above sea level, defined by the elevation of the spot of a benchmark on the steps of the State Capitol building, the elevation of the entire city ranges from . According to Geographic Names Information System (GNIS) and the National Elevation Dataset, the city's elevation is , which is reflected on various websites such as the National Weather Service.

As of January 2013, the City and County of Denver has defined 78 official neighborhoods that the city and community groups use for planning and administration. Although the city's delineation of the neighborhood boundaries is somewhat arbitrary, it corresponds roughly to the definitions used by residents. These "neighborhoods" should not be confused with cities or suburbs, which may be separate entities within the metro area.

The character of the neighborhoods varies significantly from one to another and includes everything from large skyscrapers to houses from the late 19th century to modern, suburban-style developments. Generally, the neighborhoods closest to the city center are denser, older and contain more brick building material. Many neighborhoods away from the city center were developed after World War II, and are built with more modern materials and style. Some of the neighborhoods even farther from the city center, or recently redeveloped parcels anywhere in the city, have either very suburban characteristics or are new urbanist developments that attempt to recreate the feel of older neighborhoods.

Denver does not have larger area designations, unlike the City of Chicago, which has larger areas that house the neighborhoods (IE: Northwest Side). Denver residents use the terms "north", "south", "east", and "west".

Denver also has a number of neighborhoods not reflected in the administrative boundaries. These neighborhoods may reflect the way people in an area identify themselves or they might reflect how others, such as real estate developers, have defined those areas. Well-known non-administrative neighborhoods include the historic and trendy LoDo (short for "Lower Downtown"), part of the city's Union Station neighborhood; Uptown, straddling North Capitol Hill and City Park West; Curtis Park, part of the Five Points neighborhood; Alamo Placita, the northern part of the Speer neighborhood; Park Hill, a successful example of intentional racial integration; and Golden Triangle, in the Civic Center. 

One of Denver's newer neighborhoods was built on the former site of Stapleton International Airport, which was named after former Denver mayor Benjamin Stapleton, who was a member of the Ku Klux Klan. In 2020, the neighborhood's community association voted to change the neighborhood's name from Stapleton to Central Park (see more in Politics section below).

Denver lies within the semi-arid, continental climate zone (Köppen climate classification: "BSk"). Despite having a partially dry climate, data from the University of Melbourne shows that Denver is influenced by other climates that are possibly a consequence of the adjacent elevation that changes precipitation and temperature. Humid continental and subtropical microclimates can be found. It has four distinct seasons and receives most of its precipitation from April through August. Due to its inland location on the High Plains, at the foot of the Rocky Mountains, the region can be subject to sudden changes in weather.

July is the warmest month, with an average high temperature of . Summers range from warm to hot with occasional, sometimes severe, afternoon thunderstorms and high temperatures reaching on 38 days annually, and occasionally . December, the coldest month of the year, has an average daily high temperature of . Winters consist of periods of snow and very low temperatures alternating with periods of milder weather due to the warming effect of Chinook winds. In winter, daytime highs can exceed but also often fail to reach during periods of cold weather and can even fail to rise above on occasion. On the coldest nights of the year, lows can fall to or below. Snowfall is common throughout the late fall, winter and early spring, averaging for 1981–2010. The average window for measurable (≥) snow is October 17 through April 27; however, measurable snowfall has fallen in Denver as early as September 4 and as late as June 3. Extremes in temperature range from on January 9, 1875, up to as recently as June 28, 2018. Due to the city's high elevation and aridity, diurnal temperature variation is large throughout the year.

Tornadoes are rare west of the I-25 corridor; however, one notable exception was an F3 tornado that struck 4.4 miles south of downtown on June 15, 1988. On the other hand, the suburbs east of Denver and the city's east-northeastern extension (Denver International Airport) can see a few tornadoes, often weak landspout tornadoes, each spring and summer especially during June with the enhancement of the Denver Convergence Vorticity Zone (DCVZ). The DCVZ, also known as the Denver Cyclone, is a variable vortex of storm-forming air flow usually found north and east of downtown, and which often includes the airport. Heavy weather from the DCVZ can disrupt airport operations. In a study looking at hail events in areas with a population of at least 50,000, Denver was found to be ranked 10th most prone to hail storms in the continental United States. In fact, Denver has received 3 of the top 10 costliest hailstorms in United States history, which occurred on July 11, 1990; July 20, 2009; and May 8, 2017 respectively.

Based on 30-year averages obtained from NOAA's National Climatic Data Center for the months of December, January and February, Weather Channel ranked Denver the 18th coldest major U.S. city .

Denver’s official weather station is at Denver International Airport, roughly 20 miles from downtown. A 2019 analysis showed the average temperature at Denver International Airport, , was significantly cooler than downtown, . Many of the suburbs also have warmer temperatures and there is controversy regarding the location of the official temperature readings.

As of the 2010 census, the population of the City and County of Denver was 600,158, making it the 24th most populous U.S. city. The Denver-Aurora-Lakewood, CO Metropolitan Statistical Area had an estimated 2013 population of 2,697,476 and ranked as the 21st most populous U.S. metropolitan statistical area, and the larger Denver-Aurora-Boulder Combined Statistical Area had an estimated 2013 population of 3,277,309 and ranked as the 16th most populous U.S. metropolitan area. Denver is the most populous city within a radius centered in the city and of magnitude. Denverites is a term used for residents of Denver.

According to the 2010 census, the City and County of Denver contained 600,158 people and 285,797 households. The population density was 3,698 inhabitants per square mile (1,428/km) including the airport. There were 285,797 housing units at an average density of 1,751 per square mile (676/km). However, the average density throughout most Denver neighborhoods tends to be higher. Without the 80249 zip code (47.3 sq mi, 8,407 residents) near the airport, the average density increases to around 5,470 per square mile. Denver, Colorado, is at the top of the list of 2017 Best Places to Live, according to "U.S. News & World Report", landing a place in the top two in terms of affordability and quality of lifestyle.

According to the 2010 United States Census, the racial composition of Denver was as follows:


Approximately 70.3% of the population (over five years old) spoke only English at home. An additional 23.5% of the population spoke Spanish at home. In terms of ancestry, 31.8% were Hispanic or Latino, 14.6% of the population were of German ancestry, 9.7% were of Irish ancestry, 8.9% were of English ancestry, and 4.0% were of Italian ancestry.

There were 250,906 households, of which 23.2% had children under the age of 18 living with them, 34.7% were married couples living together, 10.8% had a female householder with no husband present, and 50.1% were non-families. 39.3% of all households were made up of individuals, and 9.4% had someone living alone who was 65 years of age or older. The average household size was 2.27, and the average family size was 3.14.

Age distribution was 22.0% under the age of 18, 10.7% from 18 to 24, 36.1% from 25 to 44, 20.0% from 45 to 64, and 11.3% who were 65 years of age or older. The median age was 33 years. Overall there were 102.1 males for every 100 females. Due to a skewed sex ratio wherein single men outnumber single women, some protologists had nicknamed the city as "Menver".

The median household income was $45,438, and the median family income was $48,195. Males had a median income of $36,232 versus $33,768 for females. The per capita income for the city was $24,101. 19.1% of the population and 14.6% of families were below the poverty line. Out of the total population, 25.3% of those under the age of 18 and 13.7% of those 65 and older were living below the poverty line.

, 72.28% (386,815) of Denver residents aged five and older spoke only English at home, while 21.42% (114,635) spoke Spanish, 0.85% (4,550) Vietnamese, 0.57% (3,073) African languages, 0.53% (2,845) Russian, 0.50% (2,681) Chinese, 0.47% (2,527) French, and 0.46% (2,465) German. In total, 27.72% (148,335) of Denver's population aged five and older spoke a language other than English.

According to a report in the Journal of the American Medical Association, residents of Denver had a 2014 life expectancy of 80.02 years.

The Denver MSA has a gross metropolitan product of $157.6 billion in 2010, making it the 18th largest metro economy in the United States. Denver's economy is based partially on its geographic position and its connection to some of the country's major transportation systems. Because Denver is the largest city within , it has become a natural location for storage and distribution of goods and services to the Mountain States, Southwest states, as well as all western states. Another benefit for distribution is that Denver is nearly equidistant from large cities of the Midwest, such as Chicago and St. Louis and some large cities of the West Coast, such as Los Angeles and San Francisco.

Over the years, the city has been home to other large corporations in the central United States, making Denver a key trade point for the country. Several well-known companies originated in or have relocated to Denver. William Ainsworth opened the Denver Instrument Company in 1895 to make analytical balances for gold assayers. Its factory is now in Arvada. AIMCO (NYSE: AIV)—the largest owner and operator of apartment communities in the United States, with approximately 870 communities comprising nearly 136,000 units in 44 states—is headquartered in Denver, employing approximately 3,500 people. Also Samsonite Corp., the world's largest luggage manufacturer, began in Denver in 1910 as Shwayder Trunk Manufacturing Company, but Samsonite closed its NE Denver factory in 2001, and moved its headquarters to Massachusetts after a change of ownership in 2006. The Mountain States Telephone & Telegraph Company, founded in Denver in 1911, is now a part of telecommunications giant CenturyLink.

On October 31, 1937, Continental Airlines, now United Airlines, moved its headquarters to Stapleton Airport in Denver, Colorado. Robert F. Six arranged to have the headquarters moved to Denver from El Paso, Texas because Six believed that the airline should have its headquarters in a large city with a potential base of customers.
MediaNews Group purchased the "Denver Post" in 1987; the company is based in Denver. The Gates Corporation, the world's largest producer of automotive belts and hoses, was established in S. Denver in 1919. Russell Stover Candies made its first chocolate candy in Denver in 1923, but moved to Kansas City in 1969. The Wright & McGill Company has been making its Eagle Claw brand of fishing gear in NE Denver since 1925. The original Frontier Airlines began operations at Denver's old Stapleton International Airport in 1950; Frontier was reincarnated at DIA in 1994. Scott's Liquid Gold, Inc., has been making furniture polish in Denver since 1954. Village Inn restaurants began as a single pancake house in Denver in 1958. Big O Tires, LLC, of Centennial opened its first franchise in 1962 in Denver. The Shane Company sold its first diamond jewelry in 1971 in Denver. In 1973 Re/Max made Denver its headquarters. Johns Manville Corp., a manufacturer of insulation and roofing products, relocated its headquarters to Denver from New York in 1972. CH2M Hill, an engineering and construction firm, relocated from Oregon to the Denver Technological Center in 1980. The Ball Corporation sold its glass business in Indiana in the 1990s and moved to suburban Broomfield; Ball has several operations in greater Denver.

Molson Coors Brewing Company established its U.S. headquarters in Denver in 2005, but announced its departure in 2019. Its subsidiary and regional wholesale distributor, Coors Distributing Company, is in NW Denver. The Newmont Mining Corporation, the second-largest gold producer in North America and one of the largest in the world, is headquartered in Denver. MapQuest, an online site for maps, directions and business listings, is headquartered in Denver's LoDo district.

Large Denver-area employers that have headquarters elsewhere include Lockheed Martin Corp., United Airlines, Kroger Co. and Xcel Energy, Inc.

Geography also allows Denver to have a considerable government presence, with many federal agencies based or having offices in the Denver area. Along with federal agencies come many companies based on US defense and space projects, and more jobs are brought to the city by virtue of its being the capital of the state of Colorado. The Denver area is home to the former nuclear weapons plant Rocky Flats, the Denver Federal Center, Byron G. Rogers Federal Building and United States Courthouse, the Denver Mint, and the National Renewable Energy Laboratory.

In 2005, a $310.7 million expansion for the Colorado Convention Center was completed, doubling its size. The hope was the center's expansion would elevate the city to one of the top 10 cities in the nation for holding a convention.

Denver's position near the mineral-rich Rocky Mountains encouraged mining and energy companies to spring up in the area. In the early days of the city, gold and silver booms and busts played a large role in the city's economic success. In the 1970s and early 1980s, the energy crisis in America and resulting high oil prices created an energy boom in Denver captured in the soap opera "Dynasty". Denver was built up considerably during this time with the construction of many new downtown skyscrapers. When the price of oil dropped from $34 a barrel in 1981 to $9 a barrel in 1986, the Denver economy also dropped, leaving almost 15,000 oil industry workers in the area unemployed (including former mayor and governor John Hickenlooper, a former geologist), and the nation's highest office vacancy rate (30%). The industry has recovered and the region has 700 employed petroleum engineers. Advances in hydraulic fracturing have made the DJ Basin of Colorado into an accessible and lucrative oil play. Energy and mining are still important in Denver's economy today, with companies such as EnCana, Halliburton, Smith International, Rio Tinto Group, Newmont Mining, and Noble Energy, headquartered or having significant operations. Denver is in 149th place in terms of the cost of doing business in the United States.
Denver's west-central geographic location in the Mountain Time Zone (UTC−7) also benefits the telecommunications industry by allowing communication with both North American coasts, South America, Europe, and Asia in the same business day. Denver's location on the 105th meridian at over one mile (1.6 km) in elevation also enables it to be the largest city in the U.S. to offer a "one-bounce" real-time satellite uplink to six continents in the same business day. Qwest Communications now part of CenturyLink, Dish Network Corporation, Starz, DIRECTV, and Comcast are a few of the many telecommunications companies with operations in the Denver area. These and other high-tech companies had a boom in Denver in the mid to late 1990s. After a rise in unemployment in the Great Recession, Denver's unemployment rate recovered and had one of the lowest unemployment rates in the nation at 2.6% in November 2016. As of December 2016, the unemployment rate for the Denver-Aurora-Broomfield MSA is 2.6%. The Downtown region has seen increased real estate investment with the construction of several new skyscrapers from 2010 onward and major development around Denver Union Station.

Denver has also enjoyed success as a pioneer in the fast-casual restaurant industry, with many popular national chain restaurants founded and based in Denver. Chipotle Mexican Grill, Quiznos, and Smashburger were founded and headquartered in Denver. Qdoba Mexican Grill, Noodles & Company, and Good Times Burgers & Frozen Custard originated in Denver, but have moved their headquarters to the suburbs of Wheat Ridge, Broomfield, and Golden, respectively.

In 2015, Denver ranked No. 1 on "Forbes"' list of the Best Places for Business and Careers.

Apollo Hall opened soon after the city's founding in 1859 and staged many plays for eager settlers. In the 1880s Horace Tabor built Denver's first opera house. After the start of the 20th century, city leaders embarked on a city beautification program that created many of the city's parks, parkways, museums, and the Municipal Auditorium, which was home to the 1908 Democratic National Convention and is now known as the Ellie Caulkins Opera House. Denver and the metropolitan areas around it continued to support culture. In 1988, voters in the Denver Metropolitan Area approved the Scientific and Cultural Facilities Tax (commonly known as SCFD), a 0.1% (1 cent per $10) sales tax that contributes money to various cultural and scientific facilities and organizations throughout the Metro area. The tax was renewed by voters in 1994 and 2004 and allows the SCFD to operate until 2018.

Denver is home to a wide array of museums. Denver has many nationally recognized museums, including a new wing for the Denver Art Museum by world-renowned architect Daniel Libeskind, the second largest Performing Arts Center in the nation after Lincoln Center in New York City and bustling neighborhoods such as LoDo, filled with art galleries, restaurants, bars and clubs. That is part of the reason why Denver was, in 2006, recognized for the third year in a row as the best city for singles. Denver's neighborhoods also continue their influx of diverse people and businesses while the city's cultural institutions grow and prosper. The city acquired the estate of abstract expressionist painter Clyfford Still in 2004 and built a museum to exhibit his works near the Denver Art Museum.
The Denver Museum of Nature and Science holds an aquamarine specimen valued at over $1 million, as well as specimens of the state mineral, rhodochrosite. Every September the Denver Mart, at 451 E. 58th Avenue, hosts a gem and mineral show. The state history museum, History Colorado Center, opened in April 2012. It features hands-on and interactive exhibits, artifacts and programs about Colorado history. It was named in 2013 by "True West Magazine" as one of the top-ten "must see" history museums in the country. History Colorado's Byers-Evans House Museum and the Molly Brown House are nearby.

Denver has numerous art districts around the city, including Denver's Art District on Santa Fe and the River North Art District (RiNo).
While Denver may not be as recognized for historical musical prominence as some other American cities, it has an active pop, jazz, jam, folk, metal, and classical music scene, which has nurtured several artists and genres to regional, national, and even international attention. Of particular note is Denver's importance in the folk scene of the 1960s and 1970s. Well-known folk artists such as Bob Dylan, Judy Collins and John Denver lived in Denver at various points during this time and performed at local clubs. Three members of the widely popular group Earth, Wind, and Fire are also from Denver. More recent Denver-based artists include Nathaniel Rateliff & the Night Sweats, The Lumineers, Air Dubai, The Fray, Flobots, Cephalic Carnage, Axe Murder Boyz, Deuce Mob, Havok, Bloodstrike, Primitive Man, and Five Iron Frenzy.

Because of its proximity to the mountains and generally sunny weather, Denver has gained a reputation as being a very active, outdoor-oriented city. Many Denver residents spend the weekends in the mountains; skiing in the winter and hiking, climbing, kayaking, and camping in the summer.

Denver and surrounding cities are home to a large number of local and national breweries. Many of the region's restaurants have on-site breweries, and some larger brewers offer tours, including Coors and New Belgium Brewing Company. The city also welcomes visitors from around the world when it hosts the annual Great American Beer Festival each fall.

Denver used to be a major trading center for beef and livestock when ranchers would drive (or later transport) cattle to the Denver Union Stockyards for sale. As a celebration of that history, for more than a century Denver has hosted the annual National Western Stock Show, attracting as many as 10,000 animals and 700,000 attendees. The show is held every January at the National Western Complex northeast of downtown.

Denver has one of the country's largest populations of Mexican Americans and hosts four large Mexican American celebrations: Cinco de Mayo (with over 500,000 attendees), in May; El Grito de la Independencia, in September; the annual Lowrider show, and the Dia De Los Muertos art shows/events in North Denver's Highland neighborhood, and the Lincoln Park neighborhood in the original section of West Denver.

Denver is also famous for its dedication to New Mexican cuisine and the chile. It is best known for its green and red chile sauce, Colorado burrito, Southwest (Denver) omelette, breakfast burrito, empanadas, chiles rellenos, and tamales. Denver is also well known for other types of food such as Rocky Mountain oysters, rainbow trout, and the Denver sandwich.

The Dragon Boat Festival in July, Moon Festival in September and Chinese New Year are annual events in Denver for the Chinese and Asian-American communities. Chinese hot pot (huo guo) and Korean BBQ restaurants have been growing in popularity. The Denver area has 2 Chinese newspapers, the "Chinese American Post" and the "Colorado Chinese News".

Denver has long been a place tolerant of the Lesbian, Gay, Bisexual, Transgender, and Queer (LGBTQ) community. Many gay bars can be found on Colfax Avenue and on South Broadway. Every June, Denver hosts the annual Denver PrideFest in Civic Center Park, the largest LGBTQ Pride festival in the Rocky Mountain region.

Denver is the setting for "The Bill Engvall Show", Tim Allen's Last Man Standing and of MTV's "The Real World". It was also the setting for the prime time drama "Dynasty" from 1981 to 1989 (although the show was mostly filmed in Los Angeles). From 1998 to 2002 the city's Alameda East Veterinary Hospital was home to the Animal Planet series "Emergency Vets", which spun off three documentary specials and the current Animal Planet series "E-Vet Interns". The city is also the setting for the Disney Channel sitcom "Good Luck Charlie".

Denver is home to a variety of sports teams and is one of 13 U.S. cities with teams from four major sports (the Denver metro area is the smallest metropolitan area to have a team in all four major sports). Including MLS soccer, it is one of 10 cities to have five major sports teams. The Denver Broncos of the National Football League have drawn crowds of over 70,000 since their origins in the early 1960s, and continue to draw fans today to their current home Empower Field at Mile High. The Broncos have sold out every home game (except for strike-replacement games) since 1970. The Broncos have advanced to eight Super Bowls and won back-to-back titles in 1997 and 1998, and won again in 2015.

The Colorado Rockies were created as an expansion franchise in 1993 and Coors Field opened in 1995. The Rockies advanced to the playoffs that year, but were eliminated in the first round. In 2007, they advanced to the playoffs as a wild-card entrant, won the NL Championship Series, and brought the World Series to Denver for the first time but were swept in four games by the Boston Red Sox.

Denver has been home to two National Hockey League teams. The Colorado Rockies played from 1976 to 1982, but became the New Jersey Devils. The Colorado Avalanche joined in 1995, after relocating from Quebec City. While in Denver, they have won two Stanley Cups in 1996 and in 2001. The Denver Nuggets joined the American Basketball Association in 1967 and the National Basketball Association in 1976. The Avalanche and Nuggets have played at Pepsi Center since 1999. The Major League Soccer team Colorado Rapids play in Dick's Sporting Goods Park, an 18,000-seat soccer-specific stadium opened for the 2007 MLS season in the Denver suburb of Commerce City. The Rapids won the MLS Cup in 2010.

Denver has several additional professional teams. In 2006 Denver established a Major League Lacrosse team, the Denver Outlaws. They play in Empower Field at Mile High. In 2006, the Denver Outlaws won the Western Conference Championship, and then went on to become 2014 MLL Champions, eight years later. The Colorado Mammoth of the National Lacrosse League play at the Pepsi Center.

In 2018 the Denver Bandits were established as the first professional football team for women in Colorado, and will be a part of the initial season for the Women's National Football Conference WNFC in 2019.

Denver submitted the winning bid to host the 1976 Winter Olympics but subsequently withdrew, giving it the dubious distinction of being the only city to back out after having won its bid to host the Olympics. Denver and Colorado Springs hosted the 1962 World Ice Hockey Championships.
, Denver had over 200 parks, from small mini-parks all over the city to the giant City Park. Denver also has 29 recreation centers providing places and programming for resident's recreation and relaxation.

In addition to the parks within Denver, the city acquired land for mountain parks starting in the 1911s. Over the years, Denver has acquired, built and maintained approximately of mountain parks, including Red Rocks Park, which is known for its scenery and musical history revolving around the unique Red Rocks Amphitheatre. Denver also owns the mountain on which the Winter Park Resort ski area operates in Grand County, west of Denver. City parks are important places for Denverites and visitors, inciting controversy with every change. Denver continues to grow its park system with the development of many new parks along the Platte River through the city, and with Central Park and Bluff Lake Nature Center in the Central Park neighborhood redevelopment. All of these parks are important gathering places for residents and allow what was once a dry plain to be lush, active, and green. Denver is also home to a large network of public community gardens, most of which are managed by Denver Urban Gardens, a non-profit organization.

Since 1974, Denver and the surrounding jurisdictions have rehabilitated the urban South Platte River and its tributaries for recreational use by hikers and cyclists. The main stem of the South Platte River Greenway runs along the South Platte from Chatfield Reservoir into Adams County in the north. The Greenway project is recognized as one of the best urban reclamation projects in the U.S., winning, for example, the Silver Medal Rudy Bruner Award for Urban Excellence in 2001.

In its 2013 ParkScore ranking, The Trust for Public Land, a national land conservation organization, reported Denver had the 17th best park system among the 50 most populous U.S. cities.

Denver is a consolidated city-county with a mayor elected on a nonpartisan ballot, a 13-member city council and an auditor. The Denver City Council is elected from 11 districts with two at-large council-members and is responsible for passing and changing all laws, resolutions, and ordinances, usually after a public hearing, and can also call for misconduct investigations of Denver's departmental officials. All elected officials have four-year terms, with a maximum of three terms. The current mayor is Michael Hancock.

Denver has a strong mayor/weak city council government. The mayor can approve or veto any ordinances or resolutions approved by the council, makes sure all contracts with the city are kept and performed, signs all bonds and contracts, is responsible for the city budget, and can appoint people to various city departments, organizations, and commissions. However, the council can override the mayor's veto with a nine out of thirteen member vote, and the city budget must be approved and can be changed by a simple majority vote of the council. The auditor checks all expenditures and may refuse to allow specific ones, usually based on financial reasons.

The Denver Department of Safety oversees three branches: the Denver Police Department, Denver Fire Department, and Denver Sheriff Department. The Denver County Court is an integrated Colorado County Court and Municipal Court and is managed by Denver instead of the state.

While Denver elections are non-partisan, Democrats have long dominated the city's politics; most citywide officials are known to be Democrats. The mayor's office has been occupied by a Democrat since the 1963 municipal election. All of the city's seats in the state legislature are held by Democrats.

In federal elections, Denverites also tend to vote for Democratic candidates, voting for the Democratic Presidential nominee in every election since 1960, excluding 1972 and 1980. At the federal level, Denver is the heart of , which includes all of Denver and parts of Arapahoe County. It is represented by Democrat Diana DeGette.

Benjamin F. Stapleton was the mayor of Denver, Colorado, for two periods, the first from 1923 to 1931 and the second from 1935 to 1947. Stapleton was responsible for many civic improvements, notably during his second stint as mayor when he had access to funds and manpower from the New Deal. During this time, the park system was considerably expanded and the Civic Center completed. His signature project was the construction of Denver Municipal Airport, which began in 1929 amidst heavy criticism. It was later renamed Stapleton International Airport in his honor. Today, the airport has been replaced by a neighborhood initially named Stapleton. However, because of Stapleton's demonstrated racism and prominent membership in the Ku Klux Klan, during the George Floyd protests, residents of the neighborhood changed the name to "Central Park" in 2020. Stapleton Street continues to bear his name. 

During the 1960s and 1970s, Denver was one of the centers of the Chicano Movement. The boxer-turned-activist Rodolfo "Corky" Gonzales formed an organization called the Crusade for Justice, which battled police brutality, fought for bilingual education, and, most notably, hosted the First National Chicano Youth Liberation Conference in March 1969.

In recent years, Denver has taken a stance on helping people who are or become homeless, particularly under the administrations of mayors John Hickenlooper and Wellington Webb. At a rate of 19 homeless per 10,000 residents in 2011 as compared to 50 or more per 10,000 residents for the four metro areas with the highest rate of homelessness, Denver's homeless population and rate of homeless are both considerably lower than many other major cities. However, residents of the city streets suffer Denver winters – which, although mild and dry much of the time, can have brief periods of extremely cold temperatures and snow.

In 2005, Denver became the first major city in the U.S. to vote to make the private possession of less than an ounce of marijuana legal for adults 21 and older. The city voted 53.5 percent in favor of the marijuana legalization measure, which, as then-mayor John Hickenlooper pointed out, was without effect, because the city cannot usurp state law, which at that time treated marijuana possession in much the same way as a speeding ticket, with fines of up to $100 and no jail time. Denver passed an initiative in the fourth quarter of 2007 requiring the mayor to appoint an 11-member review panel to monitor the city's compliance with the 2005 ordinance. In 2012, Colorado Amendment 64 was signed into law by Governor John Hickenlooper and at the beginning of 2014 Colorado became the first state to allow the sale of marijuana for recreational use.

In May 2019, Denver became the first U.S. city to decriminalize psilocybin mushrooms after an initiative passed with 50.6% of the vote. The measure prohibits Denver from using any resources to prosecute adults over 21 for personal use of psilocybin mushrooms, though such use remains illegal under state and federal law.

Former Denver mayor John Hickenlooper was a member of the Mayors Against Illegal Guns Coalition, an organization formed in 2006 and co-chaired by New York City mayor Michael Bloomberg and Boston mayor Thomas Menino.

Denver hosted the 2008 Democratic National Convention, which was the centennial of the city's first hosting of the landmark 1908 convention. It also hosted the G7 (now G8) summit between June 20 and 22 in 1997 and the 2000 National Convention of the Green Party. In 1972, 1981, and 2008, Denver also played host to the Libertarian Party of the United States National Convention. The 1972 Convention was notable for nominating Tonie Nathan as the Vice Presidential candidate, the first woman, as well as the first Jew, to receive an electoral vote in a United States presidential election.

On October 31, 2011, it was announced The University of Denver in Denver would host the first of three 2012 presidential debates to be held on October 3, 2012.

In July 2019, Mayor Hancock said that Denver will not assist U.S. Immigration and Customs Enforcement agents with immigration raids.

The City and County of Denver levies an Occupational Privilege Tax (OPT or head tax) on employers and employees.

Denver Public Schools (DPS) is the public school system in Denver. It educates approximately 92,000 students in 92 elementary schools, 18 K-8 schools, 34 middle schools, 44 high schools, and 19 charter schools. The first school of what is now DPS was a log cabin that opened in 1859 on the corner of 12th Street between Market and Larimer Streets. The district boundaries are coextensive with the city limits. The Cherry Creek School District serves some areas with Denver postal addresses that are outside the city limits.

Denver's many colleges and universities range in age and study programs. Three major public schools constitute the Auraria Campus: the University of Colorado Denver, Metropolitan State University of Denver, and Community College of Denver. The private University of Denver was the first institution of higher learning in the city and was founded in 1864. Other prominent Denver higher education institutions include Johnson & Wales University, Catholic (Jesuit) Regis University and the city has Roman Catholic and Jewish institutions, as well as a health sciences school. In addition to those schools within the city, there are a number of schools throughout the surrounding metro area.

The Denver Metropolitan Area is served by a variety of media outlets in print, radio, television, and the Internet.

Denver is the 16th-largest market in the country for television, according to the 2009–2010 rankings from Nielsen Media Research.

Denver is also served by over 40 AM and FM radio stations, covering a wide variety of formats and styles. Denver-Boulder radio is the No. 19 market in the United States, according to the Spring 2011 Arbitron ranking (up from No. 20 in Fall 2009).
For a list of radio stations, see Radio Stations in Colorado.

After a continued rivalry between Denver's two main newspapers, the "Denver Post" and "Rocky Mountain News", the papers merged operations in 2001 under a Joint Operating Agreement that formed the Denver Newspaper Agency until February 2009 when E. W. Scripps Company, the owner of the "Rocky Mountain News", closed the paper. There are also several alternative or localized newspapers published in Denver, including the "Westword", "Law Week Colorado", "Out Front Colorado" and the "Intermountain Jewish News". Denver is home to multiple regional magazines such as "5280", which takes its name from the city's mile-high elevation ().

Most of Denver has a straightforward street grid oriented to the four cardinal directions. Blocks are usually identified in hundreds from the median streets, identified as "00", which are Broadway (the east–west median, running north–south) and Ellsworth Avenue (the north–south median, running east–west). Colfax Avenue, a major east–west artery through Denver, is 15 blocks (1500) north of the median. Avenues north of Ellsworth are numbered (with the exception of Colfax Avenue and several others, such as Martin Luther King, Jr. Blvd and Montview Blvd.), while avenues south of Ellsworth are named.

There is also an older downtown grid system that was designed to be parallel to the confluence of the South Platte River and Cherry Creek. Most of the streets downtown and in LoDo run northeast–southwest and northwest–southeast. This system has an unplanned benefit for snow removal; if the streets were in a normal N–S/E–W grid, only the N–S streets would receive sunlight. With the grid oriented to the diagonal directions, the NW–SE streets receive sunlight to melt snow in the morning and the NE–SW streets receive it in the afternoon. This idea was from Henry Brown the founder of the Brown Palace Hotel. There is now a plaque across the street from the Brown Palace Hotel that honors this idea. The NW–SE streets are numbered, while the NE–SW streets are named. The named streets start at the intersection of Colfax Avenue and Broadway with the block-long Cheyenne Place. The numbered streets start underneath the Colfax and I-25 viaducts. There are 27 named and 44 numbered streets on this grid. There are also a few vestiges of the old grid system in the normal grid, such as Park Avenue, Morrison Road, and Speer Boulevard. Larimer Street, named after William Larimer, Jr., the founder of Denver, which is in the heart of LoDo, is the oldest street in Denver.

All roads in the downtown grid system are streets (e.g. 16th Street, Stout Street), except for the five NE-SW roads nearest the intersection of Colfax Avenue and Broadway: Cheyenne Place, Cleveland Place, Court Place, Tremont Place and Glenarm Place. Roads outside that system that travel east/west are given the suffix "avenue" and those that head north and south are given the "street" suffix (e.g. Colfax Avenue, Lincoln Street). Boulevards are higher capacity streets and travel any direction (more commonly north and south). Smaller roads are sometimes referred to as places, drives (though not all drives are smaller capacity roads, some are major thoroughfares) or courts. Most streets outside the area between Broadway and Colorado Boulevard are organized alphabetically from the city's center.

Some Denver streets have bicycle lanes, leaving a patchwork of disjointed routes throughout the city. There are over 850 miles of paved, off-road, bike paths in Denver parks and along bodies of water, like Cherry Creek and the South Platte. This allows for a significant portion of Denver's population to be bicycle commuters and has led to Denver being known as a bicycle-friendly city. Some residents are very opposed to bike lanes, which have caused some plans to be watered down or nixed. The review process for one bike line on Broadway will last over a year before city council members will make a decision. In addition to the many bike paths, Denver launched B-Cycle – a citywide bicycle sharing program – in late April 2010. The B-Cycle network was the largest in the United States at the time of its launch, boasting 400 bicycles.

The Denver Boot, a car-disabling device, was first used in Denver.

The League of American Bicyclists has rated Colorado as the sixth most bicycle-friendly state in the nation for the year 2014. This is due in large part to Front Range cities like Boulder, Fort Collins and Denver placing an emphasis on legislation, programs and infrastructure developments that promote cycling as a mode of transportation. Walk score has rated Denver as the fourth most bicycle-friendly large city in the United States.
According to data from the 2011 American Community Survey, Denver ranks 6th among US cities with populations over 400,000 in terms of the percentage of workers who commute by bicycle at 2.2% of commuters. B-Cycle – Denver's citywide bicycle sharing program – was the largest in the United States at the time of its launch in 2010, boasting 400 bicycles. B-Cycle ridership peaked in 2014, then steadily declined. The program announced it would cease operations at the end of January 2020. The city announced plans to seek one or more new contractors to run a bike-share program starting mid-2020.

In 2018, electric scooter services began to place scooters in Denver. Hundreds of unsanctioned LimeBike and Bird electric scooters appeared on Denver streets in May, causing an uproar. In June, the city ordered the companies to remove them and acted quickly to create an official program, making a requirement that scooters be left at RTD stops and out of the public right-of-way. Lime and Bird scooters then reappeared in late July, with limited compliance. Uber's Jump e-bikes arrived in late August, followed by Lyft's nationwide electric scooter launch in early September. Lyft plans to offer ride-sharing, electric scooter and e-bike services all from its app. It says that it will, each night, take the scooters to the warehouse for safety checks, maintenance and charging. Additionally, Spin and Razor each were permitted to add 350 scooters.

2017 rankings by Walk Score placed Denver twenty-sixth among 108 U.S. cities with a population of 200,000 or greater. City leaders have acknowledged the concerns of walkability advocates that Denver has serious gaps in its sidewalk network. The 2019 Denver Moves: Pedestrians plan outlines a need for approximate $1.3 billion in sidewalk funding, plus $400 million for trails. Denver does not currently have resources to fully fund this plan.

In 2015, 9.6 percent of Denver households lacked a car, and in 2016, this was virtually unchanged (9.4 percent). The national average was 8.7 percent in 2016. Denver averaged 1.62 cars per household in 2016, compared to a national average of 1.8.

Denver is primarily served by the interstate freeways I-25 and I-70. The problematic intersection of the two interstates is referred to locally as "the mousetrap" because, when viewed from the air, the junction (and subsequent vehicles) resemble mice in a large trap.

Denver also has a nearly complete beltway known as "the 470's". These are SH 470 (also known as C-470), a freeway in the southwest Metro area, and two toll highways, E-470 (from southeast to northeast) and Northwest Parkway (from terminus of E-470 to US 36). SH 470 was intended to be I-470 and built with federal highway funds, but the funding was redirected to complete conversion of downtown Denver's 16th Street to a pedestrian mall. As a result, construction was delayed until 1980 after state and local legislation was passed. I-470 was also once called "The Silver Stake Highway", from Gov. Lamm's declared intention to drive a silver stake through it and kill it.

A highway expansion and transit project for the southern I-25 corridor, dubbed T-REX (Transportation Expansion Project), was completed on November 17, 2006. The project installed wider and additional highway lanes, and improved highway access and drainage. The project also includes a light rail line that traverses from downtown to the south end of the metro area at Lincoln Avenue. The project spanned almost along the highway with an additional line traveling parallel to part of I-225, stopping just short of Parker Road.

Metro Denver highway conditions can be accessed on the Colorado Department of Transportation website Traffic Conditions.

Mass transportation throughout the Denver metropolitan area is managed and coordinated by the Regional Transportation District (RTD). RTD operates more than 1,000 buses serving over 10,000 bus stops in 38 municipal jurisdictions in eight counties around the Denver and Boulder metropolitan areas. Additionally, RTD operates eleven rail lines, the A, B, C, D, E, F, G, L, R, W, and H with a total of of track, serving 44 stations. The C, D, E, F, L, R, W and H lines are light rail while the A Line, B Line and G Line are commuter rail.

FasTracks is a commuter rail, light rail, and bus expansion project approved by voters in 2004, which will serve neighboring suburbs and communities. The W Line, or West line, opened in April 2013 serving Golden/Federal Center. The commuter rail A Line from Denver Union Station to Denver International Airport opened in April 2016 with ridership exceeding RTD's early expectations. The light rail R Line through Aurora opened in February 2017. The G Line to the suburb of Arvada opened on April 26, 2019 after being originally planned to open in the Fall of 2016. The N Line to Commerce City and Thornton, was last estimated to open in Spring 2020.

An express bus service, known as the Flatiron Flyer, serves to connect Boulder and Denver. The service, billed as bus rapid transit, has been accused of bus rapid transit creep for failing to meet the majority of BRT requirements, including level boarding and all-door entry. A commuter rail connection to Boulder and its suburb of Longmont, also part of the FasTracks ballot initiative and an extension of the B Line, is planned to be finished by RTD, but no construction funds have yet been identified prior to 2040. RTD is currently considering an interim commuter service which would run rush-hour trains from Longmont to Denver.

The Colorado Department of Transportation runs Bustang, a bus system that offers weekday and weekend service connecting Denver with Grand Junction, Colorado Springs, Fort Collins and Gunnison.

Greyhound Lines, the intercity bus operator, has a major hub in Denver, with routes to New York City, Portland, Reno, Las Vegas, and their headquarters, Dallas. Subsidiary Autobuses Americanos provides service to El Paso. Allied bus operators Black Hills Trailways, and Burlington Trailways provide service to Billings, Omaha, Indianapolis, and Alamosa.

Amtrak, the national passenger rail system, provides service to Denver, operating its "California Zephyr" daily in both directions between Chicago and Emeryville, California, across the bay from San Francisco. Amtrak Thruway service operated by private bus companies links the Denver station with Rocky Mountain points. In 2017 the Colorado legislature reinvigorated studies of passenger rail service along the Front Range, potentially connecting Denver to Fort Collins and Pueblo, or further to Amtrak connections in Cheyenne, Wyoming and Trinidad.

At Albuquerque, New Mexico, Denver Thruway connections are made daily with the Amtrak "Southwest Chief". Additionally, the Ski Train operated on the former Denver & Rio Grande Western Railroad, which took passengers between Denver and the Winter Park Ski Resort, but it is no longer in service. The Ski Train made its final run to Winter Park on March 29, 2009. The service was revived on a trial basis in 2016 with a great amount of local fanfare. Further development of a mountain corridor rail option, though publicly popular, has been met with resistance from politicians, namely the director of Colorado Department of Transportation. The Ski Train did return to service under Amtrak with the name "Winter Park Express" in 2017, and currently runs only on Saturdays, Sundays, and major holidays during the winter ski seasons.

Denver's early years as a major train hub of the west are still very visible today. Trains stop in Denver at historic Union Station, where travelers can access RTD's 16th Street Free MallRide or use light rail to tour the city. Union Station will also serve as the main juncture for rail travel in the metro area, at the completion of FasTracks. The city also plans to invest billions to bringing frequent public transit within one-fourth of a mile of most of its residents.

The average amount of time people spend commuting on public transit in Denver and Boulder, Colorado—for example, to and from work, on a weekday—is 77 minutes; 31% of public transit riders ride for more than 2 hours every day. The average amount of time people wait at a stop or station for public transit is 14 minutes, while 25% of riders wait for over 20 minutes, on average, every day. The average distance people usually ride in a single trip with public transit is , while 31% travel over in a single direction.

Denver International Airport (IATA: DEN, ICAO: KDEN), commonly known as DIA or DEN, serves as the primary airport for the Front Range Urban Corridor surrounding Denver. DIA is east-northeast of the Colorado State Capitol. DIA is the 20th busiest airport in the world and ranks 5th in the United States, with 64,494,613 passengers passing through it in 2018. It covers more than , making it the largest airport by land area in the United States and larger than the island of Manhattan. Denver serves as a major hub for United Airlines, is the headquarters and primary hub for Frontier Airlines, and is a major focus city and the fastest-growing market for Southwest Airlines.

As of 2017, Denver International Airport has been rated by Skytrax as the 28th best airport in the world, falling to second place in the United States behind only Cincinnati/Northern Kentucky International Airport. Skytrax also named DIA as the second best regional airport in North America for 2017, and the fourth best regional airport in the world.

Three general aviation airports serve the Denver area. Rocky Mountain Metropolitan Airport (KBJC) is north-northwest, Centennial Airport (KAPA) is south-southeast, and Colorado Air and Space Port formerly, Front Range Airport (KCFO) is east of the state capitol.

In the past, Denver has been home to several other airports that are no longer operational. Stapleton International Airport was closed in 1995 when it was replaced by DIA. Lowry Air Force Base was a military flight training facility that ceased flight operations in 1966, with the base finally being closed in 1994. Both Stapleton and Lowry have since been redeveloped into primarily residential neighborhoods. Buckley Air Force Base, a former Air National Guard base, is the only military facility in the Denver area.


Denver's relationship with Brest, France, began in 1948, making it the second-oldest sister city in the United States. In 1947, Amanda Knecht, a teacher at East High School, visited World War II-ravaged Brest. When she returned, she shared her experiences in the city with her students, and her class raised $32,000 to help rebuild the children's wing of Brest's hospital. The gift led to the development of the sister city program with Brest.

Since then, Denver has established relationships with additional sister cities:




</doc>
<doc id="8524" url="https://en.wikipedia.org/wiki?curid=8524" title="Deuterium">
Deuterium

Deuterium (or hydrogen-2, symbol ' or ', also known as heavy hydrogen) is one of two stable isotopes of hydrogen (the other being protium, or hydrogen-1). The nucleus of a deuterium atom, called a deuteron, contains one proton and one neutron, whereas the far more common protium has no neutrons in the nucleus. Deuterium has a natural abundance in Earth's oceans of about one atom in of hydrogen. Thus deuterium accounts for approximately 0.02% (0.03% by mass) of all the naturally occurring hydrogen in the oceans, while protium accounts for more than 99.98%. The abundance of deuterium changes slightly from one kind of natural water to another (see Vienna Standard Mean Ocean Water).

The name "deuterium" is derived from the Greek , meaning "second", to denote the two particles composing the nucleus. Deuterium was discovered and named in 1931 by Harold Urey. When the neutron was discovered in 1932, this made the nuclear structure of deuterium obvious, and Urey won the Nobel Prize in 1934 "for his discovery of heavy hydrogen". Soon after deuterium's discovery, Urey and others produced samples of "heavy water" in which the deuterium content had been highly concentrated.

Deuterium is destroyed in the interiors of the stars faster than it is produced. Other natural processes are thought to produce only an insignificant amount of deuterium. Nearly all deuterium found in nature was produced in the Big Bang 13.8 billion years ago, as the basic or primordial ratio of hydrogen-1 to deuterium (about 26 atoms of deuterium per million hydrogen atoms) has its origin from that time. This is the ratio found in the gas giant planets, such as Jupiter. The analysis of deuterium–protium ratios in comets found results very similar to the mean ratio in Earth's oceans (156 atoms of deuterium per million hydrogen atoms). This reinforces theories that much of Earth's ocean water is of cometary origin. The deuterium–protium ratio of the comet 67P/Churyumov-Gerasimenko, as measured by the "Rosetta" space probe, is about three times that of earth water. This figure is the highest yet measured in a comet.

Deuterium–protium ratios thus continue to be an active topic of research in both astronomy and climatology.

Deuterium is frequently represented by the chemical symbol D. Since it is an isotope of hydrogen with mass number 2, it is also represented by . IUPAC allows both D and , although is preferred. A distinct chemical symbol is used for convenience because of the isotope's common use in various scientific processes. Also, its large mass difference with protium (H) (deuterium has a mass of , compared to the mean hydrogen atomic weight of , and protium's mass of ) confers non-negligible chemical dissimilarities with protium-containing compounds, whereas the isotope weight ratios within other chemical elements are largely insignificant in this regard.

In quantum mechanics the energy levels of electrons in atoms depend on the reduced mass of the system of electron and nucleus. For the hydrogen atom, the role of reduced mass is most simply seen in the Bohr model of the atom, where the reduced mass appears in a simple calculation of the Rydberg constant and Rydberg equation, but the reduced mass also appears in the Schrödinger equation, and the Dirac equation for calculating atomic energy levels.

The reduced mass of the system in these equations is close to the mass of a single electron, but differs from it by a small amount about equal to the ratio of mass of the electron to the atomic nucleus. For hydrogen, this amount is about 1837/1836, or 1.000545, and for deuterium it is even smaller: 3671/3670, or 1.0002725. The energies of spectroscopic lines for deuterium and light hydrogen (hydrogen-1) therefore differ by the ratios of these two numbers, which is 1.000272. The wavelengths of all deuterium spectroscopic lines are shorter than the corresponding lines of light hydrogen, by a factor of 1.000272. In astronomical observation, this corresponds to a blue Doppler shift of 0.000272 times the speed of light, or 81.6 km/s.

The differences are much more pronounced in vibrational spectroscopy such as infrared spectroscopy and Raman spectroscopy, and in rotational spectra such as microwave spectroscopy because the reduced mass of the deuterium is markedly higher than that of protium. In nuclear magnetic resonance spectroscopy, deuterium has a very different NMR frequency (e.g. 61 MHz when protium is at 400 MHz) and is much less sensitive. Deuterated solvents are usually used in protium NMR to prevent the solvent from overlapping with the signal, although deuterium NMR on its own right is also possible.

Deuterium is thought to have played an important role in setting the number and ratios of the elements that were formed in the Big Bang. Combining thermodynamics and the changes brought about by cosmic expansion, one can calculate the fraction of protons and neutrons based on the temperature at the point that the universe cooled enough to allow formation of nuclei. This calculation indicates seven protons for every neutron at the beginning of nucleogenesis, a ratio that would remain stable even after nucleogenesis was over. This fraction was in favor of protons initially, primarily because the lower mass of the proton favored their production. As the universe expanded, it cooled. Free neutrons and protons are less stable than helium nuclei, and the protons and neutrons had a strong energetic reason to form helium-4. However, forming helium-4 requires the intermediate step of forming deuterium.

Through much of the few minutes after the big bang during which nucleosynthesis could have occurred, the temperature was high enough that the mean energy per particle was greater than the binding energy of weakly bound deuterium; therefore any deuterium that was formed was immediately destroyed. This situation is known as the deuterium bottleneck. The bottleneck delayed formation of any helium-4 until the universe became cool enough to form deuterium (at about a temperature equivalent to 100 keV). At this point, there was a sudden burst of element formation (first deuterium, which immediately fused to helium). However, very shortly thereafter, at twenty minutes after the Big Bang, the universe became too cool for any further nuclear fusion and nucleosynthesis to occur. At this point, the elemental abundances were nearly fixed, with the only change as some of the radioactive products of big bang nucleosynthesis (such as tritium) decay. The deuterium bottleneck in the formation of helium, together with the lack of stable ways for helium to combine with hydrogen or with itself (there are no stable nuclei with mass numbers of five or eight) meant that an insignificant amount of carbon, or any elements heavier than carbon, formed in the Big Bang. These elements thus required formation in stars. At the same time, the failure of much nucleogenesis during the Big Bang ensured that there would be plenty of hydrogen in the later universe available to form long-lived stars, such as our Sun.

Deuterium occurs in trace amounts naturally as deuterium gas, written or D, but most natural occurrence in the universe is bonded with a typical atom, a gas called hydrogen deuteride (HD or ).

The existence of deuterium on Earth, elsewhere in the Solar System (as confirmed by planetary probes), and in the spectra of stars, is also an important datum in cosmology. Gamma radiation from ordinary nuclear fusion dissociates deuterium into protons and neutrons, and there are no known natural processes other than the Big Bang nucleosynthesis, which might have produced deuterium at anything close to its observed natural abundance (deuterium is produced by the rare cluster decay, and occasional absorption of naturally occurring neutrons by light hydrogen, but these are trivial sources). There is thought to be little deuterium in the interior of the Sun and other stars, as at these temperatures the nuclear fusion reactions that consume deuterium happen much faster than the proton-proton reaction that creates deuterium. However, deuterium persists in the outer solar atmosphere at roughly the same concentration as in Jupiter, and this has probably been unchanged since the origin of the Solar System. The natural abundance of deuterium seems to be a very similar fraction of hydrogen, wherever hydrogen is found, unless there are obvious processes at work that concentrate it.

The existence of deuterium at a low but constant primordial fraction in all hydrogen is another one of the arguments in favor of the Big Bang theory over the Steady State theory of the universe. The observed ratios of hydrogen to helium to deuterium in the universe are difficult to explain except with a Big Bang model. It is estimated that the abundances of deuterium have not evolved significantly since their production about 13.8 billion years ago. Measurements of Milky Way galactic deuterium from ultraviolet spectral analysis show a ratio of as much as 23 atoms of deuterium per million hydrogen atoms in undisturbed gas clouds, which is only 15% below the WMAP estimated primordial ratio of about 27 atoms per million from the Big Bang. This has been interpreted to mean that less deuterium has been destroyed in star formation in our galaxy than expected, or perhaps deuterium has been replenished by a large in-fall of primordial hydrogen from outside the galaxy. In space a few hundred light years from the Sun, deuterium abundance is only 15 atoms per million, but this value is presumably influenced by differential adsorption of deuterium onto carbon dust grains in interstellar space.

The abundance of deuterium in the atmosphere of Jupiter has been directly measured by the Galileo space probe as 26 atoms per million hydrogen atoms. ISO-SWS observations find 22 atoms per million hydrogen atoms in Jupiter. and this abundance is thought to represent close to the primordial solar system ratio. This is about 17% of the terrestrial deuterium-to-hydrogen ratio of 156 deuterium atoms per million hydrogen atoms.

Cometary bodies such as Comet Hale-Bopp and Halley's Comet have been measured to contain relatively more deuterium (about 200 atoms D per million hydrogens), ratios which are enriched with respect to the presumed protosolar nebula ratio, probably due to heating, and which are similar to the ratios found in Earth seawater. The recent measurement of deuterium amounts of 161 atoms D per million hydrogen in Comet 103P/Hartley (a former Kuiper belt object), a ratio almost exactly that in Earth's oceans, emphasizes the theory that Earth's surface water may be largely comet-derived. Most recently the deuterium–protium (D–H) ratio of 67P/Churyumov–Gerasimenko as measured by "Rosetta" is about three times that of Earth water, a figure that is high. This has caused renewed interest in suggestions that Earth's water may be partly of asteroidal origin.

Deuterium has also observed to be concentrated over the mean solar abundance in other terrestrial planets, in particular Mars and Venus.

Deuterium is produced for industrial, scientific and military purposes, by starting with ordinary water—a small fraction of which is naturally-occurring heavy water—and then separating out the heavy water by the Girdler sulfide process, distillation, or other methods.

In theory, deuterium for heavy water could be created in a nuclear reactor, but separation from ordinary water is the cheapest bulk production process.

The world's leading supplier of deuterium was Atomic Energy of Canada Limited until 1997, when the last heavy water plant was shut down. Canada uses heavy water as a neutron moderator for the operation of the CANDU reactor design.

Another major producer of heavy water is India. All but one of India's atomic energy plants are pressurised heavy water plants, which use natural (i.e., not enriched) uranium. India has eight heavy water plants, of which seven are in operation. Six plants, of which five are in operation, are based on D–H exchange in ammonia gas. The other two plants extract deuterium from natural water in a process that uses hydrogen sulphide gas at high pressure.

While India is self-sufficient in heavy water for its own use, India now also exports reactor-grade heavy water.

The physical properties of deuterium compounds can exhibit significant kinetic isotope effects and other physical and chemical property differences from the protium analogs. DO, for example, is more viscous than HO. Chemically, there are differences in bond energy and length for compounds of heavy hydrogen isotopes compared to protium, which are larger than the isotopic differences in any other element. Bonds involving deuterium and tritium are somewhat stronger than the corresponding bonds in protium, and these differences are enough to cause significant changes in biological reactions. Pharmaceutical firms are interested in the fact that deuterium is harder to remove from carbon than protium.

Deuterium can replace protium in water molecules to form heavy water (DO), which is about 10.6% denser than normal water (so that ice made from it sinks in ordinary water). Heavy water is slightly toxic in eukaryotic animals, with 25% substitution of the body water causing cell division problems and sterility, and 50% substitution causing death by cytotoxic syndrome (bone marrow failure and gastrointestinal lining failure). Prokaryotic organisms, however, can survive and grow in pure heavy water, though they develop slowly. Despite this toxicity, consumption of heavy water under normal circumstances does not pose a health threat to humans. It is estimated that a person might drink of heavy water without serious consequences. Small doses of heavy water (a few grams in humans, containing an amount of deuterium comparable to that normally present in the body) are routinely used as harmless metabolic tracers in humans and animals.

The deuteron has spin +1 ("triplet state") and is thus a boson. The NMR frequency of deuterium is significantly different from common light hydrogen. Infrared spectroscopy also easily differentiates many deuterated compounds, due to the large difference in IR absorption frequency seen in the vibration of a chemical bond containing deuterium, versus light hydrogen. The two stable isotopes of hydrogen can also be distinguished by using mass spectrometry.

The triplet deuteron nucleon is barely bound at E = , and none of the higher energy states are bound. The singlet deuteron is a virtual state, with a negative binding energy of . There is no such stable particle, but this virtual particle transiently exists during neutron-proton inelastic scattering, accounting for the unusually large neutron scattering cross-section of the proton.

The nucleus of deuterium is called a deuteron. It has a mass of (equal to 1875.612 928(12) MeV)

The charge radius of the deuteron is .

Like the proton radius, measurements using muonic deuterium produce a smaller result: .

Deuterium is one of only five stable nuclides with an odd number of protons and an odd number of neutrons. (, , , , ; also, the long-lived radioactive nuclides , , , occur naturally.) Most odd-odd nuclei are unstable with respect to beta decay, because the decay products are even-even, and are therefore more strongly bound, due to nuclear pairing effects. Deuterium, however, benefits from having its proton and neutron coupled to a spin-1 state, which gives a stronger nuclear attraction; the corresponding spin-1 state does not exist in the two-neutron or two-proton system, due to the Pauli exclusion principle which would require one or the other identical particle with the same spin to have some other different quantum number, such as orbital angular momentum. But orbital angular momentum of either particle gives a lower binding energy for the system, primarily due to increasing distance of the particles in the steep gradient of the nuclear force. In both cases, this causes the diproton and dineutron nucleus to be unstable.

The proton and neutron making up deuterium can be dissociated through neutral current interactions with neutrinos. The cross section for this interaction is comparatively large, and deuterium was successfully used as a neutrino target in the Sudbury Neutrino Observatory experiment.

Diatomic deuterium (D) has ortho and para nuclear spin isomers like diatomic hydrogen, but with differences in the number and population of spin states and rotational levels, which occur because the deuteron is a boson with nuclear spin equal to one.

Due to the similarity in mass and nuclear properties between the proton and neutron, they are sometimes considered as two symmetric types of the same object, a nucleon. While only the proton has an electric charge, this is often negligible due to the weakness of the electromagnetic interaction relative to the strong nuclear interaction. The symmetry relating the proton and neutron is known as isospin and denoted "I" (or sometimes "T").

Isospin is an SU(2) symmetry, like ordinary spin, so is completely analogous to it. The proton and neutron, each of which have isospin-, form an isospin doublet (analogous to a spin doublet), with a "down" state (↓) being a neutron and an "up" state (↑) being a proton. A pair of nucleons can either be in an antisymmetric state of isospin called singlet, or in a symmetric state called triplet. In terms of the "down" state and "up" state, the singlet is

This is a nucleus with one proton and one neutron, i.e. a deuterium nucleus. The triplet is
and thus consists of three types of nuclei, which are supposed to be symmetric: a deuterium nucleus (actually a highly excited state of it), a nucleus with two protons, and a nucleus with two neutrons. These states are not stable.

The deuteron wavefunction must be antisymmetric if the isospin representation is used (since a proton and a neutron are not identical particles, the wavefunction
need not be antisymmetric in general). Apart from their isospin, the two nucleons also have spin and spatial distributions of their wavefunction. The latter is symmetric if the deuteron is symmetric under parity (i.e. have an "even" or "positive" parity), and antisymmetric if the deuteron is antisymmetric under parity (i.e. have an "odd" or "negative" parity). The parity is fully determined by the total orbital angular momentum of the two nucleons: if it is even then the parity is even (positive), and if it is odd then the parity is odd (negative).

The deuteron, being an isospin singlet, is antisymmetric under nucleons exchange due to isospin, and therefore must be symmetric under the double exchange of their spin and location. Therefore, it can be in either of the following two different states:

In the first case the deuteron is a spin triplet, so that its total spin "s" is 1. It also has an even parity and therefore even orbital angular momentum "l" ; The lower its orbital angular momentum, the lower its energy. Therefore, the lowest possible energy state has , .

In the second case the deuteron is a spin singlet, so that its total spin "s" is 0. It also has an odd parity and therefore odd orbital angular momentum "l". Therefore, the lowest possible energy state has , .

Since gives a stronger nuclear attraction, the deuterium ground state is in the , state.

The same considerations lead to the possible states of an isospin triplet having , or , . Thus the state of lowest energy has , , higher than that of the isospin singlet.

The analysis just given is in fact only approximate, both because isospin is not an exact symmetry, and more importantly because the strong nuclear interaction between the two nucleons is related to angular momentum in spin-orbit interaction that mixes different "s" and "l" states. That is, "s" and "l" are not constant in time (they do not commute with the Hamiltonian), and over time a state such as , may become a state of , . Parity is still constant in time so these do not mix with odd "l" states (such as , ). Therefore, the quantum state of the deuterium is a superposition (a linear combination) of the , state and the , state, even though the first component is much bigger. Since the total angular momentum "j" is also a good quantum number (it is a constant in time), both components must have the same "j", and therefore . This is the total spin of the deuterium nucleus.

To summarize, the deuterium nucleus is antisymmetric in terms of isospin, and has spin 1 and even (+1) parity. The relative angular momentum of its nucleons "l" is not well defined, and the deuteron is a superposition of mostly with some .

In order to find theoretically the deuterium magnetic dipole moment μ, one uses the formula for a nuclear magnetic moment
with
g and g are g-factors of the nucleons.

Since the proton and neutron have different values for g and g, one must separate their contributions. Each gets half of the deuterium orbital angular momentum formula_6 and spin formula_7. One arrives at

where subscripts p and n stand for the proton and neutron, and .

By using the same identities as here and using the value , we arrive at the following result, in nuclear magneton units

For the , state (), we obtain

For the , state (), we obtain

The measured value of the deuterium magnetic dipole moment, is , which is 97.5% of the value obtained by simply adding moments of the proton and neutron. This suggests that the state of the deuterium is indeed to a good approximation , state, which occurs with both nucleons spinning in the same direction, but their magnetic moments subtracting because of the neutron's negative moment.

But the slightly lower experimental number than that which results from simple addition of proton and (negative) neutron moments shows that deuterium is actually a linear combination of mostly , state with a slight admixture of , state.

The electric dipole is zero as usual.

The measured electric quadrupole of the deuterium is . While the order of magnitude is reasonable, since the deuterium radius is of order of 1 femtometer (see below) and its electric charge is e, the above model does not suffice for its computation. More specifically, the electric quadrupole does not get a contribution from the "l" =0 state (which is the dominant one) and does get a contribution from a term mixing the "l" =0 and the "l" =2 states, because the electric quadrupole operator does not commute with angular momentum.

The latter contribution is dominant in the absence of a pure contribution, but cannot be calculated without knowing the exact spatial form of the nucleons wavefunction inside the deuterium.

Higher magnetic and electric multipole moments cannot be calculated by the above model, for similar reasons.

Deuterium has a number of commercial and scientific uses. These include:

Deuterium is used in heavy water moderated fission reactors, usually as liquid DO, to slow neutrons without the high neutron absorption of ordinary hydrogen. This is a common commercial use for larger amounts of deuterium.

In research reactors, liquid D is used in cold sources to moderate neutrons to very low energies and wavelengths appropriate for scattering experiments.

Experimentally, deuterium is the most common nuclide used in nuclear fusion reactor designs, especially in combination with tritium, because of the large reaction rate (or nuclear cross section) and high energy yield of the D–T reaction. There is an even higher-yield D– fusion reaction, though the breakeven point of D– is higher than that of most other fusion reactions; together with the scarcity of , this makes it implausible as a practical power source until at least D–T and D–D fusion reactions have been performed on a commercial scale. Commercial nuclear fusion is not yet an accomplished technology.

Deuterium is most commonly used in hydrogen nuclear magnetic resonance spectroscopy (proton NMR) in the following way. NMR ordinarily requires compounds of interest to be analyzed as dissolved in solution. Because of deuterium's nuclear spin properties which differ from the light hydrogen usually present in organic molecules, NMR spectra of hydrogen/protium are highly differentiable from that of deuterium, and in practice deuterium is not "seen" by an NMR instrument tuned for light-hydrogen. Deuterated solvents (including heavy water, but also compounds like deuterated chloroform, CDCl) are therefore routinely used in NMR spectroscopy, in order to allow only the light-hydrogen spectra of the compound of interest to be measured, without solvent-signal interference.

Nuclear magnetic resonance spectroscopy can also be used to obtain information about the deuteron's environment in isotopically labelled samples (Deuterium NMR). For example, the flexibility in the tail, which is a long hydrocarbon chain, in deuterium-labelled lipid molecules can be quantified using solid state deuterium NMR.

Deuterium NMR spectra are especially informative in the solid state because of its relatively small quadrupole moment in comparison with those of bigger quadrupolar nuclei such as chlorine-35, for example.

In chemistry, biochemistry and environmental sciences, deuterium is used as a non-radioactive, stable isotopic tracer, for example, in the doubly labeled water test. In chemical reactions and metabolic pathways, deuterium behaves somewhat similarly to ordinary hydrogen (with a few chemical differences, as noted). It can be distinguished from ordinary hydrogen most easily by its mass, using mass spectrometry or infrared spectrometry. Deuterium can be detected by femtosecond infrared spectroscopy, since the mass difference drastically affects the frequency of molecular vibrations; deuterium-carbon bond vibrations are found in spectral regions free of other signals.

Measurements of small variations in the natural abundances of deuterium, along with those of the stable heavy oxygen isotopes O and O, are of importance in hydrology, to trace the geographic origin of Earth's waters. The heavy isotopes of hydrogen and oxygen in rainwater (so-called meteoric water) are enriched as a function of the environmental temperature of the region in which the precipitation falls (and thus enrichment is related to mean latitude). The relative enrichment of the heavy isotopes in rainwater (as referenced to mean ocean water), when plotted against temperature falls predictably along a line called the global meteoric water line (GMWL). This plot allows samples of precipitation-originated water to be identified along with general information about the climate in which it originated. Evaporative and other processes in bodies of water, and also ground water processes, also differentially alter the ratios of heavy hydrogen and oxygen isotopes in fresh and salt waters, in characteristic and often regionally distinctive ways. The ratio of concentration of H to H is usually indicated with a delta as δH and the geographic patterns of these values are plotted in maps termed as isoscapes. Stable isotopes are incorporated into plants and animals and an analysis of the ratios in a migrant bird or insect can help suggest a rough guide to their origins.

Neutron scattering techniques particularly profit from availability of deuterated samples: The H and D cross sections are very distinct and different in sign, which allows contrast variation in such experiments. Further, a nuisance problem of ordinary hydrogen is its large incoherent neutron cross section, which is nil for D. The substitution of deuterium atoms for hydrogen atoms thus reduces scattering noise.

Hydrogen is an important and major component in all materials of organic chemistry and life science, but it barely interacts with X-rays. As hydrogen (and deuterium) interact strongly with neutrons, neutron scattering techniques, together with a modern deuteration facility, fills a niche in many studies of macromolecules in biology and many other areas.

This is discussed below. It is notable that although most stars, including the Sun, generate energy over most of their lives by fusing hydrogen into heavier elements, such fusion of light hydrogen (protium) has never been successful in the conditions attainable on Earth. Thus, all artificial fusion, including the hydrogen fusion that occurs in so-called hydrogen bombs, requires heavy hydrogen (either tritium or deuterium, or both) in order for the process to work.

A deuterated drug is a small molecule medicinal product in which one or more of the hydrogen atoms contained in the drug molecule have been replaced by deuterium. Because of the kinetic isotope effect, deuterium-containing drugs may have significantly lower rates of metabolism, and hence a longer half-life. In 2017, deutetrabenazine became the first deuterated drug to receive FDA approval.

Deuterium can be used to reinforce specific oxidation-vulnerable C-H bonds within essential or conditionally essential nutrients, such as certain amino acids, or polyunsaturated fatty acids (PUFA), making them more resistant to oxidative damage. Deuterated polyunsaturated fatty acids, such as linoleic acid, slow down the chain reaction of lipid peroxidation that damage living cells. Deuterated ethyl ester of linoleic acid (RT001), developed by Retrotope, is in a compassionate use trial in infantile neuroaxonal dystrophy and has successfully completed a Phase I/II trial in Friedreich's ataxia.

The existence of nonradioactive isotopes of lighter elements had been suspected in studies of neon as early as 1913, and proven by mass spectrometry of light elements in 1920. The prevailing theory at the time was that isotopes of an element differ by the existence of additional "protons" in the nucleus accompanied by an equal number of "nuclear electrons". In this theory, the deuterium nucleus with mass two and charge one would contain two protons and one nuclear electron. However, it was expected that the element hydrogen with a measured average atomic mass very close to , the known mass of the proton, always has a nucleus composed of a single proton (a known particle), and could not contain a second proton. Thus, hydrogen was thought to have no heavy isotopes.

It was first detected spectroscopically in late 1931 by Harold Urey, a chemist at Columbia University. Urey's collaborator, Ferdinand Brickwedde, distilled five liters of cryogenically produced liquid hydrogen to of liquid, using the low-temperature physics laboratory that had recently been established at the National Bureau of Standards in Washington, D.C. (now the National Institute of Standards and Technology). The technique had previously been used to isolate heavy isotopes of neon. The cryogenic boiloff technique concentrated the fraction of the mass-2 isotope of hydrogen to a degree that made its spectroscopic identification unambiguous.

Urey created the names "protium", "deuterium", and "tritium" in an article published in 1934. The name is based in part on advice from G. N. Lewis who had proposed the name "deutium". The name is derived from the Greek ('second'), and the nucleus to be called "deuteron" or "deuton". Isotopes and new elements were traditionally given the name that their discoverer decided. Some British scientists, such as Ernest Rutherford, wanted the isotope to be called "diplogen", from the Greek ('double'), and the nucleus to be called "diplon".

The amount inferred for normal abundance of this heavy isotope of hydrogen was so small (only about 1 atom in 6400 hydrogen atoms in ocean water (156 deuteriums per million hydrogens)) that it had not noticeably affected previous measurements of (average) hydrogen atomic mass. This explained why it hadn't been experimentally suspected before. Urey was able to concentrate water to show partial enrichment of deuterium. Lewis had prepared the first samples of pure heavy water in 1933. The discovery of deuterium, coming before the discovery of the neutron in 1932, was an experimental shock to theory, but when the neutron was reported, making deuterium's existence more explainable, deuterium won Urey the Nobel Prize in Chemistry in 1934. Lewis was embittered by being passed over for this recognition given to his former student.

Shortly before the war, Hans von Halban and Lew Kowarski moved their research on neutron moderation from France to Britain, smuggling the entire global supply of heavy water (which had been made in Norway) across in twenty-six steel drums.

During World War II, Nazi Germany was known to be conducting experiments using heavy water as moderator for a nuclear reactor design. Such experiments were a source of concern because they might allow them to produce plutonium for an atomic bomb. Ultimately it led to the Allied operation called the "Norwegian heavy water sabotage", the purpose of which was to destroy the Vemork deuterium production/enrichment facility in Norway. At the time this was considered important to the potential progress of the war.

After World War II ended, the Allies discovered that Germany was not putting as much serious effort into the program as had been previously thought. They had been unable to sustain a chain reaction. The Germans had completed only a small, partly built experimental reactor (which had been hidden away). By the end of the war, the Germans did not even have a fifth of the amount of heavy water needed to run the reactor, partially due to the Norwegian heavy water sabotage operation. However, even had the Germans succeeded in getting a reactor operational (as the U.S. did with a graphite reactor in late 1942), they would still have been at least several years away from development of an atomic bomb with maximal effort. The engineering process, even with maximal effort and funding, required about two and a half years (from first critical reactor to bomb) in both the U.S. and U.S.S.R., for example.

The 62-ton Ivy Mike device built by the United States and exploded on 1 November 1952, was the first fully successful "hydrogen bomb" (thermonuclear bomb). In this context, it was the first bomb in which most of the energy released came from nuclear reaction stages that followed the primary nuclear fission stage of the atomic bomb. The Ivy Mike bomb was a factory-like building, rather than a deliverable weapon. At its center, a very large cylindrical, insulated vacuum flask or cryostat, held cryogenic liquid deuterium in a volume of about 1000 liters (160 kilograms in mass, if this volume had been completely filled). Then, a conventional atomic bomb (the "primary") at one end of the bomb was used to create the conditions of extreme temperature and pressure that were needed to set off the thermonuclear reaction.

Within a few years, so-called "dry" hydrogen bombs were developed that did not need cryogenic hydrogen. Released information suggests that all thermonuclear weapons built since then contain chemical compounds of deuterium and lithium in their secondary stages. The material that contains the deuterium is mostly lithium deuteride, with the lithium consisting of the isotope lithium-6. When the lithium-6 is bombarded with fast neutrons from the atomic bomb, tritium (hydrogen-3) is produced, and then the deuterium and the tritium quickly engage in thermonuclear fusion, releasing abundant energy, helium-4, and even more free neutrons.

In August 2018, scientists announced the transformation of gaseous deuterium into a liquid metallic form. This may help researchers better understand giant gas planets, such as Jupiter, Saturn and related exoplanets, since such planets are thought to contain a lot of liquid metallic hydrogen, which may be responsible for their observed powerful magnetic fields.

Formula: D or 


Data at approximately for D (triple point):

An antideuteron is the antimatter counterpart of the nucleus of deuterium, consisting of an antiproton and an antineutron. The antideuteron was first produced in 1965 at the Proton Synchrotron at CERN and the Alternating Gradient Synchrotron at Brookhaven National Laboratory. A complete atom, with a positron orbiting the nucleus, would be called "antideuterium", but antideuterium has not yet been created. The proposed symbol for antideuterium is , that is, D with an overbar.




</doc>
<doc id="8525" url="https://en.wikipedia.org/wiki?curid=8525" title="Digital signal processing">
Digital signal processing

Digital signal processing (DSP) is the use of digital processing, such as by computers or more specialized digital signal processors, to perform a wide variety of signal processing operations. The digital signals processed in this manner are a sequence of numbers that represent samples of a continuous variable in a domain such as time, space, or frequency. In digital electronics, a digital signal is represented as a pulse train, which is typically generated by the switching of a transistor.

Digital signal processing and analog signal processing are subfields of signal processing. DSP applications include audio and speech processing, sonar, radar and other sensor array processing, spectral density estimation, statistical signal processing, digital image processing, data compression, video coding, audio coding, image compression, signal processing for telecommunications, control systems, biomedical engineering, and seismology, among others.

DSP can involve linear or nonlinear operations. Nonlinear signal processing is closely related to nonlinear system identification and can be implemented in the time, frequency, and spatio-temporal domains.

The application of digital computation to signal processing allows for many advantages over analog processing in many applications, such as error detection and correction in transmission as well as data compression. Digital signal processing is also fundamental to digital technology, such as digital telecommunication and wireless communications. DSP is applicable to both streaming data and static (stored) data.

To digitally analyze and manipulate an analog signal, it must be digitized with an analog-to-digital converter (ADC). Sampling is usually carried out in two stages, discretization and quantization. Discretization means that the signal is divided into equal intervals of time, and each interval is represented by a single measurement of amplitude. Quantization means each amplitude measurement is approximated by a value from a finite set. Rounding real numbers to integers is an example.

The Nyquist–Shannon sampling theorem states that a signal can be exactly reconstructed from its samples if the sampling frequency is greater than twice the highest frequency component in the signal. In practice, the sampling frequency is often significantly higher than twice the Nyquist frequency.

Theoretical DSP analyses and derivations are typically performed on discrete-time signal models with no amplitude inaccuracies (quantization error), "created" by the abstract process of sampling. Numerical methods require a quantized signal, such as those produced by an ADC. The processed result might be a frequency spectrum or a set of statistics. But often it is another quantized signal that is converted back to analog form by a digital-to-analog converter (DAC).

In DSP, engineers usually study digital signals in one of the following domains: time domain (one-dimensional signals), spatial domain (multidimensional signals), frequency domain, and wavelet domains. They choose the domain in which to process a signal by making an informed assumption (or by trying different possibilities) as to which domain best represents the essential characteristics of the signal and the processing to be applied to it. A sequence of samples from a measuring device produces a temporal or spatial domain representation, whereas a discrete Fourier transform produces the frequency domain representation.

Time domain refers to the analysis of signals with respect to time. Similarly, space domain refers to the analysis of signals with respect to position, e.g., pixel location for the case of image processing.

The most common processing approach in the time or space domain is enhancement of the input signal through a method called filtering. Digital filtering generally consists of some linear transformation of a number of surrounding samples around the current sample of the input or output signal. The surrounding samples may be identified with respect to time or space. The output of a linear digital filter to any given input may be calculated by convolving the input signal with an impulse response.

Signals are converted from time or space domain to the frequency domain usually through use of the Fourier transform. The Fourier transform converts the time or space information to a magnitude and phase component of each frequency. With some applications, how the phase varies with frequency can be a significant consideration. Where phase is unimportant, often the Fourier transform is converted to the power spectrum, which is the magnitude of each frequency component squared.

The most common purpose for analysis of signals in the frequency domain is analysis of signal properties. The engineer can study the spectrum to determine which frequencies are present in the input signal and which are missing. Frequency domain analysis is also called "spectrum-" or "spectral analysis".

Filtering, particularly in non-realtime work can also be achieved in the frequency domain, applying the filter and then converting back to the time domain. This can be an efficient implementation and can give essentially any filter response including excellent approximations to brickwall filters.

There are some commonly used frequency domain transformations. For example, the cepstrum converts a signal to the frequency domain through Fourier transform, takes the logarithm, then applies another Fourier transform. This emphasizes the harmonic structure of the original spectrum.

Digital filters come in both IIR and FIR types. Whereas FIR filters are always stable, IIR filters have feedback loops that may become unstable and oscillate. The Z-transform provides a tool for analyzing stability issues of digital IIR filters. It is analogous to the Laplace transform, which is used to design and analyze analog IIR filters.

In numerical analysis and functional analysis, a discrete wavelet transform is any wavelet transform for which the wavelets are discretely sampled. As with other wavelet transforms, a key advantage it has over Fourier transforms is temporal resolution: it captures both frequency "and" location information. The accuracy of the joint time-frequency resolution is limited by the uncertainty principle of time-frequency.

DSP algorithms may be run on general-purpose computers and digital signal processors. DSP algorithms are also implemented on purpose-built hardware such as application-specific integrated circuit (ASICs). Additional technologies for digital signal processing include more powerful general purpose microprocessors, field-programmable gate arrays (FPGAs), digital signal controllers (mostly for industrial applications such as motor control), and stream processors.

For systems that do not have a real-time computing requirement and the signal data (either input or output) exists in data files, processing may be done economically with a general-purpose computer. This is essentially no different from any other data processing, except DSP mathematical techniques (such as the DCT and FFT) are used, and the sampled data is usually assumed to be uniformly sampled in time or space. An example of such an application is processing digital photographs with software such as Photoshop.

When the application requirement is real-time, DSP is often implemented using specialized or dedicated processors or microprocessors, sometimes using multiple processors or multiple processing cores. These may process data using fixed-point arithmetic or floating point. For more demanding applications FPGAs may be used. For the most demanding applications or high-volume products, ASICs might be designed specifically for the application.

General application areas for DSP include

Specific examples include speech coding and transmission in digital mobile phones, room correction of sound in hi-fi and sound reinforcement applications, analysis and control of industrial processes, medical imaging such as CAT scans and MRI, audio crossovers and equalization, digital synthesizers, and audio effects units.



</doc>
<doc id="8527" url="https://en.wikipedia.org/wiki?curid=8527" title="Discordianism">
Discordianism

Discordianism is a paradigm based upon the book "Principia Discordia," written by Greg Hill with Kerry Wendell Thornley in 1963, the two working under the pseudonyms Malaclypse the Younger and Omar Khayyam Ravenhurst. According to self-proclaimed "crackpot historian" Adam Gorightly, Discordianism was founded as a parody religion. Many outside observers still regard Discordianism as a parody religion, although some of its adherents may utilize it as a legitimate religion or as a metaphor for a governing philosophy.

The "Principia Discordia", if read literally, encourages the worship of the Greek goddess Eris, known in Latin as Discordia, the goddess of disorder, or archetypes and ideals associated with her. Depending on the version of Discordianism, Eris might be considered the goddess exclusively of disorder or the goddess of disorder and chaos. Both views are supported by the "Principia Discordia". The "Principia Discordia" holds three core principles: the Aneristic (order), the Eristic (disorder), and the notion that both are mere illusions. Due to these principles, a Discordian believes there is no distinction between order and disorder, since they are both man-made conceptual divisions of the pure element of chaos. An argument presented by the text is that it is only by rejecting these principles that you can truly perceive reality as it is, chaos.

It is difficult to estimate the number of Discordians because they are not required to hold Discordianism as their only belief system, and because, by nature of the system itself, there is an encouragement to form schisms and cabals.

The foundational document of Discordianism is the "Principia Discordia", fourth edition, written by Malaclypse the Younger, an alias of Greg Hill. The "Principia Discordia" often hints that Discordianism was founded as a dialectic antithesis to more popular religions based on order, although the rhetoric throughout the book describes chaos as a much more underlying impulse of the universe. This may have been done with the intention of merely "balancing out" the creative forces of order and disorder, but the focus is on the more disorderly aspects of the world – at times the forces of order are even vilified.

According to the "Principia Discordia", "every single man, woman, and child on this Earth" is deemed a pope.

Included in the "Principia Discordia" is an official pope card that may be reproduced and distributed freely to anyone and everyone. Papacy, however, is not granted through possession of this card; it merely informs people that they are "a genuine and authorized Pope" of Discordia.

There are also five classes of saints within Discordianism, who are those who best act as exemplars and are closer to perfection. Only the first of these classes "Saint Second Class" contains real human beings (deceased and alive), with higher classes reserved for fictional beings who, by virtue of being fictional, are better able to reach the Discordian view of perfection.

A well-known example of a second-class saint is Emperor Norton, a citizen in 19th century San Francisco, who despite suffering delusions was beloved by much of the city. He is honoured as a saint within Discordianism for living his life according to truth as he saw it and a disregard for reality as others would perceive it.

In discordian mythology, Aneris is described as the sister of Eris a.k.a. Discordia. Whereas Eris/Discordia is the goddess of disorder and being, Aneris/Harmonia is the goddess of order and non-being.

"DOGMA III – HISTORY 32, 'COSMOGONY' " in "Principia Discordia", states:

The sterile Aneris becomes jealous of Eris (who was born pregnant), and starts making existent things non-existent. This explains why life begins, and later ends in death.

The names of Eris and Aneris (who are later given a brother, "Spirituality"), are used to show some fundamental Discordian principles in "Psycho-Metaphysics":

The hand of Eris (shown at right) and other proposed symbols are used informally in certain circles; however, it is unlikely that Eris, the trans-Neptunian dwarf planet, will be assigned an official symbol by the IAU, since graphical symbols are rarely assigned to minor objects in modern times. A request to the Unicode Consortium to add the hand as a unicode symbol to represent the planet, along with a symbol for 90377 Sedna, was filed in 2016 and accepted the same year, releasing with Unicode 11 as ERIS FORM ONE.

The "original snub" is the Discordian name for the events preceding the judgement of Paris, although more focus is put on the actions of Eris. Zeus believes that Eris is a troublemaker, so he does not invite her to Peleus and Thetis's wedding. Having been snubbed, Eris creates a golden apple with the word "kallisti" (, to the prettiest one) inscribed in it. This, the Apple of Discord, is a notable symbol in Discordianism for its inclusion in the Holy Chao, and is traditionally described as being made of gold (although whether that gold was metallic or Acapulco is noted as uncertain).

Some recent interpretations of the original snub place Eris as being not at all mischievous with her delivery of the apple, but instead suggest that Eris was simply bringing the apple as a wedding present for Thetis. This interpretation would see Eris as innocent and her causing of chaos as a by-product of the other wedding guests' reaction upon seeing her at the wedding.

The "Principia Discordia" holds three core principles: the Aneristic and Eristic principles representing order and disorder, and the notion that both are mere illusions. The following excerpt summarizes these principles:

Operation Mindfuck is an important practice in the Discordian religion. The concept was developed by Kerry Thornley and Robert Anton Wilson in 1968 and given its name by Wilson and Robert Shea in "The Illuminatus! Trilogy".

Discordian works include a number of books, not all of which actually exist. Among those that have been published are "Principia Discordia", first published in 1965 (which includes portions of "The Honest Book of Truth"); and "The Illuminatus! Trilogy", which had its first volume published in 1975.

The "Principia Discordia" is a Discordian religious text written by Greg Hill (Malaclypse the Younger) with Kerry Wendell Thornley (Lord Omar Khayyam Ravenhurst).The phrase "Principia Discordia", reminiscent of Newton's "Principia Mathematica", is presumably intended to mean "Discordant Principles", or "Principles of Discordance".

"Summa Universalia" was another work by Malaclypse the Younger, purported to be a summary of the universe. It was excerpted in the first edition of "Principia" but never published. It was mentioned in an introduction to one of the "Principia" editions, and the work was quoted from in the first edition.

"Zenarchy" was first self-published by Thornley, under the pen name Ho Chi Zen, as a series of one-page (or "broadsheet") newsletters in the 1960s. A selection of the material was later reedited and expanded by Thornley and republished in paperback by IllumiNet Press in 1991. The book describes Thornley's concept of Zenarchy "a way of Zen applied to social life. A non-combative, non-participatory, no-politics approach to anarchy intended to get the serious student thinking."

One of the most influential of all Discordian works, "the Illuminatus! Trilogy" is a series of three novels written by Robert Shea and Robert Anton Wilson purportedly between 1969 and 1971. In a 1980 interview given to the science fiction magazine "Starship", Wilson suggested the novel was an attempt to build a myth around Discordianism. 

"Zen Without Zen Masters" is a book by Camden Benares (The Count of Five), published in 1977, of koans, stories and exercises of a Discordian nature. It includes tales of several early Discordians including Hill (as Mal) and Thornley (as Omar and Ho Chi Zen). "Enlightenment of a Seeker" from this book is also present in "Principia Discordia" as "A Zen Story".

The first edition was printed using Jim Garrison's Xerox printer in 1963. The second edition was published under the title "Principia Discordia or How The West Was Lost" in a limited edition of five copies (and released into the public domain) in 1965. 

In 1978, a copy of a work from Kerry Thornley titled "THE PRINCIPIA Discordia or HOW THE WEST WAS LOST" was placed in the HSCA JFK collections as document 010857. Adam Gorightly, author of "The Prankster and the Conspiracy" about Kerry Thornley and the early Discordians, said the copy in the JFK collection was not a copy of the first edition but a later and altered version containing some of the original material. In an interview with researcher Brenton Clutterbuck, Gorightly said he had been given Greg Hill's copy of the first edition. This appeared in its entirety in "Historia Discordia", a book on Discordian history released in spring of 2014.

Several other editions have been published by Steve Jackson Games, Ronin Publishing, and others.

"The Black Iron Prison" was an effort by the Good Reverend Roger — among other authors — to create an updated, modern book that would function as "Principia Discordia" did when released. The collaborators stated that "while the original "Principia Discordia" holds important messages and philosophies, we wondered if some of the humor and language might be dated and lost on a younger generation of Discordians. We wanted to crystalize some of our favorite themes from the "Principia", those of radical free will and self-emancipation." The goal was to encourage "critical thinking and self awareness" in the reader.

"Ek-sen-trik-kuh Discordia: The Tales of Shamlicht" by Reverend Loveshade with "foreplay" or foreword by S. John Ross was published in 2012 by Anaphora Literary Press. The controversial book reportedly was inspired by an investigation by the FBI with portions of the book having been previously seized. "Ek-sen-trik-kuh Discordia" includes blurbs (short reviews of the book) by R. Crumb, Sondra London, Alan Moore, Rev. Ivan Stang, Robert Anton Wilson (who saw an early draft), and others. It was listed in January 2013 in both the print and online version of the "New York Review of Books". The book was soon pulled from publication after allegations of plagiarism were made on amazon.com and sent to the publisher. An editor denied the claims which did not specify what material was allegedly plagiarized. The publisher stated, "In part, I took the book out of print because I was receiving harassing phone calls and emails with threat of harm via 'discordian' jakes, and my phone was infected with a virus with a Discordian flavor."

"Historia Discordia" was compiled by Adam Gorightly with foreword by Robert Anton Wilson. It is a compilation of early Discordian photos, tracts, art collages, and more including works by Discordianism founders Greg Hill (Malaclypse the Younger) and Kerry Thornley (Omar Khayyam Ravenhurst). Among other things, it contains the long-missing "The Honest Book of Truth" and the first edition of "Principia Discordia". It features a blurb by famed comic book writer Alan Moore.




</doc>
<doc id="8528" url="https://en.wikipedia.org/wiki?curid=8528" title="Disjunction introduction">
Disjunction introduction

Disjunction introduction or addition (also called or introduction) is a rule of inference of propositional logic and almost every other deduction system. The rule makes it possible to introduce disjunctions to logical proofs. It is the inference that if "P" is true, then "P or Q" must be true.

An example in English:

The rule can be expressed as:

where the rule is that whenever instances of "formula_2" appear on lines of a proof, "formula_3" can be placed on a subsequent line. 

More generally it's also a simple valid argument form, this means that if the premise is true, then the conclusion is also true as any rule of inference should be, and an immediate inference, as it has a single proposition in its premises. 

Disjunction introduction is not a rule in some paraconsistent logics because in combination with other rules of logic, it leads to explosion (i.e. everything becomes provable) and paraconsistent logic tries to avoid explosion and to be able to reason with contradictions. One of the solutions is to introduce disjunction with over rules. See .

The "disjunction introduction" rule may be written in sequent notation:

where formula_5 is a metalogical symbol meaning that formula_3 is a syntactic consequence of formula_2 in some logical system;

and expressed as a truth-functional tautology or theorem of propositional logic:

where formula_2 and formula_10 are propositions expressed in some formal system.


</doc>
<doc id="8529" url="https://en.wikipedia.org/wiki?curid=8529" title="Disjunction elimination">
Disjunction elimination

In propositional logic, disjunction elimination (sometimes named proof by cases, case analysis, or or elimination), is the valid argument form and rule of inference that allows one to eliminate a disjunctive statement from a logical proof. It is the inference that if a statement formula_1 implies a statement formula_2 and a statement formula_3 also implies formula_2, then if either formula_1 or formula_3 is true, then formula_2 has to be true. The reasoning is simple: since at least one of the statements P and R is true, and since either of them would be sufficient to entail Q, Q is certainly true.

An example in English:

It is the rule can be stated as:

where the rule is that whenever instances of "formula_9", and "formula_10" and "formula_11" appear on lines of a proof, "formula_2" can be placed on a subsequent line.

The "disjunction elimination" rule may be written in sequent notation:

where formula_14 is a metalogical symbol meaning that formula_2 is a syntactic consequence of formula_9, and formula_10 and formula_11 in some logical system;

and expressed as a truth-functional tautology or theorem of propositional logic:

where formula_1, formula_2, and formula_3 are propositions expressed in some formal system.



</doc>
<doc id="8530" url="https://en.wikipedia.org/wiki?curid=8530" title="Dead Sea">
Dead Sea

The Dead Sea ( lit. Sea of Salt; or Buhayrat, Bahret or Birket Lut, "lit." "Lake/Sea of Lot") is a salt lake bordered by Jordan to the east and Israel and the West Bank to the west. It lies in the Jordan Rift Valley, and its main tributary is the Jordan River.

Its surface and shores are below sea level, Earth's lowest elevation on land. It is deep, the deepest hypersaline lake in the world. With a salinity of 342 g/kg, or 34.2% (in 2011), it is one of the world's saltiest bodies of water – 9.6 times as salty as the ocean – and has a density of 1.24 kg/litre, which makes swimming similar to floating. This salinity makes for a harsh environment in which plants and animals cannot flourish, hence its name. The Dead Sea's main, northern basin is long and wide at its widest point.

The Dead Sea has attracted visitors from around the Mediterranean Basin for thousands of years. It was one of the world's first health resorts (for Herod the Great), and it has been the supplier of a wide variety of products, from asphalt for Egyptian mummification to potash for fertilisers.

The Dead Sea is receding at a swift rate; its surface area today is , having been in 1930. The recession of the Dead Sea has begun causing problems, and multiple canal and pipeline proposals have been made to reduce its recession. One of these proposals is the Red Sea–Dead Sea Water Conveyance project, carried out by Jordan, which will provide water to neighbouring countries, while the brine will be carried to the Dead Sea to help stabilise its water level. The first phase of the project is scheduled to begin in 2018 and be completed in 2021.

In Hebrew, the Dead Sea is ' (), meaning "sea of salt" (Genesis 14:3). The Bible uses this term alongside two others: the Sea of the Arabah (' ), and the Eastern Sea (' ). The designation "Dead Sea" never appears in the Bible. In prose sometimes the term ' (, "sea of death") is used, due to the scarcity of aquatic life there.

In Arabic, the Dead Sea is called ("the Dead Sea"), or less commonly ' (, "the Sea of Lot"). Another historic name in Arabic was the "Sea of Zoʼar", after a nearby town in biblical times. The Greeks called it "Lake Asphaltites" (Attic Greek , ', "the Asphaltite sea").

The Dead Sea is an endorheic lake located in the Jordan Rift Valley, a geographic feature formed by the Dead Sea Transform (DST). This left lateral-moving transform fault lies along the tectonic plate boundary between the African Plate and the Arabian Plate. It runs between the East Anatolian Fault zone in Turkey and the northern end of the Red Sea Rift offshore of the southern tip of Sinai. It is here that the Upper Jordan River/Sea of Galilee/Lower Jordan River water system comes to an end.

The Jordan River is the only major water source flowing into the Dead Sea, although there are small perennial springs under and around the Dead Sea, forming pools and quicksand pits along the edges. There are no outlet streams.

The Mujib River, biblical Arnon, is one of the larger water sources of the Dead Sea other than the Jordan. The Wadi Mujib valley, 420 m below the sea level in the southern part of the Jordan valley, is a biosphere reserve, with an area of . Other more substantial sources are Wadi Darajeh (Arabic)/Nahal Dragot (Hebrew), and Nahal Arugot that ends at Ein Gedi (German article at: ). Wadi Hasa (biblical Zered) is another wadi flowing into the Dead Sea.

Rainfall is scarcely per year in the northern part of the Dead Sea and barely in the southern part. The Dead Sea zone's aridity is due to the rainshadow effect of the Judaean Mountains. The highlands east of the Dead Sea receive more rainfall than the Dead Sea itself.

To the west of the Dead Sea, the Judaean mountains rise less steeply and are much lower than the mountains to the east. Along the southwestern side of the lake is a tall Halite mineral formation called Mount Sodom.

There are two contending hypotheses about the origin of the low elevation of the Dead Sea. The older hypothesis is that the Dead Sea lies in a true rift zone, an extension of the Red Sea Rift, or even of the Great Rift Valley of eastern Africa. A more recent hypothesis is that the Dead Sea basin is a consequence of a "step-over" discontinuity along the Dead Sea Transform, creating an extension of the crust with consequent subsidence.

During the late Pliocene-early Pleistocene, around 3.7 million years ago, what is now the valley of the Jordan River, Dead Sea, and the northern Wadi Arabah was repeatedly inundated by waters from the Mediterranean Sea. The waters formed in a narrow, crooked bay that is called by geologists the Sedom Lagoon, which was connected to the sea through what is now the Jezreel Valley. The floods of the valley came and went depending on long-scale changes in the tectonic and climatic conditions.

The Sedom Lagoon extended at its maximum from the Sea of Galilee in the north to somewhere around south of the current southern end of the Dead Sea, and the subsequent lakes never surpassed this expanse. The Hula Depression was never part of any of these water bodies due to its higher elevation and the high threshold of the Korazim block separating it from the Sea of Galilee basin.

The Sedom Lagoon deposited evaporites mainly consisting of rock salt, which eventually reached a thickness of on the old basin floor in the area of today's Mount Sedom.

Approximately two million years ago, the land between the Rift Valley and the Mediterranean Sea rose to such an extent that the ocean could no longer flood the area. Thus, the long lagoon became a landlocked lake.

The first prehistoric lake to follow the Sedom Lagoon is named Lake Amora (which possibly appeared in the early Pleistocene; its sediments developed into the Amora (Samra) Formation, dated to over 200-80 kyr BP), followed by Lake Lisan (c. 70-14 kyr) and finally by the Dead Sea.

The water levels and salinity of the successive lakes (Amora, Lisan, Dead Sea) have either risen or fallen as an effect of the tectonic dropping of the valley bottom, and due to climate variation. As the climate became more arid, Lake Lisan finally shrank and became saltier, leaving the Dead Sea as its last remainder.

From 70,000 to 12,000 years ago, Lake Lisan's level was to higher than its current level. Its level fluctuated dramatically, rising to its highest level around 26,000 years ago, indicating a very wet climate in the Near East. Around 10,000 years ago, the lake's level dropped dramatically, probably even lower than today. During the last several thousand years, the lake has fluctuated approximately , with some significant drops and rises. Current theories as to the cause of this dramatic drop in levels rule out volcanic activity; therefore, it may have been a seismic event.

In prehistoric times, great amounts of sediment collected on the floor of Lake Amora. The sediment was heavier than the salt deposits and squeezed the salt deposits upwards into what are now the Lisan Peninsula and Mount Sodom (on the southwest side of the lake). Geologists explain the effect in terms of a bucket of mud into which a large flat stone is placed, forcing the mud to creep up the sides of the bucket. When the floor of the Dead Sea dropped further due to tectonic forces, the salt mounts of Lisan and Mount Sodom stayed in place as high cliffs (see salt dome).

The Dead Sea has a hot desert climate (Köppen climate classification BWh), with year-round sunny skies and dry air. It has less than mean annual rainfall and a summer average temperature between . Winter average temperatures range between . The region has weaker ultraviolet radiation, particularly the UVB (erythrogenic rays). Given the higher atmospheric pressure, the air has a slightly higher oxygen content (3.3% in summer to 4.8% in winter) as compared to oxygen concentration at sea level. Barometric pressures at the Dead Sea were measured between 1061 and 1065 hPa and clinically compared with health effects at higher altitude. (This barometric measure is about 5% higher than sea level standard atmospheric pressure of 1013.25 hPa, which is the global ocean mean or ATM.) The Dead Sea affects temperatures nearby because of the moderating effect a large body of water has on climate. During the winter, sea temperatures tend to be higher than land temperatures, and vice versa during the summer months. This is the result of the water's mass and specific heat capacity. On average, there are 192 days above annually.

With 34.2% salinity (in 2011), it is one of the world's saltiest bodies of water, though Lake Vanda in Antarctica (35%), Lake Assal in Djibouti (34.8%), Lagoon Garabogazköl in the Caspian Sea (up to 35%) and some hypersaline ponds and lakes of the McMurdo Dry Valleys in Antarctica (such as Don Juan Pond (44%)) have reported higher salinities.

Until the winter of 1978–79, when a major mixing event took place, the Dead Sea was composed of two stratified layers of water that differed in temperature, density, age, and salinity. The topmost or so of the Dead Sea had an average salinity of 342 parts per thousand (in 2002), and a temperature that swung between and . Underneath a zone of transition, the lowest level of the Dead Sea had waters of a consistent temperature and complete saturation of sodium chloride (NaCl). Since the water near the bottom is saturated, the salt precipitates out of solution onto the sea floor.

Beginning in the 1960s, water inflow to the Dead Sea from the Jordan River was reduced as a result of large-scale irrigation and generally low rainfall. By 1975, the upper water layer was saltier than the lower layer. Nevertheless, the upper layer remained suspended above the lower layer because its waters were warmer and thus less dense. When the upper layer cooled so its density was greater than the lower layer, the waters mixed (1978–79). For the first time in centuries, the lake was a homogeneous body of water. Since then, stratification has begun to redevelop.

The mineral content of the Dead Sea is very different from that of ocean water. The exact composition of the Dead Sea water varies mainly with season, depth and temperature. In the early 1980s, the concentration of ionic species (in g/kg) of Dead Sea surface water was Cl (181.4), Br (4.2), SO (0.4), HCO (0.2), Ca (14.1), Na (32.5), K (6.2) and Mg (35.2). The total salinity was 276 g/kg. These results show that the composition of the salt, as anhydrous chlorides on a weight percentage basis, was calcium chloride (CaCl) 14.4%, potassium chloride (KCl) 4.4%, magnesium chloride (MgCl) 50.8% and sodium chloride (NaCl) 30.4%. In comparison, the salt in the water of most oceans and seas is approximately 85% sodium chloride. The concentration of sulfate ions (SO) is very low, and the concentration of bromide ions (Br) is the highest of all waters on Earth.

The salt concentration of the Dead Sea fluctuates around 31.5%. This is unusually high and results in a nominal density of 1.24 kg/l. Anyone can easily float in the Dead Sea because of natural buoyancy. In this respect the Dead Sea is similar to the Great Salt Lake in Utah in the United States.

An unusual feature of the Dead Sea is its discharge of asphalt. From deep seeps, the Dead Sea constantly spits up small pebbles and blocks of the black substance. Asphalt-coated figurines and bitumen-coated Neolithic skulls from archaeological sites have been found. Egyptian mummification processes used asphalt imported from the Dead Sea region.

The Dead Sea area has become a location for health research and potential treatment for several reasons. The mineral content of the water, the low content of pollens and other allergens in the atmosphere, the reduced ultraviolet component of solar radiation, and the higher atmospheric pressure at this great depth each may have specific health effects. For example, persons experiencing reduced respiratory function from diseases such as cystic fibrosis seem to benefit from the increased atmospheric pressure.

The region's climate and low elevation have made it a popular center for assessment of putative therapies:

Climatotherapy at the Dead Sea may be a therapy for psoriasis by sunbathing for long periods in the area due to its position below sea level and subsequent result that UV rays are partially blocked by the increased cloud cover over the Dead Sea.

Rhinosinusitis patients receiving Dead Sea saline nasal irrigation exhibited improved symptom relief compared to standard hypertonic saline spray in one study.

Dead Sea mud pack therapy has been suggested to temporarily relieve pain in patients with osteoarthritis of the knees. According to researchers of the Ben Gurion University of the Negev, treatment with mineral-rich mud compresses can be used to augment conventional medical therapy.

The sea is called "dead" because its high salinity prevents macroscopic aquatic organisms, such as fish and aquatic plants, from living in it, though minuscule quantities of bacteria and microbial fungi are present.

In times of flood, the salt content of the Dead Sea can drop from its usual 35% to 30% or lower. The Dead Sea temporarily comes to life in the wake of rainy winters. In 1980, after one such rainy winter, the normally dark blue Dead Sea turned red. Researchers from Hebrew University of Jerusalem found the Dead Sea to be teeming with a type of alga called "Dunaliella". "Dunaliella" in turn nourished carotenoid-containing (red-pigmented) halobacteria, whose presence caused the color change. Since 1980, the Dead Sea basin has been dry and the algae and the bacteria have not returned in measurable numbers.

In 2011 a group of scientists from Be'er Sheva, Israel and Germany discovered fissures in the floor of the Dead Sea by scuba diving and observing the surface. These fissures allow fresh and brackish water to enter the Dead Sea. They sampled biofilms surrounding the fissures and discovered numerous species of bacteria and archaea.

Many animal species live in the mountains surrounding the Dead Sea. Hikers can see ibex, hares, hyraxes, jackals, foxes, and even leopards. Hundreds of bird species inhabit the zone as well. Both Jordan and Israel have established nature reserves around the Dead Sea.

The delta of the Jordan River was formerly a jungle of papyrus and palm trees. The Jewish historian Flavius Josephus described Jericho as "the most fertile spot in Judea". In Roman and Byzantine times, sugarcane, henna, and sycamore fig all made the lower Jordan valley wealthy. One of the most valuable products produced by Jericho was the sap of the balsam tree, which could be made into perfume. By the 19th century, Jericho's fertility had disappeared.

There are several small communities near the Dead Sea. These include Ein Gedi, Neve Zohar and the Israeli settlements in the Megilot Regional Council: Kalya, Mitzpe Shalem and Avnat. There is a nature preserve at Ein Gedi, and several Dead Sea hotels are located on the southwest end at Ein Bokek near Neve Zohar. Highway 90 runs north-south on the Israeli side for a total distance of from Metula on the Lebanese border in the north to its southern terminus at the Egyptian border near the Red Sea port of Eilat.

Potash City is a small community on the Jordanian side of the Dead Sea, and others including Suweima. Highway 65 runs north-south on the Jordanian side from near Jordan's northern tip down past the Dead Sea to the port of Aqaba.

Dwelling in caves near the Dead Sea is recorded in the Hebrew Bible as having taken place before the Israelites came to Canaan, and extensively at the time of King David.

Just northwest of the Dead Sea is Jericho. Somewhere, perhaps on the southeastern shore, would be the cities mentioned in the Book of Genesis which were said to have been destroyed in the time of Abraham: Sodom and Gomorra (Genesis 18) and the three other "Cities of the Plain", Admah, Zeboim and Zoar (Deuteronomy 29:23). Zoar escaped destruction when Abraham's nephew Lot escaped to Zoar from Sodom (Genesis 19:21–22). Before the destruction, the Dead Sea was a valley full of natural tar pits, which was called the vale of Siddim. King David was said to have hidden from Saul at Ein Gedi nearby.

In there is a specific prophecy that the sea will "be healed and made fresh", becoming a normal lake capable of supporting marine life. A similar prophecy is stated in , which says that "living waters will go out from Jerusalem, half of them to the eastern sea [likely the Dead Sea] and half to the western sea [the Mediterranean]."

Aristotle wrote about the remarkable waters. The Nabateans and others discovered the value of the globs of natural asphalt that constantly floated to the surface where they could be harvested with nets. The Egyptians were steady customers, as they used asphalt in the embalming process that created mummies. The Ancient Romans knew the Dead Sea as ""Palus Asphaltites"" (Asphalt Lake).
The Dead Sea was an important trade route with ships carrying salt, asphalt and agricultural produce. Multiple anchorages existed on both sides of the sea, including in Ein Gedi, Khirbet Mazin (where the ruins of a Hasmonean-era dry dock are located), Numeira and near Masada.

King Herod the Great built or rebuilt several fortresses and palaces on the western bank of the Dead Sea. The most famous was Masada, where in 70 CE a small group of Jewish zealots fled after the fall of the destruction of the Second Temple. The zealots survived until 73 CE, when a siege by the X Legion ended in the deaths by suicide of its 960 inhabitants. Another historically important fortress was Machaerus (מכוור), on the eastern bank, where, according to Josephus, John the Baptist was imprisoned by Herod Antipas and died.

Also in Roman times, some Essenes settled on the Dead Sea's western shore; Pliny the Elder identifies their location with the words, "on the west side of the Dead Sea, away from the coast ... [above] the town of Engeda" ("Natural History", Bk 5.73); and it is therefore a hugely popular but contested hypothesis today, that same Essenes are identical with the settlers at Qumran and that "the Dead Sea Scrolls" discovered during the 20th century in the nearby caves had been their own library.

Josephus identified the Dead Sea in geographic proximity to the ancient Biblical city of Sodom. However, he referred to the lake by its Greek name, Asphaltites.

Various sects of Jews settled in caves overlooking the Dead Sea. The best known of these are the Essenes of Qumran, who left an extensive library known as the Dead Sea Scrolls. The town of Ein Gedi, mentioned many times in the Mishna, produced persimmon for the temple's fragrance and for export, using a secret recipe. "Sodomite salt" was an essential mineral for the temple's holy incense, but was said to be dangerous for home use and could cause blindness. The Roman camps surrounding Masada were built by Jewish slaves receiving water from the towns around the lake. These towns had drinking water from the Ein Feshcha springs and other sweetwater springs in the vicinity.

Intimately connected with the Judean wilderness to its northwest and west, the Dead Sea was a place of escape and refuge. The remoteness of the region attracted Greek Orthodox monks since the Byzantine era. Their monasteries, such as Saint George in Wadi Kelt and Mar Saba in the Judaean Desert, are places of pilgrimage.

In the 19th century the River Jordan and the Dead Sea were explored by boat primarily by Christopher Costigan in 1835, Thomas Howard Molyneux in 1847, William Francis Lynch in 1848, and John MacGregor in 1869. The full text of W. F. Lynch's 1949 book "" is available online. Charles Leonard Irby and James Mangles travelled along the shores of the Dead Sea already in 1817–18, but didn't navigate on its waters.
Explorers and scientists arrived in the area to analyze the minerals and research the unique climate.

After the find of the "Moabite Stone" in 1868 on the plateau east of the Dead Sea, Moses Wilhelm Shapira and his partner Salim al-Khouri forged and sold a whole range of presumed "Moabite" antiquities, and in 1883 Shapira presented what is now known as the "Shapira Strips", a supposedly ancient scroll written on leather strips which he claimed had been found near the Dead Sea. The strips were declared to be forgeries and Shapira took his own life in disgrace.

In the late 1940s and early 1950s, hundreds of religious documents dated between 150 BCE and 70 CE were found in caves near the ancient settlement of Qumran, about inland from the northwestern shore of the Dead Sea (presently in the West Bank). They became known and famous as the Dead Sea Scrolls.

The world's lowest roads, Highway 90, run along the Israeli and West Bank shores of the Dead Sea, along with Highway 65 on the Jordanian side, at below sea level.

A golf course named for Sodom and Gomorrah was built by the British at Kalia on the northern shore.

The first major Israeli hotels were built in nearby Arad, and since the 1960s at the Ein Bokek resort complex.

Israel has 15 hotels along the Dead Sea shore, generating total revenues of $291 million in 2012. Most Israeli hotels and resorts on the Dead Sea are on a stretch of the southern shore.

On the Jordanian side, nine international franchises have opened seaside resort hotels near the King Hussein Bin Talal Convention Center, along with resort apartments, on the eastern shore of the Dead Sea. The 9 hotels have boosted the Jordanian side's capacity to 2,800 rooms.

On November 22, 2015, the Dead Sea panorama road was included along with 40 archaeological locations in Jordan, to become live on Google Street View.

The Palestinian Dead Sea Coast is about long. The World Bank estimates that a Palestinian Dead Sea tourism industry could generate $290 million of revenues per year and 2,900 jobs. However, Palestinians have been unable to obtain construction permits for tourism-related investments on the Dead Sea. According to the World Bank, Officials in the Palestinian Ministry of Tourism and Antiquities state that the only way to apply for such permits is through the Joint Committees established under the Oslo Agreement, but the relevant committee has not met with any degree of regularity since 2000.

In the early part of the 20th century, the Dead Sea began to attract interest from chemists who deduced the sea was a natural deposit of potash (potassium chloride) and bromine. The Palestine Potash Company was chartered in 1929, after its founder, Siberian Jewish engineer and pioneer of Lake Baikal exploitation, Moses Novomeysky, worked for the charter for over ten years having first visited the area in 1911. The first plant, on the north shore of the Dead Sea at Kalya, commenced production in 1931 and produced potash by solar evaporation of the brine. Employing Arabs and Jews, it was an island of peace in turbulent times. The company quickly grew into the largest industrial site in the Middle East, and in 1934 built a second plant on the southwest shore, in the Mount Sodom area, south of the 'Lashon' region of the Dead Sea. Palestine Potash Company supplied half of Britain's potash during World War II. Both plants were destroyed by the Jordanians in the 1948 Arab–Israeli War.

The Dead Sea Works was founded in 1952 as a state-owned enterprise based on the remnants of the Palestine Potash Company. In 1995, the company was privatized and it is now owned by Israel Chemicals. From the Dead Sea brine, Israel produces (2001) 1.77 million tons potash, 206,000 tons elemental bromine, 44,900 tons caustic soda, 25,000 tons magnesium metal, and sodium chloride. Israeli companies generate around US$3 billion annually from the sale of Dead Sea minerals (primarily potash and bromine), and from other products that are derived from Dead Sea Minerals.

On the Jordanian side of the Dead Sea, Arab Potash (APC), formed in 1956, produces 2.0 million tons of potash annually, as well as sodium chloride and bromine. The plant is located at Safi, South Aghwar Department, in the Karak Governorate.

Jordanian Dead Sea mineral industries generate about $1.2 billion in sales (equivalent to 4 percent of Jordan's GDP).

The Palestinian Dead Sea Coast is about long. The Palestinian economy is unable to benefit from Dead Sea chemicals due to restricted access, permit issues and the uncertainties of the investment climate. The World Bank estimates that a Palestinian Dead Sea chemicals industry could generate $918M incremental value added per year, "almost equivalent to the contribution of the entire manufacturing sector of Palestinian territories today".

Both companies, Dead Sea Works Ltd. and Arab Potash, use extensive salt evaporation pans that have essentially diked the entire southern end of the Dead Sea for the purpose of producing carnallite, potassium magnesium chloride, which is then processed further to produce potassium chloride. The ponds are separated by a central dike that runs roughly north-south along the international border. The power plant on the Israeli side allows production of magnesium metal (by a subsidiary, Dead Sea Magnesium Ltd.).

Due to the popularity of the sea's therapeutic and healing properties, several companies have also shown interest in the manufacturing and supplying of Dead Sea salts as raw materials for body and skin care products.

Since 1930, when its surface was and its level was below sea level, the Dead Sea has been monitored continuously. In recent decades, the Dead Sea has been rapidly shrinking because of diversion of incoming water from the Jordan River to the north. The southern end is fed by a canal maintained by the Dead Sea Works, a company that converts the sea's raw materials. From a water surface of below sea level in 1970 it fell to below sea level in 2006, reaching a drop rate of per year. As the water level decreases, the characteristics of the Sea and surrounding region may substantially change.
The Dead Sea level drop has been followed by a groundwater level drop, causing brines that used to occupy underground layers near the shoreline to be flushed out by freshwater. This is believed to be the cause of the recent appearance of large sinkholes along the western shore—incoming freshwater dissolves salt layers, rapidly creating subsurface cavities that subsequently collapse to form these sinkholes.

In May 2009 at the World Economic Forum, Jordan announced its plans to construct the "Jordan National Red Sea Development Project" (JRSP). This is a plan to convey seawater from the Red Sea near Aqaba to the Dead Sea. Water would be desalinated along the route to provide fresh water to Jordan, with the brine discharge sent to the Dead Sea for replenishment. Israel has expressed its support and will likely benefit from some of the water delivery to its Negev region.

At a regional conference in July 2009, officials expressed concern about the declining water levels. Some suggested industrial activities around the Dead Sea might need to be reduced. Others advised environmental measures to restore conditions such as increasing the volume of flow from the Jordan River to replenish the Dead Sea. Currently, only sewage and effluent from fish ponds run in the river's channel. Experts also stressed the need for strict conservation efforts. They said agriculture should not be expanded, sustainable support capabilities should be incorporated into the area and pollution sources should be reduced.
Sources: Israel Oceanographic and Limnological Research, "Haaretz", Jewish Virtual Library, Jordan Valley Authority.

In October 2009, the Jordanians announced accelerated plans to extract around of water per year from the Red Sea, desalinate it for use as fresh water and send the waste water to the Dead Sea by tunnel, despite concerns about inadequate time to assess the potential environmental impact. According to Jordan's minister for water, General Maysoun Zu'bi, this project could be considered as the first phase of the Red Sea–Dead Sea Water Conveyance.

In December 2013, Israel, Jordan and the Palestinian Authority signed an agreement for laying a water pipeline to link the Red Sea with the Dead Sea. The pipeline will be long and is estimated to take up to five years to complete. In January 2015 it was reported that the level of water is now dropping by a year.

On 27 November 2016, it was announced that the Jordanian government is shortlisting five consortiums to implement the project. Jordan's ministry of Water and Irrigation said that the $100 million first phase of the project will begin construction in the first quarter of 2018, and will be completed by 2021.





</doc>
<doc id="8531" url="https://en.wikipedia.org/wiki?curid=8531" title="Dragon">
Dragon

A dragon is a large, serpentine legendary creature that appears in the folklore of many cultures around the world. Beliefs about dragons vary considerably through regions, but dragons in western cultures since the High Middle Ages have often been depicted as winged, horned, four-legged, and capable of breathing fire. Dragons in eastern cultures are usually depicted as wingless, four-legged, serpentine creatures with above-average intelligence.

The earliest attested reports of draconic creatures resemble giant snakes. Draconic creatures are first described in the mythologies of the ancient Near East and appear in ancient Mesopotamian art and literature. Stories about storm-gods slaying giant serpents occur throughout nearly all Indo-European and Near Eastern mythologies. Famous prototypical draconic creatures include the "mušḫuššu" of ancient Mesopotamia; Apep in Egyptian mythology; Vṛtra in the "Rigveda"; the Leviathan in the Hebrew Bible; Grand'Goule in the Poitou region in France, Python, Ladon, Wyvern, and the Lernaean Hydra in Greek mythology; Jörmungandr, Níðhöggr, and Fafnir in Norse mythology; and the dragon from "Beowulf".

The popular western image of a dragon is based on a conflation of earlier dragons from different traditions, and of inaccurate scribal drawings of snakes. In western cultures, dragons are portrayed as monsters to be tamed or overcome, usually by saints or culture heroes, as in the popular legend of Saint George and the Dragon. They are often said to have ravenous appetites and to live in caves, where they hoard treasure. These dragons appear frequently in western fantasy literature, including "The Hobbit" by J. R. R. Tolkien, the "Harry Potter" series by J. K. Rowling, and "A Song of Ice and Fire" by George R. R. Martin.

The word "dragon" has also come to be applied to the Chinese "lung" (traditional 龍, simplified 龙, Pinyin "lóng"), which are associated with good fortune and are thought to have power over rain. Dragons and their associations with rain are the source of the Chinese customs of dragon dancing and dragon boat racing. Many East Asian deities and demigods have dragons as their personal mounts or companions. Dragons were also identified with the Emperor of China, who, during later Chinese imperial history, was the only one permitted to have dragons on his house, clothing, or personal articles.

Commonalities between dragons' traits are often a hybridization of avian, feline, and reptilian features, and may include: snakelike features, reptilian scaly skin, four legs with three or four toes on each, spinal nodes running down the back, a tail, and a serrated jaw with rows of teeth. Several modern scholars believe huge extinct or migrating crocodiles bear the closest resemblance, especially when encountered in forested or swampy areas, and are most likely the template of modern dragon imagery. This also fits with the ancient words 'Draco' and 'Drakon', meaning 'large serpent' or 'sea serpent.'

The word "dragon" entered the English language in the early 13th century from Old French "dragon", which in turn comes from (nominative "draco") meaning "huge serpent, dragon", from Ancient Greek , ' (genitive , ') "serpent, giant seafish". The Greek and Latin term referred to any great serpent, not necessarily mythological. The Greek word is most likely derived from the Greek verb (') meaning "I see", the aorist form of which is (').

Draconic creatures appear in virtually all cultures around the globe. Nonetheless, scholars dispute where the idea of a dragon originates from and a wide variety of hypotheses have been proposed.

In his book "An Instinct for Dragons" (2000), anthropologist David E. Jones suggests a hypothesis that humans, just like monkeys, have inherited instinctive reactions to snakes, large cats, and birds of prey. He cites a study which found that approximately 39 people in a hundred are afraid of snakes and notes that fear of snakes is especially prominent in children, even in areas where snakes are rare. The earliest attested dragons all resemble snakes or bear snakelike attributes. Jones therefore concludes that the reason why dragons appear in nearly all cultures is because of humans' innate fear of snakes and other animals that were major predators of humans' primate ancestors. Dragons are usually said to reside in "dank caves, deep pools, wild mountain reaches, sea bottoms, haunted forests", all places which would have been fraught with danger for early human ancestors.

In her book "The First Fossil Hunters: Dinosaurs, Mammoths, and Myth in Greek and Roman Times" (2000), Adrienne Mayor argues that some stories of dragons may have been inspired by ancient discoveries of fossils belonging to dinosaurs and other prehistoric animals. She argues that the dragon lore of northern India may have been inspired by "observations of oversized, extraordinary bones in the fossilbeds of the Siwalik Hills below the Himalayas" and that ancient Greek artistic depictions of the Monster of Troy may have been influenced by fossils of "Samotherium", an extinct species of giraffe whose fossils are common in the Mediterranean region. In China, a region where fossils of large prehistoric animals are common, these remains are frequently identified as "dragon bones" and are commonly used in Chinese traditional medicine. Mayor, however, is careful to point out that not all stories of dragons and giants are inspired by fossils and notes that Scandinavia has many stories of dragons and sea monsters, but has long "been considered barren of large fossils." In one of her later books, she states that "Many dragon images around the world were based on folk knowledge or exaggerations of living reptiles, such as Komodo dragons, Gila monsters, iguanas, alligators, or, in California, alligator lizards."

Robert Blust in "The Origin Of Dragons" (2000) argues that, like many other creations of traditional cultures, dragons are largely explicable as products of a convergence of rational pre-scientific speculation about the world of real events. In this case, the event is the natural mechanism governing rainfall and drought, with particular attention paid to the phenomenon of the rainbow.

In Egyptian mythology, Apep is a giant serpentine creature who resides in the Duat, the Egyptian Underworld. The Bremner-Rhind papyrus, written in around 310 BC, preserves an account of a much older Egyptian tradition that the setting of the sun is caused by Ra descending to the Duat to battle Apep. In some accounts, Apep is as long as the height of eight men with a head made of flint. Thunderstorms and earthquakes were thought to be caused by Apep's roar and solar eclipses were thought to be the result of Apep attacking Ra during the daytime. In some myths, Apep is slain by the god Set. Nehebkau is another giant serpent who guards the Duat and aided Ra in his battle against Apep. Nehebkau was so massive in some stories that the entire earth was believed to rest atop his coils. Denwen is a giant serpent mentioned in the Pyramid Texts whose body was made of fire and who ignited a conflagration that nearly destroyed all the gods of the Egyptian pantheon. He was ultimately defeated by the Pharaoh, a victory which affirmed the Pharaoh's divine right to rule.

The ouroboros was a well-known Egyptian symbol of a serpent swallowing its own tail. The precursor to the ouroboros was the "Many-Faced", a serpent with five heads, who, according to the Amduat, the oldest surviving Book of the Afterlife, was said to coil around the corpse of the sun god Ra protectively. The earliest surviving depiction of a "true" ouroboros comes from the gilded shrines in the tomb of Tutankhamun. In the early centuries AD, the ouroboros was adopted as a symbol by Gnostic Christians and chapter 136 of the "Pistis Sophia", an early Gnostic text, describes "a great dragon whose tail is in its mouth". In medieval alchemy, the ouroboros became a typical western dragon with wings, legs, and a tail. A famous image of the dragon gnawing on its tail from the eleventh-century Codex Marcianus was copied in numerous works on alchemy.

In the "Rigveda", the oldest of the four Vedas, Indra, the Vedic god of storms, battles Vṛtra, a giant serpent who represents drought. Indra kills Vṛtra using his "vajra" (thunderbolt) and clears the path for rain, which is described in the form of cattle: "You won the cows, hero, you won the Soma,/You freed the seven streams to flow" ("Rigveda" 1.32.12). In another Rigvedic legend, the three-headed serpent Viśvarūpa, the son of Tvaṣṭṛ, guards a wealth of cows and horses. Indra delivers Viśvarūpa to a god named Trita Āptya, who fights and kills him and sets his cattle free. Indra cuts off Viśvarūpa's heads and drives the cattle home for Trita. This same story is alluded to in the Younger Avesta, in which the hero Thraētaona, the son of Āthbya, slays the three-headed dragon Aži Dahāka and takes his two beautiful wives as spoils. Thraētaona's name (meaning "third grandson of the waters") indicates that Aži Dahāka, like Vṛtra, was seen as a blocker of waters and cause of drought.

The Druk (), also known as 'Thunder Dragon', is one of the National symbols of Bhutan. In the Dzongkha language, Bhutan is known as "Druk Yul" "Land of Druk", and Bhutanese leaders are called Druk Gyalpo, "Thunder Dragon Kings". The druk was adopted as an emblem by the Drukpa Lineage, which originated in Tibet and later spread to Bhutan.

Archaeologist Zhōu Chong-Fa believes that the Chinese word for dragon is an onomatopoeia of the sound of thunder or "lùhng" in Cantonese.

The Chinese dragon () is the highest-ranking creature in the Chinese animal hierarchy. Its origins are vague, but its "ancestors can be found on Neolithic pottery as well as Bronze Age ritual vessels." A number of popular stories deal with the rearing of dragons. The "Zuo zhuan", which was probably written during the Warring States period, describes a man named Dongfu, a descendant of Yangshu'an, who loved dragons and, because he could understand a dragon's will, he was able to tame them and raise them well. He served Emperor Shun, who gave him the family name Huanlong, meaning "Dragon-Raiser". In another story, Kongjia, the fourteenth emperor of the Xia dynasty, was given a male and a female dragon as a reward for his obedience to the god of heaven, but could not train them, so he hired a dragon-trainer named Liulei, who had learned how to train dragons from Huanlong. One day, the female dragon died unexpectedly, so Liulei secretly chopped her up, cooked her meat, and served it to the king, who loved it so much that he demanded Liulei to serve him the same meal again. Since Liulei had no means of procuring more dragon meat, he fled the palace.

One of the most famous dragon stories is about the Lord Ye Gao, who loved dragons obsessively, even though he had never seen one. He decorated his whole house with dragon motifs and, seeing this display of admiration, a real dragon came and visited Ye Gao, but the lord was so terrified at the sight of the creature that he ran away. In Chinese legend, the culture hero Fu Hsi is said to have been crossing the Lo River, when he saw the "lung ma", a Chinese horse-dragon with seven dots on its face, six on its back, eight on its left flank, and nine on its right flank. He was so moved by this apparition that, when he arrived home, he drew a picture of it, including the dots. He later used these dots as letters and invented Chinese writing, which he used to write his book "I Ching". In another Chinese legend, the physician Ma Shih Huang is said to have healed a sick dragon. Another legend reports that a man once came to the healer Lo Chên-jen, telling him that he was a dragon and that he needed to be healed. After Lo Chên-jen healed the man, a dragon appeared to him and carried him to heaven.

In the "Shanhaijing", a classic mythography probably compiled mostly during the Han dynasty, various deities and demigods are associated with dragons. One of the most famous Chinese dragons is Ying Long ("Responding Dragon"), who helped the Huangdi, the Yellow Emperor, defeat the tyrant Chiyou. The dragon Zhulong ("Torch Dragon") is a god "who composed the universe with his body." In the "Shanhaijing", many mythic heroes are said to have been conceived after their mothers copulated with divine dragons, including Huangdi, Shennong, Emperor Yao, and Emperor Shun. The god Zhurong and the emperor Qi are both described as being carried by two dragons, as are Huangdi, Zhuanxu, Yuqiang, and Roshou in various other texts. According to the "Huainanzi", an evil black dragon once caused a destructive deluge, which was ended by the mother goddess Nüwa by slaying the dragon.
A large number of ethnic myths about dragons are told throughout China. The "Houhanshu", compiled in the fifth century BC by Fan Ye, reports a story belonging to the Ailaoyi people, which holds that a woman named Shayi who lived in the region around Mount Lao became pregnant with ten sons after being touched by a tree trunk floating in the water while fishing. She gave birth to the sons and the tree trunk turned into a dragon, who asked to see his sons. The woman showed them to him, but all of them ran away except for the youngest, who the dragon licked on the back and named Jiu Long, meaning "Sitting Back". The sons later elected him king and the descendants of the ten sons became the Ailaoyi people, who tattooed dragons on their backs in honor of their ancestor. The Miao people of southwest China have a story that a divine dragon created the first humans by breathing on monkeys that came to play in his cave. The Han people have many stories about Short-Tailed Old Li, a black dragon who was born to a poor family in Shandong. When his mother saw him for the first time, she fainted and, when his father came home from the field and saw him, he hit him with a spade and cut off part of his tail. Li burst through the ceiling and flew away to the Black Dragon River in northeast China, where he became the god of that river. On the anniversary of his mother's death on the Chinese lunar calendar, Old Li returns home, causing it to rain. He is still worshipped as a rain god.

In China, dragons are closely associated with rain and drought is thought to be caused by a dragon's laziness. Prayers invoking dragons to bring rain are common in Chinese texts. The "Luxuriant Dew of the Spring and Autumn Annals", attributed to the Han dynasty scholar Dong Zhongshu, prescribes making clay figurines of dragons during a time of drought and having young men and boys pace and dance among the figurines in order to encourage the dragons to bring rain. Texts from the Qing dynasty advise hurling the bone of a tiger or dirty objects into the pool where the dragon lives; since dragons cannot stand tigers or dirt, the dragon of the pool will cause heavy rain to drive the object out. Rainmaking rituals invoking dragons are still very common in many Chinese villages, where each village has its own god said to bring rain and many of these gods are dragons. Although stories of the Dragon Kings are among the most popular dragon stories in China today, these stories did not begin to emerge until the Eastern Han, when Buddhist stories of the serpent rain-god Nāga became popular. Taoists began to invent their own dragon kings and eventually such stories developed in every major Chinese religion. According to these stories, every body of water is ruled by a dragon king, each with a different power, rank, and ability, so people began establishing temples across the countryside dedicated to these figures.
Many traditional Chinese customs revolve around dragons. During various holidays, including the Spring Festival and Lantern Festival, villagers will construct an approximately sixteen-foot-long dragon from grass, cloth, bamboo strips, and paper, which they will parade through the city as part of a dragon dance. The original purpose of this ritual was to bring good weather and a strong harvest, but now it is done mostly only for entertainment. During the Duanwu festival, several villages, or even a whole province, will hold a dragon boat race, in which people race across a body of water in boats carved to look like dragons, while a large audience watches on the banks. The custom is traditionally said to have originated after the poet Qu Yuan committed suicide by drowning himself in the Miluo River and people raced out in boats hoping to save him, but most historians agree that the custom actually originated much earlier as a ritual to avert ill fortune. Starting during the Han dynasty and continuing until the Qing dynasty, the Chinese emperor gradually became closely identified with dragons, and emperors themselves claimed to be the incarnation of a divine dragon. Eventually, dragons were only allowed to appear on clothing, houses, and articles of everyday use belonging to the emperor and any commoner who possessed everyday items bearing the image of the dragon were ordered to be executed. After the last Chinese emperor was overthrown in 1911, this situation changed and now many ordinary Chinese people identify themselves as descendants of dragons.

The Korean dragon is in many ways similar in appearance to other East Asian dragons such as the Chinese and Japanese dragons. It differs from the Chinese dragon in that it developed a longer beard. Very occasionally a dragon may be depicted as carrying an orb known as the Yeouiju (여의주), the Korean name for the mythical Cintamani, in its claws or its mouth. It was said that whoever could wield the Yeouiju was blessed with the abilities of omnipotence and creation at will, and that only four-toed dragons (who had thumbs with which to hold the orbs) were both wise and powerful enough to wield these orbs, as opposed to the lesser, three-toed dragons. As with China, the number nine is significant and auspicious in Korea, and dragons were said to have 81 (9×9) scales on their backs, representing yang essence. Dragons in Korean mythology are primarily benevolent beings related to water and agriculture, often considered bringers of rain and clouds. Hence, many Korean dragons are said to have resided in rivers, lakes, oceans, or even deep mountain ponds. And human journeys to undersea realms, and especially the undersea palace of the Dragon King (용왕), are common in Korean folklore.

In Korean myths, some kings who founded kingdoms were described as descendants of dragons because the dragon was a symbol of the monarch. Lady Aryeong, who was the first queen of Silla is said to have been born from a cockatrice, while the grandmother of Taejo of Goryeo, founder of Goryeo, was reportedly the daughter of the dragon king of the West Sea. And King Munmu of Silla, who on his deathbed wished to become a dragon of the East Sea in order to protect the kingdom. Dragon patterns were used exclusively by the royal family. The royal robe was also called the dragon robe (용포). In Joseon Dynasty, the royal insignia, featuring embroidered dragons, were attached to the robe's shoulders, the chest, and back. The King wore five-taloned dragon insignia while the Crown Prince wore four-taloned dragon insignia.

Korean folk mythology states that most dragons were originally (이무기), or lesser dragons, which were said to resemble gigantic serpents. There are a few different versions of Korean folklore that describe both what imugis are and how they aspire to become full-fledged dragons. Koreans thought that an Imugi could become a true dragon, "yong" or "mireu", if it caught a Yeouiju which had fallen from heaven. Another explanation states they are hornless creatures resembling dragons who have been cursed and thus were unable to become dragons. By other accounts, an Imugi is a "proto-dragon" which must survive one thousand years in order to become a fully fledged dragon. In either case they are said to be large, benevolent, python-like creatures that live in water or caves, and their sighting is associated with good luck.

Japanese dragon myths amalgamate native legends with imported stories about dragons from China, Korea and India. Like these other Asian dragons, most Japanese ones are water deities associated with rainfall and bodies of water, and are typically depicted as large, wingless, serpentine creatures with clawed feet. Gould writes (1896:248), the Japanese dragon is "invariably figured as possessing three claws". A story about the "samurai" Minamoto no Mitsunaka tells that, while he was hunting in his own territory of Settsu, he fell asleep under a tree and had a dream in which a beautiful woman appeared to him and begged him to save her land from a giant serpent which was defiling it. Mitsunaka agreed to help and the maiden gave him a magnificent horse. When he woke up, the horse was standing before him. He rode it to the Sumiyoshi temple, where he prayed for eight days. Then he confronted the serpent and slew it with an arrow.

It was believed that dragons could be appeased or exorcised with metal. Nitta Yoshisada is said to have hurled a famous sword into the sea at Sagami to appease the dragon-god of the sea and Ki no Tsurayuki threw a metal mirror into the sea at Sumiyoshi for the same purpose. Japanese Buddhism has also adapted dragons by subjecting them to Buddhist law; the Japanese Buddhist deities Benten and Kwannon are often shown sitting or standing on the back of a dragon. Several Japanese "sennin" ("immortals") have taken dragons as their mounts. Bômô is said to have hurled his staff into a puddle of water, causing a dragon to come forth and let him ride it to heaven. The "rakan" Handaka is said to have been able to conjure a dragon out of a bowl, which he is often shown playing with on "kagamibuta". The "shachihoko" is a creature with the head of a dragon, a bushy tail, fishlike scales, and sometimes fire emerging from its armpits. The "shifun" has the head of a dragon, feathered wings, and the tail and claws of a bird. A white dragon was believed to reside in a pool in Yamashiro Province and, every fifty years, it would turn into a bird called the Ogonchô, which had a call like the "howling of a wild dog". This event was believed to herald terrible famine. In the Japanese village of Okumura, near Edo, during times of drought, the villagers would make a dragon effigy out of straw, magnolia leaves, and bamboo and parade it through the village to attract rainfall.

Ancient peoples across the Near East believed in creatures similar to what modern people call "dragons". These ancient peoples were unaware of the existence of dinosaurs or similar creatures in the distant past. References to dragons of both benevolent and malevolent characters occur throughout ancient Mesopotamian literature. In Sumerian poetry, great kings are often compared to the "ušumgal", a gigantic, serpentine monster. A draconic creature with the foreparts of a lion and the hind-legs, tail, and wings of a bird appears in Mesopotamian artwork from the Akkadian Period ( 2334 – 2154 BC) until the Neo-Babylonian Period (626 BC–539 BC). The dragon is usually shown with its mouth open. It may have been known as the "(ūmu) nā’iru", which means "roaring weather beast", and may have been associated with the god Ishkur (Hadad). A slightly different lion-dragon with two horns and the tail of a scorpion appears in art from the Neo-Assyrian Period (911 BC–609 BC). A relief probably commissioned by Sennacherib shows the gods Ashur, Sin, and Adad standing on its back.

Another draconic creature with horns, the body and neck of a snake, the forelegs of a lion, and the hind-legs of a bird appears in Mesopotamian art from the Akkadian Period until the Hellenistic Period (323 BC–31 BC). This creature, known in Akkadian as the "mušḫuššu", meaning "furious serpent", was used as a symbol for particular deities and also as a general protective emblem. It seems to have originally been the attendant of the Underworld god Ninazu, but later became the attendant to the Hurrian storm-god Tishpak, as well as, later, Ninazu's son Ningishzida, the Babylonian national god Marduk, the scribal god Nabu, and the Assyrian national god Ashur.

Scholars disagree regarding the appearance of Tiamat, the Babylonian goddess personifying primeval chaos slain by Marduk in the Babylonian creation epic "Enûma Eliš". She was traditionally regarded by scholars as having had the form of a giant serpent, but several scholars have pointed out that this shape "cannot be imputed to Tiamat with certainty" and she seems to have at least sometimes been regarded as anthropomorphic. Nonetheless, in some texts, she seems to be described with horns, a tail, and a hide that no weapon can penetrate, all features which suggest she was conceived as some form of dragoness.

In the Ugaritic Baal Cycle, the sea-dragon Lōtanu is described as "the twisting serpent/ the powerful one with seven heads." In "KTU" 1.5 I 2–3, Lōtanu is slain by the storm-god Baal, but, in "KTU" 1.3 III 41–42, he is instead slain by the virgin warrior goddess Anat. In the Book of Psalms, Psalm 74, , the sea-dragon Leviathan, whose name is a cognate of "Lōtanu", is slain by Yahweh, the national god of the kingdoms of Israel and Judah, as part of the creation of the world. In , Yahweh's destruction of Leviathan is foretold as part of Yahweh's impending overhaul of the universal order:

In Sufi literature, Rumi writes in his "Masnavi" (III: 976–1066; IV: 120) that the dragon symbolizes the sensual soul, greed and lust, that need to be mortified in a spiritual battle.

In Ferdowsi's "Shahnameh," the Iranian hero Rostam must slay an 80-meter-long dragon (which renders itself invisible to human sight) with the aid of his legendary horse, Rakhsh. As Rostam is sleeping, the dragon approaches; Rakhsh attempts to wake Rostam, but fails to alert him to the danger until Rostam sees the dragon. Rakhsh bites the serpent, while Rostam decapitates it. This is the third trial of Rostam's Seven Labors.

Rostam is also credited with the slaughter of other dragons in the "Shahnameh" and in other Iranian oral traditions, notably in the myth of "Babr-e-Bayan". In this tale, Rostam is still an adolescent and kills a dragon in the "Orient" (either India or China depending on the source) by forcing it to swallow either ox hides filled with quicklime and stones or poisoned blades. The dragon swallows these foreign objects and its stomach bursts, after which Rostam flays the dragon and fashions a coat from its hide called the "babr-e bayān". In some variants of the story, Rostam then remains unconscious for two days and nights, but is guarded by his steed Rakhsh. On reviving, he washes himself in a spring. In the Mandean tradition of the story, Rostam hides in a box, is swallowed by the dragon and kills it from inside its belly. The king of China then gives Rostam his daughter in marriage as a reward.

The story of a hero slaying a giant serpent occurs in nearly every Indo-European mythology. In most stories, the hero is some kind of thunder-god. In nearly every iteration of the story, the serpent is either multi-headed or "multiple" in some other way. Furthermore, in nearly every story, the serpent is always somehow associated with water. Bruce Lincoln has proposed that a Proto-Indo-European dragon-slaying myth can be reconstructed as follows: First, the sky gods give cattle to a man named "*Tritos" ("the third"), who is so named because he is the third man on earth, but a three-headed serpent named *"" steals them. "*Tritos" pursues the serpent and is accompanied by "*Hnér", whose name means "man". Together, the two heroes slay the serpent and rescue the cattle.

The ancient Greek word usually translated as "dragon" (δράκων "drákōn", genitive δράκοντοϛ "drákontos") could also mean "snake", but it usually refers to a kind of giant serpent that either possesses supernatural characteristics or is otherwise controlled by some supernatural power. The first mention of a "dragon" in ancient Greek literature occurs in the "Iliad", in which Agamemnon is described as having a blue dragon motif on his sword belt and an emblem of a three-headed dragon on his breast plate. In lines 820–880 of the "Theogony", a Greek poem written in the seventh century BC by the Boeotian poet Hesiod, the Greek god Zeus battles the monster Typhon, who has one hundred serpent heads that breathe fire and speak all kinds of frightening animal noises. Zeus scorches all of Typhon's heads with his lightning bolts and then hurls Typhon into Tartarus. In the "Homeric Hymn to Apollo", the god Apollo uses his poisoned arrows to slay the serpent Python, who has been causing death and pestilence in the area around Delphi. Apollo then sets up his shrine there.

The Roman poet Virgil in his poem "Culex", lines 163–201 , describing a shepherd having a fight with a big constricting snake, calls it "serpens" and also "draco", showing that in his time the two words were probably interchangeable.
Hesiod also mentions that the hero Heracles slew the Lernaean Hydra, a multiple-headed serpent which dwelt in the swamps of Lerna. The name "Hydra" means "water snake" in Greek. According to the "Bibliotheka" of Pseudo-Apollodorus, the slaying of the Hydra was the second of the Twelve Labors of Heracles. Accounts disagree on which weapon Heracles used to slay the Hydra, but, by the end of the sixth century BC, it was agreed that the clubbed or severed heads needed to be cauterized to prevent them from growing back. Heracles was aided in this task by his nephew Iolaus. During the battle, a giant crab crawled out of the marsh and pinched Heracles's foot, but he crushed it under his heel. Hera placed the crab in the sky as the constellation Cancer. One of the Hydra's heads was immortal, so Heracles buried it under a heavy rock after cutting it off. For his Eleventh Labor, Heracles must procure a golden apple from the tree in the Garden of the Hesperides, which is guarded by an enormous serpent that never sleeps, which Pseudo-Apollodorus calls "Ladon". In earlier depictions, Ladon is often shown with many heads. In Pseudo-Apollodorus's account, Ladon is immortal, but Sophocles and Euripides both describe Heracles as killing him, although neither of them specifies how. The mythographer Herodorus is the first to state that Heracles slew him using his famous club. Apollonius of Rhodes, in his epic poem the "Argonautica", describes Ladon as having been shot full of poisoned arrows dipped in the blood of the Hydra.

In Pindar's "Fourth Pythian Ode", Aeëtes of Colchis tells the hero Jason that the Golden Fleece he is seeking is in a copse guarded by a dragon, "which surpassed in breadth and length a fifty-oared ship". Jason slays the dragon and makes off with the Golden Fleece together with his co-conspirator, Aeëtes's daughter, Medea. The earliest artistic representation of this story is an Attic red-figure "kylix" dated to 480–470 BC, showing a bedraggled Jason being disgorged from the dragon's open mouth as the Golden Fleece hangs in a tree behind him and Athena, the goddess of wisdom, stands watching. A fragment from Pherecydes of Athens states that Jason killed the dragon, but fragments from the "Naupactica" and from Herodorus state that he merely stole the Fleece and escaped. In Euripides's "Medea", Medea boasts that she killed the Colchian dragon herself. In the most famous retelling of the story from Apollonius of Rhodes's "Argonautica", Medea drugs the dragon to sleep, allowing Jason to steal the Fleece. Greek vase paintings show her feeding the dragon the sleeping drug in a liquid form from a "phialē", or shallow cup.
In the founding myth of Thebes, Cadmus, a Phoenician prince, was instructed by Apollo to follow a heifer and found a city wherever it laid down. Cadmus and his men followed the heifer and, when it laid down, Cadmus ordered his men to find a spring so he could sacrifice the heifer to Athena. His men found a spring, but it was guarded by a dragon, which had been placed there by the god Ares, and the dragon killed them. Cadmus killed the dragon in revenge, either by smashing its head with a rock or using his sword. Following the advice of Athena, Cadmus tore out the dragon's teeth and planted them in the earth. An army of giant warriors (known as "spartoi", which means "sown men") grew from the teeth like plants. Cadmus hurled stones into their midst, causing them to kill each other until only five were left. To make restitution for having killed Ares's dragon, Cadmus was forced to serve Ares as a slave for eight years. At the end of this period, Cadmus married Harmonia, the daughter of Ares and Aphrodite. Cadmus and Harmonia moved to Illyria, where they ruled as king and queen, before eventually being transformed into dragons themselves.

In the fifth century BC, the Greek historian Herodotus reported in Book IV of his "Histories" that western Libya was inhabited by monstrous serpents and, in Book III, he states that Arabia was home to many small, winged serpents, which came in a variety of colors and enjoyed the trees that produced frankincense. Herodotus remarks that the serpent's wings were like those of bats and that, unlike vipers, which are found in every land, winged serpents are only found in Arabia. The second-century BC Greek astronomer Hipparchus ( 190 BC –  120 BC) listed the constellation Draco ("the dragon") as one of forty-six constellations. Hipparchus described the constellation as containing fifteen stars, but the later astronomer Ptolemy ( 100 –  170 AD) increased this number to thirty-one in his "Almagest".
In the New Testament, , written by John of Patmos, describes a vision of a Great Red Dragon with seven heads, ten horns, seven crowns, and a massive tail, an image which is clearly inspired by the vision of the four beasts from the sea in the Book of Daniel and the Leviathan described in various Old Testament passages. The Great Red Dragon knocks "a third of the sun ... a third of the moon, and a third of the stars" out the sky and pursues the Woman of the Apocalypse. declares: "And war broke out in Heaven. Michael and his angels fought against Dragon. Dragon and his angels fought back, but they were defeated, and there was no longer any place for them in Heaven. Dragon the Great was thrown down, that ancient serpent who is called Devil and Satan, the one deceiving the whole inhabited World – he was thrown down to earth and his angels were thrown down with him." Then a voice booms down from Heaven heralding the defeat of "the Accuser" ("ho Kantegor").

In , Flavius Philostratus discussed dragons (δράκων, drákōn) in India in "The Life of Apollonius of Tyana" (II,17 and III,6–8). The Loeb Classical Library translation (by F.C. Conybeare) mentions (III,7) that "In most respects the tusks resemble the largest swine's, but they are slighter in build and twisted, and have a point as unabraded as sharks' teeth." According to a collection of books by Claudius Aelianus called "On Animals", Ethiopia was inhabited by a species of dragon that hunted elephants and could grow to a length of 180 feet (55 m) with a lifespan rivaling that of the most enduring of animals.

In the Old Norse poem "Grímnismál" in the "Poetic Edda", the dragon Níðhöggr is described as gnawing on the roots of Yggdrasil, the world tree. In Norse mythology, Jörmungandr is a giant serpent that encircles the entire realm of Miðgarð in the sea around it. According to the "Gylfaginning" from the "Prose Edda", written by the thirteenth-century Icelandic mythographer Snorri Sturluson, Thor, the Norse god of thunder, once went out on a boat with the giant Hymnir to the outer sea and fished for Jörmungandr using an ox-head as bait. Thor caught the serpent and, after pulling its head out of the water, smashed it with his hammer Mjölnir. Snorri states that the blow was not fatal: "and men say that he struck its head off on the sea bed. But I think the truth to tell you is that the Miðgarð Serpent still lives and lies in the surrounding sea."

Towards the end of the Old English epic poem "Beowulf", a slave steals a cup from the hoard of a sleeping dragon, causing the dragon to wake up and go on a rampage of destruction across the countryside. The eponymous hero of the poem insists on confronting the dragon alone, even though he is of advanced age, but Wiglaf, the youngest of the twelve warriors Beowulf has brought with him, insists on accompanying his king into the battle. Beowulf's sword shatters during the fight and he is mortally wounded, but Wiglaf comes to his rescue and helps him slay the dragon. Beowulf dies and tells Wiglaf that the dragon's treasure must be buried rather than shared with the cowardly warriors who did not come to the aid of their king.

In the Old Norse "Völsunga saga", the hero Sigurd catches the dragon Fafnir by digging a pit between the cave where he lives and the spring where he drinks his water and kills him by stabbing him in the underside. At the advice of Odin, Sigurd drains Fafnir's blood and drinks it, which gives him the ability to understand the language of the birds, who he hears talking about how his mentor Regin is plotting to betray him so that he can keep all of Fafnir's treasure for himself. The motif of a hero trying to sneak past a sleeping dragon and steal some of its treasure is common throughout many Old Norse sagas. The fourteenth-century "Flóres saga konungs ok sona hans" describes a hero who is actively concerned not to wake a sleeping dragon while sneaking past it. In the "Yngvars saga víðförla", the protagonist attempts to steal treasure from several sleeping dragons, but accidentally wakes them up.

The modern, western image of a dragon developed in western Europe during the Middle Ages through the combination of the snakelike dragons of classical Graeco-Roman literature, references to Near Eastern European dragons preserved in the Bible, and western European folk traditions. The period between the eleventh and thirteenth centuries represents the height of European interest in dragons as living creatures. The twelfth-century Welsh monk Geoffrey of Monmouth recounts a famous legend in his "Historia Regum Britanniae" in which the child prophet Merlin witnesses the Romano-Celtic warlord Vortigern attempt to build a tower on Mount Snowdon to keep safe from the Anglo-Saxons, but the tower keeps being swallowed into the ground. Merlin informs Vortigern that, underneath the foundation he has built, is a pool with two dragons sleeping in it. Vortigern orders for the pool to be drained, exposing a red dragon and a white dragon, who immediately begin fighting. Merlin delivers a prophecy that the white dragon will triumph over the red, symbolizing England's conquest of Wales, but declares that the red dragon will eventually return and defeat the white one. This story remained popular throughout the fifteenth century.
The oldest recognizable image of a fully modern, western dragon appears in a hand-painted illustration from the medieval manuscript "MS Harley 3244", which was produced in around 1260 AD. The dragon in the illustration has two sets of wings and its tail is longer than most modern depictions of dragons, but it clearly displays many of the same distinctive features. Dragons are generally depicted as living in rivers or having an underground lair or cave. They are envisioned as greedy and gluttonous, with voracious appetites. They are often identified with Satan, due to the references to Satan as a "dragon" in the Book of Revelation. The thirteenth-century "Golden Legend", written in Latin, records the story of Saint Margaret of Antioch, a virgin martyr who, after being tortured for her faith in the Diocletianic Persecution and thrown back into her cell, is said to have been confronted by a monstrous dragon, but she made the sign of the cross and the dragon vanished. In some versions of the story, she is actually swallowed by the dragon alive and, after making the sign of the cross in the dragon's stomach, emerges unharmed.
The legend of Saint George and the Dragon may be referenced as early as the sixth century AD, but the earliest artistic representations of it come from the eleventh century and the first full account of it comes from an eleventh-century Georgian text. The most famous version of the story from the "Golden Legend" holds that a dragon kept pillaging the sheep of the town of Silene in Libya. After it ate a young shepherd, the people were forced to placate it by leaving two sheep as sacrificial offerings every morning beside the lake where the dragon lived. Eventually, the dragon ate all of the sheep and the people were forced to start offering it their own children. One day, the king's own daughter came up in the lottery and, despite the king's pleas for her life, she was dressed as a bride and chained to a rock beside the lake to be eaten. Then, Saint George arrived and saw the princess. When the dragon arrived to eat her, he stabbed it with his lance and subdued it by making the sign of the cross and tying the princess's girdle around its neck. Saint George and the princess led the now-docile dragon into the town and George promised to kill it if the townspeople would convert to Christianity. All the townspeople converted and Saint George killed the dragon with his sword. In some versions, Saint George marries the princess, but, in others, he continues wandering.

Gargoyles are carved stone figures sometimes resembling dragons that originally served as waterspouts on buildings. Precursors to the medieval gargoyle can be found on ancient Greek and Egyptian temples, but, over the course of the Middle Ages, many fantastic stories were invented to explain them. One medieval French legend holds that, in ancient times, a fearsome dragon known as "La Gargouille" had been causing floods and sinking ships on the river Seine, so the people of the town of Rouen would offer the dragon a human sacrifice once each year to appease its hunger. Then, in around 600 AD, a priest named Romanus promised that, if the people would build a church, he would rid them of the dragon. Romanus slew the dragon and its severed head was mounted on the walls of the city as the first gargoyle.

Dragons are prominent in medieval heraldry. Uther Pendragon was famously said to have had two gold dragons crowned with red standing back-to-back on his royal coat of arms. Originally, heraldic dragons could have any number of legs, but, by the late Middle Ages, due to the widespread proliferation of bestiaries, heraldry began to distinguish between a "dragon" (which could only have exactly four legs) and a "wyvern" (which could only have exactly two). In myths, wyverns are associated with viciousness, envy, and pestilence, but, in heraldry, they are used as symbols for overthrowing the tyranny of Satan and his demonic forces. Late medieval heraldry also distinguished a draconic creature known as a "cockatrice". A cockatrice is supposedly born when a serpent hatches an egg that has been laid on a dunghill by a rooster and it is so venomous that its breath and its gaze are both lethal to any living creature, except for a weasel, which is the cockatrice's mortal enemy. A basilisk is a serpent with the head of a dragon at the end of its tail that is born when a toad hatches an egg that has been laid in a midden by a nine-year-old cockatrice. Like the cockatrice, its glare is said to be deadly.

In Albanian mythology and folklore, "stihi", "ljubi", "bolla, bollar, errshaja and kulshedra" are mythological figures described as serpentine dragons. It is believed that "bolla", a water and chthonic demonic serpent, undergoes metamorphosis passing through four distinct phases if it lives many years without being seen by a human. The "bollar" and "errshaja" are the intermediate stages, while the "kulshedra" is the ultimate phase, described as a huge multi-headed fire-spitting female serpent which causes drought, storms, flooding, earthquakes and other natural disasters against mankind. She is usually fought and defeated by a drangue, a semi-human winged divine hero and protector of humans. Heavy thunderstorms are thought to be the result of their battles.

In Slavic mythology, the words ""zmey"", ""zmiy"" or ""zmaj"" are used to describe dragons. These words are masculine forms of the Slavic word for "snake", which are normally feminine (like Russian "zmeya"). In Romania, there is a similar figure, derived from the Slavic dragon and named "zmeu". Exclusively in Polish and Belarusian folklore, as well as in the other Slavic folklores, a dragon is also called (variously) "смок", "цмок", or "smok". In South Slavic folklores, the same thing is also called "lamya" (ламя, ламjа, lamja). Although quite similar to other European dragons, Slavic dragons have their peculiarities.

In Russian and Ukrainian folklore, Zmey Gorynych is a dragon with three heads, each one bearing twin goatlike horns. He is said to have breathed fire and smelled of sulfur. It was believed that eclipses were caused by Gorynych temporarily swallowing the sun. According to one legend, Gorynych's uncle was the evil sorcerer Nemal Chelovek, who abducted the daughter of the tsar and imprisoned her in his castle in the Ural Mountains. Many knights tried to free her, but all of them were killed by Gorynych's fire. Then a palace guard in Moscow named Ivan Tsarevich overheard two crows talking about the princess. He went to the tsar, who gave him a magic sword, and snuck into the castle. When Chelovek attacked Ivan in the form of a giant, the sword flew from Ivan's hand unbidden and killed him. Then the sword cut off all three of Gorynych's heads at once. Ivan brought the princess back to the tsar, who declared Ivan a nobleman and allowed him to marry the princess.

A popular Polish folk tale is the legend of the Wawel Dragon, which is first recorded in the "Chronica Polonorum" of Wincenty Kadłubek, written between 1190 and 1208. According to Kadłubek, the dragon appeared during the reign of King Krakus and demanded to be fed a fixed number of cattle every week. If the villagers failed to provide enough cattle, the dragon would eat the same number of villagers as the number of cattle they had failed to provide. Krakus ordered his sons to slay the dragon. Since they could not slay it by hand, they tricked the dragon into eating calfskins filled with burning sulfur. Once the dragon was dead, the younger brother attacked and murdered his older brother and returned home to claim all the glory for himself, telling his father that his brother had died fighting the dragon. The younger brother became king after his father died, but his secret was eventually revealed and he was banished. In the fifteenth century, Jan Długosz rewrote the story so that King Krakus himself was the one who slew the dragon. Another version of the story told by Marcin Bielski instead has the clever shoemaker Skubę come up with the idea for slaying the dragon. Bielski's version is now the most popular.

Dragons and dragon motifs are featured in many works of modern literature, particularly within the fantasy genre. As early as the eighteenth century, critical thinkers such as Denis Diderot were already asserting that too much literature had been published on dragons: "There are already in books all too many fabulous stories of dragons". In Lewis Carroll's classic children's novel "Through the Looking-Glass" (1872), one of the inset poems describes the Jabberwock, a kind of dragon. Carroll's illustrator John Tenniel, a famous political cartoonist, humorously showed the Jabberwock with the waistcoat, buck teeth, and myopic eyes of a Victorian university lecturer, such as Carroll himself. In works of comedic children's fantasy, dragons often fulfill the role of a magic fairy tale helper. In such works, rather than being frightening as they are traditionally portrayed, dragons are instead represented as harmless, benevolent, and inferior to humans. They are sometimes shown living in contact with humans, or in isolated communities of only dragons. Though popular in the late nineteenth and early twentieth centuries, "such comic and idyllic stories" began to grow increasingly rare after the 1960s, due to demand for more serious children's literature.

One of the most iconic modern dragons is Smaug from J. R. R. Tolkien's classic novel "The Hobbit". Dragons also appear in the best-selling "Harry Potter" series of children's novels by J. K. Rowling. Other prominent works depicting dragons include Anne McCaffrey's "Dragonriders of Pern", Ursula K. Le Guin's "Earthsea Cycle", George R. R. Martin's series "A Song of Ice and Fire", and Christopher Paolini's "Inheritance Cycle". Sandra Martina Schwab writes, "With a few exceptions, including McCaffrey's Pern novels and the 2002 film "Reign of Fire", dragons seem to fit more into the medievalized setting of fantasy literature than into the more technological world of science fiction. Indeed, they have been called the emblem of fantasy. The hero's fight against the dragon emphasizes and celebrates his masculinity, whereas revisionist fantasies of dragons and dragon-slaying often undermine traditional gender roles. In children's literature the friendly dragon becomes a powerful ally in battling the child's fears." The popular role-playing game system "Dungeons & Dragons" (D&D) makes heavy use of dragons.

After recent discoveries in palaeontology, fictional dragons are sometimes represented with no front legs, but (when on the ground) walking on their back feet and the wrists of their wings, like pterosaurs did: for example see (in Game of Thrones) and (Smaug, as in the movie).



</doc>
<doc id="8533" url="https://en.wikipedia.org/wiki?curid=8533" title="Depeche Mode">
Depeche Mode

Depeche Mode () are an English electronic music band formed in Basildon, Essex in 1980. The group as of now consists of a trio of Dave Gahan (lead vocals and co-songwriting), Martin Gore (keyboards, guitar, co-lead vocals and main songwriting), and Andy Fletcher (keyboards).

Depeche Mode released their debut album "Speak & Spell" in 1981, bringing the band onto the British new wave scene. Founding member Vince Clarke left after the release of the album; they recorded "A Broken Frame" as a trio. Gore took over as main songwriter and, later in 1982, Alan Wilder replaced Clarke, establishing a lineup that continued for 13 years.

The band's last albums of the 1980s, "Black Celebration" and "Music for the Masses", established them as a dominant force within the electronic music scene. A highlight of this era was the band's June 1988 concert at the Pasadena Rose Bowl, where they drew a crowd in excess of 60,000 people. In early 1990, they released "Violator", an international mainstream success. The following album, "Songs of Faith and Devotion," released in 1993, was also a success, though internal struggles within the band during recording and touring resulted in Wilder's departure in 1995.

Depeche Mode have had 54 songs in the UK Singles Chart and 17 top 10 albums in the UK chart; they have sold more than 100 million records worldwide. "Q" included the band in the list of the "50 Bands That Changed the World!". Depeche Mode also ranks number 98 on VH1's "100 Greatest Artists of All Time". In December 2016, "Billboard" named Depeche Mode the 10th most successful dance club artist of all time. They were nominated for induction into the Rock and Roll Hall of Fame in 2017 and 2018, and will be inducted as part of the Class of 2020.

Depeche Mode's origins date to 1977, when schoolmates Vince Clarke and Andy Fletcher formed a band called No Romance in China, later influenced by the Cure, with Clarke on vocals and guitar and Fletcher on bass guitar. Fletcher would later recall, "Why am I in the band? It was accidental right from the beginning. I was actually forced to be in the band. I played the guitar and I had a bass; it was a question of them roping me in." In 1979, Clarke played guitar in an "Ultravox rip-off band", The Plan, with friends Robert Marlow and Paul Langwith. In 1978–79, Martin Gore played guitar in an acoustic duo, Norman and the Worms, with school friend Phil Burdett on vocals. In 1979, Marlow, Gore and friend Paul Redmond formed a band called the French Look, with Marlow on vocals/keyboards, Gore on guitar and Redmond on keyboards. In March 1980, Clarke, Gore and Fletcher formed a band called Composition of Sound, with Clarke on vocals/guitar, Gore on keyboards and Fletcher on bass.

Soon after the formation of Composition of Sound, Clarke heard Wirral band Orchestral Manoeuvres in the Dark (OMD), whose output inspired him to make electronic music. Along with OMD, other early influences included the Human League, Daniel Miller and Fad Gadget. Clarke and Fletcher switched to synthesisers, working odd jobs in order to buy the instruments, or borrowing them from friends. Dave Gahan joined the band in 1980 after Clarke heard him perform at a local Scout hut jam session, singing a rendition of David Bowie's "Heroes", and Depeche Mode was born. Gahan's and Gore's favourite artists included Sparks, Siouxsie and the Banshees, Cabaret Voltaire, Talking Heads and Iggy Pop. Gahan's persona onstage was influenced by Dave Vanian, frontman of The Damned.

When explaining the choice for the new name, taken from French fashion magazine "Dépêche mode", Gore said, "It means hurried fashion or fashion dispatch. I like the sound of that." However, the magazine's name (and hence the band's) is "Fashion News" or "Fashion Update" ("dépêche", "dispatch" or "news report", from Old French "despesche/despeche", and "mode" or "fashion").

Gore recalled that the first time the band played as Depeche Mode was a school gig in May 1980. There is a plaque commemorating the gig at the James Hornsby School in Basildon, where Gore and Fletcher were pupils. The band made their recording debut in 1980 on the "Some Bizzare Album" with the song "Photographic", later re-recorded for their debut album "Speak & Spell".

The band made a demo tape but, instead of mailing the tape to record companies, they would go in and personally deliver it. They would demand the companies play it; according to Dave Gahan, "most of them would tell us to fuck off. They'd say 'leave the tape with us' and we'd say 'it's our only one'. Then we'd say goodbye and go somewhere else."

According to Gahan, prior to securing their record contract, they were receiving offers from all the major labels. Phonogram offered them "money you could never have imagined and all sorts of crazy things like clothes allowances".

While playing a live gig at the Bridge House in Canning Town, the band was approached by Daniel Miller, an electronic musician and founder of Mute Records, who was interested in their recording a single for his burgeoning label. The result of this verbal contract was their first single, "Dreaming of Me", recorded in December 1980 and released in February 1981. It reached number 57 in the UK charts. Encouraged by this, the band recorded their second single, "New Life", which climbed to number 11 in the UK charts and got them an appearance on "Top of the Pops". The band went to London by train, carrying their synthesisers all the way to the BBC studios.

The band's next single was "Just Can't Get Enough". The synth-pop single became the band's first UK top ten hit. The video is the only one of the band's videos to feature Vince Clarke. Depeche Mode's debut album, "Speak & Spell", was released in October 1981 and peaked at number ten on the UK album charts. Critical reviews were mixed; "Melody Maker" described it as a "great album … one they had to make to conquer fresh audiences and please the fans who just can't get enough", while "Rolling Stone" was more critical, calling the album "PG-rated fluff".

Clarke began to voice his discomfort at the direction the band was taking, saying "there was never enough time to do anything. Not with all the interviews and photo sessions". Clarke also said he was sick of touring, which Gahan said years later was "bullshit to be quite honest." Gahan went on to say he "suddenly lost interest in it and he started getting letters from fans asking what kind of socks he wore." In November 1981, Clarke publicly announced that he was leaving Depeche Mode.

Soon afterwards, Clarke joined up with blues singer Alison Moyet to form Yazoo (or Yaz in the United States). Initial talk of Clarke's continuing to write material for Depeche Mode ultimately amounted to nothing. According to third-party sources, Clarke offered the remaining members of Depeche Mode the track "Only You", but they declined. Clarke, however, denied in an interview that such an offer ever took place saying, "I don't know where that came from. That's not true." The song went on to become a UK Top 3 hit for Yazoo. Gore, who had written "Tora! Tora! Tora!" and the instrumental "Big Muff" for "Speak & Spell", became the band's main lyricist.

In late 1981, the band placed an anonymous ad in "Melody Maker" looking for another musician: "Name band, synthesise, must be under twenty-one." Alan Wilder, a classically trained keyboardist from West London, responded and, after two auditions and despite being 22 years old, was hired in early 1982, initially on a trial basis as a touring member. Wilder would later be called the "Musical Director" of the band, responsible for the band's sound until his departure in 1995. As producer Flood would say, "[Alan] is sort of the craftsman, Martin's the idea man and [Dave] is the attitude."

In January 1982, the band released "See You", their first single without Clarke, which managed to beat all three Clarke-penned singles in the UK charts, reaching number six. The following tour saw the band playing their first shows in North America. Two more singles, "The Meaning of Love" and "Leave in Silence", were released ahead of the band's second studio album, on which they began work in July 1982. Daniel Miller informed Wilder that he was not needed for the recording of the album, as the core trio wanted to prove they could succeed without Vince Clarke. "A Broken Frame" was released that September, and the following month the band began their 1982 tour. A non-album single, "Get the Balance Right!", was released in January 1983, the first Depeche Mode track to be recorded with Wilder.

For its third album, "Construction Time Again", Depeche Mode worked with producer Gareth Jones, at John Foxx's Garden Studios and at Hansa Studios in West Berlin (where much of David Bowie's trilogy of seminal electronic albums featuring Brian Eno had been produced). The album saw a dramatic shift in the group's sound, due in part to Wilder's introduction of the Synclavier and E-mu Emulator samplers. By sampling the noises of everyday objects, the band created an eclectic, industrial-influenced sound, with similarities to groups such as the Art of Noise and Einstürzende Neubauten (the latter becoming Mute labelmates in 1983).

"Everything Counts" rose to number six in the UK, also reaching the top 30 in Ireland, South Africa, Switzerland, Sweden and West Germany. Wilder contributed two songs to the album, "The Landscape Is Changing" and "Two Minute Warning". In September 1983, to promote "Construction Time Again", the band launched a European concert tour.

In their early years, Depeche Mode had only really attained success in Europe and Australia. This changed in March 1984, when they released the single "People Are People". The song became a hit, reaching No. 2 in Ireland and Poland, No. 4 in the UK and Switzerland, and No. 1 in West Germany — the first time a DM single topped a country's singles chart — where it was used as the theme to West German TV's coverage of the 1984 Olympics. Beyond this European success, the song also reached No. 13 on the US charts in mid-1985, the first appearance of a DM single on the "Billboard" Hot 100, and was a Top 20 hit in Canada. "People Are People" became an anthem for the LGBT community, regularly played at gay establishments and gay pride festivals in the late 1980s. Sire, the band's North American record label, released a compilation of the same name which included tracks from "A Broken Frame" and "Construction Time Again" as well as several B-sides.

On the American tour, the band was, according to Gore, "shocked by the way the fans were turning up in droves at the concerts". He said that although the concerts were selling well, Depeche Mode struggled to sell records.

In September 1984, "Some Great Reward" was released. "Melody Maker" claimed that the album made one "sit up and take notice of what is happening here, right under your nose." In contrast to the political and environmental subjects addressed on the previous album, the songs on "Some Great Reward" were mostly concerned with more personal themes such as sexual politics ("Master and Servant"), adulterous relationships ("Lie to Me"), and arbitrary divine justice ("Blasphemous Rumours"). Also included was the first Martin Gore ballad, "Somebody" — such songs would become a feature of all following albums. "Somebody" was released as a double A-side with "Blasphemous Rumours", and was the first single with Gore on lead vocal. "Some Great Reward" became the first Depeche Mode album to enter the US album charts, and made the Top 10 in several European countries.

"The World We Live In and Live in Hamburg" was the band's first video release, almost an entire concert from their 1984 Some Great Reward Tour. In July 1985, the band played their first-ever concerts behind the Iron Curtain, in Budapest and Warsaw. In October 1985, Mute released a compilation, "The Singles 81→85" ("Catching Up with Depeche Mode" in the US), which included the two non-album hit singles "Shake the Disease" and "It's Called a Heart" along with their B-sides.

In the United States, the band's music first gained prominence on college radio and modern rock stations such as KROQ in Los Angeles, KQAK ("The Quake") in San Francisco, WFNX in Boston and WLIR on Long Island, New York, and hence they appealed primarily to an alternative audience who were disenfranchised with the predominance of "soft rock and 'disco hell'" on the radio. This view of the band was in sharp contrast to how the band was perceived in Europe, despite the increasingly dark and serious tone in their songs. In Germany, France, and other European countries, Depeche Mode were considered teen idols and regularly featured in European teen magazines, becoming one of the most famous synth-pop bands in the mid-'80s.

Depeche Mode's musical style shifted slightly again in 1986 with the release of their fifteenth single, "Stripped", and its accompanying album "Black Celebration". Retaining their often imaginative sampling and beginning to move away from the "industrial pop" sound that had characterised their previous two LPs, the band introduced an ominous, highly atmospheric and textured sound. Gore's lyrics also took on a darker tone and became more pessimistic.

The music video for "A Question of Time" was the first to be directed by Anton Corbijn, beginning a working relationship that continues to present. Corbijn has directed 20 of the band's videos (the latest being 2017's "Where's the Revolution."). He has also filmed some of their live performances and designed stage sets, as well as most covers for albums and singles from "Violator" and onwards.

1987's "Music for the Masses" saw further alterations in the band's sound and working methods. For the first time a producer not related to Mute Records, Dave Bascombe, was called to assist with the recording sessions, although, according to Alan Wilder, Bascombe's role ended up being more that of engineer. In making the album, the band largely eschewed sampling in favour of synthesizer experimentation. While chart performance of the singles "Strangelove", "Never Let Me Down Again" and "Behind the Wheel" proved to be disappointing in the UK, they performed well in countries such as Canada, Brazil, West Germany, South Africa, Sweden and Switzerland, often reaching the top 10. "Record Mirror" described "Music for the Masses" as "the most accomplished and sexy Mode album to date". The album also peaked at No. 35 on the "Billboard" 200 chart.

The Music for the Masses Tour began 22 October 1987. On 7 March 1988, with no previous announcement that they would be the headlining act, Depeche Mode played in the Werner-Seelenbinder-Halle, East Berlin, becoming one of the few Western groups to perform in the Communist East Germany. They also performed concerts in Budapest and Prague in 1988, both at the time also Communist.

The world tour ended 18 June 1988 with a concert at the Pasadena Rose Bowl with paid attendance of 60,453, the highest in eight years for the venue. The tour was a breakthrough for the band and a massive success in the United States. It was documented in "101" – a concert film by D. A. Pennebaker and its accompanying soundtrack album. The film is notable for its portrayal of fan interaction. Alan Wilder is credited with coming up with the title, noting that the performance was the 101st and final performance of the tour. On 7 September 1988, Depeche Mode performed "Strangelove" at the 1988 MTV Video Music Awards at the Universal Amphitheatre in Los Angeles.

In mid-1989, the band began recording in Milan with producer Flood and engineer François Kevorkian. The initial result of this session was the single "Personal Jesus." Prior to its release, a marketing campaign was launched with advertisements placed in the personals columns of UK regional newspapers with the words "Your own personal Jesus." Later, the ads included a phone number one could dial to hear the song. The resulting furor helped propel the single to number 13 on the UK charts, becoming one of their biggest sellers to date; in the United States, it was their first gold single and their first Top 40 hit since "People Are People", eventually becoming the biggest-selling 12-inch single in Warner Records' history up to that point.
Released in January 1990, "Enjoy the Silence" reached number six in the UK (the first Top 10 hit in that country since "Master And Servant"). A few months later in the US, it reached number eight and earned the band a second gold single. It won Best British Single at the 1991 Brit Awards. To promote their new album, "Violator", the band held an in-store autograph signing at Wherehouse Entertainment in Los Angeles. The event attracted approximately 20,000 fans and turned into a near riot. Some who attended were injured by being pressed against the store's glass by the crowd. As an apology to the fans who were injured, the band released a limited edition cassette tape to fans living in Los Angeles, distributed through radio station KROQ (the sponsor of the Wherehouse event).

"Violator" was the first Depeche Mode album to enter the Top 10 of the "Billboard" 200, reaching Number 7 and staying 74 weeks in the chart. It was certified triple platinum in America, selling over 4.5 million units there. It remains the band's best selling album worldwide. Two more singles from the album — "Policy of Truth" and "World in My Eyes" — were hits in the UK, with the former also charting in the US.
The World Violation Tour saw the band play several stadium shows in the US. 42,000 tickets were sold within four hours for a show at Giants Stadium, and 48,000 tickets were sold within half-an-hour of going on sale for a show at Dodger Stadium. An estimated 1.2 million fans saw this tour worldwide.

In 1991, Depeche Mode contribution "Death's Door" was released on the soundtrack album for the film "Until the End of the World". Film director Wim Wenders had challenged musical artists to write music the way they imagined they would in the year 2000, the setting of the movie.

The members of Depeche Mode regrouped in Madrid in January 1992, Dave Gahan had become interested in the new grunge scene sweeping the U.S. and was influenced by the likes of Jane's Addiction, Soundgarden and Nirvana.

In 1993, "Songs of Faith and Devotion", again with Flood producing, saw them experimenting with arrangements based as much on heavily distorted electric guitars and live drums (played by Alan Wilder, whose debut as a studio drummer had come on the "Violator" track "Clean") as on synthesizers. Live strings, uilleann pipes and female gospel vocals were other new additions to the band's sound. The album debuted at number one in both the UK and the US, only the sixth British act to achieve such a distinction to date. The first single from the album was the grunge-influenced "I Feel You." The gospel influences are most noticeable on the album's third single, "Condemnation." Interviews given by the band during this period tended to be conducted separately, unlike earlier albums, where the band was interviewed as a group.

The Devotional world tour followed, documented by a concert film of the same name. The film was directed by Anton Corbijn, and in 1995 earned the band their first Grammy nomination. The band's second live album, "Songs of Faith and Devotion Live", was released in December 1993. The tour continued into 1994 with the Exotic Tour, which began in February 1994 in South Africa, and ended in April in Mexico. The final leg of the tour, consisting of more North American dates, followed shortly thereafter and ran until July. As a whole, the Devotional Tour is to date the longest and most geographically diverse Depeche Mode tour, spanning fourteen months and 159 individual performances.

"Q" magazine described the 1993 Devotional Tour as "The Most Debauched Rock'n'Roll Tour Ever." According to "The Independent", the "smack-blasted" Gahan "required cortisone shots just to perform, borderline alcoholic Gore suffered two stress-induced seizures, and Andrew Fletcher's deepening depression resulted, in the summer of 1994, in a full nervous breakdown." Fletcher declined to participate in the second half of the Exotic Tour due to mental instability; he was replaced on stage by Daryl Bamonte, who had worked with the band as a personal assistant since the beginning of their career in 1980.

In June 1995, Alan Wilder announced that he was leaving Depeche Mode, explaining:
He continued to work on his personal project Recoil, releasing a fourth album ("Unsound Methods") in 1997.

Despite Gahan's increasingly severe personal problems, Gore tried repeatedly during 1995 and 1996 to get the band recording again. However, Gahan would rarely turn up to scheduled sessions, and when he did, it would take weeks to get any vocals recorded; one six-week session at Electric Lady in New York produced just one usable vocal (for "Sister of Night"), and even that was pieced together from multiple takes. Gore was forced to contemplate breaking the band up and considered releasing the songs he had written as a solo album. In mid-1996, after his near-fatal overdose, Gahan entered a court-ordered drug rehabilitation program to battle his addiction to cocaine and heroin. With Gahan out of rehab in 1996, Depeche Mode held recording sessions with producer Tim Simenon.

Preceded by two singles, "Barrel of a Gun" and "It's No Good", the album "Ultra" was released in April 1997. The album debuted at No. 1 in the UK (as well as Germany), and No. 5 in the US. The band did not tour in support of the album, with Fletcher quoted as saying: "We're not fit enough. Dave's only eight months into his sobriety, and our bodies are telling us to spend time with our families." As part of the promotion for the release of the album, they did perform two short concerts in London and Los Angeles, called "Ultra Parties." "Ultra" spawned two further singles, "Home" and "Useless".

A second singles compilation, "The Singles 86–98", was released in 1998, preceded by the new single "Only When I Lose Myself", which had been recorded during the "Ultra" sessions. In April 1998, Depeche Mode held a press conference at the Hyatt Hotel in Cologne to announce The Singles Tour. The tour was the first to feature two backing musicians in place of Alan Wilder—Austrian drummer Christian Eigner and British keyboardist Peter Gordeno.

In 2001, Depeche Mode released "Exciter", produced by Mark Bell (of techno group LFO). Bell introduced a minimalist, digital sound to much of the album, influenced by IDM and glitch. "Dream On", "I Feel Loved", "Freelove" and "Goodnight Lovers" were released as singles in 2001 and 2002. Critical response to the album was mixed, with reasonably positive reviews from some magazines ("NME", "Rolling Stone" and "LA Weekly"), while others (including "Q" magazine, "PopMatters", and "Pitchfork") derided it as sounding underproduced, dull and lacklustre.

In March 2001, Depeche Mode held a press conference at the Valentino Hotel in Hamburg to announce the Exciter Tour. The tour featured 84 performances for over 1.5 million fans in 24 countries. The concerts held in Paris at the Palais Omnisports de Paris-Bercy were filmed and later released in May 2002 as a live DVD entitled "One Night in Paris".

In October 2002 the band won the first-ever "Q" magazine "Innovation Award".

In 2003, Gahan released his first solo album, "Paper Monsters", and toured to promote the record. Also released in 2003 was Gore's second solo album "Counterfeit²". Fletcher founded his own record label, Toast Hawaii, specialising in promoting electronic music.

A new remix compilation album, "Remixes 81–04", was released in 2004, featuring new and unreleased promo mixes of the band's singles from 1981 to 2004. A new version of "Enjoy the Silence", remixed by Mike Shinoda of Linkin Park, "Enjoy the Silence 04", was released as a single and reached No. 7 on the UK charts.

In October 2005, the band released their 11th studio album "Playing the Angel". Produced by Ben Hillier, the album peaked at No. 1 in 18 countries and featured the hit single "Precious". This is the first Depeche Mode album to feature lyrics written by Gahan and, consequently, the first album since 1984's "Some Great Reward" featuring songs not written by Gore. "Suffer Well" was the first ever post-Clarke Depeche Mode single not to be written by Gore (lyrics by Gahan, music by Philpott/Eigner). The final single from the album was "John the Revelator", an uptempo electronic track with a running religious theme, accompanied by "Lilian", a lush track that was a hit in many clubs all over the world.

To promote "Playing the Angel", the band launched Touring the Angel, a concert tour of Europe and North America that began in November 2005 and ran for nine months. During the last two legs of the tour Depeche Mode headlined a number of festivals including the Coachella Valley Music and Arts Festival and the O Wireless Festival. In total, the band played to more than 2.8 million people across 31 countries and the tour was one of the highest grossing and critically acclaimed tours of 2005/06. Speaking about the tour, Gahan praised it as "probably the most enjoyable, rewarding live shows we've ever done. The new material was just waiting to be played live. It took on a life of its own. With the energy of the crowds, it just came to life." Two shows at Milan's Fila Forum were filmed and edited into a concert film, released on DVD as "".

A "best-of" compilation was released in November 2006, entitled "The Best Of, Volume 1" featuring a new single "Martyr", an outtake from the "Playing the Angel" sessions. Later that month Depeche Mode received the MTV Europe Music Award in the Best Group category.

In December 2006, iTunes released "The Complete Depeche Mode" as its fourth ever digital box-set.

In August 2007, during promotion for Dave Gahan's second solo album, "Hourglass", it was announced that Depeche Mode were heading back in studio in early 2008 to work on a new album.

In May 2008, the band returned to the studio with producer Ben Hillier to work on some songs that Martin Gore had demoed at his home studio in Santa Barbara, California. Later that year it was announced that Depeche Mode were splitting from their long-term US label, Warner Music, and signing with EMI Music worldwide. The album was created in four sessions, two in New York and two in Santa Barbara. A total of 22 songs were recorded, with the standard album being 13 songs in length while many of the others were released in subsequent deluxe editions.

In 2009, Depeche Mode allowed their likeness to be used in Valve's "Left 4 Dead 2".
On 15 January 2009, the official Depeche Mode website announced that the band's 12th studio album would be called "Sounds of the Universe". The album was released in April 2009, also made available through an iTunes Pass, where the buyer received individual tracks in the weeks leading up to official release date. Andy Fletcher says the idea for their iTunes Pass was a combination of the band's and iTunes': "I think the digital and record companies are starting to get their act together. They were very lazy in the first 10 years when downloads came in. Now they're collaborating more and coming up with interesting ideas for fans to buy products." The album went to number one in 21 countries. Critical response was generally positive and it was nominated for a Grammy in the Best Alternative Album category. "Wrong" was the first single from the album, released digitally in February 2009. Subsequent singles were "Peace" and the double A-side "Fragile Tension / Hole to Feed". In addition, "Perfect" was released as a promotional-only (non-commercial) single in the United States.

On 23 April 2009, Depeche Mode performed for the television program "Jimmy Kimmel Live!" at the famed corner of Hollywood Boulevard and Vine Street, drawing more than 12,000 fans, which was the largest audience the program had seen since its 2003 premiere, with a performance by Coldplay.

In May 2009, the band embarked on a concert tour in support of the album — called Tour of the Universe; it had been announced at a press conference in October 2008 at the Olympiastadion in Berlin. There was a warm up show in Luxembourg and it officially started on 10 May 2009 in Tel Aviv. The first leg of the tour was disrupted when Dave Gahan was struck down with gastroenteritis. During treatment, doctors found and removed a low grade tumour from the singer's bladder. Gahan's illness caused 16 concerts to be cancelled, but several of the shows were rescheduled for 2010. The band headlined the Lollapalooza festival during the North American leg of the tour. The tour also took the band back to South America for the first time since 1994's Exotic Tour. During the final European leg, the band played a show at London's Royal Albert Hall in aid of the Teenage Cancer Trust, where former member Alan Wilder joined Martin Gore on stage for a performance of "Somebody". In total the band played to more than 2.7 million people across 32 countries and the tour was one of the most profitable in America in 2009. The concerts held at Palau Sant Jordi, Barcelona, Spain were filmed and later released on DVD and Blu-ray Disc release entitled "". In March 2010, Depeche Mode won the award for "Best International Group – Rock / Pop" at the ECHO Awards in Germany.

On 6 June 2011, as the final commitment to their contract with EMI, the band released a remix compilation album, entitled "" that features remixes by former members Vince Clarke and Alan Wilder. Other remixers involved with the project were Nick Rhodes of Duran Duran, Röyksopp, Karlsson & Winnberg of Miike Snow, Eric Prydz, Clark and more. A new remix of "Personal Jesus" by Stargate, entitled "Personal Jesus 2011", was released as a single on 30 May 2011, in support of the compilation.

Depeche Mode contributed their cover of the U2 song "So Cruel" to the tribute album "AHK-toong BAY-bi Covered" honouring the 20th anniversary of "Achtung Baby", a 1991 album by U2. The compilation CD was released with the December 2011 issue of "Q".

In October 2012 during a press conference in Paris, Dave Gahan, Martin Gore and Andy Fletcher announced plans for a new album and a 2013 worldwide tour starting from Tel Aviv and continuing in Europe and North America. Martin Gore revealed that Flood mixed the album, marking the producer's first studio collaboration with the band since 1993's "Songs of Faith and Devotion".

In December 2012, the band officially announced signing a worldwide deal with Columbia Records and releasing a new album in March 2013. On 24 January 2013, it was confirmed that the album was titled "Delta Machine". "Heaven", the debut single from "Delta Machine" was released commercially on Friday 1 February 2013 (although not in the UK). The release date in the UK was pushed back to 18 March 2013 (17 March 2013 on iTunes). The physical release still bore the Mute Records logo, even though the band have now severed ties with their long standing label. Andy Fletcher mentioned in an interview this was due to their "devotion" to the label and with the band's insistence.

In March, the band announced North American dates to its Delta Machine summer tour, starting 22 August from Detroit and ending 8 October in Phoenix. In June, other European dates were confirmed for early 2014. The final gig of "Delta Machine Tour" took place in Moscow (Russia) on 7 March 2014, at Olimpiski venue.

That month, Depeche Mode won the award for "Best International Group – Rock / Pop" at the ECHO Awards in Germany. Also they were nominated at the category "Album des Jahres (national oder international)" for "Delta Machine", but lost against Helene Fischer's "Farbenspiel".

On 8 October 2014, the band announced "Live in Berlin", the new video and audio release filmed and recorded at the O2 World in Berlin, Germany in November 2013 during the Delta Machine Tour. It was released on 17 November 2014 worldwide.

In a 2015 Rolling Stone interview celebrating the 25th anniversary of "Violator", Martin Gore stated that Johnny Cash's cover of "Personal Jesus" is his favorite cover version of a Depeche Mode song.

On 25 January 2016, Martin Gore announced a projected return to the recording studio in April, with both Gore and Gahan having already written and demoed new songs.

In September, the official Depeche Mode Facebook page hinted at a new release, later confirmed by the band to be a music video compilation, "Video Singles Collection", scheduled for release in November by Sony. In October 2016, the band announced that their fourteenth album, titled "Spirit" and produced by James Ford, would be released in spring 2017. The group has also been nominated for the 2018 Rock and Roll Hall of Fame.

"Where's the Revolution", the lead single from "Spirit", was released 3 February 2017, along with its lyric video. The official video was published a week later, on 9 February. The Global Spirit Tour officially kicked off on 5 May 2017 with a performance in Stockholm, Sweden, at the Friends Arena. The first leg of the tour covered European countries only, ending with a final stadium show in Cluj-Napoca, Romania, at the Cluj Arena. The second leg of the tour covered North America and returned to Europe. The North America leg of the tour kicked off in Salt Lake City, Utah, on 23 August, at the USANA Amphitheatre. The band remained in North America until 15 November when they left for Dublin to resume the European leg. The band ended the tour in Europe with two sold-out shows on 23 and 25 July 2018 in Berlin, Germany, at the Waldbühne. In September 2019, the band announced that "Spirits in the Forest", a documentary that was partially filmed during these shows, would be released in theaters for one night only, 21 November 2019.

On 15 January 2020, the band was elected to the Rock and Roll Hall of Fame with an induction ceremony originally scheduled to take place on 2 May 2020, but postponed due to the COVID-19 pandemic.

Depeche Mode drew its artistic influences from a wide range of artists and scenes. They cited the electronic quartet band Kraftwerk as a primary influence for everyone in the band. Gore related what was their intent at their beginnings. "My dream was to combine the emotion of Neil Young or John Lennon transmitted by Kraftwerk's synthesizers. Soul music played by electronic instruments." They also cited David Bowie, The Clash, Roxy Music and Brian Eno, Elvis Presley, the Velvet Underground, and blues. Depeche Mode's music has mainly been described as synth-pop, new wave, electronic rock, dance-rock, alternative rock, arena rock and pop rock. The band also experimented with various other genres throughout its career, including avant-garde, electronica, pop, soul, techno, industrial rock and heavy metal.

Depeche Mode were considered a teen pop band during their early period in the UK, and interviewed in teen pop magazines such as "Smash Hits". Following the departure of Vince Clarke, their music began to take on a darker tone, establishing a darker sound in the band's music, as Martin Gore assumed lead songwriting duties. Gore's lyrics included themes such as sex, religion, and politics. Gore has stated he feels lyrical themes which tackle issues related to solitude and loneliness are a better representation of reality, whereas he finds "happy songs" fake and unrealistic. At the same time, he asserts that the band's music contains "an element of hope."

Depeche Mode have released a total of 14 studio albums, 10 compilation albums, six live albums, eight box sets, 13 video albums, 71 music videos, and 54 singles. They have sold over 100 million records and played live to more than 30 million fans worldwide. The band has had 50 songs in the UK Singles Chart, and one US and two UK number-one albums. In addition, all of their studio albums have reached the UK Top 10 and their albums have spent over 210 weeks on the UK Charts.

Music critic Sasha Frere-Jones claimed that "the last serious English influence was Depeche Mode, who seem more and more significant as time passes." Depeche Mode's releases have been nominated for five Grammy Awards: "Devotional" for Best Long Form Music Video; "I Feel Loved" and "Suffer Well", both for Best Dance Recording; "Sounds of the Universe" for Best Alternative Album; and "Wrong" for Best Short Form Music Video. In addition, Depeche Mode have been honoured with a Brit Award for "Enjoy the Silence" in the Best British Single category, the first-ever Q Magazine Innovation Award, and an Ivor Novello Award for Martin Gore in the category of International Achievement.

Depeche Mode were called "the most popular electronic band the world has ever known" by "Q" magazine, "one of the greatest British pop groups of all time" by "The Sunday Telegraph", and "the quintessential eighties techno-pop band" by "Rolling Stone" and AllMusic. They were ranked No. 2 on Electronic Music Realm's list of The 100 Greatest Artists of Electronic Music, ranked No. 158 on Acclaimed Music's list of Top 1000 Artists of All Time and "Q" Magazine included them on their list of "50 bands that changed the world". In an interview in 2009, Simple Minds lead singer Jim Kerr argued that Depeche Mode and U2 were the only contemporaries of his band which could be said to have "stayed constantly relevant".

Several major artists have cited the band as an influence, including: No Doubt, Marilyn Manson, The Killers, Coldplay, Muse, Linkin Park, The Crystal Method, Fear Factory, La Roux, Gotye, Rammstein, a-ha, Arcade Fire, Nine Inch Nails, Chvrches, Tegan and Sara (on "Sainthood") and A Perfect Circle.

Depeche Mode contemporaries Pet Shop Boys and Gary Numan have also cited the band as an influence.

The dark themes and moods of Depeche Mode's lyrics and music have been enjoyed by several heavy metal artists, and the band influenced acts such as Marilyn Manson and Deftones. They have also been named as an influence on Detroit techno and indie rock.

Early in their career, Depeche Mode was dismissive of benefit concerts such as Live Aid. Martin himself stated, "If these bands really care so much, they should just donate the money and let that be it. Why can't they do it without all the surrounding hype?". But in recent years, the band has applied their celebrity and cultural longevity to help promote and raise funds for several notable charity endeavors. They lent their support to high-profile charities such as MusiCares, Cancer Research UK and the Teenage Cancer Trust. The band has also supported the Small Steps Project, a humanitarian organization based in the United Kingdom, aiming to assist economically disadvantaged children into education. Since 2010, Depeche Mode have partnered with Swiss watchmaker Hublot to support Charity: Water, aimed at the provision of clean drinking water in developing countries. Such collaboration led to the release of two different limited edition watches, the Hublot Big Bang Depeche Mode in 2017 and The Singles Limited Edition series based from the Big Bang model in 2018. The proceeds helped raise $1.7 million for Charity:Water. In 2014, the partnership hosted a gala and fundraiser at the TsUM building in Moscow, raising $1.4 million for the charity.

Current members

Touring members

Former members







</doc>
<doc id="8536" url="https://en.wikipedia.org/wiki?curid=8536" title="Differential cryptanalysis">
Differential cryptanalysis

Differential cryptanalysis is a general form of cryptanalysis applicable primarily to block ciphers, but also to stream ciphers and cryptographic hash functions. In the broadest sense, it is the study of how differences in information input can affect the resultant difference at the output. In the case of a block cipher, it refers to a set of techniques for tracing differences through the network of transformation, discovering where the cipher exhibits non-random behavior, and exploiting such properties to recover the secret key (cryptography key).

The discovery of differential cryptanalysis is generally attributed to Eli Biham and Adi Shamir in the late 1980s, who published a number of attacks against various block ciphers and hash functions, including a theoretical weakness in the Data Encryption Standard (DES). It was noted by Biham and Shamir that DES was surprisingly resistant to differential cryptanalysis but small modifications to the algorithm would make it much more susceptible.

In 1994, a member of the original IBM DES team, Don Coppersmith, published a paper stating that differential cryptanalysis was known to IBM as early as 1974, and that defending against differential cryptanalysis had been a design goal. According to author Steven Levy, IBM had discovered differential cryptanalysis on its own, and the NSA was apparently well aware of the technique. IBM kept some secrets, as Coppersmith explains: "After discussions with NSA, it was decided that disclosure of the design considerations would reveal the technique of differential cryptanalysis, a powerful technique that could be used against many ciphers. This in turn would weaken the competitive advantage the United States enjoyed over other countries in the field of cryptography." Within IBM, differential cryptanalysis was known as the "T-attack" or "Tickle attack".

While DES was designed with resistance to differential cryptanalysis in mind, other contemporary ciphers proved to be vulnerable. An early target for the attack was the FEAL block cipher. The original proposed version with four rounds (FEAL-4) can be broken using only eight chosen plaintexts, and even a 31-round version of FEAL is susceptible to the attack. In contrast, the scheme can successfully cryptanalyze DES with an effort on the order 2 chosen plaintexts.

Differential cryptanalysis is usually a chosen plaintext attack, meaning that the attacker must be able to obtain ciphertexts for some set of plaintexts of their choosing. There are, however, extensions that would allow a known plaintext or even a ciphertext-only attack. The basic method uses pairs of plaintext related by a constant "difference". Difference can be defined in several ways, but the eXclusive OR (XOR) operation is usual. The attacker then computes the differences of the corresponding ciphertexts, hoping to detect statistical patterns in their distribution. The resulting pair of differences is called a differential. Their statistical properties depend upon the nature of the S-boxes used for encryption, so the attacker analyses differentials (Δ, Δ), where Δ = "S"("X" ⊕ Δ) ⊕ "S"("X") (and ⊕ denotes exclusive or) for each such S-box "S". In the basic attack, one particular ciphertext difference is expected to be especially frequent; in this way, the cipher can be distinguished from random. More sophisticated variations allow the key to be recovered faster than exhaustive search.

In the most basic form of key recovery through differential cryptanalysis, an attacker requests the ciphertexts for a large number of plaintext pairs, then assumes that the differential holds for at least "r" − 1 rounds, where "r" is the total number of rounds. The attacker then deduces which round keys (for the final round) are possible, assuming the difference between the blocks before the final round is fixed. When round keys are short, this can be achieved by simply exhaustively decrypting the ciphertext pairs one round with each possible round key. When one round key has been deemed a potential round key considerably more often than any other key, it is assumed to be the correct round key.

For any particular cipher, the input difference must be carefully selected for the attack to be successful. An analysis of the algorithm's internals is undertaken; the standard method is to trace a path of highly probable differences through the various stages of encryption, termed a "differential characteristic".

Since differential cryptanalysis became public knowledge, it has become a basic concern of cipher designers. New designs are expected to be accompanied by evidence that the algorithm is resistant to this attack, and many, including the Advanced Encryption Standard, have been proven secure against the attack.

The attack relies primarily on the fact that a given input/output difference pattern only occurs for certain values of inputs. Usually the attack is applied in essence to the non-linear components as if they were a solid component (usually they are in fact look-up tables or "S-boxes"). Observing the desired output difference (between two chosen or known plaintext inputs) "suggests" possible key values.

For example, if a differential of 1 => 1 (implying a difference in the least significant bit (LSB) of the input leads to an output difference in the LSB) occurs with probability of 4/256 (possible with the non-linear function in the AES cipher for instance) then for only 4 values (or 2 pairs) of inputs is that differential possible. Suppose we have a non-linear function where the key is XOR'ed before evaluation and the values that allow the differential are {2,3} and {4,5}. If the attacker sends in the values of {6, 7} and observes the correct output difference it means the key is either 6 ⊕ K = 2, or 6 ⊕ K = 4, meaning the key K is either 2 or 4.

In essence, for an n-bit non-linear function one would ideally seek as close to 2 as possible to achieve "differential uniformity". When this happens, the differential attack requires as much work to determine the key as simply brute forcing the key.

The AES non-linear function has a maximum differential probability of 4/256 (most entries however are either 0 or 2). Meaning that in theory one could determine the key with half as much work as brute force, however, the high branch of AES prevents any high probability trails from existing over multiple rounds. In fact, the AES cipher would be just as immune to differential and linear attacks with a much "weaker" non-linear function. The incredibly high branch (active S-box count) of 25 over 4R means that over 8 rounds no attack involves fewer than 50 non-linear transforms, meaning that the probability of success does not exceed Pr[attack] ≤ Pr[best attack on S-box]. For example, with the current S-box AES emits no fixed differential with a probability higher than (4/256) or 2 which is far lower than the required threshold of 2 for a 128-bit block cipher. This would have allowed room for a more efficient S-box, even if it is 16-uniform the probability of attack would have still been 2.

There exist no bijections for even sized inputs/outputs with 2-uniformity. They exist in odd fields (such as GF(2)) using either cubing or inversion (there are other exponents that can be used as well). For instance S(x) = x in any odd binary field is immune to differential and linear cryptanalysis. This is in part why the MISTY designs use 7- and 9-bit functions in the 16-bit non-linear function. What these functions gain in immunity to differential and linear attacks they lose to algebraic attacks. That is, they are possible to describe and solve via a SAT solver. This is in part why AES (for instance) has an affine mapping after the inversion.







</doc>
<doc id="8537" url="https://en.wikipedia.org/wiki?curid=8537" title="Document type definition">
Document type definition

A document type definition (DTD) is a set of "markup declarations" that define a "document type" for an SGML-family markup language (GML, SGML, XML, HTML).

A DTD defines the valid building blocks of an XML document. It defines the document structure with a list of validated elements and attributes. A DTD can be declared inline inside an XML document, or as an external reference.

XML uses a subset of SGML DTD.

, newer XML namespace-aware schema languages (such as W3C XML Schema and ISO RELAX NG) have largely superseded DTDs. A namespace-aware version of DTDs is being developed as Part 9 of ISO DSDL. DTDs persist in applications that need special publishing characters, such as the XML and HTML Character Entity References, which derive from larger sets defined as part of the ISO SGML standard effort.

A DTD is associated with an XML or SGML document by means of a document type declaration (DOCTYPE). The DOCTYPE appears in the syntactic fragment "doctypedecl" near the start of an XML document. The declaration establishes that the document is an instance of the type defined by the referenced DTD.

DOCTYPEs make two sorts of declaration:

The declarations in the internal subset form part of the DOCTYPE in the document itself. The declarations in the external subset are located in a separate text file. The external subset may be referenced via a "public identifier" and/or a "system identifier". Programs for reading documents may not be required to read the external subset.

Any valid SGML or XML document that references an "external subset" in its DTD, or whose body contains references to "parsed external entities" declared in its DTD (including those declared within its "internal subset"), may only be partially parsed but cannot be fully validated by "validating" SGML or XML parsers in their "standalone" mode (this means that these validating parsers don't attempt to retrieve these external entities, and their replacement text is not accessible).

However, such documents are still fully parsable in the "non"-standalone mode of validating parsers, which signals an error if it can't locate these external entities with their specified "public identifier" (FPI) or "system identifier" (a URI), or are inaccessible. (Notations declared in the DTD are also referencing external entities, but these unparsed entities are not needed for the validation of documents in the "standalone" mode of these parsers: the validation of all external entities referenced by notations is left to the application using the SGML or XML parser). Non-validating parsers "may" eventually attempt to locate these external entities in the "non"-standalone mode (by partially interpreting the DTD only to resolve their declared parsable entities), but do not validate the content model of these documents.

The following example of a DOCTYPE contains both public and system identifiers:
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
All HTML 4.01 documents conform to one of three SGML DTDs. The public identifiers of these DTDs are constant and are as follows:

The system identifiers of these DTDs, if present in the DOCTYPE, are URI references. A system identifier usually points to a specific set of declarations in a resolvable location. SGML allows mapping public identifiers to system identifiers in catalogs that are optionally available to the URI resolvers used by document parsing software.

This DOCTYPE can only appear "after" the optional XML declaration, and before the document body, if the document syntax conforms to XML. This includes XHTML documents:
<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- the XHTML document body starts here-->
<html xmlns="http://www.w3.org/1999/xhtml">
</html>
An additional internal subset can also be provided after the external subset:
<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd" [
<!-- the XHTML document body starts here-->
<html xmlns="http://www.w3.org/1999/xhtml">
</html>
Alternatively, only the internal subset may be provided:
<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html [
<!-- the XHTML document body starts here-->
<html xmlns="http://www.w3.org/1999/xhtml">
</html>
Finally, the document type definition may include no subset at all; in that case, it just specifies that the document has a single top-level element (this is an implicit requirement for all valid XML and HTML documents, but not for document fragments or for all SGML documents, whose top-level elements may be different from the implied root element), and it indicates the type name of the root element:

<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html>
<!-- the XHTML document body starts here-->
<html xmlns="http://www.w3.org/1999/xhtml">
</html>
DTDs describe the structure of a class of documents via element and attribute-list declarations. Element declarations name the allowable set of elements within the document, and specify whether and how declared elements and runs of character data may be contained within each element. Attribute-list declarations name the allowable set of attributes for each declared element, including the type of each attribute value, if not an explicit set of valid values.

DTD markup declarations declare which element types, attribute lists, entities, and notations are allowed in the structure of the corresponding class of XML documents.

An element type declaration defines an element and its possible content. A valid XML document contains only elements that are defined in the DTD.

Various keywords and characters specify an element's content:

For example:

<!ELEMENT html (head, body)>
<!ELEMENT p (#PCDATA | p | ul | dl | table | h1|h2|h3)*>
Element type declarations are ignored by "non-validating" SGML and XML parsers (in which cases, any elements are accepted in any order, and in any number of occurrences in the parsed document), but these declarations are still checked for form and validity.

An attribute list specifies for a given element type the list of all possible attribute associated with that type. For each possible attribute, it contains:

For example:

<!ATTLIST img

Here are some attribute types supported by both SGML and XML:

A default value can define whether an attribute must occur (#REQUIRED) or not (#IMPLIED), or whether it has a fixed value (#FIXED), or which value should be used as a default value ("…") in case the given attribute is left out in an XML tag.

Attribute list declarations are ignored by "non-validating" SGML and XML parsers (in which cases any attribute is accepted within all elements of the parsed document), but these declarations are still checked for well-formedness and validity.

An entity is similar to a macro. The entity declaration assigns it a value that is retained throughout the document. A common use is to have a name more recognizable than a numeric character reference for an unfamiliar character. Entities help to improve legibility of an XML text. In general, there are two types: internal and external.

An example of internal entity declarations (here in an internal DTD subset of an SGML document) is:

<!DOCTYPE sgml [

<sgml>&question;&signature;</sgml>
Internal entities may be defined in any order, as long as they are not referenced and parsed in the DTD or in the body of the document, in their order of parsing: it is valid to include a reference to a still undefined entity within the content of a parsed entity, but it is invalid to include anywhere else any named entity reference before this entity has been fully defined, including all other internal entities referenced in its defined content (this also prevents circular or recursive definitions of internal entities). This document is parsed as if it was:

<!DOCTYPE sgml [

<sgml>Why couldn’t I publish my books directly in standard SGML? — William Shakespeare.</sgml>
Reference to the "author" internal entity is not substituted in the replacement text of the "signature" internal entity. Instead, it is replaced only when the "signature" entity reference is parsed within the content of the "sgml" element, but only by validating parsers (non-validating parsers do not substitute entity references occurring within contents of element or within attribute values, in the body of the document.

This is possible because the replacement text specified in the internal entity definitions permits a distinction between parameter entity references (that are introduced by the "%" character and whose replacement applies to the parsed DTD contents) and general entity references (that are introduced by the "&" character and whose replacement is delayed until they are effectively parsed and validated). The "%" character for introducing parameter entity references in the DTD loses its special role outside the DTD and it becomes a literal character.

However, the references to predefined numeric character entities are substituted wherever they occur, without needing a validating parser (they are only introduced by the "&" character).

Notations are used in SGML or XML. They provide a complete reference to unparsed external entities whose interpretation is left to the application (which interprets them directly or retrieves the external entity themselves), by assigning them a simple name, which is usable in the body of the document. For example, notations may be used to reference non-XML data in an XML 1.1 document. For example, to annotate SVG images to associate them with a specific renderer:

<!NOTATION type-image-svg SYSTEM "image/svg">
This declares the MIME type of external images with this type, and associates it with a notation name "type-image-svg". However, notation names usually follow a naming convention that is specific to the application generating or using the notation: notations are interpreted as additional meta-data whose effective content is an external entity and either a PUBLIC FPI, registered in the catalogs used by XML or SGML parsers, or a SYSTEM URI, whose interpretation is application dependent (here a MIME type, interpreted as a relative URI, but it could be an absolute URI to a specific renderer, or a URN indicating an OS-specific object identifier such as a UUID).

The declared notation name must be unique within all the document type declaration, i.e. in the external subset as well as the internal subset, at least for conformance with XML.

Notations can be associated to unparsed external entities included in the body of the SGML or XML document. The PUBLIC or SYSTEM parameter of these external entities specifies the FPI and/or the URI where the unparsed data of the external entity is located, and the additional NDATA parameter of these defined entities specifies the additional notation (i.e., effectively the MIME type here). For example:

<!DOCTYPE sgml [

<sgml>
</sgml>
Within the body of the SGML document, these referenced external entities (whose name is specified between "&" and ";") are "not" replaced like usual named entities (defined with a CDATA value), but are left as distinct unparsed tokens that may be used either as the value of an element attribute (like above) or within the element contents, provided that either the DTD allows such external entities in the declared content type of elements or in the declared type of attributes (here the ENTITY type for the data attribute), or the SGML parser is not validating the content.

Notations may also be associated directly to elements as additional meta-data, without associating them to another external entity, by giving their names as possible values of some additional attributes (also declared in the DTD within the <!ATTLIST ...> declaration of the element). For example:

<!DOCTYPE sgml [

<sgml type="type-vendor-specific">

</sgml>
The example above shows a notation named "type-image-svg" that references the standard public FPI and the system identifier (the standard URI) of an SVG 1.1 document, instead of specifying just a system identifier as in the first example (which was a relative URI interpreted locally as a MIME type). This annotation is referenced directly within the unparsed "type" attribute of the "img" element, but its content is not retrieved. It also declares another notation for a vendor-specific application, to annotate the "sgml" root element in the document. In both cases, the declared notation named is used directly in a declared "type" attribute, whose content is specified in the DTD with the "NOTATION" attribute type (this "type" attribute is declared for the "sgml" element, as well as for the "img" element).

However, the "title" attribute of the "img" element specifies the internal entity "example1SVGTitle" whose declaration that does not define an annotation, so it is parsed by validating parsers and the entity replacement text is "Title of example1.svg".

The content of the "img" element references another external entity "example1SVG" whose declaration also does not define an notation, so it is also parsed by validating parsers and the entity replacement text is located by its defined SYSTEM identifier "example1.svg" (also interpreted as a relative URI). The effective content for the "img" element be the content of this second external resource. The difference with the GIF image, is that the SVG image is parsed within the SGML document, according to the declarations in the DTD, where the GIF image is just referenced as an opaque external object (which is not parsable with SGML) via its "data" attribute (whose value type is an opaque ENTITY).

Only one notation name may be specified in the value of ENTITY attributes (there's no support in SGML, XML 1.0 or XML 1.1 for multiple notation names in the same declared external ENTITY, so separate attributes are needed). However multiple external entities may be referenced (in a space-separated list of names) in attributes declared with type ENTITIES, and where each named external entity is also declared with its own notation).

Notations are also completely opaque for XML and SGML parsers, so they are not differentiated by the type of the external entity that they may reference (for these parsers they just have a unique name associated to a public identifier (an FPI) and/or a system identifier (a URI)).

Some applications (but not XML or SGML parsers themselves) also allow referencing notations indirectly by naming them in the "URN:"name"" value of a standard CDATA attribute, everywhere a URI can be specified. However this behaviour is application-specific, and requires that the application maintains a catalog of known URNs to resolve them into the notations that have been parsed in a standard SGML or XML parser. This use allows notations to be defined only in a DTD stored as an external entity and referenced only as the external subset of documents, and allows these documents to remain compatible with validating XML or SGML parsers that have no direct support for notations.

Notations are not used in HTML, or in basic profiles for XHTML and SVG, because:

Even in validating SGML or XML 1.0 or XML 1.1 parsers, the external entities referenced by an FPI and/or URI in declared notations are not retrieved automatically by the parsers themselves. Instead, these parsers just provide to the application the parsed FPI and/or URI associated to the notations found in the parsed SGML or XML document, and with a facility for a dictionary containing all notation names declared in the DTD; these validating parsers also check the uniqueness of notation name declarations, and report a validation error if some notation names are used anywhere in the DTD or in the document body but not declared:

The XML DTD syntax is one of several XML schema languages. However, many of the schema languages do not fully replace the XML DTD. Notably, the XML DTD allows defining entities and notations that have no direct equivalents in DTD-less XML (because internal entities and parsable external entities are not part of XML schema languages, and because other unparsed external entities and notations have no simple equivalent mappings in most XML schema languages).

Most XML schema languages are only replacements for element declarations and attribute list declarations, in such a way that it becomes possible to parse XML documents with "non-validating" XML parsers (if the only purpose of the external DTD subset was to define the schema). In addition, documents for these XML schema languages must be parsed separately, so validating the schema of XML documents in pure standalone mode is not really possible with these languages: the document type declaration remains necessary for at least identifying (with a XML Catalog) the schema used in the parsed XML document and that is validated in another language.

A common misconception holds that a "non-validating" XML parser does not have to read document type declarations, when in fact, the document type declarations must still be scanned for correct syntax as well as validity of declarations, and the parser must still parse all entity declarations in the "internal subset", and substitute the replacement texts of internal entities occurring anywhere in the document type declaration or in the document body.

A "non-validating" parser may, however, elect not to read parsable "external entities" (including the "external subset"), and does not have to honor the content model restrictions defined in element declarations and in attribute list declarations.

If the XML document depends on parsable external entities (including the specified "external subset", or parsable external entities declared in the "internal subset"), it should assert codice_4 in its XML declaration. The validating DTD may be identified by using XML Catalogs to retrieve its specified "external subset".

In the example below, the XML document is declared with codice_4 because it has an external subset in its document type declaration:

<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE people_list SYSTEM "example.dtd">
<people_list />
If the XML document type declaration includes any SYSTEM identifier for the external subset, it can't be safely processed as standalone: the URI should be retrieved, otherwise there may be unknown named character entities whose definition may be needed to correctly parse the effective XML syntax in the internal subset or in the document body (the XML syntax parsing is normally performed "after" the substitution of all named entities, excluding the five entities that are predefined in XML and that are implicitly substituted "after" parsing the XML document into lexical tokens). If it just includes any PUBLIC identifier, it "may" be processed as standalone, if the XML processor knows this PUBLIC identifier in its local catalog from where it can retrieve an associated DTD entity.

An example of a very simple external XML DTD to describe the schema of a list of persons might consist of:

<!ELEMENT people_list (person)*>
<!ELEMENT person (name, birthdate?, gender?, socialsecuritynumber?)>
<!ELEMENT name (#PCDATA)>
<!ELEMENT birthdate (#PCDATA)>
<!ELEMENT gender (#PCDATA)>
<!ELEMENT socialsecuritynumber (#PCDATA)>
Taking this line by line:

An example of an XML file that uses and conforms to this DTD follows. The DTD is referenced here as an external subset, via the SYSTEM specifier and a URI. It assumes that we can identify the DTD with the relative URI reference "example.dtd"; the "people_list" after "!DOCTYPE" tells us that the root tags, or the first element defined in the DTD, is called "people_list":

<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE people_list SYSTEM "example.dtd">
<people_list>
</people_list>
One can render this in an XML-enabled browser (such as Internet Explorer or Mozilla Firefox) by pasting and saving the DTD component above to a text file named "example.dtd" and the XML file to a differently-named text file, and opening the XML file with the browser. The files should both be saved in the same directory. However, many browsers do not check that an XML document confirms to the rules in the DTD; they are only required to check that the DTD is syntactically correct. For security reasons, they may also choose not to read the external DTD.

The same DTD can also be embedded directly in the XML document itself as an internal subset, by encasing it within [square brackets] in the document type declaration, in which case the document no longer depends on external entities and can be processed in standalone mode:

<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<!DOCTYPE people_list [
<people_list>
</people_list>
Alternatives to DTDs (for specifying schemas) are available:

An XML DTD can be used to create a denial of service (DoS) attack by defining nested entities that expand exponentially, or by sending the XML parser to an external resource that never returns.

For this reason, .NET Framework provides a property that allows prohibiting or skipping DTD parsing, and recent versions of Microsoft Office applications (Microsoft Office 2010 and higher) refuse to open XML files that contain DTD declarations.




</doc>
<doc id="8539" url="https://en.wikipedia.org/wiki?curid=8539" title="Devil">
Devil

A devil is the personification of evil as it is conceived in many and various cultures and religious traditions. It is seen as the objectification of a hostile and destructive force.

It is difficult to specify a particular definition of any complexity that will cover all of the traditions, beyond that it is a manifestation of evil. It is meaningful to consider the devil through the lens of each of the cultures and religions that have the devil as part of their mythos.

The history of this concept intertwines with theology, mythology, psychiatry, art and literature, maintaining a validity, and developing independently within each of the traditions. It occurs historically in many contexts and cultures, and is given many different names—Satan, Lucifer, Beelzebub, Mephistopheles—and attributes: It is portrayed as blue, black, or red; it is portrayed as having horns on its head, and without horns, and so on. The idea of the devil has been taken seriously often, but not always, for example when devil figures are used in advertising and on candy wrappers.

The Modern English word "devil" derives from the Middle English "devel", from the Old English "dēofol", that in turn represents an early Germanic borrowing of the Latin "diabolus". This in turn was borrowed from the "diábolos", "slanderer", from "diabállein", "to slander" from διά "diá", "across, through" and βάλλειν "bállein", "to hurl", probably akin to the Sanskrit "gurate", "he lifts up".

In his book "The Devil: Perceptions of Evil from Antiquity to Primitive Christianity", Jeffrey Burton Russell discusses various meanings and difficulties that are encountered when using the term "devil". He does not claim to define the word in a general sense, but he describes the limited use that he intends for the word in his book—limited in order to "minimize this difficulty" and "for the sake of clarity". In this book Russell uses the word "devil" as "the personification of evil found in a variety of cultures", as opposed to the word "Satan", which he reserves specifically for the figure in the Abrahamic religions.

In the Introduction to his book "Satan: A Biography", Henry Ansgar Kelly discusses various considerations and meanings that he has encountered in using terms such as "devil" and "Satan", etc. While not offering a general definition, he describes that in his book "whenever "diabolos" is used as the proper name of Satan", he signals it by using "small caps".

The "Oxford English Dictionary" has a variety of definitions for the meaning of "devil", supported by a range of citations: "Devil" may refer to Satan, the supreme spirit of evil, or one of Satan's emissaries or demons that populate Hell, or to one of the spirits that possess a demonic person; "devil" may refer to one of the "malignant deities" feared and worshiped by "heathen people", a demon, a malignant being of superhuman powers; figuratively "devil" may be applied to a wicked person, or playfully to a rogue or rascal, or in empathy often accompanied by the word "poor" to a person—"poor devil".

In the Bahá'í Faith, a malevolent, superhuman entity such as a "devil" or "satan" is not believed to exist. These terms do, however, appear in the Bahá'í writings, where they are used as metaphors for the lower nature of man. Human beings are seen to have free will, and are thus able to turn towards God and develop spiritual qualities or turn away from God and become immersed in their self-centered desires. Individuals who follow the temptations of the self and do not develop spiritual virtues are often described in the Bahá'í writings with the word "satanic". The Bahá'í writings also state that the devil is a metaphor for the "insistent self" or "lower self" which is a self-serving inclination within each individual. Those who follow their lower nature are also described as followers of "the Evil One".

In Christianity, evil is incarnate in the devil or Satan, a fallen angel who is the primary opponent of God. Christians also considered the Roman and Greek deities as devils.

Christianity describes Satan as a fallen angel who terrorizes the world through evil, is the antithesis of truth, and shall be condemned, together with the fallen angels who follow him, to eternal fire at the Last Judgment.

In mainstream Christianity, the devil is usually referred to as Satan. This is because Christian beliefs in Satan are inspired directly by the dominant view of Second Temple Judaism, as expressed/practiced by Jesus, and with some minor variations. Some modern Christians consider the devil to be an angel who, along with one-third of the angelic host (the demons), rebelled against God and has consequently been condemned to the Lake of Fire. He is described as hating all humanity (or more accurately creation), opposing God, spreading lies and wreaking havoc on their souls.

Satan is traditionally identified as the serpent who convinced Eve to eat the forbidden fruit; thus, Satan has often been depicted as a serpent. Although this identification is not present in the Adam and Eve narrative, this interpretation goes back at least as far as the time of the writing of the Book of Revelation, which specifically identifies Satan as being the serpent (Rev. 20:2).

In the Bible, the devil is identified with "the dragon" and "the old serpent" seen in the Book of Revelation (12:9, 20:2), as has "the prince of this world" in the Gospel of John (12:31, 14:30); and "the spirit that now worketh in the children of disobedience" in the Epistle to the Ephesians (2:2); and "the god of this world" in 2 Corinthians (4:4). He is also identified as the dragon in the Book of Revelation (e.g.), and the tempter of the Gospels (e.g. Matthew 4:1).

The devil is sometimes called Lucifer, particularly when describing him as an angel before his fall, although the reference in Isaiah 14:12 to Lucifer (Latin "Luciferus", "bringer of light"), the "son of the dawn", is a reference to a Babylonian king.

Beelzebub is originally the name of a Philistine god (more specifically a certain type of Baal, from "Ba‘al Zebûb", lit. "Lord of Flies") but is also used in the New Testament as a synonym for Satan. A corrupted version, "Belzeboub", appears in "The Divine Comedy" ("Inferno" XXXIV).

In other, non-mainstream, Christian beliefs (e.g. the beliefs of the Christadelphians) the word "satan" in the Bible is not regarded as referring to a supernatural, personal being but to any 'adversary' and figuratively refers to human sin and temptation.

In the Book of Wisdom, the devil is represented as the one who brought death into the world. The Second Book of Enoch contains references to a Watcher called Satanael, describing him as the prince of the "Grigori" who was cast out of heaven and an evil spirit who knew the difference between what was "righteous" and "sinful".

In the Book of Jubilees, Satan rules over a host of angels. Mastema, who induced God to test Abraham through the sacrifice of Isaac, is identical with Satan in both name and nature. The Book of Enoch contains references to Sathariel, thought also to be Sataniel and Satan'el. The similar spellings mirror that of his angelic brethren Michael, Raphael, Uriel and Gabriel, previous to his expulsion from Heaven.

In some traditions, divinities can become demons. The Teutonic gods demonized the Giants.

Gnostic and Gnostic-influenced religions postulate the idea that the material world is inherently evil. The "One true God" is remote, beyond the material universe, therefore this universe must be governed by an inferior imposter deity. This deity was identified with the deity of the Old Testament by some sects, such as the Sethians and the Marcions. Tertullian accuses Marcion of Sinope, that he John Arendzen (1909) in the "Catholic Encyclopedia" (1913) mentions that Eusebius accused Apelles, the 2nd-century AD Gnostic, of considering the Inspirer of Old Testament prophecies to be not a god, but an evil angel. These writings commonly refer to the Creator of the material world as "a demiurgus" to distinguish him from the "One true God". Some texts, such as the Apocryphon of John and On the Origin of the World, not only demonized the Creator God but also called him by the name of the devil in some Jewish writings, "Samael".

According to Mandaean mythology, "Ruha Qadishta" fell apart from the "world of light" and gave birth to the devil, called "Lord of Darkness" ("malka dhshuka") or "Ur". According to one tradition, Ur is an androgyne lion-headed dragon with the wings of an eagle. Together they create several evil demons, liliths and vampires. Ruha Qadishta is described as a liar and sorcerer. Several Abrahamitic prophets are regarded as servants of these devils or their subordinates such as Adonai, including Moses. Jesus appears as another son of Ruha Qadishta and Ur, who distorted the Baptism-ritual thought by John the Baptist. Eventually Ruha will be rehabilitated and return to the world of light.

In the 12th century in Europe the Cathars, who were rooted in Gnosticism, dealt with the problem of evil, and developed ideas of dualism and demonology. The Cathars were seen as a serious potential challenge to the Catholic church of the time. The Cathars split into two camps. The first is "absolute" dualism, which held that evil was completely separate from the good God, and that God and the devil each had power. The second camp is "mitigated" dualism, which considers Lucifer to be a son of God, and a brother to Christ. To explain this they used the parable of the prodigal son, with Christ as the good soon, and Lucifer as the son that strayed into evilness. The Catholic Church responded to dualism in AD 1215 in the Fourth Lateran Council, saying that God created everything from nothing, and the devil was good when he was created, but he made himself bad by his own free will. In the "Gospel of the Secret Supper", Lucifer, just as in prior Gnostic systems, appears as a demiurge, who created the material world.

The earliest Hindu texts do not offer further explanations for evil, regarding evil as something natural. However, later texts offer various explanations for evil. According to an explanation given by the Brahmins, both demons and gods spoke truth and untruth, but the demons relinquished the truth and the gods relinquished the untruth. But both spirits are regarded as different aspects of one supreme god. Even some fierce deities like Kali are not thought of as devils but just as darker aspects of god and may even manifest benevolence.

In Islam, the principle of evil is expressed by two terms referring to the same entity: "Shaitan" (meaning "astray", "distant" or "devil") and "Iblis". Iblis is the proper name of the devil representing the characteristics of evil. Iblis is mentioned in the Quranic narrative about the creation of humanity. When God created Adam, he ordered the angels to prostrate themselves before him. All did, but Iblis refused and claimed to be superior to Adam out of pride. Therefore, pride but also envy became a sign of "unbelief" in Islam. Thereafter Iblis was condemned to Hell, but God granted him a request to lead humanity astray, knowing the righteous will resist Iblis' attempts to misguide them. In Islam, both good and evil are ultimately created by God. But since God's will is good, the evil in the world must be part of God's plan. Actually, God allowed the devil to seduce humanity. Evil and suffering are regarded as a test or a chance to proof confidence in God. Some philosophers and mystics emphasized Iblis himself as a role model of confidence in God, because God ordered the angels to prostrate themselves, Iblis was forced to choose between God's command and God's will (not to praise someone else than God). He successfully passed the test, yet his disobedience caused his punishment and therefore suffering. However, he stays patient and is rewarded in the end.

Muslims held that the pre-Islamic jinn, tutelary deities, became subject under Islam to the judgment of God, and that those who did not submit to the law of God are devils.

Like in Christianity, Iblis was once a pious creature of God but later cast out of Heaven due to his pride. However, to maintain God's absolute sovereignty, Islam matches the line taken by Irenaeus instead of the later Christian consensus that the devil did not rebel against God but against humanity. Further, although Iblis is generally regarded as a real bodily entity, he plays a less significant role as the personification of evil than in Christianity. Iblis is merely a tempter, notable for inciting humans into sin by "whispering" into humans minds (waswās), akin to the Jewish idea of the devil as "yetzer hara".

On the other hand, "Shaitan" refers unilaterally to forces of evil, including the devil Iblis, then he causes mischief. Shaitan is also linked to humans psychological nature, appearing in dreams, causing anger or interrupting the mental preparation for prayer. Furthermore, the term "Shaitan" also refers to beings, who follow the evil suggestions of Iblis. Furthermore, the principle of "Shaitan" is in many ways a symbol of spiritual impurity, representing humans' own deficits, in contrast to a "true Muslim", who is free from anger, lust and other devilish desires.

In contrast to "Occidental philosophy", the Sufi idea of seeing "Many as One" and considering the creation in their essence as the Absolute, leads to the idea of the dissolution of any dualism between the ego substance and the "external" substinantial objects. The rebellion against God, mentioned in the Quran, takes place on the level of the psyche, that must be trained and disciplined for its union with the spirit that is pure. Since psyche drives the body, "flesh" is not the obstacle to human, but an unawarness that allowed the impulsive forces to cause rebellion against God on the level of the psyche. Yet, it is not a dualism between body, psyche and spirit, since the spirit embraces both psyche and corperal aspects of human. Since the world is hold as the mirror in which God's attributes are reflected, participation in worldly affairs is not necessarily seen as opposed to God. The devil activates the selfish desires of the psyche, leading him astray from the Divine. Thus it is the "I" that is regarded as evil, and both Iblis as well as "Pharao" are present as symbols for uttering "I" in ones own behavior. Therefore, it is recommended, to use the term "I" as rare as possible. It is only God who has the right to say "I", since it is only God who is self-subsistent. Uttering "I" is therefore a way to compare oneselves to God, regarded as "shirk".

Salafi strands of Islam commonly emphasize a dualistic worldview between the believers and the unbelievers, with the devil as the enemy of God's path. Even though the devil will be finally defeated by God, he is a serious and dangerous opponent of humans. While in classical hadiths, the demons ("Shayateen") and the jinn are responsible for impurity and possibly endanger people, in Salafi thought, it is the devil himself, who lurks on the believers, always striving to lead them astray from God. The devil is regarded as an omnipresent entity, permanently inciting humans into sin, but can be "pushed away" by remembering the name God. The devil is regarded as an external entity, threatening the everyday life of the believer, even in social aspects of life. Thus for example, it is the devil who is responsible for Western emancipation.

Yahweh, the god in pre-exilic Judaism, created both good and evil, as stated in Isaiah 45:7: "I form the light, and create darkness: I make peace, and create evil: I the Lord do all these things." The devil does not exist in Jewish scriptures. However, the influence of Zoroastrianism during the Achaemenid Empire introduced evil as a separate principle into the Jewish belief system, which gradually externalized the opposition until the Hebrew term "satan" developed into a specific type of supernatural entity, changing the monistic view of Judaism into a dualistic one. Later, Rabbinic Judaism rejected the Enochian books (written during the Second Temple period under Persian influence), which depicted the devil as an independent force of evil besides God. After the apocalyptic period, references to Satan in the Tanakh are thought to be allegorical.

In Manichaeism, God and the devil are two unrelated principles. God created "good" and inhabits the realm of light, while the devil (also called the "prince of darkness") created evil and inhabits the kingdom of darkness. The contemporary world came into existence, when the kingdom of darkness assaulted the kingdom of light and mingled with the spiritual world. At the end, the devil and his followers will be sealed forever and the kingdom of light and the kingdom of darkness will continue to co-exist eternally, never to commingle again.

Hegemonius (4th century AD) accuses that the Persian prophet Mani, founder of the Manichaean sect in the 3rd century AD, identified Jehovah as "the devil god which created the world" and said that "he who spoke with Moses, the Jews, and the priests … is the [Prince] of Darkness, … not the god of truth."

Among the Tengristic myths of central Asia, Erlik refers to a devil-like figure as the ruler of Hell, who is also the first human. According to one narrative, Erlik and God swam together over the primordial waters. When God was about to create the Earth, he send Erlik to dive into the waters and collect some mud. Erlik hid some inside his mouth to later create his own world. But when God commanded the Earth to expand, Erlik got troubled by the mud in his mouth. God aided Erlik to spit it out. The mud carried by Erlik gave place to the unpleasant areas of the world. Because of his sin, he was assigned to evil. In another variant, the creator-god is identified with Ulgen. Again, Erlik appears to be the first human. He desired to create a human just as Ulgen did, thereupon Ulgen reacted by punishing Erlik, casting him into the Underworld where he becomes its ruler.

According to Tengrism, there is no death by meaning that life comes to an end, it is merely a transition into the invisible world. As the ruler of Hell, Erlik enslaves the souls, who are damned to Hell. Further, he lurks on the souls of those humans living on Earth by causing death, disease and illnesses. At the time of birth, Erlik sends a Kormos to seize the soul of the newborn, following him for the rest of his life in an attempt to seize his soul by hampering, misguiding and injuring him. When Erlik succeeds in destroying a human's body, the Kormos sent by Erlik will try take him down into the Underworld. However a good soul will be brought to Paradise by a "Yayutshi" sent by Ulgen. Some shamans also made sacrifices to Erlik, for gaining a higher rank in the Underworld, if they should be damned to Hell.

According to Yazidism there is no entity that represents evil in opposition to God; such dualism is rejected by Yazidis, and evil is regarded as nonexistent. Yazidis adhere to strict monism and are prohibited from uttering the word "devil" and from speaking of anything related to Hell.

Zoroastrianism probably introduced the first idea of the conceptual "devil"; a principle of evil independently existing apart from God. In Zoroastrianism, good and evil derive from two ultimately opposed forces. The force of good is called Ahura Mazda and the "destructive spirit" in Avestan-language called Angra Mainyu. The Middle Persian equivalent is Ahriman. They are in eternal struggle and neither is all-powerful, especially Angra Mainyu is limited to space and time: in the end of time, he will be finally defeated. While Ahura Mazda creates what is good, Angra Mainyu is responsible for every evil and suffering in the world, such as toads and scorpions.

In some religions and traditions, these titles are separate demons; others identify these names as guises of the devil. Even when thought of as individual demons, some are often thought of being under the devil's direct control. This identifies only those thought of as the devil; List of demons has a more general listing.

These are titles that almost always refer to devil-figures.





</doc>
<doc id="8540" url="https://en.wikipedia.org/wiki?curid=8540" title="Diesel engine">
Diesel engine

The diesel engine, named after Rudolf Diesel, is an internal combustion engine in which ignition of the fuel is caused by the elevated temperature of the air in the cylinder due to the mechanical compression (adiabatic compression); thus, the diesel engine is a so-called compression-ignition engine (CI engine). This contrasts with engines using spark plug-ignition of the air-fuel mixture, such as a petrol engine (gasoline engine) or a gas engine (using a gaseous fuel like natural gas or liquefied petroleum gas).

Diesel engines work by compressing only the air. This increases the air temperature inside the cylinder to such a high degree that atomised diesel fuel injected into the combustion chamber ignites spontaneously. With the fuel being injected into the air just before combustion, the dispersion of the fuel is uneven; this is called a heterogeneous air-fuel mixture. The torque a diesel engine produces is controlled by manipulating the air-fuel ratio (λ); instead of throttling the intake air, the diesel engine relies on altering the amount of fuel that is injected, and the air-fuel ratio is usually high.

The diesel engine has the highest thermal efficiency (engine efficiency) of any practical internal or external combustion engine due to its very high expansion ratio and inherent lean burn which enables heat dissipation by the excess air. A small efficiency loss is also avoided compared with non-direct-injection gasoline engines since unburned fuel is not present during valve overlap and therefore no fuel goes directly from the intake/injection to the exhaust. Low-speed diesel engines (as used in ships and other applications where overall engine weight is relatively unimportant) can reach effective efficiencies of up to 55%.

Diesel engines may be designed as either two-stroke or four-stroke cycles. They were originally used as a more efficient replacement for stationary steam engines. Since the 1910s, they have been used in submarines and ships. Use in locomotives, trucks, heavy equipment and electricity generation plants followed later. In the 1930s, they slowly began to be used in a few automobiles. Since the 1970s, the use of diesel engines in larger on-road and off-road vehicles in the US has increased. According to Konrad Reif, the EU average for diesel cars accounts for half of newly registered cars.

The world's largest diesel engines put in service are 14-cylinder, two-stroke watercraft diesel engines; they produce a peak power of almost 100 MW each.

In 1878, Rudolf Diesel, who was a student at the "Polytechnikum" in Munich, attended the lectures of Carl von Linde. Linde explained that steam engines are capable of converting just 6–10% of the heat energy into work, but that the Carnot cycle allows conversion of much more of the heat energy into work by means of isothermal change in condition. According to Diesel, this ignited the idea of creating a highly efficient engine that could work on the Carnot cycle. Diesel was also exposed to a fire piston, a traditional fire starter using rapid adiabatic compression principles which Linde had acquired from Southeast Asia. After several years of working on his ideas, Diesel published them in 1893 in the essay Theory and Construction of a Rational Heat Motor.

Diesel was heavily criticised for his essay, but only few found the mistake that he made; his "rational heat motor" was supposed to utilise a constant temperature cycle (with isothermal compression) that would require a much higher level of compression than that needed for compression ignition. Diesel's idea was to compress the air so tightly that the temperature of the air would exceed that of combustion. However, such an engine could never perform any usable work. In his 1892 US patent (granted in 1895) #542846 Diesel describes the compression required for his cycle:

By June 1893, Diesel had realised his original cycle would not work and he adopted the constant pressure cycle. Diesel describes the cycle in his 1895 patent application. Notice that there is no longer a mention of compression temperatures exceeding the temperature of combustion. Now it is simply stated that the compression must be sufficient to trigger ignition.

In 1892, Diesel received patents in Germany, Switzerland, the United Kingdom and the United States for "Method of and Apparatus for Converting Heat into Work". In 1894 and 1895, he filed patents and addenda in various countries for his engine; the first patents were issued in Spain (No. 16,654), France (No. 243,531) and Belgium (No. 113,139) in December 1894, and in Germany (No. 86,633) in 1895 and the United States (No. 608,845) in 1898.

Diesel was attacked and criticised over a time period of several years. Critics have claimed that Diesel never invented a new motor and that the invention of the diesel engine is fraud. Otto Köhler and Emil Capitaine were two of the most prominent critics of Diesel's time. Köhler had published an essay in 1887, in which he describes an engine similar to the engine Diesel describes in his 1893 essay. Köhler figured that such an engine could not perform any work. Emil Capitaine had built a petroleum engine with glow-tube ignition in the early 1890s; he claimed against his own better judgement, that his glow-tube ignition engine worked the same way Diesel's engine did. His claims were unfounded and he lost a patent lawsuit against Diesel. Other engines, such as the Akroyd engine and the Brayton engine, also use an operating cycle that is different from the diesel engine cycle. Friedrich Sass says that the diesel engine is Diesel's "very own work" and that any "Diesel myth" is "falsification of history".

Diesel sought out firms and factories that would build his engine. With the help of Moritz Schröter and , he succeeded in convincing both Krupp in Essen and the Maschinenfabrik Augsburg. Contracts were signed in April 1893, and in early summer 1893, Diesel's first prototype engine was built in Augsburg. On 10 August 1893, the first ignition took place, the fuel used was petrol. In winter 1893/1894, Diesel redesigned the existing engine, and by 18 January 1894, his mechanics had converted it into the second prototype. On February 17, 1894, the redesigned engine ran for 88 revolutions – one minute; with this news, Maschinenfabrik Augsburg's stock rose by 30%, indicative of the tremendous anticipated demands for a more efficient engine. On 26 June 1895 the engine achieved an effective efficiency of 16.6% and had a fuel consumption of 519 g·kW·h.

In February 1896, Diesel considered supercharging the third prototype. Imanuel Lauster, who was ordered to draw the third prototype, had finished the drawings by 30 April 1896. During summer that year the engine was built, it was completed on 6 October 1896. Tests were conducted until early 1897. First public tests began on 1 February 1897. Moritz Schröter's test on 17 February 1897 was the main test of Diesel's engine. The engine was rated 13.1 kW with a specific fuel consumption of 324 g·kW·h, resulting in an effective efficiency of 26.2%. By 1898, Diesel had become a millionaire.














The characteristics of a diesel engine are

The diesel internal combustion engine differs from the gasoline powered Otto cycle by using highly compressed hot air to ignite the fuel rather than using a spark plug ("compression ignition" rather than "spark ignition").

In the diesel engine, only air is initially introduced into the combustion chamber. The air is then compressed with a compression ratio typically between 15:1 and 23:1. This high compression causes the temperature of the air to rise. At about the top of the compression stroke, fuel is injected directly into the compressed air in the combustion chamber. This may be into a (typically toroidal) void in the top of the piston or a "pre-chamber" depending upon the design of the engine. The fuel injector ensures that the fuel is broken down into small droplets, and that the fuel is distributed evenly. The heat of the compressed air vaporises fuel from the surface of the droplets. The vapour is then ignited by the heat from the compressed air in the combustion chamber, the droplets continue to vaporise from their surfaces and burn, getting smaller, until all the fuel in the droplets has been burnt. Combustion occurs at a substantially constant pressure during the initial part of the power stroke. The start of vaporisation causes a delay before ignition and the characteristic diesel knocking sound as the vapour reaches ignition temperature and causes an abrupt increase in pressure above the piston (not shown on the P-V indicator diagram). When combustion is complete the combustion gases expand as the piston descends further; the high pressure in the cylinder drives the piston downward, supplying power to the crankshaft.

As well as the high level of compression allowing combustion to take place without a separate ignition system, a high compression ratio greatly increases the engine's efficiency. Increasing the compression ratio in a spark-ignition engine where fuel and air are mixed before entry to the cylinder is limited by the need to prevent pre-ignition, which would cause engine damage. Since only air is compressed in a diesel engine, and fuel is not introduced into the cylinder until shortly before top dead centre (TDC), premature detonation is not a problem and compression ratios are much higher.

The p–V diagram is a simplified and idealised representation of the events involved in a diesel engine cycle, arranged to illustrate the similarity with a Carnot cycle. Starting at 1, the piston is at bottom dead centre and both valves are closed at the start of the compression stroke; the cylinder contains air at atmospheric pressure. Between 1 and 2 the air is compressed adiabatically – that is without heat transfer to or from the environment – by the rising piston. (This is only approximately true since there will be some heat exchange with the cylinder walls.) During this compression, the volume is reduced, the pressure and temperature both rise. At or slightly before 2 (TDC) fuel is injected and burns in the compressed hot air. Chemical energy is released and this constitutes an injection of thermal energy (heat) into the compressed gas. Combustion and heating occur between 2 and 3. In this interval the pressure remains constant since the piston descends, and the volume increases; the temperature rises as a consequence of the energy of combustion. At 3 fuel injection and combustion are complete, and the cylinder contains gas at a higher temperature than at 2. Between 3 and 4 this hot gas expands, again approximately adiabatically. Work is done on the system to which the engine is connected. During this expansion phase the volume of the gas rises, and its temperature and pressure both fall. At 4 the exhaust valve opens, and the pressure falls abruptly to atmospheric (approximately). This is unresisted expansion and no useful work is done by it. Ideally the adiabatic expansion should continue, extending the line 3–4 to the right until the pressure falls to that of the surrounding air, but the loss of efficiency caused by this unresisted expansion is justified by the practical difficulties involved in recovering it (the engine would have to be much larger). After the opening of the exhaust valve, the exhaust stroke follows, but this (and the following induction stroke) are not shown on the diagram. If shown, they would be represented by a low-pressure loop at the bottom of the diagram. At 1 it is assumed that the exhaust and induction strokes have been completed, and the cylinder is again filled with air. The piston-cylinder system absorbs energy between 1 and 2 – this is the work needed to compress the air in the cylinder, and is provided by mechanical kinetic energy stored in the flywheel of the engine. Work output is done by the piston-cylinder combination between 2 and 4. The difference between these two increments of work is the indicated work output per cycle, and is represented by the area enclosed by the p–V loop. The adiabatic expansion is in a higher pressure range than that of the compression because the gas in the cylinder is hotter during expansion than during compression. It is for this reason that the loop has a finite area, and the net output of work during a cycle is positive.

Due to its high compression ratio, the diesel engine has a high efficiency, and the lack of a throttle valve means that the charge-exchange losses are fairly low, resulting in a low specific fuel consumption, especially in medium and low load situations. This makes the diesel engine very economical. Even though diesel engines have a theoretical efficiency of 75%, in practice it is much lower. In his 1893 essay "Theory and Construction of a Rational Heat Motor", Rudolf Diesel describes that the effective efficiency of the diesel engine would be in between 43.2% and 50.4% , or maybe even greater. Modern passenger car diesel engines may have an effective efficiency of up to 43%, whilst engines in large diesel trucks, and buses can achieve peak efficiencies around 45%. However, average efficiency over a driving cycle is lower than peak efficiency. For example, it might be 37% for an engine with a peak efficiency of 44%. The highest diesel engine efficiency of up to 55% is achieved by large two-stroke watercraft diesel engines.

Diesel engines have several advantages over engines operating on other principles:

Diesel engines rely on the air/fuel mixing being done in the cylinder, which means they need a fuel injection system. The fuel is injected directly into the combustion chamber, which can be either a segmented combustion chamber, known as "indirect injection" (IDI), or an unsegmented combustion chamber, known as "direct injection" (DI). The definition of the diesel engine is specific in requiring that the fuel be introduced directly into the combustion, or pre-combustion chamber, rather than initially into an external manifold. For creating the fuel pressure, diesel engines usually have an injection pump. There are several different types of injection pumps and methods for creating a fine air-fuel mixture. Over the years many different injection methods have been used. These can be described as the following:

A necessary component of all diesel engines is a mechanical or electronic governor which regulates the torque of the engine and thus idling speed and maximum speed by controlling the rate of fuel delivery. This means a change of formula_2. Unlike Otto-cycle engines, incoming air is not throttled. Mechanically-governed fuel injection systems are driven by the engine's accessory gear train or serpentine belt. These systems use a combination of springs and weights to control fuel delivery relative to both load and speed. Modern electronically controlled diesel engines control fuel delivery by use of an electronic control module (ECM) or electronic control unit (ECU). The ECM/ECU receives an engine speed signal, as well as other operating parameters such as intake manifold pressure and fuel temperature, from a sensor and controls the amount of fuel and start of injection timing through actuators to maximise power and efficiency and minimise emissions. Controlling the timing of the start of injection of fuel into the cylinder is a key to minimizing emissions, and maximizing fuel economy (efficiency), of the engine. The timing is measured in degrees of crank angle of the piston before top dead centre. For example, if the ECM/ECU initiates fuel injection when the piston is 10° before TDC, the start of injection, or timing, is said to be 10° before TDC. Optimal timing will depend on the engine design as well as its speed and load.

Diesel's original engine injected fuel with the assistance of compressed air, which atomised the fuel and forced it into the engine through a nozzle (a similar principle to an aerosol spray). The nozzle opening was closed by a pin valve lifted by the camshaft to initiate the fuel injection before top dead centre (TDC). This is called an air-blast injection. Driving the compressor used some power but the efficiency was better than the efficiency of any other combustion engine at that time. Also, air-blast injection made engines very heavy and did not allow for quick load changes making it unsuitable for road vehicles.

An indirect diesel injection system (IDI) engine delivers fuel into a small chamber called a swirl chamber, precombustion chamber, pre chamber or ante-chamber, which is connected to the cylinder by a narrow air passage. Generally the goal of the pre chamber is to create increased turbulence for better air / fuel mixing. This system also allows for a smoother, quieter running engine, and because fuel mixing is assisted by turbulence, injector pressures can be lower. Most IDI systems use a single orifice injector. The pre-chamber has the disadvantage of lowering efficiency due to increased heat loss to the engine's cooling system, restricting the combustion burn, thus reducing the efficiency by 5–10%. IDI engines are also more difficult to start and usually require the use of glow plugs. IDI engines may be cheaper to build but generally require a higher compression ratio than the DI counterpart. IDI also makes it easier to produce smooth, quieter running engines with a simple mechanical injection system since exact injection timing is not as critical. Most modern automotive engines are DI which have the benefits of greater efficiency and easier starting; however, IDI engines can still be found in the many ATV and small diesel applications. Indirect injected diesel engines use pintle-type fuel injectiors.

Direct injection Diesel engines inject fuel directly into the cylinder. Usually there is a combustion cup in the top of the piston where the fuel is sprayed. Many different methods of injection can be used. Usually, an engine with helix-controlled mechanic direct injection has either an inline or a distributor injection pump. For each engine cylinder, the corresponding plunger in the fuel pump measures out the correct amount of fuel and determines the timing of each injection. These engines use injectors that are very precise spring-loaded valves that open and close at a specific fuel pressure. Separate high-pressure fuel lines connect the fuel pump with each cylinder. Fuel volume for each single combustion is controlled by a slanted groove in the plunger which rotates only a few degrees releasing the pressure and is controlled by a mechanical governor, consisting of weights rotating at engine speed constrained by springs and a lever. The injectors are held open by the fuel pressure. On high-speed engines the plunger pumps are together in one unit. The length of fuel lines from the pump to each injector is normally the same for each cylinder in order to obtain the same pressure delay. Direct injected diesel engines usually use orifice-type fuel injectors.

Electronic control of the fuel injection transformed the direct injection engine by allowing much greater control over the combustion.

Unit direct injection, also known as Pumpe-Düse ("pump-nozzle"), is a high pressure fuel injection system that injects fuel directly into the cylinder of the engine. In this system the injector and the pump are combined into one unit positioned over each cylinder controlled by the camshaft. Each cylinder has its own unit eliminating the high-pressure fuel lines, achieving a more consistent injection. Under full load, the injection pressure can reach up to 220 MPa. Unit injection systems used to dominate the commercial diesel engine market, but due to higher requirements of the flexibility of the injection system, they have been rendered obsolete by the more advanced common-rail-system.

Common rail (CR) direct injection systems do not have the fuel metering, pressure-raising and delivery functions in a single unit, as in the case of a Bosch distributor-type pump, for example. A high-pressure pump supplies the CR. The requirements of each cylinder injector are supplied from this common high pressure reservoir of fuel. An Electronic Diesel Control (EDC) controls both rail pressure and injections depending on engine operating conditions. The injectors of older CR systems have solenoid-driven plungers for lifting the injection needle, whilst newer CR injectors use plungers driven by piezoelectric actuators, that have fewer moving mass and therefore allow even more injections in a very short period of time. The injection pressure of modern CR systems ranges from 140 MPa to 270 MPa.

There are several different ways of categorising diesel engines, based on different design characteristics:

"Source"


"Source":

"Source"


Regular cylinder configurations such as straight (inline), V, and boxer (flat) configurations can be used for diesel engines. The inline-six-cylinder design is the most prolific in light- to medium-duty engines, though inline-four engines are also common. Small-capacity engines (generally considered to be those below five litres in capacity) are generally four- or six-cylinder types, with the four-cylinder being the most common type found in automotive uses. The V configuration used to be common for commercial vehicles, but it has been abandoned in favour of the inline configuration.

Günter Mau categorises diesel engines by their rotational speeds into three groups:

"Source"

High-speed engines are used to power trucks (lorries), buses, tractors, cars, yachts, compressors, pumps and small electrical generators. As of 2018, most high-speed engines have direct injection. Many modern engines, particularly in on-highway applications, have common rail direct injection. On bigger ships, high-speed diesel engines are often used for powering electric generators. The highest power output of high-speed diesel engines is approximately 5 MW.

Medium-speed engines are used in large electrical generators, ship propulsion and mechanical drive applications such as large compressors or pumps. Medium speed diesel engines operate on either diesel fuel or heavy fuel oil by direct injection in the same manner as low-speed engines. Usually, they are four-stroke engines with trunk pistons.

The power output of medium-speed diesel engines can be as high as 21,870 kW, with the effective efficiency being around 47...48% (1982). Most larger medium-speed engines are started with compressed air direct on pistons, using an air distributor, as opposed to a pneumatic starting motor acting on the flywheel, which tends to be used for smaller engines.

Medium-speed engines intended for marine applications are usually used to power (ro-ro) ferries, passenger ships or small freight ships. Using medium-speed engines reduces the cost of smaller ships and increases their transport capacity. In addition to that, a single ship can use two smaller engines instead of one big engine, which increases the ship's safety.

Low-speed diesel engines are usually very large in size and mostly used to power ships. There are two different types of low-speed engines that are commonly used: Two-stroke engines with a crosshead, and four-stroke engines with a regular trunk-piston. Two-stroke engines have a limited rotational frequency and their charge exchange is more difficult, which means that they are usually bigger than four-stroke engines and used to directly power a ship's propeller. Four-stroke engines on ships are usually used to power an electric generator. An electric motor powers the propeller. Both types are usually very undersquare. Low-speed diesel engines (as used in ships and other applications where overall engine weight is relatively unimportant) often have an effective efficiency of up to 55%. Like medium-speed engines, low-speed engines are started with compressed air, and they use heavy oil as their primary fuel.

Two-stroke diesel engines use only two strokes instead of four strokes for a complete engine cycle. Filling the cylinder with air and compressing it takes place in one stroke, and the power and exhaust strokes are combined. The compression in a two-stroke diesel engine is similar to the compression that takes place in a four-stroke diesel engine: As the piston passes through bottom centre and starts upward, compression commences, culminating in fuel injection and ignition. Instead of a full set of valves, two-stroke diesel engines have simple intake ports, and exhaust ports (or exhaust valves). When the piston approaches bottom dead centre, both the intake and the exhaust ports are "open", which means that there is atmospheric pressure inside the cylinder. Therefore, some sort of pump is required to blow the air into the cylinder and the combustion gasses into the exhaust. This process is called "scavenging". The pressure required is approximately 10 - 30 kPa.


In general, there are three types of scavenging possible:

Crossflow scavenging is incomplete and limits the stroke, yet some manufacturers used it. Reverse flow scavenging is a very simple way of scavenging, and it was popular amongst manufacturers until the early 1980s. Uniflow scavenging is more complicated to make but allows the highest fuel efficiency; since the early 1980s, manufacturers such as MAN and Sulzer have switched to this system. It is standard for modern marine two-stroke diesel engines.

So-called dual-fuel diesel engines or gas diesel engines burn two different types of fuel "simultaneously", for instance, a gaseous fuel and diesel engine fuel. The diesel engine fuel auto-ignites due to compression ignition, and then ignites the gaseous fuel. Such engines do not require any type of spark ignition and operate similar to regular diesel engines.

Torque is a force applied to a lever at a right angle multiplied by the lever length. This means that the torque an engine produces depends on the displacement of the engine and the force that the gas pressure inside the cylinder applies to the piston, commonly referred to as "effective piston pressure":


Power is the quotient of work and time:


This means, that increasing either torque or time will result in an increase in power. As the maximum rotational frequency of the diesel engine's crankshaft is usually in between 3500...5000 min due to diesel principle limitations, the torque of the diesel engine must be great to achieve a high power, or, in other words, as the diesel engine cannot use a lot of time for achieving a certain amount of power, it has to perform more work (=produce more torque).

The average diesel engine has a poorer power-to-mass ratio than the Otto engine. This is because the diesel must operate at lower engine speeds. Due to the higher operating pressure inside the combustion chamber, which increases the forces on the parts due to inertial forces, the diesel engine needs heavier, stronger parts capable of resisting these forces, which results in an overall greater engine mass.

As diesel engines burn a mixture of fuel and air, the exhaust therefore contains substances that consist of the same chemical elements, as fuel and air. The main elements of air are nitrogen (N) and oxygen (O), fuel consists of hydrogen (H) and carbon (C). Burning the fuel will result in the final stage of oxidation. An "ideal diesel engine", (a hypothetical model that we use as an example), running on an ideal air-fuel mixture, produces an exhaust that consists of carbon dioxide (CO), water (HO), nitrogen (N), and the remaining oxygen (O). The combustion process in a real engine differs from an ideal engine's combustion process, and due to incomplete combustion, the exhaust contains additional substances, most notably, carbon monoxide (CO), diesel particulate matter (PM), and due to dissociation, nitrogen oxide ().

When diesel engines burn their fuel with high oxygen levels, this results in high combustion temperatures and higher efficiency, and particulate matter tends to burn, but the amount of pollution tends to increase. pollution can be reduced by recirculating a portion of an engine's exhaust gas back to the engine cylinders, which reduces the oxygen quantity, causing a reduction of combustion temperature, and resulting in fewer . To further reduce emissions, lean traps (LNTs) and SCR-catalysts can be used. Lean traps adsorb the nitrogen oxide and "trap" it. Once the LNT is full, it has to be "regenerated" using hydrocarbons. This is achieved by using a very rich air-fuel mixture, resulting in incomplete combustion. An SCR-catalyst converts nitrogen oxide using urea, which is injected into the exhaust stream, and catalytically converts the into nitrogen (N) and water (HO). Compared with an Otto engine, the diesel engine produces approximately the same amount of , but some older diesel engines may have an exhaust that contains up to 50% less . However, Otto engines, unlike diesel engines, can use a three-way-catalyst, that converts most of the .

The distinctive noise of a diesel engine is variably called diesel clatter, diesel nailing, or diesel knock. Diesel clatter is caused largely by the way the fuel ignites; the sudden ignition of the diesel fuel when injected into the combustion chamber causes a pressure wave, resulting in an audible ″knock″. Engine designers can reduce diesel clatter through: indirect injection; pilot or pre-injection; injection timing; injection rate; compression ratio; turbo boost; and exhaust gas recirculation (EGR). Common rail diesel injection systems permit multiple injection events as an aid to noise reduction. Therefore, newer diesel engines do not knock anymore. Diesel fuels with a higher cetane rating are more likely to ignite and hence reduce diesel clatter.

In general, diesel engines do not require any starting aid. In cold weather however, some diesel engines can be difficult to start and may need preheating depending on the combustion chamber design. The minimum starting temperature that allows starting without pre-heating is 40 °C for precombustion chamber engines, 20 °C for swirl chamber engines, and 0 °C for direct injected engines. Smaller engines with a displacement of less than 1 litre per cylinder usually have glowplugs, whilst larger heavy-duty engines have flame-start systems.

In the past, a wider variety of cold-start methods were used. Some engines, such as Detroit Diesel engines used a system to introduce small amounts of ether into the inlet manifold to start combustion. Instead of glowplugs, some diesel engines are equipped with starting aid systems that change valve timing. The simplest way this can be done is with a decompression lever. Activating the decompression lever locks the outlet valves in a slight down position, resulting in the engine not having any compression and thus allowing for turning the crankshaft over without resistance. When the crankshaft reaches a higher speed, flipping the decompression lever back into its normal position will abruptly re-activate the outlet valves, resulting in compression − the flywheel's mass moment of inertia then starts the engine. Other diesel engines, such as the precombustion chamber engine XII Jv 170/240 made by Ganz & Co., have a valve timing changing system that is operated by adjusting the inlet valve camshaft, moving it into a slight "late" position. This will make the inlet valves open with a delay, forcing the inlet air to heat up when entering the combustion chamber.

As the diesel engine relies on manipulation of formula_2 for torque controlling and speed regulation, the intake air mass does not have to precisely match the injected fuel mass (which would be formula_20). diesel engines are thus ideally suited for supercharging and turbocharging. An additional advantage of the diesel engine is the lack of fuel during the compression stroke. In diesel engines, the fuel is injected near top dead centre (TDC), when the piston is near its highest position. The fuel then ignites due to compression heat. Preignition, caused by the artificial turbocharger compression increase during the compression stroke, cannot occur.

Many diesels are therefore turbocharged and some are both turbocharged and supercharged. A turbocharged engine can produce more power than a naturally aspirated engine of the same configuration. A supercharger is powered mechanically by the engine's crankshaft, while a turbocharger is powered by the engine exhaust. Turbocharging can improve the fuel economy of diesel engines by recovering waste heat from the exhaust, increasing the excess air factor, and increasing the ratio of engine output to friction losses. Adding an intercooler to a turbocharged engine further increases engine performance by cooling down the air-mass and thus allowing more air-mass per volume.

A two-stroke engine does not have a discrete exhaust and intake stroke and thus is incapable of self-aspiration. Therefore, all two-stroke diesel engines must be fitted with a blower or some form of compressor to charge the cylinders with air and assist in dispersing exhaust gases, a process referred to as scavenging. Roots-type superchargers were used for ship engines until the mid-1950s, since 1955 they have been widely replaced by turbochargers. Usually, a two-stroke ship diesel engine has a single-stage turbocharger with a turbine that has an axial inflow and a radial outflow.

In diesel engines, a mechanical injector system atomizes the fuel directly into the combustion chamber (as opposed to a Venturi jet in a carburetor, or a fuel injector in a manifold injection system atomizing fuel into the intake manifold or intake runners as in a petrol engine). Because only air is inducted into the cylinder in a diesel engine, the compression ratio can be much higher as there is no risk of pre-ignition provided the injection process is accurately timed. This means that cylinder temperatures are much higher in a diesel engine than a petrol engine, allowing less volatile fuels to be used.

Therefore, diesel engines can operate on a huge variety of different fuels. In general, fuel for diesel engines should have a proper viscosity, so that the injection pump can pump the fuel to the injection nozzles without causing damage to itself or corrosion of the fuel line. At injection, the fuel should form a good fuel spray, and it should not have a coking effect upon the injection nozzles. To ensure proper engine starting and smooth operation, the fuel should be willing to ignite and hence not cause a high ignition delay, (this means that the fuel should have a high cetane number). Diesel fuel should also have a high lower heating value.

Inline mechanical injector pumps generally tolerate poor-quality or bio-fuels better than distributor-type pumps. Also, indirect injection engines generally run more satisfactorily on fuels with a high ignition delay (for instance, petrol) than direct injection engines. This is partly because an indirect injection engine has a much greater 'swirl' effect, improving vaporisation and combustion of fuel, and because (in the case of vegetable oil-type fuels) lipid depositions can condense on the cylinder walls of a direct-injection engine if combustion temperatures are too low (such as starting the engine from cold). Direct-injected engines with an MAN centre sphere combustion chamber rely on fuel condensing on the combustion chamber walls. The fuel starts vaporising only after ignition sets in, and it burns relatively smoothly. Therefore, such engines also tolerate fuels with poor ignition delay characteristics, and, in general, they can operate on petrol rated 86 RON.

In his 1893 work "Theory and Construction of a Rational Heat Motor", Rudolf Diesel considers using coal dust as fuel for the diesel engine. However, Diesel just "considered" using coal dust (as well as liquid fuels and gas); his actual engine was designed to operate on petroleum, which was soon replaced with regular petrol and kerosene for further testing purposes, as petroleum proved to be too viscous. In addition to kerosene and petrol, Diesel's engine could also operate on ligroin.

Before diesel engine fuel was standardised, fuels such as petrol, kerosene, gas oil, vegetable oil and mineral oil, as well as mixtures of these fuels, were used. Typical fuels specifically intended to be used for diesel engines were petroleum distillates and coal-tar distillates such as the following; these fuels have specific lower heating values of:

"Source:"

The first diesel fuel standards were the DIN 51601, VTL 9140-001, and NATO F 54, which appeared after World War II. The modern European EN 590 diesel fuel standard was established in May 1993; the modern version of the NATO F 54 standard is mostly identical with it. The DIN 51628 biodiesel standard was rendered obsolete by the 2009 version of the EN 590; FAME biodiesel conforms to the EN 14214 standard. Watercraft diesel engines usually operate on diesel engine fuel that conforms to the ISO 8217 standard (Bunker C). Also, some diesel engines can operate on gasses (such as LNG).

DIN 51601 diesel fuel was prone to "waxing" or "gelling" in cold weather; both are terms for the solidification of diesel oil into a partially crystalline state. The crystals build up in the fuel system (especially in fuel filters), eventually starving the engine of fuel and causing it to stop running. Low-output electric heaters in fuel tanks and around fuel lines were used to solve this problem. Also, most engines have a "spill return" system, by which any excess fuel from the injector pump and injectors is returned to the fuel tank. Once the engine has warmed, returning warm fuel prevents waxing in the tank. Before direct injection diesel engines, some manufacturers, such as BMW, recommended mixing up to 30% petrol in with the diesel by fuelling diesel cars with petrol to prevent the fuel from gelling when the temperatures dropped below −15 °C.

Diesel fuel is less flammable than petrol, because its flash point is 55 °C, leading to a lower risk of fire caused by fuel in a vehicle equipped with a diesel engine.

Diesel fuel can create an explosive air/vapour mix under the right conditions. However, compared with petrol, it is less prone due to its lower vapour pressure, which is an indication of evaporation rate. The Material Safety Data Sheet for ultra-low sulfur diesel fuel indicates a vapour explosion hazard for diesel fuel indoors, outdoors, or in sewers.

Diesel exhaust has been classified as an IARC Group 1 carcinogen. It causes lung cancer and is associated with an increased risk for bladder cancer.

See diesel engine runaway.

The characteristics of diesel have different advantages for different applications.

Diesel engines have long been popular in bigger cars and have been used in smaller cars such as superminis in Europe since the 1980s. They were popular in larger cars earlier, as the weight and cost penalties were less noticeable. Smooth operation as well as high low end torque are deemed important for passenger cars and small commercial vehicles. The introduction of electronically controlled fuel injection significantly improved the smooth torque generation, and starting in the early 1990s, car manufacturers began offering their high-end luxury vehicles with diesel engines. Passenger car diesel engines usually have between three and ten cylinders, and a displacement ranging from 0.8 to 5.0 litres. Modern powerplants are usually turbocharged and have direct injection.

Diesel engines do not suffer from intake-air throttling, resulting in very low fuel consumption especially at low partial load (for instance: driving at city speeds). One fifth of all passenger cars worldwide have diesel engines, with many of them being in Europe, where approximately 47% of all passenger cars are diesel-powered. Daimler-Benz in conjunction with Robert Bosch GmbH produced diesel-powered passenger cars starting in 1936. The popularity of diesel-powered passenger cars in markets such as India, South Korea and Japan is increasing (as of 2018).

In 1893, Rudolf Diesel suggested that the diesel engine could possibly power ‘wagons’ (lorries). The first lorries with diesel engines were brought to market in 1924.

Modern diesel engines for lorries have to be both extremely reliable and very fuel efficient. Common-rail direct injection, turbocharging and four valves per cylinder are standard. Displacements range from 4.5 to 15.5 litres, with power-to-mass ratios of 2.5–3.5 kg·kW for heavy duty and 2.0–3.0 kg·kW for medium duty engines. V6 and V8 engines used to be common, due to the relatively low engine mass the V configuration provides. Recently, the V configuration has been abandoned in favour of straight engines. These engines are usually straight-6 for heavy and medium duties and straight-4 for medium duty. Their undersquare design causes lower overall piston speeds which results in increased lifespan of up to . Compared with 1970s diesel engines, the expected lifespan of modern lorry diesel engines has more than doubled.

Diesel engines for locomotives are built for continuous operation between refuellings and may need to be designed to use poor quality fuel in some circumstances. Some locomotives use two-stroke diesel engines. Diesel engines have replaced steam engines on all non-electrified railroads in the world. The first diesel locomotives appeared in 1913, and diesel multiple units soon after. Most modern diesel locomotives are more correctly known as diesel-electric locomotives because they use an electric transmission: the diesel engine drives an electric generator which powers electric traction motors. While electric locomotives have replaced the diesel locomotive for passenger services in many areas diesel traction is widely used for cargo-hauling freight trains and on tracks where electrification is not economically viable.

In the 1940s, road vehicle diesel engines with power outputs of 150...200 PS (110...147 kW) were considered reasonable for DMUs. Commonly, regular truck powerplants were used. The height of these engines had to be less than 1,000 mm to allow underfloor installation. Usually, the engine was mated with a pneumatically operated mechanical gearbox, due to the low size, mass, and production costs of this design. Some DMUs used hydraulic torque converters instead. Diesel-electric transmission was not suitable for such small engines. In the 1930s, the Deutsche Reichsbahn standardised its first DMU engine. It was a 30.3 litre, 12-cylinder boxer unit, producing 275 PS (202 kW). Several German manufacturers produced engines according to this standard.

The requirements for marine diesel engines vary, depending on the application. For military use and medium-size boats, medium-speed four-stroke diesel engines are most suitable. These engines usually have up to 24 cylinders and come with power outputs in the one-digit Megawatt region. Small boats may use lorry diesel engines. Large ships use extremely efficient, low-speed two-stroke diesel engines. They can reach efficiencies of up to 55%. Unlike most regular diesel engines, two-stroke watercraft engines use highly viscous fuel oil. Submarines are usually diesel-electric.

The first diesel engines for ships were made by A. B. Diesels Motorer Stockholm in 1903. These engines were three-cylinder units of 120 PS (88 kW) and four-cylinder units of 180 PS (132 kW) and used for Russian ships. In World War I, especially submarine diesel engine development advanced quickly. By the end of the War, double acting piston two-stroke engines with up to 12,200 PS (9 MW) had been made for marine use.

Diesel engines had been used in aircraft before World War II, for instance, in the rigid airship "LZ 129 Hindenburg", which was powered by four Daimler-Benz DB 602 diesel engines, or in several Junkers aircraft, which had Jumo 205 engines installed. Until the late 1970s, there has not been any applications of the diesel engine in aircraft. In 1978, Karl H. Bergey argued that “the likelihood of a general aviation diesel in the near future is remote.” In recent years (2016), diesel engines have found use in unmanned aircraft (UAV), due to their reliability, durability, and low fuel consumption. In early 2019, AOPA reported, that a diesel engine model for general aviation aircraft is “approaching the finish line.”

Non-road diesel engines are commonly used for construction equipment. Fuel efficiency, reliability and ease of maintenance are very important for such engines, whilst high power output and quiet operation are negligible. Therefore, mechanically controlled fuel injection and air-cooling are still very common. The common power outputs of non-road diesel engines vary a lot, with the smallest units starting at 3 kW, and the most powerful engines being heavy duty lorry engines.

Stationary diesel engines are commonly used for electricity generation, but also for powering refrigerator compressors, or other types of compressors or pumps. Usually, these engines run permanently, either with mostly partial load, or intermittently, with full load. Stationary diesel engines powering electric generators that put out an alternating current, usually operate with alternating load, but fixed rotational frequency. This is due to the mains' fixed frequency of either 50 Hz (Europe), or 60 Hz (United States). The engine's crankshaft rotational frequency is chosen so that the mains' frequency is a multiple of it. For practical reasons, this results in crankshaft rotational frequencies of either 25 Hz (1500 per minute) or 30 Hz (1800 per minute).

A special class of prototype internal combustion piston engines has been developed over several decades with the goal of improving efficiency by reducing heat loss. These engines are variously called adiabatic engines; due to better approximation of adiabatic expansion; low heat rejection engines, or high temperature engines. They are generally piston engines with combustion chamber parts lined with ceramic thermal barrier coatings. Some make use of pistons and other parts made of titanium which has a low thermal conductivity and density. Some designs are able to eliminate the use of a cooling system and associated parasitic losses altogether. Developing lubricants able to withstand the higher temperatures involved has been a major barrier to commercialization.

In mid-2010s literature, main development goals for future diesel engines are described as improvements of exhaust emissions, reduction of fuel consumption, and increase of lifespan (2014). It is said that the diesel engine, especially the diesel engine for commercial vehicles, will remain the most important vehicle powerplant until the mid-2030s. Editors assume that the complexity of the diesel engine will increase further (2014). Some editors expect a future convergency of diesel and Otto engines' operating principles due to Otto engine development steps made towards homogeneous charge compression ignition (2017).




</doc>
<doc id="8541" url="https://en.wikipedia.org/wiki?curid=8541" title="Dark Star">
Dark Star

Dark Star or Darkstar may refer to:












</doc>
<doc id="8544" url="https://en.wikipedia.org/wiki?curid=8544" title="Drawing">
Drawing

Drawing is a form of visual art in which a person uses various drawing instruments to mark paper or another two-dimensional medium. Instruments include graphite pencils, pen and ink, various kinds of paints, inked brushes, colored pencils, crayons, charcoal, chalk, pastels, various kinds of erasers, markers, styluses, and various metals (such as silverpoint). Digital drawing is the act of using a computer to draw. Common methods of digital drawing include a stylus or finger on a touchscreen device, stylus- or finger-to-touchpad, or in some cases, a mouse. There are many digital art programs and devices.

A drawing instrument releases a small amount of material onto a surface, leaving a visible mark. The most common support for drawing is paper, although other materials, such as cardboard, wood, plastic, leather, canvas, and board, may be used. Temporary drawings may be made on a blackboard or whiteboard or indeed almost anything. The medium has been a popular and fundamental means of public expression throughout human history. It is one of the simplest and most efficient means of communicating visual ideas. The wide availability of drawing instruments makes drawing one of the most common artistic activities.

In addition to its more artistic forms, drawing is frequently used in commercial illustration, animation, architecture, engineering and technical drawing. A quick, freehand drawing, usually not intended as a finished work, is sometimes called a sketch. An artist who practices or works in technical drawing may be called a drafter, draftsman or a draughtsman.

Drawing is one of the oldest forms of human expression within the visual arts. It is generally concerned with the marking of lines and areas of tone onto paper/other material, where the accurate representation of the visual world is expressed upon a plane surface. Traditional drawings were monochrome, or at least had little colour, while modern colored-pencil drawings may approach or cross a boundary between drawing and painting. In Western terminology, drawing is distinct from painting, even though similar media often are employed in both tasks. Dry media, normally associated with drawing, such as chalk, may be used in pastel paintings. Drawing may be done with a liquid medium, applied with brushes or pens. Similar supports likewise can serve both: painting generally involves the application of liquid paint onto prepared canvas or panels, but sometimes an underdrawing is drawn first on that same support.
Drawing is often exploratory, with considerable emphasis on observation, problem-solving and composition. Drawing is also regularly used in preparation for a painting, further obfuscating their distinction. Drawings created for these purposes are called studies.There are several categories of drawing, including figure drawing, cartooning, doodling, and freehand. There are also many drawing methods, such as line drawing, stippling, shading, the surrealist method of entopic graphomania (in which dots are made at the sites of impurities in a blank sheet of paper, and lines are then made between the dots), and tracing (drawing on a translucent paper, such as "tracing paper", around the outline of preexisting shapes that show through the paper). 

A quick, unrefined drawing may be called a "sketch".

In fields outside art, technical drawings or plans of buildings, machinery, circuitry and other things are often called "drawings" even when they have been transferred to another medium by printing.

Drawing is one of the oldest forms of human expression, with evidence for its existence preceding that of written communication. It is believed that drawing was used as a specialised form of communication before the invention of the written language, demonstrated by the production of cave and rock paintings around 30,000 years ago (Art of the Upper Paleolithic).
These drawings, known as pictograms, depicted objects and abstract concepts. The sketches and paintings produced by Neolithic times were eventually stylised and simplified in to symbol systems (proto-writing) and eventually into early writing systems.

Before the widespread availability of paper, 12th-century monks in European monasteries used intricate drawings to prepare illustrated, illuminated manuscripts on vellum and parchment. Drawing has also been used extensively in the field of science, as a method of discovery, understanding and explanation.

Drawing diagrams of observations is an important part of scientific study.

In 1609, astronomer Galileo Galilei explained the changing phases of Venus and also the sunspots through his observational telescopic drawings. In 1924, geophysicist Alfred Wegener used illustrations to visually demonstrate the origin of the continents.

Drawing is used to express one's creativity, and therefore has been prominent in the world of art. Throughout much of history, drawing was regarded as the foundation for artistic practice. Initially, artists used and reused wooden tablets for the production of their drawings. Following the widespread availability of paper in the 14th century, the use of drawing in the arts increased. At this point, drawing was commonly used as a tool for thought and investigation, acting as a study medium whilst artists were preparing for their final pieces of work. The Renaissance brought about a great sophistication in drawing techniques, enabling artists to represent things more realistically than before, and revealing an interest in geometry and philosophy.

The invention of the first widely available form of photography led to a shift in the hierarchy of the arts. Photography offered an alternative to drawing as a method for accurately representing visual phenomena, and traditional drawing practice was given less emphasis as an essential skill for artists, particularly so in Western society.

Drawing became significant as an art form around the late 15th century, with artists and master engravers such as Albrecht Dürer and Martin Schongauer (c. 1448-1491), the very first Northern engraver known by name. Schongauer came from Alsace, and was born into a family of goldsmiths. Albrecht Dürer, a master of the next generation, was also the son of a goldsmith.

Old Master Drawings often reflect the history of the country in which they were produced, and the fundamental characteristics of a nation at that time. In 17th-century Holland, a Protestant country, there were almost no religious artworks, and, with no King or court, most art was bought privately. Drawings of landscapes or genre scenes were often viewed not as sketches but as highly finished works of art. Italian drawings, however, show the influence of Catholicism and the Church, which played a major role in artistic patronage. The same is often true of French drawings, although in the 17th century the disciplines of French Classicism meant drawings were less Baroque than the more free Italian counterparts, which conveyed a greater sense of movement.

In the 20th century Modernism encouraged "imaginative originality" and some artists' approach to drawing became less literal, more abstract. World-renowned artists such as Pablo Picasso, Andy Warhol and Jean-Michel Basquiat helped challenge the status quo, with drawing being very much at the centre of their practice, and often re-interpreting traditional technique.

Basquiat's drawings were produced in many different mediums, most commonly ink, pencil, felt-tip or marker, and oil-stick, and he drew on any surface that came to hand, such as doors, clothing, refrigerators, walls and baseball helmets.

Modern-day artists such as Tracey Emin observe the legacy and importance of drawing, engraving and print making techniques in their vast array, passed down through millennia.

The centuries have produced a canon of notable artists and draftsmen, each with their own distinct language of drawing, including:

The "medium" is the means by which ink, pigment or color are delivered onto the drawing surface. Most drawing media are either dry (e.g. graphite, charcoal, pastels, Conté, silverpoint), or use a fluid solvent or carrier (marker, pen and ink). Watercolor pencils can be used dry like ordinary pencils, then moistened with a wet brush to get various painterly effects. Very rarely, artists have drawn with (usually decoded) invisible ink. Metalpoint drawing usually employs either of two metals: silver or lead. More rarely used are gold, platinum, copper, brass, bronze, and tinpoint.

Paper comes in a variety of different sizes and qualities, ranging from newspaper grade up to high quality and relatively expensive paper sold as individual sheets. Papers vary in texture, hue, acidity, and strength when wet. Smooth paper is good for rendering fine detail, but a more "toothy" paper holds the drawing material better. Thus a coarser material is useful for producing deeper contrast.

Newsprint and typing paper may be useful for practice and rough sketches. Tracing paper is used to experiment over a half-finished drawing, and to transfer a design from one sheet to another. Cartridge paper is the basic type of drawing paper sold in pads. Bristol board and even heavier acid-free boards, frequently with smooth finishes, are used for drawing fine detail and do not distort when wet media (ink, washes) are applied. Vellum is extremely smooth and suitable for very fine detail. Coldpressed watercolor paper may be favored for ink drawing due to its texture.

Acid-free, archival quality paper keeps its color and texture far longer than wood pulp based paper such as newsprint, which turns yellow and becomes brittle much sooner.

The basic tools are a drawing board or table, pencil sharpener and eraser, and for ink drawing, blotting paper. Other tools used are circle compass, ruler, and set square. Fixative is used to prevent pencil and crayon marks from smudging. Drafting tape is used to secure paper to drawing surface, and also to mask an area to keep it free of accidental marks, such as sprayed or spattered materials and washes. An easel or slanted table is used to keep the drawing surface in a suitable position, which is generally more horizontal than the position used in painting.

Almost all draftsmen use their hands and fingers to apply the media, with the exception of some handicapped individuals who draw with their mouth or feet.

Prior to working on an image, the artist typically explores how various media work. They may try different drawing implements on practice sheets to determine value and texture, and how to apply the implement to produce various effects.

The artist's choice of drawing strokes affects the appearance of the image. Pen and ink drawings often use hatching – groups of parallel lines. Cross-hatching uses hatching in two or more different directions to create a darker tone. Broken hatching, or lines with intermittent breaks, form lighter tones – and controlling the density of the breaks achieves a gradation of tone. Stippling uses dots to produce tone, texture and shade. Different textures can be achieved depending on the method used to build tone.

Drawings in dry media often use similar techniques, though pencils and drawing sticks can achieve continuous variations in tone. Typically a drawing is filled in based on which hand the artist favors. A right-handed artist draws from left to right to avoid smearing the image. Erasers can remove unwanted lines, lighten tones, and clean up stray marks. In a sketch or outline drawing, lines drawn often follow the contour of the subject, creating depth by looking like shadows cast from a light in the artist's position.

Sometimes the artist leaves a section of the image untouched while filling in the remainder. The shape of the area to preserve can be painted with masking fluid or cut out of a frisket and applied to the drawing surface, protecting the surface from stray marks until the mask is removed.

Another method to preserve a section of the image is to apply a spray-on "fixative" to the surface. This holds loose material more firmly to the sheet and prevents it from smearing. However the fixative spray typically uses chemicals that can harm the respiratory system, so it should be employed in a well-ventilated area such as outdoors.

Another technique is subtractive drawing in which the drawing surface is covered with graphite or charcoal and then erased to make the image.

Shading is the technique of varying the tonal values on the paper to represent the shade of the material as well as the placement of the shadows. Careful attention to reflected light, shadows and highlights can result in a very realistic rendition of the image.

Blending uses an implement to soften or spread the original drawing strokes. Blending is most easily done with a medium that does not immediately fix itself, such as graphite, chalk, or charcoal, although freshly applied ink can be smudged, wet or dry, for some effects. For shading and blending, the artist can use a blending stump, tissue, a kneaded eraser, a fingertip, or any combination of them. A piece of chamois is useful for creating smooth textures, and for removing material to lighten the tone. Continuous tone can be achieved with graphite on a smooth surface without blending, but the technique is laborious, involving small circular or oval strokes with a somewhat blunt point.

Shading techniques that also introduce texture to the drawing include hatching and stippling. A number of other methods produce texture. In addition to the choice of paper, drawing material and technique affect texture. Texture can be made to appear more realistic when it is drawn next to a contrasting texture; a coarse texture is more obvious when placed next to a smoothly blended area. A similar effect can be achieved by drawing different tones close together. A light edge next to a dark background stands out to the eye, and almost appears to float above the surface.

Measuring the dimensions of a subject while blocking in the drawing is an important step in producing a realistic rendition of the subject. Tools such as a compass can be used to measure the angles of different sides. These angles can be reproduced on the drawing surface and then rechecked to make sure they are accurate. Another form of measurement is to compare the relative sizes of different parts of the subject with each other. A finger placed at a point along the drawing implement can be used to compare that dimension with other parts of the image. A ruler can be used both as a straightedge and a device to compute proportions.

When attempting to draw a complicated shape such as a human figure, it is helpful at first to represent the form with a set of primitive volumes. Almost any form can be represented by some combination of the cube, sphere, cylinder, and cone. Once these basic volumes have been assembled into a likeness, then the drawing can be refined into a more accurate and polished form. The lines of the primitive volumes are removed and replaced by the final likeness. Drawing the underlying construction is a fundamental skill for representational art, and is taught in many books and schools. Its correct application resolves most uncertainties about smaller details, and makes the final image look consistent.

A more refined art of figure drawing relies upon the artist possessing a deep understanding of anatomy and the human proportions. A trained artist is familiar with the skeleton structure, joint location, muscle placement, tendon movement, and how the different parts work together during movement. This allows the artist to render more natural poses that do not appear artificially stiff. The artist is also familiar with how the proportions vary depending on the age of the subject, particularly when drawing a portrait.

Linear perspective is a method of portraying objects on a flat surface so that the dimensions shrink with distance. Each set of parallel, straight edges of any object, whether a building or a table, follows lines that eventually converge at a vanishing point. Typically this convergence point is somewhere along the horizon, as buildings are built level with the flat surface. When multiple structures are aligned with each other, such as buildings along a street, the horizontal tops and bottoms of the structures typically converge at a vanishing point.

When both the fronts and sides of a building are drawn, then the parallel lines forming a side converge at a second point along the horizon (which may be off the drawing paper.) This is a two-point perspective. Converging the vertical lines to a third point above or below the horizon then produces a three-point perspective.

Depth can also be portrayed by several techniques in addition to the perspective approach above. Objects of similar size should appear ever smaller the further they are from the viewer. Thus the back wheel of a cart appears slightly smaller than the front wheel. Depth can be portrayed through the use of texture. As the texture of an object gets further away it becomes more compressed and busy, taking on an entirely different character than if it was close. Depth can also be portrayed by reducing the contrast in more distant objects, and by making their colors less saturated. This reproduces the effect of atmospheric haze, and cause the eye to focus primarily on objects drawn in the foreground.

The composition of the image is an important element in producing an interesting work of artistic merit. The artist plans element placement in the art to communicate ideas and feelings with the viewer. The composition can determine the focus of the art, and result in a harmonious whole that is aesthetically appealing and stimulating.

The illumination of the subject is also a key element in creating an artistic piece, and the interplay of light and shadow is a valuable method in the artist's toolbox. The placement of the light sources can make a considerable difference in the type of message that is being presented. Multiple light sources can wash out any wrinkles in a person's face, for instance, and give a more youthful appearance. In contrast, a single light source, such as harsh daylight, can serve to highlight any texture or interesting features.

When drawing an object or figure, the skilled artist pays attention to both the area within the silhouette and what lies outside. The exterior is termed the negative space, and can be as important in the representation as the figure. Objects placed in the background of the figure should appear properly placed wherever they can be viewed.

A study is a draft drawing that is made in preparation for a planned final image. Studies can be used to determine the appearances of specific parts of the completed image, or for experimenting with the best approach for accomplishing the end goal. However a well-crafted study can be a piece of art in its own right, and many hours of careful work can go into completing a study.

Individuals display differences in their ability to produce visually accurate drawings. A visually accurate drawing is described as being "recognized as a particular object at a particular time and in a particular space, rendered with little addition of visual detail that can not be seen in the object represented or with little deletion of visual detail”. 

Investigative studies have aimed to explain the reasons why some individuals draw better than others.
One study posited four key abilities in the drawing process: motor skills required for mark-making, the drawer's own perception of their drawing, perception of objects being drawn, and the ability to make good representational decisions. Following this hypothesis, several studies have sought to conclude which of these processes are most significant in affecting the accuracy of drawings.

Motor control is an important physical component in the 'Production Phase' of the drawing process. It has been suggested that motor control plays a role in drawing ability, though its effects are not significant.

It has been suggested that an individual's ability to perceive an object they are drawing is the most important stage in the drawing process. This suggestion is supported by the discovery of a robust relationship between perception and drawing ability.

This evidence acted as the basis of Betty Edwards' how-to-draw book, "Drawing on the Right Side of the Brain". Edwards aimed to teach her readers how to draw, based on the development of the reader's perceptual abilities.

Furthermore, the influential artist and art critic John Ruskin emphasised the importance of perception in the drawing process in his book "The Elements of Drawing". He stated that "For I am nearly convinced, that once we see keenly enough, there is very little difficult in drawing what we see".

This has also been shown to influence one's ability to create visually accurate drawings.
Short-term memory plays an important part in drawing as one's gaze shifts between the object they are drawing and the drawing itself.

Some studies comparing artists to non-artists have found that artists spend more time thinking strategically while drawing. In particular, artists spend more time on 'metacognitive' activities such as considering different hypothetical plans for how they might progress with a drawing.

Notes
Further reading



</doc>
<doc id="8545" url="https://en.wikipedia.org/wiki?curid=8545" title="Dedham, Massachusetts">
Dedham, Massachusetts

Dedham ( ) is a town in and the county seat of Norfolk County, Massachusetts, United States. The population was 24,729 at the 2010 census. It is located on Boston's southwest border. On the northwest it is bordered by Needham, on the southwest by Westwood, and on the southeast by Canton. The town was first settled by European colonists in 1635.

Settled in 1635 by people from Roxbury and Watertown, Dedham was incorporated in 1636. It became the county seat of Norfolk County when the county was formed from parts of Suffolk County on March 26, 1793. When the Town was originally incorporated, the residents wanted to name it "Contentment." The Massachusetts General Court overruled them and named the town after Dedham, Essex in England, where some of the original inhabitants were born. The boundaries of the town at the time stretched to the Rhode Island border.

At the first public meeting on August 15, 1636, eighteen men signed the town covenant. They swore that they would "in the fear and reverence of our Almighty God, mutually and severally promise amongst ourselves and each to profess and practice one truth according to that most perfect rule, the foundation whereof is ever lasting love."

They also agreed that "we shall by all means labor to keep off from us all such as are contrary minded, and receive only such unto us as may be probably of one heart with us, [and such] as that we either know or may well and truly be informed to walk in a peaceable conversation with all meekness of spirit, [this] for the edification of each other in the knowledge and faith of the Lord Jesus…" The covenant also stipulated that if differences were to arise between townsmen, they would seek arbitration for resolution and each would pay his fair share for the common good.

In November 1798, David Brown led a group in Dedham protesting the federal government; they set up a liberty pole, as people had before the American Revolution. It carried the words, "No Stamp Act, No Sedition Act, No Alien Bills, No Land Tax, downfall to the Tyrants of America; peace and retirement to the President; Long Live the Vice President," referring to then-President John Adams and Vice President Thomas Jefferson. Brown was arrested in Andover but because he could not afford the $4,000 bail, he was taken to Salem for trial. Brown was tried in June 1799. Although he wanted to plead guilty, Justice Samuel Chase urged him to name those who had helped him or subscribed to his writings in exchange for freedom. Brown refused, was fined $480, and sentenced to eighteen months in prison. It was the most severe sentence up to then imposed under the Alien and Sedition Acts.

Dedham is home to the Fairbanks House, the oldest surviving timber-frame house in the United States, scientifically dated to 1637. On January 1, 1643, by unanimous vote, Dedham authorized the first taxpayer-funded public school, "the seed of American education." Its first schoolmaster, Rev. Ralph Wheelock, a Clare College graduate, was paid 20 pounds annually to instruct the youth of the community. Descendants of these students would become presidents of Dartmouth College, Yale University and Harvard University.

The first man-made canal in North America, Mother Brook, was created in Dedham in 1639. It linked the Charles River to the Neponset River. Although both are slow-moving rivers, they are at different elevations. The difference in elevation made the canal's current swift enough to power several local mills.

In 1818, though citizens were still taxed for the support of ministers and other "public teachers of religion," Dedham set a precedent toward the separation of church and state. Residents of the town selected a minister different than that chosen by the church members; the selection by residents was confirmed by the Supreme Judicial Court. This decision increased support for the disestablishment of the Congregational churches.

The local Endicott Estate burned to the ground in 1904 after the local volunteer fire department, responding to three separate fires burning simultaneously, reached the Endicott fire last. By the time they arrived, only ashes remained. It is said that the estate's owner, Henry Bradford Endicott (also founder of the Endicott Johnson Corporation) took the burning of the homestead as a divine command to rebuild (which he did). The rebuilt Endicott Estate is listed on the National Register of Historic Places. The estate and surrounding grounds are open to the public, upholding Henry's stepdaughter Katherine's wish to use the house and property for "educational, civic, social and recreational purposes."

In 1921, the historic Sacco and Vanzetti trial was held in the Norfolk County Courthouse in Dedham. Dedham Pottery is a cherished class of antiques, characterized by a distinctive crackle glaze, blue-and-white color scheme, and a frequent motif of rabbits and other animals. Dedham is sometimes called the "mother of towns" because 14 present-day communities were included within its original broad borders.

Dedham is located at (42.244609, −71.165531). On the northeast corner of High Street and Court Street the U.S. Coast & Geodetic Survey, now the U.S. National Geodetic Survey, has placed a small medallion into a granite block showing an elevation of .

Dedham is made up of a number of neighborhoods:

According to the United States Census Bureau, the town has a total area of , of which is land and (1.79%) is water.

As of the census of 2000, there were 23,464 people, 8,654 households, and 6,144 families residing in the town. The population density was 2,244.6 people per square mile (866.9/km). There were 8,908 housing units at an average density of 852.2 per square mile (329.1/km). The racial makeup of the town was 94.51% White, 1.54% Black or African American, 0.16% Native American, 1.87% Asian, 0.04% Pacific Islander, 0.80% from other races, and 1.08% from two or more races. 2.42% of the population were Hispanic or Latino of any race.

There were 8,654 households, of which 30.1% had children under the age of 18 living with them. 56.3% were married couples living together, 11.1% had a female householder with no husband present, and 29.0% were non-families. 23.9% of all households were made up of individuals, and 10.4% had someone living alone who was 65 years of age or older. The average household size was 2.61 and the average family size was 3.14.

Dedham's population was spread out, with 22.2% under the age of 18, 5.8% from 18 to 24, 31.1% from 25 to 44, 24.2% from 45 to 64, and 16.6% who were 65 years of age or older. The median age was 40 years. For every 100 females, there were 93.4 males. For every 100 females age 18 and over, there were 92.0 males.

The median income for a household in the town was $61,699, and the median income for a family was $72,330. Males had a median income of $46,216 versus $35,682 for females. The per capita income for the town was $28,199. About 3.2% of families and 4.6% of the population were below the poverty line, including 3.9% of those under age 18 and 6.5% of those age 65 or over.

The town's seal was originally designed by a member of the Dedham Historical Society. In the center is a crest containing the Old Avery Oak. When the tree was finally felled, the gavel used by the Moderator at Town Meeting was carved out of it. Above the tree are the scales of justice, representing Dedham as the county seat and home to Norfolk County's courts. On the left of the tree are agricultural instruments, and on the right is a factory, showing Dedham's history first as a town of farmers and then as one with a number of mills and factories, particularly along Mother Brook. Below the tree is a banner with the word "Contentment," the name of the original plantation.

The town flag is red with the seal prominent and in the center. In the lower left corner is part of the Avery Oak, and in the lower right is part of the Fairbanks House. It hangs in the selectmen's chambers at town hall and in the Great Hall of the Massachusetts State House.

A charter adopted in 1998 lays out the basic structure of the Town government, although it has been amended occasionally over the years. A seven-member Charter Advisory Committee, appointed in 2012, recommended six substantial changes and numerous minor changes be made to the document. The Selectmen consolidated them into six articles for Town Meeting's consideration, and five were presented to the Meeting in 2013. Voters approved four of them in 2014. A version of the sixth and final proposal was adopted at the Spring 2014 Annual Town Meeting.

According to Dedham's Charter, the "administration of all the fiscal, prudential, and municipal affairs of the town, with the government thereof, shall be vested in a legislative branch, to consist of a representative town meeting." Town Meeting is to consist of no less than 270 members, but not more than necessary to achieve an equal number coming from each precinct. There are currently seven districts, but could be as few as six or as many as nine, with lines drawn by the Select Board and the Registrars of Voters every ten years.

Votes are by voice unless members call for a standing or roll call vote, either of which can be called for by the Moderator. All Town officers are required to attend Town Meeting and multiple member bodies must send at least one representative who have all the privileges of a Member except the right to vote. If 5% of Town voters petition the Select Board within 14 days of Town Meeting, any action taken may be submitted to voters. The final result is to be determined by majority vote, but Town Meeting can not be overruled unless 20% of registered voters participate.

Town Meeting sets its own rules and keeps a journal of proceedings. The Town Meeting may establish various ad-hoc and standing committees on which any Town Meeting Member or voter may serve.

Before each Spring Annual Town Meeting, the Public Service Recognition Award is given to recognize citizens who have performed outstanding acts of service to the community.

Currently Town Meeting consists of 273 members, or representatives, with each of the seven districts, or precincts, electing 39. Thirteen are elected from each precinct each year and serve a three-year term. Each precinct elects from its own members a Chairman, Vice Chairman, and Secretary.

To be eligible, candidates must have 10 registered voters from their precinct sign nomination papers. Town Meeting Representatives can not serve on any other elected board or on the Finance and Warrant Committee. Members who move from the district or are removed by redistricting may serve until the next Town Election; however, any member who moves out of the Town immediately ceases to be a Member.

In case of a vacancy, the remaining term is to be filled at the next town election. If no election is to take place within 120 days of the vacancy, then the district chairman is to call together the members of the district, and they are to elect a member who will serve until the next town election.

The Warrant at Town Meeting includes the articles to be voted on. Any elected or appointed board, committee, town officer, or any ten voters may place an article on the warrant. Each article to be voted on is directed by the Select Board to an appropriate board or committee to hear and provide the original motion at Town Meeting. All articles expending funds are directed to the Finance Committee; articles dealing with planning and zoning to the Planning Board; articles relating to by-laws to the By-Law Committee. The Finance Committee recommendation has the force of the original motion on all articles except those related to zoning. The Planning Board makes the original motion for those.

The Chairmen of the several districts elect from amongst themselves a chairman. This Chairman of the Chairmen hosts what is officially known as the District Chairmen's Warrant Review Meeting, but is much more commonly referred to as Mini Town Meeting. The "Mini," first held in 1978, is generally a week or two before the actual Town Meeting. The purpose of the Mini is to air out several of the contentious issues before bringing them to the floor of Town Meeting.

The executive branch of the Town Government is "headed" by a Select Board. The Board has five members who are elected for three-year terms and are the chief policy making body for the town. They appoint a Town Manager who runs the day-to-day affairs of the Town. They also appoint constables, registrars of voters and other election officers, the board of appeals, conservation commission, historic district commission, and members of several other multiple member boards. Current members are Chair Dennis J. Teehan, Jr., James A. MacDonald, Dimitria Sullivan, Sarah MacDonald, and Kevin R. Coughlin.

Selectmen set policy for all departments below it, but are not involved in the day-to-day affairs of the Town. They issue licenses and can investigate the affairs and the conduct of any town agency.

The Elected Town Clerk serves a three-year term and works full-time for the Town. The Clerk is "the keeper of vital statistics of the town and the custodian of the town seal and all public records, administer[s] the oaths of office to all town officers... [and is] the clerk of the town meeting." In the role as clerk of town meeting, he notifies the public and members of the Town Meeting and keeps a verbatim record of proceedings. The current Town Clerk is Paul Munchbach.

Town Meetings are presided over by the Town Moderator, but he has no vote unless all the Members present and voting are equally divided. At the first Town Meeting following the annual town election, he is to appoint, subject to Town Meeting's confirmation, a Deputy Moderator from the elected Members. The Deputy serves in case of the Moderator's absence or disability. The current Town Moderator is Dan Driscoll.

The seven members of the School Committee are elected for three-year terms and appoint a Superintendent of Schools. They also set policy for the School Department. The School Committee is currently chaired by Kevin R. Coughlin, with Lisa Laprade serving as Vice Chair. The other members of the Committee are Stephen M. Bilafer, Mayanne MacDonald Briggs, Joshua Donai, Melissa Pearrow, and Tracey White.

The three elected members of the Board of Assessors serve three-year terms and annually make a fair cash valuation of all property within the town. The current chair of the board is Christopher J. Polito, with Cheryl Dever Sullivan serving as Vice Chair and Richard J. Schoenfeld serving as Secretary.

The three elected members of the Board of Health are responsible for the formulation and enforcement of rules and regulations affecting the environment and the public health. Currently the board is chaired by Leanne Jasset, B.S.P. RPH, with Katherine M Reda R.N serving as Vice Chair. Mary P. Ellard also serves on the board.

The Board of Library Trustees has five members, each of whom serves three-year terms, and has care of the Town's public library at the Endicott Branch and Main Branch. The Board is responsible for all library policy, the library budget, and hiring and firing the library director. The board is currently co-chaired by Margaret M. Connolly and Mary Ann Sliwa. Tracy Driscoll, Sarah Santos, and Monika Wilkinson also serve as members.

The five elected members of the Planning Board make studies and prepare plans concerning the resources, possibilities, and needs of the town. It also prepares the Master Plan. Currently the board is chaired by John R. Bethoney, with James E. O'Brien IV serving as clerk. James F. McGrail, Jessica Porter, and Michael A. Podolski, Esq. are also members.

There are five elected members of the Parks & Recreation Commission. Section 3-10 of the Town Charter states that the goal of the commission is to promote physical education, play, recreation, sport and other programs for people of all ages. The commission is currently chaired by Tye Donahue, with Lisas Moran serving as Vice Chair. Chuck Dello Iacono is the Commission's Secretary. Alix O'Connell and Jon Briggs are also members.

There are five elected Commissioners of Trust Funds who manage and control all funds left, given, bequeathed, or devised to the town, and distribute the income in accordance with the terms of the respective trusts. The Commission's Chair is Emily Reynolds, with Salvatore A Spada serving as Vice Chair. Heather Springer serves as the Commission's Clerk. Bob Desmond and Dan Jon Oneil Jr. are also members.

There are five members of the Housing Authority Board. Four are elected by the Town and one is appointed by the Commonwealth Commissioner of Community Affairs. As members of the Board, they have all of the powers and duties which are given to housing authorities under the constitution and laws of the Commonwealth. The current Chair is Donna M. Brown Rego and Margaret Matthews serves as the Assistant Chair & State Appointee. Skye Annette Kessler serves as Treasurer, John B. Kane as Assistant Treasurer, and John Wagner as a member.

Dedham has been featured on both television and film screens.

The Dedham Public Schools operates seven schools and is known for the first implementation of a tax supported, free public school system, now used nationally.


In addition, there are several private schools in the town, including:




Boston United Hand in Hand Cemetery is located on Lower East Street straddling the West Roxbury line. Dating back to 1875, the original plot was full by 1896 but subsequently expanded a number of times. There are graves as recent as 1980 in the West Roxbury portion; the Dedham portion is still active. Chestnut Hill's Congregation Mishka Tefila currently owns the property.

Dedham is home to a number of community organizations, including


Commuter rail service from Boston's South Station is provided by the MBTA with stops at Endicott and
Dedham Corporate Center on its Franklin Line. Also MBTA bus route 34 Dedham Line to Forest Hills serves Washington Street. Bus route 34E Walpole Center to Forest Hills serves Washington Street, Dedham Square, and the Dedham Mall. Bus route 35 Dedham Mall to Forest Hills serves Washington Street.












</doc>
