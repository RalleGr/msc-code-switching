<doc id="20202" url="https://en.wikipedia.org/wiki?curid=20202" title="Meir Kahane">
Meir Kahane

Rabbi Meir David HaKohen Kahane (; ; August 1, 1932 – November 5, 1990) was an Israeli-American ordained Orthodox rabbi, writer, and ultra-nationalist politician who served one term in Israel's Knesset. His legacy continues to influence militant and far-right political groups active today in Israel.

Kahane publicized his "Kahanism" ideology, which he claimed was simply Torah Judaism based on "halakha" (Jewish law), through published works, weekly articles, speeches, debates on college campuses and in synagogues throughout the United States, and appearances on various televised programs and radio shows. He was an intense advocate for Jewish causes, such as organizing defense squads and patrols in Jewish neighborhoods and demanding for the Soviet Union to "release its oppressed Jews". He supported violence against those he regarded as enemies of the Jewish people, called for immediate Jewish mass migration to Israel to avoid a potential "Holocaust" in the United States, supported the restriction of Israel's democracy to its Jewish citizens, hoped that Israel would eventually adopt "halakha", and endorsed the annexation of the West Bank and Gaza Strip.

Kahane proposed enforcing "halakha" as codified by Maimonides. Non-Jews wishing to dwell in Israel would have three options: remain as "resident strangers" with limited rights, leave Israel and receive compensation for their property, or be forcibly removed without compensation. While serving in the Knesset in the mid-1980s Kahane proposed numerous laws, none of which passed, to emphasize Judaism in public schools, reduce Israel's bureaucracy, forbid sexual relations between non-Jews and Jews, and end cultural meetings between Jewish and Arab students.

In 1968, Kahane was one of the co-founders of the Jewish Defense League (JDL) in the United States. In 1971, he co-founded Kach ("Thus"), a new political party in Israel. The same year, he was convicted in New York for conspiracy to manufacture explosives and received a suspended sentence of five years. In 1984, he became a member of the Knesset, when Kach gained its only-ever seat in parliamentary elections. In 1988, after polls showed Kach gaining popularity, the Israeli government banned Kach for being "racist" and "anti-democratic" under the terms of a law that it had just passed.

Kahane was assassinated in a New York hotel by an Egyptian-born U.S. citizen in November 1990.

Martin David Kahane was born in Brooklyn, New York, in 1932 to an Orthodox Jewish family. His father, Yechezkel (Charles) Kahane, the author of the "Torah Yesharah", studied at Polish and Czech yeshivas, was involved in the Revisionist Zionist movement, and was a close friend of Ze'ev Jabotinsky.

As a teenager, Kahane became an ardent admirer of Jabotinsky and Peter Bergson, who were frequent guests in his parents' home. He joined the Betar (Brit Trumpeldor) youth wing of Revisionist Zionism. He was active in protests against Ernest Bevin, the British Foreign Secretary who maintained restrictions on the immigration of Jews, even Nazi death camp survivors, to Palestine after the end of the Second World War. In 1947, Kahane was arrested for throwing eggs and tomatoes at Bevin, who was disembarking at Pier 84 on a visit to New York. A photo of the arrest appeared in the "New York Daily News". In 1954, he became the Mazkir (Secretary) of Greater New York City's 16 Bnei Akiva chapters.

Kahane's formal education included elementary school at the Yeshiva of Flatbush, and he attended high school at both Abraham Lincoln High School and the Brooklyn Talmudical Academy. Kahane received his rabbinical ordination from the Mir Yeshiva, in Brooklyn, where he was especially admired by the head Rabbi Abraham Kalmanowitz, and he began going by his Hebrew name, Meir. He was fully conversant in the Tanakh (Jewish Bible), the Talmud, the Midrash and Jewish law. Subsequently, Kahane earned a B.A. in Political Science from Brooklyn College in 1954, a Bachelor of Law - LL.B. from New York Law School, and an M.A. in International Relations from New York University.

In 1956, Kahane married Libby Blum, with whom he had four children: Tzipporah, Tova, Baruch, and Binyamin.

Journalists Michael T. Kaufman and Robert I. Friedman have separately said that Kahane, under the alias of Michael King and while already married, proposed to 21-year old model Gloria Jean D'Argenio (who used the stage name Estelle Donna Evans) in 1966. Kahane allegedly sent a letter to D'Argenio in which he unilaterally ended their relationship. In response, D'Argenio jumped off the Queensboro Bridge and died of her injuries the next day. In 2008, Kahane's wife dismissed the incident as lacking proof.

After D'Argenio's death, Kahane started the Estelle Donna Evans Foundation in her name. Kahane claimed D'Argenio had been his former secretary in his failed consulting operation, she had died of terminal cancer, and her “well-to-do” family had endowed the foundation. Robert Friedman reported, “In reality, Kahane used the money to help finance the JDL.” That meant two different things: funding the purchase of supplies for bombings and fattening his own wallet, spending lavishly on trips for himself.

In 1958, Kahane became the rabbi of the Howard Beach Jewish Center in Queens, New York City. Although the synagogue was originally Conservative, rather than strictly Orthodox, the board of directors agreed to Kahane's conditions, which included resigning from the Conservative movement's United Synagogue of America, installing a partition separating men and women during prayer, instituting traditional prayers, and maintaining a kosher kitchen. At the Jewish Center, Kahane influenced many of the synagogue's youngsters to adopt a more observant lifestyle, which often troubled parents. He trained Arlo Guthrie for his bar mitzvah. When his contract was not renewed, he soon published an article entitled "End of the Miracle of Howard Beach". That was Kahane's first article in "The Jewish Press", an American Orthodox Jewish weekly for which he would continue to write for the rest of his life. Kahane also used the pen name David Sinai, and the pseudonyms Michael King, David Borac, and Martin Keene.

In the late 1950s and the early 1960s, Kahane's life of secrecy and his strong anticommunism landed him a position as a consultant with the FBI. According to his wife, Libby, his assignment was to infiltrate the anticommunist John Birch Society and report his findings to the FBI. 

At some time in the late 1950s, Kahane assumed the persona of a Gentile, along with the pseudonym Michael King. Kahane began openly expressing his anticommunism. He and Joseph Churba created the July Fourth Movement, which was formed to counteract widespread opposition towards U.S. involvement in the Vietnam War. Subsequently, they coauthored the book "The Jewish Stake in Vietnam", an attempt to convince American Jews of the "evil of Communism". The introduction states that, "All Americans have a stake in this grim war against Communism... It is vital that Jews realize the threat to their very survival [should Communism succeed]." Churba had a major falling out with Kahane over the use of paramilitary activities, and they parted ways permanently. Churba went on to pursue his own career, joining the U.S. Air Force, writing many books on the Middle East, and eventually becoming one of Ronald Reagan's consultants. Kahane chose to fight for Jewish rights, and was willing to use extreme measures. He even attempted to acquire and grow biological weapons to use on a Soviet military installation. He began using the phrase "Never Again" and conceived the Jewish Star and fist insignia, a symbol resembling that of the Black Panther Party. However, Kahane himself opposed the Black Panthers because they had supported anti-Jewish riots in Massachusetts and had left-wing views.

Kahane founded the Jewish Defense League (JDL) in New York City in 1968. Its self-described purpose was to protect Jews from local manifestations of anti-Semitism. The JDL said it was committed to five fundamental principles:


The JDL favored civil rights for blacks, but opposed black anti-Semites and racism of any form. In 1971, the JDL formed an alliance with a black rights group in what Kahane termed "a turning point in Black-Jewish relations". The Anti-Defamation League claimed that Kahane "preached a radical form of Jewish nationalism which reflected racism, violence and political extremism" that was replicated by Irv Rubin, the JDL's successor to Kahane.

A number of the JDL's members and leaders, including Kahane, were convicted of acts related to domestic terrorism. In 1971, Kahane was sentenced to a suspended five-year prison sentence for conspiring to manufacture explosives. In 1975, Kahane was arrested for leading the attack on the Soviet United Nations mission and injuring two officers, but he was released after being given summonses for disorderly conduct. Later the same year, Kahane was accused of conspiring to kidnap a Soviet diplomat, bomb the Iraqi embassy in Washington, and ship arms abroad from Israel. He was convicted of violating his probation for the 1971 bombing conviction and was sentenced to one year in prison. However, he served most of it in a hotel, with frequent unsupervised absences, because of a concession over the provision of kosher food.

In a 1984 interview with "Washington Post" correspondent Carla Hall, Kahane admitted that the JDL "bombed the Russian [Soviet] mission in New York, the Russian cultural mission here [Washington] in 1971, the Soviet trade offices".

In 1971, Kahane moved to Israel. At the time, he declared that he would focus on Jewish education. He later began gathering lists of Arab citizens of the State of Israel who were willing to emigrate for compensation, and eventually, he initiated protests that advocated the expulsion of Arabs from that country, and Israeli-occupied territories. In 1972, Jewish Defense League leaflets were distributed in Hebron, calling for the mayor to stand trial for the 1929 Hebron massacre. Kahane was arrested dozens of times. In 1971, he founded Kach, a political party that ran for the Knesset, the Israeli Parliament, during the 1973 general elections under the name "The League List". It won 12,811 votes (0.82%), just 2,857 (0.18%) short of the electoral threshold at the time (1%) for winning a Knesset seat. The party was even less successful in the 1977 elections, winning only 4,836 votes.

In 1980, Kahane was arrested for the 62nd time since his emigration, and he was jailed for six months after a detention order that was based on allegations of him planning armed attacks against Palestinians in response to the killings of Jewish settlers. Kahane was held in prison in Ramla, where he wrote the book "They Must Go". Kahane was banned from entering the United Kingdom in 1981.

In 1981, Kahane's party again ran for the Knesset during the 1981 elections, but it did not win a seat and received only 5,128 votes. In 1984, the Israeli Central Elections Committee banned him from being a candidate on the grounds that Kach was a racist party, but the Supreme Court of Israel overturned the ban on the grounds that the committee was not authorized to ban Kahane's candidacy. The Supreme Court suggested that the Knesset pass a law excluding racist parties from future elections. The Knesset responded in 1985 by amending the "Basic Law: Knesset" to include a prohibition (paragraph 7a) against the registration of parties that explicitly or implicitly incite racism.

In the 1984 legislative elections, Kahane's Kach party received 25,907 votes, gaining one seat in the Knesset, which was taken by Kahane. He refused to take the standard oath of office and insisted on adding a Biblical verse from Psalms to indicate that national laws were overruled by the Torah if they conflict. Kahane's legislative proposals focused on Jewish education, an open economy, transferring the Arab population out of the Land of Israel, revoking Israeli citizenship from non-Jews, and banning Jewish-Gentile marriages and sexual relations. 

While his popularity in Israel grew, Kahane was boycotted in the Knesset, where his speeches were often made to an empty assembly except for the duty chairman and the transcriptionist. Kahane's legislative proposals and motions of no-confidence against the government were ignored or rejected. Kahane often pejoratively called other Knesset members "Hellenists," a reference to Jews who assimilated into Greek culture after Judea's occupation by Alexander the Great. In 1987, Kahane opened a yeshiva ("HaRaayon HaYehudi") with funding from US supporters to teach "the Authentic Jewish Idea". Despite the boycott, his popularity grew among the Israeli public, especially for working-class Sephardi Jews. Polls showed that Kach would have likely received anywhere from four to twelve seats in the coming November 1988 elections.

In 1985, the Knesset passed an amendment to the Basic Law of Israel, barring political parties that incited to racism. The Central Elections Committee banned Kahane a second time, and he appealed to the Israeli Supreme Court. However, the Supreme Court this time ruled in favor of the Committee, disqualifying Kach from running in the 1988 legislative elections. Kahane was thus the first candidate in Israel to be barred from election for racism. The move was criticized as being anti-democratic by Alan M. Dershowitz.

After Kahane's election to the Knesset in 1984, the United States government attempted to revoke his U.S. citizenship, which Kahane successfully challenged in court. However, in 1987, the Knesset passed a law declaring that a Knesset member could only be an Israeli citizen. As a result of this legislation, Kahane renounced his United States citizenship. Following his banning from the Knesset, he again filed suit to get his U.S. citizenship reinstated based on the argument that he was compelled to relinquish it by the Knesset. The court rejected this argument, but he was permitted to continue travelling to the United States.

In November 1990, Kahane gave a speech to an audience of mostly Orthodox Jews from Brooklyn, where he warned American Jews to immigrate to Israel before it was "too late". As a crowd gathered around Kahane in the second-floor lecture hall in Midtown Manhattan's New York Marriott East Side, Kahane was assassinated by El Sayyid Nosair, an Egyptian-born U.S. citizen who had trained in Pakistan. He was initially charged and acquitted of the murder. Nosair was later convicted of the murder in U.S. District Court for his involvement in the 1993 World Trade Center bombing. Prosecutors were able to try Nosair again for the murder because the federal indictment included the killing as part of the alleged terrorist conspiracy. He was sentenced to life imprisonment and later made a confession to federal agents.

Kahane was buried on Har HaMenuchot, in Jerusalem. He was eulogized by a number of prominent supporters in both the U.S. and in Israel, including Rabbi Moshe Tendler and the Sephardic Chief Rabbi of Israel, Mordechai Eliyahu, who spoke of how little the people understood of Kahane's "true value".

Kahane argued that there was a glory in Jewish destiny, which came through the observance of the Torah and "halakha" (Jewish law). He also noted, "Democracy and Judaism are not the same thing." Kahane also stressed the view that a Jewish state and a Western democracy were incompatible, since Western democracy is religion-blind, and a Jewish state is religion-oriented by its very name. He also warned of the danger of non-Jewish citizens becoming a majority and voting against the Jewish character of the state: "The question is as follows: if the Arabs settle among us and make enough children to become a majority, will Israel continue to be a Jewish state? Do we have to accept that the Arab majority will decide?" "Western democracy has to be ruled out. For me, that's cut and dried: There's no question of setting up democracy in Israel, because democracy means equal rights for all, irrespective of racial or religious origins."

Kahane proposed an "exchange of populations" that would continue the Jewish exodus from Arab lands: "A total of some 750,000 Jews fled Arab lands since 1948. Surely it is time for Jews, worried over the huge growth of Arabs in Israel, to consider finishing the exchange of populations that began 35 years ago." Kahane proposed a $40,000 compensation plan for Arabs who would leave voluntarily, and forcible expulsion for those who "don't want to leave". He encouraged retaliatory violence against Arabs who attacked Jews: "I approve of anybody who commits such acts of violence. Really, I don't think that we can sit back and watch Arabs throwing rocks at buses whenever they feel like it. They must understand that a bomb thrown at a Jewish bus is going to mean a bomb thrown at an Arab bus."

In some of his writings, Kahane argued that Israel should never start a war for territory but that if a war were launched against Israel, Biblical territory should be annexed. However, in an interview, he defined Israel's "minimal borders" as follows: "The southern boundary goes up to El Arish, which takes in all of northern Sinai, including Yamit. To the east, the frontier runs along the western part of the East Bank of the Jordan River, hence part of what is now Jordan. Eretz Yisrael also includes part of Lebanon and certain parts of Syria, and part of Iraq, all the way to the Euphrates River." When critics suggested that following Kahane's plans would mean a perpetual war between Jews and Arabs, Kahane responded, "There will be a perpetual war. With or without Kahane."


Following Kahane's death, no leader emerged to replace him in the movement. However, the idea of transferring populations, attributed mainly to Kahane, was subsequently incorporated into the political platform of various political parties in Israel, such as Moledet (applying to Arab non-citizen residents of the West Bank) and Yisrael Beiteinu (in the form of population exchange). Two small Kahanist factions later emerged; one under the name "Kach", and the other under the name "Kahane chai" (Hebrew: כהנא חי, literally "Kahane lives [on]"), the second one being led by his younger son, Binyamin Ze'ev Kahane. Neither one was permitted to participate in the Knesset elections by the Central Elections Committee.

In 1994, following the Cave of the Patriarchs massacre of Palestinian Muslim worshippers in Hebron by Kach supporter Baruch Goldstein, in which 29 Muslim worshipers were killed, the Israeli government declared both parties to be terrorist organizations. The US State Department also added Kach and Kahane Chai to its list of Foreign Terrorist Organizations.

In the 2003 Knesset elections, Herut, which had split off from the National Union list, ran with Michael Kleiner and former Kach activist Baruch Marzel taking the top two spots on the list. The joint effort narrowly missed the 1.5% barrier. In the following 2006 elections, the Jewish National Front, led by Baruch Marzel, fared better, but it also failed to pass the minimum threshold. A follower of Kahane who was involved with Kach for many years, Michael Ben-Ari, was elected to the Knesset in the 2009 elections on renewed National Union list. He stood again in the 2013 elections as the second candidate on the list of Otzma LeYisrael, but the party failed to pass the minimum threshold.

In 2007, the FBI released over a thousand documents relating to its daily surveillance of Kahane since the early 1960s.

In 2015, Kahane's grandson, Meir Ettinger, was detained by Israeli law enforcement. He was the alleged leader of the radical Jewish group "The Revolt". In an online "manifesto" echoing some of his grandfather's teachings, Ettinger promotes the "dispossession of gentiles" who live in Israel and the establishment of a new "kingdom of Israel", a theocracy ruled according to the Halacha. Ettinger's writings condemned Israel's government, mainstream rabbis, and the IDF, and also have denounced Christian churches as "idolatry".

In 2016, Kahane's widow claimed that modern Jewish extremists in Israel do not follow the ideology of her late husband, Rabbi Meir Kahane. She justified that claim by arguing that unlike modern Jewish extremists, Rabbi Kahane had a more mature approach that did not encourage illegal activities.

In 2017, "The Forward" reported that some of Kahane's followers were aligning themselves with white nationalists and the alt-right. Other Kahanists declared that such moves did not reflect Kahane's teachings, and they supported that declaration by arguing that Kahane worked together with African Americans.





</doc>
<doc id="20203" url="https://en.wikipedia.org/wiki?curid=20203" title="Marietta Alboni">
Marietta Alboni

Marietta Alboni (6 March 1826 – 23 June 1894) was a renowned Italian contralto opera singer. She is considered as 'one of the greatest contraltos in operatic history'.

Alboni was born at Città di Castello, in Umbria. She became a pupil of of Cesena, Emilia–Romagna, and later of the composer Gioachino Rossini, when he was 'perpetual honorary adviser' in (and then the principal of) the Liceo Musicale, now Conservatorio Giovanni Battista Martini, in Bologna. Rossini tested the humble thirteen-year-old girl himself, had her admitted to the school with special treatment, and even procured her an early engagement to tour his "Stabat Mater" around Northern Italy, so that she could pay for her studies. After she achieved her diploma and made a modest debut in Bologna, in 1842, as "Climene" in Pacini's "Saffo", she obtained a triennial engagement thanks to Rossini's influence on the impresario Bartolomeo Merelli, Intendant at both Milan's Teatro alla Scala and Vienna's Imperial Kärntnertortheater. The favourable contract was signed by Rossini himself, "on behalf of Eustachio Alboni", father of Marietta, who was still a minor. The singer remained, throughout her life, deeply grateful to her ancient "maestro", nearly a second father to her.

Her debut at Teatro alla Scala took place in December 1842 as "Neocle" in the Italian version of "Le siège de Corinthe", which was followed by roles in operas by Marliani, Donizetti (as "Maffio Orsini" and "Leonora" in the Scala premiere of an Italian version of "La favorite"), Salvi and Pacini. In the season 1844–1845 she was engaged in the Saint Petersburg Imperial Bolshoi Kamenny Theatre; later, in 1846–47, she toured the principal cities of Central Europe, finally reaching London and Paris, where she settled permanently. In London, "she appeared in leading roles by Rossini and Donizetti (where she outshone Giulia Grisi and Jenny Lind) and also sang Cherubino (performing with Henriette Sontag)". For the 1848 London run of "Les Huguenots", Meyerbeer transposed the role of the page "Urbain" 'from soprano to contralto and composed the aria "Non! – non, non, non, non, non! Vous n'avez jamais, je gage" in Act 2' for her. On 28 August 1848, she sang at a concert in Manchester's Concert Hall, sharing the stage with Lorenzo Salvi and Frédéric Chopin. She toured the United States in 1852–53, appearing there with Camilla Urso.
In 1853 she wed a nobleman, Count Carlo Pepoli, of the Papal States, but she kept her maiden name for the stage. In 1863 she had to retire the first time on account of her husband's serious mental illness. He died in 1867. A year later, in 1868, Alboni would take part in the funeral of her beloved master and friend, Rossini, in the Église de la Sainte-Trinité. There she sang, alongside Adelina Patti, the leading soprano of the time, a stanza of "Dies irae", "Liber scriptum", adjusted to the music of the duet "Quis est Homo" from Rossini's own "Stabat Mater". Out of deference to her master, she also accepted to resume her singing career mainly in order to tour the orchestral version of the "Petite messe solennelle" around Europe. Rossini had once expressed his hope that she would take upon herself to perform it when he was dead. He had said that he had composed it, and especially the new section "O salutaris", just having her voice in mind.

In 1872 she permanently retired from the stage with four performances of "Fidalma" in Cimarosa's "Il matrimonio segreto", at the Paris Théâtre des Italiens but, in fact, she never gave up singing in private and in benefit concerts. When in 1887 the French and Italian Governments agreed upon moving the mortal remains of Rossini into the Basilica di Santa Croce in Florence, Alboni, then a sixty-one-year-old lady living in seclusion, wrote to the Italian Foreign Minister, Di Robilant, proposing that the "Petite Messe Solennelle", "the last musical composition by Rossini", be performed in Santa Croce the day of the funeral, and "demanding the honour, as an Italian and a pupil of the immortal Maestro," of singing it herself in her "dear and beloved homeland". Her wish, however, never came true and she was just given the chance of being present at the exhumation ceremony in Paris. The Paris correspondent of the Rome newspaper "Il Fanfulla" wrote on the occasion: "photographers snapped in the same shot the greatest performer of "Cenerentola" and "Semiramide", and what is left of the man who wrote these masterpieces".

In 1877 she had remarried—to a French military officer named Charles Zieger. She died at Ville-d'Avray, near Paris, in her "Villa La Cenerentola", and was buried at Père Lachaise Cemetery. Always engaged in charity (often in memory of Maestro Rossini), she left nearly all her estate to the poor of Paris. In her will she wrote that by singing she had earned all her fortune, and on singing she would pass away, with the sweet thought that she had employed it to encourage and to console.
Alboni's voice, an exceptionally fine contralto with a seamless compass of two and one-half octaves, extending as high as the soprano range was said to possess at once power, sweetness, fullness, and extraordinary flexibility. She had no peers in passages requiring a sensitive delivery and semi-religious calmness, owing to the moving quality of her velvety tone. She possessed vivacity, grace, and charm as an actress of the "comédienne" type; but she was not a natural "tragédienne", and her attempt at the strongly dramatic part of Norma was sometimes reported to have turned out a failure. Nevertheless, she scored a real triumph in 1850, when she made her operatic debut at the Paris Opéra performing the tragic role of "Fidès" in Meyerbeer's "Le prophète", which had been created the year before by no less than Pauline Viardot. Furthermore, she was able to cope with such dramatic roles as "Azucena" and "Ulrica" in Verdi's "Il trovatore" and "Un ballo in maschera", and even with the baritone role of "Don Carlo" in "Ernani" (London, 1847).

The following list of the roles performed by Marietta Alboni was drawn up by Arthur Pougin and published in his biography of the singer. It is reported here with the addition of further works and characters according to the sources stated in footnotes. 

Notes
Sources



</doc>
<doc id="20204" url="https://en.wikipedia.org/wiki?curid=20204" title="Manatee">
Manatee

Manatees (family Trichechidae, genus Trichechus) are large, fully aquatic, mostly herbivorous marine mammals sometimes known as sea cows. There are three accepted living species of Trichechidae, representing three of the four living species in the order Sirenia: the Amazonian manatee ("Trichechus inunguis"), the West Indian manatee ("Trichechus manatus"), and the West African manatee ("Trichechus senegalensis"). They measure up to long, weigh as much as , and have paddle-like flippers. The etymology of the name is unclear, with connections having been made to Latin (‘hand’), and to a word – sometimes cited as "manati" – used by the Taíno, a pre-Columbian people of the Caribbean, meaning "breast". Manatees' other name, "sea cows", comes from the fact that they are slow plant-eaters, peaceful and similar to cows on land. They often graze on water plants in tropical seas.

Manatees are three of the four living species in the order Sirenia. The fourth is the Eastern Hemisphere's dugong. The Sirenia are thought to have evolved from four-legged land mammals more than 60 million years ago, with the closest living relatives being the Proboscidea (elephants) and Hyracoidea (hyraxes).

The Amazonian's hair color is brownish gray, and it has thick wrinkled skin, often with coarse hair, or "whiskers". Photos are rare; although very little is known about this species, scientists think it is similar to West Indian manatee.

Manatees weigh , and average in length, sometimes growing to and (the females tend to be larger and heavier). At birth, baby manatees weigh about each. The manatee has a large, flexible, prehensile upper lip, used to gather food and eat and for social interaction and communication. Manatees have shorter snouts than their fellow sirenians, the dugongs. The lids of manatees' small, widely spaced eyes close in a circular manner. The adults have no incisor or canine teeth, just a set of cheek teeth, which are not clearly differentiated into molars and premolars. These teeth are repeatedly replaced throughout life, with new teeth growing at the rear as older teeth fall out from farther forward in the mouth, somewhat as elephants' teeth do. At any time, a manatee typically has no more than six teeth in each jaw of its mouth. Its tail is paddle-shaped, and is the clearest visible difference between manatees and dugongs; a dugong tail is fluked, similar in shape to that of a whale. The female manatee has two teats, one under each flipper, a characteristic that was used to make early links between the manatee and elephants.

The manatee is unusual among mammals in having just six cervical vertebrae, a number that may be due to mutations in the homeotic genes. All other mammals have seven cervical vertebrae, other than the two-toed and three-toed sloths.

Like the horse, the manatee has a simple stomach, but a large cecum, in which it can digest tough plant matter. Generally, the intestines are about 45 meters, unusually long for an animal of the manatee's size.

Fossil remains of manatee ancestors - also known as sirenians - date back to the Early Eocene.

Apart from mothers with their young, or males following a receptive female, manatees are generally solitary animals. Manatees spend approximately 50% of the day sleeping submerged, surfacing for air regularly at intervals of less than 20 minutes. The remainder of the time is mostly spent grazing in shallow waters at depths of . The Florida subspecies ("T. m. latirostris") has been known to live up to 60 years.

Generally, manatees swim at about . However, they have been known to swim at up to in short bursts.

Manatees are capable of understanding discrimination tasks and show signs of complex associative learning. They also have good long-term memory. They demonstrate discrimination and task-learning abilities similar to dolphins and pinnipeds in acoustic and visual studies.

Manatees typically breed once every two years; generally only a single calf is born. Gestation lasts about 12 months and to wean the calf takes a further 12 to 18 months, although females may have more than one estrous cycle per year.

Manatees emit a wide range of sounds used in communication, especially between cows and their calves. Their ears are large internally but the external openings are small, and they are located four inches behind each eye. Adults communicate to maintain contact and during sexual and play behaviors. Taste and smell, in addition to sight, sound, and touch, may also be forms of communication.

Manatees are herbivores and eat over 60 different freshwater (e.g., floating hyacinth, pickerel weed, alligator weed, water lettuce, hydrilla, water celery, musk grass, mangrove leaves) and saltwater plants (e.g., sea grasses, shoal grass, manatee grass, turtle grass, widgeon grass, sea clover, and marine algae). Using their divided upper lip, an adult manatee will commonly eat up to 10%–15% of their body weight (about 50 kg) per day. Consuming such an amount requires the manatee to graze for up to seven hours a day. To be able to cope with the high levels of cellulose in their plant based diet, manatees utilize hindgut fermentation to help with the digestion process. Manatees have been known to eat small numbers of fish from nets.

Manatees use their flippers to "walk" along the bottom whilst they dig for plants and roots in the substrate. When plants are detected, the flippers are used to scoop the vegetation toward the manatee's lips. The manatee has prehensile lips; the upper lip pad is split into left and right sides which can move independently. The lips use seven muscles to manipulate and tear at plants. Manatees use their lips and front flippers to move the plants into the mouth. The manatee does not have front teeth, however, behind the lips, on the roof of the mouth, there are dense, ridged pads. These horny ridges, and the manatee's lower jaw, tear through ingested plant material.

Manatees have four rows of teeth. There are 6 to 8 high-crowned, open-rooted molars located along each side of the upper and lower jaw giving a total of 24 to 32 flat, rough-textured teeth. Eating gritty vegetation abrades the teeth, particularly the enamel crown; however, research indicates that the enamel structure in manatee molars is weak. To compensate for this, manatee teeth are continually replaced. When anterior molars wear down, they are shed. Posterior molars erupt at the back of the row and slowly move forward to replace these like enamel crowns on a conveyor belt, similarly to elephants. This process continues throughout the manatee's lifetime. The rate at which the teeth migrate forward depends on how quickly the anterior teeth abrade. Some studies indicate that the rate is about 1 cm/month although other studies indicate 0.1 cm/month.

Manatees inhabit the shallow, marshy coastal areas and rivers of the Caribbean Sea and the Gulf of Mexico ("T. manatus", West Indian manatee), the Amazon basin ("T. inunguis", Amazonian manatee), and West Africa ("T. senegalensis", West African manatee).

West Indian manatees prefer warmer temperatures and are known to congregate in shallow waters. They frequently migrate through brackish water estuaries to freshwater springs. They cannot survive below 15 °C (60 °F). Their natural source for warmth during winter is warm, spring-fed rivers.

The coast of the state of Georgia is usually the northernmost range of the West Indian manatees because their low metabolic rate does not protect them in cold water. Prolonged exposure to water below 20 °C (68 °F) can cause "cold stress syndrome" and death.

Florida manatees can move freely between fresh water and salt water.

Manatees have been seen as far north as Cape Cod, and in 1995 and again in 2006, one was seen in New York City and Rhode Island's Narragansett Bay. A manatee was spotted in the Wolf River harbor near the Mississippi River in downtown Memphis in 2006, and was later found dead 10 miles downriver in McKellar Lake. Another manatee was found dead on a New Jersey beach in February 2020, considered especially unusual given the time of year. At the time of the manatee's discovery, the water temperature in the area was below 6.5 °C (43.7 °F).

The West Indian manatee migrates into Florida rivers—such as the Crystal, the Homosassa, and the Chassahowitzka rivers, whose headsprings are 22 °C (72 °F) all year. Between November and March each year, about 600 West Indian manatees gather in the rivers in Citrus County, Florida such as the Crystal River National Wildlife Refuge.

In winter, manatees often gather near the warm-water outflows of power plants along the Florida coast, instead of migrating south as they once did. Some conservationists are concerned that these manatees have become too reliant on these artificially warmed areas. The U.S. Fish and Wildlife Service is trying to find a new way to heat the water for manatees that depended on plants that have closed. 

Studies suggest that Florida manatees need access to fresh water for proper regulation of water and salts in their bodies.

Accurate population estimates of the Florida manatee ("T. manatus") are difficult. They have been called scientifically weak because they vary widely from year to year, some areas showing increases, others decreases, and little strong evidence of increases except in two areas. Manatee counts are highly variable without an accurate way to estimate numbers: In Florida in 1996, a winter survey found 2,639 manatees; in 1997, a January survey found 2,229, and a February survey found 1,706. A statewide synoptic survey in January 2010 found 5,067 manatees living in Florida, the highest number recorded to that time.

As of January 2016, the USFWS estimates the range-wide manatee population to be at least 13,000; as of January, 2018, at least 6,100 are estimated to be in Florida.

Population viability studies conducted in 1997 found that decreasing adult survival and eventual extinction were a probable future outcome for Florida manatees unless they got more protection. The U.S. Fish and Wildlife Service proposed downgrading the manatee's status from endangered to threatened in January 2016 after more than 40 years of the manatee's being classified as on the endangered.

The freshwater Amazonian manatee ("T. inunguis") inhabits the Amazon River and its tributaries, and never ventures into salt water.

They are found in coastal marine and estuarine habitats, and in freshwater river systems along the west coast of Africa from the Senegal River south to the Cuanza River in Angola. They live as far upriver on the Niger River as Koulikoro in Mali, 2,000 km from the coast.

In relation to the threat posed by humans, predation does not present a significant threat to manatees. When threatened, the manatee's response is to dive as deeply as it can, suggesting that threats have most frequently come from land dwellers such as humans rather than from other water-dwelling creatures such as caimans or sharks.

The main causes of death for manatees are human-related issues, such as habitat destruction and human objects. Natural causes of death include adverse temperatures, predation by crocodiles on young, and disease.

Their slow-moving, curious nature, coupled with dense coastal development, has led to many violent collisions with propeller-driven boats and ships, leading frequently to maiming, disfigurement, and even death. As a result, a large proportion of manatees exhibit spiral cutting propeller scars on their backs, usually caused by larger vessels that do not have skegs in front of the propellers like the smaller outboard and inboard-outboard recreational boats have. They are now even identified by humans based on their scar patterns. Many manatees have been cut in two by large vessels like ships and tug boats, even in the highly populated lower St. Johns River's narrow channels. Some are concerned that the current situation is inhumane, with upwards of 50 scars and disfigurements from vessel strikes on a single manatee. Often, the lacerations lead to infections, which can prove fatal. Internal injuries stemming from being trapped between hulls and docks and impacts have also been fatal. Recent testing shows that manatees may be able to hear speed boats and other watercraft approaching, due to the frequency the boat makes. However, a manatee may not be able to hear the approaching boats when they are performing day-to-day activities or distractions. The manatee has a tested frequency range of 8 kilohertz to 32 kilohertz.

Manatees hear on a higher frequency than would be expected for such large marine mammals. Many large boats emit very low frequencies, which confuse the manatee and explain their lack of awareness around boats. The Lloyd's mirror effect results in low frequency propeller sounds not being discernible near the surface, where most accidents occur. Research indicates that when a boat has a higher frequency the manatees rapidly swim away from danger.

In 2003, a population model was released by the United States Geological Survey that predicted an extremely grave situation confronting the manatee in both the Southwest and Atlantic regions where the vast majority of manatees are found. It states,
According to marine mammal veterinarians:
These veterinarians go on to state:
In 2009, of the 429 Florida manatees recorded dead, 97 were killed by commercial and recreational vessels, which broke the earlier record number of 95 set in 2002.

Another cause of manatee deaths are red tides, a term used for the proliferation, or "blooms", of the microscopic marine algae, "Karenia brevis". This dinoflagellate produces brevetoxins that can have toxic effects on the central nervous system of animals.

In 1996, a red tide was responsible for 151 manatee deaths. The bloom was present from early March to the end of April and killed approximately 15% of the known population of manatees along South Florida's western coast.
Other blooms in 1982 and 2005 resulted in 37 and 44 deaths, respectively.

Manatees can also be crushed and isolated in water control structures (navigation locks, floodgates, etc.) and are occasionally killed by entanglement in fishing gear, such as crab pot float lines, box traps, and shark nets.

While humans are allowed to swim with manatees in one area of Florida, there have been numerous charges of people harassing and disturbing the manatees. According to the United States Fish and Wildlife Service, approximately 99 manatee deaths each year are related to human activities. In January 2016, there were 43 manatee deaths in Florida alone.

All three species of manatee are listed by the World Conservation Union as vulnerable to extinction. However, The U.S. Fish and Wildlife Service (FWS) does not consider the West Indian manatee to be "endangered" anymore, having downgraded its status to "threatened" as of March 2017. They cite improvements to habitat conditions, population growth and reductions of threats as reasoning for the change. The reclassification was met with controversy, with Floridan senator Vern Buchanan and groups such as the Save the Manatee Club and the Center for Biological Diversity expressing concerns that the change would have a detrimental effect on conservation efforts. The new classification will not affect current federal protections. West Indian manatees were originally classified as endangered with the 1967 class of endangered species.

Manatee population in the United States reached a low in the 1970's, during which only a few hundred individuals lived in the nation. As of February 2016, 6,250 manatees were reported swimming in Florida's springs. It is illegal under federal and Florida law to injure or harm a manatee.

The MV "Freedom Star" and MV "Liberty Star", ships used by NASA to tow space shuttle solid rocket boosters back to Kennedy Space Center, were propelled only by water jets to protect the endangered manatee population that inhabits regions of the Banana River where the ships are based.

Brazil outlawed hunting in 1973 in an effort to preserve the species. Deaths by boat strikes are still common.

The oldest manatee in captivity was Snooty, at the South Florida Museum's Parker Manatee Aquarium in Bradenton, Florida. Born at the Miami Aquarium and Tackle Company on July 21, 1948, Snooty was one of the first recorded captive manatee births. Raised entirely in captivity, Snooty was never to be released into the wild. As such he was the only manatee at the aquarium, and one of only a few captive manatees in the United States that was allowed to interact with human handlers. That made him uniquely suitable for manatee research and education.

Snooty died suddenly two days after his 69th birthday, July 23, 2017, when he was found in an underwater area only used to access plumbing for the exhibit life support system. The South Florida Museum's initial press release stated, “Early indications are that an access panel door that is normally bolted shut had somehow been knocked loose and that Snooty was able to swim in.”

There are a number of manatee rehabilitation centers in the United States. These include three government-run critical care facilities in Florida at Lowry Park Zoo, Miami Seaquarium, and SeaWorld Orlando. After initial treatment at these facilities, the manatees are transferred to rehabilitation facilities before release. These include the Cincinnati Zoo and Botanical Garden, Columbus Zoo and Aquarium, Epcot's The Seas, South Florida Museum, and Homosassa Springs Wildlife State Park.

The Columbus Zoo was a founding member of the Manatee Rehabilitation Partnership in 2001. Since 1999, the zoo's Manatee Bay facility has helped rehabilitate 20 manatees. The Cincinnati Zoo has rehabilitated and released more than a dozen manatees since 1999.

Manatees can also be viewed in a number of European zoos, such as the Tierpark Berlin, the Nuremberg Zoo, in ZooParc de Beauval in France and in the Aquarium of Genoa in Italy. The River Safari at Singapore features seven of them.

Since the 19th century, Georgetown, Guyana has kept West Indian manatees in its botanical garden, and later, its national park.
In the 1910s and again in the 1950s, sugar estates in Guyana used manatees to keep their irrigation canals weed-free.
Between the 1950s and 1970s, the Georgetown water treatment plant used manatees in their storage canals for the same purpose. 

The manatee has been linked to folklore on mermaids. In West African folklore, they were considered sacred and thought to have been once human. Killing one was taboo and required penance.

In the novel "Moby-Dick", Herman Melville distinguishes manatees ("Lamatins", cf. "lamatins") from small whales; stating, "I am aware that down to the present time, the fish styled Lamatins and Dugongs (Pig-fish and Sow-fish of the Coffins of Nantucket) are included by many naturalists among the whales. But as these pig-fish are a noisy, contemptible set, mostly lurking in the mouths of rivers, and feeding on wet hay, and especially as they do not spout, I deny their credentials as whales; and have presented them with their passports to quit the Kingdom of Cetology."




</doc>
<doc id="20205" url="https://en.wikipedia.org/wiki?curid=20205" title="Marsupial">
Marsupial

Marsupials are any members of the mammalian infraclass Marsupialia. All extant marsupials are endemic to Australasia and the Americas. A distinctive characteristic common to most of these species is that the young are carried in a pouch. Well-known marsupials include kangaroos, wallabies, koalas, phalangeriformes, opossums, wombats, Tasmanian devils, and the extinct thylacine. Some lesser-known marsupials are the dunnarts, potoroos, and the cuscus.

Marsupials represent the clade originating from the last common ancestor of extant metatherians. Like other mammals in the Metatheria, they give birth to relatively undeveloped young that often reside in a pouch located on their mothers' abdomen for a certain amount of time. Close to 70% of the 334 extant species occur on the Australian continent (the mainland, Tasmania, New Guinea and nearby islands). The remaining 30% are found in the Americas—primarily in South America, thirteen in Central America, and one in North America, north of Mexico.

The word "marsupial" comes from "marsupium", the technical term for the abdominal pouch. It, in turn, is borrowed from Latin and ultimately from the ancient Greek , meaning "pouch".

Marsupials are taxonomically identified as members of mammalian infraclass Marsupialia, first described as a family under the order Pollicata by German zoologist Johann Karl Wilhelm Illiger in his 1811 work "Prodromus Systematis Mammalium et Avium". However, James Rennie, author of "The Natural History of Monkeys, Opossums and Lemurs" (1838), pointed out that the placement of five different groups of mammals – monkeys, lemurs, tarsiers, aye-ayes and marsupials (with the exception of kangaroos, that were placed under the order Salientia) – under a single order (Pollicata) did not appear to have a strong justification. In 1816, French zoologist George Cuvier classified all marsupials under the order Marsupialia. In 1997, researcher J. A. W. Kirsch and others accorded infraclass rank to Marsupialia. There are two primary divisions: American marsupials (Ameridelphia) and Australian marsupials (Australidelphia).

Marsupialia is further divided as follows:

† – Extinct


Comprising over 300 extant species, several attempts have been made to accurately interpret the phylogenetic relationships among the different marsupial orders. Studies differ on whether Didelphimorphia or Paucituberculata is the sister group to all other marsupials. Though the order Microbiotheria (which has only one species, the monito del monte) is found in South America, morphological similarities suggest it is closely related to Australian marsupials. Molecular analyses in 2010 and 2011 identified Microbiotheria as the sister group to all Australian marsupials. However, the relations among the four Australidelphid orders are not as well understood. The cladogram below, depicting the relationships among the various marsupial orders, is based on a 2015 phylogenetic study.

DNA evidence supports a South American origin for marsupials, with Australian marsupials arising from a single Gondwanan migration of marsupials from South America, across Antarctica, to Australia. There are many small arboreal species in each group. The term "opossum" is used to refer to American species (though "possum" is a common abbreviation), while similar Australian species are properly called "possums".

Marsupials have the typical characteristics of mammals—e.g., mammary glands, three middle ear bones, and true hair. There are, however, striking differences as well as a number of anatomical features that separate them from Eutherians.

In addition to the front pouch, which contains multiple teats for the sustenance of their young, marsupials have other common structural features. Ossified patellae are absent in most modern marsupials (though a small number of exceptions are reported) and epipubic bones are present. Marsupials (and monotremes) also lack a gross communication (corpus callosum) between the right and left brain hemispheres.

The skull has peculiarities in comparison to placental mammals. In general, the skull is relatively small and tight. Holes ("foramen lacrimale") are located in the front of the orbit. The cheekbone is enlarged and extends further to the rear. The angular extension ("processus angularis") of the lower jaw is bent toward the center. Another feature is the hard palate which, in contrast to the placental mammals' foramina, always have more openings. The teeth differ from that of placental mammals, so that all taxa except wombats have a different number of incisors in the upper and lower jaws. The early marsupials had a dental formula from 5/4 – 1/1 – 3/3 – 4/4, that is, per pine half; they have five maxilla or four mandibular incisors, one canine, three premolars and four molars, for a total of 50 teeth. Some taxa, such as the opossum, have the original number of teeth. In other groups the number of teeth is reduced. The dental formula for Macropodidae (kangaroos and wallabies etc.) is 3/1 – (0 or 1)/0 – 2/2 – 4/4. Marsupials in many cases have 40 to 50 teeth, significantly more than placental mammals. The upper jaw has a high number of incisors, up to ten, and they have more molars than premolars. The second set of teeth grows in only at the 3rd premolar: all remaining teeth are already created as permanent teeth.

Few general characteristics describe their skeleton. In addition to details in the construction of the ankle, bones ("Ossa epubica") are characteristic, two from the pubic bone of the pelvis, which is a forwardly projecting bone. Since these are present in males and pouchless species, it is believed that they originally had nothing to do with reproduction, but served in the muscular approach to the movement of the hind limbs. This could be explained by an original feature of mammals, as these epipubic bones are also found in monotremes. Marsupial reproductive organs differ from the placental mammals. For them, the reproductive tract is doubled. The females have two uteri and two vaginas, and before birth, a birth canal forms between them, the median vagina. The males have a split or double penis lying in front of the scrotum.

A pouch is present in most, but not all, species. Many marsupials have a permanent bag, whereas in others the pouch develops during gestation, as with the shrew opossum, where the young are hidden only by skin folds or in the fur of the mother. The arrangement of the pouch is variable to allow the offspring to receive maximum protection. Locomotive kangaroos have a pouch opening at the front, while many others that walk or climb on all fours have the opening in the back. Usually, only females have a pouch, but the male water opossum has a pouch that is used to accommodate his genitalia while swimming or running.

Marsupials have adapted to many habitats, reflected in the wide variety in their build. The largest living marsupial, the red kangaroo, grows up to in height and in weight, but extinct genera, such as "Diprotodon", were significantly larger and heavier. The smallest members of this group are the marsupial mice, which often reach only in body length.

Some species resemble placental mammals and are examples of convergent evolution. The extinct "Thylacine" strongly resembled the placental wolf, hence its nickname "Tasmanian wolf". Flying and the associated ability to glide occurred both with marsupials (as with sugar gliders) and some placental mammals (as with flying squirrels), which developed independently. Other groups such as the kangaroo, however, do not have clear placental counterparts, though they share similarities in lifestyle and ecological niches with ruminants.

Marsupials' reproductive systems differ markedly from those of placental mammals. During embryonic development, a choriovitelline placenta forms in all marsupials. In bandicoots, an additional chorioallantoic placenta forms, although it lacks the chorionic villi found in eutherian placentas.

The evolution of reproduction in marsupials, and speculation about the ancestral state of mammalian reproduction, have engaged discussion since the end of the 19th century. Both sexes possess a cloaca, which is connected to a urogenital sac used to store waste before expulsion. The bladder of marsupials functions as a site to concentrate urine and empties into the common urogenital sinus in both females and males.

Most male marsupials, except for macropods and marsupial moles, have a bifurcated penis, separated into two columns, so that the penis has two ends corresponding to the females' two vaginas. The penis is used only during copulation, and is separate from the urinary tract. It curves forward when erect, and when not erect, it is retracted into the body in an S-shaped curve. Neither marsupials nor monotremes possess a baculum. The shape of the glans penis varies among marsupial species.

The male thylacine had a pouch that acted as a protective sheath, covering his external reproductive organs while he ran through thick brush.

The shape of the urethral grooves of the males' genitalia is used to distinguish between "Monodelphis brevicaudata", "Monodelphis domestica", and "Monodelphis americana". The grooves form 2 separate channels that form the ventral and dorsal folds of the erectile tissue. Several species of dasyurid marsupials can also be distinguished by their penis morphology.

The only accessory sex glands marsupials possess are the prostate and bulbourethral glands. There are no ampullae, seminal vesicles or coagulating glands. The prostate is proportionally larger in marsupials than in placental mammals. During the breeding season, the male tammar wallaby's prostate and bulbourethral gland enlarge. However, there does not appear to be any seasonal difference in the weight of the testes.

Female marsupials have two lateral vaginas, which lead to separate uteri, but both open externally through the same orifice. A third canal, the median vagina, is used for birth. This canal can be transitory or permanent. Some marsupial species are able to store sperm in the oviduct after mating.

Marsupials give birth at a very early stage of development; after birth, newborn marsupials crawl up the bodies of their mothers and attach themselves to a teat, which is located on the underside of the mother, either inside a pouch called the marsupium, or open to the environment. There they remain for a number of weeks, attached to the teat. The offspring are eventually able to leave the marsupium for short periods, returning to it for warmth, protection, and nourishment.

Pre-natal development differs between marsupials and placental mammals. Key aspects of the first stages of placental mammal embryo development, such as the inner cell mass and the process of compaction, are not found in marsupials. The cleavage stages of marsupial development are very variable between groups and aspects of marsupial early development are not yet fully understood.

An early birth removes a developing marsupial from its mother's body much sooner than in placental mammals, thus marsupials have not developed a complex placenta to protect the embryo from its mother's immune system. Though early birth puts the tiny newborn marsupial at a greater environmental risk, it significantly reduces the dangers associated with long pregnancies, as there is no need to carry a large fetus to full term in bad seasons. Marsupials are extremely altricial animals, needing to be intensely cared for immediately following birth (cf. precocial).

Because newborn marsupials must climb up to their mother's teats, their front limbs and facial structures are much more developed than the rest of their bodies at the time of birth. This requirement has been argued to have resulted in the limited range of locomotor adaptations in marsupials compared to placentals. Marsupials must develop grasping forepaws during their early youth, making the evolutive transition from these limbs into hooves, wings, or flippers, as some groups of placental mammals have done, more difficult. However, several marsupials do possess atypical forelimb morphologies, such as the hooved forelimbs of the pig-footed bandicoot, suggesting that the range of forelimb specialization is not as limited as assumed.

An infant marsupial is known as a joey. Marsupials have a very short gestation period—usually around four to five weeks, but as low as 12 days for some species—and the joey is born in an essentially fetal state. The blind, furless, miniature newborn, the size of a jelly bean, crawls across its mother's fur to make its way into the pouch, where it latches onto a teat for food. It will not re-emerge for several months, during which time it develops fully. After this period, the joey begins to spend increasing lengths of time out of the pouch, feeding and learning survival skills. However, it returns to the pouch to sleep, and if danger threatens, it will seek refuge in its mother's pouch for safety.

Joeys stay in the pouch for up to a year in some species, or until the next joey is born. A marsupial joey is unable to regulate its own body temperature and relies upon an external heat source. Until the joey is well-furred and old enough to leave the pouch, a pouch temperature of must be constantly maintained.

Joeys are born with "oral shields". In species without pouches or with rudimentary pouches these are more developed than in forms with well-developed pouches, implying a role in maintaining the young attached to the mother's teat.

The first American marsupial the Europeans encountered was the common opossum. Vicente Yáñez Pinzón, commander of the "Niña" on Christopher Columbus' first voyage in the late 1400s, collected a female opossum with young in her pouch off the Brazilian coast. He presented them to the Spanish monarchs, though by then the young were lost and the female had died. The animal was noted for its strange pouch or "second belly", and how the offspring reached the pouch was a mystery.

On the other hand, it was the Portuguese who first described Australian marsupials. António Galvão, a Portuguese administrator in Ternate (1536–40), wrote a detailed account of the northern common cuscus ("Phalanger orientalis"):

From the start of the 17th century more accounts of marsupials arrived. For instance, a 1606 record of an animal, killed on the southern coast of New Guinea, described it as "in the shape of a dog, smaller than a greyhound", with a snakelike "bare scaly tail" and hanging testicles. The meat tasted like venison, and the stomach contained ginger leaves. This description appears to closely resemble the dusky pademelon ("Thylogale brunii"), in which case this would be the earliest European record of a member of the kangaroo family (Macropodidae).

The relationships among the three extant divisions of mammals (monotremes, marsupials, and placentals) were long a matter of debate among taxonomists. Most morphological evidence comparing traits such as number and arrangement of teeth and structure of the reproductive and waste elimination systems as well as most genetic and molecular evidence favors a closer evolutionary relationship between the marsupials and placental mammals than either has with the monotremes.
The ancestors of marsupials, part of a larger group called metatherians, probably split from those of placental mammals (eutherians) during the mid-Jurassic period, though no fossil evidence of metatherians themselves are known from this time. From DNA and protein analyses, the time of divergence of the two lineages has been estimated to be around 100 to 120 mya. Fossil metatherians are distinguished from eutherians by the form of their teeth; metatherians possess four pairs of molar teeth in each jaw, whereas eutherian mammals (including true placentals) never have more than three pairs. Using this criterion, the earliest known metatherian is "Sinodelphys szalayi", which lived in China around 125 mya. This makes it a contemporary to some early eutherian species which have been found in the same area. While placental fossils dominate in Asia, marsupial fossils occur in larger numbers in North America.

The oldest metatherian fossils are found in present-day China. About 100 mya, the supercontinent Pangaea was in the process of splitting into the northern continent Laurasia and the southern continent Gondwana, with what would become China and Australia already separated by the Tethys Ocean. From there, metatherians spread westward into modern North America (still attached to Eurasia), where the earliest true marsupials are found. Marsupials are difficult to distinguish from other fossils, as they are characterized by aspects of the reproductive system which do not normally fossilize (including pouches) and by subtle changes in the bone and tooth structure that show a metatherian is part of the marsupial crown group (the most exclusive group that contains all living marsupials). The earliest definite marsupial fossil belongs to the species "Peradectes minor", from the Paleocene of Montana, dated to about 65 million years ago. From their point of origin in Laurasia, marsupials spread to South America, which was possibly connected to North America at around 65 mya through a ridge that has since moved on to become the Caribbean Archipelago. Laurasian marsupials eventually died off, for not entirely clear reasons; convention has it that they disappeared due to competition with placentals, but this is no longer accepted to be the primary reason.

Marsupials, "Peradectes" and the related Herpetotheriidae are nested within a clade of metatherians that also included a variety of Cretaceous North American taxa.

In South America, the opossums evolved and developed a strong presence, and the Paleogene also saw the evolution of shrew opossums (Paucituberculata) alongside non-marsupial metatherian predators such as the borhyaenids and the saber-toothed "Thylacosmilus". South American niches for mammalian carnivores were dominated by these marsupial and sparassodont metatherians, which seem to have competitively excluded South American placentals from evolving carnivory. While placental predators were absent, the metatherians did have to contend with avian (terror bird) and terrestrial crocodylomorph competition. Marsupials were excluded in turn from large herbivore niches in South America by the presence of native placental ungulates (now extinct) and xenarthrans (whose largest forms are also extinct). South America and Antarctica remained connected until 35 mya, as shown by the unique fossils found there. North and South America were disconnected until about three million years ago, when the Isthmus of Panama formed. This led to the Great American Interchange. Sparassodonts disappeared for unclear reasons – again, this has classically assumed as competition from carnivoran placentals, but the last sparassodonts co-existed with a few small carnivorans like procyonids and canines, and disappeared long before the arrival of macropredatory forms like felines, while didelphimorphs (opossums) invaded Central America, with the Virginia opossum reaching as far north as Canada.

Marsupials reached Australia via Antarctica about 50 mya, shortly after Australia had split off. This suggests a single dispersion event of just one species, most likely a relative to South America's monito del monte (a microbiothere, the only New World australidelphian). This progenitor may have rafted across the widening, but still narrow, gap between Australia and Antarctica. The journey must not have been easy; South American ungulate and xenarthran remains have been found in Antarctica, but these groups did not reach Australia.

In Australia, marsupials radiated into the wide variety seen today, including not only omnivorous and carnivorous forms such as were present in South America, but also into large herbivores. Modern marsupials appear to have reached the islands of New Guinea and Sulawesi relatively recently via Australia. A 2010 analysis of retroposon insertion sites in the nuclear DNA of a variety of marsupials has confirmed all living marsupials have South American ancestors. The branching sequence of marsupial orders indicated by the study puts Didelphimorphia in the most basal position, followed by Paucituberculata, then Microbiotheria, and ending with the radiation of Australian marsupials. This indicates that Australidelphia arose in South America, and reached Australia after Microbiotheria split off.

In Australia, terrestrial placental mammals disappeared early in the Cenozoic (their most recent known fossils being 55 million-year-old teeth resembling those of condylarths) for reasons that are not clear, allowing marsupials to dominate the Australian ecosystem. Extant native Australian terrestrial placental mammals (such as hopping mice) are relatively recent immigrants, arriving via island hopping from Southeast Asia.

Genetic analysis suggests a divergence date between the marsupials and the placentals at . The ancestral number of chromosomes has been estimated to be 2n = 14.

A new hypothesis suggests that South American microbiotheres resulted from a back-dispersal from eastern Gondwana due to new cranial and post-cranial marsupial fossils from the "Djarthia murgonensis" from the early Eocene Tingamarra Local Fauna in Australia that indicate the "Djarthia murgonensis" is the most plesiomorphic, the oldest unequivocal australidelphian, and may be the ancestral morphotype of the Australian marsupial radiation.




</doc>
<doc id="20206" url="https://en.wikipedia.org/wiki?curid=20206" title="Manchester">
Manchester

Manchester () is a city and metropolitan borough in Greater Manchester, England. It has a population of 547,627 as of 2018 (making it the fifth-most populous English district). It lies within the United Kingdom's second-most populous urban area, with a population of 2.5 million and third-most populous metropolitan area, with a population of 3.3 million. It is fringed by the Cheshire Plain to the south, the Pennines to the north and east, and an arc of towns with which it forms a continuous conurbation. The local authority for the city is Manchester City Council.

The recorded history of Manchester began with the civilian settlement associated with the Roman fort of "Mamucium" or "Mancunium", which was established in about AD 79 on a sandstone bluff near the confluence of the rivers Medlock and Irwell. Although historically and traditionally a part of Lancashire, areas of Cheshire south of the River Mersey were incorporated into Manchester in the 20th century. The first to be included, Wythenshawe, was added to the city in 1931. Throughout the Middle Ages Manchester remained a manorial township, but began to expand "at an astonishing rate" around the turn of the 19th century. Manchester's unplanned urbanisation was brought on by a boom in textile manufacture during the Industrial Revolution, and resulted in it becoming the world's first industrialised city. Manchester achieved city status in 1853. The Manchester Ship Canal opened in 1894, creating the Port of Manchester and directly linking the city to the Irish Sea, to the west. Its fortune declined after the Second World War, owing to deindustrialisation, but the IRA bombing in 1996 led to extensive investment and regeneration. Following successful redevelopment after the IRA bombing, Manchester was the host city for the 2002 Commonwealth Games.

The city is notable for its architecture, culture, musical exports, media links, scientific and engineering output, social impact, sports clubs and transport connections. Manchester is a city of notable firsts. Manchester Liverpool Road railway station was the world's first inter-city passenger railway station and the oldest remaining railway station. The city has also excelled in scientific and engineering advancement, as it was at The University of Manchester, in 1917, that scientist Ernest Rutherford first split the atom. The university's further achievements include Frederic C. Williams, Tom Kilburn and Geoff Tootill who developed and built the world's first stored-program computer in 1948; and, in 2004, Andre Geim and Konstantin Novoselov successfully isolated and characterised the first graphene.

The name "Manchester" originates from the Latin name "Mamucium" or its variant "Mancunio" and the citizens are still referred to as Mancunians (). These names are generally thought to represent a Latinisation of an original Brittonic name. The generally accepted etymology of this name is that it comes from Brittonic *"mamm-" ("breast", in reference to a "breast-like hill"). However, more recent work suggests that it could come from *"mamma" ("mother", in reference to a local river goddess). Both usages are preserved in Insular Celtic languages, such as "mam" meaning "breast" in Irish and "mother" in Welsh. The suffix "-chester" is from Old English "ceaster" ("Roman fortification", itself a loanword from Latin "castra", "fort; fortified town").

The Brigantes were the major Celtic tribe in what is now known as Northern England; they had a stronghold in the locality at a sandstone outcrop on which Manchester Cathedral now stands, opposite the bank River Irwell. Their territory extended across the fertile lowland of what is now Salford and Stretford. Following the Roman conquest of Britain in the 1st century, General Agricola ordered the construction of a fort named Mamucium in the year 79 to ensure that Roman interests in Deva Victrix (Chester) and Eboracum (York) were protected from the Brigantes. Central Manchester has been permanently settled since this time. A stabilised fragment of foundations of the final version of the Roman fort is visible in Castlefield. The Roman habitation of Manchester probably ended around the 3rd century; its civilian settlement appears to have been abandoned by the mid-3rd century, although the fort may have supported a small garrison until the late 3rd or early 4th century. After the Roman withdrawal and Saxon conquest, the focus of settlement shifted to the confluence of the Irwell and Irk sometime before the arrival of the Normans after 1066. Much of the wider area was laid waste in the subsequent Harrying of the North.

In the doomsday book Manchester is recorded as within the hundred of Salford and held as tenant in chief by a Norman named Roger of Poitou, later being held by the family of Grelley, lord of the manor and residents of Manchester Castle until 1215 before a Manor House was built. By 1421 Thomas de la Warre founded and constructed a collegiate church for the parish, now Manchester Cathedral; the domestic premises of the college house Chetham's School of Music and Chetham's Library. The library, which opened in 1653 and is still open to the public today, is the oldest free public reference library in the United Kingdom.

Manchester is mentioned as having a market in 1282. Around the 14th century, Manchester received an influx of Flemish weavers, sometimes credited as the foundation of the region's textile industry. Manchester became an important centre for the manufacture and trade of woollens and linen, and by about 1540, had expanded to become, in John Leland's words, "The fairest, best builded, quickest, and most populous town of all Lancashire." The cathedral and Chetham's buildings are the only significant survivors of Leland's Manchester.

During the English Civil War Manchester strongly favoured the Parliamentary interest. Although not long-lasting, Cromwell granted it the right to elect its own MP. Charles Worsley, who sat for the city for only a year, was later appointed Major General for Lancashire, Cheshire and Staffordshire during the Rule of the Major Generals. He was a diligent puritan, turning out ale houses and banning the celebration of Christmas; he died in 1656.

Significant quantities of cotton began to be used after about 1600, firstly in linen/cotton fustians, but by around 1750 pure cotton fabrics were being produced and cotton had overtaken wool in importance. The Irwell and Mersey were made navigable by 1736, opening a route from Manchester to the sea docks on the Mersey. The Bridgewater Canal, Britain's first wholly artificial waterway, was opened in 1761, bringing coal from mines at Worsley to central Manchester. The canal was extended to the Mersey at Runcorn by 1776. The combination of competition and improved efficiency halved the cost of coal and halved the transport cost of raw cotton. Manchester became the dominant marketplace for textiles produced in the surrounding towns. A commodities exchange, opened in 1729, and numerous large warehouses, aided commerce. In 1780, Richard Arkwright began construction of Manchester's first cotton mill. In the early 1800s, John Dalton formulated his atomic theory in Manchester.

Manchester's history is concerned with textile manufacture during the Industrial Revolution. The great majority of cotton spinning took place in the towns of south Lancashire and north Cheshire, and Manchester was for a time the most productive centre of cotton processing.

Manchester became known as the world's largest marketplace for cotton goods and was dubbed "Cottonopolis" and "Warehouse City" during the Victorian era. In Australia, New Zealand and South Africa, the term "manchester" is still used for household linen: sheets, pillow cases, towels, etc. The industrial revolution brought about huge change in Manchester and was key to the increase in Manchester's population.

Manchester began expanding "at an astonishing rate" around the turn of the 19th century as people flocked to the city for work from Scotland, Wales, Ireland and other areas of England as part of a process of unplanned urbanisation brought on by the Industrial Revolution. It developed a wide range of industries, so that by 1835 "Manchester was without challenge the first and greatest industrial city in the world." Engineering firms initially made machines for the cotton trade, but diversified into general manufacture. Similarly, the chemical industry started by producing bleaches and dyes, but expanded into other areas. Commerce was supported by financial service industries such as banking and insurance. Trade, and feeding the growing population, required a large transport and distribution infrastructure: the canal system was extended, and Manchester became one end of the world's first intercity passenger railway—the Liverpool and Manchester Railway. Competition between the various forms of transport kept costs down. In 1878 the GPO (the forerunner of British Telecom) provided its first telephones to a firm in Manchester.

The Manchester Ship Canal was built between 1888 and 1894, in some sections by canalisation of the Rivers Irwell and Mersey, running from Salford to Eastham Locks on the tidal Mersey. This enabled oceangoing ships to sail right into the Port of Manchester. On the canal's banks, just outside the borough, the world's first industrial estate was created at Trafford Park. Large quantities of machinery, including cotton processing plant, were exported around the world.

A centre of capitalism, Manchester was once the scene of bread and labour riots, as well as calls for greater political recognition by the city's working and non-titled classes. One such gathering ended with the Peterloo massacre of 16 August 1819. The economic school of Manchester Capitalism developed there, and Manchester was the centre of the Anti-Corn Law League from 1838 onward.

Manchester has a notable place in the history of Marxism and left-wing politics; being the subject of Friedrich Engels' work "The Condition of the Working Class in England in 1844"; Engels spent much of his life in and around Manchester, and when Karl Marx visited Manchester, they met at Chetham's Library. The economics books Marx was reading at the time can be seen in the library, as can the window seat where Marx and Engels would meet. The first Trades Union Congress was held in Manchester (at the Mechanics' Institute, David Street), from 2 to 6 June 1868. Manchester was an important cradle of the Labour Party and the Suffragette Movement.

At that time, it seemed a place in which anything could happen—new industrial processes, new ways of thinking (the Manchester School, promoting free trade and "laissez-faire"), new classes or groups in society, new religious sects, and new forms of labour organisation. It attracted educated visitors from all parts of Britain and Europe. A saying capturing this sense of innovation survives today: "What Manchester does today, the rest of the world does tomorrow." Manchester's golden age was perhaps the last quarter of the 19th century. Many of the great public buildings (including Manchester Town Hall) date from then. The city's cosmopolitan atmosphere contributed to a vibrant culture, which included the Hallé Orchestra. In 1889, when county councils were created in England, the municipal borough became a county borough with even greater autonomy.

Although the Industrial Revolution brought wealth to the city, it also brought poverty and squalor to a large part of the population. Historian Simon Schama noted that "Manchester was the very best and the very worst taken to terrifying extremes, a new kind of city in the world; the chimneys of industrial suburbs greeting you with columns of smoke". An American visitor taken to Manchester's blackspots saw "wretched, defrauded, oppressed, crushed human nature, lying and bleeding fragments".

The number of cotton mills in Manchester itself reached a peak of 108 in 1853. Thereafter the number began to decline and Manchester was surpassed as the largest centre of cotton spinning by Bolton in the 1850s and Oldham in the 1860s. However, this period of decline coincided with the rise of the city as the financial centre of the region. Manchester continued to process cotton, and in 1913, 65% of the world's cotton was processed in the area. The First World War interrupted access to the export markets. Cotton processing in other parts of the world increased, often on machines produced in Manchester. Manchester suffered greatly from the Great Depression and the underlying structural changes that began to supplant the old industries, including textile manufacture.

Like most of the UK, the Manchester area was mobilised extensively during the Second World War. For example, casting and machining expertise at Beyer, Peacock and Company's locomotive works in Gorton was switched to bomb making; Dunlop's rubber works in Chorlton-on-Medlock made barrage balloons; and just outside the city in Trafford Park, engineers Metropolitan-Vickers made Avro Manchester and Avro Lancaster bombers and Ford built the Rolls-Royce Merlin engines to power them. Manchester was thus the target of bombing by the Luftwaffe, and by late 1940 air raids were taking place against non-military targets. The biggest took place during the "Christmas Blitz" on the nights of 22/23 and 24 December 1940, when an estimated of high explosives plus over 37,000 incendiary bombs were dropped. A large part of the historic city centre was destroyed, including 165 warehouses, 200 business premises, and 150 offices. 376 were killed and 30,000 houses were damaged. Manchester Cathedral, Royal Exchange and Free Trade Hall were among the buildings seriously damaged; restoration of the cathedral took 20 years.

Cotton processing and trading continued to fall in peacetime, and the exchange closed in 1968. By 1963 the port of Manchester was the UK's third largest, and employed over 3,000 men, but the canal was unable to handle the increasingly large container ships. Traffic declined, and the port closed in 1982. Heavy industry suffered a downturn from the 1960s and was greatly reduced under the economic policies followed by Margaret Thatcher's government after 1979. Manchester lost 150,000 jobs in manufacturing between 1961 and 1983.
Regeneration began in the late 1980s, with initiatives such as the Metrolink, the Bridgewater Concert Hall, the Manchester Arena, and (in Salford) the rebranding of the port as Salford Quays. Two bids to host the Olympic Games were part of a process to raise the international profile of the city.
Manchester has a history of attacks attributed to Irish Republicans, including the Manchester Martyrs of 1867, arson in 1920, a series of explosions in 1939, and two bombs in 1992.
On Saturday 15 June 1996, the Provisional Irish Republican Army (IRA) carried out the 1996 Manchester bombing, the detonation of a large bomb next to a department store in the city centre. The largest to be detonated on British soil, the bomb injured over 200 people, heavily damaged nearby buildings, and broke windows away. The cost of the immediate damage was initially estimated at £50 million, but this was quickly revised upwards. The final insurance payout was over £400 million; many affected businesses never recovered from the loss of trade.

Spurred by the investment after the 1996 bomb and aided by the XVII Commonwealth Games, the city centre has undergone extensive regeneration. New and renovated complexes such as The Printworks and Corn Exchange have become popular shopping, eating and entertainment areas. Manchester Arndale is the UK's largest city-centre shopping centre.

Large city sections from the 1960s have been demolished, re-developed or modernised with the use of glass and steel. Old mills have been converted into apartments. Hulme has undergone extensive regeneration, with million-pound loft-house apartments being developed. The 47-storey, Beetham Tower was the tallest UK building outside London and the highest residential accommodation in Europe when completed in 2006. It was surpassed in 2018 by the South Tower of the Deansgate Square project, also in Manchester. In January 2007, the independent Casino Advisory Panel licensed Manchester to build the UK's only supercasino, but plans were abandoned in February 2008.

On 22 May 2017, an Islamist terrorist carried out a bombing at an Ariana Grande concert in the Manchester Arena; the bomb killed 23, including the attacker, and injured over 800. It was the deadliest terrorist attack and first suicide bombing in Britain since the 7 July 2005 London bombings. It caused worldwide condemnation and changed the UK's threat level to "critical" for the first time since 2007.

Since around the turn of the 21st century, Manchester has been regarded as one of the candidates for the unofficial title of second city of the United Kingdom alongside Birmingham by sections of the international press, British public, and government ministers. The BBC reports that redevelopment of recent years has heightened claims that Manchester is the second city of the UK. Manchester and Birmingham traditionally compete as front runners for this unofficial title.

The City of Manchester is governed by the Manchester City Council. The Greater Manchester Combined Authority, with a directly elected mayor, has responsibilities for economic strategy and transport, amongst other areas, on a Greater Manchester-wide basis. Manchester has been a member of the English Core Cities Group since its inception in 1995.

The town of Manchester was granted a charter by Thomas Grelley in 1301, but lost its borough status in a court case of 1359. Until the 19th century local government was largely in the hands of manorial courts, the last of which was dissolved in 1846.

From a very early time, the township of Manchester lay within the historic or ceremonial county boundaries of Lancashire. Pevsner wrote "That [neighbouring] Stretford and Salford are not administratively one with Manchester is one of the most curious anomalies of England". A stroke of a baron's pen is said to have divorced Manchester and Salford, though it was not Salford that became separated from Manchester, it was Manchester, with its humbler line of lords, that was separated from Salford. It was this separation that resulted in Salford becoming the judicial seat of Salfordshire, which included the ancient parish of Manchester. Manchester later formed its own Poor Law Union using the name "Manchester". In 1792, Commissioners—usually known as "Police Commissioners"—were established for the social improvement of Manchester. Manchester regained its borough status in 1838, and comprised the townships of Beswick, Cheetham Hill, Chorlton upon Medlock and Hulme. By 1846, with increasing population and greater industrialisation, the Borough Council had taken over the powers of the "Police Commissioners". In 1853, Manchester was granted "city status" in the United Kingdom.

In 1885, Bradford, Harpurhey, Rusholme and parts of Moss Side and Withington townships became part of the City of Manchester. In 1889, the city became a county borough as did many larger Lancashire towns, and therefore not governed by Lancashire County Council. Between 1890 and 1933, more areas were added to the city which had been administered by Lancashire County Council, including former villages such as Burnage, Chorlton-cum-Hardy, Didsbury, Fallowfield, Levenshulme, Longsight, and Withington. In 1931, the Cheshire civil parishes of Baguley, Northenden and Northen Etchells from the south of the River Mersey were added. In 1974, by way of the Local Government Act 1972, the City of Manchester became a metropolitan district of the metropolitan county of Greater Manchester. That year, Ringway, the village where the Manchester Airport is located, was added to the city.

In November 2014, it was announced that Greater Manchester would receive a new directly elected Mayor. The Mayor would have fiscal control over health, transport, housing and police in the area. Andy Burnham was elected as the first Mayor of Greater Manchester in 2017.

At , northwest of London, Manchester lies in a bowl-shaped land area bordered to the north and east by the Pennines, an upland chain that runs the length of northern England, and to the south by the Cheshire Plain. Manchester is north-east of Liverpool and north-west of Sheffield, making the city the halfway point between the two. The city centre is on the east bank of the River Irwell, near its confluences with the Rivers Medlock and Irk, and is relatively low-lying, being between above sea level. The River Mersey flows through the south of Manchester. Much of the inner city, especially in the south, is flat, offering extensive views from many highrise buildings in the city of the foothills and moors of the Pennines, which can often be capped with snow in the winter months. Manchester's geographic features were highly influential in its early development as the world's first industrial city. These features are its climate, its proximity to a seaport at Liverpool, the availability of water power from its rivers, and its nearby coal reserves.

The name Manchester, though officially applied only to the metropolitan district within Greater Manchester, has been applied to other, wider divisions of land, particularly across much of the Greater Manchester county and urban area. The "Manchester City Zone", "Manchester post town" and the "Manchester Congestion Charge" are all examples of this.

For purposes of the Office for National Statistics, Manchester forms the most populous settlement within the Greater Manchester Urban Area, the United Kingdom's third-largest conurbation. There is a mix of high-density urban and suburban locations. The largest open space in the city, at around , is Heaton Park. Manchester is contiguous on all sides with several large settlements, except for a small section along its southern boundary with Cheshire. The M60 and M56 motorways pass through Northenden and Wythenshawe respectively in the south of Manchester. Heavy rail lines enter the city from all directions, the principal destination being Manchester Piccadilly station.

Manchester experiences a temperate oceanic climate (Köppen: "Cfb"), like much of the British Isles, with warm summers and cool winters. Summer daytime temperatures regularly top 20 Celsius, quite often reaching 25 Celsius on sunny days during July and August in particular. In more recent years, temperatures have occasionally reached over 30 Celsius. There is regular but generally light precipitation throughout the year. The city's average annual rainfall is compared to a UK average of , and its mean rain days are 140.4 per annum, compared to the UK average of 154.4. Manchester has a relatively high humidity level, and this, along with abundant soft water, was one factor that led to advancement of the textile industry in the area. Snowfalls are not common in the city because of the urban warming effect but the West Pennine Moors to the north-west, South Pennines to the north-east and Peak District to the east receive more snow, which can close roads leading out of the city. They include the A62 via Oldham and Standedge, the A57, Snake Pass, towards Sheffield, and the Pennine section of the M62. The lowest temperature ever recorded in Manchester was on 7 January 2010.

Manchester lies at the centre of a green belt region extending into the wider surrounding counties. This reduces urban sprawl, prevents towns in the conurbation from further convergence, protects the identity of outlying communities, and preserves nearby countryside. It is achieved by restricting inappropriate development within the designated areas and imposing stricter conditions on permitted building.

Due to being already highly urban, the city contains limited portions of protected green-belt area within greenfield throughout the borough, with minimal development opportunities, at Clayton Vale, Heaton Park, Chorlton Water Park along with the Chorlton Ees & Ivy Green nature reserve and the floodplain surrounding the River Mersey, as well as the southern area around Manchester Airport. The green belt was first drawn up in 1961.

Below are the 10 largest foreign nationalities of Manchester in 2011.

Historically the population of Manchester began to increase rapidly during the Victorian era, estimated at 354,930 for Manchester and 110,833 for Salford in 1865, and peaking at 766,311 in 1931. From then the population began to decrease rapidly, due to slum clearance and the increased building of social housing overspill estates by Manchester City Council after the Second World War such as Hattersley and Langley.

The 2012 mid-year estimate for the population of Manchester was 510,700. This was an increase of 7,900, or 1.6 per cent, since the 2011 estimate. Since 2001, the population has grown by 87,900, or 20.8 per cent, making Manchester the third fastest-growing area in the 2011 census. The city experienced the greatest percentage population growth outside London, with an increase of 19 per cent to over 500,000. Manchester's population is projected to reach 532,200 by 2021, an increase of 5.8 per cent from 2011. This represents a slower rate of growth than the previous decade.

The Greater Manchester Built-up Area in 2011 had an estimated population of 2,553,400. In 2012 an estimated 2,702,200 people lived in Greater Manchester. An 6,547,000 people were estimated in 2012 to live within of Manchester and 11,694,000 within .

Between the beginning of July 2011 and end of June 2012 (mid-year estimate date), births exceeded deaths by 4,800. Migration (internal and international) and other changes accounted for a net increase of 3,100 people between July 2011 and June 2012. Compared with Greater Manchester and with England, Manchester has a younger population, with a particularly large 20–35 age group.

There were 76,095 undergraduate and postgraduate students at Manchester Metropolitan University, the University of Manchester and Royal Northern College of Music in the 2011/2012 academic year.

Since the 2001 census, the proportion of Christians in Manchester has fallen by 22 per cent from 62.4 per cent to 48.7 per cent. The proportion of those with no religious affiliation rose by 58.1 per cent from 16 per cent to 25.3 per cent, whilst the proportion of Muslims increased by 73.6 per cent from 9.1 per cent to 15.8 per cent. The size of the Jewish population in Greater Manchester is the largest in Britain outside London.
Of all households in Manchester, 0.23 per cent were Same-Sex Civil Partnership households, compared with an English national average of 0.16 per cent in 2011.

In terms of ethnic composition, the City of Manchester has the highest non-white proportion of any district in Greater Manchester. Statistics from the 2011 census showed that 66.7 per cent of the population was White (59.3 per cent White British, 2.4 per cent White Irish, 0.1 per cent Gypsy or Irish Traveller, 4.9 per cent Other White – although the size of mixed European and British ethnic groups is unclear, there are reportedly over 25,000 Mancunians of at least partial Italian descent alone, which represents 5.5 per cent of its population). 4.7 per cent were mixed race (1.8 per cent White and Black Caribbean, 0.9 per cent White and Black African, 1.0 per cent White and Asian, 1.0 per cent other mixed), 17.1 per cent Asian (2.3 per cent Indian, 8.5 per cent Pakistani, 1.3 per cent Bangladeshi, 2.7 per cent Chinese, 2.3 per cent other Asian), 8.6 per cent Black (5.1 per cent African, 1.6 per cent other Black), 1.9 per cent Arab and 1.2 per cent of other ethnic heritage.

Kidd identifies Moss Side, Longsight, Cheetham Hill, Rusholme, as centres of population for ethnic minorities. Manchester's Irish Festival, including a St Patrick's Day parade, is one of Europe's largest. There is also a well-established Chinatown in the city with a substantial number of oriental restaurants and Chinese supermarkets. The area also attracts large numbers of Chinese students to the city who, in attending the local universities, contribute to Manchester having the third-largest Chinese population in Europe.

The Manchester Larger Urban Zone, a Eurostat measure of the functional city-region approximated to local government districts, had a population of 2,539,100 in 2004. In addition to Manchester itself, the LUZ includes the remainder of the county of Greater Manchester. The Manchester LUZ is the second largest within the United Kingdom, behind that of London.

The Office for National Statistics does not produce economic data for the City of Manchester alone, but includes four other metropolitan boroughs, Salford, Stockport, Tameside, Trafford, in an area named Greater Manchester South, which had a GVA of £34.8 billion. The economy grew relatively strongly between 2002 and 2012, when growth was 2.3 per cent above the national average. The wider metropolitan economy is the second largest in the United Kingdom. It is ranked as a beta world city by the Globalization and World Cities Research Network.

As the UK economy continues to recover from its 2008–2010 downturn, Manchester compares favourably according to recent figures. In 2012 it showed the strongest annual growth in business stock (5 per cent) of all core cities. The city had a relatively sharp increase in the number of business deaths, the largest increase in all the core cities, but this was offset by strong growth in new businesses, resulting in strong net growth.

Manchester's civic leadership has a reputation for business acumen. It owns two of the country's four busiest airports and uses its earnings to fund local projects. Meanwhile, KPMG's competitive alternative report found that in 2012 Manchester had the 9th lowest tax cost of any industrialised city in the world, and fiscal devolution has come earlier to Manchester than to any other British city: it can keep half the extra taxes it gets from transport investment.

KPMG's competitive alternative report also found that Manchester was Europe's most affordable city featured, ranking slightly better than the Dutch cities of Rotterdam and Amsterdam, which all have a cost-of-living index of less than 95.

Manchester is a city of contrast, where some of the country's most deprived and most affluent neighbourhoods can be found. According to 2010 Indices of Multiple Deprivation, Manchester is the 4th most deprived local council in England. Unemployment throughout 2012–2013 averaged 11.9 per cent, which was above national average, but lower than some of the country's comparable large cities. On the other hand, Greater Manchester is home to more multi-millionaires than anywhere outside London, with the City of Manchester taking up most of the tally. In 2013 Manchester was ranked 6th in the UK for quality of life, according to a rating of the UK's 12 largest cities.

Women fare better in Manchester than the rest of the country in comparative pay with men. The per hours-worked gender pay gap is 3.3 per cent compared with 11.1 per cent for Britain. 37 per cent of the working-age population in Manchester have degree-level qualifications, as opposed to an average of 33 per cent across other core cities, although its schools under-perform slightly compared with the national average.

Manchester has the largest UK office market outside London, according to GVA Grimley, with a quarterly office uptake (averaged over 2010–2014) of some 250,000 square ft – equivalent to the quarterly office uptake of Leeds, Liverpool and Newcastle combined and 90,000 square feet more than the nearest rival, Birmingham. The strong office market in Manchester has been partly attributed to "northshoring", (from offshoring) which entails the relocation or alternative creation of jobs away from the overheated South to areas where office space is possibly cheaper and the workforce market less saturated.

According to 2019 property investment research, Manchester is rated as No. 2 location for "Best Places To Invest in Property in the UK". This was attributed to a 5.6 per cent increase in house prices and local investment in infrastructure and in Manchester Airport.

Manchester's buildings display a variety of architectural styles, ranging from Victorian to contemporary architecture. The widespread use of red brick characterises the city, much of the architecture of which harks back to its days as a global centre for the cotton trade. Just outside the immediate city centre are a large number of former cotton mills, some of which have been left virtually untouched since their closure, while many have been redeveloped as apartment buildings and office space. Manchester Town Hall, in Albert Square, was built in the Gothic revival style and is seen as one of the most important Victorian buildings in England.

Manchester also has a number of skyscrapers built in the 1960s and 1970s, the tallest being the CIS Tower near Manchester Victoria station until the Beetham Tower was completed in 2006. The latter exemplifies a new surge in high-rise building. It includes a Hilton hotel, a restaurant and apartments. The largest skyscraper is now Deansgate Square South Tower, at 201 metres (659 feet).The Green Building, opposite Oxford Road station, is a pioneering eco-friendly housing project, while the recently completed One Angel Square, is one of the most sustainable large buildings in the world.

The award-winning Heaton Park in the north of the city borough is one of the largest municipal parks in Europe, covering of parkland. The city has 135 parks, gardens, and open spaces.

Two large squares hold many of Manchester's public monuments. Albert Square has monuments to Prince Albert, Bishop James Fraser, Oliver Heywood, William Ewart Gladstone and John Bright. Piccadilly Gardens has monuments dedicated to Queen Victoria, Robert Peel, James Watt and the Duke of Wellington. The cenotaph in St Peter's Square is Manchester's main memorial to its war dead. Designed by Edwin Lutyens, it echoes the original on Whitehall in London. The Alan Turing Memorial in Sackville Park commemorates his role as the father of modern computing. A larger-than-life statue of Abraham Lincoln by George Gray Barnard in the eponymous Lincoln Square (having stood for many years in Platt Fields) was presented to the city by Mr and Mrs Charles Phelps Taft of Cincinnati, Ohio, to mark the part Lancashire played in the cotton famine and American Civil War of 1861–1865. A Concorde is on display near Manchester Airport.

Manchester has six designated local nature reserves: Chorlton Water Park, Blackley Forest, Clayton Vale and Chorlton Ees, Ivy Green, Boggart Hole Clough and Highfield Country Park.

Manchester Liverpool Road was the world's first purpose-built passenger and goods railway station and served as the Manchester terminus on the Liverpool and Manchester Railway – the world's first inter-city passenger railway. It is still extant and its buildings form part of the Museum of Science and Industry.
Two of the city's four main line termini did not survive the 1960s: Manchester Central and Manchester Exchange each closed in 1969. In addition, Manchester Mayfield station closed to passenger services in 1960; its buildings and platforms are still extant, next to Piccadilly station, but are due to be redeveloped in the 2020s.

Today, the city is well served by its rail network although it is now working to capacity, and is at the centre of an extensive county-wide railway network, including the West Coast Main Line, with two mainline stations: Manchester Piccadilly and Manchester Victoria. The Manchester station group – comprising Manchester Piccadilly, Manchester Victoria, Manchester Oxford Road and Deansgate – is the third busiest in the United Kingdom, with 44.9 million passengers recorded in 2017/2018. The High Speed 2 link to Birmingham and London is also planned, which if built will include a tunnel under Manchester on the final approach into an upgraded Piccadilly station.

Recent improvements in Manchester as part of the Northern Hub in the 2010s have been numerous electrification schemes into and through Manchester, redevelopment of Victoria station and construction of the Ordsall Chord directly linking Victoria and Piccadilly. Work on two new through platforms at Piccadilly and an extensive upgrade at Oxford Road had not commenced as of 2019. Manchester city centre suffers from constrained rail capacity that frequently leads to delays and cancellations – a 2018 report found that all three major Manchester stations are among the top ten worst stations in the United Kingdom for punctuality, with Oxford Road deemed the worst in the country.

Manchester became the first city in the UK to acquire a modern light rail tram system when the Manchester Metrolink opened in 1992. In 2016–2017, 37.8 million passenger journeys were made on the system.<ref name="16/17DfTstats"></ref> The present system mostly runs on former commuter rail lines converted for light rail use, and crosses the city centre via on-street tram lines. The network consists of eight lines with 99 stops. A new line to the Trafford Centre opened in 2020.
Manchester city centre is also serviced by over a dozen heavy and light rail-based park and ride sites.

The city has one of the most extensive bus networks outside London, with over 50 bus companies operating in the Greater Manchester region radiating from the city. In 2011, 80 per cent of public transport journeys in Greater Manchester were made by bus, amounting to 220 million passenger journeys each year. After deregulation in 1986, the bus system was taken over by GM Buses, which after privatisation was split into GM Buses North and GM Buses South. Later these were taken over by First Greater Manchester and Stagecoach Manchester. Much of the First Greater Manchester business was sold to Diamond Bus North West and Go North West in 2019. Go North West operate a three-route zero-fare bus service, called "Metroshuttle", which carries 2.8 million commuters a year around Manchester's business districts. Stagecoach Manchester is the Stagecoach Group's largest subsidiary and operates around 690 buses.

Manchester Airport serves Manchester, Northern England and North Wales. The airport is the third busiest in the United Kingdom, with over double the number of annual passengers of the next busiest non-London airport. Services cover many destinations in Europe, North America, the Caribbean, Africa, the Middle East, and Asia (with more destinations from Manchester than any other airport in Britain). A second runway was opened in 2001 and there have been continued terminal improvements. The airport has the highest rating available: ""Category 10"", encompassing an elite group of airports able to handle ""Code F"" aircraft, including the Airbus A380 and Boeing 747-8. From September 2010 the airport became one of only 17 airports in the world and the only UK airport other than Heathrow Airport and Gatwick Airport to operate the Airbus A380.

A smaller City Airport Manchester exists to the west of Manchester city centre. It was Manchester's first municipal airport and became the site of the first air traffic control tower in the UK, and the first municipal airfield in the UK to be licensed by the Air Ministry. Today, private charter flights and general aviation use City. It also has a flight school, and both the Greater Manchester Police Air Support Unit and the North West Air Ambulance have helicopters based there.

An extensive canal network, including the Manchester Ship Canal, was built to carry freight from the Industrial Revolution onward; the canals are still maintained, though now largely repurposed for leisure use. In 2012, plans were approved to introduce a water taxi service between Manchester city centre and MediaCityUK at Salford Quays. This ceased to operate in June 2018, citing poor infrastructure.

Cycling for transportation and leisure enjoys popularity in Manchester and the city also plays a major role in British cycle racing.

Bands that have emerged from the Manchester music scene include Van der Graaf Generator, Oasis, The Smiths, Joy Division and its successor group New Order, Buzzcocks, The Stone Roses, The Fall, The Durutti Column, 10cc, Godley & Creme, The Verve, Elbow, Doves, The Charlatans, M People, The 1975, Simply Red, Take That, Dutch Uncles, Everything Everything, Pale Waves and The Outfield. Manchester was credited as the main driving force behind British indie music of the 1980s led by The Smiths, later including The Stone Roses, Happy Mondays, Inspiral Carpets, and James. The later groups came from what became known as the "Madchester" scene that also centred on The Haçienda nightclub developed by the founder of Factory Records, Tony Wilson. Although from southern England, The Chemical Brothers subsequently formed in Manchester. Former Smiths frontman Morrissey, whose lyrics often refer to Manchester locations and culture, later found international success as a solo artist. Previously, notable Manchester acts of the 1960s include The Hollies, Herman's Hermits, and Davy Jones of the Monkees (famed in the mid-1960s for their albums and their American TV show), and the earlier Bee Gees, who grew up in Chorlton. Another notable contemporary band from near Manchester is The Courteeners consisting of Liam Fray and four close friends. Singer-songwriter Ren Harvieu is also from Greater Manchester.

Manchester has two symphony orchestras, the Hallé and the BBC Philharmonic, and a chamber orchestra, the Manchester Camerata. In the 1950s, the city was home to a so-called "Manchester School" of classical composers, which was composed of Harrison Birtwistle, Peter Maxwell Davies, David Ellis and Alexander Goehr. Manchester is a centre for musical education: the Royal Northern College of Music and Chetham's School of Music. Forerunners of the RNCM were the Northern School of Music (founded 1920) and the Royal Manchester College of Music (founded 1893), which merged in 1973. One of the earliest instructors and classical music pianists/conductors at the RNCM, shortly after its founding, was the Russian-born Arthur Friedheim, (1859–1932), who later had the music library at the famed Peabody Institute conservatory of music in Baltimore, Maryland, named after him. The main classical music venue was the Free Trade Hall on Peter Street until the opening in 1996 of the 2,500 seat Bridgewater Hall.

Brass band music, a tradition in the north of England, is important to Manchester's musical heritage; some of the UK's leading bands, such as the CWS Manchester Band and the Fairey Band, are from Manchester and surrounding areas, and the Whit Friday brass-band contest takes place annually in the neighbouring areas of Saddleworth and Tameside.

Manchester has a thriving theatre, opera and dance scene, with a number of large performance venues, including Manchester Opera House, which feature large-scale touring shows and West End productions; the Palace Theatre; and the Royal Exchange Theatre in Manchester's former cotton exchange, which is the largest theatre in the round in the UK.

Smaller venues include the Contact Theatre and Z-arts in Hulme. The Dancehouse on Oxford Road is dedicated to dance productions. In 2014, HOME, a new custom-built arts complex opened. Housing two theatre spaces, five cinemas and an art exhibition space, it replaced the Cornerhouse and The Library Theatre.

Since 2007 the city has hosted the Manchester International Festival, a biennial international arts festival with a focus on original work, which has included major new commissions by artists, including Bjork. A government statement in 2014 announced a £78 million grant for a new "large-scale, ultra-flexible arts space" for the city. Later the council stated it had secured a further £32 million. The £110 million venue was confirmed in July 2016. The theatre, to be called The Factory, after Manchester's Factory Records, will provide a permanent home for the Manchester International Festival. It is due to open at the end of 2019.

Manchester's museums celebrate Manchester's Roman history, rich industrial heritage and its role in the Industrial Revolution, the textile industry, the Trade Union movement, women's suffrage and football. A reconstructed part of the Roman fort of Mamucium is open to the public in Castlefield. The Science and Industry Museum, housed in the former Liverpool Road railway station, has a large collection of steam locomotives, industrial machinery, aircraft and a replica of the world's first stored computer program (known as the Manchester Baby). The Museum of Transport displays a collection of historic buses and trams. Trafford Park in the neighbouring borough of Trafford is home to Imperial War Museum North. The Manchester Museum opened to the public in the 1880s, has notable Egyptology and natural history collections.
The municipally owned Manchester Art Gallery in Mosley Street houses a permanent collection of European painting and one of Britain's main collections of Pre-Raphaelite paintings.

In the south of the city, the Whitworth Art Gallery displays modern art, sculpture and textiles and was voted Museum of the Year in 2015. Other exhibition spaces and museums in Manchester include Islington Mill in Salford, the National Football Museum at Urbis, Castlefield Gallery, the Manchester Costume Gallery at Platt Fields Park, the People's History Museum and the Manchester Jewish Museum.

The work of Stretford-born painter , known for "matchstick" paintings of industrial Manchester and Salford, can be seen in the City and Whitworth Manchester galleries, and at the Lowry art centre in Salford Quays (in the neighbouring borough of Salford), which devotes a large permanent exhibition to his works.

Manchester is a UNESCO City of Literature known for a "radical literary history". Manchester in the 19th century featured in works highlighting the changes that industrialisation had brought. They include Elizabeth Gaskell's novel "Mary Barton: A Tale of Manchester Life" (1848), and studies such as "The Condition of the Working Class in England in 1844" by Friedrich Engels, while living and working here. Manchester was the meeting place of Engels and Karl Marx. The two began writing "The Communist Manifesto" in Chetham's Library – founded in 1653 and claiming to be the oldest public library in the English-speaking world. Elsewhere in the city, the John Rylands Library holds an extensive collection of early printing. The Rylands Library Papyrus P52, believed to be the earliest extant New Testament text, is on permanent display there.
Letitia Landon's poem "Manchester" in Fisher's Drawing Room Scrap Book, 1835, records the rapid growth of the city and its cultural importance.

Charles Dickens is reputed to have set his novel "Hard Times" in the city, and though partly modelled on Preston, it shows the influence of his friend Mrs Gaskell. Gaskell penned all her novels but "Mary Barton" at her home in 84 Plymouth Grove. Often her house played host to influential authors: Dickens, Charlotte Brontë, Harriet Beecher Stowe and Charles Eliot Norton, for example. It is now open as a literary museum.

Charlotte Brontë began writing her novel "Jane Eyre" in 1846, while staying at lodgings in Hulme. She was accompanying her father Patrick, who was convalescing in the city after cataract surgery. She probably envisioned Manchester Cathedral churchyard as the burial place for Jane's parents and the birthplace of Jane herself. Also associated with the city is the Victorian poet and novelist Isabella Banks, famed for her 1876 novel "The Manchester Man". Anglo-American author Frances Hodgson Burnett was born in the city's Cheetham Hill district in 1849, and wrote much of her classic children's novel "The Secret Garden" while visiting nearby Salford's Buile Hill Park.

Anthony Burgess is among the 20th-century writers who made Manchester their home. He wrote here the dystopian satire "A Clockwork Orange" in 1962. Dame Carol Ann Duffy, Poet Laureate from 2009 to 2019, moved to the city in 1996 and lives in West Didsbury.

The night-time economy of Manchester has expanded significantly since about 1993, with investment from breweries in bars, public houses and clubs, along with active support from the local authorities. The more than 500 licensed premises in the city centre have a capacity to deal with more than visitors, with 110,000–130,000 people visiting on a typical weekend night, making Manchester the most popular city for events at 79 per thousand people. The night-time economy has a value of about £100 million. and supports 12,000 jobs.

The Madchester scene of the 1980s, from which groups including The Stone Roses, the Happy Mondays, Inspiral Carpets, 808 State, James and The Charlatans emerged, was based around clubs such as The Hacienda. The period was the subject of the movie "24 Hour Party People". Many of the big clubs suffered problems with organised crime at that time; Haslam describes one where staff were so completely intimidated that free admission and drinks were demanded (and given) and drugs were openly dealt. Following a series of drug-related violent incidents, The Hacienda closed in 1997.
Public houses in the Canal Street area have had an LGBTQ+ clientele since at least 1940, and now form the centre of Manchester's LGBTQ+ community. Since the opening of new bars and clubs, the area attracts 20,000 visitors each weekend and has hosted a popular festival, Manchester Pride, each August since 1995.

There are three universities in the City of Manchester. The University of Manchester, Manchester Metropolitan University and Royal Northern College of Music. The University of Manchester is the largest full-time non-collegiate university in the United Kingdom, created in 2004 by the merger of Victoria University of Manchester, founded in 1904, and UMIST, founded in 1956 having developed from the Mechanics' Institute founded, as indicated in the university's logo, in 1824. The University of Manchester includes the Manchester Business School, which offered the first MBA course in the UK in 1965.

Manchester Metropolitan University was formed as Manchester Polytechnic on the merger of three colleges in 1970. It gained university status in 1992, and in the same year absorbed Crewe and Alsager College of Higher Education in South Cheshire. The University of Law, the largest provider of vocation legal training in Europe, has a campus in the city.

The three universities are grouped around Oxford Road on the southern side of the city centre, which forms Europe's largest urban higher-education precinct. Together they have a combined population of 76,025 students in higher education as of 2015, although almost 6,000 of them were based at Manchester Metropolitan University's campuses at Crewe and Alsager in Cheshire.

One of Manchester's notable secondary schools is Manchester Grammar School. Established in 1515, as a free grammar school next to what is now the cathedral, it moved in 1931 to Old Hall Lane in Fallowfield, south Manchester, to accommodate the growing student body. In the post-war period, it was a direct grant grammar school (i.e. partially state funded), but it reverted to independent status in 1976 after abolition of the direct-grant system. Its previous premises are now used by Chetham's School of Music. There are three schools nearby: William Hulme's Grammar School, Withington Girls' School and Manchester High School for Girls.

In 2010, the Manchester Local Education Authority was ranked last out of Greater Manchester's ten LEAs and 147th out of 150 in the country LEAs based on the percentage of pupils attaining at least five A*–C grades at General Certificate of Secondary Education (GCSE) including maths and English (38.6 per cent compared with the national average of 50.7 per cent). The LEA also had the highest occurrence of absences: 11.11 per cent of "half-day sessions missed by pupils", well above the national average of 5.8 per cent. Of the schools in the LEA with 30 or more pupils, four had 90 per cent or more pupils achieving at least five A*–C grades at GCSE including maths and English: Manchester High School for Girls, St Bede's College, Manchester Islamic High School for Girls, and The King David High School. Three managed 25 per cent or less: Plant Hill Arts College, North Manchester High School for Boys, Brookway High School and Sports College.

Manchester is well known as a city of sport. Two decorated Premier League football clubs bear the city name – Manchester United and Manchester City. Manchester United play its home games at Old Trafford, in the Manchester suburb of Trafford, the largest club football ground in the United Kingdom. Manchester City's home ground is the City of Manchester Stadium (also known as the Etihad Stadium for sponsorship purposes); its former ground, Maine Road was demolished in 2003. The City of Manchester Stadium was initially built as the main athletics stadium for the 2002 Commonwealth Games and was then reconfigured into a football stadium before Manchester City's arrival. Manchester has hosted domestic, continental and international football competitions at Fallowfield Stadium, Maine Road, Old Trafford and the City of Manchester Stadium. Competitions hosted in city include the FIFA World Cup (1966), UEFA European Football Championship (1996), Olympic Football (2012), UEFA Champions League Final (2003), UEFA Cup Final (2008), four FA Cup Finals (1893, 1911, 1915, 1970) and three League Cup Finals (1977, 1978, 1984).

First-class sporting facilities were built for the 2002 Commonwealth Games, including the City of Manchester Stadium, the National Squash Centre and the Manchester Aquatics Centre. Manchester has competed twice to host the Olympic Games, beaten by Atlanta for 1996 and Sydney for 2000. The National Cycling Centre includes a velodrome, BMX Arena and Mountainbike trials, and is the home of British Cycling, UCI ProTeam Team Sky and Sky Track Cycling. The Manchester Velodrome was built as a part of the bid for the 2000 games and has become a catalyst for British success in cycling. The velodrome hosted the UCI Track Cycling World Championships for a record third time in 2008. The National Indoor BMX Arena (2,000 capacity) adjacent to the velodrome opened in 2011. The Manchester Arena hosted the FINA World Swimming Championships in 2008. Manchester Cricket Club evolved into Lancashire County Cricket Club and play at Old Trafford Cricket Ground, as do Manchester Originals, a new city-based cricket team founded in 2019 which will play in the new cricket competition The Hundred, representing Lancashire and Manchester. Manchester also hosted the World Squash Championships in 2008, and also hosted the 2010 World Lacrosse Championship in July 2010. Recent sporting events hosted by Manchester include the 2013 Ashes series, 2013 Rugby League World Cup and the 2015 Rugby World Cup.

"The Guardian" newspaper was founded in the city in 1821 as "The Manchester Guardian". Until 2008, its head office was still in the city, though many of its management functions were moved to London in 1964. For many years most national newspapers had offices in Manchester: "The Daily Telegraph", "Daily Express", "Daily Mail", "Daily Mirror", "The Sun". At its height, 1,500 journalists were employed, earning the city the nickname "second Fleet Street". In the 1980s the titles closed their northern offices and centred their operations in London.

The main regional newspaper in the city is the "Manchester Evening News", which was for over 80 years the sister publication of "The Manchester Guardian". The "Manchester Evening News" has the largest circulation of a UK regional evening newspaper and is distributed free of charge in the city centre on Thursdays and Fridays, but paid for in the suburbs. Despite its title, it is available all day. 

Several local weekly free papers are distributed by the MEN group. The "Metro North West" is available free at Metrolink stops, rail stations and other busy locations. 

An attempt to launch a Northern daily newspaper, the "North West Times", employing journalists made redundant by other titles, closed in 1988. Another attempt was made with the "North West Enquirer", which hoped to provide a true "regional" newspaper for the North West, much in the same vein as the "Yorkshire Post" does for Yorkshire or "The Northern Echo" does for the North East; it folded in October 2006.

Manchester has been a centre of television broadcasting since the 1950s. A number of television studios have been in operation around the city, and have since relocated to MediaCityUK in neighbouring Salford.

The ITV franchise Granada Television has been based in Manchester since 1954. Now based at MediaCityUK, the company's former headquarters at Granada Studios on Quay Street with its distinctive illuminated sign were a prominent landmark on the Manchester skyline for several decades. Granada produces "Coronation Street," local news and programmes for North West England. Although its influence has waned, Granada had been described as "the best commercial television company in the world".

With the growth in regional television in the 1950s, Manchester became one of the BBC's three main centres in England. In 1954, the BBC opened its first regional BBC Television studio outside London, Dickenson Road Studios, in a converted Methodist chapel in Rusholme. The first edition of "Top of the Pops" was broadcast here on New Year's Day 1964. 
From 1975, BBC programmes including "Mastermind", and "Real Story", were made at New Broadcasting House on Oxford Road. The "Cutting It" series set in the city's Northern Quarter and "The Street" were set in Manchester as was "Life on Mars". Manchester was the regional base for BBC One North West Region programmes before it relocated to MediaCityUK in nearby Salford Quays. 

The Manchester television channel, Channel M, owned by the Guardian Media Group operated from 2000, but closed in 2012. Manchester is also covered by two internet television channels: Quays News and Manchester.tv. The city had a new terrestrial channel from January 2014 when YourTV Manchester, which won the OFCOM licence bid in February 2013. It began its first broadcast, but in 2015, That's Manchester took over to air on 31 May and launched the freeview channel 8 service slot, before moving to channel 7 in April 2016.

The city has the highest number of local radio stations outside London, including BBC Radio Manchester, Hits Radio Manchester, Capital Manchester, Greatest Hits Manchester, Heart North West, Smooth North West, Gold, 96.2 The Revolution, NMFM (North Manchester FM) and XS Manchester. Student radio stations include Fuse FM at the University of Manchester and MMU Radio at the Manchester Metropolitan University. A community radio network is coordinated by Radio Regen, with stations covering Ardwick, Longsight and Levenshulme (All FM 96.9) and Wythenshawe (Wythenshawe FM 97.2). Defunct radio stations include Sunset 102, which became Kiss 102, then Galaxy Manchester), and KFM which became Signal Cheshire (now Imagine FM). These stations and pirate radio played a significant role in the city's house music culture, the Madchester scene.

Manchester has formal twinning arrangements (or "friendship agreements") with several places. In addition, the British Council maintains a metropolitan centre in Manchester.

Manchester is home to the largest group of consuls in the UK outside London. The expansion of international trade links during the Industrial Revolution led to the introduction of the first consuls in the 1820s and since then over 800, from all parts of the world, have been based in Manchester. Manchester hosts consular services for most of the north of England.






</doc>
<doc id="20208" url="https://en.wikipedia.org/wiki?curid=20208" title="Margaret Murray">
Margaret Murray

Margaret Alice Murray (13 July 1863 – 13 November 1963) was an Anglo-Indian Egyptologist, archaeologist, anthropologist, historian, and folklorist. The first woman to be appointed as a lecturer in archaeology in the United Kingdom, she worked at University College London (UCL) from 1898 to 1935. She served as President of the Folklore Society from 1953 to 1955, and published widely over the course of her career.

Born to a wealthy middle-class English family in Calcutta, British India, Murray divided her youth between India, Britain, and Germany, training as both a nurse and a social worker. Moving to London, in 1894 she began studying Egyptology at UCL, developing a friendship with department head Flinders Petrie, who encouraged her early academic publications and appointed her Junior Professor in 1898. In 1902–03 she took part in Petrie's excavations at Abydos, Egypt, there discovering the Osireion temple and the following season investigated the Saqqara cemetery, both of which established her reputation in Egyptology. Supplementing her UCL wage by giving public classes and lectures at the British Museum and Manchester Museum, it was at the latter in 1908 that she led the unwrapping of Khnum-nakht, one of the mummies recovered from the Tomb of the Two Brothers – the first time that a woman had publicly unwrapped a mummy. Recognising that British Egyptomania reflected the existence of a widespread public interest in Ancient Egypt, Murray wrote several books on Egyptology targeted at a general audience.

Murray also became closely involved in the first-wave feminist movement, joining the Women's Social and Political Union and devoting much time to improving women's status at UCL. Unable to return to Egypt due to the First World War, she focused her research on the witch-cult hypothesis, the theory that the witch trials of Early Modern Christendom were an attempt to extinguish a surviving pre-Christian, pagan religion devoted to a Horned God. Although later academically discredited, the theory gained widespread attention and proved a significant influence on the emerging new religious movement of Wicca. From 1921 to 1931 Murray undertook excavations of prehistoric sites on Malta and Menorca and developed her interest in folkloristics. Awarded an honorary doctorate in 1927, she was appointed Assistant Professor in 1928 and retired from UCL in 1935. That year she visited Palestine to aid Petrie's excavation of Tall al-Ajjul and in 1937 she led a small excavation at Petra in Jordan. Taking on the presidency of the Folklore Society in later life, she lectured at such institutions as the University of Cambridge and City Literary Institute, and continued to publish in an independent capacity until her death.

Murray's work in Egyptology and archaeology was widely acclaimed and earned her the moniker of "The Grand Old Woman of Egyptology", although after her death many of her contributions to the field were overshadowed by those of Petrie. Conversely, Murray's work in folkloristics and the history of witchcraft has been academically discredited and her methods in these areas heavily criticised. The influence of her witch-cult theory in both religion and literature has been examined by various scholars, and she herself has been dubbed the "Grandmother of Wicca".

Margaret Murray was born on 13 July 1863 in Calcutta, Bengal Presidency, then a major military city in British India. A member of the wealthy British imperial elite, she lived in the city with her family: parents James and Margaret Murray, an older sister named Mary, and her paternal grandmother and great-grandmother. James Murray, born in India of English descent, was a businessman and manager of the Serampore paper mills who was thrice elected President of the Calcutta Chamber of Commerce. His wife, Margaret (née Carr), had moved to India from Britain in 1857 to work as a missionary, preaching Christianity and educating Indian women. She continued with this work after marrying James and giving birth to her two daughters.
Although most of their lives were spent in the European area of Calcutta, which was walled off from the indigenous sectors of the city, Murray encountered members of indigenous society through her family's employment of 10 Indian servants and through childhood holidays to Mussoorie. The historian Amara Thornton has suggested that Murray's Indian childhood continued to exert an influence over her throughout her life, expressing the view that Murray could be seen as having a hybrid transnational identity that was both British and Indian. During her childhood, Murray never received a formal education, and in later life expressed pride in the fact that she had never had to sit an exam before entering university.

In 1870, Margaret and her sister Mary were sent to Britain, there moving in with their uncle John, a vicar, and his wife Harriet at their home in Lambourn, Berkshire. Although John provided them with a strongly Christian education and a belief in the inferiority of women, both of which she would reject, he awakened Murray's interest in archaeology through taking her to see local monuments. In 1873, the girls' mother arrived in Europe and took them with her to Bonn in Germany, where they both became fluent in German. In 1875 they returned to Calcutta, staying there till 1877. They then moved with their parents back to England, where they settled in Sydenham, South London. There, they spent much time visiting The Crystal Palace, while their father worked at his firm's London office. In 1880, they returned to Calcutta, where Margaret remained for the next seven years. She became a nurse at the Calcutta General Hospital, which was run by the Sisters of the Anglican Sisterhood of Clower, and there was involved with the hospital's attempts to deal with a cholera outbreak. In 1887, she returned to England, moving to Rugby, Warwickshire, where her uncle John had moved, now widowed. Here she took up employment as a social worker dealing with local underprivileged people. When her father retired and moved to England, she moved into his house in Bushey Heath, Hertfordshire, living with him until his death in 1891. In 1893 she then travelled to Madras, Tamil Nadu, where her sister had moved to with her new husband.

Encouraged by her mother and sister, Murray decided to enroll at the newly opened department of Egyptology at University College London (UCL) in Bloomsbury, Central London. Having been founded by an endowment from Amelia Edwards, one of the co-founders of the Egypt Exploration Fund (EEF), the department was run by the pioneering early archaeologist Sir William Flinders Petrie, and based in the Edwards Library of UCL's South Cloisters. Murray began her studies at UCL at age 30 in January 1894, as part of a class composed largely of other women and older men. There, she took courses in the Ancient Egyptian and Coptic languages which were taught by Francis Llewellyn Griffith and Walter Ewing Crum respectively.

Murray soon got to know Petrie, becoming his copyist and illustrator and producing the drawings for the published report on his excavations at Qift, "Koptos". In turn, he aided and encouraged her to write her first research paper, "The Descent of Property in the Early Periods of Egyptian History", which was published in the "Proceedings of the Society for Biblical Archaeology" in 1895. Becoming Petrie's "de facto" though unofficial assistant, Murray began to give some of the linguistic lessons in Griffith's absence. In 1898 she was appointed to the position of Junior Lecturer, responsible for teaching the linguistic courses at the Egyptology department; this made her the first female lecturer in archaeology in the United Kingdom. In this capacity, she spent two days a week at UCL, devoting the other days to caring for her ailing mother. As time went on, she came to teach courses on Ancient Egyptian history, religion, and language. Among Murray's students – to whom she referred as "the Gang" – were several who went on to produce noted contributions to Egyptology, including Reginald Engelbach, Georgina Aitken, Guy Brunton, and Myrtle Broome. She supplemented her UCL salary by teaching evening classes in Egyptology at the British Museum.

At this point, Murray had no experience in field archaeology, and so during the 1902–03 field season, she travelled to Egypt to join Petrie's excavations at Abydos. Petrie and his wife, Hilda Petrie, had been excavating at the site since 1899, having taken over the archaeological investigation from French Coptic scholar Émile Amélineau. Murray at first joined as site nurse, but was subsequently taught how to excavate by Petrie and given a senior position. This led to some issues with some of the male excavators, who disliked the idea of taking orders from a woman. This experience, coupled with discussions with other female excavators (some of whom were active in the feminist movement) led Murray to adopt openly feminist viewpoints. While excavating at Abydos, Murray uncovered the Osireion, a temple devoted to the god Osiris which had been constructed by order of Pharaoh Seti I during the period of the New Kingdom. She published her site report as "The Osireion at Abydos" in 1904; in the report, she examined the inscriptions that had been discovered at the site to discern the purpose and use of the building.

During the 1903–04 field season, Murray returned to Egypt, and at Petrie's instruction began her investigations at the Saqqara cemetery near to Cairo, which dated from the period of the Old Kingdom. Murray did not have legal permission to excavate the site, and instead spent her time transcribing the inscriptions from ten of the tombs that had been excavated during the 1860s by Auguste Mariette. She published her findings in 1905 as "Saqqara Mastabas I", although would not publish translations of the inscriptions until 1937 as "Saqqara Mastabas II". Both "The Osireion at Abydos" and "Saqqara Mastabas I" proved to be very influential in the Egyptological community, with Petrie recognising Murray's contribution to his own career.

On returning to London, Murray took an active role in the feminist movement, volunteering and financially donating to the cause and taking part in feminist demonstrations, protests, and marches. Joining the Women's Social and Political Union, she was present at large marches like the Mud March of 1907 and the Women's Coronation Procession of June 1911. She concealed the militancy of her actions in order to retain the image of respectability within academia. Murray also pushed the professional boundaries for women throughout her own career, and mentored other women in archaeology and throughout academia. As women could not use the men's common room, she successfully campaigned for UCL to open a common room for women, and later ensured that a larger, better-equipped room was converted for the purpose; it was later renamed the Margaret Murray Room. At UCL, she became a friend of fellow female lecturer Winifred Smith, and together they campaigned to improve the status and recognition of women in the university, with Murray becoming particularly annoyed at female staff who were afraid of upsetting or offending the male university establishment with their demands. Feeling that students should get nutritious yet affordable lunches, for many years she sat on the UCL Refectory Committee.

Various museums around the United Kingdom invited Murray to advise them on their Egyptological collections, resulting in her cataloguing the Egyptian artefacts owned by the Dublin National Museum, the National Museum of Antiquities in Edinburgh, and the Society of Antiquaries of Scotland, being elected a Fellow of the latter in thanks.
Petrie had established connections with the Egyptological wing of Manchester Museum in Manchester, and it was there that many of his finds had been housed. Murray thus often travelled to the museum to catalogue these artefacts, and during the 1906–07 school year regularly lectured there. In 1907, Petrie excavated the Tomb of the Two Brothers, a Middle Kingdom burial of two Egyptian priests, Nakht-ankh and Khnum-nakht, and it was decided that Murray would carry out the public unwrapping of the latter's mummified body. Taking place at the museum in May 1908, it represented the first time that a woman had led a public mummy unwrapping and was attended by over 500 onlookers, attracting press attention. Murray was particularly keen to emphasise the importance that the unwrapping would have for the scholarly understanding of the Middle Kingdom and its burial practices, and lashed out against members of the public who saw it as immoral; she declared that "every vestige of ancient remains must be carefully studied and recorded without sentimentality and without fear of the outcry of the ignorant". She subsequently published a book about her analysis of the two bodies, "The Tomb of the Two Brothers", which remained a key publication on Middle Kingdom mummification practices into the 21st century.
Murray was dedicated to public education, hoping to infuse Egyptomania with solid scholarship about Ancient Egypt, and to this end authored a series of books aimed at a general audience. In 1905 she published "Elementary Egyptian Grammar" which was followed in 1911 by "Elementary Coptic (Sahidic) Grammar". In 1913, she published "Ancient Egyptian Legends" for John Murray's "The Wisdom of the East" series. She was particularly pleased with the increased public interest in Egyptology that followed Howard Carter's discovery of the tomb of Pharaoh Tutankhamun in 1922. From at least 1911 until his death in 1940, Murray was a close friend of the anthropologist Charles Gabriel Seligman of the London School of Economics, and together they co-authored a variety of papers on Egyptology that were aimed at an anthropological audience. Many of these dealt with subjects that Egyptological journals would not publish, such as the "Sa" sign for the uterus, and thus were published in "Man", the journal of the Royal Anthropological Institute. It was at Seligman's recommendation that she was invited to become a member of the Institute in 1916.

In 1914, Petrie launched the academic journal "Ancient Egypt", published through his own British School of Archaeology in Egypt (BSAE), which was based at UCL. Given that he was often away from London excavating in Egypt, Murray was left to operate as "de facto" editor much of the time. She also published many research articles in the journal and authored many of its book reviews, particularly of the German-language publications which Petrie could not read.

The outbreak of the First World War in 1914, in which the United Kingdom went to war against Germany and the Ottoman Empire, meant that Petrie and other staff members were unable to return to Egypt for excavation. Instead, Petrie and Murray spent much of the time reorganising the artefact collections that they had attained over the past decades. To aid Britain's war effort, Murray enrolled as a volunteer nurse in the Volunteer Air Detachment of the College Women's Union Society, and for several weeks was posted to Saint-Malo in France. After being taken ill herself, she was sent to recuperate in Glastonbury, Somerset, where she became interested in Glastonbury Abbey and the folklore surrounding it which connected it to the legendary figure of King Arthur and to the idea that the Holy Grail had been brought there by Joseph of Aramathea. Pursuing this interest, she published the paper "Egyptian Elements in the Grail Romance" in the journal "Ancient Egypt", although few agreed with her conclusions and it was criticised for making unsubstantiated leaps with the evidence by the likes of Jessie Weston.

Murray's interest in folklore led her to develop an interest in the witch trials of Early Modern Europe. In 1917, she published a paper in "Folklore", the journal of the Folklore Society, in which she first articulated her version of the witch-cult theory, arguing that the witches persecuted in European history were actually followers of "a definite religion with beliefs, ritual, and organization as highly developed as that of any cult in the end". She followed this up with papers on the subject in the journals "Man" and the "Scottish Historical Review". She articulated these views more fully in her 1921 book "The Witch-Cult in Western Europe", published by Oxford University Press after receiving a positive peer review by Henry Balfour, and which received both criticism and support on publication. Many reviews in academic journals were critical, with historians claiming that she had distorted and misinterpreted the contemporary records that she was using, but the book was nevertheless influential.
As a result of her work in this area, she was invited to provide the entry on "witchcraft" for the fourteenth edition of the "Encyclopædia Britannica" in 1929. She used the opportunity to propagate her own witch-cult theory, failing to mention the alternate theories proposed by other academics. Her entry would be included in the encyclopedia until 1969, becoming readily accessible to the public, and it was for this reason that her ideas on the subject had such a significant impact. It received a particularly enthusiastic reception by occultists such as Dion Fortune, Lewis Spence, Ralph Shirley, and J. W. Brodie Innes, perhaps because its claims regarding an ancient secret society chimed with similar claims common among various occult groups. Murray joined the Folklore Society in February 1927, and was elected to the society's council a month later, although she stood down in 1929. Murray reiterated her witch-cult theory in her 1933 book, "The God of the Witches", which was aimed at a wider, non-academic audience. In this book, she cut out or toned down what she saw as the more unpleasant aspects of the witch-cult, such as animal and child sacrifice, and began describing the religion in more positive terms as "the Old Religion".

From 1921 to 1927, Murray led archaeological excavations on Malta, assisted by Edith Guest and Gertrude Caton Thompson. She excavated the Bronze Age megalithic monuments of Santa Sofia, Santa Maria tal-Bakkari, Għar Dalam, and Borġ in-Nadur, all of which were threatened by the construction of a new aerodrome. In this she was funded by the Percy Sladen Memorial Fund. Her resulting three-volume excavation report came to be seen as an important publication within the field of Maltese archaeology. During the excavations, she had taken an interest in the island's folklore, resulting in the 1932 publication of her book "Maltese Folktales", much of which was a translation of earlier stories collected by Manuel Magri and her friend Liza Galea. In 1932 Murray returned to Malta to aid in the cataloguing of the Bronze Age pottery collection held in Malta Museum, resulting in another publication, "Corpus of the Bronze Age Pottery of Malta".

On the basis of her work in Malta, Louis C. G. Clarke, the curator of the Cambridge Museum of Ethnology and Anthropology, invited her to lead excavations on the island of Menorca from 1930 to 1931. With the aid of Guest, she excavated the talaiotic sites of Trepucó and Sa Torreta de Tramuntana, resulting in the publication of "Cambridge Excavations in Minorca". Murray also continued to publish works on Egyptology for a general audience, such as "Egyptian Sculpture" (1930) and "Egyptian Temples" (1931), which received largely positive reviews. In the summer of 1925 she led a team of volunteers to excavate Homestead Moat in Whomerle Wood near to Stevenage, Hertfordshire; she did not publish an excavation report and did not mention the event in her autobiography, with her motives for carrying out the excavation remaining unclear.

In 1924, UCL promoted Murray to the position of assistant professor, and in 1927 she was awarded an honorary doctorate for her career in Egyptology. That year, Murray was tasked with guiding Mary of Teck, the Queen consort, around the Egyptology department during the latter's visit to UCL. The pressures of teaching had eased by this point, allowing Murray to spend more time travelling internationally; in 1920 she returned to Egypt and in 1929 visited South Africa, where she attended the meeting of the British Association for the Advancement of Science, whose theme was the prehistory of southern Africa. In the early 1930s she travelled to the Soviet Union, where she visited museums in Leningrad, Moscow, Kharkiv, and Kiev, and then in late 1935 she undertook a lecture tour of Norway, Sweden, Finland, and Estonia.
Although having reached legal retirement age in 1927, and thus unable to be offered another five-year contract, Murray was reappointed on an annual basis each year until 1935. At this point, she retired, expressing the opinion that she was glad to leave UCL, for reasons that she did not make clear. In 1933, Petrie had retired from UCL and moved to Jerusalem in Mandatory Palestine with his wife; Murray therefore took over as editor of the "Ancient Egypt" journal, renaming it "Ancient Egypt and the East" to reflect its increasing research interest in the ancient societies that surrounded and interacted with Egypt. The journal folded in 1935, perhaps due to Murray's retirement. Murray then spent some time in Jerusalem, where she aided the Petries in their excavation at Tall al-Ajjul, a Bronze Age mound south of Gaza.

During Murray's 1935 trip to Palestine, she had taken the opportunity to visit Petra in neighbouring Jordan. Intrigued by the site, in March and April 1937 she returned in order to carry out a small excavation in several cave dwellings at the site, subsequently writing both an excavation report and a guidebook on Petra. Back in England, from 1934 to 1940, Murray aided the cataloguing of Egyptian antiquities at Girton College, Cambridge, and also gave lectures in Egyptology at the university until 1942.
During the Second World War, Murray evaded the Blitz of London by moving to Cambridge, where she volunteered for a group (probably the Army Bureau of Current Affairs or The British Way and Purpose) who educated military personnel to prepare them for post-war life. Based in the city, she embarked on research into the town's Early Modern history, examining documents stored in local parish churches, Downing College, and Ely Cathedral; she never published her findings. In 1945, she briefly became involved in the "Who put Bella in the Wych Elm?" murder case.

After the war ended she returned to London, settling into a bedsit room in Endsleigh Street, which was close to University College London (UCL) and the Institute of Archaeology (then an independent institution, now part of UCL); she continued her involvement with the former and made use of the latter's library. On most days she visited the British Museum in order to consult their library, and twice a week she taught adult education classes on Ancient Egyptian history and religion at the City Literary Institute; upon her retirement from this position she nominated her former pupil, Veronica Seton-Williams, to replace her.

Murray's interest in popularising Egyptology among the wider public continued; in 1949 she published "Ancient Egyptian Religious Poetry", her second work for John Murray's "The Wisdom of the East" series. That same year she also published "The Splendour That Was Egypt", in which she collated many of her UCL lectures. The book adopted a diffusionist perspective that argued that Egypt influenced Greco-Roman society and thus modern Western society. This was seen as a compromise between Petrie's belief that other societies influenced the emergence of Egyptian civilisation and Grafton Elliot Smith's highly unorthodox and heavily criticised hyperdiffusionist view that Egypt was the source of all global civilisation. The book received a mixed reception from the archaeological community.

In 1953, Murray was appointed to the presidency of the Folklore Society following the resignation of former president Allan Gomme. The Society had initially approached John Mavrogordato for the post, but he had declined, with Murray accepting the nomination several months later. Murray remained President for two terms, until 1955. In her 1954 presidential address, "England as a Field for Folklore Research", she lamented what she saw as the English people's disinterest in their own folklore in favour of that from other nations. For the autumn 1961 issue of "Folklore", the society published a "festschrift" to Murray to commemorate her 98th birthday. The issue contained contributions from various scholars paying tribute to her – with papers dealing with archaeology, fairies, Near Eastern religious symbols, Greek folk songs – but notably not about witchcraft, potentially because no other folklorists were willing to defend her witch-cult theory.

In May 1957, Murray had championed the archaeologist T. C. Lethbridge's controversial claims that he had discovered three pre-Christian chalk hill figures on Wandlebury Hill in the Gog Magog Hills, Cambridgeshire. Privately she expressed concern about the reality of the figures. Lethbridge subsequently authored a book championing her witch-cult theory in which he sought the cult's origins in pre-Christian culture. In 1960, she donated her collection of papers – including correspondences with a wide range of individuals across the country – to the Folklore Society Archive, where it is now known as "the Murray Collection".

Crippled with arthritis, Murray had moved into a home in North Finchley, north London, where she was cared for by a retired couple who were trained nurses; from here she occasionally took taxis into central London to visit the UCL library.
Amid failing health, in 1962 Murray moved into the Queen Victoria Memorial Hospital in Welwyn, Hertfordshire, where she could receive 24-hour care; she lived here for the final 18 months of her life. To mark her hundredth birthday, on 13 July 1963 a group of her friends, former students, and doctors gathered for a party at nearby Ayot St. Lawrence. Two days later, her doctor drove her to UCL for a second birthday party, again attended by many of her friends, colleagues, and former students; it was the last time that she visited the university. In "Man", the journal of the Royal Anthropological Institute, it was noted that Murray was "the only Fellow of the Institute to [reach their centenary] within living memory, if not in its whole history". That year she published two books; one was "The Genesis of Religion", in which she argued that humanity's first deities had been goddesses rather than male gods. The second was her autobiography, "My First Hundred Years", which received predominantly positive reviews. She died on 13 November 1963, and her body was cremated.

The later folklorists Caroline Oates and Juliette Wood have suggested that Murray was best known for her witch-cult theory, with biographer Margaret S. Drower expressing the view that it was her work on this subject which "perhaps more than any other, made her known to the general public". It has been claimed that Murray's was the "first feminist study of the witch trials", as well as being the first to have actually "empowered the witches" by giving the (largely female) accused both free will and a voice distinct from that of their interrogators. The theory was faulty, in part because all of her academic training was in Egyptology, with no background knowledge in European history, but also because she exhibited a "tendency to generalize wildly on the basis of very slender evidence". Oates and Wood, however, noted that Murray's interpretations of the evidence fitted within wider perspectives on the past that existed at the time, stating that "Murray was far from isolated in her method of reading ancient ritual origins into later myths". In particular, her approach was influenced by the work of the anthropologist James Frazer, who had argued for the existence of a pervasive dying-and-resurrecting god myth, and she was also influenced by the interpretative approaches of E. O. James, Karl Pearson, Herbert Fleure, and Harold Peake.

In "The Witch-Cult in Western Europe", Murray stated that she had restricted her research to Great Britain, although made some recourse to sources from France, Flanders, and New England. She drew a division between what she termed "Operative Witchcraft", which referred to the performance of charms and spells with any purpose, and "Ritual Witchcraft", by which she meant "the ancient religion of Western Europe", a fertility-based faith that she also termed "the Dianic cult". She claimed that the cult had "very probably" once been devoted to the worship of both a male deity and a "Mother Goddess" but that "at the time when the cult is recorded the worship of the male deity appears to have superseded that of the female". In her argument, Murray claimed that the figure referred to as the Devil in the trial accounts was the witches' god, "manifest and incarnate", to whom the witches offered their prayers. She claimed that at the witches' meetings, the god would be personified, usually by a man or at times by a woman or an animal; when a human personified this entity, Murray claimed that they were usually dressed plainly, though they appeared in full costume for the witches' Sabbaths.

Members joined the cult either as children or adults through what Murray called "admission ceremonies"; Murray asserted that applicants had to agree to join of their own free will, and agree to devote themselves to the service of their deity. She also claimed that in some cases, these individuals had to sign a covenant or were baptised into the faith. At the same time, she claimed that the religion was largely passed down hereditary lines. Murray described the religion as being divided into covens containing thirteen members, led by a coven officer who was often termed the "Devil" in the trial accounts, but who was accountable to a "Grand Master". According to Murray, the records of the coven were kept in a secret book, with the coven also disciplining its members, to the extent of executing those deemed traitors.

Describing this witch-cult as "a joyous religion", she claimed that the two primary festivals that it celebrated were on May Eve and November Eve, although that other dates of religious observation were 1 February and 1 August, the winter and summer solstices, and Easter. She asserted that the "General Meeting of all members of the religion" were known as Sabbaths, while the more private ritual meetings were known as Esbats. The Esbats, Murray claimed, were nocturnal rites that began at midnight, and were "primarily for business, whereas the Sabbath was purely religious". At the former, magical rites were performed both for malevolent and benevolent ends. She also asserted that the Sabbath ceremonies involved the witches paying homage to the deity, renewing their "vows of fidelity and obedience" to him, and providing him with accounts of all the magical actions that they had conducted since the previous Sabbath. Once this business had been concluded, admissions to the cult or marriages were conducted, ceremonies and fertility rites took place, and then the Sabbath ended with feasting and dancing.
Deeming Ritual Witchcraft to be "a fertility cult", she asserted that many of its rites were designed to ensure fertility and rain-making. She claimed that there were four types of sacrifice performed by the witches: blood-sacrifice, in which the neophyte writes their name in blood; the sacrifice of animals; the sacrifice of a non-Christian child to procure magical powers; and the sacrifice of the witches' god by fire to ensure fertility.
She interpreted accounts of witches shapeshifting into various animals as being representative of a rite in which the witches dressed as specific animals which they took to be sacred. She asserted that accounts of familiars were based on the witches' use of animals, which she divided into "divining familiars" used in divination and "domestic familiars" used in other magic rites.

Murray asserted that a pre-Christian fertility-based religion had survived the Christianization process in Britain, although that it came to be "practised only in certain places and among certain classes of the community". She believed that folkloric stories of fairies in Britain were based on a surviving race of dwarfs, who continued to live on the island up until the Early Modern period. She asserted that this race followed the same pagan religion as the witches, thus explaining the folkloric connection between the two. In the appendices to the book, she also alleged that Joan of Arc and Gilles de Rais were members of the witch-cult and were executed for it, a claim which has been refuted by historians, especially in the case of Joan of Arc.

The later historian Ronald Hutton commented that "The Witch-Cult in Western Europe" "rested upon a small amount of archival research, with extensive use of printed trial records in 19th-century editions, plus early modern pamphlets and works of demonology". He also noted that the book's tone was generally "dry and clinical, and every assertion was meticulously footnoted to a source, with lavish quotation". It was not a bestseller; in its first thirty years, only 2,020 copies were sold. However, it led many people to treat Murray as an authority on the subject; in 1929, she was invited to provide the entry on "Witchcraft" for the "Encyclopædia Britannica", and used it to present her interpretation of the subject as if it were universally accepted in scholarship. It remained in the encyclopedia until being replaced in 1969.

Murray followed "The Witch-Cult in Western Europe" with "The God of the Witches", published by the popular press Sampson Low in 1931; although similar in content, unlike her previous volume it was aimed at a mass market audience. The tone of the book also differed strongly from its predecessor, containing "emotionally inflated [language] and coloured with religious phraseology" and repeatedly referring to the witch-cult as "the Old Religion". In this book she also "cut out or toned down" many of the claims made in her previous volume which would have painted the cult in a bad light, such as those which discussed sex and the sacrifice of animals and children.

In this book she began to refer to the witches' deity as the Horned God, and asserted that it was an entity who had been worshipped in Europe since the Palaeolithic.
She further asserted that in the Bronze Age, the worship of the deity could be found throughout Europe, Asia, and parts of Africa, claiming that the depiction of various horned figures from these societies proved that. Among the evidence cited were the horned figures found at Mohenjo-Daro, which are often interpreted as depictions of Pashupati, as well as the deities Osiris and Amon in Egypt and the Minotaur of Minoan Crete. Within continental Europe, she claimed that the Horned God was represented by Pan in Greece, Cernunnos in Gaul, and in various Scandinavian rock carvings. Claiming that this divinity had been declared the Devil by the Christian authorities, she nevertheless asserted that his worship was testified in officially Christian societies right through to the Modern period, citing folkloric practices such as the Dorset Ooser and the Puck Fair as evidence of his veneration.

In 1954, she published "The Divine King in England", in which she greatly extended on the theory, taking influence from Frazer's "The Golden Bough", an anthropological book that made the claim that societies all over the world sacrificed their kings to the deities of nature. In her book, she claimed that this practice had continued into medieval England, and that, for instance, the death of William II was really a ritual sacrifice.
No academic took the book seriously, and it was ignored by many of her supporters.

Upon initial publication, Murray's thesis gained a favourable reception from many readers, including some significant scholars, albeit none who were experts in the witch trials. Historians of Early Modern Britain like George Norman Clark and Christopher Hill incorporated her theories into their work, although the latter subsequently distanced himself from the theory. For the 1961 reprint of "The Witch-Cult in Western Europe", the Medieval historian Steven Runciman provided a foreword in which he accepted that some of Murray's "minor details may be open to criticism", but in which he was otherwise supportive of her thesis. Her theories were recapitulated by Arno Runeberg in his 1947 book "Witches, Demons and Fertility Magic" as well as Pennethorne Hughes in his 1952 book "Witches". As a result, the Canadian historian Elliot Rose, writing in 1962, claimed that the Murrayite interpretations of the witch trials "seem to hold, at the time of writing, an almost undisputed sway at the higher intellectual levels", being widely accepted among "educated people".

Rose suggested that the reason that Murray's theory gained such support was partly because of her "imposing credentials" as a member of staff at UCL, a position that lent her theory greater legitimacy in the eyes of many readers. He further suggested that the Murrayite view was attractive to many as it confirmed "the general picture of pre-Christian Europe a reader of Frazer or [Robert] Graves would be familiar with". Similarly, Hutton suggested that the cause of the Murrayite theory's popularity was because it "appealed to so many of the emotional impulses of the age", including "the notion of the English countryside as a timeless place full of ancient secrets", the literary popularity of Pan, the widespread belief that the majority of British had remained pagan long after the process of Christianisation, and the idea that folk customs represented pagan survivals. At the same time, Hutton suggested, it seemed more plausible to many than the previously dominant rationalist idea that the witch trials were the result of mass delusion. Related to this, the folklorist Jacqueline Simpson suggested that part of the Murrayite theory's appeal was that it appeared to give a "sensible, demystifying, liberating approach to a longstanding but sterile argument" between the rationalists who denied that there had been any witches and those, like Montague Summers, who insisted that there had been a real Satanic conspiracy against Christendom in the Early Modern period replete with witches with supernatural powers. "How refreshing", noted the historian Hilda Ellis Davidson, "and exciting her first book was "at that period". A new approach, and such a surprising one."

Murray's theories never received support from experts in the Early Modern witch trials, and from her early publications onward many of her ideas were challenged by those who highlighted her "factual errors and methodological failings". Indeed, the majority of scholarly reviews of her work produced during the 1920s and 1930s were largely critical. George L. Burr reviewed both of her initial books on the witch-cult for the "American Historical Review". He stated that she was not acquainted with the "careful general histories by modern scholars" and criticised her for assuming that the trial accounts accurately reflected the accused witches' genuine experiences of witchcraft, regardless of whether those confessions had been obtained through torture and coercion. He also charged her with selectively using the evidence to serve her interpretation, for instance by omitting any supernatural or miraculous events that appear in the trial accounts. W. R. Halliday was highly critical in his review for "Folklore", as was E. M. Loeb in his review for "American Anthropologist".

Soon after, one of the foremost specialists of the trial records, L'Estrange Ewen, brought out a series of books which rejected Murray's interpretation.
Rose suggested that Murray's books on the witch-cult "contain an incredible number of minor errors of fact or of calculation and several inconsistencies of reasoning". He accepted that her case "could, perhaps, still be proved by somebody else, though I very much doubt it". Highlighting that there is a gap of about a thousand years between the Christianisation of Britain and the start of the witch trials there, he argues that there is no evidence for the existence of the witch-cult anywhere in the intervening period. He further criticises Murray for treating pre-Christian Britain as a socially and culturally monolithic entity, whereas in reality, it contained a diverse array of societies and religious beliefs. He also challenges Murray's claim that the majority of Britons in the Middle Ages remained pagan as "a view grounded on ignorance alone".

Murray did not respond directly to the criticisms of her work, but reacted to her critics in a hostile manner; in later life she asserted that she eventually ceased reading reviews of her work, and believed that her critics were simply acting out of their own Christian prejudices to non-Christian religion.
Simpson noted that despite these critical reviews, within the field of British folkloristics, Murray's theories were permitted "to pass unapproved but unchallenged, either out of politeness or because nobody was really interested enough to research the topic". As evidence, she noted that no substantial research articles on the subject of witchcraft were published in "Folklore" between Murray's in 1917 and Rossell Hope Robbins's in 1963. She also highlighted that when regional studies of British folklore were published in this period by folklorists like Theo Brown, Ruth Tongue, or Enid Porter, none adopted the Murrayite framework for interpreting witchcraft beliefs, thus evidencing her claim that Murray's theories were widely ignored by scholars of folkloristics.

Murray's work was increasingly criticised following her death in 1963, with the definitive academic rejection of the Murrayite witch-cult theory occurring during the 1970s. During these decades, a variety of scholars across Europe and North America – such as Alan Macfarlane, Erik Midelfort, William Monter, Robert Muchembled, Gerhard Schormann, Bente Alver and Bengt Ankarloo – published in-depth studies of the archival records from the witch trials, leaving no doubt that those tried for witchcraft were not practitioners of a surviving pre-Christian religion.
In 1971, the English historian Keith Thomas stated that on the basis of this research, there was "very little evidence to suggest that the accused witches were either devil-worshippers or members of a pagan fertility cult". He stated that Murray's conclusions were "almost totally groundless" because she ignored the systematic study of the trial accounts provided by Ewen and instead used sources very selectively to argue her point.

In 1975, the historian Norman Cohn commented that Murray's "knowledge of European history, even of English history, was superficial and her grasp of historical method was non-existent", adding that her ideas were "firmly set in an exaggerated and distorted version of the Frazerian mould". That same year, the historian of religion Mircea Eliade described Murray's work as "hopelessly inadequate", containing "numberless and appalling errors". In 1996, the feminist historian Diane Purkiss stated that although Murray's thesis was "intrinsically improbable" and commanded "little or no allegiance within the modern academy", she felt that male scholars like Thomas, Cohn, and Macfarlane had unfairly adopted an androcentric approach by which they contrasted their own, male and methodologically sound interpretation against Murray's "feminised belief" about the witch-cult.

Hutton stated that Murray had treated her source material with "reckless abandon", in that she had taken "vivid details of alleged witch practices" from "sources scattered across a great extent of space and time" and then declared them to be normative of the cult as a whole. Simpson outlined how Murray had selected her use of evidence very specifically, particularly by ignoring and/or rationalising any accounts of supernatural or miraculous events in the trial records, thereby distorting the events that she was describing. Thus, Simpson pointed out, Murray rationalised claims that the cloven-hoofed Devil appeared at the witches' Sabbath by stating that he was a man with a special kind of shoe, and similarly asserted that witches' claims to have flown through the air on broomsticks were actually based on their practice of either hopping along on broomsticks or smearing hallucinogenic salves onto themselves. Concurring with this assessment, the historian Jeffrey Burton Russell, writing with the independent author Brooks Alexander, stated that "Murray's use of sources, in general, is appalling". The pair went on to claim that "today, scholars are agreed that Murray was more than just wrong – she was completely and embarrassingly wrong on nearly all of her basic premises".

The Italian historian Carlo Ginzburg has been cited as being willing to give "some slight support" to Murray's theory. Ginzburg stated that although her thesis had been "formulated in a wholly uncritical way" and contained "serious defects", it did contain "a kernel of truth". He stated his opinion that she was right in claiming that European witchcraft had "roots in an ancient fertility cult", something that he argued was vindicated by his work researching the "benandanti", an agrarian visionary tradition recorded in the Friuli district of Northeastern Italy during the 16th and 17th centuries. Several historians and folklorists have pointed out that Ginzburg's arguments are very different to Murray's: whereas Murray argued for the existence of a pre-Christian witches' cult whose members physically met during the witches' Sabbaths, Ginzburg argued that some of the European visionary traditions that were conflated with witchcraft in the Early Modern period had their origins in pre-Christian fertility religions. Moreover, other historians have expressed criticism of Ginzburg's interpretation of the "benandanti"; Cohn stated that there was "nothing whatsoever" in the source material to justify the idea that the "benandanti" were the "survival of an age-old fertility cult". Echoing these views, Hutton commented that Ginzburg's claim that the "benandanti" visionary traditions were a survival from pre-Christian practices was an idea resting on "imperfect material and conceptual foundations". He added that Ginzburg's "assumption" that "what was being dreamed about in the sixteenth century had in fact been acted out in religious ceremonies" dating to "pagan times", was entirely "an inference of his own" and not one supported by the documentary evidence.

On researching the history of UCL's Egyptology department, the historian Rosalind M. Janssen stated that Murray was "remembered with gratitude and immense affection by all her former students. A wise and witty teacher, two generations of Egyptologists have forever been in her debt." Alongside teaching them, Murray was known to socialise with her UCL students outside of class hours. The archaeologist Ralph Merrifield, who knew Murray through the Folklore Society, described her as a "diminutive and kindly scholar, who radiated intelligence and strength of character into extreme old age". Davidson, who also knew Murray through the Society, noted that at their meetings "she would sit near the front, a bent and seemingly guileless old lady dozing peacefully, and then in the middle of a discussion would suddenly intervene with a relevant and penetrating comment which showed that she had missed not one word of the argument". The later folklorist Juliette Wood noted that many members of the Folklore Society "remember her fondly", adding that Murray had been "especially keen to encourage younger researchers, even those who disagreed with her ideas".

One of Murray's friends in the Society, E. O. James, described her as a "mine of information and a perpetual inspiration ever ready to impart her vast and varied stores of specialised knowledge without reserve, or, be it said, much if any regard for the generally accepted opinions and conclusions of the experts!" Davidson described her as being "not at all assertive ... [she] never thrust her ideas on anyone. [In relation to her witch-cult theory,] she behaved in fact rather like someone who was a fully convinced member of some unusual religious sect, or perhaps, of the Freemasons, but never on any account got into arguments about it in public." The archaeologist Glyn Daniel observed that Murray remained mentally alert into her old age, commenting that "her vigour and forthrightness and ruthless energy never deserted her".

Murray never married, instead devoting her life to her work, and for this reason, Hutton drew comparisons between her and two other prominent female British scholars of the period, Jane Harrison and Jessie Weston. Murray's biographer Kathleen L. Sheppard stated that she was deeply committed to public outreach, particularly when it came to Egyptology, and that as such she "wanted to change the means by which the public obtained knowledge about Egypt's history: she wished to throw open the doors to the scientific laboratory and invite the public in". She considered travel to be one of her favourite activities, although due to restraints on her time and finances she was unable to do this regularly; her salary remained small and the revenue from her books was meagre.

Raised a devout Christian by her mother, Murray had initially become a Sunday School teacher to preach the faith, but after entering the academic profession she rejected religion, gaining a reputation among other members of the Folklore Society as a noted sceptic and a rationalist. She was openly critical of organised religion, although continued to maintain a personal belief in a God of some sort, relating in her autobiography that she believed in "an unseen over-ruling Power", "which science calls Nature and religion calls God".
She was also a believer and a practitioner of magic, performing curses against those she felt deserved it; in one case she cursed a fellow academic, Jaroslav Černý, when she felt that his promotion to the position of Professor of Egyptology over her friend Walter Bryan Emery was unworthy. Her curse entailed mixing up ingredients in a frying pan, and was undertaken in the presence of two colleagues. In another instance, she was claimed to have created a wax image of Kaiser Wilhelm II and then melted it during the First World War. Ruth Whitehouse argues that, given Murray's lack of mention of such incidents in her autobiography and generally rational approach, a "spirit of mischief" as opposed to "a real belief in the efficacy of the spells" may have motivated her practice of magic.

Hutton noted that Murray was one of the earliest women to "make a serious impact upon the world of professional scholarship", and the archaeologist Niall Finneran described her as "one of the greatest characters of post-war British archaeology". Upon her death, Daniel referred to her as "the Grand Old Woman of Egyptology", with Hutton noting that Egyptology represented "the core of her academic career". In 2014, Thornton referred to her as "one of Britain's most famous Egyptologists". However, according to the archaeologist Ruth Whitehouse, Murray's contributions to archaeology and Egyptology were often overlooked as her work was overshadowed by that of Petrie, to the extent that she was often thought of primarily as one of Petrie's assistants rather than as a scholar in her own right. By her retirement she had come to be highly regarded within the discipline, although, according to Whitehouse, Murray's reputation declined following her death, something that Whitehouse attributed to the rejection of her witch-cult theory and the general erasure of women archaeologists from the discipline's male-dominated history.

In his obituary for Murray in "Folklore", James noted that her death was "an event of unusual interest and importance in the annals of the Folk-Lore Society in particular as well as in the wider sphere in which her influence was felt in so many directions and
disciplines". However, later academic folklorists, such as Simpson and Wood, have cited Murray and her witch-cult theory as an embarrassment to their field, and to the Folklore Society specifically. Simpson suggested that Murray's position as President of the Society was a causal factor in the mistrustful attitude that many historians held toward folkloristics as an academic discipline, as they erroneously came to believe that all folklorists endorsed Murray's ideas. Similarly, Catherine Noble stated that "Murray caused considerable damage to the study of witchcraft".

In 1935, UCL introduced the Margaret Murray Prize, awarded to the student who is deemed to have produced the best dissertation in Egyptology; it continued to be presented annually into the 21st century. In 1969, UCL named one of their common rooms in her honour, but it was converted into an office in 1989. In June 1983, Queen Elizabeth The Queen Mother visited the room and there was gifted a copy of Murray's "My First Hundred Years". UCL also hold two busts of Murray, one kept in the Petrie Museum and the other in the library of the UCL Institute of Archaeology. This sculpture was commissioned by one of her students, Violet MacDermot, and produced by the artist Stephen Rickard. UCL also possess a watercolour painting of Murray by Winifred Brunton; formerly exhibited in the Petrie Gallery, it was later placed into the Art Collection stores.
In 2013, on the 150th anniversary of Murray's birth and the 50th of her death, the UCL Institute of Archaeology's Ruth Whitehouse described Murray as "a remarkable woman" whose life was "well worth celebrating, both in the archaeological world at large and especially in UCL".

The historian of archaeology Rosalind M. Janssen titled her study of Egyptology at UCL "The First Hundred Years" "as a tribute" to Murray. Murray's friend Margaret Stefana Drower authored a short biography of her, which was included as a chapter in the 2004 edited volume on "Breaking Ground: Pioneering Women Archaeologists". In 2013, Lexington Books published "The Life of Margaret Alice Murray: A Woman's Work in Archaeology", a biography of Murray authored by Kathleen L. Sheppard, then an assistant professor at Missouri University of Science and Technology; the book was based upon Sheppard's doctoral dissertation produced at the University of Oklahoma. Although characterising it as being "written in a clear and engaging manner", one reviewer noted that Sheppard's book focuses on Murray the "scientist" and as such neglects to discuss Murray's involvement in magical practices and her relationship with Wicca.

Murray's witch-cult theories provided the blueprint for the contemporary Pagan religion of Wicca, with Murray being referred to as the "Grandmother of Wicca". The Pagan studies scholar Ethan Doyle White stated that it was the theory which "formed the historical narrative around which Wicca built itself", for on its emergence in England during the 1940s and 1950s, Wicca claimed to be the survival of this witch-cult. Wicca's theological structure, revolving around a Horned God and Mother Goddess, was adopted from Murray's ideas about the ancient witch-cult, and Wiccan groups were named "covens" and their meetings termed "esbats", both words that Murray had popularised. As with Murray's witch-cult, Wicca's practitioners entered via an initiation ceremony; Murray's claims that witches wrote down their spells in a book may have been an influence on Wicca's Book of Shadows. Wicca's early system of seasonal festivities were also based on Murray's framework.

Noting that there is no evidence of Wicca existing before the publication of Murray's books, Merrifield commented that for those in 20th century Britain who wished to form their own witches' covens, "Murray may have seemed the ideal fairy godmother, and her theory became the pumpkin coach that could transport them into the realm of fantasy for which they longed". The historian Philip Heselton suggested that the New Forest coven – the oldest alleged Wiccan group – was founded "circa" 1935 by esotericists aware of Murray's theory and who may have believed themselves to be reincarnated witch-cult members. It was Gerald Gardner, who claimed to be an initiate of the New Forest coven, who established the tradition of Gardnerian Wicca and popularised the religion; according to Simpson, Gardner was the only member of the Folklore Society to "wholeheartedly" accept Murray's witch-cult hypothesis. The duo knew each other, with Murray writing the foreword to Gardner's 1954 book "Witchcraft Today", although in that foreword she did not explicitly specify whether she believed Gardner's claim that he had discovered a survival of her witch-cult. In 2005, Noble suggested that "Murray's name might be all but forgotten today if it were not for Gerald Gardner".

Murray's witch-cult theories were likely also a core influence on the non-Gardnerian Wiccan traditions that were established in Britain and Australia between 1930 and 1970 by the likes of Bob Clay-Egerton, Robert Cochrane, Charles Cardell, and Rosaleen Norton.
The prominent Wiccan Doreen Valiente eagerly searched for what she believed were other surviving remnants of the Murrayite witch-cult around Britain. Valiente remained committed to a belief in Murray's witch-cult after its academic rejection, and she described Murray as "a remarkable woman". In San Francisco during the late 1960s, Murray's writings were among the sources used by Aidan A. Kelly in the creation of his Wiccan tradition, the New Reformed Orthodox Order of the Golden Dawn. In Los Angeles during the early 1970s, they were used by Zsuzsanna Budapest when she was establishing her feminist-oriented tradition of Dianic Wicca. The Murrayite witch-cult theory also provided the basis for the ideas espoused in "Witchcraft and the Gay Counterculture", a 1978 book written by the American gay liberation activist Arthur Evans.

Members of the Wiccan community gradually became aware of academia's rejection of the witch-cult theory. Accordingly, belief in its literal truth declined during the 1980s and 1990s, with many Wiccans instead coming to view it as a myth that conveyed metaphorical or symbolic truths. Others insisted that the historical origins of the religion did not matter and that instead Wicca was legitimated by the spiritual experiences it gave to its participants. In response, Hutton authored "The Triumph of the Moon", a historical study exploring Wicca's early development; on publication in 1999 the book exerted a strong impact on the British Pagan community, further eroding belief in the Murrayite theory among Wiccans. Conversely, other practitioners clung on to the theory, treating it as an important article of faith and rejecting post-Murrayite scholarship on European witchcraft. Several prominent practitioners continued to insist that Wicca was a religion with origins stretching back to the Palaeolithic, but others rejected the validity of historical scholarship and emphasised intuition and emotion as the arbiter of truth. A few "counter-revisionist" Wiccans – among them Donald H. Frew, Jani Farrell-Roberts, and Ben Whitmore – published critiques in which they attacked post-Murrayite scholarship on matters of detail, but none defended Murray's original hypothesis completely.

Simpson noted that the publication of the Murray thesis in the "Encyclopædia Britannica" made it accessible to "journalists, film-makers popular novelists and thriller writers", who adopted it "enthusiastically". It influenced the work of Aldous Huxley and Robert Graves. It was also an influence on the American horror author H. P. Lovecraft, who cited "The Witch-Cult in Western Europe" in his writings about the fictional cult of Cthulhu.

The author Sylvia Townsend Warner cited Murray's work on the witch-cult as an influence on her 1926 novel "Lolly Willowes", and sent a copy of her book to Murray in appreciation, with the two meeting for lunch shortly after. There was nevertheless some difference in their depictions of the witch-cult; whereas Murray had depicted an organised pre-Christian cult, Warner depicted a vague family tradition that was explicitly Satanic.
In 1927, Warner lectured on the subject of witchcraft, exhibiting a strong influence from Murray's work. Analysing the relationship between Murray and Warner, the English literature scholar Mimi Winick characterised both as being "engaged in imagining new possibilities for women in modernity".

A bibliography of Murray's published work was published in "Folklore" by Wilfrid Bonser in 1961, and her friend Drower produced a posthumous limited bibliography in 2004, and another limited bibliography appeared in Kathleen L. Sheppard's 2013 biography of her.




</doc>
<doc id="20209" url="https://en.wikipedia.org/wiki?curid=20209" title="March 24">
March 24

March 24th is the 365th and last day of the year in many European implementations of the Julian calendar.





</doc>
<doc id="20210" url="https://en.wikipedia.org/wiki?curid=20210" title="March 23">
March 23





</doc>
<doc id="20211" url="https://en.wikipedia.org/wiki?curid=20211" title="March 22">
March 22





</doc>
<doc id="20212" url="https://en.wikipedia.org/wiki?curid=20212" title="Aoraki / Mount Cook">
Aoraki / Mount Cook

Aoraki / Mount Cook is the highest mountain in New Zealand. Its height, as of 2014, is listed as . It lies in the Southern Alps, the mountain range which runs the length of the South Island. A popular tourist destination, it is also a favourite challenge for mountain climbers. Aoraki / Mount Cook consists of three summits, from South to North the Low Peak (), Middle Peak () and High Peak. The summits lie slightly south and east of the main divide of the Southern Alps, with the Tasman Glacier to the east and the Hooker Glacier to the southwest.

The mountain is in the Aoraki / Mount Cook National Park, in the Canterbury region. The park was established in 1953 and along with Westland National Park, Mount Aspiring National Park and Fiordland National Park forms one of the UNESCO World Heritage Sites. The park contains more than 140 peaks standing over and 72 named glaciers, which cover 40 percent of its .

The peak is located at the northern end of the Kirikirikatata / Mount Cook Range, where it meets with the main spine of the Main Divide, forming a massif between the Hooker Valley to the southwest and the Tasman Valley east of the mountain. These two valleys provide the closest easily accessible view points of Aoraki / Mount Cook. A lookout point at the end of the Hooker Valley Track located only 10 km from the peak has views of the entire mountainside.

The settlement of Mount Cook Village, also referred to as "Aoraki / Mount Cook", is a tourist centre and base camp for the mountain. It is 7 km from the end of the Tasman Glacier and 15 km south of Aoraki / Mount Cook's summit.

On clear days, Aoraki / Mount Cook is visible from the West Coast as far north as Greymouth, some 150 kilometres away, and from most of State Highway 80 along Lake Pukaki and State Highway 6 south of Lake Pukaki. The near horizontal ridge connecting the mountain's three summits forms a distinctive blocky shape when viewed from an eastern or western direction.
Another popular view point is from Lake Matheson on the West Coast, described as the "view of views", where on calm days, the peaks of Aoraki / Mount Cook and Mt Tasman are reflected in Lake Matheson.

Aoraki / Mount Cook receives substantial orographic precipitation throughout the year, as breezy, moisture-laden westerly winds dominate all year-round, bringing rainclouds from the Tasman Sea with them.

Annual precipitation around the mountain ranges varies greatly as the local climate is dominated by the eastward movement of depressions and anticyclones from across the Tasman Sea. The Aoraki / Mount Cook massif is a major obstacle to the prevailing westerly winds as they push depressions and associated cold fronts of moist air from the subtropics in the northwest against the mountain range. As the air rises towards the peaks, it expands and cools, and forms clouds. Rain and snowfall are often heaviest around the level and can last for several days if the front is slow-moving.

As a result of the local weather patterns, the western slopes of Aoraki / Mount Cook can receive well over of annual precipitation, whereas the nearby Mount Cook Village, only south of the mountain receives of rain or snowfall.
While the weather on the eastern side of the mountain is generally better, rain or snow can quickly become widespread on that side as well if the wind turns to the south or southeast. This brings with it a rapid drop in temperature and poor visibility, adding to the difficult climbing conditions on Aoraki / Mount Cook.

Temperatures at the mountain's base in the Hooker Valley around range from to , and generally fall just over 1 °C for every 200 metres of altitude.

From about and higher, semi-permanent snow and ice fields exist during winter. Winter and spring are usually less settled than summer and autumn. Anticyclones often bring days of settled weather in summer, or clear cold conditions in winter with severe frost.

' is the name of a person in the traditions of the Ngāi Tahu iwi; an early name for the South Island is ' (Aoraki's Canoe). In the past many believed it meant "Cloud Piercer", a romantic rendering of the name's components: ' (world, daytime, cloud, etc.) and ' or ' (day, sky, weather, etc.). Historically, the Māori name has been spelt ', using the standard Māori form.

Aoraki / Mount Cook became known to Māori after their arrival in New Zealand some time around the 14th century CE. The first Europeans who may have seen Aoraki / Mount Cook were members of Abel Tasman's crew, who saw a "large land uplifted high" (probably some part of the Southern Alps) while off the west coast of the South Island, just north of present-day Greymouth on 13 December 1642 during Tasman's first Pacific voyage. The English name of "Mount Cook" was given to the mountain in 1851 by Captain John Lort Stokes to honour Captain James Cook who surveyed and circumnavigated the islands of New Zealand in 1770. Captain Cook did not sight the mountain during his exploration.

Following the settlement between Ngāi Tahu and the Crown in 1998, the name of the mountain was officially changed from Mount Cook to Aoraki / Mount Cook to incorporate its historic Māori name, Aoraki. As part of the settlement, a number of South Island placenames were amended to incorporate their original Māori name. Signifying the importance of Aoraki / Mount Cook, it is the only one of these names where the Māori name precedes the English. Under the settlement the Crown agreed to return title to Aoraki / Mount Cook to Ngāi Tahu, who would then formally gift it back to the nation. Neither transfer has yet occurred; Ngāi Tahu can decide when this will happen.

The Southern Alps in the South Island were formed by tectonic uplifting and pressure as the Pacific and Indo-Australian Plates collided along the island's western coast. The uplifting continues, raising Aoraki / Mount Cook an average of each year. However, erosive forces are also powerful shapers of the mountains. The severe weather is due to the mountain's jutting into powerful westerly winds of the Roaring Forties which run around approximately 45°S latitude, south of both Africa and Australia. The Southern Alps are the first obstacle the winds encounter after South America, having moved east across the Southern Ocean.

The height of Aoraki / Mount Cook was established in 1881 by G. J. Roberts (from the west side) and in 1889 by T. N. Brodrick (from the Canterbury side). Their measurements agreed closely at . The height was reduced by when approximately 12–14 million cubic metres of rock and ice fell off the northern peak on 14 December 1991. Two decades of erosion of the ice cap exposed after this collapse reduced the height by another 30 m to 3724 m, as revealed by new GPS data from a University of Otago climbing expedition in November 2013.

Aoraki / Mount Cook lies in the centre of the distinctive Alpine Fault, a 650 km long active fault in the Southern Alps. It is responsible for the uplift of Aoraki / Mt Cook and is believed to move every 100 to 300 years. It last moved in 1717.

The average annual rainfall in the surrounding lowlands, in particular to the west, is around . This very high rainfall leads to temperate rainforests in these coastal lowlands and a reliable source of snow in the mountains to keep the glaciers flowing. These include the Tasman Glacier to the east of the mountain and the smaller Hooker Glacier immediately to its south.

The vegetation in the valleys to the east, in particular the Tasman Valley, is noticeably less lush than that on the western slopes of the mountain. Forest would normally grow to about 1,300 m in this area, but a lack of soil due to scree, rock falls and the effects of glaciation prevent this in most localities around the mountain. Snow tussock and other alpine plants cling to as high as 1,900 m.
Above the snowline, only lichen can be found amongst the rock, snowfields and ice that dominate the highest parts of Aoraki / Mt Cook.

The first recorded attempt on the summit was made by the Irishman Rev. William S. Green and the Swiss hotelier Emil Boss and the Swiss mountain guide Ulrich Kaufmann on 2 March 1882 via the Tasman and Linda Glaciers. Mt Cook Guidebook author Hugh Logan believe they came within 50 metres of the summit.
The first known ascent was on 25 December 1894, when New Zealanders Tom Fyfe, John Michael (Jack) Clarke and George Graham reached the summit via the Hooker Valley and the north ridge. Despite an earlier failed attempt on 20 December, the local climbers were spurred on by their desire for the first ascent to be made by New Zealand mountaineers amid reports that the American mountaineer Edward FitzGerald had his eye on the summit.<ref name="Aoraki/Mt Cook"></ref> The party reached the summit at approximately 1:30pm after bounding up the last leg of the mountain full of excitement at reaching the top. The route they had successfully traversed was not repeated again until the 100th ascent over 60 years later in 1955. Swiss guide Matthias Zurbriggen of FitzGerald's party made the second ascent on 14 March 1895 from the Tasman Glacier side, via the ridge that now bears his name. This is credited as the first solo ascent, although Zurbriggen was accompanied part of the way up the ridge by J Adamson. After Zurbriggen's ascent it was another ten years before the mountain was climbed again. In February 1905 Jack Clarke with four others completed the third ascent following Zurbriggen's route. So Clarke therefore became the first person to do a repeat ascent.

The first woman to ascend the mountain was Freda Du Faur, an Australian, on 3 December 1910. Local guide George Bannister, a nephew of another guide, Pahikore Te Koeti Turanga of Ngāi Tahu, was the first Māori to successfully scale the peak in 1912.
A traverse of the three peaks was first accomplished in 1913 by Freda Du Faur and guides Peter and Alex Graham. This 'grand traverse' was repeated in January 1916 by Conrad Kain, guiding the 57-year-old Mrs. Jane Thomson, considered at the time "a marvellous feat unequalled for daring in the annals of the Southern Alps".

Sir Edmund Hillary made his first ascent in January 1948. In February 1948 with Ruth Adams, Harry Ayres and Mick Sullivan, Hillary made the first ascent of the South Ridge to the Low Peak In order to celebrate the life of Hillary the South Ridge was renamed as Hillary Ridge in August 2011.

Aoraki / Mount Cook is a technically challenging mountain with a high level of glaciation. Its level of difficulty is often underestimated and can change dramatically depending on weather, snow and ice conditions. The climb crosses large crevasses, and involves risks of ice and rock falls, avalanches and rapidly changing weather conditions.

Since the early 20th century, around 80 people have died attempting to climb the mountain, making it New Zealand's deadliest peak. The climbing season traditionally runs from November to February, and hardly a season goes by without at least one fatality.

According to Māori legend, Aoraki was a young boy who, along with his three brothers, were the sons of Rakinui, the Sky Father. On their voyage around the Papatūānuku, the Earth Mother, their canoe became stranded on a reef and tilted. Aoraki and his brothers climbed onto the top side of their canoe. However, the south wind froze them and turned them to stone. Their canoe became the Te Waka o Aoraki, the South Island, and their prows, the Marlborough Sounds. Aoraki, the tallest, became the highest peak, and his brothers created the Kā Tiritiri o te Moana, the Southern Alps.

Ngāi Tahu, the main iwi (tribe) of New Zealand's southern region, consider Aoraki as the most sacred of the ancestors that they had descended from. Aoraki brings the iwi with its sense of community and purpose, and remains the physical form of Aoraki and the link between the worlds of the supernatural and nature.





</doc>
<doc id="20213" url="https://en.wikipedia.org/wiki?curid=20213" title="Multiple-image Network Graphics">
Multiple-image Network Graphics

Multiple-image Network Graphics (MNG) is a graphics file format, published in 2001, for animated images. Its specification is publicly documented and there are free software reference implementations available.

MNG is closely related to the PNG image format. When PNG development started in early 1995, developers decided not to incorporate support for animation, because the majority of the PNG developers felt that overloading a single file type with both still and animation features is a bad design, both for users (who have no simple way of determining to which class a given image file belongs) and for web servers (which should use a MIME type starting with image/ for stills and video/ for animations—GIF notwithstanding). However, work soon started on MNG as an animation-supporting version of PNG. Version 1.0 of the MNG specification was released on 31 January 2001.

Gwenview has native MNG support. GIMP can export images as MNG files. Imagemagick can create a MNG file from a series of PNG files. With the MNG plugin, Irfanview can read a MNG file. If MPlayer is linked against libmng, it and all its graphical front-ends like Gnome MPlayer can display MNG files.

Mozilla browsers and Netscape 6.0, 6.01 and 7.0 included native support for MNG until the code was removed in 2003 due to code size and little actual usage, causing complaints on the Mozilla development site. Mozilla later added support for APNG as a simpler alternative. Similarly, early versions of the Konqueror browser included MNG support but it was later dropped. MNG support was never included in Google Chrome, Internet Explorer, Opera, or Safari.
Web servers generally don't come pre-configured to support MNG files.

The MNG developers had hoped that MNG would replace GIF for animated images on the World Wide Web, just as PNG had done for still images. However, with the expiration of LZW patents and existence of alternative file formats such as Flash and SVG, combined with lack of MNG-supporting viewers and services, web usage was far less than expected.

The structure of MNG files is essentially the same as that of PNG files, differing only in the slightly different signature (codice_1 in hexadecimal, where codice_2 is ASCII for "MNG" – see Portable Network Graphics: File header) and the use of a much greater variety of chunks to support all the animation features that it provides. Images to be used in the animation are stored in the MNG file as encapsulated PNG or JNG images.

Two versions of MNG of reduced complexity are also defined: MNG-LC (low complexity) and MNG-VLC (very low complexity). These allow applications to include some level of MNG support without having to implement the entire MNG specification, just as the SVG standard offers the "SVG Basic" and "SVG Tiny" subsets.

MNG does not have a registered MIME media type, but codice_3 or codice_4 can be used.
MNG animations may be included in HTML pages using the codice_5 or codice_6 tag.

MNG can either be lossy or lossless, depending whether the frames are encoded in PNG (lossless) or JNG (lossy).

The most common alternatives are Animated GIF and Adobe Flash, with the relative newcomer video alternative to GIF recently gaining momentum. Animated GIF images are restricted to 256 colors and are used in simple scenarios but are supported in all major web browsers. Adobe Flash is a common alternative for creating complex and/or interactive animations and is natively supported by Internet Explorer 10 and Google Chrome, although support is deprecated as of 2016.

In web pages, it is possible to create pseudo-animations by writing JavaScript code that loads still PNG or JPEG images of each frame and displays them one by one for a specified time interval. Apart from requiring the user to have JavaScript support and choose not to disable it, this method can be CPU- and bandwidth-intensive for pages with more than one image, large images, or high framerates, and does not allow the animation to be saved in one image file or posted on image-based sites such as flickr or imageboards.

Most web browsers support APNG, a non-standard extension to PNG for simple GIF-like animations. Another alternative is SVG images with embedded PNG or JPEG graphics, using SVG animation (if supported) or JavaScript to flip between images.

Internet Explorer supports neither APNG nor SVG animation.

Another approach uses CSS 3 features, notably CSS Animation, which now has some level of support in most major web browsers. CSS Sprites (providing several images as tiles in a single large image file) can be used as animations by varying which part of the large image is visible using CSS Animation or JavaScript.




</doc>
<doc id="20215" url="https://en.wikipedia.org/wiki?curid=20215" title="Mississippi John Hurt">
Mississippi John Hurt

John Smith Hurt (March 8, 1893 – November 2, 1966), better known as Mississippi John Hurt, was an American country blues singer and guitarist.

Raised in Avalon, Mississippi, Hurt taught himself to play the guitar around the age of nine. He worked as a sharecropper and began playing at dances and parties, singing to a melodious fingerpicked accompaniment. His first recordings, made for Okeh Records in 1928, were commercial failures, and he continued to work as a farmer.

Dick Spottswood and Tom Hoskins, a blues enthusiast, located Hurt in 1963 and persuaded him to move to Washington, D.C. He was recorded by the Library of Congress in 1964. This helped further the American folk music revival, which led to the rediscovery of many other bluesmen of Hurt's era. Hurt performed on the university and coffeehouse concert circuit with other Delta blues musicians who were brought out of retirement. He also recorded several albums for Vanguard Records.

Hurt returned to Mississippi, where he died, in Grenada, a year later.

Material recorded by him has been re-released by many record labels. His songs have been recorded by Bob Dylan, Dave Van Ronk, Jerry Garcia, Beck, Doc Watson, John McCutcheon, Taj Mahal, Bruce Cockburn, David Johansen, Bill Morrissey, Gillian Welch, Josh Ritter, Chris Smither, Guthrie Thomas, Parsonsfield, and Rory Block.

Hurt was born in Teoc, Carroll County, Mississippi, and raised in Avalon, Mississippi. He taught himself to play guitar at the age of nine, stealthily playing the guitar of a friend of his mother's, who often stayed at the Hurt home while courting a woman who lived nearby. As a youth he played old-time music for friends and at dances. He worked as a farmhand and sharecropper into the 1920s.

His fast, highly syncopated style of playing was meant for dancing. On occasion, a medicine show would come through the area. Hurt recalled that one wanted to hire him: "One of them wanted me, but I said no because I just never wanted to get away from home." In 1923, he played with the fiddle player Willie Narmour as a substitute for Narmour's regular partner, Shell Smith.

When Narmour got a chance to record for Okeh Records as a prize for winning first place in a 1928 fiddle contest, he recommended Hurt to Okeh producer Tommy Rockwell. After auditioning "Monday Morning Blues" at his home, Hurt took part in two recording sessions, in Memphis and New York City (see Discography below). While in Memphis, he recalled seeing "many, many blues singers ... Lonnie Johnson, Blind Lemon Jefferson, Bessie Smith, and lots, lots more." Hurt described his first recording session as follows:

Hurt attempted further negotiations with Okeh to record again, but his records were commercial failures. Okeh went out of business during the Great Depression, and Hurt returned to Avalon and obscurity, working as a sharecropper and playing at local parties and dances.

Hurt's renditions of "Frankie" and "Spike Driver Blues" were included in "The Anthology of American Folk Music" in 1952 which generated considerable interest in locating him. When a copy of "Avalon Blues" was discovered in 1963, it led musicologist Dick Spottswood to locate Avalon in an atlas, and ask Tom Hoskins, who was traveling that way, to enquire after Hurt. When Hoskins arrived in Avalon the first person he asked directed him to Hurt's cabin.

Hoskins persuaded an apprehensive Hurt to perform several songs for him, to ensure that he was genuine. Hoskins was convinced and, seeing that Hurt's guitar playing skills were still intact, encouraged him to move to Washington, D.C., and perform for a broader audience. His performance at the 1963 Newport Folk Festival caused his star to rise in the folk revival occurring at that time. He performed extensively at colleges, concert halls, and coffeehouses and appeared on "The Tonight Show Starring Johnny Carson". He also recorded three albums for Vanguard Records. Much of his repertoire was also recorded for the Library of Congress. His fans particularly liked the ragtime songs "Salty Dog" and "Candy Man" and the blues ballads "Spike Driver Blues" (a variant of "John Henry") and "Frankie".

Hurt's influence spanned several music genres, including blues, spirituals, country, bluegrass, folk, and contemporary rock and roll. A soft-spoken man, his nature was reflected in the work, which consisted of a mellow mix of country, blues, and old-time music.

Hurt died on November 2, 1966, of a heart attack, in hospital at Grenada, Mississippi. His last recordings had been done at a hotel in New York City in February and July of that year, and were not released until 1972 on the Vanguard LP "Last Sessions".

Hurt used a fast, syncopated fingerpicking style of guitar playing that he taught himself. He was influenced by few other musicians, among whom was an elderly, unrecorded blues singer from the area where he lived, Rufus Hanks, who played twelve-string guitar and harmonica. He also recalled listening to the country singer Jimmie Rodgers. On occasion, Hurt would use an open tuning and a slide, as he did in his arrangement of "The Ballad of Casey Jones". According to the music critic Robert Christgau, "the school of John Fahey proceeded from his finger-picking, and while he's not the only quietly conversational singer in the modern folk tradition, no one else has talked the blues with such delicacy or restraint."

There is a memorial to Hurt in Avalon, Mississippi. It is parallel to RR2, the rural road on which he grew up.

The American singer-songwriter Tom Paxton, who met Hurt and played on the same bill with him at the Gaslight in Greenwich Village around 1963, wrote and recorded a song about him in 1977, "Did You Hear John Hurt?", which he still frequently plays in live performances.

The first track of John Fahey's 1968 solo acoustic guitar album "Requia" is "Requiem for John Hurt". Fahey's posthumous live album, "The Great Santa Barbara Oil Slick", also features a version of the piece, entitled "Requiem for Mississippi John Hurt".

The British folk and blues artist Wizz Jones recorded a tribute song, "Mississippi John", for his 1977 album "Magical Flight".

The Delta blues artist Rory Block recorded the album "Avalon: A Tribute to Mississippi John Hurt", released in 2013 as part of her "Mentor Series".

The New England singer-songwriter Bill Morrissey released the Grammy-nominated album "Songs of Mississippi John Hurt" in 1999.

In 2017, John Hurt's life story was told in the award-winning documentary series "American Epic". The film featured unseen film footage of Hurt performing and being interviewed, and radically improved restorations of his 1920s recordings. Director Bernard MacMahon stated that Hurt "was the inspiration for "American Epic"". Hurt's life was profiled in the accompanying book, "".

Sources for this section are as follows:.







</doc>
<doc id="20216" url="https://en.wikipedia.org/wiki?curid=20216" title="Moravia">
Moravia

Moravia ( , , ; ; ; ; ) is a historical region in the east of the Czech Republic and one of three historical Czech lands, with Bohemia and Czech Silesia.

The medieval and early modern Margraviate of Moravia was a crown land of the Lands of the Bohemian Crown from 1348 to 1918, an imperial state of the Holy Roman Empire from 1004 to 1806, a crown land of the Austrian Empire from 1804 to 1867, and a part of Austria-Hungary from 1867 to 1918. Moravia was one of the five lands of Czechoslovakia founded in 1918, in 1928 it was merged with Czech Silesia, and dissolved during the abolition of the land system in 1949 following the communist coup d'état.

Its area of 22,623.41 km is home to more than 3 million people.
The people are historically named Moravians, a subgroup of Czechs, the other group being called Bohemians. Moravia also had been home of a large German-speaking population until their expulsion in 1945. The land takes its name from the Morava river, which runs from its north to south, being its principal watercourse. Moravia's largest city and historical capital is Brno. Before being sacked by the Swedish army during the Thirty Years' War, Olomouc was another capital, and it is still the seat of the Roman Catholic Archdiocese of Olomouc.

The region and former margraviate of Moravia, "Morava" in Czech, is named after its principal river Morava. It is theorized that the river's name is derived from Proto-Indo-European "*mori": "waters", or indeed any word denoting "water" or a "marsh".

The German name for Moravia is "Mähren", from the river's German name "March". This could have a different etymology, as "march" is a term used in the Medieval times for an outlying territory, a border or a frontier (cf. English "march").

Moravia occupies most of the eastern part of the Czech Republic. Moravian territory is naturally strongly determined, in fact, as the Morava river basin, with strong effect of mountains in the west ("de facto" main European continental divide) and partly in the east, where all the rivers rise.

Moravia occupies an exceptional position in Central Europe. All the highlands in the west and east of this part of Europe run west–east, and therefore form a kind of filter, making north–south or south north movement more difficult. Only Moravia with the depression of the westernmost Outer Subcarpathia, wide, between the Bohemian Massif and the Outer Western Carpathians (gripping the meridian at a constant angle of 30°), provides a comfortable connection between the Danubian and Polish regions, and this area is thus of great importance in terms of the possible migration routes of large mammals – both as regards periodically recurring seasonal migrations triggered by climatic oscillations in the prehistory, when permanent settlement started.

Moravia borders Bohemia in the west, Lower Austria in the south(west), Slovakia in the southeast, Poland very shortly in the north, and Czech Silesia in the northeast. Its natural boundary is formed by the Sudetes mountains in the north, the Carpathians in the east and the Bohemian-Moravian Highlands in the west (the border runs from Králický Sněžník in the north, over Suchý vrch, across Upper Svratka Highlands and Javořice Highlands to tripoint nearby Slavonice in the south). The Thaya river meanders along the border with Austria and the tripoint of Moravia, Austria and Slovakia is at the confluence of the Thaya and Morava rivers. The northeast border with Silesia runs partly along the Moravice, Oder and Ostravice rivers. Between 1782–1850, Moravia (also thus known as "Moravia-Silesia") also included a small portion of the former province of Silesia – the Austrian Silesia (when Frederick the Great annexed most of ancient Silesia (the land of upper and middle Oder river) to Prussia, Silesia's southernmost part remained with the Habsburgs).

Today Moravia includes the South Moravian Region, the Zlín Region, vast majority of the Olomouc Region, southeastern half of the Vysočina Region and parts of the Moravian-Silesian, Pardubice and South Bohemian regions.

Geologically, Moravia covers a transitive area between the Bohemian Massif and the Carpathians (from (north)west to southeast), and between the Danube basin and the North European Plain (from south to northeast). Its core geomorphological features are three wide valleys, namely the Dyje-Svratka Valley ("Dyjsko-svratecký úval"), the Upper Morava Valley ("Hornomoravský úval") and the Lower Morava Valley ("Dolnomoravský úval"). The first two form the westernmost part of the Outer Subcarpathia, the last is the northernmost part of the Vienna Basin. The valleys surround the low range of Central Moravian Carpathians. The highest mountains of Moravia are situated on its northern border in Hrubý Jeseník, the highest peak is Praděd (1491 m). Second highest is the massive of Králický Sněžník (1424  m) the third are the Moravian-Silesian Beskids at the very east, with Smrk (1278 m), and then south from here Javorníky (1072). The White Carpathians along the southeastern border rise up to 970 m at Velká Javořina. The spacious, but moderate Bohemian-Moravian Highlands on the west reach 837 m at Javořice.

The fluvial system of Moravia is very cohesive, as the region border is similar to the watershed of the Morava river, and thus almost the entire area is drained exclusively by a single stream. Morava's far biggest tributaries are Thaya (Dyje) from the right (or west) and Bečva (east). Morava and Thaya meet at the southernmost and lowest (148 m) point of Moravia. Small peripheral parts of Moravia belong to the catchment area of Elbe, Váh and especially Oder (the northeast). The watershed line running along Moravia's border from west to north and east is part of the European Watershed. For centuries, there have been plans to build a waterway across Moravia to join the Danube and Oder river systems, using the natural route through the Moravian Gate.

Evidence of the presence of members of the human genus, "Homo", dates back more than 600,000 years in the paleontological area of Stránská Skála.

Attracted by suitable living conditions, early modern humans settled in the region by the Paleolithic period. The Předmostí archeological (Cro-magnon) site in Moravia is dated to between 24,000 and 27,000 years old. Caves in Moravský kras were used by mammoth hunters. Venus of Dolní Věstonice, the oldest ceramic figure in the world, was found in the excavation of Dolní Věstonice by Karel Absolon.

Around 60 BC, the Celtic Volcae people withdrew from the region and were succeeded by the Germanic Quadi. Some of the events of the Marcomannic Wars took place in Moravia in AD 169–180. After the war exposed the weakness of Rome's northern frontier, half of the Roman legions (16 out of 33) were stationed along the Danube. In response to increasing numbers of Germanic settlers in frontier regions like Pannonia, Dacia, Rome established two new frontier provinces on the left shore of the Danube, Marcomannia and Sarmatia, including today's Moravia and western Slovakia.

In the 2nd century AD, a Roman fortress stood on the vineyards hill known as and ("hillfort"), situated above the former village Mušov and above today's beach resort at Pasohlávky. During the reign of the Emperor Marcus Aurelius, the 10th Legion was assigned to control the Germanic tribes who had been defeated in the Marcomannic Wars. In 1927, the archeologist Gnirs, with the support of president Tomáš Garrigue Masaryk, began research on the site, located 80 km from Vindobona and 22 km to the south of Brno. The researchers found remnants of two masonry buildings, a "praetorium" and a "balneum" ("bath"), including a "hypocaustum". The discovery of bricks with the stamp of the Legio X Gemina and coins from the period of the emperors Antoninus Pius, Marcus Aurelius and Commodus facilitated dating of the locality.

A variety of Germanic and major Slavic tribes crossed through Moravia during the Migration Period before Slavs established themselves in the 6th century AD. At the end of the 8th century, the Moravian Principality came into being in present-day south-eastern Moravia, Záhorie in south-western Slovakia and parts of Lower Austria. In 833 AD, this became the state of Great Moravia with the conquest of the Principality of Nitra (present-day Slovakia). Their first king was Mojmír I (ruled 830–846). Louis the German invaded Moravia and replaced Mojmír I with his nephew Rastiz who became St. Rastislav. St. Rastislav (846–870) tried to emancipate his land from the Carolingian influence, so he sent envoys to Rome to get missionaries to come. When Rome refused he turned to Constantinople to the Byzantine emperor Michael. The result was the mission of Saints Cyril and Methodius who translated liturgical books into Slavonic, which had lately been elevated by the Pope to the same level as Latin and Greek. Methodius became the first Moravian archbishop, but after his death the German influence again prevailed and the disciples of Methodius were forced to flee. Great Moravia reached its greatest territorial extent in the 890s under Svatopluk I. At this time, the empire encompassed the territory of the present-day Czech Republic and Slovakia, the western part of present Hungary (Pannonia), as well as Lusatia in present-day Germany and Silesia and the upper Vistula basin in southern Poland. After Svatopluk's death in 895, the Bohemian princes defected to become vassals of the East Frankish ruler Arnulf of Carinthia, and the Moravian state ceased to exist after being overrun by invading Magyars in 907.

Following the defeat of the Magyars by Emperor Otto I at the Battle of Lechfeld in 955, Otto's ally Boleslaus I, the Přemyslid ruler of Bohemia, took control over Moravia. Bolesław I Chrobry of Poland annexed Moravia in 999, and ruled it until 1019, when the Přemyslid prince Bretislaus recaptured it. Upon his father's death in 1034, Bretislaus became the ruler of Bohemia. In 1055, he decreed that Bohemia and Moravia would be inherited together by primogeniture, although he also provided that his younger sons should govern parts (quarters) of Moravia as vassals to his oldest son.

Throughout the Přemyslid era, junior princes often ruled all or part of Moravia from Olomouc, Brno or Znojmo, with varying degrees of autonomy from the ruler of Bohemia. Dukes of Olomouc often acted as the "right hand" of Prague dukes and kings, while Dukes of Brno and especially those of Znojmo were much more insubordinate. Moravia reached its height of autonomy in 1182, when Emperor Frederick I elevated Conrad II Otto of Znojmo to the status of a margrave, immediately subject to the emperor, independent of Bohemia. This status was short-lived: in 1186, Conrad Otto was forced to obey the supreme rule of Bohemian duke Frederick. Three years later, Conrad Otto succeeded to Frederick as Duke of Bohemia and subsequently canceled his margrave title. Nevertheless, the margrave title was restored in 1197 when Vladislaus III of Bohemia resolved the succession dispute between him and his brother Ottokar by abdicating from the Bohemian throne and accepting Moravia as a vassal land of Bohemian (i.e., Prague) rulers. Vladislaus gradually established this land as Margraviate, slightly administratively different from Bohemia. After the Battle of Legnica, the Mongols carried their raids into Moravia.

The main line of the Přemyslid dynasty became extinct in 1306, and in 1310 John of Luxembourg became Margrave of Moravia and King of Bohemia. In 1333, he made his son Charles the next Margrave of Moravia (later in 1346, Charles also became the King of Bohemia). In 1349, Charles gave Moravia to his younger brother John Henry who ruled in the margraviate until his death in 1375, after him Moravia was ruled by his oldest son Jobst of Moravia who was in 1410 elected the Holy Roman King but died in 1411 (he is buried with his father in the Church of St. Thomas in Brno – the Moravian capital from which they both ruled). Moravia and Bohemia remained within the Luxembourg dynasty of Holy Roman kings and emperors (except during the Hussite wars), until inherited by Albert II of Habsburg in 1437.

After his death followed the interregnum until 1453; land (as the rest of lands of the Bohemian Crown) was administered by the landfriedens ("landfrýdy"). The rule of young Ladislaus the Posthumous subsisted only less than five years and subsequently (1458) the Hussite George of Poděbrady was elected as the king. He again reunited all Czech lands (then Bohemia, Moravia, Silesia, Upper & Lower Lusatia) into one-man ruled state. In 1466, Pope Paul II excommunicated George and forbade all Catholics (i.e. about 15% of population) from continuing to serve him. The Hungarian crusade followed and in 1469 Matthias Corvinus conquered Moravia and proclaimed himself (with assistance of rebelling Bohemian nobility) as the king of Bohemia.

The subsequent 21-year period of a divided kingdom was decisive for the rising awareness of a specific Moravian identity, distinct from that of Bohemia. Although Moravia was reunited with Bohemia in 1490 when Vladislaus Jagiellon, king of Bohemia, also became king of Hungary, some attachment to Moravian "freedoms" and resistance to government by Prague continued until the end of independence in 1620. In 1526, Vladislaus' son Louis died in battle and the Habsburg Ferdinand I was elected as his successor.

After the death of King Louis II of Hungary and Bohemia in 1526, Ferdinand I of Austria was elected King of Bohemia and thus ruler of the Crown of Bohemia (including Moravia). The epoch 1526–1620 was marked by increasing animosity between Catholic Habsburg kings (emperors) and the Protestant Moravian nobility (and other Crowns') estates. Moravia, like Bohemia, was a Habsburg possession until the end of World War I. In 1573 the Jesuit University of Olomouc was established; this was the first university in Moravia. The establishment of a special papal seminary, Collegium Nordicum, made the University a centre of the Catholic Reformation and effort to revive Catholicism in Central and Northern Europe. The second largest group of students were from Scandinavia.

Brno and Olomouc served as Moravia's capitals until 1641. As the only city to successfully resist the Swedish invasion, Brno become the sole capital following the capture of Olomouc. The Margraviate of Moravia had, from 1348 in Olomouc and Brno, its own Diet, or parliament, "zemský sněm" ("Landtag" in German), whose deputies from 1905 onward were elected separately from the ethnically separate German and Czech constituencies.

The oldest surviving theatre building in Central Europe, the Reduta Theatre, was established in 17th-century Moravia. Ottoman Turks and Tatars invaded the region in 1663, taking 12,000 captives. In 1740, Moravia was invaded by Prussian forces under Frederick the Great, and Olomouc was forced to surrender on 27 December 1741. A few months later the Prussians were repelled, mainly because of their unsuccessful siege of Brno in 1742. In 1758, Olomouc was besieged by Prussians again, but this time its defenders forced the Prussians to withdraw following the Battle of Domstadtl. In 1777, a new Moravian bishopric was established in Brno, and the Olomouc bishopric was elevated to an archbishopric. In 1782, the Margraviate of Moravia was merged with Austrian Silesia into "Moravia-Silesia", with Brno as its capital. This lasted until 1850. Moravia was briefly one of 17 former crown lands of the Cisleithanian part of Austria-Hungary after 1867. According to Austro-Hungarian census of 1910 the proportion of Czech in the population of Moravia at the time (2.622.000) was 71,8 %, while the proportion of Germans was 27,6 %.

Following the break-up of the Austro-Hungarian Empire in 1918, Moravia became part of Czechoslovakia. As one of the five lands of Czechoslovakia, it had restricted autonomy. In 1928 Moravia ceased to exist as a territorial unity and was merged with Czech Silesia into the Moravian-Silesian Land (yet with the natural dominance of Moravia). By the Munich Agreement (1938), the southwestern and northern peripheries of Moravia, which had a German-speaking majority, were annexed by Nazi Germany, and during the German occupation of Czechoslovakia (1939–1945), the remnant of Moravia was an administrative unit within the Protectorate of Bohemia and Moravia. During the WW II Moravia lost 46,306 Jews according to religion.

In 1945 after the end of World War II and Allied defeat of Germany, Czechoslovakia expelled the ethnic German minority of Moravia to Germany and Austria. The Moravian-Silesian Land was restored with Moravia as part of it and towns and villages that were left by the former German inhabitants, were re-settled by Czech-speakers. In 1949 the territorial division of Czechoslovakia was radically changed, as the Moravian-Silesian Land was abolished and Lands were replaced by ""kraje"" (regions), whose borders substantially differ from the historical Bohemian-Moravian border, so Moravia politically ceased to exist after more than 1100 years (833–1949) of its history. Although another administrative reform in 1960 implemented (among others) the North Moravian and the South Moravian regions ("Severomoravský" and "Jihomoravský kraj"), with capitals in Ostrava and Brno respectively, their joint area was only roughly alike the historical state and, chiefly, there was no land or federal autonomy, unlike Slovakia.

After the fall of the Soviet Union and the whole Eastern Bloc, the Czechoslovak Federal Assembly condemned the cancellation of Moravian-Silesian land and expressed "firm conviction that this injustice will be corrected" in 1990. However, after the breakup of Czechoslovakia into Czech Republic and Slovakia in 1993, Moravian area remained integral to the Czech territory, and the latest administrative division of Czech Republic (introduced in 2000) is similar to the administrative division of 1949. Nevertheless, the federalist or separatist movement in Moravia is completely marginal.

The centuries-lasting historical Bohemian-Moravian border has been preserved up to now only by the Czech Roman Catholic Administration, as the Ecclesiastical Province of Moravia corresponds with the former Moravian-Silesian Land. The popular perception of the Bohemian-Moravian border's location is distorted by the memory of the 1960 regions (whose boundaries are still partly in use).

An area in South Moravia, around Hodonín and Břeclav, is part of the Viennese Basin. Petroleum and lignite are found there in abundance. The main economic centres of Moravia are Brno, Olomouc and Zlín, plus Ostrava lying directly on the Moravian-Silesian border. As well as agriculture in general, Moravia is noted for its viticulture; it contains 94% of the Czech Republic's vineyards and is at the centre of the country's wine industry. Wallachia have at least a 400-year-old tradition of slivovitz making.

Czech automotive industry also had a large role in the industry of Moravia, plants such as in Prostějov or Tatra in Kopřivnice had produced many aerodynamic automobiles in the 20th century.

Moravia is also the centre of the Czech firearm industry, as the vast majority of Czech firearms manufacturers (e.g. CZUB, Zbrojovka Brno, Czech Small Arms, Czech Weapons, ZVI, Great Gun) are settled in Moravia. Almost all well-known Czech sporting, self-defence, military and hunting firearms come from Moravia. Also, Meopta rifle scopes are of Moravian origin. The original Bren gun was conceived here, as was the assault rifles CZ-805 BREN or Sa vz. 58, and handguns CZ 75 or ZVI Kevin (also known as the "Micro Desert Eagle").

The Zlín Region hosts several aircraft manufacturers, namely Let Kunovice (also known as Aircraft Industries, a.s.), ZLIN AIRCRAFT a.s. Otrokovice (former well-known name Moravan Otrokovice), Evektor-Aerotechnik and Czech Sport Aircraft. Sport aircraft are also manufactured in Jihlava by Jihlavan Airplanes/Skyleader.

Aircraft production in the region started in 1930s and there are signs of recovery in recent years and the production is expected to grow from 2013 onwards.

Machinery has been the most important industrial sector in the region, especially in South Moravia, for many decades. The main centres of machinery production are Brno (Zbrojovka Brno, Zetor, První brněnská strojírna, Siemens), Blansko (ČKD Blansko, Metra), Adamov (ADAST), Kuřim (TOS Kuřim), Boskovice (Minerva, Novibra) and Břeclav (Otis Elevator Company), together with a large number of other variously sized machinery or machining factories, companies or workshops spread all over Moravia.

The beginnings of the electrical industry in Moravia date back to 1918. The biggest centres of electrical production are Brno (VUES, ZPA Brno, EM Brno), Drásov, Frenštát pod Radhoštěm and Mohelnice (currently Siemens).



The Moravians are generally a Slavic ethnic group who speak various (generally more archaic) dialects of Czech. Before the expulsion of Germans from Moravia the Moravian German minority also referred to themselves as "Moravians" ("Mährer"). Those expelled and their descendants continue to identify as Moravian.

Moravia historically had a large minority of ethnic Germans, some of whom had arrived as early as the 13th century at the behest of the Přemyslid dynasty. Germans continued to come to Moravia in waves, culminating in the 18th century. They lived in the main city centres and in the countryside along the border with Austria (stretching up to Brno) and along the border with Silesia at Jeseníky, and also in two language islands, around Jihlava and around Moravská Třebová. After the Second World War, Czechoslovakia almost fully expelled them in retaliation for Nazi German efforts to create a Greater Germanic Reich in Central Europe.

Notable people from Moravia include (in order of birth):


Moravia can be divided on dialectal and lore basis into several ethnographic regions of comparable significance. In this sense, it is more heterogenous than Bohemia. Significant parts of Moravia, usually those formerly inhabited by the German speakers, are dialectally indifferent, as they have been resettled by people from various Czech (and Slovak) regions.

The principal cultural regions of Moravia are:








</doc>
<doc id="20217" url="https://en.wikipedia.org/wiki?curid=20217" title="Murray Rothbard">
Murray Rothbard

Murray Newton Rothbard (; March 2, 1926 – January 7, 1995) was an American heterodox economist of the Austrian School, economic historian and political theorist. Rothbard was the founder and leading theoretician of anarcho-capitalism, a staunch advocate of historical revisionism and a central figure in the 20th-century American libertarian movement. He wrote over twenty books on political theory, revisionist history, economics, and other subjects.

Rothbard argued that all services provided by the "monopoly system of the corporate state" could be provided more efficiently by the private sector and wrote that the state is "the organization of robbery systematized and writ large". He called fractional-reserve banking a form of fraud and opposed central banking. He categorically opposed all military, political, and economic interventionism in the affairs of other nations. According to his protégé Hans-Hermann Hoppe, "[t]here would be no anarcho-capitalist movement to speak of without Rothbard".

Libertarian economist Jeffrey Herbener, who calls Rothbard his friend and "intellectual mentor", wrote that Rothbard received "only ostracism" from mainstream academia. Rothbard rejected mainstream economic methodologies and instead embraced the praxeology of his most important intellectual precursor, Ludwig von Mises. To promote his economic and political ideas, Rothbard joined Lew Rockwell and Burton Blumert in 1982 to establish the Mises Institute in Alabama.

Rothbard's parents were David and Rae Rothbard, Jewish immigrants to the United States from Poland and Russia, respectively. David was a chemist. Murray attended Birch Wathen Lenox School, a private school in New York City. He later said he much preferred Birch Wathen to the "debasing and egalitarian public school system" he had attended in the Bronx.

Rothbard wrote of having grown up as a "right-winger" (adherent of the "Old Right") among friends and neighbors who were "communists or fellow-travelers". He was a member of The New York Young Republican Club in his youth. Rothbard characterized his immigrant father as an individualist who embraced the American values of minimal government, free enterprise, private property and "a determination to rise by one's own merits ... "[A]ll socialism seemed to me monstrously coercive and abhorrent".
Rothbard attended Columbia University, where he received a Bachelor of Arts degree in mathematics in 1945 and a Ph.D. in economics in 1956. The delay in receiving his Ph.D. was due in part to conflict with his advisor, Joseph Dorfman, and in part to Arthur Burns’s rejecting his dissertation. Burns was a longtime friend of the Rothbards and their neighbor at their Manhattan apartment building. It was only after Burns went on leave from the Columbia faculty to head President Eisenhower's Council of Economic Advisors that Rothbard's thesis was accepted and he received his doctorate. Rothbard later said that all his fellow students were extreme leftists and that he was one of only two Republicans at Columbia at the time.

During the 1940s, Rothbard became acquainted with Frank Chodorov and read widely in libertarian-oriented works by Albert Jay Nock, Garet Garrett, Isabel Paterson, H. L. Mencken, and Austrian economist Ludwig von Mises. In the early 1950s, when Mises was teaching in the Wall Street division of the New York University Stern School of Business, Rothbard attended his unofficial seminar. Rothbard was greatly influenced by Mises's book "Human Action". He attracted the attention of the William Volker Fund, a group that provided financial backing to promote right-wing ideologies in the 1950s and early 1960s. The Volker Fund paid Rothbard to write a textbook to explain "Human Action" in a form that could be used to introduce college undergraduates to Mises's views; a sample chapter he wrote on money and credit won Mises's approval. For ten years, the Volker Fund paid him a retainer as a "senior analyst". As Rothbard continued his work, he enlarged the project. The result was his book "Man, Economy, and State", published in 1962. Upon its publication, Mises praised Rothbard's work effusively.

In 1953, Rothbard married JoAnn Beatrice Schumacher (September 17, 1928 – October 29, 1999), whom he called Joey, in New York City. JoAnn was a historian and was Rothbard's personal editor and a close adviser as well as hostess of his Rothbard Salon. They enjoyed a loving marriage and Rothbard often called her "the indispensable framework" of his life and achievements. According to Joey, the Volker Fund's patronage allowed Rothbard to work from home as a freelance theorist and pundit for the first 15 years of their marriage. The Volker Fund collapsed in 1962, leading Rothbard to seek employment from various New York academic institutions. He was offered a part-time position teaching economics to engineering students at Brooklyn Polytechnic Institute in 1966 at age 40. The institution had no economics department or economics majors and Rothbard derided its social science department as "Marxist", but Justin Raimondo writes that Rothbard liked teaching at Brooklyn Polytechnic because working only two days a week gave him freedom to contribute to developments in libertarian politics.

Rothbard continued in this role until 1986. Then 60 years old, Rothbard left Brooklyn Polytechnic Institute for the Lee Business School at the University of Nevada, Las Vegas (UNLV), where he held the title of S.J. Hall Distinguished Professor of Economics, a chair endowed by a libertarian businessman. According to Rothbard's friend, colleague and fellow Misesian economist Hans-Hermann Hoppe, Rothbard led a "fringe existence" in academia, but he was able to attract a large number of "students and disciples" through his writings, thereby becoming "the creator and one of the principal agents of the contemporary libertarian movement". He kept his position at UNLV from 1986 until his death. Rothbard founded the Center for Libertarian Studies in 1976 and the "Journal of Libertarian Studies" in 1977. In 1982, he co-founded the Ludwig von Mises Institute in Auburn, Alabama, and was vice president of academic affairs until 1995. Rothbard also founded the Institute's "Review of Austrian Economics", a heterodox economics journal later renamed the "Quarterly Journal of Austrian Economics", in 1987.
After Rothbard's death, Joey reflected on his happiness and bright spirit, saying, "he managed to make a living for 40 years without having to get up before noon. This was important to him". She recalled how Rothbard would begin every day with a phone conversation with his colleague Lew Rockwell: "Gales of laughter would shake the house or apartment, as they checked in with each other. Murray thought it was the best possible way to start a day". Rothbard was irreligious and agnostic about God, describing himself as a "mixture of an agnostic and a Reform Jew". Despite identifying as an agnostic and an atheist, he was critical of the "left-libertarian hostility to religion". In Rothbard's later years, many of his friends anticipated that he would convert to Catholicism, but he never did. "The New York Times" obituary called Rothbard "an economist and social philosopher who fiercely defended individual freedom against government intervention".

In 1954, Rothbard, along with several other attendees of Mises's seminar, joined the circle of novelist Ayn Rand, the founder of Objectivism. He soon parted from her, writing among other things that her ideas were not as original as she proclaimed, but similar to those of Aristotle, Thomas Aquinas and Herbert Spencer. In 1958, after the publication of Rand's novel "Atlas Shrugged", Rothbard wrote her a "fan letter", calling the book "an infinite treasure house" and "not merely the greatest novel ever written, [but] one of the very greatest books ever written, fiction or nonfiction". He also wrote: "[Y]ou introduced me to the whole field of natural rights and natural law philosophy", prompting him to learn "the glorious natural rights tradition". Rothbard rejoined Rand's circle for a few months, but soon broke with Rand again over various differences, including his defense of anarchism.

Rothbard later satirized Rand's acolytes in his unpublished one-act farce "Mozart Was a Red" and his essay "The Sociology of the Ayn Rand Cult". He characterized Rand's circle as a "dogmatic, personality cult". His play parodies Rand (through the character Carson Sand) and her friends and is set during a visit from Keith Hackley, a fan of Sand's novel "The Brow of Zeus" (a play on "Atlas Shrugged").

Rothbard died of a heart attack on January 7, 1995, at the age of 68. He was buried in Oakwood Cemetery, Unionville, Virginia.

Rothbard was an advocate and practitioner of the Austrian School tradition of his teacher Ludwig von Mises. Like Mises, Rothbard rejected the application of the scientific method to economics and dismissed econometrics, empirical and statistical analysis and other tools of mainstream social science as useless for the study of economics. He instead embraced praxeology, the strictly "a priori" methodology of Mises. Praxeology conceives of economic laws as akin to geometric or mathematical axioms: fixed, unchanging, objective and discernible through logical reasoning without the use of any uncontrolled observation. According to Misesian economist Hans-Hermann Hoppe, eschewing the scientific method and uncontrolled observation distinguishes the Misesian approach "from all other current economic schools". Mark Skousen of Chapman University and the Foundation for Economic Education, a critic of mainstream economics, praises Rothbard as brilliant, his writing style persuasive, his economic arguments nuanced and logically rigorous and his Misesian methodology sound. But Skousen concedes that Rothbard was effectively "outside the discipline" of mainstream economics and that his work "fell on deaf ears" outside his ideological circles. Paralleling Skousen's remarks, Hoppe laments that non-Misesian economists dismiss as "dogmatic and unscientific" the Misesian approach, which both he and Rothbard embraced.

Rothbard wrote extensively on Austrian business cycle theory and as part of this approach strongly opposed central banking, fiat money and fractional-reserve banking, advocating a gold standard and a 100% reserve requirement for banks.

Rothbard wrote a series of scathing polemics against modern mainstream economics. He was critical of Adam Smith, calling him a "shameless plagiarist" who set economics off track, ultimately leading to the rise of Marxism. Rothbard praised Smith's contemporaries, including Richard Cantillon, Anne Robert Jacques Turgot and Étienne Bonnot de Condillac, for developing the subjective theory of value. In response to Rothbard's charge that Smith's "The Wealth of Nations" was largely plagiarized, David D. Friedman castigated Rothbard's scholarship and character, saying that he "was [either] deliberately dishonest or never really read the book he was criticizing". Tony Endres called Rothbard's treatment of Smith a "travesty".

Rothbard was equally scathing in his criticism of John Maynard Keynes, calling him weak on economic theory and a shallow political opportunist. Rothbard also wrote more generally that Keynesian-style governmental regulation of money and credit created a "dismal monetary and banking situation". He called John Stuart Mill a "wooly man of mush" and speculated that Mill's "soft" personality led his economic thought astray.

Rothbard was critical of monetarist economist Milton Friedman. In his polemic "Milton Friedman Unraveled", he called Friedman a "statist", a "favorite of the establishment", a friend of and "apologist" for Richard Nixon and a "pernicious influence" on public policy. Rothbard said that libertarians should scorn rather than celebrate Friedman's academic prestige and political influence. Noting that Rothbard has "been nasty to me and my work", Friedman responded to Rothbard's criticism by calling him a "cult builder and a dogmatist".

In a memorial volume published by the Mises Institute, Rothbard's protégé and libertarian theorist Hans-Hermann Hoppe wrote that "Man, Economy, and State" "presented a blistering refutation of all variants of mathematical economics" and included it among Rothbard's "almost mind-boggling achievements". Hoppe lamented that, like Mises, Rothbard died without winning the Nobel Prize that Hoppe says Rothbard deserved "twice over". Although Hoppe acknowledged that Rothbard and his work were largely ignored by academia, he called Rothbard an "intellectual giant" comparable to Aristotle, John Locke, and Immanuel Kant.

Although he self-identified as an Austrian economist, Rothbard's methodology was at odds with that of many other Austrians. In 1956, Rothbard deprecated the views of Austrian economist Fritz Machlup, stating that Machlup was no praxeologist and calling him instead a "positivist" who failed to represent the views of Ludwig von Mises. Rothbard stated that in fact Machlup shared the opposing positivist view associated with economist Milton Friedman. Mises and Machlup had been colleagues in 1920s Vienna before each relocated to the United States and Mises later urged his American protege Israel Kirzner to pursue his PhD studies with Machlup at Johns Hopkins University.

According to libertarian economists Tyler Cowen and Richard Fink, Rothbard wrote that the term evenly rotating economy (ERE) can be used to analyze complexity in a world of change. The words ERE had been introduced by Mises as an alternative nomenclature for the mainstream economic method of static equilibrium and general equilibrium analysis. Cowen and Fink found "serious inconsistencies in both the nature of the ERE and its suggested uses". With the sole exception of Rothbard, no other economist adopted Mises' term and the concept continued to be called "equilibrium analysis".

In a 2011 article critical of Rothbard's "reflexive opposition" to inflation, "The Economist" noted that his views are increasingly gaining influence among politicians and laypeople on the right. The article contrasted Rothbard's categorical rejection of inflationary policies with the monetary views of "sophisticated Austrian-school monetary economists such as George Selgin and Larry White", [who] follow Hayek in treating stability of nominal spending as a monetary ideal—a position "not all that different from Mr [Scott] Sumner's".

According to economist Peter Boettke, Rothbard is better described as a property rights economist than as an Austrian economist. In 1988, Boettke noted that Rothbard "vehemently attacked all of the books of the younger Austrians".

Although Rothbard adopted Ludwig von Mises' deductive methodology for his social theory and economics, he parted with Mises on the question of ethics. Specifically, he rejected Mises conviction that ethical values remain subjective and opposed utilitarianism in favor of principle-based, natural law reasoning. In defense of his free market views, Mises employed utilitarian economic arguments aimed at demonstrating that interventionist policies made all of society worse off. On the other hand, Rothbard concluded that interventionist policies do in fact benefit some people, including certain government employees and beneficiaries of social programs. Therefore, unlike Mises, Rothbard argued for an objective, natural law basis for the free market. He called this principle "self-ownership", loosely basing the idea on the writings of John Locke and also borrowing concepts from classical liberalism and the anti-imperialism of the Old Right.

Rothbard accepted the labor theory of property, but rejected the Lockean proviso, arguing that if an individual mixes his labor with unowned land then he becomes the proper owner eternally and that after that time it is private property which may change hands only by trade or gift.

Rothbard was a strong critic of egalitarianism. The title essay of Rothbard's 1974 book "Egalitarianism as a Revolt Against Nature and Other Essays" held: "Equality is not in the natural order of things, and the crusade to make everyone equal in every respect (except before the law) is certain to have disastrous consequences". In it, Rothbard wrote: "At the heart of the egalitarian left is the pathological belief that there is no structure of reality; that all the world is a tabula rasa that can be changed at any moment in any desired direction by the mere exercise of human will".

Noam Chomsky critiqued Rothbard's ideal society as "a world so full of hate that no human being would want to live in it... First of all, it couldn't function for a second—and if it could, all you'd want to do is get out, or commit suicide or something."

Various theorists have espoused legal philosophies similar to anarcho-capitalism. However, Rothbard was the first person to use the term as in the mid-20th century he synthesized elements from the Austrian School of economics, classical liberalism and 19th-century American individualist anarchists. According to Lew Rockwell, Rothbard was the "conscience" of all the various strains of libertarian anarchism, because their advocates (described as Rothbard’s former "colleagues"), had often been personally inspired by his example.

During his years at graduate school in the late 1940s, Rothbard considered whether a strict "laissez-faire" policy would require that private police agencies replace government protective services. He visited Baldy Harper, a founder of the Foundation for Economic Education, who doubted the need for any government whatsoever. During this period, Rothbard was influenced by 19th-century American individualist anarchists like Lysander Spooner and Benjamin Tucker and the Belgian economist Gustave de Molinari who wrote about how such a system could work. Thus, he "combined the "laissez-faire" economics of Mises with the absolutist views of human rights and rejection of the state" from individualist anarchists. In an unpublished memo written around 1949, Rothbard concluded that in order to believe in "laissez-faire" one must also embrace anarchism.

Rothbard began to consider himself a private property anarchist in 1950 and later began to use "anarcho-capitalist" to describe his political ideology. In his anarcho-capitalist model, a system of protection agencies compete in a free market and are voluntarily supported by consumers who choose to use their protective and judicial services. Anarcho-capitalism would mean the end of the state monopoly on force.

In "Man, Economy, and State", Rothbard divides the various kinds of state intervention in three categories: "autistic intervention", which is interference with private non-economic activities; "binary intervention", which is forced exchange between individuals and the state; and "triangular intervention", which is state-mandated exchange between individuals. According to Sanford Ikeda, Rothbard's typology "eliminates the gaps and inconsistencies that appear in Mises's original formulation". Rothbard writes in "Power and Market" that the role of the economist in a free market is limited, but it is much larger in a government that solicits economic policy recommendations. Rothbard argues that self-interest therefore prejudices the views of many economists in favor of increased government intervention.

Michael O'Malley, associate professor of history at George Mason University, characterizes Rothbard's "overall tone regard[ing]" the civil rights movement and the women's suffrage movement to be "contemptuous and hostile". Rothbard vilified women's rights activists, attributing the growth of the welfare state to politically active spinsters "whose busybody inclinations were not fettered by the responsibilities of health and heart". Rothbard argued that the progressive movement, which he regarded as a noxious influence on the United States, was spearheaded by a coalition of Yankee Protestants, Jewish women and "lesbian spinsters".

Rothbard called for the elimination of "the entire 'civil rights' structure" stating that it "tramples on the property rights of every American". He consistently favored repeal of the 1964 Civil Rights Act, including Title VII regarding employment discrimination, and called for overturning the "Brown v. Board of Education" decision on the grounds that forced integration of schools was aggressive. In an essay called "Right-wing Populism", Rothbard proposed a set of measures to "reach out" to the "middle and working classes", which included urging the police to crack down on "street criminals", writing that "cops must be unleashed" and "allowed to administer instant punishment, subject of course to liability when they are in error". He also advocated that the police "clear the streets of bums and vagrants. Where will they go? Who cares? Hopefully, they will disappear, that is, move from the ranks of the petted and cosseted bum class to the ranks of the productive members of society."

Rothbard held strong opinions about many leaders of the civil rights movement. He considered black separatist Malcolm X to be a "great black leader" and integrationist Martin Luther King Jr. to be favored by whites because he "was the major restraining force on the developing Negro revolution". Rothbard rejected the idea of "compulsory integration" and felt that "self-help, pride, thrift, Negro businesses, etc... cannot hope to flourish within the context of the black reality in America: permanent oppression by the white 'power structure.' None of these good and libertarian things can be achieved without first and foremost, getting the white-run U. S. and local and state governments off the backs of the Negro people." In 1993 he rejected the vision of a "separate black nation", asking "does anyone really believe that ... New Africa would be content to strike out on its own, with no massive "foreign aid" from the U.S.A.?". Rothbard also suggested that opposition to King, whom he demeaned as a "coercive integrationist", should be a litmus test for members of his "paleolibertarian" political movement.

Like Randolph Bourne, Rothbard believed that "war is the health of the state". According to David Gordon, this was the reason for Rothbard's opposition to aggressive foreign policy. Rothbard believed that stopping new wars was necessary and that knowledge of how government had led citizens into earlier wars was important. Two essays expanded on these views "War, Peace, and the State" and "Anatomy of the State". Rothbard used insights of Vilfredo Pareto, Gaetano Mosca and Robert Michels to build a model of state personnel, goals and ideology. In an obituary for his friend historical revisionist Harry Elmer Barnes, Rothbard wrote:
Rothbard's colleague Joseph Stromberg notes that Rothbard made two exceptions to his general condemnation of war: "the American Revolution and the War for Southern Independence, as viewed from the Confederate side". Rothbard condemned the "Northern war against slavery", saying it was inspired by "fanatical" religious faith and characterized by "a cheerful willingness to uproot institutions, to commit mayhem and mass murder, to plunder and loot and destroy, all in the name of high moral principle". He celebrated Jefferson Davis, Robert E. Lee and other prominent Confederates as heroes while denouncing Abraham Lincoln, Ulysses S. Grant and other Union leaders for "open[ing] the Pandora's Box of genocide and the extermination of civilians" in their war against the South.

Rothbard's "The Libertarian Forum" blamed the Middle East conflict on Israeli aggression "fueled by American arms and money". Rothbard warned that the Middle East conflict would draw the United States into a world war. He was anti-Zionist and opposed United States involvement in the Middle East. Rothbard criticized the Camp David Accords for having betrayed Palestinian aspirations and opposed Israel's 1982 invasion of Lebanon. In his essay, "War Guilt in the Middle East", Rothbard states that Israel refused "to let these refugees return and reclaim the property taken from them". He took negative views of the two state solution for the Israeli–Palestinian conflict, saying: On the one hand there are the Palestinian Arabs, who have tilled the soil or otherwise used the land of Palestine for centuries; and on the other, there are a group of external fanatics, who come from all over the world, and who claim the entire land area as "given" to them as a collective religion or tribe at some remote or legendary time in the past. There is no way the two claims can be resolved to the satisfaction of both parties. There can be no genuine settlement, no "peace" in the face of this irrepressible conflict; there can only be either a war to the death, or an uneasy practical compromise which can satisfy no one. That is the harsh reality of the Middle East.

Rothbard embraced "historical revisionism" as an antidote to what he perceived to be the dominant influence exerted by corrupt "court intellectuals" over mainstream historical narratives. Rothbard wrote that these mainstream intellectuals distorted the historical record in favor of "the state" in exchange for "wealth, power, and prestige" from the state. Rothbard characterized the revisionist task as "penetrating the fog of lies and deception of the State and its Court Intellectuals, and to present to the public the true history". He was influenced by and called a champion of the historian Harry Elmer Barnes, a Holocaust denier. Rothbard endorsed Barnes's revisionism on World War II, favorably citing his view that "the murder of Germans and Japanese was the overriding aim of World War II". In addition to broadly supporting his historical views, Rothbard promoted Barnes as an influence for future revisionists.

Rothbard's endorsing of World War II revisionism and his association with Barnes and other Holocaust deniers have drawn criticism from within the political right. Kevin D. Williamson wrote an opinion piece published by "National Review" which condemned Rothbard for "making common cause with the 'revisionist' historians of the Third Reich", a term he used to describe American Holocaust deniers associated with Rothbard, such as James J. Martin of the Institute for Historical Review. The piece also characterized "Rothbard and his faction" as being "culpably indulgent" of Holocaust denial, the view which "specifically denies that the Holocaust actually happened or holds that it was in some way exaggerated".

In an article for Rothbard's 50th birthday, Rothbard's friend and Buffalo State College historian Ralph Raico stated that Rothbard "is the main reason that revisionism has become a crucial part of the whole libertarian position".

In the "Ethics of Liberty", Rothbard explores issues regarding children's rights in terms of self-ownership and contract. These include support for a woman's right to abortion, condemnation of parents showing aggression towards children and opposition to the state forcing parents to care for children. He also holds children have the right to run away from parents and seek new guardians as soon as they are able to choose to do so. He argued that parents have the right to put a child out for adoption or sell the rights to the child in a voluntary contract in what Rothbard suggests will be a "flourishing free market in children". He believes that selling children as consumer goods in accord with market forces—while "superficially monstrous"—will benefit "everyone" involved in the market: "the natural parents, the children, and the foster parents purchasing".

In Rothbard's view of parenthood, "the parent should not have a legal obligation to feed, clothe, or educate his children, since such obligations would entail positive acts coerced upon the parent and depriving the parent of his rights". Thus, Rothbard stated that parents should have the legal right to let any infant die by starvation and should be free to engage in other forms of child neglect. However, according to Rothbard, "the purely free society will have a flourishing free market in children". In a fully libertarian society, he wrote, "the existence of a free baby market will bring such 'neglect' down to a minimum".

Economist Gene Callahan of Cardiff University, formerly a scholar at the Rothbard-affiliated Mises Institute, observes that Rothbard allows "the logical elegance of his legal theory" to "trump any arguments based on the moral reprehensibility of a parent idly watching her six-month-old child slowly starve to death in its crib".

Rothbard consistently advocated for abolition of the subpoena power, court attendance, contempt of court powers, coerced testimony of witnesses, compulsory jury duty, and the bail system, arguing that all these functions of the judiciary were violations of natural rights and American common law. He instead advocated that until a defendant is convicted, he or she should not be held in prison or jails, writing that "except in those cases where the criminal has been caught red-handed and where a certain presumption of guilt therefore exists, it is impossible to justify any imprisonment before conviction, let alone before trial. And even when someone is caught red-handed, there is an important reform that needs to be instituted to keep the system honest: subjecting the police and the other authorities to the same law as everyone else. If everyone is supposed to be subject to the same criminal law, then exempting the authorities from that law gives them a legal license to commit continual aggression. The policeman who apprehends a criminal and arrests him, and the judicial and penal authorities who incarcerate him before trial and conviction—all should be subject to the universal law". Rothbard argued that police who make wrongful arrests or indictments should be charged with kidnapping.

In "The Ethics of Liberty", Rothbard advocates for a "frankly retributive theory of punishment" or a system of "a tooth (or two teeth) for a tooth". Rothbard emphasizes that all punishment must be proportional, stating that "the criminal, or invader, loses his rights to the extent that he deprived another man of his". Applying his retributive theory, Rothbard states that a thief "must pay double the extent of theft". Rothbard gives the example of a thief who stole $15,000 and says he not only would have to return the stolen money, but also provide the victim an additional $15,000, money to which the thief has forfeited his right. The thief would be "put in a [temporary] state of enslavement to his victim" if he is unable to pay him immediately. Rothbard also applies his theory to justify beating and torturing violent criminals, although the beatings are required to be proportional to the crimes for which they are being punished.

In chapter twelve of "Ethics", Rothbard turns his attention to suspects arrested by the police. He argues that police should be able to torture certain types of criminal suspects, including accused murderers, for information related to their alleged crime. Writes Rothbard: "Suppose ... police beat and torture a suspected murderer to find information (not to wring a confession, since obviously a coerced confession could never be considered valid). If the suspect turns out to be guilty, then the police should be exonerated, for then they have only ladled out to the murderer a parcel of what he deserves in return; his rights had already been forfeited by more than that extent. But if the suspect is not convicted, then that means that the police have beaten and tortured an innocent man, and that they in turn must be put into the dock for criminal assault". Gene Callahan examines this position and concludes that Rothbard rejects the widely held belief that torture is inherently wrong, no matter who the victim. Callahan goes on to state that Rothbard's scheme gives the police a strong motive to frame the suspect after having tortured him or her.

In an essay condemning "scientism in the study of man", Rothbard rejected the application of causal determinism to human beings, arguing that the actions of human beings—as opposed to those of everything else in nature—are not determined by prior causes, but by "free will". He argued that "determinism as applied to man, is a self-contradictory thesis, since the man who employs it relies implicitly on the existence of free will". Rothbard opposed what he considered the overspecialization of the academy and sought to fuse the disciplines of economics, history, ethics and political science to create a "science of liberty". Rothbard described the moral basis for his anarcho-capitalist position in two of his books: "For a New Liberty", published in 1973; and "The Ethics of Liberty", published in 1982. In his "Power and Market" (1970), Rothbard describes how a stateless economy might function.

As a young man, Rothbard considered himself part of the Old Right, an anti-statist and anti-interventionist branch of the Republican Party. In the 1948 presidential election, Rothbard, "as a Jewish student at Columbia, horrified his peers by organizing a Students for Strom Thurmond chapter, so staunchly did he believe in states' rights". He was a member of The New York Young Republican Club.

By the late 1960s, Rothbard's "long and winding yet somehow consistent road had taken him from anti-New Deal and anti-interventionist Robert A. Taft supporter into friendship with the quasi-pacifist Nebraska Republican Congressman Howard Buffett (father of Warren Buffett) then over to the League of (Adlai) Stevensonian Democrats and, by 1968, into tentative comradeship with the anarchist factions of the New Left". Rothbard advocated an alliance with the New Left anti-war movement on the grounds that the conservative movement had been completely subsumed by the statist establishment. However, Rothbard later criticized the New Left for supporting a "People's Republic" style draft. It was during this phase that he associated with Karl Hess and founded "" with Leonard Liggio and George Resch, which existed from 1965 to 1968.

From 1969 to 1984, he edited "The Libertarian Forum", also initially with Hess (although Hess's involvement ended in 1971). The "Libertarian Forum" provided a platform for Rothbard's writing. Despite its small readership, it engaged conservatives associated with the "National Review" in nationwide debate. Rothbard rejected the view that Ronald Reagan's 1980 election as President was a victory for libertarian principles and he attacked Reagan's economic program in a series of "Libertarian Forum" articles. In 1982, Rothbard called Reagan's claims of spending cuts a "fraud" and a "hoax" and accused Reaganites of doctoring the economic statistics in order to give the false impression that their policies were successfully reducing inflation and unemployment. He further criticized the "myths of Reaganomics" in 1987.

Rothbard criticized the "frenzied nihilism" of left-wing libertarians, but also criticized right-wing libertarians who were content to rely only on education to bring down the state; he believed that libertarians should adopt any moral tactic available to them in order to bring about liberty.

Imbibing Randolph Bourne's idea that "war is the health of the state", Rothbard opposed all wars in his lifetime and engaged in anti-war activism. During the 1970s and 1980s, Rothbard was active in the Libertarian Party. He was frequently involved in the party's internal politics. He was one of the founders of the Cato Institute and "came up with the idea of naming this libertarian think tank after "Cato's Letters", a powerful series of British newspaper essays by John Trenchard and Thomas Gordon which played a decisive influence upon America's Founding Fathers in fomenting the Revolution". From 1978 to 1983, he was associated with the Libertarian Party Radical Caucus, allying himself with Justin Raimondo, Eric Garris and Williamson Evers. He opposed the "low-tax liberalism" espoused by 1980 Libertarian Party presidential candidate Ed Clark and Cato Institute president Edward H Crane III. According to Charles Burris, "Rothbard and Crane became bitter rivals after disputes emerging from the 1980 LP presidential campaign of Ed Clark carried over to strategic direction and management of Cato".

Rothbard split with the Radical Caucus at the 1983 national convention over cultural issues and aligned himself with what he called the "right-wing populist" wing of the party, notably Lew Rockwell and Ron Paul, who ran for President on the Libertarian Party ticket in 1988. Rothbard "worked closely with Lew Rockwell (joined later by his long-time friend Burton Blumert) in nurturing the Ludwig von Mises Institute, and the publication, "The Rothbard-Rockwell Report"; which after Rothbard's 1995 death evolved into the website, "LewRockwell.com"".

In 1989, Rothbard left the Libertarian Party and began building bridges to the post-Cold War anti-interventionist right, calling himself a paleolibertarian, a conservative reaction against the cultural liberalism of mainstream libertarianism. Paleolibertarianism sought to appeal to disaffected working class whites through a synthesis of cultural conservatism and libertarian economics. According to "Reason", Rothbard advocated right-wing populism in part because he was frustrated that mainstream thinkers were not adopting the libertarian view and suggested that former KKK Grand Wizard David Duke and Wisconsin Senator Joseph McCarthy were models for an "Outreach to the Rednecks" effort that could be used by a broad libertarian/paleoconservative coalition. Working together, the coalition would expose the "unholy alliance of 'corporate liberal' Big Business and media elites, who, through big government, have privileged and caused to rise up a parasitic Underclass". Rothbard blamed this "Underclass" for "looting and oppressing the bulk of the middle and working classes in America". Rothbard noted that Duke's substantive political program in a Louisiana governor's race had "nothing" in it that "could not also be embraced by paleoconservatives or paleolibertarians; lower taxes, dismantling the bureaucracy, slashing the welfare system, attacking affirmative action and racial set-asides, calling for equal rights for all Americans, including whites".

Rothbard supported the presidential campaign of Pat Buchanan in 1992 and wrote that "with Pat Buchanan as our leader, we shall break the clock of social democracy". When Buchanan dropped out of the Republican primary race, Rothbard then shifted his interest and support to Ross Perot, who Rothbard wrote had "brought an excitement, a verve, a sense of dynamics and of open possibilities to what had threatened to be a dreary race". Rothbard ultimately supported George H. W. Bush over Bill Clinton in the 1992 election.

Like Buchanan, Rothbard opposed the North American Free Trade Agreement (NAFTA). However, he had become disillusioned with Buchanan by 1995, believing that the latter's "commitment to protectionism was mutating into an all-round faith in economic planning and the nation state".

After Rothbard's death in 1995, Lew Rockwell, president of the Mises Institute, told "The New York Times" that Rothbard was "the founder of right-wing anarchism". William F. Buckley Jr. wrote a critical obituary in the "National Review", criticizing Rothbard's "defective judgment" and views on the Cold War. The Mises Institute published "Murray N. Rothbard, In Memoriam" which included memorials from 31 individuals, including libertarians and academics. Journalist Brian Doherty has summarized Buckley's obituary as follows: "[W]hen Rothbard died in 1995, his old pal William Buckley took pen in hand to piss on his grave". Hoppe, Rockwell, and Rothbard's colleagues at the Mises Institute took a different view, arguing that he was one of the most important philosophers in history.

Articles

Books

Book contributions

Monographs






</doc>
<doc id="20218" url="https://en.wikipedia.org/wiki?curid=20218" title="Mel Brooks">
Mel Brooks

Melvin James Kaminsky (born June 28, 1926), known professionally as Mel Brooks, is an American director, writer, actor, comedian, producer and composer. He is known as a creator of broad film farces and comedic parodies. Brooks began his career as a comic and a writer for Sid Caesar's variety show "Your Show of Shows" (1950–1954) alongside Woody Allen, Neil Simon, and Larry Gelbart. Together with Carl Reiner, he created the comic character The 2000 Year Old Man. He wrote, with Buck Henry, the hit television comedy series "Get Smart", which ran from 1965 to 1970.

In middle age, Brooks became one of the most successful film directors of the 1970s, with many of his films being among the top 10 moneymakers of the year they were released. His best-known films include "The Producers" (1967), "The Twelve Chairs" (1970), "Blazing Saddles" (1974), "Young Frankenstein" (1974), "Silent Movie" (1976), "High Anxiety" (1977), "History of the World, Part I" (1981), "Spaceballs" (1987), and "" (1993). A musical adaptation of his first film, "The Producers", ran on Broadway from 2001 to 2007, and was remade into a musical film in 2005 by Brooks himself.

In 2001, having previously won an Emmy, a Grammy and an Oscar, he joined a small list of EGOT winners with his Tony Award wins for "The Producers". He received a Kennedy Center Honor in 2009, a Hollywood Walk of Fame star in 2010, the 41st AFI Life Achievement Award in June 2013, a British Film Institute Fellowship in March 2015, a National Medal of Arts in September 2016, and a BAFTA Fellowship in February 2017. Three of his films ranked in the American Film Institute's list of the top 100 comedy films of the past 100 years (1900–2000), all of which ranked in the top 15 of the list: "Blazing Saddles" at number 6, "The Producers" at number 11, and "Young Frankenstein" at number 13.

Brooks was married to the actress Anne Bancroft from 1964 until her death in 2005. Their son Max Brooks is an actor and author, known for his novel "" (2006).

Brooks was born Melvyn Kaminsky on June 28, 1926, in Brooklyn, New York, to Max (1895–1929) and Kate (née Brookman) Kaminsky (1896–1989), and grew up in Williamsburg. His father's family were German Jews from Danzig (present-day Gdańsk, Poland); his mother's family were Jews from Kiev, in the Pale of Settlement of the Russian Empire (present-day Ukraine). He had three older brothers: Irving, Lenny, and Bernie. Brooks' father died of kidney disease at 34 when Brooks was 2 years old. He has said of his father's death, "There's an outrage there. I may be angry at God, or at the world, for that. And I'm sure a lot of my comedy is based on anger and hostility. Growing up in Williamsburg, I learned to clothe it in comedy to spare myself problems—like a punch in the face."

Brooks was a small, sickly boy who often was bullied and teased by his classmates because of his size. He grew up in tenement housing. At age 9, Brooks went to a Broadway show with his uncle Joe—a taxi driver who drove the Broadway doormen back to Brooklyn for free and was given the tickets in gratitude—and saw "Anything Goes" with William Gaxton, Ethel Merman and Victor Moore at the Alvin Theater. After the show, he told his uncle that he was not going to work in the garment district like everyone else but was absolutely going into show business.

When Brooks was 14 he gained employment as a pool tummler. Brooks kept his guests amused with his crazy antics. In a "Playboy" interview Brooks explained that one day he stood at the edge of a diving board wearing a large overcoat and 2 suitcases full of rocks who then announced: "Business is terrible! I can't go on!" before jumping, fully clothed into the pool. He was taught by Buddy Rich (who had also grown up in Williamsburg) how to play the drums and started to earn money as a musician when he was 14. During Brooks' time as a drummer he was given his first opportunity as a comedian at the age of 16 following an ill MC. During his teens, Melvyn Kaminsky officially changed his name to Mel Brooks, influenced by his mother's maiden name Brookman, after being confused with the trumpeter Max Kaminsky.

Brooks graduated from Eastern District High School. He also studied psychology at Brooklyn College for one year.

Brooks was drafted into the United States Army in 1944. After scoring highly on the Army General Classification Test—a Stanford–Binet-type IQ test—he was sent to the elite Army Specialized Training Program at the Virginia Military Institute to be taught skills such as military engineering, foreign languages, or medicine.

Manpower shortages led the Army to disband the training program so Brooks returned to basic training at Fort Sill, Oklahoma, in May 1944.

Brooks served as a corporal in the 1104th Engineer Combat Battalion, 78th Infantry Division, defusing land mines as the allies advanced into Nazi Germany. With the end of the war in Europe, Brooks took part in organizing shows for captured Germans and American forces.

After the war, Brooks started working in various Borscht Belt resorts and nightclubs in the Catskill Mountains as a drummer and pianist. After a regular comic at one of the nightclubs was too sick to perform one night, Brooks started working as a stand-up comic, telling jokes and doing movie-star impressions. He also began acting in summer stock in Red Bank, New Jersey, and did some radio work. He eventually worked his way up to the comically aggressive job of tummler (master entertainer) at Grossinger's, one of the Borscht Belt's most famous resorts. Brooks found more rewarding work behind the scenes, becoming a comedy writer for television. In 1949, his friend Sid Caesar hired Brooks to write jokes for the DuMont/NBC series "The Admiral Broadway Revue", paying him $50 a week.

In 1950, Caesar created the revolutionary variety comedy series "Your Show of Shows" and hired Brooks as a writer along with Carl Reiner, Neil Simon, Danny Simon, and head writer Mel Tolkin. The writing staff proved widely influential. Reiner, as creator of "The Dick Van Dyke Show", based Morey Amsterdam's character Buddy Sorell on Brooks. Likewise, the film "My Favorite Year" (1982) is loosely based on Brooks' experiences as a writer on the show including an encounter with the actor Errol Flynn. Neil Simon's play "Laughter on the 23rd Floor" (1993) is also loosely based on the production of the show, and the character Ira Stone is based on Brooks. "Your Show of Shows" ended in 1954 when performer Imogene Coca left to host her own show. Caesar then created "Caesar's Hour" with most of the same cast and writers (including Brooks and adding Woody Allen and Larry Gelbart). "Caesar's Hour" ran from 1954 until 1957.

Brooks and co-writer Reiner had become close friends and began to casually improvise comedy routines when they were not working. Reiner played the straight-man interviewer and set Brooks up as anything from a Tibetan monk to an astronaut. As Reiner explained: "In the evening, we'd go to a party and I'd pick a character for him to play. I never told him what it was going to be." On one of these occasions, Reiner's suggestion concerned a 2000 year-old-man who had witnessed the crucifixion of Jesus Christ (who "came in the store but never bought anything"), had been married several hundred times, and had "over forty-two thousand children, and not one comes to visit me." At first Brooks and Reiner only performed the routine for friends but, by the late 1950s, it gained a reputation in New York City. Kenneth Tynan saw the comedy duo perform at a party in 1959 and wrote that Brooks "was the most original comic improvisor I had ever seen."

In 1960, Brooks moved from New York to Hollywood. He and Reiner began performing the "2000 Year Old Man" act on "The Steve Allen Show". Their performances led to the release of the comedy album "2000 Years with Carl Reiner and Mel Brooks" that sold over a million copies in 1961. They eventually expanded their routine with two more albums in 1961 and 1962, a revival in 1973, a 1975 animated TV special, and a reunion album in 1998. At one point, when Brooks had financial and career struggles, the record sales from the 2000 Year Old Man were his chief source of income.

Brooks adapted the 2000 Year Old Man character to create the 2500 Year Old Brewmaster for Ballantine Beer in the 1960s. Interviewed by Dick Cavett in a series of ads, the Brewmaster (in a German accent, as opposed to the 2000 Year Old Man's Yiddish accent) said he was inside the original Trojan horse and "could've used a six-pack of fresh air."

Brooks was involved in the creation of the Broadway musical "All American" which debuted on Broadway in 1962. Brooks wrote the play with lyrics by Lee Adams, and music by Charles Strouse. The show starred Ray Bolger as a southern science professor at a large university who uses the principles of engineering on the college's football team and the team begins to win games. The show was directed by Joshua Logan, whose script doctored the second act and added a gay subtext to the plot. The show ran for 80 performances and received two Tony Award nominations.

The animated short film "The Critic" (1963), a satire of arty, esoteric cinema, was conceived by Brooks and directed by Ernest Pintoff. Brooks supplied running commentary as the baffled moviegoer trying to make sense of the obscure visuals. The short film won the Academy Award for Animated Short Film.

With comedy writer Buck Henry, Brooks created a comedic TV show titled "Get Smart" about a bumbling James Bond-inspired spy. Brooks explains: "I was sick of looking at all those nice sensible situation comedies. They were such distortions of life... I wanted to do a crazy, unreal comic-strip kind of thing about something besides a family. No one had ever done a show about an idiot before. I decided to be the first." The show stars Don Adams as Maxwell Smart, Agent 86. The series ran from 1965 until 1970, although Brooks had little involvement after the first season. "Get Smart" was highly rated for most of its production and won seven Emmy Awards, including Outstanding Comedy Series in 1968 and 1969.

For several years, Brooks had been toying with a bizarre and unconventional idea about a musical comedy of Adolf Hitler. Brooks explored the idea as a novel and a play before finally writing a script. Eventually, he was able to find two producers to fund the show, Joseph E. Levine and Sidney Glazier, and made his first feature film, "The Producers" (1967).

"The Producers" was so brazen in its satire that major studios would not touch it, nor would many exhibitors. Brooks finally found an independent distributor who released it as an art film, a specialized attraction. At the 41st Academy Awards, Brooks won the Oscar for Best Original Screenplay for the film over fellow writers Stanley Kubrick and John Cassavetes. "The Producers" became a smash underground hit, first on the nationwide college circuit, then in revivals and on home video. Brooks later turned it into a musical, which became hugely successful on Broadway, receiving an unprecedented twelve Tony awards.

With the moderate financial success of the film "The Producers", Glazier financed Brooks' next film, "The Twelve Chairs" (1970). Loosely based on Ilf and Petrov's 1928 Russian novel of the same name about greedy materialism in post-revolutionary Russia, the film stars Ron Moody, Frank Langella, and Dom DeLuise as three men individually searching for a fortune in diamonds hidden in a set of 12 antique chairs. Brooks makes a cameo appearance as an alcoholic ex-serf who "yearns for the regular beatings of yesteryear." The film was shot in Yugoslavia with a budget of $1.5 million. The film received poor reviews and was not financially successful.

Brooks then wrote an adaptation of Oliver Goldsmith's "She Stoops to Conquer", but was unable to sell the idea to any studio and believed that his career was over. In 1972, Brooks met agent David Begelman, who helped him set up a deal with Warner Brothers to hire Brooks (as well as Richard Pryor, Andrew Bergman, Norman Steinberg, and Al Uger) as a script doctor for an unproduced script called "Tex-X". Eventually, Brooks was hired as director for what became "Blazing Saddles" (1974), his third film.

"Blazing Saddles" starred Cleavon Little, Gene Wilder, Harvey Korman, Slim Pickens, Madeline Kahn, Alex Karras, and Brooks himself, with cameos by Dom DeLuise and Count Basie. The film had music by Brooks and John Morris, and had a modest budget of $2.6 million. This film is a satire on the Western film genre and references older films such as "Destry Rides Again" (1939), "High Noon" (1952), "Once Upon a Time in the West" (1968), and "The Treasure of the Sierra Madre" (1948), as well as a surreal scene towards the end of the film referencing the extravagant musicals of Busby Berkeley.

Upon its release, "Blazing Saddles" was the second-highest US grossing film of 1974, earning $119.5 million worldwide. Despite mixed reviews, the film was a success with younger audiences. It was nominated for three Academy Awards: Best Actress in a Supporting Role for Madeline Kahn, Best Film Editing, and Best Music, Original Song. The film won the Writers Guild of America Award for "Best Comedy Written Directly for the Screen" and in 2006 it was deemed "culturally, historically or aesthetically significant" by the Library of Congress and was selected for preservation in the National Film Registry. Brooks has said that the film "has to do with love more than anything else. I mean when that black guy rides into that Old Western town and even a little old lady says 'Up yours, nigger!', you know that his heart is broken. So it's really the story of that heart being mended."

When Gene Wilder replaced Gig Young as the Waco Kid, he did so only if Brooks agreed that his next film would be an idea that Wilder had been working on; a spoof of the Universal series of "Frankenstein" films from several decades earlier. After the filming of "Blazing Saddles" was completed, Wilder and Brooks began writing the script for "Young Frankenstein" and shot the film in the spring of 1974. It starred Wilder, Marty Feldman, Peter Boyle, Teri Garr, Madeline Kahn, Cloris Leachman and Kenneth Mars, with Gene Hackman in a cameo role. Brooks' voice can be heard three times, first as the wolf howl when the characters are on their way to the castle, second as the voice of Victor Frankenstein when the characters discover the laboratory, and third as the cat sound when Gene Wilder accidentally throws a dart out of the window in a scene with Kenneth Mars. Composer John Morris again provided the music score and Universal monsters film special effects veteran Kenneth Strickfaden worked on the film.

"Young Frankenstein" was the third-highest-grossing film domestically of 1974, just behind "Blazing Saddles". It earned $86 million worldwide and received two Academy Award nominations: Academy Award for Writing Adapted Screenplay and Academy Award for Best Sound. It received some of the best reviews of Brooks' career and even critic Pauline Kael liked the film, saying: "Brooks makes a leap up as a director because, although the comedy doesn't build, he carries the story through ... Brooks even has a satisfying windup, which makes this just about the only comedy of recent years that doesn't collapse."

In 1975, at the height of his movie career, Brooks tried TV again with "When Things Were Rotten", a Robin Hood parody that lasted only 13 episodes. Nearly 20 years later, in response to the 1991 hit film "", Brooks mounted another Robin Hood parody with "" (1993). Brooks' film resurrected several pieces of dialogue from his TV series, as well as from earlier Brooks films.

Brooks followed up his two hit films with an audacious idea: the first feature-length silent comedy in four decades. "Silent Movie" (1976) was written by Brooks and Ron Clark, starring Brooks in his first leading role, Dom DeLuise, Marty Feldman, Sid Caesar, Bernadette Peters, and in cameo roles playing themselves: Paul Newman, Burt Reynolds, James Caan, Liza Minnelli, Anne Bancroft, and the non-speaking Marcel Marceau who ironically uttered the film's only word of audible dialogue: "Non!" Although not as successful as his previous two films, "Silent Movie" was a hit and grossed $36 million. Later that year, Brooks was named number 5 on a list of the Top Ten Box Office Stars.

Brooks' parody of the films of Alfred Hitchcock in "High Anxiety" (1977) was written by Brooks, Ron Clark, Rudy De Luca, and Barry Levinson. It was the first movie produced by Brooks himself. It starred Brooks, Madeline Kahn, Cloris Leachman, Harvey Korman, Ron Carey, Howard Morris, and Dick Van Patten. The film satirizes such Hitchcock films as "Vertigo", "Spellbound", "Psycho", "The Birds", "North by Northwest", "Dial M for Murder", and "Suspicion". Brooks stars as Professor Richard H. (for Harpo) Thorndyke, a Nobel Prize-winning psychologist who also happens to suffer from "high anxiety".

By 1980, Gene Siskel and Roger Ebert had referred to Mel Brooks and Woody Allen as "the two most successful comedy directors in the world today ... America's two funniest filmmakers." Released that year was the dramatic film "The Elephant Man" directed by David Lynch and produced by Brooks. Knowing that anyone seeing a poster reading "Mel Brooks presents "The Elephant Man"" would expect a comedy, he set up the company Brooksfilms. Brooksfilms has since produced a number of non-comedy films, including "Frances" (1982), "The Fly" (1986), and "84 Charing Cross Road" (1987), starring Anthony Hopkins and Anne Bancroft, along with comedies, including Richard Benjamin's "My Favorite Year" (1982), which was partially based on Mel Brooks' real life. Brooks sought to purchase the rights to "84 Charing Cross Road" for his wife, Anne Bancroft, for many years. He also produced the comedy "Fatso" (1980) that Bancroft directed.

In 1981, Brooks joked that the only genres that he had not spoofed were historical epics and Biblical spectacles. "History of the World Part I" was a tongue-in-cheek look at human culture from the Dawn of Man to the French Revolution. The film was written, produced, and directed by Brooks with narration by Orson Welles. This film was another modest financial hit, earning $31 million. It received mixed critical reviews. Critic Pauline Kael, who for years had been critical of Brooks, said: "Either you get stuck thinking about the bad taste or you let yourself laugh at the obscenity in the humor as you do Buñuel's perverse dirty jokes."

Brooks produced and starred in (but did not write or direct) a remake of Ernst Lubitsch's 1942 film "To Be or Not to Be". Brooks' 1983 version was directed by Alan Johnson and starred Brooks, Anne Bancroft, Charles Durning, Tim Matheson, Jose Ferrer, and Christopher Lloyd. The film garnered international publicity by featuring a controversial song on its soundtrack—"To Be or Not to Be (The Hitler Rap)"—satirizing German society in the 1940s with Brooks playing Hitler.

The second movie Brooks directed in the 1980s came in the form of "Spaceballs" (1987), a parody of science fiction, mainly "Star Wars". The film starred Bill Pullman, John Candy, Rick Moranis, Daphne Zuniga, Dick Van Patten, Joan Rivers, Dom DeLuise, and Brooks. In 1989, Brooks (with co-executive producer Alan Spencer) made another attempt at television success with the sitcom "The Nutt House", which featured Brooks regulars Harvey Korman and Cloris Leachman and was originally broadcast on NBC, but the network only aired five of the eleven episodes produced before canceling the series. During the next decade, Brooks directed "Life Stinks" (1991), "" (1993), and "" (1995). "People" magazine suggested, "anyone in a mood for a hearty laugh couldn't do better than "Robin Hood: Men in Tights", which gave fans a parody of Robin Hood, especially ""."

Like Brooks' other films, it is filled with one-liners and even the occasional breaking of the fourth wall. "Robin Hood: Men in Tights" was Brooks' second time exploring the life of Robin Hood, the first, as mentioned above, having been with his 1975 TV show, "When Things Were Rotten". "Life Stinks" was a financial and critical failure, but is notable as being the only film that Brooks directed that is neither a parody nor a film about other films or theater. ("The Twelve Chairs" was actually a parody of the original novel.) In the 2000s, Brooks worked on an animated series sequel to "Spaceballs" called "", which premiered on September 21, 2008, on G4 TV. Brooks has also supplied vocal roles for animation. He voiced Bigweld, the master inventor, in the animated film "Robots" (2005), and in the later animated film "Mr. Peabody & Sherman" (2014) he had a cameo appearance as Albert Einstein. He returned, to voice Dracula's father, Vlad, in "Hotel Transylvania 2" (2015) and "" (2018).

The musical adaptation of his film "The Producers" to the Broadway stage broke the Tony record with 12 wins, a record that had previously been held for 37 years by "Hello, Dolly!" at 10 wins. This success led to a big-screen version of the Broadway adaptation/remake with actors Matthew Broderick, Nathan Lane, Gary Beach, and Roger Bart reprising their stage roles, in addition to new cast members Uma Thurman and Will Ferrell in 2005. In early April 2006, Brooks began composing the score to a Broadway musical adaptation of "Young Frankenstein", which he says is "perhaps the best movie [he] ever made." The world premiere was performed at Seattle's Paramount Theater, between August 7, 2007, and September 1, 2007, after which it opened on Broadway at the former Lyric Theater (then the Hilton Theatre), New York, on October 11, 2007. It earned mixed reviews from the critics.

Brooks joked about the concept of a musical adaptation of "Blazing Saddles" in the final number in "Young Frankenstein", in which the full company sings, "next year, "Blazing Saddles"!" In 2010, Mel Brooks confirmed this, saying that the musical could be finished within a year. No creative team or plan has been announced.

Brooks is one of the few people who have received an Oscar, an Emmy, a Tony, and a Grammy. He was awarded his first Grammy for Best Spoken Comedy Album in 1999 for his recording of "The 2000 Year Old Man in the Year 2000" with Carl Reiner. His two other Grammys came in 2002 for Best Musical Show Album for the cast album of "The Producers" and for Best Long Form Music Video for the DVD "Recording the Producers – A Musical Romp with Mel Brooks". He won his first of four Emmy awards in 1967 for Outstanding Writing Achievement in Variety for a Sid Caesar special and went on to win three consecutive Emmys in 1997, 1998, and 1999 for Outstanding Guest Actor in a Comedy Series for his role of Uncle Phil on "Mad About You". Brooks won his Academy Award for Original Screenplay (Oscar) in 1968 for "The Producers". He won his three Tony awards in 2001 for his work on the musical, "The Producers" for Best Musical, Best Original Musical Score, and Best Book of a Musical.

Brooks won a Hugo Award and a Nebula Award for "Young Frankenstein". In a 2005 poll by Channel 4 to find "The Comedian's Comedian", he was voted No. 50 of the top 50 comedy acts ever by fellow comedians and comedy insiders.

The American Film Institute (AFI) list three of Brooks' films on their AFI's 100 Years...100 Laughs list: "Blazing Saddles" (#6), "The Producers" (#11), and "Young Frankenstein" (#13).

On December 5, 2009, Brooks was one of five recipients of the 2009 Kennedy Center Honors at the John F. Kennedy Center for the Performing Arts in Washington, DC. He was inducted into the Hollywood Walk of Fame on April 23, 2010 with a motion pictures star located at 6712 Hollywood Boulevard. American Masters produced a biography on Brooks which premiered May 20, 2013, on PBS. The AFI presented Brooks with its highest tribute, the AFI Life Achievement Award, in June 2013. In 2014 Brooks was honored in a handprint and footprint ceremony at TCL Chinese Theatre. His concrete handprints include a six-fingered left hand as he wore a prosthetic finger when making his prints. On March 20, 2015, Brooks was awarded a British Film Institute Fellowship from the British Film Institute.

Brooks was married to Florence Baum (1926–2008) from 1953 to 1962, their marriage ending in divorce. They had three children: Stephanie, Nicky, and Eddie. Brooks married stage, film and television actress Anne Bancroft in 1964, and they remained together until her death in 2005. They met at a rehearsal for the "Perry Como Variety Show" in 1961, and were married three years later on August 5, 1964, at the Manhattan Marriage Bureau. Their son, Max Brooks, was born in 1972, and their grandson, Henry Michael Brooks, was born in 2005.

In 2010, Brooks credited Bancroft with having been "the guiding force" behind his involvement in developing "The Producers" and "Young Frankenstein" for the musical theater, saying of an early meeting with her: "From that day, until her death ... we were glued together."

Regarding religion, Brooks stated, "I'm rather secular. I'm basically Jewish. But I think I'm Jewish not because of the Jewish religion at all. I think it's the relationship with the people and the pride I have. The tribe surviving so many misfortunes, and being so brave and contributing so much knowledge to the world and showing courage."On Jewish cinema, Brooks said,"They can be anything and anywhere … if there’s a tribal thing, like, the ‘please God, protect us’ feeling … we don’t know where and how it’s gonna come out. Avatar was a Jewish movie … these people on the run, chasing—and being pursued.”




</doc>
<doc id="20219" url="https://en.wikipedia.org/wiki?curid=20219" title="Mycoplasma genitalium">
Mycoplasma genitalium

Mycoplasma genitalium (MG, commonly known as Mgen), is a sexually transmitted, small and pathogenic bacterium that lives on the skin cells of the urinary and genital tracts in humans. Medical reports published in 2007 and 2015 state Mgen is becoming increasingly common. Resistance to multiple antibiotics is occurring, including azithromycin which until recently was the most reliable treatment. The bacteria was first isolated from urogenital tract of humans in 1981, and was eventually identified as a new species of "Mycoplasma" in 1983. It can cause negative health effects in men and women. It also increases the risk factor for HIV spread with higher occurrences in homosexual men and those previously treated with the azithromycin antibiotics.

Specifically, it causes urethritis in both men and women, and also cervicitis and pelvic inflammation in women. It presents clinically similar symptoms to that of "Chlamydia trachomatis" infection and has shown higher incidence rates, compared to both "Chlamydia trachomatis" and "Neisseria gonorrhoeae" infections in some populations. Its complete genome sequence was published in 1995 (size 0.58 Mbp, with 475 genes). It was regarded as a cellular unit with the smallest genome size (in Mbp) until 2003 when a new species of Archaea, namely "Nanoarchaeum equitans", was sequenced (0.49 Mbp, with 540 genes). However, Mgen still has the smallest genome of any known (naturally occurring) self-replicating organism and thus is often the organism of choice in minimal genome research.

The synthetic genome of Mgen named "Mycoplasma genitalium" JCVI-1.0 (after the research centre, J. Craig Venter Institute, where it was synthesised) was produced in 2008, becoming the first organism with a synthetic genome. In 2014, a protein was described called Protein M from "M. genitalium".

Infection with Mgen produces a combination of clinical symptoms, but can be asymptomatic. It causes inflammation in the urethra (urethritis) both in men and women, which is associated with mucopurulent discharge in the urinary tract, and burning while urinating. In women, it causes cervicitis and pelvic inflammatory diseases (PID), including endometritis and salpingitis. Women may also experience bleeding after sex and it is also linked with tubal factor infertility. For men, the most common signs are painful urination or a watery discharge from the penis. Polymerase chain reaction analyses indicated that it is a cause of acute non-gonococcal urethritis (NGU) and probably chronic NGU. It is strongly associated with persistent and recurring non-gonococcal urethritis (NGU) responsible for 15 percent to 20 percent of symptomatic NGU cases in men. Unlike other "Mycoplasma", the infection is not associated with bacterial vaginosis. It is highly associated with the intensity of HIV infection. Some scientists are doing research to see if Mgen could play a role in the development of prostate and ovarian cancers and lymphomas in some individuals. These studies have yet to find conclusive evidence to suggest a link.

The genome of "M. genitalium" consists of 525 genes in one circular DNA of 580,070 base pairs. Scott N. Peterson and his team at the University of North Carolina at Chapel Hill reported the first genetic map using pulsed-field gel electrophoresis in 1991. They performed an initial study of the genome using random sequencing in 1993, by which they found 100,993 nucleotides and 390 protein-coding genes. Collaborating with researchers at the Institute for Genomic Research, which included Craig Venter, they made the complete genome sequence in 1995 using shotgun sequencing. Only 470 predicted coding regions (out of 482 protein encoding genes) were identified, including genes required for DNA replication, transcription and translation, DNA repair, cellular transport, and energy metabolism. It was the second complete bacterial genome ever sequenced, after "Haemophilus influenzae". In 2006, the team at the J. Craig Venter Institute reported that only 382 genes are essential for biological functions. The small genome of "M. genitalium" made it the organism of choice in The Minimal Genome Project, a study to find the smallest set of genetic material necessary to sustain life.

There is a consistent association of "M. genitalium" infection and female reproductive tract syndromes. "M. genitalium" infection was significantly associated with increased risk of preterm birth, spontaneous abortion, cervicitis, and pelvic inflammatory disease. In addition, this pathogen may latently infect the chorionic villi tissues of pregnant women, thereby impacting pregnancy outcome. Infertility risk is also strongly associated with infection with "M. genitalium", although evidence suggests it is not associated with male infertility. When "M. genitalium" is a co-infectious agent risk associations are stronger and statistically significant. "M. genitalium" is strongly associated with HIV-1.

Recent research shows that prevalence of Mgen is currently higher than other commonly occurring STIs (Sexually Transmitted Infections). Mgen is a fastidious organism with prolonged growth durations. This makes detection of the pathogen in clinical specimens and subsequent isolation, extremely difficult. Lacking a cell wall, mycoplasma remains unaffected by commonly used antibiotics. The absence of specific serological assays leaves nucleic acid amplification tests (NAAT) as the only viable option for detection of Mgen DNA or RNA. However, samples with positive NAAT for the pathogen should be tested for macrolide resistance mutations, which are strongly correlated to azithromycin treatment failures, owing to rapid rates of mutation of the pathogen. Mutations in the 23S rRNA gene of Mgen have been linked with clinical treatment failure and high level in vitro macrolide resistance. Macrolide resistance mediating mutations have been observed in 20-50% of cases in the UK, Denmark, Sweden, Australia, and Japan. Resistance is also developing towards the second-line antimicrobials like fluoroquinolone.

According to the European guidelines, the indication for commencement of diagnosis for Mgen infection are:


Screening for Mgen with a combination of detection and macrolide resistance mutations will provide the adequate information required to develop personalised antimicrobial treatments, in order to optimise patient management and control the spread of antimicrobial resistance (AMR).

Owing to the widespread macrolide resistance, samples that are positive for Mgen should ideally be followed up with an assay capable of detecting mutations that mediate antimicrobial resistance. The European Guideline on Mgen infections, in 2016, recommended complementing the molecular detection of Mgen with an assay capable of detecting macrolide resistance-associated mutations.

The U.S. Centers for Disease Control and Prevention has one specific recommended regimen with azithromycin and another specific recommended regimen with doxycycline. As alternative regimens, the agency has specific regimens each with erythromycin or erythromycin ethylsuccinate or ofloxacin or levofloxacin.

Treatment of "Mycoplasma genitalium" infections is becoming increasingly difficult due to rapidly growing antimicrobial resistance. Diagnosis and treatment is further hampered by the fact that "Mycoplasma genitalium" infections are not routinely tested. Studies have demonstrated that a 5-day course of azithromycin has a superior cure rate compared to a single, larger dose. Further, a single dose of azithromycin can lead to the bacteria becoming resistant to azithromycin. Among Swedish patients, doxycycline was shown to be relatively ineffective (with a cure rate of 48% for women and 38% for men); and treatment with a single dose of azithromycin is not prescribed due to it inducing antimicrobial resistance. The five-day treatment with azithromycin showed no development of antimicrobial resistance. Based on these findings, UK doctors are moving to the 5-day azithromycin regimen. Doxycycline is also still used, and moxifloxacin is used as a second-line treatment in case doxycyline and azithromycin are not able to eradicate the infection.
In patients where doxycycline, azithromycin and moxifloxacin all failed, pristinamycin has been shown to still be able to eradicate the infection.

"Mycoplasma genitalium" was originally isolated in 1980 from urethral specimens of two male patients suffering from non-gonococcal urethritis in the genitourinary medicine (GUM) clinic at St Mary's Hospital, Paddington, London. It was reported in 1981 by a team led by Joseph G. Tully. Under electron microscopy, it appears as a flask-shaped cell with a narrow terminal portion that is crucial for its attachment to the host cell surfaces. The bacterial cell is slightly elongated somewhat like a vase, and measures 0.6-0.7 μm in length, 0.3-0.4 μm at the broadest region, and 0.06-0.08 μm at the tip. The base is broad while the tip is stretched into a narrow neck, which terminates with a cap. The terminal region has a specialised region called nap, which is absent in other "Mycoplasma". Serological tests indicated that the bacterium was not related to known species of "Mycoplasma". The comparison of genome sequences with other urinogenital bacteria, such as "M. hominis" and "Ureaplasma parvum", revealed that "M. genitalium" is significantly different, especially in the energy-generating pathways, although it shared a core genome of ~250 protein-encoding genes.

On 6 October 2007, Craig Venter announced that a team of scientists led by Nobel laureate Hamilton Smith at the J. Craig Venter Institute had successfully constructed synthetic DNA with which they planned to make the first synthetic genome. Reporting in "The Guardian", Venter said that they had stitched together a DNA strand containing 381 genes, consisting of 580,000 base pairs, based on the genome of "M. genitalium". On 24 January 2008, they announced the successful creation of a synthetic bacterium, which they named "Mycoplasma genitalium" JCVI-1.0 (the name of the strain indicating J. Craig Venter Institute with its specimen number). They synthesised and assembled the complete 582,970-base pair genome of the bacterium. The final stages of synthesis involved cloning the DNA into the bacterium "E. coli" for nucleotide production and sequencing. This produced large fragments of approximately 144,000 base pairs or 1/4th of the whole genome. Finally, the products were cloned inside the yeast "Saccharomyces cerevisiae" to synthesize the 580,000 base pairs. The molecular size of the synthetic bacterial genome is 360,110 kilodaltons (kDa). Printed in 10-point font, the letters of the genome cover 147 pages.

On 20 July 2012, Stanford University and the J. Craig Venter Institute announced successful simulation of the complete life cycle of a "Mycoplasma genitalium" cell, in the journal "Cell". The entire organism is modeled in terms of its molecular components, integrating all cellular processes into a single model. Using object oriented programming to model the interactions of 28 categories of molecules, including DNA, RNA, proteins, and metabolites, and running on a 128-core Linux cluster, the simulation takes 10 hours for a single "M. genitalium" cell to divide once — about the same time the actual cell takes — and generates half a gigabyte of data.

The discovery of Protein M, a new protein from "M. genitalium", was announced in February 2014. The protein was identified during investigations on the origin of multiple myeloma, a B-cell hematologic neoplasm. To understand the long-term "Mycoplasma" infection, it was found that antibodies from multiple myeloma patients' blood were recognised by "M. genitalium". The antibody reactivity was due to a protein never known before, and is chemically responsive to all types of human and nonhuman antibodies available. The protein is about 50 kDa in size, and composed of 556 amino acids.

Future research must focus on the development of novel antimicrobials and treatment algorithms that emphasize on dual antimicrobial therapy and AMR testing in treatment protocols. Importantly, most patients with MG are treated syndromically and this treatment is even more compromised by the emerging resistances to several antimicrobials. This also stresses the importance of evidence-based knowledge regarding the activity of novel antimicrobials against several pathogens that cause STIs. The rapid development of AMR in Mgen suggests that single-dose antimicrobial monotherapy may be inappropriate even for uncomplicated STIs. For Mgen, antimicrobial combination therapy and AMR testing, in conjunction with the development and evaluation of new classes of antimicrobials, are of utmost importance. Some of the novel antimicrobials, particularly the fluoroketolide solithromycin, might at least temporarily replace azithromycin in the treatment of Mgen. Ultimately, the only sustainable solution to control these infections might be the development of vaccines, a task that remains to be incredibly difficult with most pathogens of commonly occurring STIs, being unculturable.



</doc>
<doc id="20221" url="https://en.wikipedia.org/wiki?curid=20221" title="Mehmet Ali Ağca">
Mehmet Ali Ağca

Mehmet Ali Ağca (; born 9 January 1958) is a Turkish assassin and Grey Wolves member who murdered left-wing journalist Abdi İpekçi on 1 February 1979, and later shot and wounded Pope John Paul II on 13 May 1981, after escaping from a Turkish prison. After serving 19 years of imprisonment in Italy where he was visited by the Pope, he was deported to Turkey, where he served a ten-year sentence. In 2007, he converted to Roman Catholicism and was released from jail on 18 January 2010. Ağca has described himself as a mercenary with no political orientation, although he is known to have been a member of the Turkish ultra-nationalist Grey Wolves organization and the state-sponsored Counter-Guerrilla.

On 27 December 2014, 33 years after his crime, Mehmet Ali Ağca publicly arrived at the Vatican to lay white roses on the recently canonized John Paul II's tomb and said he wanted to meet Pope Francis – a request that was denied.

Ağca was born in the Hekimhan district, Malatya Province in Turkey. As a youth, he became a petty criminal and a member of numerous street gangs in his hometown. He became a smuggler between Turkey and Bulgaria. He claims to have received two months of training in weaponry and terrorist tactics in Syria as a member of the Marxist Popular Front for the Liberation of Palestine paid for by the Communist Bulgarian government, although the PFLP has denied this.

After training, Mehmet Ali Ağca went to work for the ultranationalist Turkish organization Grey Wolves.

On 1 February 1979, in Istanbul, under orders from the Grey Wolves, he murdered Abdi İpekçi, editor of the major Turkish newspaper "Milliyet". After being denounced by an informant, he was caught and sentenced to life in prison. After serving six months, he escaped with the help of Abdullah Çatlı, second-in-command of the Grey Wolves, and fled to Bulgaria, which was a base of operations for the Turkish mafia. According to investigative journalist Lucy Komisar, Mehmet Ali Ağca had worked in the 1979 assassination with Abdullah Çatlı, who “then reportedly helped organize Ağca's escape from an Istanbul military prison”. According to Komisar, “some have suggested Çatlı was even involved in the Pope's assassination attempt”. According to Reuters, Ağca had "escaped with suspected help from sympathizers in the security services". Lucy Komisar added that at the scene of the Mercedes-Benz crash where Çatlı died, he was found with a passport under the name of "Mehmet Özbay" — an alias also used by Mehmet Ali Ağca.

 Beginning in August 1980, Ağca began criss-crossing the Mediterranean region.

According to Ağca's later testimony, he met with three accomplices in Rome, one a fellow Turk and the other two Bulgarians. The operation was commanded by Zilo Vassilev, the Bulgarian military attaché in Italy. He said that he was assigned this mission by Turkish mafioso Bekir Çelenk in Bulgaria. "Le Monde diplomatique", however, has alleged that the assassination attempt was organized by Abdullah Çatlı "in exchange for the sum of 3 million marks", paid by Bekir Çelenk to the Grey Wolves.

According to Ağca, the plan was for him and the back-up gunman Oral Çelik to open fire in St. Peter's Square and escape to the Bulgarian embassy under the cover of the panic generated by a small explosion. On 13 May they sat in the square, writing postcards and waiting for the Pope to arrive. When the Pope passed them, Ağca fired several shots and wounded him, but was grabbed by spectators and Vatican security chief Camillo Cibin. This prevented him from finishing the assassination or escaping. Four bullets hit John Paul II, two of them lodging in his lower intestine, the others hitting his left hand and right arm. Two bystanders were also hit. Çelik panicked and fled without setting off his bomb or opening fire. The Pope survived the assassination attempt.

Ağca was sentenced in July 1981 to life imprisonment in Italy for the assassination attempt. Following his shooting, Pope John Paul II asked people to "pray for my brother (Ağca), whom I have sincerely forgiven." In 1983, the pope and Ağca met and spoke privately at the prison where Ağca was being held. The Pope was also in touch with Ağca's family over the years, meeting his mother in 1987 and his brother a decade later. 

On 9 June 1997, Air Malta Flight 830 was hijacked by two men. After landing in Cologne, the hijackers demanded the release of Ağca. He was not released and the hijackers surrendered.

After serving almost 20 years of a life sentence in prison in Italy, at the request of Pope John Paul II, Ağca was pardoned by the then Italian president Carlo Azeglio Ciampi in June 2000 and deported to Turkey.

Following his extradition to Turkey, he was imprisoned for the 1979 murder of Abdi İpekçi and for two bank raids carried out in the 1970s. Ağca was arrested on 25 June and incarcerated in the Maltepe Military Prison. He fled to Bulgaria on 25 November and was sentenced to death "in absentia". Ağca was extradited to Turkey in 2000 by benefiting from the Conditional Amnesty Law. This consideration granted to the ex-convict elicited strong reactions. Both cases about Ağca were merged and tried before the Kadıköy 1st High Criminal Court. The single trial concerned the hijacking of Cengiz Aydos's taxi in 1979, robbing the Yıldırım jewelry store in Kızıltoprak on 22 March 1979 and stealing money from the Fruko soda storage on 4 April 1979. On 18 January 2000, the judges dismissed the charges because of the statute of limitation on the case filed for the jewelry store robbery and for "breach of the Firearms Act" (law no. 6136). For embezzlement and money theft Ağca was sentenced to 36 years of imprisonment. Ağca's lawyers applied for their client's release under Law no. 4516 on Parole and Deferral of Penalties in December 2000. Their request was denied by the 1st High Criminal Court of Kartal. The lawyers filed an appeal against this decision, but the appeals court upheld the ruling. Ağca's life sentence was reduced to 10 years in prison for murder under a Turkish law that shortened prison sentences if served in a foreign prison. The money-laundering conviction and 36-year sentence were overturned because of the statute of limitations for robbery, which was 7 years under Turkish law.

In early February 2005, during the Pope's illness, Ağca sent a letter to the Pope wishing him well and also warning him that the world would end soon. When the Pope died on 2 April 2005, Ağca's brother Adnan gave an interview in which he said that Ağca and his entire family were grieving, and that the Pope had been a great friend to them.

Ağca was released on parole on 12 January 2006. Mustafa Demirbağ, his lawyer, explained his release as a combination of amnesty and penal reform: an amnesty in 2000 deducted 10 years from his time, the court then deducted his 20 years in the Italian prison based on a new article in the penal code, and so he became eligible for parole for good behavior. However, a report from the French AFP news agency stated that "The Turkish judicial authorities still haven't explained exactly which legal resources he had access to", and former Minister of Justice Hikmet Sami Türk, in government at the time of Ağca's extradition, claimed that, from a legal viewpoint, his release was a "serious mistake" at best, and that he should have not been freed before 2012. However, on 20 January 2006, the Turkish Supreme Court ruled that his time served in Italy could not be deducted from his Turkish sentence and he was again imprisoned.

On 2 May 2008, Ağca asked to be awarded Polish citizenship as he wished to spend the final years of his life in Poland, Pope John Paul II's country of birth. Ağca stated that upon his release he wanted to visit Pope John Paul II's tomb and partner with Dan Brown on writing a book.

Ağca was released from jail on 18 January 2010. He was transferred to a military hospital in order to assess if, at 52, he was still fit for compulsory military service. The military found him unfit for military service for having "antisocial personality disorder". In a statement, he announced: "I will meet you in the next three days. In the name of God Almighty, I proclaim the end of the world in this century. All the world will be destroyed, every human being will die. I am not God, I am not son of God, I am Christ eternal."

The former assassin visited the tomb of John Paul II on 27 December 2014.

Ağca manifested a desire to become a Catholic priest in 2016 and go to Fatima, Portugal to celebrate the 100th anniversary of the Marian apparitions there (Our Lady of Fátima).

In November 2010, he accused Cardinal Agostino Casaroli as the mastermind behind the assassination attempt on John Paul II in 1981.

It has also been alleged that the Soviet Union's KGB ordered the assassination, because of John Paul II's support for the Solidarity labor movement in Poland. Ağca stated this during one of his interrogations before trial.

However, when Ağca published his memoirs in 2013, his story changed completely, writing that the Iranian government and Ayatollah Khomeini ordered the assassination attempt on John Paul II.

According to this new version of the events, Ağca received instructions and training in weapons and explosives in Iran, from Mohsen Rezai, under the orders of Ayatollah Jaffar Subhani and Ayatollah Khomeini. In his book, Ağca acknowledges that he lied previously about the Bulgarian and Soviet connection. He stayed in Sofia for about a month, but he was not in contact with any Bulgarian or other intelligence officers, he was in transit from Turkey to Western Europe, and was delayed in Sofia because his fake Indian passport was of such poor quality that on several occasions he had to bribe officials who became suspicious. So, he waited to receive a much better quality Turkish passport from the Grey Wolves: a genuine passport issued by the Turkish government to another person, Faruk Faruk Özgün, only the photo of Özgün was replaced by a photo of Ağca.

When Pope John Paul II visited him in prison in Italy, on 27 December 1983 (two and a half years after the assassination attempt), Ağca recalls in his memoirs he kissed the hand of the pope, having kissed three years earlier the hand of Khomeini in Iran, and when asked, he told John Paul II "Khomeini and the Iranian government gave me the order to kill you".

Ağca's shooting of the Pope and possible KGB involvement is featured in Tom Clancy's 2002 novel, "Red Rabbit", and Frederick Forsyth's novel, "The Fourth Protocol". He has also been mentioned in the book, "The Third Revelation", by Ralph McInerny, and was portrayed by actors Christopher Bucholz in the RAI production "Attentato al papa", Sebastian Knapp in the ABC TV biopic movie "", Massimiliano Ubaldi in CBS' TV miniseries "Pope John Paul II" (both 2005) and Alkis Zanis in the 2006 Canadian TV sequel "".



 


</doc>
<doc id="20223" url="https://en.wikipedia.org/wiki?curid=20223" title="March 17">
March 17





</doc>
<doc id="20224" url="https://en.wikipedia.org/wiki?curid=20224" title="Mummy">
Mummy

A mummy is a dead human or an animal whose soft tissues and organs have been preserved by either intentional or accidental exposure to chemicals, extreme cold, very low humidity, or lack of air, so that the recovered body does not decay further if kept in cool and dry conditions. Some authorities restrict the use of the term to bodies deliberately embalmed with chemicals, but the use of the word to cover accidentally desiccated bodies goes back to at least 1615 AD (see the section Etymology and meaning).

Mummies of humans and animals have been found on every continent, both as a result of natural preservation through unusual conditions, and as cultural artifacts. Over one million animal mummies have been found in Egypt, many of which are cats. Many of the Egyptian animal mummies are sacred ibis, and radiocarbon dating suggests the Egyptian Ibis mummies that have been analyzed were from time frame that falls between approximately 450 and 250 BC.

In addition to the mummies of ancient Egypt, deliberate mummification was a feature of several ancient cultures in areas of America and Asia with very dry climates. The Spirit Cave mummies of Fallon, Nevada in North America were accurately dated at more than 9,400 years old. Before this discovery, the oldest known deliberate mummy was a child, one of the Chinchorro mummies found in the Camarones Valley, Chile, which dates around 5050 BC. The oldest known naturally mummified human corpse is a severed head dated as 6,000 years old, found in 1936 AD at the site named Inca Cueva No. 4 in South America.

The English word "mummy" is derived from medieval Latin "mumia", a borrowing of the medieval Arabic word "mūmiya" (مومياء) and from a Persian word "mūm" (wax), which meant an embalmed corpse, and as well as the bituminous embalming substance, and also meant "bitumen". The Medieval English term "mummy" was defined as "medical preparation of the substance of mummies", rather than the entire corpse, with Richard Hakluyt in 1599 AD complaining that "these dead bodies are the Mummy which the Phisistians and Apothecaries doe against our willes make us to swallow". These substances were defined as mummia.

The OED defines a mummy as "the body of a human being or animal embalmed (according to the ancient Egyptian or some analogous method) as a preparation for burial", citing sources from 1615 AD onward. However, Chamber's "Cyclopædia" and the Victorian zoologist Francis Trevelyan Buckland define a mummy as follows: "A human or animal body desiccated by exposure to sun or air. Also applied to the frozen carcase of an animal imbedded in prehistoric snow".

Wasps of the genus "Aleiodes" are known as "mummy wasps" because they wrap their caterpillar prey as "mummies".

While interest in the study of mummies dates as far back as Ptolemaic Greece, most structured scientific study began at the beginning of the 20th century. Prior to this, many rediscovered mummies were sold as curiosities or for use in pseudoscientific novelties such as mummia. The first modern scientific examinations of mummies began in 1901, conducted by professors at the English-language Government School of Medicine in Cairo, Egypt. The first X-ray of a mummy came in 1903, when professors Grafton Elliot Smith and Howard Carter used the only X-ray machine in Cairo at the time to examine the mummified body of Thutmose IV. British chemist Alfred Lucas applied chemical analyses to Egyptian mummies during this same period, which returned many results about the types of substances used in embalming. Lucas also made significant contributions to the analysis of Tutankhamun in 1922.

Pathological study of mummies saw varying levels of popularity throughout the 20th century. In 1992, the First World Congress on Mummy Studies was held in Puerto de la Cruz on Tenerife in the Canary Islands. More than 300 scientists attended the Congress to share nearly 100 years of collected data on mummies. The information presented at the meeting triggered a new surge of interest in the subject, with one of the major results being integration of biomedical and bioarchaeological information on mummies with existing databases. This was not possible prior to the Congress due to the unique and highly specialized techniques required to gather such data.

In more recent years, CT scanning has become an invaluable tool in the study of mummification by allowing researchers to digitally "unwrap" mummies without risking damage to the body. The level of detail in such scans is so intricate that small linens used in tiny areas such as the nostrils can be digitally reconstructed in 3-D. Such modelling has been utilized to perform digital autopsies on mummies to determine cause of death and lifestyle, such as in the case of Tutankhamun.

Mummies are typically divided into one of two distinct categories: anthropogenic or spontaneous. Anthropogenic mummies were deliberately created by the living for any number of reasons, the most common being for religious purposes. Spontaneous mummies, such as Ötzi, were created unintentionally due to natural conditions such as extremely dry heat or cold, or anaerobic conditions such as those found in bogs. While most individual mummies exclusively belong to one category or the other, there are examples of both types being connected to a single culture, such as those from the ancient Egyptian culture and the Andean cultures of South America. Some of the later well-preserved corpses of the mummification were found under Christian churches, such as the mummified vicar Nicolaus Rungius found under the St. Michael Church in Keminmaa, Finland.

Until recently, it was believed that the earliest ancient Egyptian mummies were created naturally due to the environment in which they were buried. In 2014, an 11-year study by University of York, Macquarie University and University of Oxford suggested that artificial mummification occurred 1,500 years earlier than first thought. This was confirmed in 2018, when tests on a 5,600 year-old mummy in Turin revealed that it had been deliberately mummified using linen wrappings and embalming oils made from conifer resin and aromatic plant extracts.

The preservation of the dead had a profound effect on ancient Egyptian religion. Mummification was an integral part of the rituals for the dead beginning as early as the 2nd dynasty (about 2800 BC). Egyptians saw the preservation of the body after death as an important step to living well in the afterlife. As Egypt gained more prosperity, burial practices became a status symbol for the wealthy as well. This cultural hierarchy lead to the creation of elaborate tombs, and more sophisticated methods of embalming.
By the 4th dynasty (about 2600 BC) Egyptian embalmers began to achieve "true mummification" through a process of evisceration. Much of this early experimentation with mummification in Egypt is unknown.

The few documents that directly describe the mummification process date to the Greco-Roman period. The majority of the papyri that have survived only describe the ceremonial rituals involved in embalming, not the actual surgical processes involved. A text known as "The Ritual of Embalming" does describe some of the practical logistics of embalming, however, there are only two known copies and each is incomplete. With regards to mummification shown in images, there are apparently also very few. The tomb of Tjay designated TT23, is one of only two known which show the wrapping of a mummy (Riggs 2014).

Another text that describes the processes being used in latter periods is Herodotus' Histories. Written in Book 2 of the "Histories" is one of the most detailed descriptions of the Egyptian mummification process, including the mention of using natron in order to dehydrate corpses for preservation. However, these descriptions are short and fairly vague, leaving scholars to infer the majority of the techniques that were used by studying mummies that have been unearthed.

By utilizing current advancements in technology, scientists have been able to uncover a plethora of new information about the techniques used in mummification. A series of CT scans performed on a 2,400-year-old mummy in 2008 revealed a tool that was left inside the cranial cavity of the skull. The tool was a rod, made of an organic material, that was used to break apart the brain to allow it to drain out of the nose. This discovery helped to dispel the claim within Herodotus' works that the rod had been a hook made of iron. Earlier experimentation in 1994 by researchers Bob Brier and Ronald Wade supported these findings. While attempting to replicate Egyptian mummification, Brier and Wade discovered that removal of the brain was much easier when the brain was liquefied and allowed to drain with the help of gravity, as opposed to trying to pull the organ out piece-by-piece with a hook.
Through various methods of study over many decades, modern Egyptologists now have an accurate understanding of how mummification was achieved in ancient Egypt. The first and most important step was to halt the process of decomposition, by removing the internal organs and washing out the body with a mix of spices and palm wine. The only organ left behind was the heart, as tradition held the heart was the seat of thought and feeling and would therefore still be needed in the afterlife. After cleansing, the body was then dried out with natron inside the empty body cavity as well as outside on the skin. The internal organs were also dried and either sealed in individual jars, or wrapped to be replaced within the body. This process typically took forty days.
After dehydration, the mummy was wrapped in many layers of linen cloth. Within the layers, Egyptian priests placed small amulets to guard the decedent from evil. Once the mummy was completely wrapped, it was coated in a resin in order to keep the threat of moist air away. Resin was also applied to the coffin in order to seal it. The mummy was then sealed within its tomb, alongside the worldly goods that were believed to help aid it in the afterlife.

Aspergillus niger has been found in the mummies of ancient Egyptian tombs and can be inhaled when they are disturbed.

Mummification is one of the defining customs in ancient Egyptian society for people today. The practice of preserving the human body is believed to be a quintessential feature of Egyptian life. Yet even mummification has a history of development and was accessible to different ranks of society in different ways during different periods. There were at least three different processes of mummification according to Herodotus. They range from "the most perfect" to the method employed by the "poorer classes".

The most expensive process was to preserve the body by dehydration and protect against pests, such as insects. Almost all of the actions Herodotus described serve one of these two functions.

First, the brain was removed from the cranium through the nose; the gray matter was discarded. Modern mummy excavations have shown that instead of an iron hook inserted through the nose as Herodotus claims, a rod was used to liquefy the brain via the cranium, which then drained out the nose by gravity. The embalmers then rinsed the skull with certain drugs that mostly cleared any residue of brain tissue and also had the effect of killing bacteria. Next, the embalmers made an incision along the flank with a sharp blade fashioned from an Ethiopian stone and removed the contents of the abdomen. Herodotus does not discuss the separate preservation of these organs and their placement either in special jars or back in the cavity, a process that was part of the most expensive embalming, according to archaeological evidence.

The abdominal cavity was then rinsed with palm wine and an infusion of crushed, fragrant herbs and spices; the cavity was then filled with spices including myrrh, cassia, and, Herodotus notes, "every other sort of spice except frankincense", also to preserve the person.

The body was further dehydrated by placing it in natron, a naturally occurring salt, for seventy days. Herodotus insists that the body did not stay in the natron longer than seventy days. Any shorter time and the body is not completely dehydrated; any longer, and the body is too stiff to move into position for wrapping. The embalmers then wash the body again and wrapped it with linen bandages. The bandages were covered with a gum that modern research has shown is both waterproofing agent and an antimicrobial agent.

At this point, the body was given back to the family. These "perfect" mummies were then placed in wooden cases that were human-shaped. Richer people placed these wooden cases in stone sarcophagi that provided further protection. The family placed the sarcophagus in the tomb upright against the wall, according to Herodotus.

The second process that Herodotus describes was used by middle-class people or people who "wish to avoid expense". In this method, an oil derived from cedar trees was injected with a syringe into the abdomen. A rectal plug prevented the oil from escaping. This oil probably had the dual purpose of liquefying the internal organs but also of disinfecting the abdominal cavity. (By liquefying the organs, the family avoided the expense of canopic jars and separate preservation.) The body was then placed in natron for seventy days. At the end of this time, the body was removed and the cedar oil, now containing the liquefied organs, was drained through the rectum. With the body dehydrated, it could be returned to the family. Herodotus does not describe the process of burial of such mummies, but they were perhaps placed in a shaft tomb. Poorer people used coffins fashioned from terracotta.

The third and least-expensive method the embalmers offered was to clear the intestines with an unnamed liquid, injected as an enema. The body was then placed in natron for seventy days and returned to the family. Herodotus gives no further details.

In Christian tradition, some bodies of saints are naturally conserved and venerated.

In addition to the mummies of Egypt, there have been instances of mummies being discovered in other areas of the African continent. The bodies show a mix of anthropogenic and spontaneous mummification, with some being thousands of years old.

The mummified remains of an infant were discovered during an expedition by archaeologist Fabrizio Mori to Libya during the winter of 1958–1959 in the natural cave structure of Uan Muhuggiag. After curious deposits and cave paintings were discovered on the surfaces of the cave, expedition leaders decided to excavate. Uncovered alongside fragmented animal bone tools was the mummified body of an infant, wrapped in animal skin and wearing a necklace made of ostrich egg shell beads. Professor Tongiorgi of the University of Pisa radiocarbon-dated the infant to between 5,000–8,000 years old. A long incision located on the right abdominal wall, and the absence of internal organs, indicated that the body had been eviscerated post-mortem, possibly in an effort to preserve the remains. A bundle of herbs found within the body cavity also supported this conclusion. Further research revealed that the child had been around 30 months old at the time of death, though gender could not be determined due to poor preservation of the sex organs.

The first mummy to be discovered in South Africa was found in the Baviaanskloof Wilderness Area by Dr. Johan Binneman in 1999. Nicknamed Moses, the mummy was estimated to be around 2,000 years old. After being linked to the indigenous Khoi culture of the region, the National Council of Khoi Chiefs of South Africa began to make legal demands that the mummy be returned shortly after the body was moved to the Albany Museum in Grahamstown.

The mummies of Asia are usually considered to be accidental. The decedents were buried in just the right place where the environment could act as an agent for preservation. This is particularly common in the desert areas of the Tarim Basin and Iran. Mummies have been discovered in more humid Asian climates, however these are subject to rapid decay after being removed from the grave.

Mummies from various dynasties throughout China's history have been discovered in several locations across the country. They are almost exclusively considered to be unintentional mummifications. Many areas in which mummies have been uncovered are difficult for preservation, due to their warm, moist climates. This makes the recovery of mummies a challenge, as exposure to the outside world can cause the bodies to decay in a matter of hours.

An example of a Chinese mummy that was preserved despite being buried in an environment not conducive to mummification is Xin Zhui. Also known as Lady Dai, she was discovered in the early 1970s at the Mawangdui archaeological site in Changsha. She was the wife of the marquis of Dai during the Han dynasty, who was also buried with her alongside another young man often considered to be a very close relative. However, Xin Zhui's body was the only one of the three to be mummified. Her corpse was so well-preserved that surgeons from the Hunan Provincial Medical Institute were able to perform an autopsy. The exact reason why her body was so completely preserved has yet to be determined.

Among the mummies discovered in China are those termed Tarim mummies because of their discovery in the Tarim Basin. The dry desert climate of the basin proved to be an excellent agent for desiccation. For this reason, over 200 Tarim mummies, which are over 4,000 years old, were excavated from a cemetery in the present-day Xinjiang region. The mummies were found buried in upside-down boats with hundreds of 13-foot-long wooden poles in the place of tombstones. DNA sequence data shows that the mummies had Haplogroup R1a (Y-DNA) characteristic of western Eurasia in the area of East-Central Europe, Central Asia and Indus Valley. This has created a stir in the Turkic-speaking Uighur population of the region, who claim the area has always belonged to their culture, while it was not until the 10th century when the Uighurs are said by scholars to have moved to the region from Central Asia. American Sinologist Victor H. Mair claims that ""the earliest mummies in the Tarim Basin were exclusively Caucasoid, or Europoid"" with "east Asian migrants arriving in the eastern portions of the Tarim Basin around 3,000 years ago", while Mair also notes that it was not until 842 that the Uighur peoples settled in the area. Other mummified remains have been recovered from around the Tarim Basin at sites including Qäwrighul, Yanghai, Shengjindian, Shanpula (Sampul), Zaghunluq, and Qizilchoqa.

As of 2012, at least eight mummified human remains have been recovered from the Douzlakh Salt Mine at Chehr Abad in northwestern Iran. Due to their salt preservation, these bodies are collectively known as Saltmen. Carbon-14 testing conducted in 2008 dated three of the bodies to around 400 BC. Later isotopic research on the other mummies returned similar dates, however, many of these individuals were found to be from a region that is not closely associated with the mine. It was during this time that researchers determined the mine suffered a major collapse, which likely caused the death of the miners. Since there is significant archaeological data that indicates the area was not actively inhabited during this time period, current consensus holds that the accident occurred during a brief period of temporary mining activity.

In 1993, a team of Russian archaeologists led by Dr. Natalia Polosmak discovered the Siberian Ice Maiden, a Scytho-Siberian woman, on the Ukok Plateau in the Altai Mountains near the Mongolian border. The mummy was naturally frozen due to the severe climatic conditions of the Siberian steppe. Also known as Princess Ukok, the mummy was dressed in finely detailed clothing and wore an elaborate headdress and jewelry. Alongside her body were buried six decorated horses and a symbolic meal for her last journey. Her left arm and hand were tattooed with animal style figures, including a highly stylized deer.

The Ice Maiden has been a source of some recent controversy. The mummy's skin has suffered some slight decay, and the tattoos have faded since the excavation. Some residents of the Altai Republic, formed after the breakup of the Soviet Union, have requested the return of the Ice Maiden, who is currently stored in Novosibirsk in Siberia.

Another Siberian mummy, a man, was discovered much earlier in 1929. His skin was also marked with tattoos of two monsters resembling griffins, which decorated his chest, and three partially obliterated images which seem to represent two deer and a mountain goat on his left arm.

Philippine mummies are called Kabayan Mummies. They are common in Igorot culture and their heritage. The mummies are found in some areas named Kabayan, Sagada and among others. The mummies are dated between the 14th and 19th centuries.

The European continent is home to a diverse spectrum of spontaneous and anthropogenic mummies. Some of the best-preserved mummies have come from bogs located across the region. The Capuchin monks that inhabited the area left behind hundreds of intentionally-preserved bodies that have provided insight into the customs and cultures of people from various eras. One of the oldest mummies (nicknamed Ötzi) was discovered on this continent. New mummies continue to be uncovered in Europe well into the 21st Century.

The United Kingdom, the Republic of Ireland, Germany, the Netherlands, Sweden, and Denmark have produced a number of bog bodies, mummies of people deposited in sphagnum bogs, apparently as a result of murder or ritual sacrifices. In such cases, the acidity of the water, low temperature and lack of oxygen combined to tan the body's skin and soft tissues. The skeleton typically disintegrates over time. Such mummies are remarkably well preserved on emerging from the bog, with skin and internal organs intact; it is even possible to determine the decedent's last meal by examining stomach contents. The Haraldskær Woman was discovered by labourers in a bog in Jutland in 1835. She was erroneously identified as an early medieval Danish queen, and for that reason was placed in a royal sarcophagus at the Saint Nicolai Church, Vejle, where she currently remains. Another bog body, also from Denmark, known as the Tollund Man was discovered in 1950. The corpse was noted for its excellent preservation of the face and feet, which appeared as if the man had recently died. Only the head of Tollund Man remains, due to the decomposition of the rest of his body, which was not preserved along with the head.

The mummies of the Canary Islands belong to the indigenous Guanche people and date to the time before 14th Century Spanish explorers settled in the area. All deceased people within the Guanche culture were mummified during this time, though the level of care taken with embalming and burial varied depending on individual social status. Embalming was carried out by specialized groups, organized according to gender, who were considered unclean by the rest of the community. The techniques for embalming were similar to those of the ancient Egyptians; involving evisceration, preservation, and stuffing of the evacuated bodily cavities, then wrapping of the body in animal skins. Despite the successful techniques utilized by the Guanche, very few mummies remain due to looting and desecration.

The majority of mummies recovered in the Czech Republic come from underground crypts. While there is some evidence of deliberate mummification, most sources state that desiccation occurred naturally due to unique conditions within the crypts.

The Capuchin Crypt in Brno contains three hundred years of mummified remains directly below the main altar. Beginning in the 18th Century when the crypt was opened, and continuing until the practice was discontinued in 1787, the Capuchin monks of the monastery would lay the deceased on a pillow of bricks on the ground. The unique air quality and topsoil within the crypt naturally preserved the bodies over time.

Approximately fifty mummies were discovered in an abandoned crypt beneath the Church of St. Procopius of Sázava in Vamberk in the mid-1980s. Workers digging a trench accidentally broke into the crypt, which began to fill with waste water. The mummies quickly began to deteriorate, though thirty-four were able to be rescued and stored temporarily at the District Museum of the Orlické Mountains until they could be returned to the monastery in 2000. The mummies range in age and social status at time of death, with at least two children and one priest. The majority of the Vamberk mummies date from the 18th century.

The Klatovy catacombs currently house an exhibition of Jesuit mummies, alongside some aristocrats, that were originally interred between 1674 and 1783. In the early 1930s, the mummies were accidentally damaged during repairs, resulting in the loss of 140 bodies. The newly updated airing system preserves the thirty-eight bodies that are currently on display.

Apart from several bog bodies, Denmark has also yielded several other mummies, such as the three Borum Eshøj mummies, the Skrydstrup Woman and the Egtved Girl, who were all found inside burial mounds, or tumuli.

In 1875, the Borum Eshøj grave mound was uncovered, which had been built around three coffins, which belonged to a middle aged man and woman as well as a man in his early twenties. Through examination, the woman was discovered to be around 50–60 years old. She was found with several artifacts made of bronze, consisting of buttons, a belt plate, and rings, showing she was of higher class. All of the hair had been removed from the skull later when farmers had dug through the casket. Her original hairstyle is unknown. The two men wore kilts, and the younger man wore a sheath which contained a bronze dagger. All three mummies were dated to 1351–1345 BC.

The Skrydstrup Woman was unearthed from a tumulus in Southern Jutland, in 1935. Carbon-14 dating showed that she had died around 1300 BC; examination also revealed that she was around 18–19 years old at the time of death, and that she had been buried in the summertime. Her hair had been drawn up in an elaborate hairstyle, which was then covered by a horse hair hairnet made by the sprang technique. She was wearing a blouse and a necklace as well as two golden earrings, showing she was of higher class.

The Egtved Girl, dated to 1370 BC, was also found inside a sealed coffin within a tumulus, in 1921. She was wearing a bodice and a skirt, including a belt and bronze bracelets. Found with the girl, at her feet, were the cremated remains of a child and, by her head, a box containing some bronze pins, a hairnet, and an awl.

In 1994, 265 mummified bodies were found in the crypt of a Dominican church in Vác, Hungary from the 1729–1838 period. The discovery proved to be scientifically important, and by 2006 an exhibition was established in the Museum of Natural History in Budapest. Unique to the Hungarian mummies are their elaborately decorated coffins, with no two being exactly alike.

The varied geography and climatology of Italy has led to many cases of spontaneous mummification. Italian mummies display the same diversity, with a conglomeration of natural and intentional mummification spread across many centuries and cultures.

The oldest natural mummy in Europe was discovered in 1991 in the Ötztal Alps on the Austrian-Italian border. Nicknamed Ötzi, the mummy is a 5,300-year-old male believed to be a member of the Tamins-Carasso-Isera cultural group of South Tyrol. Despite his age, a recent DNA study conducted by Walther Parson of Innsbruck Medical University revealed Ötzi has 19 living genetic relatives.

The Capuchin Catacombs of Palermo were built in the 16th century by the monks of Palermo's Capuchin monastery. Originally intended to hold the deliberately mummified remains of dead friars, interment in the catacombs became a status symbol for the local population in the following centuries. Burials continued until the 1920s, with one of the final burials being that of Rosalia Lombardo. In all, the catacombs host nearly 8000 mummies. (See: Catacombe dei Cappuccini)

The most recent discovery of mummies in Italy came in 2010, when sixty mummified human remains were found in the crypt of the Conversion of St Paul church in Roccapelago di Pievepelago, Italy. Built in the 15th century as a cannon hold and later converted in the 16th century, the crypt had been sealed once it had reached capacity, leaving the bodies to be protected and preserved. The crypt was reopened during restoration work on the church, revealing the diverse array of mummies inside. The bodies were quickly moved to a museum for further study.

The mummies of North America are often steeped in controversy, as many of these bodies have been linked to still-existing native cultures. While the mummies provide a wealth of historically-significant data, native cultures and tradition often demands the remains be returned to their original resting places. This has led to many legal actions by Native American councils, leading to most museums keeping mummified remains out of the public eye.

Kwäday Dän Ts'ìnchi ("Long ago person found" in the Southern Tutchone language of the Champagne and Aishihik First Nations), was found in August 1999 by three First Nations hunters at the edge of a glacier in Tatshenshini-Alsek Provincial Park, British Columbia, Canada. According to the Kwäday Dän Ts'ìnchi Project, the remains are the oldest well preserved mummy discovered in North America. (The Spirit Cave mummy although not well preserved, is much older.) Initial radiocarbon tests date the mummy to around 550 years-old.

In 1972, eight remarkably preserved mummies were discovered at an abandoned Inuit settlement called Qilakitsoq, in Greenland. The "Greenland Mummies" consisted of a six-month-old baby, a four-year-old boy, and six women of various ages, who died around 500 years ago. Their bodies were naturally mummified by the sub-zero temperatures and dry winds in the cave in which they were found.

Intentional mummification in pre-Columbian Mexico was practiced by the Aztec culture. These bodies are collectively known as Aztec mummies. Genuine Aztec mummies were "bundled" in a woven wrap and often had their faces covered by a ceremonial mask. Public knowledge of Aztec mummies increased due to traveling exhibits and museums in the 19th and 20th centuries, though these bodies were typically naturally desiccated remains and not actually the mummies associated with Aztec culture. (See: Aztec mummy)

Natural mummification has been known to occur in several places in Mexico; this includes the mummies of Guanajuato. A collection of these mummies, most of which date to the late 19th century, have been on display at "El Museo de las Momias" in the city of Guanajuato since 1970. The museum claims to have the smallest mummy in the world on display (a mummified fetus). It was thought that minerals in the soil had the preserving effect, however it may rather be due to the warm, arid climate. Mexican mummies are also on display in the small town of Encarnación de Díaz, Jalisco.

Spirit Cave Man was discovered in 1940 during salvage work prior to guano mining activity that was scheduled to begin in the area. The mummy is a middle-aged male, found completely dressed and lying on a blanket made of animal skin. Radiocarbon tests in the 1990s dated the mummy to being nearly 9,000 years old. The remains are currently held at the Nevada State Museum. There has been some controversy within the local Native American community, who began petitioning to have the remains returned and reburied in 1995.

Mummies from the Oceania are not limited only to Australia. Discoveries of mummified remains have also been located in New Zealand, and the Torres Strait, though these mummies have been historically harder to examine and classify. Prior to the 20th Century, most literature on mummification in the region was either silent or anecdotal. However, the boom of interest generated by the scientific study of Egyptian mummification lead to more concentrated study of mummies in other cultures, including those of Oceania.

The aboriginal mummification traditions found in Australia are thought be related to those found in the Torres Strait islands, the inhabitants of which achieved a high level of sophisticated mummification techniques (See:Torres Strait). Australian mummies lack some of the technical ability of the Torres Strait mummies, however much of the ritual aspects of the mummification process are similar. Full-body mummification was achieved by these cultures, but not the level of artistic preservation as found on smaller islands. The reason for this seems to be for easier transport of bodies by more nomadic tribes.

The mummies of the Torres Strait have a considerably higher level of preservation technique as well as creativity compared to those found on Australia. The process began with removal of viscera, after which the bodies were set in a seated position on a platform and either left to dry in the sun or smoked over a fire in order to aid in desiccation. In the case of smoking, some tribes would collect the fat that drained from the body to mix with ocher to create red paint that would then be smeared back on the skin of the mummy. The mummies remained on the platforms, decorated with the clothing and jewelry they wore in life, before being buried.

Some Māori tribes from New Zealand would keep mummified heads as trophies from tribal warfare. They are also known as Mokomokai. In the 19th Century, many of the trophies were acquired by Europeans who found the tattooed skin to be a phenomenal curiosity. Westerners began to offer valuable commodities in exchange for the uniquely tattooed mummified heads. The heads were later put on display in museums, 16 of which being housed across France alone. In 2010, the Rouen City Hall of France returned one of the heads to New Zealand, despite earlier protests by the Culture Ministry of France.

There is also evidence that some Maori tribes may have practiced full-body mummification, though the practice is not thought to have been widespread. The discussion of Maori mummification has been historically controversial, with some experts in past decades claiming that such mummies have never existed. Contemporary science does now acknowledge the existence of full-body mummification in the culture. There is still controversy, however, as to the nature of the mummification process. Some bodies appear to be spontaneously created by the natural environment, while others exhibit signs of deliberate practices. General modern consensus tends to agree that there could be a mixture of both types of mummification, similar to that of the ancient Egyptian mummies.

The South American continent contains some of the oldest mummies in the world, both deliberate and accidental. The bodies were preserved by the best agent for mummification: the environment. The Pacific coastal desert in Peru and Chile is one of the driest areas in the world and the dryness facilitated mummification. Rather than developing elaborate processes such as later-dynasty ancient Egyptians, the early South Americans often left their dead in naturally dry or frozen areas, though some did perform surgical preparation when mummification was intentional. Some of the reasons for intentional mummification in South America include memorialization, immortalization, and religious offerings. A large number of mummified bodies have been found in pre-Columbian cemeteries scattered around Peru. The bodies had often been wrapped for burial in finely-woven textiles.

The Chinchorro mummies are the oldest intentionally prepared mummified bodies ever found. Beginning in 5th millennium BC and continuing for an estimated 3,500 years, all human burials within the Chinchorro culture were prepared for mummification. The bodies were carefully prepared, beginning with removal of the internal organs and skin, before being left in the hot, dry climate of the Atacama Desert, which aided in desiccation. A large number of Chinchorro mummies were also prepared by skilled artisans to be preserved in a more artistic fashion, though the purpose of this practice is widely debated.

Several naturally-preserved, unintentional mummies dating from the Incan period (1438–1532 AD) have been found in the colder regions of Argentina, Chile, and Peru. These are collectively known as "ice mummies". The first Incan ice mummy was discovered in 1954 atop El Plomo Peak in Chile, after an eruption of the nearby volcano Sabancaya melted away ice that covered the body. The Mummy of El Plomo was a male child who was presumed to be wealthy due to his well-fed bodily characteristics. He was considered to be the most well-preserved ice mummy in the world until the discovery of Mummy Juanita in 1995.

Mummy Juanita was discovered near the summit of Ampato in the Peruvian section of the Andes mountains by archaeologist Johan Reinhard. Her body had been so thoroughly frozen that it had not been desiccated; much of her skin, muscle tissue, and internal organs retained their original structure. She is believed to be a ritual sacrifice, due to the close proximity of her body to the Incan capital of Cusco, as well as the fact she was wearing highly intricate clothing to indicate her special social status. Several Incan ceremonial artifacts and temporary shelters uncovered in the surrounding area seem to support this theory.

More evidence that the Inca left sacrificial victims to die in the elements, and later be unintentionally preserved, came in 1999 with the discovery of the Llullaillaco mummies on the border of Argentina and Chile. The three mummies are children, two girls and one boy, who are thought to be sacrifices associated with the ancient ritual of "qhapaq hucha". Recent biochemical analysis of the mummies has revealed that the victims had consumed increasing quantities of alcohol and coca, possibly in the form of chicha, in the months leading up to sacrifice. The dominant theory for the drugging reasons that, alongside ritual uses, the substances probably made the children more docile. Chewed coca leaves found inside the eldest child's mouth upon her discovery in 1999 supports this theory.

The bodies of Inca emperors and wives were mummified after death. In 1533, the Spanish conquistadors of the Inca Empire viewed the mummies in the Inca capital of Cuzco. The mummies were displayed, often in lifelike positions, in the palaces of the deceased emperors and had a retinue of servants to care for them. The Spanish were impressed with the quality of the mummification which involved removal of the organs, embalming, and freeze-drying.

The population revered the mummies of the Inca emperors. This reverence seemed idolatry to the Roman Catholic Spanish and in 1550 they confiscated the mummies. The mummies were taken to Lima where they were displayed in the San Andres Hospital. The mummies deteriorated in the humid climate of Lima and eventually they were either buried or destroyed by the Spanish.

An attempt to find the mummies of the Inca emperors beneath the San Andres hospital in 2001 was unsuccessful. The archaeologists found a crypt, but it was empty. Possibly the mummies had been removed when the building was repaired after an earthquake.

Monks whose bodies remain incorrupt without any traces of deliberate mummification are venerated by some Buddhists who believe they successfully were able to mortify their flesh to death. Self-mummification was practiced until the late 1800s in Japan and has been outlawed since the early 1900s.

Many Mahayana Buddhist monks were reported to know their time of death and left their last testaments and their students accordingly buried them sitting in lotus position, put into a vessel with drying agents (such as wood, paper, or lime) and surrounded by bricks, to be exhumed later, usually after three years. The preserved bodies would then be decorated with paint and adorned with gold.

Bodies purported to be those of self-mummified monks are exhibited in several Japanese shrines, and it has been claimed that the monks, prior to their death, stuck to a sparse diet made up of salt, nuts, seeds, roots, pine bark, and "urushi" tea.

In the 1830s, Jeremy Bentham, the founder of utilitarianism, left instructions to be followed upon his death which led to the creation of a sort of modern-day mummy. He asked that his body be displayed to illustrate how the "horror at dissection originates in ignorance"; once so displayed and lectured about, he asked that his body parts be preserved, including his skeleton (minus his skull, which despite being mis-preserved, was displayed beneath his feet until theft required it to be stored elsewhere), which were to be dressed in the clothes he usually wore and "seated in a Chair usually occupied by me when living in the attitude in which I am sitting when engaged in thought". His body, outfitted with a wax head created because of problems preparing it as Bentham requested, is on open display in the University College London.

During the early 20th century, the Russian movement of Cosmism, as represented by Nikolai Fyodorovich Fyodorov, envisioned scientific resurrection of dead people. The idea was so popular that, after Vladimir Lenin's death, Leonid Krasin and Alexander Bogdanov suggested to cryonically preserve his body and brain in order to revive him in the future. Necessary equipment was purchased abroad, but for a variety of reasons the plan was not realized. Instead his body was embalmed and placed on permanent exhibition in the Lenin Mausoleum in Moscow, where it is displayed to this day. The mausoleum itself was modeled by Alexey Shchusev on the Pyramid of Djoser and the Tomb of Cyrus.

In late 19th-century Venezuela, a German-born doctor named Gottfried Knoche conducted experiments in mummification at his laboratory in the forest near La Guaira. He developed an embalming fluid (based on an aluminum chloride compound) that mummified corpses without having to remove the internal organs. The formula for his fluid was never revealed and has not been discovered. Most of the several dozen mummies created with the fluid (including himself and his immediate family) have been lost or were severely damaged by vandals and looters.

In 1975, an esoteric organization by the name of Summum introduced "Modern Mummification", a service that utilizes modern techniques along with aspects of ancient methods of mummification. The first person to formally undergo Summum's process of modern mummification was the founder of Summum, Summum Bonum Amen Ra, who died in January 2008. Summum is currently considered to be the only "commercial mummification business" in the world.

In 2010, a team led by forensic archaeologist Stephen Buckley mummified Alan Billis using techniques based on 19 years of research of 18th-dynasty Egyptian mummification. The process was filmed for television, for the documentary "Mummifying Alan: Egypt's Last Secret". Billis made the decision to allow his body to be mummified after being diagnosed with terminal cancer in 2009. His body currently resides at London's Gordon Museum.

Plastination is a technique used in anatomy to conserve bodies or body parts. The water and fat are replaced by certain plastics, yielding specimens that can be touched, do not smell or decay, and even retain most microscopic properties of the original sample.

The technique was invented by Gunther von Hagens when working at the anatomical institute of the Heidelberg University in 1978. Von Hagens has patented the technique in several countries and is heavily involved in its promotion, especially as the creator and director of the Body Worlds traveling exhibitions, exhibiting plastinated human bodies internationally. He also founded and directs the Institute for Plastination in Heidelberg.

More than 40 institutions worldwide have facilities for plastination, mainly for medical research and study, and most affiliated to the International Society for Plastination.

In the Middle Ages, based on a mistranslation from the Arabic term for bitumen, it was thought that mummies possessed healing properties. As a result, it became common practice to grind Egyptian mummies into a powder to be sold and used as medicine. When actual mummies became unavailable, the sun-desiccated corpses of criminals, slaves and suicidal people were substituted by mendacious merchants. Mummies were said to have a lot of healing properties. Francis Bacon and Robert Boyle recommended them for healing bruises and preventing bleeding. The trade in mummies seems to have been frowned upon by Turkish authorities who ruled Egypt – several Egyptians were imprisoned for boiling mummies to make oil in 1424. However, mummies were in high demand in Europe and it was possible to buy them for the right amount of money. John Snaderson, an English tradesman who visited Egypt in the 16th century shipped six hundred pounds of mummy back to England.

The practice developed into a wide-scale business that flourished until the late 16th century. Two centuries ago, mummies were still believed to have medicinal properties to stop bleeding, and were sold as pharmaceuticals in powdered form as in mellified man. Artists also made use of Egyptian mummies; a brownish pigment known as mummy brown, based on "mummia" (sometimes called alternatively "caput mortuum", Latin for "death's head"), which was originally obtained by grinding human and animal Egyptian mummies. It was most popular in the 17th century, but was discontinued in the early 19th century when its composition became generally known to artists who replaced the said pigment by a totally different blend -but keeping the original name, mummia or mummy brown-yielding a similar tint and based on ground minerals (oxides and fired earths) and or blends of powdered gums and oleoresins (such as myrrh and frankincense) as well as ground bitumen. These blends appeared on the market as forgeries of powdered mummy pigment but were ultimately considered as acceptable replacements, once antique mummies were no longer permitted to be destroyed. Many thousands of mummified cats were also sent from Egypt to England to be processed for use in fertilizer.

During the 19th century, following the discovery of the first tombs and artifacts in Egypt, egyptology was a huge fad in Europe, especially in Victorian England. European aristocrats would occasionally entertain themselves by purchasing mummies, having them unwrapped, and holding observation sessions. The pioneer of this kind of entertainment in Britain was Thomas Pettigrew known as "Mummy" Pettigrew due to his work. Such unrolling sessions destroyed hundreds of mummies, because the exposure to the air caused them to disintegrate.

The use of mummies as fuel for locomotives was documented by Mark Twain (likely as a joke or humor), but the truth of the story remains debatable. During the American Civil War, mummy-wrapping linens were said to have been used to manufacture paper. Evidence for the reality of these claims is still equivocal. Researcher Ben Radford reports that, in her book "The Mummy Congress", Heather Pringle writes: "No mummy expert has ever been able to authenticate the story ... Twain seems to be the only published source – and a rather suspect one at that". Pringle also writes that there is no evidence for the "mummy paper" either. Radford also says that many journalists have not done a good job with their research, and while it is true that mummies were often not shown respect in the 1800s, there is no evidence for this rumor.

While mummies were used in medicine, some researchers have brought into question these other uses such as making paper and paint, fueling locomotives and fertilizing land.

Bibliography

Books

Online

Video


</doc>
<doc id="20226" url="https://en.wikipedia.org/wiki?curid=20226" title="Melilla">
Melilla

Melilla (Arabic : مليلة, , , ; ) is a Spanish autonomous city located on the northwest coast of Africa, sharing a border with Morocco. It has an area of . Melilla is one of two permanently inhabited Spanish cities in mainland Africa, the other being nearby Ceuta. It was part of the Province of Málaga until 14 March 1995, when the city's Statute of Autonomy was passed.

Melilla is one of the special territories of the European Union.

As of 2019, Melilla had a population of 86,487. The population is chiefly divided between people of Iberian and Riffian extraction. There is also a small number of Sephardic Jews and Sindhi Hindus. Spanish and Riffian-Berber are the two most widely spoken languages, the former being the official language.

Melilla, just like Ceuta and other Spain's remaining territories in Africa, is subject to an irredentist claim by Morocco.

The original name (currently rendered as "Rusadir"), was a Phoenician name, coming from the name given to the nearby Cape Three Forks. "Addir" meant "powerful". The name creation is similar to that of other names given in Antiquity to outlets along the north-african coast, including "Rusguniae", "Rusubbicari", "Rusuccuru", "Rusippisir", "Rusigan" (Rachgoun), "Rusicade", "Ruspina", "Ruspe" or "Rsmlqr".

Meanwhile, the etymology of the current city name (dating back to the 9th century, rendered as "Melilla" in Spanish) is uncertain. An active apicultural location in the past, the name has been related to honey; this is tentatively backed up by two ancient coins featuring a bee as well as the inscriptions and . Others relate the name to "discord" or "fever" or also to an ancient Arab personality.

The current Riffian name of Melilla is "Mřič" or "Mlilt", which means the "white one".

It was a Phoenician and later Punic trade establishment under the name of Rusadir ("Rusaddir" for the Romans and "Russadeiron" () for the Greeks). Later Rome absorbed it as part of the Roman province of Mauretania Tingitana. Rusaddir is mentioned by Ptolemy (IV, 1) and Pliny (V, 18) who called it ""oppidum et portus"" (a fortified town and port). It was also cited by Mela (I, 33) as "Rusicada," and by the "Itinerarium Antonini". Rusaddir was said to have once been the seat of a bishop, but there is no record of any bishop of the purported see, which is not included in the Catholic Church's list of titular sees.

As centuries passed, it was ruled by Vandal, Byzantine and Hispano-Visigothic bands. The political history is similar to that of towns in the region of the Moroccan Rif and southern Spain. Local rule passed through a succession of Phoenician, Punic, Roman, Umayyad, Cordobese, Idrisid, Almoravid, Almohad, Marinid, and then Wattasid rulers.

During the 15th century, the city subsumed into decadence, just like most of the rest of cities of the Kingdom of Fez located along the Mediterranean coast, eclipsed by those along the Atlantic facade. Following the completion of the conquest of the Nasrid Kingdom of Granada by the Catholic Monarchs in 1492, their Secretary started to compile information about the sorry state of the north-african coast with the prospect of a potential territorial expansion in mind, sending field agents to investigate, and subsequently reporting the Catholic Monarchs that, by early 1494, locals had expelled the authority of the Sultan of Fez and had offered to pledge service. While the 1494 Treaty of Tordesillas put Melilla and Cazaza (until then reserved to the Portuguese) under the sphere of Castile, the conquest of the city had to wait, delayed by the occupation of Naples by Charles VIII of France.

The Duke of Medina Sidonia, Juan Alfonso Pérez de Guzmán promoted the seizure of the city, to be headed by , while the Catholic Monarchs, Isabella of Castile and Ferdinand of Aragon endorsed the initiative, also providing the assistance of their artillery officer Francisco Ramírez de Madrid during the operation. The city was occupied on 17 September 1497 virtually without any violence as it, as located in the border between the Kingdom of Tlemcen and the Kingdom of Fez and fought over many times by those powers, it had been left abandoned and partially ruined. No big-scale expansion into the Kingdom of Fez ensued, and, barring the enterprises of the Cardinal Cisneros along the coast in Mers El Kébir and Oran (in the Algerian coast), and the rock of Badis (this one in the territorial scope of the Kingdom of Fez), the imperial impetus of the Hispanic Monarchy was eventually directed elsewhere, to the Italian Wars waged against France, and, particularly since 1519, to the newly discovered continent across the Atlantic.

Melilla was initially jointly administered by the House of Medina Sidonia and the Crown, and a 1498 settlement forced the former to station a 700-men garrison in Melilla and forced the latter to provide the city with a number of maravedíes and wheat "fanegas". The Crown's interest in the city decreased during the reign of Charles V. During the 16th century, soldiers stationed in Melilla were badly remunerated, leading to many desertions.

During the late 17th century, Alaouite sultan Ismail Ibn Sharif attempted to conquer the city, taking the outer forts protecting the city in the 1680s and further unsuccessfully besieging the city in the 1690s.

One Spanish officer reflected, "an hour in Melilla, from the point of view of merit, was worth more than thirty years of service to Spain."

The current limits of the Spanish territory around the Melilla fortress were fixed by treaties with Morocco in 1859, 1860, 1861, and 1894. In the late 19th century, as Spanish influence expanded in this area, the Crown authorized Melilla as the only centre of trade on the Rif coast between Tetuan and the Algerian frontier. The value of trade increased, with goat skins, eggs and beeswax being the principal exports, and cotton goods, tea, sugar and candles being the chief imports.

In a 1866 Hispano-Moroccan arrangement signed in Fes, both parts agreed to allow for the installment of a customs office near the border with Melilla, to be operated by Moroccan officials.

The Treaty of Peace with Morocco that followed the 1859–60 War entailed the acquisition of a new city perimetre for Melilla, bringing its area to the 12 km the city currently stands. Following the declaration of Melilla as free port in 1863, the population began to increase, chiefly by Sephardi jews fleeing from Tetouan who fostered trade in and out the city.

In 1893, the Rif Berbers launched the First Melillan campaign to take back this area; Spain sent 25,000 Spanish soldiers to defend against them. The conflict was also known as the "Margallo War", after Spanish General Juan García y Margallo, who was killed in the battle, and was the Governor of Melilla. The new 1894 agreement with Morocco that followed the 1893 Margallo War between Spaniards and Riffian tribesmen increased trade with the hinterland, bringing the economic prosperity of the city to a new level.

The turn of the new century saw however the attempts by France (based in French Algeria) to profit from their newly acquired sphere of influence in Morocco to counter the trading prowess of Melilla by fostering trade links with the Algerian cities of Ghazaouet and Oran. Melilla began to suffer from this, to which the instability brought by revolts against Muley Abdel Aziz in the hinterland also added, although after 1905 Sultan pretender El Rogui (Bou Hmara) carried out a defusing policy in the area that favoured Spain. The French occupation of Oujda in 1907, compromised the Melillan trade with that city. and the enduring instability in the Rif still threatened Melilla. Mining companies began to enter the "hinterland" of Melilla by 1908. A Spanish one, the , was constituted in July 1908, shared by Clemente Fernández, Enrique Macpherson, the Count of Romanones, the and , who appointed Miguel Villanueva as chairman. Thus two mining under the protection of Bou Hmara, started mining lead and iron some 20 kilometers (12.4 miles) from Melilla. They started to construct a railway between the port and the mines. In October of that year the Bou Hmara's vassals revolted against him and raided the mines, which remained closed until June 1909. By July the workmen were again attacked and several were killed. Severe fighting between the Spaniards and the tribesmen followed, in the Second Melillan campaign that took place in the vicinity of Melilla.

In 1910, the Spaniards restarted the mines and undertook harbor works at Mar Chica, but hostilities broke out again in 1911. On 22 July 1921, the Berbers under the leadership of Abd el Krim inflicted a grave defeat on the Spanish at the Battle of Annual. The Spanish retreated to Melilla, leaving most of the protectorate under the control of the Republic of Rif.
The city was used as one of the staging grounds for the July 1936 military coup d'état that started the Spanish Civil War. A statue of Francisco Franco, the putschist general assuming the control of the Army of Africa in 1936, is still prominently featured, the last statue of Franco in Spain.

On 6 November 2007, King Juan Carlos I and Queen Sofia visited the city, which caused a demonstration of support. The visit also sparked protests from the Moroccan government. It was the first time a Spanish monarch had visited Melilla in 80 years.

Melilla (and Ceuta) have declared the Muslim holiday of Eid al-Adha or Feast of the Sacrifice, as an official public holiday from 2010 onward. This is the first time a non-Christian religious festival has been officially celebrated in Spain since the Reconquista.

In 2018, Morocco decided to close the customs office near Melilla, in operation since the mid 19th century, without consulting the counterparty.

Melilla is located in the northwest of the African continent, in the shores of the Alboran Sea, a marginal sea of the Mediterranean, the latter's westernmost portion. The city layout is arranged in a wide semicircle around the beach and the Port of Melilla, on the eastern side of the peninsula of Cape Tres Forcas, at the foot of and around the mouth of the Río de Oro intermittent water stream, above sea level. The urban nucleus was originally a fortress, Melilla la Vieja, built on a peninsular mound about in height.

The Moroccan settlement of Beni Ansar lies immediately south of Melilla. The nearest Moroccan city is Nador, and the ports of Melilla and Nador are both within the same bay; nearby is the Bou Areg Lagoon
Melilla has a warm Mediterranean climate influenced by its proximity to the sea, rendering much cooler summers and more precipitation than inland areas deeper into Africa. The climate, in general, is similar to the southern coast of peninsular Spain and the northern coast of Morocco, with relatively small temperature differences between seasons.

The government bodies stipulated in the Statute of Autonomy are the Assembly of Melilla, the President of Melilla and the Council of Government.
The assembly is a 25-member body whose members are elected through universal suffrage every 4 years in closed party lists following the schedule of local elections at the national level. Its members are called "local deputies" but they rather enjoy the status of "concejales" (municipal councillors). Unlike regional legislatures (and akin to municipal councils), the assembly does not enjoy right of initiative for primary legislation. 

The president of Melilla (who, often addressed as Mayor-President, also exerts the roles of Mayor, president of the Assembly, president of the Council of Government and representative of the city) is invested by the Assembly. After local elections, the president is invested through a qualified majority from among the leaders of the election lists, or, failing to achieve the former, the leader of the most voted list at the election is invested to the office. In case of a motion of no confidence the president can only be ousted with a qualified majority voting for an alternative assembly member.

The Council of Government is the traditional collegiate executive body for parliamentary systems. Unlike the municipal government boards in the standard "ayuntamientos", the members of the Council of Government (including the Vice-Presidents) do not need to be members of the assembly.

Melilla is the city in Spain with the highest proportion of postal voting; vote buying (via mail-in ballots) is widely reported to be a common practice in the poor neighborhoods of Melilla. Court cases in this matter had involved the PP, the CPM and the PSOE.

On 15 June 2019, following the May 2019 Melilla Assembly election, the regionalist and left-leaning party of Muslim and Amazigh persuasion Coalition for Melilla (CPM, 8 seats), the Spanish Socialist Workers' Party (PSOE, 4 seats) and Citizens–Party of the Citizenry (Cs, 1 seat) voted in favour of the Cs' candidate (Eduardo de Castro) vis-à-vis the Presidency of the Autonomous City, ousting Juan José Imbroda, from the People's Party (PP, 10 seats), who had been in office since 2000.

Melilla is subdivided into eight districts ("distritos"), which are further subdivided into neighbourhoods ("barrios"):

The Gross domestic product (GDP) of the autonomous community was 1.6 billion euros in 2018, accounting for 0.1% of Spanish economic output. GDP per capita adjusted for purchasing power was 19,900 euros or 66% of the EU27 average in the same year. Melilla was the NUTS2 region with the lowest GDP per capita in Spain.

Melilla does not participate into the European Union Customs Union (EUCU). There is no VAT (IVA) tax, but a local reduced-rate tax called IPSI. Preserving the status of free port, imports are free of tariffs and the only tax concerning them is the IPSI. Exports to the Customs Union (including Peninsular Spain) are however subject to the correspondent customs tariff and are taxed with the correspondent VAT. There are some special manufacturing taxes regarding electricity and transport, as well as complementary charges on tobacco and oil and fuel products.
The principal industry is fishing. Cross-border commerce (legal or smuggled) and Spanish and European grants and wages are the other income sources.

Melilla is regularly connected to the Iberian peninsula by air and sea traffic and is also economically connected to Morocco: most of its fruit and vegetables are imported across the border. Moroccans in the city's hinterland are attracted to it: 36,000 Moroccans cross the border daily to work, shop or trade goods. The port of Melilla offers several daily connections to Almería and Málaga. Melilla Airport offers daily flights to Almería, Málaga and Madrid. Spanish operators Air Europa and Iberia operate in Melilla's airport.

Many people travelling between Europe and Morocco use the ferry links to Melilla, both for passengers and for freight. Because of this, the port and related companies form an important economic driver for the city.

Melilla's Capilla de Santiago, or James's Chapel, by the city walls, is the only authentic Gothic structure in Africa.

In the first quarter of the 20th century, Melilla became a thriving port benefitting from the recently established Protectorate of Spanish Morocco in the nearby Rif region. The new architectural style of "modernismo" was expressed by a new bourgeois class. This style, frequently referred to as the Catalan version of Art Nouveau, was extremely popular in the early part of the 20th century in Spain.

The workshops inspired by the Catalan architect Enrique Nieto continued in the modernist style, even after Modernisme went out of fashion elsewhere. Accordingly, Melilla has the second most important concentration of Modernist works in Spain after Barcelona. Nieto was in charge of designing the main Synagogue, the Central Mosque and various Catholic Churches.

Melilla has been praised as an example of multiculturalism, being a small city in which one can find Christians, Muslims, Jews and Hindus represented. There is a small, autonomous, and commercially important Hindu community present in Melilla, which has fallen over the past decades as its members move to the Spanish mainland and numbers about 100 members today.

Melilla has been a popular destination for migrants in order to enter the European Union. The border is secured by the Melilla border fence, a six-metre-tall double fence with watch towers; yet migrants (in groups of tens or sometimes hundreds) storm the fence and manage to cross it from time to time. Detection wires, radar, and day/night vision cameras are planned to increase security and prevent illegal immigration. In February 2014, over 200 migrants from sub-Saharan Africa scaled a security fence to get into the Melilla migrant reception centre. The reception centre, built for 480 migrants, was already overcrowded with 1,300 people.

In recent years, the Spanish government has urged Moroccan security forces to stem the flow of migrants traveling towards Melilla. In 2015, Moroccan police dispersed migrant camps in the forests surrounding Melilla by torching makeshift homes and arresting migrants. Since the 2014 incident, Spain has installed additional security measures, including increased fencing, camera surveillance systems, and a more salient troop presence. Attempted border crossings by migrants has decreased at both Melilla and Ceuta since its peak in 2015–2016; arrivals are down twenty-five percent since 2018. However, attempts by migrants to swarm the security fences at Melilla have been widely broadcast by Spanish media sources, creating a sense of urgency in mainland Spain. This fear over African migrants is seen by many as the main factor leading to the rise of Vox, Spain's populist party. Vox officials have frequently pointed to the immigration situation at Melilla and Ceuta proof of a crisis at Spain's border.

Melilla Airport is serviced by Air Nostrum, flying to the Spanish cities of Málaga, Madrid, Barcelona, Las Palmas de Gran Canaria, Palma de Mallorca, Granada, Badajoz, Sevilla and Almería. In April 2013, a local enterprise set up Melilla Airlines, flying from the city to Málaga. The city is linked to Málaga, Almería and Motril by ferry.

Three roads connect Melilla and Morocco but require clearance through border checkpoints.

Melilla is a surfing destination. The city's football club, UD Melilla, plays in the third tier of Spanish football, the Segunda División B. The club was founded in 1943 and since 1945 have played at the 12,000-seater Estadio Municipal Álvarez Claro. Until the other club was dissolved in 2012, UD Melilla played the Ceuta-Melilla derby against AD Ceuta. The clubs travelled to each other via the Spanish mainland to avoid entering Morocco. The second-highest ranked club in the city are Casino del Real CF of the fourth-tier Tercera División. The football's governing institution is the Melilla Football Federation.

The government of Morocco has repeatedly called for Spain to transfer the sovereignty of Ceuta and Melilla, along with uninhabited islets such as the islands of Alhucemas, the rock of Vélez and the Perejil island, drawing comparisons with Spain's territorial claim to Gibraltar. In both cases, the national governments and local populations of the disputed territories reject these claims by a large majority. The Spanish position states that both Ceuta and Melilla are integral parts of Spain, and have been since the 16th century, centuries prior to Morocco's independence from France in 1956, whereas Gibraltar, being a British Overseas Territory, is not and never has been part of the United Kingdom. Both cities also have the same semi-autonomous status as the mainland region in Spain. Melilla has been under Spanish rule for longer than cities in northern Spain such as Pamplona or Tudela, and was conquered roughly in the same period as the last Muslim cities of Southern Spain such as Granada, Málaga, Ronda or Almería: Spain claims that the enclaves were established before the creation of the Kingdom of Morocco. Morocco denies these claims and maintains that the Spanish presence on or near its coast is a remnant of the colonial past which should be ended. The United Nations list of Non-Self-Governing Territories does not include these Spanish territories and the dispute remains bilaterally debated between Spain and Morocco.

Melilla is twinned with:






</doc>
<doc id="20229" url="https://en.wikipedia.org/wiki?curid=20229" title="Macaroni">
Macaroni

Macaroni (, Italian: maccheroni) is dry pasta shaped like narrow tubes. Made with durum wheat, macaroni is commonly cut in short lengths; curved macaroni may be referred to as elbow macaroni. Some home machines can make macaroni shapes, but like most pasta, macaroni is usually made commercially by large-scale extrusion. The curved shape is created by different speeds of extrusion on opposite sides of the pasta tube as it comes out of the machine.

In North America, the word "macaroni" is often used synonymously with elbow-shaped macaroni, as it is the variety most often used in macaroni and cheese recipes. In Italy, the noun "maccheroni" refers to straight, tubular, square-ended "pasta corta" ("short-length pasta"). Maccheroni may also refer to long pasta dishes such as "maccheroni alla chitarra" and "frittata di maccheroni", which are prepared with long pasta like spaghetti.

The name comes from Italian "maccheroni" , plural form of "maccherone". The many variants sometimes differ from each other because of the texture of each pasta: "rigatoni" and "tortiglioni", for example, have ridges down their lengths, while "chifferi", "lumache", "lumaconi", "pipe", "pipette", etc. refer to elbow-shaped pasta similar to macaroni in North American culture.

However, the product as well as the name derive from the ancient Greek "Macaria". The academic consensus supports that the word is derived from the Greek μακαρία ("makaria"), a kind of barley broth which was served to commemorate the dead. In turn, that comes from μάκαρες ("makares") meaning "blessed dead", and ultimately from μακάριος ("makarios"), collateral of μάκαρ ("makar") which means "blessed, happy".

However, the Italian linguist G. Alessio argues that the word can have two origins. The first is the Medieval Greek μακαρώνεια ("makarōneia") "dirge" (stated in sec. XIII by James of Bulgaria), which would mean "funeral meal" and then "food to serve" during this office (see modern Eastern Thrace's μαχαρωνιά - "macharōnia" in the sense of "rice-based dish served at the funeral"), in which case, the term would be composed of the double root of μακάριος "blessed" and αἰωνίος ("aiōnios"), "eternally". The second is the Greek μακαρία "barley broth", which would have added the suffix "-one".

In his book "Delizia! The Epic History of Italians and their Food" (2007), John Dickie instead says that the word macaroni, and its earlier variants like "maccheroni", "comes from "maccare", meaning to pound or crush."

The word first appears in English as "makerouns" in the 1390 "Forme of Cury" which records the earliest recipe for macaroni cheese. The word later came to be applied to overdressed dandies and was associated with foppish Italian fashions of dress and periwigs, as in the eighteenth-century British song "Yankee Doodle".

The Russian language borrowed the word (as ) as a generic term for all varieties of pasta; this also holds for several other Slavic languages, as well as for Estonian, Turkish, Greek, and Brazilian Portuguese. In Iran, all sorts of pasta are collectively called "makaroni".

As is the case with dishes made with other types of pasta, macaroni and cheese is a popular dish in North America, and is often made with elbow macaroni. The same dish, known simply as macaroni cheese, is also popular in Great Britain, where it originated. A sweet macaroni pudding, known as creamed macaroni, containing milk and sugar (and rather similar to a rice pudding) was also popular with the British during the Victorian era. It is still manufactured by Ambrosia and sold in UK supermarkets.

In areas with large Chinese populations open to Western cultural influence such as Hong Kong, Macao, Malaysia and Singapore, the local Chinese have adopted macaroni as an ingredient for Chinese-style Western cuisine. In Hong Kong's "cha chaan teng" ("tea restaurants") and Southeast Asia's "kopi tiam" ("coffee shops"), macaroni is cooked in water and then rinsed to remove starch, and served in clear broth with ham or frankfurter sausages, peas, black mushrooms, and optionally eggs, reminiscent of noodle soup dishes. This is often a course for breakfast or light lunch fare. Macaroni has also been incorporated into Malay Malaysian cuisine where it is stir-fried akin to mee goreng using Asian seasoning similar to said noodle dish (i.e shallots, oyster sauce and chili paste).




</doc>
<doc id="20232" url="https://en.wikipedia.org/wiki?curid=20232" title="Messenger RNA">
Messenger RNA

In molecular biology, messenger RNA (mRNA) is a single-stranded molecule of RNA that corresponds to the genetic sequence of a gene and is read by a ribosome in the process of synthesizing a protein. 

mRNA is created during the process of transcription, where an enzyme (RNA polymerase) converts the gene into primary transcript mRNA (also known as pre-mRNA). This pre-mRNA usually still contains introns, regions that will not go on to code for the final amino acid sequence. These are removed in the process of RNA splicing, leaving only exons, regions that will encode the protein. This exon sequence constitutes mature mRNA. Mature mRNA is then read by the ribosome, and, utilising amino acids carried by transfer RNA (tRNA), the ribosome creates the protein. This process is known as translation. All of these processes form part of the central dogma of molecular biology, which describes the flow of genetic information in a biological system.

As in DNA, genetic information in mRNA is contained in the sequence of nucleotides, which are arranged into codons consisting of three base pairs each. Each codon codes for a specific amino acid, except the stop codons, which terminate protein synthesis. This process of translation of codons into amino acids requires two other types of RNA: transfer RNA, which recognises the codon and provides the corresponding amino acid, and ribosomal RNA (rRNA), the central component of the ribosome's protein-manufacturing machinery.

The existence of mRNA was first suggested by Jacques Monod and François Jacob, and was subsequently discovered by Jacob, Sydney Brenner and Matthew Meselson at the California Institute of Technology in 1961.

The brief existence of an mRNA molecule begins with transcription, and ultimately ends in degradation. During its life, an mRNA molecule may also be processed, edited, and transported prior to translation. Eukaryotic mRNA molecules often require extensive processing and transport, while prokaryotic mRNA molecules do not. A molecule of eukaryotic mRNA and the proteins surrounding it are together called a messenger RNP.

Transcription is when RNA is made from DNA. During transcription, RNA polymerase makes a copy of a gene from the DNA to mRNA as needed. This process is similar in eukaryotes and prokaryotes. One notable difference, however, is that eukaryotic RNA polymerase associates with mRNA-processing enzymes during transcription so that processing can proceed quickly after the start of transcription. The short-lived, unprocessed or partially processed product is termed "precursor mRNA", or "pre-mRNA"; once completely processed, it is termed "mature mRNA".

Processing of mRNA differs greatly among eukaryotes, bacteria, and archaea. Non-eukaryotic mRNA is, in essence, mature upon transcription and requires no processing, except in rare cases. Eukaryotic pre-mRNA, however, requires several processing steps before its transport to the cytoplasm and its translation by the ribosome.

The extensive processing of eukaryotic pre-mRNA that leads to the mature mRNA is the RNA splicing, a mechanism by which introns or outrons (non-coding regions) are removed and exons (coding regions) are joined together.

A "5' cap" (also termed an RNA cap, an RNA 7-methylguanosine cap, or an RNA mG cap) is a modified guanine nucleotide that has been added to the "front" or 5' end of a eukaryotic messenger RNA shortly after the start of transcription. The 5' cap consists of a terminal 7-methylguanosine residue that is linked through a 5'-5'-triphosphate bond to the first transcribed nucleotide. Its presence is critical for recognition by the ribosome and protection from RNases.

Cap addition is coupled to transcription, and occurs co-transcriptionally, such that each influences the other. Shortly after the start of transcription, the 5' end of the mRNA being synthesized is bound by a cap-synthesizing complex associated with RNA polymerase. This enzymatic complex catalyzes the chemical reactions that are required for mRNA capping. Synthesis proceeds as a multi-step biochemical reaction.

In some instances, an mRNA will be edited, changing the nucleotide composition of that mRNA. An example in humans is the apolipoprotein B mRNA, which is edited in some tissues, but not others. The editing creates an early stop codon, which, upon translation, produces a shorter protein.

Polyadenylation is the covalent linkage of a polyadenylyl moiety to a messenger RNA molecule. In eukaryotic organisms most messenger RNA (mRNA) molecules are polyadenylated at the 3' end, but recent studies have shown that short stretches of uridine (oligouridylation) are also common. The poly(A) tail and the protein bound to it aid in protecting mRNA from degradation by exonucleases. Polyadenylation is also important for transcription termination, export of the mRNA from the nucleus, and translation. mRNA can also be polyadenylated in prokaryotic organisms, where poly(A) tails act to facilitate, rather than impede, exonucleolytic degradation.

Polyadenylation occurs during and/or immediately after transcription of DNA into RNA. After transcription has been terminated, the mRNA chain is cleaved through the action of an endonuclease complex associated with RNA polymerase. After the mRNA has been cleaved, around 250 adenosine residues are added to the free 3' end at the cleavage site. This reaction is catalyzed by polyadenylate polymerase. Just as in alternative splicing, there can be more than one polyadenylation variant of an mRNA.

Polyadenylation site mutations also occur. The primary RNA transcript of a gene is cleaved at the poly-A addition site, and 100–200 A's are added to the 3’ end of the RNA. If this site is altered, an abnormally long and unstable mRNA construct will be formed.

Another difference between eukaryotes and prokaryotes is mRNA transport. Because eukaryotic transcription and translation is compartmentally separated, eukaryotic mRNAs must be exported from the nucleus to the cytoplasm—a process that may be regulated by different signaling pathways. Mature mRNAs are recognized by their processed modifications and then exported through the nuclear pore by binding to the cap-binding proteins CBP20 and CBP80, as well as the transcription/export complex (TREX). Multiple mRNA export pathways have been identified in eukaryotes.

In spatially complex cells, some mRNAs are transported to particular subcellular destinations. In mature neurons, certain mRNA are transported from the soma to dendrites. One site of mRNA translation is at polyribosomes selectively localized beneath synapses. The mRNA for Arc/Arg3.1 is induced by synaptic activity and localizes selectively near active synapses based on signals generated by NMDA receptors. Other mRNAs also move into dendrites in response to external stimuli, such as β-actin mRNA. Upon export from the nucleus, actin mRNA associates with ZBP1 and the 40S subunit. The complex is bound by a motor protein and is transported to the target location (neurite extension) along the cytoskeleton. Eventually ZBP1 is phosphorylated by Src in order for translation to be initiated. In developing neurons, mRNAs are also transported into growing axons and especially growth cones. Many mRNAs are marked with so-called "zip codes," which target their transport to a specific location.

Because prokaryotic mRNA does not need to be processed or transported, translation by the ribosome can begin immediately after the end of transcription. Therefore, it can be said that prokaryotic translation is "coupled" to transcription and occurs "co-transcriptionally".

Eukaryotic mRNA that has been processed and transported to the cytoplasm (i.e., mature mRNA) can then be translated by the ribosome. Translation may occur at ribosomes free-floating in the cytoplasm, or directed to the endoplasmic reticulum by the signal recognition particle. Therefore, unlike in prokaryotes, eukaryotic translation "is not" directly coupled to transcription. It is even possible in some contexts that reduced mRNA levels are accompanied by increased protein levels, as has been observed for mRNA/protein levels of EEF1A1 in breast cancer.

Coding regions are composed of codons, which are decoded and translated (in eukaryotes usually into one and in prokaryotes usually into several) into proteins by the ribosome. Coding regions begin with the start codon and end with a stop codon. In general, the start codon is an AUG triplet and the stop codon is UAG ("amber"), UAA ("ochre"), or UGA ("opal"). The coding regions tend to be stabilised by internal base pairs, this impedes degradation. In addition to being protein-coding, portions of coding regions may serve as regulatory sequences in the pre-mRNA as exonic splicing enhancers or exonic splicing silencers.

Untranslated regions (UTRs) are sections of the mRNA before the start codon and after the stop codon that are not translated, termed the five prime untranslated region (5' UTR) and three prime untranslated region (3' UTR), respectively. These regions are transcribed with the coding region and thus are exonic as they are present in the mature mRNA. Several roles in gene expression have been attributed to the untranslated regions, including mRNA stability, mRNA localization, and translational efficiency. The ability of a UTR to perform these functions depends on the sequence of the UTR and can differ between mRNAs. Genetic variants in 3' UTR have also been implicated in disease susceptibility because of the change in RNA structure and protein translation.

The stability of mRNAs may be controlled by the 5' UTR and/or 3' UTR due to varying affinity for RNA degrading enzymes called ribonucleases and for ancillary proteins that can promote or inhibit RNA degradation. (See also, C-rich stability element.)

Translational efficiency, including sometimes the complete inhibition of translation, can be controlled by UTRs. Proteins that bind to either the 3' or 5' UTR may affect translation by influencing the ribosome's ability to bind to the mRNA. MicroRNAs bound to the 3' UTR also may affect translational efficiency or mRNA stability.

Cytoplasmic localization of mRNA is thought to be a function of the 3' UTR. Proteins that are needed in a particular region of the cell can also be translated there; in such a case, the 3' UTR may contain sequences that allow the transcript to be localized to this region for translation.

Some of the elements contained in untranslated regions form a characteristic secondary structure when transcribed into RNA. These structural mRNA elements are involved in regulating the mRNA. Some, such as the SECIS element, are targets for proteins to bind. One class of mRNA element, the riboswitches, directly bind small molecules, changing their fold to modify levels of transcription or translation. In these cases, the mRNA regulates itself.

The 3' poly(A) tail is a long sequence of adenine nucleotides (often several hundred) added to the 3' end of the pre-mRNA. This tail promotes export from the nucleus and translation, and protects the mRNA from degradation.

An mRNA molecule is said to be monocistronic when it contains the genetic information to translate only a single protein chain (polypeptide). This is the case for most of the eukaryotic mRNAs. On the other hand, polycistronic mRNA carries several open reading frames (ORFs), each of which is translated into a polypeptide. These polypeptides usually have a related function (they often are the subunits composing a final complex protein) and their coding sequence is grouped and regulated together in a regulatory region, containing a promoter and an operator. Most of the mRNA found in bacteria and archaea is polycistronic, as is the human mitochondrial genome. Dicistronic or bicistronic mRNA encodes only two proteins.

In eukaryotes mRNA molecules form circular structures due to an interaction between the eIF4E and poly(A)-binding protein, which both bind to eIF4G, forming an mRNA-protein-mRNA bridge. Circularization is thought to promote cycling of ribosomes on the mRNA leading to time-efficient translation, and may also function to ensure only intact mRNA are translated (partially degraded mRNA characteristically have no m7G cap, or no poly-A tail).

Other mechanisms for circularization exist, particularly in virus mRNA. Poliovirus mRNA uses a cloverleaf section towards its 5' end to bind PCBP2, which binds poly(A)-binding protein, forming the familiar mRNA-protein-mRNA circle. Barley yellow dwarf virus has binding between mRNA segments on its 5' end and 3' end (called kissing stem loops), circularizing the mRNA without any proteins involved.

RNA virus genomes (the + strands of which are translated as mRNA) are also commonly circularized. During genome replication the circularization acts to enhance genome replication speeds, cycling viral RNA-dependent RNA polymerase much the same as the ribosome is hypothesized to cycle.

Different mRNAs within the same cell have distinct lifetimes (stabilities). In bacterial cells, individual mRNAs can survive from seconds to more than an hour. However, the lifetime averages between 1 and 3 minutes, making bacterial mRNA much less stable than eukaryotic mRNA. In mammalian cells, mRNA lifetimes range from several minutes to days. The greater the stability of an mRNA the more protein may be produced from that mRNA. The limited lifetime of mRNA enables a cell to alter protein synthesis rapidly in response to its changing needs. There are many mechanisms that lead to the destruction of an mRNA, some of which are described below.

In general, in prokaryotes the lifetime of mRNA is much shorter than in eukaryotes. Prokaryotes degrade messages by using a combination of ribonucleases, including endonucleases, 3' exonucleases, and 5' exonucleases. In some instances, small RNA molecules (sRNA) tens to hundreds of nucleotides long can stimulate the degradation of specific mRNAs by base-pairing with complementary sequences and facilitating ribonuclease cleavage by RNase III. It was recently shown that bacteria also have a sort of 5' cap consisting of a triphosphate on the 5' end. Removal of two of the phosphates leaves a 5' monophosphate, causing the message to be destroyed by the exonuclease RNase J, which degrades 5' to 3'.

Inside eukaryotic cells, there is a balance between the processes of translation and mRNA decay. Messages that are being actively translated are bound by ribosomes, the eukaryotic initiation factors eIF-4E and eIF-4G, and poly(A)-binding protein. eIF-4E and eIF-4G block the decapping enzyme (DCP2), and poly(A)-binding protein blocks the exosome complex, protecting the ends of the message. The balance between translation and decay is reflected in the size and abundance of cytoplasmic structures known as P-bodies The poly(A) tail of the mRNA is shortened by specialized exonucleases that are targeted to specific messenger RNAs by a combination of cis-regulatory sequences on the RNA and trans-acting RNA-binding proteins. Poly(A) tail removal is thought to disrupt the circular structure of the message and destabilize the cap binding complex. The message is then subject to degradation by either the exosome complex or the decapping complex. In this way, translationally inactive messages can be destroyed quickly, while active messages remain intact. The mechanism by which translation stops and the message is handed-off to decay complexes is not understood in detail.

The presence of AU-rich elements in some mammalian mRNAs tends to destabilize those transcripts through the action of cellular proteins that bind these sequences and stimulate poly(A) tail removal. Loss of the poly(A) tail is thought to promote mRNA degradation by facilitating attack by both the exosome complex and the decapping complex. Rapid mRNA degradation via AU-rich elements is a critical mechanism for preventing the overproduction of potent cytokines such as tumor necrosis factor (TNF) and granulocyte-macrophage colony stimulating factor (GM-CSF). AU-rich elements also regulate the biosynthesis of proto-oncogenic transcription factors like c-Jun and c-Fos.

Eukaryotic messages are subject to surveillance by nonsense mediated decay (NMD), which checks for the presence of premature stop codons (nonsense codons) in the message. These can arise via incomplete splicing, V(D)J recombination in the adaptive immune system, mutations in DNA, transcription errors, leaky scanning by the ribosome causing a frame shift, and other causes. Detection of a premature stop codon triggers mRNA degradation by 5' decapping, 3' poly(A) tail removal, or endonucleolytic cleavage.

In metazoans, small interfering RNAs (siRNAs) processed by Dicer are incorporated into a complex known as the RNA-induced silencing complex or RISC. This complex contains an endonuclease that cleaves perfectly complementary messages to which the siRNA binds. The resulting mRNA fragments are then destroyed by exonucleases. siRNA is commonly used in laboratories to block the function of genes in cell culture. It is thought to be part of the innate immune system as a defense against double-stranded RNA viruses.

MicroRNAs (miRNAs) are small RNAs that typically are partially complementary to sequences in metazoan messenger RNAs. Binding of a miRNA to a message can repress translation of that message and accelerate poly(A) tail removal, thereby hastening mRNA degradation. The mechanism of action of miRNAs is the subject of active research.

There are other ways by which messages can be degraded, including non-stop decay and silencing by Piwi-interacting RNA (piRNA), among others.

Full length mRNA molecules have been proposed as therapeutics since the beginning of the biotech era but there was little traction until the 2010s, when Moderna Therapeutics was founded and managed to raise almost a billion dollars in venture funding in its first three years.

Theoretically, the administered mRNA sequence can cause a cell to make a protein, which in turn could directly treat a disease or could function as a vaccine; more indirectly the protein could drive an endogenous stem cell to differentiate in a desired way.

The primary challenges of RNA therapy center on delivering the RNA to directed cells, more even than determining what sequence to deliver. Naked RNA sequences will naturally degrade after preparation; they may trigger the body's immune system to attack them as an invader; and they are impermeable to the cell membrane. Once within the cell, they must then leave the cell's transport mechanism to take action within the cytoplasm, which houses the ribosomes that direct manufacture of proteins.





</doc>
<doc id="20237" url="https://en.wikipedia.org/wiki?curid=20237" title="Mount Saint Vincent University">
Mount Saint Vincent University

Mount Saint Vincent University, often referred to as The Mount, is a public primarily undergraduate university located in Halifax, Nova Scotia, Canada, and was established in 1873. Mount Saint Vincent offers undergraduate programs in Arts, Science, Education, and Professional Studies. The Mount has 13 graduate degrees in areas including Applied Human Nutrition, School Psychology, Child and Youth Study, Education, Family Studies and Gerontology, Public Relations and Women's Studies. The Mount offers a doctorate program, a Ph.D. in Educational Studies, through a joint-initiative with St. Francis Xavier University and Acadia University. The Mount offers more than 190 courses, over 10 full undergraduate degree programs and four graduate degree, programs online.

The university attracts many students in part because of its small class sizes, specialty programs, and location. The Mount has Canada Research Chairs in Gender Identity and Social Practices as well as Food Security and Policy Change. This institution is unique nationwide as it has a Chair in learning disabilities, Master of Public Relations program, Bachelor of Science in Communication Studies, and numerous other programs, faculty, and research initiatives.

Established by the Sisters of Charity of Saint Vincent de Paul as a women's college in 1873, the Mount was one of the few institutions of higher education for women in Canada at a time when women could not vote. The original purpose of the academy was to train novices and young sisters as teachers, but the Sisters also recognized a need to educate other young women. Over the ensuing years, the order developed a convent, schools, an orphanage, and health care facilities throughout the Halifax area, as well as across North America.

Architect Charles Welsford West designed the Romanesque chapel and annex (1903–05) at Mount St. Vincent Academy (now University). He served as the Architect, Nova Scotia Public Works & Mines 1932-1950.

By 1912, the Sisters of Charity of Saint Vincent de Paul recognized the need to offer greater opportunity through university education and adopted a plan to establish a college for young women. It was two years later in 1914 that the Sisters partnered with Dalhousie University, enabling Mount Saint Vincent to offer the first two years of a bachelor's degree program to be credited toward a Dalhousie degree.

In 1925, the Nova Scotia Legislature awarded the Mount the right to grant its own degrees, making it the only independent women's college in the British Commonwealth. By 1951, degrees were offered in Arts, Secretarial Science, Music, Home Economics, Library Science, Nursing and Education.

A new charter was granted in 1966 and the College became Mount Saint Vincent University, bringing forth the establishment of a Board of Governors and Senate. This was also a period of tremendous growth – with enrollment increases, new construction and new agreements. In 1967 the Mount began admitting men as students. The University continued to evolve with the expansion of programs during the 1970s and entered into several new fields, including Child Study, Public Relations, Gerontology, Tourism and Hospitality Management, Cooperative Education and Distance Education. In July 1988, the Sisters of Charity of Saint Vincent de Paul officially transferred ownership of the institution to the Board of Governors.

After a fire in 1951 burned down Mount Saint Vincent’s solitary building, the people of Halifax came together to support students by providing alternative accommodations for their classes. In recognition of the generosity of their community, the Sisters of Charity established a memorial holiday in appreciation of their gesture. Caritas Day, named after the Christian virtue of charity, takes place on the last Wednesday of January of each year. No classes are held on this day, and students are encouraged to volunteer their time instead. Caritas Day is an opportunity for students and faculty alike to connect with the Sisters of Charity and come together outside of class time in a setting that is both personally and academically beneficial.

Mount Saint Vincent University offers over 40 undergraduate degrees in the Arts, Sciences and Professional Studies. Professional Studies programs include Applied Human Nutrition, Business Administration, Child and Youth Study, Family Studies and Gerontology, Information Technology, Public Relations, Non-profit Leadership and Tourism and Hospitality Management. All undergraduate programs are work-experience eligible, meaning any Mount student can take part in a work placement (practicum, co-op, internship) as part of their program.

The Mount also offers diplomas in Business Administration and Tourism & Hospitality Management, and certificates in Accounting, Business Administration, Marketing, Proficiency in French and Non-profit Leadership.

Following consolidation of post-secondary programs across Nova Scotia in the 1990s, the Mount became home to the only education program in the Halifax area. The faculty of Education is home to the only school psychology graduate program in Atlantic Canada. Graduates of this program are eligible to become registered psychologists in Nova Scotia and several other provinces in Canada.

The Mount houses 16 research centres and institutes.

The Department of Applied Human Nutrition has an accredited dietetic program. The University is accredited by a professional organization such as the Dietitians of Canada and the university's graduates may subsequently become registered dietitians.

Mount Saint Vincent University is the only university in Canada to offer a Master of Public Relations program (MPR). The MPR program graduated its first class in October 2009. The Canadian Public Relations Society (CPRS) recognizes MSVU's MPR program for excellence in PR education in its Pathways to the Profession guide.

Academic programs are supported by a wide variety of electronic and print research resources in the MSVU Library. Research services include drop-in reference assistance, research appointments and classroom workshops.

January 2019 marked the 40th anniversary of the Mount's co-operative education program. It is the longest-standing nationally accredited co-op program in the Maritime Provinces, offering an optional co-op program in 1979 for students in the Bachelor of Business Administration program. Four decades later, more than 8,000 Business Administration, Public Relations, and Tourism & Hospitality Management students have taken their learning from the classroom to the workplace, completing paid work terms in industries related to their field of study (today co-op is a required part of the Public Relations and Tourism & Hospitality Management degrees). Since 2014, the Mount Co-op Office has also enabled experiential opportunities for Arts and Science students through an Arts & Science Internship Program.

Mount Saint Vincent University is home to the Centre for Women in Business, a not-for-profit university business development centre (UBDC), dedicated to assisting with entrepreneurial activities both within the university and throughout Nova Scotia. Founded in 1992 by the University's Department of Business & Tourism, this remains the only UBDC in Canada with a primary focus on women. The Centre has served more than 7500 clients over the past 18 years.

The Mount Saint Vincent University Art Gallery is located on the first floor of Seton Academic Centre. The gallery opened in 1971 as a resource to Mount Saint Vincent, communities served by the university, artists, Metro Halifax residents and art publics everywhere. Admission is always free of charge.

MSVU Art Gallery reflects the University's educational aims by devoting a significant part of its activities to the representation of women as cultural subjects and producers. Its exhibitions explore various forms of cultural production, highlighting the achievements of Nova Scotian artists and themes relevant to academic programs offered by the university.

The Mount was the first Nova Scotia university to add a wikuom to its campus facilities. First raised on June 12, 2017, the wikuom is a welcoming traditional Mi'kmaq space where both Indigenous and non-Indigenous communities can gather and learn together.

The Mount is also home to the Aboriginal Student Centre (ASC), which is home to ASC staff who provide academic advising, counselling and other support services to students. The ASC hosts a number of events, including the Mount's Mid-Winter Feast, Blanket Exercises, Cultural Workshops, Mini-Mount Camps, and more.

Home to the Mystics, the Mount competes in the Atlantic Colleges Athletic Association (ACAA) in Women's & Men's Basketball, Women's & Men's Soccer, Cross Country and Women's Volleyball. The Mystics hold a championship titles in all sports, making them the most acclaimed team of the ACAA division.


Notable graduates of the Mount include:


During the 1995 G7 summit, Mount Saint Vincent University awarded an honorary Doctor of Laws degree to Hillary Clinton.




</doc>
<doc id="20239" url="https://en.wikipedia.org/wiki?curid=20239" title="Minimal pair">
Minimal pair

In phonology, minimal pairs are pairs of words or phrases in a particular language, spoken or signed, that differ in only one phonological element, such as a phoneme, toneme or chroneme, and have distinct meanings. They are used to demonstrate that two phones are two separate phonemes in the language.

Many phonologists in the middle part of the 20th century had a strong interest in developing techniques for discovering the phonemes of unknown languages, and in some cases, they set up writing systems for the languages. The major work of Kenneth Pike on the subject is "Phonemics: a technique for reducing languages to writing". The minimal pair was an essential tool in the discovery process and was found by substitution or commutation tests.

As an example for English vowels, the pair "let" + "lit" can be used to demonstrate that the phones (in let) and (in lit) actually represent distinct phonemes and . An example for English consonants is the minimal pair of "pat" + "bat". The following table shows other pairs demonstrating the existence of various distinct phonemes in English. All of the possible minimal pairs for any language may be set out in the same way.

Phonemic differentiation may vary between different dialects of a language so a particular minimal pair in one accent may be a pair of homophones in another. That means not that one of the phonemes is absent in the homonym accent but only that it is not contrastive in the same range of contexts.

In addition to the minimal pairs of vowels and consonants provided above, others may be found:

Many languages show contrasts between long and short vowels and consonants. A distinctive difference in length is attributed by some phonologists to a unit called a chroneme. Thus, Italian has the following minimal pair that is based on long and short :

However, in such a case it is not easy to decide whether a long vowel or consonant should be treated as having an added chroneme or simply as a geminate sound with phonemes.

Classical Latin, German, some Italian dialects, almost all Uralic languages, Thai, and many other languages also have distinctive length in vowels. An example is the "cŭ/cū" minimal pair in the dialect that is spoken near Palmi (Calabria, Italy):

In some languages like Italian, word-initial consonants are geminated after certain vowel-final words in the same prosodic unit. Sometimes, the phenomenon can create some syntactic-gemination-minimal-pairs:
In the example, the graphical accent on "dà" is just a diacritical mark that does not change the pronunciation of the word itself. However, in some specific areas, like Tuscany, both phrases are pronounced and so can be distinguished only from the context.

Minimal pairs for tone contrasts in tone languages can be established; some writers refer to that as a contrast involving a toneme. For example, Kono distinguishes high tone and low tone on syllables:
Languages in which stress may occur in different positions within the word often have contrasts that can be shown in minimal pairs, as in Greek and Spanish:
English-speakers are able to hear the difference between, for example, "great ape" and "grey tape", but phonemically, the two phrases are identical: . The difference between the two phrases, which constitute a minimal pair, is said to be one of juncture. At the word boundary, a "plus juncture" /+/ has been posited and said to be the factor conditioning allophones to allow distinctivity: in this example, the phrase "great ape" has an diphthong shortened by pre-fortis clipping and, since it is not syllable-initial, a with little aspiration (variously , , , , etc., depending on dialect); meanwhile in "grey tape", the has its full length and the is aspirated .

Only languages with allophonic differences associated with grammatical boundaries may have juncture as a phonological element. There is disagreement over whether or not French has phonological juncture: it seems likely that the difference between, for example, "" (some little holes) and "" (some little wheels), phonemically both , is only perceptible in slow, careful speech.

The principle of a simple binary opposition between the two members of a minimal pair may be extended to cover a minimal set in which a number of words differ from one another in terms of one phone in a particular position in the word. For example, the vowels , , , , of Swahili are shown to be distinct by the following set of words:
"pata" 'hinge', "peta" 'bend', "pita" 'pass', "pota" 'twist', "puta" 'thrash'. However, establishing such sets is not always straightforward and may require very complex study of multiple oppositions as expounded by, for example, Nikolai Trubetzkoy.

Minimal pairs were an important part of the theory of pronunciation teaching during its development in the period of structuralist linguistics, particularly in the 1940s and 1950s, and minimal pair drills were widely used to train students to discriminate among the phonemes of the target language. These drills took the form of minimal pair word drills and minimal pair sentence drills. For example, if the focus of a lesson was on the distinction /ɪ/ versus /ɛ/, learners might be asked to signal which sound they heard as the teacher pronounced lists of words with these phonemes such as "lid/led", "tin/ten", or "slipped/slept". Minimal pair sentence drills consisted of paired sentences such as "He slipped on the floor/He slept on the floor." Again, learners would be asked to distinguish which of the sentences they heard as the teacher read them aloud. Another use of minimal pair drills was in pair work. Here, one member of the pair would be responsible for listening to the other member read the minimal pair word or sentence aloud and would be tasked with identifying which phoneme was being produced. In this form of classroom practice, both the skills of perception and production were practiced. Later writers have criticized the approach as being artificial and lacking in relevance to language learners' needs. However, even today minimal pair listening and production drills remain a common tool for the teaching of segmental differences.

Some writers have claimed that learners are likely not to hear differences between phones if the difference is not a phonemic one. One of the objectives of contrastive analysis of languages' sound systems was to identify points of likely difficulty for language learners that would arise from differences in phoneme inventories between the native language and the target language. However, experimental evidence for this claim is hard to find, and the claim should be treated with caution.

In the past, signs were considered holistic forms without internal structure. However, the discovery in the mid-20th century that minimal pairs also exist in sign languages showed that sign languages have sublexical structure. Signs consist of phonemes, which are specifications for location, movement, handshape, orientation, and non-manual elements. When signs differ in only one of these specifications, they form a minimal pair. For instance, the German Sign Language signs shoes and socks are identical in form apart from their handshapes.




</doc>
<doc id="20242" url="https://en.wikipedia.org/wiki?curid=20242" title="Minestrone">
Minestrone

Minestrone (; ) is a thick soup of Italian origin made with vegetables, often with the addition of pasta or rice, sometimes both. Common ingredients include beans, onions, celery, carrots, stock, and tomatoes.

There is no set recipe for minestrone, since it can be usually made out of whatever vegetables are at one's disposal. It can be vegetarian, contain meat, or contain an animal bone-based stock (such as chicken stock). Angelo Pellegrini, however, argued that the base of minestrone is bean broth, and that borlotti beans (also called Roman beans) "are the beans to use for genuine minestrone".

Some of the earliest origins of minestrone soup pre-date the expansion of the Latin tribes of Rome into what became the Roman Kingdom (later Roman Republic and Empire), when the local diet was "vegetarian by necessity" and consisted mostly of vegetables, such as onions, lentils, cabbage, garlic, broad beans, mushrooms, carrots, asparagus, and turnips.

During this time, the main dish of a meal would have been "pulte", a simple but filling porridge of spelt flour cooked in salt water, to which whatever vegetables that were available would have been added.

It was not until the 2nd century B.C., when Rome had conquered Italy and monopolized the commercial and road networks, that a huge diversity of products flooded the capital and began to change their diet, and by association, the diet of Italy most notably with the more frequent inclusion of meats, including as a stock for soups.

Spelt flour was also removed from soups, as bread had been introduced into the Roman diet by the Greeks, and "pulte" became a meal largely for the poor.

The ancient Romans recognized the health benefits of a simple or "frugal" diet (from the Latin "fruges", the common name given to cereals, vegetables and legumes) and thick vegetable soups and vegetables remained a staple.

Marcus Apicius's ancient cookbook "De Re Coquinaria" described "polus", a Roman soup dating back to 30 AD made up of farro, chickpeas, and fava beans, with onions, garlic, lard, and greens thrown in.

As eating habits and ingredients changed in Italy, so did minestrone. Apicius updates the "pultes" and "pulticulae" with fancy trimmings such as cooked brains and wine.

The introduction of tomatoes and potatoes from the Americas in the mid-16th century changed the soup by making available two ingredients which have since become staples.

The tradition of not losing rural roots continues today, and minestrone is now known in Italy as belonging to the style of cooking called "cucina povera" (literally "poor kitchen") meaning dishes that have rustic, rural roots, as opposed to "cucina nobile" or the cooking style of the aristocracy and nobles.

The word "minestrone", meaning a thick vegetable soup, is attested in English from 1871. It is from Italian "minestrone", the augmentative form of "minestra", "soup", or more literally, "that which is served", from "minestrare", "to serve" and cognate with "administer" as in "to administer a remedy".

Because of its unique origins and the absence of a fixed recipe, minestrone varies widely across Italy depending on traditional cooking times, ingredients, and season. Minestrone ranges from a thick and dense texture with very boiled-down vegetables, to a more brothy soup with large quantities of diced and lightly cooked vegetables; it may also include meats.

In modern Italian there are three words corresponding to the English word "soup": "zuppa", which is used in the sense of tomato soup, or fish soup; "minestra", which is used in the sense of a more substantial soup such as a vegetable soup, and also for "dry" soups, namely pasta dishes; and "minestrone", which means a very substantial or large soup or stew, though the meaning has now come to be associated with this particular dish.

"Minestrone alla Genovese" is a variant typical of Liguria, which contains greater use of herbs, including pesto.

"Minestra" is a variant from Malta, which prominently features "kunserva" (a thick tomato paste), potatoes, kohlrabi, cauliflower and sometimes spaghetti.



</doc>
<doc id="20254" url="https://en.wikipedia.org/wiki?curid=20254" title="Miranda (moon)">
Miranda (moon)

Miranda, also designated Uranus V, is the smallest and innermost of Uranus's five round satellites. It was discovered by Gerard Kuiper on 16 February 1948 at McDonald Observatory in Texas, and named after Miranda from William Shakespeare's play "The Tempest". Like the other large moons of Uranus, Miranda orbits close to its planet's equatorial plane. Because Uranus orbits the Sun on its side, Miranda's orbit is perpendicular to the ecliptic and shares Uranus' extreme seasonal cycle.

At just 470 km in diameter, Miranda is one of the smallest closely observed objects in the Solar System that might be in hydrostatic equilibrium (spherical under its own gravity). The only close-up images of Miranda are from the "Voyager 2" probe, which made observations of Miranda during its Uranus flyby in January 1986. During the flyby, Miranda's southern hemisphere pointed towards the Sun, so only that part was studied.

Miranda probably formed from an accretion disc that surrounded the planet shortly after its formation, and, like other large moons, it is likely differentiated, with an inner core of rock surrounded by a mantle of ice. Miranda has one of the most extreme and varied topographies of any object in the Solar System, including Verona Rupes, a 20-kilometer-high scarp that is the highest cliff in the Solar System, and chevron-shaped tectonic features called "coronae". The origin and evolution of this varied geology, the most of any Uranian satellite, are still not fully understood, and multiple hypotheses exist regarding Miranda's evolution.

Miranda was discovered on 16 February 1948 by planetary astronomer Gerard Kuiper using the McDonald Observatory's Otto Struve Telescope. Its motion around Uranus was confirmed on 1 March 1948. It was the first satellite of Uranus discovered in nearly 100 years. Kuiper elected to name the object "Miranda" after the character in Shakespeare's "The Tempest", because the four previously discovered moons of Uranus, Ariel, Umbriel, Titania and Oberon, had all been named after characters of Shakespeare or Alexander Pope. However, the previous moons had been named specifically after fairies, whereas Miranda was a human. Subsequently, discovered satellites of Uranus were named after characters from Shakespeare and Pope, whether fairies or not. The moon is also designated Uranus V.

Of Uranus's five round satellites, Miranda orbits closest to it, at roughly 129,000 km from the surface; about a quarter again as far as its most distant ring. Its orbital period is 34 hours, and, like that of the Moon, is synchronous with its rotation period, which means it always shows the same face to Uranus, a condition known as tidal locking. Miranda's orbital inclination (4.34°) is unusually high for a body so close to its planet, and roughly ten times that of the other major Uranian satellites. The reason for this is still uncertain; there are no mean-motion resonances between the moons that could explain it, leading to the hypothesis that the moons occasionally pass through secondary resonances, which at some point in the past led to Miranda being locked for a time into a 3:1 resonance with Umbriel, before chaotic behaviour induced by the secondary resonances moved it out of it again. In the Uranian system, due to the planet's lesser degree of oblateness, and the larger relative size of its satellites, escape from a mean-motion resonance is much easier than for satellites of Jupiter or Saturn. Miranda's orbit is the most inclined of any of Uranus's large satellites, at 4.232°, it is 10-20 times that of Titania, Ariel and Umbriel and 73 times that of Oberon.

At 1.2 g/cm, Miranda is the least dense of Uranus's round satellites. That density suggests a composition of more than 60% water ice. Miranda's surface may be mostly water ice, though it is far rockier than its corresponding satellites in the Saturn system, indicating that heat from radioactive decay may have led to internal differentiation, allowing silicate rock and organic compounds to settle in its interior. Miranda is too small for any internal heat to have been retained over the age of the Solar System. Miranda is the least spherical of Uranus's satellites, with an equatorial diameter 3% wider than its polar diameter. Only water has been detected so far on Miranda's surface, though it has been speculated that methane, ammonia, carbon monoxide or nitrogen may also exist at 3% concentrations. These bulk properties are similar to Saturn's moon Mimas, though Mimas is smaller, less dense, and more oblate.

Precisely how a body as small as Miranda could have enough internal energy to produce the myriad geological features seen on its surface is not established with certainty, though the currently favoured hypothesis is that it was driven by tidal heating during a past time when it was in 3:1 orbital resonance with Umbriel. The resonance would have increased Miranda's orbital eccentricity to 0.1, and generated tidal friction due to the varying tidal forces from Uranus. As Miranda approached Uranus, tidal force increased; as it retreated, tidal force decreased, causing flexing that would have warmed Miranda's interior by 20 K, enough to trigger melting. The period of tidal flexing could have lasted for up to 100 million years. Also, if clathrate existed within Miranda, as has been hypothesised for the satellites of Uranus, it may have acted as an insulator, since it has a lower conductivity than water, increasing Miranda's temperature still further. Miranda may have also once been in a 5:3 orbital resonance with Ariel, which would have also contributed to its internal heating. However, the maximum heating attributable to the resonance with Umbriel was likely about three times greater.

Due to Uranus's near-sideways orientation, only Miranda's southern hemisphere was visible to "Voyager 2" when it arrived. The observed surface has patchwork regions of broken terrain, indicating intense geological activity in Miranda's past, and is criss-crossed by huge canyons, believed to be the result of extensional tectonics; as liquid water froze beneath the surface, it expanded, causing the surface ice to split, creating graben. The canyons are hundreds of kilometers long and tens of kilometers wide. Miranda also has the largest known cliff in the Solar System, Verona Rupes, which has a height of . Some of Miranda's terrain is possibly less than 100 million years old based on crater counts, while sizeable regions possess crater counts that indicate ancient terrain.

While crater counts suggest that the majority of Miranda's surface is old, with a similar geological history to the other Uranian satellites, few of those craters are particularly large, indicating that most must have formed after a major resurfacing event in its distant past. Craters on Miranda also appear to possess softened edges, which could be the result either of ejecta or of cryovolcanism. The temperature at Miranda's south pole is roughly 85 K, a temperature at which pure water ice adopts the properties of rock. Also, the cryovolcanic material responsible for the surfacing is too viscous to have been pure liquid water, but too fluid to have been solid water. Rather, it is believed to have been a viscous, lava-like mixture of water and ammonia, which freezes at , or perhaps ethanol.

Miranda's observed hemisphere contains three giant 'racetrack'-like grooved structures called coronae, each at least wide and up to deep, named Arden, Elsinore and Inverness after locations in Shakespeare's plays. Inverness is lower in altitude than the surrounding terrain (though domes and ridges are of comparable elevation), while Elsinore is higher, The relative sparsity of craters on their surfaces means they overlay the earlier cratered terrain. The coronae, which are unique to Miranda, initially defied easy explanation; one early hypothesis was that Miranda, at some time in its distant past, (prior to any of the current cratering) had been completely torn to pieces, perhaps by a massive impact, and then reassembled in a random jumble. The heavier core material fell through the crust, and the coronae formed as the water re-froze.

However, the current favoured hypothesis is that they formed via extensional processes at the tops of diapirs, or upwellings of warm ice from within Miranda itself. The coronae are surrounded by rings of concentric faults with a similar low-crater count, suggesting they played a role in their formation. If the coronae formed through downwelling from a catastrophic disruption, then the concentric faults would present as compressed. If they formed through upwelling, such as by diapirism, then they would be extensional tilt blocks, and present extensional features, as current evidence suggests they do. The concentric rings would have formed as ice moved away from the heat source. The diapirs may have changed the density distribution within Miranda, which could have caused Miranda to reorient itself, similar to a process believed to have occurred at Saturn's geologically active moon Enceladus. Evidence suggests the reorientation would have been as extreme as 60 degrees from the sub-Uranian point. The positions of all the coronae require a tidal heating pattern consistent with Miranda being solid, and lacking an internal liquid ocean. It is believed through computer modelling that Miranda may have an additional corona on the unimaged hemisphere.

Miranda's apparent magnitude is +16.6, making it invisible to many amateur telescopes. Virtually all known information regarding its geology and geography was obtained during the flyby of Uranus made by "Voyager 2" on 25 January 1986, The closest approach of "Voyager 2" to Miranda was —significantly less than the distances to all other Uranian moons. Of all the Uranian satellites, Miranda had the most visible surface. The discovery team had expected Miranda to resemble Mimas, and found themselves at a loss to explain the moon's unique geography in the 24-hour window before releasing the images to the press. In 2017, as part of its Planetary Science Decadal Survey, NASA evaluated the possibility of an orbiter to return to Uranus some time in the 2020s. Uranus was the preferred destination over Neptune due to favourable planetary alignments meaning shorter flight times.



</doc>
<doc id="20257" url="https://en.wikipedia.org/wiki?curid=20257" title="Mars in fiction">
Mars in fiction

Fictional representations of Mars have been popular for over a century. Interest in Mars has been stimulated by the planet's dramatic red color, by early scientific speculations that its surface conditions might be capable of supporting life, and by the possibility that Mars could be colonized by humans in the future. Almost as popular as stories about Mars are stories about Martians engaging in activity (frequently invasions) away from their home planet.

In the 20th century, actual spaceflights to the planet Mars, including seminal events such as the first artificial object to impact the surface of Mars in 1971, and then later the first landing of "the first mechanized device to successfully operate on Mars" in 1976 (in the Viking program by the United States), inspired a great deal of interest in Mars-related fiction. Exploration of the planet has continued in the 21st century on to the present day.

The following works of fiction deal with the planet itself, with any assumed Martian civilization as part of its planetary landscape. Mars has been seen as the perfect distance away from Earth to create the idea of a different life. As this allowed for early works to fuel the minds of what Mars could hold. The ideas of Mars as science fiction, would first start with Giovanni Schiaparelli in 1877. The ideas of Mars will grow and change with new information changing the way Mars would be seen in the science fiction world.

Several early modern writers, including Athanasius Kircher (1602–1680) and Emanuel Swedenborg (1688-1772), hypothesized contact with Mars. Early science fiction about Mars often involved the first voyages to the planet, sometimes as an invasion force, more often for the purposes of exploration.






By the 1930s, stories about reaching Mars had become somewhat trite, and the focus shifted to Mars as an alien landscape. In the following stories, human contact and basic exploration had taken place sometime in the past; Mars is a setting rather than a goal.





Mariner 4 in July 1965 found that Mars—contrary to expectations—is heavily cratered, with a very thin atmosphere. No canals were found; while scientists did not believe that Mars was a moist planet, the lack of surface water surprised them. Science fiction had so influenced real explorations of the planet, however—Carl Sagan was among the many fans who became scientists—that after Mariner 9 in 1971-1972, craters were named after Wells, Burroughs, and other authors. The Mariner and Viking space probes confirmed that the Martian environment is extremely hostile to life. By the 1970s, the ideas of canals and ancient civilizations had to be abandoned.

Authors soon began writing stories based on the new Mars (frequently treating it as a desert planet). Most of these works feature humans struggling to tame the planet, and some of them refer to terraforming (using technology to transform a planet's environment to be Earthlike).

A common theme, particularly among American writers, is that of a Martian colony fighting for independence from Earth. It appeared already in Heinlein's "Red Planet" and is a major plot element in Greg Bear's "Moving Mars" and Kim Stanley Robinson's "Mars" trilogy. It is also part of the plot of the movie "Total Recall" and the television series "Babylon 5". Many video games also use this concept, such as the "Red Faction" and "Zone of the Enders" series, and "". A historical rebellion of Mars against Earth is also mentioned in the "Star Trek" series of novels, which are not considered canon.

In the decades following Mariner and Apollo, the once-popular subgenre of realistic stories about a first expedition to Mars fell out of fashion, possibly due to the failure of the Apollo Program to continue on to Mars. The early 1990s saw a revival and re-envisioning of realistic novels about Mars expeditions. Early novels in this renaissance were Jack Williamson's novel "Beachhead" and Ben Bova's novel "Mars" (both 1992), which envisioned large-scale expeditions to Mars according to the thinking of the 1990s. These were followed by Gregory Benford's "The Martian Race" (1999), Geoffrey A. Landis's "Mars Crossing" (2000), and Robert Zubrin's "First Landing" (2002), which took as their starting points the smaller and more focused expedition strategies evolved in the late 1990s, mostly building on the concepts of Mars Direct.






Several post-Mariner works are homages to the older phase of Mars fiction, circumventing the scientific picture of a dry and lifeless Mars with an unbreathable atmosphere through such science fiction generic staples as positing its future terraforming, or creating alternate history versions of Mars, where Burroughs' Barsoom, Bradbury's "Martian Chronicles" or "The War of the Worlds" are literal truth.

Nostalgia for the older Mars also frequently appears in comics and role-playing games, particularly of the steampunk genre:


 is a ride at Walt Disney World's Epcot theme park about astronauts training in a flight simulation of the first mission to Mars. Along the way, riders experience changes in G-Force, cryosleep, and a meteor shower.

In the following works of fiction, the Martian setting is of secondary importance to the work as a whole.

The "Doctor Who" television series has Mars as the uninhabitable homeworld of the Ice Warriors, a recurring adversary of the Second and Third Doctors from 1967 to 1974. In "Pyramids of Mars" (1975), the Fourth Doctor defeats Sutekh, last of the Osirians, who had been imprisoned for his crimes beneath a pyramid, with a signal to keep him paralyzed sent from a Martian pyramid. In "The Waters of Mars" (2009), an episode set on the planet itself, the Tenth Doctor implies that the Ice Warriors have become extinct. (This episode also introduces a viral, water-borne Martian named the Flood.) The episode is set in 2059, and implies that the first human colony on Mars will arrive in 2057, two years before the episode is set (as told in dialogue).






The Martian is a favorite character of classical science fiction; he was frequently found away from his home planet, often invading Earth, but sometimes simply a lonely character representing alienness from his surroundings. Martians, other than human beings transplanted to Mars, became rare in fiction after Mariner, except in exercises of deliberate nostalgia – more frequently in some genres, such as comics and animation, than in written literature.



</doc>
<doc id="20258" url="https://en.wikipedia.org/wiki?curid=20258" title="McIntosh (apple)">
McIntosh (apple)

The McIntosh ( ), McIntosh Red, or colloquially the Mac is an apple cultivar, the national apple of Canada. The fruit has red and green skin, a tart flavour, and tender white flesh, which ripens in late September. In the 20th century it was the most popular cultivar in Eastern Canada and New England, and is considered an all-purpose apple, suitable both for cooking and eating raw. Apple Inc. employee Jef Raskin named the Macintosh line of personal computers after the fruit.

John McIntosh discovered the original McIntosh sapling on his Dundela farm in Upper Canada in 1811. He and his wife bred it, and the family started grafting the tree and selling the fruit in 1835. In 1870, it entered commercial production, and became common in northeastern North America after 1900. While still important in production, the fruit's popularity fell in the early 21st century in the face of competition from varieties such as the Gala. According to the US Apple Association website it is one of the fifteen most popular apple cultivars in the United States.

The McIntosh or McIntosh Red (nicknamed the "Mac"), is the most popular apple cultivar in eastern Canada and the northeastern United States. It also sells well in eastern Europe.

A spreading tree that is moderately vigorous, the McIntosh bears annually or in alternate years. The tree is hardy to at least USDA Hardiness zone 4a, or . 50% or more of its flowers die at or below.

The McIntosh apple is a small- to medium-sized round fruit with a short stem. It has a red and green skin that is thick, tender, and easy to peel. Its white flesh is sometime tinged with green or pink and is juicy, tender, and firm, soon becoming soft. The flesh is easily bruised.

The fruit is considered "all-purpose", suitable both for eating raw and for cooking. It is used primarily for dessert, and requires less time to cook than most cultivars. It is usually blended when used for juice.

The fruit grows best in cool areas where nights are cold and autumn days are clear; otherwise, it suffers from poor colour and soft flesh, and tends to fall from the tree before harvest. It stores for two to three months in air, but is prone to scald, flesh softening, chilling sensitivity, and coprinus rot. It can become mealy when stored at temperatures below . The fruit is optimally stored in a controlled atmosphere in which temperatures are between , and air content is 1.5–4.5% oxygen and 1–5% carbon dioxide; under such conditions, the McIntosh will keep for five to eight months.

The McIntosh is most commonly cultivated in Canada, the United States, and eastern Europe. The parentage of the McIntosh is unknown, but the Snow Apple (or Fameuse), Fall St Lawrence, and Alexander have been speculated. It is one of the top five apple cultivars used in cloning, and research indicates the McIntosh combines well for winter hardiness.

If unsprayed, the McIntosh succumbs easily to apple scab, which may lead to entire crops being unmarketable. It has generally low susceptibility to fire blight, powdery mildew, cedar-apple rust, quince rust, and hawthorn rust. It is susceptible to fungal diseases such as "Nectria" canker, brown rot, black rot, race 1 of apple rust (but resists race 2). It is moderately resistant to "Pezicula" bark rot and "Alternaria" leaf blotch, and resists brown leaf spot well.

The McIntosh is one of the most common cultivars used in cloning; a 1996 study found that the McIntosh was a parent in 101 of 439 cultivars selected, more than any other founding clone. It was used in over half of the Canadian cultivars selected, and was used extensively in the United States and Eastern Europe as well; rarely was it used elsewhere. Offspring of the McIntosh include: the Jersey Black hybrid the Macoun, the Newtown Pippin hybrid the Spartan, the Cortland; the Empire; the Jonamac, the Jersey Mac, the Lobo, the Melba, the Summered, the Tydeman's Red, and possibly the Paula Red.

Apple trees were introduced to Canada at the Habitation at Port-Royal (modern Port Royal, Annapolis County, Nova Scotia) as early as 1606 by French settlers. Following its introduction, apple cultivation spread inland.

The McIntosh's discoverer, John McIntosh (1777 – ), left his native Mohawk Valley home in New York State in 1796 to follow his love, Dolly Irwin, who had been taken to Upper Canada by her Loyalist parents. She had died by the time he found her, but he settled as a farmer in Upper Canada. He married Hannah Doran in 1801, and they farmed along the Saint Lawrence River until 1811, when McIntosh exchanged the land he had with his brother-in-law Edward Doran for a plot in Dundela.

While clearing the overgrown plot McIntosh discovered some wild apple seedlings on his farm. He transplanted the seedlings next to his house. One of the seedlings bore particularly good fruit. The McIntosh grandchildren dubbed the fruit it produced "Granny's apple", as they often saw their grandmother taking care of the tree in the orchard. McIntosh was selling seedlings from the tree by 1820, but they did not produce fruit of the quality of the original.

John McIntosh's son Allan (1815–1899) learned grafting about 1835; with this cloning the McIntoshes could maintain the distinctive properties of the fruit of the original tree. Allan and brother Sandy (1825–1906), nicknamed "Sandy the Grafter", increased production and promotion of the cultivar. Earliest sales were in 1835, and in 1836 the cultivar was renamed the "McIntosh Red"; it entered commercial production in 1870. The apple became popular after 1900, when the first sprays for apple scab were developed. A house fire damaged the original McIntosh tree in 1894; it last produced fruit in 1908, and died and fell over in 1910.

Horticulturist William Tyrrell Macoun of the Central Experimental Farm in Ottawa is credited with popularizing the McIntosh in Canada. He stated the McIntosh needed "no words of praise", that it was "one of the finest appearing and best dessert apples grown". The Macoun, a hybrid of the McIntosh and Jersey Black grown by the Agricultural Experiment Station in Geneva, NY, was named for him in 1923. In the northeastern United States the McIntosh replaced a large number of Baldwins that were killed in a severe winter in 1933–34. In the late 1940s, Canadian ambassador to the United Nations Andrew McNaughton told Soviet Minister for Foreign Affairs Andrei Gromyko that the McIntosh Red was Canada's best apple.

The McIntosh made up 40% of the Canadian apple market by the 1960s; and at least thirty varieties of McIntosh hybrid were known by 1970. Its popularity later waned in the face of competition from foreign imports; in the first decade of the 21st century, the Gala accounted for 33% of the apple market in Ontario to the McIntosh's 12%, and the Northern Spy had become the preferred apple for pies. Production remained important to Ontario, however, as of McIntoshes were produced in 2010.

The original tree discovered by John McIntosh bore fruit for more than ninety years, and died in 1910. Horticulturalists from the Upper Canada Village heritage park saved cuttings from the last known first-generation McIntosh graft before it died in 2011 for producing clones.

The McIntosh has been designated the national apple of Canada. A popular subscription funded a plaque placed from the original McIntosh tree in 1912. The Ontario Archaeological and Historic Sites Board replaced the plaque with a more descriptive one in 1962, and the Historic Sites and Monuments Board of Canada put up another in a park nearby in 2001, by a painted mural commemorating the fruit.

Apple Inc. employee Jef Raskin named the Macintosh line of personal computers after the McIntosh. He deliberately misspelled the name to avoid conflict with the hi-fi equipment manufacturer McIntosh Laboratory. Apple's attempt in 1982 to trademark the name Macintosh was nevertheless denied due to the phonetic similarity between Apple's product and the name of the hi-fi manufacturer. Apple licensed the rights to the name in 1983, and bought the trademark in 1986.

In 1995 the Royal Canadian Mint commissioned Toronto artist Roger Hill to design a commemorative silver dollar for release in 1996. Mint engraver Sheldon Beveridge engraved the image of a group of three McIntoshes and a McIntosh blossom which adorn one side with a ribbon naming the variety. An inscription on the edge reads "1796 Canada Dollar 1996". Issued sheathed in a silver cardboard sleeve in a black leatherette case, 133,779 pieces of the proof were sold, as well as 58,834 pieces of the uncirculated version in a plastic capsule and silver sleeve.




</doc>
<doc id="20261" url="https://en.wikipedia.org/wiki?curid=20261" title="Machete">
Machete

A machete (; ) is a broad blade used either as an agricultural implement similar to an axe, or in combat like a long-bladed knife. The blade is typically long and usually under thick. In the Spanish language, the word is a diminutive form of the word "macho", which was used to refer to sledgehammers. In the English language, an equivalent term is matchet, though it is less commonly used. In the English-speaking Caribbean, such as Jamaica, Barbados, Guyana, and Grenada and in Trinidad and Tobago, the term "cutlass" is used for these agricultural tools.

In various tropical and subtropical countries, the machete is frequently used to cut through rainforest undergrowth and for agricultural purposes (e.g. cutting sugar cane). Besides this, in Latin America a common use is for such household tasks as cutting large foodstuffs into pieces—much as a cleaver is used—or to perform crude cutting tasks, such as making simple wooden handles for other tools. It is common to see people using machetes for other jobs, such as splitting open coconuts, yard work, removing small branches and plants, chopping animals' food, and clearing bushes.

Machetes are often considered tools and used by adults. However, many hunter–gatherer societies and cultures surviving through subsistence agriculture begin teaching babies to use sharp tools, including machetes, before their first birthdays.

Because the machete is common in many tropical countries, it is often the weapon of choice for uprisings. For example, the Boricua Popular Army are unofficially called "macheteros" because of the machete-wielding laborers of sugar cane fields of past Puerto Rico.

Many of the killings in the 1994 Rwandan genocide were performed with machetes, and they were the primary weapon used by the Interahamwe militias there. Machetes were also a distinctive tool and weapon of the Haitian "Tonton Macoute".

In 1762, the Kingdom of Great Britain invaded Cuba in the Battle of Havana, and peasant guerrillas led by Pepe Antonio, a Guanabacoa councilman, used machetes in the defense of the city. The machete was also the most iconic weapon during the independence wars in that country (1868–1898), although it saw limited battlefield use. Carlos Manuel de Céspedes, owner of the sugar refinery "La Demajagua" near Manzanillo, freed his slaves on 10 October 1868. He proceeded to lead them, armed with machetes, in revolt against the Spanish government. The first cavalry charge using machetes as the primary weapon was carried out on 4 November 1868 by Máximo Gómez, a sergeant born in the Dominican Republic, who later became the general in chief of the Cuban Army.

The machete was (and still is) a common side arm and tool for many ethnic groups in West Africa. Machetes in this role are referenced in Chinua Achebe's "Things Fall Apart".

Some countries have a name for the blow of a machete; the Spanish "machetazo" is sometimes used in English. In the British Virgin Islands, Grenada, Jamaica, Saint Kitts and Nevis, Barbados, Saint Lucia, and Trinidad and Tobago, the word "planass" means to hit someone with the flat of the blade of a machete or cutlass. To strike with the sharpened edge is to "chop". Throughout the Caribbean, the term 'cutlass' refers to a laborers' cutting tool.

The Brazilian Army's Instruction Center on Jungle Warfare developed a machete with a blade in length and a very pronounced clip point. This machete is issued with a 5-inch Bowie knife and a sharpening stone in the scabbard; collectively called a "jungle kit" ("Conjunto de Selva" in Portuguese); it is manufactured by Indústria de Material Bélico do Brasil (IMBEL).

Many fictitious slashers have used it as a weapon in horror and fighting movies, the most well known and notorious being Jason Voorhees, from the "Friday the 13th" movie series and Quincy, from the Downtown Defenders (franchise).

The tsakat is used primarily in southern Armenia and Artsakh when clearing areas or hiking. It's especially well suited for clearing the plentiful blackberry plants in these regions.

The "panga" or "tapanga" is a variant used in East and Southern Africa. This name may be of Swahili etymology; not to be confused with the Panga fish. The "panga" blade broadens on the backside and has a length of . The upper inclined portion of the blade may be sharpened.

This tool has been used as a weapon: during the Mau Mau Uprising; in the Rwandan Genocide; in South Africa particularly in the 1980s and early 1990s when the former province of Natal was wracked by conflict between the African National Congress and the Zulu-nationalist Inkatha Freedom Party.

In the Philippines, the "bolo" is a very similar tool, but with the blade swelling just before the tip to make the knife even more efficient for chopping. Variations include the longer and more pointed "iták" intended for combat; this was used during the Philippine Revolution against the Spanish colonial authorities, later becoming a signature weapon of guerrillas in the Philippine–American War. Filipinos still use the "bolo" for everyday tasks, such as clearing vegetation and chopping various large foodstuffs. These are also commonly found in most Filipino kitchens, with some sets displayed on the walls and other sets for less practical use. The "bolo" is also used in training in "eskrima", the indigenous martial art of the Philippines.

Other similar tools include the "parang" and the "golok" (from Malaysia and Indonesia); however, these tend to have shorter, thicker blades with a primary grind, and are more effective on woody vegetation. The Nepalese "kukri" is a curved blade that is often used for similar tasks.

In Thailand, more variations exist, such as the "e-nep", or "nep", which translates as "leaf" (มีดเหน็บ). It may resemble some forms of Muslim blades like the "jambiya", or the Nepali "khukuri", having aspects of both with the up-swept tip and protruding belly. Another design found in Thailand is the "e-toh", which is prominent in Southern China, Laos, and other northern parts of South East Asia. Generally, "e-tohs" must have forward weighted tips, and are used around the home for splitting stove wood or chopping bone. The Chinese "dao", with its triangular tip, is found in Thailand as the "hua-tad" (หัวแตด), which translates roughly as "head chopper". The most common blade in Thailand is called the "pra", (พร้า) it can describe long straight designs, or billhook designs. The primary purpose of a "pra" is farm work and clearing vegetation.

In the various regions of Ecuador, it is still used as an everyday tool in agricultural labors, such as clearing, chopping, cutting and felling. In the Pacific coast region, the machete has a long history of use and can be seen as part of the everyday dress of the rural male inhabitants, especially in the provinces of Manabi, Los Rios and Guayas. In its day, the machete and the skills related to it were seen as a token of manliness, and it was carried, sword-like, in ornamented sheaths made out of leather or in sashes around the waist. Its use was not limited to agriculture: it also had a double role as a ready-to-hand weapon for self-defense or attack. Although modern laws in Ecuador now prohibit its use as a weapon, there are still cases of vicious fighting or intimidation related to it. Being a part of the male dress, it also has a part in the cultural expressions of the coastal rural regions of Ecuador, such as dances, horse taming contests and skill exhibitions.

In the southern Brazilian state of Rio Grande do Sul, the machete made by Spanish is largely used. It is used to clear paths through the bush, and was used to fight against the Brazilian Empire in the Ragamuffin War. There, the machete is called "facão" or "facón" (literally "big knife"). Today, this region has a dance called the "dança dos facões" (machetes' dance) in which the dancers, who also always men, knock their machetes while dancing, simulating a battle. "Maculelê", an Afro-Brazilian dance and martial art, can also be performed with "facões". This practice began in the city of Santo Amaro, Bahia, in the northeastern part of the country.

In southern Mexico and Central America it is widely used to clear bush and often hundreds of "macheteros" are contracted to assist in clearing paths for the construction of new roads or structures. Many people in the rural regions own machetes to clear the constant overgrowth of jungle bush. In the recent drug cartel wars of the region, many homicides and decapitations are suspected of being committed with machetes or similar tools.
The "taiga" is a machete of Russian origin that combines the functions of machetes, axes, knives, saws, and shovels into one tool. It is easily distinguished by the large swell at the end of the blade to facilitate chopping. The "taiga" is used by military air and special forces, including the "Spetsnaz".

The modern machete is very similar to some forms of the medieval falchion, a short sword popular from the 13th century onwards. The cutting edge of the falchion is curved, widening toward the point, and has a straight, unsharpened back edge. The machete differs from the falchion mainly in the lack of a guard and a simpler hilt, though some machetes do have a guard for greater hand protection during work.

The "kopis" is an ancient Greek weapon comparable to the machete. The "makhaira" is also similar, but was intended primarily to be a weapon rather than a tool.

The "seax" is a Germanic weapon that is also similar in function, although different in shape.

The "kukri" is a Nepalese curved blade used for many purposes similar to the machete.

The "parang" is a Malaysian knife that many machetes are based on.

The "grosse messer" is a large "medieval" knife, employed both as a tool and as a weapon.

The "dao" is a traditional Chinese weapon resembling the machete. It is also known as "The General of All Weapons" and one of the traditional weapons of china. Dao is basically used for clearing and chopping tasks.

The fascine knife is a somewhat similar tool and weapon used by European armies throughout the late 18th to early 20th centuries. The Spanish Army called its fascine knives "machetes". Whereas infantry were usually issued short sabres as side arms, engineers and artillerymen often received fascine knives, as besides being side arms they also served as useful tools for the construction of fortifications and other utilitarian tasks. They differ from machetes in that they generally have far thicker, tapered blades optimized for chopping European vegetation (the thin, flat blade of the machete is better for soft plants found in tropical environments), sword-like hilts and guards, and sometimes a sawback-blade. Some later models could be fixed to rifles as bayonets as well.

The katana, typically acquired through trade, was used by the Ainu people in a machete-like fashion rather than a weapon as it was originally intended to be.

Both the materials used and the shape of the machete itself are important to make a good machete. In the past, the most famous manufacturer of machetes in Latin America and the Spanish-speaking Caribbean was Collins Company of Collinsville, Connecticut. The company was founded as Collins & Company in 1826 by Samuel W. Collins to make axes. Its first machetes were sold in 1845 and became so famous that all good machetes were called "un Collins". In the English-speaking Caribbean, Robert Mole & Sons of Birmingham, England, was long considered the manufacturer of agricultural cutlasses of the best quality. Some Robert Mole blades survive as souvenirs of travelers to Trinidad, Jamaica, and, less commonly, St. Lucia.

Since the 1950s, however, manufacturing shortcuts have resulted in a quality decline of machetes. Today, most modern factory-made machetes are of very simple construction, consisting of a blade and full-length tang punched from a single piece of flat steel plate of uniform thickness (and thus lack a primary grind), and a simple grip of two plates of wood or plastic bolted or riveted together around the tang. Finally, both sides are ground down to a rough edge so that the purchaser can sharpen the blade to their specific geometry using a file. These machetes are occasionally provided with a simple cord loop as a sort of lanyard, and a canvas scabbard—although in some regions where machetes are valuable, commonly used tools, the users may make decorative leather scabbards for them.

Toughness is important because of the twisting and impact forces that the relatively thin blade may encounter, while edge retention is secondary. Medium to high carbon spring steels, such as 1050 to 1095, are well suited to this application (with better machetes using the latter), and are relatively easy to sharpen. Most stainless steel machetes should be avoided, as many high-carbon stainless-steel machetes cannot stand up to repeated impacts, and will easily break if abused.

In comparison to most other knives, which are commonly heat treated to a very high degree of hardness, many machete blades are tempered to maximum toughness, often nearly spring tempered. This results in a tougher blade, more resistant to chipping and breaking, with an edge that is easier to sharpen but does not retain sharpness as well, due to its lower hardness.

A properly constructed machete will have a convex or flat primary bevel from the spine to the edge, which is formed by a secondary bevel. Better machetes will also have a slight distal taper.

Colombia is the largest exporter of machetes worldwide.

The flag of Angola features a machete, along with a cog-wheel.

The machete is also a performance weapon used in variations of the Brazilian martial dance called "maculelê", often practiced by practitioners of "capoeira". Machetes are a distinctive characteristic in the folkloric dances of the state of Nayarit. It is also seen in the state of Durango, in the folkloric dance called "Danza de los Machetes" which consists of blind-folded dancers juggling machetes and pitching them at increasing speeds between one another.

Traditional forms of fencing with machetes include Colombian grima in Colombia, "Juego del garrote" in Venezuela, and "tire machèt" in Haiti.




</doc>
<doc id="20264" url="https://en.wikipedia.org/wiki?curid=20264" title="Mushroom">
Mushroom

A mushroom or toadstool is the fleshy, spore-bearing fruiting body of a fungus, typically produced above ground, on soil, or on its food source.

The standard for the name "mushroom" is the cultivated white button mushroom, "Agaricus bisporus"; hence the word "mushroom" is most often applied to those fungi (Basidiomycota, Agaricomycetes) that have a stem (stipe), a cap (pileus), and gills (lamellae, sing. lamella) on the underside of the cap. "Mushroom" also describes a variety of other gilled fungi, with or without stems, therefore the term is used to describe the fleshy fruiting bodies of some Ascomycota. These gills produce microscopic spores that help the fungus spread across the ground or its occupant surface.

Forms deviating from the standard morphology usually have more specific names, such as "bolete", "puffball", "stinkhorn", and "morel", and gilled mushrooms themselves are often called "agarics" in reference to their similarity to "Agaricus" or their order Agaricales. By extension, the term "mushroom" can also refer to either the entire fungus when in culture, the thallus (called a mycelium) of species forming the fruiting bodies called mushrooms, or the species itself.

The terms "mushroom" and "toadstool" go back centuries and were never precisely defined, nor was there consensus on application. During the 15th and 16th centuries, the terms "mushrom, mushrum, muscheron, mousheroms, mussheron, or musserouns" were used.

The term "mushroom" and its variations may have been derived from the French word "mousseron" in reference to moss ("mousse"). Delineation between edible and poisonous fungi is not clear-cut, so a "mushroom" may be edible, poisonous, or unpalatable.

Cultural or social phobias of mushrooms and fungi may be related. The term "fungophobia" was coined by William Delisle Hay of England, who noted a national superstition or fear of "toadstools".

The word "toadstool" has apparent analogies in Dutch "padde(n)stoel" (toad-stool/chair, mushroom) and German "Krötenschwamm" (toad-fungus, alt. word for panther cap). In German folklore and old fairy tales, toads are often depicted sitting on toadstool mushrooms and catching, with their tongues, the flies that are said to be drawn to the "Fliegenpilz", a German name for the toadstool, meaning "flies' mushroom". This is how the mushroom got another of its names, "Krötenstuhl" (a less-used German name for the mushroom), literally translating to "toad-stool".

Identifying mushrooms requires a basic understanding of their macroscopic structure. Most are Basidiomycetes and gilled. Their spores, called basidiospores, are produced on the gills and fall in a fine rain of powder from under the caps as a result. At the microscopic level, the basidiospores are shot off basidia and then fall between the gills in the dead air space. As a result, for most mushrooms, if the cap is cut off and placed gill-side-down overnight, a powdery impression reflecting the shape of the gills (or pores, or spines, etc.) is formed (when the fruit body is sporulating). The color of the powdery print, called a spore print, is used to help classify mushrooms and can help to identify them. Spore print colors include white (most common), brown, black, purple-brown, pink, yellow, and creamy, but almost never blue, green, or red.

While modern identification of mushrooms is quickly becoming molecular, the standard methods for identification are still used by most and have developed into a fine art harking back to medieval times and the Victorian era, combined with microscopic examination. The presence of juices upon breaking, bruising reactions, odors, tastes, shades of color, habitat, habit, and season are all considered by both amateur and professional mycologists. Tasting and smelling mushrooms carries its own hazards because of poisons and allergens. Chemical tests are also used for some genera.

In general, identification to genus can often be accomplished in the field using a local mushroom guide. Identification to species, however, requires more effort; one must remember that a mushroom develops from a button stage into a mature structure, and only the latter can provide certain characteristics needed for the identification of the species. However, over-mature specimens lose features and cease producing spores. Many novices have mistaken humid water marks on paper for white spore prints, or discolored paper from oozing liquids on lamella edges for colored spored prints.

Typical mushrooms are the fruit bodies of members of the order Agaricales, whose type genus is "Agaricus" and type species is the field mushroom, "Agaricus campestris". However, in modern molecularly defined classifications, not all members of the order Agaricales produce mushroom fruit bodies, and many other gilled fungi, collectively called mushrooms, occur in other orders of the class Agaricomycetes. For example, chanterelles are in the Cantharellales, false chanterelles such as "Gomphus" are in the Gomphales, milk-cap mushrooms ("Lactarius", "Lactifluus") and russulas ("Russula"), as well as "Lentinellus", are in the Russulales, while the tough, leathery genera "Lentinus" and "Panus" are among the Polyporales, but "Neolentinus" is in the Gloeophyllales, and the little pin-mushroom genus, "Rickenella", along with similar genera, are in the Hymenochaetales.

Within the main body of mushrooms, in the Agaricales, are common fungi like the common fairy-ring mushroom, shiitake, enoki, oyster mushrooms, fly agarics and other Amanitas, magic mushrooms like species of "Psilocybe", paddy straw mushrooms, shaggy manes, etc.

An atypical mushroom is the lobster mushroom, which is a deformed, cooked-lobster-colored parasitized fruitbody of a "Russula" or "Lactarius", colored and deformed by the mycoparasitic Ascomycete "Hypomyces lactifluorum".

Other mushrooms are not gilled, so the term "mushroom" is loosely used, and giving a full account of their classifications is difficult. Some have pores underneath (and are usually called boletes), others have spines, such as the hedgehog mushroom and other tooth fungi, and so on. "Mushroom" has been used for polypores, puffballs, jelly fungi, coral fungi, bracket fungi, stinkhorns, and cup fungi. Thus, the term is more one of common application to macroscopic fungal fruiting bodies than one having precise taxonomic meaning. Approximately 14,000 species of mushrooms are described.

A mushroom develops from a nodule, or pinhead, less than two millimeters in diameter, called a primordium, which is typically found on or near the surface of the substrate. It is formed within the mycelium, the mass of threadlike hyphae that make up the fungus. The primordium enlarges into a roundish structure of interwoven hyphae roughly resembling an egg, called a "button". The button has a cottony roll of mycelium, the universal veil, that surrounds the developing fruit body. As the egg expands, the universal veil ruptures and may remain as a cup, or volva, at the base of the stalk, or as warts or volval patches on the cap. Many mushrooms lack a universal veil, therefore they do not have either a volva or volval patches. Often, a second layer of tissue, the partial veil, covers the bladelike gills that bear spores. As the cap expands, the veil breaks, and remnants of the partial veil may remain as a ring, or annulus, around the middle of the stalk or as fragments hanging from the margin of the cap. The ring may be skirt-like as in some species of "Amanita", collar-like as in many species of "Lepiota", or merely the faint remnants of a cortina (a partial veil composed of filaments resembling a spiderweb), which is typical of the genus "Cortinarius". Mushrooms lacking partial veils do not form an annulus.

The stalk (also called the stipe, or stem) may be central and support the cap in the middle, or it may be off-center and/or lateral, as in species of "Pleurotus" and "Panus". In other mushrooms, a stalk may be absent, as in the polypores that form shelf-like brackets. Puffballs lack a stalk, but may have a supporting base. Other mushrooms, such as truffles, jellies, earthstars, and bird's nests, usually do not have stalks, and a specialized mycological vocabulary exists to describe their parts.

The way the gills attach to the top of the stalk is an important feature of mushroom morphology. Mushrooms in the genera "Agaricus", "Amanita", "Lepiota" and "Pluteus", among others, have free gills that do not extend to the top of the stalk. Others have decurrent gills that extend down the stalk, as in the genera "Omphalotus" and "Pleurotus". There are a great number of variations between the extremes of free and decurrent, collectively called attached gills. Finer distinctions are often made to distinguish the types of attached gills: adnate gills, which adjoin squarely to the stalk; notched gills, which are notched where they join the top of the stalk; adnexed gills, which curve upward to meet the stalk, and so on. These distinctions between attached gills are sometimes difficult to interpret, since gill attachment may change as the mushroom matures, or with different environmental conditions.

A hymenium is a layer of microscopic spore-bearing cells that covers the surface of gills. In the nongilled mushrooms, the hymenium lines the inner surfaces of the tubes of boletes and polypores, or covers the teeth of spine fungi and the branches of corals. In the Ascomycota, spores develop within microscopic elongated, sac-like cells called asci, which typically contain eight spores in each ascus. The Discomycetes, which contain the cup, sponge, brain, and some club-like fungi, develop an exposed layer of asci, as on the inner surfaces of cup fungi or within the pits of morels. The Pyrenomycetes, tiny dark-colored fungi that live on a wide range of substrates including soil, dung, leaf litter, and decaying wood, as well as other fungi, produce minute, flask-shaped structures called perithecia, within which the asci develop.

In the Basidiomycetes, usually four spores develop on the tips of thin projections called sterigmata, which extend from club-shaped cells called a basidia. The fertile portion of the Gasteromycetes, called a gleba, may become powdery as in the puffballs or slimy as in the stinkhorns. Interspersed among the asci are threadlike sterile cells called paraphyses. Similar structures called cystidia often occur within the hymenium of the Basidiomycota. Many types of cystidia exist, and assessing their presence, shape, and size is often used to verify the identification of a mushroom.

The most important microscopic feature for identification of mushrooms is the spores. Their color, shape, size, attachment, ornamentation, and reaction to chemical tests often can be the crux of an identification. A spore often has a protrusion at one end, called an apiculus, which is the point of attachment to the basidium, termed the apical germ pore, from which the hypha emerges when the spore germinates.

Many species of mushrooms seemingly appear overnight, growing or expanding rapidly. This phenomenon is the source of several common expressions in the English language including "to mushroom" or "mushrooming" (expanding rapidly in size or scope) and "to pop up like a mushroom" (to appear unexpectedly and quickly). In reality, all species of mushrooms take several days to form primordial mushroom fruit bodies, though they do expand rapidly by the absorption of fluids.

The cultivated mushroom, as well as the common field mushroom, initially form a minute fruiting body, referred to as the pin stage because of their small size. Slightly expanded, they are called buttons, once again because of the relative size and shape. Once such stages are formed, the mushroom can rapidly pull in water from its mycelium and expand, mainly by inflating preformed cells that took several days to form in the primordia.

Similarly, there are other mushrooms, like "Parasola plicatilis" (formerly "Coprinus plicatlis"), that grow rapidly overnight and may disappear by late afternoon on a hot day after rainfall. The primordia form at ground level in lawns in humid spaces under the thatch and after heavy rainfall or in dewy conditions balloon to full size in a few hours, release spores, and then collapse. They "mushroom" to full size.

Not all mushrooms expand overnight; some grow very slowly and add tissue to their fruiting bodies by growing from the edges of the colony or by inserting hyphae. For example, "Pleurotus nebrodensis" grows slowly, and because of this combined with human collection, it is now critically endangered.

Though mushroom fruiting bodies are short-lived, the underlying mycelium can itself be long-lived and massive. A colony of "Armillaria solidipes" (formerly known as "Armillaria ostoyae") in Malheur National Forest in the United States is estimated to be 2,400 years old, possibly older, and spans an estimated . Most of the fungus is underground and in decaying wood or dying tree roots in the form of white mycelia combined with black shoelace-like rhizomorphs that bridge colonized separated woody substrates.

Raw brown mushrooms are 92% water, 4% carbohydrates, 2% protein and less than 1% fat. In a 100 gram (3.5 ounce) amount, raw mushrooms provide 22 calories and are a rich source (20% or more of the Daily Value, DV) of B vitamins, such as riboflavin, niacin and pantothenic acid, selenium (37% DV) and copper (25% DV), and a moderate source (10-19% DV) of phosphorus, zinc and potassium (table). They have minimal or no vitamin C and sodium content.

The vitamin D content of a mushroom depends on postharvest handling, in particular the unintended exposure to sunlight. The US Department of Agriculture provided evidence that UV-exposed mushrooms contain substantial amounts of vitamin D. When exposed to ultraviolet (UV) light, even after harvesting, ergosterol in mushrooms is converted to vitamin D, a process now used intentionally to supply fresh vitamin D mushrooms for the functional food grocery market. In a comprehensive safety assessment of producing vitamin D in fresh mushrooms, researchers showed that artificial UV light technologies were equally effective for vitamin D production as in mushrooms exposed to natural sunlight, and that UV light has a long record of safe use for production of vitamin D in food.

Mushrooms are used extensively in cooking, in many cuisines (notably Chinese, Korean, European, and Japanese).

Most mushrooms sold in supermarkets have been commercially grown on mushroom farms. The most popular of these, "Agaricus bisporus", is considered safe for most people to eat because it is grown in controlled, sterilized environments. Several varieties of "A. bisporus" are grown commercially, including whites, crimini, and portobello. Other cultivated species available at many grocers include "Hericium erinaceus", shiitake, maitake (hen-of-the-woods), "Pleurotus", and enoki. In recent years, increasing affluence in developing countries has led to a considerable growth in interest in mushroom cultivation, which is now seen as a potentially important economic activity for small farmers.

China is a major edible mushroom producer. The country produces about half of all cultivated mushrooms, and around of mushrooms are consumed per person per year by 1.4 billion people. In 2014, Poland was the world's largest mushroom exporter, reporting an estimated annually.

Separating edible from poisonous species requires meticulous attention to detail; there is no single trait by which all toxic mushrooms can be identified, nor one by which all edible mushrooms can be identified. People who collect mushrooms for consumption are known as mycophagists, and the act of collecting them for such is known as mushroom hunting, or simply "mushrooming". Even edible mushrooms may produce allergic reactions in susceptible individuals, from a mild asthmatic response to severe anaphylactic shock. Even the cultivated "A. bisporus" contains small amounts of hydrazines, the most abundant of which is agaritine (a mycotoxin and carcinogen). However, the hydrazines are destroyed by moderate heat when cooking.

A number of species of mushrooms are poisonous; although some resemble certain edible species, consuming them could be fatal. Eating mushrooms gathered in the wild is risky and should only be undertaken by individuals knowledgeable in mushroom identification. Common best practice is for wild mushroom pickers to focus on collecting a small number of visually distinctive, edible mushroom species that cannot be easily confused with poisonous varieties.

Many mushroom species produce secondary metabolites that can be toxic, mind-altering, antibiotic, antiviral, or bioluminescent. Although there are only a small number of deadly species, several others can cause particularly severe and unpleasant symptoms. Toxicity likely plays a role in protecting the function of the basidiocarp: the mycelium has expended considerable energy and protoplasmic material to develop a structure to efficiently distribute its spores. One defense against consumption and premature destruction is the evolution of chemicals that render the mushroom inedible, either causing the consumer to vomit the meal (see emetics), or to learn to avoid consumption altogether. In addition, due to the propensity of mushrooms to absorb heavy metals, including those that are radioactive, European mushrooms may, as late as 2008, include toxicity from the 1986 Chernobyl disaster and continue to be studied.

Mushrooms with psychoactive properties have long played a role in various native medicine traditions in cultures all around the world. They have been used as sacrament in rituals aimed at mental and physical healing, and to facilitate visionary states. One such ritual is the "velada" ceremony. A practitioner of traditional mushroom use is the "shaman" or "curandera" (priest-healer).

Psilocybin mushrooms possess psychedelic properties. Commonly known as "magic mushrooms" or shrooms", they are openly available in smart shops in many parts of the world, or on the black market in those countries that have outlawed their sale. Psilocybin mushrooms have been reported as facilitating profound and life-changing insights often described as mystical experiences. Recent scientific work has supported these claims, as well as the long-lasting effects of such induced spiritual experiences.
Psilocybin, a naturally occurring chemical in certain psychedelic mushrooms such as "Psilocybe cubensis", is being studied for its ability to help people suffering from psychological disorders, such as obsessive–compulsive disorder. Minute amounts have been reported to stop cluster and migraine headaches. A double-blind study, done by the Johns Hopkins Hospital, showed psychedelic mushrooms could provide people an experience with substantial personal meaning and spiritual significance. In the study, one third of the subjects reported ingestion of psychedelic mushrooms was the single most spiritually significant event of their lives. Over two-thirds reported it among their five most meaningful and spiritually significant events. On the other hand, one-third of the subjects reported extreme anxiety. However, the anxiety went away after a short period of time. Psilocybin mushrooms have also shown to be successful in treating addiction, specifically with alcohol and cigarettes.

A few species in the genus "Amanita", most recognizably "A. muscaria", but also "A. pantherina", among others, contain the psychoactive compound muscimol. The muscimol-containing chemotaxonomic group of "Amanitas" contains no amatoxins or phallotoxins, and as such are not hepatoxic, though if not properly cured will be non-lethally neurotoxic due to the presence of ibotenic acid. The "Amanita" intoxication is similar to Z-drugs in that it includes CNS depressant and sedative-hypnotic effects, but also dissociation and delirium in high doses.

Some mushrooms are used or studied as possible treatments for diseases, particularly their extracts, including polysaccharides, glycoproteins and proteoglycans. In some countries, extracts of polysaccharide-K, schizophyllan, polysaccharide peptide, or lentinan are government-registered adjuvant cancer therapies, even though clinical evidence of efficacy in humans has not been confirmed.

Historically in traditional Chinese medicine, mushrooms are believed to have medicinal value, although there is no evidence for such uses.

Mushrooms can be used for dyeing wool and other natural fibers. The chromophores of mushroom dyes are organic compounds and produce strong and vivid colors, and all colors of the spectrum can be achieved with mushroom dyes. Before the invention of synthetic dyes, mushrooms were the source of many textile dyes.

Some fungi, types of polypores loosely called mushrooms, have been used as fire starters (known as tinder fungi).

Mushrooms and other fungi play a role in the development of new biological remediation techniques (e.g., using mycorrhizae to spur plant growth) and filtration technologies (e.g. using fungi to lower bacterial levels in contaminated water).






</doc>
<doc id="20266" url="https://en.wikipedia.org/wiki?curid=20266" title="Mainframe computer">
Mainframe computer

Mainframe computers or mainframes, also known as "big iron", are computers used primarily by large organizations for critical applications; bulk data processing, such as census, industry and consumer statistics; enterprise resource planning; and transaction processing. They are larger and have more processing power than some other classes of computers: minicomputers, servers, workstations, and personal computers.

The term originally referred to the large cabinets called "main frames" that housed the central processing unit and main memory of early computers. Later, the term was used to distinguish high-end commercial machines from less-powerful units. Most large-scale computer-system architectures were established in the 1960s, but continue to evolve. Mainframe computers are often used as servers.

Modern mainframe design is characterized less by raw computational speed and more by:

Their high stability and reliability enable these machines to run uninterrupted for very long periods of time, with mean time between failures (MTBF) measured in decades.

Mainframes have high availability, one of the primary reasons for their longevity, since they are typically used in applications where downtime would be costly or catastrophic. The term reliability, availability and serviceability (RAS) is a defining characteristic of mainframe computers. Proper planning and implementation are required to realize these features. In addition, mainframes are more secure than other computer types: the NIST vulnerabilities database, US-CERT, rates traditional mainframes such as IBM Z (previously called z Systems, System z and zSeries), Unisys Dorado and Unisys Libra as among the most secure with vulnerabilities in the low single digits as compared with thousands for Windows, UNIX, and Linux. Software upgrades usually require setting up the operating system or portions thereof, and are non-disruptive only when using virtualizing facilities such as IBM z/OS and Parallel Sysplex, or Unisys XPCL, which support workload sharing so that one system can take over another's application while it is being refreshed.

In the late 1950s, mainframes had only a rudimentary interactive interface (the console) and used sets of punched cards, paper tape, or magnetic tape to transfer data and programs. They operated in batch mode to support back office functions such as payroll and customer billing, most of which were based on repeated tape-based sorting and merging operations followed by line printing to preprinted continuous stationery. When interactive user terminals were introduced, they were used almost exclusively for applications (e.g. airline booking) rather than program development. Typewriter and Teletype devices were common control consoles for system operators through the early 1970s, although ultimately supplanted by keyboard/display devices.

By the early 1970s, many mainframes acquired interactive user terminals operating as timesharing computers, supporting hundreds of users simultaneously along with batch processing. Users gained access through keyboard/typewriter terminals and specialized text terminal CRT displays with integral keyboards, or later from personal computers equipped with terminal emulation software. By the 1980s, many mainframes supported graphic display terminals, and terminal emulation, but not graphical user interfaces. This form of end-user computing became obsolete in the 1990s due to the advent of personal computers provided with GUIs. After 2000, modern mainframes partially or entirely phased out classic "green screen" and color display terminal access for end-users in favour of Web-style user interfaces.

The infrastructure requirements were drastically reduced during the mid-1990s, when CMOS mainframe designs replaced the older bipolar technology. IBM claimed that its newer mainframes reduced data center energy costs for power and cooling, and reduced physical space requirements compared to server farms.

Modern mainframes can run multiple different instances of operating systems at the same time. This technique of virtual machines allows applications to run as if they were on physically distinct computers. In this role, a single mainframe can replace higher-functioning hardware services available to conventional servers. While mainframes pioneered this capability, virtualization is now available on most families of computer systems, though not always to the same degree or level of sophistication.

Mainframes can add or hot swap system capacity without disrupting system function, with specificity and granularity to a level of sophistication not usually available with most server solutions. Modern mainframes, notably the IBM zSeries, System z9 and System z10 servers, offer two levels of virtualization: logical partitions (LPARs, via the PR/SM facility) and virtual machines (via the z/VM operating system). Many mainframe customers run two machines: one in their primary data center and one in their backup data center—fully active, partially active, or on standby—in case there is a catastrophe affecting the first building. Test, development, training, and production workload for applications and databases can run on a single machine, except for extremely large demands where the capacity of one machine might be limiting. Such a two-mainframe installation can support continuous business service, avoiding both planned and unplanned outages. In practice many customers use multiple mainframes linked either by Parallel Sysplex and shared DASD (in IBM's case), or with shared, geographically dispersed storage provided by EMC or Hitachi.

Mainframes are designed to handle very high volume input and output (I/O) and emphasize throughput computing. Since the late 1950s, mainframe designs have included subsidiary hardware (called "channels" or "peripheral processors") which manage the I/O devices, leaving the CPU free to deal only with high-speed memory. It is common in mainframe shops to deal with massive databases and files. Gigabyte to terabyte-size record files are not unusual. Compared to a typical PC, mainframes commonly have hundreds to thousands of times as much data storage online, and can access it reasonably quickly. Other server families also offload I/O processing and emphasize throughput computing.

Mainframe return on investment (ROI), like any other computing platform, is dependent on its ability to scale, support mixed workloads, reduce labor costs, deliver uninterrupted service for critical business applications, and several other risk-adjusted cost factors.

Mainframes also have execution integrity characteristics for fault tolerant computing. For example, z900, z990, System z9, and System z10 servers effectively execute result-oriented instructions twice, compare results, arbitrate between any differences (through instruction retry and failure isolation), then shift workloads "in flight" to functioning processors, including spares, without any impact to operating systems, applications, or users. This hardware-level feature, also found in HP's NonStop systems, is known as lock-stepping, because both processors take their "steps" (i.e. instructions) together. Not all applications absolutely need the assured integrity that these systems provide, but many do, such as financial transaction processing.

IBM, with z Systems, continues to be a major manufacturer in the mainframe market. Unisys manufactures ClearPath Libra mainframes, based on earlier Burroughs MCP products and ClearPath Dorado mainframes based on Sperry Univac OS 1100 product lines. In 2000, Hitachi co-developed the zSeries z900 with IBM to share expenses, but subsequently the two companies have not collaborated on new Hitachi models. Hewlett-Packard sells its unique NonStop systems, which it acquired with Tandem Computers and which some analysts classify as mainframes. Groupe Bull's GCOS, Stratus OpenVOS, Fujitsu (formerly Siemens) BS2000, and Fujitsu-ICL VME mainframes are still available in Europe, and Fujitsu (formerly Amdahl) GS21 mainframes globally. NEC with ACOS and Hitachi with AP10000-VOS3 still maintain mainframe hardware businesses in the Japanese market.

The amount of vendor investment in mainframe development varies with market share. Fujitsu and Hitachi both continue to use custom S/390-compatible processors, as well as other CPUs (including POWER and Xeon) for lower-end systems. Bull uses a mixture of Itanium and Xeon processors. NEC uses Xeon processors for its low-end ACOS-2 line, but develops the custom NOAH-6 processor for its high-end ACOS-4 series. IBM also develops custom processors in-house, such as the zEC12. Unisys produces code compatible mainframe systems that range from laptops to cabinet-sized mainframes that use homegrown CPUs as well as Xeon processors. Furthermore, there exists a market for software applications to manage the performance of mainframe implementations. In addition to IBM, significant players in this market include BMC, Compuware, and CA Technologies.

Several manufacturers and their successors produced mainframe computers from the late 1950s until the early 21st Century, with gradually decreasing numbers and a gradual transition to simulation on Intel chips rather than proprietary hardware. The US group of manufacturers was first known as "IBM and the Seven Dwarfs": usually Burroughs, UNIVAC, NCR, Control Data, Honeywell, General Electric and RCA, although some lists varied. Later, with the departure of General Electric and RCA, it was referred to as IBM and the BUNCH. IBM's dominance grew out of their 700/7000 series and, later, the development of the 360 series mainframes. The latter architecture has continued to evolve into their current zSeries mainframes which, along with the then Burroughs and Sperry (now Unisys) MCP-based and OS1100 mainframes, are among the few mainframe architectures still extant that can trace their roots to this early period. While IBM's zSeries can still run 24-bit System/360 code, the 64-bit zSeries and System z9 CMOS servers have nothing physically in common with the older systems. Notable manufacturers outside the US were Siemens and Telefunken in Germany, ICL in the United Kingdom, Olivetti in Italy, and Fujitsu, Hitachi, Oki, and NEC in Japan. The Soviet Union and Warsaw Pact countries manufactured close copies of IBM mainframes during the Cold War; the BESM series and Strela are examples of an independently designed Soviet computer.

Shrinking demand and tough competition started a shakeout in the market in the early 1970s—RCA sold out to UNIVAC and GE sold its business to Honeywell; between 1986 and 1990 Honeywell was bought out by Bull; UNIVAC became a division of Sperry, which later merged with Burroughs to form Unisys Corporation in 1986.

In 1984 estimated sales of desktop computers ($11.6 billion) exceeded mainframe computers ($11.4 billion) for the first time. IBM received the vast majority of mainframe revenue. During the 1980s, minicomputer-based systems grew more sophisticated and were able to displace the lower-end of the mainframes. These computers, sometimes called "departmental computers" were typified by the DEC VAX.

In 1991, AT&T Corporation briefly owned NCR. During the same period, companies found that servers based on microcomputer designs could be deployed at a fraction of the acquisition price and offer local users much greater control over their own systems given the IT policies and practices at that time. Terminals used for interacting with mainframe systems were gradually replaced by personal computers. Consequently, demand plummeted and new mainframe installations were restricted mainly to financial services and government. In the early 1990s, there was a rough consensus among industry analysts that the mainframe was a dying market as mainframe platforms were increasingly replaced by personal computer networks. InfoWorld's Stewart Alsop infamously predicted that the last mainframe would be unplugged in 1996; in 1993, he cited Cheryl Currid, a computer industry analyst as saying that the last mainframe "will stop working on December 31, 1999", a reference to the anticipated Year 2000 problem (Y2K).

That trend started to turn around in the late 1990s as corporations found new uses for their existing mainframes and as the price of data networking collapsed in most parts of the world, encouraging trends toward more centralized computing. The growth of e-business also dramatically increased the number of back-end transactions processed by mainframe software as well as the size and throughput of databases. Batch processing, such as billing, became even more important (and larger) with the growth of e-business, and mainframes are particularly adept at large-scale batch computing. Another factor currently increasing mainframe use is the development of the Linux operating system, which arrived on IBM mainframe systems in 1999 and is typically run in scores or up to c. 8,000 virtual machines on a single mainframe. Linux allows users to take advantage of open source software combined with mainframe hardware RAS. Rapid expansion and development in emerging markets, particularly People's Republic of China, is also spurring major mainframe investments to solve exceptionally difficult computing problems, e.g. providing unified, extremely high volume online transaction processing databases for 1 billion consumers across multiple industries (banking, insurance, credit reporting, government services, etc.) In late 2000, IBM introduced 64-bit z/Architecture, acquired numerous software companies such as Cognos and introduced those software products to the mainframe. IBM's quarterly and annual reports in the 2000s usually reported increasing mainframe revenues and capacity shipments. However, IBM's mainframe hardware business has not been immune to the recent overall downturn in the server hardware market or to model cycle effects. For example, in the 4th quarter of 2009, IBM's System z hardware revenues decreased by 27% year over year. But MIPS (millions of instructions per second) shipments increased 4% per year over the past two years. Alsop had himself photographed in 2000, symbolically eating his own words ("death of the mainframe").

In 2012, NASA powered down its last mainframe, an IBM System z9. However, IBM's successor to the z9, the z10, led a New York Times reporter to state four years earlier that "mainframe technology—hardware, software and services—remains a large and lucrative business for I.B.M., and mainframes are still the back-office engines behind the world's financial markets and much of global commerce". , while mainframe technology represented less than 3% of IBM's revenues, it "continue[d] to play an outsized role in Big Blue's results".

In 2015, IBM launched the IBM z13, in June 2017 the IBM z14 and in September 2019 IBM launched the latest version of the product, the IBM z15.

A supercomputer is a computer at the leading edge of data processing capability, with respect to calculation speed. Supercomputers are used for scientific and engineering problems (high-performance computing) which crunch numbers and data, while mainframes focus on transaction processing. The differences are:

Mainframes and supercomputers cannot always be clearly distinguished; up until the early 1990s, many supercomputers were based on a mainframe architecture with supercomputing extensions. An example of such a system is the HITAC S-3800, which was instruction-set compatible with IBM System/370 mainframes, and could run the Hitachi VOS3 operating system (a fork of IBM MVS). The S-3800 therefore can be seen as being both simultaneously a supercomputer and also an IBM-compatible mainframe. 

In 2007, an amalgamation of the different technologies and architectures for supercomputers and mainframes has led to the so-called gameframe.




</doc>
<doc id="20268" url="https://en.wikipedia.org/wiki?curid=20268" title="Microsoft Excel">
Microsoft Excel

Microsoft Excel is a spreadsheet developed by Microsoft for Windows, macOS, Android and iOS. It features calculation, graphing tools, pivot tables, and a macro programming language called Visual Basic for Applications. It has been a very widely applied spreadsheet for these platforms, especially since version 5 in 1993, and it has replaced Lotus 1-2-3 as the industry standard for spreadsheets. Excel forms part of the Microsoft Office suite of software.

Microsoft Excel has the basic features of all spreadsheets, using a grid of "cells" arranged in numbered "rows" and letter-named "columns" to organize data manipulations like arithmetic operations. It has a battery of supplied functions to answer statistical, engineering, and financial needs. In addition, it can display data as line graphs, histograms and charts, and with a very limited three-dimensional graphical display. It allows sectioning of data to view its dependencies on various factors for different perspectives (using "pivot tables" and the "scenario manager"). It has a programming aspect, "Visual Basic for Applications", allowing the user to employ a wide variety of numerical methods, for example, for solving differential equations of mathematical physics, and then reporting the results back to the spreadsheet. It also has a variety of interactive features allowing user interfaces that can completely hide the spreadsheet from the user, so the spreadsheet presents itself as a so-called "application", or "decision support system" (DSS), via a custom-designed user interface, for example, a stock analyzer, or in general, as a design tool that asks the user questions and provides answers and reports. In a more elaborate realization, an Excel application can automatically poll external databases and measuring instruments using an update schedule, analyze the results, make a Word report or PowerPoint slide show, and e-mail these presentations on a regular basis to a list of participants. Excel was not designed to be used as a database.

Microsoft allows for a number of optional command-line switches to control the manner in which Excel starts.

Excel 2016 has 484 functions. Of these, 360 existed prior to Excel 2010. Microsoft classifies these functions in 14 categories. Of the 484 current functions, 386 may be called from VBA as methods of the object "WorksheetFunction" and 44 have the same names as VBA functions.

The Windows version of Excel supports programming through Microsoft's Visual Basic for Applications (VBA), which is a dialect of Visual Basic. Programming with VBA allows spreadsheet manipulation that is awkward or impossible with standard spreadsheet techniques. Programmers may write code directly using the Visual Basic Editor (VBE), which includes a window for writing code, debugging code, and code module organization environment. The user can implement numerical methods as well as automating tasks such as formatting or data organization in VBA and guide the calculation using any desired intermediate results reported back to the spreadsheet.

VBA was removed from Mac Excel 2008, as the developers did not believe that a timely release would allow porting the VBA engine natively to Mac OS X. VBA was restored in the next version, Mac Excel 2011, although the build lacks support for ActiveX objects, impacting some high level developer tools.

A common and easy way to generate VBA code is by using the Macro Recorder. The Macro Recorder records actions of the user and generates VBA code in the form of a macro. These actions can then be repeated automatically by running the macro. The macros can also be linked to different trigger types like keyboard shortcuts, a command button or a graphic. The actions in the macro can be executed from these trigger types or from the generic toolbar options. The VBA code of the macro can also be edited in the VBE. Certain features such as loop functions and screen prompt by their own properties, and some graphical display items, cannot be recorded but must be entered into the VBA module directly by the programmer. Advanced users can employ user prompts to create an interactive program, or react to events such as sheets being loaded or changed.

Macro Recorded code may not be compatible with Excel versions. Some code that is used in Excel 2010 cannot be used in Excel 2003. Making a Macro that changes the cell colors and making changes to other aspects of cells may not be backward compatible.

VBA code interacts with the spreadsheet through the Excel "Object Model", a vocabulary identifying spreadsheet objects, and a set of supplied functions or "methods" that enable reading and writing to the spreadsheet and interaction with its users (for example, through custom toolbars or "command bars" and "message boxes"). User-created VBA subroutines execute these actions and operate like macros generated using the macro recorder, but are more flexible and efficient.

From its first version Excel supported end-user programming of macros (automation of repetitive tasks) and user-defined functions (extension of Excel's built-in function library). In early versions of Excel, these programs were written in a macro language whose statements had formula syntax and resided in the cells of special-purpose macro sheets (stored with file extension .XLM in Windows.) XLM was the default macro language for Excel through Excel 4.0. Beginning with version 5.0 Excel recorded macros in VBA by default but with version 5.0 XLM recording was still allowed as an option. After version 5.0 that option was discontinued. All versions of Excel, including Excel 2010 are capable of running an XLM macro, though Microsoft discourages their use.

Excel supports charts, graphs, or histograms generated from specified groups of cells. The generated graphic component can either be embedded within the current sheet or added as a separate object.

These displays are dynamically updated if the content of cells changes. For example, suppose that the important design requirements are displayed visually; then, in response to a user's change in trial values for parameters, the curves describing the design change shape, and their points of intersection shift, assisting the selection of the best design.

Additional features are available using add-ins. Several are provided with Excel, including:


Excel for the web is a free lightweight version of Microsoft Excel available as part of Office on the web, which also includes web versions of Microsoft Word and Microsoft PowerPoint.

Excel for the web can display most of the features available in the desktop versions of Excel, although it may not be able to insert or edit them. Certain data connections are not accessible on Excel for the web, including with charts that may use these external connections. Excel for the web also cannot display legacy features, such as Excel 4.0 macros or Excel 5.0 dialog sheets. There are also small differences between how some of the Excel functions work.

Versions of Excel up to 7.0 had a limitation in the size of their data sets of 16K (2 = ) rows. Versions 8.0 through 11.0 could handle 64K (2 = ) rows and 256 columns (2 as label 'IV'). Version 12.0 onwards, including the current Version 16.x, can handle over 1M (2 = ) rows, and (2 as label 'XFD') columns.

Microsoft Excel up until 2007 version used a proprietary binary file format called Excel Binary File Format (.XLS) as its primary format. Excel 2007 uses Office Open XML as its primary file format, an XML-based format that followed after a previous XML-based format called "XML Spreadsheet" ("XMLSS"), first introduced in Excel 2002.

Although supporting and encouraging the use of new XML-based formats as replacements, Excel 2007 remained backwards-compatible with the traditional, binary formats. In addition, most versions of Microsoft Excel can read CSV, DBF, SYLK, DIF, and other legacy formats. Support for some older file formats was removed in Excel 2007. The file formats were mainly from DOS-based programs.

OpenOffice.org has created documentation of the Excel format. Two epochs of the format exist: the 97-2003 OLE format, and the older stream format. Since then Microsoft made the Excel binary format specification available to freely download.

The "XML Spreadsheet" format introduced in Excel 2002 is a simple, XML based format missing some more advanced features like storage of VBA macros. Though the intended file extension for this format is ".xml", the program also correctly handles XML files with ".xls" extension. This feature is widely used by third-party applications (e.g. "MySQL Query Browser") to offer "export to Excel" capabilities without implementing binary file format. The following example will be correctly opened by Excel if saved either as "Book1.xml" or "Book1.xls":
<?xml version="1.0"?>
<Workbook xmlns="urn:schemas-microsoft-com:office:spreadsheet"
</Workbook>
Microsoft Excel 2007, along with the other products in the Microsoft Office 2007 suite, introduced new file formats. The first of these (.xlsx) is defined in the Office Open XML (OOXML) specification.

Windows applications such as Microsoft Access and Microsoft Word, as well as Excel can communicate with each other and use each other's capabilities. The most common are Dynamic Data Exchange: although strongly deprecated by Microsoft, this is a common method to send data between applications running on Windows, with official MS publications referring to it as "the protocol from hell". As the name suggests, it allows applications to supply data to others for calculation and display. It is very common in financial markets, being used to connect to important financial data services such as Bloomberg and Reuters.

OLE Object Linking and Embedding allows a Windows application to control another to enable it to format or calculate data. This may take on the form of "embedding" where an application uses another to handle a task that it is more suited to, for example a PowerPoint presentation may be embedded in an Excel spreadsheet or vice versa.

Excel users can access external data sources via Microsoft Office features such as (for example) codice_1 connections built with the Office Data Connection file format. Excel files themselves may be updated using a Microsoft supplied ODBC driver.

Excel can accept data in real-time through several programming interfaces, which allow it to communicate with many data sources such as Bloomberg and Reuters (through addins such as Power Plus Pro).


Alternatively, Microsoft Query provides ODBC-based browsing within Microsoft Excel.

Programmers have produced APIs to open Excel spreadsheets in a variety of applications and environments other than Microsoft Excel. These include opening Excel documents on the web using either ActiveX controls, or plugins like the Adobe Flash Player. The Apache POI opensource project provides Java libraries for reading and writing Excel spreadsheet files. ExcelPackage is another open-source project that provides server-side generation of Microsoft Excel 2007 spreadsheets. PHPExcel is a PHP library that converts Excel5, Excel 2003, and Excel 2007 formats into objects for reading and writing within a web application. Excel Services is a current .NET developer tool that can enhance Excel's capabilities. Excel spreadsheets can be accessed from Python with xlrd and openpyxl. js-xlsx and js-xls can open Excel spreadsheets from JavaScript.

Microsoft Excel protection offers several types of passwords:
All passwords except "password to open a document" can be removed instantly regardless of the Microsoft Excel version used to create the document. These types of passwords are used primarily for shared work on a document. Such password-protected documents are not encrypted, and a data sources from a set password is saved in a document's header. "Password to protect workbook" is an exception – when it is set, a document is encrypted with the standard password “"VelvetSweatshop"”, but since it is known to the public, it actually does not add any extra protection to the document. The only type of password that can prevent a trespasser from gaining access to a document is "password to open a document". The cryptographic strength of this kind of protection depends strongly on the Microsoft Excel version that was used to create the document.

In "Microsoft Excel 95" and earlier versions, the password to open is converted to a 16-bit key that can be instantly cracked. In "Excel 97/2000" the password is converted to a 40-bit key, which can also be cracked very quickly using modern equipment. As regards services that use rainbow tables (e.g. Password-Find), it takes up to several seconds to remove protection. In addition, password-cracking programs can brute-force attack passwords at a rate of hundreds of thousands of passwords a second, which not only lets them decrypt a document but also find the original password.

In "Excel 2003/XP" the encryption is slightly better – a user can choose any encryption algorithm that is available in the system (see Cryptographic Service Provider). Due to the CSP, an "Excel" file can't be decrypted, and thus the "password to open" can't be removed, though the brute-force attack speed remains quite high. Nevertheless, the older "Excel 97/2000" algorithm is set by the default. Therefore, users who do not change the default settings lack reliable protection of their documents.

The situation changed fundamentally in "Excel 2007", where the modern AES algorithm with a key of 128 bits started being used for decryption, and a 50,000-fold use of the hash function SHA1 reduced the speed of brute-force attacks down to hundreds of passwords per second. In "Excel 2010", the strength of the protection by the default was increased two times due to the use of a 100,000-fold SHA1 to convert a password to a key.

Microsoft Excel Viewer was a freeware program for viewing and printing spreadsheet documents created by Excel. The Microsoft Excel Viewer was retired in April 2018 in lieu of Excel Online. Excel Viewer is similar to Microsoft Word Viewer in functionality. (There is not a current version for the Mac.) Excel Viewer is available for Microsoft Windows and Windows CE handheld PCs, such as the NEC MobilePro. It is also possible to open Excel files using certain online tools and services. Online excel viewers do not require users to have Microsoft Excel installed.

In addition to issues with spreadsheets in general, other problems specific to Excel include numeric precision, misleading statistics functions, mod function errors, date limitations and more.

Despite the use of 15-figure precision, Excel can display many more figures (up to thirty) upon user request. But the displayed figures are "not" those actually used in its computations, and so, for example, the difference of two numbers may differ from the difference of their displayed values. Although such departures are usually beyond the 15th decimal, exceptions do occur, especially for very large or very small numbers. Serious errors can occur if decisions are made based upon automated comparisons of numbers (for example, using the Excel "If" function), as equality of two numbers can be unpredictable.

In the figure, the fraction 1/9000 is displayed in Excel. Although this number has a decimal representation that is an infinite string of ones, Excel displays only the leading 15 figures. In the second line, the number one is added to the fraction, and again Excel displays only 15 figures. In the third line, one is subtracted from the sum using Excel. Because the sum in the second line has only eleven 1's after the decimal, the difference when 1 is subtracted from this displayed value is three 0's followed by a string of eleven 1's. However, the difference reported by Excel in the third line is three 0's followed by a string of "thirteen" 1's and two extra erroneous digits. This is because Excel calculates with about half a digit more than it displays.

Excel works with a modified 1985 version of the IEEE 754 specification. Excel's implementation involves conversions between binary and decimal representations, leading to accuracy that is on average better than one would expect from simple fifteen digit precision, but that can be worse. See the main article for details.

Besides accuracy in user computations, the question of accuracy in Excel-provided functions may be raised. Particularly in the arena of statistical functions, Excel has been criticized for sacrificing accuracy for speed of calculation.

As many calculations in Excel are executed using VBA, an additional issue is the accuracy of VBA, which varies with variable type and user-requested precision.

The accuracy and convenience of statistical tools in Excel has been criticized, as mishandling missing data, as returning incorrect values due to inept handling of round-off and large numbers, as only selectively updating calculations on a spreadsheet when some cell values are changed, and as having a limited set of statistical tools. Microsoft has announced some of these issues are addressed in Excel 2010.

Excel has issues with modulo operations. In the case of excessively large results, Excel will return the error warning instead of an answer.

Excel includes February 29, 1900, incorrectly treating 1900 as a leap year, even though e.g. 2100 is correctly treated as a non-leap year. The bug originated from Lotus 1-2-3 (deliberately implemented to save computer memory), and was also purposely implemented in Excel, for the purpose of bug compatibility. This legacy has later been carried over into Office Open XML file format.

Thus a (not necessarily whole) number greater than or equal to 61 interpreted as a date and time are the (real) number of days after December 30, 1899, 0:00, a non-negative number less than 60 is the number of days after December 31, 1899, 0:00, and numbers with whole part 60 represent the fictional day.

Excel supports dates with years in the range 1900-9999, except that December 31, 1899, can be entered as 0 and is displayed as 0-jan-1900.

Converting a fraction of a day into hours, minutes and days by treating it as a moment on the day January 1, 1900, does not work for a negative fraction.

Entering text that happens to be in a form that is interpreted as a date, the text can be unintentionally changed to a standard date format. A similar problem occurs when a text happens to be in the form of a floating-point notation of a number. In these cases the original exact text cannot be recovered from the result.

This issue has caused a well known problem in the analysis of DNA, for example in bioinformatics. As first reported in 2004, genetic scientists found that Excel automatically and incorrectly converts certain gene names into dates. A follow-up study in 2016 found many peer reviewed scientific journal papers had been affected and that "Of the selected journals, the proportion of published articles with Excel files containing gene lists that are affected by gene name errors is 19.6 %." Excel parses the copied and pasted data and sometimes changes them depending on what it thinks they are. For example, MARCH1 (Membrane Associated Ring-CH-type finger 1) gets converted to the date March 1 (1-Mar) and SEPT2 (Septin 2) is converted into September 2 (2-Sep) etc. While some secondary news sources reported this as a fault with Excel, the original authors of the 2016 paper placed the blame with the researchers mis-using Excel.

Apostrophe entered before MARCH1 as in 'MARCH1 prevents Excel convert to date.<br>
Format cell as TEXT before entering MARCH1 also prevents Excel convert to date.

The following functions return incorrect results when passed a string longer than 255 characters:

Microsoft Excel will not open two documents with the same name and instead will display the following error:

The reason is for calculation ambiguity with linked cells. If there is a cell ='[Book1.xlsx]Sheet1'!$G$33, and there are two books named "Book1" open, there is no way to tell which one the user means.

Microsoft originally marketed a spreadsheet program called Multiplan in 1982. Multiplan became very popular on CP/M systems, but on MS-DOS systems it lost popularity to Lotus 1-2-3. Microsoft released the first version of Excel for the Macintosh on September 30, 1985, and the first Windows version was 2.05 (to synchronize with the Macintosh version 2.2) in November 1987. Lotus was slow to bring 1-2-3 to Windows and by the early 1990s, Excel had started to outsell 1-2-3 and helped Microsoft achieve its position as a leading PC software developer. This accomplishment solidified Microsoft as a valid competitor and showed its future of developing GUI software. Microsoft maintained its advantage with regular new releases, every two years or so.

Excel 2.0 is the first version of Excel for the Intel platform. Versions prior to 2.0 were only available on the Apple Macintosh.

The first Windows version was labeled "2" to correspond to the Mac version. This included a run-time version of Windows.

"BYTE" in 1989 listed Excel for Windows as among the "Distinction" winners of the BYTE Awards. The magazine stated that the port of the "extraordinary" Macintosh version "shines", with a user interface as good as or better than the original.

Included toolbars, drawing capabilities, outlining, add-in support, 3D charts, and many more new features.

Introduced auto-fill.

Also, an easter egg in Excel 4.0 reveals a hidden animation of a dancing set of numbers 1 through 3, representing Lotus 1-2-3, which was then crushed by an Excel logo.

With version 5.0, Excel has included Visual Basic for Applications (VBA), a programming language based on Visual Basic which adds the ability to automate tasks in Excel and to provide user-defined functions (UDF) for use in worksheets. VBA is a powerful addition to the application and includes a fully featured integrated development environment (IDE). Macro recording can produce VBA code replicating user actions, thus allowing simple automation of regular tasks. VBA allows the creation of forms and in‑worksheet controls to communicate with the user. The language supports use (but not creation) of ActiveX (COM) DLL's; later versions add support for class modules allowing the use of basic object-oriented programming techniques.

The automation functionality provided by VBA made Excel a target for macro viruses. This caused serious problems until antivirus products began to detect these viruses. Microsoft belatedly took steps to prevent the misuse by adding the ability to disable macros completely, to enable macros when opening a workbook or to trust all macros signed using a trusted certificate.

Versions 5.0 to 9.0 of Excel contain various Easter eggs, including a "Hall of Tortured Souls", although since version 10 Microsoft has taken measures to eliminate such undocumented features from their products.

5.0 was released in a 16-bit x86 version for Windows 3.1 and later in a 32-bit version for NT 3.51 (x86/Alpha/PowerPC)

Released in 1995 with Microsoft Office for Windows 95, this is the first major version after Excel 5.0, as there is no Excel 6.0 with all of the Office applications standardizing on the same major version number.

Internal rewrite to 32-bits. Almost no external changes, but faster and more stable.

Included in Office 97 (for x86 and Alpha). This was a major upgrade that introduced the paper clip office assistant and featured standard VBA used instead of internal Excel Basic. It introduced the now-removed Natural Language labels.

This version of Excel includes a flight simulator as an Easter Egg.

Included in Office 2000. This was a minor upgrade but introduced an upgrade to the clipboard where it can hold multiple objects at once. The Office Assistant, whose frequent unsolicited appearance in Excel 97 had annoyed many users, became less intrusive.

Included in Office XP. Very minor enhancements.

Included in Office 2003. Minor enhancements, most significant being the new Tables.

Included in Office 2007. This release was a major upgrade from the previous version. Similar to other updated Office products, Excel in 2007 used the new Ribbon menu system. This was different from what users were used to, and was met with mixed reactions. One study reported fairly good acceptance by users except highly experienced users and users of word processing applications with a classical WIMP interface, but was less convinced in terms of efficiency and organization. However, an online survey reported that a majority of respondents had a negative opinion of the change, with advanced users being "somewhat more negative" than intermediate users, and users reporting a self-estimated reduction in productivity.

Added functionality included the SmartArt set of editable business diagrams. Also added was an improved management of named variables through the "Name Manager", and much-improved flexibility in formatting graphs, which allow ("x, y") coordinate labeling and lines of arbitrary weight. Several improvements to pivot tables were introduced.

Also like other office products, the Office Open XML file formats were introduced, including ".xlsm" for a workbook with macros and ".xlsx" for a workbook without macros.

Specifically, many of the size limitations of previous versions were greatly increased. To illustrate, the number of rows was now 1,048,576 (2) and columns was 16,384 (2; the far-right column is XFD). This changes what is a valid "A1" reference versus a named range. This version made more extensive use of multiple cores for the calculation of spreadsheets; however, VBA macros are not handled in parallel and XLL add‑ins were only executed in parallel if they were thread-safe and this was indicated at registration.

Included in Office 2010, this is the next major version after v12.0, as version number 13 was skipped.

Minor enhancements and 64-bit support, including the following:

Included in Office 2013, along with a lot of new tools included in this release:

Included in Office 2016, along with a lot of new tools included in this release:

Microsoft no longer releases Office or Excel in discrete versions. Instead, features are introduced automatically over time using Windows Update. The version number remains 16.0. Thereafter only the approximate dates when features appear can now be given.




Excel Mobile is a spreadsheet program that can edit XLSX files. It can edit and format text in cells, calculate formulas, search within the spreadsheet, sort rows and columns, freeze panes, filter the columns, add comments, and create charts. It can't add columns or rows except at the edge of the document, rearrange columns or rows, delete rows or columns, or add spreadsheet tabs. The 2007 version has the ability to use a full-screen mode to deal with limited screen resolution, as well as split panes to view different parts of a worksheet at one time. Protection settings, zoom settings, autofilter settings, certain chart formatting, hidden sheets, and other features are not supported on Excel Mobile, and will be modified upon opening and saving a workbook. In 2015, Excel Mobile became available for Windows 10 and Windows 10 Mobile on Windows Store.

Excel offers many user interface tweaks over the earliest electronic spreadsheets; however, the essence remains the same as in the original spreadsheet software, VisiCalc: the program displays cells organized in rows and columns, and each cell may contain data or a formula, with relative or absolute references to other cells.

Excel 2.0 for Windows, which was modeled after its Mac GUI-based counterpart, indirectly expanded the installed base of the then-nascent Windows environment. Excel 2.0 was released a month before Windows 2.0, and the installed base of Windows was so low at that point in 1987 that Microsoft had to bundle a runtime version of Windows 1.0 with Excel 2.0. Unlike Microsoft Word, there never was a DOS version of Excel.

Excel became the first spreadsheet to allow the user to define the appearance of spreadsheets (fonts, character attributes, and cell appearance). It also introduced intelligent cell recomputation, where only cells dependent on the cell being modified are updated (previous spreadsheet programs recomputed everything all the time or waited for a specific user command). Excel introduced auto-fill, the ability to drag and expand the selection box to automatically copy a cell or row contents to adjacent cells or rows, adjusting the copies intelligently by automatically incrementing cell references or contents. Excel also introduced extensive graphing capabilities.

Because Excel is widely used, it has been attacked by hackers. While Excel is not directly exposed to the Internet, if an attacker can get a victim to open a file in Excel, and there is an appropriate security bug in Excel, then the attacker can gain control of the victim's computer. UK's GCHQ has a tool named TORNADO ALLEY with this purpose.





</doc>
<doc id="20269" url="https://en.wikipedia.org/wiki?curid=20269" title="Michael Hutchence">
Michael Hutchence

Michael Kelland John Hutchence (22 January 1960 – 22 November 1997) was an Australian musician, singer-songwriter and actor. Hutchence co-founded the rock band INXS, which sold over 60 million records worldwide and was inducted into the ARIA Hall of Fame in 2001. He was the lead singer and lyricist of INXS from 1977 until his death.

Hutchence was a member of the short-lived pop rock group Max Q. He also recorded some solo material and acted in feature films, including "Dogs in Space" (1986), "Frankenstein Unbound" (1990), and "Limp" (1997).

Hutchence had a string of love affairs with prominent actresses, models and singers, and his private life was often reported in the Australian and international press. In July 1996, Hutchence and English television presenter Paula Yates had a daughter, Heavenly Hiraani Tiger Lily.

On the morning of 22 November 1997, Hutchence was found dead in his hotel room in Sydney. His death was reported by the New South Wales Coroner to be the result of suicide by hanging.

Michael Kelland John Hutchence was born on 22 January 1960, to Sydney businessman Kelland ("Kell") Frank Hutchence (1924-2002) and make-up artist Patricia Glassop (née Kennedy, 1926-2010). Kelland's parents were sea captain Frank Hutchence and Mabs from England who settled in Sydney in 1922. Michael joined elder half-sister Tina; both siblings were of Irish ancestry from their mother's side, as Patricia's father was from County Cork in Ireland. 

Following Kell's business interests, the Hutchence family moved to Brisbane (where younger brother Rhett was born) and later to Hong Kong. During the early years in Hong Kong, both boys attended Beacon Hill School in Kowloon Tong. While in Hong Kong, Michael showed promise as a swimmer before breaking his arm badly. He then began to show interest in poetry and performed his first song in a local toy store commercial. Michael attended King George V School during his early teens.

The family returned to Sydney in 1972, buying a house in Belrose near the Northern Beaches. Hutchence attended Davidson High School, where he met and befriended Andrew Farriss. Around this time, Hutchence and Farriss spent a lot of time jamming in the garage with Andrew's brothers. Farriss then convinced Hutchence to join his band, Doctor Dolphin, alongside classmates Kent Kerny and Neil Sanders. Bass guitarist Garry Beers and drummer Geoff Kennelly from nearby Forest High School filled out the line-up. Hutchence's parents separated when he was 15; for a short time in 1976, he lived with his mother and half-sister Tina in California. Hutchence later returned to Sydney with his mother.

In 1977, a new band, The Farriss Brothers, was formed with Tim Farriss on lead guitar, his younger brother Andrew as keyboardist, and youngest brother Jon on drums. Andrew brought Hutchence on board as a vocalist and Beers on bass guitar, and Tim brought in his former bandmate Kirk Pengilly to play guitar and saxophone. The band made their debut on 16 August 1977 at Whale Beach, 40 km (25 mi) north of Sydney.

Hutchence, the Farriss brothers, Kerny, Sanders, Beers and Kennelly briefly performed as The Vegetables, singing "We Are the Vegetables". Ten months later, they returned to Sydney and recorded a set of demos. The Farriss Brothers regularly supported hard rockers Midnight Oil on the pub rock circuit, and were renamed as INXS in 1979. Their first performance under the new name was on 1 September at the Oceanview Hotel in Toukley. In May 1980, the group released their first single, "Simple Simon"/"We Are the Vegetables" which was followed by the debut album "INXS" in October. Their first Top 40 Australian hit on the Kent Music Report Singles Chart, "Just Keep Walking", was released in September 1980.

Hutchence became the main spokesperson for the band. He co-wrote almost all of INXS's songs with Andrew Farriss.

According to Hutchence, most of the songs on the band's second album, "Underneath the Colours", were written within a fairly short space of time: "Most bands shudder at the prospect of having 20 years to write their first album and four days to write their second. For us, though, it was good. It left less room for us to go off on all sorts of tangents". Soon after recording sessions for "Underneath the Colours" – produced by Richard Clapton – had finished, band members started work on outside projects. Hutchence recorded "Speed Kills", written by Don Walker of hard rockers Cold Chisel, for the "Freedom" (1982) film soundtrack, directed by Scott Hicks. It was Hutchence's first solo single and was released by WEA in early 1982.

In March 1985, after Hutchence and INXS recorded their album "The Swing" (1984), WEA released the Australian version of "Dekadance", as a limited edition cassette only EP of six tracks including remixes from the album. The cassette also included a cover version of Nancy Sinatra and Lee Hazlewood's hit "Jackson", which Hutchence sang as a duet with Jenny Morris, a backing singer for "The Swing" sessions. The EP reached No 2 on the Kent Music Report Albums Chart. Hutchence provided vocals for new wave band Beargarden's 1985 single release.

On 19 May, INXS won seven awards at the 1984 "Countdown" Music and Video Awards ceremony, including 'Best Songwriter' for Hutchence and Andrew, and 'Most Popular Male' for Hutchence. They performed "Burn for You", dressed in Akubras (a brand of hats) and Drizabones (a brand of outdoor coats/oilskin jackets) followed by Hutchence and Morris singing "Jackson" to close.

In 1986, Hutchence played Sam, the lead male role, in the Australian film "Dogs in Space", directed by long-time INXS music video collaborator Richard Lowenstein. Sam's girlfriend, Anna, was portrayed by Saskia Post as a "fragile peroxide blonde in op-shop clothes". Hutchence provided four songs on the film's soundtrack. Also working on the film and its soundtrack, as music director, was Ollie Olsen (ex-Whirlywirld).

Late in 1986, before commencing work on a new INXS album and while supposedly taking an eight-month break, the band's management decided to stage the Australian Made tour as a series of major outdoor concerts across the country. The roster featured INXS, Jimmy Barnes (Cold Chisel), Models, Divinyls, Mental as Anything, The Triffids and I'm Talking. To promote the tour, Hutchence and Barnes shared vocals on The Easybeats cover "Good Times" and "Laying Down the Law", which Barnes cowrote with Beers, Andrew Farriss, Jon Farriss, Hutchence and Pengilly. "Good Times" was used as the theme for the concert series of 1986–1987. It peaked at No. 2 on the Australian charts, and months later was featured in the Joel Schumacher film "The Lost Boys" and its soundtrack, allowing it to peak at No. 47 in the U.S. on 1 August 1987. Divinyls' lead singer Chrissie Amphlett enjoyed the tour and reconnected with Hutchence, stating that "[he] was a sweet man, who said in one interview that he wanted me to have his baby."

In 1987, Hutchence provided vocals for Richard Clapton's album "Glory Road", which was produced by Jon Farriss.

INXS released "Kick" in October 1987, and the album provided the band with worldwide popularity. "Kick" peaked at No. 1 in Australia, No. 3 on the US "Billboard" 200, No. 9 in UK, and No. 15 in Austria. The band's most successful studio album, "Kick" has been certified six times platinum by the RIAA and spawned four US top 10 singles ("New Sensation", "Never Tear Us Apart", "Devil Inside" and "Need You Tonight", the last of which reached the top of the US "Billboard" singles charts). According to "1001 Songs: The Great Songs of All Time and the Artists, Stories and Secrets Behind Them", the single "Need You Tonight" is not lyrically complex; it is Hutchence's performance where "he sings in kittenish whisper, gently drawing back with the incredible lust of a tiger hunting in the night" that makes the song "as sexy and funky as any white rock group has ever been". In September 1988, the band swept the MTV Video Music Awards with the video for "Need You Tonight/Mediate" winning in five categories.

In 1989, Hutchence collaborated further with Olsen for the Max Q project, and was joined by members of Olsen's previous groups including Whirlywirld, No and Orchestra of Skin and Bone. They released a self-titled album and three singles, "Way of the World", "Sometimes" and "Monday Night by Satellite". Max Q disbanded in 1990. "Max Q" showed Hutchence exploring the darker side of his music and, with Olsen, he created "one of the most innovative dance music albums of the decade". Hutchence wrote most of the music and provided "an extraordinary performance ... it was one of the most significant statements Hutchence was to make". In 1990, Hutchence portrayed nineteenth-century Romantic poet Percy Shelley in Roger Corman's film version of "Frankenstein Unbound", which was based on a science fiction time travel story of the same name written by Brian Aldiss.

In 1990, INXS released "X", which spawned more international hits such as "Suicide Blonde" and "Disappear" (both Top 10 in the US). "Suicide Blonde" peaked at No. 2 in Australia and No. 11 in the UK. Hutchence, with Andrew Farriss, wrote the song after Hutchence's then-girlfriend, Kylie Minogue, used the phrase "suicide blonde" to describe her look during her 1989 film, "The Delinquents"; the film depicted Minogue in a platinum blonde wig. Hutchence won the 'Best International Artist' at the 1991 BRIT Awards with INXS winning the related group award. Hutchence provided vocals for pub rockers Noiseworks' album, "Love Versus Money" (1991).
"Welcome to Wherever You Are" was released by INXS in August 1992. It received good critical reviews and went to No. 1 in the UK.

Hutchence and INXS faced reduced commercial success with "Full Moon, Dirty Hearts", especially in the U.S. The band took time off to rest and be with their families, while Hutchence remained in the public eye through his romances. He commenced work on a self-titled solo album in the mid-1990s.

After a period of inactivity and releases that received lukewarm reviews, INXS recorded the band's 10th official album, "Elegantly Wasted", in 1996.

Hutchence was a baritone. In 2013, News.com.au ranked Hutchence fourth in a list of the 15 greatest Australian singers of all time. Billboard described Hutchence as "charismatic," with a "seductive purr and [a] lithe, magnetic stage presence." Paul Donoughue of ABC.net.au wrote that Hutchence had "a phenomenal voice — moody, sexual, and dynamic, able to shift effortlessly from fragile to cocksure." Reviewing an INXS concert, Dave Simpson of "The Guardian" wrote, "Watching Hutchence, hair flailing, crotch thrusting, a mischievous smile forever creeping across his leathery face, I realised that here was a man born to be onstage, living and loving every minute, an explosion of sexual energy". Hutchence biographer Toby Creswell asserted that "Hutchence was, without question, one of the truly great frontmen — he expressed the music in a dynamic way that few others could."

According to "People", Hutchence's "public brawls and onetime open drug use led London tabloids to dub him the 'wild man of rock.'" He was romantically linked to Kylie Minogue, Belinda Carlisle, Helena Christensen, and Kym Wilson.

In August 1992, Helena Christensen and Hutchence were walking late at night on a street in Copenhagen after drinking heavily when he refused to move for a taxi. The taxi driver then assaulted him, causing him to fall backwards and hit his head on the roadway. Hutchence suffered a fractured skull in the altercation. Hutchence did not immediately seek medical assistance for the injury, instead waiting several days before seeing a doctor. As a result, his fractured skull left him with an almost complete loss of the sense of smell and significant loss of taste. This injury led to periods of depression and increased levels of aggression; he had not fully recovered after two weeks in a Copenhagen hospital. According to INXS bandmate Beers, Hutchence pulled a knife and threatened to kill him during the 1993 recording of "Full Moon, Dirty Hearts" on the isle of Capri. Beers said: "Over those six weeks, Michael threatened or physically confronted nearly every member of the band."

In the mid-1990s, Hutchence became romantically involved with Paula Yates. He had met her in 1985, during an interview for her program, "The Tube". Yates interviewed him again in 1994 for her "Big Breakfast" show, and their affair was soon uncovered by the British press. At the time, Yates was married to The Boomtown Rats' lead singer and Live Aid organiser Bob Geldof. Media scrutiny was intense, and Hutchence assaulted a photographer who had followed them. Yates' separation from Geldof in February 1995 sparked a public and at times bitter custody battle over their daughters. Yates and Geldof divorced in May 1996. On 22 July 1996, Yates gave birth to Hutchence's daughter, Heavenly Hiraani Tiger Lily Hutchence.

In September 1996, Yates and Hutchence made headlines when they were arrested for suspicion of drug possession after the family nanny reportedly found a small amount of opium in a shoebox underneath their bed. The case was later dropped due to lack of evidence.

Hutchence and INXS went on a world tour to support the April 1997 release of "Elegantly Wasted". The final 20th anniversary tour was to occur in Australia in November and December. During the tour, Paula Yates planned to visit Hutchence with their daughter and Yates's three children, but Bob Geldof had taken legal action to prevent the visit.

On the morning of 22 November 1997, Hutchence, aged 37, was found dead in Room 524 at the Ritz-Carlton hotel in Double Bay, Sydney.
Actress Kym Wilson was the last person to see Hutchence alive, after partying with him in his hotel room prior to his death.
Geldof and Yates each gave police statements on the phone calls they exchanged with Hutchence on the morning of his death; however, they did not volunteer their phone records. Yates's statement on 26 November indicated that she had informed Hutchence of the Geldof girls' custody hearing being adjourned until 17 December, which meant that Yates would not be able to bring Tiger and the Geldof girls to Australia for a visit as previously intended. According to Yates, Hutchence "was frightened and couldn't stand a minute more without his baby... [he] was terribly upset and he said, 'I don't know how I'll live without seeing Tiger'". Yates indicated that Hutchence said he was going to phone Geldof "to let the girls come to Australia". 

Geldof's police statements and evidence to the coroner indicated that Geldof did receive a call from Hutchence, who was "hectoring and abusive and threatening" during their phone conversation. The occupant in the room next to Hutchence's heard a loud male voice and swearing at about 5 am; the coroner was satisfied that this was Hutchence arguing with Geldof.

At 9:54 am on 22 November, Hutchence spoke with a former girlfriend, Michèle Bennett; according to Bennett, Hutchence was crying, sounded upset, and told her he needed to see her. Bennett arrived at his hotel room door at about 10:40 am, but there was no response. Hutchence's body was discovered by a hotel maid at 11:50 am. Police reported that Hutchence was found "in a kneeling position facing the door. He had used his snakeskin belt to tie a knot on the automatic door closure at the top of the door, and had strained his head forward into the loop so hard that the buckle had broken."

On 6 February 1998, after an autopsy and coronial inquest, New South Wales State Coroner, Derrick Hand, presented his report. The report ruled that Hutchence's death was suicide while depressed and under the influence of alcohol and other drugs. "An analysis report of Hutchence's blood [indicated] the presence of alcohol, cocaine, Prozac and prescription drugs." In producing his coroner's report, Hand had specifically considered the suggestions of accidental death (coupled with the fact that Hutchence left no suicide note), but had discounted them based on substantial evidence presented to the contrary. In a 1999 interview on "60 Minutes" (and in a documentary film on Channel 4), Yates claimed that Hutchence's death might have resulted from autoerotic asphyxiation; this claim contradicted her previous statements to police investigators and the coroner.

On 27 November 1997, Hutchence's funeral was held at St Andrew's Cathedral, Sydney. His casket was carried out of the cathedral by members of INXS and by his younger brother, Rhett; "Never Tear Us Apart" was played in the background. Nick Cave, a friend of Hutchence, performed his 1997 song "Into My Arms" during the funeral and requested that television cameras be switched off. Rhett claimed in his 2004 book, "Total XS", that on the previous day at the funeral parlour, Yates had put a gram of heroin into Hutchence's pocket.

Following Hutchence's death, INXS continued recording and performing until 2012. According to the Recording Industry Association of America (RIAA), INXS has sold 30 million units in the United States alone, making them the highest-selling Australian music act in the United States behind AC/DC. INXS has sold over 60 million records worldwide. INXS was inducted into the ARIA Hall of Fame in 2001.

Hutchence's solo album, "Michael Hutchence", was released in October 1999. He had started on the album in 1995, recording songs in between INXS sessions; he had last worked on it three days prior to his death. The last song he recorded was "Possibilities". The album includes "Slide Away", a duet with U2's Bono; Bono's vocals were recorded after Hutchence's death.

The 1999 movie "Limp" includes a cameo by Hutchence.

On 18 June 2000, Patricia Glassop and Tina Schorr released their book, "Just a Man: The Real Michael Hutchence", which has been described as "an odd biography ... [that] combines the basic facts of Hutchence's early life ... with an almost too-intimate view of the authors' feelings".

Paula Yates died on 17 September 2000 of an accidental heroin overdose; she was discovered in the presence of then four year old Tiger, her daughter by Hutchence. Soon after Yates's death, Geldof assumed foster custody of Tiger so that she could be brought up with her three older half-sisters, Fifi, Peaches and Pixie. In 2007, Tiger was adopted by Bob Geldof, the father of her half-sisters. As of 2019, Tiger's legal name is Heavenly Hiraani Tiger Lily Hutchence Geldof. 

On 12 December 2002, Hutchence's father, Kelland, died of cancer in Sydney. Kelland had helped create and maintain a memorial website for his son.

On 20 August 2005, Melbourne's "The Age" reported on the disposition of Hutchence's estate and assets, estimated at between $10 to $20 million but containing virtually nothing. The remainder of his estate had reportedly been sold off or swallowed in legal fees.

In July 2009, Hutchence's mother, Patricia Glassop, protested that Geldof had prevented access to her granddaughter for three years. Glassop died on 21 September 2010.

A documentary about Hutchence entitled "Michael Hutchence: The Last Rockstar" aired in 2017. In 2019, "Mystify: Michael Hutchence"—another documentary about Hutchence's life—was released.





General

Specific



</doc>
<doc id="20270" url="https://en.wikipedia.org/wiki?curid=20270" title="Motorola 68000">
Motorola 68000

The Motorola 68000 ("'sixty-eight-thousand'"; also called the "Texas Cockroach", the m68k or Motorola 68k, ""sixty-eight-kay"") is a 16/32-bit CISC microprocessor, introduced in 1979 by Motorola Semiconductor Products Sector.

The design implements a 32-bit instruction set, with 32-bit registers and a 32-bit internal data bus. The address bus is 24-bits and does not use memory segmentation, which made it popular with programmers. Internally, it uses a 16-bit data ALU and two additional 16-bit ALUs used mostly for addresses, and has a 16-bit external data bus. For this reason, Motorola referred to it as a 16/32-bit processor.

As one of the first widely available processors with a 32-bit instruction set, and running at relatively high speeds for the era, the 68k was a popular design through the 1980s. It was widely used in a new generation of personal computers with graphical user interfaces, including the Apple Macintosh, Commodore Amiga, Atari ST and many others. It competed primarily against the Intel 8088, found in the IBM PC, which it easily outperformed. The 68k and 8088 pushed other designs, like the Zilog Z8000 and , into niche markets, and made Motorola a major player in the CPU space.

The 68k was soon expanded with additional family members, implementing full 32-bit ALUs as part of the growing Motorola 68000 series. The original 68k is generally software forward-compatible with the rest of the line despite being limited to a 16-bit wide external bus. After 40 years in production, the 68000 architecture is still in use.

Motorola's first widely-produced CPU was the Motorola 6800. Although a capable design, it was eclipsed by more powerful designs, such as the Zilog Z80, and less powerful but faster designs, such as the MOS 6502. As the sales prospects of the 6800 dimmed, Motorola began a totally new design to replace it. This became the Motorola Advanced Computer System on Silicon project, or MACSS, begun in 1976.

The MACSS aimed to develop an entirely new architecture without backward compatibility with the 6800. It ultimately does retain a bus protocol compatibility mode for existing 6800 peripheral devices, and a version with an 8-bit data bus was produced. However, the designers mainly focused on the future, or forward compatibility, which gives the 68000 design a head start against later 32-bit instruction set architectures. For instance, the CPU registers are 32 bits wide, though few self-contained structures in the processor itself operate on 32 bits at a time. The MACSS team drew heavily on the influence of minicomputer processor design, such as the PDP-11 and VAX systems, which are similarly microcode-based.

In the mid 1970s, the 8-bit microprocessor manufacturers raced to introduce the 16-bit generation. National Semiconductor had been first with its IMP-16 and PACE processors in 1973–1975, but these have issues with speed. Intel had worked on their advanced 16/32-bit Intel iAPX 432 (alias 8800) since 1975 and their Intel 8086 since 1976 (it was introduced in 1978 but became widespread in the form of the almost identical 8088 in the IBM PC a few years later). Arriving late to the 16-bit arena affords the new processor more transistors (roughly 40,000 active versus 20,000 active in the 8086), 32-bit macroinstructions, and acclaimed general ease of use.

The original MC68000 was fabricated using an HMOS process with a 3.5 µm feature size. Formally introduced in September 1979, initial samples were released in February 1980, with production chips available over the counter in November. Initial speed grades are 4, 6, and 8 MHz. 10 MHz chips became available during 1981, and 12.5 MHz chips by June 1982. The 16.67 MHz "12F" version of the MC68000, the fastest version of the original HMOS chip, was not produced until the late 1980s. 

IBM considered the 68000 for the IBM PC but chose the Intel 8088 because the 68000 was not ready; Walden C. Rhines wrote that thus "Motorola, with its superior technology, lost the single most important design contest of the last 50 years". The 68k instruction set is particularly well suited to implement Unix, and the 68000 and its successors became the dominant CPUs for Unix-based workstations including Sun workstations and Apollo/Domain workstations. The 68000 also is used for mass-market computers such as the Apple Lisa, Macintosh, Amiga, and Atari ST. The 68000 is used in Microsoft Xenix systems, as well as an early NetWare Unix-based Server. The 68000 is used in the first generation of desktop laser printers, including the original Apple Inc. LaserWriter and the HP LaserJet.

In 1982, the 68000 received a minor update to its ISA to support virtual memory and to conform to the Popek and Goldberg virtualization requirements. The updated chip is called the 68010. It also adds a new "loop mode" which speeds up small loops, and increases overall performance by about 10% at the same clock speeds. A further extended version, which exposes 31 bits of the address bus, was also produced in small quantities as the 68012.

To support lower-cost systems and control applications with smaller memory sizes, Motorola introduced the 8-bit compatible MC68008, also in 1982. This is a 68000 with an 8-bit data bus and a smaller (20-bit) address bus. After 1982, Motorola devoted more attention to the 68020 and 88000 projects.

Several other companies were second-source manufacturers of the HMOS 68000. These included Hitachi (HD68000), who shrank the feature size to 2.7 µm for their 12.5 MHz version, Mostek (MK68000), Rockwell (R68000), Signetics (SCN68000), Thomson/SGS-Thomson (originally EF68000 and later TS68000), and Toshiba (TMP68000). Toshiba was also a second-source maker of the CMOS 68HC000 (TMP68HC000).

Encrypted variants of the 68000, being the Hitachi FD1089 and FD1094, store decryption keys for opcodes and opcode data in battery-backed memory and were used in certain Sega arcade systems including System 16 to prevent piracy and illegal bootleg games.

The 68HC000, the first CMOS version of the 68000, was designed by Hitachi and jointly introduced in 1985. Motorola's version was called the MC68HC000, while Hitachi's was the HD68HC000. The 68HC000 was eventually offered at speeds of 8–20 MHz. Except for using CMOS circuitry, it behaved identically to the HMOS MC68000, but the change to CMOS greatly reduced its power consumption. The original HMOS MC68000 consumed around 1.35 watts at an ambient temperature of 25 °C, regardless of clock speed, while the MC68HC000 consumed only 0.13 watts at 8 MHz and 0.38 watts at 20 MHz. (Unlike CMOS circuits, HMOS still draws power when idle, so power consumption varies little with clock rate.) Apple selected the 68HC000 for use in the Macintosh Portable.

Motorola replaced the MC68008 with the MC68HC001 in 1990. This chip resembled the 68HC000 in most respects, but its data bus could operate in either 16-bit or 8-bit mode, depending on the value of an input pin at reset. Thus, like the 68008, it could be used in systems with cheaper 8-bit memories.

The later evolution of the 68000 focused on more modern embedded control applications and on-chip peripherals. The 68EC000 chip and SCM68000 core removed the M6800 peripheral bus, and excluded the MOVE from SR instruction from user mode programs, making the 68EC000 and 68SEC000 the only 68000 CPUs not 100% object code compatible with previous 68000 CPUs when run in User Mode. When run in Supervisor Mode, there was no difference. In 1996, Motorola updated the standalone core with fully static circuitry, drawing only 2 µW in low-power mode, calling it the MC68SEC000.

Motorola ceased production of the HMOS MC68000 and MC68008 in 1996, but its spin-off company Freescale Semiconductor was still producing the MC68HC000, MC68HC001, MC68EC000, and MC68SEC000, as well as the MC68302 and MC68306 microcontrollers and later versions of the DragonBall family. The 68000's architectural descendants, the 680x0, CPU32, and Coldfire families, were also still in production. More recently, with the Sendai fab closure, all 68HC000, 68020, 68030, and 68882 parts have been discontinued, leaving only the 68SEC000 in production.

After being succeeded by "true" 32-bit microprocessors, the 68000 was used as the core of many microcontrollers. In 1989, Motorola introduced the MC68302 communications processor.

At its introduction, the 68000 was first used in high-priced systems, including multiuser microcomputers like the WICAT 150, early Alpha Microsystems computers, Sage II / IV, Tandy 6000 / TRS-80 Model 16, and ; single-user workstations such as Hewlett-Packard's HP 9000 Series 200 systems, the first Apollo/Domain systems, Sun Microsystems' Sun-1, and the Corvus Concept; and graphics terminals like Digital Equipment Corporation's VAXstation 100 and Silicon Graphics' IRIS 1000 and 1200. Unix systems rapidly moved to the more capable later generations of the 68k line, which remained popular in that market throughout the 1980s.

By the mid-1980s, falling production cost made the 68000 viable for use in personal and home computers, starting with the Apple Lisa and Macintosh, and followed by the Commodore Amiga, Atari ST, and Sharp X68000. On the other hand, the Sinclair QL microcomputer was the most commercially important utilisation of the 68008, along with its derivatives, such as the ICL One Per Desk business terminal. Helix Systems (in Missouri, United States) designed an extension to the SWTPC SS-50 bus, the SS-64, and produced systems built around the 68008 processor.

While the adoption of RISC and x86 displaced the 68000 series as desktop/workstation CPU, the processor found substantial use in embedded applications. By the early 1980s, quantities of 68000 CPUs could be purchased for less than 30 USD per part.

Video game manufacturers used the 68000 as the backbone of many arcade games and home game consoles: Atari's "Food Fight", from 1982, was one of the first 68000-based arcade games. Others included Sega's System 16, Capcom's CP System and CPS-2, and SNK's Neo Geo. By the late 1980s, the 68000 was inexpensive enough to power home game consoles, such as Sega's Mega Drive/Genesis console and also the Sega CD attachment for it (A Sega CD system has three CPUs, two of them 68000s). The 1993 multi-processor Atari Jaguar console used a 68000 as a support chip, although some developers used it as the primary processor due to familiarity. The 1994 multi-processor Sega Saturn console used the 68000 as a sound co-processor (much as the Mega Drive/Genesis uses the Z80 as a co-processor for sound and/or other purposes).

Certain arcade games (such as "Steel Gunner" and others based on Namco System 2) use a dual 68000 CPU configuration, and systems with a triple 68000 CPU configuration also exist (such as "Galaxy Force" and others based on the Sega Y Board), along with a quad 68000 CPU configuration, which has been used by Jaleco (one 68000 for sound has a lower clock rate compared to the other 68000 CPUs) for games such as "Big Run" and "Cisco Heat"; a fifth 68000 (at a different clock rate compared to the other 68000 CPUs) was additionally used in the Jaleco arcade game "Wild Pilot" for I/O processing.

The 68000 also saw great success as an embedded controller. As early as 1981, laser printers such as the Imagen Imprint-10 were controlled by external boards equipped with the 68000. The first HP LaserJet—introduced in 1984—came with a built-in 8 MHz 68000. Other printer manufacturers adopted the 68000, including Apple with its introduction of the LaserWriter in 1985, the first PostScript laser printer. The 68000 continued to be widely used in printers throughout the rest of the 1980s, persisting well into the 1990s in low-end printers.

The 68000 also saw success in the field of industrial control systems. Among the systems benefited from having a 68000 or derivative as their microprocessor were families of programmable logic controllers (PLCs) manufactured by Allen-Bradley, Texas Instruments and subsequently, following the acquisition of that division of TI, by Siemens. Users of such systems do not accept product obsolescence at the same rate as domestic users, and it is entirely likely that despite having been installed over 20 years ago, many 68000-based controllers will continue in reliable service well into the 21st century.

In a number of digital oscilloscopes from the 80s, the 68000 has been used as a waveform display processor; some models including the LeCroy 9400/9400A also use the 68000 as a waveform math processor (including addition, subtraction, multiplication, and division of two waveforms/references/waveform memories), and some digital oscilloscopes using the 68000 (including the 9400/9400A) can also perform fast Fourier transform functions on a waveform.

The 683XX microcontrollers, based on the 68000 architecture, are used in networking and telecom equipment, television set-top boxes, laboratory and medical instruments, and even handheld calculators. The MC68302 and its derivatives have been used in many telecom products from Cisco, 3com, Ascend, Marconi, Cyclades and others. Past models of the Palm PDAs and the Handspring Visor used the DragonBall, a derivative of the 68000. AlphaSmart uses the DragonBall family in later versions of its portable word processors. Texas Instruments uses the 68000 in its high-end graphing calculators, the TI-89 and TI-92 series and Voyage 200. Early versions of these used a specialized microcontroller with a static 68EC000 core; later versions use a standard MC68SEC000 processor.

A modified version of the 68000 formed the basis of the IBM XT/370 hardware emulator of the System 370 processor.

The 68000 has a 24-bit external address bus and two byte-select signals "replaced" A0. These 24 lines can therefore address 16 MB of physical memory with byte resolution. Address storage and computation uses 32 bits internally; however, the 8 high-order address bits are ignored due to the physical lack of device pins. This allows it to run software written for a logically flat 32-bit address space, while accessing only a 24-bit physical address space. Motorola's intent with the internal 32-bit address space was forward compatibility, making it feasible to write 68000 software that would take full advantage of later 32-bit implementations of the 68000 instruction set.

However, this did not prevent programmers from writing forward incompatible software. "24-bit" software that discarded the upper address byte, or used it for purposes other than addressing, could fail on 32-bit 68000 implementations. For example, early (pre-7.0) versions of Apple's Mac OS used the high byte of memory-block master pointers to hold flags such as "locked" and "purgeable". Later versions of the OS moved the flags to a nearby location, and Apple began shipping computers which had "32-bit clean" ROMs beginning with the release of the 1989 Mac IIci.

The 68000 family stores multi-byte integers in memory in big-endian order.

The CPU has eight 32-bit general-purpose data registers (D0-D7), and eight address registers (A0-A7). The last address register is the stack pointer, and assemblers accept the label SP as equivalent to A7. This was a good number of registers at the time in many ways. It was small enough to allow the 68000 to respond quickly to interrupts (even in the worst case where all 8 data registers D0–D7 and 7 address registers A0–A6 needed to be saved, 15 registers in total), and yet large enough to make most calculations fast, because they could be done entirely within the processor without keeping any partial results in memory. (Note that an exception routine in supervisor mode can also save the user stack pointer A7, which would total 8 address registers. However, the dual stack pointer (A7 and supervisor-mode A7') design of the 68000 makes this normally unnecessary, except when a task switch is performed in a multitasking system.)

Having two types of registers was mildly annoying at times, but not hard to use in practice. Reportedly, it allowed the CPU designers to achieve a higher degree of parallelism, by using an auxiliary execution unit for the address registers.

The 68000 has a 16-bit status register. The upper 8 bits is the system byte, and modification of it is privileged. The lower 8 bits is the user byte, also known as the condition code register (CCR), and modification of it is not privileged. The 68000 comparison, arithmetic, and logic operations modify condition codes to record their results for use by later conditional jumps. The condition code bits are "zero" (Z), "carry" (C), "overflow" (V), "extend" (X), and "negative" (N). The "extend" (X) flag deserves special mention, because it is separate from the carry flag. This permits the extra bit from arithmetic, logic, and shift operations to be separated from the carry for flow-of-control and linkage.

The designers attempted to make the assembly language orthogonal. That is, instructions are divided into operations and address modes, and almost all address modes are available for almost all instructions. There are 56 instructions and a minimum instruction size of 16 bits. Many instructions and addressing modes are longer to include additional address or mode bits.

The CPU, and later the whole family, implements two levels of privilege. User mode gives access to everything except privileged instructions such as interrupt level controls. Supervisor privilege gives access to everything. An interrupt always becomes supervisory. The supervisor bit is stored in the status register, and is visible to user programs.

An advantage of this system is that the supervisor level has a separate stack pointer. This permits a multitasking system to use very small stacks for tasks, because the designers do not have to allocate the memory required to hold the stack frames of a maximum stack-up of interrupts.

The CPU recognizes seven interrupt levels. Levels 1 through 5 are strictly prioritized. That is, a higher-numbered interrupt can always interrupt a lower-numbered interrupt. In the status register, a privileged instruction allows one to set the current minimum interrupt level, blocking lower or equal priority interrupts. For example, if the interrupt level in the status register is set to 3, higher levels from 4 to 7 can cause an exception. Level 7 is a level triggered non-maskable interrupt (NMI). Level 1 can be interrupted by any higher level. Level 0 means no interrupt. The level is stored in the status register, and is visible to user-level programs.

Hardware interrupts are signalled to the CPU using three inputs that encode the highest pending interrupt priority. A separate Encoder is usually required to encode the interrupts, though for systems that do not require more than three hardware interrupts it is possible to connect the interrupt signals directly to the encoded inputs at the cost of additional software complexity. The interrupt controller can be as simple as a 74LS148 priority encoder, or may be part of a VLSI peripheral chip such as the MC68901 Multi-Function Peripheral (used in the Atari ST range of computers and Sharp X68000), which also provided a UART, timer, and parallel I/O.

The "exception table" (interrupt vector table interrupt vector addresses) is fixed at addresses 0 through 1023, permitting 256 32-bit vectors. The first vector (RESET) consists of two vectors, namely the starting stack address, and the starting code address. Vectors 3 through 15 are used to report various errors: bus error, address error, illegal instruction, zero division, CHK and CHK2 vector, privilege violation (to block privilege escalation), and some reserved vectors that became line 1010 emulator, line 1111 emulator, and hardware breakpoint. Vector 24 starts the real interrupts: spurious interrupt (no hardware acknowledgement), and level 1 through level 7 autovectors, then the 16 TRAP vectors, then some more reserved vectors, then the user defined vectors.

Since at a minimum the starting code address vector must always be valid on reset, systems commonly included some nonvolatile memory (e.g. ROM) starting at address zero to contain the vectors and bootstrap code. However, for a general purpose system it is desirable for the operating system to be able to change the vectors at runtime. This was often accomplished by either pointing the vectors in ROM to a jump table in RAM, or through use of bank switching to allow the ROM to be replaced by RAM at runtime.

The 68000 does not meet the Popek and Goldberg virtualization requirements for full processor virtualization because it has a single unprivileged instruction, "MOVE from SR", which allows user-mode software read-only access to a small amount of privileged state. The 68EC000 and 68SEC000, which are later derivatives of the 68000, do meet the requirements, however, as the "MOVE from SR" instruction is privileged. The same change was introduced on the 68010 and later CPUs.

The 68000 is also unable to easily support virtual memory, which requires the ability to trap and recover from a failed memory access. The 68000 does provide a bus error exception which can be used to trap, but it does not save enough processor state to resume the faulted instruction once the operating system has handled the exception. Several companies did succeed in making 68000-based Unix workstations with virtual memory that worked by using two 68000 chips running in parallel on different phased clocks. When the "leading" 68000 encountered a bad memory access, extra hardware would interrupt the "main" 68000 to prevent it from also encountering the bad memory access. This interrupt routine would handle the virtual memory functions and restart the "leading" 68000 in the correct state to continue properly synchronized operation when the "main" 68000 returned from the interrupt.

These problems were fixed in the next major revision of the 68k architecture, with the release of the MC68010. The Bus Error and Address Error exceptions push a large amount of internal state onto the supervisor stack in order to facilitate recovery, and the "MOVE from SR" instruction was made privileged. A new unprivileged "MOVE from CCR" instruction is provided for use in its place by user mode software; an operating system can trap and emulate user-mode "MOVE from SR" instructions if desired.

The standard addressing modes are:


Plus: access to the status register, and, in later models, other special registers.

Most instructions have dot-letter suffixes, permitting operations to occur on 8-bit bytes (".b"), 16-bit words (".w"), and 32-bit longs (".l").

Like many CPUs of its era the cycle timing of some instructions varied depending on the source operand(s). For example, the unsigned multiply instruction takes (38+2n) clock cycles to complete where 'n' is equal to the number of bits set in the operand. To create a function that took a fixed cycle count required the addition of extra code after the multiply instruction. This would typically consume extra cycles for each bit that wasn't set in the original multiplication operand.

Most instructions are dyadic, that is, the operation has a source, and a destination, and the destination is changed. Notable instructions were:


The 68EC000 is a low-cost version of the 68000 with a slightly different pinout, designed for embedded controller applications. The 68EC000 can have either a 8-bit or 16-bit data bus, switchable at reset.

The processors are available in a variety of speeds including 8 and 16 MHz configurations, producing 2,100 and 4,376 Dhrystones each. These processors have no floating-point unit, and it is difficult to implement an FPU coprocessor (MC68881/2) with one because the EC series lacks necessary coprocessor instructions.

The 68EC000 was used as a controller in many audio applications, including Ensoniq musical instruments and sound cards, where it was part of the MIDI synthesizer. On Ensoniq sound boards, the controller provided several advantages compared to competitors without a CPU on board. The processor allowed the board to be configured to perform various audio tasks, such as MPU-401 MIDI synthesis or MT-32 emulation, without the use of a TSR program. This improved software compatibility, lowered CPU usage, and eliminated host system memory usage.

The Motorola 68EC000 core was later used in the m68k-based DragonBall processors from Motorola/Freescale.

It also was used as a sound controller in the Sega Saturn game console and as a controller for the HP JetDirect Ethernet controller boards for the mid-1990s LaserJet printers.

The 68000 assembly code below is for a subroutine named , which copies a null-terminated string of 8-bit characters to a destination string, converting all alphabetic characters to lower case.

The subroutine establishes a call frame using register A6 as the frame pointer. This kind of calling convention supports reentrant and recursive code and is typically used by languages like C and C++. The subroutine then retrieves the parameters passed to it ( and ) from the stack. It then loops, reading an ASCII character (a single byte) from the string, checking whether it is a capital alphabetic character, and if so, converting it into a lower-case character, otherwise leaving it as it is, then writing the character into the string. Finally, it checks whether the character was a null character; if not, it repeats the loop, otherwise it restores the previous stack frame (and A6 register) and returns. Note that the string pointers (registers A0 and A1) are auto-incremented in each iteration of the loop.
In contrast, the code below is for a stand-alone function, even on the most restrictive version of AMS for the TI-89 series of calculators, being kernel-independent, with no values looked up in tables, files or libraries when executing, no system calls, no exception processing, minimal registers to be used, nor the need to save any. It is valid for historical Julian dates from 1 March 1 AD, or for Gregorian ones. In less than two dozen operations it calculates a day number compatible with ISO 8601 when called with three inputs stored at their corresponding LOCATIONS:
 move.l DATE,d0
 andi.l #$f00,d0
 swap d0
 mulu FLAG,d1





</doc>
<doc id="20272" url="https://en.wikipedia.org/wiki?curid=20272" title="Minicomputer">
Minicomputer

A minicomputer, or colloquially mini, is a class of smaller computers that was developed in the mid-1960s and sold for much less than mainframe and mid-size computers from IBM and its direct competitors. In a 1970 survey, "The New York Times" suggested a consensus definition of a minicomputer as a machine costing less than (), with an input-output device such as a teleprinter and at least four thousand words of memory, that is capable of running programs in a higher level language, such as Fortran or BASIC.

The class formed a distinct group with its own software architectures and operating systems. Minis were designed for control, instrumentation, human interaction, and communication switching as distinct from calculation and record keeping. Many were sold indirectly to original equipment manufacturers (OEMs) for final end use application. During the two decade lifetime of the minicomputer class (1965–1985), almost 100 companies formed and only a half dozen remained.

When single-chip CPU microprocessors appeared, beginning with the Intel 4004 in 1971, the term "minicomputer" came to mean a machine that lies in the middle range of the computing spectrum, in between the smallest mainframe computers and the microcomputers. The term "minicomputer" is little used today; the contemporary term for this class of system is "midrange computer", such as the higher-end SPARC, Power ISA and Itanium-based systems from Oracle, IBM and Hewlett-Packard.

The term "minicomputer" developed in the 1960s to describe the smaller computers that became possible with the use of transistors and core memory technologies, minimal instructions sets and less expensive peripherals such as the ubiquitous Teletype Model 33 ASR. They usually took up one or a few 19-inch rack cabinets, compared with the large mainframes that could fill a room.

The definition of minicomputer is vague with the consequence that there are a number of candidates for the "first" minicomputer, ranging from the CDC 160 circa 1960 to the DEC PDP-8 circa 1965. An early and highly successful minicomputer was Digital Equipment Corporation's (DEC) 12-bit PDP-8, which was built using discrete transistors and cost from upwards when launched in 1964. Later versions of the PDP-8 took advantage of small-scale integrated circuits. The important precursors of the PDP-8 include the PDP-5, LINC, the TX-0, the TX-2, and the PDP-1. DEC gave rise to a number of minicomputer companies along Massachusetts Route 128, including Data General, Wang Laboratories, Apollo Computer, and Prime Computer.

Minicomputers were also known as midrange computers. They grew to have relatively high processing power and capacity. They were used in manufacturing process control, telephone switching and to control laboratory equipment. In the 1970s, they were the hardware that was used to launch the computer-aided design (CAD) industry and other similar industries where a smaller dedicated system was needed.

The 7400 series of TTL integrated circuits started appearing in minicomputers in the late 1960s. The 74181 arithmetic logic unit (ALU) was commonly used in the CPU data paths. Each 74181 had a bus width of four bits, hence the popularity of "bit-slice" architecture. Some scientific computers, such as the Nicolet 1080, would use the 7400 series in groups of five ICs (parallel) for their uncommon twenty bits architecture. The 7400 series offered data-selectors, multiplexers, three-state buffers, memories, etc. in dual in-line packages with one-tenth inch spacing, making major system components and architecture evident to the naked eye. Starting in the 1980s, many minicomputers used VLSI circuits.

At the launch of the MITS Altair 8800 in 1975, "Radio Electronics" magazine referred to the system as a "minicomputer", although the term microcomputer soon became usual for personal computers based on single-chip microprocessors. At the time, microcomputers were 8-bit single-user, relatively simple machines running simple program-launcher operating systems like CP/M or MS-DOS, while minis were much more powerful systems that ran full multi-user, multitasking operating systems, such as VMS and Unix, and although the classical mini was a 16-bit computer, the emerging higher performance superminis were 32-bit.

The decline of the minis happened due to the lower cost of microprocessor-based hardware, the emergence of inexpensive and easily deployable local area network systems, the emergence of the 68020, 80286 and the 80386 microprocessors, and the desire of end-users to be less reliant on inflexible minicomputer manufacturers and IT departments or "data centers". The result was that minicomputers and computer terminals were replaced by networked workstations, file servers and PCs in some installations, beginning in the latter half of the 1980s.

During the 1990s, the change from minicomputers to inexpensive PC networks was cemented by the development of several versions of Unix and Unix-like systems that ran on the Intel x86 microprocessor architecture, including Solaris, Linux, FreeBSD, NetBSD and OpenBSD. Also, the Microsoft Windows series of operating systems, beginning with Windows NT, now included server versions that supported preemptive multitasking and other features required for servers.

As microprocessors have become more powerful, the CPUs built up from multiple components – once the distinguishing feature differentiating mainframes and midrange systems from microcomputers – have become increasingly obsolete, even in the largest mainframe computers.

Digital Equipment Corporation (DEC) was once the leading minicomputer manufacturer, at one time the second-largest computer company after IBM. But as the minicomputer declined in the face of generic Unix servers and Intel-based PCs, not only DEC, but almost every other minicomputer company including Data General, Prime, Computervision, Honeywell and Wang Laboratories, many based in New England (hence the end of the Massachusetts Miracle), also collapsed or merged. DEC was sold to Compaq in 1998, while Data General was acquired by EMC Corporation.

Today only a few proprietary minicomputer architectures survive. The IBM System/38 operating system, which introduced many advanced concepts, lives on with IBM's AS/400. Realising the importance of the myriad lines of 'legacy code' (programs) written, 'AS' stands for 'Application System'. Great efforts were made by IBM to enable programs originally written for the System/34 and System/36 to be moved to the AS/400. The AS/400 was replaced by the iSeries, which was subsequently replaced by the System i. In 2008, the System i was replaced by the IBM Power Systems. By contrast, competing proprietary computing architectures from the early 1980s, such as DEC's VAX, Wang VS and Hewlett Packard's HP 3000 have long been discontinued without a compatible upgrade path. OpenVMS runs HP Alpha and Intel IA-64 (Itanium) CPU architectures.

Tandem Computers, which specialized in reliable large-scale computing, was acquired by Compaq, and a few years afterward the combined entity merged with Hewlett Packard. The NSK-based NonStop product line was re-ported from MIPS processors to Itanium-based processors branded as 'HP Integrity NonStop Servers'. As in the earlier migration from stack machines to MIPS microprocessors, all customer software was carried forward without source changes. Integrity NonStop continues to be HP's answer for the extreme scaling needs of its very largest customers. The NSK operating system, now termed NonStop OS, continues as the base software environment for the NonStop Servers, and has been extended to include support for Java and integration with popular development tools like Visual Studio and Eclipse.

A variety of companies emerged that built turnkey systems around minicomputers with specialized software and, in many cases, custom peripherals that addressed specialized problems such as computer-aided design, computer-aided manufacturing, process control, manufacturing resource planning, and so on. Many if not most minicomputers were sold through these original equipment manufacturers and value-added resellers.

Several pioneering computer companies first built minicomputers, such as DEC, Data General, and Hewlett-Packard (HP) (who now refers to its HP3000 minicomputers as "servers" rather than "minicomputers"). And although today's PCs and servers are clearly microcomputers physically, architecturally their CPUs and operating systems have developed largely by integrating features from minicomputers.

In the software context, the relatively simple OSs for early microcomputers were usually inspired by minicomputer OSs (such as CP/M's similarity to Digital's single user OS/8 and RT-11 and multi-user RSTS time-sharing system). Also, the multiuser OSs of today are often either inspired by, or directly descended from, minicomputer OSs. UNIX was originally a minicomputer OS, while Windows NT kernel—the foundation for all current versions of Microsoft Windows-borrowed design ideas liberally from VMS. Many of the first generation of PC programmers were educated on minicomputer systems.





</doc>
<doc id="20273" url="https://en.wikipedia.org/wiki?curid=20273" title="March 18">
March 18





</doc>
<doc id="20282" url="https://en.wikipedia.org/wiki?curid=20282" title="Mechanized infantry">
Mechanized infantry

Mechanized infantry (or mechanised infantry) are infantry units equipped with armored personnel carriers (APCs) or infantry fighting vehicles (IFVs) for transport and combat (see also mechanized force).

Mechanized infantry is distinguished from motorized infantry in that its vehicles provide a degree of protection from hostile fire, as opposed to "soft-skinned" wheeled vehicles (trucks or jeeps) for motorized infantry. Most APCs and IFVs are fully tracked or are all-wheel drive vehicles (6×6 or 8×8), for mobility across rough ground. Some nations distinguish between mechanized and armored (or armoured) infantry, designating troops carried by APCs as mechanized and those in IFVs as armored.

The support weapons for mechanized infantry are also provided with motorized transport, or they are built directly into combat vehicles to keep pace with the mechanized infantry in combat. For units equipped with most types of APC or any type of IFV, fire support weapons, such as machine guns, autocannons, small-bore direct-fire howitzers, and anti-tank guided missiles are often mounted directly on the infantry's own transport vehicles.

Compared with "light" truck-mobile infantry, mechanized infantry can maintain rapid tactical movement and, if mounted in IFVs, have more integral firepower. It requires more combat supplies (ammunition and especially fuel) and ordnance supplies (spare vehicle components), and a comparatively larger proportion of manpower is required to crew and maintain the vehicles. For example, most APCs mount a section of seven or eight infantrymen but have a crew of two. Most IFVs carry only six or seven infantry but require a crew of three. To be effective in the field, mechanized units also require many mechanics, with specialized maintenance and recovery vehicles and equipment.

Some of the first mechanized infantry were German assault teams mounted on A7V tanks during World War I. The vehicles were extra-large to let them carry sizeable assault teams and would regularly carry infantry on board in addition to their already large crews that were trained as stormtroopers. All machine-gun-armed A7V tanks carried two small flame throwers for their dismounts to use. A7V tank would often carry a second officer to lead the assault team.

During the Battle of St. Quentin, A7Vs were accompanied by 20 stormtroopers from Rohr Assault Battalion, but it is unspecified if they were acting as dismounts or were accompanying the tanks on foot. During the battle, tank crews were reported to have dismounted and attacked enemy positions with grenades and flamethrowers on numerous occasions.

Another example of the use of such a method of fighting is the capture of Villers-Bretonneux, in which A7Vs would suppress the defenders with machine gun fire and assault teams would dismount and attack them with grenades.

Towards the end of World War I, all the armies involved were faced with the problem of maintaining the momentum of an attack. Tanks, artillery, or infiltration tactics could all be used to break through an enemy defense, but almost all offensives launched in 1918 ground to a halt after a few days. The following infantry quickly became exhausted, and artillery, supplies and fresh formations could not be brought forward over the battlefields quickly enough to maintain the pressure on the regrouping enemy

It was widely acknowledged that cavalry was too vulnerable to be used on most European battlefields, but many armies continued to deploy them. Motorized infantry could maintain rapid movement, but their trucks required either a good road network or firm open terrain, such as desert. They were unable to traverse a battlefield obstructed by craters, barbed wire, and trenches. Tracked or all-wheel drive vehicles were to be the solution.

Following the war, development of mechanized forces was largely theoretical for some time, but many nations began rearming in the 1930s. The British Army had established an Experimental Mechanized Force in 1927, but it failed to pursue that line because of budget constraints and the prior need to garrison the frontiers of the British Empire.

Although some proponents of mobile warfare, such as J. F. C. Fuller, advocated building "tank fleets", other, such as Heinz Guderian in Germany, Adna R. Chaffee Jr. in the United States, and Mikhail Tukhachevsky in the Soviet Union, recognized that tank units required close support from infantry and other arms and that such supporting arms needed to maintain the same pace as the tanks.

As the Germans rearmed in the 1930s, they equipped some infantry units in their new "Panzer" divisions with the half-track Sd.Kfz. 251, which could keep up with tanks on most terrain. The French Army also created "light mechanized" ("légère mécanisée") divisions in which some of the infantry units possessed small tracked carriers. Together with the motorization of the other infantry and support units, this gave both armies highly mobile combined-arms formations. The German doctrine was to use them to exploit breakthroughs in "Blitzkrieg" offensives, whereas the French envisaged them being used to shift reserves rapidly in a defensive battle.

As World War II progressed, most major armies integrated tanks or assault guns with mechanized infantry, as well as other supporting arms, such as artillery and engineers, as combined arms units.

Allied armored formations included a mechanized infantry element for combined arms teamwork. For example, US armored divisions had a balance of three battalions each of tanks, armored infantry, and self-propelled artillery. The US armored infantry was fully equipped with M2 and M3 halftracks. In the British and Commonwealth armies, "Type A armoured brigades," intended for independent operations or to form part of armored divisions, had a "motor infantry" battalion mounted in Bren Carriers or later in lend-lease halftracks. "Type B" brigades lacked a motor infantry component and were subordinated to infantry formations.

The Canadian Army and, subsequently the British Army, used expedients such as the Kangaroo APC, usually for specific operations rather than to create permanent mechanized infantry formations. The first such operation was Operation Totalize in the Battle of Normandy, which failed to achieve its ultimate objectives but showed that mechanized infantry could incur far fewer casualties than dismounted troops in set-piece operations.

The German Army, having introduced mechanized infantry in its "Panzer" divisions, later named them "Panzergrenadier" units. In the middle of the war, it created entire mechanized infantry divisions and named Panzergrenadier divisions.

Because the German economy could not produce adequate numbers of its half-track APC, barely a quarter or a third of the infantry in Panzer or Panzergrenadier divisions were mechanized, except in a few favored formations. The rest were moved by truck. However, most German reconnaissance units in such formations were also primarily mechanized infantry and could undertake infantry missions when it was needed. The Allies generally used jeeps, armored cars, or light tanks for reconnaissance.

The Red Army began the war while still in the process of reorganizing its armored and mechanized formations, most of which were destroyed during the first months of the German Invasion of the Soviet Union. About a year later, the Soviets recreated division-sized mechanized infantry units, termed mechanized corps, usually with one tank brigade and three mechanized infantry brigades, with motorized supporting arms. They were generally used in the exploitation phase of offensives, as part of the prewar Soviet concept of deep operations.

The Soviet Army also created several cavalry mechanized groups in which tanks, mechanized infantry and horsed cavalry were mixed. They were also used in the exploitation and pursuit phases of offensives. Red Army mechanized infantry were generally carried on tanks or trucks, with only a few dedicated lend-lease half-track APCs.

The New Zealand Army ultimately fielded a division of a roughly similar composition to a Soviet mechanized corps, which fought in the Italian Campaign, but it had little scope for mobile operations until near the end of the war.

The Romanian Army fielded a mixed assortment of vehicles. These amounted to 126 French-designed Renault UE Chenillettes which were licence-built locally, 34 captured and refurbished Soviet armored tractors, 27 German-made armored half-tracks of the Sd.Kfz. 250 and Sd.Kfz. 251 types, over 200 Czechoslovak Tatra, Praga and Skoda trucks (the Tatra trucks were a model which was specifically built for the Romanian Army) as well as 300 German Horch 901 4x4 field cars. Sd.Kfz. 8 and Sd.Kfz. 9 half-tracks were also acquired, as well as nine vehicles of the Sd.Kfz. 10 type and 100 RSO/01 fully tracked tractors. The Romanians also produced five prototypes of an indigenous artillery tractor.

In the postwar era, the early years of the Cold War, the Soviet Army and NATO further developed the equipment and doctrine for mechanized infantry. With the exception of airborne formations, the Red Army mechanized all its infantry formations. Initially, wheeled APCs, like the BTR-152, were used, some of which lacked overhead protection and were therefore vulnerable to artillery fire. It still gave the Soviet Army greater strategic flexibility because of the large land area and the long borders of the Soviet Union and its allies in the Warsaw Pact.

The US Army established the basic configuration of the tracked APC with the M75 and M59 before it adopted the lighter M113, which could be carried by Lockheed C-130 Hercules and other transport aircraft. The vehicle gave infantry the same mobility as tanks but with much less effective armor protection (it still had nuclear, biological, and chemical protection).

In the Vietnam War, the M113 was often fitted with extra armament and used as an "ad hoc" infantry fighting vehicle. Early operations by the Army of the Republic of Vietnam using the vehicle showed that troops were far more effective while they were mounted in the vehicles than when they dismounted. American doctrine subsequently emphasized mounted tactics. The Americans ultimately deployed a mechanized brigade and ten mechanized battalions to Vietnam.

Even more important for future developments was the Soviet BMP-1, which was the first true IFV. Its introduction prompted the development of similar vehicles in Western armies, such as the West German Marder and American M2 Bradley. Unlike the APC, which was intended merely to transport the infantry from place to place under armor, the IFV possessed heavy firepower that could support the infantry in attack or defense. Many IFVs were also equipped with firing ports from which their infantry could fire their weapons from inside, but they were generally not successful and have been dropped from modern IFVs.

Soviet organization led to different tactics between the "light" and the "heavy" varieties of mechanized infantry. In the Soviet Army, a first-line "motor rifle" division from the 1970s onward usually had two regiments equipped with wheeled BTR-60 APCs and one with the tracked BMP-1 IFV. The "light" regiments were intended to make dismounted attacks on the division's flanks, and the BMP-equipped "heavy" regiment remained mounted and supported the division's tank regiment on the main axis of advance. Both types of infantry regiment still were officially titled "motor rifle" units.

A line of development in the Soviet Armed Forces from the 1980s was the provision of specialized IFVs for use by the Russian Airborne Troops. The first of them was the BMD-1, which had the same firepower as the BMP-1 but be carried in or even parachuted from the standard Soviet transport aircraft. That made airborne formations into mechanized infantry at the cost of reducing "bayonet" strength, as the BMD could carry only three or at most four paratroopers in addition to its three-man crew. They were used in that role in the Soviet invasion of Afghanistan in 1979.

At present, almost all infantry units from industrialized nations are provided with some type of motor transport. Infantry units equipped with IFVs rather than lighter vehicles are commonly designated as "heavy", indicating more combat power but also more costly long-range transportation requirements. In Operation Desert Shield, during the buildup phase of the First Gulf War, the U.S. Army was concerned about the lack of mobility, protection and firepower offered by existing rapid deployment (i.e., airborne) formations; and also about the slowness of deploying regular armored units. The experience led the U.S. Army to form combat brigades based on the Stryker wheeled IFV.

In the British Army, "heavy" units equipped with the Warrior IFV are described as "armoured infantry", and units with the Bulldog APC as "mechanised infantry". This convention is becoming widespread; for example the French Army has ""motorisées"" units equipped with the wheeled VAB and ""mécanisées"" (armoured) units with the tracked AMX-10P.

The transport and other logistic requirements have led many armies to adopt wheeled APCs when their existing stocks of tracked APCs require replacement. An example is the Canadian Army, which has used the LAV III wheeled IFV in fighting in Afghanistan. The Italian, Spanish and Swedish armies are adopting (and exporting) new indigenous-produced tracked IFVs. The Swedish CV90 IFV in particular has been adopted by several armies.
A recent trend seen in the Israel Defense Forces and the Armed Forces of the Russian Federation is the development and introduction of exceptionally well-armored APCs (HAPC), such as the IDF Achzarit, that are converted from obsolete main battle tanks (such as the Soviet T-55). Such vehicles are usually expedients, and lack of space prevents the armament of an IFV being carried in addition to an infantry section or squad. In the Russian Army, such vehicles were introduced for fighting in urban areas, where the risk from short range infantry anti-tank weapons, such as the RPG-7, is highest, after Russian tank and motor infantry units suffered heavy losses fighting Chechen troops in Grozny during the First Chechen War in 1995.

Many APCs and IFVs currently under development are intended for rapid deployment by aircraft. New technologies that promise reduction in weight, such as electric drive, may be incorporated. However, facing a similar threat in post-invasion Iraq to that which prompted the Russians to convert tanks to APCs, the occupying armies have found it necessary to apply extra armor to existing APCs and IFVs, which adds to the overall size and weight. Some of the latest designs (such as the German Puma) are intended to allow a light, basic model vehicle, which is air-transportable, to be fitted in the field with additional protection, thereby ensuring both strategic flexibility and survivability.

It is generally accepted that single weapons system types are much less effective without the support of the full combined arms team; the pre-World War II notion of "tank fleets" has proven to be as unsound as the World War I idea of unsupported infantry attacks. Though many nations' armored formations included an organic mechanized infantry component at the start of World War II, the proportion of mechanized infantry in such combined arms formations was increased by most armies as the war progressed.

The lesson was re-learned, first by the Pakistani Army in the 1965 War with India, where the nation fielded two different types of armored divisions: one which was almost exclusively armor (the 1st), while another was more balanced (the 6th). The latter division showed itself to be far more combat capable than the former.

Having achieved spectacular successes in the offensive with tank-heavy formations during the Six-Day War, the Israel Defense Forces found in the Yom Kippur War of 1973 that a doctrine that relied primarily on tanks and aircraft had proven inadequate. As a makeshift remedy, paratroopers were provided with motorized transport and used as mechanized infantry in coordination with the armor.




</doc>
<doc id="20284" url="https://en.wikipedia.org/wiki?curid=20284" title="Micah">
Micah

Micah (; ) is a given name.

Micah is the name of several people in the Hebrew Bible (Old Testament), and means "Who is like God?" The name is sometimes found with theophoric extensions. Suffix theophory in "Yah" and in "Yahweh" results in Michaiah or Michaihu (), meaning "who is like Yahweh?" Suffix theophory in "El" results in "Michael" (), meaning "who is like god".

In German and Dutch, Micah is spelled and the "ch" in the name is pronounced either or ; the first is more common in female names, the latter in male names. The name is not as common as Michael or Michiel.





</doc>
<doc id="20285" url="https://en.wikipedia.org/wiki?curid=20285" title="Malachi">
Malachi

Malachi, Malachias, Malache or Mal'achi (; ) was the traditional writer of the Book of Malachi, the last book of the Neviim (prophets) section in the Hebrew Bible. No allusion is made to him by Ezra, however, and he does not directly mention the restoration of the temple. The editors of the 1906 Jewish Encyclopedia implied that he prophesied after Haggai and Zechariah (; , ) and speculated that he delivered his prophecies about 420 BCE, after the second return of Nehemiah from Persia (Book of Nehemiah ), or possibly before his return, comparing with ( with ).

In the Septuagint, or Greek Old Testament, the Prophetic Books are placed last, making the Book of Malachi the last protocanonical book before the Deuterocanonical books or The New Testament. According to the 1897 Easton's Bible Dictionary, it is possible that Malachi is not a proper name, but simply means "messenger of YHWH". The Greek Old Testament superscription is ἐν χειρὶ ἀγγέλου αὐτοῦ, (by the hand of his messenger).

Because Malachi's name does not occur elsewhere in the Bible, some scholars doubt whether "Malachi" is intended to be the personal name of the prophet. None of the other prophetic books of the Hebrew Bible or the Greek Old Testament are anonymous. The form "mal'akhi", signifies "my messenger"; it occurs in Malachi 3:1 (compare to Malachi 2:7). But this form of itself would hardly be appropriate as a proper name without some additional syllable such as Yah, whence "mal'akhiah", i.e. "messenger of Elohim." Haggai, in fact, is expressly designated "messenger of Elohim" (Haggai 1:13). Besides, the superscriptions prefixed to the book, in both the Septuagint and the Vulgate, warrant the supposition that Malachi's full name ended with the syllable -yah. At the same time the Greek Old Testament translates the last clause of Malachi 1:1, "by the hand of his messenger," and the Targum reads, "by the hand of my angel, whose name is called Ezra the scribe." 

The Jews of his day ascribed the Book of Malachi, the last book of prophecy, to Ezra, but if Ezra's name was originally associated with the book, it would hardly have been dropped by the collectors of the prophetic canon who lived only a century or two after Ezra's time. Certain traditions ascribe the book to Zerubbabel and Nehemiah; others, still, to Malachi, whom they designate as a Levite and a member of the "Great Synagogue." Certain modern scholars, however, on the basis of the similarity of the title (compare Malachi 1:1 to Zechariah 9:1 and Zechariah 12:1), declare it to be anonymous. Professor G.G. Cameron, suggests that the termination of the word "Malachi" is adjectival, and equivalent to the Latin angelicus, signifying "one charged with a message or mission" (a missionary). The term would thus be an official title, and the thought would not be unsuitable to one whose message closed the prophetical canon of the Old Testament.

Opinions vary as to the prophet's exact date, but nearly all scholars agree that Malachi prophesied during the Persian period, and after the reconstruction and dedication of the second temple in 516 BCE (compare Malachi 1:10 ; Malachi 3:1, Malachi 3:10). The prophet speaks of the "people's governor" (Hebrew "pechah", Malachi 1:8), as do Haggai and Nehemiah (Haggai 1:1 ; Nehemiah 5:14 ; Nehemiah 12:26). The social conditions portrayed appear to be those of the period of the Restoration. More specifically, Malachi probably lived and labored during the times of Ezra and Nehemiah. The abuses which Malachi mentions in his writings correspond so exactly with those which Nehemiah found on his second visit to Jerusalem in 432 BCE (Nehemiah 13:7) that it seems reasonably certain that he prophesied concurrently with Nehemiah or shortly after.

According to Rabbi W. Gunther Plaut, "Malachi describes a priesthood that is forgetful of its duties, a Temple that is underfunded because the people have lost interest in it, and a society in which Jewish men divorce their Jewish wives to marry out of the faith."





</doc>
<doc id="20286" url="https://en.wikipedia.org/wiki?curid=20286" title="Martin Fowler (software engineer)">
Martin Fowler (software engineer)

Martin Fowler (born 1963) is a British software developer, author and international public speaker on software development, specialising in object-oriented analysis and design, UML, patterns, and agile software development methodologies, including extreme programming.

His 1999 book "Refactoring" popularised the practice of code refactoring. In 2004 he introduced Presentation Model (PM), an architectural pattern.

Fowler was born and grew up in Walsall, England, where he went to Queen Mary's Grammar School for his secondary education. He graduated at University College London in 1986. In 1994 he moved to the United States, where he lives near Boston, Massachusetts in the suburb of Melrose.

Fowler started working with software in the early 1980s. Out of university in 1986 he started working in software development for Coopers & Lybrand until 1991. In 2000 he joined ThoughtWorks, a systems integration and consulting company, where he serves as Chief Scientist.

Fowler has written nine books on the topic of software development (see "Publications"). He is a member of the "Agile Alliance" and helped create the Manifesto for Agile Software Development in 2001, along with 16 fellow signatories. He maintains a "bliki", a mix of blog and wiki. He popularised the term Dependency Injection as a form of Inversion of Control.




</doc>
<doc id="20287" url="https://en.wikipedia.org/wiki?curid=20287" title="Microsoft Word">
Microsoft Word

Microsoft Word is a word processor developed by Microsoft. It was first released on October 25, 1983 under the name "Multi-Tool Word" for Xenix systems. Subsequent versions were later written for several other platforms including IBM PCs running DOS (1983), Apple Macintosh running the Classic Mac OS (1985), AT&T Unix PC (1985), Atari ST (1988), OS/2 (1989), Microsoft Windows (1989), SCO Unix (1994), and macOS (formerly OS X; 2001).

Commercial versions of Word are licensed as a standalone product or as a component of Microsoft Office, Windows RT or the discontinued Microsoft Works suite.

In 1981, Microsoft hired Charles Simonyi, the primary developer of Bravo, the first GUI word processor, which was developed at Xerox PARC. Simonyi started work on a word processor called "Multi-Tool Word" and soon hired Richard Brodie, a former Xerox intern, who became the primary software engineer.

Microsoft announced Multi-Tool Word for Xenix and MS-DOS in 1983. Its name was soon simplified to "Microsoft Word". Free demonstration copies of the application were bundled with the November 1983 issue of "PC World", making it the first to be distributed on-disk with a magazine. That year Microsoft demonstrated Word running on Windows.

Unlike most MS-DOS programs at the time, Microsoft Word was designed to be used with a mouse. Advertisements depicted the Microsoft Mouse, and described Word as a WYSIWYG, windowed word processor with the ability to undo and display bold, italic, and underlined text, although it could not render fonts. It was not initially popular, since its user interface was different from the leading word processor at the time, WordStar. However, Microsoft steadily improved the product, releasing versions 2.0 through 5.0 over the next six years. In 1985, Microsoft ported Word to the classic Mac OS (known as Macintosh System Software at the time). This was made easier by Word for DOS having been designed for use with high-resolution displays and laser printers, even though none were yet available to the general public. Following the precedents of LisaWrite and MacWrite, Word for Mac OS added true WYSIWYG features. It fulfilled a need for a word processor that was more capable than MacWrite. After its release, Word for Mac OS's sales were higher than its MS-DOS counterpart for at least four years.

The second release of Word for Mac OS, shipped in 1987, was named Word 3.0 to synchronize its version number with Word for DOS; this was Microsoft's first attempt to synchronize version numbers across platforms. Word 3.0 included numerous internal enhancements and new features, including the first implementation of the Rich Text Format (RTF) specification, but was plagued with bugs. Within a few months, Word 3.0 was superseded by a more stable Word 3.01, which was mailed free to all registered users of 3.0. After MacWrite Pro was discontinued in the mid-1990s, Word for Mac OS never had any serious rivals. Word 5.1 for Mac OS, released in 1992, was a very popular word processor owing to its elegance, relative ease of use and feature set. Many users say it is the best version of Word for Mac OS ever created.

In 1986, an agreement between Atari and Microsoft brought Word to the Atari ST under the name "Microsoft Write". The Atari ST version was a port of Word 1.05 for the Mac OS and was never updated.

The first version of Word for Windows was released in 1989. With the release of Windows 3.0 the following year, sales began to pick up and Microsoft soon became the market leader for word processors for IBM PC-compatible computers. In 1991, Microsoft capitalized on Word for Windows' increasing popularity by releasing a version of Word for DOS, version 5.5, that replaced its unique user interface with an interface similar to a Windows application. When Microsoft became aware of the Year 2000 problem, it made Microsoft Word 5.5 for DOS available for download free. , it is still available for download from Microsoft's web site.
In 1991, Microsoft embarked on a project code-named Pyramid to completely rewrite Microsoft Word from the ground up. Both the Windows and Mac OS versions would start from the same code base. It was abandoned when it was determined that it would take the development team too long to rewrite and then catch up with all the new capabilities that could have been added at the same time without a rewrite. Instead, the next versions of Word for Windows and Mac OS, dubbed version 6.0, both started from the code base of Word for Windows 2.0.

With the release of Word 6.0 in 1993, Microsoft again attempted to synchronize the version numbers and coordinate product naming across platforms, this time across DOS, Mac OS, and Windows (this was the last version of Word for DOS). It introduced AutoCorrect, which automatically fixed certain typing errors, and AutoFormat, which could reformat many parts of a document at once. While the Windows version received favorable reviews (e.g., from "InfoWorld"), the Mac OS version was widely derided. Many accused it of being slow, clumsy and memory intensive, and its user interface differed significantly from Word 5.1. In response to user requests, Microsoft offered Word 5 again, after it had been discontinued. Subsequent versions of Word for macOS are no longer direct ports of Word for Windows, instead featuring a mixture of ported code and native code.

Word for Windows is available stand-alone or as part of the Microsoft Office suite. Word contains rudimentary desktop publishing capabilities and is the most widely used word processing program on the market. Word files are commonly used as the format for sending text documents via e-mail because almost every user with a computer can read a Word document by using the Word application, a Word viewer or a word processor that imports the Word format (see Microsoft Word Viewer).

Word 6 for Windows NT was the first 32-bit version of the product, released with Microsoft Office for Windows NT around the same time as Windows 95. It was a straightforward port of Word 6.0. Starting with Word 95, releases of Word were named after the year of its release, instead of its version number.

Word 2010 allows more customization of the Ribbon, adds a Backstage view for file management, has improved document navigation, allows creation and embedding of screenshots, and integrates with Word Web App.

Word 2019 added the Dictate function.

The Mac was introduced January 24, 1984, and Microsoft introduced Word 1.0 for Mac a year later, on January 18, 1985. The DOS, Mac, and Windows versions are quite different from each other. Only the Mac version was WYSIWYG and used a graphical user interface, far ahead of the other platforms. Each platform restarted its version numbering at "1.0" (https://winworldpc.com/product/microsoft-word/1x-mac). There was no version 2 on the Mac, but version 3 came out on January 31, 1987, as described above. Word 4.0 came out on November 6, 1990, and added automatic linking with Excel, the ability to flow text around graphics and a WYSIWYG page view editing mode.

Word 5.1 for Mac, released in 1992 ran on the original 68000 CPU and was the last to be specifically designed as a Macintosh application. The later Word 6 was a Windows port and poorly received. Word 5.1 continued to run well until the very last Classic MacOS. Many people continue to run Word 5.1 to this day under an emulated Mac classic system for some of its excellent features like document generation and renumbering or to access their old files.
In 1997, Microsoft formed the Macintosh Business Unit as an independent group within Microsoft focused on writing software for Mac OS. Its first version of Word, Word 98, was released with Office 98 Macintosh Edition. Document compatibility reached parity with Word 97, and it included features from Word 97 for Windows, including spell and grammar checking with squiggles. Users could choose the menus and keyboard shortcuts to be similar to either Word 97 for Windows or Word 5 for Mac OS.

Word 2001, released in 2000, added a few new features, including the Office Clipboard, which allowed users to copy and paste multiple items. It was the last version to run on classic Mac OS and, on Mac OS X, it could only run within the Classic Environment. Word X, released in 2001, was the first version to run natively on, and required, Mac OS X, and introduced non-contiguous text selection.

Word 2004 was released in May 2004. It included a new Notebook Layout view for taking notes either by typing or by voice. Other features, such as tracking changes, were made more similar with Office for Windows.

Word 2008, released on January 15, 2008, included a Ribbon-like feature, called the Elements Gallery, that can be used to select page layouts and insert custom diagrams and images. It also included a new view focused on publishing layout, integrated bibliography management, and native support for the new Office Open XML format. It was the first version to run natively on Intel-based Macs.

Word 2011, released in October 2010, replaced the Elements Gallery in favor of a Ribbon user interface that is much more similar to Office for Windows, and includes a full-screen mode that allows users to focus on reading and writing documents, and support for Office Web Apps.

Word Mobile is a word processor that allows creating and editing documents. It supports basic formatting, such as bolding, changing font size, and changing colors (from red, yellow, or green). It can add comments, but can't edit documents with tracked changes. It can't open password protected documents, change the typeface, text alignment, or style (normal, heading 1); create bulleted lists; insert pictures; or undo. Word Mobile is neither able to display nor insert footnotes, endnotes, page headers, page footers, page breaks, certain indentation of lists, and certain fonts while working on a document, but retains them if the original document has them. In addition to the features of the 2013 version, the 2007 version on Windows Mobile also has the ability to save documents in the Rich Text Format and open legacy PSW (Pocket Word). Furthermore, it includes a spell checker, word count tool, and a "Find and Replace" command. In 2015, Word Mobile became available for Windows 10 and Windows 10 Mobile on Windows Store.

Microsoft Word's native file formats are denoted either by a codice_1 or codice_2 filename extension.

Although the codice_1 extension has been used in many different versions of Word, it actually encompasses four distinct file formats:

The newer codice_2 extension signifies the Office Open XML international standard for Office documents and is used by Word 2007 and later for Windows, Word 2008 and later for macOS, as well as by a growing number of applications from other vendors, including OpenOffice.org Writer, an open source word processing program.

During the late 1990s and early 2000s, the default Word document format (.DOC) became a "de facto" standard of document file formats for Microsoft Office users. There are different versions of "Word Document Format" used by default in Word 97–2007. Each binary word file is a Compound File, a hierarchical file system within a file. According to Joel Spolsky, Word Binary File Format is extremely complex mainly because its developers had to accommodate an overwhelming number of features and prioritize performance over anything else.

As with all OLE Compound Files, Word Binary Format consists of "storages", which are analogous to computer folders, and "streams", which are similar to computer files. Each storage may contain streams or other storage. Each Word Binary File must contain a stream called "WordDocument" stream and this stream must start with a File Information Block (FIB). FIB serves as the first point of reference for locating everything else, such as where the text in a Word document starts, ends, what version of Word created the document and other attributes.

Word 2007 and later continue to support the DOC file format, although it is no longer the default.

The .docx "XML " format introduced in Word 2003 was a simple, XML-based format called WordprocessingML.

Opening a Word Document file in a version of Word other than the one with which it was created can cause an incorrect display of the document. The document formats of the various versions change in subtle and not so subtle ways (such as changing the font, or the handling of more complex tasks like footnotes). Formatting created in newer versions does not always survive when viewed in older versions of the program, nearly always because that capability does not exist in the previous version. Rich Text Format (RTF), an early effort to create a format for interchanging formatted text between applications, is an optional format for Word that retains most formatting and all content of the original document.

Plugins permitting the Windows versions of Word to read and write formats it does not natively support, such as international standard OpenDocument format (ODF) (ISO/IEC 26300:2006), are available. Up until the release of Service Pack 2 (SP2) for Office 2007, Word did not natively support reading or writing ODF documents without a plugin, namely the SUN ODF Plugin or the OpenXML/ODF Translator. With SP2 installed, ODF format 1.1 documents can be read and saved like any other supported format in addition to those already available in Word 2007. The implementation faces substantial criticism, and the ODF Alliance and others have claimed that the third-party plugins provide better support. Microsoft later declared that the ODF support has some limitations.

In October 2005, one year before the Microsoft Office 2007 suite was released, Microsoft declared that there was insufficient demand from Microsoft customers for the international standard OpenDocument format support, and that therefore it would not be included in Microsoft Office 2007. This statement was repeated in the following months. As an answer, on October 20, 2005 an online petition was created to demand ODF support from Microsoft.

In May 2006, the ODF plugin for Microsoft Office was released by the OpenDocument Foundation. Microsoft declared that it had no relationship with the developers of the plugin.

In July 2006, Microsoft announced the creation of the Open XML Translator project – tools to build a technical bridge between the Microsoft Office Open XML Formats and the OpenDocument Format (ODF). This work was started in response to government requests for interoperability with ODF. The goal of project was not to add ODF support to Microsoft Office, but only to create a plugin and an external toolset. In February 2007, this project released a first version of the ODF plugin for Microsoft Word.

In February 2007, Sun released an initial version of its ODF plugin for Microsoft Office. Version 1.0 was released in July 2007.

Microsoft Word 2007 (Service Pack 1) supports (for output only) PDF and XPS formats, but only after manual installation of the Microsoft 'Save as PDF or XPS' add-on. On later releases, this was offered by default.

Among its features, Word includes a built-in spell checker, a thesaurus, a dictionary, and utilities for manipulating and editing text. The following are some aspects of its feature set.

Several later versions of Word include the ability for users to create their own formatting templates, allowing them to define a file in which the title, heading, paragraph, and other element designs differ from the standard Word templates. Users can find how to do this under the Help section located near the top right corner (Word 2013 on Windows 8).

For example, Normal.dot is the master template from which all Word documents are created. It determines the margin defaults as well as the layout of the text and font defaults. Although normal.dot is already set with certain defaults, the user can change normal.dot to new defaults. This will change other documents which were created using the template, usually in unexpected ways.

Word can import and display images in common bitmap formats such as JPG and GIF. It can also be used to create and display simple line-art. Microsoft Word added support for the common SVG vector image format in 2017 for Office 365 ProPlus subscribers and this functionality was also included in the Office 2019 release.

WordArt enables drawing text in a Microsoft Word document such as a title, watermark, or other text, with graphical effects such as skewing, shadowing, rotating, stretching in a variety of shapes and colors and even including three-dimensional effects. Users can apply formatting effects such as shadow, bevel, glow, and reflection to their document text as easily as applying bold or underline. Users can also spell-check text that uses visual effects, and add text effects to paragraph styles.

A Macro is a rule of pattern that specifies how a certain input sequence (often a sequence of characters) should be mapped to an output sequence according to a defined process. Frequently used or repetitive sequences of keystrokes and mouse movements can be automated.
Like other Microsoft Office documents, Word files can include advanced macros and even embedded programs. The language was originally WordBasic, but changed to Visual Basic for Applications as of Word 97.

This extensive functionality can also be used to run and propagate viruses in documents. The tendency for people to exchange Word documents via email, USB flash drives, and floppy disks made this an especially attractive vector in 1999. A prominent example was the Melissa virus, but countless others have existed.

These macro viruses were the only known cross-platform threats between Windows and Macintosh computers and they were the only infection vectors to affect any macOS system up until the advent of video codec trojans in 2007. Microsoft released patches for Word X and Word 2004 that effectively eliminated the macro problem on the Mac by 2006.

Word's macro security setting, which regulates when macros may execute, can be adjusted by the user, but in the most recent versions of Word, it is set to HIGH by default, generally reducing the risk from macro-based viruses, which have become uncommon.

Before Word 2010 (Word 14) for Windows, the program was unable to correctly handle ligatures defined in OpenType fonts. Those ligature glyphs with Unicode codepoints may be inserted manually, but are not recognized by Word for what they are, breaking spell checking, while custom ligatures present in the font are not accessible at all. Since Word 2010, the program now has advanced typesetting features which can be enabled: OpenType ligatures, kerning, and hyphenation. Other layout deficiencies of Word include the inability to set crop marks or thin spaces. Various third-party workaround utilities have been developed.

In Word 2004 for Mac OS X, support of complex scripts was inferior even to Word 97, and Word 2004 did not support Apple Advanced Typography features like ligatures or glyph variants.

Microsoft Word supports bullet lists and numbered lists. It also features a numbering system that helps add correct numbers to pages, chapters, headers, footnotes, and entries of tables of content; these numbers automatically change to correct ones as new items are added or existing items are deleted. Bullets and numbering can be applied directly to paragraphs and convert them to lists. Word 97 through 2003, however, had problems adding correct numbers to numbered lists. In particular, a second irrelevant numbered list might have not started with number one but instead resumed numbering after the last numbered list. Although Word 97 supported a hidden marker that said the list numbering must restart afterward, the command to insert this marker (Restart Numbering command) was only added in Word 2003. However, if one were to cut the first item of the listed and paste it as another item (e.g. fifth), then the restart marker would have moved with it and the list would have restarted in the middle instead of at the top.

Users can also create tables in "Word". Depending on the version, "Word" can perform simple calculations — along with support for formulas and equations as well.

Available in certain versions of Word (e.g., Word 2007), AutoSummarize highlights passages or phrases that it considers valuable and can be a quick way of generating a crude abstract or an executive summary. The amount of text to be retained can be specified by the user as a percentage of the current amount of text.

According to Ron Fein of the Word 97 team, AutoSummarize cuts wordy copy to the bone by counting words and ranking sentences. First, AutoSummarize identifies the most common words in the document (barring "a" and "the" and the like) and assigns a "score" to each word – the more frequently a word is used, the higher the score. Then, it "averages" each sentence by adding the scores of its words and dividing the sum by the number of words in the sentence – the higher the average, the higher the rank of the sentence. "It's like the ratio of wheat to chaff," explains Fein.

AutoSummarize was removed from Microsoft Word for Mac OS X 2011, although it was present in Word for Mac 2008. AutoSummarize was removed from the Office 2010 release version (14) as well.

There are many shortcuts that can be used in Microsoft Word, however, there are a couple of mostly used shortcuts. To make letters bold: "Control+B", Make letters italic: "Control+I", Make letters underline: "Control+U", Copy text: "Control+C", and to Paste text: Control+V. There are many other shortcut keys that you can use in Microsoft Office as well.

Word for the web is a free lightweight version of Microsoft Word available as part of Office on the web, which also includes web versions of Microsoft Excel and Microsoft PowerPoint.

Word for the web lacks some Ribbon tabs, such as Design and Mailings. Mailings allows users to print envelopes and labels, and manage mail merge printing of Word documents. Word for the web is not able to edit certain objects, such as equations, shapes, text boxes, or drawings, but a placeholder may be present in the document. Certain advanced features like table sorting or columns will not be displayed but are preserved as they were in the document. Other views available in the Word desktop app (Outline, Draft, Web Layout, and Full Screen Reading) are not available, nor are side-by-side viewing, split windows, and the ruler.

There are three password types that can be set in Microsoft Word:


The second and the third type of passwords were developed by Microsoft for convenient shared use of documents rather than for their protection. There is no encryption of documents that are protected by such passwords, and the Microsoft Office protection system saves a hash sum of a password in a document's header where it can be easily accessed and removed by the specialized software.
"Password to open a document" offers much tougher protection that had been steadily enhanced in the subsequent editions of Microsoft Office.

"Word 95" and all the preceding editions had the weakest protection that utilized a conversion of a password to a 16-bit key.

Key length in "Word 97" and "2000" was strengthened up to 40 bit. However, modern cracking software allows removing such a password very quickly – a persistent cracking process takes one week at most. Use of rainbow tables reduces password removal time to several seconds. Some password recovery software can not only remove a password but also find an actual password that was used by a user to encrypt the document using brute-force attack approach. Statistically, the possibility of recovering the password depends on the password strength.

Word's 2003/XP version default protection remained the same but an option that allowed advanced users choosing a Cryptographic Service Provider was added. If a strong CSP is chosen, guaranteed document decryption becomes unavailable, and therefore a password can't be removed from the document. Nonetheless, a password can be fairly quickly picked with a brute-force attack, because its speed is still high regardless of the CSP selected. Moreover, since the CSPs are not active by default, their use is limited to advanced users only.

Word 2007 offers significantly more secure document protection which utilizes the modern Advanced Encryption Standard (AES) that converts a password to a 128-bit key using a SHA-1 hash function 50000 times. It makes password removal impossible (as of today, no computer that can pick the key in a reasonable amount of time exists), and drastically slows the brute-force attack speed down to several hundreds of passwords per second.

Word's 2010 protection algorithm was not changed apart from the increasing number of SHA-1 conversions up to 100000 times, and consequently, the brute-force attack speed decreased two times more.

"BYTE" in 1984 criticized the documentation for Word 1.1 and 2.0 for DOS, calling it "a complete farce". It called the software "clever, put together well, and performs some extraordinary feats", but concluded that "especially when operated with the mouse, has many more limitations than benefits ... extremely frustrating to learn and operate efficiently". "PC Magazine" review was very mixed, stating "I've run into weird word processors before, but this is the first time one's nearly knocked me down for the count" but acknowledging that Word's innovations were the first that caused the reviewer to consider abandoning WordStar. While the review cited an excellent WYSIWYG display, sophisticated print formatting, windows, and footnoting as merits, it criticized many small flaws, very slow performance, and "documentation apparently produced by Madame Sadie's Pain Palace". It concluded that Word was "two releases away from potential greatness".

"Compute!'s Apple Applications" in 1987 stated that "despite a certain awkwardness", Word 3.01 "will likely become the major Macintosh word processor" with "far too many features to list here". While criticizing the lack of true WYSIWYG, the magazine concluded that ""Word" is marvelous. It's like a Mozart or Edison, whose occasional gaucherie we excuse because of his great gifts".

"Compute!" in 1989 stated that Word 5.0's integration of text and graphics made it "a solid engine for basic desktop publishing". The magazine approved of improvements to text mode, described the $75 price for upgrading from an earlier version as "the deal of the decade", and concluded that "as a high-octane word processor, "Word" is definitely worth a look".

During the first quarter of 1996, "Microsoft Word" accounted for 80% of the worldwide word processing market.

Despite its commercial success, it has also been argued in the scientific community that "Word" might not be well-suited for large-scale projects with high typographical demands, due to issues such as file compatibility, poor typography, low image quality, and limited feature scalability.




</doc>
<doc id="20288" url="https://en.wikipedia.org/wiki?curid=20288" title="Microsoft Office">
Microsoft Office

Microsoft Office, or simply Office, is a family of client software, server software, and services developed by Microsoft. It was first announced by Bill Gates on August 1, 1988, at COMDEX in Las Vegas. Initially a marketing term for an office suite (bundled set of productivity applications), the first version of Office contained Microsoft Word, Microsoft Excel, and Microsoft PowerPoint. Over the years, Office applications have grown substantially closer with shared features such as a common spell checker, OLE data integration and Visual Basic for Applications scripting language. Microsoft also positions Office as a development platform for line-of-business software under the Office Business Applications brand. On July 10, 2012, Softpedia reported that Office was being used by over a billion people worldwide.

Office is produced in several versions targeted towards different end-users and computing environments. The original, and most widely used version, is the desktop version, available for PCs running the Windows and macOS operating systems. Microsoft also maintains mobile apps for Android and iOS. Office on the web is a version of the software that runs within a web browser.

Since Office 2013, Microsoft has promoted Office 365 as the primary means of obtaining Microsoft Office: it allows the use of the software and other services on a subscription business model, and users receive feature updates to the software for the lifetime of the subscription, including new features and cloud computing integration that are not necessarily included in the "on-premises" releases of Office sold under conventional license terms. In 2017, revenue from Office 365 overtook conventional license sales.

The current on-premises, desktop version of Office is Office 2019, released on September 24, 2018.






Office on the web is a free lightweight web version of Microsoft Office and primarily includes four web applications: Word, Excel, Powerpoint and OneNote. The offering also includes Outlook.com and OneDrive which are accessible through a unified app switcher. Users can install the on-premises version of this service, called Office Online Server, in private clouds in conjunction with SharePoint, Microsoft Exchange Server and Microsoft Lync Server.

Word, Excel, and PowerPoint on the web can all natively open, edit, and save Office Open XML files (docx, xlsx, pptx) as well as OpenDocument files (odt, ods, odp). They can also open the older Office file formats (doc, xls, ppt), but will be converted to the newer Open XML formats if the user wishes to edit them online. Other formats cannot be opened in the browser apps, such as CSV in Excel or HTML in Word, nor can Office files that are encrypted with a password be opened. Files with macros can be opened in the browser apps, but the macros cannot be accessed or executed. Starting on July 2013, Word can render PDF documents or convert them to Microsoft Word documents, although the formatting of the document may deviate from the original. Since November 2013, the apps have supported real-time co-authoring and autosaving files.

Office on the web lacks a number of the advanced features present in the full desktop versions of Office, including lacking the programs Access and Publisher entirely. However, users are able to select the command "Open in Desktop App" that brings up the document in the desktop version of Office on their computer or device to utilize the advanced features there.

Supported web browsers include Microsoft Edge, Internet Explorer 11, the latest versions of Firefox or Google Chrome, as well as Safari for OS X 10.8 or later.

The Personal edition of Office on the web is available to the general public free of charge with a Microsoft account through the Office.com website, which superseded SkyDrive (now OneDrive) and Office Live Workspace. Enterprise-managed versions are available through Office 365. In February 2013, the ability to view and edit files on SkyDrive without signing in was added. The service can also be installed privately in enterprise environments as a SharePoint app, or through Office Web Apps Server. Microsoft also offers other web apps in the Office suite, such as the Outlook Web App (formerly Outlook Web Access), Lync Web App (formerly Office Communicator Web Access), Project Web App (formerly Project Web Access). Additionally, Microsoft offers a service under the name of Online Doc Viewer to view Office documents on a website via Office on the web.

There are free extensions available to use Office on the web directly in Google Chrome and Microsoft Edge.

Most versions of Microsoft Office (including Office 97 and later) use their own widget set and do not exactly match the native operating system. This is most apparent in Microsoft Office XP and 2003, where the standard menus were replaced with a colored, flat-looking, shadowed menu style. The user interface of a particular version of Microsoft Office often heavily influences a subsequent version of Microsoft Windows. For example, the toolbar, colored buttons and the gray-colored 3D look of Office 4.3 were added to Windows 95, and the ribbon, introduced in Office 2007, has been incorporated into several programs bundled with Windows 7 and later. In 2012, Office 2013 replicated the flat, box-like design of Windows 8.

Users of Microsoft Office may access external data via connection-specifications saved in Office Data Connection (.odc) files.

Both Windows and Office use service packs to update software. Office had non-cumulative service releases, which were discontinued after Office 2000 Service Release 1.

Past versions of Office often contained Easter eggs. For example, Excel 97 contained a reasonably functional flight-simulator.

Microsoft Office prior to Office 2007 used proprietary file formats based on the OLE Compound File Binary Format. This forced users who share data to adopt the same software platform. In 2008, Microsoft made the entire documentation for the binary Office formats freely available for download and granted any possible patents rights for use or implementations of those binary format for free under the Open Specification Promise. Previously, Microsoft had supplied such documentation freely but only on request.

Starting with Office 2007, the default file format has been a version of Office Open XML, though different than the one standardized and published by Ecma International and by ISO/IEC. Microsoft has granted patent rights to the formats technology under the Open Specification Promise and has made available free downloadable converters for previous versions of Microsoft Office including Office 2003, Office XP, Office 2000 and Office 2004 for Mac OS X. Third-party implementations of Office Open XML exist on the Windows platform (LibreOffice, all platforms), macOS platform (iWork '08, NeoOffice, LibreOffice) and Linux (LibreOffice and OpenOffice.org 3.0). In addition, Office 2010, Service Pack 2 for Office 2007, and Office 2016 for Mac supports the OpenDocument Format (ODF) for opening and saving documents – only the old ODF 1.0 (2006 ISO/IEC standard) is supported, not the 1.2 version (2015 ISO/IEC standard).

Microsoft provides the ability to remove metadata from Office documents. This was in response to highly publicized incidents where sensitive data about a document was leaked via its metadata. Metadata removal was first available in 2004, when Microsoft released a tool called "Remove Hidden Data Add-in for Office 2003/XP" for this purpose. It was directly integrated into Office 2007 in a feature called the "Document Inspector".

A major feature of the Office suite is the ability for users and third party companies to write add-ins (plug-ins) that extend the capabilities of an application by adding custom commands and specialized features. One of the new features is the Office Store. Plugins and other tools can be downloaded by users. Developers can make money by selling their applications in the Office Store. The revenue is divided between the developer and Microsoft where the developer gets 80% of the money. Developers are able to share applications with all Office users.

The app travels with the document, and it is for the developer to decide what the recipient will see when they open it. The recipient will either have the option to download the app from the Office Store for free, start a free trial or be directed to payment.
With Office's cloud abilities, IT department can create a set of apps for their business employees in order to increase their productivity. When employees go to the Office Store, they'll see their company's apps under "My Organization". The apps that employees have personally downloaded will appear under "My Apps". Developers can use web technologies like HTML5, XML, CSS3, JavaScript, and APIs for building the apps.
An application for Office is a webpage that is hosted inside an Office client application. User can use apps to amplify the functionality of a document, email message, meeting request, or appointment. Apps can run in multiple environments and by multiple clients, including rich Office desktop clients, Office Web Apps, mobile browsers, and also on-premises and in the cloud. The type of add-ins supported differ by Office versions:


Microsoft Office has a security feature that allows users to encrypt Office (Word, Excel, PowerPoint, Access, Skype Business) documents with a user-provided password. The password can contain up to 255 characters and uses AES 128-bit advanced encryption by default. Passwords can also be used to restrict modification of the entire document, worksheet or presentation. Due to lack of document encryption, though, these passwords can be removed using a third-party cracking software.

All versions of Microsoft Office products before Microsoft Office 2019 are eligible for ten years of support following their release, during which Microsoft releases security updates for the product version and provides paid technical support. The ten-year period is divided into two five-year phases: The mainstream phase and the extended phase. During the mainstream phase, Microsoft may provide limited complimentary technical support and release non-security updates or change the design of the product. During the extended phase, said services stop. Office 2019 only receives 5 years of mainstream and 2 years of extended support.

Microsoft supports Office for the Windows and macOS platforms, as well as mobile versions for Windows Phone, Android and iOS platforms. Beginning with Mac Office 4.2, the macOS and Windows versions of Office share the same file format, and are interoperable. Visual Basic for Applications support was dropped in Microsoft Office 2008 for Mac, then reintroduced in Office for Mac 2011.

Microsoft tried in the mid-1990s to port Office to RISC processors such as NEC/MIPS and IBM/PowerPC, but they met problems such as memory access being hampered by data structure alignment requirements. Microsoft Word 97 and Excel 97, however, did ship for the DEC Alpha platform. Difficulties in porting Office may have been a factor in discontinuing Windows NT on non-Intel platforms.

The Microsoft Office applications and suites are sold via retail channels, and volume licensing for larger organizations (also including the "Home Use Program". allowing users at participating organizations to buy low-cost licenses for use on their personal devices as part of their employer's volume license agreement).

In 2010, Microsoft introduced a software as a service platform known as Office 365, to provide cloud-hosted versions of Office's server software, including Exchange e-mail and SharePoint, on a subscription basis (competing in particular with Google Apps). Following the release of Office 2013, Microsoft began to offer Office 365 plans for the consumer market, with access to Microsoft Office software on multiple devices with free feature updates over the life of the subscription, as well as other services such as OneDrive storage.

Microsoft has since promoted Office 365 as the primary means of purchasing Microsoft Office. Although there are still "on-premises" releases roughly every three years, Microsoft marketing emphasizes that they do not receive new features or access to new cloud-based services as they are released unlike Office 365, as well as other benefits for consumer and business markets. Office 365 revenue overtook traditional license sales for Office in 2017.

Microsoft Office is available in several editions, which regroup a given number of applications for a specific price. Current retail editions are grouped by category:

Post-secondary students may obtain the University edition of Microsoft Office 365 subscription. It is limited to one user and two devices, plus the subscription price is valid for four years instead of just one. Apart from this, the University edition is identical in features to the Home Premium version. This marks the first time Microsoft does not offer physical or permanent software at academic pricing, in contrast to the University versions of Office 2010 and Office 2011. In addition, students eligible for DreamSpark program may receive select standalone Microsoft Office apps free of charge.




Microsoft Office has been criticized in the past for using proprietary file formats rather than open standards, which forces users who share data into adopting the same software platform. However, on February 15, 2008, Microsoft made the entire documentation for the binary Office formats freely available under the Open Specification Promise. Also, Office Open XML, the document format for the latest versions of Office for Windows and Mac, has been standardized under both Ecma International and ISO. Ecma International has published the Office Open XML specification free of copyrights and Microsoft has granted patent rights to the formats technology under the Open Specification Promise and has made available free downloadable converters for previous versions of Microsoft Office including Office 2003, Office XP, Office 2000 and Office 2004 for the Mac. Third-party implementations of Office Open XML exist on the Mac platform (iWork 08) and Linux (OpenOffice.org 2.3 – Novell Edition only).

Another point of criticism Microsoft Office has faced was the lack of support in its Mac versions for Unicode and Bi-directional text languages, notably Arabic and Hebrew. This issue, which had existed since the first release in 1989, was addressed in the 2016 version.

On 13 November 2018, a report initiated by the Government of the Netherlands concluded that Microsoft Office 2016 and Office 365 do not comply with GDPR, the European law which regulates data protection and privacy for all citizens in and outside the EU and EFTA region. The investigation was initiated by the observation that Microsoft does not reveal or share publicly any data collected about users of its software. In addition, the company does not provide users of its (Office) software an option to turn off diagnostic and telemetry data sent back to the company. Researchers found that most of the data that the Microsoft software collects and "sends home" is diagnostics. Researchers also observed that Microsoft "seemingly tried to make the system GDPR compliant by storing Office documents on servers based in the EU". However, they discovered the software packages collected additional data that contained private user information, some of which was stored on servers located in the US. The Netherlands Ministry of Justice hired Privacy Company to probe and evaluate the use of Microsoft Office products in the public sector. "Microsoft systematically collects data on a large scale about the individual use of Word, Excel, PowerPoint, and Outlook. Covertly, without informing people," researchers of the Privacy Company stated in their blog post. "Microsoft does not offer any choice with regard to the amount of data, or possibility to switch off the collection, or ability to see what data are collected, because the data stream is encoded."

The researchers commented that there is no need for Microsoft to store information such as IPs and email addresses, which are collected automatically by the software. "Microsoft should not store these transient, functional data, unless the retention is strictly necessary, for example, for security purposes," the researchers conclude in the final report by the Netherlands Ministry of Justice.

As a result of this in-depth study and its conclusions, the Netherlands regulatory body concluded that Microsoft has violated GDPR "on many counts" including "lack of transparency and purpose limitation, and the lack of a legal ground for the processing." Microsoft has provided the Dutch authorities with an "improvement plan" that should satisfy Dutch regulators that it "would end all violations." The Dutch regulatory body is monitoring the situation and states that "If progress is deemed insufficient or if the improvements offered are unsatisfactory, SLM Microsoft Rijk will reconsider its position and may ask the Data Protection Authority to carry out a prior consultation and to impose enforcement measures." When asked for a response by an IT professional publication, a Microsoft spokesperson stated: We are committed to our customers’ privacy, putting them in control of their data and ensuring that Office ProPlus and other Microsoft products and services comply with GDPR and other applicable laws. We appreciate the opportunity to discuss our diagnostic data handling practices in Office ProPlus with the Dutch Ministry of Justice and look forward to a successful resolution of any concerns."
The user privacy data issue affects ProPlus subscriptions of Microsoft Office 2016 and Microsoft Office 365, including the online version of Microsoft Office 365.

Microsoft Office for Windows started in October 1990 as a bundle of three applications designed for Microsoft Windows 3.0: Microsoft Word for Windows 1.1, Microsoft Excel for Windows 2.0, and Microsoft PowerPoint for Windows 2.0.

Microsoft Office for Windows 1.5 updated the suite with Microsoft Excel 3.0.

Version 1.6 added Microsoft Mail for PC Networks 2.1 to the bundle.

Microsoft Office 3.0, also called Microsoft Office 92, was released on August 30, 1992 and contained Word 2.0, Excel 4.0, PowerPoint 3.0 and Mail 3.0. It was the first version of Office also released on CD-ROM. In 1993, Microsoft Office Professional was released, which added Microsoft Access 1.1.

Microsoft Office 4.0 was released containing Word 6.0, Excel 4.0a, PowerPoint 3.0 and Mail in 1993. Word's version number jumped from 2.0 to 6.0 so that it would have the same version number as the MS-DOS and Macintosh versions (Excel and PowerPoint were already numbered the same as the Macintosh versions).

Microsoft Office 4.2 for Windows NT was released in 1994 for i386, Alpha, MIPS and PowerPC architectures, containing Word 6.0 and Excel 5.0 (both 32-bit, PowerPoint 4.0 (16-bit), and Microsoft Office Manager 4.2 (the precursor to the Office Shortcut Bar)).

Microsoft Office 95 was released on August 24, 1995. Software version numbers were altered again to create parity across the suiteevery program was called version 7.0 meaning all but Word missed out versions. Office for Windows 95 was designed as a fully 32-bit version to match Windows 95 although some apps not bundled as part of the suite at that time - Publisher for Windows 95 and Project 95 had some 16-bit components even though their main program executable was 32-bit. Office 95 was available in two versions, Office 95 Standard and Office 95 Professional. The standard version consisted of Word 7.0, Excel 7.0, PowerPoint 7.0, and Schedule+ 7.0. The professional edition contained all of the items in the standard version plus Microsoft Access 7.0. If the professional version was purchased in CD-ROM form, it also included Bookshelf.

The logo used in Office 95 returns in Office 97, 2000 and XP. Microsoft Office 98 Macintosh Edition also uses a similar logo.

Microsoft Office 97 (Office 8.0) included hundreds of new features and improvements, such as introducing command bars, a paradigm in which menus and toolbars were made more similar in capability and visual design. Office 97 also featured Natural Language Systems and grammar checking. Office 97 was the first version of Office to include the Office Assistant. In Brazil, it was also the first version to introduce the Registration Wizard, a precursor to Microsoft Product Activation. With this release, the accompanying apps, Project 98 and Publisher 98 also transitioned to fully 32-bit versions.

Microsoft Office 2000 (Office 9.0) introduced adaptive menus, where little-used options were hidden from the user. It also introduced a new security feature, built around digital signatures, to diminish the threat of macro viruses. Office 2000 automatically trusts macros (written in VBA 6) that were digitally signed from authors who have been previously designated as trusted. The Registration Wizard, a precursor to Microsoft Product Activation, remained in Brazil and was also extended to Australia and New Zealand, though not for volume-licensed editions. Academic software in the United States and Canada also featured the Registration Wizard.

Microsoft Office XP (Office 10.0 or Office 2002) was released in conjunction with Windows XP, and was a major upgrade with numerous enhancements and changes over Office 2000. Office XP introduced the Safe Mode feature, which allows applications such as Outlook to boot when it might otherwise fail by bypassing a corrupted registry or a faulty add-in. Smart tag is a technology introduced with Office XP in Word and Excel and discontinued in Office 2010. Office XP includes integrated voice command and text dictation capabilities, as well as handwriting recognition. It was the first version to require Microsoft Product Activation worldwide and in all editions as an anti-piracy measure, which attracted widespread controversy. Product Activation remained absent from Office for Mac releases until it was introduced in Office 2011 for Mac.

Microsoft Office 2003 (Office 11.0) was released in 2003. It featured a new logo. Two new applications made their debut in Office 2003: Microsoft InfoPath and OneNote. It is the first version to use new, more colorful icons. Outlook 2003 provides improved functionality in many areas, including Kerberos authentication, RPC over HTTP, Cached Exchange Mode, and an improved junk mail filter.

Microsoft Office 2007 (Office 12.0) was released in 2007. Office 2007's new features include a new graphical user interface called the Fluent User Interface, replacing the menus and toolbars that have been the cornerstone of Office since its inception with a tabbed toolbar, known as the Ribbon; new XML-based file formats called Office Open XML; and the inclusion of Groove, a collaborative software application.

Microsoft Office 2010 (Office 14.0, because Microsoft skipped 13.0) was finalized on April 15, 2010 and made available to consumers on June 15, 2010. The main features of Office 2010 include the backstage file menu, new collaboration tools, a customizable ribbon, protected view and a navigation panel. This is the first version to ship in 32-bit and 64-bit variants. Microsoft Office 2010 featured a new logo, which resembled the 2007 logo, except in gold, and with a modification in shape.

Microsoft released Service Pack 1 for Office 2010 on June 28, 2011 and Service Pack 2 on July 16, 2013.

A technical preview of Microsoft Office 2013 (Build 15.0.3612.1010) was released on January 30, 2012, and a Customer Preview version was made available to consumers on July 16, 2012. It sports a revamped application interface; the interface is based on Metro, the interface of Windows Phone and Windows 8. Microsoft Outlook has received the most pronounced changes so far; for example, the Metro interface provides a new visualization for scheduled tasks. PowerPoint includes more templates and transition effects, and OneNote includes a new splash screen. On May 16, 2011, new images of Office 15 were revealed, showing Excel with a tool for filtering data in a timeline, the ability to convert Roman numerals to Arabic numerals, and the integration of advanced trigonometric functions. In Word, the capability of inserting video and audio online as well as the broadcasting of documents on the Web were implemented. Microsoft has promised support for Office Open XML Strict starting with version 15, a format Microsoft has submitted to the ISO for interoperability with other office suites, and to aid adoption in the public sector. This version can read and write ODF 1.2 (Windows only).

On October 24, 2012, Office 2013 Professional Plus was released to manufacturing and was made available to TechNet and MSDN subscribers for download. On November 15, 2012, the 60-day trial version was released for public download. Office 2013 was released to general availability on January 29, 2013.

Service Pack 1 for Office 2013 was released on February 25, 2014.

On January 22, 2015, the Microsoft Office blog announced that the next version of the suite for Windows desktop, Office 2016, was in development. On May 4, 2015, a public preview of Microsoft Office 2016 was released. Office 2016 was released for Mac OS X on July 9, 2015 and for Windows on September 22, 2015.

On September 26, 2017, Microsoft announced that the next version of the suite for Windows desktop, Office 2019, was in development. On April 27, 2018, Microsoft released Office 2019 Commercial Preview for Windows 10. It was released to general availability for Windows 10 and for macOS on September 24, 2018.

Prior to packaging its various office-type Mac OS software applications into Office, Microsoft released Mac versions of Word 1.0 in 1984, the first year of the Macintosh computer; Excel 1.0 in 1985; and PowerPoint 1.0 in 1987. Microsoft does not include its Access database application in Office for Mac.

Microsoft has noted that some features are added to Office for Mac before they appear in Windows versions, such as Office for Mac 2001's Office Project Gallery and PowerPoint Movie feature, which allows users to save presentations as QuickTime movies. However, Microsoft Office for Mac has been long criticized for its lack of support of Unicode and for its lack of support for right-to-left languages, notably Arabic, Hebrew and Persian.

Microsoft Office for Mac was introduced for Mac OS in 1989, before Office was released for Windows. It included Word 4.0, Excel 2.2, PowerPoint 2.01, and Mail 1.37. It was originally a limited-time promotion but later became a regular product. With the release of Office on CD-ROM later that year, Microsoft became the first major Mac publisher to put its applications on CD-ROM.

Microsoft Office 1.5 for Mac was released in 1991 and included the updated Excel 3.0, the first application to support Apple's System 7 operating system.

Microsoft Office 3.0 for Mac was released in 1992 and included Word 5.0, Excel 4.0, PowerPoint 3.0 and Mail Client. Excel 4.0 was the first application to support new AppleScript.

Microsoft Office 4.2 for Mac was released in 1994. (Version 4.0 was skipped to synchronize version numbers with Office for Windows) Version 4.2 included Word 6.0, Excel 5.0, PowerPoint 4.0 and Mail 3.2. It was the first Office suite for Power Macintosh. Its user interface was identical to Office 4.2 for Windows leading many customers to comment that it wasn't Mac-like enough. The final release for Mac 68K was Office 4.2.1, which updated Word to version 6.0.1, somewhat improving performance.

Microsoft Office 98 Macintosh Edition was unveiled at MacWorld Expo/San Francisco in 1998. It introduced the Internet Explorer 4.0 web browser and Outlook Express, an Internet e-mail client and usenet newsgroup reader. Office 98 was re-engineered by Microsoft's Macintosh Business Unit to satisfy customers' desire for software they felt was more Mac-like. It included drag–and-drop installation, self-repairing applications and Quick Thesaurus, before such features were available in Office for Windows. It also was the first version to support QuickTime movies.

Microsoft Office 2001 was launched in 2000 as the last Office suite for the classic Mac OS. It required a PowerPC processor. This version introduced Entourage, an e-mail client that included information management tools such as a calendar, an address book, task lists and notes.

Microsoft Office v. X was released in 2001 and was the first version of Microsoft Office for Mac OS X. Support for Office v. X ended on January 9, 2007 after the release of the final update, 10.1.9 Office v.X includes Word X, Excel X, PowerPoint X, Entourage X, MSN Messenger for Mac and Windows Media Player 9 for Mac; it was the last version of Office for Mac to include Internet Explorer for Mac.

Microsoft Office 2004 for Mac was released on May 11, 2004. It includes Microsoft Word, Excel, PowerPoint, Entourage and Virtual PC. It is the final version of Office to be built exclusively for PowerPC and to officially support G3 processors, as its sequel lists a G4, G5 or Intel processor as a requirement. It was notable for supporting Visual Basic for Applications (VBA), which is unavailable in Office 2008. This led Microsoft to extend support for Office 2004 from October 13, 2009 to January 10, 2012. VBA functionality was reintroduced in Office 2011, which is only compatible with Intel processors.

Microsoft Office 2008 for Mac was released on January 15, 2008. It was the only Office for Mac suite to be compiled as a universal binary, being the first to feature native Intel support and the last to feature PowerPC support for G4 and G5 processors, although the suite is unofficially compatible with G3 processors. New features include native Office Open XML file format support, which debuted in Office 2007 for Windows, and stronger Microsoft Office password protection employing AES-128 and SHA-1. Benchmarks suggested that compared to its predecessor, Office 2008 ran at similar speeds on Intel machines and slower speeds on PowerPC machines. Office 2008 also lacked Visual Basic for Applications (VBA) support, leaving it with only 15 months of additional mainstream support compared to its predecessor. Nevertheless, five months after it was released, Microsoft said that Office 2008 was "selling faster than any previous version of Office for Mac in the past 19 years" and affirmed "its commitment to future products for the Mac."

Microsoft Office for Mac 2011 was released on October 26, 2010. It is the first version of Office for Mac to be compiled exclusively for Intel processors, dropping support for the PowerPC architecture. It features an OS X version of Outlook to replace the Entourage email client. This version of Outlook is intended to make the OS X version of Office work better with Microsoft's Exchange server and with those using Office for Windows. Office 2011 includes a Mac-based Ribbon similar to Office for Windows.

Microsoft OneNote for Mac was released on March 17, 2014. It marks the company's first release of the note-taking software on the Mac. It is available as a free download to all users of the Mac App Store in OS X Mavericks.

Microsoft Outlook 2016 for Mac debuted on October 31, 2014. It requires a paid Office 365 subscription, meaning that traditional Office 2011 retail or volume licenses cannot activate this version of Outlook. On that day, Microsoft confirmed that it would release the next version of Office for Mac in late 2015.

Despite dropping support for older versions of OS X and only keeping support for 64-bit-only versions of OS X, these versions of OneNote and Outlook are 32-bit applications like their predecessors.

The first Preview version of Microsoft Office 2016 for Mac was released on March 5, 2015. On July 9, 2015, Microsoft released the final version of Microsoft Office 2016 for Mac which includes Word, Excel, PowerPoint, Outlook and OneNote. It was immediately made available for Office 365 subscribers with either a Home, Personal, Business, Business Premium, E3 or ProPlus subscription. A non–Office 365 edition of Office 2016 was made available as a one-time purchase option on September 22, 2015.

Office Mobile for iPhone was released on June 14, 2013 in the United States. Support for 135 markets and 27 languages was rolled out over a few days. It requires iOS 8 or later. Although the app also works on iPad devices, excluding the first generation, it is designed for a small screen. Office Mobile was released for Android phones on July 31, 2013 in the United States. Support for 117 markets and 33 languages was added gradually over several weeks. It is supported on Android 4.0 and later.

Office Mobile is or was also available, though no longer supported, on Windows Mobile, Windows Phone and Symbian. There was also Office RT, a touch-optimized version of the standard desktop Office suite, pre-installed on Windows RT.

Originally called Office Mobile which was shipped initially as "Pocket Office", was released by Microsoft with the Windows CE 1.0 operating system in 1996. This release was specifically for the Handheld PC hardware platform, as Windows Mobile Smartphone and Pocket PC hardware specifications had not yet been released. It consisted of Pocket Word and Pocket Excel; PowerPoint, Access, and Outlook were added later. With steady updates throughout subsequent releases of Windows Mobile, Office Mobile was rebranded as its current name after the release of the Windows Mobile 5.0 operating system. This release of Office Mobile also included PowerPoint Mobile for the first time. Accompanying the release of Microsoft OneNote 2007, a new optional addition to the Office Mobile line of programs was released as OneNote Mobile. With the release of Windows Mobile 6 Standard, Office Mobile became available for the Smartphone hardware platform, but unlike Office Mobile for the Professional and Classic versions of Windows Mobile, creation of new documents is not an added feature. A popular workaround is to create a new blank document in a desktop version of Office, synchronize it to the device, and then edit and save on the Windows Mobile device.

In June 2007, Microsoft announced a new version of the office suite, Office Mobile 2007. It became available as "Office Mobile 6.1" on September 26, 2007 as a free upgrade download to current Windows Mobile 5.0 and 6 users. However, "Office Mobile 6.1 Upgrade" is not compatible with Windows Mobile 5.0 powered devices running builds earlier than 14847. It is a pre-installed feature in subsequent releases of Windows Mobile 6 devices. Office Mobile 6.1 is compatible with the Office Open XML specification like its desktop counterpart.

On August 12, 2009, it was announced that Office Mobile would also be released for the Symbian platform as a joint agreement between Microsoft and Nokia. It was the first time Microsoft would develop Office mobile applications for another smartphone platform. The first application to appear on Nokia Eseries smartphones was Microsoft Office Communicator. In February 2012, Microsoft released OneNote, Lync 2010, Document Connection and PowerPoint Broadcast for Symbian. In April, Word Mobile, PowerPoint Mobile and Excel Mobile joined the Office Suite.

On October 21, 2010, Microsoft debuted Office Mobile 2010 with the release of Windows Phone 7. In Windows Phone, users can access and edit documents directly off of their SkyDrive or Office 365 accounts in a dedicated Office hub. The Office Hub, which is preinstalled into the operating system, contains Word, PowerPoint and Excel. The operating system also includes OneNote, although not as a part of the Office Hub. Lync is not included, but can be downloaded as standalone app from the Windows Phone Store free of charge.

In October 2012, Microsoft released a new version of Microsoft Office Mobile for Windows Phone 8 and Windows Phone 7.8.

Office Mobile was released for iPhone on June 14, 2013, and for Android phones on July 31, 2013.

In March 2014, Microsoft released Office Lens, a scanner app that enhances photos. Photos are then attached to an Office document. Office Lens is an app in the Windows Phone store, as well as built into the camera functionality in the OneNote apps for iOS and Windows 8.
On March 27, 2014, Microsoft launched Office for iPad, the first dedicated version of Office for tablet computers. In addition, Microsoft made the Android and iOS versions of Office Mobile free for 'home use' on phones, although the company still requires an Office 365 subscription for using Office Mobile for business use. On November 6, 2014, Office was subsequently made free for personal use on the iPad in addition to phones. As part of this announcement, Microsoft also split up its single "Office suite" app on iPhones into separate, standalone apps for Word, Excel and PowerPoint, released a revamped version of Office Mobile for iPhone, added direct integration with Dropbox, and previewed future versions of Office for other platforms.

Office for Android tablets was released on January 29, 2015, following a successful two-month preview period. These apps allow users to edit and create documents for free on devices with screen sizes of 10.1 inches or less, though as with the iPad versions, an Office 365 subscription is required to unlock premium features and for commercial use of the apps. Tablets with screen sizes larger than 10.1 inches are also supported, but, as was originally the case with the iPad version, are restricted to viewing documents only unless a valid Office 365 subscription is used to enable editing and document creation.

On January 21, 2015, during the "Windows 10: The Next Chapter" press event, Microsoft unveiled Office for Windows 10, Windows Runtime ports of the Android and iOS versions of the Office Mobile suite. Optimized for smartphones and tablets, they are universal apps that can run on both Windows and Windows for phones, and share similar underlying code. A simplified version of Outlook was also added to the suite. They will be bundled with Windows 10 mobile devices, and available from the Windows Store for the PC version of Windows 10. Although the preview versions were free for most editing, the release versions will require an Office 365 subscription on larger tablets (screen size larger than 10.1 inches) and desktops for editing, as with large Android tablets. Smaller tablets and phones will have most editing features for free.

On June 24, 2015, Microsoft released Word, Excel and PowerPoint as standalone apps on Google Play for Android phones, following a one-month preview. These apps have also been bundled with Android devices from major OEMs, as a result of Microsoft tying distribution of them and Skype to patent-licensing agreements related to the Android platform. The Android version is also supported on certain Chrome OS machines.

On February 19, 2020, Microsoft announced a new unified Office mobile app for Android and iOS. This app combines Word, Excel, and PowerPoint into a single app and introduces new capabilities as making quick notes, signing PDFs, scanning QR codes, and transferring files.

Office Web Apps was first revealed on October 2008 at PDC 2008 in Los Angeles. Chris Capossela, senior vice president of Microsoft business division, introduced Office Web Apps as lightweight versions of Word, Excel, PowerPoint and OneNote that allow people to create, edit and collaborate on Office documents through a web browser. According to Capossela, Office Web Apps was to become available as a part of Office Live Workspace. Office Web Apps was announced to be powered by AJAX as well as Silverlight; however, the latter is optional and its availability will only "enhance the user experience, resulting in sharper images and improved rendering." Microsoft's Business Division President Stephen Elop stated during PDC 2008 that "a technology preview of Office Web Apps would become available later in 2008". However, the Technical Preview of Office Web Apps was not released until 2009.

On July 13, 2009, Microsoft announced at its Worldwide Partners Conference 2009 in New Orleans that Microsoft Office 2010 reached its "Technical Preview" development milestone and features of Office Web Apps were demonstrated to the public for the first time. Additionally, Microsoft announced that Office Web Apps would be made available to consumers online and free of charge, while Microsoft Software Assurance customers will have the option of running them on premises. Office 2010 beta testers were not given access to Office Web Apps at this date, and it was announced that it would be available for testers during August 2009. However, in August 2009, a Microsoft spokesperson stated that there had been a delay in the release of Office Web Apps Technical Preview and it would not be available by the end of August.

Microsoft officially released the Technical Preview of Office Web Apps on September 17, 2009. Office Web Apps was made available to selected testers via its OneDrive (at the time Skydrive) service. The final version of Office Web Apps was made available to the public via Windows Live Office on June 7, 2010.

On October 22, 2012, Microsoft announced the release of new features including co-authoring, performance improvements and touch support.

On November 6, 2013, Microsoft announced further new features including "real-time" co-authoring and an Auto-Save feature in Word (replacing the save button).

In February 2014, Office Web Apps were re-branded Office Online and incorporated into other Microsoft web services, including Calendar, OneDrive, Outlook.com, and People. Microsoft had previously attempted to unify its online services suite (including Microsoft Passport, Hotmail, MSN Messenger, and later SkyDrive) under a brand known as Windows Live, first launched in 2005. However, with the impending launch of Windows 8 and its increased use of cloud services, Microsoft dropped the Windows Live brand to emphasize that these services would now be built directly into Windows and not merely be a "bolted on" add-on. Critics had criticized the Windows Live brand for having no clear vision, as it was being applied to an increasingly broad array of unrelated services. At the same time, Windows Live Hotmail was re-launched as Outlook.com (sharing its name with the Microsoft Outlook personal information manager).

In July 2019, Microsoft announced that they were retiring the "Online" branding for Office Online. The product is now Office, and may be referred to as "Office for the web" or "Office in a browser".



</doc>
<doc id="20289" url="https://en.wikipedia.org/wiki?curid=20289" title="MultiMate">
MultiMate

MultiMate was a word processor developed by Multimate International for IBM PC MS-DOS computers in the early 1980s.

With 1,000 computers, Connecticut Mutual Life Insurance was one of the first large-volume customers for the IBM PC. It hired W. H. Jones & Associates to write word-processing software for the computer that would not require retraining its employees, already familiar with Wang Laboratories word processing systems. W. H. Jones' head Will Jones and five other developers created the software. W. H. Jones retained the right to sell the program elsewhere, and WordMate appeared in December 1982. The company renamed itself to SoftWord Systems, then Multimate International, while renaming WordMate to MultiMate. Advertisements stated that MultiMate "mimic[ked] the features and functions of a dedicated system", and that it was "modeled after the Wang word processor". Like Connecticut Mutual, many customers purchased it because of the similarity with the Wang.

MultiMate was not marketed heavily to end-users, but was quickly popular with insurance companies, law firms, other business computer users and US government agencies and the military. While the Wang WP keyboard was different from the original PC keyboard, MultiMate compensated by providing a large plastic template that clipped on the PC keyboard, and stick-on labels for the fronts of the PC keys. The template and labels color-coded the combination keystrokes using the SHIFT, ALT and CTRL keys with all 10 of the PC's function keys and many of the character keys. Like Wang systems, MultiMate controlled most editing operations with function keys, assigning four functions to each of the 10 function keys, which IBM initially located at the left side of the keyboard in two vertical rows. It also included a "document summary" screen for each document, another Wang feature, which allowed more sophisticated document-management than the brief file names allowed by MS-DOS and PC DOS. As function selection through key-controlled screen-top drop-down menus was popularized by other programs, MultiMate added menus.

MultiMate's popularity rapidly grew. In January 1983 some employees were paid late because of slow sales, but two months later revenue grew 25-fold after good reviews appeared in magazines. The company's fiscal 1984 sales were $15 million or more, and by early 1985 MultiMate's installed base in companies was as large as former market leader WordStar's. Jones sold the company to Ashton-Tate in December 1985 for about $20 million. an Ashton-Tate press release called the acquisition "the largest ever in the microcomputer software industry".

Other MultiMate products included foreign language versions of the software (i.e., "MultiTexto" in Spanish), a hardware interface card for file-transfer with Wang systems and versions of MultiMate for different PC clone MS-DOS computers, and for use on Novell, 3COM and IBM's PC Token Ring networks. Early attempts to create a MultiMate Data Manager and List Manager in-house never reached the market.

Multimate International developed the core word processing software and utilities (file conversion, printer drivers), but purchased and adapted sub-programs for spelling and grammar checking, list management, outlining and print-time incorporation of graphics in word processing documents (MultiMate GraphLink). In addition to rebranding such externally developed programs, Multimate rewrote the documentation for each program and adapted the program interfaces to more closely resemble the word processor. The last version of MultiMate was packaged with many of these add-on programs under the product name "MultiMate Advantage" to compete with other word processor software of the day, especially IBM DisplayWrite for DOS, which Multimate International developers saw as their main competition in the business market, and to a lesser extent WordPerfect, the DOS incarnation of Microsoft Word and the Samna word processor, which had its roots in another office word processing computer.

One of the first "clone" versions of MultiMate was bundled with an early portable PC made by Corona. Other versions were written to match PCs by Radio Shack, Texas Instruments, Toshiba, the early Grid laptop and the IBM PC Junior.

The detailed MultiMate word processor documentation, which quickly grew to three volumes, gave the product a solid "office production" feel, using high-quality paper with its main reference section presented in a padded binder with fold-out easel. (A company legend was that the MultiMate user manual was written first, by an experienced Wang WP manager, then the programmers were told to write software to match it, which is how the Wang WP was created.)

Early versions of the program came with both color-coded key stickers and a plastic full-keyboard template to make Wang operators more comfortable with the smaller IBM PC keyboard. MultiMate eventually sold a hardware keyboard with dedicated function keys and issued versions of its software for networked PCs. It adapted list-management, graphics and outlining software from other vendors to the look-and-feel of MultiMate, shipping the expanded version as MultiMate Advantage, with additional volumes of MultiMate-style documentation for the add-on programs.

Early releases of MultiMate also gave users unlimited access to a toll-free support number and a promise of low-cost upgrades, which contributed to its dedicated user population. Support policies later were brought in line with Ashton-Tate's standard practices.

MultiMate was especially good at supporting a variety of PC clones and hundreds of computer printers, each of which required its own printer driver. Such printer support was very strong with daisy-wheel and dot-matrix printers, but did not take much advantage of the development of PostScript fonts and laser printers.

Ashton-Tate never released a Windows version. It discontinued MultiMate's development efforts on VMS and Unix platforms and closed a development group in Dublin, Ireland. The product was dropped after the company was purchased by Borland.

"PC Magazine" in February 1983 stated that MultiMate "virtually remakes your computer into a Wang-like dedicated word processor", and that it was "very fast, easy to learn, and capable" with many features. The review noted the application's inability to use more than 128K of RAM, but praised the documentation and built-in help, and stated that many commands required half the keystrokes of the WordStar equivalent. The review concluded "MultiMate stands head and shoulders above many if not most [IBM PC word processors] ... an impressive entrant".

"BYTE" in 1984 was less positive. It described version 3.20 as being "very safe" because of many backups and safeguards and praised the formatting features, customization ability, and quality of the (very busy) toll-free help line. The review, however, called MultiMate "the klunkiest package" of five tested word processors because of the overemphasis on safety, criticized the built-in help and slow performance, and reported being unable to use the spell checker because of its poor quality.



</doc>
<doc id="20290" url="https://en.wikipedia.org/wiki?curid=20290" title="Mohammad Najibullah">
Mohammad Najibullah

Najibullah Ahmadzai (Pashto/; 6 August 1947 – 27 September 1996), commonly known as Najibullah or Dr. Najib, was the President of Afghanistan from 1987 until his resignation in April 1992, shortly after which the mujahideen took over Kabul. After a failed attempt to flee to India, Najibullah remained in Kabul living in the United Nations headquarters until his death at the hands of the Taliban after their capture of the city.

A graduate of Kabul University, Najibullah held different careers under the People's Democratic Party of Afghanistan (PDPA). Following the Saur Revolution and the establishment of the Democratic Republic of Afghanistan, Najibullah was a low profile bureaucrat: he was sent into exile as Ambassador to Iran during Hafizullah Amin's rise to power. He returned to Afghanistan following the Soviet intervention which toppled Amin's rule and placed Babrak Karmal as head of state, party and government. During Karmal's rule, Najibullah became head of the KHAD, the Afghan equivalent of the Soviet KGB. He was a member of the Parcham faction led by Karmal. During Najibullah's tenure as KHAD head, it became one of the most brutally efficient governmental organs. Because of this, he gained the attention of several leading Soviet officials, such as Yuri Andropov, Dmitriy Ustinov and Boris Ponomarev. In 1981, Najibullah was appointed to the PDPA Politburo. In 1985 Najibullah stepped down as state security minister to focus on PDPA politics; he had been appointed to the PDPA Secretariat. Mikhail Gorbachev, the last Soviet leader, was able to get Karmal to step down as PDPA General Secretary in 1986, and replace him with Najibullah. For a number of months Najibullah was locked in a power struggle against Karmal, who still retained his post of Chairman of the Revolutionary Council. Najibullah accused Karmal of trying to wreck his policy of National Reconciliation, which were a series of efforts by Najibullah to end the conflict.

During his tenure as leader of Afghanistan, the Soviets began their withdrawal, and from 1989 until 1992, his government tried to solve the ongoing civil war without Soviet troops on the ground. While direct Soviet assistance ended with the withdrawal, the Soviet Union still supported Najibullah with economic and military aid, while Pakistan and the United States continued its support for the mujahideen. Throughout his tenure, he tried to build support for his government via the National Reconciliation reforms by distancing from socialism in favor of Afghan nationalism, abolishing the one-party state and letting non-communists join the government. He remained open to dialogue with the mujahideen and other groups, made Islam an official religion, and invited exiled businessmen back to re-take their properties. In the 1990 constitution all references to communism were removed and Islam became the state religion. For various reasons such changes did not win Najibullah any significant support. With the dissolution of the Soviet Union in December 1991, Najibullah was left without foreign aid. This, coupled with the internal collapse of his government, led to his resignation in April 1992. Although feared at the time as head of the intelligence, by the 21st century public opinion turned positive and he is now seen to have been a strong and patriotic leader with a "normal" regime compared to his PDPA predecessors and the mayhem that happened after his ousting. In 2017 a pro-Najibist "Watan Party" was created as a continuation of Najibullah's party.

Najibullah was born on 6 August 1947 in the city of Gardez, Paktia Province, in the Kingdom of Afghanistan. His ancestral village is located between the towns of Gardez and Said Karam in Paktia Province; this place is known as Mehlan. He belonged to the Ahmadzai Ghilji tribe of Pashtuns.

He was educated at Habibia High School in Kabul, at St. Joseph's School in Baramulla, Jammu and Kashmir, India, and at Kabul University, where he began studying in 1964 and completed his Bachelor of Medicine, Bachelor of Surgery (MBBS) in 1975. However, he never practiced medicine. In 1965, during his study in Kabul, Najibullah joined the Parcham (Banner) faction of the People's Democratic Party of Afghanistan (PDPA) and was twice imprisoned for political activities. He served as Babrak Karmal's close associate and bodyguard during the latter's tenure in the lower house of parliament (1965–1973). In 1977 he was elected to the Central Committee. In April 1978, the PDPA took power in Afghanistan, with Najibullah a member of the ruling Revolutionary Council. However, the Khalq (People's) faction of the PDPA gained supremacy over his own Parcham (Banner) faction, and after a brief stint as Ambassador to Iran, he was dismissed from government and went into exile in Europe, until the Soviet Union intervened in 1979 and supported a Parcham-dominated government.

In 1980, Najibullah was appointed the head of KHAD, the Afghan equivalent to the Soviet KGB, and was promoted to the rank of Major General. He was appointed following lobbying made by the Soviets, most notable among them was Yuri Andropov, the KGB Chairman. During his six years as head of KHAD he had two to four deputies under his command, who in turn were responsible for an estimated 12 departments. According to evidence, Najibullah was dependent on his family and his professional network, and appointed more often than not people he knew to top positions within the KHAD. In June 1981, Najibullah, along with Mohammad Aslam Watanjar, a former tank commander and the then Minister of Communications and Major General Mohammad Rafi, the Minister of Defence were appointed to the PDPA Politburo. Under Najibullah, KHAD's personnel increased from 120 to 25,000 to 30,000. KHAD employees were amongst the best-paid government bureaucrats in communist Afghanistan, and because of it, the political indoctrination of KHAD officials was a top priority. During a PDPA conference Najibullah, talking about the indoctrination programme of KHAD officials, said "a weapon in one hand, a book in the other." Terrorist activities launched by KHAD reached its peak under Najibullah. He reported directly to the Soviet KGB, and a big part of KHAD's budget came from the Soviet Union itself.

As time would show, Najibullah was very efficient, and during his tenure as leader of KHAD, thousands were arrested, tortured, and executed. There are first-hand accounts of survivors who stated that Najibullah would personally participate in the torture of high-profile anti-communist citizens. KHAD targeted anti-communist citizens, political opponents, and educated members of society. It was this efficiency which made him interesting to the Soviets. Because of this, KHAD became known for its ruthlessness. During his ascension to power, several Afghan politicians did not want Najibullah to succeed Babrak Karmal because of the fact that Najibullah was known for exploiting his powers for his own benefit. It didn't help either that during his period as KHAD chief that the Pul-i Charki had become the home of several Khalqist politicians. Another problem was that Najibullah allowed graft, theft, bribery and corruption on a scale not seen previously. As would later be proven by the power struggle he had with Karmal after becoming PDPA General Secretary, despite Najibullah heading the KHAD for five years, Karmal still had sizable support in the organisation.

He was appointed to the PDPA Secretariat in November 1985. Najibullah's ascent to power was proven by turning KHAD from a government organ to a ministry in January 1986. With the situation in Afghanistan deteriorating, and the Soviet leadership looking for ways to withdraw, Mikhail Gorbachev wanted Karmal to resign as PDPA General Secretary. The question of who was to succeed Karmal was hotly debated, but Gorbachev supported Najibullah. Yuri Andropov, Boris Ponomarev and Dmitriy Ustinov all thought highly of Najibullah, and negotiations of who would succeed Karmal might have begun as early as 1983. Despite this, Najibullah was not the only choice the Soviets had. A GRU report argued that he was a Pashtun nationalist, a stance which could decrease the regime's popularity even more. The GRU preferred Assadullah Sarwari, earlier head of ASGA, the pre-KHAD secret police, who they believed would be better able to balance between the Pashtuns, Tajiks and Uzbeks. Another viable candidate was Abdul Qadir, who had been a participant in the Saur Revolution. Najibullah succeeded Karmal as PDPA General Secretary on 4 May 1986 at the 18th PDPA meeting, but Karmal still retained his post as Chairman of the Presidium of the Revolutionary Council.

On 15 May Najibullah announced that a collective leadership had been established, which was led by himself consisted of himself as head of party, Karmal as head of state and Sultan Ali Keshtmand as Chairman of the Council of Ministers. When Najibullah took the office of PDPA General Secretary, Karmal still had enough support in the party to disgrace Najibullah. Karmal went as far as to spread rumours that Najibullah's rule was little more than an interregnum, and that he would soon be reappointed to the general secretaryship. As it turned out, Karmal's power base during this period was KHAD. The Soviet leadership wanted to ease Karmal out of politics, but when Najibullah began to complain that he was hampering his plans of National Reconciliation, the Soviet Politburo decided to remove Karmal; this motion was supported by Andrei Gromyko, Yuli Vorontsov, Eduard Shevardnadze, Anatoly Dobrynin and Viktor Chebrikov. A meeting in the PDPA in November relieved Karmal of his Revolutionary Council chairmanship, and he was exiled to Moscow where he was given a state-owned apartment and a dacha. In his position as Revolutionary Council chairman Karmal was succeeded by Haji Mohammad Chamkani, who was not a member of the PDPA.

In 1986 there were more than 100,000 political prisoners and there had been more than 16,500 extrajudicial executions. Its main objectives were the opponents of communism and the most educated classes in society.

In September 1986 the National Compromise Commission (NCC) was established on the orders of Najibullah. The NCC's goal was to contact counter-revolutionaries "in order to complete the Saur Revolution in its new phase." Allegedly, an estimated 40,000 rebels were contacted by the government. At the end of 1986, Najibullah called for a six-months ceasefire and talks between the various opposition forces, this was part of his policy of National Reconciliation. The discussions, if fruitful, would lead to the establishment of a coalition government and be the end of the PDPA's monopoly of power. The programme failed, but the government was able to recruit disillusioned mujahideen fighters as government militias. In many ways, the National Reconciliation led to an increasing number of urban dwellers to support his rule, and the stabilisation of the Afghan defence forces.

In September 1986 a new constitution was written, which was adopted on 29 November 1987. The constitution weakened the powers of the head of state by canceling his absolute veto. The reason for this move, according to Najibullah, was the need for real-power sharing. On 13 July 1987 the official name of Afghanistan was changed from the Democratic Republic of Afghanistan to Republic of Afghanistan, and in June 1988 the Revolutionary Council, whose members were elected by the party leadership, was replaced by a National Assembly, an organ in which members were to be elected by the people. The PDPA's socialist stance was denied even more than previously, in 1989 the Minister of Higher Education began to work on the "de-Sovietisation" of universities, and in 1990 it was even announced by a party member that all PDPA members were Muslims and that the party had abandoned Marxism. Many parts of the Afghan government's economic monopoly was also broken, this had more to do with the tight situation than any ideological conviction. Abdul Hakim Misaq, the Mayor of Kabul, even stated that traffickers of stolen goods would not be prosecuted by law as long as their goods were given to the market. Yuli Vorontsov, on Gorbachev's orders, was able to get an agreement with the PDPA leadership to offer the posts of Gossoviet chairman (the state planning organ), the Council of Ministers chairmanship (head of government), ministries of defence, state security, communications, finance, presidencies of banks and the Supreme Court. The PDPA still demanded it held on to all deputy ministers, retained its majority in the state bureaucracy and that it retained all its provincial governors. The government was not willing to concede all of these positions, and when the offer was broadcast, the ministries of defence and state security.

Local elections were held in 1987. It began when the government introduced a law permitting the formation of other political parties, announced that it would be prepared to share power with representatives of opposition groups in the event of a coalition government, and issued a new constitution providing for a new bicameral National Assembly (Meli Shura), consisting of a Senate (Sena) and a House of Representatives (Wolesi Jirga), and a president to be indirectly elected to a 7-year term. The new political parties had to oppose colonialism, imperialism, neo-colonialism, Zionism, racial discrimination, apartheid and fascism. Najibullah stated that only the extremist part of the opposition could not join the planned coalition government. No parties had to share the PDPA's policy or ideology, but they could not oppose the bond between Afghanistan and the Soviet Union. A parliamentary election was held in 1988. The PDPA won 46 seats in the House of Representatives and controlled the government with support from the National Front, which won 45 seats, and from various newly recognized left-wing parties, which had won a total of 24 seats. Although the election was boycotted by the Mujahideen, the government left 50 of the 234 seats in the House of Representatives, as well as a small number of seats in the Senate, vacant in the hope that the guerrillas would end their armed struggle and participate in the government. The only armed opposition party to make peace with the government was Hizbollah, a small Shi'a party not to be confused with the bigger party in Iran or the Lebanese organization.

Several figures of the intelligentsia took Najibullah's offer seriously, even if they sympathised or were against the regime. Their hopes were dampened when the Najibullah government introduced the state of emergency on 18 February 1989, four days after the Soviet withdrawal. 1,700 intellectuals were arrested in February alone, and until November 1991 the government still supervised and restricted freedom of speech. Another problem was that party members took his policy seriously too, Najibullah recanted that most party members felt "panic and pessimism." At the Second Conference of the party, the majority of members, maybe up to 60 percent, were radical socialists. According to Soviet advisors (in 1987), a bitter debate within the party had broken out between those who advocated the islamisation of the party and those who wanted to defend the gains of the Saur Revolution. Opposition to his policy of National Reconciliation was met party-wide, but especially from Karmalists. Many people did not support the handing out of the already small state resources the Afghan state had at its disposal. On the other side, several members were proclaiming anti-Soviet slogans as they accused the National Reconciliation programme to be supported and developed by the Soviet Union. Najibullah reassured the inter-party opposition that he would not give up the gains of the Saur Revolution, but to the contrary, preserve them, not give up the PDPA's monopoly on power, or to collaborate with reactionary Mullahs.

During Babrak Karmal's later years, and during Najibullah's tenure, the PDPA tried to improve their standing with Muslims by moving, or appearing to move, to the political centre. They wanted to create a new image for the party and state. In 1987 Najibullah re-added Ullah to his name to appease the Muslim community. Communist symbols were either replaced or removed. These measures did not contribute to any notable increase in support for the government, because the mujahideen had a stronger legitimacy to protect Islam than the government; they had rebelled against what they saw as an anti-Islamic government, that government was the PDPA. Islamic principles were embedded in the 1987 constitution, for instance, Article 2 of the constitution stated that Islam was the state religion, and Article 73 stated that the head of state had to be born into a Muslim Afghan family. The 1990 constitution stated that Afghanistan was an Islamic state, and the last references to communism were removed. Article 1 of the 1990 Constitution said that Afghanistan was an "independent, unitary and Islamic state."

Najibullah continued Karmal's economic policies. The augmenting of links with the Eastern Bloc and the Soviet Union continued, and so did bilateral trade. He encouraged the development of the private sector in industry. The Five-Year Economic and Social Development Plan which was introduced in January 1986 continued until March 1992, one month before the government's fall. According to the plan, the economy, which had grown less than 2 percent annually until 1985, would grow 25 percent in the plan. Industry would grow 28 percent, agriculture 14–16 percent, domestic trade by 150 percent and foreign trade with 15 percent. As expected, none of these targets were met, and 2 percent growth annually which had been the norm before the plan continued under Najibullah. The 1990 constitution gave due attention to the private sector. Article 20 was about the establishment of private firms, and Article 25 encouraged foreign investments in the private sector.

While he may have been the "de jure" leader of Afghanistan, Soviet advisers still did the majority of work when Najibullah took power. As Gorbachev remarked "We're still doing everything ourselves [...]. That's all our people know how to do. They've tied Najibullah hand and foot." Fikryat Tabeev, the Soviet ambassador to Afghanistan, was accused of acting like a governor general by Gorbachev. Tabeev was recalled from Afghanistan in July 1986, but while Gorbachev called for the end of Soviet management of Afghanistan, he could not help but to do some managing himself. At a Soviet Politburo meeting, Gorbachev said "It's difficult to build a new building out of old material [...] I hope to God that we haven't made a mistake with Najibullah." As time would prove, the problem was that Najibullah's aims were the opposite of the Soviet Union's; Najibullah was opposed to a Soviet withdrawal, the Soviet Union wanted a Soviet withdrawal. This was logical, considering the fact that the Afghan military was on the brink of dissolution. The only means of survival seemed to Najibullah was to retain the Soviet presence. In July 1986 six regiments, which consisted up to 15,000 troops, were withdrawn from Afghanistan. The aim of this early withdrawal was, according to Gorbachev, to show the world that the Soviet leadership was serious about leaving Afghanistan. The Soviets told the United States Government that they were planning to withdraw, but the United States Government didn't believe it. When Gorbachev met with Ronald Reagan during his visit the United States, Reagan called for the dissolution of the Afghan army.

On 14 April 1988 the Afghan and Pakistani governments signed the Geneva Accords, and the Soviet Union and the United States signed as guarantors; the treaty specifically stated that the Soviet military had to withdraw from Afghanistan by 15 February 1989. Gorbachev later confided to Anatoly Chernyaev, a personal advisor to Gorbachev, that the Soviet withdrawal would be criticised for creating a bloodbath which could have been averted if the Soviets stayed. During a Politburo meeting Eduard Shevardnadze said "We will leave the country in a deplorable situation", and further talked about the economic collapse, and the need to keep at least 10 to 15,000 troops in Afghanistan. In this Vladimir Kryuchkov, the KGB Chairman, supported him. This stance, if implemented, would be a betrayal of the Geneva Accords just signed. During the second phase of the Soviet withdrawal, in 1989, Najibullah told Valentin Varennikov openly that he would do everything to slow down the Soviet departure. Varennikov in turn replied that such a move would not help, and would only lead to an international outcry against the war. Najibullah would repeat his position later that year, to a group of senior Soviet representatives in Kabul. This time Najibullah stated that Ahmad Shah Massoud was the main problem, and that he needed to be killed. In this, the Soviets agreed, but repeated that such a move would be a breach of the Geneva Accords; to hunt for Ahmad Shah Massoud so early on would disrupt the withdrawal, and would mean that the Soviet Union would fail to meet its deadline for withdrawal.

During his January 1989 visit to Shevardnadze Najibullah wanted to retain a small presence of Soviet troops in Afghanistan, and called for moving Soviet bombers to military bases close to the Afghan–Soviet border and place them on permanent alert. Najibullah also repeated his claims that his government could not survive if Ahmad Shah Massoud remained alive. Shevardnadze again repeated that troops could not stay, since it would lead to international outcry, but said he would look into the matter. Shevardnadze demanded that the Soviet embassy created a plan in which at least 12,000 Soviet troops would remain in Afghanistan either under direct control of the United Nations or remain as "volunteers". The Soviet military leadership, when hearing of Shevardnadze's plan, became furious. But they followed orders, and named the operation "Typhoon", maybe ironic considering that Operation Typhoon was the German military operation against the city of Moscow during World War II. Shevardnadze contacted the Soviet leadership about moving a unit to break the siege of Kandahar, and to protect convoys from and to the city. The Soviet leadership were against Shevardnadze's plan, and Chernyaev even believed it was part of Najibullah's plan to keep Soviet troops in the country. To which Shevardnadze replied angrily "You've not been there, [...] You've no idea all the things we have done there in the past ten years." At a Politburo meeting on 24 January, Shevardnadze argued that the Soviet leadership could not be indifferent to Najibullah and his government; again, Shevardnadze received support from Kryuchkov. In the end Shevardnadze lost the debate, and the Politburo reaffirmed their commitment to withdraw from Afghanistan. There was still a small presence of Soviet troops after the Soviet withdrawal; for instance, parachutists who protected the Soviet embassy staff, military advisors and special forces and reconnaissance troops still operated in the "outlying provinces", especially along the Afghan–Soviet border.

Soviet military aid continued after their withdrawal, and massive quantities of food, fuel, ammunition and military equipment was given to the government. Varennikov visited Afghanistan in May 1989 to discuss ways and means to deliver the aid to the government. In 1990 Soviet aid amounted to an estimated 3 billion United States dollars. As it turned out, the Afghan military was entirely dependent on Soviet aid to function. When the Soviet Union was dissolved on 26 December 1991, Najibullah turned to former Soviet Central Asia for aid. These newly independent states had no wish to see Afghanistan being taken over by religious fundamentalists, and supplied Afghanistan with 6 million barrels of oil and 500,000 tons of wheat to survive the winter.

With the Soviets' withdrawal in 1989, the Afghan army was left on its own to battle the insurgents. The most effective, and largest, assaults on the mujahideen were undertaken during the 1985–86 period. These offensives had forced the mujahideen on the defensive near Herat and Kandahar. The Soviets ensued a bomb and negotiate during 1986, and a major offensive that year included 10,000 Soviet troops and 8,000 Afghan troops.

The Pakistani people and establishment continued to support the Afghan mujahideen even if it was in contravention of the Geneva Accords. At the beginning most observers expected the Najibullah government to collapse immediately, and to be replaced with an Islamic fundamentalist government. The Central Intelligence Agency stated in a report that the new government would be ambivalent, or even worse, hostile towards the United States. Almost immediately after the Soviet withdrawal, the Battle of Jalalabad broke out between Afghan government forces and the mujahideen, in cooperation with Pakistan's Inter-Service Intelligence (ISI). The offensive against the city began when the mujahideen bribed several government military officers, from there, they tried to take the airport, but were repulsed with heavy casualties. The willingness of the common Afghan government soldier to fight increased when the mujahideen began to execute people during the battle. Hamid Gul, leader of the ISI, hoped that the battle would topple Najibullah's government and create a mujahideen government seated in Jalalabad. During the battle Najibullah called for Soviet assistance. Gorbachev called an emergency session of the Politburo to discuss his proposal, but Najibullah's request was rejected. Other attacks against the city failed, and by April the government forces were on the offensive. During the battle over four hundred Scud missiles were shot, which were fired by a Soviet crew which had stayed behind. When the battle ended in July, the mujahideen had lost an estimated 3,000 troops. One mujahideen commander lamented "the battle of Jalalabad lost us credit won in ten years of fighting." After the mujahideen's defeat in Jalalabad, Gul blamed the administration of Pakistani Prime Minister Benazir Bhutto for the defeat. Bhutto eventually sacked Gul.

Hardline Khalqist Shahnawaz Tanai attempted to overthrow Najibullah in a failed coup attempt in March 1990. Although Tanai and his forces failed and fled to Pakistan, the coup attempt still managed to show weaknesses in Najibullah's government.

From 1989 to 1990, the Najibullah government was partially successful in building up the Afghan defence forces. The Ministry of State Security had established a local militia force which stood at an estimated 100,000 men. The 17th Division in Herat, which had begun the 1979 Herat uprising against PDPA-rule, stood at 3,400 regular troops and 14,000 tribal men. In 1988, the total number of security forces available to the government stood at 300,000. This trend did not continue, and by the summer of 1990, the Afghan government forces were on the defensive again. By the beginning of 1991, the government controlled only 10 percent of Afghanistan, the eleven-year Siege of Khost had ended in a mujahideen victory and the morale of the Afghan military finally collapsed. In the Soviet Union, Kryuchkov and Shevardnadze had both supported continuing aid to the Najibullah government, but Kryuchkov had been arrested following the failed 1991 Soviet coup d'état attempt and Shevardnadze had resigned from his posts in the Soviet government in December 1990 – there were no longer any pro-Najibullah people in the Soviet leadership and the Soviet Union was in the middle of an economic and political crisis, which would lead directly to the dissolution of the Soviet Union on 26 December 1991. At the same time Boris Yeltsin became Russia's new hope, and he had no wish to continue to aid Najibullah's government, which he considered a relic of the past. In the autumn of 1991, Najibullah wrote to Shevardnadze "I didn't want to be president, you talked me into it, insisted on it, and promised support. Now you are throwing me and the Republic of Afghanistan to its fate."

In January 1992, the Russian government ended its aid to the Najibullah government. The effects were felt immediately: the Afghan Air Force, the most effective part of the Afghan military, was grounded due to lack of fuel. The Afghan mujahideen continued to be supported by Pakistan and establishment. Major cities were lost to the rebels, and terrorist attacks became common in Kabul. On the fifth anniversary of his policy of National Reconciliation, Najibullah blamed the Soviet Union for the disaster that had stricken Afghanistan. The day the Soviet Union withdrew was hailed by Najibullah as the Day of National Salvation. But it was too late, and his government's collapse was imminent.

On March 18, 1992, Najibullah offered his government's immediate resignation, and followed the United Nations (UN) plan to be replaced by an interim government with all parties involved in the struggle. The announcement daunted his supporters and led to many territories surrendering to the mujahideen without resistance. In mid-April Najibullah accepted a UN plan to hand power to a seven-man council, and several days later on 14 April, Najibullah was forced to resign on the orders of the Watan Party because of the loss of Bagram Airbase and the town of Charikar. Abdul Rahim Hatef became acting head of state following Najibullah's resignation. The mujahideen forces took Kabul shortly thereafter and most of them signed the Peshawar Accord, creating the new Islamic State of Afghanistan.

Not long before Kabul's fall, Najibullah appealed to the UN for amnesty, which he was granted. But his attempt to flee to the airport was thwarted by troops of Abdul Rashid Dostum - once loyal to him, but now allied with Ahmad Shah Massoud - who controlled the airport. At the UN compound in Kabul, while waiting for the UN to negotiate his safe passage to India, he engaged himself in translating Peter Hopkirk's book "The Great Game" into his mother tongue Pashto. India was at a difficult position in deciding to allow Najibullah political asylum and safely escort him out of the country. Supporters claimed he had always been close to India and should not be denied asylum, but others said doing so would risk antagonizing India's relationship with the new mujahideen government formed under the Peshawar Accord.

India also refused to let him take refuge at the Indian embassy as it risked creating "subcontinental rivalries" and reprisals against Kabul's Indian community, arguing that Najibullah would be far safer at the UN compound. All attempts failed and he eventually sought haven in the local UN headquarters, where he would stay until 1996. In 1994, India sent senior diplomat M. K. Bhadrakumar to Kabul to hold talks with Ahmad Shah Massoud, the defence minister, to consolidate relations with the Afghan authorities, reopen the embassy, and allow Najibullah to fly to India, but Massoud refused. Bhadrakumar wrote in 2016 that he believed Massoud did not want Najibullah to leave as Massoud could strategically make use of him, and that Massoud "probably harboured hopes of a co-habitation with Najib somewhere in the womb of time because that extraordinary Afghan politician was a strategic asset to have by his side". At the time, Massoud was commanding the government's forces fighting the militias of Dostum and Gulbuddin Hekmatyar during the Battle of Kabul. A few months before his death, he quoted, "Afghans keep making the same mistake," reflecting upon his translation to a visitor.

In September 1996, when the Pakistan-backed Taliban were about to enter Kabul, Massoud offered Najibullah an opportunity to flee the capital. Najibullah refused. The reasons as to why he refused remain unclear. Massoud himself has claimed that Najibullah feared that "if he fled with the Tajiks, he would be for ever damned in the eyes of his fellow Pashtuns." Others, like general Tokhi, who was with Dr. Najibullah until the day before his torture and execution, have stated that Najibullah mistrusted Massoud after his militia had repeatedly put the UN compound under rocket fire and had effectively barred Najibullah from leaving Kabul. "If they wanted Najibullah to flee Kabul in safety," Tokhi said, "they could have provided him the opportunity as they did with other high ranking officials from the communist party from 1992 to 1996." Thus when Massoud's militia came to both Dr. Najibullah and General Tokhi and asked them to come with them to flee Kabul, they rejected the offer.

Najibullah was at the UN compound when the Taliban soldiers came for him on the evening of 26 September 1996. The Taliban abducted him from UN custody and tortured him to death, and then dragged his dead, castrated body behind a truck through the streets of Kabul. His brother, Ahmadzai, was given the same treatment. Najibullah and Ahmadzai's bodies were hanged from a traffic light pole outside the Arg presidential palace the next day in order to show the public that a new era had begun. The Taliban prevented Islamic funeral prayers for Najibullah and Ahmadzai in Kabul, but the bodies were later handed over to the International Committee of the Red Cross who in turn sent their bodies to Gardez in Paktia Province, where both of them were buried after the Islamic funeral prayers for them by their fellow Ahmadzai tribesmen.

There was widespread international condemnation,<ref name="un-51/108">"Situation of human rights in Afghanistan" United Nations Resolution 51/108, Article 10. 12 December 1996. Retrieved 15 June 2015 ""Endorses the Special Rapporteur's condemnation of the abduction from United Nations premises of the former President of Afghanistan, Mr. Najibullah, and of his brother, and of their subsequent summary execution;""</ref> particularly from the Muslim world. The United Nations issued a statement which condemned the execution of Najibullah, and claimed that it would further destabilise Afghanistan. The Taliban responded by issuing death sentences on Dostum, Massoud and Burhanuddin Rabbani. India, which had been supporting Najibullah, strongly condemned his public execution and began to support Massoud's United Front/Northern Alliance in an attempt to contain the rise of the Taliban.

On the 20th anniversary of his death, in 2016, Afghanistan's Research Center blamed the Pakistani Inter-Services Intelligence (ISI) for his death, saying that the plan to kill Najibullah was implemented by the ISI through the Taliban they backed.

On 1 June 2020, following a visit to his grave in Gardez by the Afghan National Security Advisor Hamdullah Mohib, Najibullah's widow Fatana Najib said that before constructing a mausoleum for him, the government should first investigate his assassination.

After Najibullah's death, the brutal civil war between mujahideen factions, the hardline Taliban regime, continued fighting, and enduring problems with corruption and poverty, his image among the Afghan people dramatically improved, and Najibullah came to be seen as a strong and patriotic leader. Since the 2010s, posters and pictures of him have become a common sight in many Afghan cities.

In 1997, the Watan Party of Afghanistan was formed and in 2003, the National United Party of Afghanistan was registered - who seek to unite former PDPA members formerly led by Najibullah.

He left three daughters and a wife who fled Kabul in 1992 at the start of the civil war. The eldest daughter Heela Najibullah - worked in the international red cross, in 2006 she spoke at the summit of young UN leaders representing Afghanistan. She is currently an employee of the "Transnational Foundation for Peace and Future Research" in Sweden, she maintains his Twitter page. The second daughter, Moska Najib, works as a photographer for the international company Weber Shandwick.



</doc>
<doc id="20292" url="https://en.wikipedia.org/wiki?curid=20292" title="Multiplan">
Multiplan

Multiplan was an early spreadsheet program developed by Microsoft. Known initially by the code name "EP" (for "Electronic Paper"), it was introduced in 1982 as a competitor for VisiCalc.

Multiplan was released first for computers running CP/M; it was developed using a Microsoft proprietary p-code C compiler as part of a portability strategy that facilitated ports to systems such as MS-DOS, Xenix, Commodore 64 and 128, Texas Instruments TI-99/4A (on four 6K GROMs and a single 8K ROM), Radio Shack TRS-80 Model II, TRS-80 Model 4, TRS-80 Model 100 (on ROM), Apple II, and Burroughs B20 series. The CP/M version was also runnable on the TRS-80 Model II and 4, Commodore 128, and Apple II with a CP/M card. In France, Multiplan was also released for the Thomson computers in 1986.

Despite the release of Microsoft Chart, a graphics companion program, Multiplan continued to be outsold by Lotus 1-2-3. Multiplan was replaced by Microsoft Excel, which followed some years later on both the Apple Macintosh (1985) and Microsoft Windows (1987).

Although over a million copies were sold, Multiplan was not able to mount an effective challenge to Lotus 1-2-3. According to Bill Gates, this was due to the excessive number of ports (there were approximately 100 different versions of Multiplan). He also believed that it was a mistake to release 8-bit versions instead of focusing on the newer 16-bit machines and as a result, "We decided to let [Lotus] have the character-based DOS market while we would instead focus on the next generation--graphical software on the Macintosh and Windows."

Around 1983, during the development of the first release of Windows, Microsoft had plans to make a Windows version. However the plans changed a year later.

A version was available for the Apple Lisa 2 running Microsoft/SCO Xenix 3. It fit on one 400K microfloppy diskette.

A fundamental difference between Multiplan and its competitors was Microsoft's decision to use R1C1 addressing instead of the A1 addressing introduced by VisiCalc. Although R1C1-style formulae are more straightforward than A1-style formulae for instance, "RC[-1]" (meaning "current row, previous column") is expressed as "A1" in cell B1, then "A2" in cell B2, etc. most spreadsheet users prefer the A1 addressing style introduced by VisiCalc.

Microsoft carried Multiplan's R1C1 legacy forward into Microsoft Excel, which offers both addressing modes, although A1 is MS Excel's default addressing mode.

"Ahoy!" called the Commodore 64 version of Multiplan, distributed by Human Engineered Software, a "professional quality spreadsheet ... There is not enough room in this article to mention all the mathematical operations performed ... Documentation is lengthy but well written". A second review in the magazine noted the limitation of the computer's 40-column screen, but praised the ability to stop any ongoing action. It also praised the documentation, and concluded that "its ease of use and foolproof design make "Multiplan" an outstanding value". "BYTE" said that "Multiplan for the Macintosh is a winner", stating that combining other versions' power and features with the Macintosh's graphics and user interface "rivals, and in many ways exceeds, anything else available in the spreadsheet genre".



</doc>
<doc id="20297" url="https://en.wikipedia.org/wiki?curid=20297" title="MOS Technology 6502">
MOS Technology 6502

The MOS Technology 6502 (typically "sixty-five-oh-two" or "six-five-oh-two") is an 8-bit microprocessor that was designed by a small team led by Chuck Peddle for MOS Technology. The design team had formerly worked at Motorola on the Motorola 6800 project; the 6502 is essentially a simplified, less expensive and faster version of that design.

When it was introduced in 1975, the 6502 was the least expensive microprocessor on the market by a considerable margin. It initially sold for less than one-sixth the cost of competing designs from larger companies, such as the 6800 or Intel 8080. Its introduction caused rapid decreases in pricing across the entire processor market. Along with the Zilog Z80, it sparked a series of projects that resulted in the home computer revolution of the early 1980s.

Popular home video game consoles and computers, such as the Atari 2600, Atari 8-bit family, Apple II, Nintendo Entertainment System, Commodore 64, Atari Lynx, BBC Micro and others, used the 6502 or variations of the basic design. Soon after the 6502's introduction, MOS Technology was purchased outright by Commodore International, who continued to sell the microprocessor and licenses to other manufacturers. In the early days of the 6502, it was second-sourced by Rockwell and Synertek, and later licensed to other companies.

In its CMOS form, the 65C02, which was developed by the Western Design Center (WDC), the 6502 family continues to be widely used in embedded systems, with estimated production volumes in the hundreds of millions.

The 6502 was designed by many of the same engineers that had designed the Motorola 6800 microprocessor family. Motorola started the 6800 microprocessor project in 1971 with Tom Bennett as the main architect. The chip layout began in late 1972, the first 6800 chips were fabricated in February 1974 and the full family was officially released in November 1974. John Buchanan was the designer of the 6800 chip and Rod Orgill, who later did the 6501, assisted Buchanan with circuit analyses and chip layout. Bill Mensch joined Motorola in June 1971 after graduating from the University of Arizona (at age 26). His first assignment was helping define the peripheral ICs for the 6800 family and later he was the principal designer of the 6820 Peripheral Interface Adapter (PIA). Motorola's engineers could run analog and digital simulations on an IBM 370-165 mainframe computer. Bennett hired Chuck Peddle in 1973 to do architectural support work on the 6800 family products already in progress. He contributed in many areas, including the design of the 6850 ACIA (serial interface).

Motorola's target customers were established electronics companies such as Hewlett-Packard, Tektronix, TRW, and Chrysler. In May 1972, Motorola's engineers began visiting select customers and sharing the details of their proposed 8-bit microprocessor system with ROM, RAM, parallel and serial interfaces. In early 1974, they provided engineering samples of the chips so that customers could prototype their designs. Motorola's "total product family" strategy did not focus on the price of the microprocessor, but on reducing the customer's total design cost. They offered development software on a timeshare computer, the "EXORciser" debugging system, onsite training and field application engineer support. Both Intel and Motorola had initially announced a $360 price for a single microprocessor. The actual price for production quantities was much less. Motorola offered a design kit containing the 6800 with six support chips for $300.

Peddle, who would accompany the salespeople on customer visits, found that customers were put off by the high cost of the microprocessor chips. At the same time, these visits invariably resulted in the engineers he presented to producing lists of required instructions that were much smaller than "all these fancy instructions" that had been included in the 6800. Peddle and other team members started outlining the design of an improved feature, reduced size microprocessor. At that time, Motorola's new semiconductor fabrication facility in Austin, Texas, was having difficulty producing MOS chips, and mid-1974 was the beginning of a year-long recession in the semiconductor industry. Also, many of the Mesa, Arizona, employees were displeased with the upcoming relocation to Austin.

Motorola's Semiconductor Products Division management was overwhelmed with problems and showed no interest in Peddle's low-cost microprocessor proposal. Eventually Peddle was given an official letter telling him to stop working on the system. Peddle responded to the order by informing Motorola that the letter represented an official declaration of "project abandonment", and as such, the intellectual property he had developed to that point was now his. In a November 1975 interview, Motorola's Chairman, Robert Galvin, ultimately agreed that Peddle's concept was a good one and that the division missed an opportunity, "We did not choose the right leaders in the Semiconductor Products division." The division was reorganized and the management replaced. The new group vice-president John Welty said, "The semiconductor sales organization lost its sensitivity to customer needs and couldn't make speedy decisions."

Peddle began looking outside Motorola for a source of funding for this new project. He initially approached MOSTEK CEO L. J. Sevin, but Sevin declined and later admitted this was because he was afraid Motorola would sue them.

While Peddle was visiting Ford Motor Company on one of his sales trips, Bob Johnson, later head of Ford's engine automation division, mentioned that their former colleague John Paivinen had moved to General Instrument and taught himself semiconductor design. He had since moved on and was doing some very interesting work on calculator chipsets at a new company he formed in Valley Forge, Pennsylvania.

Paivinen had formed MOS Technology in 1969 with two other executives from General Instrument, Mort Jaffe and Don McLaughlin. Allen-Bradley, a supplier of electronic components and industrial controls, acquired a majority interest in 1970. The company designed and fabricated custom ICs for customers and had developed a line of calculator chips.

After the MOSTEK efforts fell through, Peddle approached Paivinen, who "immediately got it". On 19 August 1974, Chuck Peddle, Bill Mensch, Rod Orgill, Harry Bawcom, Ray Hirt, Terry Holdt, and Wil Mathys left Motorola to join MOS. Mike Janes joined later. Of the seventeen chip designers and layout people on the 6800 team, seven left. The goal of the team was to design and produce a low-cost microprocessor for embedded applications and to target as wide as possible a customer base. This would be possible only if the microprocessor was low cost, and the price goal was set at $5 in volume.

The original 6800 chips were intended to be , but layout was completed at , or an area of 29.0 mm. For the new design, the cost goal demanded a size goal of , or an area of 16.6 mm. Several new techniques would be needed to hit this goal.

Chips are produced by printing multiple copies of the chip design on the surface of a "wafer", a thin disk of highly pure silicon. Smaller chips can be printed in greater numbers on the same wafer, decreasing their relative price. Additionally, wafers always include some number of tiny physical defects that are scattered across the surface of the disk. Any chip printed in that location will fail and has to be discarded. Smaller chips mean any one is less likely to be printed on a defect. For both of these reasons, the cost of the final product is strongly dependent on the size of the chip design. There were two significant advances that arrived in the market just as the 6502 was being designed that provided significant cost reductions.

The first was the move from PMOS to NMOS. PMOS circuits always had power running through them, even in the "off" state. To make changes from on to off easily visible in the signals, most PMOS systems used two positive voltages, often +12 V and +5 V, as well as ground and a negative voltage. An example is the Intel 8080, which had +12 V, +5 V, −5 V and ground. In contrast, NMOS circuits, also known as "depletion-load" transistors, used about half as much energy and thus could be built smaller, reducing the chip size. They also required only a single feed voltage, typically +5 V, which simplified wiring on the chip and further reduced size.

A further practical advantage was that the clock signal for PMOS CPUs had to be strong enough to survive all the dissipation as it traveled through the circuits, which almost always required a separate external chip that could supply a strong enough signal. With the reduced power requirements of NMOS, the clock could be moved onto the chip, simplifying the overall computer design. These changes greatly reduced complexity and the cost of implementing a complete system.

Another change that was taking place was the introduction of contact-less projections systems by Perkin-Elmer in 1973. Previously, chips were patterned onto the surface of the wafer by placing a "mask" on the surface and then shining a bright light on it. The masks were fragile and lasted only a few dozen applications before wearing out. The Micralign system instead projected the image from a distance, so the masks lasted much longer. This did not reduce the size of the resulting designs, but meant that the production line could be run much more efficiently, lowering costs.

MOS Technology's existing fabrication lines were based on the older PMOS technology, they had not yet begun to work with NMOS when the team arrived. Paivinen promised to have an NMOS line up and running in time to begin the production of the new CPU. He delivered on the promise, the new line was ready by June 1975.

Chuck Peddle, Rod Orgill, and Wil Mathys designed the initial architecture of the new processors. A September 1975 article in EDN magazine gives this summary of the design:

The MOS Technology 650X family represents a conscious attempt of eight former Motorola employees who worked on the development of the 6800 system to put out a part that would replace and outperform the 6800, yet undersell it. With the benefit of hindsight gained on the 6800 project, the MOS Technology team headed by Chuck Peddle, made the following architectural changes in the Motorola CPU…
The main change in terms of chip size was the elimination of the three-state from the address bus outputs. This had been included in the 6800 to allow it to work with other chips in direct memory access (DMA) and co-processing roles, at the cost of significant die space. In practice, using such a system required the other devices to be similarly complex, and designers instead tended to use off-chip systems to coordinate such access. The 6502 simply removed this feature, in keeping with its design as an inexpensive controller being used for specific tasks and communicating with simple devices. Peddle suggested that anyone that actually required this style of access could implement it with a single 74158.

The next major difference was to simplify the registers. To start with, one of the two accumulators was removed. General-purpose registers like accumulators have to be accessed by many parts of the instruction decoder, and thus require significant amounts of wiring to move data to and from their storage. Two accumulators makes many coding tasks easier, but costs the chip design itself significant complexity. Further savings were made by reducing the stack register from 16 to 8 bits, meaning that the stack could only be 256 bytes long, which was enough for its intended role as a microcontroller.

The 16-bit IX index register was split in two, becoming X and Y. More importantly, the style of access changed; in the 6800, IX held a 16-bit address, which was offset by a number supplied with the instruction, the two were added to produce the final address. In the 6502 (and most other designs), the base address was stored in the instruction, and the X or Y was added to it.

Finally, the instruction set was simplified, freeing up room in the decoder and control logic. Of the original 72 instructions in the 6800, 56 were left. Among those removed were any instruction that moved data between the 6800's two accumulators, as well as a number of branch instructions inspired by the PDP-11 like the ability to directly compare two numeric values. The 6502 used a simpler system that handled comparisons by performing math on the accumulator and then examining result flags.

The chip's high-level design had to be turned into drawings of transistors and interconnects. At MOS Technology, the "layout" was a very manual process done with color pencils and vellum paper. The layout consisted of thousands of polygon shapes on six different drawings; one for each layer of the fabrication process. Given the size limits, the entire chip design had to be constantly considered. Mench and Paivinen worked on the instruction decoder while Mench, Peddle and Orgill worked on the ALU and registers. A further advance, developed at a party, was a way to share some of the internal wiring to allow the ALU to be reduced in size.

In spite of their best efforts, the final design ended up being 5 mils too wide. The first 6502 chips were , or an area of 19.8 mm. The rotate right instruction (ROR) did not work in the first silicon, so the instruction was temporarily omitted from the published documents, but the next iteration of the design shrank the chip and corrected the rotate right instruction, which was then included in revised documentation.

MOS would introduce two microprocessors based on the same underlying design: the 6501 would plug into the same socket as the Motorola 6800, while the 6502 re-arranged the pinout to support an on-chip clock oscillator. Both would work with other support chips designed for the 6800. They would not run 6800 software because they had a different instruction set, different registers, and mostly different addressing modes. Rod Orgill was responsible for the 6501 design; he had assisted John Buchanan at Motorola on the 6800. Bill Mensch did the 6502; he was the designer of the 6820 Peripheral Interface Adapter (PIA) at Motorola. Harry Bawcom, Mike Janes and Sydney-Anne Holt helped with the layout.

MOS Technology's microprocessor introduction was quite different from the traditional months-long product launch. The first run of a new integrated circuit is normally used for internal testing and shared with select customers as "engineering samples". These chips often have a minor design defect or two that will be corrected before production begins. Chuck Peddle's goal was to sell the first run 6501 and 6502 chips to the attendees at the Wescon trade show in San Francisco beginning on September 16, 1975. Peddle was a very effective spokesman and the MOS Technology microprocessors were extensively covered in the trade press. One of the earliest was a full-page story on the MCS6501 and MCS6502 microprocessors in the July 24, 1975 issue of "Electronics" magazine. Stories also ran in "EE Times" (August 24, 1975), "EDN" (September 20, 1975), "Electronic News" (November 3, 1975), "Byte" (November 1975) and "Microcomputer Digest" (November 1975). Advertisements for the 6501 appeared in several publications the first week of August 1975. The 6501 would be for sale at Wescon for $20 each. In September 1975, the advertisements included both the 6501 and the 6502 microprocessors. The 6502 would cost only $25 ().

When MOS Technology arrived at Wescon, they found that exhibitors were not permitted to sell anything on the show floor. They rented the MacArthur Suite at the St. Francis Hotel and directed customers there to purchase the processors. At the suite, the processors were stored in large jars to imply that the chips were in production and readily available. The customers did not know the bottom half of each jar contained non-functional chips. The chips were $20 and $25 while the documentation package was an additional $10. Users were encouraged to make photocopies of the documents, an inexpensive way for MOS Technology to distribute product information. The processors were supposed to have 56 instructions, but the Rotate Right (ROR) instruction did not work correctly on these chips, so the preliminary data sheets listed just 55 instructions. The reviews in "Byte" and "EDN" noted the lack of the ROR instruction. The next revision of the layout fixed this problem and the May 1976 datasheet listed 56 instructions. Peddle wanted every interested engineer and hobbyist to have access to the chips and documentation; other semiconductor companies only wanted to deal with "serious" customers. For example, Signetics was introducing the 2650 microprocessor and its advertisements asked readers to write for information on their company letterhead.

The 6501/6502 introduction in print and at Wescon was an enormous success. The downside was that the extensive press coverage got Motorola's attention. In October 1975, Motorola reduced the price of a single 6800 microprocessor from $175 to $69. The $300 system design kit was reduced to $150 and it now came with a printed circuit board. On November 3, 1975, Motorola sought an injunction in Federal Court to stop MOS Technology from making and selling microprocessor products. They also filed a lawsuit claiming patent infringement and misappropriation of trade secrets. Motorola claimed that seven former employees joined MOS Technology to create that company's microprocessor products.

Motorola was a billion-dollar company with a plausible case and lawyers. On October 30, 1974, Motorola had filed numerous patent applications on the microprocessor family and was granted twenty-five patents. The first was in June 1976 and the second was to Bill Mensch on July 6, 1976, for the 6820 PIA chip layout. These patents covered the 6800 bus and how the peripheral chips interfaced with the microprocessor. Motorola began making transistors in 1950 and had a portfolio of semiconductor patents. Allen-Bradley decided not to fight this case and sold their interest in MOS Technology back to the founders. Four of the former Motorola engineers were named in the suit: Chuck Peddle, Will Mathys, Bill Mensch and Rod Orgill. All were named inventors in the 6800 patent applications. During the discovery process, Motorola found that one engineer, Mike Janes, had ignored Peddle's instructions and brought his 6800 design documents to MOS Technology. In March 1976, the now independent MOS Technology was running out of money and had to settle the case. They agreed to drop the 6501 processor, pay Motorola $200,000 and return the documents that Motorola contended were confidential. Both companies agreed to cross-license microprocessor patents. That May, Motorola dropped the price of a single 6800 microprocessor to $35. By November, Commodore had acquired MOS Technology.

With legal troubles behind them, MOS was still left with the problem of getting developers to try their processor, prompting Chuck Peddle to design the MDT-650 ("microcomputer development terminal") single-board computer. Another group inside the company designed the KIM-1, which was sold semi-complete and could be turned into a usable system with the addition of a 3rd party computer terminal and compact cassette drive. Much to their amazement, the KIM-1 sold well to hobbyists and tinkerers, as well as to the engineers to which it had been targeted. The related Rockwell AIM 65 control/training/development system also did well. The software in the AIM 65 was based on that in the MDT. Another roughly similar product was the Synertek SYM-1.

One of the first "public" uses for the design was the Apple I microcomputer, introduced in 1976. The 6502 was next used in the Commodore PET and the Apple II, both released in 1977. It was later used in the Atari 8-bit family and Acorn Atom home computers, the BBC Micro, Commodore VIC-20 and other designs both for home computers and business, such as Ohio Scientific and Oric. The 6510, a direct successor of the 6502 with a digital I/O port and a tri-state address bus, was the CPU utilized in the best-selling Commodore 64 home computer. 6520 and/or 6502-variant CPUs were used in all of Commodore's floppy disk drives for all of their 8-bit computers, from the PET line (some of which had two 6502-based CPUs) through the Commodore 128D, including the Commodore 64, and in all of Atari's disk drives for all of their 8-bit computer line, from the 400/800 through the XEGS.

Another important use of the 6500 family was in video games. The first to make use of the processor design was the Atari VCS, later renamed the Atari 2600. The VCS used a variant of the 6502 called the 6507, which had fewer pins and, as a result, could address only 8 KB of memory. Millions of the Atari consoles would be sold, each with a MOS processor. Another significant use was by the Nintendo Entertainment System and Famicom. The 6502 used in the NES was a second source version by Ricoh, a partial system-on-a-chip, that lacked the binary-coded decimal mode but added 22 memory-mapped registers and on-die hardware for sound generation, joypad reading, and sprite list DMA. Called 2A03 in NTSC consoles and 2A07 in PAL consoles (the difference being the memory divider ratio and a lookup table for audio sample rates), this processor was produced exclusively for Nintendo. The Atari Lynx used a 4 MHz version of the chip, the 65SC02.

In the 1980s, a popular electronics magazine Elektor/Elektuur used the processor in its microprocessor development board Junior Computer.

The 6502 is a little-endian 8-bit processor with a 16-bit address bus. The original versions were fabricated using an process technology chip with an advertised die size of (), or an area of 16.6 mm.

The internal logic runs at the same speed as the external clock rate, but despite the low clock speeds (typically in the neighborhood of 1 to 2 MHz), the 6502's performance was competitive with other contemporary CPUs using significantly faster clocks. This is partly due to a simple state machine implemented by combinational (clockless) logic to a greater extent than in many other designs; the two-phase clock (supplying two synchronizations per cycle) can thereby control the whole "machine"-cycle directly. Typical instructions might take half as many cycles to complete on the 6502 as on contemporary designs. Like most simple CPUs of the era, the dynamic NMOS 6502 chip is not sequenced by a microcode ROM but uses a PLA (which occupied about 15% of the chip area) for instruction decoding and sequencing. As in most 8-bit microprocessors, the chip does some limited overlapping of fetching and execution.

The low clock frequency moderated the speed requirement of memory and peripherals attached to the CPU, as only about 50% of the clock cycle was available for memory access (due to the asynchronous design, this fraction varied strongly among chip versions). This was critical at a time when affordable memory had access times in the range . The original NMOS 6502 was minimalistically engineered and efficiently manufactured, and therefore cheap—an important factor in getting design wins in the very price-sensitive game-console and home-computer markets.

Like its precursor, the 6800, the 6502 has very few registers. The 6502's registers include one 8-bit accumulator register (A), two 8-bit index registers (X and Y), 7 processor status flag bits (P), an 8-bit stack pointer (S), and a 16-bit program counter (PC). This compares to a typical design of the same era, the Z80, which has eight general-purpose 8-bit registers, which can be combined into four 16-bit ones. The Z80 also had a complete set of alternate registers which made a total of sixteen general-purpose registers.
In order to make up somewhat for the lack of registers, the 6502 included a "zero-page" addressing mode that uses one address byte in the instruction instead of the two needed to address the full 64 KB of memory. This provides fast access to the first 256 bytes of RAM by using shorter instructions. Chuck Peddle has said in interviews that the specific intention was to allow these first 256 bytes of RAM to be used like registers.

The stack address space is to memory page $01, i.e. the address range $0100–$01FF (256–511). Software access to the stack is done via four implied addressing mode instructions, whose functions are to push or pop (pull) the accumulator or the processor status register. The same stack is also used for subroutine calls via the JSR (jump to subroutine) and RTS (return from subroutine) instructions and for interrupt handling.

The chip uses the index and stack registers effectively with several addressing modes, including a fast "direct page" or "zero page" mode, similar to that found on the PDP-8, that accesses memory locations from addresses 0 to 255 with a single 8-bit address (saving the cycle normally required to fetch the high-order byte of the address)—code for the 6502 uses the zero page much as code for other processors would use registers. On some 6502-based microcomputers with an operating system, the operating system uses most of zero page, leaving only a handful of locations for the user.

Addressing modes also include "implied" (1-byte instructions); "absolute" (3 bytes); "indexed absolute" (3 bytes); "indexed zero-page" (2 bytes); "relative" (2 bytes); "accumulator" (1); "indirect,x" and "indirect,y" (2); and "immediate" (2). Absolute mode is a general-purpose mode. Branch instructions use a signed 8-bit offset relative to the instruction after the branch; the numerical range −128..127 therefore translates to 128 bytes backward and 127 bytes forward from the instruction following the branch (which is 126 bytes backward and 129 bytes forward from the start of the branch instruction). Accumulator mode uses the accumulator as an effective address and does not need any operand data. Immediate mode uses an 8-bit literal operand.

The indirect modes are useful for array processing and other looping. With the 5/6 cycle "(indirect),y" mode, the 8-bit Y register is added to a 16-bit base address read from zero page, which is located by a single byte following the opcode. The Y register is therefore an "index" register in the sense that it is used to hold an actual "index" (as opposed to the X register in the 6800, where a base address was directly stored and to which an immediate offset could be added). Incrementing the index register to walk the array byte-wise takes only two additional cycles. With the less frequently used "(indirect,x)" mode the effective address for the operation is found at the zero page address formed by adding the second byte of the instruction to the contents of the X register. Using the indexed modes, the zero page effectively acts as a set of up to 128 additional (though very slow) address registers.

The 6502 is capable of performing addition and subtraction in binary or binary-coded decimal. Placing the CPU into BCD mode with the codice_1 (set D flag) instruction results in decimal arithmetic, in which codice_2 would result in $00 and the carry (C) flag being set. In binary mode (codice_3, clear D flag), the same operation would result in $9A and the carry flag being cleared. Other than Atari BASIC, BCD mode was seldom used in home-computer applications.

See the article for a simple but characteristic example of 6502 assembly language.

6502 instruction operation codes ("opcodes") are eight-bits long and have the general form AAABBBCC, where AAA and CC define the opcode, and BBB defines the addressing mode.

For instance, consider the codice_4 instruction, which performs a bitwise OR on the bits in the accumulator with another value. The instruction opcode is of the form 000bbb01, where bbb may be 010 for an immediate mode value (constant), 001 for zero page fixed address, 011 for an absolute address, and so on.

This pattern is not absolute and there are a number of exceptions. However, where it does apply it allows one to easily deconstruct opcode values back to assembler mnemonics for the majority of instructions, handling the edge cases with special-purpose code.

Of the 256 possible opcodes available using an 8-bit pattern, the original 6502 uses 151 of them, organized into 56 instructions with (possibly) multiple addressing modes. Depending on the instruction and addressing mode, the opcode may require zero, one or two additional bytes for operands. Hence 6502 machine instructions vary in length from one to three bytes. The operand is stored in the 6502's customary little-endian format.

The 65C816, the 16-bit CMOS descendant of the 6502, also supports 24-bit addressing, which results in instructions being assembled with three-byte operands, also arranged in little-endian format.

The remaining 105 opcodes are undefined. In the original design, instructions where the low-order 4-bits ("nibble") were 3, 7, B or F were not used, providing room for future expansion. Likewise, the $2xxx column had only a single entry, codice_5. The remaining 25 empty slots were distributed. Some of the empty slots were used in the 65C02 to provide both new instructions as well as variations on existing ones with new addressing modes. The $Fxxx instructions were initially left free to allow 3rd party vendors to add their own instructions, but later versions of the 65C02 standardized a set of bit fiddling instructions developed by Rockwell Semiconductor.

A 6502 assembly language statement consists of a three-character instruction mnemonic, followed by any operands. Instructions that do not take a separate operand but target a single register based on the addressing mode combine the target register in the instruction mnemonic, so the assembler uses codice_6 as opposed to codice_7 to increment the X register.

The processor's non-maskable interrupt (NMI) input is edge sensitive, which means that the interrupt is triggered by the falling edge of the signal rather than its level. The implication of this feature is that a wired-OR interrupt circuit is not readily supported. However, this also prevents nested NMI interrupts from occurring until the hardware makes the NMI input inactive again, often under control of the NMI interrupt handler.

The simultaneous assertion of the NMI and IRQ (maskable) hardware interrupt lines causes IRQ to be ignored. However, if the IRQ line remains asserted after the servicing of the NMI, the processor will immediately respond to IRQ, as IRQ is level sensitive. Thus a sort of built-in interrupt priority was established in the 6502 design.

The "Break" flag of the processor is very different from the other flag bits. It has no flag setting, resetting, or testing instructions of its own, and is not affected by the PHP and PLP instructions. It exists only on the stack, where BRK and PHP always write a 1, while IRQ and NMI always write a 0.

The "SO" input pin, when asserted, will set the processor's overflow status bit (deasserting it does not clear the overflow bit, however). This can be used by a high-speed polling device driver, which can poll the hardware once in only three cycles by using a Branch-on-oVerflow-Clear (codice_8) instruction that branches to itself. For example, the Commodore 1541 and other Commodore floppy disk drives use this technique to detect without delay whether the serializer is ready to accept or provide another byte of disk data. Obviously great care must be used in the device driver and the associated system design, as spurious assertion of the overflow bit could ruin arithmetic processing.

There were numerous variants of the NMOS 6502:


The MOS Technology 6512, 6513, 6514, and 6515 each rely on an external clock, instead of using an internal clock generator like the 650x (e.g. 6502). This was used to advantage in some designs where the clocks could be run asymmetrically, increasing overall CPU performance.

The 6512 was used in the BBC Micro B+64.

The Western Design Center designed and currently produces the W65C816S processor, a 16-bit, static-core successor to the 65C02, with greatly enhanced features. The W65C816S is a newer variant of the 65C816, which was the core of the Apple II computer and was the basis of the Ricoh 5A22 processor that powered the popular Super Nintendo Entertainment System. The W65C816S incorporates minor improvements over the 65C816 that make the newer chip not an exact hardware-compatible replacement for the earlier one. Among these improvements was conversion to a static core, which makes it possible to stop the clock in either phase without the registers losing data. Available through electronics distributors, as of March 2020, the W65C816S is officially rated for 14 MHz operation.

The Western Design Center also designed and produced the 65C802, which was a 65C816 core with a 64-kilobyte address space in a 65(C)02 pin-compatible package. The 65C802 could be retrofitted to a 6502 board and would function as a 65C02 on power-up, operating in "emulation mode." As with the 65C816, a two-instruction sequence would switch the 65C802 to "native mode" operation, exposing its 16-bit accumulator and index registers, as well as other 65C816 enhanced features. The 65C802 was not widely used; new designs almost always were built around the 65C816, resulting in 65C802 production being discontinued.

The following 6502 assembly language source code is for a subroutine named codice_10, which copies a null-terminated character string from one location to another, converting upper-case letter characters to lower-case letters. The string being copied is the "source", and the string into which the converted source is stored is the "destination".

The 6502 had several bugs and quirks, which had to be accounted for when programming it:








</doc>
<doc id="20298" url="https://en.wikipedia.org/wiki?curid=20298" title="MOS Technology 65xx">
MOS Technology 65xx

The MOS Technology 65xx series is a family of 8-bit microprocessors from MOS Technology, based on the Motorola 6800 (introduced ca. 1975). The 65xx family included the 6502, used in home computers such as the Commodore PET and VIC-20, the Apple II, the Atari 800, and the British BBC Micro.

The 6501 and 6502 have 40-pin DIP packages; the 6503, 6504, 6505, and 6507 are 28-pin DIP versions, for reduced chip and circuit board cost. In all of the 28-pin versions, the pin count is reduced by leaving off some of the high-order address pins and various combinations of function pins, making those functions unavailable.

Typically, the 12 pins omitted are the three not connected (NC) pins, one of the two Vss pins, one of the clock pins, the SYNC pin, the set overflow (SO) pin, either the maskable interrupt or the non-maskable interrupt (NMI), and the four most-significant address lines (A12–A15) are the 12 pins omitted to reduce the pin count from 40 to 28. The omission of four address pins reduces the external addressability to 4 KB (from the 64 KB of the 6502), though the internal PC register and all effective address calculations remain 16-bit.

The 6507 omits both interrupt pins in order to include address line A12, providing 8 KB of external addressability but no interrupt capability. The 6507 was used in the popular Atari 2600 video game console, the design of which divides the 8 KB memory space in half, allocating the lower half to the console's internal RAM and peripherals, and the upper half to the Game Cartridge, so Atari 2600 cartridges have a 4 KB address limit (and the same capacity limit unless the cartridge contains bank switching circuitry).

One popular 6502 based computer, the Commodore 64, used a modified 6502 CPU, the 6510. Unlike the 6503–6505 and 6507, the 6510 is a 40-pin chip that adds internal hardware: an 8-bit parallel I/O port mapped to addresses 0000 and 0001. The 6508 is another chip that, like the 6510, adds internal hardware: 256 bytes of SRAM and the same 8-bit I/O port featured by the 6510. Though these chips do not have reduced pin counts compared to the 6502, they need 8 new pins for the added parallel I/O port. In this case, no address lines are among the 8 removed pins.



</doc>
<doc id="20299" url="https://en.wikipedia.org/wiki?curid=20299" title="MOS Technology 6510">
MOS Technology 6510

The MOS Technology 6510 is an 8-bit microprocessor designed by MOS Technology. It is a modified form of the very successful 6502. The 6510 was only widely used in the Commodore 64 (C64) home computer and its variants.

The primary change from the 6502 was the addition of an 8-bit general purpose I/O port, although only six I/O pins were available in the most common version of the 6510. In addition, the address bus could be made tristate.

In the C64, the extra I/O pins of the processor were used to control the computer's memory map by bank switching, and for controlling three of the four signal lines of the Datasette tape recorder (the electric motor control, key-press sensing and write data lines; the read data line went to another I/O chip). It was possible, by writing the correct bit pattern to the processor at address $01, to completely expose almost the full 64 KB of RAM in the C64, leaving no ROM or I/O hardware exposed except for the processor I/O port itself and its data directional register.

In 1985, MOS produced the 8500, an HMOS version of the 6510. Other than the process modification, it is virtually identical to the NMOS version of the 6510. The 8500 was originally designed for use in the modernised C64, the C64C. However, in 1985, limited quantities of 8500s were found on older NMOS-based C64s. It finally made its official debut in 1987, appearing in a motherboard using the new 85xx HMOS chipset.

The 7501/8501 variant of the 6510 was introduced in 1984. Compared to the 6510, this variant extends the number of I/O port pins from 6 to 8, but omits the pins for non-maskable interrupt and clock output.. It was used in Commodore's C16, C116 and Plus/4 home computers, where its I/O port controlled not only the Datasette but also the CBM Bus interface. The main difference between 7501 and 8501 CPUs is that they were manufactured with slightly different processes: 7501 was manufactured with HMOS-1 and 8501 with HMOS-2.

The 2 MHz-capable 8502 variant was used in the Commodore 128. All these CPUs are opcode compatible (including undocumented opcodes).

The Commodore 1551 disk drive used the 6510T, a version of the 6510 with eight I/O lines. The NMI and RDY signals are not available.




</doc>
<doc id="20301" url="https://en.wikipedia.org/wiki?curid=20301" title="Motorola 6800">
Motorola 6800

The 6800 (""sixty-eight hundred"") is an 8-bit microprocessor designed and first manufactured by Motorola in 1974. The MC6800 microprocessor was part of the M6800 Microcomputer System that also included serial and parallel interface ICs, RAM, ROM and other support chips. A significant design feature was that the M6800 family of ICs required only a single five-volt power supply at a time when most other microprocessors required three voltages. The M6800 Microcomputer System was announced in March 1974 and was in full production by the end of that year.

The 6800 has a 16-bit address bus that can directly access 64 KB of memory and an 8-bit bi-directional data bus. It has 72 instructions with seven addressing modes for a total of 197 opcodes. The original MC6800 could have a clock frequency of up to 1 MHz. Later versions had a maximum clock frequency of 2 MHz.

In addition to the ICs, Motorola also provided a complete assembly language development system. The customer could use the software on a remote timeshare computer or on an in-house minicomputer system. The Motorola EXORciser was a desktop computer built with the M6800 ICs that could be used for prototyping and debugging new designs. An expansive documentation package included datasheets on all ICs, two assembly language programming manuals, and a 700-page application manual that showed how to design a point-of-sale computer terminal.

The 6800 was popular in computer peripherals, test equipment applications and point-of-sale terminals. It also found use in arcade games and pinball machines. The MC6802, introduced in 1977, included 128 bytes of RAM and an internal clock oscillator on chip. The MC6801 and MC6805 included RAM, ROM and I/O on a single chip and were popular in automotive applications.

Galvin Manufacturing Corporation was founded in 1928; the company name was changed to Motorola in 1947. They began commercial production of transistors at a new US$1.5 million facility in Phoenix in 1955.

Motorola's transistors and integrated circuits were used in-house for their communication, military, automotive and consumer products and they were also sold to other companies. By 1973 the Semiconductor Products Division (SPD) had sales of $419 million and was the second largest semiconductor company after Texas Instruments.

In the early 1970s Motorola started a project that developed their first microprocessor, the MC6800. This was followed by single-chip microcontrollers such as the MC6801 and MC6805.

Motorola did not chronicle the development of the 6800 microprocessor the way that Intel did for their microprocessors. In 2008 the Computer History Museum interviewed four members of the 6800 microprocessor design team. Their recollections can be confirmed and expanded by magazine and journal articles written at the time.

The Motorola microprocessor project began in 1971 with a team composed of designer Tom Bennett, engineering director Jeff LaVell, product marketer Link Young and systems designers Mike Wiles, Gene Schriber and Doug Powell. They were all located in Mesa, Arizona. By the time the project was finished, Bennett had 17 chip designers and layout people working on five chips. LaVell had 15 to 20 system engineers and there was another applications engineering group of similar size.

Tom Bennett had a background in industrial controls and had worked for Victor Comptometer in the 1960s designing the first electronic calculator to use MOS ICs, the Victor 3900. In May 1969 Ted Hoff showed Bennett early diagrams of the Intel 4004 to see if it would meet their calculator needs. Bennett joined Motorola in 1971 to design calculator ICs. He was soon assigned as the chief architect of the microprocessor project that produced the 6800. Others have taken credit for designing the 6800. In September 1975 Robert H. Cushman, "EDN" magazine's microprocessor editor, interviewed Chuck Peddle about MOS Technology's new 6502 microprocessor. Cushman then asked "Tom Bennett, master architect of the 6800", to comment about this new competitor. After the 6800 project Bennett worked on automotive applications and Motorola became a major supplier of microprocessors used in automobiles.

Jeff LaVell joined Motorola in 1966 and worked in the computer industry marketing organization. LaVell had previously worked for Collins Radio on their C8500 computer that was built with small scale ECL ICs. In 1971, he led a group that examined the needs of their existing customers such as Hewlett-Packard, National Cash Register, Control Data Corporation (CDC), and Digital Equipment Corporation (DEC). They would study the customer's products and try to identify functions that could be implemented in larger integrated circuits at a lower cost. The result of the survey was a family of 15 building blocks; each could be implemented in an integrated circuit. Some of these blocks were implemented in the initial M6800 release and more were added over the next few years. To evaluate the 6800 architecture while the chip was being designed, LaVell's team built an equivalent circuit using 451 small scale TTL ICs on five 10 by 10 inch (25 by 25 cm) circuit boards. Later they reduced this to 114 ICs on one board by using ROMs and MSI (medium scale integration) logic devices.

John Buchanan was a memory designer at Motorola when Bennett asked him to design a voltage doubler for the 6800. Typical n-channel MOS IC's required three power supplies: -5 volts, +5 volts and +12 volts. The M6800 family was to use only one, +5 volts. It was easy to eliminate the -5 volt supply but the MOS transistors needed a supply of 10 to 12 volts. This on-chip voltage doubler would supply the higher voltage and Buchanan did the circuit design, analysis and layout for the 6800 microprocessor. He received patents on the voltage doubler and the 6800 chip layout. Rod Orgill assisted Buchanan with analyses and 6800 chip layout. Later Orgill would design the MOS Technology 6501 microprocessor that was socket compatible with the 6800.

Bill Lattin joined Motorola in 1969 and his group provided the computer simulation tools for characterizing the new MOS circuits in the 6800. Lattin and Frank Jenkins had both attended UC Berkeley and studied computer circuit simulators under Donald Pederson, the designer of the SPICE circuit simulator. Motorola's simulator, MTIME, was an advanced version of the TIME circuit simulator that Jenkins had developed at Berkeley. The group published a technical paper, "MOS-device modeling for computer implementation" in 1973 describing a "5-V single-supply n-channel technology" operating at 1 MHz. They could simulate a 50 MOSFET circuit on an IBM 370/165 mainframe computer. In November 1975, Lattin joined Intel to work on their next generation microprocessor.

Bill Mensch joined Motorola in 1971 after graduating from the University of Arizona. He had worked several years as an electronics technician before earning his BSEE degree. The first year at Motorola was a series of three-month rotations through four different areas. Mensch did a flowchart for a modem that would become the 6860. He also worked the application group that was defining the M6800 system. After this training year, he was assigned to the 6820 Peripheral Interface Adapter (PIA) development team. Mensch was a major contributor to the design of this chip and received a patent on the IC layout and was named as a co-inventor of seven other M6800 system patents. Later Mensch would design the MOS Technology 6502 microprocessor.

Mike Wiles was a design engineer in Jeff LaVell's group and made numerous customer visits with Tom Bennett during 6800 product definition phase. He is listed as an inventor on eighteen 6800 patents but is best known for a computer program, MIKBUG. This was a monitor for a 6800 computer system that allowed the user to examine the contents of RAM and to save or load programs to tape. This 512 byte program occupied half of an MCM6830 ROM. This ROM was used in the Motorola MEK6800 design evaluation kit and early hobby computer kits. Wiles stayed with Motorola, moved to Austin and helped design the MC6801 microcontroller that was released in 1978.

Chuck Peddle joined the design team in 1973 after the 6800 processor design was done but he contributed to overall system design and to several peripheral chips, particularly the 6820 (PIA) parallel interface. Peddle is listed as an inventor on sixteen Motorola patents, most have six or more co-inventors. Like the other engineers on the team, Peddle visited potential customers and solicited their feedback. Peddle and John Buchanan built one of the earliest 6800 demonstration boards. In August 1974 Chuck Peddle left Motorola and joined a small semiconductor company in Pennsylvania, MOS Technology. There he led the team that designed the 6500 microprocessor family.

The Motorola 6800 and the Intel 8080 were designed at the same time and were similar in function. The 8080 was an extension and enhancement of the Intel 8008, which in turn was an LSI implementation of the TTL-based CPU design used in the Datapoint 2200. The 6800 architecture was a TTL-compatible LSI design modeled after the DEC PDP-11 processor.

The 6800 had an 8-bit bidirectional data bus, a 16-bit address bus that could address 64 KB of memory, and came in a 40-pin DIP package. The 6800 had two 8-bit accumulators, a 16-bit index register, and a 16-bit stack pointer. The direct addressing mode allowed fast access to the first 256 bytes of memory. I/O devices were addressed as memory so there were no special I/O instructions. When the 6800 was reset, it loaded the program counter from the highest address and started execution at the memory location stored there.

The 6800 had a three-state control that would disable the address bus to allow another device direct memory access. A disk controller could, therefore, transfer data into memory with no load on the processor. It was even possible to have two 6800 processors access the same memory. However, in practice systems of such complexity usually required the use of external bus transceivers to drive the system bus; in such circuits, the on-processor bus control was disabled entirely in favor of using the similar capabilities of the bus transceiver. In contrast, the 6802 dispensed with this on-chip control entirely in order to free up pins for other functions in the same 40-pin package as the 6800, but this functionality could still be achieved using an external bus transceiver.

MOS ICs typically used dual clock signals (a two-phase clock) in the 1970s. These were generated externally for the 6800, The 6800 had a minimum clock rate of 100 kHz, and initially ran at a maximum rate of 1 MHz. Higher-speed versions of the 6800 were released in 1976.

Other divisions in Motorola developed components for the M6800 family. The Components Products Department designed the MC6870 two-phase clock IC, and the Memory Products group provided a full line of ROMs and RAMs. The CMOS group's MC14411 Bit Rate Generator provided a 75 to 9600 baud clock for the MC6850 serial interface. The buffers for address and data buses were standard Motorola products. Motorola could supply every IC, transistor, and diode necessary to build an MC6800-based computer.

The first-generation metal–oxide–semiconductor (MOS) chips used p-channel field-effect transistors, known as p-channel MOSFETs (p-channel describes the configuration of the transistor). These ICs were used in calculators and in the first microprocessor, the Intel 4004. They were easy to produce but were slow and difficult to interface to the popular TTL digital logic ICs. An n-channel MOS integrated circuit could operate two or three times faster and was compatible with TTL. They were much more difficult to produce because of an increased sensitivity to contamination that required an ultra clean production line and meticulous process control. Motorola did not have an n-channel MOS production capability and had to develop one for the 6800 family.

Motorola's n-channel MOS test integrated circuits were complete in late 1971 and these indicated the clock rate would be limited to 1 MHz. These used "enhancement-mode" MOS transistors. There was a newer fabrication technology that used "depletion-mode" MOS transistors as loads, which would allow smaller and faster circuits (this was also known as depletion-load nMOS). The "depletion-mode" processing required extra steps so Motorola decided to stay with "enhancement-mode" for the new single-supply-voltage design. The 1 MHz clock rate meant the chip designers would have to come up with several architectural innovations to speed up the microprocessor throughput. These resulting circuits were faster but required more area on the chip.

In the 1970s, semiconductors were fabricated on 3 inch (75 mm) diameter silicon wafers. Each wafer could produce 100 to 200 integrated circuit chips or dies. The technical literature would state the length and width of each chip in "mils" (0.001 inch). The current industry practice is to state the chip area. Processing wafers required multiple steps and flaws would appear at various locations on the wafer during each step. The larger the chip the more likely it would encounter a defect. The percentage of working chips, or yield, began to decline for chips larger than 160 mils (4 mm) on a side.

The target size for the 6800 was 180 mils (4.6 mm) on each side but the final size was 212 mils (5.4 mm) with an area of 29.0 mm. At 180 mils, a wafer will hold about 190 chips, 212 mils reduces that to 140 chips. At this size the yield may be 20% or 28 chips per wafer. The Motorola 1975 annual report highlights the new MC6800 microprocessor but has several paragraphs on the "MOS yield problems." The yield problem was solved with a design revision started in 1975 to use depletion mode in the M6800 family devices. The 6800 die size was reduced to 160 mils (4 mm) per side with an area of 16.5 mm. This also allowed faster clock speeds, the MC68A00 would operate at 1.5 MHz and the MC68B00 at 2.0 MHz. The new parts were available in July 1976.

The March 7, 1974 issue of "Electronics" had a two-page story on the Motorola MC6800 microprocessor along with the MC6820 Peripheral Interface Adapter, the MC6850 communications interface adapter, the MCM6810 128 byte RAM and the MCM6830 1024 byte ROM. This was followed by an eight-page article in the April 18, 1974 issue, written by the Motorola design team. This issue also had an article introducing the Intel 8080.

Both the Intel 8080 and the Motorola MC6800 processors began layout around December 1972. The first working 8080 chips were produced January 1974 and the first public announcement was in February 1974. The 8080 used same three voltage N-channel MOS process as Intel's existing memory chips allowing full production to begin that April.

The first working MC6800 chips were produced in February 1974 and engineering samples were given to select customers. Hewlett-Packard in Loveland, Colorado wanted the MC6800 for a new desktop calculator and had a prototype system working by June. The MC6800 used a new single-voltage N-channel MOS process that proved to be very difficult to implement. The M6800 microcomputer system was finally in production by November 1974. Motorola matched Intel's price for single microprocessor, $360. (The IBM System/360 was a well-known computer at this time.) In April 1975 the MEK6800D1 microcomputer design kit was offered for $300. The kit included all six chips in the M6800 family plus application and programming manuals. The price of a single MC6800 microprocessor was $175.

Link Young was the product marketer that developed the total system approach for the M6800 family release. In addition to releasing a full set of support chips with the 6800 microprocessor, Motorola offered a software and hardware development system. The software development tools were available on remote time-sharing computers or the source code was available so the customer could use an in-house computer system. The software that would run on a microprocessor system was typically written in assembly language. The development system consisted of a text editor, assembler and a simulator. This allowed the developer to test the software before the target system was complete. The hardware development was a desktop computer built with M6800 family CPU and peripherals known as the EXORcisor. Motorola offered a three- to five-day microprocessor design course for the 6800 hardware and software. This systems-oriented approach became the standard way new microprocessor were introduced.

The principal design effort on the M6800 family was complete in mid-1974, and many engineers left the group or the company. Several factors led to the break-up of the design group.

Motorola had opened a new MOS semiconductor facility in Austin, Texas. The entire engineering team was scheduled to relocate there in 1975. Many of the employees liked living in the Phoenix suburb of Mesa and were very wary about moving to Austin. The team leaders were unsuccessful with their pleas to senior management on deferring the move.

A recession hit the semiconductor industry in mid-1974 resulting in thousands of layoffs. A November 1974 issue of "Electronics" magazine reports that Motorola had laid off 4,500 employees, Texas Instruments 7,000 and Signetics 4,000. Motorola's Semiconductor Products Division would lose thirty million dollars in the next 12 months and there were rumors that the IC group would be sold off. Motorola did not sell the division but they did change the management and organization. By the end of 1974 Intel fired almost a third of its 3,500 employees. The MOS IC business rebounded but job security was not taken for granted in 1974 and 1975.

Chuck Peddle (and other Motorola engineers) had been visiting customers to explain the benefits of microprocessors. Both Intel and Motorola had initially set the price of a single microprocessor at $360. Many customers were hesitant to adopt this new microprocessor technology with such a high price tag. (The actual price for production quantities was much lower.) In mid-1974 Peddle proposed a simplified microprocessor that could be sold at a much lower price. Motorola's "total product family" strategy did not focus on the price of MPU but on reducing the customer's total design cost. Their immediate goal was to get their completed system into production and they would work on improvements in 1975.

Peddle continued working for Motorola while looking for investors for his new microprocessor concept. In August 1974 Chuck Peddle left Motorola and joined a small semiconductor company in Pennsylvania, MOS Technology. He was followed by seven other Motorola engineers: Harry Bawcum, Ray Hirt, Terry Holdt, Mike James, Will Mathis, Bill Mensch and Rod Orgill. Peddle's group at MOS Technology developed two new microprocessors that were compatible with the Motorola peripheral chips like the 6820 PIA. Rod Orgill designed the MCS6501 processor that would plug into a MC6800 socket and Bill Mensch did the MCS6502 that had the clock generation circuit on chip. These microprocessors would not run 6800 programs because they had a different architecture and instruction set. The major goal was a microprocessor that would sell for under $25. This would be done by removing non-essential features to reduce the chip size. An 8-bit stack pointer was used instead of a 16-bit one. The second accumulator was omitted. The address buffers did not have a three-state mode for Direct Memory Access (DMA) data transfers. The goal was to get the chip size down to 153 mils x 168 mils (3.9 mm x 4.3 mm).

Chuck Peddle was a very effective spokesman and the MOS Technology microprocessors were extensively covered in the trade press. One of the earliest was a full-page story on the MCS6501 and MCS6502 microprocessors in the July 24, 1975 issue of "Electronics" magazine. Stories also ran in "EE Times" (August 24, 1975), "EDN" (September 20, 1975), "Electronic News" (November 3, 1975) and "Byte" (November 1975). Advertisements for the 6501 appeared in several publications the first week of August 1975. The 6501 would be for sale at the WESCON trade show in San Francisco, September 16–19, 1975, for $20 each. In September 1975 the advertisements included both the 6501 and the 6502 microprocessors. The 6502 would only cost $25.

Motorola responded to MOS Technology's $20 microprocessor by immediately reducing the single-unit price of the 6800 microprocessor from $175 to $69 and then suing MOS Technology in November 1975. Motorola claimed that the eight former Motorola engineers used technical information developed at Motorola in the design of the 6501 and 6502 microprocessors. MOS Technology's other business, calculator chips, was declining due to a price war with Texas Instruments so their financial backer, Allen-Bradley, decided to limit the possible losses and sold the assets of MOS Technology back to the founders. The lawsuit was settled in April 1976 with MOS Technology dropping the 6501 chip that would plug into a Motorola 6800 socket and licensing Motorola's peripheral chips. Motorola reduced the single-unit price of the 6800 to $35.

The MOS Technology vs. Motorola lawsuit has developed a David and Goliath narrative over the years. One point was that Motorola did not have patents on the technology. This was technically true when the lawsuit was filed in late 1975. On October 30, 1974, before the 6800 was released, Motorola filed numerous patents applications on the microprocessor family, and over twenty patents were subsequently granted. The first was to Tom Bennett on June 8, 1976 for the 6800 internal address bus. The second was to Bill Mensch on July 6, 1976 for the 6820 chip layout. Many of these patents named several of the departing engineers as co-inventors. These patents covered the 6800 bus and how the peripheral chips interfaced with the microprocessor.

Gary Daniels was designing ICs for electronic wristwatches when Motorola shut down their Timepiece Electronics Unit. Tom Bennett offered him a job in the microprocessor group in November 1974. Bennett did not want to leave the Phoenix area so Gary Daniels managed the microprocessor development in Austin. (Daniels was the microprocessor design manager for the next ten years before he was promoted to a vice president.)

The first task was to redesign the 6800 MPU to improve the manufacturing yield and to operate at a faster clock. This design used depletion-mode technology and was known internally as the MC6800D. The transistor count went from 4000 to 5000 but the die area was reduced from 29.0 mm to 16.5 mm. The maximum clock rate for selected parts doubled to 2 MHz. The other chips in the M6800 family were also redesigned to use depletion-mode technology. The Peripheral Interface Adapter had a slight change in the electrical characteristics of the I/O pins so the MC6820 became the MC6821. These new IC were completed in July 1976.

A new low-cost clock generator chip, the MC6875, was released in 1977. It replaced the $35 MC6870 hybrid IC. The MC6875 came in a 16-pin dip package and could use quartz crystal or a resistor capacitor network.

Another project was incorporating 128 bytes of RAM and the clock generator on a single 11,000-transistor chip. The MC6802 microprocessor was released in March 1977. The companion MC6846 chip had 2048 byte ROM, an 8-bit bidirectional port and a programmable timer. This was a two-chip microcomputer. The 6802 has an on-chip oscillator that uses an external 4 MHz quartz crystal to produce the two-phase 1 MHz clock. The internal 128 byte RAM could be disabled by grounding a pin and devices with defective RAM were sold as a MC6808.

A series of peripheral chip were introduced by 1978. The MC6840 programmable counter had three 16-bit binary counters that could be used for frequency measurement, event counting, or interval measurement. The MC6844 Direct Memory Access Controller could transfer data from an I/O controller to RAM without loading down the MC6800 microprocessor. The MC6845 CRT Controller (CRTC) provided the control logic for a character based computer terminal. The 6845 had support for a light pen, an alternative to a computer mouse.

The MC6845 was a very popular chip: it was even used in the original Monochrome Display Adapter and the original IBM Color Graphics Adapter for the IBM PC and successors, where the 6845 was used with an Intel 8088 CPU. The later IBM Enhanced Graphics Adapter (EGA) card contained a custom IBM chip (the EGA CRTC) that replaced the Motorola 6845, adding many enhancements, in a mostly-compatible way. The IBM Video Graphics Array (VGA), which became ubiquitous (to the point that it is still emulated as the baseline functionality of most modern PC video adapter chips) incorporates a compatible near-superset of the EGA CRTC, still mostly-compatible with the MC6845 (but by this point without the light pen support, which the EGA CRTC retained).

The MC6801 was a single-chip microcomputer (that today would also be called a microcontroller) incorporating a 6802 CPU with 128 bytes of RAM, a 2 KB ROM, a 16-bit timer, 31 programmable parallel I/O lines, and a serial port. (The MC6803 was the same except without the ROM and with fewer different bus configurations.) It could also use the I/O lines as data and address buses to connect to standard M6800 peripherals. The 6801 would execute 6800 code, but it had ten additional instructions, and the execution time of key instructions was reduced. The two 8-bit accumulators could act as a single 16-bit accumulator for double precision addition, subtraction and multiplication. It was initially designed for automotive use, with General Motors as the lead customer. The first application was a trip computer for the 1978 Cadillac Seville. This 35,000 transistor chip was too expensive for wide-scale adoption in automobiles, so a reduced function MC6805 single-chip microcomputer was designed.
The MC6809 was the most advanced 8-bit microprocessor Motorola produced. It had a new instruction set that was similar to the 6800 but abandoned op-code compatibility for improved performance and high-level language support; the 6809 and 6800 were software compatible in that assemblers could (and generally did) generate code which was equivalent to 6800 opcodes that the 6809 did not directly emulate. In that sense, the 6809 was upward compatible with the 6800. The 6809 had two 16-bit index registers, two 16-bit stack pointers, and many instructions to perform 16-bit operations, including the first 8-bit multiply instruction (generating a 16-bit product) in a microprocessor. Other key points of the 6809 design were full support for both position independent code (object code that can run wherever it is loaded in memory) and reentrant code (object code that can be re-invoked when interrupted or by calling itself recursively), features previously seen only in much larger machines such as IBM 360 mainframes.

The MITS Altair 8800, the first successful personal computer, used the Intel 8080 microprocessor and was featured on the January 1975 cover of "Popular Electronics". The first personal computers using the Motorola 6800 were introduced in late 1975. Sphere Corporation of Bountiful, Utah ran a quarter-page advertisement in the July 1975 issue of "Radio-Electronics" for a computer kit with a 6800 microprocessor, of RAM, a video board and a keyboard. This would display 16 lines of 32 characters on a TV or monitor. The Sphere computer kits began shipping in November 1975. Southwest Technical Products Corporation of San Antonio, Texas, officially announced their SWTPC 6800 Computer System in November 1975. Wayne Green visited SWTPC in August 1975 and described the SWTPC computer kit complete with photos of a working system in the October 1975 issue of "73". The SWTPC 6800 was based on the Motorola MEK6800 design evaluation kit chip set and used the MIKBUG ROM Software. The MITS Altair 680 was on the cover of the November 1975 issue of "Popular Electronics". The Altair 680 used a 6800 microprocessor and, unlike the SWTPC machine, also had a front panel with toggle switches and LEDs. The initial design had to be revised and first deliveries of the Altair 680B were in April 1976.

Sphere was a small startup company and had difficulties delivering all of the products they announced. They filed for a Chapter 11 bankruptcy in April 1977. The Altair 680B was popular but MITS focused most of the resources on their Altair 8800 computer system and they exited the hobby market in 1978. The Southwest Technical Products computer was the most successful 6800 based personal computer. Other companies, for instance, Smoke Signal Broadcasting (California), Gimix (Chicago), Midwest Scientific (Olathe, Kansas), and Helix Systems (Hazelwood, Missouri), started producing SWTPC 6800 bus compatible boards and complete systems. Technical Systems Consultants of West Lafayette, Indiana, supplied tape based software for the 6800 (and later 6809) based computers and, after disk systems became available, operating systems and disk software as well. The 8080 systems were far more popular than the 6800 ones.

The Tektronix 4051 Graphics Computing System was introduced in October 1975. This was a professional desktop computer that had a 6800 microprocessor with up to 32 KB of user RAM, 300 KB magnetic tape storage, BASIC in ROM and a 1024 by 780 graphics display. The Tektronix 4051 sold for $7000, rather higher than the personal computers using the 6800.

The 6800 processor was also used in the APF MP1000 game console.

The architecture and instruction set of the 6800 were easy for beginners to understand and Heathkit developed a microprocessor course and the ET3400 6800 trainer. The course and trainer proved popular with individuals and schools.

Motorola's next generation 8-bit microprocessor architecture, the MC6809 (1979), was not binary code compatible with the 6800, but nearly all assembly code would assemble and run on the 6809; 6800 family peripheral chips worked as a matter of course.

The following 6800 assembly language source code is for a subroutine named codice_1 that copies a block of data bytes of a given size from one location to another. The data block is copied one byte at a time, from lowest address to highest.


cnt dw $0000 ; sets aside space for memory addr
src dw $0000 ; sets aside space for memory addr
dst dw $0000 ; sets aside space for memory addr

memcpy public
loop ldx src ;Set IX = src
check tst cnt+0 ;If cnt.H=0,
done rts ;Return
List from "Motorola Microcomputer Components", November 1978
A common requirement for manufacturing companies was to require two or more sources for every part in the products they made. This ensured they could get parts if a supplier had financial problems or a disaster. Initially Motorola selected American Microsystems Inc (AMI) as a second source for the M6800 family. Hitachi, Fujitsu, Fairchild, Rockwell and Thomson Semiconductors were added later. 

Rochester Electronics was Authorized by Freescale/Motorola in 2014 to continue manufacturing any of the 8-bit peripherals and 8-bit processors of this era. Rochester specializes in fully authorized device duplication. Freescale has provided all the source design archives to enable Rochester Electronics for this product and others. At the end of 2016, Rochester was fully qualified and shipping the MC6802 processor, the MC6840 PTM, and the MC6809 processor (including the MC68A09, and MC68B09 versions) and can still be bought today.






</doc>
<doc id="20302" url="https://en.wikipedia.org/wiki?curid=20302" title="Motorola 68020">
Motorola 68020

The Motorola 68020 (""sixty-eight-oh-twenty"", ""sixty-eight-oh-two-oh"" or ""six-eight-oh-two-oh"") is a 32-bit microprocessor from Motorola, released in 1984. It is the successor to the Motorola 68010 and is succeeded by the Motorola 68030. A lower cost version was also made available, known as the 68EC020. In keeping with naming practices common to Motorola designs, the 68020 is usually referred to as the "020", pronounced "oh-two-oh" or "oh-twenty".

The 68020 had 32-bit internal and external data and address buses, compared to the early 680x0 models with 16-bit data and 24-bit address buses. The 68020's ALU was also natively 32-bit, so could perform 32-bit operations in one clock cycle, whereas the 68000 took a minimum of two clock cycles due to its 16-bit ALU. Newer packaging methods allowed the '020 to feature more external pins without the large size that the earlier dual in-line package method required. The 68EC020 lowered cost through a 24-bit address bus. The 68020 was produced at speeds ranging from 12 MHz to 33 MHz.
The 68020 added many improvements over the 68010 including a 32-bit arithmetic logic unit (ALU), 32-bit external data and address buses, extra instructions and additional addressing modes. The 68020 (and 68030) had a proper three-stage pipeline. Though the 68010 had a "loop mode", which sped loops through what was effectively a tiny instruction cache, it held only two short instructions and was thus little used. The 68020 replaced this with a proper instruction cache of 256 bytes, the first 68k series processor to feature true on-chip cache memory.
The previous 68000 and 68010 processors could only access word (16-bit) and long word (32-bit) data in memory if it were word-aligned (located at an even address). The 68020 had no alignment restrictions on data access. Naturally, unaligned accesses were slower than aligned accesses because they required an extra memory access.

The 68020 has a coprocessor interface supporting up to eight coprocessors. The main CPU recognizes "F-line" instructions (with the four most significant opcode bits all one), and uses special bus cycles to interact with a coprocessor to execute these instructions. Two types of coprocessors were defined: floating point units (MC68881 or MC68882 FPUs) and the paged memory management unit (MC68841 or MC68851 PMMU). Only one PMMU can be used with a CPU. In principle, multiple FPUs could be used with a CPU, but it was not commonly done. The coprocessor interface is asynchronous, so it is possible to run the coprocessors at a different clock rate than the CPU.

Multiprocessing support was implemented externally by the use of a RMC pin to indicate an indivisible read-modify-write cycle in progress. All other processors had to hold off memory accesses until the cycle was complete. Software support for multiprocessing included the TAS, CAS and CAS2 instructions.

In a multiprocessor system, coprocessors could not be shared between CPUs. To avoid problems with returns from coprocessor, bus error, and address error exceptions, it was generally necessary in a multiprocessor system for all CPUs to be the same model, and for all FPUs to be the same model as well.

The new instructions included some minor improvements and extensions to the supervisor state, several instructions for software management of a multiprocessing system (which were removed in the 68060), some support for high-level languages which did not get used much (and was removed from future 680x0 processors), bigger multiply (32×32→64 bits) and divide (64÷32→32 bits quotient and 32 bits remainder) instructions, and bit field manipulations.

While the 68000 had 'supervisor mode', it did not meet the Popek and Goldberg virtualization requirements due to the single instruction 'MOVE from SR' being unprivileged but sensitive. Under the 68010 and later, this was made privileged, to better support virtualization software.

The new addressing modes added scaled indexing and another level of indirection to many of the pre-existing modes, and added quite a bit of flexibility to various indexing modes and operations. Though it was not intended, these new modes made the 68020 very suitable for page printing; most laser printers in the early 1990s had a 68EC020 at their core.

The 68020 had a small 256-byte direct-mapped instruction cache, arranged as 64 four-byte entries. Although small, it still made a significant difference in the performance of many applications. The resulting decrease in bus traffic was particularly important in systems relying heavily on DMA.

The 68020 was used in the Apple Macintosh II and Macintosh LC personal computers, Sun 3 workstations, Commodore Amiga 1200, the Hewlett-Packard 8711 Series Network Analyzers and later members of the HP 9000/300 family and the Alpha Microsystems AM-2000. Also the 68020 was an alternative upgrade to the Sinclair QL computer's 68008 in the Super Gold Card interface by Miracle Systems.

The Amiga 2500 and A2500UX was shipped with the A2620 Accelerator using a 68020, a 68881 floating point unit and the 68851 Memory Management Unit. The 2500UX shipped with Amiga Unix, requiring an '020 or '030 processor.

A number of digital oscilloscopes from the mid-80s to the late-90s used the 68020, including the LeCroy 9300 Series (higher end models including "C" suffix models used the more powerful 68EC030; the 9300 models with a 68020 processor can be upgraded to the 68EC030 with a change of the CPU board) and the earlier LeCroy 9400 series (all models excluding the 9400/9400A which used the 68000), along with certain Tektronix TDS Series models.. The HP 54520, 54522, 54540 and 54542 also use the 68020, together with a 68882 math coprocessor.

It is also the processor used on board TGV trains to decode signalling information which is sent to the trains through the rails. It is further being used in the flight control and radar systems of the Eurofighter Typhoon combat aircraft.

The Nortel Networks DMS-100 telephone central office switch also used the 68020 as the first microprocessor of the SuperNode computing core.

For more information on the instructions and architecture see Motorola 68000.

The 68EC020 is a lower cost version of the Motorola 68020. The main difference between the two is that the 68EC020 only has a 24-bit address bus, rather than the 32-bit address bus of the full 68020, and thus is only able to address 16 MB of memory.

The Commodore Amiga 1200 computer and the Amiga CD32 games console used the cost-reduced 68EC020; the Namco System 22 and Taito F3 arcade boards also used this processor. The Atari Jaguar II prototype also featured this to replace the 68000 of the original Atari Jaguar console. It also found use in laser printers. Apple used it in the LaserWriter IIɴᴛx. Kodak used it in the Ektaplus 7016PS, and Dataproducts used it in the LZR 1260.

In 2014, Rochester Electronics has re-established manufacturing capability for the 68020 microprocessor and it is still available today.


</doc>
<doc id="20303" url="https://en.wikipedia.org/wiki?curid=20303" title="The Muppets">
The Muppets

The Muppets are an ensemble cast of puppet characters known for an absurdist, burlesque, and self-referential style of variety-sketch comedy. Created by Jim and Jane Henson in 1955, they are the namesakes of the Disney-owned media franchise that encompasses television, film, music, and other media associated with the characters.

The Muppets originated in the short-form television series "Sam and Friends", which aired from 1955 to 1961. Following appearances on late night talk shows and in advertising during the 1960s, the Muppets began appearing on "Sesame Street" in 1969, and attained celebrity status and international recognition through "The Muppet Show" (1976–1981), which received four Primetime Emmy Award wins and twenty-one nominations during its five-year run.

During the 1970s and 1980s, the Muppets diversified into theatrical films, including "The Muppet Movie" (1979); "The Great Muppet Caper" (1981); and "The Muppets Take Manhattan" (1984). Disney began involvement with them in the late 1980s, during which Henson entered negotiations to sell The Jim Henson Company. The Muppets continued their media presence on television with "Muppet Babies" (1984–91), as well as "The Jim Henson Hour" (1989) and "Muppets Tonight" (1996–98), both of which were similar in format to "The Muppet Show"; and three films: "The Muppet Christmas Carol" (1992), "Muppet Treasure Island" (1996) and "Muppets from Space" (1999).

Disney acquired the Muppets in February 2004, allowing the characters to gain broader public exposure than in previous years. Under Disney, subsequent projects included two films: "The Muppets" (2011) and "Muppets Most Wanted" (2014); a short-lived primetime series (2015–2016); a reboot of "Muppet Babies" (2018–present); and the web television series "Muppets Now" (2020–present).

In their six-decade career, the Muppets have been regarded as a staple of the entertainment industry and popular culture in the United States and English-speaking area generally, being recognized by various cultural institutions and organizations, including the American Film Institute, Academy of Motion Picture Arts and Sciences, Library of Congress, and the Hollywood Walk of Fame.

The Muppets were created by puppeteer Jim Henson in the 1950s; among his earliest creations was Kermit the Frog, who would become Henson's most recognizable character. Originally conceived for an adult audience, Henson claimed, and later recanted, that he coined the term "Muppet" as a portmanteau of the words "marionette" and "puppet". In 1955, the Muppets were introduced in "Sam and Friends", a short-form television series produced for WRC-TV in Washington D.C. Developed by Henson and his future wife Jane Nebel, the series was the first form of puppet media not to incorporate a physical proscenium arch typical of such works, relying instead on the natural framing of the television set through which it was viewed.

During the 1960s, the characters—in particular, Kermit and Rowlf the Dog—appeared in skits on several late-night talk shows and on television commercials, including "The Ed Sullivan Show." Rowlf became the first Muppet character to appear regularly on network television when he began appearing with Jimmy Dean on "The Jimmy Dean Show". In 1966, Joan Ganz Cooney and Lloyd Morrisett began developing a children's educational television program and approached Henson to design a cast of Muppet characters during this stage. Produced by the Children's Television Workshop, the program debuted as "Sesame Street" in 1969.

Henson and his creative team became closely involved with "Sesame Street" during the years that followed; Henson waived his performance fee in exchange for retaining ownership rights to the Muppet characters created for the program. "Sesame Street" garnered a positive response, and the Muppets' involvement in the series was said to be a vital component of its increasing popularity, providing an "effective and pleasurable viewing" method of presentation for its educational curriculum.

In the early 1970s, the Muppets continued their presence in television, primarily appearing in "The Land of Gorch" segments during the first season of "Saturday Night Live". As his involvement with "Sesame Street" continued, Henson began developing a network television series focusing on the Muppets; as opposed to "Sesame Street", however, this series would be aimed at a more adult audience and focus largely on sketch comedy. Two television pilots, "The Muppets Valentine Show" and "", aired on ABC in 1974 and 1975, respectively.

After ABC passed on the pilots and other networks in the United States expressed little interest in the project, British producer Lew Grade approached Henson and agreed to co-produce the series for Associated Television. Debuting in 1976, "The Muppet Show" introduced new characters such as Miss Piggy, Fozzie Bear, and Gonzo, alongside existing characters such as Kermit and Rowlf. Aired in first-run syndication in the United States, "The Muppet Show" became increasingly popular due to its sketch-variety format, unique form of vaudeville-style humor, and prolific roster of guest stars. It was nominated for twenty-one Primetime Emmy Awards during its run, winning four, including Outstanding Variety Series in 1978. The success of "The Muppet Show" allowed Henson Associates to diversify into theatrical films, the first of which, "The Muppet Movie", was released in 1979.

Following "The Muppet Movie" were "The Great Muppet Caper" and "The Muppets Take Manhattan", released in 1981 and 1984, respectively. Collectively, the three films received four Academy Award nominations. "The Muppet Show" ended its five-season run in 1981. In 1983, Henson debuted "Fraggle Rock", which aired on HBO in the United States until 1987.

In 1989, Henson entered negotiations with Michael Eisner and The Walt Disney Company, in which the latter would acquire Jim Henson Productions and, in turn, the Muppets. Disney expressed interest in purchasing the company for $150 million. Eisner was also interested in acquiring the "Sesame Street" Muppet characters. Henson declined the proposal, however, considering it a "non-starter" for the deal. As discussions continued, Henson and Walt Disney Imagineering preemptively began developing Muppets-themed attractions for the Disney-MGM Studios at Walt Disney World.

However, the proposed merger was canceled after Henson's death in 1990. Nevertheless, Disney initiated a licensing agreement with Henson to continue developing Muppets attractions. The following year, Muppet*Vision 3D debuted at Disney–MGM Studios, the only attraction successfully developed from the original plans. Disney also co-produced the fourth and fifth Muppets films, "The Muppet Christmas Carol" (1992) and "Muppet Treasure Island" (1996), with Henson. The characters subsequently starred in "Muppets Tonight", which aired on ABC from 1996 to 1998; and a sixth film, "Muppets from Space", released by Columbia Pictures in 1999.

In 2000, Henson was sold to EM.TV & Merchandising AG for $680 million. However, EM.TV's stock collapsed and the Henson family re-acquired the company in 2003, with the exception of the "Sesame Street" characters, which were in the interim sold to Sesame Workshop.

Fourteen years after initial negotiations began, Disney acquired the Muppets intellectual property from Henson for $75 million on February 17, 2004. The acquisition consisted of most of the Muppets film and television library, as well as the "Bear in the Big Blue House" television series. Exceptions included the "Sesame Street" characters; the "Fraggle Rock" characters, which were retained by Henson; and the distribution rights to four films: "The Muppets Take Manhattan", "Muppets from Space", and "Kermit's Swamp Years," which were retained by Sony Pictures Entertainment; and "It's a Very Merry Muppet Christmas Movie", retained by NBCUniversal Television Distribution. Following the acquisition, Disney formed The Muppets Studio (originally The Muppets Holding Company), a wholly owned subsidiary responsible for managing the characters and franchise. As a result, the term "Muppet" became a legal trademark of Disney; under license from Disney, Sesame Workshop continues to use the term for their characters, as well as archival footage of Kermit the Frog.

Henson retains the rights to several productions featuring the Disney-owned Muppet characters, including "Emmet Otter's Jug-Band Christmas"; "The Christmas Toy"; ""; "Henson's Place"; "Billy Bunny's Animal Songs"; the original "Dog City" special; and "Donna's Day". While some of these have since been released uncut, most current releases of "Emmet Otter's Jug-Band Christmas" and "The Christmas Toy" omit the appearances by Kermit the Frog. The 2015 ABC Family airing, the 2017 DVD and the 2018 Blu-ray releases of Emmet Otter's Jugband Christmas and the Amazon Prime Video release of The Christmas Toy re-instate Kermit's scenes.

After the acquisition was complete, Disney gradually began reintroducing the franchise to the mainstream, promoting the Muppets across different parts of the company. The Muppets made appearances on Disney Channel and starred in the ABC television film, "The Muppets' Wizard of Oz" (2005). A television special, "", premiered on NBC on December 17, 2008. As a method of regaining a wider audience, Disney produced a series of vignettes for YouTube and Disney.com. A "Bohemian Rhapsody" cover version was among these projects and immediately went viral, ultimately amassing 90 million views and winning two Webby Awards. In 2010, the Muppets starred in "The Muppets Kitchen with Cat Cora", which co-starred Cat Cora and showcased cooking demonstrations. That same year, Disney used the Muppets to promote their volunteerism program at the company's theme parks. A Halloween special featuring the Muppets was developed during that time and expected to air on ABC that October, but was canceled.

In 2011, the Muppets were featured in an eponymous seventh film, intended to serve as a "creative reboot" for the characters. Walt Disney Pictures had been furthering development on a Muppets film since 2008, when it considered adapting an unused screenplay by Jerry Juhl. Directed by James Bobin; written by Jason Segel and Nicholas Stoller; and starring Segel, Amy Adams, Chris Cooper, and Rashida Jones, "The Muppets" was a critical and commercial success, and won an Academy Award for Best Original Song. During the film's publicity campaign, the Muppets appeared in promotional advertisements and effusive marketing efforts by Disney and were also featured in a promotional video for Google+. In March 2012, the Muppets received a collective star on the Hollywood Walk of Fame. That year, the Muppets hosted a "Just for Laughs" comedy gala in Montreal.

Following the successful performance of "The Muppets", Disney announced an eighth film in 2012, with Bobin and Stoller returning to direct and write, respectively. "Muppets Most Wanted" was released in 2014, and starred Ricky Gervais; Tina Fey; and Ty Burrell. The film received positive reviews, but was a commercial disappointment at the box office.

Disney Theatrical Productions announced in 2013 that a live show based on the Muppets was in active development and that a 15-minute show had been conducted by Thomas Schumacher to see how the technical components would work. "Muppet Moments", an interstitial television series, premiered on Disney Junior in April 2015. The short-form series features conversations between the Muppets and young children.

After the lackluster release of "Muppets Most Wanted", Disney was interested in expanding the Muppets' presence across other media platforms, particularly in television. Discussions for a new primetime series began internally within The Muppets Studio. By April 2015, Bill Prady was commissioned to write a script for a pilot with the working title "Muppets 2015". In May 2015, ABC commissioned an eponymous series, co-developed by Prady and Bob Kushell and directed by Randall Einhorn. Developed as a parody of other mockumentary-style series such as "The Office", "Modern Family", and "Parks and Recreation", "The Muppets" portrayed the everyday personal and professional lives of the Muppets in Los Angeles, as they produced a late-night talk show hosted by Miss Piggy. The series premiered on September 22, 2015 in the United States, and received mixed reviews, with critics praising the show's adult humor, but criticizing the writing and characterization. "The Muppets" was canceled after one season, which concluded on March 1, 2016.

In September 2017, the Muppets performed a live concert series at the Hollywood Bowl, hosted by Bobby Moynihan. This performance was followed by a second event in July 2018 at London's O2 Arena, their first outside of the United States.

In February 2018, Disney announced that a web television reboot series was in development for Disney+. The project, known as "Muppets Live Another Day", was intended as a limited-run series set in the 1980s after the events of "The Muppets Take Manhattan" and depicted Kermit recruiting the Muppets to locate Rowlf the Dog after his disappearance. The series was intended to be directed by Jason Moore; written by Josh Gad, Adam Horowitz and Eddy Kitsis; produced by ABC Signature Studios and The Muppets Studio, and feature original music by Robert Lopez and Kristen Anderson-Lopez. After an executive change at The Muppets Studio that prompted a different creative direction for the Muppets, Disney canceled development on the project in September 2019. A second Disney+ series, "Muppets Now", a short-form improvisational comedy series, was announced in August 2019; and was released on July 31, 2020.

The principal characters of "The Muppet Show" and subsequent media include Kermit the Frog; Miss Piggy; Fozzie Bear; Gonzo; Rowlf the Dog; Scooter; Rizzo the Rat; Pepe the King Prawn; Dr. Bunsen Honeydew; Beaker; Statler and Waldorf; the Swedish Chef; Sam Eagle; Walter; and the Electric Mayhem, fronted by Dr. Teeth (lead vocals, keyboards) and consisting of Animal (drums), Floyd Pepper (bass, background vocals), Janice (guitar, background vocals), Zoot (saxophone), and occasionally Lips (trumpet).

As well as "The Muppet Show", the characters are popular for their appearances on "Sesame Street" and "Fraggle Rock"; and also feature in "The Jimmy Dean Show", "The Jim Henson Hour", "Muppets Tonight", "Bear in the Big Blue House", "", and "The Muppets". An adult-oriented segment, "The Land of Gorch", was a regular feature in the first season of "Saturday Night Live". Guest stars on "Saturday Night Live" occasionally include both the Muppets and "Sesame Street" characters, as well as Muppet likenesses of real people; these likenesses appear recurrently in early episodes of "The Muppet Show" and on "Sesame Street", and appear occasionally on other series such as "30 Rock".

Following Disney's acquisition of the Muppets, puppets created by The Jim Henson Company are no longer referred to as Muppets. Puppets created by Jim Henson's Creature Shop, including those in "Labyrinth" and "The Dark Crystal", have never been considered Muppets, as they are generally more complex in design and performance than regular Muppets. At Henson's suggestion, the "Star Wars" character Yoda was originally performed by Frank Oz, and has been loosely described as a Muppet in media and reference works; he is not, however, and Henson otherwise had no involvement in the character's conception.

At the start of the Muppets' formation, Jim and Jane Henson were the group's only performers. In 1961, Jane retired to focus on raising their children. Seeking additional performers, Jim came into contact with Frank Oz that year. Although interested, Oz initially declined due to his youth and commitment to high school, and instead suggested Jerry Juhl, who worked with Oz at the Vagabond Puppet Theater in Oakland, California. Upon graduating, Oz subsequently joined in August 1963. By the time "The Muppet Show" began, the primary cast of performers grew to consist of Henson; Oz; Dave Goelz; Jerry Nelson; Richard Hunt; and later, Steve Whitmire, while Juhl became head writer for the series. From "The Muppet Show" onward, Kevin Clash; Kathryn Mullen; Louise Gold; Karen Prell; Fran Brill, Caroll Spinney; and Brian Henson performed several minor characters and assisted the main performers with puppeteering. Many of these puppeteers performed characters across "The Muppet Show," "Sesame Street", "Fraggle Rock", and other Henson-related projects.

Henson, Hunt, and Nelson continued performing until their deaths in 1990, 1992, and 2012, respectively. Goelz, Whitmire, and Bill Barretta, who joined the main cast of performers in the mid-1990s, assumed Henson's characters, with Whitmire cast in the role of Beaker and Nelson cast in the role of Statler, both previously performed by Hunt. The remainder of Hunt's characters were left without a stable performer until David Rudman was cast in those roles in the late 2000s. Oz continued performing until his retirement from puppeteering in 2000; Eric Jacobson was cast as his characters beginning in 2002. At Nelson's behest, Matt Vogel gradually began performing his characters in 2008. Peter Linz joined the main cast in 2011, debuting the role of Walter in "The Muppets".

Whitmire was dismissed from the cast in 2016, with Vogel cast as Kermit the Frog in 2017, and most of Whitmire's other characters assumed by the remainder of the cast. The Muppets are currently performed by a cast of six principal puppeteers: Vogel, Jacobson, Goelz, Barretta, Rudman, and Linz.

The majority of the Muppets are designed as hand puppets, with several characters utilizing rods. Common design elements of the Muppets include wide mouths and large protruding eyes. Most of the Muppets are molded or carved out of various types of foam and covered with any felt-like material. The characters may represent humans; anthropomorphic characters; realistic animals; robots; extraterrestrial or mythical creatures; or other forms of abstract characters.

The Muppets are distinguished from ventriloquist dummies, which are usually animated only in the head and face, in that their arms or other features are also animated. They are also generally made of softer material. They are presented as being independent of the puppeteer, officially known as a "Muppet performer", who is usually hidden behind a set or outside of the camera frame. Using the camera frame to this advantage was an innovation of the Muppets. Prior to this, a stage was used to mask the performers, as would be the case in a live performance. Sometimes, they are seen full-bodied; in most cases, invisible strings are used to manipulate these puppets, with vocals added at a later point. Performers often use dollies to mimic walking.

Since 2006, Disney has contracted Puppet Heap to produce and maintain newer models of the Muppets. During most performances, the performer holds the character above their head or in front of their body, with one hand operating the head and mouth and the other manipulating the hands and arms, either with two separate control rods or – in the case of "live-hand" Muppets – wearing the hands similarly to gloves. One consequence of this design is that most of the Muppets are left-handed, with the performer using their right hand to operate the head while operating the arm with their left hand.

For more complex Muppets, several performers may operate a single character, with the performer controlling the mouth usually voicing the character. As technology has advanced, the Jim Henson team and other performers have developed several means to operate the Muppets for film and television; these include the use of suspended rigs, internal motors, remote manipulators, and computer enhanced and superimposed images. Creative use of different technologies has allowed for scenes in which the Muppets appear to exhibit complex movements wholly independently of the performer.

In his book "Street Gang", author Michael Davis wrote that the characters tend to develop "organically", alluding to the performers taking up to a year to develop their characters and voices. They are also "test-driven, passed around from one Henson troupe member to another in the hope of finding the perfect human-Muppet match". When interacting with them, children believed that Muppets were living beings, even when the performers were present.

On September 17, 2002, Rhino Records released "", a compilation album of music from "The Muppet Show" and subsequent film releases. With John Denver, "" was produced and released in 1979.

Under Disney ownership, The Muppets album releases have been issued by Walt Disney Records; as well as new album releases, some albums have been re-released, including "The Muppet Christmas Carol" in 2005 and "The Muppet Movie" in 2013. Legal music publishing rights to The Muppets songs are controlled by Fuzzy Muppet Songs and Mad Muppet Melodies, imprints of Disney Music Publishing.

The Muppets appear at the Walt Disney Parks and Resorts, having first appeared at Walt Disney World in 1990. Their first featured attraction, "Here Come the Muppets", was a live stage show that opened shortly after Jim Henson's death and ran at Disney's Hollywood Studios (known at that time as Disney-MGM Studios) for a year. Muppet*Vision 3D, a 4D film attraction that also uses audio-animatronic characters, opened at Disney's Hollywood Studios on May 16, 1991, exactly one year after Henson's death. It is notable as Henson's final directorial effort. Muppet*Vision 3D subsequently opened at Disney California Adventure, on February 8, 2001; this version closed in 2014.

The Muppets also were featured in "The Muppets Present...Great Moments in American History" at the Magic Kingdom from 2016 to 2020; and the Muppet Mobile Lab at Epcot since 2007. The latter attraction is a free-roving vehicle with audio-animatronics of Bunsen Honeydew and Beaker. As part of Disney's Living Character Initiative, it premiered at Epcot and was later previewed at Disney California Adventure and Hong Kong Disneyland.

In 2010, the Muppets were the face of the "Give a Day, Get a Disney Day" charity campaign. Kermit, Miss Piggy, and Sweetums appeared in daily parades at Disneyland and Magic Kingdom. The Muppets appeared in television and print ads for the campaign and were featured prominently on the campaign's Web site.

Disney has released numerous collector pins featuring the Muppets since 2004. These include Limited Edition pins, Hidden Mickey pin collections, mystery pin sets, 2008 pin sets promoting "The Muppets", cast lanyard pins, and assorted individual rack pins. Over 100 pins displaying the characters have been released overall.

Among other print media, the Muppets have featured in comics since the 1970s. An eponymous comic strip by Guy and Brad Gilchrist first ran on September 21, 1981 in over 500 daily newspapers, six months after "The Muppet Show" ended its five-year run. By the end of its run in 1986, the comic strip was seen in over 660 newspapers worldwide. Many of the strips were compiled in various book collections. Special strips were also created in color, exclusively for issues of "Muppet Magazine".

"Muppet Magazine" was published from 1983 to 1989. The magazine was presented as being run by the Muppets themselves and included such features as celebrity interviews and comic stories.

The only Muppets film adapted as a comic book was "The Muppets Take Manhattan". The comic book series was adapted by Marvel Comics in 1984, as the 68-page story in "Marvel Super Special" issue #32. The adaptation was later re-printed into three limited series issues, released under Marvel's Star Comics imprint (November 1984 – January 1985).

In the wake of "Muppet Babies"' success, Star Comics adapted the series into a bi-monthly title, of which twenty-six issues were produced.

The final issue of "Disney Adventures", released in 2007, included a one-page strip by Roger Langridge. In 2009, Boom! Studios began publishing a series of comic books based on "The Muppet Show", written and illustrated by Langridge. Following two mini-series, an ongoing series, "The Muppet Show Comic Book", was published for eleven issues. Additionally, Boom! Studios published fairy tale adaptations centered on the Muppets. In 2012, the Langridge series was transferred to Marvel Comics, which released an omnibus edition in 2013.

The Muppets' prevalence in popular culture is such that the characters have become regarded as celebrities in their own right. The Muppets have a collective star on the Hollywood Walk of Fame, with Kermit having been previously individually inducted in 2002. The characters have appeared at the Academy Awards and Emmy Awards; made cameo appearances in films including "Rocky III", "An American Werewolf in London", and "Mr. Magorium's Wonder Emporium"; and have been interviewed on the news magazine "60 Minutes".

Kermit was interviewed by Jon Stewart on "The Daily Show"; guest hosted "The Tonight Show", "Jimmy Kimmel Live!", "", "America's Funniest Home Videos", and an April Fools' Day edition of "Larry King Live"; and has served as Grand Marshal of the Tournament of Roses Parade. The characters also appeared on "The Cosby Show" and "The Torkelsons", among other sitcoms. The music video for Weezer's "Keep Fishin'" is aesthetically based on "The Muppet Show" and consists of the band interacting with the characters.

On September 28, 2005, the United States Postal Service released a "Jim Henson and the Muppets" postage stamp series. The Muppets also appeared on "Dick Clark's New Year's Rockin' Eve" on December 31, 2007, in which Kermit and other characters presented segments following advertising breaks. After one such segment, with Kermit in Times Square, co-host Ryan Seacrest thanked "Kerms" for his assistance. Miss Piggy has appeared as a guest on "The Late Late Show with Craig Ferguson", and Kermit appeared on "Hollywood Squares" and as one of the celebrity commentators on VH1's "I Love" documentary series. The Muppets, as well as the title character of "Bear in the Big Blue House", have made frequent appearances on "The Jerry Lewis MDA Labor Day Telethon".

On July 25, 2007, the Center for Puppetry Arts in Atlanta announced the opening of the Jim Henson Wing, which would house up to 700 retired Muppet characters. The wing, first set to open in 2012 with films, sketches, and other materials from the Jim Henson Company archives, eventually opened as a gallery within the "Worlds of Puppetry" exhibition at the Center in November 2015.

Muppet-like characters star in the Broadway musical "Avenue Q", the concept of which is a parody of "Sesame Street". The Peter Jackson film "Meet the Feebles", a satire on the television industry, is largely reminiscent of "The Muppet Show". A Kermit the Frog stuffed toy rigged to spray fake vomit recurred on "Late Night with Conan O'Brien", and the Muppets were frequently preempted at the beginning of episodes of "You Can't Do That on Television." The sitcom series "Greg the Bunny" centered on sentient hand puppets working on a Muppet-like children's show. Among other examples, series such as "The Simpsons", "Family Guy", "The West Wing" and "Robot Chicken" have referenced the Muppets.

The term "muppet" is commonly used in the British Isles and Australasia to refer to a stupid or ineffectual person.




</doc>
<doc id="20306" url="https://en.wikipedia.org/wiki?curid=20306" title="Mole fraction">
Mole fraction

In chemistry, the mole fraction or molar fraction (x) is defined as unit of the amount of a constituent (expressed in moles), "n" divided by the total amount of all constituents in a mixture (also expressed in moles), "n":.These expression is given below:-

The sum of all the mole fractions is equal to 1:

The same concept expressed with a denominator of 100 is the mole percent or molar percentage or molar proportion (mol%).

The mole fraction is also called the amount fraction. It is identical to the number fraction, which is defined as the number of molecules of a constituent "N" divided by the total number of all molecules "N". The mole fraction is sometimes denoted by the lowercase Greek letter "χ" (chi) instead of a Roman "x". For mixtures of gases, IUPAC recommends the letter "y".

The National Institute of Standards and Technology of the United States prefers the term amount-of-substance fraction over mole fraction because it does not contain the name of the unit mole.

Whereas mole fraction is a ratio of moles to moles, molar concentration is a quotient of moles to volume.

The mole fraction is one way of expressing the composition of a mixture with a dimensionless quantity; mass fraction (percentage by weight, wt%) and volume fraction (percentage by volume, vol%) are others.

Mole fraction is used very frequently in the construction of phase diagrams. It has a number of advantages:

Differential quotients can be formed at constant ratios like those above:

or 

Ratios X, Y, Z of mole fractions can be written for ternary and multicomponent systems:

These can be used for solving PDE like:

or 

This equality can be rearranged to have differential quotient of mole amounts or fractions on one side.

or 

Mole amounts can be eliminated by forming ratios:

Thus the ratio of chemical potentials becomes:

Similarly the ratio for the multicomponents system becomes

The mass fraction "w" can be calculated using the formula

where "M" is the molar mass of the component "i" and "M̄" is the average molar mass of the mixture.

The mixing of two pure components can be expressed introducing the amount or molar mixing ratio of them formula_15. Then the mole fractions of the components will be:

The amount ratio equals the ratio of mole fractions of components:

due to division of both numerator and denominator by the sum of molar amounts of components. This property has consequences for representations of phase diagrams using, for instance, ternary plots.

Mixing binary mixtures with a common component gives a ternary mixture with certain mixing ratios between the three components. These mixing ratios from the ternary and the corresponding mole fractions of the ternary mixture x, x, x can be expressed as a function of several mixing ratios involved, the mixing ratios between the components of the binary mixtures and the mixing ratio of the binary mixtures to form the ternary one.

Multiplying mole fraction by 100 gives the mole percentage, also referred as amount/amount percent (abbreviated as n/n%).

The conversion to and from mass concentration "ρ" is given by:

where "M̄" is the average molar mass of the mixture.

The conversion to molar concentration "c" is given by:

where "M̄" is the average molar mass of the solution, "c" is the total molar concentration and "ρ" is the density of the solution.

The mole fraction can be calculated from the masses "m" and molar masses "M" of the components:

In a spatially non-uniform mixture, the mole fraction gradient triggers the phenomenon of diffusion.


</doc>
<doc id="20308" url="https://en.wikipedia.org/wiki?curid=20308" title="Mary Cassatt">
Mary Cassatt

Mary Stevenson Cassatt (; May 22, 1844June 14, 1926) was an American painter and printmaker. She was born in Allegheny City, Pennsylvania (now part of Pittsburgh's North Side), but lived much of her adult life in France where she befriended Edgar Degas and exhibited with the Impressionists. Cassatt often created images of the social and private lives of women, with particular emphasis on the intimate bonds between mothers and children.

She was described by Gustave Geffroy as one of "les trois grandes dames" (the three great ladies) of Impressionism alongside Marie Bracquemond and Berthe Morisot. In 1879, Diego Martelli compared her to Degas, as they both sought to depict movement, light, and design in the most modern sense.

Cassatt was born in Allegheny City, Pennsylvania, which is now part of Pittsburgh. She was born into an upper-middle-class family: Her father, Robert Simpson Cassat (later Cassatt), was a successful stockbroker and land speculator. He was descended from French Huguenot Jacques Cossart, who came to New Amsterdam in 1662. Her mother, Katherine Kelso Johnston, came from a banking family. Katherine Cassatt, educated and well-read, had a profound influence on her daughter. To that effect, Cassatt's lifelong friend Louisine Havemeyer wrote in her memoirs: "Anyone who had the privilege of knowing Mary Cassatt's mother would know at once that it was from her and her alone that [Mary] inherited her ability." The ancestral name had been Cossart. A distant cousin of artist Robert Henri, Cassatt was one of seven children, of whom two died in infancy. One brother, Alexander Johnston Cassatt, later became president of the Pennsylvania Railroad. The family moved eastward, first to Lancaster, Pennsylvania, then to the Philadelphia area, where she started her schooling at the age of six.

Cassatt grew up in an environment that viewed travel as integral to education; she spent five years in Europe and visited many of the capitals, including London, Paris, and Berlin. While abroad she learned German and French and had her first lessons in drawing and music. It is likely that her first exposure to French artists Jean Auguste Dominique Ingres, Eugène Delacroix, Camille Corot, and Gustave Courbet was at the Paris World's Fair of 1855. Also in the exhibition were Edgar Degas and Camille Pissarro, both of whom were later her colleagues and mentors.

Though her family objected to her becoming a professional artist, Cassatt began studying painting at the Pennsylvania Academy of the Fine Arts in Philadelphia at the early age of 15. Part of her parents' concern may have been Cassatt's exposure to feminist ideas and the bohemian behavior of some of the male students. As such, Cassatt and her network of friends were lifelong advocates of equal rights for the sexes. Although about 20% of the students were female, most viewed art as a socially valuable skill; few of them were determined, as Cassatt was, to make art their career. She continued her studies from 1861 through 1865, the duration of the American Civil War. Thomas Eakins was among her fellow students; later Eakins was forced to resign as director of the Academy.

Impatient with the slow pace of instruction and the patronizing attitude of the male students and teachers, she decided to study the old masters on her own. She later said: "There was no teaching" at the Academy. Female students could not use live models, until somewhat later, and the principal training was primarily drawing from casts.

Cassatt decided to end her studies: At that time, no degree was granted. After overcoming her father's objections, she moved to Paris in 1866, with her mother and family friends acting as chaperones. Since women could not yet attend the École des Beaux-Arts, Cassatt applied to study privately with masters from the school and was accepted to study with Jean-Léon Gérôme, a highly regarded teacher known for his hyper-realistic technique and his depiction of exotic subjects. (A few months later Gérôme also accepted Eakins as a student.) Cassatt augmented her artistic training with daily copying in the Louvre, obtaining the required permit, which was necessary to control the "copyists", usually low-paid women, who daily filled the museum to paint copies for sale. The museum also served as a social place for Frenchmen and American female students, who, like Cassatt, were not allowed to attend cafes where the avant-garde socialized. In this manner, fellow artist and friend Elizabeth Jane Gardner met and married famed academic painter William-Adolphe Bouguereau.

Toward the end of 1866, she joined a painting class taught by Charles Joshua Chaplin, a genre artist. In 1868, Cassatt also studied with artist Thomas Couture, whose subjects were mostly romantic and urban. On trips to the countryside, the students drew from life, particularly the peasants going about their daily activities. In 1868, one of her paintings, "A Mandoline Player", was accepted for the first time by the selection jury for the Paris Salon. With Elizabeth Jane Gardner, whose work was also accepted by the jury that year, Cassatt was one of two American women to first exhibit in the Salon. "A Mandoline Player" is in the Romantic style of Corot and Couture, and is one of only two paintings from the first decade of her career that is documented today.

The French art scene was in a process of change, as radical artists such as Courbet and Édouard Manet tried to break away from accepted Academic tradition and the Impressionists were in their formative years. Cassatt's friend Eliza Haldeman wrote home that artists "are leaving the Academy style and each seeking a new way, consequently just now everything is Chaos." Cassatt, on the other hand, continued to work in the traditional manner, submitting works to the Salon for over ten years, with increasing frustration.

Returning to the United States in the late summer of 1870—as the Franco-Prussian War was starting—Cassatt lived with her family in Altoona. Her father continued to resist her chosen vocation, and paid for her basic needs, but not her art supplies. Cassatt placed two of her paintings in a New York gallery and found many admirers but no purchasers. She was also dismayed at the lack of paintings to study while staying at her summer residence. Cassatt even considered giving up art, as she was determined to make an independent living. She wrote in a letter of July 1871, "I have given up my studio & torn up my father's portrait, & have not touched a brush for six weeks nor ever will again until I see some prospect of getting back to Europe. I am very anxious to go out west next fall & get some employment, but I have not yet decided where."

Cassatt traveled to Chicago to try her luck, but lost some of her early paintings in the Great Chicago Fire of 1871. Shortly afterward, her work attracted the attention of Roman Catholic Bishop Michael Domenec of Pittsburgh, who commissioned her to paint two copies of paintings by Correggio in Parma, Italy, advancing her enough money to cover her travel expenses and part of her stay. In her excitement she wrote, "O how wild I am to get to work, my fingers farely itch & my eyes water to see a fine picture again". With Emily Sartain, a fellow artist from a well-regarded artistic family from Philadelphia, Cassatt set out for Europe again.

Within months of her return to Europe in the autumn of 1871, Cassatt's prospects had brightened. Her painting "Two Women Throwing Flowers During Carnival" was well received in the Salon of 1872, and was purchased. She attracted much favorable notice in Parma and was supported and encouraged by the art community there: "All Parma is talking of Miss Cassatt and her picture, and everyone is anxious to know her".

After completing her commission for the bishop, Cassatt traveled to Madrid and Seville, where she painted a group of paintings of Spanish subjects, including "Spanish Dancer Wearing a Lace Mantilla" (1873, in the National Museum of American Art, Smithsonian Institution). In 1874, she made the decision to take up residence in France. She was joined by her sister Lydia who shared an apartment with her. Cassatt opened a studio in Paris. Louisa May Alcott's sister, Abigail May Alcott, was then an art student in Paris and visited Cassatt. Cassatt continued to express criticism of the politics of the Salon and the conventional taste that prevailed there. She was blunt in her comments, as reported by Sartain, who wrote: "she is entirely too slashing, snubs all modern art, disdains the Salon pictures of Cabanel, Bonnat, all the names we are used to revere".

Cassatt saw that works by female artists were often dismissed with contempt unless the artist had a friend or protector on the jury, and she would not flirt with jurors to curry favor. Her cynicism grew when one of the two pictures she submitted in 1875 was refused by the jury, only to be accepted the following year after she darkened the background. She had quarrels with Sartain, who thought Cassatt too outspoken and self-centered, and eventually they parted. Out of her distress and self-criticism, Cassatt decided that she needed to move away from genre paintings and onto more fashionable subjects, in order to attract portrait commissions from American socialites abroad, but that attempt bore little fruit at first.

In 1877, both her entries were rejected, and for the first time in seven years she had no works in the Salon. At this low point in her career she was invited by Edgar Degas to show her works with the Impressionists, a group that had begun their own series of independent exhibitions in 1874 with much attendant notoriety. The Impressionists (also known as the "Independents" or "Intransigents") had no formal manifesto and varied considerably in subject matter and technique. They tended to prefer plein air painting and the application of vibrant color in separate strokes with little pre-mixing, which allows the eye to merge the results in an "impressionistic" manner. The Impressionists had been receiving the wrath of the critics for several years. Henry Bacon, a friend of the Cassatts, thought that the Impressionists were so radical that they were "afflicted with some hitherto unknown disease of the eye". They already had one female member, artist Berthe Morisot, who became Cassatt's friend and colleague.

Cassatt admired Degas, whose pastels had made a powerful impression on her when she encountered them in an art dealer's window in 1875. "I used to go and flatten my nose against that window and absorb all I could of his art," she later recalled. "It changed my life. I saw art then as I wanted to see it." She accepted Degas' invitation with enthusiasm and began preparing paintings for the next Impressionist show, planned for 1878, which (after a postponement because of the World's Fair) took place on April 10, 1879. She felt comfortable with the Impressionists and joined their cause enthusiastically, declaring: "we are carrying on a despairing fight & need all our forces". Unable to attend cafes with them without attracting unfavorable attention, she met with them privately and at exhibitions. She now hoped for commercial success selling paintings to the sophisticated Parisians who preferred the avant-garde. Her style had gained a new spontaneity during the intervening two years. Previously a studio-bound artist, she had adopted the practice of carrying a sketchbook with her while out-of-doors or at the theater, and recording the scenes she saw.

In 1877, Cassatt was joined in Paris by her father and mother, who returned with her sister Lydia, all eventually to share a large apartment on the fifth floor of 13, Avenue Trudaine, (). Mary valued their companionship, as neither she nor Lydia had married. A case was made that Mary suffered from narcissistic disturbance, never completing the recognition of herself as a person outside of the orbit of her mother. Mary had decided early in life that marriage would be incompatible with her career. Lydia, who was frequently painted by her sister, suffered from recurrent bouts of illness, and her death in 1882 left Cassatt temporarily unable to work.

Cassatt's father insisted that her studio and supplies be covered by her sales, which were still meager. Afraid of having to paint "potboilers" to make ends meet, Cassatt applied herself to produce some quality paintings for the next Impressionist exhibition. Three of her most accomplished works from 1878 were "Portrait of the Artist" (self-portrait), "Little Girl in a Blue Armchair", and "Reading Le Figaro" (portrait of her mother).

Degas had considerable influence on Cassatt. Both were highly experimental in their use of materials, trying distemper and metallic paints in many works, such as "Woman Standing Holding a Fan", 1878-79 (Amon Carter Museum of American Art).

She became extremely proficient in the use of pastels, eventually creating many of her most important works in this medium. Degas also introduced her to etching, of which he was a recognized master. The two worked side by side for a while, and her draftsmanship gained considerable strength under his tutelage. One example of her thoughtful approach to the medium of drypoint as a mode for reflecting on her status as an artist is 'Reflection' of 1889–90, which has recently been interpreted as a self-portrait. Degas in turn depicted Cassatt in a series of etchings recording their trips to the Louvre. She treasured his friendship but learned not to expect too much from his fickle and temperamental nature after a project they were collaborating on at the time, a proposed journal devoted to prints, was abruptly dropped by him. The sophisticated and well-dressed Degas, then forty-five, was a welcome dinner guest at the Cassatt residence, and likewise they at his "soirées".

The Impressionist exhibit of 1879 was the most successful to date, despite the absence of Renoir, Sisley, Manet and Cézanne, who were attempting once again to gain recognition at the Salon. Through the efforts of Gustave Caillebotte, who organized and underwrote the show, the group made a profit and sold many works, although the criticism continued as harsh as ever. The "Revue des Deux Mondes" wrote, "M. Degas and Mlle. Cassatt are, nevertheless, the only artists who distinguish themselves... and who offer some attraction and some excuse in the pretentious show of window dressing and infantile daubing".

Cassatt displayed eleven works, including "Lydia in a Loge, Wearing a Pearl Necklace, (Woman in a Loge)". Although critics claimed that Cassatt's colors were too bright and that her portraits were too accurate to be flattering to the subjects, her work was not savaged as was Monet's, whose circumstances were the most desperate of all the Impressionists at that time. She used her share of the profits to purchase a work by Degas and one by Monet. She participated in the Impressionist Exhibitions that followed in 1880 and 1881, and she remained an active member of the Impressionist circle until 1886. In 1886, Cassatt provided two paintings for the first Impressionist exhibition in the US, organized by art dealer Paul Durand-Ruel. Her friend Louisine Elder married Harry Havemeyer in 1883, and with Cassatt as advisor, the couple began collecting the Impressionists on a grand scale. Much of their vast collection is now in the Metropolitan Museum of Art in New York City.

Cassatt also made several portraits of family members during that period, of which "Portrait of Alexander Cassatt and His Son Robert Kelso" (1885) is one of her best regarded. Cassatt's style then evolved, and she moved away from Impressionism to a simpler, more straightforward approach. She began to exhibit her works in New York galleries as well. After 1886, Cassatt no longer identified herself with any art movement and experimented with a variety of techniques.

Cassatt and her contemporaries enjoyed the wave of feminism that occurred in the 1840s, allowing them access to educational institutions at newly coed colleges and universities, such as Oberlin and the University of Michigan. Likewise, women's colleges such as Vassar, Smith and Wellesley opened their doors during this time. Cassat was an outspoken advocate for women's equality, campaigning with her friends for equal travel scholarships for students in the 1860s, and the right to vote in the 1910s.

Mary Cassatt depicted the "New Woman" of the 19th century from the woman's perspective. As a successful, highly trained woman artist who never married, Cassatt—like Ellen Day Hale, Elizabeth Coffin, Elizabeth Nourse and Cecilia Beaux—personified the "New Woman". She "initiated the profound beginnings in recreating the image of the 'new' women", drawn from the influence of her intelligent and active mother, Katherine Cassatt, who believed in educating women to be knowledgeable and socially active. She is depicted in "Reading 'Le Figaro' "(1878).

Although Cassatt did not explicitly make political statements about women's rights in her work, her artistic portrayal of women was consistently done with dignity and the suggestion of a deeper, meaningful inner life. Cassatt objected to being stereotyped as a "woman artist", she supported women's suffrage, and in 1915 showed eighteen works in an exhibition supporting the movement organised by Louisine Havemeyer, a committed and active feminist. The exhibition brought her into conflict with her sister-in-law Eugenie Carter Cassatt, who was anti-suffrage and who boycotted the show along with Philadelphia society in general. Cassatt responded by selling off her work that was otherwise destined for her heirs. In particular "The Boating Party", thought to have been inspired by the birth of Eugenie's daughter Ellen Mary, was bought by the National Gallery, Washington DC.

Cassatt and Degas had a long period of collaboration. The two painters had studios close together, Cassatt at 19, rue Laval, (), Degas at 4, rue Frochot, (), less than a five-minute stroll apart, and Degas developed the habit of looking in at Cassatt's studio and offering her advice and helping her gain models.

They had much in common: they shared similar tastes in art and literature, came from affluent backgrounds, had studied painting in Italy, and both were independent, never marrying. The degree of intimacy between them cannot be assessed now, as no letters survive, but it is unlikely they were in a relationship given their conservative social backgrounds and strong moral principles. Several of Vincent van Gogh's letters attest Degas' sexual continence. Degas introduced Cassatt to pastel and engraving, both of which Cassatt quickly mastered, while for her part Cassatt was instrumental in helping Degas sell his paintings and promoting his reputation in America.

Both regarded themselves as figure painters, and the art historian George Shackelford suggests they were influenced by the art critic Louis Edmond Duranty's appeal in his pamphlet "The New Painting" for a revitalization in figure painting: "Let us take leave of the stylized human body, which is treated like a vase. What we need is the characteristic modern person in his clothes, in the midst of his social surroundings, at home or out in the street."

After Cassatt's parents and sister Lydia joined Cassatt in Paris in 1877, Degas, Cassatt, and Lydia were often to be seen at the Louvre studying artworks together. Degas produced two prints, notable for their technical innovation, depicting Cassatt at the Louvre looking at artworks while Lydia reads a guidebook. These were destined for a prints journal planned by Degas (together with Camille Pissarro and others), which never came to fruition. Cassatt frequently posed for Degas, notably for his millinery series trying on hats.

Around 1884, Degas made a portrait in oils of Cassatt, "Mary Cassatt Seated, Holding Cards". A "Self-Portrait" (c. 1880) by Cassatt depicts her in the identical hat and dress, leading art historian Griselda Pollock to speculate they were executed in a joint painting session in the early years of their acquaintance.

Cassatt and Degas worked most closely together in the fall and winter of 1879–80 when Cassatt was mastering her printmaking technique. Degas owned a small printing press, and by day she worked at his studio using his tools and press while in the evening she made studies for the etching plate the next day. However, in April 1880, Degas abruptly withdrew from the prints journal they had been collaborating on, and without his support the project folded. Degas' withdrawal piqued Cassatt who had worked hard at preparing a print, "In the Opera Box", in a large edition of fifty impressions, no doubt destined for the journal. Although Cassatt's warm feelings for Degas were to last her entire life, she never again worked with him as closely as she had over the prints journal. Mathews notes that she ceased executing her theater scenes at this time.

Degas was forthright in his views, as was Cassatt. They clashed over the Dreyfus affair (early in her career she had executed a portrait of the art collector Moyse Dreyfus, a relative of the court-martialled lieutenant at the center of the affair). Cassatt later expressed satisfaction at the irony of Lousine Havermeyer's 1915 joint exhibition of hers and Degas' work being held in aid of women's suffrage, equally capable of affectionately repeating Degas' antifemale comments as being estranged by them (when viewing her "Two Women Picking Fruit" for the first time, he had commented "No woman has the right to draw like that"). From the 1890s onwards their relationship took on a decidedly commercial aspect, as in general had Cassatt's other relations with the Impressionist circle; nevertheless they continued to visit each other until Degas died in 1917.

Cassatt's reputation is based on an extensive series of rigorously drawn and tenderly observed paintings and prints on the theme of the mother and child. The earliest dated work on this subject is the drypoint "Gardner Held by His Mother" (an impression inscribed "Jan/88" is in the New York Public Library), although she had painted a few earlier works on the theme. Some of these works depict her own relatives, friends, or clients, although in her later years she generally used professional models in compositions that are often reminiscent of Italian Renaissance depictions of the Madonna and Child. After 1900, she concentrated almost exclusively on mother-and-child subjects.

The 1890s were Cassatt's busiest and most creative period. She had matured considerably and became more diplomatic and less blunt in her opinions. She also became a role model for young American artists who sought her advice. Among them was Lucy A. Bacon, whom Cassatt introduced to Camille Pissarro. Though the Impressionist group disbanded, Cassatt still had contact with some of the members, including Renoir, Monet, and Pissarro.

In 1891, she exhibited a series of highly original colored drypoint and aquatint prints, including "Woman Bathing" and "The Coiffure", inspired by the Japanese masters shown in Paris the year before. (See Japonism) Cassatt was attracted to the simplicity and clarity of Japanese design, and the skillful use of blocks of color. In her interpretation, she used primarily light, delicate pastel colors and avoided black (a "forbidden" color among the Impressionists). Adelyn D. Breeskin, the author of two "catalogue raisonnés" of Cassatt's work, comments that these colored prints, "now stand as her most original contribution... adding a new chapter to the history of graphic arts...technically, as color prints, they have never been surpassed".
Also in 1891, Chicago businesswoman Bertha Palmer approached Cassatt to paint a 12' × 58' mural about "Modern Woman" for the Women's Building for the World's Columbian Exposition to be held in 1893. Cassatt completed the project over the next two years while living in France with her mother. The mural was designed as a triptych. The central theme was titled "Young Women Plucking the Fruits of Knowledge or Science". The left panel was "Young Girls Pursuing Fame" and the right panel "Arts, Music, Dancing". The mural displays a community of women apart from their relation to men, as accomplished persons in their own right. Palmer considered Cassatt to be an American treasure and could think of no one better to paint a mural at an exposition that was to do so much to focus the world's attention on the status of women. Unfortunately the mural did not survive following the run of the exhibition when the building was torn down. Cassatt made several studies and paintings on themes similar to those in the mural, so it is possible to see her development of those ideas and images. Cassatt also exhibited other paintings in the Exposition.

As the new century arrived, Cassatt served as an advisor to several major art collectors and stipulated that they eventually donate their purchases to American art museums. In recognition of her contributions to the arts, France awarded her the Légion d'honneur in 1904. Although instrumental in advising American collectors, recognition of her art came more slowly in the United States. Even among her family members back in America, she received little recognition and was totally overshadowed by her famous brother.
Mary Cassatt's brother, Alexander Cassatt, was president of the Pennsylvania Railroad from 1899 until his death in 1906. She was shaken, as they had been close, but she continued to be very productive in the years leading up to 1910. An increasing sentimentality is apparent in her work of the 1900s; her work was popular with the public and the critics, but she was no longer breaking new ground, and her Impressionist colleagues who once provided stimulation and criticism were dying. She was hostile to such new developments in art as post-Impressionism, Fauvism and Cubism. Two of her works appeared in the Armory Show of 1913, both images of a mother and child.

A trip to Egypt in 1910 impressed Cassatt with the beauty of its ancient art, but was followed by a crisis of creativity; not only had the trip exhausted her, but she declared herself "crushed by the strength of this Art", saying, "I fought against it but it conquered, it is surely the greatest Art the past has left us ... how are my feeble hands to ever paint the effect on me." Diagnosed with diabetes, rheumatism, neuralgia, and cataracts in 1911, she did not slow down, but after 1914 she was forced to stop painting as she became almost blind.

Cassatt died on June 14, 1926 at Château de Beaufresne, near Paris, and was buried in the family vault at Le Mesnil-Théribus, France.





</doc>
<doc id="20311" url="https://en.wikipedia.org/wiki?curid=20311" title="Military academy">
Military academy

A military academy or service academy (in the United States) is an educational institution which prepares candidates for service in the officer corps. It normally provides education in a military environment, the exact definition depending on the country concerned.

Three types of academy exist: pre-collegiate-level institutions awarding academic qualifications, university-level institutions awarding bachelor's-degree-level qualifications, and those preparing Officer Cadets for commissioning into the armed services of the state.

A naval academy is either a type of military academy (in the broad sense of that term) or is distinguished from one (in the narrow sense). In U.S. usage, the United States Military Academy and the United States Naval Academy are both service academies.

The first military academies were established in the 18th century to provide future officers for technically specialized corps, such as military engineers and artillery, with scientific training.

The Royal Danish Naval Academy was set up in 1701, making it the oldest military academy in existence. The Royal Military Academy, Woolwich was set up in 1741, after a false start in 1720 because of a lack of funds, as the earliest military academy in Britain. Its original purpose was to train cadets entering the Royal Artillery and Royal Engineers. In France, the École Royale du Génie at Mézières was founded in 1748, followed by a non-technical academy in 1751, the École Royale Militaire offering a general military education to the nobility. French military academies were widely copied in Prussia, Austria, Russia and even minor powers, including Turin and the Kingdom of Savoy, in the late 18th century. The Norwegian Military Academy in Oslo, educates officers of the Norwegian Army. The academy was established in 1750, and is the oldest institution for higher education in Norway.

By the turn of the century, under the impetus of the Napoleonic Wars and the strain that the armies of Europe subsequently came under, military academies for the training of commissioned officers of the army were set up in most of the combatant nations. These military schools had two functions: to provide instruction for serving officers in the functions of the efficient staff-officer, and to school youngsters before they gained an officer's commission. The Kriegsakademie in Prussia was founded in 1801 and the École spéciale militaire de Saint-Cyr was created by order of Napoleon Bonaparte in 1802 as a replacement for the École Royale Militaire of the Ancien Régime (the institution that Napoleon himself had graduated from).

The Royal Military College, Sandhurst, in England was the brainchild of John Le Marchant in 1801, who established schools for the military instruction of officers at High Wycombe and Great Marlow, with a grant of £30,000 from Parliament. The two original departments were later combined and moved to Sandhurst.

In the United States, the United States Military Academy (USMA) in West Point, New York was founded on March 16, 1802, and is one of five service academies in the nation. West Point rose to prominence after the Mexican-American War (1846–1848). Notable alumni include astronaut Buzz Aldrin, American presidents Ulysses S. Grant and Dwight D. Eisenhower, and several American and Confederate generals such as William Tecumseh Sherman, Robert E. Lee, Stonewall Jackson, John J. Pershing, Douglas MacArthur and George S. Patton.

A military school teaches children of various ages (elementary school, middle school or high school) in a military environment which includes training in military aspects, such as drill. Many military schools are also boarding schools, and others are simply magnet schools in a larger school system. Many are privately run institutions, though some are public and are run either by a public school system (such as the Chicago Public Schools) or by a state.

A common misconception results because some states have chosen to house their juvenile criminal populations in higher-security boarding schools that are run in a manner similar to military boarding schools. These are also called reform schools, and are functionally a combination of school and prison. They attempt to emulate the environment of military boarding schools in the belief that a strict structured environment can reform these children. This may or may not be true. However, their environment and target population are different from those of military schools.

Popular culture sometimes shows parents sending or threatening to send unruly children off to military school (or boarding school) to teach them good behavior (e.g. in the "Army of One" episode of "The Sopranos", Tony and Carmela Soprano consider sending their son, AJ, to the Hudson Military Institute; a similar situation appears in "Bill & Ted's Excellent Adventure"), while other fictional depictions don't show military academies as threats or punishment (e.g. "" and "The Presidio").

A college-level military academy is an institute of higher learning of things military. It is part of a larger system of military education and training institutions. The primary educational goal at military academies is to provide a high quality education that includes significant coursework and training in the fields of military tactics and military strategy. The amount of non-military coursework varies by both the institution and the country, and the amount of practical military experience gained varies as well.

Military academies may or may not grant university degrees. In the US, graduates have a major field of study, earning a Bachelor's degree in that subject just as at other universities. However, in British academies, the graduate does not achieve a university degree, since the whole of the one-year course (nowadays undertaken mainly but not exclusively by university graduates) is dedicated to military training.

There are two types of military academies: national (government-run) and state/private-run.




Argentine Army:

Argentine Navy:

Argentine Air Force:









Brazil has several military academies:



Two post-secondary military academies are operated under the Canadian Military Colleges system, the Royal Military College of Canada (RMCC) in Kingston, Ontario; and the Collège militaire royal de Saint-Jean (CMR) in Saint-Jean-sur-Richelieu, Quebec. RMCC was established in 1876, while CMR was established in 1954. The two institutions provided military education to officer cadets of all three elements in the Canadian Forces; the navy, army and air force; with RMC granted the authority to confer academic degrees in arts, science and engineering by the 1960s. From 1940 to 1995, the Department of National Defence operated a third military college in Victoria, British Columbia, known as Royal Roads Military College. 

Graduates of the Colleges are widely acknowledged to have had a disproportionate impact in the Canadian services and society, thanks to the solid foundations provided by their military education. Military discipline and training, as well as a focus on physical fitness and fluency in both of Canada's two official languages, English and French, provided cadets with ample challenges and a very fulfilling experience. In 1995 the Department of National Defence was forced to close RRMC and CMR due to budget considerations, but RMCC continues to operate.
RRMC reopened as a civilian university in the fall of 1995, and is maintained by the Government of British Columbia. In 2007, the Department of National Defence reopened CMR as a military academy that offers equivalent schooling as CEGEP, a level of post-secondary education in Quebec's education system.

In addition to Canadian Military Colleges, the Canadian Armed Forces also operate a number of training centres and schools, including the Canadian Forces College, and the Canadian Forces Language School. The components of the Canadian Armed Forces also maintain training centres and schools. The Canadian Army Doctrine and Training Centre (CADTC) is a formation in the Army that delivers combat, and doctrinal training. The CADTC includes several training establishments, such as the Canadian Manoeuvre Training Centre, Combat Training Centre, Command and Staff College, and the Peace Support Training Centre. The 2 Canadian Air Division is the formation responsible for training in the Royal Canadian Air Force (RCAF), and includes establishments like the Royal Canadian Air Force Academy, 2 Canadian Forces Flying Training School, and 3 Canadian Forces Flying Training School. The RCAF also maintains the Canadian Forces School of Survival and Aeromedical Training.

In addition to publicly operated institutions, Canada is also home to one private military boarding school, Robert Land Academy, in West Lincoln, Ontario. Founded in 1978, it is an all-boys' institute that is fully accredited by Ontario's Ministry of Education. The school offers elementary and secondary levels of education, providing schooling for students from Grade 6 to Grade 12.


National Army of Colombia:
Colombian Air Force:
Colombian Naval Infantry and Colombian Navy:
National Police of Colombia:











Germany has a unique system for civil and military education. The only true military academy is the "Führungsakademie der Bundeswehr" where mainly future staff officers and general staff officers are further trained.

The standard education in military leadership is the task of the "Offizierschulen" (officers' schools) run by the three branches. The contents differ from branch to branch. According to the doctrine "leading by task", in the army all prospective platoon leaders are trained down to the level of a commander of a mixed combat battalion. There they also have to pass an officer exam to become commissioned later on. 

Moreover, there exist so called "Waffenschulen" (school of weapons) like infantry school or artillery school. There the officers learn to deal with the typical tasks of their respective corps.

A specialty of the German concept of officer formation is the academic education. Germany runs two "Universities of the German Federal Armed Forces" where almost every future officer has to pass non-military studies and achieve a bachelor's or master's degree. During their studies (after at least three years of service) the candidates become commissioned "Leutnant" (second lieutenant).

The three officer's schools are:


Academic and staff education:


The Hellenic Armed Forces have military academies supervised by each branch of the Armed Forces individually:



Military Schools
1. 5 Rashtriya Military Schools across India in the Belgaum Military School, Bangalore Military School, Chail Military School, Dholpur Military School and Ajmer Military School

The Indonesian Military Academy was founded in Yogyakarta, October 13, 1945, by the order of General Staff Chief of Indonesia Army Lieutenant General Urip Sumohardjo as the Militaire Academie (MA) Yogyakarta.

Currently, the Tentara Nasional Indonesia or the TNI (Indonesian National Armed Forces), under the supervision of the Commanding General of the Indonesian National Armed Forces Academy System (a two or three-star officer in billet) in the HQ of the Indonesian National Armed Forces, has divided the academies into the three respective services:


Each service academy is headed by a two-star general who serves as superintendent, and his/her deputy is a one-star officer. All the students (cadets/midshipman) are recruited from senior high school graduates from all over Indonesia. Shortly after graduation, they are commissioned as "Letnan Dua" (Second Lieutenant/Ensign)) in their respective service branches and get the "Diploma IV" (Associate degree, 4th Grade) comparable to civil academies or universities. The length term is now 4 years and is divided into five grades of cadets' ranks, starting from the lowest:


"Taruna" refers to cadets in the Military Academy, "Kadet" refers to cadets in the Naval Academy, and "Karbol" refers to cadets in the Air Force Academy.

Until 1999, before the Indonesian National Police officially separated from the armed forces, the Indonesian Police Academy ("AKPOL") also stood under the National Armed Forces Academy but now has separated from the Military and is under the auspices of the President of Indonesia controlled by the National Police Headquarters ("Mabes Polri"), where in the other hand the Armed Forces (Army, Naval, and Air Force) Academies of Indonesia is under the auspices of the Ministry of Defense controlled by the Armed Forces General Headquarters ("Mabes TNI"). Presently, the Police Academy is in Semarang (Central Java), and is supervised under the supervision of the Chief of Indonesian National Police ("Kapolri").

All three academies and the Police Academy have a joint 4th class cadet training program since 2008, after completing it the cadets go to their respective academies to continue with the three remaining years of study before commissioning.

As of July 2019, Rear Admiral Aan Kurnia is the Commanding General, INAF Academy System, with Air Vice Marshal Sri Pulung as the assistant commander. The academies system was founded on December 16, 1965.

Imam Ali Officers' University (Persian: دانشگاه افسری امام علی; acronym: "دا اف, DĀʿAF), " formerly known as Officers' School "(Persian: دانشکده افسری)" is the military academy of Ground Forces of Islamic Republic of Iran Army, in Tehran, Iran. Cadets of the academy achieve the second Lieutenant rank upon graduation and join one of Islamic Republic of Iran Army branches.

High school level institutions (only for classical and scientific liceum, starting from grade 10):

2009–2010 school year was the first school year with girls attending.

Non Commissioned Officer (NCO) schools:


University level institutions:



Cadet Corps


The three main military academies:

Other military academies:


Secondary level institutions:

University level:

Specialist training and staff institutions:

Reserve Officer Training Units ( or ) or ROTU exists only in public universities in Malaysia. This is a tertiary institution based officer commissioning program to equip students as officer cadets with military knowledge and understanding for service as Commissioned Officers in the reserve components of the various branches of the Malaysian Armed Forces.







Tier One – initial officer training

Tier Two – junior officer education

Tier Three – senior officer education









Undergraduate officer training

The Philippines patterned all its service academies after the United States Military Academy (West Point) and the United States Merchant Marine Academy (King's Point).

These higher education institutions are operated by the Philippine Government and grant different baccalaureate degrees.


Aside from the PMA and the PMMA, all three branches of the AFP have their own Officer Candidate Course Programs for both men and women, patterned after their US counterparts.

The nation's higher military colleges are:








See also: Cadet Corps (Russia), Military academies in Russia











The General Sir John Kotelawala Defense University, was established in 1980 and is named after Gen. Sri John Kotelawala the 2nd Prime Minister of Sri Lanka. Taking cadets from all three armed services, 3 non-university level Military Academies, one for each armed service providing basic training for officer and a Command and Staff College for senior officers of the three armed services.











Uganda maintains the followings military training institutions, as of December 2010:


A number of universities have specialized military institutes, such as the Faculty of Military Legal Studies at Kharkiv's National Yaroslav Mudryi Law Academy of Ukraine; however, the primary Ukrainian military academies are the following:



There are also numerous Cadet forces that operate for all branches of the armed forces for children aged 10–20. These are not designed to recruit people into the armed forces but rather are simply Ministry of Defence sponsored youth organisations.

Although an undergraduate degree is not a prerequisite for Officer training, the majority of potential Officers will have attended University before joining the Armed Forces. At some universities there may be the option for people to join either a University Royal Naval Unit, a University Officer Training Corps (UOTC) or a University Air Squadron, which are designed to introduce students to life in the Forces and show them the careers that are available. People sponsored under the Defence Technical Undergraduate Scheme will join one of the four Support Units attached to universities participating in DTUS. There is a requirement for bursars of DTUS to join the military for three years after completion of their degree, there no requirement for students of any other organisation to join the military after they finish their degree programs; and the great majority have no further contact with the armed forces. Although service with these organisations may give some initial benefit to cadets attending the military colleges/academies, the next stage of the officer training programs assumes no prior military experience/knowledge, and those that did not partake in military activities at university are not disadvantaged.

There are now four military academies in the United Kingdom. Although the curriculum at each varies due to the differing nature of the service a man or woman is joining, it is a combination of military and academic study that is designed to turn young civilians into comprehensively trained military officers.


Officer Training for the Reserve Forces (e.g. Army Reserve, Royal Naval Reserve, RAF Reserves and Royal Marines Reserves) also takes place at the relevant military academies, but under a different curriculum and the courses tend to be concentrated into a much shorter period – a significant amount of the study will be undertaken at the cadet's reserve unit.


In the United States, the term "military academy" does not necessarily mean a government-owned institution run by the armed forces to train its own officers. It may also mean a middle school, high school, or college, whether public or private, which instructs its students in military-style education, discipline and tradition. Students at such civilian institutions can earn a commission in the U.S. military through the successful completion of a Reserve Officer Training Corps program along with their college or university's academic coursework.


Most state-level military academies maintain both a civilian student body and a traditional corps of cadets. The only exception is the Virginia Military Institute, which remains all-military.

The colleges operated by the U.S. Federal Government, referred to as federal service academies, are:



There is one all-military state-sponsored military academy:


In addition, these five institutions that were military colleges at the time of their founding now maintain both a corps of cadets and a civilian student body. Many of these institutions also offer on-line degree programs:


Along with VMI, these institutions are known as the senior military colleges of the US.

Today four institutions are considered military junior colleges (MJC). These four military schools participate in the Army's two-year Early Commissioning Program, an Army ROTC program where qualified students can earn a commission as a Second Lieutenant after only two years of college. The four military Junior jolleges are as follows:


There are six state-operated Merchant Marine academies:

These merchant marine academies operate on a military college system. Part of the training that the cadets receive is naval and military in nature. Cadets may apply for Naval Reserve commissions upon obtaining their Merchant Marine Officer's licenses. Most if not all also offer some form of military commissioning program into the active duty US Navy, US Marine Corps, or US Coast Guard.

The United States staff colleges, mandated to serve the needs of officers for post-graduate studies and other such graduate institutions as mandated by the Department of Defense are:













</doc>
<doc id="20312" url="https://en.wikipedia.org/wiki?curid=20312" title="Hayao Miyazaki">
Hayao Miyazaki

Born in Bunkyō ward of Tokyo, Miyazaki expressed interest in manga and animation from an early age, and he joined Toei Animation in 1963. During his early years at Toei Animation he worked as an in-between artist and later collaborated with director Isao Takahata. Notable films to which Miyazaki contributed at Toei include "Doggie March" and "Gulliver's Travels Beyond the Moon". He provided key animation to other films at Toei, such as "Puss in Boots" and "Animal Treasure Island", before moving to A-Pro in 1971, where he co-directed "Lupin the Third Part I" alongside Takahata. After moving to Zuiyō Eizō (later known as Nippon Animation) in 1973, Miyazaki worked as an animator on "World Masterpiece Theater", and directed the television series "Future Boy Conan". He joined Telecom Animation Film/Tokyo Movie Shinsha in 1979 to direct his first feature films, "The Castle of Cagliostro" in 1979 and "Nausicaä of the Valley of the Wind" in 1984, as well as the television series "Sherlock Hound".

Miyazaki co-founded Studio Ghibli in 1985. He directed numerous films with Ghibli, including "Castle in the Sky" (1986), "My Neighbor Totoro" (1988), "Kiki's Delivery Service" (1989), and "Porco Rosso" (1992). The films were met with critical and commercial success in Japan. Miyazaki's film "Princess Mononoke" was the first animated film ever to win the Japan Academy Prize for Picture of the Year, and briefly became the highest-grossing film in Japan following its release in 1997; its distribution to the Western world greatly increased Ghibli's popularity and influence outside Japan. His 2001 film "Spirited Away" became the highest-grossing film in Japanese history, winning the Academy Award for Best Animated Feature at the 75th Academy Awards and is frequently ranked among the greatest films of the 2000s. Miyazaki's later films—"Howl's Moving Castle" (2004), "Ponyo" (2008), and "The Wind Rises" (2013)—also enjoyed critical and commercial success. Following the release of "The Wind Rises", Miyazaki announced his retirement from feature films, though he returned to work on a new feature film in 2016.

Miyazaki's works are characterized by the recurrence of themes such as humanity's relationship with nature and technology, the wholesomeness of natural and traditional patterns of living, the importance of art and craftsmanship, and the difficulty of maintaining a pacifist ethic in a violent world. The protagonists of his films are often strong girls or young women, and several of his films present morally ambiguous antagonists with redeeming qualities. Miyazaki's works have been highly praised and awarded; he was named a Person of Cultural Merit for outstanding cultural contributions in November 2012, and received the Academy Honorary Award for his impact on animation and cinema in November 2014. Miyazaki has frequently been cited as an inspiration for numerous animators, directors, and writers.

Hayao Miyazaki was born on 5 January 1941, in the town of Akebono-cho in Bunkyō, Tokyo, the second of four sons. His father, Katsuji Miyazaki ( 1915 – 18 March 1993), was the director of Miyazaki Airplane, which manufactured rudders for fighter planes during World War II. The business allowed his family to remain affluent during Miyazaki's early life. In 1944, when Miyazaki was three years old, his family evacuated to Utsunomiya. After the bombing of Utsunomiya in July 1945, Miyazaki's family evacuated to Kanuma. The bombing left a lasting impression on Miyazaki, who was aged four at the time. From 1947 to 1955, Miyazaki's mother suffered from spinal tuberculosis; she spent the first few years in hospital, before being nursed from home. Miyazaki's mother was a strict, intellectual woman who regularly questioned "socially accepted norms". She died in July 1983 at the age of 71.

Miyazaki began school in 1947, at an elementary school in Utsunomiya, completing the first through third grades. After his family moved back to Suginami-ku, Miyazaki completed the fourth grade at Ōmiya Elementary School, and fifth grade at Eifuku Elementary School. After graduating from Eifuku, he attended Ōmiya Junior High School. He aspired to become a manga artist, but discovered he could not draw people; instead, he only drew planes, tanks, and battleships for several years. Miyazaki was influenced by several manga artists, such as , and Osamu Tezuka. Miyazaki destroyed much of his early work, believing it was "bad form" to copy Tezuka's style as it was hindering his own development as an artist. After graduating from Ōmiya Junior High, Miyazaki attended Toyotama High School. During his third year, Miyazaki's interest in animation was sparked by "Panda and the Magic Serpent" (1958). He "fell in love" with the movie's heroine and it left a strong impression on him. After graduating from Toyotama, Miyazaki attended Gakushuin University and was a member of the "Children's Literature Research Club", the "closest thing back then to a comics club". In his free time, Miyazaki would visit his art teacher from middle school and sketch in his studio, where the two would drink and "talk about politics, life, all sorts of things". Miyazaki graduated from Gakushuin in 1963 with degrees in political science and economics.

In 1963, Miyazaki was employed at Toei Animation. He worked as an in-between artist on the theatrical feature anime "Doggie March" and the television anime "Wolf Boy Ken" (both 1963). He also worked on "Gulliver's Travels Beyond the Moon" (1964). He was a leader in a labor dispute soon after his arrival, and became chief secretary of Toei's labor union in 1964. Miyazaki later worked as chief animator, concept artist, and scene designer on "The Great Adventure of Horus, Prince of the Sun" (1968). Throughout the film's production, Miyazaki worked closely with his mentor, Yasuo Ōtsuka, whose approach to animation profoundly influenced Miyazaki's work. Directed by Isao Takahata, with whom Miyazaki would continue to collaborate for the remainder of his career, the film was highly praised, and deemed a pivotal work in the evolution of animation.

Under the pseudonym , Miyazaki wrote and illustrated the manga "People of the Desert", published in 26 installments between September 1969 and March 1970 in . He was influenced by illustrated stories such as Fukushima's . Miyazaki also provided key animation for "The Wonderful World of Puss 'n Boots" (1969), directed by Kimio Yabuki. He created a 12-chapter manga series as a promotional tie-in for the film; the series ran in the Sunday edition of "Tokyo Shimbun" from January to March 1969. Miyazaki later proposed scenes in the screenplay for "Flying Phantom Ship" (1969), in which military tanks would cause mass hysteria in downtown Tokyo, and was hired to storyboard and animate the scenes. In 1971, he developed structure, characters and designs for Hiroshi Ikeda's adaptation of "Animal Treasure Island"; he created the 13-part manga adaptation, printed in "Tokyo Shimbun" from January to March 1971. Miyazaki also provided key animation for "Ali Baba and the Forty Thieves".

Miyazaki left Toei Animation in August 1971, and was hired at A-Pro, where he directed, or co-directed with Takahata, 23 episodes of "Lupin the Third Part I", often using the pseudonym . The two also began pre-production on a series based on Astrid Lindgren's "Pippi Longstocking" books, designing extensive storyboards; the series was canceled after Miyazaki and Takahata met Lindgren, and permission was refused to complete the project. In 1972 and 1973, Miyazaki wrote, designed and animated two "Panda! Go, Panda!" shorts, directed by Takahata. After moving from A-Pro to Zuiyō Eizō in June 1973, Miyazaki and Takahata worked on "World Masterpiece Theater", which featured their animation series "Heidi, Girl of the Alps", an adaptation of Johanna Spyri's "Heidi". Zuiyō Eizō continued as Nippon Animation in July 1975. Miyazaki also directed the television series "Future Boy Conan" (1978), an adaptation of Alexander Key's "The Incredible Tide".

Miyazaki left Nippon Animation in 1979, during the production of "Anne of Green Gables"; he provided scene design and organization on the first fifteen episodes. He moved to Telecom Animation Film, a subsidiary of TMS Entertainment, to direct his first feature anime film, "The Castle of Cagliostro" (1979), a "Lupin III" film. In his role at Telecom, Miyazaki helped train the second wave of employees. Miyazaki directed six episodes of "Sherlock Hound" in 1981, until issues with Sir Arthur Conan Doyle's estate led to a suspension in production; Miyazaki was busy with other projects by the time the issues were resolved, and the remaining episodes were directed by Kyosuke Mikuriya. They were broadcast from November 1984 to May 1985. Miyazaki also wrote the graphic novel "The Journey of Shuna", inspired by the Tibetan folk tale "Prince who became a dog". The novel was published by Tokuma Shoten in June 1983, and dramatised for radio broadcast in 1987. "Hayao Miyazaki's Daydream Data Notes" was also irregularly published from November 1984 to October 1994 in "Model Graphix"; selections of the stories received radio broadcast in 1995.

After the release of "The Castle of Cagliostro", Miyazaki began working on his ideas for an animated film adaptation of Richard Corben's comic book "Rowlf" and pitched the idea to Yutaka Fujioka at TMS. In November 1980, a proposal was drawn up to acquire the film rights. Around that time, Miyazaki was also approached for a series of magazine articles by the editorial staff of "Animage". During subsequent conversations, he showed his sketchbooks and discussed basic outlines for envisioned animation projects with editors Toshio Suzuki and Osamu Kameyama, who saw the potential for collaboration on their development into animation. Two projects were proposed: , to be set in the Sengoku period; and the adaptation of Corben's "Rowlf". Both were rejected, as the company was unwilling to fund anime projects not based on existing manga, and the rights for the adaptation of "Rowlf" could not be secured. An agreement was reached that Miyazaki could start developing his sketches and ideas into a manga for the magazine with the proviso that it would never be made into a film. The manga—titled "Nausicaä of the Valley of the Wind"—ran from February 1982 to March 1994. The story, as re-printed in the "tankōbon" volumes, spans seven volumes for a combined total of 1060 pages. Miyazaki drew the episodes primarily in pencil, and it was printed monochrome in sepia toned ink. Miyazaki resigned from Telecom Animation Film in November 1982.

Following the success of "Nausicaä of the Valley of the Wind", Yasuyoshi Tokuma, the founder of Tokuma Shoten, encouraged Miyazaki to work on a film adaptation. Miyazaki initially refused, but agreed on the condition that he could direct. Miyazaki's imagination was sparked by the mercury poisoning of Minamata Bay and how nature responded and thrived in a poisoned environment, using it to create the film's polluted world. Miyazaki and Takahata chose the minor studio Topcraft to animate the film, as they believed its artistic talent could transpose the sophisticated atmosphere of the manga to the film. Pre-production began on 31 May 1983; Miyazaki encountered difficulties in creating the screenplay, with only sixteen chapters of the manga to work with. Takahata enlisted experimental and minimalist musician Joe Hisaishi to compose the film's score. "Nausicaä of the Valley of the Wind" was released on 11 March 1984. It grossed ¥1.48 billion at the box office, and made an additional ¥742 million in distribution income. It is often seen as Miyazaki's pivotal work, cementing his reputation as an animator. It was lauded for its positive portrayal of women, particularly that of main character Nausicaä. Several critics have labeled "Nausicaä of the Valley of the Wind" as possessing anti-war and feminist themes; Miyazaki argues otherwise, stating that he only wishes to entertain. The successful cooperation on the creation of the manga and the film laid the foundation for other collaborative projects. In April 1984, Miyazaki opened his own office in Suginami Ward, naming it Nibariki.

In June 1985, Miyazaki, Takahata, Tokuma and Suzuki founded the animation production company Studio Ghibli, with funding from Tokuma Shoten. Studio Ghibli's first film, "Laputa: Castle in the Sky" (1986), employed the same production crew of "Nausicaä". Miyazaki's designs for the film's setting were inspired by Greek architecture and "European urbanistic templates". Some of the architecture in the film was also inspired by a Welsh mining town; Miyazaki witnessed the mining strike upon his first visit to Wales in 1984, and admired the miners' dedication to their work and community. "Laputa" was released on 2 August 1986. It was the highest-grossing animation film of the year in Japan. Miyazaki's following film, "My Neighbor Totoro", was released alongside Takahata's "Grave of the Fireflies" in April 1988 to ensure Studio Ghibli's financial status. The simultaneous production was chaotic for the artists, as they switched between projects. "My Neighbor Totoro" features the theme of the relationship between the environment and humanity—a contrast to "Nausicaä", which emphasises technology's negative effect on nature. While the film received critical acclaim, it was commercially unsuccessful at the box office. However, merchandising was successful, and the film was labelled as a cult classic.

In 1987, Studio Ghibli acquired the rights to create a film adaptation of Eiko Kadono's novel "Kiki's Delivery Service". Miyazaki's work on "My Neighbor Totoro" prevented him from directing the adaptation; Sunao Katabuchi was chosen as director, and Nobuyuki Isshiki was hired as script writer. Miyazaki's dissatisfaction of Isshiki's first draft led him to make changes to the project, ultimately taking the role of director. Kadono was unhappy with the differences between the book and the screenplay. Miyazaki and Suzuki visited Kadono and invited her to the studio; she allowed the project to continue. The film was originally intended to be a 60-minute special, but expanded into a feature film after Miyazaki completed the storyboards and screenplay. "Kiki's Delivery Service" premiered on 29 July 1989. It earned ¥2.15 billion at the box office, and was the highest-grossing film in Japan in 1989.

From March to May 1989, Miyazaki's manga "Hikōtei Jidai" was published in the magazine "". Miyazaki began production on a 45 minute in-flight film for Japan Airlines based on the manga; Suzuki ultimately extended the film into the feature-length film, titled "Porco Rosso", as expectations grew. Due to the end of production on Takahata's "Only Yesterday" (1991), Miyazaki initially managed the production of "Porco Rosso" independently. The outbreak of the Yugoslav Wars in 1991 affected Miyazaki, prompting a more sombre tone for the film; Miyazaki would later refer to the film as "foolish", as its mature tones were unsuitable for children. The film featured anti-war themes, which Miyazaki would later revisit. The airline remained a major investor in the film, resulting in its initial premiere as an in-flight film, prior to its theatrical release on 18 July 1992. The film was critically and commercially successful, remaining the highest-grossing animated film in Japan for several years.

Studio Ghibli set up its headquarters in Koganei, Tokyo in August 1992. In November 1992, two television spots directed by Miyazaki were broadcast by Nippon Television Network (NTV): "Sora Iro no Tane", a 90-second spot loosely based on the illustrated story "Sora Iro no Tane" by Rieko Nakagawa and Yuriko Omura, and commissioned to celebrate NTV's fortieth anniversary; and "Nandarou", aired as one 15-second and four 5-second spots, centered on an undefinable creature which ultimately became NTV's mascot. Miyazaki designed the storyboards and wrote the screenplay for "Whisper of the Heart" (1995), directed by Yoshifumi Kondō.

Miyazaki began work on the initial storyboards for "Princess Mononoke" in August 1994, based on preliminary thoughts and sketches from the late 1970s. While experiencing writer's block during production, Miyazaki accepted a request for the creation of "On Your Mark", a music video for the song of the same name by Chage and Aska. In the production of the video, Miyazaki experimented with computer animation to supplement traditional animation, a technique he would soon revisit for "Princess Mononoke". "On Your Mark" premiered as a short before "Whisper of the Heart". Despite the video's popularity, Suzuki said that it was not given "100 percent" focus.

In May 1995, Miyazaki took a group of artists and animators to the ancient forests of Yakushima and the mountains of Shirakami-Sanchi, taking photographs and making sketches. The landscapes in the film were inspired by Yakushima. In "Princess Mononoke", Miyazaki revisited the ecological and political themes of "Nausicaä of the Valley of the Wind". Miyazaki supervised the 144,000 cels in the film, about 80,000 of which were key animation. "Princess Mononoke" was produced with an estimated budget of ¥2.35 billion (approximately US$23.5 million), making it the most expensive film by Studio Ghibli at the time. Approximately fifteen minutes of the film uses computer animation: about five minutes uses techniques such as 3D rendering, digital composition, and texture mapping; the remaining ten minutes uses ink and paint. While the original intention was to digitally paint 5,000 of the film's frames, time constraints doubled this.

Upon its premiere on 12 July 1997, "Princess Mononoke" was critically acclaimed, becoming the first animated film to win the Japan Academy Prize for Picture of the Year. The film was also commercially successful, earning a domestic total of ¥14 billion (US$148 million), and becoming the highest-grossing film in Japan for several months. Miramax Films purchased the film's distributions rights for North America; it was the first Studio Ghibli production to receive a substantial theatrical distribution in the United States. While it was largely unsuccessful at the box office, grossing about US$3 million, it was seen as the introduction of Studio Ghibli to global markets. Miyazaki claimed that "Princess Mononoke" would be his final film.

Tokuma Shoten merged with Studio Ghibli in June 1997. Miyazaki's next film was conceived while on vacation at a mountain cabin with his family and five young girls who were family friends. Miyazaki realised that he had not created a film for ten-year-old girls, and set out to do so. He read shōjo manga magazines like "Nakayoshi" and "Ribon" for inspiration, but felt they only offered subjects on "crushes and romance", which is not what the girls "held dear in their hearts". He decided to produce the film about a female heroine whom they could look up to. Production of the film, titled "Spirited Away", commenced in 2000 on a budget of ¥1.9 billion (US$15 million). As with "Princess Mononoke", the staff experimented with computer animation, but kept the technology at a level to enhance the story, not to "steal the show". "Spirited Away" deals with symbols of human greed, and a liminal journey through the realm of spirits. The film was released on 20 July 2001; it received critical acclaim, and is considered among the greatest films of the 2000s. It won the Japan Academy Prize for Picture of the Year, and the Academy Award for Best Animated Feature. The film was also commercially successful, earning ¥30.4 billion (US$289.1 million) at the box office. It is the highest-grossing film in Japan.

In September 2001, Studio Ghibli announced the production of "Howl's Moving Castle", based on the novel by Diana Wynne Jones. Mamoru Hosoda of Toei Animation was originally selected to direct the film, but disagreements between Hosoda and Studio Ghibli executives led to the project's abandonment. After six months, Studio Ghibli resurrected the project. Miyazaki was inspired to direct the film upon reading Jones' novel, and was struck by the image of a castle moving around the countryside; the novel does not explain how the castle moved, which led to Miyazaki's designs. He travelled to Colmar and Riquewihr in Alsace, France, to study the architecture and the surroundings for the film's setting. Additional inspiration came from the concepts of future technology in Albert Robida's work, as well as the "illusion art" of 19th century Europe. The film was produced digitally, but the characters and backgrounds were drawn by hand prior to being digitized. It was released on 20 November 2004, and received widespread critical acclaim. The film received the Osella Award for Technical Excellence at the 61st Venice International Film Festival, and was nominated for the Academy Award for Best Animated Feature. In Japan, the film grossed a record $14.5 million in its first week of release. It remains among the highest-grossing films in Japan, with a worldwide gross of over ¥19.3 billion. Miyazaki received the honorary Golden Lion for Lifetime Achievement award at the 62nd Venice International Film Festival in 2005.

In March 2005, Studio Ghibli split from Tokuma Shoten. In the 1980s, Miyazaki contacted Ursula K. Le Guin expressing interest in producing an adaptation of her "Earthsea" novels; unaware of Miyazaki's work, Le Guin declined. Upon watching "My Neighbor Totoro" several years later, Le Guin expressed approval to the concept of the adaptation. She met with Suzuki in August 2005, who wanted Miyazaki's son Gorō to direct the film, as Miyazaki had wished to retire. Disappointed that Miyazaki was not directing, but under the impression that he would supervise his son's work, Le Guin approved of the film's production. Miyazaki later publicly opposed and criticized Gorō's appointment as director. Upon Miyazaki's viewing of the film, he wrote a message for his son: "It was made honestly, so it was good".

Miyazaki designed the covers for several manga novels in 2006, including "A Trip to Tynemouth"; he also worked as editor, and created a short manga for the book. Miyazaki's next film, "Ponyo", began production in May 2006. It was initially inspired by "The Little Mermaid" by Hans Christian Andersen, though began to take its own form as production continued. Miyazaki aimed for the film to celebrate the innocence and cheerfulness of a child's universe. He intended for it to only use traditional animation, and was intimately involved with the artwork. He preferred to draw the sea and waves himself, as he enjoyed experimenting. "Ponyo" features 170,000 frames—a record for Miyazaki. The film's seaside village was inspired by Tomonoura, a town in Setonaikai National Park, where Miyazaki stayed in 2005. The main character, Sōsuke, is based on Gorō. Following its release on 19 July 2008, "Ponyo" was critically acclaimed, receiving Animation of the Year at the 32nd Japan Academy Prize. The film was also a commercial success, earning ¥10 billion (US$93.2 million) in its first month and ¥15.5 billion by the end of 2008, placing it among the highest-grossing films in Japan.

In early 2009, Miyazaki began writing a manga called , telling the story of Mitsubishi A6M Zero fighter designer Jiro Horikoshi. The manga was first published in two issues of the Model Graphix magazine, published on 25 February and 25 March 2009. Miyazaki later co-wrote the screenplay for "Arrietty" (2010) and "From Up on Poppy Hill", directed by Hiromasa Yonebayashi and Gorō Miyazaki, respectively. Miyazaki wanted his next film to be a sequel to "Ponyo", but Suzuki convinced him to instead adapt "Kaze Tachinu" to film. In November 2012, Studio Ghibli announced the production of "The Wind Rises", based on "Kaze Tachinu", to be released alongside Takahata's "The Tale of the Princess Kaguya".

Miyazaki was inspired to create "The Wind Rises" after reading a quote from Horikoshi: "All I wanted to do was to make something beautiful". Several scenes in "The Wind Rises" were inspired by Tatsuo Hori's novel , in which Hori wrote about his life experiences with his fiancée before she died from tuberculosis. The female lead character's name, Naoko Satomi, was borrowed from Hori's novel . "The Wind Rises" continues to reflect Miyazaki's pacifist stance, continuing the themes of his earlier works, despite stating that condemning war was not the intention of the film. The film premiered on 20 July 2013, and received critical acclaim; it was named Animation of the Year at the 37th Japan Academy Prize, and was nominated for Best Animated Feature at the 86th Academy Awards. It was also commercially successful, grossing ¥11.6 billion (US$110 million) at the Japanese box office, becoming the highest-grossing film in Japan in 2013.

In September 2013, Miyazaki announced that he was retiring from the production of feature films due to his age, but wished to continue working on the displays at the Studio Ghibli Museum. Miyazaki was awarded the Academy Honorary Award at the Governors Awards in November 2014. He developed "Boro the Caterpillar", a computer-animated short film which was first discussed during pre-production for "Princess Mononoke". It was screened exclusively at the Studio Ghibli Museum in July 2017. He is also working on an untitled samurai manga. In August 2016, Miyazaki proposed a new feature-length film, "How Do You Live?", on which he began animation work without receiving official approval. He had hoped to complete the film by 2019; Suzuki predicts a 2020–2021 release.

In January 2019, it has been reported that Vincent Maraval, a frequent collaborator of Miyazaki, tweeted a hint that Miyazaki may have plans for another film in the works. In February 2019, a four-part documentary was broadcast on the NHK network titled "10 Years with Hayao Miyazaki", documenting production of his films in his private studio. On August 28, 2020, a musical adaptation of "Nausicaa of the Valley of the Wind", which Miyazaki accepted since a kabuki trope was heading it, started streaming until September 25th on the Japanese streaming service Mirail.

Miyazaki has often criticized the current state of the anime industry, stating that animators are unrealistic when creating people. He has stated that anime is "produced by humans who can't stand looking at other humans… that's why the industry is full of "otaku"!". He has also frequently criticized "otaku", including "gun "otaku"" and "Zero fanatics", declaring it a "fetish", and refusing to identify himself as such.

In 2013, several Studio Ghibli staff members, including Miyazaki, criticized Japanese Prime Minister Shinzō Abe's policies, and the proposed Constitutional amendment that would allow Abe to revise the clause which outlaws war as a means to settle international disputes. Miyazaki felt that Abe wished to "leave his name in history as a great man who revised the Constitution and its interpretation", describing it as "despicable". Miyazaki has expressed his disapproval of Abe's denial of Japan's military aggression, stating that Japan "should clearly say that [they] inflicted enormous damage on China and express deep remorse over it". He also felt that the country's government should give a "proper apology" to Korean comfort women who serviced the Japanese army during World War II, suggesting that the Senkaku Islands should be "split in half" or controlled by both Japan and China. After the release of "The Wind Rises" in 2013, some online critics labeled Miyazaki a "traitor" and "anti-Japanese", describing the film as overly "left-wing".

Miyazaki refused to attend the 75th Academy Awards in Hollywood, Los Angeles in 2003, in protest of the United States' involvement in the Iraq War, later stating that he "didn't want to visit a country that was bombing Iraq". He did not publicly express this opinion at the request of his producer until 2009, when he lifted his boycott and attended San Diego Comic Con International as a favor to his friend John Lasseter. Miyazaki also expressed his opinion about the terrorist attack at the offices of the French satirical magazine "Charlie Hebdo", criticizing the magazine's decision to publish the content cited as the catalyst for the incident. In November 2016, Miyazaki stated that he believed "many of the people who voted for Brexit and Trump" were affected by the increase in unemployment due to companies "building cars in Mexico because of low wages and [selling] them in the US". He did not think that Donald Trump would be elected president, calling it "a terrible thing", and said that Trump's political opponent Hillary Clinton was "terrible as well".

Miyazaki's works are characterized by the recurrence of themes such as environmentalism, pacifism, feminism, love and family. His narratives are also notable for not pitting a hero against an unsympathetic antagonist.

Miyazaki's films often emphasize environmentalism and the Earth's fragility. Margaret Talbot stated that Miyazaki dislikes modern technology, and believes much of modern culture is "thin and shallow and fake"; he anticipates a time with "no more high-rises". Miyazaki felt frustrated growing up in the Shōwa period from 1955–65 because "nature — the mountains and rivers — was being destroyed in the name of economic progress". Peter Schellhase of "The Imaginative Conservative" identified that several antagonists of Miyazaki's films "attempt to dominate nature in pursuit of political domination, and are ultimately destructive to both nature and human civilization". Miyazaki is critical of capitalism, globalization, and their effects on modern life. He believes that "a company is common property of the people that work there". Ram Prakash Dwivedi identified values of Mahatma Gandhi in the films of Miyazaki.

Several of Miyazaki's films feature anti-war themes. Daisuke Akimoto of "Animation Studies" categorized "Porco Rosso" as "anti-war propaganda"; he felt that the main character, Porco, transforms into a pig partly due to his extreme distaste of militarism. Akimoto also argues that "The Wind Rises" reflects Miyazaki's "antiwar pacifism", despite the latter stating that the film does not attempt to "denounce" war. Schellhase also identifies "Princess Mononoke" as a pacifist film due to the protagonist, Ashitaka; instead of joining the campaign of revenge against humankind, as his ethnic history would lead him to do, Ashitaka strives for peace. David Loy and Linda Goodhew argue that both "Nausicaä of the Valley of the Wind" and "Princess Mononoke" do not depict traditional evil, but the Buddhist roots of evil: greed, ill will, and delusion; according to Buddhism, the roots of evil must transform into "generosity, loving-kindness and wisdom" in order to overcome suffering, and both Nausicaä and Ashitaka accomplish this. When characters in Miyazaki's films are forced to engage in violence, it is shown as being a difficult task; in "Howl's Moving Castle", Howl is forced to fight an inescapable battle in defense of those he loves, and it almost destroys him, though he is ultimately saved by Sophie's love and bravery.

Suzuki described Miyazaki as a feminist in reference to his attitude to female workers. Miyazaki has described his female characters as "brave, self-sufficient girls that don't think twice about fighting for what they believe in with all their heart", stating that they may "need a friend, or a supporter, but never a saviour" and that "any woman is just as capable of being a hero as any man". "Nausicaä of the Valley of the Wind" was lauded for its positive portrayal of women, particularly the protagonist Nausicaä. Schellhase noted that the female characters in Miyazaki's films are not objectified or sexualized, and possess complex and individual characteristics absent from Hollywood productions. Schellhase also identified a "coming of age" element for the heroines in Miyazaki's films, as they each discover "individual personality and strengths". Gabrielle Bellot of "The Atlantic" wrote that, in his films, Miyazaki "shows a keen understanding of the complexities of what it might mean to be a woman". In particular, Bellot cites "Nausicaä of the Valley of the Wind", praising the film's challenging of gender expectations, and the strong and independent nature of Nausicaä. Bellot also noted that "Princess Mononoke"s San represents the "conflict between selfhood and expression".

Miyazaki is concerned with the sense of wonder in young people, seeking to maintain themes of love and family in his films. Michael Toscano of "Curator" found that Miyazaki "fears Japanese children are dimmed by a culture of overconsumption, overprotection, utilitarian education, careerism, techno-industrialism, and a secularism that is swallowing Japan’s native animism". Schellhase wrote that several of Miyazaki's works feature themes of love and romance, but felt that emphasis is placed on "the way lonely and vulnerable individuals are integrated into relationships of mutual reliance and responsibility, which generally benefit everyone around them". He also found that many of the protagonists in Miyazaki's films present an idealized image of families, whereas others are dysfunctional. He felt that the non-biological family in "Howl's Moving Castle" (consisting of Howl, Sophie, Markl, the Witch of the Waste, and Heen) gives a message of hope: that those cast out by society can "find a healthy place to belong".

Miyazaki forgoes traditional screenplays in his productions, instead developing the film's narrative as he designs the storyboards. "We never know where the story will go but we just keep working on the film as it develops," he said. In each of his films, Miyazaki has employed traditional animation methods, drawing each frame by hand; computer-generated imagery has been employed in several of his later films, beginning with "Princess Mononoke", to "enrich the visual look", though he ensures that each film can "retain the right ratio between working by hand and computer ... and still be able to call my films 2D". He oversees every frame of his films.

Miyazaki has cited several Japanese artists as his influences, including Sanpei Shirato, Osamu Tezuka, Soji Yamakawa, and Isao Takahata. A number of Western authors have also influenced his works, including Frédéric Back, Lewis Carroll, Roald Dahl, Jean Giraud, Paul Grimault, Ursula K. Le Guin, and Yuri Norstein, as well as animation studio Aardman Animations (specifically the works of Nick Park). Specific works that have influenced Miyazaki include "Animal Farm" (1945), "The Snow Queen" (1957), and "The King and the Mockingbird" (1980). When animating young children, Miyazaki often takes inspiration from his friends' children, as well as memories of his own childhood.

Miyazaki has frequently been cited as an inspiration to numerous animators, directors and writers around the world, including Guillermo del Toro, Pete Docter, Glen Keane, John Lasseter, James Cameron, Steven Spielberg, Wes Anderson, Mamoru Hosoda, Makoto Shinkai, Henry Selick, Travis Knight, Dean DeBlois, Jennifer Lee, and Nick Park. Keane said Miyazaki is a "huge influence" on Walt Disney Animation Studios and has been "part of our heritage" ever since "The Rescuers Down Under" (1990). Artists from Pixar and Aardman Studios signed a tribute stating, "You're our inspiration, Miyazaki-san!" He has also been cited as inspiration for video game designers including Shigeru Miyamoto and Hironobu Sakaguchi, as well as the "", and the video game "Ori and the Blind Forest" (2015).

Miyazaki married fellow animator Akemi Ota in October 1965. The couple have two sons: Gorō, born in January 1967, and Keisuke, born in April 1969. Miyazaki's dedication to his work harmed his relationship with Gorō, as he was often absent. Gorō watched his father's works in an attempt to "understand" him, since the two rarely talked. During the production of "Tales from Earthsea" in 2006, Gorō said that his father "gets zero marks as a father but full marks as a director of animated films". Miyazaki's niece, Mei Okuyama, who was the inspiration behind the character Mei in "My Neighbor Totoro", is married to animation artist Daisuke Tsutsumi.

Miyazaki won the Ōfuji Noburō Award at the Mainichi Film Awards for "The Castle of Cagliostro" (1979), "Nausicaä of the Valley of the Wind" (1984), "Laputa: Castle in the Sky" (1986), and "My Neighbor Totoro" (1988), and the Mainichi Film Award for Best Animation Film for "Kiki's Delivery Service" (1989), "Porco Rosso" (1992), "Princess Mononoke" (1997), "Spirited Away" and "Whale Hunt" (both 2001). "Spirited Away" was also awarded the Academy Award for Best Animated Feature, while "Howl's Moving Castle" (2004) and "The Wind Rises" (2013) received nominations. He was named a Person of Cultural Merit by the Japanese government in November 2012, for outstanding cultural contributions. His other accolades include eight Tokyo Anime Awards, eight Kinema Junpo Awards, six Japan Academy Awards, five Annie Awards, and three awards from the Anime Grand Prix and the Venice Film Festival.





 


</doc>
<doc id="20314" url="https://en.wikipedia.org/wiki?curid=20314" title="March 5">
March 5





</doc>
<doc id="20315" url="https://en.wikipedia.org/wiki?curid=20315" title="March 4">
March 4



</doc>
<doc id="20316" url="https://en.wikipedia.org/wiki?curid=20316" title="March 19">
March 19





</doc>
<doc id="20318" url="https://en.wikipedia.org/wiki?curid=20318" title="Macrobiotic diet">
Macrobiotic diet

A macrobiotic diet (or macrobiotics) is a fad diet based on ideas about types of food drawn from Zen Buddhism. The diet attempts to balance the supposed yin and yang elements of food and cookware. Major principles of macrobiotic diets are to reduce animal products, eat locally grown foods that are in season, and consume meals in moderation.

There is no high-quality clinical evidence that a macrobiotic diet is helpful for people with cancer or other diseases, and it may be harmful. Neither the American Cancer Society nor Cancer Research UK recommends adopting the diet.

The macrobiotic diet is associated with Zen Buddhism and is based on the idea of balancing yin and yang. The diet proposes 10 plans which are followed to reach a supposedly ideal yin:yang ratio of 5:1. The diet was popularized by George Ohsawa in the 1930s and subsequently elaborated by his disciple Michio Kushi. Medical historian Barbara Clow writes that, in common with many other types of quackery, macrobiotics takes a view of illness and of therapy which conflicts with mainstream medicine. 

Macrobiotics emphasizes locally grown whole grain cereals, pulses (legumes), vegetables, edible seaweed, fermented soy products, and fruit combined into meals according to the ancient Chinese principle of balance known as yin and yang. Whole grains and whole-grain products such as brown rice and buckwheat pasta (soba), a variety of cooked and raw vegetables, beans and bean products, mild natural seasonings, fish, nuts and seeds, mild (non-stimulating) beverages such as bancha twig tea, and fruit are recommended.

Some macrobiotic proponents stress that yin and yang are relative qualities that can only be determined in a comparison. All food is considered to have both properties, with one dominating. Foods with yang qualities are considered compact, dense, heavy, and hot, whereas those with yin qualities are considered expansive, light, cold, and diffuse. However, these terms are relative; "yangness" or "yinness" is only discussed in relation to other foods.

Brown rice and other whole grains such as barley, millet, oats, quinoa, spelt, rye, and teff are considered by macrobiotics to be the foods in which yin and yang are closest to being in balance. Therefore, lists of macrobiotic foods that determine a food as yin or yang generally compare them to whole grains.

Nightshade vegetables, including tomatoes, peppers, potatoes, and eggplant; also, spinach, beets, and avocados are not recommended or are used sparingly in macrobiotic cooking, as they are considered extremely yin. Some macrobiotic practitioners also discourage the use of nightshades because of the alkaloid solanine which is thought to affect calcium balance. Some proponents of a macrobiotic diet believe that nightshade vegetables can cause inflammation in the body and osteoporosis.

Some general guidelines for the Japanese-style macrobiotic diet are the following (it is also said that a macrobiotic diet varies greatly, depending on geographical and life circumstances):


Fish and seafood, seeds and nuts, seed and nut butters, seasonings, sweeteners, fruits, and beverages may be enjoyed occasionally, two to three times per week. Other naturally-raised animal products may be included if needed during dietary transition or according to individual needs.

Cooking utensils should be made from certain materials such as wood or glass, while some materials including plastic, copper, and non-stick coatings are to be avoided. Electric ovens should not be used.

The macrobiotic way of eating was developed and popularized by the Japanese. During the Edo period in Japan peasants were not allowed to eat meat and had a diet based on staples of rice and soybeans. According to some macrobiotic advocates, a majority of the world population in the past ate a diet based primarily on grains, vegetables, and other plants. Because the macrobiotic diet was developed in Japan, Japanese foods that are thought to be beneficial for health are incorporated by most modern macrobiotic eaters.

The American Cancer Society recommends "low-fat, high-fiber diets that consist mainly of plant products"; however, they urge people with cancer not to rely on a dietary program as an exclusive or primary means of treatment. Cancer Research UK states, "some people think living a macrobiotic lifestyle may help them to fight their cancer and lead to a cure. But there is no scientific evidence to prove this."

Nutritionist Fredrick J. Stare has commented that "there is no scientific evidence that macrobiotic diets can be helpful for cancer or any other disease."

The macrobiotic diet is a type of fad diet. Most macrobiotic diets are not nutritionally sound. 

Fish provides vitamin B in a macrobiotic diet, as bioavailable B analogues have not been established in any natural plant food, including sea vegetables, soya, fermented products, and algae. Although plant-derived foods do not naturally contain B, some are fortified during processing with added B and other nutrients. Vitamin A, as its precursor beta-carotene, is available from plants such as carrots and spinach. Adequate protein is available from grains, nuts, seeds, beans, and bean products. Sources of Omega-3 fatty acids are discussed in the relevant article, and include soy products, walnuts, flax seeds, pumpkin seeds, hemp seeds, and fatty fish. Riboflavin along with most other B vitamins are abundant in whole grains. Iron in the form of non-heme iron in beans, sea vegetables and leafy greens is sufficient for good health; detailed information is in the USDA database.

One of the earlier versions of the macrobiotic diet that involved eating only brown rice and water has been linked to severe nutritional deficiencies and even death. Strict macrobiotic diets that include no animal products may result in nutritional deficiencies unless they are carefully planned. The danger may be worse for people with cancer, who may have to contend with unwanted weight loss and often have increased nutritional and caloric requirements. Relying on this type of treatment alone and avoiding or delaying conventional medical care for cancer may have serious health consequences.

Children may also be particularly prone to nutritional deficiencies resulting from a macrobiotic diet.

Macrobiotic diets have not been tested in women who are pregnant or breast-feeding, and the most extreme versions may not include enough of certain nutrients for normal fetal growth.



</doc>
<doc id="20319" url="https://en.wikipedia.org/wiki?curid=20319" title="Motorola">
Motorola

Motorola, Inc. () was an American multinational telecommunications company founded on September 25, 1928, based in Schaumburg, Illinois. After having lost $4.3 billion from 2007 to 2009, the company demerged into two independent public companies, Motorola Mobility and Motorola Solutions on January 4, 2011. Motorola Inc. was renamed Motorola Solutions and is legally the direct successor to the original company after the demerger from Motorola Mobility. Motorola Mobility was sold to Google in 2012, and acquired by Lenovo in 2014.

Motorola designed and sold wireless network equipment such as cellular transmission base stations and signal amplifiers. Motorola's home and broadcast network products included set-top boxes, digital video recorders, and network equipment used to enable video broadcasting, computer telephony, and high-definition television. Its business and government customers consisted mainly of wireless voice and broadband systems (used to build private networks), and public safety communications systems like Astro and Dimetra. These businesses (except for set-top boxes, wireless networks, and cable modems) are now part of Motorola Solutions. Google sold Motorola Home (the former General Instrument cable businesses) to the Arris Group in December 2012 for US$2.35 billion.

Motorola's wireless telephone handset division was a pioneer in cellular telephones. Also known as the Personal Communication Sector (PCS) prior to 2004, it pioneered the "mobile phone" with DynaTAC, "flip phone" with the MicroTAC, as well as the "clam phone" with the StarTAC in the 1990s. It had staged a resurgence by the 2000s with the Razr, but lost market share in the second half of that decade. Later it focused on smartphones using Google's open-source Android mobile operating system. The first phone to use the newest version of Google's open source OS, Android 2.0, was released on November 2, 2009 as the Motorola Droid (the GSM version launched a month later, in Europe, as the Motorola Milestone).

The handset division (along with cable set-top boxes and cable modems divisions, which would later be sold to Arris Group) was later spun off into the independent Motorola Mobility. On May 22, 2012, Google CEO Larry Page announced that Google had closed on its deal to acquire Motorola Mobility. On January 29, 2014, Page announced that, pending closure of the deal, Motorola Mobility would be acquired by Hong Kong based technology company Lenovo for US$2.91 billion (subject to certain adjustments). On October 30, 2014, Lenovo finalized its purchase of Motorola Mobility from Google.

Motorola started in Chicago, Illinois, as Galvin Manufacturing Corporation (at 847 West Harrison Street) in 1928 when brothers Paul V. and Joseph E. Galvin purchased the bankrupt Stewart Battery Company's battery-eliminator plans and manufacturing equipment at auction for $750. Galvin Manufacturing Corporation set up shop in a small section of a rented building. The company had $565 in working capital and five employees. The first week's payroll was $63.

The company's first products were the battery eliminators, devices that enabled battery-powered radios to operate on household electricity. Due to advances in radio technology, battery-eliminators soon became obsolete. Paul Galvin learned that some radio technicians were installing sets in cars, and challenged his engineers to design an inexpensive car radio that could be installed in most vehicles. His team was successful, and Galvin was able to demonstrate a working model of the radio at the June 1930 Radio Manufacturers Association convention in Atlantic City, New Jersey. He brought home enough orders to keep the company in business.

Paul Galvin wanted a brand name for Galvin Manufacturing Corporation's new car radio, and created the name “Motorola” by linking "motor" (for motorcar) with "ola" (from Victrola), which was also a popular ending for many companies at the time, e.g. Moviola, Crayola. The company sold its first Motorola branded radio on June 23, 1930, to Herbert C. Wall of Fort Wayne, Indiana, for $30. Wall went on to become one of the first Motorola distributors in the country. The Motorola brand name became so well known that Galvin Manufacturing Corporation later changed its name to Motorola, Inc.

Galvin Manufacturing Corporation began selling Motorola car-radio receivers to police departments and municipalities in November 1930. The company's first public safety customers (all in the U.S. state of Illinois) included the Village of River Forest, Village of Bellwood Police Department, City of Evanston Police, Illinois State Highway Police, and Cook County (Chicago area) Police with a one-way radio communication.
In the same year, the company built its research and development program with Dan Noble, a pioneer in FM radio and semiconductor technologies, who joined the company as director of research. The company produced the hand-held AM SCR-536 radio during World War II, which was vital to Allied communication. Motorola ranked 94th among United States corporations in the value of World War II military production contracts.

Motorola went public in 1939, and became Motorola, Inc. in 1947. At that time Motorola's main business was producing and selling televisions and radios.

In October 1946, Motorola communications equipment carried the first calls on Illinois Bell telephone company's new car radiotelephone service in Chicago. The company began making televisions in 1947, with the model VT-71 with 7-inch cathode ray tube. In 1952, Motorola opened its first international subsidiary in Toronto, Ontario, Canada to produce radios and televisions. In 1953, the company established the Motorola Foundation to support leading universities in the United States.

In 1955, years after Motorola started its research and development laboratory in Phoenix, Arizona, to research new solid-state technology, Motorola introduced the world's first commercial high-power germanium-based transistor. The present "batwing" logo was also introduced in 1955 (having been created by award-winning Chicago graphic designer Morton Goldsholl in late 1954).

Beginning in 1958, with Explorer 1 Motorola provided radio equipment for most NASA space-flights for decades, including the 1969 Moon landing. A year later it established a subsidiary to conduct licensing and manufacturing for international markets. Motorola created numerous products for use by the government, public safety officials, business installments, and the general public.

In 1960, it introduced the world's first large-screen portable (19-inch), transistorized, cordless television. According to the 1962 Illinois Manufacturers Directory (50th-anniversary edition), Motorola had 14,000 employees worldwide of which at least 5,823 employees in 6 plants were located in Illinois. The company headquarters were at 9401 West Grand Avenue in Franklin Park and it listed TV receivers, stereo hi-fi equipment as the products at this plant made by 1,700 employees. The Communications Division was in Chicago at 4545 West Augusta Blvd. where 2,000 employees made electronic communications equipment. The Military Electronics Division was at 1450 North Cicero Avenue, Chicago where 923 employees made microwave and industrial equipment. Two more Chicago locations were listed at 4900 West Flourney Street and at 650 North Pulaski but no employee count was listed for these. The last plant was listed in Quincy, Illinois at 1400 North 30th Street where 1,200 employees made radio assemblies for both home and automobile.

In 1963, it introduced the first rectangular color picture tube. In 1964, the company opened its first Research and development branch outside of the United States, in Israel, under the management of Moses Basin. The modular Quasar brand was introduced in 1967.

In 1969, Neil Armstrong spoke the famous words "one small step for a man, one giant leap for mankind" from the Moon on a Motorola transceiver.

In 1971, Motorola demonstrated the first hand-held portable telephone.

In 1973, Motorola introduced its first microprocessor, the 8-bit MC6800, used in automotive, computing and video game applications. That same year, Motorola sold its television business to the Japan-based Matsushita, the parent company of Panasonic.

In 1976, Motorola moved its headquarters to the Chicago suburb of Schaumburg, Illinois.

In 1980, Motorola's next generation 32-bit microprocessor, the MC68000, led the wave of technologies that spurred the computing revolution in 1984, powering devices from companies such as Apple, Commodore, Atari, Sun, and Hewlett Packard.
In September 1983, the U.S. Federal Communications Commission (FCC) approved the DynaTAC 8000X telephone, the world's first commercial cellular device. By 1998, cell phones accounted for two-thirds of Motorola's gross revenue. The company was also strong in semiconductor technology, including integrated circuits used in computers. In particular, it is known for the 6800 family and 68000 family of microprocessors and related peripheral ICs; the processors were used in Atari ST, Commodore Amiga, Color Computer, and Apple Macintosh personal computers and in the early HP laser printers, and some 6800-family peripheral devices were used in the IBM PC series of personal computers. The PowerPC family was developed with IBM and in a partnership with Apple (known as the AIM alliance). Motorola also has a diverse line of communication products, including satellite systems, digital cable boxes and modems.

In 1986, Motorola invented the Six Sigma quality improvement process. This became a global standard. In 1990 General Instrument Corporation, which was later acquired by Motorola, proposed the first all-digital HDTV standard. In the same year, the company introduced the Bravo numeric pager which became the world's best-selling pager.

In 1991, Motorola demonstrated the world's first working-prototype digital cellular system and phones using GSM standard in Hanover, Germany. In 1994, Motorola introduced the world's first commercial digital radio system that combined paging, data and cellular communications and voice dispatch in a single radio network and handset. In 1995, Motorola introduced the world's first two-way pager which allowed users to receive text messages and e-mail and reply with a standard response.

In 1995, Motorola introduced the two-way pager.

In 1997, to optimize cell phone production with room for future growth, production was moved from Arlington Heights, Illinois to the new giant factory in Harvard, Illinois. Later with Motorola losing market share, phone assembly was moved to Fort Worth, Texas. closing the Harvard facility.

In 1998, Motorola was overtaken by Nokia as the world's biggest seller of mobile phone handsets.

On September 15, 1999, Motorola announced it would buy General Instrument in an $11-billion stock swap. General Instrument had long been the No. 1 cable TV equipment provider, supplying cable operators with end-to-end hybrid fiber coax cable solutions. This meant that GI offers all cable TV transmission network components from the head-end to the fiber optic transmission nodes to the cable set-top boxes and cable modems, now at the availability of Motorola. GI's acquisition created the Broadband Communications Sector (BCS).

In 1999, Motorola separated a portion of its semiconductor business—the Semiconductor Components Group (SCG)-- and formed ON Semiconductor, whose headquarters are located in Phoenix, Arizona.

In June 2000, Motorola and Cisco supplied the world's first commercial GPRS cellular network to BT Cellnet in the United Kingdom. The world's first GPRS cell phone was also developed by Motorola. In August 2000, with recent acquisitions, Motorola reached its peak employment of 150,000 employees worldwide. Two years later, employment would be at 93,000 due to layoffs and spinoffs.

In 2001, Motorola sold the RFID badge reader business to HID. Motorola Solutions would reenter the same market later.

In 2002, Motorola introduced the world's first wireless cable modem gateway which combined a high-speed cable modem router with an ethernet switch and wireless home gateway. In 2003, Motorola introduced the world's first handset to combine a Linux operating system and Java technology with "full PDA functionality". In 2004, Motorola divested its whole semiconductor business to form Freescale Semiconductor.

The Motorola RAZR line sold over 130 million units, which brought the company to the number two mobile phone slot in 2005.

In June 2005, Motorola overtook the intellectual property of Sendo for $30,000 and paid £362,575 for the plant, machinery and equipment.

In June 2006, Motorola acquired the software platform (AJAR) developed by the British company TTP Communications plc. Later in 2006, the firm announced a music subscription service named "iRadio". The technology came after a break in a partnership with Apple Computer (which in 2005 had produced an iTunes compatible cell phone ROKR E1, and most recently, mid-2007, its own iPhone). iRadio has many similarities with existing satellite radio services (such as Sirius and XM Radio) by offering live streams of commercial-free music content. Unlike satellite services, however, iRadio content will be downloaded via a broadband internet connection. As of 2008, iRadio has not been commercially released and no further information is available.

Motorola failed to repeat the success of the highly popular RAZR phone, especially in competition with new smartphones like Apple's iPhone, leading to a dwindling in its mobile phone business. In 2006 the company's mobile phone market share was about 23% but by the end of 2007 it dropped to 12%, falling to third place behind Samsung. It was further halved again, to 6%, by 2009, by which time the market share was overtaken by LG, and by 2010 was overtaken by Research In Motion, Sony Ericsson and Apple. The company's shares also more than halved during the period and caused large losses. Motorola managed to recover with the release of the Motorola Droid in late 2009 with Verizon Wireless, which sold in good numbers and made the phone division profitable again by late 2010.

In 2007, Motorola acquired Symbol Technologies to provide products and systems for enterprise mobility solutions, including rugged mobile computing, advanced data capture, and radio frequency identification (RFID).

In 2008, Optima International purchased the empty Harvard cell phone assembly campus for $16.75 million.

In 2010, Motorola sold its cellular-infrastructure business to Nokia Siemens Networks for $1.2 billion.

In 2014, all of the Motorola Schaumburg headquarters campus property was sold except for the former headquarters tower.


Arizona was home to Motorola's semiconductor division as well as its government Electronics division


The process to split Motorola into successor companies began in 2008, driven by Motorola investor Carl Icahn. Though the split was originally planned for 2009, it was not actually executed until 2011.

In January 2011, Motorola split into two separate companies, each still using the word Motorola as part of its name. One company, Motorola Solutions (using a blue version of the Motorola logo), is based in downtown Chicago after moving recently from Schaumburg Il, and concentrates on police technologies, radios, and commercial needs. The other company, Motorola Mobility (using a red logo and owned by Lenovo), is based in Chicago (formerly at 600 US-45, Libertyville, Illinois), and is the mobile handset producer. The split was structured so that Motorola Solutions was the legal successor of the original Motorola, while Motorola Mobility was the spin-off. Despite this, the motorola.com domain name is the website for Motorola Mobility, whereas Motorola Solutions's website is motorolasolutions.com.

2011, Motorola Solutions exited the Cellular Network business selling the Arlington Heights Illinois based division to (at the time) Nokia Siemens Networks for $1.2Billion.

On August 15, 2011, Google announced that it would purchase Motorola Mobility for about $12.5 billion.
On November 17, 2011, Motorola Mobility stockholders “voted overwhelmingly to approve the proposed merger with Google Inc”.

On May 22, 2012, Google announced that the acquisition of Motorola Mobility Holdings, Inc. had closed, with Google acquiring MMI for $40.00 per share in cash. ($12.5 billion)

On October 30, 2014, Google sold off Motorola Mobility to Lenovo. The purchase price was approximately US$2.91 billion (subject to certain adjustments), including US$1.41 billion paid at close: US $660 million in cash and US$750 million in Lenovo ordinary shares (subject to a share cap/floor). The remaining US$1.5 billion was paid in the form of a three-year promissory note.
After the purchase, Google maintained ownership of the vast majority of the Motorola Mobility patent portfolio, including current patent applications and invention disclosures, while Lenovo received a license to the portfolio of patents and other intellectual property. Additionally, Lenovo received over 2,000 patent assets, as well as the Motorola Mobility brand and trademark portfolio.

Divisional Products:


In 1974, Motorola divested itself of its television and radio-manufacturing division, which included the Quasar brand of electronics. This division was acquired by Matsushita, already known under its Panasonic brand in North America, where it was looking to expand.

Motorola developed the global communication network using a set of 77 satellites. The name iridium was selected as the 77 satellites resemble the 77 protons of the element Iridium. 

The business ambitions behind this project and the need to raise venture capital to fund the project led to the creation of the Iridium company in the late 1990s. While the technology was proven to work, Iridium failed to attract sufficient customers and it filed for bankruptcy in 1999. Obligations to Motorola and loss of expected revenue caused Motorola to divest the ON Semiconductor (ONNN) business August 4, 1999, raising about $1.1 billion. Motorola manufactured two satellite phone handsets for this network – the 9500 and 9505 as well as transceiver units. Some of these are still in production by an OEM but sold under the Iridium brand.

With the bankruptcy of Iridium, the fact Iridium was setup as an independent company and was not a part of Motorola. With this, a court found Motorola not liable to the people that tried to put Motorola "on the hook" for liabilities in the bankruptcy.

The Iridium communications network is still up and running owned by the company Iridium Communications Inc.

Motorola attempted to follow the Iridium system with an envisioned Celestri constellation, to offer global, broadband "Internet in the sky" services. However, this effort was not successful, and the Celestri system was never built.

Due to declines in business in 2000 and 2001, Motorola spun off its government and defense business to General Dynamics. The business deal closed in September 2001. Thus GD Decision Systems was formed (and later merged with General Dynamics C4 Systems) from Motorola's Integrated Information Systems Group.

On August 4, 1999, Motorola, Inc.'s Semiconductor Components Group, manufacturing Motorola's discrete, standard analog and standard logic devices was spun off, recapitalized and established as an independent company named ON Semiconductor. The new company began trading on the NASDAQ on April of the following year.

On October 16, 2004, Motorola announced that it would spin off its Semiconductor Products Sector into a separate company called Freescale Semiconductor, Inc.. The new company began trading on the New York Stock Exchange on July 16 of the following year.

On December 7, 2015, Freescale Inc. was sold to NXP Semiconductor, a former Philips semiconductors European company.

On January 29, 1988, Motorola sold its Arcade, New York facility and automotive alternators, electromechanical speedometers and tachometers products to Prestolite Electric.

In July 2006, Motorola completed the sale of its automotive business to Continental AG. Motorola's automotive unit had annual sales of $1.6 billion (€1.33 billion) and employed 4,504. The division's products included telematics systems - like GM's OnStar used for vehicle navigation and safety services, engine and transmission control electronics, vehicle control, electronics and sensors used in steering, braking, and power doors and power windows.

In 2000, Motorola acquired Printrak International Inc. for $160 million. In doing so, Motorola not only acquired computer aided dispatch and related software, but also acquired Automated fingerprint identification system software.

In October 2008, Motorola agreed to sell its Biometrics business to Safran, a French defense firm. Motorola's biometric business unit was headquartered in Anaheim, Calif. The deal closed in April 2009. The unit became part of Sagem Morpho, which was renamed MorphoTrak.

On March 26, 2008, Motorola's board of directors approved a split into two different publicly traded companies. This came after talk of selling the handset division to another corporation. These new companies would be the business units of the current Motorola Mobile Devices and Motorola Broadband & Mobility Solutions. Originally it was expected that this action would be approved by regulatory bodies and complete by mid-2009, but the split was delayed due to company restructuring problems and the 2008–2009 extreme economic downturn.

On February 11, 2010, Motorola announced its separation into two independent, publicly traded companies, effective Q1 2011. The official split occurred at around 12:00 pm EST on January 4, 2011. The two new companies are called Motorola Mobility (presently a Subsidiary of Lenovo; cell phone and cable television equipment company) and Motorola Solutions (; Government and Enterprise Business). Motorola Solutions is generally considered to be the direct successor to Motorola, Inc., as the reorganization was structured with Motorola Mobility being spun off. Motorola Solutions retains Motorola, Inc.'s pre-2011 stock price history, though it retired the old ticker symbol of "MOT" in favor of "MSI."

On August 15, 2011, seven months after Motorola Mobility was spun off into an independent company, Google announced that it would acquire Motorola Mobility for $12.5 billion, subject to approval from regulators in the United States and Europe.

According to the filing, Google senior vice president Andy Rubin first reached out to Motorola Mobility in early July 2011 to discuss the purchase by some of Google's competitors of the patent portfolio of Nortel Networks Corp., and to assess its potential impact on the Android ecosystem.

Google boosted its offer for Motorola Mobility by 33% in a single day in early August, even though Motorola wasn't soliciting competing bids. The aggressive bidding by Google showed that the search engine company was under considerable pressure to beef up its patent portfolio to protect its promising Android franchise from a growing number of legal challenges.

According to the filing, Google and Motorola began discussions about Motorola's patent portfolio in early July, as well as the "intellectual property litigation and the potential impact of such litigation on the Android ecosystem".

Although the two companies discussed the possibility of an acquisition after the initial contact by Mr. Rubin, it was only after Motorola pushed back on the idea of patent sale that the acquisition talks picked up steam.

The turning point came during a meeting on July 6. At the meeting, Motorola Mobility CEO Sanjay Jha discussed the protection of the Android ecosystem with Google senior vice president Nikesh Arora, and during that talk Jha told Arora that "it could be problematic for Motorola Mobility to continue to exist as a stand-alone entity if it sold a large portion of its patent portfolio".

In connection with these discussions, the two companies signed a confidentiality and non-disclosure agreement that allowed Google to do due diligence on the company's patent portfolio. 

On July 21 and 23, Jha met with Arora and Rubin to discuss strategic options between the two companies, agreeing to continue to discuss a potential sale. On the morning of August 15, the two companies entered into a merger agreement at the offered price of $40. On November 17, Motorola Mobility stockholders approved the proposed merger with Google Inc. On April 17, 2013, ARRIS Group, Inc. (NASDAQ: ARRS) announced that it completed its acquisition of the Motorola Home business from a subsidiary of Google Inc.

On January 29, 2014, Google announced Lenovo plans to acquire the Motorola Mobility smartphone business. The purchase price was approximately $2.91 billion (subject to certain adjustments), including $1.41 billion paid at close: $660 million in cash and $750 million in Lenovo ordinary shares (subject to a share cap/floor). The remaining $1.5 billion will be paid in the form of a three-year promissory note.

Google maintained ownership of the vast majority of the Motorola Mobility patent portfolio, including active patent applications and invention disclosures. As part of its ongoing relationship with Google, Lenovo received a license to this rich portfolio of patents and other intellectual property. Additionally, Lenovo received over 2,000 patent assets, as well as the Motorola Mobility brand and trademark portfolio. On October 30, 2014, Lenovo finalized its purchase of Motorola Mobility from Google.

Cambium Networks was created when Motorola Solutions sold the Canopy and Orthogon businesses in 2011. Cambium Networks has evolved the platform and expanded it to three product lines: Point to Point (PTP) (formerly Orthogon), Point to Multipoint (PMP) (formerly Canopy) and ePMP.

Motorola's handset division recorded a loss of US$1.2 billion in the fourth quarter of 2007, while the company as a whole earned $100 million during that quarter. It lost several key executives to rivals, and the web site TrustedReviews called the company's products repetitive and uninnovative. Motorola laid off 3,500 workers in January 2008, followed by a further 4,000 job cuts in June and another 20% cut of its research division a few days later. In July 2008, a large number of executives left Motorola to work on Apple Inc.'s iPhone. The company's handset division was also put on offer for sale. Also that month, analyst Mark McKechnie from American Technology Research said that Motorola "would be lucky to fetch $500 million" for selling its handset business. Analyst Richard Windsor said that Motorola might have to pay someone to take the division off the company's hands, and that Motorola may even exit the handset market altogether. Its global market share has been on the decline; from 18.4% of the market in 2007 the company had a share of just 6.0% by Q1 2009, but at last Motorola scored a profit of $26 million in Q2 and showed an increase of 12% in stocks for the first time after losses in many quarters.
During the second quarter of 2010, the company reported a profit of $162 million, which compared very favorably to the $26 million earned for the same period the year before. Its Mobile Devices division reported, for the first time in years, earnings of $87 million.
The Six Sigma quality system was developed at is still used by Motorola even though it became best known through its use by General Electric. It was created by engineer Bill Smith, under the direction of Bob Galvin (son of founder Paul Galvin) when he was running the company. Motorola University is one of many places that provide Six Sigma training.

Motorola, Inc., along with the Arizona Water Co. has been identified as the sources of trichloroethylene (TCE) contamination that took place in Scottsdale, Arizona. The malfunction led to a ban on the use of water that lasted three days and affected almost 5000 people in the area. Motorola was found to be the main source of the TCE, an industrial solvent that can cause cancer. The TCE contamination was caused by a faulty blower on an air stripping tower that was used to take TCE from the water, and Motorola has attributed the situation to operator error.

Of eighteen leading electronics manufacturers in Greenpeace’s Guide to Greener Electronics (October 2010), Motorola shares sixth place with competitors Panasonic and Sony).

Motorola scores relatively well on the chemicals criteria and has a goal to eliminate PVC plastic and brominated flame retardants (BFRs), though only in mobile devices and not in all its products introduced after 2010, despite the fact that Sony Ericsson and Nokia are already there. All of its mobile phones are now PVC-free and it has two PVC and BFR-free mobile phones, the A45 ECO and the GRASP; all chargers are also free from PVC and BFRs.

The company is also increasing the proportion of recycled materials that used in its products. For example, the housings for the MOTO W233 Renew and MOTOCUBO A45 Eco mobile phones contain plastic from post-consumer recycled water cooler bottles. According to the company's information, all of Motorola's newly designed chargers meet the current Energy Star requirements and exceed the requirements for standby/no-load modes by at least 67%.

Motorola sponsored Scottish Premier League club Motherwell F.C. for 11 years. This long-term deal ended after the company started to reduce its manufacturing operations in Scotland. The company also sponsored Livingston F.C. between 1998 and 2002. The company also had a plant on the edge of the town. However, this closed down at the same time as their sponsorship with the club ended. The South Stand at Livingston's Almondvale Stadium, was named after the company, during their time of sponsorship. The company also sponsored a cycling team that counted Lance Armstrong amongst its members. Motorola is also a sponsor of Danica Patrick, David Beckham, and Fergie. It also sponsored the Richmond Football Club in the Australian Football League from 2004 to 2007. Motorola sponsored São Paulo FC from 2000 to 2001. Motorola also sponsored Club Bolívar since 2008. Motorola awarded TrackIT Solutions for being "The company with most Innovative Enterprise Mobility Solution" in 2010.

Motorola sponsored Indian Premier League team Rising Pune Supergiant

In Madden NFL 07 franchise mode, a Motorola phone is used to communicate with coaches and agents.

Robby Gordon was sponsored by Motorola in 2007 and 2008. Motorola is on Gordon's car in NASCAR 07 and NASCAR 08.

Motorola sponsored the golf tournament Western Open from 1994 to 1999.





</doc>
<doc id="20320" url="https://en.wikipedia.org/wiki?curid=20320" title="Mazda MX-5">
Mazda MX-5

The Mazda MX-5 is a lightweight two-passenger roadster sports car manufactured and marketed by Mazda with a front mid-engine, rear-wheel-drive layout. The convertible is marketed as the or in Japan, and as the Mazda MX-5 Miata () in North America, where it is widely known as the "Miata". 

Manufactured at Mazda's Hiroshima plant, the MX-5 debuted in 1989 at the Chicago Auto Show and was conceived and executed under a tightly focused design credo, , meaning "oneness of horse and rider". Widely noted for its small, light, technologically modern, dynamically balanced and minimally complex design, the MX-5 has frequently been called a spiritual successor to 1950s and '60s Italian and British sports cars, prominently the Lotus Elan, which had been used as a design benchmark.

Generations were internally designated with a two-letter code, beginning with the first generation, the NA. The second generation, (NB), launched in 1998 for MY 1999; followed by the third generation (NC) in 2005 for MY 2006, and the fourth generation (ND) in 2015 for MY 2016 (along with "ND2" being the designation for MY 2019).

As the best-selling two-seat convertible sports car in history, the MX-5 has been marketed globally, with production exceeding one million, as of early 2016. The name derives from Old High German for "reward".

The MX-5's first generation, the NA, sold over 400,000 units from May 1989 to 1997—with a inline-four engine to 1993, a engine thereafter (with a de-tuned 1.6 as a budget option in some markets)—recognizable by its pop-up headlights. The second generation (NB) was introduced in 1999 with a slight increase in engine power; it can be recognized by the fixed headlights and the glass rear window, although first generation owners may opt for the glass window design when replacing the original top. The third generation (NC) was introduced in 2006 with a engine and slightly larger body size, with a Power Retractable Hard Top variant added in 2007. The fourth generation (ND) was introduced in 2015 with a new SKYACTIV-G engine and a body size similar to the first generation model, with a Retractable Fastback (RF) variant added later that year.

Launched at a time when production of small roadsters had almost come to an end, the Alfa Romeo Spider was the only comparable volume model in production at the time of the MX-5's launch. Just a decade earlier, a host of similar models—notably the MG B, Triumph TR7, Triumph Spitfire, and Fiat Spider—had been available.

The body is a conventional, but light, unibody construction, with (detachable) front and rear subframes. The MX-5 also incorporates a longitudinal truss, marketed as the Powerplant Frame (PPF), providing a rigid connection between the engine and differential, minimizing flex and contributing to responsive handling. Some MX-5s feature limited slip differentials and anti-lock braking system. Traction control is an option on NC models and standard on ND models. MX-5s weigh slightly over one tonne. For example, in 1994, the very rare optional Spec C package included the desirable limited slip differential.

With an approximate 50:50 front/rear weight balance, the car has nearly neutral handling. Inducing oversteer is easy and very controllable, thus making the MX-5 a popular choice for amateur and stock racing, including, in the US, the Sports Car Club of America's Solo autocross and Spec Miata race class series, and in the UK, the 5Club Racing championship. Raddatz and Otten won the AASA Australian Endurance Championship in 2011.

The MX-5 has won awards, including "Wheels Magazine"’s Car of the Year for 1989, 2005 and 2016; "Sports Car International"’s "best sports car of the 1990s" and "ten best sports cars of all time"; 2005–2006 Car of the Year Japan; and 2005 Australian Car of the Year. The Miata has also made "Car and Driver" magazine's annual 10 Best list 17 times. In their December 2009 issue, "Grassroots Motorsports" magazine named the Miata as the most important sports car built during the previous 25 years.

In 2009, English automotive critic Jeremy Clarkson wrote: 

In 1976, Bob Hall, a journalist at "Motor Trend" magazine who was an expert in Japanese cars and fluent in the language, met Kenichi Yamamoto and Gai Arai, head of Research and Development at Mazda. Yamamoto and Gai Arai asked Hall what kind of car Mazda should make in the future:

In 1981, Hall moved to a product planning position with Mazda USA and again met Yamamoto, now chairman of Mazda Motors, who remembered their conversation about a roadster and in 1982 gave Hall the go-ahead to research the idea further. At this time Hall hired designer Mark Jordan to join the newly formed Mazda design studio in Southern California. There, Hall and Jordan collaborated on the parameters of the initial image, proportion and visualization of the "light-weight sports" concept. In 1983, the idea turned concept was approved under the "Offline 55" program, an internal Mazda initiative that sought to change the way new models were developed. Thus, under head of project Masakatsu, the concept development was turned into a competition between the Mazda design teams in Tokyo and California.

The Californian team proposed a front-engine, rear-wheel-drive layout, codenamed Duo 101, in line with the British roadster ancestry, but their Japanese counterparts favored the more common front-engine, front-wheel-drive layout or the rear mid-engine, rear-wheel-drive layout.

The first round of judging the competing designs was held in April 1984, with designs presented on paper only. The mid-engined car appeared to offer favorable qualities, although it was known at the time that such a layout would struggle to meet the noise, vibration, and harshness (NVH) requirements of the project. It was only at the second round of the competition in August 1984, when full-scale clay models were presented, that the Duo 101 won the competition and was selected as the basis for what would become the MX-5.

The Duo 101, so named as either a soft top or hardtop could be used, incorporated many key stylistic cues inspired by the Lotus Elan, a 1960s roadster, including the door handles, tail lamps and grille opening as well as engine appearance and center console layout. It is known that Mazda design studio acquired a vintage Lotus Elan as a source of inspiration for the designers. International Automotive Design (IAD) in Worthing, England was commissioned to develop a running prototype, codenamed V705. It was built with a fiberglass body, a engine from a Mazda Familia and components from a variety of early Mazda models. The V705 was completed in August 1985 and taken to the US where it rolled on the roads around Santa Barbara, California and got positive reactions.

The project received final approval on 18 January 1986. The model's codename was changed to P729 as it moved into the production phase, under head of program Toshihiko Hirai. The task of constructing five engineering "mules" (more developed prototypes) was again allocated to IAD, which also conducted the first front and rear crash tests on the P729. While Tom Matano, Mark Jordan, Wu-huang Chin (, also on the RX-7 team), Norman Garrett, and worked on the final design, the project was moved to Japan for engineering and production details.

By 1989, with a definitive model name now chosen, the MX-5 was ready to be introduced to the world as a true lightweight sports car, weighing just .

Although Mazda's concept was for the MX-5 to be an inexpensive sports car, at introduction the design met strong demand, with many dealers placing customers on pre-order lists and several dealers across North America increasing the vehicle markup.

Mazda used a design credo across the four generations of the MX-5's development: the phrase , which translates loosely into English as "rider ("jin") and horse ("ba") as one body ("ittai")".

With the first generation of the MX-5, the phrase was developed into five specific core design requirements:

The first generation MX-5 was introduced in 1989 and was in production until 1997. Upon its release, the car won numerous accolades such as "Automobile" Magazine's 1990 Automobile of the Year and "Car and Driver"s 10Best list from 1990 to 1992.
The second generation MX-5 was unveiled in 1997 and put on sale in 1998 for the 1999 model year. While it kept the same proportions of its predecessor, its most noticeable change was the deletion of the retractable headlamps, which no longer passed pedestrian safety tests and were replaced by fixed ones.

Taking design cues from the 2003 Mazda Ibuki concept car, the third-generation Mazda MX-5 was introduced in 2005 and was in production until 2015. This generation introduced a Power Retractable Hard Top (PRHT) variant that features a folding mechanism that does not interfere with trunk space. During its release, the third generation MX-5 received several accolades such as the 2005-2006 Car of the Year Japan Award and "Car and Driver"s 10Best list from 2006 to 2013.

The fourth-generation Mazda MX-5 was unveiled in 2014 and has been in production since 2015. An updated model was introduced in 2018 and is visually identical to the pre-update model. It has been designated as series "ND2" due to an engine upgrade to and several other improvements around the car. The ND generation introduced a Retractable Fastback (RF) variant that features a rigid roof and buttresses that give the silhouette a more coupé-like appearance than the soft top convertible. The fourth generation MX-5 has received several accolades such as the 2015-2016 Car of the Year Japan Award, the 2016 World Car of the Year Award, "Car and Driver"s 10Best list from 2016 to 2019, and the Red Dot Best of the Best Award in Product Design 2017. In addition, the car is the basis for the Fiat 124 Spider and Abarth 124 Spider.
In 2000, the "Guinness Book of World Records" declared the MX-5 the best-selling two-seat sports car in history, with a total production of 531,890 units. The 250,000th MX-5 rolled out of the factory on November 9, 1992; the 500,000th, on February 8, 1999; the 750,000th, in March 2004; the 800,000th in January 2007, and the 900,000th in February 2011.

On April 22, 2016, Mazda broke its "Guinness World Record" by producing its one millionth MX-5. The one millionth car rolled off the production line and was shown in select cities, where the first 240 fans of the vehicle present could physically sign it before it went to the next destination.






</doc>
<doc id="20321" url="https://en.wikipedia.org/wiki?curid=20321" title="Mackinac Bridge">
Mackinac Bridge

The Mackinac Bridge ( ) is a suspension bridge spanning the Straits of Mackinac to connect the Upper and Lower Peninsulas of the U.S. state of Michigan. Opened in 1957, the bridge (familiarly known as "Big Mac" and "Mighty Mac") is the world's 24th-longest main span and the longest suspension bridge between anchorages in the Western Hemisphere. The Mackinac Bridge is part of Interstate 75 and the Lake Michigan and Huron components of the Great Lakes Circle Tour across the straits; it is also a segment of the U.S. North Country National Scenic Trail. The bridge connects the city of St. Ignace on the north end with the village of Mackinaw City on the south.

Envisioned since the 1880s, the bridge was designed by the engineer David B. Steinman and completed in 1957 only after many decades of struggles to begin construction.

The bridge opened on November 1, 1957, connecting two peninsulas linked for decades by ferries. A year later, the bridge was formally dedicated as the "world's longest suspension bridge between anchorages", allowing a superlative comparison to the Golden Gate Bridge, which has a longer center span between towers, and the San Francisco–Oakland Bay Bridge, which has an anchorage in the middle.

It remains the longest suspension bridge with two towers between anchorages in the Western Hemisphere. Much longer anchorage-to-anchorage spans have been built in the Eastern Hemisphere, including the Akashi Kaikyō Bridge in Japan (). But the long leadups to the anchorages on the Mackinac make its total shoreline-to-shoreline length of , longer than the Akashi-Kaikyo ().

The length of the bridge's main span is , which makes it the third-longest suspension span in the United States and 20th longest suspension span worldwide. It is also one of the world's longest bridges overall.

The Algonquian peoples who lived in the straits area prior to the arrival of Europeans in the 17th century called this region "Michilimackinac", which is widely understood to mean "the Great Turtle." This is thought to refer to the shape of what is now called Mackinac Island. This interpretation of the word is debated by scholars. Trading posts at the Straits of Mackinac attracted peak populations during the summer trading season; they also developed as intertribal meeting places.

As exploitation of the state's mineral and timber resources increased during the 19th century, the area became an important transport hub. In 1881 the three railroads that reached the Straits, the Michigan Central, Grand Rapids & Indiana, and the Detroit, Mackinac & Marquette, jointly established the Mackinac Transportation Company to operate a railroad car ferry service across the straits and connect the two peninsulas.

Improved highways along the eastern shores of the Lower Peninsula brought increased automobile traffic to the Straits region starting in the 1910s. The state of Michigan initiated an automobile ferry service between Mackinaw City and St. Ignace in 1923; it eventually operated nine ferry boats that would carry as many as 9,000 vehicles per day. Traffic backups could stretch as long as .

After the opening of the Brooklyn Bridge in 1883, local residents began to imagine that such a structure could span the straits. In 1884, a store owner in St. Ignace published a newspaper advertisement that included a reprint of an artist's conception of the Brooklyn Bridge with the caption "Proposed bridge across the Straits of Mackinac".

The idea of the bridge was discussed in the Michigan Legislature as early as the 1880s. At the time, the Straits of Mackinac area was becoming a popular tourist destination, especially following the creation of Mackinac National Park on Mackinac Island in 1875.

At a July 1888 meeting of the board of directors of the Grand Hotel on Mackinac Island, Cornelius Vanderbilt II proposed that a bridge be built across the straits, of a design similar to the one then under construction across the Firth of Forth in Scotland. This would advance commerce in the region and help lengthen the resort season of the hotel.

Decades went by with no formal action. In 1920, the Michigan state highway commissioner advocated construction of a floating tunnel across the Straits. At the invitation of the state legislature, C. E. Fowler of New York City put forth a plan for a long series of causeways and bridges across the straits from Cheboygan, southeast of Mackinaw City, to St. Ignace, using Bois Blanc, Round, and Mackinac islands as intermediate steps.

In 1923, the state legislature ordered the State Highway Department to establish ferry service across the strait. More and more people used ferries to cross the straits each year, and as they did, the movement to build a bridge increased. Chase Osborn, a former governor, wrote:

By 1928, the ferry service had become so popular and so expensive to operate that Michigan Governor Fred W. Green ordered the department to study the feasibility of building a bridge across the strait. The department deemed the idea feasible, estimating the cost at $30 million (equivalent to $ in ).

In 1934, the Michigan Legislature created the "Mackinac Straits Bridge Authority" to explore possible methods of constructing and funding the proposed bridge. The Legislature authorized the Authority to seek financing for the project. In the mid-1930s, during the Great Depression, when numerous infrastructure projects received federal aid, the Authority twice attempted to obtain federal funds for the project but was unsuccessful. The United States Army Corps of Engineers and President Franklin D. Roosevelt endorsed the project but Congress never appropriated funds. Between 1936 and 1940, the Authority selected a route for the bridge based on preliminary studies. Borings were made for a detailed geological study of the route.

The preliminary plans for the bridge featured a 3-lane roadway, a railroad crossing on the underdeck of the span, and a center-anchorage double-suspension bridge configuration similar to the design of the San Francisco – Oakland Bay Bridge. Because this would have required sinking an anchorage pier in the deepest area of the Straits, the practicality of this design may have been questionable. A concrete causeway, approximately , extending from the northern shore, was constructed in shallow water from 1939 to 1941. However, a unique engineering challenge was created by the tremendous forces that operate against the base of the bridge, because the lakes freeze during the winter, causing large icebergs to place enormous stress on the bridge.

At that time, with funding for the project still uncertain, further work was put on hold because of the outbreak of World War II. The "Mackinac Straits Bridge Authority" was abolished by the state legislature in 1947, but the same body created a new Mackinac Bridge Authority three years later in 1950. In June 1950, engineers were retained for the project. By then, it was reported that cars queuing for the ferry at Mackinaw City did not reach St. Ignace until five hours later, and the typical capacity of 460 vehicles per hour could not match the estimated 1,600 for a bridge.

After a report by the engineers in January 1951, the state legislature authorized the sale of $85 million (equivalent to $ in ) in bonds for bridge construction on April 30, 1952. However, a weak bond market in 1953 forced a delay of more than a year before the bonds could be issued.

David B. Steinman was appointed as the design engineer in January 1953 and by the end of 1953, estimates and contracts had been negotiated. A civil engineer at the firm, Abul Hasnat, did the preliminary plans for the bridge. Total cost estimate at that time was $95 million (equivalent to $ in ) with estimated completion by November 1, 1956. Tolls collected were to pay for the bridge in 20 years. Construction began on May 7, 1954. The bridge was built under two major contracts. The Merritt-Chapman and Scott Corporation of New York was awarded the contract for all major substructure work for $25.7 million (equivalent to $ in ), while the American Bridge Division of United States Steel Corporation was awarded a contract of more than $44 million (equivalent to $ in ) to build the steel superstructure.

Construction, staged using the 1939–41 causeway, took three and a half years (four summers, no winter construction) at a total cost of $100 million and the lives of five workers. Contrary to popular belief, none of them are entombed in the bridge. It opened to traffic on schedule on November 1, 1957, and the ferry service was discontinued on the same day. The bridge was formally dedicated on June 25, 1958.

G. Mennen Williams was governor during the construction of the Mackinac Bridge. He began the tradition of the governor leading the Mackinac Bridge Walk across it every Labor Day. U.S. Senator Prentiss M. Brown has been called the "father of the Mackinac Bridge", and was honored with a special memorial bridge token created by the Mackinac Bridge Authority.

The bridge officially achieved its 100 millionth crossing exactly 40 years after its dedication, on June 25, 1998. The 50th anniversary of the bridge's opening was celebrated on November 1, 2007, in a ceremony hosted by the Mackinac Bridge Authority at the viewing park adjacent to the St. Ignace causeway.

The design of the Mackinac Bridge was directly influenced by the lessons from the first Tacoma Narrows Bridge, which failed in 1940 because of its instability in high winds. Three years after that disaster, Steinman had published a theoretical analysis of suspension-bridge stability problems, which recommended that future bridge designs include deep stiffening trusses to support the bridge deck and an open-grid roadway to reduce its wind resistance. Both of these features were incorporated into the design of the Mackinac Bridge. The stiffening truss is open to reduce wind resistance. The road deck is shaped as an airfoil to provide lift in a cross wind, and the center two lanes are open grid to allow vertical (upward) air flow, which fairly precisely cancels the lift, making the roadway stable in design in winds of up to .

The Mackinac Bridge is a toll bridge on Interstate 75 (I-75). The US Highway 27 (US 27) designation was initially extended across the bridge. In November 1960, sections of I-75 freeway opened from Indian River north to the southern bridge approaches in Mackinaw City, and US 27 was removed from the bridge. It is one of only three segments of I-75 that are tolled, the others being the American half of the International Bridge near Sault Ste. Marie, Michigan, and Alligator Alley in Florida. The current toll is $4.00 for automobiles and $5.00 per axle for trucks. The Mackinac Bridge Authority raised the toll in 2007 to fund a $300 million renovation program, which would include completely replacing the bridge deck.

Every Labor Day, the bridge is open to walkers for the Mackinac Bridge Walk.

Painting of the bridge takes seven years, and when painting of the bridge is complete, it begins again. The current painting project began in 1999 and was expected to take 20 years to complete because the lead-based paint needs to be removed, incurring additional disposal requirements.

The bridge celebrated its 150 millionth vehicle crossing on September 6, 2009.


Five workers died during the construction of the bridge:
All five men are memorialized on a plaque near the bridge's northern end (Bridge View Park). Contrary to folklore, no bodies are embedded in the concrete.

One worker has died since the bridge was completed. Daniel Doyle fell from scaffolding on August 7, 1997. He survived the fall but fell victim to the water temperature. His body was recovered the next day in of water.

Two vehicles have fallen off the bridge:

On September 10, 1978, a small private plane carrying United States Marine Corps Reserve officers Maj. Virgil Osborne, Capt. James Robbins, and Capt. Wayne W. Wisbrock smashed into one of the bridge's suspension cables while flying in a heavy fog. The impact tore the wings off the plane, which then plunged into the Straits of Mackinac. All three men were killed.

Because the bridge is not accessible to pedestrians, suicides by jumping from the bridge have been rare, with the most recent confirmed case taking place on December 31, 2012. There have been roughly a dozen suicides by people jumping off the bridge.

Some individuals have difficulty crossing bridges, a phenomenon known as gephyrophobia. The Mackinac Bridge Authority has a Drivers Assistance Program that provides drivers for those with gephyrophobia, or anyone who is more comfortable having someone else drive them across. More than a thousand people use this service every year. Those interested can arrange, either by phone or with the toll collector, to have their cars or motorcycles driven to the other end. There is no additional fee for this service.

Bicycles and pedestrians are not normally permitted on the bridge. An exception is allowed for riders of two annual bicycle tours. On an everyday basis, for a $5.00 fee, the Authority will transport bicyclists and their vehicles across the bridge.

Travelers across the Mackinac Bridge can listen to an AM radio broadcast that recounts the history of the bridge and provides updates on driving conditions.

The Mackinac Bridge Walk has been held each year since 1958, when it was led by Governor G. Mennen Williams. The first walk was held during the Bridge's Dedication Ceremony held in late June, and has been held on Labor Day since 1959. Until 2018, school buses from local districts transported walkers from Mackinaw City to St. Ignace to begin the walk. Thousands of people, traditionally led by the Governor of Michigan, cross the five-mile (8 km) span on foot from St. Ignace to Mackinaw City. Before 1964, people walked the Bridge from Mackinaw City to St. Ignace. Prior to 2017, two lanes of the bridge would remain open to public vehicle traffic; this policy was changed in 2017 to close the entire bridge to public vehicle traffic for the duration of the event. The Bridge Walk is the only day of the year that hikers can hike this section of the North Country National Scenic Trail.

During the summer months, the Upper Peninsula and the Mackinac Bridge have become a major tourist destination. In addition to visitors to Mackinac Island, the bridge has attracted interest from a diverse group of tourists including bridge enthusiasts, bird-watchers, and photographers. The Straits area is a popular sailing destination for boats of all types, which make it easier to get a closer view to the underlying structure of the bridge.

On June 25, 1958, to coincide with that year's celebration of the November 1957 opening, the United States Postal Service (USPS) released a 3¢ commemorative stamp featuring the recently completed bridge. It was entitled "Connecting the Peninsulas of Michigan" and 107,195,200 copies were issued. The USPS again honored the Mackinac Bridge as the subject of its 2010 priority mail $4.90 stamp, which went on sale February 3. The bridge authority and MDOT unveiled the stamp, which featured a "seagull's-eye view" of the landmark, with a passing freighter below. Artist Dan Cosgrove worked from panoramic photographs to create the artwork. This is one of several designs that Cosgrove has produced for the USPS.

On April 24, 1959, Captain John S. Lappo, an officer in the Strategic Air Command, operating from Lockbourne AFB flew his Boeing B-47 Stratojet beneath the bridge. Following a general court-martial, he was grounded for life.

A feature-length documentary entitled "Building the Mighty Mac" was produced by Hollywood filmmaker Mark Howell in 1997 and was shown on PBS. The program features numerous interviews with the key people who built the structure and includes restored 16mm color footage of the bridge's construction.

The history and building of the bridge was featured in a 2003 episode of the History Channel TV show "Modern Marvels".

On July 19, 2007, the Detroit Science Center unveiled an , scale model of the Mackinac Bridge. The exhibit was part of the state's 50th anniversary celebration of the bridge. Sherwin-Williams supplied authentic Mackinac Bridge-colored paint for the project.

The bridge and its maintenance crew were featured in an episode of the Discovery Channel TV show "Dirty Jobs" on August 7, 2007. Host Mike Rowe and crew spent several days filming the episode in May 2007.

MDOT also featured the bridge on the cover of the 2007 state highway map to celebrate its 50th anniversary.




</doc>
<doc id="20322" url="https://en.wikipedia.org/wiki?curid=20322" title="Motorola 68030">
Motorola 68030

The Motorola 68030 (""sixty-eight-oh-thirty"") is a 32-bit microprocessor in the Motorola 68000 family. It was released in 1987. The 68030 was the successor to the Motorola 68020, and was followed by the Motorola 68040. In keeping with general Motorola naming, this CPU is often referred to as the 030 (pronounced "oh-three-oh" or "oh-thirty").

The 68030 features 273,000 transistors with on-chip instruction and data caches of 256 bytes each. It also has an on-chip memory management unit (MMU) but does not have a built in floating-point unit (FPU). The 68881 and the faster 68882 floating point unit chips could be used with the 68030. A lower cost version of the 68030, the Motorola 68EC030, was also released, lacking the on-chip MMU. It was commonly available in both 132 pin QFP and 128 pin PGA packages. The poorer thermal characteristics of the QFP package limited the full 68030 QFP variant to 33 MHz; the PGA 68030s included 40 MHz and 50 MHz versions. There was also a small supply of QFP packaged EC variants.

As a microarchitecture, the 68030 is basically a 68020 core with an additional 256 byte data cache and a process shrink and an added burst mode for the caches, where four longwords can be placed in the cache without further CPU intervention. Motorola used the process shrink to pack more hardware on the die; in this case it was the MMU, which mostly (but not completely) compatible with the external 68851. The integration of the MMU made it more cost-effective than the 68020 with an external MMU; it also allowed the 68030 to access memory one cycle faster than a 68020/68851 combo. However, the 68030 can switch between synchronous and asynchronous buses without a reset. The 68030 also lacks some of the 68020's instructions, but it increases performance by ≈5% while reducing power draw by ≈25% compared to the 68020.

The 68030 can be used with the 68020 bus, in which case its performance is similar to 68020 that it was derived from. However, the 68030 provides an additional synchronous bus interface which, if used, accelerates memory accesses up to 33% compared to an equally clocked 68020. The finer manufacturing process allowed Motorola to scale the full-version processor to 50 MHz. The EC variety topped out at 40 MHz.

The 68030 was used in many models of the Apple Macintosh II and Commodore Amiga series of personal computers, NeXT Cube, later Alpha Microsystems multiuser systems, and some descendants of the Atari ST line such as the Atari TT and the Atari Falcon. It was also used in Unix workstations such as the Sun Microsystems Sun-3x line of desktop workstations (the earlier "sun3" used a 68020), laser printers and the Nortel Networks DMS-100 telephone central office switch. More recently, the 68030 core has also been adapted by Freescale into a microcontroller for embedded applications.

LeCroy has used the 68EC030 in certain models of their 9300 Series digital oscilloscopes including “C” suffix models and high performance 9300 Series models, along with the Mega Waveform Processing hardware option for 68020-based 9300 Series models.

Hewlett-Packard's HP LaserJet 4 Laserjet 4 JetDirect network attach card uses a 68030 as its main processor. That card is a small UNIX system with something which to a system on the network behaves the same as the lpd daemon.

The 68EC030 is a low cost version of the 68030, the difference between the two being that the 68EC030 omits the on-chip memory management unit (MMU) and is thus essentially an upgraded 68020.

The 68EC030 was used as the CPU for the low-cost model of the Amiga 4000, and on a number of CPU accelerator cards for the Commodore Amiga line of computers. It was also used in the Cisco Systems 2500 Series router, a small-to-medium enterprise computer internetworking appliance.

The 50 MHz speed is exclusive to the ceramic PGA package, the plastic '030 stopped at 40 MHz.




</doc>
<doc id="20324" url="https://en.wikipedia.org/wiki?curid=20324" title="Motorola 68040">
Motorola 68040

The Motorola 68040 (""sixty-eight-oh-forty"") is a 32-bit microprocessor from Motorola, released in 1990. It is the successor to the 68030 and is followed by the 68060. There was no 68050. In keeping with general Motorola naming, the 68040 is often referred to as simply the '040 (pronounced "oh-four-oh" or "oh-forty").

In Apple Macintosh computers, the 68040 was introduced in the Macintosh Quadra, which was named for the chip. The fastest 68040 processor was clocked at 40 MHz and it was used only in the Quadra 840AV. The more expensive models in the (short-lived) Macintosh Centris line also used the 68040, while the cheaper Quadra, Centris and Macintosh Performa used the 68LC040. The 68040 was also used in other personal computers, such as the Amiga 4000 and Amiga 4000T, as well as a number of workstations, Alpha Microsystems servers, the HP 9000/400 series, and later versions of the NeXT computer.

The 68040 was the first 680x0 family member with an on-chip Floating-Point Unit (FPU). It thus included all of the functionality that previously required external chips, namely the FPU and Memory Management Unit (MMU), which was added in the 68030. It also had split instruction and data caches of 4 kilobytes each. It was fully pipelined, with six stages.

Unfortunately, the 68040 ran into the transistor budget limit early in design. While the MMU did not take many transistors—indeed, having it on the same die as the CPU actually saved on transistors—the FPU certainly did. Motorola's 68882 external FPU was known as a very high performance unit and Motorola did not wish to risk integrators using the "LC" version with a 68882 instead of the more profitable full "RC" unit. (For information on Motorola's multiprocessing model with the 680x0 series, see Motorola 68020.) The FPU in the 68040 was thus made incapable of IEEE transcendental functions, which had been supported by both the 68881 and 68882 and were used by the popular fractal generating software of the time and little else. The Motorola floating point support package (FPSP) emulated these instructions in software under interrupt. As this was an exception handler, heavy use of the transcendental functions caused severe performance penalties.

Heat was always a problem throughout the 68040's life. While it delivered over four times the per-clock performance of the 68020 and 68030, the chip's complexity and power requirements came from a large die and large caches. This affected the scaling of the processor and it was never able to run with a clock rate exceeding 40 MHz. A 50 MHz variant was planned, but canceled. Overclocking enthusiasts reported success reaching 50 MHz using a 100 MHz oscillator instead of an 80 MHz part and the then novel technique of adding oversized heat sinks with fans.

The 68040 offered the same features as the Intel 80486, but on a clock-for-clock basis could significantly outperform the Intel chip in integer and floating point instructions. However, the 80486 had the ability to be clocked significantly faster without suffering from overheating problems. In late 1991, as the higher-end Macintosh desktop lineup transitioned to the '040, Apple was unable to offer the newer processor in their top-of-the-line PowerBooks until early 1994. With PowerBooks being restricted to 68030s for several years, "Macworld" reviewers conceded that the best choice for power users was the PC-compatible Texas Instruments 80486 notebook, rather than the top-of-the-line PowerBook 180.

Versions of the 68040 were created for specific market segments, including the 68LC040, which removed the FPU, and the 68EC040, which removed both the FPU and MMU. Motorola had intended the EC variant for embedded use, but embedded processors during the 68040's time did not need the power of the 68040, so EC variants of the 68020 and 68030 continued to be common in designs.

Motorola produced several speed grades. The 16 MHz and 20 MHz parts were never qualified (XC designation) and used as prototyping samples. 25 MHz and 33 MHz grades featured across the whole line, but until around 2000 the 40 MHz grade was only for the "full" 68040. A planned 50 MHz grade was canceled after it exceeded the thermal design envelope.

For more information on the instructions and architecture, see Motorola 68000.

The "68EC040" is a version of the Motorola 68040 microprocessor, intended for embedded controllers (EC). It differs from the 68040 in that it has neither an FPU nor an MMU. This makes it less expensive and it draws less power. The 68EC040 was used in Cisco switch Supervisor Engine I that is the heart of models 2900, 2948G, 2980G, 4000, 4500, 5000, 5500, 6000, 6500 and 7600.

The "68LC040" is a "low cost" version of the Motorola 68040 microprocessor with no FPU. This makes it less expensive and it draws less power. Although the CPU now fits into a feature chart more like the Motorola 68030, it continues to include the 68040's caches and pipeline and is thus significantly faster than the 68030.

Some mask revisions of the 68LC040 contained a bug that prevents the chip from operating correctly when a software FPU emulator is used. According to Motorola's errata, any chip with a mask set 2E71M or later does not contain the bug. This new mask was introduced in mid-1995 and converted the 68LC040 chip to MC status.

The buggy revisions are typically found in 68LC040-based Apple Macintosh computers. Chips with mask set 2E23G (as used in the LC 475) have been confirmed to be faulty. The fault relates to pending writes being lost when the F-line exception is triggered. The 68040 cannot update its microcode in the manner of modern x86 chips. This means that the only way to use software that requires floating-point functionality is to replace the buggy 68LC040 with a later revision, or a full 68040.

ATC = Address Translation Cache



</doc>
<doc id="20325" url="https://en.wikipedia.org/wiki?curid=20325" title="Motorola 68060">
Motorola 68060

The Motorola 68060 (""sixty-eight-oh-sixty"") is a 32-bit microprocessor from Motorola released in 1994. It is the successor to the Motorola 68040 and is the highest performing member of the 68000 series. Two derivatives were produced, the 68LC060 and the 68EC060.

There is an LC (Low-Cost) version, without an FPU and EC (Embedded Controller), without MMU and FPU. The 68060 design was led by Joe Circello.

The 68060 shares most architectural features with the P5 Pentium. Both have a very similar superscalar in-order dual instruction pipeline configuration, and an instruction decoder which breaks down complex instructions into simpler ones before execution. However, a significant difference is that the 68060 FPU is not pipelined and is therefore up to three times slower than the Pentium in floating point applications. In contrast to that, integer multiplications and bit shifting instructions are significantly faster on the 68060. The 68060 has the ability to execute simple instructions in the address generation unit (AGU) and thereby supply the result two cycles before the ALU. In the development of the 68060, large amounts of commercial compiled code were analyzed for clues as to which instructions would be the best candidates for performance optimization.

Against the Pentium, the 68060 can perform better on mixed code; Pentium's decoder cannot issue an FP instruction every opportunity and hence the FPU is not superscalar as the ALUs were. If the 68060's non-pipelined FPU can accept an instruction, it can be issued one by the decoder. This means that optimizing for the 68060 is easier: no rules prevent FP instructions from being issued whenever was convenient for the programmer other than well understood instruction latencies. However, with properly optimized and scheduled code, the Pentium's FPU is capable of double the clock for clock throughput of the 68060's FPU.

The 68060 is the last development of the 68000 family for general purpose use, abandoned in favor of the PowerPC chips. It saw use in some late-model Amiga machines and Amiga accelerator cards as well as some Atari ST clones and Falcon accelerator boards (CT60/CT63/CT60e, the latter of which was created in 2015), and very late models of the Alpha Microsystems multiuser computers before their migration to x86, but Apple Inc. and the Unix world had moved onto various RISC platforms by the time the 68060 was available. The 68060 was introduced at 50 MHz on Motorola's 0.6 µm manufacturing process. A few years later it was shrunk to 0.42 µm and clock speed raised to 66 MHz and 75 MHz. Some users were managed to overclock rev6. 68060 CPU-s up to 120 or 133 MHz.

Developments of the basic core continue, intended for embedded systems. Here they are combined with a number of peripheral interfaces to reduce the overall complexity and power requirements of a design. A number of chips, each with different sets of interfaces, are sold under the names ColdFire and DragonBall.

Model numbers with even second-to-last digit (68000, 68020, 68040, 68060) were reserved for major revisions to the 680x0 core architecture. Model numbers with odd second-to-last digit (68010, 68030) were reserved for upgrades to the architecture of the previous chip. No 68050 or 68070 was ever produced by Motorola.

For example, the Motorola 68010 (and the obscure 68012) is a 68000 with improvements to the loop instruction and the ability to suspend then continue an instruction in the event of a page fault, enabling the use of virtual memory with the appropriate MMU hardware. There were, however, no major overhauls of the core architecture. Similarly, the Motorola 68030 represents a process improvement on the 68020 with the MMU and a small data cache (256 bytes) moved on-chip. The 68030 was released in speed ratings up to 50 MHz.

The jump from the 68000/68010 to the 68020/68030, however, represents a major overhaul, with innumerable individual changes.

By the time the 68060 was in production, Motorola had abandoned development of the 68000 family in favor of the PowerPC. The 68060 is the last 68000 family processor from Motorola.

Signetics (Philips) produced a 68000-based variant that they somewhat confusingly named the 68070. It contains a modestly-improved 68000 CPU, a simple on-chip MMU and an I²C bus controller. It came out long before the 68060 and was used principally as an embedded processor in some consumer electronics items, notably CD-i consoles.

The 68060 has a history in American broadcast television graphics. Chyron's , Max!, and Maxine! series of television character generators use the 68060 as the main processor. These character generators were a fixture on many American television networks' affiliate stations.

In desktops, the 68060 is used in some variants of the Amiga 4000T produced by Amiga Technologies, and available as a third party upgrade for other Amiga models. It is also used in the Amiga clone DraCo non-linear video system.

The Q60 extended the Sinclair QL design similarly from the slowest start to the ultimate pace of the 68K architecture's capabilities; these 68060-based motherboards—at 66 MHz for the full 68060 or a non-FPU 68LC060 option overclocked to 80 MHz—are more than 100 times faster than the Sinclair QL while running the same operating systems.

The 68060 was used in Nortel Meridian 1 Option 51, 61 and 81 large office PBX systems, powering the CP3 and CP4 core processor boards. A pair of these boards each sporting a 68060 could be used to make the PBX fault tolerant. This was a logical application as previous Meridian 1 cores used other Motorola chips. Nortel later changed the architecture to use Intel processors.
The Motorola Vanguard 6560 multiprotocol router uses a 50 MHz 68EC060 processor.

Motorola MVME-17x and Force Computer SYS68K VMEbus systems use a 68060 CPU.

The 68EC060 is a version of the Motorola 68060 microprocessor, intended for embedded controllers (EC). It differs from the 68060 in that it has neither an FPU nor an MMU. This makes it less expensive and it draws less power.

The 68LC060 is a low cost version of the Motorola 68060 microprocessor with no FPU. This makes it less expensive and it draws less power.

ATC = Address Translation Cache



</doc>
<doc id="20326" url="https://en.wikipedia.org/wiki?curid=20326" title="Motorola 6809">
Motorola 6809

The Motorola 6809 (""sixty-eight-oh-nine"") is an 8-bit microprocessor CPU with some 16-bit features from Motorola. It was designed by Terry Ritter and Joel Boney and introduced in 1978. It was a major advance over both its predecessor, the Motorola 6800, and the related MOS Technology 6502. Among the systems to use the 6809 are the TRS-80 Color Computer and Dragon 32/64 home computers, the Vectrex game system, and early 1980s arcade machines including "Star Wars", "Defender", "", "Joust", and "Gyruss". Series II of the Fairlight CMI digital audio workstation and Konami's "Time Pilot '84" arcade game each use dual 6809 processors.

Unlike the 6800 and 6502, the 6809 allows fully position-independent code and fully reentrant code in a simple and straightforward way. It was one of the first microprocessors with a hardware multiplication instruction, and it includes full 16-bit arithmetic and a fast interrupt system.

Among the significant enhancements introduced in the 6809 are the use of two 8-bit accumulators (A and B, which can be combined into a single 16-bit register, D), two 16-bit index registers (X, Y) and two 16-bit stack pointers. The index and stack registers allow advanced addressing modes. Program counter relative addressing allows for the easy creation of position-independent code, while a user stack pointer (U) facilitates reentrant code.

The 6809 is assembler source-compatible with the 6800, though the 6800 has 78 instructions to the 6809's 59. Some instructions were replaced by more general ones which the assembler translated into equivalent operations and some were even replaced by addressing modes. The instruction set and register complement were highly orthogonal, making the 6809 easier to program than the 6800 or 6502. Like the 6800, the 6809 includes an undocumented address bus test instruction which came to be nicknamed Halt and Catch Fire (HCF).

Unlike contemporary processors that often used a microcoded architecture (such as the 68000 and partly the 8086), the 6809's internal design was more similar to early simple CPU designs (and to some degree also the RISC machines that appeared in the mid 1970s and onwards). Like most 8-bit microprocessors, the 6809 implementation can in be viewed as a register-transfer level (RTL) machine, using a central PLA (less combinational logic) to implement much of the instruction decoding as well as parts of the sequencing.

Just like the 6800 and 6502, the 6809 uses a two-phase clock to gate the latches. This two phase clock cycle is used as a full machine cycle in these processors. Simple instructions can therefore execute in as little as two or three such cycles, although this also means that these cycles must be pretty slow.

As a comparison, the higher resolution state machine of a CPU like the Z80 allows clock frequencies 3–5 times as high with the same speed memory chips, which was often the limiting factor. This is because the Z80 combines two full (but short) clock cycles into a "relatively" long memory access period compared to the clock, while the more asynchronous 6809 instead has "relatively" short memory access times: depending on version and speed grade, approximately 40–60% of a single clock cycle is typically available for memory access in a 6800, 6502, or 6809.

The 6809 has an internal two-phase clock generator (needing only an external crystal) whereas the 6809E needed an external clock generator. There were also variants such as the 68A09(E) and 68B09(E); the internal letter indicates the processor's rated clock speed.

A key aspect of the 6809 design is a series of built-in features to allow position-independent code. This came about because the design team believed that future system integrators would look to off-the-shelf code in ROMs to handle common tasks. Libraries of common routines like floating point arithmetic, graphics primitives, Lempel-Ziv (LZ77 and LZ78) and so forth would be available for integrators to license, combine together along with their own code, and burn to ROM. A larger example is found in Motorola's 6809 programming manual, which contains the full listing of "assist09", a so-called monitor, a miniature operating system intended to be burned in ROM.

In this sort of "pick and place" programming environment, there was no way to predict where the code would end up in the ROM. Any instructions that referred to other locations in memory would normally have to be changed to reflect these changes in layout. In contrast, the 6809 allowed code to be placed anywhere in memory without modification. The 6809 design also focused on supporting reentrant code, code that can be called from various different programs concurrently without concern for coordination between them, or that can recursively call itself.

The design team's prediction was, ultimately, incorrect. The market for pre-rolled ROM modules never materialized: Motorola's only released example was the MC6839 floating-point ROM. The industry as a whole solved the problem of integrating code modules from multiple separate sources by using automatic relocating linkers and loaders—which is still the solution used today—instead of using relocatable ROM modules.

However, the decisions made by the design team yielded a very powerful processor and made possible advanced operating systems like OS-9 and UniFlex, which took advantage of the position-independence, re-entrancy orientated nature of the 6809 to create multi-user multitasking operating systems.

The 6809 is sometimes considered to be the conceptual precursor of the Motorola 68000 family of processors, though this is mostly a misunderstanding: the 6809 and 68000 design projects ran partly in parallel, and the two CPUs have quite differing architectures as well as radically different implementation principles. However, there is a certain amount of design philosophy similarity (e.g., considerable orthogonality and flexible addressing modes) and also some assembly language syntax resemblance as well as opcode mnemonic similarity. Notwithstanding the common elements, the 6809 is a derivative of the 6800, whereas the 68000 was a totally new design.

The Motorola 6809 was originally produced in 1 MHz, 1.5 MHz (68A09) and 2 MHz (68B09) speed ratings. Faster versions were produced later by Hitachi. With little to improve, the 6809 marks the end of the evolution of Motorola's 8-bit processors; Motorola intended that future 8-bit products would be based on an 8-bit data bus version of the 68000 (the 68008). A micro-controller version with a slightly modified instruction set, the 6811, was discontinued as late as the second decade of the 21st century.

The Hitachi 6309 was an enhanced version of the 6809 with extra registers and additional instructions, including block move, additional multiply instructions and hardware-implemented division. It was used in unofficially-upgraded Tandy Color Computer 3 computers and a version of OS-9 was written to take advantages of the 6309's extra features: NitrOS9

The 6809 is used in Commodore's dual-CPU SuperPET computer, and, in its 68A09 incarnation, in the unique vector graphics based Vectrex home video game console with built-in screen display, and in the Milton Bradley Expansion (MBX) system (an arcade console for use with the Texas Instruments TI-99/4A home computer). The 6809E is the CPU in the TRS-80 Color Computer, the Acorn System 2, 3 and 4 computers (as an optional alternative to their standard 6502), the Fujitsu FM-7, the Canon CX-1, the Welsh-made Dragon 32/64 home computers, and the SWTPC, Gimix, Smoke Signal Broadcasting, etc. SS-50 bus bus systems, in addition to several of Motorola's own EXORmacs and EXORset development systems. In France, Thomson micro-informatique produced a series of micro-computers based on the 6809E (TO7, TO7/70, TO8, TO8D, TO9, TO9Plus, MO5, MO6, MO5E and MO5NR).

In addition to home computers and game consoles, the 6809 is also found in a number of arcade games released during the early to mid-1980s. Williams Electronics was a prolific user of the processor, which was deployed in "Defender", "Stargate", "Joust", "", "Sinistar", and other games. The 6809 CPU forms the core of the successful Williams Pinball Controller. The KONAMI-1 is a modified 6809 used by Konami in "Roc'n Rope", "Gyruss", and "The Simpsons".

The 6809 CPU was also used in traffic signal controllers made in the 1980s by several different manufacturers.

Software development company Microware developed the original OS-9 operating system (not to be confused with the more recent Mac OS 9) for the 6809, later porting it to the 68000 and i386 series of microprocessors. Some years later, enthusiasts developed the NitrOS9 operating system based upon the original Microware OS9.

Series II of the Fairlight CMI (computer musical instrument) used dual 6809 CPUs and OS9, and also used one 6809 CPU per voice card. The 6809 was often employed in music synthesizers from other manufacturers such as Oberheim (Xpander, Matrix 6/12/1000), PPG (Wave 2/2.2/2.3, Waveterm A), and Ensoniq (Mirage sampler, SDP-1, ESQ1, SQ80). The latter used the 6809E as their main CPU. The (E) version was used in order to synchronize the microprocessor's clock to the sound chip (Ensoniq 5503 DOC) in those machines; in the ESQ1 and SQ80 the 68B09E was used, requiring a dedicated arbiter logic in order to ensure 1 MHz bus timing when accessing the DOC chip.

Hitachi produced its own 6809-based machines, the MB6890 and later the S1. These were primarily for the Japanese market, but some were exported to and sold in Australia. There the MB6890 was dubbed the "Peach", probably in ironic reference to the popularity of the Apple II. The S1 was notable in that it contained paging hardware extending the 6809's native 64 kilobyte (64×2 byte) addressing range to a full 1 mebibyte (1×2 byte) in 4 KB pages. It was similar in this to machines produced by SWTPC, Gimix, and several other suppliers. TSC produced a Unix-like operating system uniFlex which ran only on such machines. OS-9 Level II, also took advantage of such memory management facilities. Most other computers of the time with more than 64 KB of memory addressing were limited to bank switching where much if not all the 64 KB was simply swapped for another section of memory, although in the case of the 6809, Motorola offered their own MC6829 MMU design mapping 2 mebibytes (2×2 byte) in 2 KB pages.

The very first Macintosh prototype, wire-wrapped by Burrell Smith, contained a 6809.

The 6809 was used in the mid-1980s through the early 2000s in Motorola SMARTNET and SMARTZONE Trunked Central Controllers (so dubbed the "6809 Controller"). These controllers were used as the central processors in many of Motorola's trunked two-way radio communications systems.

Motorola spun off its microprocessor division in 2004. The division changed its name to Freescale and has subsequently been acquired by NXP.

Neither Motorola nor Hitachi produce 6809 processors or derivatives anymore. 6809 cores are available in VHDL and can be programmed into an FPGA and used as an embedded processor with speed ratings up to 40 MHz. Some 6809 opcodes also live on in the Freescale embedded processors. In 2015, Freescale authorized Rochester Electronics to start manufacturing the MC6809 once again as a drop-in replacement and copy of the original NMOS device. Freescale supplied Rochester the original GDSII physical design database. At the end of 2016, Rochester's MC6809 (including the MC68A09, and MC68B09) is fully qualified and available in production.

Australian developer John Kent has synthesized the Motorola 6809 CPU in hardware description language (HDL). This has made possible the use of the 6809 core at much higher clock speeds than were available with the original 6809. Gary Becker's CoCo3FPGA runs the Kent 6809 core at 25 MHz. Roger Taylor's Matchbox CoCo runs at 7.16 MHz. Dave Philipsen's CoCoDEV runs at 25 MHz.




</doc>
<doc id="20327" url="https://en.wikipedia.org/wiki?curid=20327" title="Motorola 68HC11">
Motorola 68HC11

The 68HC11 (6811 or HC11 for short) is an 8-bit microcontroller (µC) family introduced by Motorola in 1984. Now produced by NXP Semiconductors, it descended from the Motorola 6800 microprocessor by way of the 6801. It is a CISC microcontroller. The 68HC11 devices are more powerful and more expensive than the 68HC08 microcontrollers, and are used in automotive applications, barcode readers, hotel card key writers, amateur robotics, and various other embedded systems. The MC68HC11A8 was the first microcontroller to include CMOS EEPROM.

Internally, the HC11 instruction set is upward compatible with the 6800, with the addition of a Y index register. (Instructions using the Y register have opcodes prefixed with the byte 0x18). It has two eight-bit accumulators, A and B, two sixteen-bit index registers, X and Y, a condition code register, a 16-bit stack pointer, and a program counter. In addition, there is an 8 x 8-bit multiply (A x B), with full 16-bit result, and Fractional/Integer 16-bit by 16-bit Divide instructions. A range of 16-bit instructions treat the A and B registers as a combined 16-bit D register for comparison (X and Y registers may also be compared to 16-bit memory operands), addition, subtraction and shift operations, or can add the B accumulator to the X or Y index registers. Bit test operations have also been added, performing a logical AND function between operands, setting the correct conditions codes, but not modifying the operands.

Different versions of the HC11 have different numbers of external ports, labeled alphabetically. The most common version has five ports, A, B, C, D, and E, but some have as few as 3 ports (version D3). Each port is eight-bits wide except for D, which is six bits (in some variations of the chip, D also has eight bits). It can be operated with an internal program and RAM (1 to 768 bytes) or an external memory of up to 64 kilobytes. With external memory, B and C are used as address and data bus. In this mode, port C is multiplexed to carry both the lower byte of the address and data.

In the early 1990s Motorola produced an evaluation board kit for the 68HC11 with several UARTs, RAM, and an EPROM. The cost of the evaluation kit was $68.11.

The standard monitor for the HC11 family is called BUFFALO, "Bit User Fast Friendly Aid to Logical Operation." It can be stored in on-chip ROM, EPROM, or external memory (also typically EPROM). BUFFALO is available for most 68HC11 family derivatives as it generally only depends upon having access to a single UART (SCI, or Serial Communications Interface, in Motorola parlance). BUFFALO can also run on devices that do not have internal non-volatile memory, such as the 68HC11A0, A1, E0, E1, and F1 derivatives.

The Freescale 68HC16 microcontroller family is intended as a 16-bit mostly software compatible upgrade of the 68HC11.

The Freescale 68HC12 microcontroller family is an enhanced 16-bit version of the 68HC11.

The Handy Board robotics controller by Fred Martin is based on the 68HC11.

A MC68HC24 port replacement unit is available for the HC11. When placed on the external address bus, it replicates the original functions of B and C. Port A has input capture, output compare, pulse accumulator, and other timer functions; port D has serial I/O, and port E has an analog-to-digital converter (ADC).




</doc>
<doc id="20329" url="https://en.wikipedia.org/wiki?curid=20329" title="March 21">
March 21

In astrology, the day of the equinox is the first full day of the sign of Aries. It is also the traditional first day of the astrological year. In the 21st century, the equinox usually occurs on March 19 or 20; it occurred on March 21 only in 2003 and 2007. The next year in which the equinox occurs on March 21 will be 2102.





</doc>
<doc id="20330" url="https://en.wikipedia.org/wiki?curid=20330" title="Mainframe (disambiguation)">
Mainframe (disambiguation)

A mainframe computer is a type of large data processing system.

Mainframe may also refer to:


</doc>
