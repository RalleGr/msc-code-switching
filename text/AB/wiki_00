<doc id="12336" url="https://en.wikipedia.org/wiki?curid=12336" title="Gladiator">
Gladiator

A gladiator (, "swordsman", from , "sword") was an armed combatant who entertained audiences in the Roman Republic and Roman Empire in violent confrontations with other gladiators, wild animals, and condemned criminals. Some gladiators were volunteers who risked their lives and their legal and social standing by appearing in the arena. Most were despised as slaves, schooled under harsh conditions, socially marginalized, and segregated even in death.

Irrespective of their origin, gladiators offered spectators an example of Rome's martial ethics and, in fighting or dying well, they could inspire admiration and popular acclaim. They were celebrated in high and low art, and their value as entertainers was commemorated in precious and commonplace objects throughout the Roman world.

The origin of gladiatorial combat is open to debate. There is evidence of it in funeral rites during the Punic Wars of the 3rd century BC, and thereafter it rapidly became an essential feature of politics and social life in the Roman world. Its popularity led to its use in ever more lavish and costly games.

The gladiator games lasted for nearly a thousand years, reaching their peak between the 1st century BC and the 2nd century AD. The games finally declined during the early 5th century after the adoption of Christianity as state church of the Roman Empire in 380, although beast hunts ("venationes") continued into the 6th century.

Early literary sources seldom agree on the origins of gladiators and the gladiator games. In the late 1st century BC, Nicolaus of Damascus believed they were Etruscan. A generation later, Livy wrote that they were first held in 310 BC by the Campanians in celebration of their victory over the Samnites. Long after the games had ceased, the 7th century AD writer Isidore of Seville derived Latin "lanista" (manager of gladiators) from the Etruscan word for "executioner," and the title of Charon (an official who accompanied the dead from the Roman gladiatorial arena) from Charun, psychopomp of the Etruscan underworld. This was accepted and repeated in most early modern, standard histories of the games.

Reappraisal of pictorial evidence supports a Campanian origin, or at least a borrowing, for the games and gladiators. Campania hosted the earliest known gladiator schools ("ludi"). Tomb frescoes from the Campanian city of Paestum (4th century BC) show paired fighters, with helmets, spears and shields, in a propitiatory funeral blood-rite that anticipates early Roman gladiator games. Compared to these images, supporting evidence from Etruscan tomb-paintings is tentative and late. The Paestum frescoes may represent the continuation of a much older tradition, acquired or inherited from Greek colonists of the 8th century BC.

Livy places the first Roman gladiator games (264 BC) in the early stage of Rome's First Punic War against Carthage, when Decimus Junius Brutus Scaeva had three gladiator pairs fight to the death in Rome's "cattle market" Forum ("Forum Boarium") to honor his dead father, Brutus Pera. This is described as a "munus" (plural: "munera"), a commemorative duty owed the manes of a dead ancestor by his descendants. The development of the "munus" and its gladiator types was most strongly influenced by Samnium's support for Hannibal and the subsequent punitive expeditions against the Samnites by Rome and her Campanian allies; the earliest and most frequently mentioned type was the Samnite.
The war in Samnium, immediately afterwards, was attended with equal danger and an equally glorious conclusion. The enemy, besides their other warlike preparation, had made their battle-line to glitter with new and splendid arms. There were two corps: the shields of the one were inlaid with gold, of the other with silver ... The Romans had already heard of these splendid accoutrements, but their generals had taught them that a soldier should be rough to look on, not adorned with gold and silver but putting his trust in iron and in courage ... The Dictator, as decreed by the senate, celebrated a triumph, in which by far the finest show was afforded by the captured armour. So the Romans made use of the splendid armour of their enemies to do honour to their gods; while the Campanians, in consequence of their pride and in hatred of the Samnites, equipped after this fashion the gladiators who furnished them entertainment at their feasts, and bestowed on them the name Samnites.
Livy's account skirts the funereal, sacrificial function of early Roman gladiator combats and reflects the later theatrical ethos of the Roman gladiator show: splendidly, exotically armed and armoured barbarians, treacherous and degenerate, are dominated by Roman iron and native courage. His plain Romans virtuously dedicate the magnificent spoils of war to the Gods. Their Campanian allies stage a dinner entertainment using gladiators who may not be Samnites, but play the Samnite role. Other groups and tribes would join the cast list as Roman territories expanded. Most gladiators were armed and armoured in the manner of the enemies of Rome. The "munus" became a morally instructive form of historic enactment in which the only honourable option for the gladiator was to fight well, or else die well.

In 216 BC, Marcus Aemilius Lepidus, late consul and augur, was honoured by his sons with three days of "gladiatora munera" in the Forum Romanum, using twenty-two pairs of gladiators. Ten years later, Scipio Africanus gave a commemorative "munus" in Iberia for his father and uncle, casualties in the Punic Wars. High status non-Romans, and possibly Romans too, volunteered as his gladiators. The context of the Punic Wars and Rome's near-disastrous defeat at the Battle of Cannae (216 BC) link these early games to munificence, the celebration of military victory and the religious expiation of military disaster; these "munera" appear to serve a morale-raising agenda in an era of military threat and expansion. The next recorded "munus", held for the funeral of Publius Licinius in 183 BC, was more extravagant. It involved three days of funeral games, 120 gladiators, and public distribution of meat ("visceratio data") – a practice that reflected the gladiatorial fights at Campanian banquets described by Livy and later deplored by Silius Italicus.

The enthusiastic adoption of "gladiatoria munera" by Rome's Iberian allies shows how easily, and how early, the culture of the gladiator "munus" permeated places far from Rome itself. By 174 BC, "small" Roman "munera" (private or public), provided by an "editor" of relatively low importance, may have been so commonplace and unremarkable they were not considered worth recording:
Many gladiatorial games were given in that year, some unimportant, one noteworthy beyond the rest — that of Titus Flamininus which he gave to commemorate the death of his father, which lasted four days, and was accompanied by a public distribution of meats, a banquet, and scenic performances. The climax of the show which was big for the time was that in three days seventy four gladiators fought.
In 105 BC, the ruling consuls offered Rome its first taste of state-sponsored "barbarian combat" demonstrated by gladiators from Capua, as part of a training program for the military. It proved immensely popular. Thereafter, the gladiator contests formerly restricted to private "munera" were often included in the state games ("ludi") that accompanied the major religious festivals. Where traditional "ludi" had been dedicated to a deity, such as Jupiter, the "munera" could be dedicated to an aristocratic sponsor's divine or heroic ancestor.

Gladiator games offered their sponsors extravagantly expensive but effective opportunities for self-promotion, and gave their clients and potential voters exciting entertainment at little or no cost to themselves. Gladiators became big business for trainers and owners, for politicians on the make and those who had reached the top and wished to stay there. A politically ambitious "privatus" (private citizen) might postpone his deceased father's "munus" to the election season, when a generous show might drum up votes; those in power and those seeking it needed the support of the plebeians and their tribunes, whose votes might be won with the mere promise of an exceptionally good show. Sulla, during his term as praetor, showed his usual acumen in breaking his own sumptuary laws to give the most lavish "munus" yet seen in Rome, on occasion of his wife's funeral.

In the closing years of the politically and socially unstable Late Republic, any aristocratic owner of gladiators had political muscle at his disposal. In 65 BC, newly elected curule aedile Julius Caesar held games that he justified as "munus" to his father, who had been dead for 20 years. Despite an already enormous personal debt, he used 320 gladiator pairs in silvered armour. He had more available in Capua but the Senate, mindful of the recent Spartacus revolt and fearful of Caesar's burgeoning private armies and rising popularity, imposed a limit of 320 pairs as the maximum number of gladiators any citizen could keep in Rome. Caesar's showmanship was unprecedented in scale and expense; he had staged a "munus" as memorial rather than funeral rite, eroding any practical or meaningful distinction between "munus" and "ludi".

Gladiatorial games, usually linked with beast shows, spread throughout the Republic and beyond. Anti-corruption laws of 65 and 63 BC attempted but failed to curb the political usefulness of the games to their sponsors. Following Caesar's assassination and the Roman Civil War, Augustus assumed Imperial authority over the games, including "munera", and formalised their provision as a civic and religious duty. His revision of sumptuary law capped private and public expenditure on "munera", claiming to save the Roman elite from the bankruptcies they would otherwise suffer, and restricted their performance to the festivals of Saturnalia and Quinquatria. Henceforth, the ceiling cost for a praetor's "economical" official "munus" employing a maximum 120 gladiators was to be 25,000 denarii; a "generous" Imperial "ludi" might cost no less than 180,000 denarii. Throughout the Empire, the greatest and most celebrated games would now be identified with the state-sponsored Imperial cult, which furthered public recognition, respect and approval for the Emperor's divine numen, his laws, and his agents. Between 108 and 109 AD, Trajan celebrated his Dacian victories using a reported 10,000 gladiators and 11,000 animals over 123 days. The cost of gladiators and "munera" continued to spiral out of control. Legislation of 177 AD by Marcus Aurelius did little to stop it, and was completely ignored by his son, Commodus.

The decline of the "munus" was a far from straightforward process. The crisis of the 3rd century imposed increasing military demands on the imperial purse, from which the Roman Empire never quite recovered, and lesser magistrates found the obligatory "munera" an increasingly unrewarding tax on the doubtful privileges of office. Still, emperors continued to subsidize the games as a matter of undiminished public interest. In the early 3rd century AD, the Christian writer Tertullian had acknowledged their power over the Christian flock, and was compelled to be blunt: the combats were murder, their witnessing spiritually and morally harmful and the gladiator an instrument of pagan human sacrifice. In the next century, Augustine of Hippo deplored the youthful fascination of his friend (and later fellow-convert and Bishop) Alypius of Thagaste, with the "munera" spectacle as inimical to a Christian life and salvation. Amphitheatres continued to host the spectacular administration of Imperial justice: in 315 Constantine the Great condemned child-snatchers "ad bestias" in the arena. Ten years later, he forbade criminals being forced to fight to the death as gladiators:

Bloody spectacles do not please us in civil ease and domestic quiet. For that reason we forbid those people to be gladiators who by reason of some criminal act were accustomed to deserve this condition and sentence. You shall rather sentence them to serve in the mines so that they may acknowledge the penalties of their crimes with blood

This has been interpreted as a ban on gladiatorial combat. Yet, in the last year of his life, Constantine wrote a letter to the citizens of Hispellum, granting its people the right to celebrate his rule with gladiatorial games.

In 365, Valentinian I (r. 364–375) threatened to fine a judge who sentenced Christians to the arena and in 384 attempted, like most of his predecessors, to limit the expenses of "munera".

In 393, Theodosius I (r. 379–395) adopted Nicene Christianity as the state religion of the Roman Empire and banned pagan festivals. The "ludi" continued, very gradually shorn of their stubbornly pagan "munera". Honorius (r. 395–423) legally ended "munera" in 399, and again in 404, at least in the Western Roman Empire. According to Theodoret, the ban was in consequence of Saint Telemachus' martyrdom by spectators at a "munus." Valentinian III (r. 425–455) repeated the ban in 438, perhaps effectively, though "venationes" continued beyond 536. By this time, interest in "munera" had waned throughout the Roman world. In the Byzantine Empire, theatrical shows and chariot races continued to attract the crowds, and drew a generous Imperial subsidy.
It is not known how many "gladiatoria munera" were given throughout the Roman period. Many, if not most, involved "venationes", and in the later Empire some may have been only that. In 165 BC, at least one "munus" was held during April's Megalesia. In the early Imperial era, "munera" in Pompeii and neighbouring towns were dispersed from March through November. They included a provincial magnate's five-day "munus" of thirty pairs, plus beast-hunts. A single late primary source, the "Calendar of Furius Dionysius Philocalus" for 354, shows how seldom gladiators featured among a multitude of official festivals. Of 176 days reserved for spectacles of various kinds, 102 were for theatrical shows, 64 for chariot races and just 10 in December for gladiator games and "venationes". A century before this, the emperor Alexander Severus (r. 222–235) may have intended a more even redistribution of "munera" throughout the year; but this would have broken with what had become the traditional positioning of the major gladiator games, at the year's ending. As Wiedemann points out, December was also the month for the Saturnalia, Saturn's festival, in which death was linked to renewal, and the lowest were honoured as the highest.

The earliest "munera" took place at or near the tomb of the deceased and these were organised by their "munerator" (who made the offering). Later games were held by an "editor", either identical with the "munerator" or an official employed by him. As time passed, these titles and meanings may have merged. In the Republican era, private citizens could own and train gladiators, or lease them from a "lanista" (owner of a gladiator training school). From the Principate onwards, private citizens could hold munera and own gladiators only under Imperial permission, and the role of "editor" was increasingly tied to state officialdom. Legislation by Claudius required that quaestors, the lowest rank of Roman magistrate, personally subsidise two-thirds of the costs of games for their small-town communities – in effect, both an advertisement of their personal generosity and a part-purchase of their office. Bigger games were put on by senior magistrates, who could better afford them. The largest and most lavish of all were paid for by the emperor himself.

The earliest types of gladiator were named after Rome's enemies of that time: the Samnite, Thracian and Gaul. The Samnite, heavily armed, elegantly helmed and probably the most popular type, was renamed secutor and the Gaul renamed murmillo, once these former enemies had been conquered then absorbed into Rome's Empire. In the mid-republican "munus", each type seems to have fought against a similar or identical type. In the later Republic and early Empire, various "fantasy" types were introduced, and were set against dissimilar but complementary types. For example, the bareheaded, nimble retiarius ("net-man"), armoured only at the left arm and shoulder, pitted his net, trident and dagger against the more heavily armoured, helmeted Secutor. Most depictions of gladiators show the most common and popular types. Passing literary references to others has allowed their tentative reconstruction. Other novelties introduced around this time included gladiators who fought from chariots or carts, or from horseback.

The trade in gladiators was empire-wide, and subjected to official supervision. Rome's military success produced a supply of soldier-prisoners who were redistributed for use in State mines or amphitheatres and for sale on the open market. For example, in the aftermath of the Jewish Revolt, the gladiator schools received an influx of Jews – those rejected for training would have been sent straight to the arenas as "noxii" (lit. "hurtful ones"). The best – the most robust – were sent to Rome. In Rome's military ethos, enemy soldiers who had surrendered or allowed their own capture and enslavement had been granted an unmerited gift of life. Their training as gladiators would give them opportunity to redeem their honour in the "munus".

Two other sources of gladiators, found increasingly during the Principate and the relatively low military activity of the Pax Romana, were slaves condemned to the arena ("damnati"), to gladiator schools or games ("ad ludum gladiatorium") as punishment for crimes, and the paid volunteers ("auctorati") who by the late Republic may have comprised approximately half – and possibly the most capable half – of all gladiators. The use of volunteers had a precedent in the Iberian "munus" of Scipio Africanus; but none of those had been paid.

For the poor, and for non-citizens, enrollment in a gladiator school offered a trade, regular food, housing of sorts and a fighting chance of fame and fortune. Mark Antony chose a troupe of gladiators to be his personal bodyguard. Gladiators customarily kept their prize money and any gifts they received, and these could be substantial. Tiberius offered several retired gladiators 100,000 "sesterces" each to return to the arena. Nero gave the gladiator Spiculus property and residence "equal to those of men who had celebrated triumphs."

From the 60s AD female gladiators appear as rare and "exotic markers of exceptionally lavish spectacle". In 66 AD, Nero had Ethiopian women, men and children fight at a "munus" to impress the King Tiridates I of Armenia. Romans seem to have found the idea of a female gladiator novel and entertaining, or downright absurd; Juvenal titillates his readers with a woman named "Mevia", hunting boars in the arena "with spear in hand and breasts exposed", and Petronius mocks the pretensions of a rich, low-class citizen, whose "munus" includes a woman fighting from a cart or chariot. A "munus" of 89 AD, during Domitian's reign, featured a battle between female gladiators, described as "Amazons". In Halicarnassus, a 2nd-century AD relief depicts two female combatants named "Amazon" and "Achillia"; their match ended in a draw. In the same century, an epigraph praises one of Ostia's local elite as the first to "arm women" in the history of its games. Female gladiators probably submitted to the same regulations and training as their male counterparts. Roman morality required that all gladiators be of the lowest social classes, and emperors who failed to respect this distinction earned the scorn of posterity. Cassius Dio takes pains to point out that when the much admired emperor Titus used female gladiators, they were of acceptably low class.

Some regarded female gladiators of any type or class as a symptom of corrupted Roman appetites, morals and womanhood. Before he became emperor, Septimius Severus may have attended the Antiochene Olympic Games, which had been revived by the emperor Commodus and included traditional Greek female athletics. His attempt to give Rome a similarly dignified display of female athletics was met by the crowd with ribald chants and cat-calls. Probably as a result, he banned the use of female gladiators in 200 AD.

Caligula, Titus, Hadrian, Lucius Verus, Caracalla, Geta and Didius Julianus were all said to have performed in the arena, either in public or private, but risks to themselves were minimal. Claudius, characterised by his historians as morbidly cruel and boorish, fought a whale trapped in the harbor in front of a group of spectators. Commentators invariably disapproved of such performances.

Commodus was a fanatical participant at the "ludi", and compelled Rome's elite to attend his performances as gladiator, "bestiarius" or "venator". Most of his performances as a gladiator were bloodless affairs, fought with wooden swords; he invariably won. He was said to have restyled Nero's colossal statue in his own image as "Hercules Reborn", dedicated to himself as "Champion of "secutores"; only left-handed fighter to conquer twelve times one thousand men." He was said to have killed 100 lions in one day, almost certainly from an elevated platform surrounding the arena perimeter, which allowed him to safely demonstrate his marksmanship. On another occasion, he decapitated a running ostrich with a specially designed dart, carried the bloodied head and his sword over to the Senatorial seats and gesticulated as though they were next. As reward for these services, he drew a gigantic stipend from the public purse.

Gladiator games were advertised well beforehand, on billboards that gave the reason for the game, its editor, venue, date and the number of paired gladiators ("ordinarii") to be used. Other highlighted features could include details of "venationes", executions, music and any luxuries to be provided for the spectators, such as an awning against the sun, water sprinklers, food, drink, sweets and occasionally "door prizes". For enthusiasts and gamblers, a more detailed program ("libellus") was distributed on the day of the "munus", showing the names, types and match records of gladiator pairs, and their order of appearance. Left-handed gladiators were advertised as a rarity; they were trained to fight right-handers, which gave them an advantage over most opponents and produced an interestingly unorthodox combination.

The night before the "munus", the gladiators were given a banquet and opportunity to order their personal and private affairs; Futrell notes its similarity to a ritualistic or sacramental "last meal". These were probably both family and public events which included even the "noxii", sentenced to die in the arena the following day; and the "damnati", who would have at least a slender chance of survival. The event may also have been used to drum up more publicity for the imminent game.

Official "munera" of the early Imperial era seem to have followed a standard form ("munus legitimum"). A procession ("pompa") entered the arena, led by lictors who bore the fasces that signified the magistrate-"editor"'s power over life and death. They were followed by a small band of trumpeters ("tubicines") playing a fanfare. Images of the gods were carried in to "witness" the proceedings, followed by a scribe to record the outcome, and a man carrying the palm branch used to honour victors. The magistrate "editor" entered among a retinue who carried the arms and armour to be used; the gladiators presumably came in last.
The entertainments often began with "venationes" (beast hunts) and "bestiarii" (beast fighters). Next came the "ludi meridiani", which were of variable content but usually involved executions of "noxii", some of whom were condemned to be subjects of fatal re-enactments, based on Greek or Roman myths. Gladiators may have been involved in these as executioners, though most of the crowd, and the gladiators themselves, preferred the "dignity" of an even contest. There were also comedy fights; some may have been lethal. A crude Pompeian graffito suggests a burlesque of musicians, dressed as animals named "Ursus tibicen" (flute-playing bear) and "Pullus cornicen" (horn-blowing chicken), perhaps as accompaniment to clowning by "paegniarii" during a "mock" contest of the "ludi meridiani".

The gladiators may have held informal warm-up matches, using blunted or dummy weapons – some "munera", however, may have used blunted weapons throughout. The "editor," his representative or an honoured guest would check the weapons ("probatio armorum") for the scheduled matches. These were the highlight of the day, and were as inventive, varied and novel as the "editor" could afford. Armatures could be very costly – some were flamboyantly decorated with exotic feathers, jewels and precious metals. Increasingly the "munus" was the "editor"'s gift to spectators who had come to expect the best as their due.

Lightly armed and armoured fighters, such as the retiarius, would tire less rapidly than their heavily armed opponents; most bouts would have lasted 10 to 15 minutes, or 20 minutes at most. In late Republican "munera", between 10 and 13 matches could have been fought on one day; this assumes one match at a time in the course of an afternoon.

Spectators preferred to watch highly skilled, well matched "ordinarii" with complementary fighting styles; these were the most costly to train and to hire. A general "melee" of several, lower-skilled gladiators was far less costly, but also less popular. Even among the "ordinarii", match winners might have to fight a new, well-rested opponent, either a "tertiarius" ("third choice gladiator") by prearrangement; or a "substitute" gladiator ("suppositicius") who fought at the whim of the "editor" as an unadvertised, unexpected "extra". This yielded two combats for the cost of three gladiators, rather than four; such contests were prolonged, and in some cases, more bloody. Most were probably of poor quality, but the emperor Caracalla chose to test a notably skilled and successful fighter named Bato against first one "supposicitius", whom he beat, and then another, who killed him. At the opposite level of the profession, a gladiator reluctant to confront his opponent might be whipped, or goaded with hot irons, until he engaged through sheer desperation.
Combats between experienced, well trained gladiators demonstrated a considerable degree of stagecraft. Among the cognoscenti, bravado and skill in combat were esteemed over mere hacking and bloodshed; some gladiators made their careers and reputation from bloodless victories. Suetonius describes an exceptional "munus" by Nero, in which no-one was killed, "not even "noxii" (enemies of the state)."

Trained gladiators were expected to observe professional rules of combat. Most matches employed a senior referee ("summa rudis") and an assistant, shown in mosaics with long staffs ("rudes") to caution or separate opponents at some crucial point in the match. Referees were usually retired gladiators whose decisions, judgement and discretion were, for the most part, respected; they could stop bouts entirely, or pause them to allow the combatants rest, refreshment and a rub-down.

Ludi and "munera" were accompanied by music, played as interludes, or building to a "frenzied crescendo" during combats, perhaps to heighten the suspense during a gladiator's appeal; blows may have been accompanied by trumpet-blasts. The Zliten mosaic in Libya (circa 80–100 AD) shows musicians playing an accompaniment to provincial games (with gladiators, "bestiarii", or "venatores" and prisoners attacked by beasts). Their instruments are a long straight trumpet ("tubicen"), a large curved horn ("Cornu") and a water organ ("hydraulis"). Similar representations (musicians, gladiators and "bestiari") are found on a tomb relief in Pompeii.

A match was won by the gladiator who overcame his opponent, or killed him outright. Victors received the palm branch and an award from the "editor". An outstanding fighter might receive a laurel crown and money from an appreciative crowd but for anyone originally condemned "ad ludum" the greatest reward was manumission (emancipation), symbolised by the gift of a wooden training sword or staff ("rudis") from the "editor". Martial describes a match between Priscus and Verus, who fought so evenly and bravely for so long that when both acknowledged defeat at the same instant, Titus awarded victory and a "rudis" to each. Flamma was awarded the "rudis" four times, but chose to remain a gladiator. His gravestone in Sicily includes his record: "Flamma, "secutor", lived 30 years, fought 34 times, won 21 times, fought to a draw 9 times, defeated 4 times, a Syrian by nationality. Delicatus made this for his deserving comrade-in-arms."

A gladiator could acknowledge defeat by raising a finger ("ad digitum"), in appeal to the referee to stop the combat and refer to the "editor", whose decision would usually rest on the crowd's response. In the earliest "munera", death was considered a righteous penalty for defeat; later, those who fought well might be granted remission at the whim of the crowd or the "editor". During the Imperial era, matches advertised as "sine missione" (without remission from the sentence of death) suggest that "missio" (the sparing of a defeated gladiator's life) had become common practice. The contract between "editor" and his "lanista" could include compensation for unexpected deaths; this could be "some fifty times higher than the lease price" of the gladiator.

Under Augustus' rule, the demand for gladiators began to exceed supply, and matches "sine missione" were officially banned; an economical, pragmatic development that happened to match popular notions of "natural justice". When Caligula and Claudius refused to spare defeated but popular fighters, their own popularity suffered. In general, gladiators who fought well were likely to survive. At a Pompeian match between chariot-fighters, Publius Ostorius, with previous 51 wins to his credit, was granted missio after losing to Scylax, with 26 victories. By common custom, the spectators decided whether or not a losing gladiator should be spared, and chose the winner in the rare event of a standing tie. Even more rarely, perhaps uniquely, one stalemate ended in the killing of one gladiator by the "editor" himself. In any event, the final decision of death or life belonged to the "editor", who signalled his choice with a gesture described by Roman sources as "pollice verso" meaning "with a turned thumb"; a description too imprecise for reconstruction of the gesture or its symbolism. Whether victorious or defeated, a gladiator was bound by oath to accept or implement his editor's decision, "the victor being nothing but the instrument of his [editor's] will." Not all "editors" chose to go with the crowd, and not all those condemned to death for putting on a poor show chose to submit:

Once a band of five "retiarii" in tunics, matched against the same number of "secutores", yielded without a struggle; but when their death was ordered, one of them caught up his trident and slew all the victors. Caligula bewailed this in a public proclamation as a most cruel murder.
A gladiator who was refused "missio" was despatched by his opponent. To die well, a gladiator should never ask for mercy, nor cry out. A "good death" redeemed the gladiator from the dishonourable weakness and passivity of defeat, and provided a noble example to those who watched:
For death, when it stands near us, gives even to inexperienced men the courage not to seek to avoid the inevitable. So the gladiator, no matter how faint-hearted he has been throughout the fight, offers his throat to his opponent and directs the wavering blade to the vital spot. (Seneca. "Epistles", 30.8)

Some mosaics show defeated gladiators kneeling in preparation for the moment of death. Seneca's "vital spot" seems to have meant the neck. Gladiator remains from Ephesus confirm this.

The body of a gladiator who had died well was placed on a couch of Libitina and removed with dignity to the arena morgue, where the corpse was stripped of armour, and probably had its throat cut to prove that dead was dead. The Christian author Tertullian, commenting on "ludi meridiani" in Roman Carthage during the peak era of the games, describes a more humiliating method of removal. One arena official, dressed as the "brother of Jove", Dis Pater (god of the underworld) strikes the corpse with a mallet. Another, dressed as Mercury, tests for life-signs with a heated "wand"; once confirmed as dead, the body is dragged from the arena.

Whether these victims were gladiators or "noxii" is unknown. Modern pathological examination confirms the probably fatal use of a mallet on some, but not all the gladiator skulls found in a gladiators' cemetery. Kyle (1998) proposes that gladiators who disgraced themselves might have been subjected to the same indignities as "noxii", denied the relative mercies of a quick death and dragged from the arena as carrion. Whether the corpse of such a gladiator could be redeemed from further ignominy by friends or "familia" is not known.

The bodies of "noxii", and possibly some "damnati", were thrown into rivers or dumped unburied; Denial of funeral rites and memorial condemned the shade ("manes") of the deceased to restless wandering upon the earth as a dreadful "larva" or "lemur". Ordinary citizens, slaves and freedmen were usually buried beyond the town or city limits, to avoid the ritual and physical pollution of the living; professional gladiators had their own, separate cemeteries. The taint of "infamia" was perpetual.

Gladiators could subscribe to a union ("collegia"), which ensured their proper burial, and sometimes a pension or compensation for wives and children. Otherwise, the gladiator's "familia", which included his "lanista", comrades and blood-kin, might fund his funeral and memorial costs, and use the memorial to assert their moral reputation as responsible, respectful colleagues or family members. Some monuments record the gladiator's career in some detail, including the number of appearances, victories  —  sometimes represented by an engraved crown or wreath  —  defeats, career duration, and age at death. Some include the gladiator's type, in words or direct representation: for example, the memorial of a retiarius at Verona included an engraved trident and sword. A wealthy editor might commission artwork to celebrate a particularly successful or memorable show, and include named portraits of winners and losers in action; the Borghese Gladiator Mosaic is a notable example. According to Cassius Dio, the emperor Caracalla gave the gladiator Bato a magnificent memorial and State funeral; more typical are the simple gladiator tombs of the Eastern Roman Empire, whose brief inscriptions include the following:

"The familia set this up in memory of Saturnilos."
"For Nikepharos, son of Synetos, Lakedaimonian, and for Narcissus the secutor. Titus Flavius Satyrus set up this monument in his memory from his own money."
"For Hermes. Paitraeites with his cell-mates set this up in memory".
Very little evidence survives of the religious beliefs of gladiators as a class, or their expectations of an afterlife. Modern scholarship offers little support for the once-prevalent notion that gladiators, "venatores" and "bestiarii" were personally or professionally dedicated to the cult of the Graeco-Roman goddess Nemesis. Rather, she seems to have represented a kind of "Imperial Fortuna" who dispensed Imperial retribution on the one hand, and Imperially subsidised gifts on the other – including the "munera". One gladiator's tomb dedication clearly states that her decisions are not to be trusted. Many gladiator epitaphs claim Nemesis, fate, deception or treachery as the instrument of their death, never the superior skills of the flesh-and-blood adversary who defeated and killed them. Having no personal responsibility for his own defeat and death, the losing gladiator remains the better man, worth avenging.

"I, Victor, left-handed, lie here, but my homeland was in Thessalonica. Doom killed me, not the liar Pinnas. No longer let him boast. I had a fellow gladiator, Polyneikes, who killed Pinnas and avenged me. Claudius Thallus set up this memorial from what I left behind as a legacy."
A gladiator might expect to fight in two or three munera annually, and an unknown number would have died in their first match. Few gladiators survived more than 10 contests, though one survived an extraordinary 150 bouts; and another died at 90 years of age, presumably long after retirement. A natural death following retirement is also likely for three individuals who died at 38, 45, and 48 years respectively. George Ville, using evidence from 1st century gladiator headstones, calculated an average age at death of 27, and mortality "among all who entered the arena" at 19/100. Marcus Junkelmann disputes Ville's calculation for average age at death; the majority would have received no headstone, and would have died early in their careers, at 18–25 years of age. Between the early and later Imperial periods the risk of death for defeated gladiators rose from 1/5 to 1/4, perhaps because "missio" was granted less often. Hopkins and Beard tentatively estimate a total of 400 arenas throughout the Roman Empire at its greatest extent, with a combined total of 8,000 deaths per annum from executions, combats and accidents.

The earliest named gladiator school (singular: "ludus"; plural: "ludi") is that of Aurelius Scaurus at Capua. He was "lanista" of the gladiators employed by the state circa 105 BC to instruct the legions and simultaneously entertain the public. Few other "lanistae" are known by name: they headed their "familia gladiatoria", and had lawful power over life and death of every family member, including "servi poenae", "auctorati" and ancillaries. Socially, they were "infames", on a footing with pimps and butchers and despised as price gougers. No such stigma was attached to a gladiator owner ("munerarius" or "editor") of good family, high status and independent means; Cicero congratulated his friend Atticus on buying a splendid troop – if he rented them out, he might recover their entire cost after two performances.

The Spartacus revolt had originated in a gladiator school privately owned by Lentulus Batiatus, and had been suppressed only after a protracted series of costly, sometimes disastrous campaigns by regular Roman troops. In the late Republican era, a fear of similar uprisings, the usefulness of gladiator schools in creating private armies, and the exploitation of "munera" for political gain led to increased restrictions on gladiator school ownership, siting and organisation. By Domitian's time, many had been more or less absorbed by the State, including those at Pergamum, Alexandria, Praeneste and Capua. The city of Rome itself had four; the "Ludus Magnus" (the largest and most important, housing up to about 2,000 gladiators), "Ludus Dacicus", "Ludus Gallicus", and the "Ludus Matutinus", which trained "bestiarii".

In the Imperial era, volunteers required a magistrate's permission to join a school as "auctorati". If this was granted, the school's physician assessed their suitability. Their contract ("auctoramentum") stipulated how often they were to perform, their fighting style and earnings. A condemned bankrupt or debtor accepted as novice ("novicius") could negotiate with his "lanista" or "editor" for the partial or complete payment of his debt. Faced with runaway re-enlistment fees for skilled "auctorati", Marcus Aurelius set their upper limit at 12,000 "sesterces".

All prospective gladiators, whether volunteer or condemned, were bound to service by a sacred oath ("sacramentum"). Novices ("novicii") trained under teachers of particular fighting styles, probably retired gladiators. They could ascend through a hierarchy of grades (singular: "palus") in which "primus palus" was the highest. Lethal weapons were prohibited in the schools – weighted, blunt wooden versions were probably used. Fighting styles were probably learned through constant rehearsal as choreographed "numbers". An elegant, economical style was preferred. Training included preparation for a stoical, unflinching death. Successful training required intense commitment.

Those condemned "ad ludum" were probably branded or marked with a tattoo ("stigma", plural "stigmata") on the face, legs and/or hands. These "stigmata" may have been text – slaves were sometimes thus marked on the forehead until Constantine banned the use of facial stigmata in 325 AD. Soldiers were routinely marked on the hand.

Gladiators were typically accommodated in cells, arranged in barrack formation around a central practice arena. Juvenal describes the segregation of gladiators according to type and status, suggestive of rigid hierarchies within the schools: "even the lowest scum of the arena observe this rule; even in prison they're separate". "Retiarii" were kept away from "damnati", and "fag targeteers" from "armoured heavies". As most "ordinarii" at games were from the same school, this kept potential opponents separate and safe from each other until the lawful "munus". Discipline could be extreme, even lethal. Remains of a Pompeian "ludus" site attest to developments in supply, demand and discipline; in its earliest phase, the building could accommodate 15–20 gladiators. Its replacement could have housed about 100 and included a very small cell, probably for lesser punishments and so low that standing was impossible.

Despite the harsh discipline, gladiators represented a substantial investment for their "lanista" and were otherwise well fed and cared for. Their daily, high-energy, vegetarian diet consisted of barley, boiled beans, oatmeal, ash and dried fruit. Gladiators were sometimes called "hordearii" (eaters of barley). Romans considered barley inferior to wheat — a punishment for legionaries replaced their wheat ration with it — but it was thought to strengthen the body. Regular massage and high quality medical care helped mitigate an otherwise very severe training regimen. Part of Galen's medical training was at a gladiator school in Pergamum where he saw (and would later criticise) the training, diet, and long-term health prospects of the gladiators.

"He vows to endure to be burned, to be bound, to be beaten, and to be killed by the sword." "The gladiator's oath as cited by Petronius (Satyricon, 117)."
Modern customs and institutions offer few useful parallels to the legal and social context of the "gladiatoria munera". In Roman law, anyone condemned to the arena or the gladiator schools ("damnati ad ludum") was a "servus poenae" (slave of the penalty), and was considered to be under sentence of death unless manumitted. A rescript of Hadrian reminded magistrates that "those sentenced to the sword" (execution) should be despatched immediately "or at least within the year", and those sentenced to the "ludi" should not be discharged before five years, or three years if granted manumission. Only slaves found guilty of specific offences could be sentenced to the arena; however, citizens found guilty of particular offenses could be stripped of citizenship, formally enslaved, then sentenced; and slaves, once freed, could be legally reverted to slavery for certain offences. Arena punishment could be given for banditry, theft and arson, and for treasons such as rebellion, census evasion to avoid paying due taxes and refusal to swear lawful oaths.

Offenders seen as particularly obnoxious to the state ("noxii") received the most humiliating punishments. By the 1st century BC, "noxii" were being condemned to the beasts ("damnati ad bestias") in the arena, with almost no chance of survival, or were made to kill each other. From the early Imperial era, some were forced to participate in humiliating and novel forms of mythological or historical enactment, culminating in their execution. Those judged less harshly might be condemned "ad ludum venatorium" or "ad gladiatorium" – combat with animals or gladiators – and armed as thought appropriate. These "damnati" at least might put on a good show and retrieve some respect, and very rarely, survive to fight another day. Some may even have become "proper" gladiators.

Among the most admired and skilled "auctorati" were those who, having been granted manumission, volunteered to fight in the arena. Some of these highly trained and experienced specialists may have had no other practical choice open to them. Their legal status – slave or free – is uncertain. Under Roman law, a freed gladiator could not "offer such services [as those of a gladiator] after manumission, because they cannot be performed without endangering [his] life." All contracted volunteers, including those of equestrian and senatorial class, were legally enslaved by their "auctoratio" because it involved their potentially lethal submission to a master. All "arenarii" (those who appeared in the arena) were ""infames" by reputation", a form of social dishonour which excluded them from most of the advantages and rights of citizenship. Payment for such appearances compounded their "infamia". The legal and social status of even the most popular and wealthy "auctorati" was thus marginal at best. They could not vote, plead in court nor leave a will; and unless they were manumitted, their lives and property belonged to their masters. Nevertheless, there is evidence of informal if not entirely lawful practices to the contrary. Some "unfree" gladiators bequeathed money and personal property to wives and children, possibly via a sympathetic owner or "familia"; some had their own slaves and gave them their freedom. One gladiator was even granted "citizenship" to several Greek cities of the Eastern Roman world.

Caesar's "munus" of 46 BC included at least one equestrian, son of a Praetor, and two volunteers of possible senatorial rank. Augustus, who enjoyed watching the games, forbade the participation of senators, equestrians and their descendants as fighters or "arenarii", but in 11 AD he bent his own rules and allowed equestrians to volunteer because "the prohibition was no use". Under Tiberius, the Larinum decree (19AD) reiterated Augustus' original prohibitions. Thereafter, Caligula flouted them and Claudius strengthened them. Nero and Commodus ignored them. Even after the adoption of Christianity as Rome's official religion, legislation forbade the involvement of Rome's upper social classes in the games, though not the games themselves. Throughout Rome's history, some volunteers were prepared to risk loss of status or reputation by appearing in the arena, whether for payment, glory or, as in one recorded case, to revenge an affront to their personal honour. In one extraordinary episode, an aristocratic descendant of the Gracchi, already infamous for his marriage, as a bride, to a male horn player, appeared in what may have been a non-lethal or farcical match. His motives are unknown, but his voluntary and "shameless" arena appearance combined the "womanly attire" of a lowly "retiarius tunicatus", adorned with golden ribbons, with the apex headdress that marked him out as a priest of Mars. In Juvenal's account, he seems to have relished the scandalous self-display, applause and the disgrace he inflicted on his more sturdy opponent by repeatedly skipping away from the confrontation.

As "munera" grew larger and more popular, open spaces such as the Forum Romanum were adapted (as the Forum Boarium had been) as venues in Rome and elsewhere, with temporary, elevated seating for the patron and high status spectators; they were popular but not truly public events:

A show of gladiators was to be exhibited before the people in the market-place, and most of the magistrates erected scaffolds round about, with an intention of letting them for advantage. Caius commanded them to take down their scaffolds, that the poor people might see the sport without paying anything. But nobody obeying these orders of his, he gathered together a body of labourers, who worked for him, and overthrew all the scaffolds the very night before the contest was to take place. So that by the next morning the market-place was cleared, and the common people had an opportunity of seeing the pastime. In this, the populace thought he had acted the part of a man; but he much disobliged the tribunes his colleagues, who regarded it as a piece of violent and presumptuous interference.

Towards the end of the Republic, Cicero ("Murena", 72–3) still describes gladiator shows as ticketed — their political usefulness was served by inviting the rural tribunes of the plebs, not the people of Rome "en masse" – but in Imperial times, poor citizens in receipt of the corn dole were allocated at least some free seating, possibly by lottery. Others had to pay. Ticket scalpers ("Locarii") sometimes sold or let out seats at inflated prices. Martial wrote that "Hermes [a gladiator who always drew the crowds] means riches for the ticket scalpers".

The earliest known Roman amphitheatre was built at Pompeii by Sullan colonists, around 70 BC. The first in the city of Rome was the extraordinary wooden amphitheatre of Gaius Scribonius Curio (built in 53 BC). The first part-stone amphitheatre in Rome was inaugurated in 29–30 BC, in time for the triple triumph of Octavian (later Augustus). Shortly after it burned down in 64 AD, Vespasian began its replacement, later known as the Amphitheatrum Flavium (Colosseum), which seated 50,000 spectators and would remain the largest in the Empire. It was inaugurated by Titus in 80 AD as the personal gift of the Emperor to the people of Rome, paid for by the imperial share of booty after the Jewish Revolt.

Amphitheatres were usually oval in plan. Their seating tiers surrounded the arena below, where the community's judgments were meted out, in full public view. From across the stands, crowd and "editor" could assess each other's character and temperament. For the crowd, amphitheatres afforded unique opportunities for free expression and free speech ("theatralis licentia"). Petitions could be submitted to the "editor" (as magistrate) in full view of the community. "Factiones" and claques could vent their spleen on each other, and occasionally on Emperors. The emperor Titus's dignified yet confident ease in his management of an amphitheatre crowd and its factions were taken as a measure of his enormous popularity and the rightness of his imperium. The amphitheatre "munus" thus served the Roman community as living theatre and a court in miniature, in which judgement could be served not only on those in the arena below, but on their judges. Amphitheatres also provided a means of social control. Their seating was "disorderly and indiscriminate" until Augustus prescribed its arrangement in his Social Reforms. To persuade the Senate, he expressed his distress on behalf of a Senator who could not find seating at a crowded games in Puteoli:
In consequence of this the senate decreed that, whenever any public show was given anywhere, the first row of seats should be reserved for senators; and at Rome he would not allow the envoys of the free and allied nations to sit in the orchestra, since he was informed that even freedmen were sometimes appointed. He separated the soldiery from the people. He assigned special seats to the married men of the commons, to boys under age their own section and the adjoining one to their preceptors; and he decreed that no one wearing a dark cloak should sit in the middle of the house. He would not allow women to view even the gladiators except from the upper seats, though it had been the custom for men and women to sit together at such shows. Only the Vestal virgins were assigned a place to themselves, opposite the praetor's tribunal.
These arrangements do not seem to have been strongly enforced.

Popular factions supported favourite gladiators and gladiator types. Under Augustan legislation, the Samnite type was renamed "Secutor" ("chaser", or "pursuer"). The secutor was equipped with a long, heavy "large" shield called a "scutum"; "Secutores", their supporters and any heavyweight "secutor"-based types such as the Murmillo were "secutarii". Lighter types, such as the Thraex, were equipped with a smaller, lighter shield called a "parma", from which they and their supporters were named "parmularii" ("small shields"). Titus and Trajan preferred the "parmularii" and Domitian the "secutarii"; Marcus Aurelius took neither side. Nero seems to have enjoyed the brawls between rowdy, enthusiastic and sometimes violent factions, but called in the troops if they went too far.

There were also local rivalries. At Pompeii's amphitheatre, during Nero's reign, the trading of insults between Pompeians and Nucerian spectators during public "ludi" led to stone throwing and riot. Many were killed or wounded. Nero banned gladiator "munera" (though not the games) at Pompeii for ten years as punishment. The story is told in Pompeian graffiti and high quality wall painting, with much boasting of Pompeii's "victory" over Nuceria.

A man who knows how to conquer in war is a man who knows how to arrange a banquet and put on a show.
Rome was essentially a landowning military aristocracy. From the early days of the Republic, ten years of military service were a citizen's duty and a prerequisite for election to public office. "Devotio" (willingness to sacrifice one's life to the greater good) was central to the Roman military ideal, and was the core of the Roman military oath. It applied from highest to lowest alike in the chain of command. As a soldier committed his life (voluntarily, at least in theory) to the greater cause of Rome's victory, he was not expected to survive defeat.

The Punic Wars of the late 3rd century BC – in particular the near-catastrophic defeat of Roman arms at Cannae – had long-lasting effects on the Republic, its citizen armies, and the development of the gladiatorial "munera". In the aftermath of Cannae, Scipio Africanus crucified Roman deserters and had non-Roman deserters thrown to the beasts. The Senate refused to ransom Hannibal's Roman captives: instead, they consulted the Sibylline books, then made drastic preparations:
In obedience to the Books of Destiny, some strange and unusual sacrifices were made, human sacrifices amongst them. A Gaulish man and a Gaulish woman and a Greek man and a Greek woman were buried alive under the Forum Boarium ... They were lowered into a stone vault, which had on a previous occasion also been polluted by human victims, a practice most repulsive to Roman feelings. When the gods were believed to be duly propitiated ... Armour, weapons, and other things of the kind were ordered to be in readiness, and the ancient spoils gathered from the enemy were taken down from the temples and colonnades. The dearth of freemen necessitated a new kind of enlistment; 8,000 sturdy youths from amongst the slaves were armed at the public cost, after they had each been asked whether they were willing to serve or no. These soldiers were preferred, as there would be an opportunity of ransoming them when taken prisoners at a lower price.
The account notes, uncomfortably, the bloodless human sacrifices performed to help turn the tide of the war in Rome's favour. While the Senate mustered their willing slaves, Hannibal offered his dishonoured Roman captives a chance for honourable death, in what Livy describes as something very like the Roman "munus". The "munus" thus represented an essentially military, self-sacrificial ideal, taken to extreme fulfillment in the gladiator's oath. By the "devotio" of a voluntary oath, a slave might achieve the quality of a Roman ("Romanitas"), become the embodiment of true "virtus" (manliness, or manly virtue), and paradoxically, be granted "missio" while remaining a slave. The gladiator as a specialist fighter, and the ethos and organization of the gladiator schools, would inform the development of the Roman military as the most effective force of its time. In 107 BC, the Marian Reforms established the Roman army as a professional body. Two years later, following its defeat at the Battle of Arausio:
...weapons training was given to soldiers by P. Rutilius, consul with C. Mallis. For he, following the example of no previous general, with teachers summoned from the gladiatorial training school of C. Aurelus Scaurus, implanted in the legions a more sophisticated method of avoiding and dealing a blow and mixed bravery with skill and skill back again with virtue so that skill became stronger by bravery's passion and passion became more wary with the knowledge of this art.
The military were great aficionados of the games, and supervised the schools. Many schools and amphitheatres were sited at or near military barracks, and some provincial army units owned gladiator troupes. As the Republic wore on, the term of military service increased from ten to the sixteen years formalised by Augustus in the Principate. It would rise to twenty, and later, to twenty-five years. Roman military discipline was ferocious; severe enough to provoke mutiny, despite the consequences. A career as a volunteer gladiator may have seemed an attractive option for some.

In AD 69, the Year of the Four Emperors, Otho's troops at Bedriacum included 2000 gladiators. Opposite him on the field, Vitellius's army was swollen by levies of slaves, plebs and gladiators. In 167 AD, troop depletions by plague and desertion may have prompted Marcus Aurelius to draft gladiators at his own expense. During the Civil Wars that led to the Principate, Octavian (later Augustus) acquired the personal gladiator troop of his erstwhile opponent, Mark Antony. They had served their late master with exemplary loyalty but thereafter, they disappear from the record.

Roman writing as a whole demonstrates a deep ambivalence towards the "gladiatoria munera". Even the most complex and sophisticated "munera" of the Imperial era evoked the ancient, ancestral "dii manes" of the underworld and were framed by the protective, lawful rites of "sacrificium". Their popularity made their co-option by the state inevitable; Cicero acknowledged their sponsorship as a political imperative. Despite the popular adulation of gladiators, they were set apart, despised; and despite Cicero's contempt for the mob, he shared their admiration: "Even when [gladiators] have been felled, let alone when they are standing and fighting, they never disgrace themselves. And suppose a gladiator has been brought to the ground, when do you ever see one twist his neck away after he has been ordered to extend it for the death blow?" His own death would later emulate this example. Yet, Cicero could also refer to his popularist opponent Clodius, publicly and scathingly, as a "bustuarius" – literally, a "funeral-man", implying that Clodius has shown the moral temperament of the lowest sort of gladiator. "Gladiator" could be (and was) used as an insult throughout the Roman period, and "Samnite" doubled the insult, despite the popularity of the Samnite type. Silius Italicus wrote, as the games approached their peak, that the degenerate Campanians had devised the very worst of precedents, which now threatened the moral fabric of Rome: "It was their custom to enliven their banquets with bloodshed and to combine with their feasting the horrid sight of armed men [(Samnites)] fighting; often the combatants fell dead above the very cups of the revelers, and the tables were stained with streams of blood. Thus demoralised was Capua." Death could be rightly meted out as punishment, or met with equanimity in peace or war, as a gift of fate; but when inflicted as entertainment, with no underlying moral or religious purpose, it could only pollute and demean those who witnessed it.
The "munus" itself could be interpreted as pious necessity, but its increasing luxury corroded Roman virtue, and created an un-Roman appetite for profligacy and self-indulgence. Caesar's 46 BC "ludi" were mere entertainment for political gain, a waste of lives and of money that would have been better doled out to his legionary veterans. Yet for Seneca, and for Marcus Aurelius – both professed Stoics – the degradation of gladiators in the "munus" highlighted their Stoic virtues: their unconditional obedience to their master and to fate, and equanimity in the face of death. Having "neither hope nor illusions", the gladiator could transcend his own debased nature, and disempower death itself by meeting it face to face. Courage, dignity, altruism and loyalty were morally redemptive; Lucian idealised this principle in his story of Sisinnes, who voluntarily fought as a gladiator, earned 10,000 drachmas and used it to buy freedom for his friend, Toxaris. Seneca had a lower opinion of the mob's un-Stoical appetite for "ludi meridiani": "Man [is]...now slaughtered for jest and sport; and those whom it used to be unholy to train for the purpose of inflicting and enduring wounds are thrust forth exposed and defenceless."

These accounts seek a higher moral meaning from the "munus", but Ovid's very detailed (though satirical) instructions for seduction in the amphitheatre suggest that the spectacles could generate a potent and dangerously sexual atmosphere. Augustan seating prescriptions placed women – excepting the Vestals, who were legally inviolate – as far as possible from the action of the arena floor; or tried to. There remained the thrilling possibility of clandestine sexual transgression by high-caste spectators and their heroes of the arena. Such assignations were a source for gossip and satire but some became unforgivably public:
What was the youthful charm that so fired Eppia? What hooked her? What did she see in him to make her put up with being called "the gladiator's moll"? Her poppet, her Sergius, was no chicken, with a dud arm that prompted hope of early retirement. Besides his face looked a proper mess, helmet-scarred, a great wart on his nose, an unpleasant discharge always trickling from one eye. But he was a gladiator. That word makes the whole breed seem handsome, and made her prefer him to her children and country, her sister, her husband. Steel is what they fall in love with.
Eppia – a senator's wife – and her Sergius eloped to Egypt, where he deserted her. Most gladiators would have aimed lower. Two wall "graffiti" in Pompeii describe Celadus the Thraex as "the sigh of the girls" and "the glory of the girls" – which may or may not have been Celadus' own wishful thinking.

In the later Imperial era, Servius Maurus Honoratus uses the same disparaging term as Cicero – "bustuarius" – for gladiators. Tertullian used it somewhat differently – all victims of the arena were sacrificial in his eyes – and expressed the paradox of the "arenarii" as a class, from a Christian viewpoint:
On the one and the same account they glorify them and they degrade and diminish them; yes, further, they openly condemn them to disgrace and civil degradation; they keep them religiously excluded from council chamber, rostrum, senate, knighthood, and every other kind of office and a good many distinctions. The perversity of it! They love whom they lower; they despise whom they approve; the art they glorify, the artist they disgrace.
In this new Play, I attempted to follow the old custom of mine, of making a fresh trial; I brought it on again. In the first Act I pleased; when in the meantime a rumor spread that gladiators were about to be exhibited; the populace flock together, make a tumult, clamor aloud, and fight for their places: meantime, I was unable to maintain my place.

Images of gladiators could be found throughout the Republic and Empire, among all classes. Walls in the 2nd century BC "Italian Agora" at Delos were decorated with paintings of gladiators. Mosaics dating from the 2nd through 4th centuries AD have been invaluable in the reconstruction of combat and its rules, gladiator types and the development of the "munus". Throughout the Roman world, ceramics, lamps, gems and jewellery, mosaics, reliefs, wall paintings and statuary offer evidence, sometimes the best evidence, of the clothing, props, equipment, names, events, prevalence and rules of gladiatorial combat. Earlier periods provide only occasional, perhaps exceptional examples. The Gladiator Mosaic in the Galleria Borghese displays several gladiator types, and the Bignor Roman Villa mosaic from Provincial Britain shows Cupids as gladiators. Souvenir ceramics were produced depicting named gladiators in combat; similar images of higher quality, were available on more expensive articles in high quality ceramic, glass or silver.

Pliny the Elder gives vivid examples of the popularity of gladiator portraiture in Antium and an artistic treat laid on by an adoptive aristocrat for the solidly plebeian citizens of the Roman Aventine:
When a freedman of Nero was giving a gladiatorial show at Antium, the public porticoes were covered with paintings, so we are told, containing life-like portraits of all the gladiators and assistants. This portraiture of gladiators has been the highest interest in art for many centuries now, but it was Gaius Terentius who began the practice of having pictures made of gladiatorial shows and exhibited in public; in honour of his grandfather who had adopted him he provided thirty pairs of Gladiators in the Forum for three consecutive days, and exhibited a picture of the matches in the Grove of Diana.

Some Roman reenactors attempt to recreate Roman gladiator troupes. Some of these groups are part of larger Roman reenactment groups, and others are wholly independent, though they might participate in larger demonstrations of Roman reenacting or historical reenacting in general. These groups usually focus on portraying mock gladiatorial combat in as accurate a manner as possible.

Books of fiction in which Roman gladiators play the main or an important supporting role.

Gladiator fights have been depicted in a number of peplum films (also known as "sword-and-sandal" movies). This is a genre of largely Italian-made historical epics (costume dramas) that dominated the Italian film industry from 1958 to 1965. They can be immediately differentiated from the competing Hollywood product by their use of dubbing. The pepla attempted to emulate the big-budget Hollywood historical epics of the time, such as "Spartacus". Inspired by the success of "Spartacus", there were a number of Italian peplums that emphasized the gladiatorial arena fights in their plots, with it becoming almost a peplum subgenre in itself; One group of supermen known as "The Ten Gladiators" appeared in a trilogy, all three films starring Dan Vadis in the lead role.

"The Arena" (also known as the "Naked Warriors") is a 1974 gladiator exploitation film, starring Margaret Markov and Pam Grier, and directed by Steve Carver and an uncredited Joe D'Amato. Grier and Markov portray female gladiators in ancient Rome, who have been enslaved and must fight for their freedom. "Gladiator" is a 2000 British-American epic historical drama film directed by Ridley Scott, and starring Russell Crowe and Joaquin Phoenix. Crowe portrays a fictional Roman general who is reduced to slavery and then rises through the ranks of the gladiatorial arena to avenge the murder of his family. "Amazons and Gladiators" is a 2001 drama action adventure film directed and written by Zachary Weintraub starring Patrick Bergin and Jennifer Rubin.





</doc>
<doc id="12338" url="https://en.wikipedia.org/wiki?curid=12338" title="GMO (disambiguation)">
GMO (disambiguation)

A GMO is a genetically modified organism.

GMO may also refer to:


</doc>
<doc id="12339" url="https://en.wikipedia.org/wiki?curid=12339" title="Genetically modified organism">
Genetically modified organism

A genetically modified organism (GMO) is any organism whose genetic material has been altered using genetic engineering techniques. The exact definition of a genetically modified organism and what constitutes genetic engineering varies, with the most common being an organism altered in a way that "does not occur naturally by mating and/or natural recombination". A wide variety of organisms have been genetically modified (GM), from animals to plants and microorganisms. Genes have been transferred within the same species, across species (creating transgenic organisms) and even across kingdoms. New genes can be introduced, or endogenous genes can be enhanced, altered or knocked out.

Creating a genetically modified organism is a multi-step process. Genetic engineers must isolate the gene they wish to insert into the host organism and combine it with other genetic elements, including a promoter and terminator region and often a selectable marker. A number of techniques are available for inserting the isolated gene into the host genome. Recent advancements using genome editing techniques, notably CRISPR, have made the production of GMO's much simpler. Herbert Boyer and Stanley Cohen made the first genetically modified organism in 1973, a bacteria resistant to the antibiotic kanamycin. The first genetically modified animal, a mouse, was created in 1974 by Rudolf Jaenisch, and the first plant was produced in 1983. In 1994 the Flavr Savr tomato was released, the first commercialized genetically modified food. The first genetically modified animal to be commercialized was the GloFish (2003) and the first genetically modified animal to be approved for food use was the AquAdvantage salmon in 2015.

Bacteria are the easiest organisms to engineer and have been used for research, food production, industrial protein purification (including drugs), agriculture, and art. There is potential to use them for environmental, purposes or as medicine. Fungi have been engineered with much the same goals. Viruses play an important role as vectors for inserting genetic information into other organisms. This use is especially relevant to human gene therapy. There are proposals to remove the virulent genes from viruses to create vaccines. Plants have been engineered for scientific research, to create new colors in plants, deliver vaccines and to create enhanced crops. Genetically modified crops are publicly the most controversial GMOs. The majority are engineered for herbicide tolerance or insect resistance. Golden rice has been engineered with three genes that increase its nutritional value. Other prospects for GM crops are as bioreactors for the production of biopharmaceuticals, biofuels or medicines.

Animals are generally much harder to transform and the vast majority are still at the research stage. Mammals are the best model organisms for humans, making ones genetically engineered to resemble serious human diseases important to the discovery and development of treatments. Human proteins expressed in mammals are more likely to be similar to their natural counterparts than those expressed in plants or microorganisms. Livestock are modified with the intention of improving economically important traits such as growth-rate, quality of meat, milk composition, disease resistance and survival. Genetically modified fish are used for scientific research, as pets and as a food source. Genetic engineering has been proposed as a way to control mosquitos, a vector for many deadly diseases. Although human gene therapy is still relatively new, it has been used to treat genetic disorders such as severe combined immunodeficiency, and Leber's congenital amaurosis.

Many objections have been raised over the development of GMO's, particularly their commercialization. Many of these involve GM crops and whether food produced from them is safe and what impact growing them will have on the environment. Other concerns are the objectivity and rigor of regulatory authorities, contamination of non-genetically modified food, control of the food supply, patenting of life and the use of intellectual property rights. Although there is a scientific consensus that currently available food derived from GM crops poses no greater risk to human health than conventional food, GM food safety is a leading issue with critics. Gene flow, impact on non-target organisms and escape are the major environmental concerns. Countries have adopted regulatory measures to deal with these concerns. There are differences in the regulation for the release of GMOs between countries, with some of the most marked differences occurring between the US and Europe. Key issues concerning regulators include whether GM food should be labeled and the status of gene edited organisms.

What constitutes a genetically modified organism (GMO) is not always clear and can vary widely. At its broadest it can include anything that has had its genes altered, including by nature. Taking a less broad view it can encompass every organism that has had its genes altered by humans, which would include all crops and livestock. In 1993 the "Encyclopedia Britannica" defined genetic engineering as "any of a wide range of techniques ... among them artificial insemination, "in vitro" fertilization ("e.g.", "test-tube" babies), sperm banks, cloning, and gene manipulation." The European Union (EU) included a similarly broad definition in early reviews, specifically mentioning GMOs being produced by "selective breeding and other means of artificial selection." They later excluded traditional breeding, in vitro fertilization, induction of polyploidy, mutagenesis and cell fusion techniques that do not use recombinant nucleic acids or a genetically modified organism in the process.

A narrower definition provided by the Food and Agriculture Organization, the World Health Organization and the European Commission says that the organisms must be altered in a way that does "not occur naturally by mating and/or natural recombination". There are examples of crops that fit this definition, but are not normally considered GMOs. For example, the grain crop triticale was fully developed in a laboratory in 1930 using various techniques to alter its genome. The Cartagena Protocol on Biosafety in 2000 used the synonym "living modified organism" ("LMO") and defined it as "any living organism that possesses a novel combination of genetic material obtained through the use of modern biotechnology." Modern biotechnology is further defined as "In vitro nucleic acid techniques, including recombinant deoxyribonucleic acid (DNA) and direct injection of nucleic acid into cells or organelles, or fusion of cells beyond the taxonomic family."

Genetically engineered organism (GEO) can be considered a more precise term compared to GMO when describing organisms' genomes that have been directly manipulated with biotechnology. The term GMO originally was not typically used by scientists to describe genetically engineered organisms until after usage of GMO became common in popular media. The United States Department of Agriculture (USDA) considers GMOs to be plants or animals with heritable changes introduced by genetic engineering or traditional methods, while GEO specifically refers to organisms with genes introduced, eliminated, or rearranged using molecular biology, particularly recombinant DNA techniques, such as transgenesis.

The definitions focus on the process more than the product, which means there could be GMOS and non-GMOs with very similar genotypes and phenotypes. This has led scientists to label it as a scientifically meaningless category, saying that it is impossible to group all the different types of GMOs under one common definition. It has also caused issues for organic institutions and groups looking to ban GMOs. It also poses problems as new processes are developed. The current definitions came in before genome editing became popular and there is some confusion as to whether they are GMOs. The EU has adjudged that they are changing their GMO definition to include "organisms obtained by mutagenesis". In contrast the USDA has ruled that gene edited organisms are not considered GMOs.

Creating a genetically modified organism (GMO) is a multi-step process. Genetic engineers must isolate the gene they wish to insert into the host organism. This gene can be taken from a cell or artificially synthesized. If the chosen gene or the donor organism's genome has been well studied it may already be accessible from a genetic library. The gene is then combined with other genetic elements, including a promoter and terminator region and a selectable marker.

A number of techniques are available for inserting the isolated gene into the host genome. Bacteria can be induced to take up foreign DNA, usually by exposed heat shock or electroporation. DNA is generally inserted into animal cells using microinjection, where it can be injected through the cell's nuclear envelope directly into the nucleus, or through the use of viral vectors. In plants the DNA is often inserted using "Agrobacterium"-mediated recombination, biolistics or electroporation.

As only a single cell is transformed with genetic material, the organism must be regenerated from that single cell. In plants this is accomplished through tissue culture. In animals it is necessary to ensure that the inserted DNA is present in the embryonic stem cells. Further testing using PCR, Southern hybridization, and DNA sequencing is conducted to confirm that an organism contains the new gene.

Traditionally the new genetic material was inserted randomly within the host genome. Gene targeting techniques, which creates double-stranded breaks and takes advantage on the cells natural homologous recombination repair systems, have been developed to target insertion to exact locations. Genome editing uses artificially engineered nucleases that create breaks at specific points. There are four families of engineered nucleases: meganucleases, zinc finger nucleases, transcription activator-like effector nucleases (TALENs), and the Cas9-guideRNA system (adapted from CRISPR). TALEN and CRISPR are the two most commonly used and each has its own advantages. TALENs have greater target specificity, while CRISPR is easier to design and more efficient.

Humans have domesticated plants and animals since around 12,000 BCE, using selective breeding or artificial selection (as contrasted with natural selection). The process of selective breeding, in which organisms with desired traits (and thus with the desired genes) are used to breed the next generation and organisms lacking the trait are not bred, is a precursor to the modern concept of genetic modification. Various advancements in genetics allowed humans to directly alter the DNA and therefore genes of organisms. In 1972 Paul Berg created the first recombinant DNA molecule when he combined DNA from a monkey virus with that of the lambda virus.

Herbert Boyer and Stanley Cohen made the first genetically modified organism in 1973. They took a gene from a bacterium that provided resistance to the antibiotic kanamycin, inserted it into a plasmid and then induced other bacteria to incorporate the plasmid. The bacteria that had successfully incorporated the plasmid was then able to survive in the presence of kanamycin. Boyer and Cohen expressed other genes in bacteria. This included genes from the toad "Xenopus laevis" in 1974, creating the first GMO expressing a gene from an organism of a different kingdom.
In 1974 Rudolf Jaenisch created a transgenic mouse by introducing foreign DNA into its embryo, making it the world's first transgenic animal. However it took another eight years before transgenic mice were developed that passed the transgene to their offspring. Genetically modified mice were created in 1984 that carried cloned oncogenes, predisposing them to developing cancer. Mice with genes removed (termed a knockout mouse) were created in 1989. The first transgenic livestock were produced in 1985 and the first animal to synthesize transgenic proteins in their milk were mice in 1987. The mice were engineered to produce human tissue plasminogen activator, a protein involved in breaking down blood clots.

In 1983 the first genetically engineered plant was developed by Michael W. Bevan, Richard B. Flavell and Mary-Dell Chilton. They infected tobacco with "Agrobacterium" transformed with an antibiotic resistance gene and through tissue culture techniques were able to grow a new plant containing the resistance gene. The gene gun was invented in 1987, allowing transformation of plants not susceptible to "Agrobacterium" infection. In 2000, Vitamin A-enriched golden rice was the first plant developed with increased nutrient value.

In 1976 Genentech, the first genetic engineering company was founded by Herbert Boyer and Robert Swanson; a year later, the company produced a human protein (somatostatin) in "E.coli". Genentech announced the production of genetically engineered human insulin in 1978. The insulin produced by bacteria, branded humulin, was approved for release by the Food and Drug Administration in 1982. In 1988 the first human antibodies were produced in plants. In 1987, a strain of "Pseudomonas syringae" became the first genetically modified organism to be released into the environment when a strawberry and potato field in California were sprayed with it.

The first genetically modified crop, an antibiotic-resistant tobacco plant, was produced in 1982. China was the first country to commercialize transgenic plants, introducing a virus-resistant tobacco in 1992. In 1994 Calgene attained approval to commercially release the Flavr Savr tomato, the first genetically modified food. Also in 1994, the European Union approved tobacco engineered to be resistant to the herbicide bromoxynil, making it the first genetically engineered crop commercialized in Europe. An insect resistant Potato was approved for release in the US in 1995, and by 1996 approval had been granted to commercially grow 8 transgenic crops and one flower crop (carnation) in 6 countries plus the EU.

In 2010, scientists at the J. Craig Venter Institute announced that they had created the first synthetic bacterial genome. They named it Synthia and it was the world's first synthetic life form.

The first genetically modified animal to be commercialized was the GloFish, a Zebra fish with a fluorescent gene added that allows it to glow in the dark under ultraviolet light. It was released to the US market in 2003. In 2015 AquAdvantage salmon became the first genetically modified animal to be approved for food use. Approval is for fish raised in Panama and sold in the US. The salmon were transformed with a growth hormone-regulating gene from a Pacific Chinook salmon and a promoter from an ocean pout enabling it to grow year-round instead of only during spring and summer.

Bacteria were the first organisms to be genetically modified in the laboratory, due to the relative ease of modifying their chromosomes. This ease made them important tools for the creation of other GMOs. Genes and other genetic information from a wide range of organisms can be added to a plasmid and inserted into bacteria for storage and modification. Bacteria are cheap, easy to grow, clonal, multiply quickly and can be stored at −80 °C almost indefinitely. Once a gene is isolated it can be stored inside the bacteria, providing an unlimited supply for research. A large number of custom plasmids make manipulating DNA extracted from bacteria relatively easy.

Their ease of use has made them great tools for scientists looking to study gene function and evolution. The simplest model organisms come from bacteria, with most of our early understanding of molecular biology coming from studying "Escherichia coli". Scientists can easily manipulate and combine genes within the bacteria to create novel or disrupted proteins and observe the effect this has on various molecular systems. Researchers have combined the genes from bacteria and archaea, leading to insights on how these two diverged in the past. In the field of synthetic biology, they have been used to test various synthetic approaches, from synthesising genomes to creating novel nucleotides.

Bacteria have been used in the production of food for a long time, and specific strains have been developed and selected for that work on an industrial scale. They can be used to produce enzymes, amino acids, flavourings, and other compounds used in food production. With the advent of genetic engineering, new genetic changes can easily be introduced into these bacteria. Most food-producing bacteria are lactic acid bacteria, and this is where the majority of research into genetically engineering food-producing bacteria has gone. The bacteria can be modified to operate more efficiently, reduce toxic byproduct production, increase output, create improved compounds, and remove unnecessary pathways. Food products from genetically modified bacteria include alpha-amylase, which converts starch to simple sugars, chymosin, which clots milk protein for cheese making, and pectinesterase, which improves fruit juice clarity. The majority are produced in the US and even though regulations are in place to allow production in Europe, as of 2015 no food products derived from bacteria are currently available there.

Genetically modified bacteria are used to produce large amounts of proteins for industrial use. Generally the bacteria are grown to a large volume before the gene encoding the protein is activated. The bacteria are then harvested and the desired protein purified from them. The high cost of extraction and purification has meant that only high value products have been produced at an industrial scale. The majority of these products are human proteins for use in medicine. Many of these proteins are impossible or difficult to obtain via natural methods and they are less likely to be contaminated with pathogens, making them safer. The first medicinal use of GM bacteria was to produce the protein insulin to treat diabetes. Other medicines produced include clotting factors to treat haemophilia, human growth hormone to treat various forms of dwarfism, interferon to treat some cancers, erythropoietin for anemic patients, and tissue plasminogen activator which dissolves blood clots. Outside of medicine they have been used to produce biofuels. There is interest in developing an extracellular expression system within the bacteria to reduce costs and make the production of more products economical.

With greater understanding of the role that the microbiome plays in human health, there is the potential to treat diseases by genetically altering the bacteria to, themselves, be therapeutic agents. Ideas include altering gut bacteria so they destroy harmful bacteria, or using bacteria to replace or increase deficient enzymes or proteins. One research focus is to modify "Lactobacillus", bacteria that naturally provide some protection against HIV, with genes that will further enhance this protection. If the bacteria do not form colonies inside the patient, the person must repeatedly ingest the modified bacteria in order to get the required doses. Enabling the bacteria to form a colony could provide a more long-term solution, but could also raise safety concerns as interactions between bacteria and the human body are less well understood than with traditional drugs. There are concerns that horizontal gene transfer to other bacteria could have unknown effects. As of 2018 there are clinical trials underway testing the efficacy and safety of these treatments.

For over a century bacteria have been used in agriculture. Crops have been inoculated with Rhizobia (and more recently "Azospirillum") to increase their production or to allow them to be grown outside their original habitat. Application of "Bacillus thuringiensis" (Bt) and other bacteria can help protect crops from insect infestation and plant diseases. With advances in genetic engineering, these bacteria have been manipulated for increased efficiency and expanded host range. Markers have also been added to aid in tracing the spread of the bacteria. The bacteria that naturally colonize certain crops have also been modified, in some cases to express the Bt genes responsible for pest resistance. "Pseudomonas" strains of bacteria cause frost damage by nucleating water into ice crystals around themselves. This led to the development of ice-minus bacteria, that have the ice-forming genes removed. When applied to crops they can compete with the non-modified bacteria and confer some frost resistance.
Other uses for genetically modified bacteria include bioremediation, where the bacteria are used to convert pollutants into a less toxic form. Genetic engineering can increase the levels of the enzymes used to degrade a toxin or to make the bacteria more stable under environmental conditions. Bioart has also been created using genetically modified bacteria. In the 1980s artist Jon Davis and geneticist Dana Boyd converted the Germanic symbol for femininity (ᛉ) into binary code and then into a DNA sequence, which was then expressed in "Escherichia coli". This was taken a step further in 2012, when a whole book was encoded onto DNA. Paintings have also been produced using bacteria transformed with fluorescent proteins.

Viruses are often modified so they can be used as vectors for inserting genetic information into other organisms. This process is called transduction and if successful the recipient of the introduced DNA becomes a GMO. Different viruses have different efficiencies and capabilities. Researchers can use this to control for various factors; including the target location, insert size and duration of gene expression. Any dangerous sequences inherent in the virus must be removed, while those that allow the gene to be delivered effectively are retained.

While viral vectors can be used to insert DNA into almost any organism it is especially relevant for its potential in treating human disease. Although primarily still at trial stages, there has been some successes using gene therapy to replace defective genes. This is most evident in curing patients with severe combined immunodeficiency rising from adenosine deaminase deficiency (ADA-SCID), although the development of leukemia in some ADA-SCID patients along with the death of Jesse Gelsinger in a 1999 trial set back the development of this approach for many years. In 2009 another breakthrough was achieved when an eight-year-old boy with Leber's congenital amaurosis regained normal eyesight and in 2016 GlaxoSmithKline gained approval to commercialize a gene therapy treatment for ADA-SCID. As of 2018, there are a substantial number of clinical trials underway, including treatments for hemophilia, glioblastoma, chronic granulomatous disease, cystic fibrosis and various cancers.

The most common virus used for gene delivery come from adenoviruses as they can carry up to 7.5 kb of foreign DNA and infect a relatively broad range of host cells, although they have been know to elicit immune responses in the host and only provide short term expression. Other common vectors are adeno-associated viruses, which have lower toxicity and longer term expression, but can only carry about 4kb of DNA. Herpes simplex viruses make promising vectors, having a carrying capacity of over 30kb and providing long term expression, although they are less efficient at gene delivery than other vectors. The best vectors for long term integration of the gene into the host genome are retroviruses, but their propensity for random integration is problematic. Lentiviruses are a part of the same family as retroviruses with the advantage of infecting both dividing and non-dividing cells, whereas retroviruses only target dividing cells. Other viruses that have been used as vectors include alphaviruses, flaviviruses, measles viruses, rhabdoviruses, Newcastle disease virus, poxviruses, and picornaviruses.

Most vaccines consist of viruses that have been attenuated, disabled, weakened or killed in some way so that their virulent properties are no longer effective. Genetic engineering could theoretically be used to create viruses with the virulent genes removed. This does not affect the viruses infectivity, invokes a natural immune response and there is no chance that they will regain their virulence function, which can occur with some other vaccines. As such they are generally considered safer and more efficient than conventional vaccines, although concerns remain over non-target infection, potential side effects and horizontal gene transfer to other viruses. Another potential approach is to use vectors to create novel vaccines for diseases that have no vaccines available or the vaccines that do not work effectively, such as AIDS, malaria, and tuberculosis. The most effective vaccine against Tuberculosis, the Bacillus Calmette–Guérin (BCG) vaccine, only provides partial protection. A modified vaccine expressing "a M tuberculosis" antigen is able to enhance BCG protection. It has been shown to be safe to use at phase II trials, although not as effective as initially hoped. Other vector-based vaccines have already been approved and many more are being developed.

Another potential use of genetically modified viruses is to alter them so they can directly treat diseases. This can be through expression of protective proteins or by directly targeting infected cells. In 2004, researchers reported that a genetically modified virus that exploits the selfish behaviour of cancer cells might offer an alternative way of killing tumours. Since then, several researchers have developed genetically modified oncolytic viruses that show promise as treatments for various types of cancer. In 2017 researchers genetically modified a virus to express spinach defensin proteins. The virus was injected into orange trees to combat citrus greening disease that had reduced orange production by 70% since 2005.

Natural viral diseases, such as myxomatosis and rabbit haemorrhagic disease, have been used to help control pest populations. Over time the surviving pests become resistant, leading researchers to look at alternative methods. Genetically modified viruses that make the target animals infertile through immunocontraception have been created in the laboratory as well as others that target the developmental stage of the animal. There are concerns with using this approach regarding virus containment and cross species infection. Sometimes the same virus can be modified for contrasting purposes. Genetic modification of the myxoma virus has been proposed to conserve European wild rabbits in the Iberian peninsula and to help regulate them in Australia. To protect the Iberian species from viral diseases, the myxoma virus was genetically modified to immunize the rabbits, while in Australia the same myxoma virus was genetically modified to lower fertility in the Australian rabbit population.

Outside of biology scientists have used a genetically modified virus to construct a lithium-ion battery and other nanostructured materials. It is possible to engineer bacteriophages to express modified proteins on their surface and join them up in specific patterns (a technique called phage display). These structures have potential uses for energy storage and generation, biosensing and tissue regeneration with some new materials currently produced including quantum dots, liquid crystals, nanorings and nanofibres. The battery was made by engineering M13 bacteriaophages so they would coat themselves in iron phosphate and then assemble themselves along a carbon nanotube. This created a highly conductive medium for use in a cathode, allowing energy to be transferred quickly. They could be constructed at lower temperatures with non-toxic chemicals, making them more environmentally friendly.

Fungi can be used for many of the same processes as bacteria. For industrial applications, yeasts combines the bacterial advantages of being a single celled organism that is easy to manipulate and grow with the advanced protein modifications found in eukaryotes. They can be used to produce large complex molecules for use in food, pharmaceuticals, hormones and steroids. Yeast is important for wine production and as of 2016 two genetically modified yeasts involved in the fermentation of wine have been commercialized in the United States and Canada. One has increased malolactic fermentation efficiency, while the other prevents the production of dangerous ethyl carbamate compounds during fermentation. There have also been advances in the production of biofuel from genetically modified fungi.

Fungi, being the most common pathogens of insects, make attractive biopesticides. Unlike bacteria and viruses they have the advantage of infecting the insects by contact alone, although they are out competed in efficiency by chemical pesticides. Genetic engineering can improve virulence, usually by adding more virulent proteins, increasing infection rate or enhancing spore persistence. Many of the disease carrying vectors are susceptible to entomopathogenic fungi. An attractive target for biological control are mosquitos, vectors for a range of deadly diseases, including malaria, yellow fever and dengue fever. Mosquitos can evolve quickly so it becomes a balancing act of killing them before the "Plasmodium" they carry becomes the infectious disease, but not so fast that they become resistant to the fungi. By genetically engineering fungi like "Metarhizium anisopliae" and "Beauveria bassiana" to delay the development of mosquito infectiousness the selection pressure to evolve resistance is reduced. Another strategy is to add proteins to the fungi that block transmission of malaria or remove the "Plasmodium" altogether.

A mushroom has been gene edited to resist browning, giving it a longer shelf life. The process used CRISPR to knock out a gene that encodes polyphenol oxidase. As it didn't introduce any foreign DNA into the organism it was not deemed to be regulated under existing GMO frameworks and as such is the first CRISPR-edited organism to be approved for release. This has intensified debates as to whether gene-edited organisms should be considered genetically modified organisms and how they should be regulated.

Plants have been engineered for scientific research, to display new flower colors, deliver vaccines and to create enhanced crops. Many plants are pluripotent, meaning that a single cell from a mature plant can be harvested and under the right conditions can develop into a new plant. This ability can be taken advantage of by genetic engineers; by selecting for cells that have been successfully transformed in an adult plant a new plant can then be grown that contains the transgene in every cell through a process known as tissue culture.

Much of the advances in the field of genetic engineering has come from experimentation with tobacco. Major advances in tissue culture and plant cellular mechanisms for a wide range of plants has originated from systems developed in tobacco. It was the first plant to be altered using genetic engineering and is considered a model organism for not only genetic engineering, but a range of other fields. As such the transgenic tools and procedures are well established making tobacco one of the easiest plants to transform. Another major model organism relevant to genetic engineering is "Arabidopsis thaliana." Its small genome and short life cycle makes it easy to manipulate and it contains many homologues to important crop species. It was the first plant sequenced, has a host of online resources available and can be transformed by simply dipping a flower in a transformed "Agrobacterium" solution.

In research, plants are engineered to help discover the functions of certain genes. The simplest way to do this is to remove the gene and see what phenotype develops compared to the wild type form. Any differences are possibly the result of the missing gene. Unlike mutagenisis, genetic engineering allows targeted removal without disrupting other genes in the organism. Some genes are only expressed in certain tissue, so reporter genes, like GUS, can be attached to the gene of interest allowing visualization of the location. Other ways to test a gene is to alter it slightly and then return it to the plant and see if it still has the same effect on phenotype. Other strategies include attaching the gene to a strong promoter and see what happens when it is over expressed, forcing a gene to be expressed in a different location or at different developmental stages.

Some genetically modified plants are purely ornamental. They are modified for flower color, fragrance, flower shape and plant architecture. The first genetically modified ornamentals commercialized altered color. Carnations were released in 1997, with the most popular genetically modified organism, a blue rose (actually lavender or mauve) created in 2004. The roses are sold in Japan, the United States, and Canada. Other genetically modified ornamentals include "Chrysanthemum" and "Petunia". As well as increasing aesthetic value there are plans to develop ornamentals that use less water or are resistant to the cold, which would allow them to be grown outside their natural environments.

It has been proposed to genetically modify some plant species threatened by extinction to be resistant to invasive plants and diseases, such as the emerald ash borer in North American and the fungal disease, "Ceratocystis platani", in European plane trees. The papaya ringspot virus devastated papaya trees in Hawaii in the twentieth century until transgenic papaya plants were given pathogen-derived resistance. However, genetic modification for conservation in plants remains mainly speculative. A unique concern is that a transgenic species may no longer bear enough resemblance to the original species to truly claim that the original species is being conserved. Instead, the transgenic species may be genetically different enough to be considered a new species, thus diminishing the conservation worth of genetic modification.

Genetically modified crops are genetically modified plants that are used in agriculture. The first crops developed were used for animal or human food and provide resistance to certain pests, diseases, environmental conditions, spoilage or chemical treatments (e.g. resistance to a herbicide). The second generation of crops aimed to improve the quality, often by altering the nutrient profile. Third generation genetically modified crops could be used for non-food purposes, including the production of pharmaceutical agents, biofuels, and other industrially useful goods, as well as for bioremediation.

There are three main aims to agricultural advancement; increased production, improved conditions for agricultural workers and sustainability. GM crops contribute by improving harvests through reducing insect pressure, increasing nutrient value and tolerating different abiotic stresses. Despite this potential, as of 2018, the commercialized crops are limited mostly to cash crops like cotton, soybean, maize and canola and the vast majority of the introduced traits provide either herbicide tolerance or insect resistance. Soybeans accounted for half of all genetically modified crops planted in 2014. Adoption by farmers has been rapid, between 1996 and 2013, the total surface area of land cultivated with GM crops increased by a factor of 100. Geographically though the spread has been uneven, with strong growth in the Americas and parts of Asia and little in Europe and Africa. Its socioeconomic spread has been more even, with approximately 54% of worldwide GM crops grown in developing countries in 2013. Although doubts have been raised, most studies have found growing GM crops to be beneficial to farmers through decreased pesticide use as well as increased crop yield and farm profit.

The majority of GM crops have been modified to be resistant to selected herbicides, usually a glyphosate or glufosinate based one. Genetically modified crops engineered to resist herbicides are now more available than conventionally bred resistant varieties; in the USA 93% of soybeans and most of the GM maize grown is glyphosate tolerant. Most currently available genes used to engineer insect resistance come from the "Bacillus thuringiensis" bacterium and code for delta endotoxins. A few use the genes that encode for vegetative insecticidal proteins. The only gene commercially used to provide insect protection that does not originate from "B. thuringiensis" is the Cowpea trypsin inhibitor (CpTI). CpTI was first approved for use cotton in 1999 and is currently undergoing trials in rice. Less than one percent of GM crops contained other traits, which include providing virus resistance, delaying senescence and altering the plants composition.

Golden rice is the most well known GM crop that is aimed at increasing nutrient value. It has been engineered with three genes that biosynthesise beta-carotene, a precursor of vitamin A, in the edible parts of rice. It is intended to produce a fortified food to be grown and consumed in areas with a shortage of dietary vitamin A, a deficiency which each year is estimated to kill 670,000 children under the age of 5 and cause an additional 500,000 cases of irreversible childhood blindness. The original golden rice produced 1.6μg/g of the carotenoids, with further development increasing this 23 times. In 2018 it gained its first approvals for use as food.

Plants and plant cells have been genetically engineered for production of biopharmaceuticals in bioreactors, a process known as pharming. Work has been done with duckweed "Lemna minor", the algae "Chlamydomonas reinhardtii" and the moss "Physcomitrella patens". Biopharmaceuticals produced include cytokines, hormones, antibodies, enzymes and vaccines, most of which are accumulated in the plant seeds. Many drugs also contain natural plant ingredients and the pathways that lead to their production have been genetically altered or transferred to other plant species to produce greater volume. Other options for bioreactors are biopolymers and biofuels. Unlike bacteria, plants can modify the proteins post-translationally, allowing them to make more complex molecules. They also pose less risk of being contaminated. Therapeutics have been cultured in transgenic carrot and tobacco cells, including a drug treatment for Gaucher's disease.

Vaccine production and storage has great potential in transgenic plants. Vaccines are expensive to produce, transport and administer, so having a system that could produce them locally would allow greater access to poorer and developing areas. As well as purifying vaccines expressed in plants it is also possible to produce edible vaccines in plants. Edible vaccines stimulate the immune system when ingested to protect against certain diseases. Being stored in plants reduces the long-term cost as they can be disseminated without the need for cold storage, don't need to be purified and have long term stability. Also being housed within plant cells provides some protection from the gut acids upon digestion. However the cost of developing, regulating and containing transgenic plants is high, leading to most current plant-based vaccine development being applied to veterinary medicine, where the controls are not as strict.

The vast majority of genetically modified animals are at the research stage with the number close to entering the market remaining small. As of 2018 only three genetically modified animals have been approved, all in the USA. A goat and a chicken have been engineered to produce medicines and a salmon that has increased growth. Despite the differences and difficulties in modifying them, the end aims are much the same as for plants. GM animals are created for research purposes, production of industrial or therapeutic products, agricultural uses or improving their health. There is also a market for creating genetically modified pets.

The process of genetically engineering mammals is slow, tedious, and expensive. However, new technologies are making genetic modifications easier and more precise. The first transgenic mammals were produced by injecting viral DNA into embryos and then implanting the embryos in females. The embryo would develop and it would be hoped that some of the genetic material would be incorporated into the reproductive cells. Then researchers would have to wait until the animal reached breeding age and then offspring would be screened for presence of the gene in every cell. The development of the CRISPR-Cas9 gene editing system as a cheap and fast way of directly modifying germ cells, effectively halving the amount of time needed to develop genetically modified mammals.

Mammals are the best models for human disease, making genetic engineered ones vital to the discovery and development of cures and treatments for many serious diseases. Knocking out genes responsible for human genetic disorders allows researchers to study the mechanism of the disease and to test possible cures. Genetically modified mice have been the most common mammals used in biomedical research, as they are cheap and easy to manipulate. Pigs are also a good target as they have a similar body size and anatomical features, physiology, pathophysiological response and diet. Nonhuman primates are the most similar model organisms to humans, but there is less public acceptance towards using them as research animals. In 2009, scientists announced that they had successfully transferred a gene into a primate species (marmosets) for the first time. Their first research target for these marmosets was Parkinson's disease, but they were also considering amyotrophic lateral sclerosis and Huntington's disease.

Human proteins expressed in mammals are more likely to be similar to their natural counterparts than those expressed in plants or microorganisms. Stable expression has been accomplished in sheep, pigs, rats and other animals. In 2009 the first human biological drug produced from such an animal, a goat, was approved. The drug, ATryn, is an anticoagulant which reduces the probability of blood clots during surgery or childbirth and is extracted from the goat's milk. Human alpha-1-antitrypsin is another protein that has been produced from goats and is used in treating humans with this deficiency. Another medicinal area is in creating pigs with greater capacity for human organ transplants (xenotransplantation). Pigs have been genetically modified so that their organs can no longer carry retroviruses or have modifications to reduce the chance of rejection. Pig lungs from genetically modified pigs are being considered for transplantation into humans. There is even potential to create chimeric pigs that can carry human organs.

Livestock are modified with the intention of improving economically important traits such as growth-rate, quality of meat, milk composition, disease resistance and survival. Animals have been engineered to grow faster, be healthier and resist diseases. Modifications have also improved the wool production of sheep and udder health of cows. Goats have been genetically engineered to produce milk with strong spiderweb-like silk proteins in their milk. A GM pig called Enviropig was created with the capability of digesting plant phosphorus more efficiently than conventional pigs. They could reduce water pollution since they excrete 30 to 70% less phosphorus in manure. Dairy cows have been genetically engineered to produce milk that would be the same as human breast milk. This could potentially benefit mothers who cannot produce breast milk but want their children to have breast milk rather than formula. Researchers have also developed a genetically engineered cow that produces allergy-free milk.

Scientists have genetically engineered several organisms, including some mammals, to include green fluorescent protein (GFP), for research purposes. GFP and other similar reporting genes allow easy visualization and localization of the products of the genetic modification. Fluorescent pigs have been bred to study human organ transplants, regenerating ocular photoreceptor cells, and other topics. In 2011 green-fluorescent cats were created to help find therapies for HIV/AIDS and other diseases as feline immunodeficiency virus is related to HIV.

There have been suggestions that genetic engineering could be used to bring animals back from extinction. It involves changing the genome of a close living relative to resemble the extinct one and is currently being attempted with the passenger pigeon. Genes associated with the woolly mammoth have been added to the genome of an African Elephant, although the lead researcher says he has no intention of creating live elephants and transferring all the genes and reversing years of genetic evolution is a long way from being feasible. It is more likely that scientists could use this technology to conserve endangered animals by bringing back lost diversity or transferring evolved genetic advantages from adapted organisms to those that are struggling.

Gene therapy uses genetically modified viruses to deliver genes which can cure disease in humans. Although gene therapy is still relatively new, it has had some successes. It has been used to treat genetic disorders such as severe combined immunodeficiency, and Leber's congenital amaurosis. Treatments are also being developed for a range of other currently incurable diseases, such as cystic fibrosis, sickle cell anemia, Parkinson's disease, cancer, diabetes, heart disease and muscular dystrophy. These treatments only effect somatic cells, meaning any changes would not be inheritable. Germline gene therapy results in any change being inheritable, which has raised concerns within the scientific community.

In 2015, CRISPR was used to edit the DNA of non-viable human embryos. In November 2018, He Jiankui announced that he had edited the genomes of two human embryos, in an attempt to disable the "CCR5" gene, which codes for a receptor that HIV uses to enter cells. He said that twin girls, Lulu and Nana, had been born a few weeks earlier and that they carried functional copies of CCR5 along with disabled CCR5 (mosaicism) and were still vulnerable to HIV. The work was widely condemned as unethical, dangerous, and premature.

Genetically modified fish are used for scientific research, as pets and as a food source. Aquaculture is a growing industry, currently providing over half the consumed fish worldwide. Through genetic engineering it is possible to increase growth rates, reduce food intake, remove allergenic properties, increase cold tolerance and provide disease resistance. Fish can also be used to detect aquatic pollution or function as bioreactors.

Several groups have been developing zebrafish to detect pollution by attaching fluorescent proteins to genes activated by the presence of pollutants. The fish will then glow and can be used as environmental sensors. The GloFish is a brand of genetically modified fluorescent zebrafish with bright red, green, and orange fluorescent color. It was originally developed by one of the groups to detect pollution, but is now part of the ornamental fish trade, becoming the first genetically modified animal to become publicly available as a pet when in 2003 it was introduced for sale in the USA.

GM fish are widely used in basic research in genetics and development. Two species of fish, zebrafish and medaka, are most commonly modified because they have optically clear chorions (membranes in the egg), rapidly develop, and the one-cell embryo is easy to see and microinject with transgenic DNA. Zebrafish are model organisms for developmental processes, regeneration, genetics, behaviour, disease mechanisms and toxicity testing. Their transparency allows researchers to observe developmental stages, intestinal functions and tumour growth. The generation of transgenic protocols (whole organism, cell or tissue specific, tagged with reporter genes) has increased the level of information gained by studying these fish.

GM fish have been developed with promoters driving an over-production of growth hormone for use in the aquaculture industry to increase the speed of development and potentially reduce fishing pressure on wild stocks. This has resulted in dramatic growth enhancement in several species, including salmon, trout and tilapia. AquaBounty Technologies, a biotechnology company, have produced a salmon (called AquAdvantage salmon) that can mature in half the time as wild salmon. It obtained regulatory approval in 2015, the first non-plant GMO food to be commercialized. As of August 2017, GMO salmon is being sold in Canada. Sales in the US are expected to start in the second half of 2019.

In biological research, transgenic fruit flies ("Drosophila melanogaster") are model organisms used to study the effects of genetic changes on development. Fruit flies are often preferred over other animals due to their short life cycle and low maintenance requirements. They also have a relatively simple genome compared to many vertebrates, with typically only one copy of each gene, making phenotypic analysis easy. "Drosophila" have been used to study genetics and inheritance, embryonic development, learning, behavior, and aging. The discovery of transposons, in particular the p-element, in "Drosophila" provided an early method to add transgenes to their genome, although this has been taken over by more modern gene-editing techniques.

Due to their significance to human health, scientists are looking at ways to control mosquitoes through genetic engineering. Malaria-resistant mosquitoes have been developed in the laboratory by inserting a gene that reduces the development of the malaria parasite and then use homing endonucleases to rapidly spread that gene throughout the male population (known as a gene drive). This approach has been taken further by using the gene drive to spread a lethal gene. In trials the populations of "Aedes aegypti" mosquitoes, the single most important carrier of dengue fever and Zika virus, were reduced by between 80% and by 90%. Another approach is to use a sterile insect technique, whereby males genetically engineered to be sterile out compete viable males, to reduce population numbers.

Other insect pests that make attractive targets are moths. Diamondback moths cause US$4 to $5 billion of damage each year worldwide. The approach is similar to the sterile technique tested on mosquitoes, where males are transformed with a gene that prevents any females born from reaching maturity. They underwent field trials in 2017. Genetically modified moths have previously been released in field trials. In this case a strain of pink bollworm that were sterilized with radiation were genetically engineered to express a red fluorescent protein making it easier for researchers to monitor them.

Silkworm, the larvae stage of "Bombyx mori," is an economically important insect in sericulture. Scientists are developing strategies to enhance silk quality and quantity. There is also potential to use the silk producing machinery to make other valuable proteins. Proteins currently developed to be expressed by silkworms include; human serum albumin, human collagen α-chain, mouse monoclonal antibody and N-glycanase. Silkworms have been created that produce spider silk, a stronger but extremely difficult to harvest silk, and even novel silks.

Systems have been developed to create transgenic organisms in a wide variety of other animals. Chickens have been genetically modified for a variety of purposes. This includes studying embryo development, preventing the transmission of bird flu and providing evolutionary insights using reverse engineering to recreate dinosaur-like phenotypes. A GM chicken that produces the drug Kanuma, an enzyme that treats a rare condition, in its egg passed US regulatory approval in 2015. Genetically modified frogs, in particular "Xenopus laevis" and "Xenopus tropicalis", are used in developmental biology research. GM frogs can also be used as pollution sensors, especially for endocrine disrupting chemicals. There are proposals to use genetic engineering to control cane toads in Australia.

The nematode "Caenorhabditis elegans" is one of the major model organisms for researching molecular biology. RNA interference (RNAi) was discovered in "C. elegans" and could be induced by simply feeding them bacteria modified to express double stranded RNA. It is also relatively easy to produce stable transgenic nematodes and this along with RNAi are the major tools used in studying their genes. The most common use of transgenic nematodes has been studying gene expression and localization by attaching reporter genes. Transgenes can also be combined with RNAi techniques to rescue phenotypes, study gene function, image cell development in real time or control expression for different tissues or developmental stages. Transgenic nematodes have been used to study viruses, toxicology, diseases, and to detect environmental pollutants.

The gene responsible for albinism in sea cucumbers has been found and used to engineer white sea cucumbers, a rare delicacy. The technology also opens the way to investigate the genes responsible for some of the cucumbers more unusual traits, including hibernating in summer, eviscerating their intestines, and dissolving their bodies upon death. Flatworms have the ability to regenerate themselves from a single cell. Until 2017 there was no effective way to transform them, which hampered research. By using microinjection and radiation scientists have now created the first genetically modified flatworms. The bristle worm, a marine annelid, has been modified. It is of interest due to its reproductive cycle being synchronized with lunar phases, regeneration capacity and slow evolution rate. Cnidaria such as "Hydra" and the sea anemone "Nematostella vectensis" are attractive model organisms to study the evolution of immunity and certain developmental processes. Other animals that have been genetically modified include snails, geckos, turtles, crayfish, oysters, shrimp, clams, abalone and sponges.

Genetically modified organisms are regulated by government agencies. This applies to research as well as the release of genetically modified organisms, including crops and food. The development of a regulatory framework concerning genetic engineering began in 1975, at Asilomar, California. The Asilomar meeting recommended a set of guidelines regarding the cautious use of recombinant technology and any products resulting from that technology. The Cartagena Protocol on Biosafety was adopted on 29 January 2000 and entered into force on 11 September 2003. It is an international treaty that governs the transfer, handling, and use of genetically modified organisms. One hundred and fifty-seven countries are members of the Protocol and many use it as a reference point for their own regulations.

Universities and research institutes generally have a special committee that is responsible for approving any experiments that involve genetic engineering. Many experiments also need permission from a national regulatory group or legislation. All staff must be trained in the use of GMOs and all laboratories must gain approval from their regulatory agency to work with GMOs. The legislation covering GMOs are often derived from regulations and guidelines in place for the non-GMO version of the organism, although they are more severe. There is a near universal system for assessing the relative risks associated with GMOs and other agents to laboratory staff and the community. They are assigned to one of four risk categories based on their virulence, the severity of disease, the mode of transmission, and the availability of preventive measures or treatments. There are four biosafety levels that a laboratory can fall into, ranging from level 1 (which is suitable for working with agents not associated with disease) to level 4 (working with life-threatening agents). Different countries use different nomenclature to describe the levels and can have different requirements for what can be done at each level.

There are differences in the regulation for the release of GMOs between countries, with some of the most marked differences occurring between the US and Europe. Regulation varies in a given country depending on the intended use of the products of the genetic engineering. For example, a crop not intended for food use is generally not reviewed by authorities responsible for food safety. Some nations have banned the release of GMOs or restricted their use, and others permit them with widely differing degrees of regulation. In 2016 thirty eight countries officially ban or prohibit the cultivation of GMOs and nine (Algeria, Bhutan, Kenya, Kyrgyzstan, Madagascar, Peru, Russia, Venezuela and Zimbabwe) ban their importation. Most countries that do not allow GMO cultivation do permit research using GMOs.

The European Union (EU) differentiates between approval for cultivation within the EU and approval for import and processing. While only a few GMOs have been approved for cultivation in the EU a number of GMOs have been approved for import and processing. The cultivation of GMOs has triggered a debate about the market for GMOs in Europe. Depending on the coexistence regulations, incentives for cultivation of GM crops differ. The US policy does not focus on the process as much as other countries, looks at verifiable scientific risks and uses the concept of substantial equivalence. Whether gene edited organisms should be regulated the same as genetically modified organism is debated. USA regulations sees them as separate and does not regulate them under the same conditions, while in Europe a GMO is any organism created using genetic engineering techniques.

One of the key issues concerning regulators is whether GM products should be labeled. The European Commission says that mandatory labeling and traceability are needed to allow for informed choice, avoid potential false advertising and facilitate the withdrawal of products if adverse effects on health or the environment are discovered. The American Medical Association and the American Association for the Advancement of Science say that absent scientific evidence of harm even voluntary labeling is misleading and will falsely alarm consumers. Labeling of GMO products in the marketplace is required in 64 countries. Labeling can be mandatory up to a threshold GM content level (which varies between countries) or voluntary. In Canada and the US labeling of GM food is voluntary, while in Europe all food (including processed food) or feed which contains greater than 0.9% of approved GMOs must be labelled. In 2014, sales of products that had been labeled as non-GMO grew 30 percent to $1.1 billion.

There is controversy over GMOs, especially with regard to their release outside laboratory environments. The dispute involves consumers, producers, biotechnology companies, governmental regulators, nongovernmental organizations, and scientists. Many of these concerns involve GM crops and whether food produced from them is safe and what impact growing them will have on the environment. These controversies have led to litigation, international trade disputes, and protests, and to restrictive regulation of commercial products in some countries. Most concerns are around the health and environmental effects of GMOs. These include whether they may provoke an allergic reaction, whether the transgenes could transfer to human cells and whether genes not approved for human consumption could outcross into the food supply.

There is a scientific consensus that currently available food derived from GM crops poses no greater risk to human health than conventional food, but that each GM food needs to be tested on a case-by-case basis before introduction. Nonetheless, members of the public are much less likely than scientists to perceive GM foods as safe. The legal and regulatory status of GM foods varies by country, with some nations banning or restricting them, and others permitting them with widely differing degrees of regulation.
Gene flow between GM crops and compatible plants, along with increased use of broad-spectrum herbicides, can increase the risk of herbicide resistant weed populations. Debate over the extent and consequences of gene flow intensified in 2001 when a paper was published showing transgenes had been found in landrace maize in Mexico, the crops center of diversity. Gene flow from GM crops to other organisms has been found to generally be lower than what would occur naturally. In order to address some of these concerns some GMOs have been developed with traits to help control their spread. To prevent the genetically modified salmon inadvertently breeding with wild salmon, all the fish raised for food are females, triploid, 99% are reproductively sterile, and raised in areas where escaped salmon could not survive. Bacteria have also been modified to depend on nutrients that cannot be found in nature, and genetic use restriction technology has been developed, though not yet marketed, that causes the second generation of GM plants to be sterile.

Other environmental and agronomic concerns include a decrease in biodiversity, an increase in secondary pests (non-targeted pests) and evolution of resistant insect pests. In the areas of China and the US with Bt crops the overall biodiversity of insects has increased and the impact of secondary pests has been minimal. Resistance was found to be slow to evolve when best practice strategies were followed. The impact of Bt crops on beneficial non-target organisms became a public issue after a 1999 paper suggested they could be toxic to monarch butterflies. Follow up studies have since shown that the toxicity levels encountered in the field were not high enough to harm the larvae.

Accusations that scientists are "playing God" and other religious issues have been ascribed to the technology from the beginning. With the ability to genetically engineer humans now possible there are ethical concerns over how far this technology should go, or if it should be used at all. Much debate revolves around where the line between treatment and enhancement is and whether the modifications should be inheritable. Other concerns include contamination of the non-genetically modified food supply, the rigor of the regulatory process, consolidation of control of the food supply in companies that make and sell GMOs, exaggeration of the benefits of genetic modification, or concerns over the use of herbicides with glyphosate. Other issues raised include the patenting of life and the use of intellectual property rights.

There are large differences in consumer acceptance of GMOs, with Europeans more likely to view GM food negatively than North Americans. GMOs arrived on the scene as the public confidence in food safety, attributed to recent food scares such as Bovine spongiform encephalopathy and other scandals involving government regulation of products in Europe, was low. This along with campaigns run by various non-governmental organizations (NGO) have been very successful in blocking or limiting the use of GM crops. NGOs like the Organic Consumers Association, the Union of Concerned Scientists, Greenpeace and other groups have said that risks have not been adequately identified and managed and that there are unanswered questions regarding the potential long-term impact on human health from food derived from GMOs. They propose mandatory labeling or a moratorium on such products.



</doc>
<doc id="12341" url="https://en.wikipedia.org/wiki?curid=12341" title="Ghent">
Ghent

Ghent (; , ; , ; traditional English: Gaunt) is a city and a municipality in the Flemish Region of Belgium. It is the capital and largest city of the East Flanders province, and the third largest in the country, exceeded in size only by Brussels and Antwerp. It is a port and university city.
The city originally started as a settlement at the confluence of the Rivers Scheldt and Leie and in the Late Middle Ages became one of the largest and richest cities of northern Europe, with some 50,000 people in 1300.

The municipality comprises the city of Ghent proper and the surrounding suburbs of Afsnee, Desteldonk, Drongen, Gentbrugge, Ledeberg, Mariakerke, Mendonk, Oostakker, Sint-Amandsberg, Sint-Denijs-Westrem, Sint-Kruis-Winkel, Wondelgem and Zwijnaarde. With 262,219 inhabitants at the beginning of 2019, Ghent is Belgium's second largest municipality by number of inhabitants. The metropolitan area, including the outer commuter zone, covers an area of and has a total population of 560,522 as of 1 January 2018, which ranks it as the fourth most populous in Belgium. The current mayor of Ghent, Mathias De Clercq is from the liberal & democratic party Open VLD.

The ten-day-long Ghent Festival ("Gentse Feesten" in Dutch) is held every year and attended by about 1–1.5 million visitors.

Archaeological evidence shows human presence in the region of the confluence of Scheldt and Leie going back as far as the Stone Age and the Iron Age.

Most historians believe that the older name for Ghent, 'Ganda', is derived from the Celtic word "ganda" which means confluence. Other sources connect its name with an obscure deity named Gontia.

There are no written records of the Roman period, but archaeological research confirms that the region of Ghent was further inhabited.

When the Franks invaded the Roman territories from the end of the 4th century and well into the 5th century, they brought their language with them and Celtic and Latin were replaced by Old Dutch.

Around 650, Saint Amand founded two abbeys in Ghent: St. Peter's (Blandinium) and Saint Bavo's Abbey. Around 800, Louis the Pious, son of Charlemagne, appointed Einhard, the biographer of Charlemagne, as abbot of both abbeys. The city grew from several nuclei, the abbeys and a commercial centre. However, both in 851 and 879, the city was plundered by the Vikings.
Within the protection of the County of Flanders, the city recovered and flourished from the 11th century, growing to become a small city-state. By the 13th century, Ghent was the biggest city in Europe north of the Alps after Paris; it was bigger than Cologne or Moscow. Within the city walls lived up to 65,000 people. The belfry and the towers of the Saint Bavo Cathedral and Saint Nicholas' Church are just a few examples of the skyline of the period.

The rivers flowed in an area where much land was periodically flooded. These rich grass 'meersen' ("water-meadows": a word related to the English 'marsh') were ideally suited for herding sheep, the wool of which was used for making cloth. During the Middle Ages Ghent was the leading city for cloth.

The wool industry, originally established at Bruges, created the first European industrialized zone in Ghent in the High Middle Ages. The mercantile zone was so highly developed that wool had to be imported from Scotland and England. This was one of the reasons for Flanders' good relationship with Scotland and England. Ghent was the birthplace of John of Gaunt, Duke of Lancaster. Trade with England (but not Scotland) suffered significantly during the Hundred Years' War.

The city recovered in the 15th century, when Flanders was united with neighbouring provinces under the Dukes of Burgundy. High taxes led to a rebellion and eventually the Battle of Gavere in 1453, in which Ghent suffered a terrible defeat at the hands of Philip the Good. Around this time the centre of political and social importance in the Low Countries started to shift from Flanders (Bruges–Ghent) to Brabant (Antwerp–Brussels), although Ghent continued to play an important role. With Bruges, the city led two revolts against Maximilian of Austria, the first monarch of the House of Habsburg to rule Flanders.

In 1500, Juana of Castile gave birth to Charles V, who became Holy Roman Emperor and King of Spain. Although native to Ghent, he punished the city after the 1539 Revolt of Ghent and obliged the city's nobles to walk in front of the Emperor barefoot with a noose (Dutch: ""strop"") around the neck; since this incident, the people of Ghent have been called ""Stroppendragers"" (noose bearers). Saint Bavo Abbey (not to be confused with the nearby Saint Bavo Cathedral) was abolished, torn down, and replaced with a fortress for Royal Spanish troops. Only a small portion of the abbey was spared demolition.

The late 16th and the 17th centuries brought devastation because of the Eighty Years' War. The war ended the role of Ghent as a centre of international importance. In 1745, the city was captured by French forces during the War of the Austrian Succession before being returned to the Empire of Austria under the House of Habsburg following the Treaty of Aix-la-Chapelle in 1748, when this part of Flanders became known as the Austrian Netherlands until 1815, the exile of the French Emperor Napoleon I, the end of the French Revolutionary and later Napoleonic Wars and the peace treaties arrived at by the Congress of Vienna.

In the 18th and 19th centuries, the textile industry flourished again in Ghent. Lieven Bauwens, having smuggled the industrial and factory machine plans out of England, introduced the first mechanical weaving machine on the European continent in 1800.

The Treaty of Ghent, negotiated here and adopted on Christmas Eve 1814, formally ended the War of 1812 between Great Britain and the United States (the North American phase of the Napoleonic Wars). After the Battle of Waterloo, Ghent and Flanders, previously ruled from the House of Habsburg in Vienna as the Austrian Netherlands, became a part of the United Kingdom of the Netherlands with the northern Dutch for 15 years. In this period, Ghent established its own university (1816) and a new connection to the sea (1824–27).

After the Belgian Revolution, with the loss of port access to the sea for more than a decade, the local economy collapsed and the first Belgian trade union originated in Ghent. In 1913 there was a world exhibition in Ghent. As a preparation for these festivities, the Sint-Pieters railway station was completed in 1912.

Ghent was occupied by the Germans in both World Wars but escaped severe destruction. The life of the people and the German invaders in Ghent during World War I is described by H. Wandt in "etappenleven te Gent". In World War II the city was liberated by the British 7th "Desert Rats" Armoured Division and local Belgian fighters on 6 September 1944.

After the fusions of municipalities in 1965 and 1977, the city is made up of:

The climate in this area has mild differences between highs and lows, and there is adequate rainfall year-round. According to the Köppen climate classification system, Ghent has a marine west coast climate, abbreviated "Cfb" on climate maps.

Ghent is home to a large number of people of foreign origin and immigrants. From the 2019 census, it was concluded that 34.3% of the inhabitants have roots outside of Belgium and 14.5% have a non-Belgian nationality.

Much of the city's medieval architecture remains intact and is remarkably well preserved and restored. Its centre is a carfree area. Highlights are the Saint Bavo Cathedral with the "Ghent Altarpiece", the belfry, the Gravensteen castle, and the splendid architecture along the old Graslei harbour. Ghent has established a blend between comfort of living and history; it is not a city-museum. The city of Ghent also houses three béguinages and numerous churches including Saint-Jacob's church, Saint-Nicolas' church, Saint Michael's church and St. Stefanus.
In the 19th century Ghent's most famous architect, Louis Roelandt, built the university hall Aula, the opera house and the main courthouse. Highlights of modern architecture are the university buildings (the "Boekentoren" or Book Tower) by Henry Van de Velde. There are also a few theatres from diverse periods.

The beguinages, as well as the belfry and adjacent cloth hall, were recognized by UNESCO as World Heritage Sites in 1998 and 1999.

The Zebrastraat, a social experiment in which an entirely renovated site unites living, economy and culture, can also be found in Ghent.

Campo Santo is a famous Catholic burial site of the nobility and artists.

Important museums in Ghent are the Museum voor Schone Kunsten (Museum of Fine Arts), with paintings by Hieronymus Bosch, Peter Paul Rubens, and many Flemish masters; the SMAK or Stedelijk Museum voor Actuele Kunst (City Museum for Contemporary Art), with works of the 20th century, including Joseph Beuys and Andy Warhol; and the Design Museum Gent with masterpieces of Victor Horta and Le Corbusier. The Huis van Alijn (House of the Alijn family) was originally a beguinage and is now a museum for folk art where theatre and puppet shows for children are presented. The "Museum voor Industriële Archeologie en Textiel" or MIAT displays the industrial strength of Ghent with recreations of workshops and stores from the 1800s and original spinning and weaving machines that remain from the time when the building was a weaving mill. The Ghent City Museum (Stadsmuseum, abbreviated STAM), is committed to recording and explaining the city's past and its inhabitants, and to preserving the present for future generations.

In Ghent and other regions of East-Flanders, bakeries sell a donut-shaped bun called a "mastel" (plural "mastellen"), which is basically a bagel. "Mastellen" are also called "Saint Hubert bread", because on the Saint's feast day, which is 3 November, the bakers bring their batches to the early Mass to be blessed. Traditionally, it was thought that blessed mastellen immunized against rabies.

Other local delicacies are the praline chocolates from local producers such as Leonidas, the cuberdons or 'neuzekes' ('noses'), cone-shaped purple jelly-filled candies, 'babelutten' ('babblers'), hard butterscotch-like candy, and of course, on the more fiery side, the famous 'Tierenteyn', a hot but refined mustard that has some affinity to French 'Dijon' mustard.

Stoverij is a classic Flemish meat stew, preferably made with a generous addition of brown 'Trappist' (strong abbey beer) and served with French fries. 'Waterzooi' is a local stew originally made from freshwater fish caught in the rivers and creeks of Ghent, but nowadays often made with chicken instead of fish. It is usually served nouvelle-cuisine-style, and will be supplemented by a large pot on the side.

The city promotes a meat-free day on Thursdays called "Donderdag Veggiedag" with vegetarian food being promoted in public canteens for civil servants and elected councillors, in all city funded schools, and promotion of vegetarian eating options in town (through the distribution of "veggie street maps"). This campaign is linked to the recognition of the detrimental environmental effects of meat production, which the United Nations' Food and Agriculture Organization has established to represent nearly one-fifth of global greenhouse gas emissions.

The traditional confectionery is the cuberdon (also known as neuzekes or little noses). These are conical sweets with a soft centre, usually raspberry but other flavours can be found on the many street stalls around the city. Between 2011 and 2015 a feud between two local vendors made international news.

The city is host to some big cultural events such as the Gentse Feesten, I Love Techno in Flanders Expo, the "10 Days Off" musical festival, the International Film Festival of Ghent (with the World Soundtrack Awards) and the . Also, every five years, an extensive botanical exhibition ("Gentse Floraliën") takes place in Flanders Expo in Ghent, attracting numerous visitors to the city.

The Festival of Flanders had its 50th celebration in 2008. In Ghent it opens with the OdeGand City festivities that takes place on the second Saturday of September. Some 50 concerts take place in diverse locations throughout the medieval inner city and some 250 international artists perform. Other major Flemish cities hold similar events, all of which form part of the Festival of Flanders (Antwerp with "Laus Polyphoniae"; Bruges with "MAfestival"; Brussels with "KlaraFestival"; Limburg with "Basilica", Mechelen and Brabant with "Novecento" and "Transit").

The city of Ghent will co-host the 2020 World Choir Games together with the city of Antwerp. Organised by the Interkultur Foundation, the World Choir Games is the biggest choral competition and festival in the world.

The numerous parks in the city can also be considered tourist attractions. Most notably, Ghent boasts a nature reserve (Bourgoyen-Ossemeersen, 230 hectare) and a recreation park (Blaarmeersen, 87 hectares).

The port of Ghent, in the north of the city, is the third largest port of Belgium. It is accessed by the Ghent–Terneuzen Canal, which ends near the Dutch port of Terneuzen on the Western Scheldt. The port houses, among others, large companies like ArcelorMittal, Volvo Cars, Volvo Trucks, Volvo Parts, Honda, and Stora Enso.

The Ghent University and a number of research oriented companies, such as Ablynx, Innogenetics, Cropdesign and Bayer Cropscience, are situated in the central and southern part of the city.

As the largest city in East Flanders, Ghent has many hospitals, schools and shopping streets. Flanders Expo, the biggest event hall in Flanders and the second biggest in Belgium, is also located in Ghent. Tourism is becoming a major employer in the local area. 

As one of the largest cities in Belgium, Ghent has a highly developed transport system.

By car the city is accessible via two motorways:

In addition Ghent also has two ringways:

The municipality of Ghent comprises five railway stations:

Ghent has an extensive network of public transport lines, operated by "De Lijn".



Apart from the city buses mentioned above, Ghent also has numerous regional bus lines connecting it to towns and villages across the province of East Flanders. All of these buses stop in at least one of the city's regional bus hubs at either Sint-Pieters Station, Dampoort Station, Zuid or Rabot.

International buses connecting Ghent to other European destinations are usually found at the Dampoort Station. A couple of private bus companies such as Eurolines, Megabus and Flixbus operate from the Dampoort bus hub.

Buses to and from Belgium's second airport – Brussels South Airport Charleroi – are operated by Flibco, and can be found at the rear exit of the Sint-Pieters Station.

Ghent has the largest designated cyclist area in Europe, with nearly of cycle paths and more than 700 one-way streets, where bikes are allowed to go against the traffic. It also boasts Belgium's first cycle street, where cars are considered ‘guests’ and must stay behind cyclists. In 2017 the city restricted car traffic circulation which boosts cycling. More cyclists means a higher demand for bicycle parking stations. In 2010, the plans to renovate Gent-Sint-Pieters railway station, included 10,000 bicycle parking spots. In 2020 several sections of the underground parking facilities have been build, and the targets have been adjusted to a total of 17,000 parking spots.

In the Belgian first football division Ghent is represented by K.A.A. Gent, who became Belgian football champions for the first time in its history in 2015. Another Ghent football club is KRC Gent-Zeehaven, playing in the Belgian fourth division. A football match at the 1920 Summer Olympics was held in Ghent.

The Six Days of Ghent, a six-day track cycling race, is held annually, taking place in the Kuipke velodrome in Ghent. In road cycling, the city hosts the start and finish of the Omloop Het Nieuwsblad, the traditional opening race of the cobbled classics season. It also lends its name to another cobbled classic, Gent–Wevelgem, although the race now starts in the nearby city of Deinze.

The city hosts an annual athletics IAAF event in the Flanders Sports Arena: the Indoor Flanders meeting where two-time Olympic champion Hicham El Guerrouj set an indoor world world record of 3:48.45 in the mile run in 1997.

The Flanders Sports Arena was host to the 2015 Davis Cup Final between Belgium and Great Britain.


Ghent is twinned with: 



</doc>
<doc id="12343" url="https://en.wikipedia.org/wiki?curid=12343" title="Guadeloupe">
Guadeloupe

Guadeloupe (, ; Antillean Creole: ) is an archipelago forming an overseas region of France in the Caribbean. It consists of six inhabited islands, Basse-Terre, Grande-Terre, Marie-Galante, La Désirade, and the Îles des Saintes, as well as many uninhabited islands and outcroppings. It lies south of Antigua and Barbuda and Montserrat, and north of Dominica. Its capital is Basse-Terre on the southern west coast; however, the largest city is Les Abymes and the main city is Pointe-à-Pitre.

Like the other overseas departments, it is an integral part of France. As a constituent territory of the European Union and the Eurozone, the euro is its official currency and any European Union citizen is free to settle and work there indefinitely. As an overseas department, however, it is not part of the Schengen Area. The region formerly included Saint Barthélemy and Saint Martin, which were detached from Guadeloupe in 2007 following a 2003 referendum.

The official language is French; Antillean Creole is also spoken.

The archipelago was called (or "The Island of Beautiful Waters") by the native Arawak people.

Christopher Columbus named the island in 1493 after the Our Lady of Guadalupe, a shrine to the Virgin Mary venerated in the Spanish town of Guadalupe, Extremadura. Upon becoming a French colony, the Spanish name was retained though altered to French orthography and phonology. The islands are locally known as .

The islands were first populated by indigenous peoples of the Americas, possibly as far back as 3000 BC. The Arawak people are the first identifiable group; however, they were later displaced circa 1400 AD by Kalina-Carib peoples.

Christopher Columbus was the first European to see Guadeloupe, landing in November 1493 and giving it its current name. Several attempts at colonisation by the Spanish in the 16th century failed due to attacks from the native Caribs peoples. In 1626 the French under Pierre Belain d'Esnambuc began to take an interest in Guadeloupe, expelling Spanish settlers. The Compagnie des Îles de l'Amérique settled in Guadeloupe in 1635, under the direction of Charles Liénard de L'Olive and Jean du Plessis d'Ossonville; they formally took possession of the island for France and brought in French farmers to colonise the land. This led to the death of many Caribs by disease and violence. By 1640, however, the Compagnie des Îles de l'Amérique had gone bankrupt, and they thus sold Guadeloupe to Charles Houël du Petit Pré who began plantation agriculture, with the first African slaves arriving in 1650. Ownership of the island then passed to the French West India Company before it was annexed to France in 1674 under the tutelage of their Martinique colony. Institutionalised slavery, enforced by the Code Noir from 1685, led to a booming sugar plantation economy.

During the Seven Years' War the British occupied Guadeloupe from the time of 1759 British Invasion of Guadeloupe until the 1763 Treaty of Paris. During this time Pointe-à-Pitre became a major harbour, and markets in Britain's North American colonies were opened to Guadeloupean sugar which was traded for cheap food and timber. The economy expanded quickly, creating vast wealth for the European colonists. During this time about 18,000 slaves were imported to Guadeloupe. So prosperous was Guadeloupe at the time that under the 1763 Treaty of Paris France forfeited its Canadian colonies in exchange for Guadeloupe. Coffee planting began in the late 1720s, also worked by slaves, and by 1775 cocoa had also become a major export product.
The 1789 French Revolution brought chaos to Guadeloupe. Under new revolutionary law free people of colour were entitled to equal rights. Taking advantage of the anarchic political situation, Britain invaded Guadeloupe in 1794, to which the French responded by sending in soldiers led by Victor Hugues, who retook the lands and abolished slavery. In the Reign of Terror that followed more than 1,000 colonists were killed.
In 1802 the First French Empire reinstated the pre-revolutionary government and slavery, prompting a slave rebellion led by Louis Delgrès. The French authorities responded quickly, culminating in the Battle of Matouba on 28 May 1802. Realising they had no chance of success, Delgrès and his followers committed mass suicide by deliberately exploding their gunpowder stores. In 1810 the British again seized the island, handing it over to Sweden in 1813.

In the Treaty of Paris of 1814, Sweden ceded Guadeloupe to France, giving rise to the Guadeloupe Fund. In 1815 the Treaty of Vienna definitively acknowledged French control of Guadeloupe.

Slavery was abolished in the French Empire in 1848. From 1854 indentured labourers from the French colony of Pondicherry in India were brought in. Emancipated slaves had the vote from 1849, but French nationality and the vote was not granted to Indian citizens until 1923, thanks largely to the efforts of Henry Sidambarom.

In 1936 Félix Éboué became the first black governor of Guadeloupe. During the Second World War Guadeloupe initially came under the control of the Vichy government, later joining Free France in 1943. In 1946, the colony of Guadeloupe became an overseas department of France.

Tensions arose in the post-war era over the social structure of Guadeloupe and its relationship with mainland France. The 'Massacre of St Valentine' occurred in 1952, when striking factory workers in Le Moule were shot at by the Compagnies républicaines de sécurité, resulting in four deaths. In May 1967 racial tensions exploded into rioting following a racist attack on a black Guadeloupean, resulting in eight deaths.

An independence movement grew in the 1970s, prompting France to declare Guadeloupe a French region in 1974. The Union populaire pour la libération de la Guadeloupe (UPLG) campaigned for complete independence, and by the 1980s the situation had turned violent with the actions of groups such as Groupe de libération armée (GLA) and Alliance révolutionnaire caraïbe (ARC).

Greater autonomy was granted to Guadeloupe in 2000. Through a referendum in 2003, Saint-Martin and Saint Barthélemy voted to separate from the administrative jurisdiction of Guadeloupe, this being fully enacted by 2007.

In January 2009, labour unions and others known as the Liyannaj Kont Pwofitasyon went on strike for more pay. Strikers were angry with low wages, the high cost of living, high levels of poverty relative to mainland France and levels of unemployment that are amongst the worst in the European Union. The situation quickly escalated, exacerbated by what was seen as an ineffectual response by the French government, turning violent and prompting the deployment of extra police after a union leader (Jacques Bino) was shot and killed. The strike lasted 44 days and had also inspired similar actions on nearby Martinique. President Nicolas Sarkozy later visited the island, promising reform. Tourism suffered greatly during this time and affected the 2010 tourist season as well.

Guadeloupe is an archipelago of more than 12 islands, as well as islets and rocks situated where the northeastern Caribbean Sea meets the western Atlantic Ocean. It is located in the Leeward Islands in the northern part of the Lesser Antilles, a partly volcanic island arc. To the north lies Antigua and Barbuda and the British Oversea Territory of Montserrat, with Dominica lying to the south.

The main two islands are Basse-Terre (west) and Grande-Terre (east), which form a butterfly shape as viewed from above, the two 'wings' of which are separated by the Grand Cul-de-Sac Marin, Rivière Salée and Petit Cul-de-Sac Marin. More than half of Guadeloupe's land surface consists of the 847.8 km Basse-Terre. The island is mountainous, containing such peaks as Mount Sans Toucher (4,442 feet; 1,354 metres) and Grande Découverte (4,143 feet; 1,263 metres), culminating in the active volcano La Grande Soufrière, the highest mountain peak in the Lesser Antilles with an elevation of . In contrast Grande-Terre is mostly flat, with rocky coasts to the north, irregular hills at the centre, mangrove at the southwest, and white sand beaches sheltered by coral reefs along the southern shore. This is where the main tourist resorts are found.

Marie-Galante is the third-largest island, followed by La Désirade, a north-east slanted limestone plateau, the highest point of which is . To the south lies the Îles de Petite-Terre, which are two islands (Terre de Haut and Terre de Bas) totalling 2 km.

Les Saintes is an archipelago of eight islands of which two, Terre-de-Bas and Terre-de-Haut are inhabited. The landscape is similar to that of Basse-Terre, with volcanic hills and irregular shoreline with deep bays.

There are numerous other smaller islands, most notably Tête à l'Anglais, Îlet à Kahouanne, Îlet à Fajou, Îlet Macou, Îlet aux Foux, Îlets de Carénage, La Biche, Îlet Crabière, Îlets à Goyaves, Îlet à Cochons, Îlet à Boissard, Îlet à Chasse and Îlet du Gosier.

Basse-Terre is a volcanic island. The Lesser Antilles are at the outer edge of the Caribbean Plate, and Guadeloupe is part of the outer arc of the Lesser Antilles Volcanic Arc. Many of the islands were formed as a result of the subduction of oceanic crust of the Atlantic Plate under the Caribbean Plate in the Lesser Antilles subduction zone. This process is ongoing and is responsible for volcanic and earthquake activity in the region. Guadeloupe was formed from multiple volcanoes, of which only la Soufriere is not extinct. Its last eruption was in 1976, and led to the evacuation of the southern part of Basse-Terre. 73,600 people were displaced over a course of three and a half months following the eruption.

K–Ar dating indicates that the three northern massifs on Basse-Terre Island are 2.79 million years old. Sections of volcanoes collapsed and eroded within the last 650,000 years, after which the Sans Toucher volcano grew in the collapsed area. Volcanoes in the north of Basse-Terre Island mainly produced andesite and basaltic andesite. There are several beaches of dark or "black" sand.

La Désirade, east of the main islands has a basement from the Mesozoic, overlaid with thick limestones from the Pliocene to Quaternary periods.

Grande-Terre and Marie-Galante have basements probably composed of volcanic units of Eocene to Oligocene, but there are no visible outcrops. On Grande-Terre, the overlying carbonate platform is 120 metres thick.

The islands are part of the Leeward Islands, so called because they are downwind of the prevailing trade winds, which blow out of the northeast. This was significant in the days of sailing ships. Grande-Terre is so named because it is on the eastern, or windward side, exposed to the Atlantic winds. Basse-Terre is so named because it is on the leeward south-west side and sheltered from the winds. Guadeloupe has a tropical climate tempered by maritime influences and the Trade Winds. There are two seasons, the dry season called "Lent" from January to June, and the wet season called "winter", from July to December.

The island is vulnerable to hurricanes - among the storms to make landfall on the islands are: Hurricane Cleo in 1964, Hurricane Hugo in 1989, and Hurricane Maria in 2017.

With fertile volcanic soils, heavy rainfall and a warm climate, vegetation on Basse-Terre is lush. Most of the islands' forests are on Basse-Terre, containing such species as mahogany, ironwood and chestnut trees. Mangrove swamps line the Salée River. Much of the forest on Grande-Terre has been cleared, with only a few small patches remaining.

Numerous mammal species live on the islands, notably raccoons, agouti and mongoose. Bird species include the Guadeloupe woodpecker, Antillean nighthawk and monk parakeets. The waters of the islands support a rich variety of marine life.

Guadeloupe recorded a population of 402,119 in the 2013 census. The population is mainly of Afro-Caribbean or mixed Creole, white European, Indian (Tamil, Telugu, and other South Indians), Lebanese, Syrians, and Chinese. There is also a substantial population of Haitians in Guadeloupe who work mainly in construction and as street vendors. Basse-Terre is the political capital; however, the largest city and economic hub is Pointe-à-Pitre.

The population of Guadeloupe has been stable recently, with a net increase of only 335 people between the 2008 and 2013 censuses. In 2012 the average population density in Guadeloupe was 247.7 inhabitants for every square kilometre, which is very high in comparison to the whole France's 116.5 inhabitants for every square kilometre. One third of the land is devoted to agriculture and all mountains are uninhabitable; this lack of space and shelter makes the population density even higher.

In 2011, life expectancy at birth was recorded at 77.0 years for males and 83.5 for females.

Medical centers in Guadeloupe include: University Hospital Center (CHU) in Pointe-à-Pitre, Regional Hospital Center (CHR) in Basse-Terre, and four hospitals located in Capesterre-Belle-Eau, Pointe-Noire, Bouillante and Saint-Claude.

The "Institut Pasteur de la Guadeloupe", is located in Pointe-à-Pitre and is responsible for researching environmental hygiene, vaccinations, and the spread of tuberculosis and mycobacteria

Together with Martinique, La Réunion, Mayotte and French Guiana, Guadeloupe is one of the overseas departments, being both a region and a department combined into one entity. It is also an outermost region of the European Union. The inhabitants of Guadeloupe are French citizens with full political and legal rights.
Legislative powers are centred on the separate departmental and regional councils. The elected president of the Departmental Council of Guadeloupe is currently Josette Borel-Lincertin; its main areas of responsibility include the management of a number of social and welfare allowances, of junior high school (collège) buildings and technical staff, and local roads and school and rural buses. The Regional Council of Guadeloupe is a body, elected every six years, consisting of a president (currently Ary Chalus) and eight vice-presidents. The regional council oversees secondary education, regional transportation, economic development, the environment, and some infrastructure, among other things.

Guadeloupe elects one deputy from one of each of the first, second, third, and fourth constituencies to the National Assembly of France. Three senators are chosen for the Senate of France by indirect election. For electoral purposes, Guadeloupe is divided into two arrondissements (Basse-Terre and Pointe-à-Pitre), and 21 cantons.

Most of the French political parties are active in Guadeloupe. In addition there are also regional parties such as the Guadeloupe Communist Party, the Progressive Democratic Party of Guadeloupe, the Guadeloupean Objective, the Pluralist Left, and United Guadaloupe, Socialism and Realities.

The prefecture (regional capital) of Guadeloupe is Basse-Terre. Local services of the state administration are traditionally organised at departmental level, where the prefect represents the government.

For the purposes of local government, Guadeloupe is divided into 32 communes. Each commune has a municipal council and a mayor. Revenues for the communes come from transfers from the French government, and local taxes. Administrative responsibilities at this level include water management, acts of birth, marriage, etc., and municipal police.

As a part of France, Guadeloupe uses the French tricolour as its flag and "La Marseillaise" as its anthem. However, a variety of other flags are also used in an unofficial or informal context, most notably the sun-based flag. Independentists also have their own flag.

The economy of Guadeloupe depends on tourism, agriculture, light industry and services. It is reliant upon mainland France for large subsidies and imports and public administration is the largest single employer on the islands. Unemployment is especially high among the youth population.

In 2006, the GDP per capita of Guadeloupe at market exchange rates, not at PPP, was €17,338 (US$21,780).

GDP: real exchange rate - US$9.74 billion (in 2006)

GDP - real growth rate: NA%

GDP - per capita: real exchange rate - US$21,780 (in 2006)

Exports: US$676 million (in 2005)

Exports - commodities: bananas, sugar, rum

Imports: US$3.102 billion (in 2005)

Tourism is the one of the most prominent sources of income, with most visitors coming from France and North America. An increasingly large number of cruise ships visit Guadeloupe, the cruise terminal of which is in Pointe-à-Pitre.

The traditional sugar cane crop is slowly being replaced by other crops, such as bananas (which now supply about 50% of export earnings), eggplant, guinnep, noni, sapotilla, giraumon squash, yam, gourd, plantain, christophine, cocoa, jackfruit, pomegranate, and many varieties of flowers. Other vegetables and root crops are cultivated for local consumption, although Guadeloupe is dependent upon imported food, mainly from the rest of France.

Of the various light industries, sugar and rum production, solar energy, cement, furniture and clothing are the most prominent. Most manufactured goods and fuel are imported.

Guadeloupe's official language is French, which is spoken by nearly all of the population. In addition, most of the population can also speak Guadeloupean Creole, a variety of Antillean Creole. Traditionally stigmatised as the language of the Creole majority, attitudes have changed in recent decades. In the early 1970s to the mid 1980s Guadeloupe saw the rise and fall of an at-times violent movement for (greater) political independence from France, and Creole was claimed as key to local cultural pride and unity. In the 1990s, in the wake of the independence movement's demise, Creole retained its de-stigmatized status as a symbol of local culture, albeit without de jure support from the state and without being practiced with equal competence in all strata and age groups of society. However, the language has since gained greater acceptance on the part of France, such that it was introduced as an elective in public schools. Today, the question as to whether French and Creole are stable in Guadeloupe, i.e. whether both languages are practised widely and competently throughout society, remains a subject of active research.

About 80% of the population are Roman Catholic. Guadeloupe is in the diocese of Basse-Terre (et Pointe-à-Pitre). Other major religions include various Protestant denominations.

Guadeloupe has always had a rich literary output, with Guadeloupean author Saint-John Perse winning the 1960 Nobel Prize in Literature. Other prominent writers from Guadeloupe or of Guadeloupean descent include Maryse Condé, Simone Schwarz-Bart, Myriam Warner-Vieyra, Oruno Lara, Daniel Maximin, Paul Niger, Guy Tirolien and Nicolas-Germain Léonard.

Music and dance are also very popular, and the interaction of African, French and Indian cultures has given birth to some original new forms specific to the archipelago, most notably zouk music. Since the 1970s, Guadeloupean music has increasingly claimed the local language, Guadeloupean Creole as the preferred language of popular music. Islanders enjoy many local dance styles including zouk, zouk-love, compas, as well as the modern international genres such as hip hop, etc.

Traditional Guadeloupean music includes biguine, kadans, cadence-lypso, and gwo ka. Popular music artists and bands such as Experience 7, Francky Vincent, Kassav' (which included Patrick St-Eloi, and Gilles Floro) embody the more traditional music styles of the island, whilst other musical artists such as the punk band The Bolokos (1) or Tom Frager focus on more international genres such as rock or reggae. Many international festivals take place in Guadeloupe, such as the Creole Blues Festival on Marie-Galante. All the Euro-French forms of art are also ubiquitous, enriched by other communities from Brazil, Dominican Republic, Haiti, India, Lebanon, Syria) who have migrated to the islands.

Classical music has seen a resurgent interest in Guadeloupe. One of the first known composers of African origin was born in Guadeloupe, Le Chevalier de Saint-Georges, a contemporary of Joseph Haydn and Wolfgang Amadeus Mozart, and a celebrated figure in Guadeloupe. Several monuments and cites are dedicated to Saint-Georges in Guadeloupe, and there is an annual music festival, Festival International de Musique Saint-Georges, dedicated in his honour. The festival attracts classical musicians from all over the world and is one of the largest classical music festivals in the Caribbean.

Another element of Guadeloupean culture is its dress. A few women (particularly of the older generation) wear a unique style of traditional dress, with many layers of colourful fabric, now only worn on special occasions. On festive occasions they also wore a madras (originally a "kerchief" from South India) headscarf tied in many different symbolic ways, each with a different name. The headdress could be tied in the "bat" style, or the "firefighter" style, as well as the "Guadeloupean woman". Jewellery, mainly gold, is also important in the Guadeloupean lady's dress, a product of European, African and Indian inspiration.

Football (soccer) is popular in Guadeloupe, and several notable footballers are of Guadeloupean origin, including Marius Trésor, Stéphane Auvray, Ronald Zubar and his younger brother Stéphane, Miguel Comminges, Dimitri Foulquier, Bernard Lambourde, Anthony Martial, Alexandre Lacazette, Thierry Henry, Lilian Thuram, William Gallas, Layvin Kurzawa Thomas Lemar and Kingsley Coman.

The national football team were 2007 CONCACAF Gold Cup semi-finalists, defeated by Mexico.

Basketball is also popular. Best known players are the NBA players Rudy Gobert, Mickaël Piétrus, Johan Petro, Rodrigue Beaubois, and Mickael Gelabale (now playing in Russia), who were born on the island.

Several track and field athletes, such as Marie-José Pérec, Patricia Girard-Léno, Christine Arron, and Wilhem Belocian, are also Guadeloupe natives. Triple Olympic champion Marie-José Pérec, and fourth-fastest runner Christine Arron.

The island has produced many world-class fencers. Yannick Borel, Daniel Jérent, Ysaora Thibus, Anita Blaze, Enzo Lefort and Laura Flessel were all born and raised in Guadeloupe. According to olympic gold medalist and world champion Yannick Borel, there is a good fencing school and a culture of fencing in Guadeloupe.

Even though Guadeloupe is part of France, it has its own sports teams. Rugby union is a small but rapidly growing sport in Guadeloupe.

The island is also internationally known for hosting the Karujet Race – Jet Ski World Championship since 1998. This nine-stage, four-day event attracts competitors from around the world (mostly Caribbeans, Americans, and Europeans). The Karujet, generally made up of seven races around the island, has an established reputation as one of the most difficult championships in which to compete.

The Route du Rhum is one of the most prominent nautical French sporting events, occurring every four years.

Bodybuilder Serge Nubret was born in Anse-Bertrand, Grande-Terre, representing the French state in various bodybuilding competitions throughout the 1960s and 1970s including the IFBB's Mr. Olympia contest, taking 3rd place every year from 1972 to 1974, and 2nd place in 1975. Bodybuilder Marie-Laure Mahabir also hails from Guadeloupe.

The country has also a passion for cycling. It hosted the French Cycling Championships in 2009 and continues to host the Tour de Guadeloupe every year.

Guadeloupe also continues to host the Orange Open de Guadeloupe tennis tournament (since 2011).

The Tour of Guadeloupe sailing, which was founded in 1981.

In boxing, the following athletes come from the island of Guadeloupe: Ludovic Proto (amateur; competed in the 1988 Summer Olympics in the men's light welterweight division), Gilbert Delé (professional; held the European light-middleweight title from 1989 to 1990, then won the WBA light-middleweight title in 1991, by defeating Carlos Elliott via TKO), and Jean-Marc Mormeck (professional; former two-time unified cruiserweight champion—held the WBA, WBC, and "The Ring" world titles twice between 2005 and 2007).

Guadeloupe is served by a number of airports; most international flights use Pointe-à-Pitre International Airport. Boats and cruise ships frequent the islands, using the ports at Pointe-à-Pitre and Basse-Terre.

On 9 September 2013 the county government voted in favour of constructing a tramway in Pointe-à-Pitre. The first phase will link northern Abymes to downtown Pointe-à-Pitre by 2019. The second phase, scheduled for completion in 2023, will extend the line to serve the university.

Guadeloupe is one of the safest islands in the Caribbean; nevertheless, it was the most violent overseas French department in 2016. The murder rate is slightly more than that of Paris, at 8.2 per 100,000. The high level of unemployment caused violence and crime to rise especially in 2009 and 2010, the years following a great worldwide recession. While the residents of Guadeloupe describe the island as a place with little everyday crime, most violence is caused by the drug trade or domestic disputes.



</doc>
<doc id="12345" url="https://en.wikipedia.org/wiki?curid=12345" title="Demographics of Guadeloupe">
Demographics of Guadeloupe

Guadeloupe has a population of 403,977 (2012).

According to INSEE Guadeloupe has an estimated population of 403,977 on January 1, 2012. Life expectancy at birth is 77.0 years for males, and 83.5 for females (figures for 2011).

French is the official language, taught in the school system. Antillean Creole French is spoken by a large part of the population, understood by nearly all, and taught in some schools. A 2007 document issued by the Organisation internationale de la Francophonie estimated the population to be 80.2% "francophone" and 14.9% "partially francophone".

The following vital statistics include Saint Martin and Saint Barthélemy.


Structure of the population (01.01.2010) (Provisional estimates) (Excluding data for Saint Barthélemy and Saint Martin) :


</doc>
<doc id="12349" url="https://en.wikipedia.org/wiki?curid=12349" title="Telecommunications in Guadeloupe">
Telecommunications in Guadeloupe

Telephones - main lines in use:
159,000 (1995)

Telephones - mobile cellular:
814 (1990)

Telephone system:
domestic facilities inadequate
<br>"domestic:"
NA
<br>"international:"
satellite earth station - 1 Intelsat (Atlantic Ocean); microwave radio relay to Antigua and Barbuda, Dominica, and Martinique

Radio broadcast stations:
AM 1, FM 17, shortwave 0 (1998)

Radios:
113,000 (1997)

Television broadcast stations:
5 (plus several low-power repeaters) (1997)

Televisions:
118,000 (1997)

Internet Service Providers (ISPs): France Telecom (Orange)

Country code (Top-level domain): GP



</doc>
<doc id="12350" url="https://en.wikipedia.org/wiki?curid=12350" title="Transport in Guadeloupe">
Transport in Guadeloupe

Transport in Guadeloupe.

<br>"total:"
2,082 km
<br>"paved:"
1,742 km
<br>"unpaved:"
340 km (1985 est.)
<br>"note:"
in 1996 there were a total of 3,200 km of roads

Basse-Terre, Pointe-à-Pitre (on Grande-Terre).

Merchant marine:
<br>"total:"
1 ship (1,000 GT or over) totaling 1,240 GT/
<br>"ships by type:"
passenger 1 (1999 est.)

9 (1999 est.)

<br>"total:"
8
<br>"over 3,047 m:"
1
<br>"914 to 1,523 m:"
2
<br>"under 914 m:"
5 (1999 est.)

<br>"total:"
1
<br>"under 914 m:"
1 (1999 est.)

<br>
Flights Booking Guadeloupe Flight's comparator specific for Guadeloupe Island


</doc>
<doc id="12353" url="https://en.wikipedia.org/wiki?curid=12353" title="Glagolitic script">
Glagolitic script

The Glagolitic script (, "Glagolitsa"; Bulgarian: Глаголица "Glagotitsa") is the oldest known Slavic alphabet. It is generally agreed to have been created in the 9th century by Saint Cyril, a monk from Thessaloniki. He and his brother, Saint Methodius, were sent by the Byzantine Emperor Michael III in 863 to Great Moravia to spread Christianity among the West Slavs in the area. The brothers decided to translate liturgical books into the contemporary Slavic language understandable to the general population (now known as Old Church Slavonic). As the words of that language could not be easily written by using either the Greek or Latin alphabets, Cyril decided to invent a new script, Glagolitic, which he based on the local dialect of the Slavic or Thracian tribes from the Byzantine theme of Thessalonica.

After the deaths of Cyril and Methodius, the Glagolitic alphabet ceased to be used in Moravia for political or religious needs. In 885AD Pope Stephen VI has issued a bula to restrict spreading and reading Christian services in different than Latin or Greek languages. On the other side Kniaz Sviatopolk I of Kiev followed the interests of the Frankish Empire and prosecuted the students of Cyril and Methodius. In 886AD Kliment (also known as Clement of Ohrid), Naum, Gorazd, Angelarii and Sava arrived in the First Bulgarian Empire where they have been warmly accepted by the Bulgarian Tsar Boris I of Bulgaria. Both Glagoltic and Cyrillic alphabet were used until XIII-XIV century in Bulgaria. Cyrillic alphabeth (which augmented some letters from the Glagolitic alphabet) was developed at the Preslav Literary School and Ohrid Literary School. The Glagolitic alphabet was preserved only by the clergy of Croatia to write Church Slavonic until the early 19th century. Glagoltic also spread in Dalmatia, Bohemia with traces in Panonia, Moravia and Russia.

The name was not created until many centuries after the script's creation, and comes from the Old Church Slavonic глаголъ "glagolŭ" "utterance". The verb "glagolati" means "to speak". It has been conjectured that the name "Glagolica" developed in Croatia around the 14th century and was derived from the word "glagolity", applied to adherents of the liturgy in Slavonic.

The creation of the characters is popularly attributed to Saints Cyril and Methodius, who may have created them to facilitate the introduction of Christianity. It is believed that the original letters were fitted to Macedonian dialects specifically.

The number of letters in the original Glagolitic alphabet is not known, but it may have been close to its presumed Greek model. The 41 letters known today include letters for non-Greek sounds, which may have been added by Saint Cyril, as well as ligatures added in the 12th century under the influence of Cyrillic, as Glagolitic lost its dominance. In later centuries, the number of letters dropped dramatically, to fewer than 30 in modern Croatian and Czech recensions of the Church Slavic language. Twenty-four of the 41 original Glagolitic letters (see table below) probably derive from graphemes of the medieval cursive Greek small alphabet but have been given an ornamental design.

The source of the other consonantal letters is unknown. If they were added by Cyril, it is likely that they were taken from an alphabet used for Christian scripture. It is frequently proposed that the letters "sha" , "tsi" , and "cherv" were taken from the letters "shin" ש and "tsadi" צ of the Hebrew alphabet, and that Ⰶ "zhivete" derives from Coptic "janja" Ϫ. However, Cubberley (1996) suggests that if a single prototype were presumed, the most likely source would be Armenian. Other proposals include the Samaritan alphabet, which Cyril learned during his journey to the Khazars in Cherson.

For writing numbers, the Glagolitic numerals uses letters with a numerical value assigned to each based on their native alphabetic order. This differs from Cyrillic numerals, which inherited their numeric value from the corresponding Greek letter (see Greek numerals).

The two monks later canonized as Saints Cyril and Methodius, brothers from Thessaloniki, were sent to Great Moravia in 862 by the Byzantine emperor at the request of Prince Rastislav, who wanted to weaken the dependence of his country on East Frankish priests. The Glagolitic alphabet, however it originated, was used between 863 and 885 for government and religious documents and books and at the Great Moravian Academy ("Veľkomoravské učilište") founded by the missionaries, where their followers were educated. The Kiev Missal, found in the 19th century in Jerusalem, was dated to the 10th century.

In 886 an East Frankish bishop of Nitra named Wiching banned the script and jailed 200 followers of Methodius, mostly students of the original academy. They were then dispersed or, according to some sources, sold as slaves by the Franks. Many of them (including Naum, Clement, Angelarious, Sava and Gorazd), however, reached Bulgaria and were commissioned by Boris I of Bulgaria to teach and instruct the future clergy of the state in the Slavic language. After the adoption of Christianity in Bulgaria in 865, religious ceremonies and Divine Liturgy were conducted in Greek by clergy sent from the Byzantine Empire, using the Byzantine rite. Fearing growing Byzantine influence and weakening of the state, Boris viewed the introduction of the Slavic alphabet and language into church use as a way to preserve the independence of the Bulgarian Empire from Byzantine Constantinople. As a result of Boris' measures, two academies, one in Ohrid and one in Preslav, were founded.

From there, the students travelled to other places and spread the use of their alphabet. Students of the two apostles who were expelled from Great Moravia in 886, notorious being Clement of Ohrid and Saint Naum, brought the Glagolitic alphabet to the First Bulgarian Empire on Balkans and were received and accepted officially by Boris I of Bulgaria. This led to the establishment of the two literary schools: the Preslav Literary School and the Ohrid Literary School. Some went to Croatia (Dalmatia), where the squared variant arose and where Glagolitic remained in use for a long time. In 1248, Pope Innocent IV granted the Croatians of southern Dalmatia the unique privilege of using their own language and this script in the Roman Rite liturgy. Formally granted to bishop Philip of Senj, permission to use the Glagolitic liturgy (the Roman Rite conducted in the Slavic language instead of Latin, not the Byzantine rite), actually extended to all Croatian lands, mostly along the Adriatic coast. The Holy See had several Glagolitic missals published in Rome. Authorization for the use of this language was extended to some other Slavic regions between 1886 and 1935. In missals, the Glagolitic script was eventually replaced with the Latin alphabet, but the use of the Slavic language in the Mass continued, until replaced by modern vernacular languages.

At the end of the 9th century, one of these students of Methodius – Naum, who had settled in Preslav, Bulgaria – created the Cyrillic script, which almost entirely replaced Glagolitic during the Middle Ages. The Cyrillic alphabet is derived from the Greek alphabet, with some letters (like ⟨ш⟩, ⟨ц⟩, ⟨ч⟩, ⟨ъ⟩, ⟨ь⟩, ⟨ѣ⟩) peculiar to Slavic languages being derived from the Glagolitic alphabet. The decision in favor of Cyrillic created an alphabetical difference between the two literary centres of the Bulgarian state in Pliska and Ohrid. In the western part the Glagolitic alphabet remained dominant at first. However, subsequently in the next two centuries, mostly after the fall of the First Bulgarian Empire to the Byzantines, Glagolitic gradually ceased to be used there at all. Nevertheless, particular passages or words written with the Glagolitic alphabet appeared in Bulgarian Cyrillic manuscripts till the end of the 14th century. Some students of the Ohrid academy went to Bohemia where the alphabet was used in the 10th and 11th centuries, along with other scripts. It is not clear whether the Glagolitic alphabet was used in the Duchy of Kopnik before the Wendish Crusade, but it was certainly used in Kievan Rus'.

In Croatia, from the 12th century, Glagolitic inscriptions appeared mostly in littoral areas: Istria, Primorje, Kvarner, and Kvarner islands, notably Krk, Cres, and Lošinj; in Dalmatia, on the islands of Zadar, but there were also findings in inner Lika and Krbava, reaching to Kupa river, and even as far as Međimurje and Slovenia.
The "Hrvoje's Missal" () from 1404 was written in Split, and it is considered one of the most beautiful Croatian Glagolitic books. The 1483 "Missale Romanum Glagolitice" was the first printed Croatian Glagolitic book.

It was believed that Glagolitsa in Croatia was present only in those areas. But, in 1992, the discovery of Glagolitic inscriptions in churches along the Orljava river in Slavonia totally changed the picture (churches in Brodski Drenovac, Lovčić, and some others), showing that use of the Glagolitic alphabet was spread from Slavonia also.

Sporadic instances aside, Glagolitic survived beyond the 12th century as a primary script in Croatia alone, although from there a brief attempt at reintroduction was made in the West Slavic area in the 14th century. The centre of influence appears to have been in the Kvarner Gulf, though the nature and extent of this influence remain subjects of debate. The early development of the Glagolitic minuscule script alongside the increasingly square majuscule is poorly documented, but before the advent of printing, a mutual relationship evolved between the two varieties; the majuscule being used primarily for inscriptions and higher liturgical uses, and the minuscule being applied to both religious and secular documents. Ignoring the problematic early Slavonian inscriptions, the use of the Glagolitic script at its peak before the Croatian-Ottoman wars corresponded roughly to the area that spoke the Chakavian dialect at the time, in addition to, to varying extents, the adjacent Kajkavian regions within the Zagreb bishopric. As a result, vernacular impact on the liturgical language and script largely stems from Chakavian sub-dialects.

The first major threat to Croatian Glagolitic since it attained stability was from the Ottoman excursions, though the extent of cultural damage varied locally depending on the course of war. In the 17th century, though, the first successful direct attack on the script since the 12th century was headed by the Bishop of Zagreb, and after the Magnate conspiracy left the script without secular protectors, its use was limited to the littoral region. In the meantime, printing gradually overtook handwriting for liturgical manuscripts, resulting in a decline of the majuscule script, which was absorbed for titular and sometimes initial use within for minuscule documents. It was not until the late 18th century and the onset of modernity that Glagolitic received significant further threats, and through western influence, especially secular, Glagolitic culture collapsed, so that by the mid 19th century, the script was purely liturgical, relying mostly on printed materials. By the time of the devastating Italianization movements under Fascist Italy in the early 20th century, numerous independent events had already greatly reduced the area of the liturgical use of Glagolitic.

The tradition that the alphabet was designed by Saint Cyril and Saint Methodius has not been universally accepted. A less common belief, contradicting allochthonic Slovene origin, was that the Glagolitic was created or used in the 4th century by St. Jerome (Latin: "Eusebius Sophronius Hieronymus"), hence the alphabet is sometimes named Hieronymian.

It is also acrophonically called azbuki from the names of its first two letters in Bulgaria, on the same model as "alpha" + "beta". The Slavs of Great Moravia (present-day Slovakia and Moravia), Hungary, Slovenia and Slavonia were called "Slověne" at that time, which gives rise to the name Slovenish for the alphabet. Some other, rarer, names for this alphabet are Bukvitsa (from common Slavic word "bukva" meaning "letter", and a suffix "-itsa") and Illyrian.

In the Middle Ages, Glagolica was also known as "St. Jerome's script" due to popular mediaeval legend (created by Croatian scribes in the 13th century) ascribing its invention to St. Jerome (342–429). That claim, however, has been resolutely disproven.

The epoch of traditional attribution of the script to Jerome ended probably in 1812. In modern times, only certain marginal authors share this view, usually "re-discovering" one of the already-known mediaeval sources.

A hypothetical pre-Glagolitic writing system is typically referred to as "cherty i rezy" (strokes and incisions) – but no material evidence of the existence of any pre-Glagolitic Slavic writing system has been found, except for a few brief and vague references in old chronicles and "lives of the saints". All artifacts presented as evidence of pre-Glagolitic Slavic inscriptions have later been identified as texts in known scripts and in known non-Slavic languages, or as fakes. The well-known Chernorizets Hrabar's "strokes and incisions" are usually considered to be a reference to a kind of property mark or alternatively fortune-telling signs. Some "Ruthenian letters" found in one version of St. Cyril's life are explainable as misspelled "Syrian letters" (in Slavic, the roots are very similar: "rus-" vs. "sur-" or "syr-"), etc.

The values of many of the letters are thought to have been displaced under Cyrillic influence or to have become confused through the early spread to different dialects so the original values are not always clear. For instance, the letter "yu" Ⱓ is thought to have perhaps originally had the sound /u/ but was displaced by the adoption of an "oѵ" ligature Ⱆ under the influence of later Cyrillic. Other letters were late creations after a Cyrillic model.

The following table lists each letter in its modern order, showing an image of the letter (round variant), the corresponding modern Cyrillic letter, the approximate sound transcribed with the , the name, and suggestions for its origin. Several letters have no modern counterpart.
Note that "yery" () is a digraph of either "yer" () or "yerь" (), followed by either "izhe" () or "i" (Ⰻ).

In older texts, "uk" () and three out of four "yus"es () also can be written as digraphs, in two separate parts.

The order of "izhe" () and "i" () varies from source to source, as does the order of the various forms of "yus" (). Correspondence between Glagolitic "izhe" () and "i" () with Cyrillic "И" and "І" is unknown.

The Proto-Slavic language did not have the phoneme /f/, and the letters Fert () and Fita () were used for transcribing words of Greek origin, and so was Izhitsa () for the Greek upsilon.

The Glagolitic alphabet was added to the Unicode Standard in March 2005 with the release of version 4.1.

The Unicode block for Glagolitic is U+2C00–U+2C5F.
The Glagolitic combining letters for Glagolitic Supplement block (U+1E000–U+1E02F) was added to the Unicode Standard in June, 2016 with the release of version 9.0:

Glagolitic script is the writing system used in the world of "The Witcher" books and video game series. It is also featured, in various uses, in several of the point and click adventure games made by Cateia Games, a Croatian game studio.





</doc>
<doc id="12354" url="https://en.wikipedia.org/wiki?curid=12354" title="Greatest common divisor">
Greatest common divisor

In mathematics, the greatest common divisor (gcd) of two or more integers, which are not all zero, is the largest positive integer that divides each of the integers. For two integers "x", "y", the greatest common divisor of "x" and "y" is denoted formula_1. For example, the gcd of 8 and 12 is 4, that is, formula_2.

In the name "greatest common divisor", the adjective "greatest" may be replaced by "highest", and the word "divisor" may be replaced by "factor", so that other names include greatest common factor (gcf), etc. Historically, other names for the same concept have included greatest common measure.

This notion can be extended to polynomials (see Polynomial greatest common divisor) and other commutative rings (see below).

In this article we will denote the greatest common divisor of two integers "a" and "b" as gcd("a","b"). Some authors use ("a","b").

What is the greatest common divisor of 54 and 24?

The number 54 can be expressed as a product of two integers in several different ways:

Thus the divisors of 54 are: formula_4

Similarly, the divisors of 24 are: formula_5

The numbers that these two lists share in common are the common divisors of 54 and 24:

The greatest of these is 6. That is, the greatest common divisor of 54 and 24 is 6. One writes:

Two numbers are called relatively prime, or coprime, if their greatest common divisor equals 1. For example, 9 and 28 are relatively prime.

For example, a 24-by-60 rectangular area can be divided into a grid of: 1-by-1 squares, 2-by-2 squares, 3-by-3 squares, 4-by-4 squares, 6-by-6 squares or 12-by-12 squares. Therefore, 12 is the greatest common divisor of 24 and 60. A 24-by-60 rectangular area can thus be divided into a grid of 12-by-12 squares, with two squares along one edge (24/12 = 2) and five squares along the other (60/12 = 5).

The greatest common divisor is useful for reducing fractions to the lowest terms. For example, gcd(42, 56) = 14, therefore,

The greatest common divisor can be used to find the least common multiple of two numbers when the greatest common divisor is known, using the relation,

In principle, greatest common divisors can be computed by determining the prime factorizations of the two numbers and comparing factors, as in the following example: to compute gcd(18, 84), we find the prime factorizations 18 = 2 · 3 and 84 = 2 · 3 · 7, and since the "overlap" of the two expressions is 2 · 3, gcd(18, 84) = 6. In practice, this method is only feasible for small numbers; computing prime factorizations in general takes far too long.

Here is another concrete example, illustrated by a Venn diagram. Suppose it is desired to find the greatest common divisor of 48 and 180. First, find the prime factorizations of the two numbers:

What they share in common is two "2"s and a "3":

A much more efficient method is the Euclidean algorithm, which uses a division algorithm such as long division in combination with the observation that the gcd of two numbers also divides their difference. 

For example, to compute gcd(48,18), divide 48 by 18 to get a quotient of 2 and a remainder of 12. Then divide 18 by 12 to get a quotient of 1 and a remainder of 6. Then divide 12 by 6 to get a remainder of 0, which means that 6 is the gcd. Here, we ignored the quotient in each step, except to notice when the remainder reached 0, signalling that we had arrived at the answer. Formally, the algorithm can be described as:

where
If the arguments are both greater than zero, then the algorithm can be written in more elementary terms as follows:

Lehmer's algorithm is based on the observation that the initial quotients produced by Euclid's algorithm can be determined based on only the first few digits; this is useful for numbers that are larger than a computer word. In essence, one extracts initial digits, typically forming one or two computer words, and runs Euclid's algorithms on these smaller numbers, as long as it is guaranteed that the quotients are the same with those that would be obtained with the original numbers. Those quotients are collected into a small 2-by-2 transformation matrix (that is a matrix of single-word integers), for using them all at once for reducing the original numbers. This process is repeated until numbers have a size for which the binary algorithm (see below) is more efficient.

This algorithm improves speed, because it reduces the number of operations on very large numbers, and can use the speed of hardware arithmetic for most operations. In fact, most of the quotients are very small, so a fair number of steps of the Euclidean algorithm can be collected in a 2-by-2 matrix of single-word integers. When Lehmer's algorithm encounters a quotient that is too large, it must fall back to one iteration of Euclidean algorithm, with a Euclidean division of large numbers.

The binary GCD algorithm uses only subtraction and division by 2.
The method is as follows: Let "a" and "b" be the two non-negative integers. Let the integer "d" be 0. There are five possibilities:
As gcd("a", "a") = "a", the desired gcd is "a" × 2 (as "a" and "b" are changed in the other cases, and "d" records the number of times that "a" and "b" have been both divided by 2 in the next step, the gcd of the initial pair is the product of "a" and 2).

Then 2 is a common divisor. Divide both "a" and "b" by 2, increment "d" by 1 to record the number of times 2 is a common divisor and continue.

Then 2 is not a common divisor. Divide "a" by 2 and continue.

Then 2 is not a common divisor. Divide "b" by 2 and continue.

As gcd("a","b") = gcd("b","a"), if "a" < "b" then exchange "a" and "b". The number "c" = "a" − "b" is positive and smaller than "a". Any number that divides "a" and "b" must also divide "c" so every common divisor of "a" and "b" is also a common divisor of "b" and "c". Similarly, "a" = "b" + "c" and every common divisor of "b" and "c" is also a common divisor of "a" and "b". So the two pairs ("a", "b") and ("b", "c") have the same common divisors, and thus gcd("a","b") = gcd("b","c"). Moreover, as "a" and "b" are both odd, "c" is even, the process can be continued with the pair ("a", "b") replaced by the smaller numbers ("c"/2, "b") without changing the gcd.

Each of the above steps reduces at least one of "a" and "b" while leaving them non-negative and so can only be repeated a finite number of times. Thus eventually the process results in "a" = "b", the stopping case. Then the gcd is "a" × 2.

Example: ("a", "b", "d") = (48, 18, 0) → (24, 9, 1) → (12, 9, 1) → (6, 9, 1) → (3, 9, 1) → (3, 3, 1) ; the original gcd is thus the product 6 of 2 = 2 and "a"= "b"= 3.

The binary GCD algorithm is particularly easy to implement on binary computers. Its computational complexity is
The computational complexity is usually given in terms of the length of the input. Here, this length is formula_17 and the complexity is thus

If "a" and "b" are both nonzero, the greatest common divisor of "a" and "b" can be computed by using least common multiple (lcm) of "a" and "b":

but more commonly the lcm is computed from the gcd.

Using Thomae's function "f",
which generalizes to "a" and "b" rational numbers or commensurable real numbers.

Keith Slavin has shown that for odd "a" ≥ 1:

which is a function that can be evaluated for complex "b". Wolfgang Schramm has shown that

is an entire function in the variable "b" for all positive integers "a" where "c"("k") is Ramanujan's sum.

The computational complexity of the computation of greatest common divisors has been widely studied. If one uses the Euclidean algorithm and the elementary algorithms for multiplication and division, the computation of the greatest common divisor of two integers of at most bits is formula_23 This means that the computation of greatest common divisor has, up to a constant factor, the same complexity as the multiplication.

However, if a fast multiplication algorithm is used, one may modify the Euclidean algorithm for improving the complexity, but the computation of a greatest common divisor becomes slower than the multiplication. More precisely, if the multiplication of two integers of bits takes a time of , then the fastest known algorithm for greatest common divisor has a complexity formula_24 This implies that the fastest known algorithm has a complexity of formula_25

Previous complexities are valid for the usual models of computation, specifically multitape Turing machines and random-access machines.

The computation of the greatest common divisors belongs thus to the class of problems solvable in quasilinear time. "A fortiori", the corresponding decision problem belongs to the class P of problems solvable in polynomial time. The GCD problem is not known to be in NC, and so there is no known way to parallelize it efficiently; nor is it known to be P-complete, which would imply that it is unlikely to be possible to efficiently parallelize GCD computation. Shallcross et al. showed that a related problem (EUGCD, determining the remainder sequence arising during the Euclidean algorithm) is NC-equivalent to the problem of integer linear programming with two variables; if either problem is in NC or is P-complete, the other is as well. Since NC contains NL, it is also unknown whether a space-efficient algorithm for computing the GCD exists, even for nondeterministic Turing machines.

Although the problem is not known to be in NC, parallel algorithms asymptotically faster than the Euclidean algorithm exist; the fastest known deterministic algorithm is by Chor and Goldreich, which (in the CRCW-PRAM model) can solve the problem in time with processors. Randomized algorithms can solve the problem in time on formula_26 processors (this is superpolynomial).


In 1972, James E. Nymann showed that "k" integers, chosen independently and uniformly from {1, ..., "n"}, are coprime with probability 1/"ζ"("k") as "n" goes to infinity, where "ζ" refers to the Riemann zeta function. (See coprime for a derivation.) This result was extended in 1987 to show that the probability that "k" random integers have greatest common divisor "d" is "d"/ζ("k").

Using this information, the expected value of the greatest common divisor function can be seen (informally) to not exist when "k" = 2. In this case the probability that the gcd equals "d" is "d"/ζ(2), and since ζ(2) = π/6 we have

This last summation is the harmonic series, which diverges. However, when "k" ≥ 3, the expected value is well-defined, and by the above argument, it is

For "k" = 3, this is approximately equal to 1.3684. For "k" = 4, it is approximately 1.1106.

The notion of greatest common divisor can more generally be defined for elements of an arbitrary commutative ring, although in general there need not exist one for every pair of elements.

If is a commutative ring, and and are in , then an element of is called a "common divisor" of and if it divides both and (that is, if there are elements and in such that "d"·"x" = "a" and "d"·"y" = "b").
If is a common divisor of and , and every common divisor of and divides , then is called a "greatest common divisor" of and "b".

With this definition, two elements and may very well have several greatest common divisors, or none at all. If is an integral domain then any two gcd's of and must be associate elements, since by definition either one must divide the other; indeed if a gcd exists, any one of its associates is a gcd as well. Existence of a gcd is not assured in arbitrary integral domains. However, if is a unique factorization domain, then any two elements have a gcd, and more generally this is true in gcd domains.
If is a Euclidean domain in which euclidean division is given algorithmically (as is the case for instance when "R" = "F"["X"] where is a field, or when is the ring of Gaussian integers), then greatest common divisors can be computed using a form of the Euclidean algorithm based on the division procedure.

The following is an example of an integral domain with two elements that do not have a gcd:

The elements 2 and 1 +  are two maximal common divisors (that is, any common divisor which is a multiple of 2 is associated to 2, the same holds for 1 + , but they are not associated, so there is no greatest common divisor of and "b".

Corresponding to the Bézout property we may, in any commutative ring, consider the collection of elements of the form "pa" + "qb", where and range over the ring. This is the ideal generated by and , and is denoted simply ("a", "b"). In a ring all of whose ideals are principal (a principal ideal domain or PID), this ideal will be identical with the set of multiples of some ring element "d"; then this is a greatest common divisor of and "b". But the ideal ("a", "b") can be useful even when there is no greatest common divisor of and "b". (Indeed, Ernst Kummer used this ideal as a replacement for a gcd in his treatment of Fermat's Last Theorem, although he envisioned it as the set of multiples of some hypothetical, or "ideal", ring element , whence the ring-theoretic term.)






</doc>
<doc id="12357" url="https://en.wikipedia.org/wiki?curid=12357" title="Gazpacho">
Gazpacho

Gazpacho (; ), also called Andalusian gazpacho, is a cold soup made of raw, blended vegetables. It originated in the southern regions of the Iberian peninsula, specifically Andalusia, and spread into the Algarve regions. Gazpacho is widely eaten in Spain and Portugal, particularly during hot summers, as it is refreshing and cool.

While there are other recipes called "gazpacho", such as "gazpacho manchego", the standard usage implies Andalusian gazpacho. There are also a number of dishes that are closely related to Andalusian gazpacho and often considered variants thereof, such as ajoblanco, salmorejo, pipirrana, porra antequerana (closer to a bread soup), and cojondongo.

There are many theories as to the origin of gazpacho, including one that says it is a soup of bread, olive oil, water, vinegar and garlic that arrived in Spain with the Romans. Once in Spain, it became a part of Andalusian cuisine, particularly in Córdoba, Seville, and Granada, the Moorish Al-Andalus regions; using stale bread, garlic, olive oil, salt, and vinegar, similar to ajoblanco. During the 19th century, red gazpacho was created when tomatoes were added to the ingredients. This version spread internationally, and remains commonly known.

There are many modern variations of gazpacho with avocados, cucumbers, parsley, strawberries, watermelon, grapes, meat stock, seafood, and other ingredients instead of tomatoes and bread.

In Andalusia, most gazpacho recipes include stale bread, tomato, cucumbers, onion, capsicum, garlic, olive oil, wine vinegar, water, and salt. Northern recipes often include cumin and/or "pimentón" (smoked sweet paprika).

Traditionally, gazpacho was made by pounding the vegetables in a mortar with a pestle; this more laborious method is still sometimes used as it helps keep the gazpacho cool and avoids the foam and completely smooth consistency created by blenders or food processors. A traditional way of preparation is to pound garlic cloves in a mortar, add a little soaked stale bread, then olive oil and salt, to make a paste. Next, very ripe tomatoes and vinegar are added to this paste. In the days before refrigeration the gazpacho was left in an unglazed earthenware pot to cool by evaporation, with the addition of some water.

Gazpacho may be served alone or with garnishes, such as hard-boiled eggs, chopped ham (in the salmorejo variety from Córdoba), chopped almonds, cumin crushed with mint, orange segments, finely chopped green capsicum, onion, tomato or cucumber. In Extremadura, local ham was added to the gazpacho itself rather than as a garnish, this is called "gazpacho extremeño". Andalusian sources say that gazpacho should be slightly chilled, but not iced.

The ingredients, texture, and thickness of gazpacho vary regionally and between families.

Similar cold raw soups such as arjamolho in Portugal, porra antequerana and ajoblanco, are also popular in Andalusia, although not as widespread as gazpacho. Gazpacho and salmorejo are especially similar, since they are both tomato-based cold soups that are widely popular in Spain; the main difference between gazpacho and salmorejo is the culinary technique used since gazpacho is a soup whereas salmorejo is an emulsion. In addition, while both dishes share the main ingredients of tomato, olive oil, bread, and garlic, gazpacho can also be prepared with cucumber, peppers, and vinegar, whereas salmorejo cannot.

"Gazpacho manchego", despite its name, is a meat stew, served hot, not a variation on the cold vegetable soup.

The original recipe using bread, water, vinegar, oil and salt is traditional in the Iberian Peninsula, perhaps going back to Roman times. Every Andalusian region has its own variety. The humble gazpacho became a very deeply rooted food for peasants and shepherds in the south of Spain. The basic gazpacho gave rise to many variants, some also called gazpacho, others not; some authors have tried to classify all these variations. Gazpachos may be classified by colour: the most usual red ones (which contain tomato), white ones (which contain no tomato, but include dried fruits), and green ones (which are white but contain some spices that make them green). These variants have their basic ingredients in common, including garlic paste which works as an emulsifier, bread, olive oil, vinegar and salt. In addition to the traditional ingredients, red fruits such as strawberries, muskmelon, etc., may be added, making the gazpacho a bit sweeter. Gazpacho may be served as a starter, main dish, or tapa.

A popular variation comes from the town of Rota in the province of Cadiz. During times of drought there was not enough water to make gazpacho; thus, arranque has the same ingredients as gazpacho, but requires less water and bread, making it a sort of cream. Some people add more bread until it takes on the consistency of a dip.

In Extremadura, gazpachos are a kind of purée or thick gazpacho known as "cojondongo", or "cojondongo del gañán", made of breadcrumbs, garlic, oil, and vinegar, then topped with chopped onions, tomato and peppers.

Gazpacho manchego, as its name implies, is made in the east region of La Mancha, in Albacete and nearby areas, and is popular in other areas in the center and southwest of the country.

It is a meat stew, whose main ingredients are small game animals or birds such as rabbit, hare, quail, or pigeon, and flat bread, and may include garlic, tomatoes, and mushrooms. It is cooked in a cauldron and served hot. Another well-known variant in La Mancha is gazpacho de pastor or galiano.

Some other hot meat or fish dishes from other regions are called gazpacho (gazpacho jumillano, gazpacho de Yecla, gazpacho de Requena, etc.)

Gazpacho is often eaten during the very hot and dry summers in Castilla y León. The gazpacho made in La Moraña in the province of Ávila has large pieces of vegetables floating in a watery soup.



</doc>
<doc id="12359" url="https://en.wikipedia.org/wiki?curid=12359" title="Gopher (disambiguation)">
Gopher (disambiguation)

A gopher, also known as a "pocket gopher" (family Geomyidae), is a burrowing rodent native to North America and Central America.

Gopher may also refer to:






</doc>
<doc id="12361" url="https://en.wikipedia.org/wiki?curid=12361" title="Gnome">
Gnome

A gnome is a mythological creature and diminutive spirit in Renaissance magic and alchemy, first introduced by Paracelsus in the 16th century and later adopted by more recent authors including those of modern fantasy literature. Its characteristics have been reinterpreted to suit the needs of various story tellers, but it is typically said to be a small humanoid that lives underground.

The word comes from Renaissance Latin "gnomus", which first appears in "A Book on Nymphs, Sylphs, Pygmies, and Salamanders, and on the Other Spirits" by Paracelsus, published posthumously in Nysa in 1566 (and again in the Johannes Huser edition of 1589–1591 from an autograph by Paracelsus).

The term may be an original invention of Paracelsus, possibly deriving the term from Latin "gēnomos" (itself representing a Greek , literally "earth-dweller"). In this case, the omission of the "ē" is, as the Oxford English Dictionary (OED) calls it, a blunder. Paracelsus uses "Gnomi" as a synonym of "Pygmæi" and classifies them as earth elementals. He describes them as two spans high, very reluctant to interact with humans, and able to move through solid earth as easily as humans move through air.
The chthonic, or earth-dwelling, spirit has precedents in numerous ancient and medieval mythologies, often guarding mines and precious underground treasures, notably in the Germanic dwarfs and the Greek Chalybes, Telchines or Dactyls.

The English word is attested from the early 18th century. Gnomes are used in Alexander Pope's "The Rape of the Lock". The creatures from this mock-epic are small, celestial creatures which were prudish women in their past lives, and now spend all of eternity looking out for prudish women (in parallel to the guardian angels in Catholic belief). Other uses of the term "gnome" remain obscure until the early 19th century, when it is taken up by authors of Romanticist collections of fairy tales and becomes mostly synonymous with the older word "goblin".

Pope's stated source, the French satire (by Nicolas-Pierre-Henri de Montfaucon de Villars, the abbot of Villars) "Comte de Gabalis" (1670) describes gnomes as such:
"The Earth is filled almost to the Center with "Gnomes" or "Pharyes", a People of small Stature, the Guardians of Treasures, of Mines, and of Precious Stones. They are Ingenious, Friends of Men, and easie to be commandded. They furnish the Children of the "Sages" with as much Money, as they have need of; and never ask any other Reward of their Services, than the Glory of being Commanded. The "Gnomides" or Wives of these "Gnomes" or "Pharyes", are Little, but very Handson; and their Habit marvellously Curious."
Villars used the term "gnomide" to refer to female gnomes (often "gnomid" in English translations). Modern fiction instead uses the word "gnomess" to refer to female gnomes.

In 19th-century fiction, the chthonic gnome became a sort of antithesis to the more airy or luminous fairy. Nathaniel Hawthorne in "Twice-Told Tales" (1837) contrasts the two in "Small enough to be king of the fairies, and ugly enough to be king of the gnomes" (cited after OED). Similarly, gnomes are contrasted to elves, as in William Cullen Bryant's "Little People of the Snow" (1877), which has "let us have a tale of elves that ride by night, with jingling reins, or gnomes of the mine" (cited after OED).

One of the first movements in Mussorgsky's 1874 work "Pictures at an Exhibition", named "Gnomus" (Latin for "The Gnome"), is written to sound as if a gnome is moving about, his movements constantly changing in speed.
Franz Hartmann in 1895 satirized materialism in an allegorical tale entitled "Unter den Gnomen im Untersberg". The English translation appeared in 1896 as "Among the Gnomes: An Occult Tale of Adventure in the Untersberg". In this story, the "Gnomes" are still clearly subterranean creatures, guarding treasures of gold within the Untersberg mountain.

As a figure of 19th-century fairy tales, the term gnome became largely synonymous with other terms for "little people" by the 20th century, such as "goblin", "brownie", "kobold", "leprechaun", "Heinzelmännchen" and other instances of the "domestic spirit" type, losing its strict association with earth or the underground world.




After World War II (with early references, in ironic use, from the late 1930s) the diminutive figurines introduced as lawn ornaments during the 19th century came to be known as garden gnomes. The image of the gnome changed further during the 1960s to 1970s, when the first plastic garden gnomes were manufactured. These gnomes followed the style of the 1937 depiction of the seven dwarves in "Snow White and the Seven Dwarfs" by Disney. This "Disneyfied" image of the gnome was built upon by the illustrated children's book classic "The Secret Book of Gnomes" (1976), in the original Dutch "Leven en werken van de Kabouter". Garden gnomes share a resemblance to the Scandinavian tomte and nisse, and the Swedish term "tomte" can be translated as "gnome" in English.

Several gnome themed entertainment parks exist. Notable ones are:

Gnome parades are held annually at Atlanta's Inman Park Festival. Numerous one-off gnome parades have been held, including in Savannah, Georgia (April 2012) and Cleveland, Ohio (May 2011).




</doc>
<doc id="12365" url="https://en.wikipedia.org/wiki?curid=12365" title="Googolplex">
Googolplex

A googolplex is the number 10, or equivalently, 10. Written out in ordinary decimal notation, it is 1 followed by 10 zeroes, that is, a 1 followed by a googol zeroes.

In 1920, Edward Kasner's nine-year-old nephew, Milton Sirotta, coined the term "googol", which is 10, then proposed the further term "googolplex" to be "one, followed by writing zeroes until you get tired". Kasner decided to adopt a more formal definition because "different people get tired at different times and it would never do to have Carnera a better mathematician than Dr. Einstein, simply because he had more endurance and could write for longer". It thus became standardized to 10.

A typical book can be printed with 10 zeros (around 400 pages with 50 lines per page and 50 zeros per line). Therefore, it requires 10 such books to print all the zeros of a googolplex (that is, printing a googol zeros). If each book had a mass of 100 grams, all of them would have a total mass of 10 kilograms. In comparison, Earth's mass is 5.972 x 10 kilograms, the mass of the Milky Way Galaxy is estimated at 2.5 x 10 kilograms, and the mass of matter in the observable universe is estimated at 1.5 x 10 kg.

To put this in perspective, the mass of all such books required to write out a googolplex would be vastly greater than the masses of the Milky Way and the Andromeda galaxies combined (by a factor of roughly 2.0 x 10), and greater than the mass of the observable universe by a factor of roughly 7 x 10.

In pure mathematics, there are several notational methods for representing large numbers by which the magnitude of a googolplex could be represented, such as tetration, hyperoperation, Knuth's up-arrow notation, Steinhaus–Moser notation, or Conway chained arrow notation.

In the PBS science program "", , astronomer and television personality Carl Sagan estimated that writing a googolplex in full decimal form (i.e., "10,000,000,000...") would be physically impossible, since doing so would require more space than is available in the known universe.

One googol is presumed to be greater than the number of atoms in the observable universe, which has been estimated to be approximately 10. Thus, in the physical world, it is difficult to give examples of numbers that compare to the vastly greater googolplex. However, in analyzing quantum states and black holes, physicist Don Page writes that "determining experimentally whether or not information is lost down black holes of solar mass ... would require more than 10 measurements to give a rough determination of the final density matrix after a black hole evaporates". The end of the universe via Big Freeze without proton decay is expected to be around 10 years into the future.

In a separate article, Page shows that the number of states in a black hole with a mass roughly equivalent to the Andromeda Galaxy is in the range of a googolplex.

Writing the number would take an immense amount of time: if a person can write two digits per second, then writing a googolplex would take about 1.51 years, which is about 1.1 times the accepted age of the universe.

To measure a googolplex, Carl Sagan gave an example that if the entire volume of the observable universe is filled with fine dust particles roughly 1.5 micrometers in size (0.0015 millimeters), then the number of different combinations in which the particles could be arranged and numbered would be about one googolplex.

The residues (mod "n") of a googolplex, starting with mod 1, are:
This sequence is the same as the sequence of residues (mod "n") of a googol up until the 17th position.




</doc>
<doc id="12366" url="https://en.wikipedia.org/wiki?curid=12366" title="Graphite">
Graphite

Graphite (), archaically referred to as plumbago, is a crystalline form of the element carbon with its atoms arranged in a hexagonal structure. It occurs naturally in this form and is the most stable form of carbon under standard conditions. Under high pressures and temperatures it converts to diamond. Graphite is used in pencils and lubricants. It is a good conductor of heat and electricity. Its high conductivity makes it useful in electronic products such as electrodes, batteries, and solar panels. 

The principal types of natural graphite, each occurring in different types of ore deposits, are


Graphite occurs in metamorphic rocks as a result of the reduction of sedimentary carbon compounds during metamorphism. It also occurs in igneous rocks and in meteorites. Minerals associated with graphite include quartz, calcite, micas and tourmaline. The principal export sources of mined graphite are in order of tonnage: China, Mexico, Canada, Brazil, and Madagascar. 

In meteorites, graphite occurs with troilite and silicate minerals. Small graphitic crystals in meteoritic iron are called cliftonite. Some microscopic grains have distinctive isotopic compositions, indicating that they were formed before the Solar system. They are one of about 12 known types of mineral that predate the Solar System and have also been detected in molecular clouds. These minerals were formed in the ejecta when supernovae exploded or low- to intermediate-sized stars expelled their outer envelopes late in their lives. Graphite may be the second or third oldest mineral in the Universe. 

Solid carbon comes in different forms known as allotropes depending on the type of chemical bond. The two most common are diamond and graphite (less common ones include buckminsterfullerene). In diamond the bonds are sp and the atoms form tetrahedra with each bound to four nearest neighbors. In graphite they are sp orbital hybrids and the atoms form in planes with each bound to three nearest neighbors 120 degrees apart.

The individual layers are called graphene. In each layer, the carbon atoms are arranged in a honeycomb lattice with a bond length of 0.142 nm, and the distance between planes is 0.335 nm. Atoms in the plane are bonded covalently, with only three of the four potential bonding sites satisfied. The fourth electron is free to migrate in the plane, making graphite electrically conductive. Bonding between layers is via weak van der Waals bonds, which allows layers of graphite to be easily separated, or to slide past each other.
Electrical conductivity perpendicular to the layers is consequently about 1000 times lower.

The two known forms of graphite, "alpha" (hexagonal) and "beta" (rhombohedral), have very similar physical properties, except that the graphene layers stack slightly differently. The alpha graphite may be either flat or buckled. The alpha form can be converted to the beta form through mechanical treatment and the beta form reverts to the alpha form when it is heated above 1300 °C. Rhombohedral graphite thinner than 4 nm has a band gap even without applying an external electric field.

The equilibrium pressure and temperature conditions for a transition between graphite and diamond is well established theoretically and experimentally. The pressure changes linearly between at and at (the diamond/graphite/liquid triple point).
However, the phases have a wide region about this line where they can coexist. At normal temperature and pressure, and , the stable phase of carbon is graphite, but diamond is metastable and its rate of conversion to graphite is negligible. However, at temperatures above about , diamond rapidly converts to graphite. Rapid conversion of graphite to diamond requires pressures well above the equilibrium line: at , a pressure of is needed.

The acoustic and thermal properties of graphite are highly anisotropic, since phonons propagate quickly along the tightly bound planes, but are slower to travel from one plane to another. Graphite's high thermal stability and electrical and thermal conductivity facilitate its widespread use as electrodes and refractories in high temperature material processing applications. However, in oxygen-containing atmospheres graphite readily oxidizes to form carbon dioxide at temperatures of 700 °C and above.
Graphite is an electrical conductor, hence useful in such applications as arc lamp electrodes. It can conduct electricity due to the vast electron delocalization within the carbon layers (a phenomenon called aromaticity). These valence electrons are free to move, so are able to conduct electricity. However, the electricity is primarily conducted within the plane of the layers. The conductive properties of powdered graphite allow its use as pressure sensor in carbon microphones.

Graphite and graphite powder are valued in industrial applications for their self-lubricating and dry lubricating properties. There is a common belief that graphite's lubricating properties are solely due to the loose interlamellar coupling between sheets in the structure. However, it has been shown that in a vacuum environment (such as in technologies for use in space), graphite degrades as a lubricant, due to the hypoxic conditions. This observation led to the hypothesis that the lubrication is due to the presence of fluids between the layers, such as air and water, which are naturally adsorbed from the environment. This hypothesis has been refuted by studies showing that air and water are not absorbed. Recent studies suggest that an effect called superlubricity can also account for graphite's lubricating properties. The use of graphite is limited by its tendency to facilitate pitting corrosion in some stainless steel, and to promote galvanic corrosion between dissimilar metals (due to its electrical conductivity). It is also corrosive to aluminium in the presence of moisture. For this reason, the US Air Force banned its use as a lubricant in aluminium aircraft, and discouraged its use in aluminium-containing automatic weapons. Even graphite pencil marks on aluminium parts may facilitate corrosion. Another high-temperature lubricant, hexagonal boron nitride, has the same molecular structure as graphite. It is sometimes called "white graphite", due to its similar properties.

When a large number of crystallographic defects bind these planes together, graphite loses its lubrication properties and becomes what is known as pyrolytic graphite. It is also highly anisotropic, and diamagnetic, thus it will float in mid-air above a strong magnet. If it is made in a fluidized bed at 1000–1300 °C then it is isotropic turbostratic, and is used in blood contacting devices like mechanical heart valves and is called pyrolytic carbon, and is not diamagnetic. Pyrolytic graphite and pyrolytic carbon are often confused but are very different materials.

Natural and crystalline graphites are not often used in pure form as structural materials, due to their shear-planes, brittleness, and inconsistent mechanical properties.

In the 4th millennium BC, during the Neolithic Age in southeastern Europe, the Marița culture used graphite in a ceramic paint for decorating pottery.

Some time before 1565 (some sources say as early as 1500), an enormous deposit of graphite was discovered on the approach to Grey Knotts from the hamlet of Seathwaite in Borrowdale parish, Cumbria, England, which the locals found useful for marking sheep. During the reign of Elizabeth I (1558–1603), Borrowdale graphite was used as a refractory material to line moulds for cannonballs, resulting in rounder, smoother balls that could be fired farther, contributing to the strength of the English navy. This particular deposit of graphite was extremely pure and soft, and could easily be cut into sticks. Because of its military importance, this unique mine and its production were strictly controlled by the Crown.

During the 19th century, graphite's uses greatly expanded to include stove polish, lubricants, paints, crucibles, foundry facings, and pencils, a major factor in the expansion of educational tools during the first great rise of education for the masses. The British empire controlled most of the world's production (especially from Ceylon), but production from Austrian, German and American deposits expanded by mid-century. For example, the Dixon Crucible Company of Jersey City, New Jersey, founded by Joseph Dixon and partner Orestes Cleveland in 1845, opened mines in the Lake Ticonderoga district of New York, built a processing plant there, and a factory to manufacture pencils, crucibles and other products in New Jersey, described in the "Engineering & Mining Journal" 21 December 1878. The Dixon pencil is still in production.

The beginnings of the revolutionary froth flotation process are associated with graphite mining. Included in the "E&MJ" article on the Dixon Crucible Company is a sketch of the "floating tanks" used in the age-old process of extracting graphite. Because graphite is so light, the mix of graphite and waste was sent through a final series of water tanks where a cleaner graphite “floated” off, which left waste to drop out. In an 1877 patent, the two brothers Bessel (Adolph and August) of Dresden, Germany, took this "floating" process a step further and added a small amount of oil to the tanks and boiled the mix – an agitation or frothing step – to collect the graphite, the first steps toward the future flotation process. Adolph Bessel received the Wohler Medal for the patented process that upgraded the recovery of graphite to 90% from the German deposit. In 1977, the German Society of Mining Engineers and Metallurgists organized a special symposium dedicated to their discovery and, thus, the 100th anniversary of flotation.

In the United States, in 1885, Hezekiah Bradford of Philadelphia patented a similar process, but it is uncertain if his process was used successfully in the nearby graphite deposits of Chester County, Pennsylvania, a major producer by the 1890s. The Bessel process was limited in use, primarily because of the abundant cleaner deposits found around the globe, which needed not much more than hand-sorting to gather the pure graphite. The state of the art, ca. 1900, is described in the Canadian Department of Mines report on graphite mines and mining, when Canadian deposits began to become important producers of graphite. 

Historically, graphite was called black lead or plumbago. Plumbago was commonly used in its massive mineral form. Both of these names arise from confusion with the similar-appearing lead ores, particularly galena. The Latin word for lead, "plumbum", gave its name to the English term for this grey metallic-sheened mineral and even to the leadworts or plumbagos, plants with flowers that resemble this colour.

The term "black lead" usually refers to a powdered or processed graphite, matte black in color.

Abraham Gottlob Werner coined the name "graphite" ("writing stone") in 1789. He attempted to clear up the confusion between molybdena, plumbago and black lead after Carl Wilhelm Scheele in 1778 proved that there are at least three different minerals. Scheele's analysis showed that the chemical compounds molybdenum sulfide (molybdenite), lead(II) sulfide (galena) and graphite were three different soft black minerals.

Natural graphite is mostly used for refractories, batteries, steelmaking, expanded graphite, brake linings, foundry facings and lubricants. 

The use of graphite as a refractory (heat-resistant) material began before 1900 with the graphite crucible used to hold molten metal; this is now a minor part of refractories. In the mid-1980s, the carbon-magnesite brick became important, and a bit later the alumina-graphite shape. the order of importance is: alumina-graphite shapes, carbon-magnesite brick, monolithics (gunning and ramming mixes), and then crucibles.

Crucibles began using very large flake graphite, and carbon-magnesite brick requiring not quite so large flake graphite; for these and others there is now much more flexibility in the size of flake required, and amorphous graphite is no longer restricted to low-end refractories. Alumina-graphite shapes are used as continuous casting ware, such as nozzles and troughs, to convey the molten steel from ladle to mold, and carbon magnesite bricks line steel converters and electric-arc furnaces to withstand extreme temperatures. Graphite blocks are also used in parts of blast furnace linings where the high thermal conductivity of the graphite is critical. High-purity monolithics are often used as a continuous furnace lining instead of carbon-magnesite bricks.

The US and European refractories industry had a crisis in 2000–2003, with an indifferent market for steel and a declining refractory consumption per tonne of steel underlying firm buyouts and many plant closures. Many of the plant closures resulted from the acquisition of Harbison-Walker Refractories by RHI AG and some plants had their equipment auctioned off. Since much of the lost capacity was for carbon-magnesite brick, graphite consumption within the refractories area moved towards alumina-graphite shapes and monolithics, and away from brick. The major source of carbon-magnesite brick is now imports from China. Almost all of the above refractories are used to make steel and account for 75% of refractory consumption; the rest is used by a variety of industries, such as cement.

According to the USGS, US natural graphite consumption in refractories comprised 12,500 tonnes in 2010.

The use of graphite in batteries has increased since the 1970s. Natural and synthetic graphite are used as an anode material to construct electrodes in major battery technologies.

The demand for batteries, primarily nickel–metal hydride and lithium-ion batteries, caused a growth in demand for graphite in the late 1980s and early 1990s – a growth driven by portable electronics, such as portable CD players and power tools. Laptops, mobile phones, tablets, and smartphone products have increased the demand for batteries. Electric-vehicle batteries are anticipated to increase graphite demand. As an example, a lithium-ion battery in a fully electric Nissan Leaf contains nearly 40 kg of graphite.

Radioactive graphite from old nuclear reactors is being researched as fuel. Nuclear diamond battery has the potential for long duration energy supply for electronics and the internet of things.

Natural graphite in steelmaking mostly goes into raising the carbon content in molten steel; it can also serve to lubricate the dies used to extrude hot steel. Carbon additives face competitive pricing from alternatives such as synthetic graphite powder, petroleum coke, and other forms of carbon. A carbon raiser is added to increase the carbon content of steel to a specified level. An estimate based on USGS's graphite consumption statistics indicates that steelmakers in the US used 10,500 tonnes in this fashion in 2005.

Natural amorphous and fine flake graphite are used in brake linings or brake shoes for heavier (nonautomotive) vehicles, and became important with the need to substitute for asbestos. This use has been important for quite some time, but nonasbestos organic (NAO) compositions are beginning to reduce graphite's market share. A brake-lining industry shake-out with some plant closures has not been beneficial, nor has an indifferent automotive market. According to the USGS, US natural graphite consumption in brake linings was 6,510 tonnes in 2005.

A foundry facing mold wash is a water-based paint of amorphous or fine flake graphite. Painting the inside of a mold with it and letting it dry leaves a fine graphite coat that will ease separation of the object cast after the hot metal has cooled. Graphite lubricants are specialty items for use at very high or very low temperatures, as forging die lubricant, an antiseize agent, a gear lubricant for mining machinery, and to lubricate locks. Having low-grit graphite, or even better, no-grit graphite (ultra high purity), is highly desirable. It can be used as a dry powder, in water or oil, or as colloidal graphite (a permanent suspension in a liquid). An estimate based on USGS graphite consumption statistics indicates that 2,200 tonnes was used in this fashion in 2005. Metal can also be impregnated into graphite to create a self-lubricating alloy for application in extreme conditions, such as bearings for machines exposed to high or low temperatures.

The ability to leave marks on paper and other objects gave graphite its name, given in 1789 by German mineralogist Abraham Gottlob Werner. It stems from "graphein", meaning "to write" or "draw" in Ancient Greek.

From the 16th century, all pencils were made with leads of English natural graphite, but modern pencil lead is most commonly a mix of powdered graphite and clay; it was invented by Nicolas-Jacques Conté in 1795. It is chemically unrelated to the metal lead, whose ores had a similar appearance, hence the continuation of the name. Plumbago is another older term for natural graphite used for drawing, typically as a lump of the mineral without a wood casing. The term plumbago drawing is normally restricted to 17th and 18th century works, mostly portraits.

Today, pencils are still a small but significant market for natural graphite. Around 7% of the 1.1 million tonnes produced in 2011 was used to make pencils. Low-quality amorphous graphite is used and sourced mainly from China.

Natural graphite has found uses in zinc-carbon batteries, in electric motor brushes, and various specialized applications. Graphite of various hardness or softness results in different qualities and tones when used as an artistic medium. Railroads would often mix powdered graphite with waste oil or linseed oil to create a heat-resistant protective coating for the exposed portions of a steam locomotive's boiler, such as the smokebox or lower part of the firebox.

Expanded graphite is made by immersing natural flake graphite in a bath of chromic acid, then concentrated sulfuric acid, which forces the crystal lattice planes apart, thus expanding the graphite. The expanded graphite can be used to make graphite foil or used directly as "hot top" compound to insulate molten metal in a ladle or red-hot steel ingots and decrease heat loss, or as firestops fitted around a fire door or in sheet metal collars surrounding plastic pipe (during a fire, the graphite expands and chars to resist fire penetration and spread), or to make high-performance gasket material for high-temperature use. After being made into graphite foil, the foil is machined and assembled into the bipolar plates in fuel cells.
The foil is made into heat sinks for laptop computers which keeps them cool while saving weight, and is made into a foil laminate that can be used in valve packings or made into gaskets. Old-style packings are now a minor member of this grouping: fine flake graphite in oils or greases for uses requiring heat resistance. A GAN estimate of current US natural graphite consumption in this end use is 7,500 tonnes.

Graphite forms intercalation compounds with some metals and small molecules. In these compounds, the host molecule or atom gets "sandwiched" between the graphite layers, resulting in a type of compound with variable stoichiometry. A prominent example of an intercalation compound is potassium graphite, denoted by the formula KC. Some graphite intercalation compounds are superconductors. The highest transition temperature (by June 2009) "T" = 11.5 K is achieved in CaC, and it further increases under applied pressure (15.1 K at 8 GPa). Graphite's ability to intercalate lithium ions without significant damage from swelling is what makes it the dominant anode material in lithium-ion batteries.

In 1893, Charles Street of Le Carbone discovered a process for making artificial graphite. In the mid-1890s, Edward Goodrich Acheson (1856–1931) accidentally invented another way to produce synthetic graphite after synthesizing carborundum (silicon carbide or SiC). He discovered that overheating carborundum, as opposed to pure carbon, produced almost pure graphite. While studying the effects of high temperature on carborundum, he had found that silicon vaporizes at about 4,150 °C (7,500 °F), leaving the carbon behind in graphitic carbon. This graphite became valuable as a lubricant.

Acheson's technique for producing silicon carbide and graphite is named the Acheson process. In 1896, Acheson received a patent for his method of synthesizing graphite, and in 1897 started commercial production. The Acheson Graphite Co. was formed in 1899.

Highly oriented pyrolytic graphite (HOPG) is the highest-quality synthetic form of graphite. It is used in scientific research, in particular, as a length standard for scanner calibration of scanning probe microscope.

Graphite electrodes carry the electricity that melts scrap iron and steel, and sometimes direct-reduced iron (DRI), in electric arc furnaces, which are the vast majority of steel furnaces. They are made from petroleum coke after it is mixed with coal tar pitch. They are then extruded and shaped, baked to carbonize the binder (pitch), and finally graphitized by heating it to temperatures approaching 3000 °C, at which the carbon atoms arrange into graphite. They can vary in size up to long and in diameter. An increasing proportion of global steel is made using electric arc furnaces, and the electric arc furnace itself is becoming more efficient, making more steel per tonne of electrode. An estimate based on USGS data indicates that graphite electrode consumption was 197,000 tonnes in 2005.

Electrolytic aluminium smelting also uses graphitic carbon electrodes. On a much smaller scale, synthetic graphite electrodes are used in electrical discharge machining (EDM), commonly to make injection molds for plastics.

The powder is made by heating powdered petroleum coke above the temperature of graphitization, sometimes with minor modifications. The graphite scrap comes from pieces of unusable electrode material (in the manufacturing stage or after use) and lathe turnings, usually after crushing and sizing. Most synthetic graphite powder goes to carbon raising in steel (competing with natural graphite), with some used in batteries and brake linings. According to the USGS, US synthetic graphite powder and scrap production was 95,000 tonnes in 2001 (latest data).

Special grades of synthetic graphite, such as Gilsocarbon, also find use as a matrix and neutron moderator within nuclear reactors. Its low neutron cross-section also recommends it for use in proposed fusion reactors. Care must be taken that reactor-grade graphite is free of neutron absorbing materials such as boron, widely used as the seed electrode in commercial graphite deposition systems – this caused the failure of the Germans' World War II graphite-based nuclear reactors. Since they could not isolate the difficulty they were forced to use far more expensive heavy water moderators. Graphite used for nuclear reactors is often referred to as nuclear graphite.

Graphite (carbon) fiber and carbon nanotubes are also used in carbon fiber reinforced plastics, and in heat-resistant composites such as reinforced carbon-carbon (RCC). Commercial structures made from carbon fiber graphite composites include fishing rods, golf club shafts, bicycle frames, sports car body panels, the fuselage of the Boeing 787 Dreamliner and pool cue sticks and have been successfully employed in reinforced concrete, The mechanical properties of carbon fiber graphite-reinforced plastic composites and grey cast iron are strongly influenced by the role of graphite in these materials. In this context, the term "(100%) graphite" is often loosely used to refer to a pure mixture of carbon reinforcement and resin, while the term "composite" is used for composite materials with additional ingredients.

Modern smokeless powder is coated in graphite to prevent the buildup of static charge.

Graphite has been used in at least three radar absorbent materials. It was mixed with rubber in Sumpf and Schornsteinfeger, which were used on U-boat snorkels to reduce their radar cross section. It was also used in tiles on early F-117 Nighthawk stealth strike fighters.

Graphite composites are used as absorber for high-energy particles (e.g. in the LHC beam dump).

Graphite rods when filed into shape are used as a tool in glassworking to manipulate hot molten glass.

Graphite is mined by both open pit and underground methods. Graphite usually needs beneficiation. This may be carried out by hand-picking the pieces of gangue (rock) and hand-screening the product or by crushing the rock and floating out the graphite. Beneficiation by flotation encounters the difficulty that graphite is very soft and "marks" (coats) the particles of gangue. This makes the "marked" gangue particles float off with the graphite, yielding impure concentrate. There are two ways of obtaining a commercial concentrate or product: repeated regrinding and floating (up to seven times) to purify the concentrate, or by acid leaching (dissolving) the gangue with hydrofluoric acid (for a silicate gangue) or hydrochloric acid (for a carbonate gangue).
In milling, the incoming graphite products and concentrates can be ground before being classified (sized or screened), with the coarser flake size fractions (below 8 mesh, 8–20 mesh, 20–50 mesh) carefully preserved, and then the carbon contents are determined. Some standard blends can be prepared from the different fractions, each with a certain flake size distribution and carbon content. Custom blends can also be made for individual customers who want a certain flake size distribution and carbon content. If flake size is unimportant, the concentrate can be ground more freely. Typical end products include a fine powder for use as a slurry in oil drilling and coatings for foundry molds, carbon raiser in the steel industry (Synthetic graphite powder and powdered petroleum coke can also be used as carbon raiser). Environmental impacts from graphite mills consist of air pollution including fine particulate exposure of workers and also soil contamination from powder spillages leading to heavy metal contamination of soil.
According to the United States Geological Survey (USGS), world production of natural graphite in 2016 was 1,200,000 tonnes, of which the following major exporters are: China (780,000 t), India (170,000 t), Brazil (80,000 t), Turkey (32,000 t) and North Korea (6,000 t). Graphite is not yet mined in the United States. However, Westwater Resources is currently in the development stages of creating a pilot plant for their Coosa Graphite Mine near Sylacauga, Alabama. U.S. production of synthetic graphite in 2010 was 134,000 t valued at $1.07 billion.

People can be exposed to graphite in the workplace by breathing it in, skin contact, and eye contact.

The Occupational Safety and Health Administration (OSHA) has set the legal limit (permissible exposure limit) for graphite exposure in the workplace as a time weighted average (TWA) of 15 million particles per cubic foot (1.5 mg/m) over an 8-hour workday. The National Institute for Occupational Safety and Health (NIOSH) has set a recommended exposure limit (REL) of TWA 2.5 mg/m respirable dust over an 8-hour workday. At levels of 1250 mg/m, graphite is immediately dangerous to life and health.

The most common way of recycling graphite occurs when synthetic graphite electrodes are either manufactured and pieces are cut off or lathe turnings are discarded, or the electrode (or other) are used all the way down to the electrode holder. A new electrode replaces the old one, but a sizeable piece of the old electrode remains. This is crushed and sized, and the resulting graphite powder is mostly used to raise the carbon content of molten steel. Graphite-containing refractories are sometimes also recycled, but often not because of their graphite: the largest-volume items, such as carbon-magnesite bricks that contain only 15–25% graphite, usually contain too little graphite. However, some recycled carbon–magnesite brick is used as the basis for furnace-repair materials, and also crushed carbon–magnesite brick is used in slag conditioners. While crucibles have a high graphite content, the volume of crucibles used and then recycled is very small.

A high-quality flake graphite product that closely resembles natural flake graphite can be made from steelmaking kish. Kish is a large-volume near-molten waste skimmed from the molten iron feed to a basic oxygen furnace, and consists of a mix of graphite (precipitated out of the supersaturated iron), lime-rich slag, and some iron. The iron is recycled on site, leaving a mixture of graphite and slag. The best recovery process uses hydraulic classification (which utilizes a flow of water to separate minerals by specific gravity: graphite is light and settles nearly last) to get a 70% graphite rough concentrate. Leaching this concentrate with hydrochloric acid gives a 95% graphite product with a flake size ranging from 10 mesh down.




</doc>
<doc id="12367" url="https://en.wikipedia.org/wiki?curid=12367" title="Garry Trudeau">
Garry Trudeau

Garretson Beekman Trudeau (born July 21, 1948) is an American cartoonist, best known for creating the "Doonesbury" comic strip. Trudeau is also the creator and executive producer of the Amazon Studios political comedy series "Alpha House".

Trudeau was born in New York City, the son of Jean Douglas (née Moore) and Francis Berger Trudeau Jr. He is the great-grandson of Edward Livingston Trudeau, who created Adirondack Cottage Sanitarium for the treatment of pulmonary tuberculosis at Saranac Lake, New York. Edward was succeeded by his son Francis and grandson Francis Jr. The latter founded the Trudeau Institute at Saranac Lake, with which his son Garry retains a connection.

His ancestry is French Canadian, English, Dutch, German, and Swedish.

Raised in Saranac Lake, Trudeau attended St. Paul's School in Concord, New Hampshire. He enrolled in Yale University in 1966. As an art major, Trudeau initially focused on painting, but soon discovered a greater interest in the graphic arts. He spent much of his time cartooning and writing for Yale's humor magazine "The Yale Record", eventually serving as the magazine's editor-in-chief. At the same time, Trudeau began contributing to the "Yale Daily News", which eventually led to the creation of "Bull Tales", a comic strip parodying the exploits of Yale quarterback Brian Dowling. This strip was the progenitor of "Doonesbury".

While still an undergraduate at Yale, Trudeau published two collections of "Bull Tales": "Bull Tales" (1969, published by the "Yale Daily News") and "Michael J." (1970, published by "The Yale Record").

As a senior, Trudeau became a member of Scroll and Key. He did postgraduate work at the Yale School of Art, earning a master of fine arts degree in graphic design in 1973. It was there that Trudeau first met photographer David Levinthal, with whom he collaborated on "Hitler Moves East", an influential "graphic chronicle" of the German invasion of the Soviet Union.

Soon after "Bull Tales" began running in the Yale student newspaper, the strip caught the attention of the newly formed Universal Press Syndicate. The syndicate's editor, James F. Andrews, recruited Trudeau, changed the strip's name to "Doonesbury", and began distributing it following the cartoonist's graduation in 1970. Today "Doonesbury" is syndicated to 1,000 daily and Sunday newspapers worldwide and is accessible online in association with "The Washington Post".

In 1975, Trudeau became the first comic strip artist to win a Pulitzer, traditionally awarded to editorial-page cartoonists. He was also a Pulitzer finalist in 1990, 2004, and 2005. Other awards include the National Cartoonist Society Newspaper Comic Strip Award in 1994, and the Reuben Award in 1995. In 1993, Trudeau was made a fellow of the American Academy of Arts and Sciences. Wiley Miller, fellow comic-strip artist responsible for "Non Sequitur", called him "far and away the most influential editorial cartoonist in the last 25 years". A regular graduation speaker, Trudeau has received 35 honorary degrees.

In addition to his creating his strip, Trudeau has worked in both theater and television. He was nominated for an Oscar in 1977 in the category of Animated Short Film for "A Doonesbury Special", created for NBC in collaboration with John and Faith Hubley. The film won the Cannes Film Festival Jury Special Prize in 1978. In 1984, with composer Elizabeth Swados, he wrote the book and lyrics for the Broadway musical "Doonesbury", for which he was nominated for two Drama Desk Awards. A cast album of the show, recorded for MCA, received a Grammy nomination. Trudeau again collaborated with Swados in 1984, this time on "Rap Master Ronnie", a satirical review about the Reagan Administration that opened off-Broadway at the Village Gate. A filmed version, featuring Jon Cryer, the Smothers Brothers, and Carol Kane, was broadcast on Cinemax in 1988.

Also in 1988, Trudeau wrote and co-produced with director Robert Altman HBO's critically acclaimed "Tanner '88", a satiric look at that year's presidential election campaign. The show won the gold medal for Best Television Series at the Cannes Television Festival, the British Academy Television Award for Best Foreign Program, and Best Imported Program from the British Broadcasting Press Guild. It earned an Emmy Award, as well as four ACE Award nominations. In 2004, Trudeau reunited with Altman to write and co-produce a sequel mini-series, "Tanner on Tanner", for the Sundance Channel.

In 1996, "Newsweek" and the "Washington Post" speculated that Trudeau had written the novel "Primary Colors", which was later revealed to have been written by Joe Klein. In February 2000, Trudeau, working with Dotcomix, launched "Duke2000", a web-based presidential campaign featuring a real-time, 3-D, streaming-animation version of Duke. Nearly 30 campaign videos were created for the site, and Ambassador Duke was interviewed live by satellite on the "Today Show, Larry King Live, The Charlie Rose Show", and dozens of local TV and radio news shows.

In 2013, Trudeau created, wrote and co-produced "Alpha House", a political sitcom starring John Goodman that revolves around four Republican U.S. Senators who live together in a townhouse on Capitol Hill. Trudeau was inspired to write the show's pilot after reading a 2007 "New York Times" article about a real D.C. townhouse shared by New York Senator Chuck Schumer, Illinois Senator Dick Durbin of Illinois, and California Representative George Miller, all Democrats. The pilot for "Alpha House" was produced by Amazon Studios and aired in early 2013. Due to positive response, Amazon picked up the show to develop into a full series, streaming eleven episodes for its first season. On March 31, 2014, Amazon announced that "Alpha House" had been renewed. Production began in July 2014, and the entire second season became available for streaming on October 24, 2014.

While writing "Alpha House", Trudeau put the daily Doonesbury into rerun mode. On March 3, 2014 the "Classic Doonesbury" series began, featuring approximately four weeks of daily strips from each year of the strip's run. He continues to produce new strips for Sundays. Although "Alpha House" has not been in production since the end of 2014, Trudeau has not returned to creating daily "Doonesbury" strips; new material remains a Sunday-only event.

Trudeau has contributed to such publications as "Harper's", "Rolling Stone", "The New Republic", "The New Yorker", "New York", and "The Washington Post". From 1990–94, he wrote and drew an occasional column for "The New York Times" op-ed page, and was a contributing essayist for "Time" magazine from 1996 to 2001.

Beginning with the Gulf War in 1991, Trudeau has written about military issues extensively. In recognition for his work on wounded warriors, he has been presented with the Commander's Award for Public Service by the Department of the Army, the Commander's Award from Disabled American Veterans, the President's Award for Excellence in the Arts from Vietnam Veterans of America, the Distinguished Public Service Award from the American Academy of Physical Medicine and Rehabilitation, the Mental Health Research Advocacy Award from the Yale School of Medicine, and a special citation from the Vet Centers.

He received several unit commendations from the field during the Gulf War, and he traveled with the USO to visit troops in Iraq and Afghanistan. From 2005 to 2014, his website hosted "The Sandbox", a milblog posting over 800 essays by deployed soldiers, returned vets, caregivers, and spouses. For most of the strip's run, Trudeau has eschewed merchandising, but starting in 1998 he teamed up with Starbucks to create "Doonesbury" products to raise funds for local literacy programs. The items were offered for sale in Starbucks stores for nearly two years and raised over $1 million. Also for charity, Trudeau licensed the strip to Ben & Jerry's, which created a best-selling sorbet flavor called "Doonesberry".

Garry Trudeau's son Ross, a digital media producer, is also a crossword constructor who has been published in the New York Times. As part of the ongoing celebrity partnership series, Ross and Garry collaborated on a crossword puzzle that was published on Tues. May 15, 2018 in the NYT. This is the 6th NYT puzzle for Ross and the 1st for Garry.

Trudeau married Jane Pauley in 1980; they have three children. He maintains a low personal profile. A rare early appearance on television was as a guest on "To Tell the Truth" in 1971, where only one of the three panelists guessed his identity. In 1990, Trudeau appeared on the cover of "Newsweek" for "Inside Doonesbury's Brain", a story written by Jonathan Alter. This was the first interview Trudeau had given in seventeen years.

Trudeau cooperated extensively with "Wired" magazine for a 2000 profile, "The Revolution Will be Satirized". He later spoke with the writer of that article, Edward Cone, for a 2004 newspaper column in the Greensboro, North Carolina "News & Record", about the war wounds suffered by the Doonesbury character "B.D.", and in 2006 did a Q&A at Cone's personal blog about The Sandbox. Trudeau granted an interview to "Rolling Stone" in 2004 in which he discussed his time at Yale University, which he attended two years behind George W. Bush. He granted another "Rolling Stone" interview in 2010. In 2006, "The Washington Post" printed an extensive profile of Trudeau by writer Gene Weingarten. He appeared on the "Charlie Rose" television program, and at signings for "The Long Road Home: One Step at a Time", his "Doonesbury" book about B.D.'s struggle with injuries received during the second Gulf War.

On August 1, 2016, Trudeau appeared on MSNBC on "The Rachel Maddow Show". He was brought on to discuss his ability to predict and accurately write about Donald Trump's plans to run for president almost three decades earlier. Maddow presented cartoon strips from as far back as 1987. Trudeau was on her show to promote his new book "Yuge", which covers 30 years of Trump appearing in "Doonesbury". On November 7, 2016, Trudeau appeared on "Fresh Air" with Terry Gross to discuss "Yuge". On the "CBS News Sunday Morning" broadcast of December 2, 2018 he was featured and was interviewed by his wife, Jane Pauley.

Trudeau has attracted criticism both for the comic strip and for his own opinions. The "Saturday Review" once voted Trudeau one of the "Most Overrated People in American Arts and Letters", stating that after his hiatus, his comic strip was "predictable, mean-spirited, and not as funny as before."

Eric Alterman, writing in "The Nation", called "Doonesbury" "one of the great intellectual/artistic accomplishments of the past half-century, irrespective of category".

Trudeau's acceptance speech on the occasion of receiving a Polk Award in 2015 for lifetime achievement stirred controversy. In the speech, Trudeau criticized the cartoonists of "Charlie Hebdo"—after a number of "Charlie Hebdo" writers, editors and cartoonists had been murdered execution style in their own Paris offices by Muslim terrorists—for "punching downward..., attacking a powerless, disenfranchised minority with crude, vulgar drawings closer to graffiti than cartoons", and thereby wandering "into the realm of hate speech" with cartoons of Muhammad. Writing in "The Atlantic", in which Trudeau had published his speech, political commentator David Frum criticized what he called Trudeau's "moral theory" that calls for identifying "the bearer of privilege", then holding "the privilege-bearer responsible". Trudeau was labelled a "terror apologist" by the editors of "The New York Post" for his comments, with his choice of the venue in which to make them "adding to the insult".




</doc>
<doc id="12369" url="https://en.wikipedia.org/wiki?curid=12369" title="Guild">
Guild

A guild is an association of artisans and merchants who oversee the practice of their craft/trade in a particular area. The earliest types of guild formed as confraternities of tradesmen, normally operating in a single city and covering a single trade. They were organized in a manner something between a professional association, a trade union, a cartel, and a secret society. They sometimes depended on grants of letters patent from a monarch or other ruler to enforce the flow of trade to their self-employed members, and to retain ownership of tools and the supply of materials, but were generally regulated by the city government. A lasting legacy of traditional guilds are the guildhalls constructed and used as guild meeting-places. Guild members found guilty of cheating on the public would be fined or banned from the guild.

Typically the key "privilege" was that only guild members were allowed to sell their goods or practice their skill within the city. There might be controls on minimum or maximum prices, hours of trading, numbers of apprentices, and many other things. As well as reducing free competition, but sometimes maintaining a good quality of work, often these rules made it difficult or impossible for women, immigrants to the city, and non-Christians to run businesses working in the trade. 

An important result of the guild framework was the emergence of universities at Bologna (established in 1088), Oxford (at least since 1096) and Paris (c. 1150); they originated as guilds of students (as at Bologna) or of masters (as at Paris).

A type of guild was known in Roman times. Known as "collegium", "collegia" or "corpus", these were organised groups of merchants who specialised in a particular craft and whose membership of the group was voluntary. One such example is the "corpus naviculariorum", the college of long-distance shippers based at Rome's La Ostia port. The Roman guilds failed to survive the collapse of the Roman Empire.

In medieval cities, craftsmen tended to form associations based on their trades, confraternities of textile workers, masons, carpenters, carvers, glass workers, each of whom controlled secrets of traditionally imparted technology, the "arts" or "mysteries" of their crafts. Usually the founders were free independent master craftsmen who hired apprentices.

There were several types of guilds, including the two main categories of merchant guilds and craft guilds but also the frith guild and religious guild. Guilds arose beginning in the High Middle Ages as craftsmen united to protect their common interests. In the German city of Augsburg craft guilds are mentioned in the Towncharter of 1156.

The continental system of guilds and merchants arrived in England after the Norman Conquest, with incorporated societies of merchants in each town or city holding exclusive rights of doing business there. In many cases they became the governing body of a town. For example, London's Guildhall became the seat of the Court of Common Council of the City of London Corporation, the world's oldest continuously elected local government, whose members to this day must be Freemen of the City. The Freedom of the City, effective from the Middle Ages until 1835, gave the right to trade, and was only bestowed upon members of a Guild or Livery.

Early egalitarian communities called "guilds" were denounced by Catholic clergy for their "conjurations" — the binding oaths sworn among the members to support one another in adversity, kill specific enemies, and back one another in feuds or in business ventures. The occasion for these oaths were drunken banquets held on December 26, the pagan feast of Jul (Yule)—in 858, West Francian Bishop Hincmar sought vainly to Christianise the guilds.

In the Early Middle Ages, most of the Roman craft organisations, originally formed as religious confraternities, had disappeared, with the apparent exceptions of stonecutters and perhaps glassmakers, mostly the people that had local skills. Gregory of Tours tells a miraculous tale of a builder whose art and techniques suddenly left him, but were restored by an apparition of the Virgin Mary in a dream. Michel Rouche remarks that the story speaks for the importance of practically transmitted journeymanship.

In France, guilds were called "corps de métiers". According to Viktor Ivanovich Rutenburg, "Within the guild itself there was very little division of labour, which tended to operate rather between the guilds. Thus, according to Étienne Boileau's Book of Handicrafts, by the mid-13th century there were no less than 100 guilds in Paris, a figure which by the 14th century had risen to 350." There were different guilds of metal-workers: the farriers, knife-makers, locksmiths, chain-forgers, nail-makers, often formed separate and distinct corporations; the armourers were divided into helmet-makers, escutcheon-makers, harness-makers, harness-polishers, etc. In Catalan towns, specially at Barcelona, guilds or "gremis" were a basic agent in the society: a shoemakers' guild is recorded in 1208.

In England, specifically in the City of London Corporation, more than 110 guilds, referred to as livery companies, survive today, with the oldest more than a thousand years old. Other groups, such as the Worshipful Company of Tax Advisers, have been formed far more recently. Membership in a livery company is expected for individuals participating in the governance of "The City", as the Lord Mayor and the Remembrancer.

The guild system reached a mature state in Germany circa 1300 and held on in German cities into the 19th century, with some special privileges for certain occupations remaining today. In the 15th century, Hamburg had 100 guilds, Cologne 80, and Lübeck 70. The latest guilds to develop in Western Europe were the "" of Spain: e.g., Valencia (1332) or Toledo (1426).

Not all city economies were controlled by guilds; some cities were "free." Where guilds were in control, they shaped labor, production and trade; they had strong controls over instructional capital, and the modern concepts of a lifetime progression of apprentice to craftsman, and then from journeyman eventually to widely recognized master and grandmaster began to emerge. In order to become a master, a journeyman would have to go on a three-year voyage called journeyman years. The practice of the journeyman years still exists in Germany and France.

As production became more specialized, trade guilds were divided and subdivided, eliciting the squabbles over jurisdiction that produced the paperwork by which economic historians trace their development: The metalworking guilds of Nuremberg were divided among dozens of independent trades in the boom economy of the 13th century, and there were 101 trades in Paris by 1260. In Ghent, as in Florence, the woolen textile industry developed as a congeries of specialized guilds. The appearance of the European guilds was tied to the emergent money economy, and to urbanization. Before this time it was not possible to run a money-driven organization, as commodity money was the normal way of doing business.
The guild was at the center of European handicraft organization into the 16th century. In France, a resurgence of the guilds in the second half of the 17th century is symptomatic of Louis XIV and Jean Baptiste Colbert's administration's concerns to impose unity, control production, and reap the benefits of transparent structure in the shape of efficient taxation.

The guilds were identified with organizations enjoying certain privileges (letters patent), usually issued by the king or state and overseen by local town business authorities (some kind of chamber of commerce). These were the predecessors of the modern patent and trademark system. The guilds also maintained funds in order to support infirm or elderly members, as well as widows and orphans of guild members, funeral benefits, and a 'tramping' allowance for those needing to travel to find work. As the guild system of the City of London declined during the 17th century, the Livery Companies transformed into mutual assistance fraternities along such lines.

European guilds imposed long standardized periods of apprenticeship, and made it difficult for those lacking the capital to set up for themselves or without the approval of their peers to gain access to materials or knowledge, or to sell into certain markets, an area that equally dominated the guilds' concerns. These are defining characteristics of mercantilism in economics, which dominated most European thinking about political economy until the rise of classical economics.

The guild system survived the emergence of early capitalists, which began to divide guild members into "haves" and dependent "have-nots". The civil struggles that characterize the 14th-century towns and cities were struggles in part between the greater guilds and the lesser artisanal guilds, which depended on piecework. "In Florence, they were openly distinguished: the "Arti maggiori" and the "Arti minori"—already there was a "popolo grasso" and a "popolo magro"". Fiercer struggles were those between essentially conservative guilds and the merchant class, which increasingly came to control the means of production and the capital that could be ventured in expansive schemes, often under the rules of guilds of their own. German social historians trace the "Zunftrevolution", the urban revolution of guildmembers against a controlling urban patriciate, sometimes reading into them, however, perceived foretastes of the class struggles of the 19th century.
In the countryside, where guild rules did not operate, there was freedom for the entrepreneur with capital to organize cottage industry, a network of cottagers who spun and wove in their own premises on his account, provided with their raw materials, perhaps even their looms, by the capitalist who took a share of the profits. Such a dispersed system could not so easily be controlled where there was a vigorous local market for the raw materials: wool was easily available in sheep-rearing regions, whereas silk was not.

In Florence, Italy, there were seven to twelve "greater guilds" and fourteen "lesser guilds" the most important of the greater guilds was that for judges and notaries, who handled the legal business of all the other guilds and often served as an arbitrator of disputes. Other greater guilds include the wool, silk, and the money changers' guilds. They prided themselves on a reputation for very high-quality work, which was rewarded with premium prices. The guilds fined members who deviated from standards. Other greater guilds included those of doctors, druggists, and furriers. Among the lesser guilds, were those for bakers, saddle makers, ironworkers and other artisans. They had a sizable membership, but lacked the political and social standing necessary to influence city affairs.

The guild was made up by experienced and confirmed experts in their field of handicraft. They were called master craftsmen. Before a new employee could rise to the level of mastery, he had to go through a schooling period during which he was first called an apprentice. After this period he could rise to the level of journeyman. Apprentices would typically not learn more than the most basic techniques until they were trusted by their peers to keep the guild's or company's secrets.

Like "journey", the distance that could be travelled in a day, the title 'journeyman' derives from the French words for 'day' ("jour" and "journée") from which came the middle English word "journei". Journeymen were able to work for other masters, unlike apprentices, and generally paid by the day and were thus day labourers. After being employed by a master for several years, and after producing a qualifying piece of work, the apprentice was granted the rank of journeyman and was given documents (letters or certificates from his master and/or the guild itself) which certified him as a journeyman and entitled him to travel to other towns and countries to learn the art from other masters. These journeys could span large parts of Europe and were an unofficial way of communicating new methods and techniques, though by no means all journeymen made such travels — they were most common in Germany and Italy, and in other countries journeymen from small cities would often visit the capital.
After this journey and several years of experience, a journeyman could be received as master craftsman, though in some guilds this step could be made straight from apprentice. This would typically require the approval of all masters of a guild, a donation of money and other goods (often omitted for sons of existing members), and the production of a so-called "masterpiece,' which would illustrate the abilities of the aspiring master craftsman; this was often retained by the guild.

The medieval guild was established by charters or letters patent or similar authority by the city or the ruler and normally held a monopoly on trade in its craft within the city in which it operated: handicraft workers were forbidden by law to run any business if they were not members of a guild, and only masters were allowed to be members of a guild. Before these privileges were legislated, these groups of handicraft workers were simply called 'handicraft associations'.

The town authorities might be represented in the guild meetings and thus had a means of controlling the handicraft activities. This was important since towns very often depended on a good reputation for export of a narrow range of products, on which not only the guild's, but the town's, reputation depended. Controls on the association of physical locations to well-known exported products, e.g. wine from the Champagne and Bordeaux regions of France, tin-glazed earthenwares from certain cities in Holland, lace from Chantilly, etc., helped to establish a town's place in global commerce — this led to modern trademarks.

In many German and Italian cities, the more powerful guilds often had considerable political influence, and sometimes attempted to control the city authorities. In the 14th century, this led to numerous bloody uprisings, during which the guilds dissolved town councils and detained patricians in an attempt to increase their influence. In fourteenth-century north-east Germany, people of Wendish, i.e. Slavic, origin were not allowed to join some guilds. According to Wilhelm Raabe, ""down into the eighteenth century no German guild accepted a Wend.""

Ogilvie (2004) argues that guilds negatively affected quality, skills, and innovation. Through what economists now call "rent-seeking" they imposed deadweight losses on the economy. Ogilvie argues they generated limited positive externalities and notes that industry began to flourish only after the guilds faded away. Guilds persisted over the centuries because they redistributed resources to politically powerful merchants. On the other hand, Ogilvie agrees, guilds created "social capital" of shared norms, common information, mutual sanctions, and collective political action. This social capital benefited guild members, even as it arguably hurt outsiders.

The guild system became a target of much criticism towards the end of the 18th century and the beginning of the 19th century. Critics argued that they hindered free trade and technological innovation, technology transfer and business development. According to several accounts of this time, guilds became increasingly involved in simple territorial struggles against each other and against free practitioners of their arts.

Two of the most outspoken critics of the guild system were Jean-Jacques Rousseau and Adam Smith, and all over Europe a tendency to oppose government control over trades in favour of laissez-faire free market systems grew rapidly and made its way into the political and legal systems. Many people who participated in the French Revolution saw guilds as a last remnant of feudalism. The Le Chapelier Law of 1791 abolished the guilds in France. Smith wrote in "The Wealth of Nations" (Book I, Chapter X, paragraph 72):

Karl Marx in his "Communist Manifesto" also criticized the guild system for its rigid gradation of social rank and the relation of oppressor/oppressed entailed by this system. It was the 18th and 19th centuries that saw the beginning of the low regard in which some people hold the guilds to this day. In part due to their own inability to control unruly corporate behavior, the tide of public opinion turned against the guilds.

Because of industrialization and modernization of the trade and industry, and the rise of powerful nation-states that could directly issue patent and copyright protections — often revealing the trade secrets — the guilds' power faded. After the French Revolution they gradually fell in most European nations over the course of the 19th century, as the guild system was disbanded and replaced by laws that promoted free trade. As a consequence of the decline of guilds, many former handicraft workers were forced to seek employment in the emerging manufacturing industries, using not closely guarded techniques formerly protected by guilds, but rather the standardized methods controlled by corporations.
Interest in the medieval guild system was revived during the late 19th century, among far right circles. Fascism in Italy (among other countries) implemented corporatism, operating at the national rather than city level, to try to imitate the corporatism of the Middle Ages.

Guilds are sometimes said to be the precursors of modern trade unions. Guilds, however, can also be seen as a set of self-employed skilled craftsmen with ownership and control over the materials and tools they needed to produce their goods. Some argue that guilds operated more like cartels than they were like trade unions (Olson 1982). However, the journeymen organizations, which were at the time illegal, may have been influential.

The exclusive privilege of a guild to produce certain goods or provide certain services was similar in spirit and character with the original patent systems that surfaced in England in 1624. These systems played a role in ending the guilds' dominance, as trade secret methods were superseded by modern firms directly revealing their techniques, and counting on the state to enforce their legal monopoly.

Some guild traditions still remain in a few handicrafts, in Europe especially among shoemakers and barbers. Some ritual traditions of the guilds were preserved in order organisations such as the Freemasons, allegedly deriving from the Masons Guild, and the Oddfellows, allegedly derived from various smaller guilds. These are, however, not very important economically except as reminders of the responsibilities of some trades toward the public.

Modern antitrust law could be said to derive in some ways from the original statutes by which the guilds were abolished in Europe.

The economic consequences of guilds have led to heated debates among economic historians. On the one side, scholars say that since merchant guilds persisted over long periods they must have been efficient institutions (since inefficient institutions die out). Others say they persisted not because they benefited the entire economy but because they benefited the owners, who used political power to protect them. Ogilvie (2011) says they regulated trade for their own benefit, were monopolies, distorted markets, fixed prices, and restricted entrance into the guild. Ogilvie (2008) argues that their long apprenticeships were unnecessary to acquire skills, and their conservatism reduced the rate of innovation and made the society poorer. She says their main goal was rent seeking, that is, to shift money to the membership at the expense of the entire economy.

Epstein and Prak's book (2008) rejects Ogilvie's conclusions. Specifically, Epstein argues that guilds were cost-sharing rather than rent-seeking institutions. They located and matched masters and likely apprentices through monitored learning. Whereas the acquisition of craft skills required experience-based learning, he argues that this process necessitated many years in apprenticeship.

The extent to which guilds were able to monopolize markets is also debated.

For the most part, medieval guilds limited women's participation, and usually only the widows and daughters of known masters were allowed in. Even if a woman entered a guild, she was excluded from guild offices. It's important to note that while this was the overarching practice, there were guilds and professions that did allow women's participation, and that the Medieval era was an ever-changing, mutable society—especially considering that it spanned hundreds of years and many different cultures. There were multiple accounts of women's participation in guilds in England and the Continent. In a study of London silkwomen of the 15th century by Marian K. Dale, she notes that medieval women could inherit property, belong to guilds, manage estates, and run the family business if widowed. The "Livre des métiers de Paris (Book of Trades of Paris)" was compiled by Étienne Boileau, the Grand Provost of Paris under King Louis IX. It documents that 5 out of 110 Parisian guilds were female monopolies, and that only a few guilds systematically excluded women. Boileau notes that some professions were also open to women: surgeons, glass-blowers, chain-mail forgers. Entertainment guilds also had a significant number of women members. John, Duke of Berry documents payments to female musicians from Le Puy, Lyons, and Paris.

Women did have problems with entering healers' guilds, as opposed to their relative freedom in trade or craft guilds. Their status in healers' guilds were often challenged. The idea that medicine should only be practice by men was supported by some religious and secular authorities at the time. It is believed that the Inquisition and witch hunts throughout the ages contributed to the lack of women in medical guilds.

Professional organizations replicate guild structure and operation.
Professions such as architecture, engineering, geology, and land surveying require varying lengths of apprenticeships before one can gain a "professional" certification. These certifications hold great legal weight: most states make them a prerequisite to practicing there.

Thomas W. Malone champions a modern variant of the guild structure for modern "e-lancers", professionals who do mostly telework for multiple employers. Insurance including any professional liability, intellectual capital protections, an ethical code perhaps enforced by peer pressure and software, and other benefits of a strong association of producers of knowledge, benefit from economies of scale, and may prevent cut-throat competition that leads to inferior services undercutting prices. And, as with historical guilds, such a structure will resist foreign competition. The free software community has from time to time explored a guild-like structure to unite against competition from Microsoft, e.g. Advogato assigns journeyer and master ranks to those committing to work only or mostly on free software.

In many European countries guilds have experienced a revival as local trade organizations for craftsmen, primarily in traditional skills. They may function as forums for developing competence and are often the local units of a national employer's organisation.

In the City of London, the ancient guilds survive as livery companies, all of which play a ceremonial role in the City's many customs. The City of London livery companies maintain strong links with their respective trade, craft or profession, some still retain regulatory, inspection or enforcement roles. The senior members of the City of London Livery Companies (known as liverymen) elect the sheriffs and approve the candidates for the office of Lord Mayor of London. Guilds also survive in many other towns and cities the UK including in Preston, Lancashire, as the Preston Guild Merchant where among other celebrations descendants of burgesses are still admitted into membership. With the City of London livery companies, the UK has over 300 extant guilds and growing.

In 1878 the London livery companies established the City and Guilds of London Institute the forerunner of the engineering school (still called City and Guilds College) at Imperial College London. The aim of the City and Guilds of London Institute was the advancement of technical education. "City and Guilds" operates as an examining and accreditation body for vocational, managerial and engineering qualifications from entry-level craft and trade skills up to post-doctoral achievement. A separate organisation, the City and Guilds of London Art School has also close ties with the London livery companies and is involved in the training of master craftworkers in stone and wood carving, as well as fine artists.

In Germany there are no longer any "Zünfte" (or "Gilden" – the terms used were rather different from town to town), nor any restriction of a craft to a privileged corporation. However, under one other of their old names albeit a less frequent one, "Innungen", guilds continue to exist as private member clubs with membership limited to practitioners of particular trades or activities. These clubs are corporations under public law, albeit the membership is voluntary; the president normally comes from the ranks of master-craftsmen and is called "Obermeister" ("master-in-chief"). Journeymen elect their own representative bodies, with their president having the traditional title of "Altgesell" (senior journeyman).

There are also "craft chambers" ("Handwerkskammern"), which have less resemblance to ancient guilds in that they are organized for all crafts in a certain region, not just one. In them membership is mandatory, and they serve to establish self-governance of the crafts.

In India there are Students Guild, Indian Engineers Guild, Safety Guild and other various Professional Associations are common like Indian medical Association, Indian Engineers, Indian Dental Association, United nurses Association, etc.
Most of them use Union, Association or Society as suffix.

In the United States guilds exist in several fields.

In the film and television industry, guild membership is generally a prerequisite for working on major productions in certain capacities. The Screen Actors Guild, Directors Guild of America, Writers Guild of America, East, Writers Guild of America, West and other profession-specific guilds have the ability to exercise strong control in the cinema of the United States as a result of a rigid system of intellectual-property rights and a history of power-brokers also holding guild membership (e.g., DreamWorks founder Steven Spielberg was, and is, a DGA member). These guilds maintain their own contracts with production companies to ensure a certain number of their members are hired for roles in each film or television production, and that their members are paid a minimum of guild "scale," along with other labor protections. These guilds set high standards for membership, and exclude professional actors, writers, etc. who do not abide by the strict rules for competing within the film and television industry in America.

The Newspaper Guild is a labor union for journalists and other newspaper workers, with over 30,000 members in North America.

Real-estate brokerage offers an example of a modern American guild system. Signs of guild behavior in real-estate brokerage include: standard pricing (6% of the home price), strong affiliation among all practitioners, self-regulation (see National Association of Realtors), strong cultural identity (see realtor), little price variation with quality differences, and traditional methods in use by all practitioners. In September 2005 the U.S. Department of Justice filed an antitrust lawsuit against the National Association of Realtors, challenging NAR practices that (the DOJ asserted) prevent competition from practitioners who use different methods. The DOJ and the Federal Trade Commission in 2005 advocated against state laws, supported by NAR, that disadvantage new kinds of brokers. "U.S. v. National Assoc. of Realtors", Civil Action No. 05C-5140 (N.D. Ill. Sept. 7, 2005).

The practice of law in the United States also exemplifies modern guilds at work. Every state maintains its own bar association, supervised by that state's highest court. The court decides the criteria for entering and staying in the legal profession. In most states, every attorney must become a member of that state's bar association in order to practice law. State laws forbid any person from engaging in the unauthorized practice of law and practicing attorneys are subject to rules of professional conduct that are enforced by the state's high court.

Medical associations comparable to guilds include the state Medical Boards, the American Medical Association, and the American Dental Association. Medical licensing in most states requires specific training, tests and years of low-paid apprenticeship (internship and residency) under harsh working conditions. Even qualified international or out-of-state doctors may not practice without acceptance by the local medical guild (Medical board). Similarly, nurses and physicians' practitioners have their own guilds. A doctor cannot work as a physician's assistant unless (s)he separately trains, tests and apprentices as one.

Australia is home to several guilds including the Australian Butcher's Guild (a fraternity of independent butchers) which provides links to resources like Australian meat standards and a guide to different beef cuts. Another guild is The Pharmacy Guild of Australia, created in 1928 as the Federated Pharmaceutical Services Guild of Australia, which serves "5700 community pharmacies," while also providing training and standards for the country's pharmacists. Australia's craft guilds include, among others, the Australian Director's Guild, representing the country's directors, documentary makers and animators, the Australian Writer's Guild, and The Artists Guild, a craft guild focusing on female artists.





</doc>
<doc id="12372" url="https://en.wikipedia.org/wiki?curid=12372" title="Gradius (video game)">
Gradius (video game)

The arcade version of "Gradius" was released internationally outside Japan under the title of Nemesis, although subsequent home releases have the original title. Home versions were released for various platforms, such as the NES, the MSX home computer, and the PC Engine.

The player controls the trans-dimensional spaceship Vic Viper and must battle waves of enemies through various environments. The game became synonymous with the phrase, "Destroy the core!", as the standard of boss battles in the "Gradius" series involved combat with a giant craft, in the center of which would be situated one to several blue colored spheres. These bosses would be designed in such a way that there would be a straight passage from the exterior of the giant craft which leads directly to one of these cores. The player must fire shots into this passage while avoiding attack patterns from weapon emplacements on the body of the boss. However, small but destructible walls are situated in this passage, impeding the bullet shots from damaging the core, and must be whittled away by repeated well-placed shots. In a way, these tiny walls represent the boss' shielding gauge until its core is finally vulnerable to attack. Some bosses can regenerate these walls. When the core has sustained enough hits, it usually changes color from blue to red, indicating that it is in critical condition and its destruction is imminent. Upon the destruction of a core, a piece of the boss may be put out of commission, seeing that it is no longer powered by a core, or if all of the cores are destroyed, the entire boss is defeated and explodes satisfyingly. Note that these cores are not present on the more organic bosses of "Gradius". Such bosses have weak spots in places such as a mouth, head or eye.

When gameplay begins, the Vic Viper is relatively slow and has only a weak gun. This level of capability is generally insufficient for engaging enemies, but the Vic Viper can gain greater capabilities by collecting and using power-up items. While most arcade games utilize distinct power up-items that each correspond to a specific effect on the player character, "Gradius" has a single power-up item. The effect of this power-up item is to advance the currently selected item in a power-up menu that appears at the bottom of the screen. When the desired power-up is highlighted, the player can obtain it by pressing the power-up button, returning the menu to its initial state in which no power-up is highlighted.

"Gradius" was the creation of Konami game designer Machiguchi Hiroyasu, being the first video game he publicly released. Joining the company in the early 1980s originally as a programmer, Konami was trying to transition from being a producer of medal machines to a video game developer and assigned him to a small team to try and create a game that could put the company on the map. He asked the team what kind of game they'd like to work on, responding that they'd like to make another shooting game. The shoot'em up genre had seen a resurgence at the time with Namco's "Xevious", with the goal of the project being to make a shooter that could surpass it. The project was at first intended to be a followup to Konami's earlier game "Scramble", being titled "Scramble 2" and reusing many of its material and game mechanics.

Development of "Gradius" lasted for about a year, which Hiroyasu says was filled with anxiety and worry from the production team due to it being their first game, lacking confidence in what they were doing. Members of the project came up with ideas that were then tested on the arcade monitor to see if they worked or not. While designing the Option satellites, the team tested over 20 different movement patterns for them, which were cut through the process of elimination based on those that didn't work. The game was produced for the Konami Bubble System arcade hardware, which gave the team more hardware capacity and memory to experiment with. Hiroyasu wanted the game to have a visually distinct world with unique enemies and locations, something relatively uncommon for shooters at the time. Inspiration for mechanics and the story were derived from films such as "" and "Lensman", with the Laser weapon being directly taken from those in "Lensman". The idea for the power meter mechanic stemmed from the team's desire to give players the freedom to select whichever weapons they pleased. Early versions had the player collecting individual pick-up icons, which were cut for not being "satisfying" enough; it was instead replaced with a selection bar where players collected capsules to allow access to other weapons, an idea based on the function keys on a keyboard. The Moai enemies were added to pay homage to "Xevious" and its Nazca lines, and as a way to give the game a sense of mystery.

"Gradius" was first released in Japan for Konami's Bubble System, an arcade board which allows operators to change the software through the use of a proprietary magnetic-based media called "Bubble Software". The game was distributed as a standard printed circuit board in North America and Europe under the title of "Nemesis". The North American version of "Nemesis" features a considerably increased difficulty compared to the Japanese and European version. To balance this, the game spawns a fleet of orange enemies when the player loses a life to provide as many power-up capsules as possible to recover as many upgrades as possible. The title screen was also updated, showing an in-game reproduction of the promotional artwork behind the logo.

The first home conversion of "Gradius" was released for Nintendo's Famicom console on April 25, 1986, in Japan. Due to the hardware limitations of the Famicom, many of the level designs were simplified (the Moai stage, for example, lacks the vertical scrolling present in the arcade game) and the maximum amount of options that the player can upgrade to was reduced from four to two. This version added a cheat code that can be entered while the game is paused that grants the player's ship almost all the power-ups. This code would appear again in many later Konami on the NES and other consoles (such as "Contra" and "Life Force"), becoming known as the Konami Code.

The NES version of "Gradius" was released in North America in December 1986. It is the first NES game to have been released by Konami in the region and unlike the original arcade game, the title was kept unchanged between regions. The NES version was made available in arcades as a Nintendo VS. System board (under the title of "VS. Gradius") and as a PlayChoice-10 cartridge. "VS. Gradius" was distributed to arcades by Nintendo.

The MSX version of "Gradius" was released on July 25, 1986, in Japan, a few months after the Famicom version. It was also released in Europe under the "Nemesis" title. This version changed similar to the Famicom version but adds its slew of exclusive content to make up for the downgrade. A new stage, the bone planet was added between the Inverted Volcano stage and the Antennoid stage, featuring exclusive enemy types. There also four hidden warp zones and the ability to play as the titular ship from "TwinBee" if the MSX version of that game is played alongside "Nemesis".

The PC Engine version of "Gradius" was released on November 15, 1991, exclusively in Japan. Released on a 2-Megabit HuCard, it had relatively few omissions compared to the NES and MSX versions and added a Desert Planet stage similar to the Bone Planet stage from the MSX version. Because of the lower resolution of the PC Engine compared to the original arcade hardware, the PC Engine features some slight vertical-scrolling.

In addition to the MSX, "Gradius" was also ported to other microcomputers shortly after its release, such as the ZX Spectrum, Amstrad CPC and Commodore 64 in Europe (as "Nemesis: The Final Challenge"), as well as the PC-8801 and X1 in Japan. A port for the X68000 computer was also included in the early models of the computer. The original "Gradius" is also included in collection such as "Gradius Deluxe Pack" for the PlayStation and Sega Saturn and "Gradius Collection" for the PlayStation Portable. The arcade version was digitally released on the PlayStation 4 in 2015 and Nintendo Switch in July 2020 as part of the Arcade Archives series, with the option to play all four regional variants of the game.


In Japan, "Game Machine" listed "Gradius" on their July 1, 1985 issue as being the most-successful table arcade unit of the year. The game went to number 2 in the UK sales charts, behind "Feud". The Western cover art for the NES version claimed that it had sold one million copies in Japan. 

"GameSpot" stated that "Gradius" was one of the toughest side-scrolling shooter games available on the NES, second only to "Contra". "IGN" has given the game a rating 7 out of 10 for its re-release on the Wii Virtual Console and has hailed it as one of the greatest classic side-scrolling shooter games.

"Gradius" spawned several sequels, the first of which was 1986's "Salamander". The series has continued into the seventh generation with "Gradius ReBirth".

It was also re-released on Windows Store on December 20, 2013, GameNow in May 2014 and for PlayStation 4's Arcade Archives on January 25 in Japan. An NES port was re-released for the Nintendo Switch Online on September 19, 2018, worldwide and an updated release as on November 14, 2018, worldwide. Another updated release titled Gradius SP: Second Loop was released worldwide on August 22, 2019.


</doc>
<doc id="12373" url="https://en.wikipedia.org/wiki?curid=12373" title="Gamemaster">
Gamemaster

A gamemaster (GM; also known as game master, game manager, game moderator or referee) is a person who acts as an organizer, officiant for regarding rules, arbitrator, and moderator for a multiplayer role-playing game. They are more common in co-operative games in which players work together than in competitive games in which players oppose each other. The act performed by a gamemaster is sometimes referred to as "Gamemastering" or simply "GM-ing".

The role of a gamemaster in a traditional table-top role-playing game (pencil-and-paper role-playing game) is to weave the other participants' player-character stories together, control the non-player aspects of the game, create environments in which the players can interact, and solve any player disputes. The basic role of the gamemaster is the same in almost all traditional role-playing games, although differing rule sets make the specific duties of the gamemaster unique to that system.

The role of a gamemaster in an online game is to enforce the game's rules and provide general customer service. Also, unlike gamemasters in traditional role-playing games, gamemasters for online games in some cases are paid employees.

In Dungeons & Dragons, the game master is referred to as the dungeon master.
The term "gamemaster" and the role associated with it could be found in the postal gaming hobby. In typical play-by-mail games, players control armies or civilizations and mail their chosen actions to the GM. The GM then mails the updated game state to all players on a regular basis. Usage in a wargaming context includes Guidon Games 1973 ruleset, "Ironclad". 

In a role-playing game context, it was first used by Dave Arneson while developing his game "Blackmoor" in 1971, although the first usage in print may have been "Chivalry & Sorcery". 

Each gaming system has its own name for the role of the gamemaster, such as "judge", "narrator", "referee", "director", or "storyteller", and these terms not only describe the role of the gamemaster in general but also help define how the game is intended to be run. For example, the Storyteller System used in White Wolf Game Studio's storytelling games calls its GM the "storyteller", while the rules- and setting-focused "Marvel Super Heroes" role-playing game calls its GM the "judge". The cartoon inspired role-playing game "Toon" calls its GM the "animator". A few games apply system- or setting-specific flavorful names to the GM, such as the Keeper of Arcane Lore (in "Call of Cthulhu"); the Hollyhock God ("Nobilis", in which the hollyhock represents vanity), or the most famous of such terms, "Dungeon Master" (or "DM") in "Dungeons & Dragons".

The gamemaster prepares the game session for the players and the characters they play (known as player characters or PCs), describes the events taking place and decides on the outcomes of players' decisions. The gamemaster also keeps track of non-player characters (NPCs) and random encounters, as well as of the general state of the game world. The game session (or "adventure") can be metaphorically described as a play, in which the players are the lead actors, and the GM provides the stage, the scenery, the basic plot on which the improvisational script is built, as well as all the bit parts and supporting characters. Gamemasters can also be in charge of RPG board games making the events and setting challenges.

GMs may choose to run a game based on a published game world, with the maps and history already in place; such game worlds often have pre-written adventures. Alternatively, the GM may build their own world and script their own adventures.

A good gamemaster draws the players into the adventure, making it enjoyable for everyone. Good gamemasters have quick minds, sharp wits, and rich imaginations. Gamemasters must also maintain game balance: hideously overpowered monsters "or" players are no fun. It was noted, in 1997, that those who favor their left-brain such as skilled code writers usually do not make it in the ethereal gamemaster world of storytelling and verse.


In early virtual worlds gamemasters served as a moderator or administrator; in MUD game masters were called "wizards". Gamemastering in the form found in traditional role-playing games has also been used in a semi-automatic virtual worlds. However, human moderation was sometimes considered unfair or out of context in an otherwise automated world. As online games expanded, gamemaster duties expanded to include being a customer service representative for an online community. A gamemaster in such a game is either an experienced volunteer player or an employee of the game's publisher. They enforce the game's rules by banishing spammers, player killers, cheaters, and hackers and by solving players' problems by providing general customer service. For their tasks they use special tools and characters that allow them to do things like teleport to players, summon items, and browse logs that record players' activities. Often, players who feel dissatisfied with the game will blame the GMs directly for any errors or glitches. However, this blame is misdirected as most GMs are not developers and cannot resolve those types of problems.

The now defunct America Online Online Gaming Forum used to use volunteers selected by applications from its user base. These people were simply referred to as OGFs by other members, and their screennames were indicative of their position (i.e., OGF Moose, etc.). While membership in the Online Gaming Forum had only one real requirement (that is, be a member of AOL), OGFs were given powers quite similar to AOL "Guides" and could use them at will to discipline users as they saw appropriate.

"World of Warcraft" has employees of Blizzard Entertainment that serve as gamemasters to help users with various problems in gameplay, chat, and other things like account and billing issues. A gamemaster in this game will communicate with players through chat that has blue text and they will also have a special "GM" tag and Blizzard logo in front of their names.

"RuneScape" has more than 500 moderators employed by Jagex to assist players and perform administrative duties in-game and on the site forums. These "Jagex Moderators", as they are called, usually have the word "Mod" and a gold crown preceding their account names which ordinary players are not permitted to use. The game also has "Player Moderators" and "Forum Moderators" who are player volunteers helping with moderation, having the ability to mute (block from chatting) other players who violate rules.

"Battleground Europe", a medium-sized MMOFPS has a team of "Game Moderators", anonymous volunteers who moderate the game.

"Miniconomy", a smaller text-based MMO has a team of "Federals", experienced players that help moderate the game and interactions.

"Transformice", an MMORPG, has a team of volunteer moderators called "Mods" who are experienced players that help moderate the game and interactions.

Note that a few games, notably "Neverwinter Nights" and "", are video game adaptations of tabletop role-playing games that are played online with one player acting as a traditional gamemaster.

Gamemastering, sometimes referred to as Orchestration is used in pervasive games to guide players along a trajectory desired by the game author. To ensure proper gamemastering can take place, four components are needed: some kind of sensory system to the game allowing the game masters to know current events, providing dynamic game information; dynamic and static game information lets game masters make informed decisions; decisions need to be actuated into the game, either through the game system or through manual intervention; and finally a communication structure is needed for both diegetic or non-diegetic communication. Effective gamemastering can require specialized user interfaces that are highly game specific.

Sometimes, tabletop GMs simply can not find players interested in either the same setting, product line, or play style in their local neighborhood. The advent of the networked personal computer provided a solution in the form of online chat programs. Appropriately equipped gamemasters can find players online and a group can meet via chat rooms, forums, or other electronic means.

In contrast to standard tabletop procedure (and to games "designed" to be played online), this online chat format significantly changed the balance of duties for a prospective gamemaster. Descriptive text required more preparation, if only via cut-and-paste; acting and voice skills could not be utilized to get the personality of NPCs and monsters across, increasing the value of background music ('assigned' in advance or individually chosen) as a playing aid. The GM was likely to need copies of player-character records, being unable to glance at the originals as in normal face-to-face procedure. The format also forced the issue (particularly when participants were not personally acquainted) of whether to leave all rolling of dice to the GM (making one's own rolls is a privilege not readily surrendered by some players), or to trust all players to honestly report the results of their rolls (the honor system may be strained when it is in a player's best interest to roll well).

However, workarounds to these challenges have only increased over time. The use of Wiki software helps GMs and players alike keep track of all manner of game data, sometimes evolving into a home-made gaming supplement. Scripting software allows unwieldy mechanics (e.g. a complicated formula or repetitive die-rolling) to be resolved at the push of a button. Teleconferencing enhances group communication through voice, video, and a shared whiteboard. The use of technology to enable online play is growing, as reflected in products like the D&D Insider.



</doc>
<doc id="12383" url="https://en.wikipedia.org/wiki?curid=12383" title="Genetic engineering">
Genetic engineering

Genetic engineering, also called genetic modification or genetic manipulation, is the direct manipulation of an organism's genes using biotechnology. It is a set of technologies used to change the genetic makeup of cells, including the transfer of genes within and across species boundaries to produce improved or novel organisms. New DNA is obtained by either isolating and copying the genetic material of interest using recombinant DNA methods or by artificially synthesising the DNA. A construct is usually created and used to insert this DNA into the host organism. The first recombinant DNA molecule was made by Paul Berg in 1972 by combining DNA from the monkey virus SV40 with the lambda virus. As well as inserting genes, the process can be used to remove, or "knock out", genes. The new DNA can be inserted randomly, or targeted to a specific part of the genome.

An organism that is generated through genetic engineering is considered to be genetically modified (GM) and the resulting entity is a genetically modified organism (GMO). The first GMO was a bacterium generated by Herbert Boyer and Stanley Cohen in 1973. Rudolf Jaenisch created the first GM animal when he inserted foreign DNA into a mouse in 1974. The first company to focus on genetic engineering, Genentech, was founded in 1976 and started the production of human proteins. Genetically engineered human insulin was produced in 1978 and insulin-producing bacteria were commercialised in 1982. Genetically modified food has been sold since 1994, with the release of the Flavr Savr tomato. The Flavr Savr was engineered to have a longer shelf life, but most current GM crops are modified to increase resistance to insects and herbicides. GloFish, the first GMO designed as a pet, was sold in the United States in December 2003. In 2016 salmon modified with a growth hormone were sold.

Genetic engineering has been applied in numerous fields including research, medicine, industrial biotechnology and agriculture. In research GMOs are used to study gene function and expression through loss of function, gain of function, tracking and expression experiments. By knocking out genes responsible for certain conditions it is possible to create animal model organisms of human diseases. As well as producing hormones, vaccines and other drugs genetic engineering has the potential to cure genetic diseases through gene therapy. The same techniques that are used to produce drugs can also have industrial applications such as producing enzymes for laundry detergent, cheeses and other products.

The rise of commercialised genetically modified crops has provided economic benefit to farmers in many different countries, but has also been the source of most of the controversy surrounding the technology. This has been present since its early use; the first field trials were destroyed by anti-GM activists. Although there is a scientific consensus that currently available food derived from GM crops poses no greater risk to human health than conventional food, GM food safety is a leading concern with critics. Gene flow, impact on non-target organisms, control of the food supply and intellectual property rights have also been raised as potential issues. These concerns have led to the development of a regulatory framework, which started in 1975. It has led to an international treaty, the Cartagena Protocol on Biosafety, that was adopted in 2000. Individual countries have developed their own regulatory systems regarding GMOs, with the most marked differences occurring between the US and Europe.

Genetic engineering is a process that alters the genetic structure of an organism by either removing or introducing DNA. Unlike traditional animal and plant breeding, which involves doing multiple crosses and then selecting for the organism with the desired phenotype, genetic engineering takes the gene directly from one organism and delivers it to the other. This is much faster, can be used to insert any genes from any organism (even ones from different domains) and prevents other undesirable genes from also being added.

Genetic engineering could potentially fix severe genetic disorders in humans by replacing the defective gene with a functioning one. It is an important tool in research that allows the function of specific genes to be studied. Drugs, vaccines and other products have been harvested from organisms engineered to produce them. Crops have been developed that aid food security by increasing yield, nutritional value and tolerance to environmental stresses.

The DNA can be introduced directly into the host organism or into a cell that is then fused or hybridised with the host. This relies on recombinant nucleic acid techniques to form new combinations of heritable genetic material followed by the incorporation of that material either indirectly through a vector system or directly through micro-injection, macro-injection or micro-encapsulation.

Genetic engineering does not normally include traditional breeding, in vitro fertilisation, induction of polyploidy, mutagenesis and cell fusion techniques that do not use recombinant nucleic acids or a genetically modified organism in the process. However, some broad definitions of genetic engineering include selective breeding. Cloning and stem cell research, although not considered genetic engineering, are closely related and genetic engineering can be used within them. Synthetic biology is an emerging discipline that takes genetic engineering a step further by introducing artificially synthesised material into an organism. Such synthetic DNA as Artificially Expanded Genetic Information System and Hachimoji DNA is made in this new field.

Plants, animals or microorganisms that have been changed through genetic engineering are termed genetically modified organisms or GMOs. If genetic material from another species is added to the host, the resulting organism is called transgenic. If genetic material from the same species or a species that can naturally breed with the host is used the resulting organism is called cisgenic. If genetic engineering is used to remove genetic material from the target organism the resulting organism is termed a knockout organism. In Europe genetic modification is synonymous with genetic engineering while within the United States of America and Canada genetic modification can also be used to refer to more conventional breeding methods.

Humans have altered the genomes of species for thousands of years through selective breeding, or artificial selection as contrasted with natural selection. More recently, mutation breeding has used exposure to chemicals or radiation to produce a high frequency of random mutations, for selective breeding purposes. Genetic engineering as the direct manipulation of DNA by humans outside breeding and mutations has only existed since the 1970s. The term "genetic engineering" was first coined by Jack Williamson in his science fiction novel "Dragon's Island", published in 1951 – one year before DNA's role in heredity was confirmed by Alfred Hershey and Martha Chase, and two years before James Watson and Francis Crick showed that the DNA molecule has a double-helix structure – though the general concept of direct genetic manipulation was explored in rudimentary form in Stanley G. Weinbaum's 1936 science fiction story "Proteus Island".

In 1972, Paul Berg created the first recombinant DNA molecules by combining DNA from the monkey virus SV40 with that of the lambda virus. In 1973 Herbert Boyer and Stanley Cohen created the first transgenic organism by inserting antibiotic resistance genes into the plasmid of an "Escherichia coli" bacterium. A year later Rudolf Jaenisch created a transgenic mouse by introducing foreign DNA into its embryo, making it the world's first transgenic animal These achievements led to concerns in the scientific community about potential risks from genetic engineering, which were first discussed in depth at the Asilomar Conference in 1975. One of the main recommendations from this meeting was that government oversight of recombinant DNA research should be established until the technology was deemed safe.

In 1976 Genentech, the first genetic engineering company, was founded by Herbert Boyer and Robert Swanson and a year later the company produced a human protein (somatostatin) in "E.coli". Genentech announced the production of genetically engineered human insulin in 1978. In 1980, the U.S. Supreme Court in the "Diamond v. Chakrabarty" case ruled that genetically altered life could be patented. The insulin produced by bacteria was approved for release by the Food and Drug Administration (FDA) in 1982.

In 1983, a biotech company, Advanced Genetic Sciences (AGS) applied for U.S. government authorisation to perform field tests with the ice-minus strain of "Pseudomonas syringae" to protect crops from frost, but environmental groups and protestors delayed the field tests for four years with legal challenges. In 1987, the ice-minus strain of "P. syringae" became the first genetically modified organism (GMO) to be released into the environment when a strawberry field and a potato field in California were sprayed with it. Both test fields were attacked by activist groups the night before the tests occurred: "The world's first trial site attracted the world's first field trasher".

The first field trials of genetically engineered plants occurred in France and the US in 1986, tobacco plants were engineered to be resistant to herbicides. The People's Republic of China was the first country to commercialise transgenic plants, introducing a virus-resistant tobacco in 1992. In 1994 Calgene attained approval to commercially release the first genetically modified food, the Flavr Savr, a tomato engineered to have a longer shelf life. In 1994, the European Union approved tobacco engineered to be resistant to the herbicide bromoxynil, making it the first genetically engineered crop commercialised in Europe. In 1995, Bt Potato was approved safe by the Environmental Protection Agency, after having been approved by the FDA, making it the first pesticide producing crop to be approved in the US. In 2009 11 transgenic crops were grown commercially in 25 countries, the largest of which by area grown were the US, Brazil, Argentina, India, Canada, China, Paraguay and South Africa.

In 2010, scientists at the J. Craig Venter Institute created the first synthetic genome and inserted it into an empty bacterial cell. The resulting bacterium, named Mycoplasma laboratorium, could replicate and produce proteins. Four years later this was taken a step further when a bacterium was developed that replicated a plasmid containing a unique base pair, creating the first organism engineered to use an expanded genetic alphabet. In 2012, Jennifer Doudna and Emmanuelle Charpentier collaborated to develop the CRISPR/Cas9 system, a technique which can be used to easily and specifically alter the genome of almost any organism.

Creating a GMO is a multi-step process. Genetic engineers must first choose what gene they wish to insert into the organism. This is driven by what the aim is for the resultant organism and is built on earlier research. Genetic screens can be carried out to determine potential genes and further tests then used to identify the best candidates. The development of microarrays, transcriptomics and genome sequencing has made it much easier to find suitable genes. Luck also plays its part; the round-up ready gene was discovered after scientists noticed a bacterium thriving in the presence of the herbicide.

The next step is to isolate the candidate gene. The cell containing the gene is opened and the DNA is purified. The gene is separated by using restriction enzymes to cut the DNA into fragments or polymerase chain reaction (PCR) to amplify up the gene segment. These segments can then be extracted through gel electrophoresis. If the chosen gene or the donor organism's genome has been well studied it may already be accessible from a genetic library. If the DNA sequence is known, but no copies of the gene are available, it can also be artificially synthesised. Once isolated the gene is ligated into a plasmid that is then inserted into a bacterium. The plasmid is replicated when the bacteria divide, ensuring unlimited copies of the gene are available.

Before the gene is inserted into the target organism it must be combined with other genetic elements. These include a promoter and terminator region, which initiate and end transcription. A selectable marker gene is added, which in most cases confers antibiotic resistance, so researchers can easily determine which cells have been successfully transformed. The gene can also be modified at this stage for better expression or effectiveness. These manipulations are carried out using recombinant DNA techniques, such as restriction digests, ligations and molecular cloning.

There are a number of techniques used to insert genetic material into the host genome. Some bacteria can naturally take up foreign DNA. This ability can be induced in other bacteria via stress (e.g. thermal or electric shock), which increases the cell membrane's permeability to DNA; up-taken DNA can either integrate with the genome or exist as extrachromosomal DNA. DNA is generally inserted into animal cells using microinjection, where it can be injected through the cell's nuclear envelope directly into the nucleus, or through the use of viral vectors.

Plant genomes can be engineered by physical methods or by use of "Agrobacterium" for the delivery of sequences hosted in T-DNA binary vectors. In plants the DNA is often inserted using "Agrobacterium"-mediated transformation, taking advantage of the "Agrobacterium"s T-DNA sequence that allows natural insertion of genetic material into plant cells. Other methods include biolistics, where particles of gold or tungsten are coated with DNA and then shot into young plant cells, and electroporation, which involves using an electric shock to make the cell membrane permeable to plasmid DNA.

As only a single cell is transformed with genetic material, the organism must be regenerated from that single cell. In plants this is accomplished through the use of tissue culture. In animals it is necessary to ensure that the inserted DNA is present in the embryonic stem cells. Bacteria consist of a single cell and reproduce clonally so regeneration is not necessary. Selectable markers are used to easily differentiate transformed from untransformed cells. These markers are usually present in the transgenic organism, although a number of strategies have been developed that can remove the selectable marker from the mature transgenic plant.

Further testing using PCR, Southern hybridization, and DNA sequencing is conducted to confirm that an organism contains the new gene. These tests can also confirm the chromosomal location and copy number of the inserted gene. The presence of the gene does not guarantee it will be expressed at appropriate levels in the target tissue so methods that look for and measure the gene products (RNA and protein) are also used. These include northern hybridisation, quantitative RT-PCR, Western blot, immunofluorescence, ELISA and phenotypic analysis.

The new genetic material can be inserted randomly within the host genome or targeted to a specific location. The technique of gene targeting uses homologous recombination to make desired changes to a specific endogenous gene. This tends to occur at a relatively low frequency in plants and animals and generally requires the use of selectable markers. The frequency of gene targeting can be greatly enhanced through genome editing. Genome editing uses artificially engineered nucleases that create specific double-stranded breaks at desired locations in the genome, and use the cell's endogenous mechanisms to repair the induced break by the natural processes of homologous recombination and nonhomologous end-joining. There are four families of engineered nucleases: meganucleases, zinc finger nucleases, transcription activator-like effector nucleases (TALENs), and the Cas9-guideRNA system (adapted from CRISPR). TALEN and CRISPR are the two most commonly used and each has its own advantages. TALENs have greater target specificity, while CRISPR is easier to design and more efficient. In addition to enhancing gene targeting, engineered nucleases can be used to introduce mutations at endogenous genes that generate a gene knockout.

Genetic engineering has applications in medicine, research, industry and agriculture and can be used on a wide range of plants, animals and microorganisms. Bacteria, the first organisms to be genetically modified, can have plasmid DNA inserted containing new genes that code for medicines or enzymes that process food and other substrates. Plants have been modified for insect protection, herbicide resistance, virus resistance, enhanced nutrition, tolerance to environmental pressures and the production of edible vaccines. Most commercialised GMOs are insect resistant or herbicide tolerant crop plants. Genetically modified animals have been used for research, model animals and the production of agricultural or pharmaceutical products. The genetically modified animals include animals with genes knocked out, increased susceptibility to disease, hormones for extra growth and the ability to express proteins in their milk.

Genetic engineering has many applications to medicine that include the manufacturing of drugs, creation of model animals that mimic human conditions and gene therapy. One of the earliest uses of genetic engineering was to mass-produce human insulin in bacteria. This application has now been applied to, human growth hormones, follicle stimulating hormones (for treating infertility), human albumin, monoclonal antibodies, antihemophilic factors, vaccines and many other drugs. Mouse hybridomas, cells fused together to create monoclonal antibodies, have been adapted through genetic engineering to create human monoclonal antibodies. In 2017, genetic engineering of chimeric antigen receptors on a patient's own T-cells was approved by the U.S. FDA as a treatment for the cancer acute lymphoblastic leukemia. Genetically engineered viruses are being developed that can still confer immunity, but lack the infectious sequences.

Genetic engineering is also used to create animal models of human diseases. Genetically modified mice are the most common genetically engineered animal model. They have been used to study and model cancer (the oncomouse), obesity, heart disease, diabetes, arthritis, substance abuse, anxiety, aging and Parkinson disease. Potential cures can be tested against these mouse models. Also genetically modified pigs have been bred with the aim of increasing the success of pig to human organ transplantation.

Gene therapy is the genetic engineering of humans, generally by replacing defective genes with effective ones. Clinical research using somatic gene therapy has been conducted with several diseases, including X-linked SCID, chronic lymphocytic leukemia (CLL), and Parkinson's disease. In 2012, Alipogene tiparvovec became the first gene therapy treatment to be approved for clinical use. In 2015 a virus was used to insert a healthy gene into the skin cells of a boy suffering from a rare skin disease, epidermolysis bullosa, in order to grow, and then graft healthy skin onto 80 percent of the boy's body which was affected by the illness.

Germline gene therapy would result in any change being inheritable, which has raised concerns within the scientific community. In 2015, CRISPR was used to edit the DNA of non-viable human embryos, leading scientists of major world academies to call for a moratorium on inheritable human genome edits. There are also concerns that the technology could be used not just for treatment, but for enhancement, modification or alteration of a human beings' appearance, adaptability, intelligence, character or behavior. The distinction between cure and enhancement can also be difficult to establish. In November 2018, He Jiankui announced that he had edited the genomes of two human embryos, to attempt to disable the "CCR5" gene, which codes for a receptor that HIV uses to enter cells. He said that twin girls, Lulu and Nana, had been born a few weeks earlier. He said that the girls still carried functional copies of CCR5 along with disabled CCR5 (mosaicism) and were still vulnerable to HIV. The work was widely condemned as unethical, dangerous, and premature.

Researchers are altering the genome of pigs to induce the growth of human organs to be used in transplants. Scientists are creating "gene drives", changing the genomes of mosquitoes to make them immune to malaria, and then looking to spread the genetically altered mosquitoes throughout the mosquito population in the hopes of eliminating the disease.

Genetic engineering is an important tool for natural scientists, with the creation of transgenic organisms one of the most important tools for analysis of gene function. Genes and other genetic information from a wide range of organisms can be inserted into bacteria for storage and modification, creating genetically modified bacteria in the process. Bacteria are cheap, easy to grow, clonal, multiply quickly, relatively easy to transform and can be stored at -80 °C almost indefinitely. Once a gene is isolated it can be stored inside the bacteria providing an unlimited supply for research.
Organisms are genetically engineered to discover the functions of certain genes. This could be the effect on the phenotype of the organism, where the gene is expressed or what other genes it interacts with. These experiments generally involve loss of function, gain of function, tracking and expression.


Organisms can have their cells transformed with a gene coding for a useful protein, such as an enzyme, so that they will overexpress the desired protein. Mass quantities of the protein can then be manufactured by growing the transformed organism in bioreactor equipment using industrial fermentation, and then purifying the protein. Some genes do not work well in bacteria, so yeast, insect cells or mammalians cells can also be used. These techniques are used to produce medicines such as insulin, human growth hormone, and vaccines, supplements such as tryptophan, aid in the production of food (chymosin in cheese making) and fuels. Other applications with genetically engineered bacteria could involve making them perform tasks outside their natural cycle, such as making biofuels, cleaning up oil spills, carbon and other toxic waste and detecting arsenic in drinking water. Certain genetically modified microbes can also be used in biomining and bioremediation, due to their ability to extract heavy metals from their environment and incorporate them into compounds that are more easily recoverable.

In materials science, a genetically modified virus has been used in a research laboratory as a scaffold for assembling a more environmentally friendly lithium-ion battery. Bacteria have also been engineered to function as sensors by expressing a fluorescent protein under certain environmental conditions.

One of the best-known and controversial applications of genetic engineering is the creation and use of genetically modified crops or genetically modified livestock to produce genetically modified food. Crops have been developed to increase production, increase tolerance to abiotic stresses, alter the composition of the food, or to produce novel products.

The first crops to be released commercially on a large scale provided protection from insect pests or tolerance to herbicides. Fungal and virus resistant crops have also been developed or are in development. This makes the insect and weed management of crops easier and can indirectly increase crop yield. GM crops that directly improve yield by accelerating growth or making the plant more hardy (by improving salt, cold or drought tolerance) are also under development. In 2016 Salmon have been genetically modified with growth hormones to reach normal adult size much faster.

GMOs have been developed that modify the quality of produce by increasing the nutritional value or providing more industrially useful qualities or quantities. The Amflora potato produces a more industrially useful blend of starches. Soybeans and canola have been genetically modified to produce more healthy oils. The first commercialised GM food was a tomato that had delayed ripening, increasing its shelf life.

Plants and animals have been engineered to produce materials they do not normally make. Pharming uses crops and animals as bioreactors to produce vaccines, drug intermediates, or the drugs themselves; the useful product is purified from the harvest and then used in the standard pharmaceutical production process. Cows and goats have been engineered to express drugs and other proteins in their milk, and in 2009 the FDA approved a drug produced in goat milk.

Genetic engineering has potential applications in conservation and natural area management. Gene transfer through viral vectors has been proposed as a means of controlling invasive species as well as vaccinating threatened fauna from disease. Transgenic trees have been suggested as a way to confer resistance to pathogens in wild populations. With the increasing risks of maladaptation in organisms as a result of climate change and other perturbations, facilitated adaptation through gene tweaking could be one solution to reducing extinction risks. Applications of genetic engineering in conservation are thus far mostly theoretical and have yet to be put into practice.

Genetic engineering is also being used to create microbial art. Some bacteria have been genetically engineered to create black and white photographs. Novelty items such as lavender-colored carnations, blue roses, and glowing fish have also been produced through genetic engineering.

The regulation of genetic engineering concerns the approaches taken by governments to assess and manage the risks associated with the development and release of GMOs. The development of a regulatory framework began in 1975, at Asilomar, California. The Asilomar meeting recommended a set of voluntary guidelines regarding the use of recombinant technology. As the technology improved the US established a committee at the Office of Science and Technology, which assigned regulatory approval of GM food to the USDA, FDA and EPA. The Cartagena Protocol on Biosafety, an international treaty that governs the transfer, handling, and use of GMOs, was adopted on 29 January 2000. One hundred and fifty-seven countries are members of the Protocol and many use it as a reference point for their own regulations.

The legal and regulatory status of GM foods varies by country, with some nations banning or restricting them, and others permitting them with widely differing degrees of regulation. Some countries allow the import of GM food with authorisation, but either do not allow its cultivation (Russia, Norway, Israel) or have provisions for cultivation even though no GM products are yet produced (Japan, South Korea). Most countries that do not allow GMO cultivation do permit research. Some of the most marked differences occurring between the US and Europe. The US policy focuses on the product (not the process), only looks at verifiable scientific risks and uses the concept of substantial equivalence. The European Union by contrast has possibly the most stringent GMO regulations in the world. All GMOs, along with irradiated food, are considered "new food" and subject to extensive, case-by-case, science-based food evaluation by the European Food Safety Authority. The criteria for authorisation fall in four broad categories: "safety," "freedom of choice," "labelling," and "traceability." The level of regulation in other countries that cultivate GMOs lie in between Europe and the United States.
One of the key issues concerning regulators is whether GM products should be labeled. The European Commission says that mandatory labeling and traceability are needed to allow for informed choice, avoid potential false advertising and facilitate the withdrawal of products if adverse effects on health or the environment are discovered. The American Medical Association and the American Association for the Advancement of Science say that absent scientific evidence of harm even voluntary labeling is misleading and will falsely alarm consumers. Labeling of GMO products in the marketplace is required in 64 countries. Labeling can be mandatory up to a threshold GM content level (which varies between countries) or voluntary. In Canada and the US labeling of GM food is voluntary, while in Europe all food (including processed food) or feed which contains greater than 0.9% of approved GMOs must be labelled.

Critics have objected to the use of genetic engineering on several grounds, including ethical, ecological and economic concerns. Many of these concerns involve GM crops and whether food produced from them is safe and what impact growing them will have on the environment. These controversies have led to litigation, international trade disputes, and protests, and to restrictive regulation of commercial products in some countries.

Accusations that scientists are "playing God" and other religious issues have been ascribed to the technology from the beginning. Other ethical issues raised include the patenting of life, the use of intellectual property rights, the level of labeling on products, control of the food supply and the objectivity of the regulatory process. Although doubts have been raised, economically most studies have found growing GM crops to be beneficial to farmers.

Gene flow between GM crops and compatible plants, along with increased use of selective herbicides, can increase the risk of "superweeds" developing. Other environmental concerns involve potential impacts on non-target organisms, including soil microbes, and an increase in secondary and resistant insect pests. Many of the environmental impacts regarding GM crops may take many years to be understood and are also evident in conventional agriculture practices. With the commercialisation of genetically modified fish there are concerns over what the environmental consequences will be if they escape.

There are three main concerns over the safety of genetically modified food: whether they may provoke an allergic reaction; whether the genes could transfer from the food into human cells; and whether the genes not approved for human consumption could outcross to other crops. There is a scientific consensus that currently available food derived from GM crops poses no greater risk to human health than conventional food, but that each GM food needs to be tested on a case-by-case basis before introduction. Nonetheless, members of the public are less likely than scientists to perceive GM foods as safe.

Genetic engineering features in many science fiction stories. Frank Herbert's novel "The White Plague" described the deliberate use of genetic engineering to create a pathogen which specifically killed women. Another of Herbert's creations, the "Dune" series of novels, uses genetic engineering to create the powerful but despised Tleilaxu. Films such as "The Island" and "Blade Runner" bring the engineered creature to confront the person who created it or the being it was cloned from. Few films have informed audiences about genetic engineering, with the exception of the 1978 "The Boys from Brazil" and the 1993 "Jurassic Park", both of which made use of a lesson, a demonstration, and a clip of scientific film. Genetic engineering methods are weakly represented in film; Michael Clark, writing for The Wellcome Trust, calls the portrayal of genetic engineering and biotechnology "seriously distorted" in films such as "The 6th Day". In Clark's view, the biotechnology is typically "given fantastic but visually arresting forms" while the science is either relegated to the background or fictionalised to suit a young audience.





</doc>
<doc id="12384" url="https://en.wikipedia.org/wiki?curid=12384" title="Gettysburg Address">
Gettysburg Address

The Gettysburg Address is a speech that U.S. President Abraham Lincoln delivered during the American Civil War at the dedication of the Soldiers' National Cemetery in Gettysburg, Pennsylvania, on the afternoon of Thursday, November 19, 1863, four and a half months after the Union armies defeated those of the Confederacy at the Battle of Gettysburg. It is one of the best-known speeches in American history.

Not even the day's primary speech, Lincoln's carefully crafted address came to be seen as one of the greatest and most influential statements of American national purpose. In just 271 words, beginning with the now iconic phrase "Four score and seven years ago,"‍ referring to the signing of the Declaration of Independence 87 years earlier, Lincoln described the US as a nation "conceived in Liberty, and dedicated to the proposition that all men are created equal," and represented the Civil War as a test that would determine whether such a nation, the Union sundered by the secession crisis, could endure. He extolled the sacrifices of those who died at Gettysburg in defense of those principles, and exhorted his listeners to resolve

Despite the prominent place of the speech in the history and popular culture of the United States, its exact wording is disputed. The five known manuscripts of the Gettysburg Address in Lincoln's hand differ in a number of details, and also differ from contemporary newspaper reprints of the speech. Neither is it clear where stood the platform from which Lincoln delivered the address. Modern scholarship locates the speakers' platform 40 yards (or more) away from the traditional site in Soldiers' National Cemetery at the Soldiers' National Monument, such that it stood entirely within the private, adjacent Evergreen Cemetery.

Following the Battle of Gettysburg on July 1–3, 1863, the removal of the fallen Union soldiers from the Gettysburg Battlefield graves and their reburial in graves at the National Cemetery at Gettysburg began on October 17. In inviting President Lincoln to the ceremonies, David Wills, of the committee for the November 19 Consecration of the National Cemetery at Gettysburg, wrote, "It is the desire that, after the Oration, you, as Chief Executive of the nation, formally set apart these grounds to their sacred use by a few appropriate remarks."

On the train trip from Washington, D.C., to Gettysburg on November 18, Lincoln was accompanied by three members of his Cabinet, William Seward, John Usher and Montgomery Blair, several foreign officials, his secretary John Nicolay, and his assistant secretary, John Hay. During the trip Lincoln remarked to Hay that he felt weak; on the morning of November 19, Lincoln mentioned to Nicolay that he was dizzy. Hay noted that during the speech Lincoln's face had "a ghastly color" and that he was "sad, mournful, almost haggard." After the speech, when Lincoln boarded the 6:30 pm train for Washington, D.C., he was feverish and weak, with a severe headache. A protracted illness followed, which included a vesicular rash; it was diagnosed as a mild case of smallpox. It thus seems highly likely that Lincoln was in the prodromal period of smallpox when he delivered the Gettysburg address.

The program organized for that day by Wills and his committee included:

While it is Lincoln's short speech that has gone down in history as one of the finest examples of English public oratory, it was Everett's two-hour oration that was slated to be the "Gettysburg address" that day. His now seldom-read 13,607-word oration began:

Standing beneath this serene sky, overlooking these broad fields now reposing from the labors of the waning year, the mighty Alleghenies dimly towering before us, the graves of our brethren beneath our feet, it is with hesitation that I raise my poor voice to break the eloquent silence of God and Nature. But the duty to which you have called me must be performed;—grant me, I pray you, your indulgence and your sympathy.

And ended two hours later with:

But they, I am sure, will join us in saying, as we bid farewell to the dust of these martyr-heroes, that wheresoever throughout the civilized world the accounts of this great warfare are read, and down to the latest period of recorded time, in the glorious annals of our common country, there will be no brighter page than that which relates the Battles of Gettysburg.

Lengthy dedication addresses like Everett's were common at cemeteries in this era. The tradition began in 1831 when Justice Joseph Story delivered the dedication address at Mount Auburn Cemetery in Cambridge, Massachusetts. Those addresses often linked cemeteries to the mission of Union.

Lincoln's address followed the oration by Edward Everett, who subsequently included a copy of the Gettysburg Address in his 1864 book about the event ("Address of the Hon. Edward Everett At the Consecration of the National Cemetery At Gettysburg, 19th November 1863, with the Dedicatory Speech of President Lincoln, and the Other Exercises of the Occasion; Accompanied by An Account of the Origin of the Undertaking and of the Arrangement of the Cemetery Grounds, and by a Map of the Battle-field and a Plan of the Cemetery").

Shortly after Everett's well-received remarks, Lincoln spoke for only a few minutes. With a "few appropriate remarks", he was able to summarize his view of the war in just ten sentences.

Despite the historical significance of Lincoln's speech, modern scholars disagree as to its exact wording, and contemporary transcriptions published in newspaper accounts of the event and even handwritten copies by Lincoln himself differ in their wording, punctuation, and structure. Of these versions, the Bliss version, written well after the speech as a favor for a friend, is viewed by many as the standard text. Its text differs, however, from the written versions prepared by Lincoln before and after his speech. It is the only version to which Lincoln affixed his signature, and the last he is known to have written.

In "Lincoln at Gettysburg", Garry Wills notes the parallels between Lincoln's speech and Pericles's Funeral Oration during the Peloponnesian War as described by Thucydides. (James McPherson notes this connection in his review of Wills's book. Gore Vidal also draws attention to this link in a BBC documentary about oration.) Pericles' speech, like Lincoln's:
In contrast, writer Adam Gopnik, in "The New Yorker", notes that while Everett's Oration was explicitly neoclassical, referring directly to Marathon and Pericles, "Lincoln's rhetoric is, instead, deliberately Biblical. (It is difficult to find a single obviously classical reference in any of his speeches.) Lincoln had mastered the sound of the King James Bible so completely that he could recast abstract issues of constitutional law in Biblical terms, making the proposition that Texas and New Hampshire should be forever bound by a single post office sound like something right out of Genesis."

Several theories have been advanced by Lincoln scholars to explain the provenance of Lincoln's famous phrase "government of the people, by the people, for the people". Despite many claims, there is no evidence a similar phrase appears in the Prologue to John Wycliffe's 1384 English translation of the Bible.

In a discussion "A more probable origin of a famous Lincoln phrase", in "The American Monthly Review of Reviews", Albert Shaw credits a correspondent with pointing out the writings of William Herndon, Lincoln's law partner, who wrote in the 1888 work "Abraham Lincoln: The True Story of A Great Life" that he had brought to Lincoln some of the sermons of abolitionist minister Theodore Parker, of Massachusetts, and that Lincoln was moved by Parker's use of this idea:

Craig R. Smith, in "Criticism of Political Rhetoric and Disciplinary Integrity", suggested Lincoln's view of the government as expressed in the Gettysburg Address was influenced by the noted speech of Massachusetts Senator Daniel Webster, the "Second Reply to Hayne", in which Webster famously thundered "Liberty and Union, now and forever, one and inseparable!" Specifically, in this speech on January 26, 1830, before the United States Senate, Webster described the federal government as: "made for the people, made by the people, and answerable to the people", foreshadowing Lincoln's "government of the people, by the people, for the people". Webster also noted, "This government, Sir, is the independent offspring of the popular will. It is not the creature of State legislatures; nay, more, if the whole truth must be told, the people brought it into existence, established it, and have hitherto supported it, for the very purpose, amongst others, of imposing certain salutary restraints on State sovereignties."

A source predating these others with which Lincoln was certainly familiar was Chief Justice John Marshall's opinion in "McCulloch v. Maryland" (1819), a case upholding federal authority to create a national bank and to be free from the State's powers to tax. In asserting the superiority of federal power over the states, Chief Justice Marshall stated: "The government of the Union, then (whatever may be the influence of this fact on the case), is, emphatically and truly, a government of the people. In form, and in substance, it emanates from them. Its powers are granted by them, and are to be exercised directly on them, and for their benefit." Lincoln, a lawyer and President engaged in the greatest struggle of federalism, was (more eloquently) echoing the preeminent case that had solidified federal power over the States.

Wills observed Lincoln's usage of the imagery of birth, life, and death in reference to a nation "brought forth", "conceived", and that shall not "perish". Others, including Allen C. Guelzo, the director of Civil War Era studies at Gettysburg College in Pennsylvania, suggested that Lincoln's formulation "four score and seven" was an allusion to the King James Version of the Bible's , in which man's lifespan is given as "threescore years and ten; and if by reason of strength they be fourscore years".

Lincoln was probably influenced by Lajos Kossuth—the former governor-president of Hungary—who gave a speech before the Ohio State Legislature in February 1852: "The spirit of our age is Democracy. All for the people, and all by the people. Nothing about the people without the people—That is Democracy! […]"

Each of the five known manuscript copies of the Gettysburg Address is named for the person who received it from Lincoln. Lincoln gave copies to his private secretaries, John Nicolay and John Hay. Both of these drafts were written around the time of his November 19 address, while the other three copies of the address, the Everett, Bancroft, and Bliss copies, were written by Lincoln for charitable purposes well after November 19. In part because Lincoln provided a title and signed and dated the Bliss copy, it has become the standard text of Lincoln's Gettysburg Address.

Nicolay and Hay were appointed custodians of Lincoln's papers by Lincoln's son Robert Todd Lincoln in 1874. After appearing in facsimile in an article written by John Nicolay in 1894, the Nicolay copy was presumably among the papers passed to Hay by Nicolay's daughter Helen upon Nicolay's death in 1901. Robert Lincoln began a search for the original copy in 1908, which resulted in the discovery of a handwritten copy of the Gettysburg Address among the bound papers of John Hay—a copy now known as the "Hay copy" or "Hay draft".

The Hay draft differed from the version of the Gettysburg Address published by John Nicolay in 1894 in a number of significant ways: it was written on a different type of paper, had a different number of words per line and number of lines, and contained editorial revisions in Lincoln's hand.

Both the Hay and Nicolay copies of the Address are within the Library of Congress, encased in specially designed, temperature-controlled, sealed containers with argon gas in order to protect the documents from oxidation and continued deterioration.

The Nicolay copy is often called the "first draft" because it is believed to be the earliest copy that exists. Scholars disagree over whether the Nicolay copy was actually the reading copy Lincoln held at Gettysburg on November 19. In an 1894 article that included a facsimile of this copy, Nicolay, who had become the custodian of Lincoln's papers, wrote that Lincoln had brought to Gettysburg the first part of the speech written in ink on Executive Mansion stationery, and that he had written the second page in pencil on lined paper before the dedication on November 19. Matching folds are still evident on the two pages, suggesting it could be the copy that eyewitnesses say Lincoln took from his coat pocket and read at the ceremony. Others believe that the delivery text has been lost, because some of the words and phrases of the Nicolay copy do not match contemporary transcriptions of Lincoln's original speech. The words "under God", for example, are missing in this copy from the phrase "that this nation shall have a new birth of freedom  ..." In order for the Nicolay draft to have been the reading copy, either the contemporary transcriptions were inaccurate, or Lincoln would have had to depart from his written text in several instances. This copy of the Gettysburg Address apparently remained in John Nicolay's possession until his death in 1901, when it passed to his friend and colleague John Hay. It used to be on display as part of the American Treasures exhibition of the Library of Congress in Washington, D.C.

The existence of the Hay copy was first announced to the public in 1906, after the search for the "original manuscript" of the Address among the papers of John Hay brought it to light. Significantly, it differs somewhat from the manuscript of the Address described by John Nicolay in his article, and contains numerous omissions and inserts in Lincoln's own hand, including omissions critical to the basic meaning of the sentence, not simply words that would be added by Lincoln to strengthen or clarify their meaning. In this copy, as in the Nicolay copy, the words "under God" are not present.

This version has been described as "the most inexplicable" of the drafts and is sometimes referred to as the "second draft". The "Hay copy" was made either on the morning of the delivery of the Address, or shortly after Lincoln's return to Washington. Those who believe that it was completed on the morning of his address point to the fact that it contains certain phrases that are not in the first draft but are in the reports of the address as delivered and in subsequent copies made by Lincoln. It is probable, they conclude, that, as stated in the explanatory note accompanying the original copies of the first and second drafts in the Library of Congress, Lincoln held this second draft when he delivered the address. Lincoln eventually gave this copy to Hay, whose descendants donated both it and the Nicolay copy to the Library of Congress in 1916.

The Everett copy, also known as the "Everett-Keyes copy", was sent by President Lincoln to Edward Everett in early 1864, at Everett's request. Everett was collecting the speeches at the Gettysburg dedication into one bound volume to sell for the benefit of stricken soldiers at New York's Sanitary Commission Fair. The draft Lincoln sent became the third autograph copy, and is now in the possession of the Illinois State Historical Library in Springfield, Illinois, where it is displayed in the Treasures Gallery of the Abraham Lincoln Presidential Library and Museum.

The Bancroft copy of the Gettysburg Address was written out by President Lincoln in February 1864 at the request of George Bancroft, the famed historian and former Secretary of the Navy, whose comprehensive ten-volume "History of the United States" later led him to be known as the "father of American History". Bancroft planned to include this copy in "Autograph Leaves of Our Country's Authors", which he planned to sell at a Soldiers' and Sailors' Sanitary Fair in Baltimore. As this fourth copy was written on both sides of the paper, it proved unusable for this purpose, and Bancroft was allowed to keep it. This manuscript is the only one accompanied both by a letter from Lincoln transmitting the manuscript and by the original envelope addressed and franked by Lincoln. This copy remained in the Bancroft family for many years, was sold to various dealers and purchased by Nicholas and Marguerite Lilly Noyes, who donated the manuscript to Cornell University in 1949. It is now held by the Division of Rare and Manuscript Collections in the Carl A. Kroch Library at Cornell. It is the only one of the five copies to be privately owned.

Discovering that his fourth written copy could not be used, Lincoln then wrote a fifth draft, which was accepted for the purpose requested. The Bliss copy, named for Colonel Alexander Bliss, Bancroft's stepson and publisher of "Autograph Leaves", is the only draft to which Lincoln affixed his signature. Lincoln is not known to have made any further copies of the Gettysburg Address. Because of the apparent care in its preparation, and in part, because Lincoln provided a title and signed and dated this copy, it has become the standard version of the address and the source for most facsimile reproductions of Lincoln's Gettysburg Address. It is the version that is inscribed on the South wall of the Lincoln Memorial.

This draft is now displayed in the Lincoln Room of the White House, a gift of Oscar B. Cintas, former Cuban Ambassador to the United States. Cintas, a wealthy collector of art and manuscripts, purchased the Bliss copy at a public auction in 1949 for $54,000 ($ as of 2020), at that time the highest price ever paid for a document at public auction. Cintas' properties were claimed by the Castro government after the Cuban Revolution in 1959, but Cintas, who died in 1957, willed the Gettysburg Address to the American people, provided it would be kept at the White House, where it was transferred in 1959.

Garry Wills concluded the Bliss copy "is stylistically preferable to others in one significant way: Lincoln removed 'here' from 'that cause for which they (here) gave  ... ' The seventh 'here' is in all other versions of the speech." Wills noted the fact that Lincoln "was still making such improvements", suggesting Lincoln was more concerned with a perfected text than with an 'original' one.

From November 21, 2008, to January 1, 2009, the Albert H. Small Documents Gallery at the Smithsonian Institution National Museum of American History hosted a limited public viewing of the Bliss copy, with the support of then-First Lady Laura Bush. The Museum also launched an online exhibition and interactive gallery to enable visitors to look more closely at the document.

Another contemporary source of the text is the Associated Press dispatch, transcribed from the shorthand notes taken by reporter Joseph L. Gilbert. It also differs from the drafted text in a number of minor ways.

Eyewitness reports vary as to their view of Lincoln's performance. In 1931, the printed recollections of 87-year-old Mrs. Sarah A. Cooke Myers, who was 19 when she attended the ceremony, suggest a dignified silence followed Lincoln's speech: "I was close to the President and heard all of the Address, but it seemed short. Then there was an impressive silence like our Menallen Friends Meeting. There was no applause when he stopped speaking." According to historian Shelby Foote, after Lincoln's presentation, the applause was delayed, scattered, and "barely polite". In contrast, Pennsylvania Governor Andrew Gregg Curtin maintained, "He pronounced that speech in a voice that all the multitude heard. The crowd was hushed into silence because the President stood before them  ... It was so Impressive! It was the common remark of everybody. Such a speech, as they said it was!" Reinterment of soldiers' remains from field graves into the cemetery, which had begun within months of the battle, was less than half complete on the day of the ceremony.

In an oft-repeated legend, Lincoln is said to have turned to his bodyguard Ward Hill Lamon and remarked that his speech, like a bad plow, "won't scour". According to Garry Wills, this statement has no basis in fact and largely originates from the unreliable recollections of Lamon. In Garry Wills's view, " had done what he wanted to do ".

In a letter to Lincoln written the following day, Everett praised the President for his eloquent and concise speech, saying, "I should be glad if I could flatter myself that I came as near to the central idea of the occasion, in two hours, as you did in two minutes." Lincoln replied that he was glad to know the speech was not a "total failure".

Other public reaction to the speech was divided along partisan lines. The Democratic-leaning "Chicago Times" observed, "The cheek of every American must tingle with shame as he reads the silly, flat and dishwatery utterances of the man who has to be pointed out to intelligent foreigners as the President of the United States." In contrast, the Republican-leaning "The New York Times" was complimentary and printed the speech. In Massachusetts, the "Springfield Republican" also printed the entire speech, calling it "a perfect gem" that was "deep in feeling, compact in thought and expression, and tasteful and elegant in every word and comma". The "Republican" predicted that Lincoln's brief remarks would "repay further study as the model speech". On the sesquicentennial of the address, "The Patriot-News" of Harrisburg, Pennsylvania, formerly the "Patriot & Union", retracted its original reaction ("silly remarks" deserving "the veil of oblivion") stating: "Seven score and ten years ago, the forefathers of this media institution brought forth to its audience a judgment so flawed, so tainted by hubris, so lacking in the perspective history would bring, that it cannot remain unaddressed in our archives.  ... the "Patriot & Union" failed to recognize [the speech's] momentous importance, timeless eloquence, and lasting significance. The "Patriot-News" regrets the error."

Foreign newspapers also criticized Lincoln's remarks. "The Times" of London commented: "The ceremony [at Gettysburg] was rendered ludicrous by some of the luckless sallies of that poor President Lincoln."

Congressman Joseph A. Goulden, then an eighteen-year-old school teacher, was present and heard the speech. He served in the United States Marine Corps during the war, and later had a successful career in insurance in Pennsylvania and New York City before entering Congress as a Democrat. In his later life, Goulden was often asked about the speech, since the passage of time made him one of a dwindling number of individuals who had been present for it. He commented on the event and Lincoln's speech in favorable terms, naming Lincoln's address as one of the inspirations for him to enter military service. Goulden's recollections included remarks to the House of Representatives in 1914.

William R. Rathvon is the only known eyewitness of both Lincoln's arrival at Gettysburg and the address itself to have left an audio recording of his recollections which can be found here . One year before his death in 1939, Rathvon's reminiscences were recorded on February 12, 1938, at the Boston studios of radio station WRUL, including his reading the address, itself, and a 78 RPM record was pressed. The title of the 78 record was "I Heard Lincoln That Day – William R. Rathvon, TR Productions". A copy wound up at National Public Radio (NPR) during a "Quest for Sound" project in 1999. This link depicts the story but it can no longer play it.

Like most people who came to Gettysburg, the Rathvon family was aware that Lincoln was going to make some remarks. The family went to the town square where the procession was to form to go out to the cemetery that had not been completed yet. At the head of the procession rode Lincoln on a gray horse preceded by a military band that was the first the young boy had ever seen. Rathvon describes Lincoln as so tall and with such long legs that they went almost to the ground; he also mentions the long eloquent speech given by Edward Everett of Massachusetts whom Rathvon accurately described as the "most finished orator of the day". Rathvon then goes on to describe how Lincoln stepped forward and "with a manner serious almost to sadness, gave his brief address". During the delivery, along with some other boys, young Rathvon wiggled his way forward through the crowd until he stood within 15 feet of Mr. Lincoln and looked up into what he described as Lincoln's "serious face". Rathvon recalls candidly that, although he listened "intently to every word the president uttered and heard it clearly", he explains, "boylike, I could not recall any of it afterwards". But he explains that if anyone said anything disparaging about "honest Abe", there would have been a "junior battle of Gettysburg". In the recording Rathvon speaks of Lincoln's speech allegorically "echoing through the hills".

The only known and confirmed photograph of Lincoln at Gettysburg, taken by photographer David Bachrach, was identified in the Mathew Brady collection of photographic plates in the National Archives and Records Administration in 1952. While Lincoln's speech was short and may have precluded multiple pictures of him while speaking, he and the other dignitaries sat for hours during the rest of the program. Given the length of Everett's speech and the length of time it took for 19th-century photographers to get "set up" before taking a picture, it is quite plausible that the photographers were ill-prepared for the brevity of Lincoln's remarks.

The words "under God" do not appear in the Nicolay and Hay drafts but are included in the three later copies (Everett, Bancroft, and Bliss). Accordingly, some skeptics maintain that Lincoln did not utter the words "under God" at Gettysburg. However, at least three reporters telegraphed the text of Lincoln's speech on the day the Address was given with the words "under God" included. Historian William E. Barton argues that:

The reporters present included Joseph Gilbert, from the Associated Press; Charles Hale, from the "Boston Advertiser"; John R. Young (who later became the Librarian of Congress), from the "Philadelphia Press"; and reporters from the "Cincinnati Commercial", "New York Tribune", and "The New York Times". Charles Hale "had notebook and pencil in hand, [and] took down the slow-spoken words of the President". "He took down what he declared was the exact language of Lincoln's address, and his declaration was as good as the oath of a court stenographer. His associates confirmed his testimony, which was received, as it deserved to be, at its face value." One explanation is that Lincoln deviated from his prepared text and inserted the phrase when he spoke. Ronald C. White, visiting professor of history at the University of California, Los Angeles and professor of American religious history emeritus at the San Francisco Theological Seminary, wrote in this context of Lincoln's insertion and usage of "under God":

It was an uncharacteristically spontaneous revision for a speaker who did not trust extemporaneous speech. Lincoln had added impromptu words in several earlier speeches, but always offered a subsequent apology for the change. In this instance, he did not. And Lincoln included "under God" in all three copies of the address he prepared at later dates. "Under God" pointed backward and forward: back to "this nation", which drew its breath from both political and religious sources, but also forward to a "new birth". Lincoln had come to see the Civil War as a ritual of purification. The old Union had to die. The old man had to die. Death became a transition to a new Union and a new humanity.

The phrase "under God" was used frequently in works published before 1860, usually with the meaning "with God's help".

Outside the Cemetery and within sight of the crosswalk, a historical marker reads:

Nearby, Nov. 19, 1863, in dedicating the National Cemetery, Abraham Lincoln gave the address which he had written in Washington and revised after his arrival at Gettysburg the evening of November 18.

Directly inside the Taneytown Road entrance are located the Rostrum and the "Lincoln Address Memorial." Neither of these is located within 300 yards of any of the five (or more) claimed locations for the dedicatory platform.

Colonel W. Yates Selleck was a marshal in the parade on Consecration Day and was seated on the platform when Lincoln made the address. Selleck marked a map with the position of the platform and described it as "350 feet almost due north of Soldiers' National Monument, 40 feet from a point in the outer circle of lots where [the] Michigan and New York [burial sections] are separated by a path". A location which approximates this description is 39°49.243′N, 77°13.869′W.

As pointed out in 1973 by retired park historian Frederick Tilberg, the "Selleck Site" is 25 feet lower than the crest of Cemetery Hill, and only the crest presents a panoramic view of the battlefield. A spectacular view from the location of the speech was noted by many eyewitnesses, is consistent with the "Traditional Site" at the Soldiers' National Monument (and other sites on the crest) but is inconsistent with the "Selleck Site."

The "Kentucky Memorial", erected in 1975, is directly adjacent to the Soldiers' National Monument, and states, "Kentucky honors her son, Abraham Lincoln, who delivered his immortal address at the site now marked by the soldiers' monument." With its position at the center of the concentric rings of soldiers' graves and the continuing endorsement of Lincoln's native state the Soldiers' National Monument persists as a credible location for the speech.

Writing a physical description of the layout for the Gettysburg National Cemetery under construction in November 1863, the correspondent from the "Cincinnati Daily Commercial" described the dividing lines between the state grave plots as "the radii of a common center, where a flag pole is now raised, but where it is proposed to erect a national monument". With the inclusion of this quotation Tilberg inadvertently verifies a central principle of future photographic analyses—a flagpole, rather than the speakers' platform, occupied the central point of the soldiers' graves. In fact, the precision of the photo-analyses relies upon the coincidence of position between this temporary flag pole and the future monument.

Confusing to today's tourist, the "Kentucky Memorial" is contradicted by a newer marker which was erected nearby by the Gettysburg National Military Park and locates the speakers' platform inside Evergreen Cemetery. Similarly, outdated National Park Service documents which pinpoint the location at the Soldiers' National Monument have not been systematically revised since the placement of the newer marker. Miscellaneous web pages perpetuate the "Traditional Site."

Based upon photographic analysis, the Gettysburg National Military Park (G.N.M.P.) placed a marker (near ) which states, "The speakers' platform was located in Evergreen Cemetery to your left." The observer of this marker stands facing the fence which separates the two cemeteries (one public and one private).

In 1982, Senior Park Historian Kathleen Georg Harrison first analyzed photographs and proposed a location in Evergreen Cemetery but has not published her analysis. Speaking for Harrison without revealing details, two sources characterize her proposed location as "on or near [the] Brown family vault" in Evergreen Cemetery.

William A. Frassanito, a former military intelligence analyst, documented a comprehensive photographic analysis in 1995, and it associates the location of the platform with the position of specific modern headstones in Evergreen Cemetery. According to Frassanito, the extant graves of Israel Yount (died 1892)(), John Koch (died 1913)(), and George E. Kitzmiller (died 1874)() are among those which occupy the location of the 1863 speaker's stand.

The GNMP marker, Wills's interpretation of Harrison's analysis, and the Frassanito analysis concur that the platform was located in private Evergreen Cemetery, rather than public Soldiers' National Cemetery. The National Park Service's "National Cemetery Walking Tour" brochure is one NPS document which agrees:
The Soldiers' National Monument, long misidentified as the spot from which Lincoln spoke, honors the fallen soldiers. [The location of the speech] was actually on the crown of this hill, a short distance on the other side of the iron fence and inside the Evergreen Cemetery, where President Lincoln delivered the Gettysburg Address to a crowd of some 15,000 people.

While the GNMP marker is unspecific, providing only "to your left", the locations determined by the Harrison/Wills analysis and the Frassanito analysis differ by 40 yards. Frassanito has documented 1) his own conclusion, 2) his own
methods and 3) a refutation of the Harrison site, but neither the GNMP nor Harrison has provided any documentation. Each of the three points to a location in Evergreen Cemetery, as do modern NPS publications.

Although Lincoln dedicated the Gettysburg National Cemetery, the monument at the Cemetery's center actually has nothing to do with Lincoln or his famous speech. Intended to symbolize Columbia paying tribute to her fallen sons, its appreciation has been commandeered by the thirst for a tidy home for the speech. Freeing the Cemetery and Monument to serve their original purpose, honoring of Union departed, is as unlikely as a resolution to the location controversy and the erection of a public monument to the speech in the exclusively private Evergreen Cemetery.

The importance of the Gettysburg Address in the history of the United States is underscored by its enduring presence in American culture. In addition to its prominent place carved into a stone cella on the south wall of the Lincoln Memorial in Washington, D.C., the Gettysburg Address is frequently referred to in works of popular culture, with the implicit expectation that contemporary audiences will be familiar with Lincoln's words.

In the many generations that have passed since the Address, it has remained among the most famous speeches in American history, and is often taught in classes about history or civics. Lincoln's Gettysburg Address is itself referenced in another of those famed orations, Martin Luther King Jr.'s "I Have a Dream" speech. Standing on the steps of the Lincoln Memorial in August 1963, King began with a reference, by the style of his opening phrase, to President Lincoln and his enduring words: "Five score years ago, a great American, in whose symbolic shadow we stand today, signed the Emancipation Proclamation. This momentous decree came as a great beacon light of hope to millions of Negro slaves who had been seared in the flames of withering injustice."

Phrases from the Address are often used or referenced in other works. The current Constitution of France states that the principle of the French Republic is ""gouvernement du peuple, par le peuple et pour le peuple" ("government of the people, by the people, and for the people"), a literal translation of Lincoln's words. Sun Yat-Sen's "Three Principles of the People" as well as the preamble for the 1947 Constitution of Japan were also inspired from that phrase. The aircraft carrier has as its ship's motto the phrase "shall not perish".

U.S. Senator Charles Sumner of Massachusetts wrote of the address and its enduring presence in American culture after Lincoln's assassination in April 1865: "That speech, uttered at the field of Gettysburg  ... and now sanctified by the martyrdom of its author, is a monumental act. In the modesty of his nature he said 'the world will little note, nor long remember what we say here; but it can never forget what they did here.' He was mistaken. The world at once noted what he said, and will never cease to remember it."

U.S. President John F. Kennedy stated in July 1963 about the battle and Lincoln's speech: "Five score years ago the ground on which we here stand shuddered under the clash of arms and was consecrated for all time by the blood of American manhood. Abraham Lincoln, in dedicating this great battlefield, has expressed, in words too eloquent for paraphrase or summary, why this sacrifice was necessary." Kennedy was himself assassinated three days after the Gettysburg Address centennial.

In 2015, the Abraham Lincoln Presidential Library Foundation compiled "Gettysburg Replies: The World Responds to Abraham Lincoln's Gettysburg Address". The work challenges leaders to craft 272 word responses to celebrate Lincoln, the Gettysburg Address, or a related topic.
One of the replies was by astrophysicist Neil deGrasse Tyson in which he made the point that one of Lincoln's greatest legacies was establishing, in the same year of the Gettysburg Address, the National Academy of Sciences, which had the longterm effect of "setting our Nation on a course of scientifically enlightened governance, without which we all may perish from this Earth".

A common American myth about the Gettysburg Address is that Lincoln quickly wrote the speech on the back of an envelope. This widely held misunderstanding may have originated with a popular book, "The Perfect Tribute", by Mary Raymond Shipman Andrews (1906), which was assigned reading for generations of schoolchildren, sold 600,000 copies when published as a standalone volume, and was twice adapted for film.

Other lesser-known claims include Harriet Beecher Stowe's assertion that Lincoln had composed the address "in only a few moments," and that of industrialist Andrew Carnegie, who claimed to have personally supplied Lincoln with a pen.





</doc>
<doc id="12385" url="https://en.wikipedia.org/wiki?curid=12385" title="Genetic code">
Genetic code

The genetic code is the set of rules used by living cells to translate information encoded within genetic material (DNA or mRNA sequences of nucleotide triplets, or codons) into proteins. Translation is accomplished by the ribosome, which links amino acids in an order specified by messenger RNA (mRNA), using transfer RNA (tRNA) molecules to carry amino acids and to read the mRNA three nucleotides at a time. The genetic code is highly similar among all organisms and can be expressed in a simple table with 64 entries.

The code defines how codons specify which amino acid will be added next during protein synthesis. With some exceptions, a three-nucleotide codon in a nucleic acid sequence specifies a single amino acid. The vast majority of genes are encoded with a single scheme (see the RNA codon table). That scheme is often referred to as the canonical or standard genetic code, or simply "the" genetic code, though variant codes (such as in human mitochondria) exist.

While the "genetic code" is what determines a protein's amino acid sequence, other genomic regions determine when and where these proteins are produced according to various "gene regulatory codes".

Efforts to understand how proteins are encoded began after DNA's structure was discovered in 1953. George Gamow postulated that sets of three bases must be employed to encode the 20 standard amino acids used by living cells to build proteins, which would allow a maximum of 64 amino acids.

The Crick, Brenner, Barnett and Watts-Tobin experiment first demonstrated that codons consist of three DNA bases. Marshall Nirenberg and Heinrich J. Matthaei were the first to reveal the nature of a codon in 1961.

They used a cell-free system to translate a poly-uracil RNA sequence (i.e., UUUUU...) and discovered that the polypeptide that they had synthesized consisted of only the amino acid phenylalanine. They thereby deduced that the codon UUU specified the amino acid phenylalanine.

This was followed by experiments in Severo Ochoa's laboratory that demonstrated that the poly-adenine RNA sequence (AAAAA...) coded for the polypeptide poly-lysine and that the poly-cytosine RNA sequence (CCCCC...) coded for the polypeptide poly-proline. Therefore, the codon AAA specified the amino acid lysine, and the codon CCC specified the amino acid proline. Using various copolymers most of the remaining codons were then determined.

Subsequent work by Har Gobind Khorana identified the rest of the genetic code. Shortly thereafter, Robert W. Holley determined the structure of transfer RNA (tRNA), the adapter molecule that facilitates the process of translating RNA into protein. This work was based upon Ochoa's earlier studies, yielding the latter the Nobel Prize in Physiology or Medicine in 1959 for work on the enzymology of RNA synthesis.

Extending this work, Nirenberg and Philip Leder revealed the code's triplet nature and deciphered its codons. In these experiments, various combinations of mRNA were passed through a filter that contained ribosomes, the components of cells that translate RNA into protein. Unique triplets promoted the binding of specific tRNAs to the ribosome. Leder and Nirenberg were able to determine the sequences of 54 out of 64 codons in their experiments. Khorana, Holley and Nirenberg received the 1968 Nobel for their work.

The three stop codons were named by discoverers Richard Epstein and Charles Steinberg. "Amber" was named after their friend Harris Bernstein, whose last name means "amber" in German. The other two stop codons were named "ochre" and "opal" in order to keep the "color names" theme.

In a broad academic audience, the concept of the evolution of the genetic code from the original and ambiguous genetic code to a well-defined ("frozen") code with the repertoire of 20 (+2) canonical amino acids is widely accepted.
However, there are different opinions, concepts, approaches and ideas, which is the best way to change it experimentally. Even models are proposed that predict "entry points" for synthetic amino acid invasion of the genetic code.

Since 2001, 40 non-natural amino acids have been added into protein by creating a unique codon (recoding) and a corresponding transfer-RNA:aminoacyl – tRNA-synthetase pair to encode it with diverse physicochemical and biological properties in order to be used as a tool to exploring protein structure and function or to create novel or enhanced proteins.

H. Murakami and M. Sisido extended some codons to have four and five bases. Steven A. Benner constructed a functional 65th ("in vivo") codon.

In 2015 N. Budisa, D. Söll and co-workers reported the full substitution of all 20,899 tryptophan residues (UGG codons) with unnatural thienopyrrole-alanine in the genetic code of the bacterium "Escherichia coli".

In 2016 the first stable semisynthetic organism was created. It was a (single cell) bacterium with two synthetic bases (called X and Y). The bases survived cell division.

In 2017, researchers in South Korea reported that they had engineered a mouse with an extended genetic code that can produce proteins with unnatural amino acids.

In May 2019, researchers, in a milestone effort, reported the creation of a new synthetic (possibly artificial) form of viable life, a variant of the bacteria "Escherichia coli", by reducing the natural number of 64 codons in the bacterial genome to 59 codons instead, in order to encode 20 amino acids.

A reading frame is defined by the initial triplet of nucleotides from which translation starts. It sets the frame for a run of successive, non-overlapping codons, which is known as an "open reading frame" (ORF). For example, the string 5'-AAATGAACG-3' (see figure), if read from the first position, contains the codons AAA, TGA, and ACG ; if read from the second position, it contains the codons AAT and GAA ; and if read from the third position, it contains the codons ATG and AAC. Every sequence can, thus, be read in its 5' → 3' direction in three reading frames, each producing a possibly distinct amino acid sequence: in the given example, Lys (K)-Trp (W)-Thr (T), Asn (N)-Glu (E), or Met (M)-Asn (N), respectively (when translating with the vertebrate mitochondrial code). When DNA is double-stranded, six possible reading frames are defined, three in the forward orientation on one strand and three reverse on the opposite strand. Protein-coding frames are defined by a start codon, usually the first AUG (ATG) codon in the RNA (DNA) sequence.

In eukaryotes, ORFs in exons are often interrupted by introns.

Translation starts with a chain-initiation codon or start codon. The start codon alone is not sufficient to begin the process. Nearby sequences such as the Shine-Dalgarno sequence in "E. coli" and initiation factors are also required to start translation. The most common start codon is AUG, which is read as methionine or, in bacteria, as formylmethionine. Alternative start codons depending on the organism include "GUG" or "UUG"; these codons normally represent valine and leucine, respectively, but as start codons they are translated as methionine or formylmethionine.

The three stop codons have names: UAG is "amber", UGA is "opal" (sometimes also called "umber"), and UAA is "ochre". Stop codons are also called "termination" or "nonsense" codons. They signal release of the nascent polypeptide from the ribosome because no cognate tRNA has anticodons complementary to these stop signals, allowing a release factor to bind to the ribosome instead.

During the process of DNA replication, errors occasionally occur in the polymerization of the second strand. These errors, mutations, can affect an organism's phenotype, especially if they occur within the protein coding sequence of a gene. Error rates are typically 1 error in every 10–100 million bases—due to the "proofreading" ability of DNA polymerases.

Missense mutations and nonsense mutations are examples of point mutations that can cause genetic diseases such as sickle-cell disease and thalassemia respectively. Clinically important missense mutations generally change the properties of the coded amino acid residue among basic, acidic, polar or non-polar states, whereas nonsense mutations result in a stop codon.

Mutations that disrupt the reading frame sequence by indels (insertions or deletions) of a non-multiple of 3 nucleotide bases are known as frameshift mutations. These mutations usually result in a completely different translation from the original, and likely cause a stop codon to be read, which truncates the protein. These mutations may impair the protein's function and are thus rare in "in vivo" protein-coding sequences. One reason inheritance of frameshift mutations is rare is that, if the protein being translated is essential for growth under the selective pressures the organism faces, absence of a functional protein may cause death before the organism becomes viable. Frameshift mutations may result in severe genetic diseases such as Tay–Sachs disease.

Although most mutations that change protein sequences are harmful or neutral, some mutations have benefits. These mutations may enable the mutant organism to withstand particular environmental stresses better than wild type organisms, or reproduce more quickly. In these cases a mutation will tend to become more common in a population through natural selection. Viruses that use RNA as their genetic material have rapid mutation rates, which can be an advantage, since these viruses thereby evolve rapidly, and thus evade the immune system defensive responses. In large populations of asexually reproducing organisms, for example, "E. coli", multiple beneficial mutations may co-occur. This phenomenon is called clonal interference and causes competition among the mutations.

Degeneracy is the redundancy of the genetic code. This term was given by Bernfield and Nirenberg. The genetic code has redundancy but no ambiguity (see the codon tables below for the full correlation). For example, although codons GAA and GAG both specify glutamic acid (redundancy), neither specifies another amino acid (no ambiguity). The codons encoding one amino acid may differ in any of their three positions. For example, the amino acid leucine is specified by YUR or CUN (UUA, UUG, CUU, CUC, CUA, or CUG) codons (difference in the first or third position indicated using IUPAC notation), while the amino acid serine is specified by UCN or AGY (UCA, UCG, UCC, UCU, AGU, or AGC) codons (difference in the first, second, or third position). A practical consequence of redundancy is that errors in the third position of the triplet codon cause only a silent mutation or an error that would not affect the protein because the hydrophilicity or hydrophobicity is maintained by equivalent substitution of amino acids; for example, a codon of NUN (where N = any nucleotide) tends to code for hydrophobic amino acids. NCN yields amino acid residues that are small in size and moderate in hydropathicity; NAN encodes average size hydrophilic residues. The genetic code is so well-structured for hydropathicity that a mathematical analysis (Singular Value Decomposition) of 12 variables (4 nucleotides x 3 positions) yields a remarkable correlation (C = 0.95) for predicting the hydropathicity of the encoded amino acid directly from the triplet nucleotide sequence, "without translation." Note in the table, below, eight amino acids are not affected at all by mutations at the third position of the codon, whereas in the figure above, a mutation at the second position is likely to cause a radical change in the physicochemical properties of the encoded amino acid.
Nevertheless, changes in the first position of the codons are more important than changes in the second position on a global scale. The reason may be that charge reversal (from a positive to a negative charge or vice versa) can only occur upon mutations in the first position, but never upon changes in the second position of a codon. Such charge reversal may have dramatic consequences for the structure or function of a protein. This aspect may have been largely underestimated by previous studies.

The frequency of codons, also known as codon usage bias, can vary from species to species with functional implications for the control of translation. The following codon usage table is for the human genome.

The DNA codon table is essentially identical to that for RNA, but with U replaced by T.

In some proteins, non-standard amino acids are substituted for standard stop codons, depending on associated signal sequences in the messenger RNA. For example, UGA can code for selenocysteine and UAG can code for pyrrolysine. Selenocysteine became to be seen as the 21st amino acid, and pyrrolysine as the 22nd. Unlike selenocysteine, pyrrolysine-encoded UAG is translated with the participation of a dedicated aminoacyl-tRNA synthetase. Both selenocysteine and pyrrolysine may be present in the same organism. Although the genetic code is normally fixed in an organism, the achaeal prokaryote "Acetohalobium arabaticum" can expand its genetic code from 20 to 21 amino acids (by including pyrrolysine) under different conditions of growth.

Variations on the standard code were predicted in the 1970s. The first was discovered in 1979, by researchers studying human mitochondrial genes. Many slight variants were discovered thereafter, including various alternative mitochondrial codes. These minor variants for example involve translation of the codon UGA as tryptophan in "Mycoplasma" species, and translation of CUG as a serine rather than leucine in yeasts of the "CTG clade" (such as "Candida albicans"). Because viruses must use the same genetic code as their hosts, modifications to the standard genetic code could interfere with viral protein synthesis or functioning. However, viruses such as totiviruses have adapted to the host's genetic code modification. In bacteria and archaea, GUG and UUG are common start codons. In rare cases, certain proteins may use alternative start codons.
Surprisingly, variations in the interpretation of the genetic code exist also in human nuclear-encoded genes: In 2016, researchers studying the translation of malate dehydrogenase found that in about 4% of the mRNAs encoding this enzyme the stop codon is naturally used to encode the amino acids tryptophan and arginine. This type of recoding is induced by a high-readthrough stop codon context and it is referred to as "functional translational readthrough".

Variant genetic codes used by an organism can be inferred by identifying highly conserved genes encoded in that genome, and comparing its codon usage to the amino acids in homologous proteins of other organisms. For example, the program FACIL infers a genetic code by searching which amino acids in homologous protein domains are most often aligned to every codon. The resulting amino acid probabilities for each codon are displayed in a genetic code logo, that also shows the support for a stop codon.

Despite these differences, all known naturally occurring codes are very similar. The coding mechanism is the same for all organisms: three-base codons, tRNA, ribosomes, single direction reading and translating single codons into single amino acids.

The genetic code is a key part of the history of life, according to one version of which self-replicating RNA molecules preceded life as we know it. This is the RNA world hypothesis. Under this hypothesis, any model for the emergence of the genetic code is intimately related to a model of the transfer from ribozymes (RNA enzymes) to proteins as the principal enzymes in cells. In line with the RNA world hypothesis, transfer RNA molecules appear to have evolved before modern aminoacyl-tRNA synthetases, so the latter cannot be part of the explanation of its patterns.

A hypothetical randomly evolved genetic code further motivates a biochemical or evolutionary model for its origin. If amino acids were randomly assigned to triplet codons, there would be 1.5 × 10 possible genetic codes. This number is found by calculating the number of ways that 21 items (20 amino acids plus one stop) can be placed in 64 bins, wherein each item is used at least once. However, the distribution of codon assignments in the genetic code is nonrandom. In particular, the genetic code clusters certain amino acid assignments.

Amino acids that share the same biosynthetic pathway tend to have the same first base in their codons. This could be an evolutionary relic of an early, simpler genetic code with fewer amino acids that later evolved to code a larger set of amino acids. It could also reflect steric and chemical properties that had another effect on the codon during its evolution. Amino acids with similar physical properties also tend to have similar codons, reducing the problems caused by point mutations and mistranslations.

Given the non-random genetic triplet coding scheme, a tenable hypothesis for the origin of genetic code could address multiple aspects of the codon table, such as absence of codons for D-amino acids, secondary codon patterns for some amino acids, confinement of synonymous positions to third position, the small set of only 20 amino acids (instead of a number approaching 64), and the relation of stop codon patterns to amino acid coding patterns.

Three main hypotheses address the origin of the genetic code. Many models belong to one of them or to a hybrid:


Hypotheses have addressed a variety of scenarios:

It has been claimed that the genetic code contains patterns and arithmetic coincidences that are very unlikely by chance and that would not arise through evolution. The authors of this claim contend that this is basically a message indicating that life on Earth was seeded by a previous civilization, similar to panspermia.




</doc>
<doc id="12386" url="https://en.wikipedia.org/wiki?curid=12386" title="Golden ratio">
Golden ratio

In mathematics, two quantities are in the golden ratio if their ratio is the same as the ratio of their sum to the larger of the two quantities. The figure on the right illustrates the geometric relationship. Expressed algebraically, for quantities "a" and "b" with "a" > "b" > 0,

where the Greek letter phi (formula_2 or formula_3) represents the golden ratio.{2}</math>. The sum of the two solutions is one, and the product of the two solutions is negative one.}} It is an irrational number that is a solution to the quadratic equation formula_4, with a value of:

The golden ratio is also called the golden mean or golden section (Latin: "sectio aurea"). Other names include extreme and mean ratio, medial section, divine proportion (Latin: "proportio divina"), divine section (Latin: "sectio divina"), golden proportion, golden cut, and golden number.

Mathematicians since Euclid have studied the properties of the golden ratio, including its appearance in the dimensions of a regular pentagon and in a golden rectangle, which may be cut into a square and a smaller rectangle with the same aspect ratio. The golden ratio has also been used to analyze the proportions of natural objects as well as man-made systems such as financial markets, in some cases based on dubious fits to data. The golden ratio appears in some patterns in nature, including the spiral arrangement of leaves and other plant parts.

Some twentieth-century artists and architects, including Le Corbusier and Salvador Dalí, have proportioned their works to approximate the golden ratio, believing this to be aesthetically pleasing. These often appear in the form of the golden rectangle, in which the ratio of the longer side to the shorter is the golden ratio.

Two quantities "a" and "b" are said to be in the "golden ratio" if

One method for finding the value of is to start with the left fraction. Through simplifying the fraction and substituting in b/a = 1/,

Therefore,

Multiplying by gives

which can be rearranged to

Using the quadratic formula, two solutions are obtained:

Because is the ratio between positive quantities, is necessarily positive:

According to Mario Livio,

Ancient Greek mathematicians first studied what we now call the golden ratio, because of its frequent appearance in geometry; the division of a line into "extreme and mean ratio" (the golden section) is important in the geometry of regular pentagrams and pentagons. According to one story, 5th-century BC mathematician Hippasus discovered that the golden ratio was neither a whole number nor a fraction (an irrational number), surprising Pythagoreans. Euclid's "Elements" () provides several propositions and their proofs employing the golden ratio, and contains its first known definition which proceeds as follows:

The golden ratio was studied peripherally over the next millennium. Abu Kamil (c. 850–930) employed it in his geometric calculations of pentagons and decagons; his writings influenced that of Fibonacci (Leonardo of Pisa) (c. 1170–1250), who used the ratio in related geometry problems, though never connected it to the series of numbers named after him. 

Luca Pacioli named his book "Divina proportione" (1509) after the ratio, and explored its properties including its appearance in some of the Platonic solids. Leonardo da Vinci, who illustrated the aforementioned book, called the ratio the "sectio aurea" ('golden section'). 16th-century mathematicians such as Rafael Bombelli solved geometric problems using the ratio.

German mathematician Simon Jacob (d. 1564) noted that consecutive Fibonacci numbers converge to the golden ratio; this was rediscovered by Johannes Kepler in 1608. The first known decimal approximation of the (inverse) golden ratio was stated as "about 0.6180340" in 1597 by Michael Maestlin of the University of Tübingen in a letter to Kepler, his former student. The same year, Kepler wrote to Maestlin of the Kepler triangle, which combines the golden ratio with the Pythagorean theorem. Kepler said of these:

18th-century mathematicians Abraham de Moivre, Daniel Bernoulli, and Leonhard Euler used a golden ratio-based formula which finds the value of a Fibonacci number based on its placement in the sequence; in 1843, this was rediscovered by Jacques Philippe Marie Binet, for whom it was named "Binet's formula". Martin Ohm first used the German term "goldener Schnitt" ('golden section') to describe the ratio in 1835. James Sully used the equivalent English term in 1875.

By 1910, mathematician Mark Barr began using the Greek letter Phi (φ) as a symbol for the golden ratio. It has also been represented by tau (τ), the first letter of the ancient Greek τομή ('cut' or 'section').

Between 1973 and 1974, Roger Penrose developed Penrose tiling, a pattern related to the golden ratio both in the ratio of areas of its two rhombic tiles and in their relative frequency within the pattern. This led to Dan Shechtman's early 1980s discovery of quasicrystals, some of which exhibit icosahedral symmetry.

A 2004 geometrical analysis of earlier research into the Great Mosque of Kairouan (670) reveals an application of the golden ratio in much of the design. They found ratios close to the golden ratio in the overall layout and in the dimensions of the prayer space, the court, and the minaret. However, the areas with ratios close to the golden ratio were not part of the original plan, and were likely added in a reconstruction.

It has been speculated that the golden ratio was used by the designers of the Naqsh-e Jahan Square (1629), and the adjacent Lotfollah Mosque.

The Swiss architect Le Corbusier, famous for his contributions to the modern international style, centered his design philosophy on systems of harmony and proportion. Le Corbusier's faith in the mathematical order of the universe was closely bound to the golden ratio and the Fibonacci series, which he described as "rhythms apparent to the eye and clear in their relations with one another. And these rhythms are at the very root of human activities. They resound in man by an organic inevitability, the same fine inevitability which causes the tracing out of the Golden Section by children, old men, savages and the learned."

Le Corbusier explicitly used the golden ratio in his Modulor system for the scale of architectural proportion. He saw this system as a continuation of the long tradition of Vitruvius, Leonardo da Vinci's "Vitruvian Man", the work of Leon Battista Alberti, and others who used the proportions of the human body to improve the appearance and function of architecture. 

In addition to the golden ratio, Le Corbusier based the system on human measurements, Fibonacci numbers, and the double unit. He took suggestion of the golden ratio in human proportions to an extreme: he sectioned his model human body's height at the navel with the two sections in golden ratio, then subdivided those sections in golden ratio at the knees and throat; he used these golden ratio proportions in the Modulor system. Le Corbusier's 1927 Villa Stein in Garches exemplified the Modulor system's application. The villa's rectangular ground plan, elevation, and inner structure closely approximate golden rectangles.

Another Swiss architect, Mario Botta, bases many of his designs on geometric figures. Several private houses he designed in Switzerland are composed of squares and circles, cubes and cylinders. In a house he designed in Origlio, the golden ratio is the proportion between the central section and the side sections of the house.

"Divina proportione" ("Divine proportion"), a three-volume work by Luca Pacioli, was published in 1509. Pacioli, a Franciscan friar, was known mostly as a mathematician, but he was also trained and keenly interested in art. "Divina proportione" explored the mathematics of the golden ratio. Though it is often said that Pacioli advocated the golden ratio's application to yield pleasing, harmonious proportions, Livio points out that the interpretation has been traced to an error in 1799, and that Pacioli actually advocated the Vitruvian system of rational proportions. Pacioli also saw Catholic religious significance in the ratio, which led to his work's title.

Leonardo da Vinci's illustrations of polyhedra in "Divina proportione" have led some to speculate that he incorporated the golden ratio in his paintings. But the suggestion that his "Mona Lisa", for example, employs golden ratio proportions, is not supported by Leonardo's own writings. Similarly, although the "Vitruvian Man" is often shown in connection with the golden ratio, the proportions of the figure do not actually match it, and the text only mentions whole number ratios.

Salvador Dalí, influenced by the works of Matila Ghyka, explicitly used the golden ratio in his masterpiece, "The Sacrament of the Last Supper". The dimensions of the canvas are a golden rectangle. A huge dodecahedron, in perspective so that edges appear in golden ratio to one another, is suspended above and behind Jesus and dominates the composition.

A statistical study on 565 works of art of different great painters, performed in 1999, found that these artists had not used the golden ratio in the size of their canvases. The study concluded that the average ratio of the two sides of the paintings studied is 1.34, with averages for individual artists ranging from 1.04 (Goya) to 1.46 (Bellini). On the other hand, Pablo Tosto listed over 350 works by well-known artists, including more than 100 which have canvasses with golden rectangle and root-5 proportions, and others with proportions like root-2, 3, 4, and 6.

According to Jan Tschichold,

There was a time when deviations from the truly beautiful page proportions 2:3, 1:√3, and the Golden Section were rare. Many books produced between 1550 and 1770 show these proportions exactly, to within half a millimeter.

According to some sources, the golden ratio is used in everyday design, for example in the proportions of playing cards, postcards, posters, light switch plates, and widescreen televisions.

Ernő Lendvai analyzes Béla Bartók's works as being based on two opposing systems, that of the golden ratio and the acoustic scale, though other music scholars reject that analysis. French composer Erik Satie used the golden ratio in several of his pieces, including "Sonneries de la Rose+Croix". The golden ratio is also apparent in the organization of the sections in the music of Debussy's "Reflets dans l'eau (Reflections in Water)", from "Images" (1st series, 1905), in which "the sequence of keys is marked out by the intervals 34, 21, 13 and 8, and the main climax sits at the phi position".

The musicologist Roy Howat has observed that the formal boundaries of Debussy's "La Mer" correspond exactly to the golden section. Trezise finds the intrinsic evidence "remarkable", but cautions that no written or reported evidence suggests that Debussy consciously sought such proportions.

Pearl Drums positions the air vents on its Masters Premium models based on the golden ratio. The company claims that this arrangement improves bass response and has applied for a patent on this innovation.

Though Heinz Bohlen proposed the non-octave-repeating 833 cents scale based on combination tones, the tuning features relations based on the golden ratio. As a musical interval the ratio 1.618... is 833.090... cents ().

Johannes Kepler wrote that "the image of man and woman stems from the divine proportion. In my opinion, the propagation of plants and the progenitive acts of animals are in the same ratio".

The psychologist Adolf Zeising noted that the golden ratio appeared in phyllotaxis and argued from these patterns in nature that the golden ratio was a universal law. Zeising wrote in 1854 of a universal orthogenetic law of "striving for beauty and completeness in the realms of both nature and art".

In 2010, the journal "Science" reported that the golden ratio is present at the atomic scale in the magnetic resonance of spins in cobalt niobate crystals.

However, some have argued that many apparent manifestations of the golden ratio in nature, especially in regard to animal dimensions, are fictitious.

The golden ratio is key to the golden-section search.

The golden ratio is an irrational number. Below are two short proofs of irrationality:

Recall that:

If we call the whole "n" and the longer part "m", then the second statement above becomes

or, algebraically

To say that the golden ratio is rational means that is a fraction "n"/"m" where "n" and "m" are integers. We may take "n"/"m" to be in lowest terms and "n" and "m" to be positive. But if "n"/"m" is in lowest terms, then the identity labeled (*) above says "m"/("n" − "m") is in still lower terms. That is a contradiction that follows from the assumption that is rational.

Another short proof—perhaps more commonly known—of the irrationality of the golden ratio makes use of the closure of rational numbers under addition and multiplication. If formula_15 is rational, then formula_16 is also rational, which is a contradiction if it is already known that the square root of a non-square natural number is irrational.

The golden ratio is also an algebraic number and even an algebraic integer. It has minimal polynomial

Having degree 2, this polynomial actually has two roots, the other being the golden ratio conjugate.

The conjugate root to the minimal polynomial x − x − 1 is

The absolute value of this quantity (≈ 0.618) corresponds to the length ratio taken in reverse order (shorter segment length over longer segment length, "b/a"), and is sometimes referred to as the golden ratio conjugate or silver ratio. It is denoted here by the capital Phi (formula_19):

Alternatively, formula_19 can be expressed as

This illustrates the unique property of the golden ratio among positive numbers, that

or its inverse:

This means 0.61803...:1 = 1:1.61803...

The formula = 1 + 1/ can be expanded recursively to obtain a continued fraction for the golden ratio:

and its reciprocal:

The convergents of these continued fractions (1/1, 2/1, 3/2, 5/3, 8/5, 13/8, ..., or 1/1, 1/2, 2/3, 3/5, 5/8, 8/13, ...) are ratios of successive Fibonacci numbers.

The equation = 1 + likewise produces the continued square root:

An infinite series can be derived to express "φ":

Also:

These correspond to the fact that the length of the diagonal of a regular pentagon is times the length of its side, and similar relations in a pentagram.

The number turns up frequently in geometry, particularly in figures with pentagonal symmetry.
The length of a regular pentagon's diagonal is times its side.
The vertices of a regular icosahedron are those of three mutually orthogonal golden rectangles.

There is no known general algorithm to arrange a given number of nodes evenly on a sphere, for any of several definitions of even distribution (see, for example, "Thomson problem"). However, a useful approximation results from dividing the sphere into parallel bands of equal surface area and placing one node in each band at longitudes spaced by a golden section of the circle, i.e. 360°/ ≅ 222.5°. This method was used to arrange the 1500 mirrors of the student-participatory satellite Starshine-3.

Application examples you can see in the articles Pentagon with a given side length, Decagon with given circumcircle and Decagon with a given side length.

Both of the above displayed different algorithms produce geometric constructions that determine two aligned line segments where the ratio of the longer one to the shorter one is the golden ratio.
The golden triangle can be characterized as an isosceles triangle ABC with the property that bisecting the angle C produces a new triangle CXB which is a similar triangle to the original.

If angle BCX = α, then XCA = α because of the bisection, and CAB = α because of the similar triangles; ABC = 2α from the original isosceles symmetry, and BXC = 2α by similarity. The angles in a triangle add up to 180°, so 5α = 180, giving α = 36°. So the angles of the golden triangle are thus 36°-72°-72°. The angles of the remaining obtuse isosceles triangle AXC (sometimes called the golden gnomon) are 36°-36°-108°.

Suppose XB has length 1, and we call BC length . Because of the isosceles triangles XC=XA and BC=XC, so these are also length φ. Length AC = AB, therefore equals  + 1. But triangle ABC is similar to triangle CXB, so AC/BC = BC/BX, AC/ = φ/1, and so AC also equals . Thus = φ + 1, confirming that is indeed the golden ratio.

Similarly, the ratio of the area of the larger triangle AXC to the smaller CXB is equal to , while the inverse ratio is φ − 1.

In a regular pentagon the ratio of a diagonal to a side is the golden ratio, while intersecting diagonals section each other in the golden ratio.

George Odom has given a remarkably simple construction for involving an equilateral triangle: if an equilateral triangle is inscribed in a circle and the line segment joining the midpoints of two sides is produced to intersect the circle in either of two points, then these three points are in golden proportion. This result is a straightforward consequence of the intersecting chords theorem and can be used to construct a regular pentagon, a construction that attracted the attention of the noted Canadian geometer H. S. M. Coxeter who published it in Odom's name as a diagram in the "American Mathematical Monthly" accompanied by the single word "Behold!" 

The golden ratio plays an important role in the geometry of pentagrams. Each intersection of edges sections other edges in the golden ratio. Also, the ratio of the length of the shorter segment to the segment bounded by the two intersecting edges (a side of the pentagon in the pentagram's center) is , as the four-color illustration shows.

The pentagram includes ten isosceles triangles: five acute and five obtuse isosceles triangles. In all of them, the ratio of the longer side to the shorter side is . The acute triangles are golden triangles. The obtuse isosceles triangles are golden gnomons.

The golden ratio properties of a regular pentagon can be confirmed by applying Ptolemy's theorem to the quadrilateral formed by removing one of its vertices. If the quadrilateral's long edge and diagonals are "b", and short edges are "a", then Ptolemy's theorem gives "b" = "a" + "ab" which yields

Consider a triangle with sides of lengths "a", "b", and "c" in decreasing order. Define the "scalenity" of the triangle to be the smaller of the two ratios "a"/"b" and "b"/"c". The scalenity is always less than and can be made as close as desired to .

If the side lengths of a triangle form a geometric progression and are in the ratio 1 : "r" : "r", where "r" is the common ratio, then "r" must lie in the range −1 < "r" < , which is a consequence of the triangle inequality (the sum of any two sides of a triangle must be strictly bigger than the length of the third side). If "r" = then the shorter two sides are 1 and but their sum is , thus "r" < . A similar calculation shows that "r" > −1. A triangle whose sides are in the ratio 1 : : is a right triangle (because 1 + = ) known as a Kepler triangle.

A golden rhombus is a rhombus whose diagonals are in the golden ratio. The rhombic triacontahedron is a convex polytope that has a very special property: all of its faces are golden rhombi. In the rhombic triacontahedron the dihedral angle between any two adjacent rhombi is 144°, which is twice the isosceles angle of a golden triangle and four times its most acute angle.

The mathematics of the golden ratio and of the Fibonacci sequence are intimately interconnected. The Fibonacci sequence is:

A closed-form expression for the Fibonacci sequence involves the golden ratio:

The golden ratio is the limit of the ratios of successive terms of the Fibonacci sequence (or any Fibonacci-like sequence), as shown by Kepler:

In other words, if a Fibonacci number is divided by its immediate predecessor in the sequence, the quotient approximates ; e.g., 987/610  1.6180327868852. These approximations are alternately lower and higher than , and converge to as the Fibonacci numbers increase, and:

More generally:

where above, the ratios of consecutive terms of the Fibonacci sequence, is a case when formula_38

Furthermore, the successive powers of obey the Fibonacci recurrence:

This identity allows any polynomial in to be reduced to a linear expression. For example:

The reduction to a linear expression can be accomplished in one step by using the relationship
where formula_42 is the "k"th Fibonacci number.

However, this is no special property of , because polynomials in any solution "x" to a quadratic equation can be reduced in an analogous manner, by applying:
for given coefficients "a", "b" such that "x" satisfies the equation. Even more generally, any rational function (with rational coefficients) of the root of an irreducible "n"th-degree polynomial over the rationals can be reduced to a polynomial of degree Phrased in terms of field theory, if α is a root of an irreducible "n"th-degree polynomial, then formula_44 has degree "n" over formula_45, with basis formula_46

The golden ratio and inverse golden ratio formula_47 have a set of symmetries that preserve and interrelate them. They are both preserved by the fractional linear transformations formula_48 – this fact corresponds to the identity and the definition quadratic equation.
Further, they are interchanged by the three maps formula_49 – they are reciprocals, symmetric about formula_50, and (projectively) symmetric about 2.

More deeply, these maps form a subgroup of the modular group formula_51 isomorphic to the symmetric group on 3 letters, formula_52 corresponding to the stabilizer of the set formula_53 of 3 standard points on the projective line, and the symmetries correspond to the quotient map formula_54 – the subgroup formula_55 consisting of the 3-cycles and the identity formula_56 fixes the two numbers, while the 2-cycles interchange these, thus realizing the map.

The golden ratio has the simplest expression (and slowest convergence) as a continued fraction expansion of any irrational number (see "Alternate forms" above). It is, for that reason, one of the worst cases of Lagrange's approximation theorem and it is an extremal case of the Hurwitz inequality for Diophantine approximations. This may be why angles close to the golden ratio often show up in phyllotaxis (the growth of plants).

The defining quadratic polynomial and the conjugate relationship lead to decimal values that have their fractional part in common with :

The sequence of powers of contains these values 0.618..., 1.0, 1.618..., 2.618...; more generally,
any power of is equal to the sum of the two immediately preceding powers:

As a result, one can easily decompose any power of into a multiple of and a constant. The multiple and the constant are always adjacent Fibonacci numbers. This leads to another property of the positive powers of :

If formula_60, then:

When the golden ratio is used as the base of a numeral system (see Golden ratio base, sometimes dubbed "phinary" or "-nary"), every integer has a terminating representation, despite being irrational, but every fraction has a non-terminating representation.

The golden ratio is a fundamental unit of the algebraic number field formula_63 and is a Pisot–Vijayaraghavan number. In the field formula_63 we have formula_65, where formula_66 is the formula_67-th Lucas number.

The golden ratio also appears in hyperbolic geometry, as the maximum distance from a point on one side of an ideal triangle to the closer of the other two sides: this distance, the side length of the equilateral triangle formed by the points of tangency of a circle inscribed within the ideal triangle, is formula_68.

The golden ratio appears in the theory of modular functions as well. Let
Then
Also if formula_71 and formula_72, then

The golden ratio's decimal expansion can be calculated directly from the expression

with ≈ 2.2360679774997896964 . The square root of 5 can be calculated with the Babylonian method, starting with an initial estimate such as "x" = 2 and iterating

for "n" = 1, 2, 3, ..., until the difference between "x" and "x" becomes zero, to the desired number of digits.

The Babylonian algorithm for is equivalent to Newton's method for solving the equation "x" − 5 = 0. In its more general form, Newton's method can be applied directly to any algebraic equation, including the equation "x" − x − 1 = 0 that defines the golden ratio. This gives an iteration that converges to the golden ratio itself,

for an appropriate initial estimate "x" such as "x" = 1. A slightly faster method is to rewrite the equation as "x" − 1 − 1/"x" = 0, in which case the Newton iteration becomes

These iterations all converge quadratically; that is, each step roughly doubles the number of correct digits. The golden ratio is therefore relatively easy to compute with arbitrary precision. The time needed to compute "n" digits of the golden ratio is proportional to the time needed to divide two "n"-digit numbers. This is considerably faster than known algorithms for the transcendental numbers and .

An easily programmed alternative using only integer arithmetic is to calculate two large consecutive Fibonacci numbers and divide them. The ratio of Fibonacci numbers "F" and "F" , each over 5000 digits, yields over 10,000 significant digits of the golden ratio.

The decimal expansion of the golden ratio has been calculated to an accuracy of two trillion ( = 2,000,000,000,000) digits.

Both Egyptian pyramids and the regular square pyramids that resemble them can be analyzed with respect to the golden ratio and other ratios.

A pyramid in which the apothem (slant height along the bisector of a face) is equal to times the semi-base (half the base width) is sometimes called a "golden pyramid". The isosceles triangle that is the face of such a pyramid can be constructed from the two halves of a diagonally split golden rectangle (of size semi-base by apothem), joining the medium-length edges to make the apothem. The height of this pyramid is formula_78 times the semi-base (that is, the slope of the face is formula_78); the square of the height is equal to the area of a face, times the square of the semi-base.

The medial right triangle of this "golden" pyramid (see diagram), with sides formula_80 is interesting in its own right, demonstrating via the Pythagorean theorem the relationship formula_81 or formula_82. This Kepler triangle
is the only right triangle proportion with edge lengths in geometric progression, just as the 3–4–5 triangle is the only right triangle proportion with edge lengths in arithmetic progression. The angle with tangent formula_78 corresponds to the angle that the side of the pyramid makes with respect to the ground, 51.827... degrees (51° 49' 38").

A nearly similar pyramid shape, but with rational proportions, is described in the Rhind Mathematical Papyrus (the source of a large part of modern knowledge of ancient Egyptian mathematics), based on the 3:4:5 triangle; the face slope corresponding to the angle with tangent 4/3 is, to two decimal places, 53.13 degrees (53 degrees and 8 minutes). The slant height or apothem is 5/3 or 1.666... times the semi-base. The Rhind papyrus has another pyramid problem as well, again with rational slope (expressed as run over rise). Egyptian mathematics did not include the notion of irrational numbers, and the rational inverse slope (run/rise, multiplied by a factor of 7 to convert to their conventional units of palms per cubit) was used in the building of pyramids.

Another mathematical pyramid with proportions almost identical to the "golden" one is the one with perimeter equal to 2 times the height, or h:b = 4:. This triangle has a face angle of 51.854° (51°51'), very close to the 51.827° of the Kepler triangle. This pyramid relationship corresponds to the coincidental relationship formula_84.

Egyptian pyramids very close in proportion to these mathematical pyramids are known.

One Egyptian pyramid that is close to a "golden pyramid" is the Great Pyramid of Giza (also known as the Pyramid of Cheops or Khufu). Its slope of 51° 52' is close to the "golden" pyramid inclination of 51° 50' – and even closer to the -based pyramid inclination of 51° 51'. However, several other mathematical theories of the shape of the great pyramid, based on rational slopes, have been found to be both more accurate and more plausible explanations for the 51° 52' slope.

In the mid-nineteenth century, Friedrich Röber studied various Egyptian pyramids including those of Khafre, Menkaure, and some of the Giza, Saqqara, and Abusir groups. He did not apply the golden ratio to the Great Pyramid of Giza, but instead agreed with John Shae Perring that its side-to-height ratio is 8:5. For all the other pyramids he applied measurements related to the Kepler triangle, and claimed that either their whole or half-side lengths are related to their heights by the golden ratio.

In 1859, the pyramidologist John Taylor misinterpreted Herodotus () as indicating that the Great Pyramid's height squared equals the area of one of its face triangles. This led Taylor to claim that, in the Great Pyramid, the golden ratio is represented by the ratio of the length of the face (the slope height, inclined at an angle θ to the ground) to half the length of the side of the square base (equivalent to the secant of the angle θ). The above two lengths are about and , respectively. The ratio of these lengths is the golden ratio, accurate to more digits than either of the original measurements. Similarly, Howard Vyse reported the great pyramid height , and half-base , yielding 1.6189 for the ratio of slant height to half-base, again more accurate than the data variability.

Eric Temple Bell, mathematician and historian, claimed in 1950 that Egyptian mathematics would not have supported the ability to calculate the slant height of the pyramids, or the ratio to the height, except in the case of the 3:4:5 pyramid, since the 3:4:5 triangle was the only right triangle known to the Egyptians and they did not know the Pythagorean theorem, nor any way to reason about irrationals such as or . Example geometric problems of pyramid design in the Rhind papyrus correspond to various rational slopes.

Michael Rice asserts that principal authorities on the history of Egyptian architecture have argued that the Egyptians were well acquainted with the golden ratio and that it is part of the mathematics of the pyramids, citing Giedon (1957). Historians of science have long debated whether the Egyptians had any such knowledge, contending that its appearance in the Great Pyramid is the result of chance.

Examples of disputed observations of the golden ratio include the following:


The Parthenon's façade (c. 432 BC) as well as elements of its façade and elsewhere are said by some to be circumscribed by golden rectangles. Other scholars deny that the Greeks had any aesthetic association with golden ratio. For example, Keith Devlin says, "Certainly, the oft repeated assertion that the Parthenon in Athens is based on the golden ratio is not supported by actual measurements. In fact, the entire story about the Greeks and golden ratio seems to be without foundation." Midhat J. Gazalé affirms that "It was not until Euclid ... that the golden ratio's mathematical properties were studied."

From measurements of 15 temples, 18 monumental tombs, 8 sarcophagi, and 58 grave stelae from the fifth century BC to the second century AD, one researcher concluded that the golden ratio was totally absent from Greek architecture of the classical fifth century BC, and almost absent during the following six centuries.
Later sources like Vitruvius (first century BC) exclusively discuss proportions that can be expressed in whole numbers, i.e. commensurate as opposed to irrational proportions.

The Section d'Or ('Golden Section') was a collective of painters, sculptors, poets and critics associated with Cubism and Orphism. Active from 1911 to around 1914, they adopted the name both to highlight that Cubism represented the continuation of a grand tradition, rather than being an isolated movement, and in homage to the mathematical harmony associated with Georges Seurat. The Cubists observed in its harmonies, geometric structuring of motion and form, the primacy of idea over nature, an absolute scientific clarity of conception. However, despite this general interest in mathematical harmony, whether the paintings featured in the celebrated 1912 "Salon de la Section d'Or" exhibition used the golden ratio in any compositions is more difficult to determine. Livio, for example, claims that they did not, and Marcel Duchamp said as much in an interview. On the other hand, an analysis suggests that Juan Gris made use of the golden ratio in composing works that were likely, but not definitively, shown at the exhibition. Art historian Daniel Robbins has argued that in addition to referencing the mathematical term, the exhibition's name also refers to the earlier "Bandeaux d'Or" group, with which Albert Gleizes and other former members of the Abbaye de Créteil had been involved.

Piet Mondrian has been said to have used the golden section extensively in his geometrical paintings, though other experts (including critic Yve-Alain Bois) have discredited these claims.




</doc>
<doc id="12388" url="https://en.wikipedia.org/wiki?curid=12388" title="Genome">
Genome

In the fields of molecular biology and genetics, a genome is the genetic material of an organism. It consists of DNA (or RNA in RNA viruses). The genome includes both the genes (the coding regions) and the noncoding DNA, as well as mitochondrial DNA and chloroplast DNA. The study of the genome is called genomics.

The term "genome" was created in 1920 by Hans Winkler, professor of botany at the University of Hamburg, Germany. The Oxford Dictionary suggests the name is a blend of the words "gene" and "chromosome". However, see omics for a more thorough discussion. A few related "-ome" words already existed, such as "biome" and "rhizome", forming a vocabulary into which "genome" fits systematically.

A genome sequence is the complete list of the nucleotides (A, C, G, and T for DNA genomes) that make up all the chromosomes of an individual or a species. Within a species, the vast majority of nucleotides are identical between individuals, but sequencing multiple individuals is necessary to understand the genetic diversity. 
In 1976, Walter Fiers at the University of Ghent (Belgium) was the first to establish the complete nucleotide sequence of a viral RNA-genome (Bacteriophage MS2). The next year, Fred Sanger completed the first DNA-genome sequence: Phage Φ-X174, of 5386 base pairs. The first complete genome sequences among all three domains of life were released within a short period during the mid-1990s: The first bacterial genome to be sequenced was that of Haemophilus influenzae, completed by a team at The Institute for Genomic Research in 1995. A few months later, the first eukaryotic genome was completed, with sequences of the 16 chromosomes of budding yeast "Saccharomyces cerevisiae" published as the result of a European-led effort begun in the mid-1980s. The first genome sequence for an archaeon, "Methanococcus jannaschii", was completed in 1996, again by The Institute for Genomic Research.

The development of new technologies has made genome sequencing dramatically cheaper and easier, and the number of complete genome sequences is growing rapidly. The US National Institutes of Health maintains one of several comprehensive databases of genomic information. Among the thousands of completed genome sequencing projects include those for rice, a mouse, the plant "Arabidopsis thaliana", the puffer fish, and the bacteria E. coli. In December 2013, scientists first sequenced the entire "genome" of a Neanderthal, an extinct species of humans. The genome was extracted from the toe bone of a 130,000-year-old Neanderthal found in a Siberian cave.

New sequencing technologies, such as massive parallel sequencing have also opened up the prospect of personal genome sequencing as a diagnostic tool, as pioneered by Manteia Predictive Medicine. A major step toward that goal was the completion in 2007 of the full genome of James D. Watson, one of the co-discoverers of the structure of DNA.

Whereas a genome sequence lists the order of every DNA base in a genome, a genome map identifies the landmarks. A genome map is less detailed than a genome sequence and aids in navigating around the genome. The Human Genome Project was organized to map and to sequence the human genome. A fundamental step in the project was the release of a detailed genomic map by Jean Weissenbach and his team at the Genoscope in Paris.

Reference genome sequences and maps continue to be updated, removing errors and clarifying regions of high allelic complexity. The decreasing cost of genomic mapping has permitted genealogical sites to offer it as a service, to the extent that one may submit one's genome to crowdsourced scientific endeavours such as DNA.LAND at the New York Genome Center, an example both of the economies of scale and of citizen science.

Viral genomes can be composed of either RNA or DNA. The genomes of RNA viruses can be either single-stranded RNA or double-stranded RNA, and may contain one or more separate RNA molecules (segments: monopartit or multipartit genome). DNA viruses can have either single-stranded or double-stranded genomes. Most DNA virus genomes are composed of a single, linear molecule of DNA, but some are made up of a circular DNA molecule.

Prokaryotes and eukaryotes have DNA genomes. Archaea have a single circular chromosome. Most bacteria also have a single circular chromosome; however, some bacterial species have linear chromosomes or multiple chromosomes. If the DNA is replicated faster than the bacterial cells divide, multiple copies of the chromosome can be present in a single cell, and if the cells divide faster than the DNA can be replicated, multiple replication of the chromosome is initiated before the division occurs, allowing daughter cells to inherit complete genomes and already partially replicated chromosomes. Most prokaryotes have very little repetitive DNA in their genomes. However, some symbiotic bacteria (e.g. "Serratia symbiotica") have reduced genomes and a high fraction of pseudogenes: only ~40% of their DNA encodes proteins.

Some bacteria have auxiliary genetic material, also part of their genome, which is carried in plasmids. For this, the word "genome" should not be used as a synonym of "chromosome".

Eukaryotic genomes are composed of one or more linear DNA chromosomes. The number of chromosomes varies widely from Jack jumper ants and an asexual nemotode, which each have only one pair, to a fern species that has 720 pairs. A typical human cell has two copies of each of 22 autosomes, one inherited from each parent, plus two sex chromosomes, making it diploid. Gametes, such as ova, sperm, spores, and pollen, are haploid, meaning they carry only one copy of each chromosome.

In addition to the chromosomes in the nucleus, organelles such as the chloroplasts and mitochondria have their own DNA. Mitochondria are sometimes said to have their own genome often referred to as the "mitochondrial genome". The DNA found within the chloroplast may be referred to as the "plastome". Like the bacteria they originated from, mitochondria and chloroplasts have a circular chromosome.

Unlike prokaryotes, eukaryotes have exon-intron organization of protein coding genes and variable amounts of repetitive DNA. In mammals and plants, the majority of the genome is composed of repetitive DNA.

DNA sequences that carry the instructions to make proteins are coding sequences. The proportion of the genome occupied by coding sequences varies widely. A larger genome does not necessarily contain more genes, and the proportion of non-repetitive DNA decreases along with increasing genome size in complex eukaryotes.

Simple eukaryotes such as "C. elegans" and fruit fly, have more non-repetitive DNA than repetitive DNA, while the genomes of more complex eukaryotes tend to be composed largely of repetitive DNA. In some plants and amphibians, the proportion of repetitive DNA is more than 80%. Similarly, only 2% of the human genome codes for proteins. 

Noncoding sequences include introns, sequences for non-coding RNAs, regulatory regions, and repetitive DNA. Noncoding sequences make up 98% of the human genome. There are two categories of repetitive DNA in the genome: tandem repeats and interspersed repeats.

Short, non-coding sequences that are repeated head-to-tail are called tandem repeats. Microsatellites consisting of 2-5 basepair repeats, while minisatellite repeats are 30-35 bp. Tandem repeats make up about 4% of the human genome and 9% of the fruit fly genome. Tandem repeats can be functional. For example, telomeres are composed of the tandem repeat TTAGGG in mammals, and they play an important role in protecting the ends of the chromosome.

In other cases, expansions in the number of tandem repeats in exons or introns can cause disease. For example, the human gene huntingtin typically contains 6–29 tandem repeats of the nucleotides CAG (encoding a polyglutamine tract). An expansion to over 36 repeats results in Huntington's disease, a neurodegenerative disease. Twenty human disorders are known to result from similar tandem repeat expansions in various genes. The mechanism by which proteins with expanded polygulatamine tracts cause death of neurons is not fully understood. One possibility is that the proteins fail to fold properly and avoid degradation, instead accumulating in aggregates that also sequester important transcription factors, thereby altering gene expression.

Tandem repeats are usually caused by slippage during replication, unequal crossing-over and gene conversion.

Transposable elements (TEs) are sequences of DNA with a defined structure that are able to change their location in the genome. TEs are categorized as either class I TEs, which replicate by a copy-and-paste mechanism, or class II TEs, which can be excised from the genome and inserted at a new location.

The movement of TEs is a driving force of genome evolution in eukaryotes because their insertion can disrupt gene functions, homologous recombination between TEs can produce duplications, and TE can shuffle exons and regulatory sequences to new locations.

Retrotransposons can be transcribed into RNA, which are then duplicated at another site into the genome. Retrotransposons can be divided into long terminal repeats (LTRs) and non-long terminal repeats (Non-LTRs).

Long terminal repeats (LTRs) are derived from ancient retroviral infections, so they encode proteins related to retroviral proteins including gag (structural proteins of the virus), pol (reverse transcriptase and integrase), pro (protease), and in some cases env (envelope) genes. These genes are flanked by long repeats at both 5' and 3' ends. It has been reported that LTRs consist of the largest fraction in most plant genome and might account for the huge variation in genome size.

Non-long terminal repeats (Non-LTRs) are classified as long interspersed nuclear elements (LINEs), short interspersed nuclear elements (SINEs), and Penelope-like elements (PLEs). In "Dictyostelium discoideum", there is another DIRS-like elements belong to Non-LTRs. Non-LTRs are widely spread in eukaryotic genomes.

Long interspersed elements (LINEs) encode genes for reverse transcriptase and endonuclease, making them autonomous transposable elements. The human genome has around 500,000 LINEs, taking around 17% of the genome.

Short interspersed elements (SINEs) are usually less than 500 base pairs and are non-autonomous, so they rely on the proteins encoded by LINEs for transposition. The Alu element is the most common SINE found in primates. It is about 350 base pairs and occupies about 11% of the human genome with around 1,500,000 copies.

DNA transposons encode a transposase enzyme between inverted terminal repeats. When expressed, the transposase recognizes the terminal inverted repeats that flank the transposon and catalyzes its excision and reinsertion in a new site. This cut-and-paste mechanism typically reinserts transposons near their original location (within 100kb). DNA transposons are found in bacteria and make up 3% of the human genome and 12% of the genome of the roundworm "C. elegans".

Genome size is the total number of DNA base pairs in one copy of a haploid genome. In humans, the nuclear genome comprises approximately 3.2 billion nucleotides of DNA, divided into 24 linear molecules, the shortest 50 000 000 nucleotides in length and the longest 260 000 000 nucleotides, each contained in a different chromosome. The genome size is positively correlated with the morphological complexity among prokaryotes and lower eukaryotes; however, after mollusks and all the other higher eukaryotes above, this correlation is no longer effective. This phenomenon also indicates the mighty influence coming from repetitive DNA on the genomes.

Since genomes are very complex, one research strategy is to reduce the number of genes in a genome to the bare minimum and still have the organism in question survive. There is experimental work being done on minimal genomes for single cell organisms as well as minimal genomes for multi-cellular organisms (see Developmental biology). The work is both "in vivo" and "in silico".

Here is a table of some significant or representative genomes. See #See also for lists of sequenced genomes.

All the cells of an organism originate from a single cell, so they are expected to have identical genomes; however, in some cases, differences arise. Both the process of copying DNA during cell division and exposure to environmental mutagens can result in mutations in somatic cells. In some cases, such mutations lead to cancer because they cause cells to divide more quickly and invade surrounding tissues. In certain lymphocytes in the human immune system, V(D)J recombination generates different genomic sequences such that each cell produces a unique antibody or T cell receptors.

During meiosis, diploid cells divide twice to produce haploid germ cells. During this process, recombination results in a reshuffling of the genetic material from homologous chromosomes so each gamete has a unique genome.

Genome-wide reprogramming in mouse primordial germ cells involves epigenetic imprint erasure leading to totipotency. Reprogramming is facilitated by active DNA demethylation, a process that entails the DNA base excision repair pathway. This pathway is employed in the erasure of CpG methylation (5mC) in primordial germ cells. The erasure of 5mC occurs via its conversion to 5-hydroxymethylcytosine (5hmC) driven by high levels of the ten-eleven dioxygenase enzymes TET1 and TET2.

Genomes are more than the sum of an organism's genes and have traits that may be measured and studied without reference to the details of any particular genes and their products. Researchers compare traits such as karyotype (chromosome number), genome size, gene order, codon usage bias, and GC-content to determine what mechanisms could have produced the great variety of genomes that exist today (for recent overviews, see Brown 2002; Saccone and Pesole 2003; Benfey and Protopapas 2004; Gibson and Muse 2004; Reese 2004; Gregory 2005).

Duplications play a major role in shaping the genome. Duplication may range from extension of short tandem repeats, to duplication of a cluster of genes, and all the way to duplication of entire chromosomes or even entire genomes. Such duplications are probably fundamental to the creation of genetic novelty.

Horizontal gene transfer is invoked to explain how there is often an extreme similarity between small portions of the genomes of two organisms that are otherwise very distantly related. Horizontal gene transfer seems to be common among many microbes. Also, eukaryotic cells seem to have experienced a transfer of some genetic material from their chloroplast and mitochondrial genomes to their nuclear chromosomes. Recent empirical data suggest an important role of viruses and sub-viral RNA-networks to represent a main driving role to generate genetic novelty and natural genome editing.

Works of science fiction illustrate concerns about the availability of genome sequences.

Michael Crichton's 1990 novel "Jurassic Park" and the subsequent film tell the story of a billionaire who creates a theme park of cloned dinosaurs on a remote island, with disastrous outcomes. A geneticist extracts dinosaur DNA from the blood of ancient mosquitoes and fills in the gaps with DNA from modern species to create several species of dinosaurs. A chaos theorist is asked to give his expert opinion on the safety of engineering an ecosystem with the dinosaurs, and he repeatedly warns that the outcomes of the project will be unpredictable and ultimately uncontrollable. These warnings about the perils of using genomic information are a major theme of the book.

The 1997 film "Gattaca" is set in a futurist society where genomes of children are engineered to contain the most ideal combination of their parents' traits, and metrics such as risk of heart disease and predicted life expectancy are documented for each person based on their genome. People conceived outside of the eugenics program, known as "In-Valids" suffer discrimination and are relegated to menial occupations. The protagonist of the film is an In-Valid who works to defy the supposed genetic odds and achieve his dream of working as a space navigator. The film warns against a future where genomic information fuels prejudice and extreme class differences between those who can and can't afford genetically engineered children.




</doc>
<doc id="12393" url="https://en.wikipedia.org/wiki?curid=12393" title="Gaia philosophy">
Gaia philosophy

Gaia philosophy (named after Gaia, Greek goddess of the Earth) is a broadly inclusive term for related concepts that living organisms on a planet will affect the nature of their environment in order to make the environment more suitable for life. This set of theories holds that all organisms on a life-giving planet regulate the biosphere in such a way as to promote its habitability. Gaia concept draws a connection between the survivability of a species (hence its evolutionary course) and its usefulness to the survival of other species.

While there were a number of precursors to Gaia theory, the first scientific form of this idea was proposed as the Gaia hypothesis by James Lovelock, a UK chemist, in 1970. The Gaia hypothesis deals with the concept of biological homeostasis, and claims the resident life forms of a host planet coupled with their environment have acted and act like a single, self-regulating system. This system includes the near-surface rocks, the soil, and the atmosphere. Today many scientists consider such ideas to be unsupported by, or at odds with, the available evidence (see Gaia hypothesis criticism). These theories are however significant in green politics.

There are some mystical, scientific and religious predecessors to the Gaia philosophy, which had a Gaia-like conceptual basis. Many religious mythologies had a view of Earth as being a whole that is greater than the sum of its parts (e.g. some Native American religions and various forms of shamanism).

Lewis Thomas believed that Earth should be viewed as a single cell; he derived this view from Johannes Kepler's view of Earth as a single round organism.

Isaac Newton wrote of the earth, "Thus this Earth resembles a great animall or rather inanimate vegetable, draws in æthereall breath for its dayly refreshment & vitall ferment & transpires again with gross exhalations, And according to the condition of all other things living ought to have its times of beginning youth old age & perishing."

Pierre Teilhard de Chardin, a paleontologist and geologist, believed that evolution unfolded from cell to organism to planet to solar system and ultimately the whole universe, as we humans see it from our limited perspective. Teilhard later influenced Thomas Berry and many Catholic humanist thinkers of the 20th century.

Buckminster Fuller is generally credited with making the idea respectable in Western scientific circles in the 20th century. Building to some degree on his observations and artifacts, e.g. the Dymaxion map of the Earth he created, others began to ask if there was a way to make the Gaia theory scientifically sound.

In 1931, L.G.M. Baas Becking delivered an inaugural lecture about Gaia in the sense of life and earth. 

Oberon Zell-Ravenheart in 1970 in an article in "Green Egg" Magazine, independently articulated the Gaia Thesis.

Many believe that these ideas cannot be considered scientific hypotheses; by definition a scientific hypothesis must make testable predictions. As the above claims are not currently testable, they are outside the bounds of current science. This does not mean that these ideas are not theoretically testable. As one can postulate tests that could be applied, given enough time and space, then these ideas should be seen as scientific hypotheses.

These are conjectures and perhaps can only be considered as social and maybe political philosophy; they may have implications for theology, or "thealogy" as Zell-Ravenheart and Isaac Bonewits put it.

According to James Kirchner there is a spectrum of Gaia hypotheses, ranging from the undeniable to radical. At one end is the undeniable statement that the organisms on the Earth have radically altered its composition. A stronger position is that the Earth's biosphere effectively acts as if it is a self-organizing system which works in such a way as to keep its systems in some kind of equilibrium that is conducive to life. Today many scientists consider that such a view (and any stronger views) are unlikely to be correct. An even stronger claim is that all lifeforms are part of a single planetary being, called Gaia. In this view, the atmosphere, the seas, the terrestrial crust would be the result of interventions carried out by Gaia, through the coevolving diversity of living organisms.

The most extreme form of Gaia theory is that the entire Earth is a single unified organism with a highly intelligent mind that arose as an emergent property of the whole biosphere. In this view, the Earth's biosphere is "consciously" manipulating the climate in order to make conditions more conducive to life. Scientists contend that there is no evidence at all to support this last point of view, and it has come about because many people do not understand the concept of homeostasis. Many non-scientists instinctively and incorrectly see homeostasis as a process that requires conscious control 

The more speculative versions of Gaia, including versions in which it is believed that the Earth is actually conscious, sentient, and highly intelligent, are usually considered outside the bounds of what is usually considered science.

Buckminster Fuller has been credited as the first to incorporate scientific ideas into a Gaia theory, which he did with his Dymaxion map of the Earth.

The first scientifically rigorous theory was the Gaia hypothesis by James Lovelock, a UK chemist.

A variant of this hypothesis was developed by Lynn Margulis, a microbiologist, in 1979.
Her version is sometimes called the "Gaia Theory" (note uppercase-T). Her model is more limited in scope than the one that Lovelock proposed.

Whether this sort of system is present on Earth is still open to debate. Some relatively simple homeostatic mechanisms are generally accepted. For example, when atmospheric carbon dioxide levels rise, plants are able to grow better and thus remove more carbon dioxide from the atmosphere. Other biological effects and feedbacks exist, but the extent to which these mechanisms have stabilized and modified the Earth's overall climate is largely not known.

The Gaia hypothesis is sometimes viewed from significantly different philosophical perspectives. Some environmentalists view it as an almost conscious process, in which the Earth's ecosystem is literally viewed as a single unified organism. Some evolutionary biologists, on the other hand, view it as an undirected emergent property of the ecosystem: as each individual species pursues its own self-interest, their combined actions tend to have counterbalancing effects on environmental change. Proponents of this view sometimes point to examples of life's actions in the past that have resulted in dramatic change rather than stable equilibrium, such as the conversion of the Earth's atmosphere from a reducing environment to an oxygen-rich one.

Depending on how strongly the case is stated, the hypothesis conflicts with mainstream neo-Darwinism. Most biologists would accept Daisyworld-style homeostasis as possible, but would certainly not accept the idea that this equates to the whole biosphere acting as one organism.

A very small number of scientists, and a much larger number of environmental activists, claim that Earth's biosphere is "consciously" manipulating the climate in order to make conditions more conducive to life. Scientists contend that there is no evidence to support this belief.

A social science view of Gaia theory is the role of humans as a keystone species who may be able to accomplish global homeostasis. Whilst a few social scientists who draw inspiration from 'organic' views of society have embraced Gaia philosophy as a way to explain the human-nature interconnections, most professional social scientists are more involved in reflecting upon the way Gaia philosophy is used and engaged with within sub-sections of society. Alan Marshall, in the Department of Social Sciences at Mahidol University, for example, reflects upon the way Gaia philosophy has been used and advocated by environmentalists, spiritualists, managers, economists, and scientists and engineers (see The Unity of Nature, 2002, Imperial College Press: London and Singapore). Social Scientists themselves in the 1960s gave up on systems ideas of society since they were interpreted as supporting conservatism and traditionalism.

Some radical political environmentalists who accept some form of the Gaia theory call themselves Gaians. They actively seek to restore the Earth's homeostasis — whenever they see it out of balance, e.g. to prevent manmade climate change, primate extinction, or rainforest loss. In effect, they seek to cooperate to become the "system consciously manipulating to make conditions more conducive to life". Such activity defines the homeostasis, but for leverage it relies on deep investigation of the homeorhetic balances, if only to find places to intervene in a system which is changing in undesirable ways.

Tony Bondhus brings up the point in his book, "Society of Conceivia", that if Gaia is alive, then societies are living things as well. This suggests that our understanding of Gaia can be used to create a better society and to design a better political system.

Other intellectuals in the environmental movement, like Edward Goldsmith, have used Gaia in the completely opposite way; to stake a claim about how Gaia's focus on natural balance and resistance and resilience, should be emulated to design a conservative political system (as explored in Alan Marshall's 2002 book "The Unity of Nature", (Imperial College Press: London).

Gaians do not passively ask "what is going on", but rather, "what to do next", e.g. in terraforming or climate engineering or even on a small scale, such as gardening. Changes can be planned, agreed upon by many people, being very deliberate, as in urban ecology and especially industrial ecology. "See arcology for more on this 'active' view."

Gaians argue that it is a human duty to act as such - committing themselves in particular to the Precautionary Principle. Such views began to influence the Green Parties, Greenpeace, and a few more radical wings of the environmental movement such as the Gaia Liberation Front and the Earth Liberation Front. These views dominate some such groups, e.g. the Bioneers. Some refer to this political activity as a separate and radical branch of the ecology movement, one that takes the axioms of the science of ecology in general, and Gaia theory in particular, and raises them to a kind of theory of personal conduct or moral code.

The ecologist and theologian Anne Primavesi is the author of two books dealing with the Gaia hypothesis and theology.

Rosemary Radford Ruether, the American feminist scholar and theologian, wrote a book called "Gaia and God: An Ecofeminist Theology of Earth Healing".

A book edited by Allan Hunt Badiner called Dharma Gaia explores the ground where Buddhism and ecology meet through writings by the Dalai Lama, Gary Snyder, Thich Nhat Hanh, Allen Ginsberg, Joanna Macy, Robert Aitken, and 25 other Buddhists and ecologists.

Many new age authors have written books which mix New Age teachings with Gaia philosophy. This is known as New Age Gaian. Often referred to as Gaianism, or the Gaian Religion, this spiritual aspect of the philosophy is very broad and inclusive, making it adaptable to other religions: Taoism, Neo-Paganism, Pantheism, Judeo-Christian Religions, and many others.

The question of "what is an organism", and at what scale is it rational to speak about organisms vs. biospheres, gives rise to a semantic debate. We are all ecologies in the sense that our (human) bodies contain gut bacteria, parasite species, etc., and to them our body is not organism but rather more of a microclimate or biome. Applying that thinking to whole planets:

The argument is that these symbiotic organisms, being unable to survive apart from each other and their climate and local conditions, form an organism in their own right, under a wider conception of the term organism than is conventionally used. It is a matter for often heated debate whether this is a valid usage of the term, but ultimately it appears to be a semantic dispute. In this sense of the word organism, it is argued under the theory that the entire biomass of the Earth is a single organism (as Johannes Kepler thought).

Unfortunately, many supporters of the various Gaia theories do not state exactly where they sit on this spectrum; this makes discussion and criticism difficult.

Much effort on behalf of those analyzing the theory currently is an attempt to clarify what these different hypotheses are, and whether they are proposals to 'test' or 'manipulate' outcomes. Both Lovelock's and Margulis's understanding of Gaia are considered scientific hypotheses, and like all scientific theories are constantly put to the test.

More speculative versions of Gaia, including all versions in which it is held that the Earth is actually conscious, are currently held to be outside the bounds of science, and are not supported by either Lovelock or Margulis.

One of the most problematic issues with referring to Gaia as an organism is its apparent failure to meet the biological criterion of being able to reproduce. Richard Dawkins has asserted that the planet is not the offspring of any parents and is unable to reproduce.





</doc>
<doc id="12395" url="https://en.wikipedia.org/wiki?curid=12395" title="Greenhouse effect">
Greenhouse effect

The greenhouse effect is the process by which radiation from a planet's atmosphere warms the planet's surface to a temperature above what it would be without this atmosphere.

Radiatively active gases (i.e., greenhouse gases) in a planet's atmosphere radiate energy in all directions. Part of this radiation is directed towards the surface, warming it. The intensity of the downward radiation – that is, the strength of the greenhouse effect – will depend on the atmosphere's temperature and on the amount of greenhouse gases that the atmosphere contains.

Earth's natural greenhouse effect is critical to supporting life, and initially was a precursor to life moving out of the ocean onto land. Human activities, however, mainly the burning of fossil fuels and clearcutting of forests, have accelerated the greenhouse effect and caused global warming.

The planet Venus experienced runaway greenhouse effect, resulting in an atmosphere which is 96% carbon dioxide, with surface atmospheric pressure roughly the same as found underwater on Earth. Venus may have had water oceans, but they would have boiled off as the mean surface temperature rose to the current .

The term "greenhouse effect" continues to see use in scientific circles and the media despite being a slight misnomer, as an atmosphere reduces radiative heat loss while a greenhouse blocks convective heat loss. The result, however, is an increase in temperature in both cases.

The existence of the greenhouse effect, while not named as such, was proposed by Joseph Fourier in 1824. The argument and the evidence were further strengthened by Claude Pouillet in 1827 and 1838. John Tyndall was the first to measure the infrared absorption and emission of various gases and vapours. From 1859 onwards, he showed that the effect was due to a very small proportion of the atmosphere, with the main gases having no effect, and was largely due to water vapour, though small percentages of hydrocarbons and carbon dioxide had a significant effect. The effect was more fully quantified by Svante Arrhenius in 1896, who made the first quantitative prediction of global warming due to a hypothetical doubling of atmospheric carbon dioxide. However, the term "greenhouse" was not used to refer to this effect by any of these scientists; the term was first used in this way by Nils Gustaf Ekholm in 1901.

Earth receives energy from the Sun in the form of ultraviolet, visible, and near-infrared radiation. About 26% of the incoming solar energy is reflected to space by the atmosphere and clouds, and 19% is absorbed by the atmosphere and clouds. Most of the remaining energy is absorbed at the surface of Earth. Because the Earth's surface is colder than the Sun, it radiates at wavelengths that are much longer than the wavelengths that were absorbed. Most of this thermal radiation is absorbed by the atmosphere and warms it. The atmosphere also gains heat by sensible and latent heat fluxes from the surface. The atmosphere radiates energy both upwards and downwards; the part radiated downwards is absorbed by the surface of Earth. This leads to a higher equilibrium temperature than if the atmosphere did not radiate.

An ideal thermally conductive blackbody at the same distance from the Sun as Earth would have a temperature of about . However, because Earth reflects about 30% of the incoming sunlight, this idealized planet's effective temperature (the temperature of a blackbody that would emit the same amount of radiation) would be about . The surface temperature of this hypothetical planet is below Earth's actual surface temperature of approximately . The greenhouse effect is the contribution of greenhouse gases to this difference.

The idealized greenhouse model is a simplification. In reality the atmosphere near the Earth's surface is largely opaque to thermal radiation and most heat loss from the surface is by convection. However radiative energy losses become increasingly important higher in the atmosphere, largely because of the decreasing concentration of water vapor, an important greenhouse gas. Rather than the surface itself, it is more realistic to think of the greenhouse effect as applying to a layer in the mid-troposphere, which is effectively coupled to the surface by a lapse rate. A simple picture also assumes a steady state, but in the real world, the diurnal cycle as well as the seasonal cycle and weather disturbances complicate matters. Solar heating applies only during daytime. During the night, the atmosphere cools somewhat, but not greatly, because its emissivity is low. Diurnal temperature changes decrease with height in the atmosphere.

Within the region where radiative effects are important, the description given by the idealized greenhouse model becomes realistic. Earth's surface, warmed to an "effective temperature" around , radiates long-wavelength, infrared heat in the range of 4–100 μm. At these wavelengths, greenhouse gases that were largely transparent to incoming solar radiation are more absorbent. Each layer of atmosphere with greenhouse gases absorbs some of the heat being radiated upwards from lower layers. It reradiates in all directions, both upwards and downwards; in equilibrium (by definition) the same amount as it has absorbed. This results in more warmth below. Increasing the concentration of the gases increases the amount of absorption and reradiation, and thereby further warms the layers and ultimately the surface below.

Greenhouse gases—including most diatomic gases with two different atoms (such as carbon monoxide, CO) and all gases with three or more atoms—are able to absorb and emit infrared radiation. Though more than 99% of the dry atmosphere is IR transparent (because the main constituents—, , and Ar—are not able to directly absorb or emit infrared radiation), intermolecular collisions cause the energy absorbed and emitted by the greenhouse gases to be shared with the other, non-IR-active, gases.

By their percentage contribution to the greenhouse effect on Earth the four major gases are:


It is not possible to assign a specific percentage to each gas because the absorption and emission bands of the gases overlap (hence the ranges given above). Clouds also absorb and emit infrared radiation and thus affect the radiative properties of the atmosphere.

Strengthening of the greenhouse effect through human activities is known as the enhanced (or anthropogenic) greenhouse effect. This increase in radiative forcing from human activity is attributable mainly to increased atmospheric carbon dioxide levels. According to the 2014 Assessment Report from the Intergovernmental Panel on Climate Change, "atmospheric concentrations of carbon dioxide, methane and nitrous oxide are unprecedented in at least the last 800,000 years. Their effects, together with those of other anthropogenic drivers, have been detected throughout the climate system and are extremely likely to have been the dominant cause of the observed warming since the mid-20th century'".

Over the past 800,000 years, ice core data shows that carbon dioxide has varied from values as low as 180 ppm to the pre-industrial level of 270 ppm. Paleoclimatologists consider variations in carbon dioxide concentration to be a fundamental factor influencing climate variations over this time scale.

The "greenhouse effect" of the atmosphere is named by analogy to greenhouses which become warmer in sunlight. However, a greenhouse is not primarily warmed by the "greenhouse effect".
"Greenhouse effect" is actually a misnomer since heating in the usual greenhouse is due to the reduction of convection, while the "greenhouse effect" works by preventing absorbed heat from leaving the structure through radiative transfer.

A greenhouse is built of any material that passes sunlight: usually glass or plastic. The sun warms the ground and contents inside just like the outside, and these then warm the air. Outside, the warm air near the surface rises and mixes with cooler air aloft, keeping the temperature lower than inside, where the air continues to heat up because it is confined within the greenhouse. This can be demonstrated by opening a small window near the roof of a greenhouse: the temperature will drop considerably. It was demonstrated experimentally (R. W. Wood, 1909) that a (not heated) "greenhouse" with a cover of rock salt (which is transparent to infrared) heats up an enclosure similarly to one with a glass cover. Thus greenhouses work primarily by preventing convective cooling.

Heated greenhouses are yet another matter: as they have an internal source of heating, it is desirable to minimise the amount of heat leaking out by radiative cooling. This can be done through the use of adequate glazing.

The anti-greenhouse effect is a mechanism similar and symmetrical to the greenhouse effect: in the greenhouse effect, the atmosphere lets radiation in while not letting thermal radiation out, thus warming the body surface; in the anti-greenhouse effect, the atmosphere keeps radiation out while letting thermal radiation out, which lowers the equilibrium surface temperature. Such an effect has been proposed for Saturn's moon Titan.

A runaway greenhouse effect occurs if positive feedbacks lead to the evaporation of all greenhouse gases into the atmosphere. A runaway greenhouse effect involving carbon dioxide and water vapor has long ago been hypothesized to have occurred on Venus, .

The 'greenhouse effect' on Venus is particularly large for several reasons:
"Venus experienced a runaway greenhouse in the past, and we expect that Earth will in about 2 billion years as solar luminosity increases".

Titan is a body with both a greenhouse effect and an anti-greenhouse effect. The presence of N, CH, and H in the atmosphere contribute to a greenhouse effect, increasing the surface temperature by 21K over the expected temperature of the body with no atmosphere. The existence of a high-altitude haze, which absorbs wavelengths of solar radiation but is transparent to infrared, contribute to an anti-greenhouse effect of approximately 9K. The net effect of these two phenomena result is a net warming of 21K- 9K= 12K, so Titan is 12 K warmer than it would be if there were no atmosphere.




</doc>
<doc id="12396" url="https://en.wikipedia.org/wiki?curid=12396" title="Group homomorphism">
Group homomorphism

In mathematics, given two groups, ("G", ∗) and ("H", ·), a group homomorphism from ("G", ∗) to ("H", ·) is a function "h" : "G" → "H" such that for all "u" and "v" in "G" it holds that

where the group operation on the left hand side of the equation is that of "G" and on the right hand side that of "H".

From this property, one can deduce that "h" maps the identity element "e" of "G" to the identity element "e" of "H",

and it also maps inverses to inverses in the sense that 

Hence one can say that "h" "is compatible with the group structure".

Older notations for the homomorphism "h"("x") may be "x" or "x", though this may be confused as an index or a general subscript. A more recent trend is to write group homomorphisms on the right of their arguments, omitting brackets, so that "h"("x") becomes simply "x h". This approach is especially prevalent in areas of group theory where automata play a role, since it accords better with the convention that automata read words from left to right.

In areas of mathematics where one considers groups endowed with additional structure, a "homomorphism" sometimes means a map which respects not only the group structure (as above) but also the extra structure. For example, a homomorphism of topological groups is often required to be continuous.

The purpose of defining a group homomorphism is to create functions that preserve the algebraic structure. An equivalent definition of group homomorphism is: The function "h" : "G" → "H" is a group homomorphism if whenever 

"a" ∗ "b" = "c"   we have   "h"("a") ⋅ "h"("b") = "h"("c"). 

In other words, the group "H" in some sense has a similar algebraic structure as "G" and the homomorphism "h" preserves that.


We define the "kernel of h" to be the set of elements in "G" which are mapped to the identity in "H"

and the "image of h" to be

The kernel and image of a homomorphism can be interpreted as measuring how close it is to being an isomorphism. The first isomorphism theorem states that the image of a group homomorphism, "h"("G") is isomorphic to the quotient group "G"/ker "h".

The kernel of h is a normal subgroup of "G" and the image of h is a subgroup of "H":

If and only if }, the homomorphism, "h", is a "group monomorphism"; i.e., "h" is injective (one-to-one). Injection directly gives that there is a unique element in the kernel, and a unique element in the kernel gives injection:



If and are group homomorphisms, then so is . This shows that the class of all groups, together with group homomorphisms as morphisms, forms a category.

If "G" and "H" are abelian (i.e., commutative) groups, then the set of all group homomorphisms from "G" to "H" is itself an abelian group: the sum of two homomorphisms is defined by
The commutativity of "H" is needed to prove that is again a group homomorphism.

The addition of homomorphisms is compatible with the composition of homomorphisms in the following sense: if "f" is in , "h", "k" are elements of , and "g" is in , then 
Since the composition is associative, this shows that the set End("G") of all endomorphisms of an abelian group forms a ring, the "endomorphism ring" of "G". For example, the endomorphism ring of the abelian group consisting of the direct sum of "m" copies of Z/"nZ is isomorphic to the ring of "m"-by-"m" matrices with entries in Z/"nZ. The above compatibility also shows that the category of all abelian groups with group homomorphisms forms a preadditive category; the existence of direct sums and well-behaved kernels makes this category the prototypical example of an abelian category.




</doc>
<doc id="12397" url="https://en.wikipedia.org/wiki?curid=12397" title="Group isomorphism">
Group isomorphism

In abstract algebra, a group isomorphism is a function between two groups that sets up a one-to-one correspondence between the elements of the groups in a way that respects the given group operations. If there exists an isomorphism between two groups, then the groups are called isomorphic. From the standpoint of group theory, isomorphic groups have the same properties and need not be distinguished.

Given two groups (G, ∗) and (H, formula_1), a "group isomorphism" from (G, ∗) to (H, formula_1) is a bijective group homomorphism from G to H. Spelled out, this means that a group isomorphism is a bijective function formula_3 such that for all u and v in G it holds that

The two groups (G, ∗) and (H, formula_1) are isomorphic if there exists an isomorphism from one to the other. This is written:

Often shorter and simpler notations can be used. When the relevant group operations are unambiguous they are omitted and one writes:

Sometimes one can even simply write G = H. Whether such a notation is possible without confusion or ambiguity depends on context. For example, the equals sign is not very suitable when the groups are both subgroups of the same group. See also the examples.

Conversely, given a group (G, ∗), a set H, and a bijection formula_3, we can make H a group (H, formula_1) by defining

If H = G and formula_1 = ∗ then the bijection is an automorphism ("q.v.").

Intuitively, group theorists view two isomorphic groups as follows: For every element "g" of a group "G", there exists an element "h" of "H" such that "h" 'behaves in the same way' as "g" (operates with other elements of the group in the same way as "g"). For instance, if "g" generates "G", then so does "h". This implies in particular that "G" and "H" are in bijective correspondence. Thus, the definition of an isomorphism is quite natural.

An isomorphism of groups may equivalently be defined as an invertible morphism in the category of groups, where invertible here means has a two-sided inverse.

In this section some notable examples of isomorphic groups are listed.

Some groups can be proven to be isomorphic, relying on the axiom of choice, but the proof does not indicate how to construct a concrete isomorphism. Examples:

The kernel of an isomorphism from ("G", ∗) to ("H", formula_1), is always {e} where e is the identity of the group ("G", ∗)

If ("G", ∗) is isomorphic to ("H",formula_1), and if "G" is abelian then so is "H".

If ("G", ∗) is a group that is isomorphic to ("H", formula_1) [where "f" is the isomorphism], then if "a" belongs to "G" and has order "n", then so does "f(a)".

If ("G", ∗) is a locally finite group that is isomorphic to ("H", formula_1), then ("H", formula_1) is also locally finite. 

The number of distinct groups (when isomorphic groups are considered equal) of order formula_31 is given by sequence A000001 in OEIS. The first few numbers are 0, 1, 1, 1 and 2 meaning that 4 is the lowest order with more than one group.

All cyclic groups of a given order are isomorphic to formula_32.

Let "G" be a cyclic group and "n" be the order of "G". "G" is then the group generated by formula_33. 
We will show that

Define 
Then

From the definition, it follows that any isomorphism formula_3 will map the identity element of G to the identity element of H, 
that it will map inverses to inverses,
and more generally, "n"th powers to "n"th powers,
for all u in G,
and that the inverse map formula_44 is also a group isomorphism.

The relation "being isomorphic" satisfies all the axioms of an equivalence relation. If f is an isomorphism between two groups G and H, then everything that is true about G that is only related to the group structure can be translated via f into a true ditto statement about H, and vice versa.

An isomorphism from a group (G, ∗) to itself is called an automorphism of this group. Thus it is a bijection formula_45 such that

An automorphism always maps the identity to itself. The image under an automorphism of a conjugacy class is always a conjugacy class (the same or another). The image of an element has the same order as that element.

The composition of two automorphisms is again an automorphism, and with this operation the set of all automorphisms of a group G, denoted by Aut(G), forms itself a group, the "automorphism group" of G.

For all abelian groups there is at least the automorphism that replaces the group elements by their inverses. However, in groups where all elements are equal to their inverse this is the trivial automorphism, e.g. in the Klein four-group. For that group all permutations of the three non-identity elements are automorphisms, so the automorphism group is isomorphic to S and Dih.

In Z for a prime number p, one non-identity element can be replaced by any other, with corresponding changes in the other elements. The automorphism group is isomorphic to . For example, for , multiplying all elements of Z by 3, modulo 7, is an automorphism of order 6 in the automorphism group, because , while lower powers do not give 1. Thus this automorphism generates Z. There is one more automorphism with this property: multiplying all elements of Z by 5, modulo 7. Therefore, these two correspond to the elements 1 and 5 of Z, in that order or conversely.

The automorphism group of Z is isomorphic to Z, because only each of the two elements 1 and 5 generate Z, so apart from the identity we can only interchange these.

The automorphism group of has order 168, as can be found as follows. All 7 non-identity elements play the same role, so we can choose which plays the role of (1,0,0). Any of the remaining 6 can be chosen to play the role of (0,1,0). This determines which corresponds to (1,1,0). For (0,0,1) we can choose from 4, which determines the rest. Thus we have automorphisms. They correspond to those of the Fano plane, of which the 7 points correspond to the 7 non-identity elements. The lines connecting three points correspond to the group operation: "a", "b", and "c" on one line means , , and . See also general linear group over finite fields.

For abelian groups all automorphisms except the trivial one are called outer automorphisms.

Non-abelian groups have a non-trivial inner automorphism group, and possibly also outer automorphisms.




</doc>
<doc id="12398" url="https://en.wikipedia.org/wiki?curid=12398" title="Geographic information system">
Geographic information system

A geographic information system (GIS) is a conceptualized framework that provides the ability to capture and analyze spatial and geographic data. "GIS applications" (or "GIS apps") are computer-based tools that allow the user to create "interactive queries" (user-created searches), store and edit spatial and non-spatial data, analyze spatial information output, and visually share the results of these operations by presenting them as maps. 

Geographic information science ("or, GIScience")—the scientific study of geographic concepts, applications, and systems—is commonly initialized as "GIS", as well. 

Geographic information systems are utilized in multiple technologies, processes, techniques and methods. It is attached to various operations and numerous applications, that relate to: engineering, planning, management, transport/logistics, insurance, telecommunications, and business. For this reason, "GIS" and "location intelligence applications" are at the foundation of "location-enabled services", that rely on geographic analysis and visualization.

GIS provides the capability to relate previously unrelated information, through the use of "location as the "key index variable"". Locations and extents that are found in the Earth's spacetime, are able to be recorded through the date and time of occurrence, along with x, y, and z coordinates; representing, longitude ("x"), latitude ("y"), and elevation ("z"). All Earth-based, spatial–temporal, location and extent references, should be relatable to one another, and ultimately, to a "real" physical location or extent. This key characteristic of GIS, has begun to open new avenues of scientific inquiry and studies.

The phrase, "geographic information system", was coined by Roger Tomlinson in 1968, when he published the scientific paper, "A Geographic Information System for Regional Planning". Tomlinson, acknowledged as the "father of GIS", is credited with enabling the first computerized–GIS to be created through his work on the Canada Geographic Information System in 1963. Ultimately, Tomlinson created a framework for a database that was capable of storing and analyzing huge amounts of data; leading to the Canadian government being able to implement its National Land-Use Management Program.
One of the first known instances in which spatial analysis was used, came from the field of epidemiology in the, ""Rapport sur la marche et les effets du choléra dans Paris et le département de la Seine"" (1832).French geographer and cartographer, Charles Picquet, created a map outlining the forty-eight Districts in Paris, using halftone color gradients, to provide a visual representation for the number of reported deaths due to cholera, per every 1,000 inhabitants. 

In 1854, John Snow, an epidemiologist and physician, was able to determine the source of a cholera outbreak in London through the use of spatial analysis. Snow achieved this through plotting the residence of each victim on a map of the area, as well as the nearby water sources. Once these points were marked, he was able to visualize the water source within the cluster that was responsible for the outbreak. This was one of the earliest successful uses of a geographic methodology in pinpointing the source of an outbreak in epidemiology. While the basic elements of topography and theme existed previously in cartography, Snow's map was unique due to his use of cartographic methods, not only to depict, but also to analyze clusters of geographically dependent phenomena.

The early 20th century saw the development of photozincography, which allowed maps to be split into layers, for example one layer for vegetation and another for water. This was particularly used for printing contours – drawing these was a labour-intensive task but having them on a separate layer meant they could be worked on without the other layers to confuse the draughtsman. This work was originally drawn on glass plates but later plastic film was introduced, with the advantages of being lighter, using less storage space and being less brittle, among others. When all the layers were finished, they were combined into one image using a large process camera. Once color printing came in, the layers idea was also used for creating separate printing plates for each color. While the use of layers much later became one of the main typical features of a contemporary GIS, the photographic process just described is not considered to be a GIS in itself – as the maps were just images with no database to link them to.

Two additional developments are notable in the early days of GIS: Ian McHarg's publication ""Design with Nature"" and its map overlay method and the introduction of a street network into the U.S. Census Bureau's DIME (Dual Independent Map Encoding) system.

Computer hardware development spurred by nuclear weapon research led to general-purpose computer "mapping" applications by the early 1960s.

In 1960 the world's first true operational GIS was developed in Ottawa, Ontario, Canada, by the federal Department of Forestry and Rural Development. Developed by Dr. Roger Tomlinson, it was called the Canada Geographic Information System (CGIS) and was used to store, analyze, and manipulate data collected for the Canada Land Inventory – an effort to determine the land capability for rural Canada by mapping information about soils, agriculture, recreation, wildlife, waterfowl, forestry and land use at a scale of 1:50,000. A rating classification factor was also added to permit analysis.

CGIS was an improvement over "computer mapping" applications as it provided capabilities for overlay, measurement, and digitizing/scanning. It supported a national coordinate system that spanned the continent, coded lines as arcs having a true embedded topology and it stored the attribute and locational information in separate files. As a result of this, Tomlinson has become known as the "father of GIS", particularly for his use of overlays in promoting the spatial analysis of convergent geographic data.

CGIS lasted into the 1990s and built a large digital land resource database in Canada. It was developed as a mainframe-based system in support of federal and provincial resource planning and management. Its strength was continent-wide analysis of complex datasets. The CGIS was never available commercially.

In 1964 Howard T. Fisher formed the Laboratory for Computer Graphics and Spatial Analysis at the Harvard Graduate School of Design (LCGSA 1965–1991), where a number of important theoretical concepts in spatial data handling were developed, and which by the 1970s had distributed seminal software code and systems, such as SYMAP, GRID, and ODYSSEY – that served as sources for subsequent commercial development—to universities, research centers and corporations worldwide.

By the late 1970s two public domain GIS systems (MOSS and GRASS GIS) were in development, and by the early 1980s, M&S Computing (later Intergraph) along with Bentley Systems Incorporated for the CAD platform, Environmental Systems Research Institute (ESRI), CARIS (Computer Aided Resource Information System), MapInfo Corporation and ERDAS (Earth Resource Data Analysis System) emerged as commercial vendors of GIS software, successfully incorporating many of the CGIS features, combining the first generation approach to separation of spatial and attribute information with a second generation approach to organizing attribute data into database structures.

In 1986, Mapping Display and Analysis System (MIDAS), the first desktop GIS product was released for the DOS operating system. This was renamed in 1990 to MapInfo for Windows when it was ported to the Microsoft Windows platform. This began the process of moving GIS from the research department into the business environment.

By the end of the 20th century, the rapid growth in various systems had been consolidated and standardized on relatively few platforms and users were beginning to explore viewing GIS data over the Internet, requiring data format and transfer standards. More recently, a growing number of free, open-source GIS packages run on a range of operating systems and can be customized to perform specific tasks. Increasingly geospatial data and mapping applications are being made available via the World Wide Web (see ).

Several articles on the history of GIS have been published.

Modern GIS technologies use digital information, for which various digitized data creation methods are used. The most common method of data creation is digitization, where a hard copy map or survey plan is transferred into a digital medium through the use of a CAD program, and geo-referencing capabilities. With the wide availability of ortho-rectified imagery (from satellites, aircraft, Helikites and UAVs), heads-up digitizing is becoming the main avenue through which geographic data is extracted. Heads-up digitizing involves the tracing of geographic data directly on top of the aerial imagery instead of by the traditional method of tracing the geographic form on a separate digitizing tablet (heads-down digitizing).

Geoprocessing is a GIS operation used to manipulate spatial data. A typical geoprocessing operation takes an input dataset, performs an operation on that dataset, and returns the result of the operation as an output dataset. Common geoprocessing operations include geographic feature overlay, feature selection and analysis, topology processing, raster processing, and data conversion. Geoprocessing allows for definition, management, and analysis of information used to form decisions.

GIS uses spatio-temporal (space-time) location as the key index variable for all other information. Just as a relational database containing text or numbers can relate many different tables using common key index variables, GIS can relate otherwise unrelated information by using location as the key index variable. The key is the location and/or extent in space-time.

Any variable that can be located spatially, and increasingly also temporally, can be referenced using a GIS. Locations or extents in Earth space–time may be recorded as dates/times of occurrence, and x, y, and z coordinates representing, longitude, latitude, and elevation, respectively. These GIS coordinates may represent other quantified systems of temporo-spatial reference (for example, film frame number, stream gage station, highway mile-marker, surveyor benchmark, building address, street intersection, entrance gate, water depth sounding, POS or CAD drawing origin/units). Units applied to recorded temporal-spatial data can vary widely (even when using exactly the same data, see map projections), but all Earth-based spatial–temporal location and extent references should, ideally, be relatable to one another and ultimately to a "real" physical location or extent in space–time.

Related by accurate spatial information, an incredible variety of real-world and projected past or future data can be analyzed, interpreted and represented. This key characteristic of GIS has begun to open new avenues of scientific inquiry into behaviors and patterns of real-world information that previously had not been systematically correlated.

GIS accuracy depends upon source data, and how it is encoded to be data referenced. Land surveyors have been able to provide a high level of positional accuracy utilizing the GPS-derived positions. High-resolution digital terrain and aerial imagery, powerful computers and Web technology are changing the quality, utility, and expectations of GIS to serve society on a grand scale, but nevertheless there are other source data that affect overall GIS accuracy like paper maps, though these may be of limited use in achieving the desired accuracy.

In developing a digital topographic database for a GIS, topographical maps are the main source, and aerial photography and satellite imagery are extra sources for collecting data and identifying attributes which can be mapped in layers over a location facsimile of scale. The scale of a map and geographical rendering area representation type are very important aspects since the information content depends mainly on the scale set and resulting locatability of the map's representations. In order to digitize a map, the map has to be checked within theoretical dimensions, then scanned into a raster format, and resulting raster data has to be given a theoretical dimension by a rubber sheeting/warping technology process.

A quantitative analysis of maps brings accuracy issues into focus. The electronic and other equipment used to make measurements for GIS is far more precise than the machines of conventional map analysis. All geographical data are inherently inaccurate, and these inaccuracies will propagate through GIS operations in ways that are difficult to predict.

GIS data represents real objects (such as roads, land use, elevation, trees, waterways, etc.) with digital data determining the mix. Real objects can be divided into two abstractions: discrete objects (e.g., a house) and continuous fields (such as rainfall amount, or elevations). Traditionally, there are two broad methods used to store data in a GIS for both kinds of abstractions mapping references: raster images and vector. Points, lines, and polygons are the stuff of mapped location attribute references. A new hybrid method of storing data is that of identifying point clouds, which combine three-dimensional points with RGB information at each point, returning a "3D color image". GIS thematic maps then are becoming more and more realistically visually descriptive of what they set out to show or determine.

For a list of popular GIS file formats, such as shapefiles, see .

Data capture—entering information into the system—consumes much of the time of GIS practitioners. There are a variety of methods used to enter data into a GIS where it is stored in a digital format.

Existing data printed on paper or PET film maps can be digitized or scanned to produce digital data. A digitizer produces vector data as an operator traces points, lines, and polygon boundaries from a map. Scanning a map results in raster data that could be further processed to produce vector data.

Survey data can be directly entered into a GIS from digital data collection systems on survey instruments using a technique called coordinate geometry (COGO). Positions from a global navigation satellite system (GNSS) like Global Positioning System can also be collected and then imported into a GIS. A current trend in data collection gives users the ability to utilize field computers with the ability to edit live data using wireless connections or disconnected editing sessions. This has been enhanced by the availability of low-cost mapping-grade GPS units with decimeter accuracy in real time. This eliminates the need to post process, import, and update the data in the office after fieldwork has been collected. This includes the ability to incorporate positions collected using a laser rangefinder. New technologies also allow users to create maps as well as analysis directly in the field, making projects more efficient and mapping more accurate.

Remotely sensed data also plays an important role in data collection and consist of sensors attached to a platform. Sensors include cameras, digital scanners and lidar, while platforms usually consist of aircraft and satellites. In England in the mid 1990s, hybrid kite/balloons called helikites first pioneered the use of compact airborne digital cameras as airborne geo-information systems. Aircraft measurement software, accurate to 0.4 mm was used to link the photographs and measure the ground. Helikites are inexpensive and gather more accurate data than aircraft. Helikites can be used over roads, railways and towns where unmanned aerial vehicles (UAVs) are banned.

Recently aerial data collection is becoming possible with miniature UAVs. For example, the Aeryon Scout was used to map a 50-acre area with a ground sample distance of in only 12 minutes.

The majority of digital data currently comes from photo interpretation of aerial photographs. Soft-copy workstations are used to digitize features directly from stereo pairs of digital photographs. These systems allow data to be captured in two and three dimensions, with elevations measured directly from a stereo pair using principles of photogrammetry. Analog aerial photos must be scanned before being entered into a soft-copy system, for high-quality digital cameras this step is skipped.

Satellite remote sensing provides another important source of spatial data. Here satellites use different sensor packages to passively measure the reflectance from parts of the electromagnetic spectrum or radio waves that were sent out from an active sensor such as radar. Remote sensing collects raster data that can be further processed using different bands to identify objects and classes of interest, such as land cover.

When data is captured, the user should consider if the data should be captured with either a relative accuracy or absolute accuracy, since this could not only influence how information will be interpreted but also the cost of data capture.

After entering data into a GIS, the data usually requires editing, to remove errors, or further processing. For vector data it must be made "topologically correct" before it can be used for some advanced analysis. For example, in a road network, lines must connect with nodes at an intersection. Errors such as undershoots and overshoots must also be removed. For scanned maps, blemishes on the source map may need to be removed from the resulting raster. For example, a fleck of dirt might connect two lines that should not be connected.

Data restructuring can be performed by a GIS to convert data into different formats. For example, a GIS may be used to convert a satellite image map to a vector structure by generating lines around all cells with the same classification, while determining the cell spatial relationships, such as adjacency or inclusion.

More advanced data processing can occur with image processing, a technique developed in the late 1960s by NASA and the private sector to provide contrast enhancement, false color rendering and a variety of other techniques including use of two dimensional Fourier transforms. Since digital data is collected and stored in various ways, the two data sources may not be entirely compatible. So a GIS must be able to convert geographic data from one structure to another. In so doing, the implicit assumptions behind different ontologies and classifications require analysis. Object ontologies have gained increasing prominence as a consequence of object-oriented programming and sustained work by Barry Smith and co-workers.

The earth can be represented by various models, each of which may provide a different set of coordinates (e.g., latitude, longitude, elevation) for any given point on the Earth's surface. The simplest model is to assume the earth is a perfect sphere. As more measurements of the earth have accumulated, the models of the earth have become more sophisticated and more accurate. In fact, there are models called datums that apply to different areas of the earth to provide increased accuracy, like NAD83 for U.S. measurements, and the World Geodetic System for worldwide measurements.

GIS spatial analysis is a rapidly changing field, and GIS packages are increasingly including analytical tools as standard built-in facilities, as optional toolsets, as add-ins or 'analysts'. In many instances these are provided by the original software suppliers (commercial vendors or collaborative non commercial development teams), while in other cases facilities have been developed and are provided by third parties. Furthermore, many products offer software development kits (SDKs), programming languages and language support, scripting facilities and/or special interfaces for developing one's own analytical tools or variants. The increased availability has created a new dimension to business intelligence termed "spatial intelligence" which, when openly delivered via intranet, democratizes access to geographic and social network data. Geospatial intelligence, based on GIS spatial analysis, has also become a key element for security. GIS as a whole can be described as conversion to a vectorial representation or to any other digitisation process.

Slope can be defined as the steepness or gradient of a unit of terrain, usually measured as an angle in degrees or as a percentage. Aspect can be defined as the direction in which a unit of terrain faces. Aspect is usually expressed in degrees from north. Slope, aspect, and surface curvature in terrain analysis are all derived from neighborhood operations using elevation values of a cell's adjacent neighbours. Slope is a function of resolution, and the spatial resolution used to calculate slope and aspect should always be specified. Various authors have compared techniques for calculating slope and aspect.

The following method can be used to derive slope and aspect:

The elevation at a point or unit of terrain will have perpendicular tangents (slope) passing through the point, in an east-west and north-south direction. These two tangents give two components, ∂z/∂x and ∂z/∂y, which then be used to determine the overall direction of slope, and the aspect of the slope. The gradient is defined as a vector quantity with components equal to the partial derivatives of the surface in the x and y directions.

The calculation of the overall 3×3 grid slope "S" and aspect "A" for methods that determine east-west and north-south component use the following formulas respectively:

Zhou and Liu describe another formula for calculating aspect, as follows:

It is difficult to relate wetlands maps to rainfall amounts recorded at different points such as airports, television stations, and schools. A GIS, however, can be used to depict two- and three-dimensional characteristics of the Earth's surface, subsurface, and atmosphere from information points. For example, a GIS can quickly generate a map with isopleth or contour lines that indicate differing amounts of rainfall. Such a map can be thought of as a rainfall contour map. Many sophisticated methods can estimate the characteristics of surfaces from a limited number of point measurements. A two-dimensional contour map created from the surface modeling of rainfall point measurements may be overlaid and analyzed with any other map in a GIS covering the same area. This GIS derived map can then provide additional information - such as the viability of water power potential as a renewable energy source. Similarly, GIS can be used to compare other renewable energy resources to find the best geographic potential for a region.

Additionally, from a series of three-dimensional points, or digital elevation model, isopleth lines representing elevation contours can be generated, along with slope analysis, shaded relief, and other elevation products. Watersheds can be easily defined for any given reach, by computing all of the areas contiguous and uphill from any given point of interest. Similarly, an expected thalweg of where surface water would want to travel in intermittent and permanent streams can be computed from elevation data in the GIS.

A GIS can recognize and analyze the spatial relationships that exist within digitally stored spatial data. These topological relationships allow complex spatial modelling and analysis to be performed. Topological relationships between geometric entities traditionally include adjacency (what adjoins what), containment (what encloses what), and proximity (how close something is to something else).

Geometric networks are linear networks of objects that can be used to represent interconnected features, and to perform special spatial analysis on them. A geometric network is composed of edges, which are connected at junction points, similar to graphs in mathematics and computer science. Just like graphs, networks can have weight and flow assigned to its edges, which can be used to represent various interconnected features more accurately. Geometric networks are often used to model road networks and public utility networks, such as electric, gas, and water networks. Network modeling is also commonly employed in transportation planning, hydrology modeling, and infrastructure modeling.

GIS hydrological models can provide a spatial element that other hydrological models lack, with the analysis of variables such as slope, aspect and watershed or catchment area. Terrain analysis is fundamental to hydrology, since water always flows down a slope. As basic terrain analysis of a digital elevation model (DEM) involves calculation of slope and aspect, DEMs are very useful for hydrological analysis. Slope and aspect can then be used to determine direction of surface runoff, and hence flow accumulation for the formation of streams, rivers and lakes. Areas of divergent flow can also give a clear indication of the boundaries of a catchment. Once a flow direction and accumulation matrix has been created, queries can be performed that show contributing or dispersal areas at a certain point. More detail can be added to the model, such as terrain roughness, vegetation types and soil types, which can influence infiltration and evapotranspiration rates, and hence influencing surface flow. One of the main uses of hydrological modeling is in environmental contamination research. Other applications of hydrological modeling include groundwater and surface water mapping, as well as flood risk maps.

Dana Tomlin probably coined the term "cartographic modeling" in his PhD dissertation (1983); he later used it in the title of his book, "Geographic Information Systems and Cartographic Modeling" (1990).
Cartographic modeling refers to a process where several thematic layers of the same area are produced, processed, and analyzed. Tomlin used raster layers, but the overlay method (see below) can be used more generally. Operations on map layers can be combined into algorithms, and eventually into simulation or optimization models.

The combination of several spatial datasets (points, lines, or polygons) creates a new output vector dataset, visually similar to stacking several maps of the same region. These overlays are similar to mathematical Venn diagram overlays. A union overlay combines the geographic features and attribute tables of both inputs into a single new output. An intersect overlay defines the area where both inputs overlap and retains a set of attribute fields for each. A symmetric difference overlay defines an output area that includes the total area of both inputs except for the overlapping area.

Data extraction is a GIS process similar to vector overlay, though it can be used in either vector or raster data analysis. Rather than combining the properties and features of both datasets, data extraction involves using a "clip" or "mask" to extract the features of one data set that fall within the spatial extent of another dataset.

In raster data analysis, the overlay of datasets is accomplished through a process known as "local operation on multiple rasters" or "map algebra", through a function that combines the values of each raster's matrix. This function may weigh some inputs more than others through use of an "index model" that reflects the influence of various factors upon a geographic phenomenon.

Geostatistics is a branch of statistics that deals with field data, spatial data with a continuous index. It provides methods to model spatial correlation, and predict values at arbitrary locations (interpolation).

When phenomena are measured, the observation methods dictate the accuracy of any subsequent analysis. Due to the nature of the data (e.g. traffic patterns in an urban environment; weather patterns over the Pacific Ocean), a constant or dynamic degree of precision is always lost in the measurement. This loss of precision is determined from the scale and distribution of the data collection.

To determine the statistical relevance of the analysis, an average is determined so that points (gradients) outside of any immediate measurement can be included to determine their predicted behavior. This is due to the limitations of the applied statistic and data collection methods, and interpolation is required to predict the behavior of particles, points, and locations that are not directly measurable.

Interpolation is the process by which a surface is created, usually a raster dataset, through the input of data collected at a number of sample points. There are several forms of interpolation, each which treats the data differently, depending on the properties of the data set. In comparing interpolation methods, the first consideration should be whether or not the source data will change (exact or approximate). Next is whether the method is subjective, a human interpretation, or objective. Then there is the nature of transitions between points: are they abrupt or gradual. Finally, there is whether a method is global (it uses the entire data set to form the model), or local where an algorithm is repeated for a small section of terrain.

Interpolation is a justified measurement because of a spatial autocorrelation principle that recognizes that data collected at any position will have a great similarity to, or influence of those locations within its immediate vicinity.

Digital elevation models, triangulated irregular networks, edge-finding algorithms, Thiessen polygons, Fourier analysis, (weighted) moving averages, inverse distance weighting, kriging, spline, and trend surface analysis are all mathematical methods to produce interpolative data.

Geocoding is interpolating spatial locations (X,Y coordinates) from street addresses or any other spatially referenced data such as ZIP Codes, parcel lots and address locations. A reference theme is required to geocode individual addresses, such as a road centerline file with address ranges. The individual address locations have historically been interpolated, or estimated, by examining address ranges along a road segment. These are usually provided in the form of a table or database. The software will then place a dot approximately where that address belongs along the segment of centerline. For example, an address point of 500 will be at the midpoint of a line segment that starts with address 1 and ends with address 1,000. Geocoding can also be applied against actual parcel data, typically from municipal tax maps. In this case, the result of the geocoding will be an actually positioned space as opposed to an interpolated point. This approach is being increasingly used to provide more precise location information.

Reverse geocoding is the process of returning an estimated street address number as it relates to a given coordinate. For example, a user can click on a road centerline theme (thus providing a coordinate) and have information returned that reflects the estimated house number. This house number is interpolated from a range assigned to that road segment. If the user clicks at the midpoint of a segment that starts with address 1 and ends with 100, the returned value will be somewhere near 50. Note that reverse geocoding does not return actual addresses, only estimates of what should be there based on the predetermined range.

Coupled with GIS, multi-criteria decision analysis methods support decision-makers in analysing a set of alternative spatial solutions, such as the most likely ecological habitat for restoration, against multiple criteria, such as vegetation cover or roads. MCDA uses decision rules to aggregate the criteria, which allows the alternative solutions to be ranked or prioritised. GIS MCDA may reduce costs and time involved in identifying potential restoration sites.

Cartography is the design and production of maps, or visual representations of spatial data. The vast majority of modern cartography is done with the help of computers, usually using GIS but production of quality cartography is also achieved by importing layers into a design program to refine it. Most GIS software gives the user substantial control over the appearance of the data.

Cartographic work serves two major functions:

First, it produces graphics on the screen or on paper that convey the results of analysis to the people who make decisions about resources. Wall maps and other graphics can be generated, allowing the viewer to visualize and thereby understand the results of analyses or simulations of potential events. Web Map Servers facilitate distribution of generated maps through web browsers using various implementations of web-based application programming interfaces (AJAX, Java, Flash, etc.).

Second, other database information can be generated for further analysis or use. An example would be a list of all addresses within one mile (1.6 km) of a toxic spill.

Traditional maps are abstractions of the real world, a sampling of important elements portrayed on a sheet of paper with symbols to represent physical objects. People who use maps must interpret these symbols. Topographic maps show the shape of land surface with contour lines or with shaded relief.

Today, graphic display techniques such as shading based on altitude in a GIS can make relationships among map elements visible, heightening one's ability to extract and analyze information. For example, two types of data were combined in a GIS to produce a perspective view of a portion of San Mateo County, California.

A GIS was used to register and combine the two images to render the three-dimensional perspective view looking down the San Andreas Fault, using the Thematic Mapper image pixels, but shaded using the elevation of the landforms. The GIS display depends on the viewing point of the observer and time of day of the display, to properly render the shadows created by the sun's rays at that latitude, longitude, and time of day.

An archeochrome is a new way of displaying spatial data. It is a thematic on a 3D map that is applied to a specific building or a part of a building. It is suited to the visual display of heat-loss data.

Spatial ETL tools provide the data processing functionality of traditional extract, transform, load (ETL) software, but with a primary focus on the ability to manage spatial data. They provide GIS users with the ability to translate data between different standards and proprietary formats, whilst geometrically transforming the data en route. These tools can come in the form of add-ins to existing wider-purpose software such as spreadsheets.

GIS or spatial data mining is the application of data mining methods to spatial data. Data mining, which is the partially automated search for hidden patterns in large databases, offers great potential benefits for applied GIS-based decision making. Typical applications include environmental monitoring. A characteristic of such applications is that spatial correlation between data measurements require the use of specialized algorithms for more efficient data analysis.

The implementation of a GIS is often driven by jurisdictional (such as a city), purpose, or application requirements. Generally, a GIS implementation may be custom-designed for an organization. Hence, a GIS deployment developed for an application, jurisdiction, enterprise, or purpose may not be necessarily interoperable or compatible with a GIS that has been developed for some other application, jurisdiction, enterprise, or purpose.

GIS provides, for every kind of location-based organization, a platform to update geographical data without wasting time to visit the field and update a database manually. GIS when integrated with other powerful enterprise solutions like SAP and the Wolfram Language helps creating powerful decision support system at enterprise level.
Many disciplines can benefit from GIS technology. An active GIS market has resulted in lower costs and continual improvements in the hardware and software components of GIS, and usage in the fields of science, government, business, and industry, with applications including real estate, public health, crime mapping, national defense, sustainable development, natural resources, climatology, landscape architecture, archaeology, regional and community planning, transportation and logistics. GIS is also diverging into location-based services, which allows GPS-enabled mobile devices to display their location in relation to fixed objects (nearest restaurant, gas station, fire hydrant) or mobile objects (friends, children, police car), or to relay their position back to a central server for display or other processing.

The Open Geospatial Consortium (OGC) is an international industry consortium of 384 companies, government agencies, universities, and individuals participating in a consensus process to develop publicly available geoprocessing specifications. Open interfaces and protocols defined by OpenGIS Specifications support interoperable solutions that "geo-enable" the Web, wireless and location-based services, and mainstream IT, and empower technology developers to make complex spatial information and services accessible and useful with all kinds of applications. Open Geospatial Consortium protocols include Web Map Service, and Web Feature Service.

GIS products are broken down by the OGC into two categories, based on how completely and accurately the software follows the OGC specifications.
"Compliant Products" are software products that comply to OGC's OpenGIS Specifications. When a product has been tested and certified as compliant through the OGC Testing Program, the product is automatically registered as "compliant" on this site.

"Implementing Products" are software products that implement OpenGIS Specifications but have not yet passed a compliance test. Compliance tests are not available for all specifications. Developers can register their products as implementing draft or approved specifications, though OGC reserves the right to review and verify each entry.

In recent years there has been a proliferation of free-to-use and easily accessible mapping software such as the proprietary web applications Google Maps and Bing Maps, as well as the free and open-source alternative OpenStreetMap. These services give the public access to huge amounts of geographic data; perceived by many users to be as trustworthy and usable as professional information.

Some of them, like Google Maps and OpenLayers, expose an application programming interface (API) that enable users to create custom applications. These toolkits commonly offer street maps, aerial/satellite imagery, geocoding, searches, and routing functionality. Web mapping has also uncovered the potential of crowdsourcing geodata in projects like OpenStreetMap, which is a collaborative project to create a free editable map of the world. These mashup projects have been proven to provide a high level of value and benefit to end users outside that possible through traditional geographic information.

The condition of the Earth's surface, atmosphere, and subsurface can be examined by feeding satellite data into a GIS. GIS technology gives researchers the ability to examine the variations in Earth processes over days, months, and years. As an example, the changes in vegetation vigor through a growing season can be animated to determine when drought was most extensive in a particular region. The resulting graphic represents a rough measure of plant health. Working with two variables over time would then allow researchers to detect regional differences in the lag between a decline in rainfall and its effect on vegetation.

GIS technology and the availability of digital data on regional and global scales enable such analyses. The satellite sensor output used to generate a vegetation graphic is produced for example by the advanced very-high-resolution radiometer (AVHRR). This sensor system detects the amounts of energy reflected from the Earth's surface across various bands of the spectrum for surface areas of about 1 square kilometer. The satellite sensor produces images of a particular location on the Earth twice a day. AVHRR and more recently the moderate-resolution imaging spectroradiometer (MODIS) are only two of many sensor systems used for Earth surface analysis.

In addition to the integration of time in environmental studies, GIS is also being explored for its ability to track and model the progress of humans throughout their daily routines. A concrete example of progress in this area is the recent release of time-specific population data by the U.S. Census. In this data set, the populations of cities are shown for daytime and evening hours highlighting the pattern of concentration and dispersion generated by North American commuting patterns. The manipulation and generation of data required to produce this data would not have been possible without GIS.

Using models to project the data held by a GIS forward in time have enabled planners to test policy decisions using spatial decision support systems.

Tools and technologies emerging from the World Wide Web Consortium's Semantic Web are proving useful for data integration problems in information systems. Correspondingly, such technologies have been proposed as a means to facilitate interoperability and data reuse among GIS applications. and also to enable new analysis mechanisms.

Ontologies are a key component of this semantic approach as they allow a formal, machine-readable specification of the concepts and relationships in a given domain. This in turn allows a GIS to focus on the intended meaning of data rather than its syntax or structure. For example, reasoning that a land cover type classified as "deciduous needleleaf trees" in one dataset is a specialization or subset of land cover type "forest" in another more roughly classified dataset can help a GIS automatically merge the two datasets under the more general land cover classification. Tentative ontologies have been developed in areas related to GIS applications, for example the hydrology ontology developed by the Ordnance Survey in the United Kingdom and the SWEET ontologies developed by NASA's Jet Propulsion Laboratory. Also, simpler ontologies and semantic metadata standards are being proposed by the W3C Geo Incubator Group to represent geospatial data on the web. GeoSPARQL is a standard developed by the Ordnance Survey, United States Geological Survey, Natural Resources Canada, Australia's Commonwealth Scientific and Industrial Research Organisation and others to support ontology creation and reasoning using well-understood OGC literals (GML, WKT), topological relationships (Simple Features, RCC8, DE-9IM), RDF and the SPARQL database query protocols.

Recent research results in this area can be seen in the International Conference on Geospatial Semantics and the Terra Cognita – Directions to the Geospatial Semantic Web workshop at the International Semantic Web Conference.

With the popularization of GIS in decision making, scholars have begun to scrutinize the social and political implications of GIS. GIS can also be misused to distort reality for individual and political gain. It has been argued that the production, distribution, utilization, and representation of geographic information are largely related with the social context and has the potential to increase citizen trust in government. Other related topics include discussion on copyright, privacy, and censorship. A more optimistic social approach to GIS adoption is to use it as a tool for public participation.

At the end of the 20th century, GIS began to be recognized as tools that could be used in the classroom. The benefits of GIS in education seem focused on developing spatial thinking, but there is not enough bibliography or statistical data to show the concrete scope of the use of GIS in education around the world, although the expansion has been faster in those countries where the curriculum mentions them.

GIS seem to provide many advantages in teaching geography because they allow for analyses based on real geographic data and also help raise many research questions from teachers and students in classrooms, as well as they contribute to improvement in learning by developing spatial and geographical thinking and, in many cases, student motivation.

GIS is proven as an organization-wide, enterprise and enduring technology that continues to change how local government operates. Government agencies have adopted GIS technology as a method to better manage the following areas of government organization:
The Open Data initiative is pushing local government to take advantage of technology such as GIS technology, as it encompasses the requirements to fit the Open Data/Open Government model of transparency. With Open Data, local government organizations can implement Citizen Engagement applications and online portals, allowing citizens to see land information, report potholes and signage issues, view and sort parks by assets, view real-time crime rates and utility repairs, and much more. The push for open data within government organizations is driving the growth in local government GIS technology spending, and database management.




</doc>
<doc id="12401" url="https://en.wikipedia.org/wiki?curid=12401" title="Graph theory">
Graph theory

In mathematics, graph theory is the study of "graphs", which are mathematical structures used to model pairwise relations between objects. A graph in this context is made up of "vertices" (also called "nodes" or "points") which are connected by "edges" (also called "links" or "lines"). A distinction is made between undirected graphs, where edges link two vertices symmetrically, and directed graphs, where edges link two vertices asymmetrically; see Graph (discrete mathematics) for more detailed definitions and for other variations in the types of graph that are commonly considered. Graphs are one of the prime objects of study in discrete mathematics.

Refer to the glossary of graph theory for basic definitions in graph theory.

Definitions in graph theory vary. The following are some of the more basic ways of defining graphs and related mathematical structures.

In one restricted but very common sense of the term, a graph is an ordered pair formula_1 comprising:

To avoid ambiguity, this type of object may be called precisely an undirected simple graph.

In the edge formula_4, the vertices formula_5 and formula_6 are called the "endpoints" of the edge. The edge is said to "join" formula_5 and formula_6 and to be "incident" on formula_5 and on formula_6. A vertex may exist in a graph and not belong to an edge. "Multiple edges", not allowed under the definition above, are two or more edges that join the same two vertices.

In one more general sense of the term allowing multiple edges, a graph is an ordered triple formula_11 comprising:

To avoid ambiguity, this type of object may be called precisely an undirected multigraph.

A "loop" is an edge that joins a vertex to itself. Graphs as defined in the two definitions above cannot have loops, because a loop joining a vertex formula_5 to itself is the edge (for an undirected simple graph) or is incident on (for an undirected multigraph) formula_16 which is not in formula_17. So to allow loops the definitions must be expanded. For undirected simple graphs, the definition of formula_13 should be modified to formula_19. For undirected multigraphs, the definition of formula_20 should be modified to formula_21. To avoid ambiguity, these types of objects may be called undirected simple graph permitting loops and undirected multigraph permitting loops, respectively.

formula_2 and formula_13 are usually taken to be finite, and many of the well-known results are not true (or are rather different) for "infinite graphs" because many of the arguments fail in the infinite case. Moreover, formula_2 is often assumed to be non-empty, but formula_13 is allowed to be the empty set. The "order" of a graph is formula_26, its number of vertices. The "size" of a graph is formula_27, its number of edges. The "degree" or "valency" of a vertex is the number of edges that are incident to it, where a loop is counted twice.

In an undirected simple graph of order "n", the maximum degree of each vertex is and the maximum size of the graph is .

The edges of an undirected simple graph permitting loops formula_28 induce a symmetric homogeneous relation ~ on the vertices of formula_28 that is called the "adjacency relation" of formula_28. Specifically, for each edge formula_31, its endpoints formula_5 and formula_6 are said to be "adjacent" to one another, which is denoted formula_5 ~ formula_6.

A directed graph or digraph is a graph in which edges have orientations.

In one restricted but very common sense of the term, a directed graph is an ordered pair formula_1 comprising:

To avoid ambiguity, this type of object may be called precisely a directed simple graph.

In the edge formula_39 directed from formula_5 to formula_6, the vertices formula_5 and formula_6 are called the "endpoints" of the edge, formula_5 the "tail" of the edge and formula_6 the "head" of the edge. The edge is said to "join" formula_5 and formula_6 and to be "incident" on formula_5 and on formula_6. A vertex may exist in a graph and not belong to an edge. The edge formula_50 is called the "inverted edge" of formula_39. "Multiple edges", not allowed under the definition above, are two or more edges with both the same tail and the same head.

In one more general sense of the term allowing multiple edges, a directed graph is an ordered triple formula_11 comprising:

To avoid ambiguity, this type of object may be called precisely a directed multigraph.

A "loop" is an edge that joins a vertex to itself. Directed graphs as defined in the two definitions above cannot have loops, because a loop joining a vertex formula_5 to itself is the edge (for a directed simple graph) or is incident on (for a directed multigraph) formula_57 which is not in formula_58. So to allow loops the definitions must be expanded. For directed simple graphs, the definition of formula_13 should be modified to formula_60. For directed multigraphs, the definition of formula_20 should be modified to formula_62. To avoid ambiguity, these types of objects may be called precisely a directed simple graph permitting loops and a directed multigraph permitting loops (or a "quiver") respectively.

The edges of a directed simple graph permitting loops formula_28 is a homogeneous relation ~ on the vertices of formula_28 that is called the "adjacency relation" of formula_28. Specifically, for each edge formula_31, its endpoints formula_5 and formula_6 are said to be "adjacent" to one another, which is denoted formula_5 ~ formula_6.

Graphs can be used to model many types of relations and processes in physical, biological, social and information systems. Many practical problems can be represented by graphs. Emphasizing their application to real-world systems, the term "network" is sometimes defined to mean a graph in which attributes (e.g. names) are associated with the vertices and edges, and the subject that expresses and understands the real-world systems as a network is called network science.

In computer science, graphs are used to represent networks of communication, data organization, computational devices, the flow of computation, etc. For instance, the link structure of a website can be represented by a directed graph, in which the vertices represent web pages and directed edges represent links from one page to another. A similar approach can be taken to problems in social media, travel, biology, computer chip design, mapping the progression of neuro-degenerative diseases, and many other fields. The development of algorithms to handle graphs is therefore of major interest in computer science. The transformation of graphs is often formalized and represented by graph rewrite systems. Complementary to graph transformation systems focusing on rule-based in-memory manipulation of graphs are graph databases geared towards transaction-safe, persistent storing and querying of graph-structured data.

Graph-theoretic methods, in various forms, have proven particularly useful in linguistics, since natural language often lends itself well to discrete structure. Traditionally, syntax and compositional semantics follow tree-based structures, whose expressive power lies in the principle of compositionality, modeled in a hierarchical graph. More contemporary approaches such as head-driven phrase structure grammar model the syntax of natural language using typed feature structures, which are directed acyclic graphs. 
Within lexical semantics, especially as applied to computers, modeling word meaning is easier when a given word is understood in terms of related words; semantic networks are therefore important in computational linguistics. Still, other methods in phonology (e.g. optimality theory, which uses lattice graphs) and morphology (e.g. finite-state morphology, using finite-state transducers) are common in the analysis of language as a graph. Indeed, the usefulness of this area of mathematics to linguistics has borne organizations such as TextGraphs, as well as various 'Net' projects, such as WordNet, VerbNet, and others.

Graph theory is also used to study molecules in chemistry and physics. In condensed matter physics, the three-dimensional structure of complicated simulated atomic structures can be studied quantitatively by gathering statistics on graph-theoretic properties related to the topology of the atoms. Also, "the Feynman graphs and rules of calculation summarize quantum field theory in a form in close contact with the experimental numbers one wants to understand." In chemistry a graph makes a natural model for a molecule, where vertices represent atoms and edges bonds. This approach is especially used in computer processing of molecular structures, ranging from chemical editors to database searching. In statistical physics, graphs can represent local connections between interacting parts of a system, as well as the dynamics of a physical process on such
systems. Similarly, in computational neuroscience graphs can be used to represent functional connections between brain areas that interact to give rise to various cognitive processes, where the vertices represent different areas of the brain and the edges represent the connections between those areas. Graph theory plays an important role in electrical modeling of electrical networks, here, weights are associated with resistance of the wire segments to obtain electrical properties of network structures. Graphs are also used to represent the micro-scale channels of porous media, in which the vertices represent the pores and the edges represent the smaller channels connecting the pores. Chemical graph theory uses the molecular graph as a means to model molecules.
Graphs and networks are excellent models to study and understand phase transitions and critical phenomena.
Removal of nodes or edges lead to a critical transition where the network breaks into small clusters which is studied as a phase transition. This breakdown is studied via percolation theory.

Graph theory is also widely used in sociology as a way, for example, to measure actors' prestige or to explore rumor spreading, notably through the use of social network analysis software. Under the umbrella of social networks are many different types of graphs. Acquaintanceship and friendship graphs describe whether people know each other. Influence graphs model whether certain people can influence the behavior of others. Finally, collaboration graphs model whether two people work together in a particular way, such as acting in a movie together.

Likewise, graph theory is useful in biology and conservation efforts where a vertex can represent regions where certain species exist (or inhabit) and the edges represent migration paths or movement between the regions. This information is important when looking at breeding patterns or tracking the spread of disease, parasites or how changes to the movement can affect other species.

Graphs are also commonly used in molecular biology and genomics to model and analyse datasets with complex relationships. For example, graph-based methods are often used to 'cluster' cells together into cell-types in single-cell transcriptome analysis. Another use is to model genes or proteins in a pathway and study the relationships between them, such as metabolic pathways and gene regulatory networks . Evolutionary trees, ecological networks, and hierarchical clustering of gene expression patterns are also represented as graph structures. Graph-based methods are pervasive that researchers in some fields of biology and these will only become far more widespread as technology develops to leverage this kind of high-throughout multidimensional data.

Graph theory is also used in connectomics; nervous systems can be seen as a graph, where the nodes are neurons and the edges are the connections between them.

In mathematics, graphs are useful in geometry and certain parts of topology such as knot theory. Algebraic graph theory has close links with group theory. Algebraic graph theory has been applied to many areas including dynamic systems and complexity.

A graph structure can be extended by assigning a weight to each edge of the graph. Graphs with weights, or weighted graphs, are used to represent structures in which pairwise connections have some numerical values. For example, if a graph represents a road network, the weights could represent the length of each road. There may be several weights associated with each edge, including distance (as in the previous example), travel time, or monetary cost. Such weighted graphs are commonly used to program GPS's, and travel-planning search engines that compare flight times and costs.

The paper written by Leonhard Euler on the Seven Bridges of Königsberg and published in 1736 is regarded as the first paper in the history of graph theory. This paper, as well as the one written by Vandermonde on the "knight problem," carried on with the "analysis situs" initiated by Leibniz. Euler's formula relating the number of edges, vertices, and faces of a convex polyhedron was studied and generalized by Cauchy and L'Huilier, and represents the beginning of the branch of mathematics known as topology.

More than one century after Euler's paper on the bridges of Königsberg and while Listing was introducing the concept of topology, Cayley was led by an interest in particular analytical forms arising from differential calculus to study a particular class of graphs, the "trees". This study had many implications for theoretical chemistry. The techniques he used mainly concern the enumeration of graphs with particular properties. Enumerative graph theory then arose from the results of Cayley and the fundamental results published by Pólya between 1935 and 1937. These were generalized by De Bruijn in 1959. Cayley linked his results on trees with contemporary studies of chemical composition. The fusion of ideas from mathematics with those from chemistry began what has become part of the standard terminology of graph theory.

In particular, the term "graph" was introduced by Sylvester in a paper published in 1878 in "Nature", where he draws an analogy between "quantic invariants" and "co-variants" of algebra and molecular diagrams:

The first textbook on graph theory was written by Dénes Kőnig, and published in 1936. Another book by Frank Harary, published in 1969, was "considered the world over to be the definitive textbook on the subject", and enabled mathematicians, chemists, electrical engineers and social scientists to talk to each other. Harary donated all of the royalties to fund the Pólya Prize.

One of the most famous and stimulating problems in graph theory is the four color problem: "Is it true that any map drawn in the plane may have its regions colored with four colors, in such a way that any two regions having a common border have different colors?" This problem was first posed by Francis Guthrie in 1852 and its first written record is in a letter of De Morgan addressed to Hamilton the same year. Many incorrect proofs have been proposed, including those by Cayley, Kempe, and others. The study and the generalization of this problem by Tait, Heawood, Ramsey and Hadwiger led to the study of the colorings of the graphs embedded on surfaces with arbitrary genus. Tait's reformulation generated a new class of problems, the "factorization problems", particularly studied by Petersen and Kőnig. The works of Ramsey on colorations and more specially the results obtained by Turán in 1941 was at the origin of another branch of graph theory, "extremal graph theory".

The four color problem remained unsolved for more than a century. In 1969 Heinrich Heesch published a method for solving the problem using computers. A computer-aided proof produced in 1976 by Kenneth Appel and Wolfgang Haken makes fundamental use of the notion of "discharging" developed by Heesch. The proof involved checking the properties of 1,936 configurations by computer, and was not fully accepted at the time due to its complexity. A simpler proof considering only 633 configurations was given twenty years later by Robertson, Seymour, Sanders and Thomas.

The autonomous development of topology from 1860 and 1930 fertilized graph theory back through the works of Jordan, Kuratowski and Whitney. Another important factor of common development of graph theory and topology came from the use of the techniques of modern algebra. The first example of such a use comes from the work of the physicist Gustav Kirchhoff, who published in 1845 his Kirchhoff's circuit laws for calculating the voltage and current in electric circuits.

The introduction of probabilistic methods in graph theory, especially in the study of Erdős and Rényi of the asymptotic probability of graph connectivity, gave rise to yet another branch, known as "random graph theory", which has been a fruitful source of graph-theoretic results.

Graphs are represented visually by drawing a point or circle for every vertex, and drawing a line between two vertices if they are connected by an edge. If the graph is directed, the direction is indicated by drawing an arrow.

A graph drawing should not be confused with the graph itself (the abstract, non-visual structure) as there are several ways to structure the graph drawing. All that matters is which vertices are connected to which others by how many edges and not the exact layout. In practice, it is often difficult to decide if two drawings represent the same graph. Depending on the problem domain some layouts may be better suited and easier to understand than others.

The pioneering work of W. T. Tutte was very influential on the subject of graph drawing. Among other achievements, he introduced the use of linear algebraic methods to obtain graph drawings.

Graph drawing also can be said to encompass problems that deal with the crossing number and its various generalizations. The crossing number of a graph is the minimum number of intersections between edges that a drawing of the graph in the plane must contain. For a planar graph, the crossing number is zero by definition.

Drawings on surfaces other than the plane are also studied.

There are different ways to store graphs in a computer system. The data structure used depends on both the graph structure and the algorithm used for manipulating the graph. Theoretically one can distinguish between list and matrix structures but in concrete applications the best structure is often a combination of both. List structures are often preferred for sparse graphs as they have smaller memory requirements. Matrix structures on the other hand provide faster access for some applications but can consume huge amounts of memory. Implementations of sparse matrix structures that are efficient on modern parallel computer architectures are an object of current investigation.

List structures include the incidence list, an array of pairs of vertices, and the adjacency list, which separately lists the neighbors of each vertex: Much like the incidence list, each vertex has a list of which vertices it is adjacent to.

Matrix structures include the incidence matrix, a matrix of 0's and 1's whose rows represent vertices and whose columns represent edges, and the adjacency matrix, in which both the rows and columns are indexed by vertices. In both cases a 1 indicates two adjacent objects and a 0 indicates two non-adjacent objects. The degree matrix indicates the degree of vertices. The Laplacian matrix is a modified form of the adjacency matrix that incorporates information about the degrees of the vertices, and is useful in some calculations such as Kirchhoff's theorem on the number of spanning trees of a graph.
The distance matrix, like the adjacency matrix, has both its rows and columns indexed by vertices, but rather than containing a 0 or a 1 in each cell it contains the length of a shortest path between two vertices.

There is a large literature on graphical enumeration: the problem of counting graphs meeting specified conditions. Some of this work is found in Harary and Palmer (1973).

A common problem, called the subgraph isomorphism problem, is finding a fixed graph as a subgraph in a given graph. One reason to be interested in such a question is that many graph properties are "hereditary" for subgraphs, which means that a graph has the property if and only if all subgraphs have it too.
Unfortunately, finding maximal subgraphs of a certain kind is often an NP-complete problem. For example:

One special case of subgraph isomorphism is the graph isomorphism problem. It asks whether two graphs are isomorphic. It is not known whether this problem is NP-complete, nor whether it can be solved in polynomial time.

A similar problem is finding induced subgraphs in a given graph. Again, some important graph properties are hereditary with respect to induced subgraphs, which means that a graph has a property if and only if all induced subgraphs also have it. Finding maximal induced subgraphs of a certain kind is also often NP-complete. For example:

Still another such problem, the minor containment problem, is to find a fixed graph as a minor of a given graph. A minor or subcontraction of a graph is any graph obtained by taking a subgraph and contracting some (or no) edges. Many graph properties are hereditary for minors, which means that a graph has a property if and only if all minors have it too. For example, Wagner's Theorem states: 

A similar problem, the subdivision containment problem, is to find a fixed graph as a subdivision of a given graph. A subdivision or homeomorphism of a graph is any graph obtained by subdividing some (or no) edges. Subdivision containment is related to graph properties such as planarity. For example, Kuratowski's Theorem states: 

Another problem in subdivision containment is the Kelmans–Seymour conjecture:
Another class of problems has to do with the extent to which various species and generalizations of graphs are determined by their "point-deleted subgraphs". For example:

Many problems and theorems in graph theory have to do with various ways of coloring graphs. Typically, one is interested in coloring a graph so that no two adjacent vertices have the same color, or with other similar restrictions. One may also consider coloring edges (possibly so that no two coincident edges are the same color), or other variations. Among the famous results and conjectures concerning graph coloring are the following:

Constraint modeling theories concern families of directed graphs related by a partial order. In these applications, graphs are ordered by specificity, meaning that more constrained graphs—which are more specific and thus contain a greater amount of information—are subsumed by those that are more general. Operations between graphs include evaluating the direction of a subsumption relationship between two graphs, if any, and computing graph unification. The unification of two argument graphs is defined as the most general graph (or the computation thereof) that is consistent with (i.e. contains all of the information in) the inputs, if such a graph exists; efficient unification algorithms are known.

For constraint frameworks which are strictly compositional, graph unification is the sufficient satisfiability and combination function. Well-known applications include automatic theorem proving and modeling the elaboration of linguistic structure.


There are numerous problems arising especially from applications that have to do with various notions of flows in networks, for example:


Covering problems in graphs may refer to various set cover problems on subsets of vertices/subgraphs.

Decomposition, defined as partitioning the edge set of a graph (with as many vertices as necessary accompanying the edges of each part of the partition), has a wide variety of question. Often, it is required to decompose a graph into subgraphs isomorphic to a fixed graph; for instance, decomposing a complete graph into Hamiltonian cycles. Other problems specify a family of graphs into which a given graph should be decomposed, for instance, a family of cycles, or decomposing a complete graph "K" into specified trees having, respectively, 1, 2, 3, ..., edges.

Some specific decomposition problems that have been studied include:

Many problems involve characterizing the members of various classes of graphs. Some examples of such questions are below:











</doc>
<doc id="12405" url="https://en.wikipedia.org/wiki?curid=12405" title="Gumby">
Gumby

Gumby is an American clay animation franchise, centered on the titular green clay humanoid character created and modeled by Art Clokey. The character has been the subject of two television series, a feature-length film and other media. Since the original series aired, Gumby has become a famous example of stop-motion clay animation and an influential cultural icon, spawning tributes, parodies and merchandising.

"Gumby" follows the titular character on his adventures through different environments and times in history. Gumby's primary sidekick is Pokey, a talking red pony. His nemeses are the G and J Blockheads, a pair of antagonistic red humanoid figures with cube-shaped heads, one with the letter G on the block, the other with the letter J. The blockheads were inspired by the trouble-making Katzenjammer Kids. Other characters include Prickle, a yellow dinosaur capable of breathing fire and who sometimes styles himself as a detective with pipe and deerstalker hat like Sherlock Holmes; Goo, a flying blue mermaid who spits blue goo balls and can change shape into essentially any object (including machinery) at will; Gumbo and Gumba, Gumby's parents; and Nopey, Gumby's dog whose entire vocabulary is the word "nope". The 1988 syndicated series added Gumby's sister Minga, mastodon friend Denali and chicken friend Tilly.

Gumby was created by Art Clokey in the early 1950s after he finished film school at the University of Southern California (USC).

Clokey's first animated film was a 1953 three-minute student film called "Gumbasia", a surreal montage of moving and expanding lumps of clay set to music in a parody of Disney's "Fantasia". "Gumbasia" was created in the "kinesthetic" style taught by Clokey's USC professor Slavko Vorkapić, described as "massaging of the eye cells." Much of Gumby's look and feel was inspired by this technique of camera movements and editing.

In 1955, Clokey showed "Gumbasia" to movie producer Sam Engel, who encouraged him to develop his technique by animating figures into children's stories. Clokey moved forward, producing a pilot episode featuring the character Gumby.

The name "Gumby" came from the muddy clay found at Clokey's grandparents' farm that his family called "gumbo". Gumby's appearance was inspired by a suggestion from his wife, Ruth (née Parkander), that Gumby be based on the Gingerbread Man. The color green was then chosen because Clokey saw it as both racially neutral and a symbol of life. Gumby's legs and feet were made wide for pragmatic reasons; they ensured that the character would stand up during stop-motion filming. Gumby's famous slanted head was based on the hairstyle of Clokey's father, Charles Farrington, in an old photograph.

Clokey's pilot episode was seen by NBC executive Thomas Warren Sarnoff, who asked Clokey to make another one. The second episode, "Gumby on the Moon", became a huge hit on "Howdy Doody", leading Sarnoff to order a series in 1955 entitled "The Gumby Show". In 1955 and 1956, 25 eleven-minute episodes aired on NBC. In early episodes, Gumby's voice was provided by Ruth Eggleston, wife of the show's art director Al Eggleston, until Dallas McKennon assumed her role in 1962. Gumby's best friend, an orange pony named Pokey, was introduced during the earliest episodes. Because of its variety-type format, "The Gumby Show" featured not only Clokey's puppet films, but also interviews and games. During this time, the show went through a succession of two hosts, Robert Nicholson and Pinky Lee.

In 1959, "The Gumby Show" entered syndication, and more episodes were produced in the 1960s. Production started in Hollywood and in 1960 moved to a larger studio in Glendora, California, where it remained until production ended in 1969. During this time, Gumby was primarily voiced by Norma MacMillan, and occasionally by Ginny Tyler. The cartoon shorts introduced new characters including a blue mermaid named Goo and a yellow dinosaur named Prickle.

Beginning in 1982, Gumby was parodied by Eddie Murphy on "Saturday Night Live". According to Murphy's parody, when the television cameras were turned off, the sweet Gumby reverted to his true self: an irascible, cigar-chomping celebrity who was highly demanding of the production executives. Whenever the executives refused to give in to his demands, Gumby would assert his star status by saying “I’m "Gumby", dammit!" in an exaggerated Jewish accent.

In 1987, the original Gumby shorts enjoyed a revival on home video. The following year, Gumby appeared in "The Puppetoon Movie".

This renewed interest led to a reincarnation of the series consisting of 99 new seven-minute episodes produced for television syndication in association with Lorimar-Telepictures in 1987. Dallas McKennon returned to voice Gumby in the new adventures, in which Gumby and his pals traveled beyond their toyland-type setting and established themselves as a musical band. "Gumby Adventures" also included new characters, such as Gumby's little sister Minga, a mastodon named Denali and a chicken named Tilly.

In addition to the new episodes, the 1950s and 1960s shorts were included in the series, but with new audio. The voices were re-recorded and the original music was replaced by Jerry Gerber's synthesizer score from the 1987 series. Legal issues prevented Clokey from renewing rights to the original Capitol Records production tracks.

Starting in 1992, TV channels such as Nickelodeon and Cartoon Network aired reruns of "Gumby" episodes. In 1995, Clokey's production company produced an independently released theatrical film, "", marking the character's first feature-length adventure, with John R. Dilworth, creator of "Courage the Cowardly Dog", as the film's animation consultant. In it, the villainous Blockheads replace Gumby and his band with robots and kidnap their dog, Lowbelly. The movie featured in-joke homages to science-fiction films such as "Star Wars", "The Terminator", and "". In 1998, the "Gumby" episode "Robot Rumpus" was featured on "Mystery Science Theater 3000".

On March 16, 2007, YouTube announced that all Gumby episodes would appear in their full-length form on its site, digitally remastered and with their original soundtracks. This deal also extended to other video sites, including AOL. In March 2007, KQED-TV broadcast an hour-long documentary "Gumby Dharma" as part of its "Truly CA" series. In addition to detailing Clokey's life and work, the film also featured new animation of Gumby and Pokey. For these sequences, animator Stephen A. Buckley provided Gumby's voice while Clokey reprised his role as Pokey.

In 2012, Me-TV began airing "Gumby" on weekend morning, in its weekend morning animation block. The show remained part of the channel's programming until the end of the year.


Several sources say that Dick Beals voiced Gumby in the 1960s; however, Beals refuted this claim in a 2001 interview.

In 1993, "TV Guide" named "Gumby" the best cartoon series of the 1950s in its issue celebrating 40 years of television.

Beginning in 1994, the Library of Congress used Gumby as a "spokescharacter" for "Adventures into Books: Gumby's World", a traveling exhibition that promoted the Center for the Book's national reading campaign from 1997 to 2000. By the end of the 1990s, Gumby and Pokey had also appeared in various commercials for Cheerios cereal, most notably Frosted Cheerios.

"Gumby" was also parodied in a few claymation sketches on Mad TV.

In 2005, "Gumby" made a cameo in a couch gag from the 358th episode of the animated sitcom "The Simpsons".

On August 4, 2006, the Center for Puppetry Arts in Atlanta opened "Art Clokey's Gumby: The First Fifty Years". This exhibition featured many of the original puppets and sets, along with screening of Art Clokey's films. This event was conceived by David Scheve of T.D.A. Animation and Joe Clokey of Premavision, and was one of several exhibits that opened around the country, celebrating the 50th anniversary of "The Gumby Show". The children's book "Gumby Goes to the Sun" was also published that year to commemorate the anniversary. The book was originally created in the 1980s by Clokey's daughter, Holly Harman (who voiced Gumby's sister, Minga in the 1980s incarnation).

In 2007, the "Gumby" comic book series was nominated for two Eisner Awards, Best New Series and Best Publication for a Young Audience, and won the latter.

On October 12, 2011, Google paid tribute to Art Clokey's 90th birthday with a doodle featuring clay balls transforming into characters from the show. The doodle was composed of a toy block with a "G" and five clay balls in the Google colors. Clicking each of the balls revealed the Blockheads, Prickle, Goo, Gumby and Pokey.

In a 2014 episode of Disney XD's "Gravity Falls" called "Little Gift Shop of Horrors", the character of Soos Ramirez appears in the "Clay Day" segment resembling Gumby.

Various Gumby merchandise has been produced over the years, the most prominent item being bendable figures by Lakeside Toys, headquartered in Minneapolis, Minnesota. Several single packs and multi-figure sets by Jesco (later Trendmasters), as well as a 50th anniversary collection, have been made of the Gumby characters. Also included in the Gumby merchandise catalog are plush dolls, keychains, mugs, a 1988 Colorforms set, a 1995 Trendmasters playset and a Kubricks set by Medicom. A tribute album, "Gumby: The Green Album", produced by Shepard Stern, was released in 1989 through Buena Vista Records.

In August 2005, the first video game featuring Gumby, "Gumby vs. the Astrobots", was released by Namco for the Nintendo Game Boy Advance. In it, Gumby must rescue Pokey, Prickle and Goo after they are captured by the Blockheads and their cohorts, the Astrobots.

The Gumby images and toys are registered trademarks of Prema Toy Company. Premavision owned the distribution rights to the "Gumby" cartoons, having been reverted from previous distributor Warner Bros. Television in 2003, and had licensed the rights to Classic Media until September 30, 2012. At this time, Classic Media was officially acquired by DreamWorks Animation and branded as DreamWorks Classics, which became a subsidiary of NBCUniversal in 2016. As of April 2015, NCircle Entertainment owns home video and digital distribution rights to the cartoons.




</doc>
<doc id="12406" url="https://en.wikipedia.org/wiki?curid=12406" title="Gioachino Rossini">
Gioachino Rossini

Gioachino Antonio Rossini (29 February 1792 – 13 November 1868) was an Italian composer who gained fame for his 39 operas, although he also wrote many songs, some chamber music and piano pieces, and some sacred music. He set new standards for both comic and serious opera before retiring from large-scale composition while still in his thirties, at the height of his popularity.

Born in Pesaro to parents who were both musicians (his father a trumpeter, his mother a singer), Rossini began to compose by the age of 12 and was educated at music school in Bologna. His first opera was performed in Venice in 1810 when he was 18 years old. In 1815 he was engaged to write operas and manage theatres in Naples. In the period 1810–1823 he wrote 34 operas for the Italian stage that were performed in Venice, Milan, Ferrara, Naples and elsewhere; this productivity necessitated an almost formulaic approach for some components (such as overtures) and a certain amount of self-borrowing. During this period he produced his most popular works including the comic operas "L'italiana in Algeri", "Il barbiere di Siviglia" (known in English as "The Barber of Seville") and "La Cenerentola", which brought to a peak the "opera buffa" tradition he inherited from masters such as Domenico Cimarosa and Giovanni Paisiello. He also composed "opera seria" works such as "Otello", "Tancredi" and "Semiramide". All of these attracted admiration for their innovation in melody, harmonic and instrumental colour, and dramatic form. In 1824 he was contracted by the Opéra in Paris, for which he produced an opera to celebrate the coronation of Charles X, "Il viaggio a Reims" (later cannibalised for his first opera in French, "Le comte Ory"), revisions of two of his Italian operas, "Le siège de Corinthe" and "Moïse", and in 1829 his last opera, "Guillaume Tell".

Rossini's withdrawal from opera for the last 40 years of his life has never been fully explained; contributary factors may have been ill-health, the wealth his success had brought him, and the rise of spectacular grand opera under composers such as Giacomo Meyerbeer. From the early 1830s to 1855, when he left Paris and was based in Bologna, Rossini wrote relatively little. On his return to Paris in 1855 he became renowned for his musical salons on Saturdays, regularly attended by musicians and the artistic and fashionable circles of Paris, for which he wrote the entertaining pieces "Péchés de vieillesse." Guests included Franz Liszt, Anton Rubinstein, Giuseppe Verdi, Meyerbeer and Joseph Joachim. Rossini's last major composition was his "Petite messe solennelle" (1863). He died in Paris in 1868.

Rossini was born in 1792 in Pesaro, a town on the Adriatic coast of Italy that was then part of the Papal States. He was the only child of Giuseppe Rossini, a trumpeter and horn player, and his wife Anna, "née" Guidarini, a seamstress by trade, daughter of a baker. Giuseppe Rossini was charming but impetuous and feckless; the burden of supporting the family and raising the child fell mainly on Anna, with some help from her mother and mother-in-law. Stendhal, who published a colourful biography of Rossini in 1824, wrote:

Giuseppe was imprisoned at least twice: first in 1790 for insubordination to local authorities in a dispute about his employment as town trumpeter; and in 1799 and 1800 for republican activism and support of the troops of Napoleon against the Pope's Austrian backers. In 1798, when Rossini was aged six, his mother began a career as a professional singer in comic opera, and for a little over a decade was a considerable success in cities including Trieste and Bologna, before her untrained voice began to fail.

In 1802 the family moved to Lugo, near Ravenna, where Rossini received a good basic education in Italian, Latin and arithmetic as well as music. He studied the horn with his father and other music with a priest, Giuseppe Malerbe, whose extensive library contained works by Haydn and Mozart, both little known in Italy at the time, but inspirational to the young Rossini. He was a quick learner, and by the age of twelve he had composed a set of six sonatas for four stringed instruments, which were performed under the aegis of a rich patron in 1804. Two years later he was admitted to the recently opened Liceo Musicale, Bologna, initially studying singing, cello and piano, and joining the composition class soon afterwards. He wrote some substantial works while a student, including a mass and a cantata, and after two years he was invited to continue his studies. He declined the offer: the strict academic regime of the Liceo had given him a solid compositional technique, but as his biographer Richard Osborne puts it, "his instinct to continue his education in the real world finally asserted itself".

While still at the Liceo, Rossini had performed in public as a singer and worked in theatres as a répétiteur and keyboard soloist. In 1810 at the request of the popular tenor Domenico Mombelli he wrote his first operatic score, a two-act operatic "dramma serio", "Demetrio e Polibio", to a libretto by Mombelli's wife. It was publicly staged in 1812, after the composer's first successes. Rossini and his parents concluded that his future lay in composing operas. The main operatic centre in north eastern Italy was Venice; under the tutelage of the composer Giovanni Morandi, a family friend, Rossini moved there in late 1810, when he was eighteen.

Rossini's first opera to be staged was "La cambiale di matrimonio", a one-act comedy, given at the small Teatro San Moisè in November 1810. The piece was a great success, and Rossini received what then seemed to him a considerable sum: "forty "scudi" – an amount I had never seen brought together". He later described the San Moisè as an ideal theatre for a young composer learning his craft – "everything tended to facilitate the début of a novice composer": it had no chorus, and a small company of principals; its main repertoire consisted of one-act comic operas ("farse"), staged with modest scenery and minimal rehearsal. Rossini followed the success of his first piece with three more "farse" for the house: "L'inganno felice" (1812), "La scala di seta" (1812), and "Il signor Bruschino" (1813).

Rossini maintained his links with Bologna, where in 1811 he had a success directing Haydn's "The Seasons", and a failure with his first full-length opera, "L'equivoco stravagante". He also worked for opera houses in Ferrara and Rome. In mid-1812 he received a commission from La Scala, Milan, where his two-act comedy "La pietra del paragone" ran for fifty-three performances, a considerable run for the time, which brought him not only financial benefits, but exemption from military service and the title of "maestro di cartello" – a composer whose name on advertising posters guaranteed a full house. The following year his first "opera seria", "Tancredi", did well at La Fenice in Venice, and even better at Ferrara, with a rewritten, tragic ending. The success of "Tancredi" made Rossini's name known internationally; productions of the opera followed in London (1820) and New York (1825). Within weeks of "Tancredi", Rossini had another box-office success with his comedy "L'italiana in Algeri", composed in great haste and premiered in May 1813.

1814 was a less remarkable year for the rising composer, neither "Il turco in Italia" or "Sigismondo" pleasing the Milanese or Venetian public, respectively. 1815 marked an important stage in Rossini's career. In May he moved to Naples, to take up the post of director of music for the royal theatres. These included the Teatro di San Carlo, the city's leading opera house; its manager Domenico Barbaia was to be an important influence on the composer's career there.

The musical establishment of Naples was not immediately welcoming to Rossini, who was seen as an intruder into its cherished operatic traditions. The city had once been the operatic capital of Europe; the memory of Cimarosa was revered and Paisiello was still living, but there were no local composers of any stature to follow them, and Rossini quickly won the public and critics round. Rossini's first work for the San Carlo, "Elisabetta, regina d'Inghilterra" was a dramma per musica in two acts, in which he reused substantial sections of his earlier works, unfamiliar to the local public. The Rossini scholars Philip Gossett and Patricia Brauner write, "It is as if Rossini wished to present himself to the Neapolitan public by offering a selection of the best music from operas unlikely to be revived in Naples." The new opera was received with tremendous enthusiasm, as was the Neapolitan premiere of "L'italiana in Algeri", and Rossini's position in Naples was assured.

For the first time, Rossini was able to write regularly for a resident company of first-rate singers and a fine orchestra, with adequate rehearsals, and schedules that made it unnecessary to compose in a rush to meet deadlines. Between 1815 and 1822 he composed eighteen more operas: nine for Naples and nine for opera houses in other cities. In 1816, for the Teatro Argentina in Rome, he composed the opera that was to become his best-known: "Il barbiere di Siviglia" ("The Barber of Seville"). There was already a popular opera of that title by Paisiello, and Rossini's version was originally given the same title as its hero, "Almaviva". Despite an unsuccessful opening night, with mishaps on stage and many pro-Paisiello and anti-Rossini audience members, the opera quickly became a success, and by the time of its first revival, in Bologna a few months later, it was billed by its present Italian title, and rapidly eclipsed Paisiello's setting.

Rossini's operas for the Teatro San Carlo were substantial, mainly serious pieces. His "Otello" (1816) provoked Lord Byron to write, "They have been crucifying "Othello" into an opera: music good, but lugubrious – but as for the words!" Nonetheless the piece proved generally popular, and held the stage in frequent revivals until it was overshadowed by Verdi's version, seven decades later. Among his other works for the house were "Mosè in Egitto", based on the biblical story of Moses and the Exodus from Egypt (1818), and "La donna del lago", from Sir Walter Scott's poem "The Lady of the Lake" (1819). For La Scala he wrote the opera semiseria "La gazza ladra" (1817), and for Rome his version of the Cinderella story, "La Cenerentola" (1817). In 1817 came the first performance of one of his operas ("L'Italiana") at the Theâtre-Italien in Paris; its success led to others of his operas being staged there, and eventually to his contract in Paris from 1824 to 1830.

Rossini kept his personal life as private as possible, but he was known for his susceptibility to singers in the companies he worked with. Among his lovers in his early years were Ester Mombelli (Domenico's daughter) and Maria Marcolini of the Bologna company. By far the most important of these relationships – both personal and professional – was with Isabella Colbran, prima donna of the Teatro San Carlo (and former mistress of Barbaia). Rossini had heard her sing in Bologna in 1807, and when he moved to Naples he wrote a succession of important roles for her in "opere serie".

By the early 1820s Rossini was beginning to tire of Naples. The failure of his operatic tragedy "Ermione" the previous year convinced him that he and the Neapolitan audiences had had enough of each other. An insurrection in Naples against the monarchy, though quickly crushed, unsettled Rossini; when Barbaia signed a contract to take the company to Vienna, Rossini was glad to join them, but did not reveal to Barbaia that he had no intention of returning to Naples afterwards. He travelled with Colbran, in March 1822, breaking their journey at Bologna, where they were married in the presence of his parents in a small church in Castenaso a few miles from the city. The bride was thirty-seven, the groom thirty.

In Vienna, Rossini received a hero's welcome; his biographers describe it as "unprecedentedly feverish enthusiasm", "Rossini fever", and "near hysteria". The authoritarian chancellor of the Austrian Empire, Metternich, liked Rossini's music, and thought it free of all potential revolutionary or republican associations. He was therefore happy to permit the San Carlo company to perform the composer's operas. In a three-month season they played six of them, to audiences so enthusiastic that Beethoven's assistant, Anton Schindler, described it as "an idolatrous orgy".

While in Vienna Rossini heard Beethoven's "Eroica" symphony, and was so moved that he determined to meet the reclusive composer. He finally managed to do so, and later described the encounter to many people, including Eduard Hanslick and Richard Wagner. He recalled that although conversation was hampered by Beethoven's deafness and Rossini's ignorance of German, Beethoven made it plain that he thought Rossini's talents were not for serious opera, and that "above all" he should "do more "Barbiere"" "(Barbers)".

After the Vienna season Rossini returned to Castenaso to work with his librettist, Gaetano Rossi, on "Semiramide", commissioned by La Fenice. It was premiered in February 1823, his last work for the Italian theatre. Colbran starred, but it was clear to everyone that her voice was in serious decline, and "Semiramide" ended her career in Italy. The work survived that one major disadvantage, and entered the international operatic repertory, remaining popular throughout the 19th century; in Richard Osborne's words, it brought "[Rossini's] Italian career to a spectacular close."

In November 1823 Rossini and Colbran set off for London, where a lucrative contract had been offered. They stopped for four weeks "en route" in Paris. Although he was not as feverishly acclaimed by the Parisians as he had been in Vienna, he nevertheless had an exceptionally welcoming reception from the musical establishment and the public. When he attended a performance of "Il barbiere" at the Théâtre-Italien he was applauded, dragged onto the stage, and serenaded by the musicians. A banquet was given for him and his wife, attended by leading French composers and artists, and he found the cultural climate of Paris congenial.

Once in England, Rossini was received and made much of by the king, George IV, although the composer was by now unimpressed by royalty and aristocracy. Rossini and Colbran had signed contracts for an opera season at the in the Haymarket. Her vocal shortcomings were a serious liability, and she reluctantly retired from performing. Public opinion was not improved by Rossini's failure to provide a new opera, as promised. The impresario, Vincenzo Benelli, defaulted on his contract with the composer, but this was not known to the London press and public, who blamed Rossini.

In a 2003 biography of the composer, Gaia Servadio comments that Rossini and England were not made for each other. He was prostrated by the Channel crossing, and was unlikely to be enthused by the English weather or English cooking. Although his stay in London was financially rewarding – the British press reported disapprovingly that he had earned over £30,000 – he was happy to sign a contract at the French embassy in London to return to Paris, where he had felt much more at home.

Rossini's new, and highly remunerative, contract with the French government was negotiated under Louis XVIII, who died in September 1824, soon after Rossini's arrival in Paris. It had been agreed that the composer would produce one grand opera for the Académie Royale de Musique and either an "opera buffa" or an "opera semiseria" for the Théâtre-Italien. He was also to help run the latter theatre and revise one of his earlier works for revival there. The death of the king and the accession of Charles X changed Rossini's plans, and his first new work for Paris was "Il viaggio a Reims", an operatic entertainment given in June 1825 to celebrate Charles's coronation. It was Rossini's last opera with an Italian libretto. He permitted only four performances of the piece, intending to reuse the best of the music in a less ephemeral opera. About half the score of "Le comte Ory" (1828) is from the earlier work.

Colbran's enforced retirement put a strain on the Rossinis' marriage, leaving her unoccupied while he continued to be the centre of musical attention and constantly in demand. She consoled herself with what Servadio describes as "a new pleasure in shopping"; for Rossini, Paris offered continual gourmet delights, as his increasingly rotund shape began to reflect.

The first of the four operas Rossini wrote to French librettos were "Le siège de Corinthe" (1826) and "Moïse et Pharaon" (1827). Both were substantial reworkings of pieces written for Naples: "Maometto II" and "Mosè in Egitto". Rossini took great care before beginning work on the first, learning to speak French and familiarising himself with traditional French operatic ways of declaiming the language. As well as dropping some of the original music that was in an ornate style unfashionable in Paris, Rossini accommodated local preferences by adding dances, hymn-like numbers and a greater role for the chorus.

Rossini's mother, Anna, died in 1827; he had been devoted to her, and he felt her loss deeply. She and Colbran had never got on well, and Servadio suggests that after Anna died Rossini came to resent the surviving woman in his life.

In 1828 Rossini wrote "Le comte Ory", his only French-language comic opera. His determination to reuse music from "Il viaggio a Reims" caused problems for his librettists, who had to adapt their original plot and write French words to fit existing Italian numbers, but the opera was a success, and was seen in London within six months of the Paris premiere, and in New York in 1831. The following year Rossini wrote his long-awaited French grand opera, "Guillaume Tell", based on Friedrich Schiller's 1804 play which drew on the William Tell legend.

"Guillaume Tell" was well received. The orchestra and singers gathered outside Rossini's house after the premiere and performed the rousing finale to the second act in his honour. The newspaper "Le Globe" commented that a new era of music had begun. Gaetano Donizetti remarked that the first and last acts of the opera were written by Rossini, but the middle act was written by God. The work was an undoubted success, without being a smash hit; the public took some time in getting to grips with it, and some singers found it too demanding. It nonetheless was produced abroad within months of the premiere, and there was no suspicion that it would be the composer's last opera.
Jointly with "Semiramide", "Guillaume Tell" is Rossini's longest opera, at three hours and forty-five minutes, and the effort of composing it left him exhausted. Although within a year he was planning an operatic treatment of the Faust story, events and ill health overtook him. After the opening of "Guillaume Tell" the Rossinis had left Paris and were staying in Castenaso. Within a year events in Paris had Rossini hurrying back. Charles X was overthrown in a revolution in July 1830, and the new administration, headed by Louis Philippe I, announced radical cutbacks in government spending. Among the cuts was Rossini's lifetime annuity, won after hard negotiation with the previous regime. Attempting to restore the annuity was one of Rossini's reasons for returning. The other was to be with his new mistress, Olympe Pélissier. He left Colbran in Castenaso; she never returned to Paris and they never lived together again.

The reasons for Rossini's withdrawal from opera have been continually discussed during and since his lifetime. Some have supposed that aged thirty-seven and in variable health, having negotiated a sizeable annuity from the French government, and having written thirty-nine operas, he simply planned to retire and kept to that plan. In a 1934 study of the composer, the critic Francis Toye coined the phrase "The Great Renunciation", and called Rossini's retirement a "phenomenon unique in the history of music and difficult to parallel in the whole history of art":

The poet Heine compared Rossini's retirement with Shakespeare's withdrawal from writing: two geniuses recognising when they had accomplished the unsurpassable and not seeking to follow it. Others, then and later, suggested that Rossini had retired because of pique at the successes of Giacomo Meyerbeer and Fromental Halévy in the genre of grand opéra. Modern Rossini scholarship has generally discounted such theories, maintaining that Rossini had no intention of renouncing operatic composition, and that circumstances rather than personal choice made "Guillaume Tell" his last opera. Gossett and Richard Osborne suggest that illness may have been a major factor in Rossini's retirement. From about this time, Rossini had intermittent bad health, both physical and mental. He had contracted gonorrhoea in earlier years, which later led to painful side-effects, from urethritis to arthritis; he suffered from bouts of debilitating depression, which commentators have linked to several possible causes: cyclothymia, or bipolar disorder, or reaction to his mother's death.

For the next twenty-five years following "Guillaume Tell" Rossini composed little, although Gossett comments that his comparatively few compositions from the 1830s and 1840s show no falling-off in musical inspiration. They include the "Soirées musicales" (1830–1835: a set of twelve songs for solo or duet voices and piano) and his Stabat Mater (begun in 1831 and completed in 1841). After winning his fight with the government over his annuity in 1835 Rossini left Paris and settled in Bologna. His return to Paris in 1843 for medical treatment by Jean Civiale sparked hopes that he might produce a new grand opera – it was rumoured that Eugène Scribe was preparing a libretto for him about Joan of Arc. The Opéra was moved to present a French version of "Otello" in 1844 which also included material from some of the composer's earlier operas. It is unclear to what extent – if at all – Rossini was involved with this production, which was in the event poorly received. More controversial was the "pasticcio" opera of "Robert Bruce" (1846), in which Rossini, by then returned to Bologna, closely cooperated by selecting music from his past operas which had not yet been performed in Paris, notably "La donna del lago." The Opéra sought to present "Robert" as a new Rossini opera. But although "Othello" could at least claim to be genuine, canonic, Rossini, the historian Mark Everist notes that detractors argued that "Robert" was simply "fake goods, and from a bygone era at that"; he cites Théophile Gautier regretting that "the lack of unity could have been masked by a superior performance; unfortunately the tradition of Rossini's music was lost at the Opéra a long time ago."

The period after 1835 saw Rossini's formal separation from his wife, who remained at Castenaso (1837), and the death of his father at the age of eighty (1839). In 1845 Colbran became seriously ill, and in September Rossini travelled to visit her; a month later she died. The following year Rossini and Pélissier were married in Bologna. The events of the Year of Revolution in 1848 led Rossini to move away from the Bologna area, where he felt threatened by insurrection, and to make Florence his base, which it remained until 1855.

By the early 1850s Rossini's mental and physical health had deteriorated to the point where his wife and friends feared for his sanity or his life. By the middle of the decade it was clear that he needed to return to Paris for the most advanced medical care then available. In April 1855 the Rossinis set off for their final journey from Italy to France. Rossini returned to Paris aged sixty-three and made it his home for the rest of his life.

Gossett observes that although an account of Rossini's life between 1830 and 1855 makes depressing reading, it is "no exaggeration to say that, in Paris, Rossini returned to life". He recovered his health and "joie de vivre". Once settled in Paris he maintained two homes: a flat in the rue de la Chaussée-d'Antin, a smart central area, and a neo-classical villa built for him in Passy, a commune now absorbed into the city, but then semi-rural. He and his wife established a salon that became internationally famous. The first of their Saturday evening gatherings – the "samedi soirs" – was held in December 1858, and the last, two months before he died in 1868.

Rossini began composing again. His music from his final decade was not generally intended for public performance, and he did not usually put dates of composition on the manuscripts. Consequently, musicologists have found it difficult to give definite dates for his late works, but the first, or among the first, was the song cycle "Musique anodine", dedicated to his wife and presented to her in April 1857. For their weekly salons he produced more than 150 pieces, including songs, solo piano pieces, and chamber works for many different combinations of instruments. He referred to them as his "Péchés de vieillesse" – "sins of old age". The salons were held both at Beau Séjour – the Passy villa – and, in the winter, at the Paris flat. Such gatherings were a regular feature of Parisian life – the writer James Penrose has observed that the well-connected could easily attend different salons almost every night of the week – but the Rossinis' "samedi soirs" quickly became the most sought after: "an invitation was the city's highest social prize." The music, carefully chosen by Rossini, was not only his own, but included works by Pergolesi, Haydn and Mozart and modern pieces by some of his guests. Among the composers who attended the salons, and sometimes performed, were Auber, Gounod, Liszt, Rubinstein, Meyerbeer and Verdi. Rossini liked to call himself a fourth-class pianist, but the many famous pianists who attended the "samedi soirs" were dazzled by his playing. Violinists such as Pablo Sarasate and Joseph Joachim, and the leading singers of the day were regular guests. In 1860, Wagner visited Rossini via an introduction from Rossini's friend Edmond Michotte who some forty-five years later wrote his account of the genial conversation between the two composers.

One of Rossini's few late works intended to be given in public was his "Petite messe solennelle", first performed in 1864. In the same year Rossini was made a grand officer of the Legion of Honour by Napoleon III.

After a short illness, and an unsuccessful operation to treat colorectal cancer, Rossini died at Passy on 13 November 1868 at the age of seventy-six. He left Olympe a life interest in his estate, which after her death, ten years later, passed to the Commune of Pesaro for the establishment of a Liceo Musicale, and funded a home for retired opera singers in Paris. After a funeral service attended by more than four thousand people at the church of Sainte-Trinité, Paris, Rossini's body was interred at the Père Lachaise Cemetery. In 1887 his remains were moved to the church of Santa Croce, Florence.

The writer Julian Budden, noting the formulas adopted early on by Rossini in his career and consistently followed by him thereafter as regards overtures, arias, structures and ensembles, has called them "the Code Rossini" in a reference to the Code Napoléon, the legal system established by the French Emperor. Rossini's overall style may indeed have been influenced more directly by the French: the historian John Rosselli suggests that French rule in Italy at the start of the 19th century meant that "music had taken on new military qualities of attack, noise and speed – to be heard in Rossini." Rossini's approach to opera was inevitably tempered by changing tastes and audience demands. The formal "classicist" libretti of Metastasio which had underpinned late 18th century "opera seria" were replaced by subjects more to the taste of the age of Romanticism, with stories demanding stronger characterisation and quicker action; a jobbing composer needed to meet these demands or fail. Rossini's strategies met this reality. A formulaic approach was logistically indispensable for Rossini's career, at least at the start: in the seven years 1812–1819, he wrote 27 operas, often at extremely short notice. For "La Cenerentola" (1817), for example, he had just over three weeks to write the music before the première.

Such pressures led to a further significant element of Rossini's compositional procedures, not included in Budden's "Code", namely, recycling. The composer often transferred a successful overture to subsequent operas: thus the overture to "La pietra del paragone" was later used for the "opera seria" "Tancredi" (1813), and (in the other direction) the overture to "Aureliano in Palmira" (1813) ended as (and is today known as) the overture to the comedy "Il barbiere di Siviglia (The Barber of Seville)". He also liberally re-employed arias and other sequences in later works. Spike Hughes notes that of the twenty-six numbers of "Eduardo e Cristina", produced in Venice in 1817, nineteen were lifted from previous works. "The audience ... were remarkably good-humoured  ... and asked slyly why the libretto had been changed since the last performance". Rossini expressed his disgust when the publisher Giovanni Ricordi issued a complete edition of his works in the 1850s: "The same pieces will be found several times, for I thought I had the right to remove from my fiascos those pieces which seemed best, to rescue them from shipwreck ... A fiasco seemed to be good and dead, and now look they've resuscitated them all!"

Philip Gossett notes that Rossini "was from the outset a consummate composer of overtures." His basic formula for these remained constant throughout his career: Gossett characterises them as "sonata movements without development sections, usually preceded by a slow introduction" with "clear melodies, exuberant rhythms [and] simple harmonic structure" and a "crescendo" climax. Richard Taruskin also notes that the second theme is always announced in a woodwind solo, whose "catchiness" "etch[es] a distinct profile in the aural memory", and that the richness and inventiveness of his handling of the orchestra, even in these early works, marks the start of "[t]he great nineteenth-century flowering of orchestration."

Rossini's handling of arias (and duets) in "cavatina" style marked a development from the eighteenth-century commonplace of recitative and aria. In the words of Rosselli, in Rossini's hands "the aria became an engine for releasing emotion". Rossini's typical aria structure involved a lyrical introduction (""cantabile"") and a more intensive, brilliant, conclusion (""cabaletta""). This model could be adapted in various ways so as to forward the plot (as opposed to the typical eighteenth-century handling which resulted in the action coming to a halt as the requisite repeats of the "da capo aria" were undertaken). For example, they could be punctuated by comments from other characters (a convention known as ""pertichini""), or the chorus could intervene between the "cantabile" and the "cabaletta" so as to fire up the soloist. If such developments were not necessarily Rossini's own invention, he nevertheless made them his own by his expert handling of them. A landmark in this context is the "cavatina" ""Di tanti palpiti"" from "Tancredi", which both Taruskin and Gossett (amongst others) single out as transformative, "the most famous aria Rossini ever wrote", with a "melody that seems to capture the melodic beauty and innocence characteristic of Italian opera." Both writers point out the typical Rossinian touch of avoiding an "expected" cadence in the aria by a sudden shift from the home key of F to that of A flat (see example); Taruskin notes the implicit pun, as the words talk of returning, but the music moves in a new direction. The influence was lasting; Gossett notes how the Rossinian "cabaletta" style continued to inform Italian opera as late as Giuseppe Verdi's "Aida" (1871).

Such structural integration of the forms of vocal music with the dramatic development of the opera meant a sea-change from the Metastasian primacy of the aria; in Rossini's works, solo arias progressively take up a smaller proportion of the operas, in favour of duets (also typically in "cantabile-caballetta" format) and ensembles.

During the late 18th-century, creators of "opera buffa" had increasingly developed dramatic integration of the finales of each act. Finales began to "spread backwards", taking an ever larger proportion of the act, taking the structure of a musically continuous chain, accompanied throughout by orchestra, of a series of sections, each with its own characteristics of speed and style, mounting to a clamorous and vigorous final scene. In his comic operas Rossini brought this technique to its peak, and extended its range far beyond his predecessors. Of the finale to the first act of "L'italiana in Algeri", Taruskin writes that "[r]unning through almost a hundred pages of vocal score in record time, it is the most concentrated single dose of Rossini that there is."

Of greater consequence for the history of opera was Rossini's ability to progress this technique in the genre of "opera seria". Gossett in a very detailed analysis of the first-act finale of "Tancredi" identifies several the elements in Rossini's practice. These include the contrast of "kinetic" action sequences, often characterised by orchestral motifs, with "static" expressions of emotion, the final "static" section in the form of a caballetta, with all the characters joining in the final cadences. Gossett claims that it is "from the time of "Tancredi" that the caballetta ... becomes the obligatory closing section of each musical unit in the operas of Rossini and his contemporaries."

With extremely few exceptions, all Rossini's compositions before the "Péchés de vieillesse" of his retirement involve the human voice. His very first surviving work (apart from a single song) is however a set of string sonatas for two violins, cello and double-bass, written at the age of 12, when he had barely begun instruction in composition. Tuneful and engaging, they indicate how remote the talented child was from the influence of the advances in musical form evolved by Mozart, Haydn and Beethoven; the accent is on cantabile melody, colour, variation and virtuosity rather than transformational development. These qualities are also evident in Rossini's early operas, especially his "farse" (one-act farces), rather than his more formal "opere serie". Gossett notes that these early works were written at a time when "[t]he deposited mantles of Cimarosa and Paisiello were unfilled" – these were Rossini's first, and increasingly appreciated, steps in trying them on. The Teatro San Moisè in Venice, where his "farse" were first performed, and the La Scala Theatre of Milan which premiered his two-act opera "La pietra del paragone" (1812), were seeking works in that tradition; Gossett notes that in these operas "Rossini's musical personality began to take shape ... many elements emerge that remain throughout his career" including "[a] love of sheer sound, of sharp and effective rhythms". The unusual effect employed in the overture of "Il signor Bruschino", (1813) deploying violin bows tapping rhythms on music stands, is an example of such witty originality.

The great success in Venice of the premieres of both "Tancredi" and the comic opera "L'italiana in Algeri" within a few weeks of each other (6 February 1813 and 22 May 1813 respectively) set the seal on Rossini's reputation as the rising opera composer of his generation. From the end of 1813 to mid-1814 he was in Milan creating two new operas for La Scala, "Aureliano in Palmira" and "Il Turco in Italia". Arsace in "Aureliano" was sung by the "castrato" Giambattista Velluti; this was the last opera role Rossini wrote for a "castrato" singer as the norm became to use contralto voices – another sign of change in operatic taste. Rumour had it that Rossini was displeased by Velluti's ornamentation of his music; but in fact throughout his Italian period, up to "Semiramide" (1823), Rossini's written vocal lines become increasingly florid, and this is more appropriately credited to the composer's own changing style.

Rossini's work in Naples contributed to this stylistic development. The city, which was the cradle of the operas of Cimarosa and Paisiello, had been slow to acknowledge the composer from Pesaro, but Domenico Barbaia invited him in 1815 on a seven-year contract to manage his theatres and compose operas. For the first time, Rossini was able to work over a long period with a company of musicians and singers, including amongst the latter Isabella Colbran, Andrea Nozzari, Giovanni David and others, who as Gossett notes "all specialized in florid singing" and "whose vocal talents left an indelible and not wholly positive mark on Rossini's style". Rossini's first operas for Naples, "Elisabetta, regina d'Inghilterra" and "La gazzetta" were both largely recycled from earlier works, but "Otello" (1816) is marked not only by its virtuoso vocal lines but by its masterfully integrated last act, with its drama underlined by melody, orchestration and tonal colour; here, in Gossett's opinion "Rossini came of age as a dramatic artist." He further comments:
By now, Rossini's career was arousing interest across Europe. Others came to Italy to study the revival of Italian opera and used its lessons to advance themselves; amongst these was the Berlin-born Giacomo Meyerbeer who arrived in Italy in 1816, a year after Rossini's establishment at Naples, and lived and worked there until following him to Paris in 1825; he used one of Rossini's librettists, Gaetano Rossi, for five of his seven Italian operas, which were produced at Turin, Venice and Milan. In a letter to his brother of September 1818, he includes a detailed critique of "Otello" from the point of view of a non-Italian informed observer. He is scathing about the self-borrowings in the first two acts, but concedes that the third act "so firmly established Rossini's reputation in Venice that even a thousand follies could not rob him of it. But this act is divinely beautiful, and what is so strange is that [its] beauties ... are blatantly un-Rossinian: outstanding, even passionate recitatives, mysterious accompaniments, lots of local colour."

Rossini's contract did not prevent him from undertaking other commissions, and before "Otello, Il barbiere di Siviglia", a grand culmination of the "opera buffa" tradition, had been premiered in Rome (February 1816). Richard Osborne catalogues its excellencies:Beyond the physical impact of ... Figaro's "Largo al factotum", there is Rossini's ear for vocal and instrumental timbres of a peculiar astringency and brilliance, his quick-witted word-setting, and his mastery of large musical forms with their often brilliant and explosive internal variations. Add to that what Verdi called the opera's "abundance of true musical ideas", and the reasons for the work's longer-term emergence as Rossini's most popular "opera buffa" are not hard to find.

Apart from "La Cenerentola" (Rome, 1817), and the "pen-and-ink sketch" "farsa" "Adina" (1818, not performed until 1826), Rossini's other works during his contract with Naples were all in the "opera seria" tradition. Amongst the most notable of these, all containing virtuoso singing roles, were "Mosè in Egitto" (1818), "La donna del lago" (1819), "Maometto II" (1820) all staged in Naples, and "Semiramide", his last opera written for Italy, staged at La Fenice in Venice in 1823. Both "Mosè" and "Maometto II" were later to undergo significant reconstruction in Paris (see below).

 Already in 1818, Meyerbeer had heard rumours that Rossini was seeking a lucrative appointment at the Paris Opéra – "Should [his proposals] be accepted, he will go to the French capital, and we will perhaps experience curious things." Some six years were to pass before this prophecy came true.

In 1824 Rossini, under a contract with the French government, became director of the Théâtre-Italien in Paris, where he introduced Meyerbeer's opera "Il crociato in Egitto", and for which he wrote "Il viaggio a Reims" to celebrate the coronation of Charles X (1825). This was his last opera to an Italian libretto, and was later cannibalised to create his first French opera, "Le comte Ory" (1828). A new contract in 1826 meant he could concentrate on productions at the Opéra and to this end he substantially revised "Maometto II" as "Le siège de Corinthe" (1826) and "Mosé" as "Moïse et Pharaon" (1827). Meeting French taste, the works are extended (each by one act), the vocal lines in the revisions are less florid and the dramatic structure is enhanced, with the proportion of arias reduced. One of the most striking additions was the chorus at the end of Act III of "Moïse", with a crescendo repetition of a diatonic ascending bass line, rising first by a minor third, then by a major third, at each appearance, and a descending chromatic top line, which roused the excitement of audiences.

Rossini's government contract required him to create at least one new ""grand opėra"", and Rossini settled on the story of William Tell, working closely with the librettist Étienne de Jouy. The story in particular enabled him to indulge "an underlying interest in the related genres of folk music, pastoral and the picturesque". This becomes clear from the overture, which is explicitly programmatic in describing weather, scenery and action, and presents a version of the "ranz des vaches", the Swiss cowherd's call, which "undergoes a number of transformations during the opera" and gives it in Richard Osborne's opinion "something of the character of a leitmotif". In the opinion of the music historian Benjamin Walton, Rossini "saturate[s] the work with local colour to such a degree that there is room for little else." Thus, the role of the soloists is significantly reduced compared to other Rossini operas, the hero not even having an aria of his own, whilst the chorus of the Swiss people is consistently in the musical and dramatic foregrounds.

"Guillaume Tell" premiered in August 1829. Rossini also provided for the Opéra a shorter, three-act version, which incorporated the "pas redoublé" (quick march) final section of the overture in its finale; it was first performed in 1831 and became the basis of the Opéra's future productions. "Tell" was very successful from the start and was frequently revived – in 1868 the composer was present at its 500th performance at the Opéra. The "Globe" had reported enthusiastically at its opening that "a new epoch has opened not only for French opera, but for dramatic music elsewhere." This was an era, it transpired, in which Rossini was not to participate.

Rossini's contract required him to provide five new works for the Opéra over 10 years. After the première of "Tell" he was already considering some opera subjects, including Goethe's "Faust", but the only significant works he completed before abandoning Paris in 1836 were the Stabat Mater, written for a private commission in 1831 (later completed and published in 1841), and the collection of salon vocal music "Soirées musicales" published in 1835. Living in Bologna, he occupied himself teaching singing at the Liceo Musicale, and also created a "pasticcio" of "Tell", "Rodolfo di Sterlinga", for the benefit of the singer Nikolay Ivanov, for which Giuseppe Verdi provided some new arias. Continuing demand in Paris resulted in the productions of a "new" French version of "Otello" in 1844 (with which Rossini was not involved) and a "new" opera "Robert Bruce" for which Rossini cooperated with Louis Niedermeyer and others to recast music for "La donna del lago" and others of his works which were little-known in Paris to fit a new libretto. The success of both of these was qualified, to say the least.

Not until Rossini returned to Paris in 1855 were there signs of a revival of his musical spirits. A stream of pieces, for voices, choir, piano, and chamber ensembles, written for his soirées, the "Péchés de vieillesse (Sins of old age)" were issued in thirteen volumes from 1857 to 1868; of these volumes 4 to 8 comprise "56 semi-comical piano pieces ... dedicated to pianists of the fourth class, to which I have the honour of belonging." These include a mock funeral march, "Marche et reminiscences pour mon dernier voyage (March and reminiscences for my last journey)." Gossett writes of the "Péchés" "Their historical position remains to be assessed but it seems likely that their effect, direct or indirect, on composers like Camille Saint-Saëns and Erik Satie was significant."

The most substantial work of Rossini's last decade, the "Petite messe solennelle" (1863), was written for small forces (originally voices, two pianos and harmonium), and therefore unsuited to concert hall performance; and as it included women's voices it was unacceptable for church performances at the time. For these reasons, Richard Osborne suggests, the piece has been somewhat overlooked among Rossini's compositions. It is neither especially "petite" (little) nor entirely "solennelle" (solemn), but is notable for its grace, counterpoint and melody. At the end of the manuscript, the composer wrote Dear God, here it is finished, this poor little Mass. Is it sacred music I have written, or damned music? I was born for opera buffa, as you know well. A little technique, a little heart, that's all. Be blessed then, and grant me Paradise.

The popularity of Rossini's melodies led many contemporary virtuosi to create piano transcriptions or fantasies based on them. Examples include Sigismond Thalberg's fantasy on themes from "Moïse", the sets of variations on "Non più mesta" from "La Cenerentola" by Henri Herz, Frédéric Chopin, Franz Hünten, Anton Diabelli and Friedrich Burgmüller, and Liszt's transcriptions of the "William Tell" overture (1838) and the "Soirées musicales".

The continuing popularity of his comic operas (and the decline in staging his "opere serie"), the overthrow of the singing and staging styles of his period, and the emerging concept of the composer as "creative artist" rather than craftsman, diminished and distorted Rossini's place in music history even though the forms of Italian opera continued up to the period of verismo to be indebted to his innovations. Rossini's status amongst his contemporary Italian composers is indicated by the "Messa per Rossini", a project initiated by Verdi within a few days of Rossini's death, which he and a dozen other composers created in collaboration.

If Rossini's principal legacy to Italian opera was in vocal forms and dramatic structure for serious opera, his legacy to French opera was to provide a bridge from opera buffa to the development of "opéra comique" (and thence, via Jacques Offenbach's "opéras bouffes" to the genre of operetta). "Opéras comiques" showing a debt to Rossini's style include François-Adrien Boieldieu's "La dame blanche" (1825) and Daniel Auber's "Fra Diavolo" (1830), as well as works by Ferdinand Hérold, Adolphe Adam and Fromental Halévy. Critical of Rossini's style was Hector Berlioz, who wrote of his "melodic cynicism, his contempt for dramatic and good sense, his endless repetition of a single form of cadence, his eternal puerile crescendo and his brutal bass drum".

It was perhaps inevitable that the formidable reputation which Rossini had built in his lifetime would fade thereafter. In 1886, less than twenty years after the composer's death, Bernard Shaw wrote: "The once universal Rossini, whose "Semiramide" appeared to our greener grandfathers a Ninevesque wonder, came at last to be no longer looked upon as a serious musician." In an 1877 review of "Il barbiere", he noted that Adelina Patti sang as an encore in the lesson scene "Home, Sweet Home" but that "the opera proved so intolerably wearisome that some of her audience had already displayed their appreciation of the sentiment of the ballad in the most practical way."

In the early 20th century Rossini received tributes from both Ottorino Respighi, who had orchestrated excerpts from the "Péchés de viellesse" both in his ballet "la boutique fantasque" (1918) and in his 1925 suite "Rossiniana", and from Benjamin Britten, who adapted music by Rossini for two suites, "Soirées musicales" (Op. 9) in 1936 and "Matinées musicales" (Op. 24) in 1941. Richard Osborne singles out the three-volume biography of Rossini by Giuseppe Radiciotti (1927–1929) as an important turning-point towards positive appreciation, which may also have been assisted by the trend of neoclassicism in music. A firm re-evaluation of Rossini's significance began only later in the 20th century in the light of study, and the creation of critical editions, of his works. A prime mover in these developments was the "Fondazione G. Rossini" which was created by the city of Pesaro in 1940 using the funds which had been left to the city by the composer. Since 1980 the "Fondazione" has supported the annual Rossini Opera Festival in Pesaro.

In the 21st century, the Rossini repertoire of opera houses around the world remains dominated by "Il barbiere", "La Cenerentola" being the second most popular. Several other operas are regularly produced, including "Le comte Ory", "La donna del lago", "La gazza ladra", "Guillaume Tell", "L'italiana in Algeri", "La scala di seta", "Il turco in Italia" and "Il viaggio a Reims". Other Rossini pieces in the current international repertory, given from time to time, include "Adina", "Armida", "Elisabetta regina d'Inghilterra", "Ermione", "Mosé in Egitto" and "Tancredi". The Rossini in Wildbad festival specialises in producing the rarer works. The Operabase performance-listing website records 2,319 performances of 532 productions of Rossini operas in 255 venues across the world in the three years 2017–2019. All of Rossini's operas have been recorded.






</doc>
<doc id="12407" url="https://en.wikipedia.org/wiki?curid=12407" title="Gibberish">
Gibberish

Gibberish, also called jibber-jabber or gobbledygook, is speech that is (or appears to be) nonsense. It may include speech sounds that are not actual words, or language games and specialized jargon that seems nonsensical to outsiders. 

"Gibberish" is also used as an imprecation to denigrate or tar ideas or opinions the user disagrees with or finds irksome, a rough equivalent of "nonsense", "folderol", or "claptrap". The implication is that the criticized expression or proposition lacks substance or congruence, as opposed to simply being a differing view.

The related word "jibber-jabber" refers to rapid talk that is difficult to understand.

The etymology of "gibberish" is uncertain. The term was first seen in English in the early 16th century. It is generally thought to be an onomatopoeia imitative of speech, similar to the words "jabber" (to talk rapidly) and "gibber" (to speak inarticulately).

It may originate from the word "jib", which is the Angloromani variant of the Romani language word meaning "language" or "tongue". To non-speakers, the Anglo-Romany dialect could sound like English mixed with nonsense words, and if those seemingly-nonsensical words are referred to as "jib" then the term "gibberish" (pronounced "jibberish") could be derived as a descriptor for nonsensical speech. Another theory is that "gibberish" came from the name of a famous 8th century Muslim Persian alchemist, Jābir ibn Hayyān, whose name was Latinized as "Geber". Thus, "gibberish" was a reference to the incomprehensible technical jargon and allegorical coded language used by Jabir and other alchemists.

A discredited alternative theory asserts that it is derived from the Irish word "gob" or "gab" ("mouth") or from the Irish phrase "Geab ar ais" ("back talk, backward chat"). The latter Irish etymology was suggested by Daniel Cassidy, whose work has been criticised by linguists and scholars. The terms "geab" and "geabaire" are certainly Irish words, but the phrase "geab ar ais" does not exist, and the word "gibberish" exists as a loan-word in Irish as "gibiris".

The term "gobbledygook" was coined by Maury Maverick, a former congressman from Texas and former mayor of San Antonio. When Maverick was chairman of the Smaller War Plants Corporation during World War II, he sent a memorandum that said: "Be short and use plain English. ... Stay off gobbledygook language." Maverick defined "gobbledygook" as "talk or writing which is long, pompous, vague, involved, usually with Latinized words." The allusion was to a turkey, "always gobbledygobbling and strutting with ridiculous pomposity."

The term "gobbledygook" has a long history of usage in politics. Nixon's Oval Office tape from June 14, 1971, showed H. R. Haldeman describing a situation to Nixon as "... a bunch of gobbledygook. But out of the gobbledygook comes a very clear thing: You can't trust the government; you can't believe what they say." President Ronald Reagan explained tax law revisions in an address to the nation with the word, May 28, 1985, saying that "most didn’t improve the system; they made it more like Washington itself: Complicated, unfair, cluttered with gobbledygook and loopholes designed for those with the power and influence to hire high-priced legal and tax advisers." In 2017, US Supreme Court justice John Roberts dismissed quantitative sociological reasoning as "gobbledygook" in arguing against any numerical test for gerrymandering.

Michael Shanks, former chairman to the National Consumer Council of Great Britain, characterizes professional gobbledygook as sloppy jargon intended to confuse nonspecialists: "'Gobbledygook' may indicate a failure to think clearly, a contempt for one's clients, or more probably a mixture of both. A system that can't or won't communicate is not a safe basis for a democracy."

Using gibberish whilst acting can be used as an exercise in performance art education. Another usage of gibberish is as part of Osho's "Gibberish meditation" which has been derived from an old Sufi practice.

The terms "officialese" or "bureaucratese" refer to language used by officials or authorities. "Legalese" is a closely related concept, referring to language used by lawyers, legislators, and others involved with the law. The language used in these fields may contain complex sentences and specialized jargon or buzzwords, making it difficult for those outside the field to understand. Speakers or writers of officialese or legalese may recognize that it is confusing or even meaningless to outsiders, but view its use as appropriate within their organization or group.

Bafflegab is a synonym, a slang term referring to confusing or a generally unintelligible use of jargon.



</doc>
<doc id="12408" url="https://en.wikipedia.org/wiki?curid=12408" title="Gnaeus Julius Agricola">
Gnaeus Julius Agricola

Gnaeus Julius Agricola (; 13 June 40 – 23 August 93) was a Roman Italo-Gallic general responsible for much of the Roman conquest of Britain. Written by his son-in-law Tacitus, the "De vita et moribus Iulii Agricolae" is the primary source for most of what is known about him, along with detailed archaeological evidence from northern Britain.

Agricola began his military career in Britain, serving under governor Gaius Suetonius Paulinus. In his subsequent career, he served in a variety of positions: he was appointed quaestor in Asia province in 64, Plebeian Tribune in 66, and praetor in 68. He supported Vespasian during the Year of the Four Emperors (69), and was given a military command in Britain when the latter became emperor. 

When his command ended in 73, he was made patrician in Rome and appointed governor of Gallia Aquitania. He was made consul and governor of Britannia in 77. While there, he completed the conquest of what is now Wales and northern England, and led his army to the far north of Scotland, establishing forts across much of the Lowlands. He was recalled from Britain in 85 after an unusually lengthy service. After his return, he retired from military and public life.

Agricola was born in the "colonia" of Forum Julii, Gallia Narbonensis (now Fréjus, France). Agricola's parents were from noted political families of senatorial rank in Roman Gaul. Both of his grandfathers served as imperial governors. His father, Lucius Julius Graecinus, was a "praetor" and had become a member of the Roman Senate in the year of his birth. Graecinus had become distinguished by his interest in philosophy. Between August 40 and January 41, the Emperor Caligula ordered his death because he refused to prosecute the Emperor's second cousin Marcus Junius Silanus.

His mother was Julia Procilla. The Roman historian Tacitus describes her as "a lady of singular virtue". Tacitus states that Procilla had a fond affection for her son. Agricola was educated in Massilia (Marseille), and showed what was considered an unhealthy interest in philosophy.

He began his career in Roman public life as a military tribune, serving in Britain under Gaius Suetonius Paulinus from 58 to 62. He was probably attached to the "Legio II Augusta", but was chosen to serve on Suetonius's staff and thus almost certainly participated in the suppression of Boudica's uprising in 61.

Returning from Britain to Rome in 62, he married Domitia Decidiana, a woman of noble birth. Their first child was a son. Agricola was appointed as "quaestor" for 64, which he served in the province of Asia under the corrupt proconsul Lucius Salvius Otho Titianus. While he was there, his daughter, Julia Agricola, was born, but his son died shortly afterwards. He was tribune of the plebs in 66 and "praetor" in June 68, during which time he was ordered by the Governor of Spain Galba to take an inventory of the temple treasures.

During that same, the emperor Nero was declared a public enemy by the Senate and committed suicide, and the period of civil war known as the Year of the Four Emperors began. Galba succeeded Nero, but was murdered in early 69 by Otho, who took the throne. Agricola's mother was murdered on her estate in Liguria by Otho's marauding fleet. Hearing of Vespasian's bid for the empire, Agricola immediately gave him his support. Otho meanwhile committed suicide after being defeated by Vitellius.

After Vespasian had established himself as emperor, Agricola was appointed to the command of the "Legio XX Valeria Victrix", stationed in Britain, in place of Marcus Roscius Coelius, who had stirred up a mutiny against the governor, Marcus Vettius Bolanus. Britain had revolted during the year of civil war, and Bolanus was a mild governor. Agricola reimposed discipline on the legion and helped to consolidate Roman rule. In 71, Bolanus was replaced by a more aggressive governor, Quintus Petillius Cerialis, and Agricola was able to display his talents as a commander in campaigns against the Brigantes in northern England.

When his command ended in 73, Agricola was enrolled as a patrician and appointed to govern Gallia Aquitania. There he stayed for almost three years. In 76 or 77, he was recalled to Rome and appointed suffect consul, and betrothed his daughter to Tacitus. The following year, Tacitus and Julia married; Agricola was appointed to the College of Pontiffs, and returned to Britain for a third time, as its governor ("Legatus Augusti pro praetore").

Arriving in midsummer of 77, Agricola discovered that the Ordovices of north Wales had virtually destroyed the Roman cavalry stationed in their territory. He immediately moved against them and defeated them. He then moved north to the island of Mona (Anglesey), which Suetonius Paulinus had failed to subjugate in 60 because of the outbreak of the Boudican rebellion, and forced its inhabitants to sue for peace. He established a good reputation as an administrator, as well as a commander, by reforming the widely corrupt corn levy. He introduced Romanising measures, encouraging communities to build towns on the Roman model and educating the sons of the native nobility in the Roman manner.

Agricola also expanded Roman rule north into Caledonia (modern Scotland). In the summer of 79, he pushed his armies to the estuary of the river Taus, usually interpreted as the Firth of Tay, virtually unchallenged, and established some forts. Though their location is left unspecified, the close dating of the fort at Elginhaugh in Midlothian makes it a possible candidate.

In 81, Agricola "crossed in the first ship" and defeated peoples unknown to the Romans until then. Tacitus, in Chapter 24 of "Agricola", does not tell us what body of water he crossed, although most scholars believe it was the Clyde or Forth, and some translators even add the name of their preferred river to the text; however, the rest of the chapter exclusively concerns Ireland, so southwest Scotland is perhaps to be preferred. The text of the "Agricola" has been amended here to record the Romans "crossing into trackless wastes", referring to the wilds of the Galloway peninsula. Agricola fortified the coast facing Ireland, and Tacitus recalls that his father-in-law often claimed the island could be conquered with a single legion and auxiliaries. He had given refuge to an exiled Irish king whom he hoped he might use as the excuse for conquest. This conquest never happened, but some historians believe the crossing referred to was in fact a small-scale exploratory or punitive expedition to Ireland, though no Roman camps have been identified to confirm such a suggestion.

Irish legend provides a striking parallel. Tuathal Teachtmhar, a legendary High King, is said to have been exiled from Ireland as a boy, and to have returned from Britain at the head of an army to claim the throne. The traditional date of his return is between 76 and 80, and archaeology has found Roman or Romano-British artefacts in several sites associated with Tuathal.

The following year, Agricola raised a fleet and encircled the tribes beyond the Forth, and the Caledonians rose in great numbers against him. They attacked the camp of the "Legio IX Hispana" at night, but Agricola sent in his cavalry and they were put to flight. The Romans responded by pushing further north. Another son was born to Agricola this year, but died before his first birthday.

In the summer of 83, Agricola faced the massed armies of the Caledonians, led by Calgacus, at the Battle of Mons Graupius. Tacitus estimates their numbers at more than 30,000. Agricola put his auxiliaries in the front line, keeping the legions in reserve, and relied on close-quarters fighting to make the Caledonians' unpointed slashing swords useless as they were unable to swing them properly or utilise thrusting attacks. Even though the Caledonians were put to rout and therefore lost this battle, two thirds of their army managed to escape and hide in the Highlands or the "trackless wilds" as Tacitus calls them. Battle casualties were estimated by Tacitus to be about 10,000 on the Caledonian side and 360 on the Roman side.

A number of authors have reckoned the battle to have occurred in the Grampian Mounth within sight of the North Sea. In particular, Roy, Surenne, Watt, Hogan and others have advanced notions that the site of the battle may have been Kempstone Hill, Megray Hill or other knolls near the Raedykes Roman camp; these points of high ground are proximate to the Elsick Mounth, an ancient trackway used by Romans and Caledonians for military manoeuvres. However, following the discovery of the Roman camp at Durno in 1975, most scholars now believe that the battle took place on the ground around Bennachie in Aberdeenshire.

Satisfied with his victory, Agricola extracted hostages from the Caledonian tribes. He may have marched his army to the northern coast of Britain, as evidenced by the probable discovery of a Roman fort at Cawdor (near Inverness).

He also instructed the prefect of the fleet to sail around the north coast, confirming (allegedly for the first time) that Britain was in fact an island.

Agricola was recalled from Britain in 85, after an unusually long tenure as governor. Tacitus claims Domitian ordered his recall because Agricola's successes outshone the Emperor's own modest victories in Germany. He re-entered Rome unobtrusively, reporting as ordered to the palace at night. The relationship between Agricola and the Emperor is unclear; on the one hand, Agricola was awarded triumphal decorations and a statue (the highest military honours apart from an actual triumph); on the other, Agricola never again held a civil or military post, in spite of his experience and renown. He was offered the governorship of the province of Africa, but declined it, whether due to ill health or (as Tacitus claims) the machinations of Domitian.
In 93, Agricola died on his family estates in Gallia Narbonensis aged fifty-three. Rumours circulated attributing the death to a poison administered by the Emperor Domitian, but no positive evidence for this was ever produced.




 


</doc>
<doc id="12417" url="https://en.wikipedia.org/wiki?curid=12417" title="Guanosine">
Guanosine

Guanosine is a purine nucleoside comprising guanine attached to a ribose (ribofuranose) ring via a β-N-glycosidic bond. Guanosine can be phosphorylated to become guanosine monophosphate (GMP), cyclic guanosine monophosphate (cGMP), guanosine diphosphate (GDP), and guanosine triphosphate (GTP). These forms play important roles in various biochemical processes such as synthesis of nucleic acids and proteins, photosynthesis, muscle contraction, and intracellular signal transduction (cGMP). When guanine is attached by its N9 nitrogen to the C1 carbon of a deoxyribose ring it is known as deoxyguanosine.

Guanosine is a white, crystalline powder with no odor and mild saline taste.
It is very soluble in acetic acid, slightly soluble in water, insoluble in ethanol, diethyl ether, benzene and chloroform.

Guanosine is required for an RNA splicing reaction in mRNA, when a "self-splicing" intron removes itself from the mRNA message by cutting at both ends, re-ligating, and leaving just the exons on either side to be translated into protein.
The antiviral drug acyclovir, often used in herpes treatment, and the anti-HIV drug abacavir, are structurally similar to guanosine. Guanosine was also used to make regadenoson.

Guanosine can be found in pancreas, clover, coffee plant, and pollen of pines.


</doc>
<doc id="12420" url="https://en.wikipedia.org/wiki?curid=12420" title="Gödel's ontological proof">
Gödel's ontological proof

Gödel's ontological proof is a formal argument by the mathematician Kurt Gödel (1906–1978) for the existence of God. The argument is in a line of development that goes back to Anselm of Canterbury (1033–1109). St. Anselm's ontological argument, in its most succinct form, is as follows: "God, by definition, is that for which no greater can be conceived. God exists in the understanding. If God exists in the understanding, we could imagine Him to be greater by existing in reality. Therefore, God must exist." A more elaborate version was given by Gottfried Leibniz (1646–1716); this is the version that Gödel studied and attempted to clarify with his ontological argument.

Gödel left a fourteen-point outline of his philosophical beliefs in his papers. Points relevant to the ontological proof include

The first version of the ontological proof in Gödel's papers is dated "around 1941". Gödel is not known to have told anyone about his work on the proof until 1970, when he thought he was dying. In February, he allowed Dana Scott to copy out a version of the proof, which circulated privately. In August 1970, Gödel told Oskar Morgenstern that he was "satisfied" with the proof, but Morgenstern recorded in his diary entry for 29 August 1970, that Gödel would not publish because he was afraid that others might think "that he actually believes in God, whereas he is only engaged in a logical investigation (that is, in showing that such a proof with classical assumptions (completeness, etc.) correspondingly axiomatized, is possible)." Gödel died January 14, 1978. Another version, slightly different from Scott's, was found in his papers. It was finally published, together with Scott's version, in 1987.

Morgenstern's diary is an important and usually reliable source for Gödel's later years, but the implication of the August 1970 diary entry—that Gödel did not believe in God—is not consistent with the other evidence. In letters to his mother, who was not a churchgoer and had raised Kurt and his brother as freethinkers, Gödel argued at length for a belief in an afterlife. He did the same in an interview with a skeptical Hao Wang, who said: "I expressed my doubts as G spoke [...] Gödel smiled as he replied to my questions, obviously aware that his answers were not convincing me." Wang reports that Gödel's wife, Adele, two days after Gödel's death, told Wang that "Gödel, although he did not go to church, was religious and read the Bible in bed every Sunday morning." In an unmailed answer to a questionnaire, Gödel described his religion as "baptized Lutheran (but not member of any religious congregation). My belief is "theistic", not pantheistic, following Leibniz rather than Spinoza."

The proof uses modal logic, which distinguishes between "necessary" truths and "contingent" truths. In the most common semantics for modal logic, many "possible worlds" are considered. A truth is "necessary" if it is true in all possible worlds. By contrast, if a statement happens to be true in our world, but is false in another world, then it is a "contingent" truth. A statement that is true in some world (not necessarily our own) is called a "possible" truth.

Furthermore, the proof uses higher-order (modal) logic because the definition of God employs an explicit quantification over properties.

First, Gödel axiomatizes the notion of a "positive property": for each property "φ", either "φ" or its negation ¬"φ" must be positive, but not both (axiom 2). If a positive property "φ" implies a property "ψ" in each possible world, then "ψ" is positive, too (axiom 1). Gödel then argues that each positive property is "possibly exemplified", i.e. applies at least to some object in some world (theorem 1). Defining an object to be Godlike if it has all positive properties (definition 1), and requiring that property to be positive itself (axiom 3), Gödel shows that in "some" possible world a Godlike object exists (theorem 2), called "God" in the following. Gödel proceeds to prove that a Godlike object exists in "every" possible world.

To this end, he defines "essences": if "x" is an object in some world, then a property "φ" is said to be an essence of "x" if "φ"("x") is true in that world and if "φ" necessarily entails all other properties that "x" has in that world (definition 2). Requiring positive properties being positive in every possible world (axiom 4), Gödel can show that Godlikeness is an essence of a Godlike object (theorem 3). Now, "x" is said to "exist necessarily" if, for every essence "φ" of "x", there is an element "y" with property "φ" in every possible world (definition 3). Axiom 5 requires necessary existence to be a positive property.

Hence, it must follow from Godlikeness. Moreover, Godlikeness is an essence of God, since it entails all positive properties, and any non-positive property is the negation of some positive property, so God cannot have any non-positive properties. Since necessary existence is also a positive property (axiom 5), it must be a property of every Godlike object, as every Godlike object has all the positive properties (definition 1). Since any Godlike object is necessarily existent, it follows that any Godlike object in one world is a Godlike object in all worlds, by the definition of necessary existence. Given the existence of a Godlike object in one world, proven above, we may conclude that there is a Godlike object in every possible world, as required (theorem 4). Besides axiom 1-5 and definition 1-3, a few other axioms from modal logic were tacitly used in the proof.

From these hypotheses, it is also possible to prove that there is only one God in each world by Leibniz's law, the identity of indiscernibles: two or more objects are identical (the same) if they have all their properties in common, and so, there would only be one object in each world that possesses property G. Gödel did not attempt to do so however, as he purposely limited his proof to the issue of existence, rather than uniqueness.

formula_1

Most criticism of Gödel's proof is aimed at its axioms: as with any proof in any logical system, if the axioms the proof depends on are doubted, then the conclusions can be doubted. It is particularly applicable to Gödel's proof – because it rests on five axioms, some of which are questionable. A proof does not necessitate that the conclusion be correct, but rather that by accepting the axioms, the conclusion follows logically.

Many philosophers have called the axioms into question. The first layer of criticism is simply that there are no arguments presented that give reasons why the axioms are true. A second layer is that these particular axioms lead to unwelcome conclusions. This line of thought was argued by Jordan Howard Sobel, showing that if the axioms are accepted, they lead to a "modal collapse" where every statement that is true is necessarily true, i.e. the sets of necessary, of contingent, and of possible truths all coincide (provided there are accessible worlds at all). According to Robert Koons, Sobel suggested that Gödel might have welcomed modal collapse.

There are suggested amendments to the proof, presented by C. Anthony Anderson, but argued to be refutable by Anderson and Michael Gettings. Sobel's proof of modal collapse has been questioned by Koons, but a counter-defence by Sobel has been given.

Gödel's proof has also been questioned by Graham Oppy, asking whether many other almost-gods would also be "proven" by Gödel's axioms. This counter-argument has been questioned by Gettings, who agrees that the axioms might be questioned, but disagrees that Oppy's particular counter-example can be shown from Gödel's axioms.

Religious scholar Fr. Robert J. Spitzer accepted Gödel's proof, calling it "an improvement over the Anselmian Ontological Argument (which does not work)."

There are, however, many more criticisms, most focusing on the philosophically interesting question of whether these axioms "must" be rejected to avoid odd conclusions. The broader criticism is that even if the axioms cannot be shown to be false, that does not mean that they are true. Hilbert's famous remark about interchangeability of the primitives' names applies to those in Gödel's ontological axioms ("positive", "god-like", "essence") as well as to those in Hilbert's geometry axioms ("point", "line", "plane"). According to André Fuhrmann (2005) it remains to show that the dazzling notion prescribed by traditions and often believed to be essentially mysterious satisfies Gödel's axioms. This is not a mathematical, but merely a theological task. It is this task which decides which religion's god has been proven to exist.

Christoph Benzmüller and Bruno Woltzenlogel-Paleo formalized Gödel's proof to a level that is suitable for automated theorem proving or at least computer verification via proof assistants. The effort made headlines in German newspapers. According to the authors of this effort, they were inspired by Melvin Fitting's book.

In 2014, they computer-verified Gödel's proof (in the above version).
They also proved that this version's axioms are consistent,
but imply modal collapse, thus confirming Sobel's 1987 argument.

In the same paper, they suspected Gödel's original version of the axioms to be inconsistent, as they failed to prove their consistency.
In 2016, they gave a computer proof that this version implies formula_2, i.e. is inconsistent in every modal logic with a reflexive or symmetric accessibility relation.
Moreover, they gave an argument that this version is inconsistent in every logic at all, but failed to duplicate it by automated provers. In the same paper they suggested that modal collapse is not necessarily a flaw.

A humorous variant of Gödel's ontological proof is mentioned in Quentin Canterel's novel "The Jolly Coroner".
The proof is also mentioned in the TV series "Hand of God".





</doc>
<doc id="12422" url="https://en.wikipedia.org/wiki?curid=12422" title="List of gymnasts">
List of gymnasts

Gymnasts are people who participate in the sport of gymnastics. This sport contains disciplines that include, but are not limited to:

This list is of those who are considered to be notable in their chosen discipline.

See gymnasium (ancient Greece) for the origin of the word "gymnast" from gymnastikos.




</doc>
<doc id="12424" url="https://en.wikipedia.org/wiki?curid=12424" title="Genetic programming">
Genetic programming

In artificial intelligence, genetic programming (GP) is a technique of evolving programs, starting from a population of unfit (usually random) programs, fit for a particular task by applying operations analogous to natural genetic processes to the population of programs. It is essentially a heuristic search technique often described as 'hill climbing', i.e. searching for an optimal or at least suitable program among the space of all programs.

The operations are: selection of the fittest programs for reproduction (crossover) and mutation according to a predefined fitness measure, usually proficiency at the desired task. The crossover operation involves swapping random parts of selected pairs (parents) to produce new and different offspring that become part of the new generation of programs. Mutation involves substitution of some random part of a program with some other random part of a program. Some programs not selected for reproduction are copied from the current generation to the new generation. Then the selection and other operations are recursively applied to the new generation of programs.

Typically, members of each new generation are on average more fit than the members of the previous generation, and the best-of-generation program is often better than the best-of-generation programs from previous generations. Termination of the recursion is when some individual program reaches a predefined proficiency or fitness level.

It may and often does happen that a particular run of the algorithm results in premature convergence to some local maximum which is not a globally optimal or even good solution. Multiple runs (dozens to hundreds) are usually necessary to produce a very good result. It may also be necessary to increase the starting population size and variability of the individuals to avoid pathologies.

The first record of the proposal to evolve programs is probably that of Alan Turing in 1950. There was a gap of 25 years before the publication of John Holland's 'Adaptation in Natural and Artificial Systems' laid out the theoretical and empirical foundations of the science. In 1981, Richard Forsyth demonstrated the successful evolution of small programs, represented as trees, to perform classification of crime scene evidence for the UK Home Office.

Although the idea of evolving programs, initially in the computer language Lisp, was current amongst John Holland’s students, it was not until they organised the first Genetic Algorithms conference in Pittsburgh that Nichael Cramer published evolved programs in two specially designed languages, which included the first statement of modern "tree-based" Genetic Programming (that is, procedural languages organized in tree-based structures and operated on by suitably defined GA-operators) . In 1988, John Koza (also a PhD student of John Holland) patented his invention of a GA for program evolution. This was followed by publication in the International Joint Conference on Artificial Intelligence IJCAI-89.

Koza followed this with 205 publications on “Genetic Programming” (GP), name coined by David Goldberg, also a PhD student of John Holland. However, it is the series of 4 books by Koza, starting in 1992 with accompanying videos, that really established GP. Subsequently, there was an enormous expansion of the number of publications with the Genetic Programming Bibliography, surpassing 10,000 entries. In 2010, Koza listed 77 results where Genetic Programming was human competitive.

In 1996, Koza started the annual Genetic Programming conference which was followed in 1998 by the annual EuroGP conference, and the first book in a GP series edited by Koza. 1998 also saw the first GP textbook. GP continued to flourish, leading to the first specialist GP journal and three years later (2003) the annual Genetic Programming Theory and Practice (GPTP) workshop was established by Rick Riolo. Genetic Programming papers continue to be published at a diversity of conferences and associated journals. Today there are nineteen GP books including several for students.

Early work that set the stage for current genetic programming research topics and applications is diverse, and includes software synthesis and repair, predictive modeling, data mining, financial modeling, soft sensors, design, and image processing. Applications in some areas, such as design, often make use of intermediate representations, such as Fred Gruau’s cellular encoding. Industrial uptake has been significant in several areas including finance, the chemical industry, bioinformatics and the steel industry.

GP evolves computer programs, traditionally represented in memory as tree structures. Trees can be easily evaluated in a recursive manner. Every tree node has an operator function and every terminal node has an operand, making mathematical expressions easy to evolve and evaluate. Thus traditionally GP favors the use of programming languages that naturally embody tree structures (for example, Lisp; other functional programming languages are also suitable).

Non-tree representations have been suggested and successfully implemented, such as linear genetic programming which suits the more traditional imperative languages [see, for example, Banzhaf "et al." (1998)]. The commercial GP software "Discipulus" uses automatic induction of binary machine code ("AIM") to achieve better performance. "µGP" uses directed multigraphs to generate programs that fully exploit the syntax of a given assembly language. Other program representations on which significant research and development have been conducted include programs for stack-based virtual machines, and sequences of integers that are mapped to arbitrary programming languages via grammars. Cartesian genetic programming is another form of GP, which uses a graph representation instead of the usual tree based representation to encode computer programs.

Most representations have structurally noneffective code (introns). Such non-coding genes may seem to be useless because they have no effect on the performance of any one individual. However, they alter the probabilities of generating different offspring under the variation operators, and thus alter the individual's variational properties.
Experiments seem to show faster convergence when using program representations that allow such non-coding genes, compared to program representations that do not have any non-coding genes.

Selection is a process whereby certain individuals are selected from the current generation that would serve as parents for the next generation. The individuals are selected probabilistically such that the better performing individuals have a higher chance of getting selected. The most commonly used selection method in GP is tournament selection, although other methods such as fitness proportionate selection, lexicase selection, and others have been demonstrated to perform better for many GP problems.

Elitism, which involves seeding the next generation with the best individual (or best "n" individuals) from the current generation, is a technique sometimes employed to avoid regression.

Various genetic operators (i.e., crossover and mutation) are applied to the individuals selected in the selection step described above to breed new individuals. The rate at which these operators are applied determines the diversity in the population.

Flip one or more bits from the previous offspring to generate new child or generation.

GP has been successfully used as an automatic programming tool, a machine learning tool and an automatic problem-solving engine. GP is especially useful in the domains where the exact form of the 
solution is not known in advance or an approximates solution is acceptable (possibly because finding the exact solution is very difficult). Some of the applications of GP are curve fitting, data modeling, symbolic regression, feature selection, classification, etc. John R. Koza mentions 76
instances where Genetic Programming has been able to produce results that are competitive with human-produced results (called Human-competitive results). Since 2004, the annual Genetic and Evolutionary Computation Conference (GECCO) holds Human Competitive Awards (called Humies) competition, where cash awards are presented to human-competitive results produced by any form of genetic and evolutionary computation. GP has won many awards in this competition over the years.

Meta-genetic programming is the proposed meta learning technique of evolving a genetic programming system using genetic programming itself. It suggests that chromosomes, crossover, and mutation were themselves evolved, therefore like their real life counterparts should be allowed to change on their own rather than being determined by a human programmer. Meta-GP was formally proposed by Jürgen Schmidhuber in 1987. Doug Lenat's Eurisko is an earlier effort that may be the same technique. It is a recursive but terminating algorithm, allowing it to avoid infinite recursion. In the "autoconstructive evolution" approach to meta-genetic programming, the methods for the production and variation of offspring are encoded within the evolving programs themselves, and programs are executed to produce new programs to be added to the population.

Critics of this idea often say this approach is overly broad in scope. However, it might be possible to constrain the fitness criterion onto a general class of results, and so obtain an evolved GP that would more efficiently produce results for sub-classes. This might take the form of a meta evolved GP for producing human walking algorithms which is then used to evolve human running, jumping, etc. The fitness criterion applied to the meta GP would simply be one of efficiency.




</doc>
<doc id="12425" url="https://en.wikipedia.org/wiki?curid=12425" title="Gustav Klimt">
Gustav Klimt

Gustav Klimt (July 14, 1862 – February 6, 1918) was an Austrian symbolist painter and one of the most prominent members of the Vienna Secession movement. Klimt is noted for his paintings, murals, sketches, and other objet d'art. Klimt's primary subject was the female body, and his works are marked by a frank eroticism. In addition to his figurative works, which include allegories and portraits, he painted landscapes. Among the artists of the Vienna Secession, Klimt was the most influenced by Japanese art and its methods.

Early in his artistic career, he was a successful painter of architectural decorations in a conventional manner. As he began to develop a more personal style, his work was the subject of controversy that culminated when the paintings he completed around 1900 for the ceiling of the Great Hall of the University of Vienna were criticized as pornographic. He subsequently accepted no more public commissions, but achieved a new success with the paintings of his "golden phase", many of which include gold leaf. Klimt's work was an important influence on his younger peer Egon Schiele.

Gustav Klimt was born in Baumgarten, near Vienna in Austria-Hungary, the second of seven children—three boys and four girls. His mother, Anna Klimt ("née" Finster), had an unrealized ambition to be a musical performer. His father, Ernst Klimt the Elder, formerly from Bohemia, was a gold engraver. All three of their sons displayed artistic talent early on. Klimt's younger brothers were Ernst Klimt and Georg Klimt.

Klimt lived in poverty while attending the Vienna Kunstgewerbeschule, a school of applied arts and crafts, now the University of Applied Arts Vienna, where he studied architectural painting from 1876 until 1883. He revered Vienna's foremost history painter of the time, Hans Makart. Klimt readily accepted the principles of a conservative training; his early work may be classified as academic. In 1877 his brother, Ernst, who, like his father, would become an engraver, also enrolled in the school. The two brothers and their friend, Franz Matsch, began working together and by 1880 they had received numerous commissions as a team that they called the "Company of Artists". They also helped their teacher in painting murals in the Kunsthistorisches Museum in Vienna. Klimt began his professional career painting interior murals and ceilings in large public buildings on the Ringstraße, including a successful series of "Allegories and Emblems".

In 1888 Klimt received the Golden Order of Merit from Emperor Franz Josef I of Austria for his contributions to murals painted in the Burgtheater in Vienna. He also became an honorary member of the University of Munich and the University of Vienna. In 1892 Klimt's father and brother Ernst both died, and he had to assume financial responsibility for his father's and brother's families. The tragedies also affected his artistic vision and soon he would move towards a new personal style. 
Characteristic of his style at the end of the 19th century is the inclusion of "Nuda Veritas" ("naked truth") as a symbolic figure in some of his works, including "Ancient Greece and Egypt" (1891), "Pallas Athene" (1898) and "Nuda Veritas" (1899). Historians believe that Klimt with the "nuda veritas" denounced both the policy of the Habsburgs and Austrian society, which ignored all political and social problems of that time. 
In the early 1890s Klimt met Austrian fashion designer Emilie Louise Flöge (a sibling of his sister-in-law) who was to be his companion until the end of his life. His painting, "The Kiss" (1907–08), is thought to be an image of them as lovers. He designed many costumes that she produced and modeled in his works.

During this period Klimt fathered at least fourteen children.

Klimt became one of the founding members and president of the "Wiener Sezession" (Vienna Secession) in 1897 and of the group's periodical, "Ver Sacrum" ("Sacred Spring"). He remained with the Secession until 1908. The goals of the group were to provide exhibitions for unconventional young artists, to bring the works of the best foreign artists to Vienna, and to publish its own magazine to showcase the work of members. The group declared no manifesto and did not set out to encourage any particular style—Naturalists, Realists, and Symbolists all coexisted. The government supported their efforts and gave them a lease on public land to erect an exhibition hall. The group's symbol was Pallas Athena, the Greek goddess of just causes, wisdom, and the arts—of whom Klimt painted his radical version in 1898.

In 1894, Klimt was commissioned to create three paintings to decorate the ceiling of the Great Hall of the University of Vienna. Not completed until the turn of the century, his three paintings, "Philosophy", "Medicine", and "Jurisprudence" were criticized for their radical themes and material, and were called "pornographic". Klimt had transformed traditional allegory and symbolism into a new language that was more overtly sexual and hence more disturbing to some. The public outcry came from all quarters—political, aesthetic and religious. As a result, the paintings "(seen in gallery below)" were not displayed on the ceiling of the Great Hall. This would be the last public commission accepted by the artist.

All three paintings were destroyed when retreating German forces burned Schloss Immendorf in May 1945.

His "Nuda Veritas" (1899) defined his bid to further "shake up" the establishment. The starkly naked red-headed woman holds the mirror of truth, while above her is a quotation by Friedrich Schiller in stylized lettering: "If you cannot please everyone with your deeds and your art, please only a few. To please many is bad."

In 1902, Klimt finished the "Beethoven Frieze" for the Fourteenth Vienna Secessionist exhibition, which was intended to be a celebration of the composer and featured a monumental polychrome sculpture by Max Klinger. Intended for the exhibition only, the frieze was painted directly on the walls with light materials. After the exhibition the painting was preserved, although it was not displayed again until 1986. The face on the Beethoven portrait resembled the composer and Vienna Court Opera director Gustav Mahler.

During this period Klimt did not confine himself to public commissions. Beginning in the late 1890s he took annual summer holidays with the Flöge family on the shores of Attersee and painted many of his landscapes there. These landscapes constitute the only genre aside from figure painting that seriously interested Klimt. In recognition of his intensity, the locals called him Waldschrat ("forest demon").

Klimt's Attersee paintings are of sufficient number and quality as to merit separate appreciation. Formally, the landscapes are characterized by the same refinement of design and emphatic patterning as the figural pieces. Deep space in the Attersee works is flattened so efficiently to a single plane that it is believed that Klimt painted them by using a telescope.

Klimt's 'Golden Phase' was marked by positive critical reaction and financial success. Many of his paintings from this period included gold leaf. Klimt had previously used gold in his "Pallas Athene" (1898) and "Judith I" (1901), although the works most popularly associated with this period are the "Portrait of Adele Bloch-Bauer I" (1907) and "The Kiss" (1907–08).

Klimt traveled little, but trips to Venice and Ravenna, both famous for their beautiful mosaics, most likely inspired his gold technique and his Byzantine imagery. In 1904, he collaborated with other artists on the lavish Palais Stoclet, the home of a wealthy Belgian industrialist that was one of the grandest monuments of the Art Nouveau age. Klimt's contributions to the dining room, including both "Fulfillment" and "Expectation", were some of his finest decorative works, and as he publicly stated, "probably the ultimate stage of my development of ornament."

1905, Klimt painted "The Three Ages of Woman", depicting the cycle of life. He created a painted portrait of Margarete Wittgenstein, Ludwig Wittgenstein's sister, on the occasion of her marriage. Then, between 1907 and 1909, Klimt painted five canvases of society women wrapped in fur. His apparent love of costume is expressed in the many photographs of Flöge modeling clothing he had designed.

As he worked and relaxed in his home, Klimt normally wore sandals and a long robe with no undergarments. His simple life was somewhat cloistered, devoted to his art, family, and little else except the Secessionist Movement. He avoided café society and seldom socialized with other artists. Klimt's fame usually brought patrons to his door and he could afford to be highly selective. His painting method was very deliberate and painstaking at times and he required lengthy sittings by his subjects. Although very active sexually, he kept his affairs discreet and he avoided personal scandal.

Klimt wrote little about his vision or his methods. He wrote mostly postcards to Flöge and kept no diary. In a rare writing called "Commentary on a non-existent self-portrait", he states "I have never painted a self-portrait. I am less interested in myself as a subject for a painting than I am in other people, above all women... There is nothing special about me. I am a painter who paints day after day from morning to night ... Whoever wants to know something about me ... ought to look carefully at my pictures."

In 1901 Hermann Bahr wrote, in his "Speech on Klimt": "Just as only a lover can reveal to a man what life means to him and develop its innermost significance, I feel the same about these paintings."

In 1911 his painting "Death and Life" received first prize in the world exhibitions in Rome. In 1915 Anna, his mother, died. Klimt died three years later in Vienna on February 6, 1918, having suffered a stroke and pneumonia due to the worldwide influenza epidemic of that year. He was buried at the Hietzinger Cemetery in Hietzing, Vienna. Numerous paintings by him were left unfinished.

Klimt's paintings have brought some of the highest prices recorded for individual works of art. In November 2003, Klimt's "Landhaus am Attersee" sold for $29,128,000, but that sale was soon eclipsed by prices paid for Willem de Kooning's "Woman III" and later Klimt's own "Adele Bloch-Bauer II", the latter of which sold for $150 million in 2016. More frequently than paintings, however, the artist's works on paper can be found on the art market. The art market database Artprice lists 67 auction entries for paintings, but 1564 for drawings and watercolors. The most expensive drawing sold so far was "Reclining Female Nude Facing Left", which was made between 1914 and 1915 and sold in London in 2008 for . However, the majority of the art trade traditionally takes place privately through galleries such as Wienerroither & Kohlbacher, which specialize in the trade with original works by Gustav Klimt and Egon Schiele and regularly present these at monographic exhibitions and international art fairs.

In 2006, the 1907 portrait, "Adele Bloch-Bauer I", was purchased for the Neue Galerie New York by Ronald Lauder reportedly for US$135 million, surpassing Picasso's 1905 "Boy With a Pipe" (sold May 5, 2004 for $104 million), as the highest reported price ever paid for a painting up to that point.

On August 7, 2006, Christie's auction house announced it was handling the sale of the remaining four works by Klimt that were recovered by Maria Altmann and her co-heirs after their long legal battle against Austria (see "Republic of Austria v. Altmann"). Altmann's fight to regain her family's paintings has been the subject of a number of documentary films, including "Adele's Wish". Her struggle also became the subject of the dramatic film the "Woman in Gold", a movie inspired by "Stealing Klimt", the documentary featuring Maria Altmann herself. The portrait of "Adele Bloch-Bauer II" was sold at auction in November 2006 for $88 million, the third-highest priced piece of art at auction at the time. "The Apple Tree I" (c. 1912) sold for $33 million, "Birch Forest" (1903) sold for $40.3 million, and "Houses in Unterach on Lake Atter" (1916) sold for $31 million. Collectively, the five restituted paintings netted more than $327 million. 

The painting "Litzlberg am Attersee" was auctioned for $40.4 million November 2011.

The city of Vienna, Austria had many special exhibitions commemorating the 150th anniversary of Klimt's birth in 2012.

The only folio set produced in Klimt's lifetime, "Das Werk Gustav Klimts", was published initially by H. O. Miethke (of Gallerie Miethke, Klimt's exclusive gallery in Vienna) from 1908 to 1914 in an edition of 300, supervised personally by the artist. The first thirty-five editions (I-XXXV) each included an original drawing by Klimt, and the next thirty-five editions (XXXVI-LXX) each with a facsimile signature on the title page. Fifty images depicting Klimt's most important paintings (1893–1913) were reproduced using collotype lithography and mounted on a heavy, cream-colored wove paper with deckled edges. Thirty-one of the images (ten of which are multicolored) are printed on "Chine-collé". The remaining nineteen are high quality halftones prints. Each piece was marked with a unique signet—designed by Klimt—which was impressed into the wove paper in gold metallic ink. The prints were issued in groups of ten to subscribers, in unbound black paper folders embossed with Klimt's name. Because of the delicate nature of collotype lithography, as well as the necessity for multicolored prints (a feat difficult to reproduce with collotypes), and Klimt's own desire for perfection, the series that was published in mid-1908 was not completed until 1914.

Each of the fifty prints was categorized among five themes:

The monochrome collotypes as well as the halftone works were printed with a variety of colored inks ranging from sepia to blue and green. Emperor Franz Joseph I of Austria was the first to purchase a folio set of "Das Werk Gustav Klimts" in 1908.

"Fünfundzwanzig Handzeichnungen" ("Twenty-five Drawings") was released the year after Klimt's death. Many of the drawings in the collection were erotic in nature and just as polarizing as his painted works. Published in Vienna in 1919 by Gilhofer & Ranschburg, the edition of 500 features twenty-five monochrome and two-color collotype reproductions, nearly indistinguishable from the original works. While the set was released a year after Klimt's death, some art historians suspect he was involved with production planning due to the meticulous nature of the printing (Klimt had overseen the production of the plates for "Das Werk Gustav Klimts", making sure each one was to his exact specifications, a level of quality carried through similarly in "Fünfundzwanzig Handzeichnungen"). The first ten editions also each contained an original Klimt drawing.

Many of the works contained in this volume depict erotic scenes of nude women, some of whom are masturbating alone or are coupled in sapphic embraces. When a number of the original drawings were exhibited to the public, at Gallerie Miethke in 1910 and the International Exhibition of Prints and Drawings in Vienna in 1913, they were met by critics and viewers who were hostile towards Klimt's contemporary perspective. There was an audience for Klimt's erotic drawings, however, and fifteen of his drawings were selected by Viennese poet Franz Blei for his translation of Hellenistic satirist Lucian's "Dialogues of the Courteseans". The book, limited to 450 copies, provided Klimt the opportunity to show these more lurid depictions of women and avoided censorship thanks to an audience composed of a small group of (mostly male) affluent patrons.

Composed in 1931 by editor Max Eisler and printed by the Austrian State Printing Office, "Gustav Klimt An Aftermath" was intended to complete the lifetime folio "Das Werk Gustav Klimts". The folio contains thirty colored collotypes (fourteen of which are multicolored) and follows a similar format found in "Das Werk Gustav Klimts", replacing the unique Klimt-designed signets with gold-debossed plate numbers. One hundred and fifty sets were produced in English, with twenty of them (Nos. I–XX) presented as a "gala edition" bound in gilt leather. The set contains detailed images from previously released works (Hygeia from the University Mural "Medicine", 1901; a section of the third University Mural "Jurisprudence", 1903), as well as the unfinished paintings ("Adam and Eve", "Bridal Progress").

In 1963, the Albertina museum in Vienna began researching the drawings of Gustav Klimt. The research project "Gustav Klimt. Die Zeichnungen", has since been associated with intensive exhibition and publication activities.

Between 1980 and 1984 Alice Strobl published the three-volume catalogue raisonné, which records and describes all drawings by Gustav Klimt known at the time in chronological order. An additional supplementary volume was published in 1989. In the following year Strobl transferred her work to the art historian and curator Marian Bisanz-Prakken, who had assisted her since 1975 in the determination and classification of the works and who continues the research project to this day. Since 1990, Marian Bisanz-Prakken has redefined, documented, and scientifically processed around 400 further drawings.

This makes the Albertina Vienna the only institution in the world that has been examining and scientifically classifying the artist's works for half a century. The research project now includes information on over 4300 works by Gustav Klimt.

According to the writer Frank Whitford: "Klimt of course, is an important artist—he's a very "popular" artist—but in terms of the history of art, he's a very unimportant artist. Although he sums up so much in his work, about the society in which he found himself—in art historical terms his effect was negligible. So he's an artist really in a cul-de-sac." Klimt's work had a strong influence on the paintings of Egon Schiele, with whom he would collaborate to found the "Kunsthalle" (Hall of Art) in 1917, to try to keep local artists from going abroad. Artists who reinterpreted Klimt's work include Slovak artist Rudolf Fila.

Several of Klimt's most famous works from his golden period inspired the title sequence for the animated adaptation of the manga series, "Elfen Lied", in which the art is recreated to fit with the series' own characters and is arranged as a montage with the song "Lilium". The opening to the anime "Sound of the Sky" also is largely inspired by Klimt's works, which was also directed by the same director as "Elfen Lied". The design of the land of Centopia on the TV series "Mia and Me" is inspired by Klimt's works. The art of the video game "Transistor" also uses patterns and embellishments inspired by Klimt.

Couturier John Galliano found inspiration for the Christian Dior Spring-Summer 2008 haute couture collection in Klimt's work.

Gustav Klimt and his work have been the subjects of many collector coins and medals, such as the 100 Euro Painting Gold Coin, issued on November 5, 2003, by the Austrian Mint. The obverse depicts Klimt in his studio with two unfinished paintings on easels.

In addition to the permanent exhibitions on display, the city of Vienna, Austria celebrated the 150th anniversary of the birth of Klimt with special exhibitions throughout the city. Guided walking tours through the city allowed people to see some of the buildings where Klimt worked.

Google commemorated Gustav Klimt with a Google doodle celebrating Klimt's painting "The Kiss" on his 150th birthday, 14 July 2012.

In 2012, the Austrian Mint began a five-coin gold series to coincide with the 150th anniversary of Klimt's birth. The first 50 Euro gold coin was issued on January 25, 2012 and featured a portrait of Klimt on the obverse and a portion of his painting of Adele Bloch-Bauer. Klimt was also mentioned in season 3 episode 5 of the Netflix original series Bojack Horseman.

In 2013, the Gustav Klimt Foundation was set up by Ursula Ucicky, widow of Klimt's illegitimate son Gustav Ucicky, with a mission to "preserve and disseminate Gustav Klimt's legacy." The managing director of the Leopold Museum, Peter Weinhäupl, was appointed as Chairman of the foundation. As a reaction, the museum's director Tobias G. Natter resigned in protest, citing Ucicky's past as a Nazi propaganda film-maker.

National Public Radio reported on January 17, 2006 that "The Austrian National Gallery is being compelled by a national arbitration board to return five paintings by Gustav Klimt to a Los Angeles based woman, the heir of a Jewish family that had its art stolen by the Nazis. The paintings are estimated to be worth at least $150 million." This incident, involving Maria Altmann, was subsequently made into the Hollywood movie "Woman in Gold", starring Helen Mirren.

The paintings were sold by auction house Christie's for $325 million in 2006.





</doc>
<doc id="12426" url="https://en.wikipedia.org/wiki?curid=12426" title="Groucho Marx">
Groucho Marx

Julius Henry "Groucho" Marx (; October 2, 1890 – August 19, 1977) was an American comedian, actor, writer, stage, film, radio, and television star. He is generally considered to have been a master of quick wit and one of America's greatest comedians.

He made 13 feature films as a team with his siblings the Marx Brothers, of whom he was the third-born. He also had a successful solo career, primarily on radio and television, most notably as the host of the game show "You Bet Your Life".

His distinctive appearance, carried over from his days in vaudeville, included quirks such as an exaggerated stooped posture, spectacles, cigar, a thick greasepaint mustache, and eyebrows. These exaggerated features resulted in the creation of one of the most recognizable and ubiquitous novelty disguises, known as Groucho glasses: a one-piece mask consisting of horn-rimmed glasses, a large plastic nose, bushy eyebrows and mustache.

Julius Henry Marx was born on October 2, 1890, in Manhattan, New York. Marx stated that he was born in a room above a butcher's shop on East 78th Street, "Between Lexington & 3rd", as he told Dick Cavett in a 1969 television interview. The Marx children grew up in a turn-of-the-century building on East 93rd Street off Lexington Avenue in a neighborhood now known as Carnegie Hill on the Upper East Side of the borough of Manhattan. His brother Harpo, in his memoir "Harpo Speaks", called the building "the first real home they ever knew". It was populated with European immigrants, mostly artisans. Just across the street were the oldest brownstones in the area, owned by people such as the well-connected Loew Brothers and William Orth. The Marx family lived there "for about 14 years," Groucho also told Cavett.
Marx's family was Jewish. His mother was Miene "Minnie" Schoenberg, whose family came from Dornum in northern Germany when she was 16 years old. His father was Simon "Sam" Marx, who changed his name from Marrix, and was called "Frenchie" by his sons throughout his life, because he and his family came from Alsace in France. Minnie's brother was Al Schoenberg, who shortened his name to Al Shean when he went into show business as half of Gallagher and Shean, a noted vaudeville act of the early 20th century. According to Marx, when Shean visited, he would throw the local waifs a few coins so that when he knocked at the door he would be surrounded by adoring fans. Marx and his brothers respected his opinions and asked him on several occasions to write some material for them.

Minnie Marx did not have an entertainment industry career but had intense ambition for her sons to go on the stage like their uncle. While pushing her eldest son Leonard (Chico Marx) in piano lessons, she found that Julius had a pleasant soprano voice and the ability to remain on key. Julius's early career goal was to become a doctor, but the family's need for income forced him out of school at the age of twelve. By that time, young Julius had become a voracious reader, particularly fond of Horatio Alger. Marx would continue to overcome his lack of formal education by becoming well-read.

After a few stabs at entry-level office work and jobs suitable for adolescents, Julius took to the stage as a boy singer with the Gene Leroy Trio, debuting at the Ramona Theatre in Grand Rapids, MI, on July 16, 1905. Marx reputedly claimed that he was "hopelessly average" as a vaudevillian, but this was typical Marx, wisecracking in his true form. By 1909, Minnie Marx had assembled her sons into an undistinguished vaudeville singing group billed as "The Four Nightingales". The brothers Julius, Milton (Gummo Marx) and Arthur (originally Adolph, but Harpo Marx from 1911) and another boy singer, Lou Levy, traveled the U.S. vaudeville circuits to little fanfare. After exhausting their prospects in the East, the family moved to La Grange, Illinois, to play the Midwest.
After a particularly dispiriting performance in Nacogdoches, Texas, Julius, Milton, and Arthur began cracking jokes onstage for their own amusement. Much to their surprise, the audience liked them better as comedians than as singers. They modified the then-popular Gus Edwards comedy skit "School Days" and renamed it "Fun In Hi Skule". The Marx Brothers would perform variations on this routine for the next seven years.

For a time in vaudeville, all the brothers performed using ethnic accents. Leonard, the oldest, developed the Italian accent he used as Chico Marx to convince some roving bullies that he was Italian, not Jewish. Arthur, the next oldest, donned a curly red wig and became "Patsy Brannigan", a stereotypical Irish character. His discomfort when speaking on stage led to his uncle Al Shean's suggestion that he stop speaking altogether and play the role in mime. Julius Marx's character from "Fun In Hi Skule" was an ethnic German, so Julius played him with a German accent. After the sinking of the in 1915, public anti-German sentiment was widespread, and Marx's German character was booed, so he quickly dropped the accent and developed the fast-talking wise-guy character that became his trademark.

The Marx Brothers became the biggest comedic stars of the Palace Theatre in New York, which billed itself as the "Valhalla of Vaudeville". Brother Chico's deal-making skills resulted in three hit plays on Broadway. No other comedy routine had ever so infected the Broadway circuit. All of this stage work predated their Hollywood career. By the time the Marxes made their first movie, they were already major stars with sharply honed skills; and by the time Groucho was relaunched to stardom on "You Bet Your Life", he had been performing successfully for half a century.

Marx started his career in vaudeville in 1905 when he joined up with an act called The Leroy Trio. He was asked by a man named Robin Leroy to join the group as a singer, along with fellow vaudeville actor Johnny Morris. Through this act, Marx got his first taste of life as a vaudeville performer. In 1909, Marx and his brothers had become a group act, at first called The Three Nightingales and later The Four Nightingales. The brothers' mother, Minnie Marx, was the group's manager, putting them together and booking their shows. The group had a rocky start, performing in less than adequate venues and rarely, if ever, being paid for their performances. Eventually one of the brothers would leave to serve in World War I and was replaced by Herbert (Zeppo), and the group became known as the Marx Brothers. Their first successful show was "Fun In Hi Skule" (1910).

Marx made 26 movies, 13 of them with his brothers Chico and Harpo. Marx developed a routine as a wisecracking hustler with a distinctive chicken-walking lope, an exaggerated greasepaint mustache and eyebrows, and an ever-present cigar, improvising insults to stuffy dowagers (usually played by Margaret Dumont) and anyone else who stood in his way. As the Marx Brothers, he and his brothers starred in a series of popular stage shows and movies.

Their first movie was a silent film made in 1921 that was never released, and is believed to have been destroyed at the time. A decade later, the team made two of their Broadway hits—"The Cocoanuts" and "Animal Crackers"—into movies. Other successful films were "Monkey Business", "Horse Feathers", "Duck Soup", and "A Night at the Opera". One quip from Marx concerned his response to Sam Wood, the director of "A Night at the Opera". Furious with the Marx Brothers' ad-libs and antics on the set, Wood yelled in disgust: "You can't make an actor out of clay." Marx responded, "Nor a director out of Wood."

Marx also worked as a radio comedian and show host. One of his earliest stints was a short-lived series in 1932, "Flywheel, Shyster, and Flywheel," costarring Chico. Though most of the scripts and discs were thought to have been destroyed, all but one of the scripts were found in 1988 in the Library of Congress.
In 1947, Marx was asked to host a radio quiz program "You Bet Your Life." It was broadcast by ABC and then CBS before moving to NBC. It moved from radio to television on October 5, 1950, and ran for eleven years. Filmed before an audience, the show consisted of Marx bantering with the contestants and ad-libbing jokes before briefly quizzing them. The show was responsible for popularizing the phrases "Say the secret word and the duck will come down and give you fifty dollars," "Who's buried in Grant's Tomb?" and "What color is the White House?" (asked to reward a losing contestant a consolation prize).

Throughout his career, Marx introduced a number of memorable songs in films, including "Hooray for Captain Spaulding" and "Hello, I Must Be Going", in "Animal Crackers", "Whatever It Is, I'm Against It", "Everyone Says I Love You" and "Lydia the Tattooed Lady". Frank Sinatra, who once quipped that the only thing he could do better than Marx was sing, made a film with Marx and Jane Russell in 1951 entitled "Double Dynamite".

In public and off-camera, Harpo and Chico were hard to recognize, without their wigs and costumes, and it was almost impossible for fans to recognize Groucho without his trademark eyeglasses, fake eyebrows, and mustache.
The greasepaint mustache and eyebrows originated spontaneously prior to a vaudeville performance in the early 1920s when he did not have time to apply the pasted-on mustache he had been using (or, according to his autobiography, simply did not enjoy the removal of the mustache because of the effects of tearing an adhesive bandage off the same patch of skin every night). After applying the greasepaint mustache, a quick glance in the mirror revealed his natural hair eyebrows were too undertoned and did not match the rest of his face, so Marx added the greasepaint to his eyebrows and headed for the stage. The absurdity of the greasepaint was never discussed on-screen, but in a famous scene in "Duck Soup," where both Chicolini (Chico) and Pinky (Harpo) disguise themselves as Groucho, they are briefly seen applying the greasepaint, implicitly answering any question a viewer might have had about where he got his mustache and eyebrows.

Marx was asked to apply the greasepaint mustache once more for "You Bet Your Life" when it came to television, but he refused, opting instead to grow a real one, which he wore for the rest of his life. By this time, his eyesight had weakened enough for him to actually need corrective lenses; before then, his eyeglasses had merely been a stage prop. He debuted this new, and now much-older, appearance in "Love Happy," the Marx Brothers's last film as a comedy team.

He did paint the old character mustache over his real one on a few rare occasions, including a TV sketch with Jackie Gleason on the latter's variety show in the 1960s (in which they performed a variation on the song "Mister Gallagher and Mister Shean," co-written by Marx's uncle Al Shean) and the 1968 Otto Preminger film "Skidoo". In his late 70s at the time, Marx remarked on his appearance: "I looked like I was embalmed." He played a mob boss called "God" and, according to Marx, "both my performance and the film were God-awful!"

The exaggerated walk, with one hand on the small of his back and his torso bent almost 90 degrees at the waist was a parody of a fad from the 1880s and 1890s. Fashionable young men of the upper classes would affect a walk with their right hand held fast to the base of their spines, and with a slight lean forward at the waist and a very slight twist toward the right with the left shoulder, allowing the left hand to swing free with the gait. Edmund Morris, in his biography "The Rise of Theodore Roosevelt", describes a young Roosevelt, newly elected to the State Assembly, walking into the House Chamber for the first time in this trendy, affected gait, somewhat to the amusement of the older and more rural members. Marx exaggerated this fad to a marked degree, and the comedy effect was enhanced by how out of date the fashion was by the 1940s and 1950s.

Marx's three marriages ended in divorce. His first wife was chorus girl Ruth Johnson (m. 1920-1942). He was 29 and she was 19 at the time of their wedding. The couple had two children, Arthur Marx and Miriam Marx. His second wife was Kay Marvis (m. 1945–1951), Catherine Dittig, former wife of Leo Gorcey. Marx was 54 and Kay was 21 at the time of their marriage. They had a daughter, Melinda Marx. His third wife was actress Eden Hartford (m. 1954-1969). He was 64 and she was 24 at the time of their wedding.

During the early 1950s, Marx described his perfect woman: "Someone who looks like Marilyn Monroe and talks like George S. Kaufman."

Marx was denied membership in an informal symphonietta of friends (including Harpo) organized by Ben Hecht, because he could play only the mandolin. When the group began its first rehearsal at Hecht's home, Marx rushed in and demanded silence from the "lousy amateurs". The musicians discovered him conducting the Los Angeles Symphony Orchestra in a performance of the overture to "Tannhäuser" in Hecht's living room. Marx was allowed to join the symphonietta.

Later in life, Marx would sometimes note to talk show hosts, not entirely jokingly, that he was unable to actually insult anyone, because the target of his comment would assume that it was a Groucho-esque joke, and would laugh.
Despite his lack of formal education, he wrote many books, including his autobiography, "Groucho and Me" (1959) and "Memoirs of a Mangy Lover" (1963). He was a friend of such literary figures as Booth Tarkington, T. S. Eliot and Carl Sandburg. Much of his personal correspondence with those and other figures is featured in the book "The Groucho Letters" (1967) with an introduction and commentary on the letters written by Marx, who donated his letters to the Library of Congress. His daughter Miriam published a collection of his letters to her in 1992 titled "Love, Groucho."

Marx made serious efforts to learn to play the guitar. In the 1932 film "Horse Feathers", he performs the film's love theme "Everyone Says I Love You" for costar Thelma Todd on a Gibson L-5.

In July 1937, an America vs England pro-celebrity tennis doubles match was organized, featuring Marx and Ellsworth Vines playing against Charlie Chaplin and Fred Perry, to open the new clubhouse at the Beverly Hills Tennis Club. Marx appeared on court with 12 rackets and a suitcase, leaving Chaplin – who took tennis seriously – bemused, before he asked what was in it. Marx asked Chaplin what was in his, with Chaplin responding he didn't have one. Marx replied, "What kind of tennis player are you?" After playing only a few games, Marx sat on the court and unpacked an elaborate picnic lunch from his suitcase.

Irving Berlin quipped, "The world would not be in such a snarl, had Marx been Groucho instead of Karl". In his book "The Groucho Phile", Marx says "I've been a liberal Democrat all my life", and "I frankly find Democrats a better, more sympathetic crowd... I'll continue to believe that Democrats have a greater regard for the common man than Republicans do". However, just like some of the other Democrats of the time, Marx also said in a television interview that he disliked the women's liberation movement. On the July 7, 1967, "Firing Line" TV show, Marx said, "The whole political left is the Garden of Eden of incompetence."

Marx's radio career was not as successful as his work on stage and in film, though historians such as Gerald Nachman and Michael Barson suggest that, in the case of the single-season "Flywheel, Shyster, and Flywheel" (1932), the failure may have been a combination of a poor time slot and the Marx Brothers' returning to Hollywood to make another film.
In the mid-1940s, during a depressing lull in his career (his radio show "Blue Ribbon Town" had failed, he failed to sell his proposed sitcom "The Flotsam Family" only to see it become a huge hit as "The Life of Riley" with William Bendix in the title role, and the Marx Brothers as film performers were well past their prime), Marx was scheduled to appear on a radio show with Bob Hope. Annoyed that he was made to wait in the green room for 40 minutes, he went on the air in a foul mood.

Hope started by saying "Why, Groucho Marx! Groucho, what are you doing out here in the desert?" Marx retorted, "Huh, desert, I've been sitting in the dressing room for forty minutes! Some desert alright..." Marx continued to ignore the script, ad-libbing at length and took it well beyond its allotted time slot.

Listening in on the show was producer John Guedel, who had a brainstorm. He approached Marx about doing a quiz show, to which Marx derisively retorted, "A quiz show? Only actors who are completely washed up resort to a quiz show!" Undeterred, Guedel proposed that the quiz would be only a backdrop for Marx's interviews of people, and the storm of ad-libbing that they would elicit. Marx replied, "Well, I've had no success in radio, and I can't hold on to a sponsor. At this point, I'll try anything!"

"You Bet Your Life" debuted in October 1947 on ABC radio (which aired it from 1947 to 1949), sponsored by costume jewelry manufacturer Allen Gellman; and then on CBS (1949–50), and finally NBC. The show was on radio only from 1947 to 1950; on both radio and television from 1950 to 1960; and on television only, from 1960 to 1961. The show proved a huge hit, being one of the most popular on television by the mid-1950s. With George Fenneman as his announcer and straight man, Marx entertained his audiences with improvised conversation with his guests. Since "You Bet Your Life" was mostly ad-libbed and unscripted—although writers did pre-interview the guests and feed Marx ready-made lines in advance—the producers insisted that the network prerecord it instead of it being broadcast live. There were two reasons for this: prerecording provided Marx with time to fish around for funny exchanges and any intervening dead spots to be edited out; and secondly to protect the network, since Marx was a notorious loose cannon and known to say almost anything. The television show ran for 11 seasons until it was canceled in 1961. Automobile "marque" DeSoto was a longtime major sponsor. For the DeSoto ads, Marx would sometimes say: "Tell 'em Groucho sent you", or "Try a DeSoto before you decide".

The program's theme music was an instrumental version of "Hooray for Captain Spaulding", which became increasingly identified as Marx's personal theme song. A recording of the song with Marx and the Ken Lane singers with an orchestra directed by Victor Young was released in 1952. Another recording made by Marx during this period was "The Funniest Song in the World", released on the Young People's Records label in 1949. It was a series of five original children's songs with a connecting narrative about a monkey and his fellow zoo creatures.

An apocryphal story relates Marx interviewing Charlotte Story, who had borne 20 children. When Marx asked why she had chosen to raise such a large family, Mrs. Story is said to have replied, "I love my husband"; to which Marx responded, "I love my cigar, but I take it out of my mouth once in a while." The remark was judged too risqué to be aired, according to the anecdote, and was edited out before broadcast. Charlotte Story and her husband Marion, indeed parents of 20 children, were real people who appeared on the program in 1950. Audio recordings of the interview exist, and a reference to cigars is made ("With each new kid, do you go around passing out cigars?"), but there is no evidence of the claimed remark. Marx and Fenneman both denied that the incident took place. "I get credit all the time for things I never said," Marx told Roger Ebert in 1972. "You know that line in "You Bet Your Life"? The guy says he has seventeen kids and I say, 'I smoke a cigar, but I take it out of my mouth occasionally'? I never said that." Marx's 1976 memoir recounts the episode as fact, but co-writer Hector Arce relied mostly on sources other than Marx himself—who was by then in his mid eighties, in ill health and mentally compromised—and was probably unaware that Marx had specifically denied making the observation.
Another anecdote that may or may not be apocryphal recounts how Warner Brothers threatened to sue Groucho when they learned that the next Marx Brothers film was to be called "A Night in Casablanca", contending that that title was too similar to their own film Casablanca. Groucho is reported to have replied: "I'll sue you for using the word Brothers."

By the time "You Bet Your Life" debuted on TV on October 5, 1950, Marx had grown a real mustache (which he had already sported earlier in the films "Copacabana" and "Love Happy").

During a tour of Germany in 1958, accompanied by then-wife Eden, daughter Melinda, Robert Dwan and Dwan's daughter Judith, he climbed a pile of rubble that marked the site of Adolf Hitler's bunker, the site of Hitler's death, and performed a two-minute Charleston. He later remarked to Richard J. Anobile in "The Marx Brothers Scrapbook," "Not much satisfaction after he killed six million Jews!"
In 1960, Marx, a lifelong devotee of the comic operas of Gilbert and Sullivan, appeared as Ko-Ko, the Lord High Executioner, in a televised production of "The Mikado" on NBC's "Bell Telephone Hour". A clip of this is in rotation on Classic Arts Showcase.

Another TV show, "Tell It To Groucho", premiered January 11, 1962, on CBS, but only lasted five months. On October 1, 1962, Marx, after acting as occasional guest host of "The Tonight Show" during the six-month interval between Jack Paar and Johnny Carson, introduced Carson as the new host.

In 1964, Marx starred in the "Time for Elizabeth" episode of "Bob Hope Presents the Chrysler Theatre", a truncated version of a play that he and Norman Krasna wrote in 1948.

In 1965, Marx starred in a weekly show for British TV titled "Groucho", broadcast on ITV. The program was along similar lines to "You Bet Your Life", with Keith Fordyce taking on the Fenneman role. However, it was poorly received and lasted only 11 weeks.

Marx appeared as a gangster named God in the movie "Skidoo" (1968), directed by Otto Preminger, and costarring Jackie Gleason and Carol Channing. It was released by the studio where the Marx Brothers began their film career, Paramount Pictures. The film received almost universally negative reviews. As a side note, writer Paul Krassner published a story in the February 1981 issue of "High Times", relating how Marx prepared for the LSD-themed movie by taking a dose of the drug in Krassner's company, and had a moving, largely pleasant experience.

Marx developed friendships with rock star Alice Cooper—the two were photographed together for "Rolling Stone" magazine—and television host Dick Cavett, becoming a frequent guest on Cavett's late-night talk show, even appearing in a one-man, 90-minute interview. He befriended Elton John when the British singer was staying in California in 1972, insisting on calling him "John Elton." According to writer Philip Norman, when Marx jokingly pointed his index fingers as if holding a pair of six-shooters, Elton John put up his hands and said, "Don't shoot me, I'm only the piano player," thereby naming the album he had just completed. A film poster for the Marx Bros. movie "Go West" is visible on the album cover photograph as an homage to Marx. Elton John accompanied Marx to a performance of "Jesus Christ Superstar". As the lights went down, Marx called out, "Does it have a happy ending?" And during the Crucifixion scene, he declared, "This is sure to offend the Jews."

Marx's previous work regained popularity; new books of transcribed conversations were published by Richard J. Anobile and Charlotte Chandler. In a BBC interview in 1975, Marx called his greatest achievement having a book selected for cultural preservation in the Library of Congress. In a Cavett interview in 1971, Marx said being published in The New Yorker under his own name, Julius Henry Marx, meant more than all the plays he appeared in. As a man who never had formal schooling, to have his writings declared culturally important was a point of great satisfaction. As he passed his 81st birthday in 1971, however, Marx became increasingly frail, physically and mentally, as a result of a succession of minor strokes and other health issues.

In 1972, largely at the behest of his companion Erin Fleming, Marx staged a live one-man show at Carnegie Hall that was later released as a double album, "An Evening with Groucho", on A&M Records. He also made an appearance in 1973 on a short-lived variety show hosted by Bill Cosby. Fleming's influence on Marx was controversial. Some close to Marx believed that she did much to revive his popularity, and the relationship with a younger woman boosted his ego and vitality. Others described her as a Svengali, exploiting an increasingly senile Marx in pursuit of her own stardom. Marx's children, particularly Arthur, felt strongly that Fleming was pushing their weak father beyond his physical and mental limits. Writer Mark Evanier concurred.

On the 1974 Academy Awards telecast, Marx's final major public appearance, Jack Lemmon presented him with an honorary Academy Award to a standing ovation. The award honored Harpo, Chico, and Zeppo as well: "in recognition of his brilliant creativity and for the unequalled achievements of the Marx Brothers in the art of motion picture comedy." Noticeably frail, Marx took a bow for his deceased brothers. "I wish that Harpo and Chico could be here to share with me this great honor," he said, naming the two deceased brothers (Zeppo, still alive, was in the audience). He also praised the late Margaret Dumont as a great straight woman who never understood any of his jokes. Marx's final appearance was a brief sketch with George Burns in the Bob Hope television special "Joys" (a parody of the 1975 movie "Jaws") in March 1976. His health continued to decline the following year; when his younger brother Gummo died at age 83 on April 21, 1977, Marx was never told for fear of eliciting still further deterioration of his health.

Marx maintained his irrepressible sense of humor to the very end, however. George Fenneman, his radio and TV announcer, good-natured foil, and lifelong friend, often related a story of one of his final visits to Marx's home: When the time came to end the visit, Fenneman lifted Marx from his wheelchair, put his arms around his torso, and began to "walk" the frail comedian backwards across the room towards his bed. As he did, he heard a weak voice in his ear: "Fenneman," whispered Marx, "you always were a lousy dancer." When a nurse approached him with a thermometer during his final hospitalization, explaining that she wanted to see if he had a temperature, he responded, "Don't be silly — everybody has a temperature." Actor Elliott Gould recalled a similar incident: "I recall the last time I saw Groucho, he was in the hospital, and he had tubes in his nose and what have you," he said. "And when he saw me, he was weak, but he was there; and he put his fingers on the tubes and played them like it was a clarinet. Groucho played the tubes for me, which brings me to tears."

Marx was hospitalized at Cedars-Sinai Medical Center with pneumonia on June 22, 1977, and died there nearly two months later at the age of 86 on August 19, four months after Gummo's death.

Marx was cremated and the ashes are interred in the Eden Memorial Park Cemetery in Los Angeles. He was survived by his three children and younger brother Zeppo, who outlived him by two years. His gravestone bears no epitaph, but in one of his last interviews he suggested one: "Excuse me, I can't stand up."

Litigation over his estate lasted into the 1980s. Eventually, Arthur Marx and his sisters were awarded the bulk of the estate, and Erin Fleming was ordered to repay $472,000.

Groucho Marx was considered the most recognizable of the Marx Brothers. Groucho-like characters and references have appeared in popular culture both during and after his life, some aimed at audiences who may never have seen a Marx Brothers movie. Marx's trademark eyeglasses, nose, mustache, and cigar have become icons of comedy—glasses with fake noses and mustaches (referred to as "Groucho glasses", "nose-glasses," and other names) are sold by novelty and costume shops around the world.

The cover of The Firesign Theatre's 1969 album, "How Can You Be in Two Places at Once When You're Not Anywhere at All", subtitled "All Hail Marx and Lennon" feature images of Groucho Marx and John Lennon.

Nat Perrin, close friend of Groucho Marx and writer of several Marx Brothers films, inspired John Astin's portrayal of Gomez Addams on the 1960s TV series "The Addams Family" with similarly thick mustache, eyebrows, sardonic remarks, backward logic, and ever-present cigar (pulled from his breast pocket already lit).
In 1972, at Cannes, he was made a Commander in the French Ordre des Arts et des Lettres. An honour he was very proud of.

A meeting with Elton John led to a press photo of Marx pointing both of his index fingers and thumbs at Elton like revolvers. John's spontaneous response of holding up his hands and replying, "Don't shoot me! I'm only the piano player!" was so amusing that Elton John reused it as the title of a 1973 album. An added Marx homage was that a poster for the Marx Brothers' movie "Go West" was included on the cover art.

Marx was also known to influence the Warner Bros. cartoon character Bugs Bunny, who would recite his famous line "Of course you realize this means war!" in two of his cartoons in the "Looney Tunes" series, "Long Haired Hare" and "Bully for Bugs", when his antagonist has offended him.

Two albums by British rock band Queen, "A Night at the Opera" (1975) and "A Day at the Races" (1976), are named after Marx Brothers films. In March 1977, Marx invited Queen to visit him in his Los Angeles home; there they performed "'39" a cappella.

A long-running ad campaign for Vlasic Pickles features an animated stork that imitates Marx's mannerisms and voice. On the famous Hollywood Sign in California, one of the "O"s is dedicated to Marx. Alice Cooper contributed over $27,000 to remodel the sign, in memory of his friend.

Actor Frank Ferrante has performed as Groucho Marx on stage since 1986. He continues to tour under rights granted by the Marx family in a show entitled "An Evening with Groucho" in theaters throughout the United States and Canada with supporting actors and piano accompanist Jim Furmston. In the late 1980s, Ferrante starred as Marx in the off-Broadway and London show "" penned by Marx's son Arthur. Ferrante portrayed the comedian from age 15 to 85. The show was later filmed for PBS in 2001. In 1982, Gabe Kaplan filmed a version of the same show, entitled "Groucho".

In the Hungarian dubbed version of Woody Allen's film "Annie Hall", a famous quotation told by Alvy Singer (Allen) at the beginning of the film is not attributed to Groucho Marx as in the original, but to Buster Keaton. The reason was that in communist Hungary, the name 'Marx' was associated with Karl Marx and it was not allowed to use it in such a light, humorous context.

Woody Allen's 1996 musical "Everyone Says I Love You", in addition to being named for one of Marx's signature songs, ends with a Groucho-themed New Year's Eve party in Paris, which some of the stars, including Allen and Goldie Hawn, attend in full Groucho costume. The highlight of the scene is an ensemble song-and-dance performance of "Hooray for Captain Spaulding"—done entirely in French.

On June 25, 2019, "The New York Times Magazine" listed Marx among hundreds of artists whose material was reportedly destroyed in the 2008 Universal fire.

Groucho, a supporting character in the Italian horror comics series "Dylan Dog", is a Groucho Marx impersonator whose character became his permanent personality, and he works with Dylan Dog as his professional sidekick. In the English-language version, to avoid legal complications regarding Groucho Marx's estate, the art was altered so that Groucho no longer sports the Marx brother's signature moustache, and was renamed "Felix".







</doc>
<doc id="12430" url="https://en.wikipedia.org/wiki?curid=12430" title="Game Boy Advance">
Game Boy Advance

The (GBA) is a 32-bit handheld game console developed, manufactured and marketed by Nintendo as the successor to the Game Boy Color. It was released in Japan on March 21, 2001, in North America on June 11, 2001, in Australia and Europe on June 22, 2001, and in mainland China on June 8, 2004 as iQue Game Boy Advance. The GBA is part of the sixth generation of video game consoles. The original model does not have an illuminated screen; Nintendo addressed that with the release of a redesigned model with a frontlit screen, the Game Boy Advance SP, in 2003. A newer revision of the redesign was released in 2005, with a backlit screen. The final redesign, the Game Boy Micro, was released in 2005.

As of June 30, 2010, 81.51 million units of the Game Boy Advance series have been sold worldwide. Its successor, the Nintendo DS, was released in November 2004 and is also compatible with Game Boy Advance software.

Contrary to the previous Game Boy models, which have the "portrait" form factor of the original Game Boy (designed by Gunpei Yokoi), the Game Boy Advance was designed in a "landscape" form factor, putting the buttons to the sides of the device instead of below the screen. The Game Boy Advance was designed by the French designer Gwénaël Nicolas and his Tokyo-based design studio Curiosity Inc.

News of a successor to the Game Boy Color (GBC) first emerged at the Nintendo Space World trade show in late August 1999, where it was reported that two new handheld systems were in development. An improved version of the GBC with wireless online connectivity was codenamed the Advanced Game Boy (AGB), and a brand-new 32-bit system was not set for release until the following year. On September 1, 1999, Nintendo officially announced the Game Boy Advance, revealing details about the system's specifications including online connectivity through a cellular device and an improved model of the Game Boy Camera. Nintendo teased that the handheld would first be released in Japan in August 2000, with the North American and European launch dates slated for the end of the same year. Simultaneously, Nintendo announced a partnership with Konami to form Mobile 21, a development studio that would focus on creating technology for the GBA to interact with the GameCube, Nintendo's home console which was also in development at the time under the name "Dolphin". On August 21, 2000, IGN showed off images of a GBA development kit running a demonstrational port of "Yoshi Story", and on August 22, pre-production images of the GBA were revealed in an issue of "Famitsu" magazine in Japan. On August 24, Nintendo officially revealed the console to the public in a presentation, revealing the Japanese and North American launch dates, in addition to revealing that 10 games would be available as launch games for the system. The GBA was then featured at Nintendo Space World 2000 from August 24 to 26 alongside several peripherals for the system, including the GBA Link cable, the GameCube - Game Boy Advance link cable, a rechargeable battery pack for the system, and an infrared communications adaptor which would allow systems to exchange data. In March 2001, Nintendo revealed details about the system's North American launch, including the suggested price of $99.99 and the 15 launch games. Nintendo estimated that around 60 games would be made available for the system by the end of 2001.

In 1996, magazines including "Electronic Gaming Monthly", "Next Generation", issues 53 and 54 of "Total!" and the July 1996 issue of "Game Informer" featured reports of a new Game Boy, codenamed Project Atlantis. Although Nintendo's expectations of releasing the system in at least one territory by the end of 1996 would make that machine seem to be the Game Boy Color, it was described as having a 32-bit RISC processor, a 3-by-2-inch color LCD screen, and a link port—a description that more closely matches the Game Boy Advance. It also may have referred to the unnamed, unreleased Game Boy Color successor prototype that was revealed at 2009's Game Developers Conference. It was announced that Nintendo of Japan was working on a game for the system called "Mario's Castle", ultimately unreleased. Nintendo suspended the project in 1997, since the original Game Boy's 80% of the handheld market share was too high to merit the release of a successor.

The technical specifications of the original Game Boy Advance are, as provided by Nintendo:

Backward compatibility for Game Boy and Game Boy Color games is provided by a custom 4.194/8.388 MHz 8080-based coprocessor (Game Boy Advance software can use the audio tone generators to supplement the primary sound system), while a link port at the top of the unit allows it to be connected to other devices using a Game Link cable or GameCube link cable. When playing Game Boy or Game Boy Color games on the Game Boy Advance, the L and R buttons can be used to toggle between a stretched widescreen format and the original screen ratio of the Game Boy . Game Boy games can be played using the same selectable color palettes as on the Game Boy Color. Every Nintendo handheld system following the release of the Game Boy Advance SP has included a built-in light and rechargeable battery.

The Game Boy Advance 2D graphics hardware has scaling and rotation for traditional tiled backgrounds in its modes 1 and 2 and scaling and rotation for bitmaps in modes 3 through 5 (used less often on the GBA because of technical limitations). On each machine supporting this effect, it is possible to change the scaling and rotation values during the horizontal blanking period of each scanline to draw a flat plane in a perspective projection. More complex effects such as fuzz are possible by using other equations for the position, scaling, and rotation of each line. The "character mode" supports up to 4 tile map background layers per frame, with each tile being 8x8 pixels in size and having 16 or 256 colors. The "character mode" also supports up to 128 hardware sprites per frame, with any sprite size from 8x8 to 64x64 pixels and with 16 or 256 colors per sprite.

The Game Boy Advance has been available in numerous colors and limited editions throughout its production. It was initially available in Arctic, Black, Orange, Fuchsia (translucent pink), Glacier (translucent blue/purple) and Indigo. Later in the system's availability, additional colors and special editions were released, including: Red, Clear Orange/Black, Platinum, White, Gold, Hello Kitty edition (pink with Hello Kitty and logo on bezel), "The King of Fighters" edition (black with images on bezel and buttons), "Chobits" edition (translucent light blue, with images on bezel and buttons), "Battle Network Rockman EXE 2" (light blue with images on bezel), "Mario Bros." edition (Glacier with Mario and Luigi on bezel) and Yomiuri Giants edition (Glacier with images on bezel).

A number of "Pokémon"-themed limited-edition systems were made available in Pokémon Center stores in Japan. These editions include: Gold Pokémon edition (Gold with Pikachu and Pichu on bezel), Suicune edition (blue/grey with greyscale Pikachu and Pichu on bezel, and a Pokémon Center sticker on the back), Celebi edition (olive green with Celebi images on bezel), and Latias/Latios edition (pink/red and purple, with images of Latias and Latios on bezel).

With hardware performance comparable to the Super Nintendo Entertainment System, the Game Boy Advance represents progress for sprite-based technology. The system's library includes platformers, SNES-like role-playing video games, and games ported from various 8-bit and 16-bit systems of the previous generations. This includes the "Super Mario Advance" series, as well as the system's backward compatibility with all earlier Game Boy titles. While most GBA games employ 2D graphics, developers have ambitiously designed some 3D GBA games that push the limits of the hardware, including first-person shooters like a port of "Doom" and racing games like "GT Advance Championship Racing".

In Japan, the final game to have been released on the system is "Final Fantasy VI Advance" on November 30, 2006, which is also the final game published by Nintendo on the system. In North America, the last game for the system is "Samurai Deeper Kyo", released on February 12, 2008. Lastly, in Europe, "2 Games in 1: Columns Crown & ChuChu Rocket!" is the last game for the system (and also the last one released on the system overall), released on November 28, 2008. The Japan-only "Rhythm Tengoku", the first game in what would eventually become known outside Japan as the "Rhythm Heaven"/"Rhythm Paradise" series, is the final first-party-developed game for the system, released on August 3, 2006.

An accessory for the GameCube, known as the Game Boy Player, was released in 2003 as the successor to the Super Game Boy peripheral for the Super Nintendo Entertainment System. The accessory allows Game Boy Advance games, as well as Game Boy and Game Boy Color games, to be played on the GameCube. However, some games may have compatibility issues due to certain features requiring extra hardware. For example, games with built-in motion sensors (such as "Yoshi's Topsy-Turvy") would require players to manipulate the console itself.

The GBA is the last of the three Nintendo handheld systems to bear the Game Boy name, games developed for it are incompatible with older Game Boy systems, and each game's box carries a label indicating that the game is "not compatible with other Game Boy systems". However, games designed for older Game Boy systems are conversely compatible with the Game Boy Advance, with options to play such games on either their standard aspect ratios or a stretched fullscreen.

Game Boy Advance games are compatible with Nintendo DS models that support them with a dedicated GBA cartridge slot beneath the touch screen, (specifically the original model and the Nintendo DS Lite), although they cannot support multiplayer or features involving the use of GBA accessories because they do not have the GBA's external peripheral port that these features require to function. The Nintendo DSi and Nintendo DSi XL do not have backward compatibility with the GBA.

As part of an Ambassador Program for early adopters of the Nintendo 3DS system, ten Game Boy Advance games were made available free for players who bought a system before August 2011. Unlike other Virtual Console games for the system, features such as the Home menu or save states are missing, since the games are running natively instead of in emulation. 3DS systems that have custom firmware installed can also install the ten available games available to Ambassador Program members. Many other Game Boy Advance games can also be played via custom firmware by injecting a different game into one of the released Game Boy Advance games. Satoru Iwata stated Game Boy Advance games will be available on the Wii U Virtual Console sometime during April 2014. On April 3, 2014, the first of the announced GBA games, "Advance Wars", "Metroid Fusion", and "", were released for the Wii U Virtual Console. A Virtual Console library of Game Boy Advance games was launched for the Wii U console. All of the Virtual Console releases are single player only, as they do not emulate multiplayer features enabled by Game Link cables.

Nintendo released various addons for the Game Boy Advance, which include:

Other accessories for the Game Boy Advance include:

In early 2003, Nintendo introduced a new form-factor for the handheld, known as the Game Boy Advance SP (model AGS-001). The redesigned unit resembles a pocket-size laptop computer, including a folding case approximately one-half the size of the original unit. It also supports a rechargeable lithium-ion battery, a significantly brighter LCD screen, and an internal front-light that can be toggled on and off. The redesign was intended to address some common complaints about the original Game Boy Advance, which had been criticized for being somewhat uncomfortable to use, especially due to an overly dark screen.

Around the same time as the release of the Game Boy Micro, Nintendo released a new backlit version of the SP (model AGS-101). The switch that controls the light now toggles between "normal" (which itself is already brighter than the original Game Boy Advance SP's screen), and "bright", an intense brightness level similar to an LCD television.

In September 2005, Nintendo released a second redesign of the Game Boy Advance. This model, dubbed the Game Boy Micro, is similar in style to the original Game Boy Advance's horizontal orientation, but is much smaller and sleeker. The Game Boy Micro also allows the user to switch between several colored faceplates to allow customization, a feature which Nintendo advertised heavily around the Game Boy Micro's launch. Nintendo also hoped that this "fashion" feature would help target audiences outside of typical video game players. Unlike the previous Game Boy Advance models, the Game Boy Micro is unable to support Game Boy and Game Boy Color titles. The Game Boy Micro did not make much of an impact in the video game market as it was overshadowed by Nintendo's other portable, the Nintendo DS, which also played Game Boy Advance cartridges.

Upon its North American release, IGN praised the Game Boy Advance's graphical capabilities and battery life, but criticized the system's shoulder button placement and noted the system's high price tag which "may be a tad bit too high to swallow," ultimately scoring the system with in "8.0" out of 10. They also pointed out the system's lack of a backlight which occasionally got in the way of playing games.
ABC News praised the Game Boy Advance's graphics, grip and larger screen, stating that "You've never had as much fun playing old games."

Reviewing for CNET, Darren Gladstone scored the system with a 7.0 out of 10, praising its graphical performance and backwards compatibility, but being considerably critical of the system's lack of a backlit screen, noting that it makes it "nearly impossible" to play in normal lighting conditions. Gladstone ultimately suggested the sleeker and backlit Game Boy Advance SP over the system despite noting that its cheaper price may "appeal to gamers on a lower budget."

Nintendo hoped to sell 1.1 million Game Boy Advance units by the end of March with the system's Japanese debut, and anticipated sales of 24 million units before the end of 2001; many marketing analysts believed for this to be a realistic goal due to the company's lack of major competition in the handheld video game market. Within the first week of its North American launch in June, the Game Boy Advance sold 500,000 units, making it the fastest-selling video game console in the United States at the time. In response to strong sales, Nintendo ordered 100,000 units to ship to retail stores, hoping to ship another half million of them by the end of June. The Game Boy Advance also became the fastest-selling system in the United Kingdom, selling 81,000 units in its first week of release and beating the PlayStation 2's previous record of 20,000 units. In 2004, the system's sales in the United Kingdom surpassed one million units.

On December 1, 2006, Nintendo of America released launch-to-date information indicating that the company had sold 33.6 million units of the Game Boy Advance series in the United States. In a Kotaku article published on January 18, 2008, Nintendo revealed that the Game Boy Advance series had sold 36.2 million units in the United States, as of January 1, 2008. As of December 31, 2009, the Game Boy Advance series has sold 81.51 million units worldwide, 43.57 million of which are Game Boy Advance SP units and 2.42 million of which are Game Boy Micro units.

After the Game Boy Advance's support lessened, the most popular software became mostly games oriented to younger gamers.




</doc>
<doc id="12431" url="https://en.wikipedia.org/wiki?curid=12431" title="Google Search">
Google Search

Google Search, or simply Google, is a web search engine developed by Google LLC. It is the most used search engine on the World Wide Web across all platforms, with 92.62% market share as of June 2019, handling more than 5.4 billion searches each day.

The order of search results returned by Google is based, in part, on a priority rank system called "PageRank". Google Search also provides many different options for customized search, using symbols to include, exclude, specify or require certain search behavior, and offers specialized interactive experiences, such as flight status and package tracking, weather forecasts, currency, unit, and time conversions, word definitions, and more.

The main purpose of Google Search is to search for text in publicly accessible documents offered by web servers, as opposed to other data, such as images or data contained in databases. It was originally developed in 1997 by Larry Page, Sergey Brin, and Scott Hassan. In June 2011, Google introduced "Google Voice Search" to search for spoken, rather than typed, words. In May 2012, Google introduced a Knowledge Graph semantic search feature in the U.S.

Analysis of the frequency of search terms may indicate economic, social and health trends. Data about the frequency of use of search terms on Google can be openly inquired via Google Trends and have been shown to correlate with flu outbreaks and unemployment levels, and provide the information faster than traditional reporting methods and surveys. As of mid-2016, Google's search engine has begun to rely on deep neural networks.

Competitors of Google include Baidu and Soso.com in China; Naver.com and Daum.net in South Korea; Yandex in Russia; Seznam.cz in the Czech Republic; Qwant in France; Yahoo in Japan, Taiwan and the US, as well as Bing and DuckDuckGo. Some smaller search engines offer facilities not available with Google, e.g. not storing any private or tracking information.

Within the U.S., as of July 2018, Bing handled 24.2 percent of all search queries. During the same period, Oath (formerly known as Yahoo) had a search market share of 11.5 percent. Market leader Google generated 63.2 percent of all core search queries in the U.S.

Google indexes hundreds of terabytes of information from web pages. For websites that are currently down or otherwise not available, Google provides links to cached versions of the site, formed by the search engine's latest indexing of that page. Additionally, Google indexes some file types, being able to show users PDFs, Word documents, Excel spreadsheets, PowerPoint presentations, certain Flash multimedia content, and plain text files. Users can also activate "SafeSearch", a filtering technology aimed at preventing explicit and pornographic content from appearing in search results.

Despite Google search's immense index, sources generally assume that Google is only indexing less than 5% of the total Internet, with the rest belonging to the deep web, inaccessible through its search tools.

In 2012, Google changed its search indexing tools to demote sites that had been accused of piracy. In October 2016, Gary Illyes, a webmaster trends analyst with Google, announced that the search engine would be making a separate, primary web index dedicated for mobile devices, with a secondary, less up-to-date index for desktop use. The change was a response to the continued growth in mobile usage, and a push for web developers to adopt a mobile-friendly version of their websites. In December 2017, Google began rolling out the change, having already done so for multiple websites.

In August 2009, Google invited web developers to test a new search architecture, codenamed "Caffeine", and give their feedback. The new architecture provided no visual differences in the user interface, but added significant speed improvements and a new "under-the-hood" indexing infrastructure. The move was interpreted in some quarters as a response to Microsoft's recent release of an upgraded version of its own search service, renamed Bing, as well as the launch of Wolfram Alpha, a new search engine based on "computational knowledge". Google announced completion of "Caffeine" on June 8, 2010, claiming 50% fresher results due to continuous updating of its index.

With "Caffeine", Google moved its back-end indexing system away from MapReduce and onto Bigtable, the company's distributed database platform.

In August 2018, Danny Sullivan from Google announced a broad core algorithm update. As per current analysis done by the industry leaders Search Engine Watch and Search Engine Land, the update was to drop down the medical and health-related websites that were not user friendly and were not providing good user experience. This is why the industry experts named it "Medic".

Google reserves very high standards for YMYL (Your Money or Your Life) pages. This is because misinformation can affect users financially, physically, or emotionally. Therefore, the update targeted particularly those YMYL pages that have low-quality content and misinformation. This resulted in the algorithm targeting health and medical-related websites more than others. However, many other websites from other industries were also negatively affected.

Google Search consists of a series of localized websites. The largest of those, the google.com site, is the top most-visited website in the world. Some of its features include a definition link for most searches including dictionary words, the number of results you got on your search, links to other searches (e.g. for words that Google believes to be misspelled, it provides a link to the search results using its proposed spelling), and many more.

Google search accepts queries as normal text, as well as individual keywords. It automatically corrects misspelled words, and yields the same results regardless of capitalization. For more customized results, one can use a wide variety of operators, including, but not limited to:

Google applies query expansion to submitted search queries, using techniques to deliver results that it considers "smarter" than the query users actually submitted. This technique involves several steps, including:
In 2008, Google started to give users autocompleted search suggestions in a list below the search bar while typing.

Google's homepage includes a button labeled "I'm Feeling Lucky". This feature originally allowed users to type in their search query, click the button and be taken directly to the first result, bypassing the search results page. With the 2010 announcement of Google Instant, an automatic feature that immediately displays relevant results as users are typing in their query, the "I'm Feeling Lucky" button disappears, requiring that users opt-out of Instant results through search settings to keep using the "I'm Feeling Lucky" functionality. In 2012, "I'm Feeling Lucky" was changed to serve as an advertisement for Google services; users hover their computer mouse over the button, it spins and shows an emotion ("I'm Feeling Puzzled" or "I'm Feeling Trendy", for instance), and, when clicked, takes users to a Google service related to that emotion.

Tom Chavez of "Rapt", a firm helping to determine a website's advertising worth, estimated in 2007 that Google lost $110 million in revenue per year due to use of the button, which bypasses the advertisements found on the search results page.

Besides the main text-based search-engine features of Google search, it also offers multiple quick, interactive experiences. These include, but are not limited to:

During Google's developer conference, Google I/O, in May 2013, the company announced that, on Google Chrome and Chrome OS, users would be able to say "OK Google", with the browser initiating an audio-based search, with no button presses required. After having the answer presented, users can follow up with additional, contextual questions; an example include initially asking "OK Google, will it be sunny in Santa Cruz this weekend?", hearing a spoken answer, and reply with "how far is it from here?" An update to the Chrome browser with voice-search functionality rolled out a week later, though it required a button press on a microphone icon rather than "OK Google" voice activation. Google released a browser extension for the Chrome browser, named with a "beta" tag for unfinished development, shortly thereafter. In May 2014, the company officially added "OK Google" into the browser itself; they removed it in October 2015, citing low usage, though the microphone icon for activation remained available. In May 2016, 20% of search queries on mobile devices were done through voice.

"Universal search" was launched by Google on May 16, 2007 as an idea that merged the results from different kinds of search types into one. Prior to Universal search, a standard Google search would consist of links only to websites. Universal search, however, incorporates a wide variety of sources, including websites, news, pictures, maps, blogs, videos, and more, all shown on the same search results page. Marissa Mayer, then-vice president of search products and user experience, described the goal of Universal search as "we're attempting to break down the walls that traditionally separated our various search properties and integrate the vast amounts of information available into one simple set of search results.

In June 2017, Google expanded its search results to cover available job listings. The data is aggregated from various major job boards and collected by analyzing company homepages. Initially only available in English, the feature aims to simplify finding jobs suitable for each user.

In May 2009, Google announced that they would be parsing website microformats to populate search result pages with "Rich snippets". Such snippets include additional details about results, such as displaying reviews for restaurants and social media accounts for individuals.

In May 2016, Google expanded on the "Rich snippets" format to offer "Rich cards", which, similarly to snippets, display more information about results, but shows them at the top of the mobile website in a swipeable carousel-like format. Originally limited to movie and recipe websites in the United States only, the feature expanded to all countries globally in 2017.

Now the web publishers can have greater control over the rich snippets. Preview settings from these meta tags will become effective in mid-to-late October 2019 and may take about a week for the global rollout to complete.

The Knowledge Graph is a knowledge base used by Google to enhance its search engine's results with information gathered from a variety of sources. This information is presented to users in a box to the right of search results. Knowledge Graph boxes were added to Google's search engine in May 2012, starting in the United States, with international expansion by the end of the year. The information covered by the Knowledge Graph grew significantly after launch, tripling its original size within seven months, and being able to answer "roughly one-third" of the 100 billion monthly searches Google processed in May 2016. The information is often used as a spoken answer in Google Assistant and Google Home searches. The Knowledge Graph has been criticized for providing answers without source attribution.

Google Search has been accused of using a so-called zero-click search to prevent a large part of the traffic leaving its page to third-party publishers. As a result, 71% of searches end on the Google search page. In case of one specific query out of 890'000 searches on Google, only 30'000 resulted in the user clicking on the results website.

In May 2017, Google enabled a new "Personal" tab in Google Search, letting users search for content in their Google accounts' various services, including email messages from Gmail and photos from Google Photos.

The Google feed is a personalized stream of articles, videos, and other news-related content. The feed contains a "mix of cards" which show topics of interest based on users' interactions with Google, or topics they choose to follow directly. Cards include, "links to news stories, YouTube videos, sports scores, recipes, and other content based on what [Google] determined you're most likely to be interested in at that particular moment." Users can also tell Google they're not interested in certain topics to avoid seeing future updates.

The Google feed launched in December 2016 and received a major update in July 2017. As of May 2018, the Google feed can be found on the Google app and by swiping left on the home screen of certain Android devices. As of 2019, Google will not allow political campaigns worldwide to target their advertisement to people to make them vote.

Google's rise was largely due to a patented algorithm called PageRank which helps rank web pages that match a given search string. When Google was a Stanford research project, it was nicknamed BackRub because the technology checks backlinks to determine a site's importance. Other keyword-based methods to rank search results, used by many search engines that were once more popular than Google, would check how often the search terms occurred in a page, or how strongly associated the search terms were within each resulting page. The PageRank algorithm instead analyzes human-generated links assuming that web pages linked from many important pages are also important. The algorithm computes a recursive score for pages, based on the weighted sum of other pages linking to them. PageRank is thought to correlate well with human concepts of importance. In addition to PageRank, Google, over the years, has added many other secret criteria for determining the ranking of resulting pages. This is reported to comprise over 250 different indicators, the specifics of which are kept secret to avoid difficulties created by scammers and help Google maintain an edge over its competitors globally.

PageRank was influenced by a similar page-ranking and site-scoring algorithm earlier used for RankDex, developed by Robin Li in 1996. Larry Page's patent for PageRank filed in 1998 includes a citation to Li's earlier patent. Li later went on to create the Chinese search engine Baidu in 2000.

In a potential hint of Google's future direction of their Search algorithm, Google's then chief executive Eric Schmidt, said in a 2007 interview with the "Financial Times": "The goal is to enable Google users to be able to ask the question such as 'What shall I do tomorrow?' and 'What job shall I take?'". Schmidt reaffirmed this during a 2010 interview with the Wall Street Journal: "I actually think most people don't want Google to answer their questions, they want Google to tell them what they should be doing next."

In 2013 the European Commission found that Google Search favored Google's own products, instead of the best result for consumers' needs. In February 2015 Google announced a major change to its mobile search algorithm which would favor mobile friendly over other websites. Nearly 60% of Google searches come from mobile phones. Google says it wants users to have access to premium quality websites. Those websites which lack a mobile-friendly interface would be ranked lower and it is expected that this update will cause a shake-up of ranks. Businesses who fail to update their websites accordingly could see a dip in their regular websites traffic.

Because Google is the most popular search engine, many webmasters attempt to influence their website's Google rankings. An industry of consultants has arisen to help websites increase their rankings on Google and other search engines. This field, called search engine optimization, attempts to discern patterns in search engine listings, and then develop a methodology for improving rankings to draw more searchers to their clients' sites. Search engine optimization encompasses both "on page" factors (like body copy, title elements, H1 heading elements and image alt attribute values) and Off Page Optimization factors (like anchor text and PageRank). The general idea is to affect Google's relevance algorithm by incorporating the keywords being targeted in various places "on page", in particular the title element and the body copy (note: the higher up in the page, presumably the better its keyword prominence and thus the ranking). Too many occurrences of the keyword, however, cause the page to look suspect to Google's spam checking algorithms. Google has published guidelines for website owners who would like to raise their rankings when using legitimate optimization consultants. It has been hypothesized, and, allegedly, is the opinion of the owner of one business about which there have been numerous complaints, that negative publicity, for example, numerous consumer complaints, may serve as well to elevate page rank on Google Search as favorable comments. The particular problem addressed in "The New York Times" article, which involved DecorMyEyes, was addressed shortly thereafter by an undisclosed fix in the Google algorithm. According to Google, it was not the frequently published consumer complaints about DecorMyEyes which resulted in the high ranking but mentions on news websites of events which affected the firm such as legal actions against it. Google Search Console helps to check for websites that use duplicate or copyright content.

In 2013, Google significantly upgraded its search algorithm with "Hummingbird". Its name was derived from the speed and accuracy of the hummingbird. The change was announced on September 26, 2013, having already been in use for a month. "Hummingbird" places greater emphasis on natural language queries, considering context and meaning over individual keywords. It also looks deeper at content on individual pages of a website, with improved ability to lead users directly to the most appropriate page rather than just a website's homepage. The upgrade marked the most significant change to Google search in years, with more "human" search interactions and a much heavier focus on conversation and meaning. Thus, web developers and writers were encouraged to optimize their sites with natural writing rather than forced keywords, and make effective use of technical web development for on-site navigation.

On certain occasions, the logo on Google's webpage will change to a special version, known as a "Google Doodle". This is a picture, drawing, animation, or interactive game that includes the logo. It is usually done for a special event or day although not all of them are well known. Clicking on the Doodle links to a string of Google search results about the topic. The first was a reference to the Burning Man Festival in 1998, and others have been produced for the birthdays of notable people like Albert Einstein, historical events like the interlocking Lego block's 50th anniversary and holidays like Valentine's Day. Some Google Doodles have interactivity beyond a simple search, such as the famous "Google Pacman" version that appeared on May 21, 2010.

Google offers a "Google Search" mobile app for Android and iOS devices. The mobile apps exclusively feature a "feed", a news feed-style page of continually-updated developments on news and topics of interest to individual users. Android devices were introduced to a preview of the feed in December 2016, while it was made official on both Android and iOS in July 2017.

In April 2016, Google updated its Search app on Android to feature "Trends"; search queries gaining popularity appeared in the autocomplete box along with normal query autocompletion. The update received significant backlash, due to encouraging search queries unrelated to users' interests or intentions, prompting the company to issue an update with an opt-out option. In September 2017, the Google Search app on iOS was updated to feature the same functionality.

Until May 2013, Google Search had offered a feature to translate search queries into other languages. A Google spokesperson told "Search Engine Land" that "Removing features is always tough, but we do think very hard about each decision and its implications for our users. Unfortunately, this feature never saw much pick up".
Instant search was announced in September 2010 as a feature that displayed suggested results while the user typed in their search query. The primary advantage of the new system was its ability to save time, with Marissa Mayer, then-vice president of search products and user experience, proclaiming that the feature would save 2–5 seconds per search, elaborating that "That may not seem like a lot at first, but it adds up. With Google Instant, we estimate that we'll save our users 11 hours with each passing second!" Matt Van Wagner of "Search Engine Land" wrote that "Personally, I kind of like Google Instant and I think it represents a natural evolution in the way search works", and also praised Google's efforts in public relations, writing that "With just a press conference and a few well-placed interviews, Google has parlayed this relatively minor speed improvement into an attention-grabbing front-page news story". The upgrade also became notable for the company switching Google Search's underlying technology from HTML to AJAX.

Instant Search could be disabled via Google's "preferences" menu for those who didn't want its functionality.

The publication "" compiled a list of words that Google Instant did not show suggested results for, with a Google spokesperson giving the following statement to "Mashable":

"PC Magazine" discussed the inconsistency in how some forms of the same topic are allowed; for instance, "lesbian" was blocked, while "gay" was not, and "cocaine" was blocked, while "crack" and "heroin" were not. The report further stated that seemingly normal words were also blocked due to pornographic innuendos, most notably "scat", likely due to having two completely separate contextual meanings, one for music and one for a sexual practice.

On July 26, 2017, Google removed Instant results, due to a growing number of searches on mobile devices, where interaction with search, as well as screen sizes, differ significantly from a computer.

Various search engines provide encrypted Web search facilities. In May 2010 Google rolled out SSL-encrypted web search. The encrypted search was accessed at codice_12 However, the web search is encrypted via Transport Layer Security (TLS) by default today, thus every search request should be automatically encrypted if TLS is supported by the web browser. On its support website, Google announced that the address codice_12 would be turned off April 30, 2018, stating that all Google products and most new browsers use HTTPS connections as the reason for the discontinuation.

Google Real-Time Search was a feature of Google Search in which search results also sometimes included real-time information from sources such as Twitter, Facebook, blogs, and news websites. The feature was introduced on December 7, 2009 and went offline on July 2, 2011 after the deal with Twitter expired. Real-Time Search included Facebook status updates beginning on February 24, 2010. A feature similar to Real-Time Search was already available on Microsoft's Bing search engine, which showed results from Twitter and Facebook. The interface for the engine showed a live, descending "river" of posts in the main region (which could be paused or resumed), while a bar chart metric of the frequency of posts containing a certain search term or hashtag was located on the right hand corner of the page above a list of most frequently reposted posts and outgoing links. Hashtag search links were also supported, as were "promoted" tweets hosted by Twitter (located persistently on top of the river) and thumbnails of retweeted image or video links.

In January 2011, geolocation links of posts were made available alongside results in Real-Time Search. In addition, posts containing syndicated or attached shortened links were made searchable by the "link:" query option. In July 2011 Real-Time Search became inaccessible, with the Real-Time link in the Google sidebar disappearing and a custom 404 error page generated by Google returned at its former URL. Google originally suggested that the interruption was temporary and related to the launch of Google+; they subsequently announced that it was due to the expiry of a commercial arrangement with Twitter to provide access to tweets.

Searches made by search engines, including Google, leave traces. This raises concerns about privacy. In principle, if details of a user's searches are found, those with access to the information—principally state agencies responsible for law enforcement and similar matters—can make deductions about the user's activities. This has been used for the detection and prosecution of lawbreakers; for example a murderer was found and convicted after searching for terms such as "tips with killing with a baseball bat".

A search may leave traces both on a computer used to make the search, and in records kept by the search provider. When using a search engine through a browser program on a computer, search terms and other information may be stored on the computer by default, unless the browser is set not to do this, or they are erased. Saved terms may be discovered on forensic analysis of the computer. An Internet Service Provider (ISP) or search engine provider (e.g., Google) may store records which relate search terms to an IP address and a time. Whether such logs are kept, and access to them by law enforcement agencies, is subject to legislation in different jurisdictions and working practices; the law may mandate, prohibit, or say nothing about logging of various types of information. Some search engines, located in jurisdictions where it is not illegal, make a feature of not storing user search information.

The keywords suggested by the Autocomplete feature show a population of users' research which is made possible by an identity management system. Volumes of personal data are collected via Eddystone web and proximity beacons.

Google has been criticized for placing long-term cookies on users' machines to store these preferences, a tactic which also enables them to track a user's search terms and retain the data for more than a year.

Since 2012, Google Inc. has globally introduced encrypted connections for most of its clients, to bypass governative blockings of the commercial and IT services.

In late June 2011, Google introduced a new look to the Google home page in order to boost the use of the Google+ social tools.

One of the major changes was replacing the classic navigation bar with a black one. Google's digital creative director Chris Wiggins explains: "We're working on a project to bring you a new and improved Google experience, and over the next few months, you'll continue to see more updates to our look and feel." The new navigation bar has been negatively received by a vocal minority.

In November 2013, Google started testing yellow labels for advertisements displayed in search results, to improve user experience. The new labels, highlighted in yellow color, and aligned to the left of each sponsored link help users differentiate between organic and sponsored results.

On December 15, 2016, Google rolled out a new desktop search interface that mimics their modular mobile user interface. The mobile design consists of a tabular design that highlights search features in boxes. and works by imitating the desktop Knowledge Graph real estate, which appears in the right-hand rail of the search engine result page, these featured elements frequently feature Twitter carousels, People Also Search For, and Top Stories (vertical and horizontal design) modules. The Local Pack and Answer Box were two of the original features of the Google SERP that were primarily showcased in this manner, but this new layout creates a previously unseen level of design consistency for Google results.

In addition to its tool for searching web pages, Google also provides services for searching images, Usenet newsgroups, news websites, videos (Google Videos), searching by locality, maps, and items for sale online. Google Videos allows searching the World Wide Web for video clips. The service evolved from Google Video, Google's discontinued video hosting service that also allowed to search the web for video clips.

In 2012, Google has indexed over 30 trillion web pages, and received 100 billion queries per month. It also caches much of the content that it indexes. Google operates other tools and services including Google News, Google Shopping, Google Maps, Google Custom Search, Google Earth, Google Docs, Picasa (discontinued), Panoramio (discontinued), YouTube, Google Translate, Google Blog Search and Google Desktop Search.

There are also products available from Google that are not directly search-related. Gmail, for example, is a webmail application, but still includes search features; Google Browser Sync does not offer any search facilities, although it aims to organize your browsing time.

Also Google starts many new beta products, like Google Social Search or Google Image Swirl.

In 2009, Google claimed that a search query requires altogether about 1 kJ or 0.0003 kW·h, which is enough to raise the temperature of one liter of water by 0.24 °C. According to green search engine Ecosia, the industry standard for search engines is estimated to be about 0.2 grams of CO emission per search. Google's 40,000 searches per second translate to 8 kg CO per second or over 252 million kilos of CO per year.

In 2003, "The New York Times" complained about Google's indexing, claiming that Google's caching of content on its site infringed its copyright for the content. In both "Field v. Google" and "Parker v. Google", the United States District Court of Nevada ruled in favor of Google.

Google flags search results with the message "This site may harm your computer" if the site is known to install malicious software in the background or otherwise surreptitiously. For approximately 40 minutes on January 31, 2009, all search results were mistakenly classified as malware and could therefore not be clicked; instead a warning message was displayed and the user was required to enter the requested URL manually. The bug was caused by human error. The URL of "/" (which expands to all URLs) was mistakenly added to the malware patterns file.

In 2007, a group of researchers observed a tendency for users to rely on Google Search exclusively for finding information, writing that "With the Google interface the user gets the impression that the search results imply a kind of totality. ... In fact, one only sees a small part of what one could see if one also integrates other research tools."

In 2011, Google Search query results have been shown by Internet activist Eli Pariser to be tailored to users, effectively isolating users in what he defined as a filter bubble. Pariser holds algorithms used in search engines such as Google Search responsible for catering "a personal ecosystem of information". Although contrasting views have mitigated the potential threat of "informational dystopia" and questioned the scientific nature of Pariser's claims, filter bubbles have been mentioned to account for the surprising results of the U.S. presidential election in 2016 alongside fake news and echo chambers, suggesting that Facebook and Google have designed personalized online realities in which "we only see and hear what we like".

In 2012, the US Federal Trade Commission fined Google US$22.5 million for violating their agreement not to violate the privacy of users of Apple's Safari web browser. The FTC was also continuing to investigate if Google's favoring of their own services in their search results violated antitrust regulations.

Google search engine robots are programmed to use algorithms that understand and predict human behavior. The book, "Race After Technology: Abolitionist Tools for the New Jim Code" by Ruha Benjamin talks about human bias as a behavior that the google search engine can recognize. In 2016, some users google searched “three Black teenagers” and images of criminal mugshots of young African American teenagers came up. Then, the users searched “three White teenagers” and were presented with photos of smiling, happy teenagers. They also searched for “three Asian teenagers,” and very revealing photos of Asian girls and women appeared. Benjamin concluded that these results reflect human prejudice and views on different ethnic groups. A group of analysts explained the concept of a racist computer program: “The idea here is that computers, unlike people, can’t be racist but we’re increasingly learning that they do in fact take after their makers...Some experts believe that this problem might stem from the hidden biases in the massive piles of data that the algorithms process as they learn to recognize patterns...reproducing our worst values”.

As people talk about "googling" rather than searching, the company has taken some steps to defend its trademark, in an effort to prevent it from becoming a generic trademark. This has led to lawsuits, threats of lawsuits, and the use of euphemisms, such as calling Google Search a famous web search engine.





</doc>
<doc id="12432" url="https://en.wikipedia.org/wiki?curid=12432" title="Genius">
Genius

A genius is a person who displays exceptional intellectual ability, creative productivity, universality in genres or originality, typically to a degree that is associated with the achievement of new advances in a domain of knowledge. Despite the presence of scholars in many subjects throughout history, many geniuses have shown high achievements in only a single kind of activity.

There is no scientifically precise definition of a genius. Sometimes genius is associated with talent, but several authors such as Cesare Lombroso and Arthur Schopenhauer systematically distinguish these terms.

In ancient Rome, the "genius" (plural in Latin "genii") was the guiding spirit or tutelary deity of a person, family ("gens"), or place ("genius loci"). The noun is related to the Latin verbs "gignere" (to beget, to give birth to) and "generare" (to beget, to generate, to procreate), and derives directly from the Indo-European stem thereof: "ǵenh" (to produce, to beget, to give birth). Because the achievements of exceptional individuals seemed to indicate the presence of a particularly powerful "genius", by the time of Augustus, the word began to acquire its secondary meaning of "inspiration, talent". The term "genius" acquired its modern sense in the eighteenth century, and is a conflation of two Latin terms: "genius", as above, and "Ingenium", a related noun referring to our innate dispositions, talents, and inborn nature. Beginning to blend the concepts of the divine and the talented, the "Encyclopédie" article on genius (génie) describes such a person as "he whose soul is more expansive and struck by the feelings of all others; interested by all that is in nature never to receive an idea unless it evokes a feeling; everything excites him and on which nothing is lost."

The assessment of intelligence was initiated by Francis Galton (1822–1911) and James McKeen Cattell. They had advocated the analysis of reaction time and sensory acuity as measures of "neurophysiological efficiency" and the analysis of sensory acuity as a measure of intelligence.

Galton is regarded as the founder of psychometry. He studied the work of his older half-cousin Charles Darwin about biological evolution. Hypothesizing that eminence is inherited from ancestors, Galton did a study of families of eminent people in Britain, publishing it in 1869 as "Hereditary Genius". Galton's ideas were elaborated from the work of two early 19th-century pioneers in statistics: Carl Friedrich Gauss and Adolphe Quetelet. Gauss discovered the normal distribution (bell-shaped curve): given a large number of measurements of the same variable under the same conditions, they vary at random from a most frequent value, the "average", to two least frequent values at maximum differences greater and lower than the most frequent value. Quetelet discovered that the bell-shaped curve applied to social statistics gathered by the French government in the course of its normal processes on large numbers of people passing through the courts and the military. His initial work in criminology led him to observe "the greater the number of individuals observed the more do peculiarities become effaced...". This ideal from which the peculiarities were effaced became "the average man".

Galton was inspired by Quetelet to define the average man as "an entire normal scheme"; that is, if one combines the normal curves of every measurable human characteristic, one will, in theory, perceive a syndrome straddled by "the average man" and flanked by persons that are different. In contrast to Quetelet, Galton's average man was not statistical but was theoretical only. There was no measure of general averageness, only a large number of very specific averages. Setting out to discover a general measure of the average, Galton looked at educational statistics and found bell-curves in test results of all sorts; initially in mathematics grades for the final honors examination and in entrance examination scores for Sandhurst.

Galton's method in "Hereditary Genius" was to count and assess the eminent relatives of eminent men. He found that the number of eminent relatives was greater with a closer degree of kinship. This work is considered the first example of historiometry, an analytical study of historical human progress. The work is controversial and has been criticized for several reasons. Galton then departed from Gauss in a way that became crucial to the history of the 20th century AD. The bell-shaped curve was not random, he concluded. The differences between the average and the upper end were due to a non-random factor, "natural ability", which he defined as "those qualities of intellect and disposition, which urge and qualify men to perform acts that lead to reputation…a nature which, when left to itself, will, urged by an inherent stimulus, climb the path that leads to eminence." The apparent randomness of the scores was due to the randomness of this natural ability in the population as a whole, in theory.

Criticisms include that Galton's study fails to account for the impact of social status and the associated availability of resources in the form of economic inheritance, meaning that inherited "eminence" or "genius" can be gained through the enriched environment provided by wealthy families. Galton went on to develop the field of eugenics. Galton attempted to control for economic inheritance by comparing the adopted nephews of popes, who would have the advantage of wealth without being as closely related to popes as sons are to their fathers, to the biological children of eminent individuals. 

Genius is expressed in a variety of forms (e.g., mathematical, literary, musical performance). Persons with genius tend to have strong intuitions about their domains, and they build on these insights with tremendous energy. Carl Rogers, a founder of the Humanistic Approach to Psychology, expands on the idea of a genius trusting his or her intuition in a given field, writing: "El Greco, for example, must have realized as he looked at some of his early work, that 'good artists do not paint like that.' But somehow he trusted his own experiencing of life, the process of himself, sufficiently that he could go on expressing his own unique perceptions. It was as though he could say, 'Good artists don't paint like this, but "I" paint like this.' Or to move to another field, Ernest Hemingway was surely aware that 'good writers do not write like this.' But fortunately he moved toward being Hemingway, being himself, rather than toward someone else's conception of a good writer."

A number of people commonly regarded as geniuses have been or were diagnosed with mental disorders, for example Vincent van Gogh, Virginia Woolf, John Forbes Nash Jr., and Ernest Hemingway.

It has been suggested that there exists a connection between mental illness, in particular schizophrenia and bipolar disorder, and genius. Individuals with bipolar disorder and schizotypal personality disorder, the latter of which being more common amongst relatives of schizophrenics, tend to show elevated creativity.

In a 2010 study done in the Karolinska Institute it was observed that highly creative individuals and schizophrenics have a lower density of thalamic dopamine D2 receptors. One of the investigators explained that "Fewer D2 receptors in the thalamus probably means a lower degree of signal filtering, and thus a higher flow of information from the thalamus." This could be a possible mechanism behind the ability of healthy highly creative people to see numerous uncommon connections in a problem-solving situation and the bizarre associations found in the schizophrenics.

Galton was a pioneer in investigating both eminent human achievement and mental testing. In his book "Hereditary Genius", written before the development of IQ testing, he proposed that hereditary influences on eminent achievement are strong, and that eminence is rare in the general population. Lewis Terman chose "'near' genius or genius" as the classification label for the highest classification on his 1916 version of the Stanford–Binet test. By 1926, Terman began publishing about a longitudinal study of California schoolchildren who were referred for IQ testing by their schoolteachers, called Genetic Studies of Genius, which he conducted for the rest of his life. Catherine M. Cox, a colleague of Terman's, wrote a whole book, "The Early Mental Traits of 300 Geniuses", published as volume 2 of The Genetic Studies of Genius book series, in which she analyzed biographical data about historic geniuses. Although her estimates of childhood IQ scores of historical figures who never took IQ tests have been criticized on methodological grounds, Cox's study was thorough in finding out what else matters besides IQ in becoming a genius. By the 1937 second revision of the Stanford–Binet test, Terman no longer used the term "genius" as an IQ classification, nor has any subsequent IQ test. In 1939, David Wechsler specifically commented that "we are rather hesitant about calling a person a genius on the basis of a single intelligence test score".

The Terman longitudinal study in California eventually provided historical evidence regarding how genius is related to IQ scores. Many California pupils were recommended for the study by schoolteachers. Two pupils who were tested but rejected for inclusion in the study (because their IQ scores were too low) grew up to be Nobel Prize winners in physics, William Shockley, and Luis Walter Alvarez. Based on the historical findings of the Terman study and on biographical examples such as Richard Feynman, who had an IQ of 125 and went on to win the Nobel Prize in physics and become widely known as a genius, the current view of psychologists and other scholars of genius is that a minimum level of IQ (approximately 125) is necessary for genius but not sufficient, and must be combined with personality characteristics such as drive and persistence, plus the necessary opportunities for talent development. For instance, in a chapter in an edited volume on achievement, IQ researcher Arthur Jensen proposed a multiplicative model of genius consisting of high ability, high productivity, and high creativity. Jensen's model was motivated by the finding that eminent achievement is highly positively skewed, a finding known as Price's law, and related to Lotka's law. 

Some high IQ individuals join a High IQ society. The most famous is Mensa International but others exist including The International High IQ Society, the Prometheus Society, the Triple Nine Society, and Magnus.

Various philosophers have proposed definitions of what genius is and what that implies in the context of their philosophical theories.

In the philosophy of David Hume, the way society perceives genius is similar to the way society perceives the ignorant. Hume states that a person with the characteristics of a genius is looked at as a person disconnected from society, as well as a person who works remotely, at a distance, away from the rest of the world. On the other hand, the mere ignorant is still more despised; nor is any thing deemed a surer sign of an illiberal genius in an age and nation where the sciences flourish, than to be entirely destitute of all relish for those noble entertainments. The most perfect character is supposed to lie between those extremes; retaining an equal ability and taste for books, company, and business; preserving in conversation that discernment and delicacy which arise from polite letters; and in business, that probity and accuracy which are the natural result of a just philosophy.

In the philosophy of Immanuel Kant, genius is the ability to independently arrive at and understand concepts that would normally have to be taught by another person. For Kant, originality was the essential character of genius. This genius is a talent for producing ideas which can be described as non-imitative. Kant's discussion of the characteristics of genius is largely contained within the "Critique of Judgment" and was well received by the Romantics of the early 19th century. In addition, much of Schopenhauer's theory of genius, particularly regarding talent and freedom from constraint, is directly derived from paragraphs of Part I of Kant's "Critique of Judgment".

In the philosophy of Arthur Schopenhauer, a genius is someone in whom intellect predominates over "will" much more than within the average person. In Schopenhauer's aesthetics, this predominance of the intellect over the will allows the genius to create artistic or academic works that are objects of pure, disinterested contemplation, the chief criterion of the aesthetic experience for Schopenhauer. Their remoteness from mundane concerns means that Schopenhauer's geniuses often display maladaptive traits in more mundane concerns; in Schopenhauer's words, they fall into the mire while gazing at the stars, an allusion to Plato's dialogue "Theætetus", in which Socrates tells of Thales (the first philosopher) being ridiculed for falling in such circumstances. As he says in Volume 2 of "The World as Will and Representation":

In the philosophy of Bertrand Russell, genius entails that an individual possesses unique qualities and talents that make the genius especially valuable to the society in which he or she operates, once given the chance to contribute to society. Russell's philosophy further maintains, however, that it is possible for such geniuses to be crushed in their youth and lost forever when the environment around them is unsympathetic to their potential maladaptive traits. Russell rejected the notion he believed was popular during his lifetime that, "genius will out".


Sources listed in chronological order of publication within each category.





</doc>
<doc id="12434" url="https://en.wikipedia.org/wiki?curid=12434" title="Grain (disambiguation)">
Grain (disambiguation)

Grains are the seeds of arable crops or the crops bearing them. 

Grain or grains may also refer to:







</doc>
<doc id="12435" url="https://en.wikipedia.org/wiki?curid=12435" title="Grass (disambiguation)">
Grass (disambiguation)

Grass refers to the many species of plants in the family Poaceae.

Grass may also refer to:













</doc>
<doc id="12436" url="https://en.wikipedia.org/wiki?curid=12436" title="Grape">
Grape

A grape is a fruit, botanically a berry, of the deciduous woody vines of the flowering plant genus "Vitis".

Grapes can be eaten fresh as table grapes or they can be used for making wine, jam, grape juice, jelly, grape seed extract, raisins, vinegar, and grape seed oil. Grapes are a non-climacteric type of fruit, generally occurring in clusters.

The cultivation of the domesticated grape began 6,000–8,000 years ago in the Near East. Yeast, one of the earliest domesticated microorganisms, occurs naturally on the skins of grapes, leading to the discovery of alcoholic drinks such as wine. The earliest archeological evidence for a dominant position of wine-making in human culture dates from 8,000 years ago in Georgia.

The oldest known winery was found in Armenia, dating to around 4000 BC. By the 9th century AD the city of Shiraz was known to produce some of the finest wines in the Middle East. Thus it has been proposed that Syrah red wine is named after Shiraz, a city in Persia where the grape was used to make Shirazi wine.

Ancient Egyptian hieroglyphics record the cultivation of purple grapes, and history attests to the ancient Greeks, Phoenicians, and Romans growing purple grapes both for eating and wine production. The growing of grapes would later spread to other regions in Europe, as well as North Africa, and eventually in North America.

In North America, native grapes belonging to various species of the genus "Vitis" proliferate in the wild across the continent, and were a part of the diet of many Native Americans, but were considered by early European colonists to be unsuitable for wine. In the 19th century, Ephraim Bull of Concord, Massachusetts, cultivated seeds from wild "Vitis labrusca" vines to create the Concord grape which would become an important agricultural crop in the United States.

Grapes are a type of fruit that grow in clusters of 15 to 300, and can be crimson, black, dark blue, yellow, green, orange, and pink. "White" grapes are actually green in color, and are evolutionarily derived from the purple grape. Mutations in two regulatory genes of white grapes turn off production of anthocyanins, which are responsible for the color of purple grapes. Anthocyanins and other pigment chemicals of the larger family of polyphenols in purple grapes are responsible for the varying shades of purple in red wines. Grapes are typically an ellipsoid shape resembling a prolate spheroid.

Raw grapes are 81% water, 18% carbohydrates, 1% protein, and have negligible fat (table). A reference amount of raw grapes supplies of food energy and a moderate amount of vitamin K (14% of the Daily Value), with no other micronutrients in significant content.

Most grapes come from cultivars of "Vitis vinifera", the European grapevine native to the Mediterranean and Central Asia. Minor amounts of fruit and wine come from American and Asian species such as:


According to the Food and Agriculture Organization (FAO), 75,866 square kilometers of the world are dedicated to grapes. Approximately 71% of world grape production is used for wine, 27% as fresh fruit, and 2% as dried fruit. A portion of grape production goes to producing grape juice to be reconstituted for fruits canned "with no added sugar" and "100% natural". The area dedicated to vineyards is increasing by about 2% per year.

There are no reliable statistics that break down grape production by variety. It is believed that the most widely planted variety is Sultana, also known as Thompson Seedless, with at least 3,600 km (880,000 acres) dedicated to it. The second most common variety is Airén. Other popular varieties include Cabernet Sauvignon, Sauvignon blanc, Cabernet Franc, Merlot, Grenache, Tempranillo, Riesling, and Chardonnay.

Commercially cultivated grapes can usually be classified as either table or wine grapes, based on their intended method of consumption: eaten raw (table grapes) or used to make wine (wine grapes). While almost all of them belong to the same species, "Vitis vinifera", table and wine grapes have significant differences, brought about through selective breeding. Table grape cultivars tend to have large, seedless fruit (see below) with relatively thin skin. Wine grapes are smaller, usually seeded, and have relatively thick skins (a desirable characteristic in winemaking, since much of the aroma in wine comes from the skin). Wine grapes also tend to be very sweet: they are harvested at the time when their juice is approximately 24% sugar by weight. By comparison, commercially produced "100% grape juice", made from table grapes, is usually around 15% sugar by weight.

Seedless cultivars now make up the overwhelming majority of table grape plantings. Because grapevines are vegetatively propagated by cuttings, the lack of seeds does not present a problem for reproduction. It is an issue for breeders, who must either use a seeded variety as the female parent or rescue embryos early in development using tissue culture techniques.

There are several sources of the seedlessness trait, and essentially all commercial cultivators get it from one of three sources: Thompson Seedless, Russian Seedless, and Black Monukka, all being cultivars of "Vitis vinifera". There are currently more than a dozen varieties of seedless grapes. Several, such as Einset Seedless, Benjamin Gunnels's Prime seedless grapes, Reliance, and Venus, have been specifically cultivated for hardiness and quality in the relatively cold climates of northeastern United States and southern Ontario.

An offset to the improved eating quality of seedlessness is the loss of potential health benefits provided by the enriched phytochemical content of grape seeds (see Health claims, below).

In most of Europe and North America, dried grapes are referred to as "raisins" or the local equivalent. In the UK, three different varieties are recognized, forcing the EU to use the term "dried vine fruit" in official documents.

A "raisin" is any dried grape. While "raisin" is a French loanword, the word in French refers to the fresh fruit; "grappe" (from which the English "grape" is derived) refers to the bunch (as in "une grappe de raisins").

A "currant" is a dried Zante Black Corinth grape, the name being a corruption of the French "raisin de Corinthe" (Corinth grape). "Currant" has also come to refer to the blackcurrant and redcurrant, two berries unrelated to grapes.

A "sultana" was originally a raisin made from Sultana grapes of Turkish origin (known as Thompson Seedless in the United States), but the word is now applied to raisins made from either white grapes or red grapes that are bleached to resemble the traditional sultana.

Grape juice is obtained from crushing and blending grapes into a liquid. The juice is often sold in stores or fermented and made into wine, brandy, or vinegar. Grape juice that has been pasteurized, removing any naturally occurring yeast, will not ferment if kept sterile, and thus contains no alcohol. In the wine industry, grape juice that contains 7–23% of pulp, skins, stems and seeds is often referred to as "must". In North America, the most common grape juice is purple and made from Concord grapes, while white grape juice is commonly made from Niagara grapes, both of which are varieties of grapes, a different species from European wine grapes. In California, Sultana (known there as Thompson Seedless) grapes are sometimes diverted from the raisin or table market to produce white juice.

Winemaking from red and white grape flesh and skins produces substantial quantities of organic residues, collectively called pomace (also "marc"), which includes crushed skins, seeds, stems, and leaves generally used as compost. Grape pomace – some 10-30% of the total mass of grapes crushed – contains various phytochemicals, such as unfermented sugars, alcohol, polyphenols, tannins, anthocyanins, and numerous other compounds, some of which are harvested and extracted for commercial applications (a process sometimes called "valorization" of the pomace).

Anthocyanins tend to be the main polyphenolics in purple grapes, whereas flavan-3-ols (i.e. catechins) are the more abundant class of polyphenols in white varieties. Total phenolic content is higher in purple varieties due almost entirely to anthocyanin density in purple grape skin compared to absence of anthocyanins in white grape skin. Phenolic content of grape skin varies with cultivar, soil composition, climate, geographic origin, and cultivation practices or exposure to diseases, such as fungal infections.

Muscadine grapes contain a relatively high phenolic content among dark grapes. In muscadine skins, ellagic acid, myricetin, quercetin, kaempferol, and trans-resveratrol are major phenolics.

The flavonols syringetin, syringetin 3-O-galactoside, laricitrin and laricitrin 3-O-galactoside are also found in purple grape but absent in white grape.

Muscadine grape seeds contain about twice the total polyphenol content of skins. Grape seed oil from crushed seeds is used in cosmeceuticals and skincare products. Grape seed oil, including tocopherols (vitamin E) and high contents of phytosterols and polyunsaturated fatty acids such as linoleic acid, oleic acid, and alpha-linolenic acid.

Resveratrol, a stilbene compound, is found in widely varying amounts among grape varieties, primarily in their skins and seeds. Muscadine grapes have about one hundred times higher concentration of stilbenes than pulp. Fresh grape skin contains about 50 to 100 micrograms of resveratrol per gram.

Comparing diets among Western countries, researchers have discovered that although French people tend to eat higher levels of animal fat, the incidence of heart disease remains low in France. This phenomenon has been termed the French paradox, and is thought to occur from protective benefits of regularly consuming red wine, among other dietary practices. Alcohol consumption in moderation may be cardioprotective by its minor anticoagulant effect and vasodilation.

Although adoption of wine consumption is generally not recommended by health authorities, some research indicates moderate consumption, such as one glass of red wine a day for women and two for men, may confer health benefits. Alcohol itself may have protective effects on the cardiovascular system.

The consumption of grapes and raisins presents a potential health threat to dogs. Their toxicity to dogs can cause the animal to develop acute kidney failure (the sudden development of kidney failure) with anuria (a lack of urine production) and may be fatal.

Christians have traditionally used wine during worship services as a means of remembering the blood of Jesus Christ which was shed for the remission of sins. Christians who oppose the partaking of alcoholic beverages sometimes use grape juice or water as the "cup" or "wine" in the Lord's Supper.

The Catholic Church continues to use wine in the celebration of the Eucharist because it is part of the tradition passed down through the ages starting with Jesus Christ at the Last Supper, where Catholics believe the consecrated bread and wine "literally" become the body and blood of Jesus Christ, a dogma known as transubstantiation. Wine is used (not grape juice) both due to its strong Scriptural roots, and also to follow the tradition set by the early Christian Church. The Code of Canon Law of the Catholic Church (1983), Canon 924 says that the wine used must be natural, made from grapes of the vine, and not corrupt. In some circumstances, a priest may obtain special permission to use grape juice for the consecration; however, this is extremely rare and typically requires sufficient impetus to warrant such a dispensation, such as personal health of the priest.

Although alcohol is permitted in Judaism, grape juice is sometimes used as an alternative for kiddush on Shabbat and Jewish holidays, and has the same blessing as wine. Many authorities maintain that grape juice must be capable of turning into wine naturally in order to be used for kiddush. Common practice, however, is to use any kosher grape juice for kiddush.




</doc>
<doc id="12437" url="https://en.wikipedia.org/wiki?curid=12437" title="Genetic disorder">
Genetic disorder

A genetic disorder is a health problem caused by one or more abnormalities in the genome. It can be caused by a mutation in a single gene (monogenic) or multiple genes (polygenic) or by a chromosomal abnormality. Although polygenic disorders are the most common, the term is mostly used when discussing disorders with a single genetic cause, either in a gene or chromosome. The mutation responsible can occur spontaneously before embryonic development (a "de novo" mutation), or it can be inherited from two parents who are carriers of a faulty gene (autosomal recessive inheritance) or from a parent with the disorder (autosomal dominant inheritance). Some disorders are caused by a mutation on the X chromosome and have X-linked inheritance. Very few disorders are inherited on the Y chromosome or mitochondrial DNA.

There are well over 6,000 known genetic disorders, and new genetic disorders are constantly being described in medical literature. Around 1 in 50 people are affected by a known single-gene disorder, while around 1 in 263 are affected by a chromosomal disorder. Around 65% of people have some kind of health problem as a result of congenital genetic mutations. Due to the significantly large number of genetic disorders, approximately 1 in 21 people are affected by a genetic disorder classified as "rare" (usually defined as affecting less than 1 in 2,000 people). Most genetic disorders are rare in themselves.

Cancers are caused by genetic mutations but are generally omitted when referring to genetic disorders, since most are not hereditary (though predispositions and cancer syndromes exist).

A single-gene disorder (or monogenic disorder) is the result of a single mutated gene. Single-gene disorders can be passed on to subsequent generations in several ways. Genomic imprinting and uniparental disomy, however, may affect inheritance patterns. The divisions between recessive and dominant types are not "hard and fast", although the divisions between autosomal and X-linked types are (since the latter types are distinguished purely based on the chromosomal location of the gene). For example, the common form of dwarfism, achondroplasia, is typically considered a dominant disorder, but children with two genes for achondroplasia have a severe and usually lethal skeletal disorder, one that achondroplasics could be considered carriers for. Sickle-cell anemia is also considered a recessive condition, but heterozygous carriers have increased resistance to malaria in early childhood, which could be described as a related dominant condition. When a couple where one partner or both are sufferers or carriers of a single-gene disorder wish to have a child, they can do so through "in vitro" fertilization, which enables preimplantation genetic diagnosis to occur to check whether the embryo has the genetic disorder.

Most congenital metabolic disorders known as inborn errors of metabolism result from single-gene defects. Many such single-gene defects can decrease the fitness of affected people and are therefore present in the population in lower frequencies compared to what would be expected based on simple probabilistic calculations.

Only one mutated copy of the gene will be necessary for a person to be affected by an autosomal dominant disorder. Each affected person usually has one affected parent. The chance a child will inherit the mutated gene is 50%. Autosomal dominant conditions sometimes have reduced penetrance, which means although only one mutated copy is needed, not all individuals who inherit that mutation go on to develop the disease. Examples of this type of disorder are Huntington's disease, neurofibromatosis type 1, neurofibromatosis type 2, Marfan syndrome, hereditary nonpolyposis colorectal cancer, hereditary multiple exostoses (a highly penetrant autosomal dominant disorder), tuberous sclerosis, Von Willebrand disease, and acute intermittent porphyria. Birth defects are also called congenital anomalies.

Two copies of the gene must be mutated for a person to be affected by an autosomal recessive disorder. An affected person usually has unaffected parents who each carry a single copy of the mutated gene and are referred to as genetic carriers. Each parent with a defective gene normally do not have symptoms. Two unaffected people who each carry one copy of the mutated gene have a 25% risk with each pregnancy of having a child affected by the disorder. Examples of this type of disorder are albinism, medium-chain acyl-CoA dehydrogenase deficiency, cystic fibrosis, sickle cell disease, Tay–Sachs disease, Niemann–Pick disease, spinal muscular atrophy, and Roberts syndrome. Certain other phenotypes, such as wet versus dry earwax, are also determined in an autosomal recessive fashion. Some autosomal recessive disorders are common because, in the past, carrying one of the faulty genes led to a slight protection against an infectious disease or toxin such as tuberculosis or malaria. Such disorders include cystic fibrosis, sickle cell disease, phenylketonuria and thalassaemia.

X-linked dominant disorders are caused by mutations in genes on the X chromosome. Only a few disorders have this inheritance pattern, with a prime example being X-linked hypophosphatemic rickets. Males and females are both affected in these disorders, with males typically being more severely affected than females. Some X-linked dominant conditions, such as Rett syndrome, incontinentia pigmenti type 2, and Aicardi syndrome, are usually fatal in males either "in utero" or shortly after birth, and are therefore predominantly seen in females. Exceptions to this finding are extremely rare cases in which boys with Klinefelter syndrome (44+xxy) also inherit an X-linked dominant condition and exhibit symptoms more similar to those of a female in terms of disease severity. The chance of passing on an X-linked dominant disorder differs between men and women. The sons of a man with an X-linked dominant disorder will all be unaffected (since they receive their father's Y chromosome), but his daughters will all inherit the condition. A woman with an X-linked dominant disorder has a 50% chance of having an affected fetus with each pregnancy, although in cases such as incontinentia pigmenti, only female offspring are generally viable.

X-linked recessive conditions are also caused by mutations in genes on the X chromosome. Males are much more frequently affected than females, because they only have the one X chromosome necessary for the condition to present. The chance of passing on the disorder differs between men and women. The sons of a man with an X-linked recessive disorder will not be affected (since they receive their father's Y chromosome), but his daughters will be carriers of one copy of the mutated gene. A woman who is a carrier of an X-linked recessive disorder (XX) has a 50% chance of having sons who are affected and a 50% chance of having daughters who are carriers of one copy of the mutated gene. X-linked recessive conditions include the serious diseases hemophilia A, Duchenne muscular dystrophy, and Lesch–Nyhan syndrome, as well as common and less serious conditions such as male pattern baldness and red–green color blindness. X-linked recessive conditions can sometimes manifest in females due to skewed X-inactivation or monosomy X (Turner syndrome).

Y-linked disorders are caused by mutations on the Y chromosome. These conditions may only be transmitted from the heterogametic sex (e.g. male humans) to offspring of the same sex. More simply, this means that Y-linked disorders in humans can only be passed from men to their sons; females can never be affected because they do not possess Y-allosomes.

Y-linked disorders are exceedingly rare but the most well-known examples typically cause infertility. Reproduction in such conditions is only possible through the circumvention of infertility by medical intervention.

This type of inheritance, also known as maternal inheritance, is the rarest and applies to the 13 genes encoded by mitochondrial DNA. Because only egg cells contribute mitochondria to the developing embryo, only mothers (who are affected) can pass on mitochondrial DNA conditions to their children. An example of this type of disorder is Leber's hereditary optic neuropathy.

It is important to stress that the vast majority of mitochondrial diseases (particularly when symptoms develop in early life) are actually caused by a nuclear gene defect, as the mitochondria are mostly developed by non-mitochondrial DNA. These diseases most often follow autosomal recessive inheritance.

Genetic disorders may also be complex, multifactorial, or polygenic, meaning they are likely associated with the effects of multiple genes in combination with lifestyles and environmental factors. Multifactorial disorders include heart disease and diabetes. Although complex disorders often cluster in families, they do not have a clear-cut pattern of inheritance. This makes it difficult to determine a person's risk of inheriting or passing on these disorders. Complex disorders are also difficult to study and treat because the specific factors that cause most of these disorders have not yet been identified. Studies that aim to identify the cause of complex disorders can use several methodological approaches to determine genotype–phenotype associations. One method, the genotype-first approach, starts by identifying genetic variants within patients and then determining the associated clinical manifestations. This is opposed to the more traditional phenotype-first approach, and may identify causal factors that have previously been obscured by clinical heterogeneity, penetrance, and expressivity.

On a pedigree, polygenic diseases do tend to "run in families", but the inheritance does not fit simple patterns as with Mendelian diseases. But this does not mean that the genes cannot eventually be located and studied. There is also a strong environmental component to many of them (e.g., blood pressure).


A chromosomal disorder is a missing, extra, or irregular portion of chromosomal DNA. It can be from an atypical number of chromosomes or a structural abnormality in one or more chromosomes. An example of these disorders is trisomy 21 (Down syndrome), in which there is an extra copy of chromosome 21.

Due to the wide range of genetic disorders that are known, diagnosis is widely varied and dependent of the disorder. Most genetic disorders are diagnosed at birth or during early childhood however some, such as Huntington's disease, can escape detection until the patient is well into adulthood.

The basic aspects of a genetic disorder rests on the inheritance of genetic material. With an in depth family history, it is possible to anticipate possible disorders in children which direct medical professionals to specific tests depending on the disorder and allow parents the chance to prepare for potential lifestyle changes, anticipate the possibility of stillbirth, or contemplate termination. Prenatal diagnosis can detect the presence of characteristic abnormalities in fetal development through ultrasound, or detect the presence of characteristic substances via invasive procedures which involve inserting probes or needles into the uterus such as in amniocentesis.

Not all genetic disorders directly result in death; however, there are no known cures for genetic disorders. Many genetic disorders affect stages of development, such as Down syndrome, while others result in purely physical symptoms such as muscular dystrophy. Other disorders, such as Huntington's disease, show no signs until adulthood. During the active time of a genetic disorder, patients mostly rely on maintaining or slowing the degradation of quality of life and maintain patient autonomy. This includes physical therapy, pain management, and may include a selection of alternative medicine programs.

The treatment of genetic disorders is an ongoing battle, with over 1,800 gene therapy clinical trials having been completed, are ongoing, or have been approved worldwide. Despite this, most treatment options revolve around treating the symptoms of the disorders in an attempt to improve patient quality of life.

Gene therapy refers to a form of treatment where a healthy gene is introduced to a patient. This should alleviate the defect caused by a faulty gene or slow the progression of the disease. A major obstacle has been the delivery of genes to the appropriate cell, tissue, and organ affected by the disorder. How does one introduce a gene into the potentially trillions of cells which carry the defective copy? This question has been the roadblock between understanding the genetic disorder and correcting the genetic disorder.

Around 1 in 50 people are affected by a known single-gene disorder, while around 1 in 263 are affected by a chromosomal disorder. Around 65% of people have some kind of health problem as a result of congenital genetic mutations. Due to the significantly large number of genetic disorders, approximately 1 in 21 people are affected by a genetic disorder classified as "rare" (usually defined as affecting less than 1 in 2,000 people). Most genetic disorders are rare in themselves. There are well over 6,000 known genetic disorders, and new genetic disorders are constantly being described in medical literature.

The earliest known genetic condition in a hominid was in the fossil species "Paranthropus robustus," with over a third of individuals displaying amelogenesis imperfecta.




</doc>
<doc id="12439" url="https://en.wikipedia.org/wiki?curid=12439" title="Guanine">
Guanine

Guanine (; or G, Gua) is one of the four main nucleobases found in the nucleic acids DNA and RNA, the others being adenine, cytosine, and thymine (uracil in RNA). In DNA, guanine is paired with cytosine. The guanine nucleoside is called guanosine.

With the formula CHNO, guanine is a derivative of purine, consisting of a fused pyrimidine-imidazole ring system with conjugated double bonds. This unsaturated arrangement means the bicyclic molecule is planar.

Guanine, along with adenine and cytosine, is present in both DNA and RNA, whereas thymine is usually seen only in DNA, and uracil only in RNA. Guanine has two tautomeric forms, the major keto form (see figures) and rare enol form.

It binds to cytosine through three hydrogen bonds. In cytosine, the amino group acts as the hydrogen bond donor and the C-2 carbonyl and the N-3 amine as the hydrogen-bond acceptors. Guanine has the C-6 carbonyl group that acts as the hydrogen bond acceptor, while a group at N-1 and the amino group at C-2 act as the hydrogen bond donors.

Guanine can be hydrolyzed with strong acid to glycine, ammonia, carbon dioxide, and carbon monoxide. First, guanine gets deaminated to become xanthine. Guanine oxidizes more readily than adenine, the other purine-derivative base in DNA. Its high melting point of 350 °C reflects the intermolecular hydrogen bonding between the oxo and amino groups in the molecules in the crystal. Because of this intermolecular bonding, guanine is relatively insoluble in water, but it is soluble in dilute acids and bases.

The first isolation of guanine was reported in 1844 by the German chemist (1819–1885), who obtained it as a mineral formed from the excreta of sea birds, which is known as guano and which was used as a source of fertilizer; guanine was named in 1846. Between 1882 and 1906, Fischer determined the structure and also showed that uric acid can be converted to guanine.

Trace amounts of guanine form by the polymerization of ammonium cyanide (). Two experiments conducted by Levy et al. showed that heating 10 mol·L at 80 °C for 24 hours gave a yield of 0.0007%, while using 0.1 mol·L frozen at −20 °C for 25 years gave a 0.0035% yield. These results indicate guanine could arise in frozen regions of the primitive earth. In 1984, Yuasa reported a 0.00017% yield of guanine after the electrical discharge of , , , and 50 mL of water, followed by a subsequent acid hydrolysis. However, it is unknown whether the presence of guanine was not simply a resultant contaminant of the reaction.

A Fischer-Tropsch synthesis can also be used to form guanine, along with adenine, uracil, and thymine. Heating an equimolar gas mixture of CO, H, and NH to 700 °C for 15 to 24 minutes, followed by quick cooling and then sustained reheating to 100 to 200 °C for 16 to 44 hours with an alumina catalyst, yielded guanine and uracil:

Another possible abiotic route was explored by quenching a 90% N–10%CO–HO gas mixture high-temperature plasma.

Traube's synthesis involves heating 2,4,5-triamino-1,6-dihydro-6-oxypyrimidine (as the sulfate) with formic acid for several hours.
Guanine is not synthesized de novo, instead it's split from more complex molecule, guanosine, by the enzyme guanosine phosphorylase:

The word guanine derives from the Spanish loanword "guano" ("bird/bat droppings"), which itself is from the Quechua word "wanu", meaning "dung". As the Oxford English Dictionary notes, guanine is "A white amorphous substance obtained abundantly from guano, forming a constituent of the excrement of birds".

In 1656 in Paris, a Mr. Jaquin extracted from the scales of the fish "Alburnus alburnus" so-called "pearl essence", which is crystalline guanine. In the cosmetics industry, crystalline guanine is used as an additive to various products (e.g., shampoos), where it provides a pearly iridescent effect. It is also used in metallic paints and simulated pearls and plastics. It provides shimmering luster to eye shadow and nail polish. Facial treatments using the droppings, or guano, from Japanese nightingales have been used in Japan and elsewhere, reportedly because the guanine in the droppings produces a clear, "bright" skin tone that users desire. Guanine crystals are rhombic platelets composed of multiple transparent layers, but they have a high index of refraction that partially reflects and transmits light from layer to layer, thus producing a pearly luster. It can be applied by spray, painting, or dipping. It may irritate the eyes. Its alternatives are mica, faux pearl (from ground shells), and aluminium and bronze particles.

Guanine has a very wide variety of biological uses that include a range of functions ranging in both complexity and versatility. These include camouflage, display, and vision among other purposes.

Spiders, scorpions, and some amphibians convert ammonia, as a product of protein metabolism in the cells, to guanine, as it can be excreted with minimal water loss.

Guanine is also found in specialized skin cells of fish called iridocytes (e.g., the sturgeon), as well as being present in the reflective deposits of the eyes of deep-sea fish and some reptiles, such as crocodiles.

On 8 August 2011, a report, based on NASA studies with meteorites found on Earth, was published suggesting building blocks of DNA and RNA (guanine, adenine and related organic molecules) may have been formed extra-terrestrially in outer space.




</doc>
<doc id="12441" url="https://en.wikipedia.org/wiki?curid=12441" title="Genocide">
Genocide

Genocide is the intentional action to destroy a people—usually defined as an ethnic, national, racial, or religious group—in whole or in part. A term coined by Raphael Lemkin in his 1944 book "Axis Rule in Occupied Europe", the hybrid word "genocide" is a combination of the Greek word (, "race, people") and the Latin suffix ("act of killing").

The United Nations Genocide Convention, which was established in 1948, defines genocide as "acts committed with intent to destroy, in whole or in part, a national, ethnic, racial or religious group, as such" including the killing of its members, causing serious bodily or mental harm to members of the group, deliberately imposing living conditions that seek to "bring about its physical destruction in whole or in part", preventing births, or forcibly transferring children out of the group to another group.

Examples include the Holocaust, the Armenian Genocide, the Cambodian genocide, and the Rwandan genocide.

The Political Instability Task Force estimated that, between 1956 and 2016, a total of 43 genocides took place, causing the death of about 50 million people. The UNHCR estimated that a further 50 million had been displaced by such episodes of violence up to 2008.

Before 1944, various terms, including "massacre," "extermination," and "crimes against humanity" were used to describe the intentional systematic killings. In 1941, Winston Churchill, when describing the German invasion of the Soviet Union, spoke of "a crime without a name".

In 1944, Raphael Lemkin created the term "genocide" in his book "Axis Rule in Occupied Europe". The book describes the implementation of Nazi policies in occupied Europe, and cites earlier mass killings. The term described the systematic destruction of a nation or people, and the word was quickly adopted by many in the international community. The word "genocide" is a combination of the Ancient Greek word "génos" (γένος, meaning "race" or "people") with the Latin "caedere" ("to kill"). The word "genocide" was used in indictments at the Nuremberg trials, held from 1945, but solely as a descriptive term, not yet as a formal legal term. The so-called Polish Genocide Trials of Arthur Greiser and Amon Leopold Goth in 1946 were the first trials in which judgments included the term genocide.

According to Lemkin, genocide was "a coordinated strategy to destroy a group of people, a process that could be accomplished through total annihilation as well as strategies that eliminate key elements of the group's basic existence, including language, culture, and economic infrastructure".
Lemkin defined genocide as follows:
The preamble to the 1948 Genocide Convention (CPPCG) notes that instances of genocide have taken place throughout history. But it was not until Lemkin coined the term and the prosecution of perpetrators of the Holocaust at the Nuremberg trials that the United Nations defined the crime of genocide under international law in the Genocide Convention.

Lemkin's lifelong interest in the mass murder of populations in the 20th century was initially in response to the killing of Armenians in 1915 and later to the mass murders in Nazi-controlled Europe. He referred to the Albigensian Crusade as "one of the most conclusive cases of genocide in religious history". He dedicated his life to mobilizing the international community, to work together to prevent the occurrence of such events. In a 1949 interview, Lemkin said "I became interested in genocide because it happened so many times. It happened to the Armenians, then after the Armenians, Hitler took action."

After the Holocaust, which had been perpetrated by Nazi Germany prior to and during World War II, Lemkin successfully campaigned for the universal acceptance of international laws defining and forbidding genocides. In 1946, the first session of the United Nations General Assembly adopted a resolution that "affirmed" that genocide was a crime under international law and enumerated examples of such events (but did not provide a full legal definition of the crime). In 1948, the UN General Assembly adopted the "Convention on the Prevention and Punishment of the Crime of Genocide" (CPPCG) which defined the crime of genocide for the first time.

The "CPPCG" was adopted by the UN General Assembly on 9 December 1948 and came into effect on 12 January 1951 (Resolution 260 (III)). It contains an internationally recognized definition of genocide which has been incorporated into the national criminal legislation of many countries, and was also adopted by the Rome Statute of the International Criminal Court, which established the International Criminal Court (ICC). Article II of the Convention defines genocide as:

The first draft of the convention included political killings, but these provisions were removed in a political and diplomatic compromise following objections from some countries, including the USSR, a permanent United Nations Security Council member. The USSR argued that the convention's definition should follow the etymology of the term, and may have feared greater international scrutiny of its own mass killings. Other nations feared that including political groups in the definition would invite international intervention in domestic politics. However leading genocide scholar William Schabas states: "Rigorous examination of the travaux fails to confirm a popular impression in the literature that the opposition to inclusion of political genocide was some Soviet machination. The Soviet views were also shared by a number of other States for whom it is difficult to establish any geographic or social common denominator: Lebanon, Sweden, Brazil, Peru, Venezuela, the Philippines, the Dominican Republic, Iran, Egypt, Belgium, and Uruguay. The exclusion of political groups was in fact originally promoted by a non-governmental organization, the World Jewish Congress, and it corresponded to Raphael Lemkin's vision of the nature of the crime of genocide."

Incitement to genocide is recognized as a separate crime under international law and an inchoate crime which does not require genocide to have taken place to be prosecutable.

Under international law, genocide has two mental (or "mens rea") elements – the general mental element and the element of specific intent ("dolus specialis"). The general element refers to the whether the prohibited acts were committed with intent, knowledge, recklessness, or negligence. For most serious international crimes, including genocide, the requirement is that the perpetrator act with intent. The Rome Statute defines intent as meaning to engage in the conduct and, in relation to consequences, as meaning to cause that consequence or being "aware that it will occur in the ordinary course of events".

The specific intent element defines the purpose of committing the acts: "to destroy in whole or in part, a national, ethnical, racial or religious group, as such". The specific intent is a core factor distinguishing genocide from other international crimes, such as war crimes or crimes against humanity.

In 2007, the European Court of Human Rights (ECHR) noted in its judgement on "Jorgic v. Germany" case that, in 1992, the majority of legal scholars took the narrow view that "intent to destroy" in the CPPCG meant the intended physical-biological destruction of the protected group, and that this was still the majority opinion. But the ECHR also noted that a minority took a broader view, and did not consider biological-physical destruction to be necessary, as the intent to destroy a national, racial, religious or ethnic group was enough to qualify as genocide.

In the same judgement, the ECHR reviewed the judgements of several international and municipal courts. It noted that the International Criminal Tribunal for the Former Yugoslavia and the International Court of Justice had agreed with the narrow interpretation (that biological-physical destruction was necessary for an act to qualify as genocide). The ECHR also noted that at the time of its judgement, apart from courts in Germany (which had taken a broad view), that there had been few cases of genocide under other Convention states' municipal laws, and that "There are no reported cases in which the courts of these States have defined the type of group destruction the perpetrator must have intended in order to be found guilty of genocide."

In the case of "Onesphore Rwabukombe", the German Supreme Court adhered to its previous judgement, and did not follow the narrow interpretation of the ICTY and the ICJ.

The phrase "in whole or in part" has been subject to much discussion by scholars of international humanitarian law. The International Criminal Tribunal for the Former Yugoslavia found in "Prosecutor v. Radislav Krstic – Trial Chamber I – Judgment – IT-98-33 (2001) ICTY8 (2 August 2001)" that Genocide had been committed. In "Prosecutor v. Radislav Krstic – Appeals Chamber – Judgment – IT-98-33 (2004) ICTY 7 (19 April 2004)" paragraphs 8, 9, 10, and 11 addressed the issue of "in part" and found that "the part must be a substantial part of that group. The aim of the Genocide Convention is to prevent the intentional destruction of entire human groups, and the part targeted must be significant enough to have an impact on the group as a whole." The Appeals Chamber goes into details of other cases and the opinions of respected commentators on the Genocide Convention to explain how they came to this conclusion.

The judges continue in paragraph 12, "The determination of when the targeted part is substantial enough to meet this requirement may involve a number of considerations. The numeric size of the targeted part of the group is the necessary and important starting point, though not in all cases the ending point of the inquiry. The number of individuals targeted should be evaluated not only in absolute terms, but also in relation to the overall size of the entire group. In addition to the numeric size of the targeted portion, its prominence within the group can be a useful consideration. If a specific part of the group is emblematic of the overall group, or is essential to its survival, that may support a finding that the part qualifies as substantial within the meaning of Article 4 [of the Tribunal's Statute]."

In paragraph 13 the judges raise the issue of the perpetrators' access to the victims: "The historical examples of genocide also suggest that the area of the perpetrators' activity and control, as well as the possible extent of their reach, should be considered. [...] The intent to destroy formed by a perpetrator of genocide will always be limited by the opportunity presented to him. While this factor alone will not indicate whether the targeted group is substantial, it can—in combination with other factors—inform the analysis."

The drafters of the CPPCG chose not to include political or social groups among the protected groups. Instead they opted to focus on "stable" identities, attributes that are historically understood as being born into and unable or unlikely to change overtime. This definition conflicts with modern conceptions of race as a social construct rather than innate fact and the practice of changing religion, etc.

International criminal courts have typically applied a mix of objective and subjective markers for determining whether or not the targeted population is a distinct group. Differences in language, physical appearance, religion, and cultural practices are objective criterion that may show that the groups are distinct. However, in circumstances such as the Rwandan genocide, Hutus and Tutsis were often physically indistinguishable.

In such a situation where a definitive answer based on objective markers is not clear, courts have turned to the subjective standard that "if a victim was perceived by a perpetrator as belonging to a protected group, the victim could be considered by the Chamber as a member of the protected group". Stigmatization of the group by the perpetrators through legal measures, such as withholding citizenship, requiring the group to be identified, or isolating them from the whole could show that the perpetrators viewed the victims as a protected group.

The Genocide Convention establishes five prohibited acts that, when committed with the requisite intent, amount to genocide. Although massacre-style killings are the most commonly identified and punished as genocide, the range of violence that is contemplated by the law is significantly broader.

While mass killing is not necessary to commit genocide, it has been present in every recognized genocide. A near-uniform pattern has emerged throughout history in which men and adolescent boys are singled out for murder in the early stages, such as in the genocide of the Yazidis by Daesh, the Ottoman Turks' attack on the Armenians, and the Burmese security forces' attacks on the Rohingya. Men and boys are typically subject to "fast" killings, such as by gunshot. Women and girls are more likely to die slower deaths by slashing, burning, or as a result of sexual violence. The jurisprudence of the International Criminal Tribunal for Rwanda (ICTR), among others, shows that both the initial executions and those that quickly follow other acts of extreme violence, such as rape and torture, are recognized as falling under the first prohibited act.

A less settled discussion is whether deaths that are further removed from the initial acts of violence can be addressed under this provision of the Genocide Convention. Legal scholars have posited, for example, that deaths resulting from other genocidal acts including causing serious bodily or mental harm or the successful deliberate infliction of conditions of life calculated to bring about physical destruction should be considered genocidal killings.

This second prohibited act can encompass a wide range of non-fatal genocidal acts. The ICTR and International Criminal Tribunal for the Former Yugoslavia (ICTY) have held that rape and sexual violence may constitute the second prohibited act of genocide by causing both physical and mental harm. In its landmark Akayesu decision, the ICTR held that rapes and sexual violence resulted in "physical and psychological destruction". Sexual violence is a hallmark of genocidal violence, with most genocidal campaigns explicitly or implicitly sanctioning it. It is estimated that 250,000 to 500,000 women were raped in the three months of the Rwandan genocide, many of whom were subjected to multiple rapes or gang rape. In Darfur, a systemic campaign of rape and often sexual mutilation was carried out and in Burma public mass rapes and gang rapes were inflicted on the Rohingya by Burmese security forces. Sexual slavery was documented in the Armenian Genocide by the Ottoman Turks and Daesh's genocide of the Yazidi. These acts are frequently, but not exclusively committed against women.

Torture and other cruel, inhuman, or degrading treatment or punishment, when committed with the requisite intent, are also genocide by causing serious bodily or mental harm to members of the group. The ICTY found that both experiencing a failed execution and watching the murder of one's family members may constitute torture. The Syrian Commission of Inquiry (COI) also found that enslavement, removal of one's children into indoctrination or sexual slavery, and acts of physical and sexual violence rise to the level of torture, as well. While it was subject to some debate, the ICTY and, later, the Syrian COI held that under some circumstances deportation and forcible transfer may also cause serious bodily or mental harm.

The third prohibited act is distinguished from the genocidal act of killing because the deaths are not immediate (or may not even come to pass), but rather create circumstances that do not support prolonged life. Due to the longer period of time before the actual destruction would be achieved, the ICTR held that courts must consider the duration of time the conditions are imposed as an element of the act. The drafters incorporated the act to account for the horrors of the Nazi concentration camps and to ensure that similar conditions never be imposed again. However, it could also apply to the Armenian death marches, the siege of Mount Sinjar by Daesh, the deprivation of water and forcible deportation against ethnic groups in Darfur, and the destruction and razing of communities in Burma.

The ICTR provided guidance into what constitutes a violation of the third act. In Akayesu, it identified "subjecting a group of people to a subsistence diet, systematic expulsion from homes and the reduction of essential medical services below minimum requirement" as rising to genocide. In Kayishema and Ruzindana, it extended the list to include: "lack of proper housing, clothing, hygiene and medical care or excessive work or physical exertion" among the conditions. It further noted that, in addition to deprivation of necessary resources, rape could also fit within this prohibited act.

The fourth prohibited act is aimed at preventing the protected group from regenerating through reproduction. It encompasses acts with the single intent of affecting reproduction and intimate relationships, such as involuntary sterilization, forced abortion, prohibition of marriage, and long-term separation of men and women intended to prevent procreation. Rape has been found to violate the fourth prohibited act on two bases: where the rape was committed with the intent to impregnate her and thereby force her to carry a child of another group (in societies where group identity is determined by patrilineal identity) and where the person raped subsequently refuses to procreate as a result of the trauma. Accordingly, it can take into account both physical and mental measures imposed by the perpetrators.

The final prohibited act is the only prohibited act which does not lead to physical or biological destruction, but rather to destruction of the group as a cultural and social unit. It occurs when children of the protected group are transferred to the perpetrator group. Boys are typically taken into the group through changing their names to those common of the perpetrator group, converting their religion, and using them for labor or as soldiers. Girls who are transferred are not generally converted to the perpetrator group, but instead treated as chattel, as played out in both the Yazidi and Armenian genocides. The measures used to forcibly transfer children may be imposed by direct force or psychological coercion, such as threats, duress, or detention.

The convention came into force as international law on 12 January 1951 after the minimum 20 countries became parties. At that time however, only two of the five permanent members of the UN Security Council were parties to the treaty: France and the Republic of China. The Soviet Union ratified in 1954, the United Kingdom in 1970, the People's Republic of China in 1983 (having replaced the Taiwan-based Republic of China on the UNSC in 1971), and the United States in 1988. This long delay in support for the convention by the world's most powerful nations caused the convention to languish for over four decades. Only in the 1990s did the international law on the crime of genocide begin to be enforced.

UN Security Council Resolution 1674, adopted by the United Nations Security Council on 28 April 2006, "reaffirms the provisions of paragraphs 138 and 139 of the 2005 World Summit Outcome Document regarding the responsibility to protect populations from genocide, war crimes, ethnic cleansing and crimes against humanity". The resolution committed the council to action to protect civilians in armed conflict.

In 2008 the UN Security Council adopted resolution 1820, which noted that "rape and other forms of sexual violence can constitute war crimes, crimes against humanity or a constitutive act with respect to genocide".

Since the Convention came into effect in January 1951 about 80 United Nations member states have passed legislation that incorporates the provisions of CPPCG into their municipal law.

William Schabas has suggested that a permanent body as recommended by the Whitaker Report to monitor the implementation of the Genocide Convention, and require States to issue reports on their compliance with the convention (such as were incorporated into the United Nations Optional Protocol to the Convention against Torture), would make the convention more effective.

Writing in 1998 Kurt Jonassohn and Karin Björnson stated that the CPPCG was a legal instrument resulting from a diplomatic compromise. As such the wording of the treaty is not intended to be a definition suitable as a research tool, and although it is used for this purpose, as it has an international legal credibility that others lack, other definitions have also been postulated. Jonassohn and Björnson go on to say that none of these alternative definitions have gained widespread support for various reasons.

Jonassohn and Björnson postulate that the major reason why no single generally accepted genocide definition has emerged is because academics have adjusted their focus to emphasise different periods and have found it expedient to use slightly different definitions to help them interpret events. For example, Frank Chalk and Kurt Jonassohn studied the whole of human history, while Leo Kuper and R. J. Rummel in their more recent works concentrated on the 20th century, and Helen Fein, Barbara Harff and Ted Gurr have looked at post World War II events. Jonassohn and Björnson are critical of some of these studies, arguing that they are too expansive, and conclude that the academic discipline of genocide studies is too young to have a canon of work on which to build an academic paradigm.

The exclusion of social and political groups as targets of genocide in the CPPCG legal definition has been criticized by some historians and sociologists, for example M. Hassan Kakar in his book "The Soviet Invasion and the Afghan Response, 1979–1982" argues that the international definition of genocide is too restricted, and that it should include political groups or any group so defined by the perpetrator and quotes Chalk and Jonassohn: "Genocide is a form of one-sided mass killing in which a state or other authority intends to destroy a group, as that group and membership in it are defined by the perpetrator." In turn some states such as Ethiopia, France, and Spain include political groups as legitimate genocide victims in their anti-genocide laws.

Barbara Harff and Ted Gurr defined genocide as "the promotion and execution of policies by a state or its agents which result in the deaths of a substantial portion of a group ... [when] the victimized groups are defined primarily in terms of their communal characteristics, i.e., ethnicity, religion or nationality". Harff and Gurr also differentiate between genocides and politicides by the characteristics by which members of a group are identified by the state. In genocides, the victimized groups are defined primarily in terms of their communal characteristics, i.e., ethnicity, religion or nationality. In politicides the victim groups are defined primarily in terms of their hierarchical position or political opposition to the regime and dominant groups. Daniel D. Polsby and Don B. Kates, Jr. state that "we follow Harff's distinction between genocides and 'pogroms', which she describes as 'short-lived outbursts by mobs, which, although often condoned by authorities, rarely persist'. If the violence persists for long enough, however, Harff argues, the distinction between condonation and complicity collapses."

According to R. J. Rummel, genocide has 3 different meanings. The ordinary meaning is murder by government of people due to their national, ethnic, racial, or religious group membership. The legal meaning of genocide refers to the international treaty, the "Convention on the Prevention and Punishment of the Crime of Genocide" (CPPCG). This also includes non-killings that in the end eliminate the group, such as preventing births or forcibly transferring children out of the group to another group. A generalized meaning of genocide is similar to the ordinary meaning but also includes government killings of political opponents or otherwise intentional murder. It is to avoid confusion regarding what meaning is intended that Rummel created the term democide for the third meaning.

Highlighting the potential for state and non-state actors to commit genocide in the 21st century, for example, in failed states or as non-state actors acquire weapons of mass destruction, Adrian Gallagher defined genocide as 'When a source of collective power (usually a state) intentionally uses its power base to implement a process of destruction in order to destroy a group (as defined by the perpetrator), in whole or in substantial part, dependent upon relative group size'. The definition upholds the centrality of intent, the multidimensional understanding of destroy, broadens the definition of group identity beyond that of the 1948 definition yet argues that a substantial part of a group has to be destroyed before it can be classified as genocide.

All signatories to the CPPCG are required to prevent and punish acts of genocide, both in peace and wartime, though some barriers make this enforcement difficult. In particular, some of the signatories—namely, Bahrain, Bangladesh, India, Malaysia, the Philippines, Singapore, the United States, Vietnam, Yemen, and former Yugoslavia—signed with the proviso that no claim of genocide could be brought against them at the International Court of Justice without their consent. Despite official protests from other signatories (notably Cyprus and Norway) on the ethics and legal standing of these reservations, the immunity from prosecution they grant has been invoked from time to time, as when the United States refused to allow a charge of genocide brought against it by former Yugoslavia following the 1999 Kosovo War.

It is commonly accepted that, at least since World War II, genocide has been illegal under customary international law as a peremptory norm, as well as under conventional international law. Acts of genocide are generally difficult to establish for prosecution, because a chain of accountability must be established. International criminal courts and tribunals function primarily because the states involved are incapable or unwilling to prosecute crimes of this magnitude themselves.

The Nazi leaders who were prosecuted shortly after World War II for taking part in the Holocaust, and other mass murders, were charged under existing international laws, such as crimes against humanity, as the crime of "genocide' was not formally defined until the 1948 "Convention on the Prevention and Punishment of the Crime of Genocide" (CPPCG). Nevertheless, the recently coined term appeared in the indictment of the Nazi leaders, Count 3, which stated that those charged had "conducted deliberate and systematic genocide—namely, the extermination of racial and national groups—against the civilian populations of certain occupied territories in order to destroy particular races and classes of people, and national, racial or religious groups, particularly Jews, Poles, Gypsies and others."

The term "Bosnian genocide" is used to refer either to the killings committed by Serb forces in Srebrenica in 1995, or to ethnic cleansing that took place elsewhere during the 1992–1995 Bosnian War.

In 2001, the International Criminal Tribunal for the Former Yugoslavia (ICTY) judged that the 1995 Srebrenica massacre was an act of genocide. On 26 February 2007, the International Court of Justice (ICJ), in the "Bosnian Genocide Case" upheld the ICTY's earlier finding that the massacre in Srebrenica and Zepa constituted genocide, but found that the Serbian government had not participated in a wider genocide on the territory of Bosnia and Herzegovina during the war, as the Bosnian government had claimed.

On 12 July 2007, European Court of Human Rights when dismissing the appeal by Nikola Jorgić against his conviction for genocide by a German court (Jorgic v. Germany) noted that the German courts wider interpretation of genocide has since been rejected by international courts considering similar cases. The ECHR also noted that in the 21st century "Amongst scholars, the majority have taken the view that ethnic cleansing, in the way in which it was carried out by the Serb forces in Bosnia and Herzegovina in order to expel Muslims and Croats from their homes, did not constitute genocide. However, there are also a considerable number of scholars who have suggested that these acts did amount to genocide, and the ICTY has found in the Momcilo Krajisnik case that the actus reus of genocide was met in Prijedor "With regard to the charge of genocide, the Chamber found that in spite of evidence of acts perpetrated in the municipalities which constituted the actus reus of genocide".

About 30 people have been indicted for participating in genocide or complicity in genocide during the early 1990s in Bosnia. To date, after several plea bargains and some convictions that were successfully challenged on appeal two men, Vujadin Popović and Ljubiša Beara, have been found guilty of committing genocide, Zdravko Tolimir has been found guilty of committing genocide and conspiracy to commit genocide, and two others, Radislav Krstić and Drago Nikolić, have been found guilty of aiding and abetting genocide. Three others have been found guilty of participating in genocides in Bosnia by German courts, one of whom Nikola Jorgić lost an appeal against his conviction in the European Court of Human Rights. A further eight men, former members of the Bosnian Serb security forces were found guilty of genocide by the State Court of Bosnia and Herzegovina (See List of Bosnian genocide prosecutions).

Slobodan Milošević, as the former President of Serbia and of Yugoslavia, was the most senior political figure to stand trial at the ICTY. He died on 11 March 2006 during his trial where he was accused of genocide or complicity in genocide in territories within Bosnia and Herzegovina, so no verdict was returned. In 1995, the ICTY issued a warrant for the arrest of Bosnian Serbs Radovan Karadžić and Ratko Mladić on several charges including genocide. On 21 July 2008, Karadžić was arrested in Belgrade, and later tried in The Hague accused of genocide among other crimes. On 24 March 2016, Karadžić was found guilty of genocide in Srebrenica, war crimes and crimes against humanity, 10 of the 11 charges in total, and sentenced to 40 years' imprisonment. Mladić was arrested on 26 May 2011 in Lazarevo, Serbia, and was tried in The Hague. The verdict, delivered on 22 November 2017 found Mladić guilty of 10 of the 11 charges, including genocide and he was sentenced to life imprisonment.

The International Criminal Tribunal for Rwanda (ICTR) is a court under the auspices of the United Nations for the prosecution of offenses committed in Rwanda during the genocide which occurred there during April 1994, commencing on 6 April. The ICTR was created on 8 November 1994 by the Security Council of the United Nations in order to judge those people responsible for the acts of genocide and other serious violations of the international law performed in the territory of Rwanda, or by Rwandan citizens in nearby states, between 1 January and 31 December 1994.

So far, the ICTR has finished nineteen trials and convicted twenty seven accused persons. On 14 December 2009 two more men were accused and convicted for their crimes. Another twenty five persons are still on trial. Twenty-one are awaiting trial in detention, two more added on 14 December 2009. Ten are still at large. The first trial, of Jean-Paul Akayesu, began in 1997. In October 1998, Akayesu was sentenced to life imprisonment. Jean Kambanda, interim Prime Minister, pleaded guilty.

The Khmer Rouge, led by Pol Pot, Ta Mok and other leaders, organized the mass killing of ideologically suspect groups. The total number of victims is estimated at approximately 1.7 million Cambodians between 1975–1979, including deaths from slave labour.

On 6 June 2003 the Cambodian government and the United Nations reached an agreement to set up the Extraordinary Chambers in the Courts of Cambodia (ECCC) which would focus exclusively on crimes committed by the most senior Khmer Rouge officials during the period of Khmer Rouge rule of 1975–1979. The judges were sworn in early July 2006.

The genocide charges related to killings of Cambodia's Vietnamese and Cham minorities, which is estimated to make up tens of thousand killings and possibly more

The investigating judges were presented with the names of five possible suspects by the prosecution on 18 July 2007.

There has been disagreement between some of the international jurists and the Cambodian government over whether any other people should be tried by the Tribunal.

Since 2002, the International Criminal Court can exercise its jurisdiction if national courts are unwilling or unable to investigate or prosecute genocide, thus being a "court of last resort," leaving the primary responsibility to exercise jurisdiction over alleged criminals to individual states. Due to the United States concerns over the ICC, the United States prefers to continue to use specially convened international tribunals for such investigations and potential prosecutions.

There has been much debate over categorizing the situation in Darfur as genocide. The ongoing conflict in Darfur, Sudan, which started in 2003, was declared a "genocide" by United States Secretary of State Colin Powell on 9 September 2004 in testimony before the Senate Foreign Relations Committee. Since that time however, no other permanent member of the UN Security Council has done so. In fact, in January 2005, an International Commission of Inquiry on Darfur, authorized by UN Security Council Resolution 1564 of 2004, issued a report to the Secretary-General stating that "the Government of the Sudan has not pursued a policy of genocide." Nevertheless, the Commission cautioned that "The conclusion that no genocidal policy has been pursued and implemented in Darfur by the Government authorities, directly or through the militias under their control, should not be taken in any way as detracting from the gravity of the crimes perpetrated in that region. International offences such as the crimes against humanity and war crimes that have been committed in Darfur may be no less serious and heinous than genocide."

In March 2005, the Security Council formally referred the situation in Darfur to the Prosecutor of the International Criminal Court, taking into account the Commission report but without mentioning any specific crimes. Two permanent members of the Security Council, the United States and China, abstained from the vote on the referral resolution. As of his fourth report to the Security Council, the Prosecutor has found "reasonable grounds to believe that the individuals identified [in the UN Security Council Resolution 1593] have committed crimes against humanity and war crimes," but did not find sufficient evidence to prosecute for genocide.

In April 2007, the Judges of the ICC issued arrest warrants against the former Minister of State for the Interior, Ahmad Harun, and a Militia
Janjaweed leader, Ali Kushayb, for crimes against humanity and war crimes.

On 14 July 2008, prosecutors at the International Criminal Court (ICC), filed ten charges of war crimes against Sudan's President Omar al-Bashir: three counts of genocide, five of crimes against humanity and two of murder. The ICC's prosecutors claimed that al-Bashir "masterminded and implemented a plan to destroy in substantial part" three tribal groups in Darfur because of their ethnicity.

On 4 March 2009, the ICC issued a warrant of arrest for Omar Al Bashir, President of Sudan as the ICC Pre-Trial Chamber I concluded that his position as head of state does not grant him immunity against prosecution before the ICC. The warrant was for war crimes and crimes against humanity. It did not include the crime of genocide because the majority of the Chamber did not find that the prosecutors had provided enough evidence to include such a charge. Later the decision was changed by the Appeals Panel and after issuing the second decision, charges against Omar al-Bashir include three counts of genocide.

The concept of genocide can be applied to historical events of the past. The preamble to the CPPCG states that "at all periods of history genocide has inflicted great losses on humanity."

Revisionist attempts to challenge or affirm claims of genocide are illegal in some countries. For example, several European countries ban the denial of the Holocaust or the Armenian Genocide, while in Turkey referring to the mass killings of Armenians, Greeks, Assyrians and Maronites as genocides may be prosecuted under Article 301.

William Rubinstein argues that the origin of 20th century genocides can be traced back to the collapse of the elite structure and normal modes of government in parts of Europe following the First World War:

In 1996 Gregory Stanton, the president of Genocide Watch, presented a briefing paper called "The 8 Stages of Genocide" at the United States Department of State. In it he suggested that genocide develops in eight stages that are "predictable but not inexorable".

The Stanton paper was presented to the State Department, shortly after the Rwandan Genocide and much of its analysis is based on why that genocide occurred. The preventative measures suggested, given the briefing paper's original target audience, were those that the United States could implement directly or indirectly by using its influence on other governments.

In April 2012, it was reported that Stanton would soon be officially adding two new stages, Discrimination and Persecution, to his original theory, which would make for a 10-stage theory of genocide.

In a paper for the Social Science Research Council Dirk Moses criticises the Stanton approach, concluding:

Other authors have focused on the structural conditions leading up to genocide and the psychological and social processes that create an evolution toward genocide. Ervin Staub showed that economic deterioration and political confusion and disorganization were starting points of increasing discrimination and violence in many instances of genocides and mass killing. They lead to scapegoating a group and ideologies that identified that group as an enemy. A history of devaluation of the group that becomes the victim, past violence against the group that becomes the perpetrator leading to psychological wounds, authoritarian cultures and political systems, and the passivity of internal and external witnesses (bystanders) all contribute to the probability that the violence develops into genocide. Intense conflict between groups that is unresolved, becomes intractable and violent can also lead to genocide. The conditions that lead to genocide provide guidance to early prevention, such as humanizing a devalued group, creating ideologies that embrace all groups, and activating bystander responses. There is substantial research to indicate how this can be done, but information is only slowly transformed into action.

Kjell Anderson uses a dichotomistic classification of genocides: "hot genocides, motivated by hate and the victims' threatening nature, with low-intensity cold genocides, rooted in victims' supposed inferiority."





</doc>
<doc id="12442" url="https://en.wikipedia.org/wiki?curid=12442" title="George Clinton">
George Clinton

George Clinton may refer to:






</doc>
<doc id="12446" url="https://en.wikipedia.org/wiki?curid=12446" title="Germanic peoples">
Germanic peoples

The Germanic peoples (from ) are a category of north European ethnic groups, first mentioned by Graeco-Roman authors. They are also associated with Germanic languages, which originated and dispersed among them, and are one of several criteria used to define Germanic ethnicity. 

Although the English language possesses the adjective "Germanic" as distinct from "German", it lacks an equivalent distinct noun. The terms "Germanic peoples" and "Germani" are therefore used by modern English-speaking scholars to avoid confusion with the inhabitants of present-day Germany ("Deutschland"), including the modern "German" ("Deutsche") people and language.

Starting with Julius Caesar (100–44 BCE), several Roman Empire authors placed their homeland, "Germania", roughly between the Lower Rhine (west) and the Vistula Rivers (east), and distinguished them from other broad categories of peoples better known to Rome, especially the Celtic Gauls to their southwest, and "Scythian" Sarmatians to their further east and southeast. Greek writers, in contrast, consistently categorized the Germanic peoples from east of the Rhine as Gauls. And with the possible exception of some groups near the Rhine, there is no evidence that the Germanic peoples called themselves or their lands "Germanic" (see below). Latin and Greek writers report centuries of historical interactions with Germanic peoples on the Rhine and Danube River border regions, but from about 400, several long-established Germanic peoples on the Middle Danube were replaced by newcomers migrating from the further north or east of Europe. The description of peoples as Germanic in late antiquity was mainly restricted to those in the Rhine region, and thus referred to the Franks especially, and sometimes also the Alamanni.

Broader modern definitions of the Germanic peoples include peoples who were not known as "Germani" or Germanic peoples in their own time, but who are treated as one group of cultures, mostly because of their use of Germanic languages. Thus, in modern writing, "Germanic peoples" is a term which commonly includes peoples who were not referred to as Germanic by their contemporaries, and spoke distinct languages, but only categorized as Germanic in modern times. Examples include the late Roman era Goths, or the early medieval Norse-speaking Vikings in Scandinavia.

The languages of the earliest known Germanic peoples of classical antiquity have left only fragmentary evidence. The first long texts which have survived were written outside "Germania" in the Gothic language from the region that is today Ukraine. Languages in this family are widespread today in Europe, and have dispersed worldwide, the family being represented by major modern languages such as English, Dutch, Nordic languages and German. The Eastern Germanic branch of the Germanic language family, once found in what is now Poland and Ukraine, is extinct.

Apart from language and geography, proposed connections between the diverse Germanic peoples described by classical and medieval sources, archaeology, and linguistics are the subject of ongoing debate among scholars:

In the 21st century, genetic studies have begun to look more systematically at questions of ancestry, using both modern and ancient DNA. However, the connection between modern Germanic languages, ethnicity and genetic heritage is thought by many scholars to be unlikely to ever be simple or uncontroversial. Guy Halsall for example writes: "The danger, barely addressed (at best dismissed as a purely 'ideological' objection), is of reducing ethnicity to biology and thus to something close to the nineteenth-century idea of race, at the basis of the 'nation state'."
Julius Caesar published the first basic description, possibly based on discussions with Gaulish allies during his campaign in Gaul, of what makes any people or peoples "Germanic", rather than for example Gaulish. The implied definition involved several criteria, allowing the possibility of debatable cases. Definitions of Germanic peoples continue to involve discussion of similar criteria:


In modern times, attempts to define characteristics which unite all or some of these peoples more objectively, using linguistic or archaeological criteria, have thus led to the possibility of the term "Germanic" being used to apply to more peoples, in other periods and regions. However, these definitions are still based upon the old definitions, and overlap with them. 

Such modern definitions have focused attention upon uncertainties and disagreements about the ethnic origins and backgrounds of both early Roman-era Germanic peoples, and late-Roman Germanic peoples.

According to all available evidence, the theoretical concept of the Germanic peoples as a large grouping distinct from the Gauls—whose homeland was east of the Rhine, and included areas very far from it—originated with Julius Caesar's published account of his "Gallic Wars", and specifically those parts concerning his battles near the Rhine. Importantly for all future conceptions of what Germanic means, Caesar was apparently the first to categorize distant peoples such as the Cimbri and the large group of Suevian peoples as "Germanic". The Suevians and their languages, which had perhaps never been called Germanic before then, had started expanding their influence in his time, as Caesar experienced personally. Caesar's categorization of the "Germani" was in the context of explaining his battle against Ariovistus, who had been a Roman ally. He led a large and armed population, made up of several peoples from east of the Rhine, including significant Suevian contingents. Rome had suffered a history of Gaulish invasions from the distant north, including those by the Cimbri, whom they had previously categorized as Gauls. Caesar, while describing his subsequent use of Roman soldiers deep in Gaulish territory, categorized the Cimbri, together with the peoples allied under Ariovistus, not as Gaulish, but as "Germanic", apparently using an ethnic term that was more local to the Rhine region where he fought Ariovistus. Modern scholars are undecided about whether the Cimbri were Germanic speakers like the Suevians, and even where exactly they lived in northern Europe, though it is likely to have been in or near Jutland. Caesar thus proposed that these more distant peoples were the cause of invasions into Italy. His solution was controlling Gaul, and defending the Rhine as a boundary against these "Germani".

Several Roman writers—Strabo (about 63 BCE – 24 CE), Pliny the Elder (about 23–79 CE), and especially Tacitus (about 56–120 CE)—followed Caesar's tradition in the next few generations, by partly defining the Germanic peoples of their time geographically, according to their presumed homeland. This ""Germania magna"", or Greater "Germania", was seen as a large wild country roughly east of the Rhine, and north of the Danube, but not everyone from within the area bounded by those rivers was ever described by Roman authors as Germanic, and not all "Germani" lived there. The opening of Tacitus's "Germania" gave a rough definition only:
Germania is separated from the Gauls, the Rhaetians, and Pannonii, by the rivers Rhine and Danube. Mountain ranges, or the fear which each feels for the other, divide it from the Sarmatians and Dacians.

It is the northern part of Greater "Germania", including the North European Plain, Southern Scandinavia, and the Baltic coast that was presumed to be the original Germanic homeland by early Roman authors such as Caesar and Tacitus. (Modern scholars also see the central part of this area, between the Elbe and the Oder, as the region from which Germanic languages dispersed.) In the east, "Germania magna's" boundaries were unclear according to Tacitus, although geographers such as Ptolemy and Pomponius Mela took it to be the Vistula. For Tacitus the boundaries of Germania stretched further, to somewhere east of the Baltic Sea in the north, and its people blended with the "Scythian" (or Sarmatian) steppe peoples in the area of today's Ukraine in the south. In the north, greater "Germania" stretched all the way to the relatively unknown Arctic Ocean. In contrast, in the south of Greater "Germania" nearer the Danube, the Germanic peoples were seen by these Roman writers as immigrants or conquerors, living among other peoples whom they had come to dominate. More specifically, Tacitus noted various Suevian Germanic-speaking peoples from the Elbe river in the north, such as the Marcomanni and Quadi, pushing into the Hercynian forest regions towards the Danube, where the Gaulish Volcae, Helvetii and Boii had lived.

Roman writers who added to Caesar's theoretical description, especially Tacitus, also at least partly defined the "Germani" by non-geographic criteria such as their economy, religion, clothing, and language. Caesar had, for example, previously noted that the "Germani" had no druids, and were less interested in farming than Gauls, and also that Gaulish ("lingua gallica") was a language the Germanic King Ariovistus had to learn. Tacitus mentioned Germanic languages at least three times, each mention concerning eastern peoples whose ethnicity was uncertain, and such remarks are seen by some modern authors as evidence of a unifying Germanic language. His comments are not detailed, but they indicate that there were Suevian languages (plural) "within" the category of Germanic languages, and that customs varied between different Germanic peoples. For example:
Tacitus says nothing about the languages of the "Germani" living near the Rhine.

The etymology of the Latin word "Germani", from which Latin "Germania", and English "Germanic" are derived, is unknown, although several different proposals have been made. Even the language from which it derives is a subject of dispute.
Whatever it meant, the name probably applied originally only to a smaller group of people, the so-called ""Germani cisrhenani"", whose Latin scholarly name simply indicates that these were "Germani" living on the western side of the Rhine (see below). Tacitus reported that these Germanic peoples in Gaul, ancestors of the Tungri of his time, were the first people to be called "Germani". According to Tacitus, their name had transferred to peoples such as those within the alliance of Ariovistus, as a name having connotations that frightened potential enemies. While Caesar and Tacitus saw this Rhineland people as Germanic in the broader sense also, they do not fit easily with the much broader definitions of "Germanic" used by them or modern scholars. These original "Germani" are therefore a significant complication for all attempts to define the Germanic peoples according to which side of the Rhine they lived on, or according to their probable language.
Caesar described how the country of these "Germani cisrhenani" stretched well west of the Lower Rhine, into what is now Belgium, and how it had done so long before the Romans came into close contact. Neither Caesar nor Tacitus saw this as clashing with their broader definitions, because they believed these "Germani" had moved from east of the Rhine, where the other "Germani" lived. But this event was not recent: Caesar reported that they were already on the west side during the Cimbrian War (113–101 BCE), generations earlier. The early "Germani" on both sides of the Lower Rhine were however distinguished from the Suevian "Germani" by Caesar, Tacitus, Pliny the Elder, and Strabo. Strabo even said that the "Germani" near the Rhine not only differed little from the Celts, but also that the Latin-speakers called them "Germani" because they were the "genuine" Gauls (which is a possible meaning of "Germani" in Latin). Modern historical linguists and archaeologists have also come to doubt that these western "Germani" spoke a Germanic language as defined today, or shared the same material culture, at least at the time of their first contact with Caesar and the Romans. Caesar himself refers to them also as Gauls.

The older concept of the "Germani" being local to the Rhine, and especially the west bank of the lower Rhine, remained common among Graeco-Roman writers for a longer time than the more theoretical and general concept of Caesar. Cassius Dio writing in Greek in the 3rd century, consistently called the right-bank "Germani" of Caesar, the Celts (Κελτοί) and their country "Keltikḗ" (Κελτική). Cassius contrasted them with the "Gauls" ("Γαλάται") on the left bank of the Rhine, and described Caesar doing the same in a speech. He reported that the peoples on either side of the Rhine had long ago taken to using these contrasting names, treating it as a boundary, but "very anciently both peoples dwelling on either side of the river were called Celts". For Cassius Dio, the only "Germani" and the only "Germania" were west of the Rhine within the empire: "some of the Celts ("Keltoí"), whom we call Germans ("Germanoí")", had "occupied all the Belgic territory ["Belgikḗ"] along the Rhine and caused it to be called Germany ["Germanía"]".

At least two well-read 6th century Byzantine writers, Agathias and Procopius, understood the Franks on the Rhine to effectively be the old "Germani" under a new name, since, as Agathias wrote, they inhabit the banks of the Rhine and the surrounding territory.

All surviving written evidence implying any clear "Germanic" concept, broad or narrow, from before Julius Caesar is doubtful and unclear. There are two or three cases to consider.

After Caesar, Roman authors such as Tacitus followed his example in using the Germanic terminology to refer retroactively to peoples known to the Romans or Greeks before Caesar. As noted above, the Cimbri had previously been described as Celtic or Cimmerian, and Greek writers continued to do so, while Caesar described them as Germanic. Tacitus and Strabo both proposed with some uncertainty that the Bastarnae, a large people known to the Graeco-Roman world before Caesar, from the region of what is now Ukrainian Galicia and Moldava, might also have had mixed Germanic ancestry, and according to Tacitus, even a Germanic language. Pliny the Elder categorized them as a separate major division of the "Germani" like Istvaeones, Ingvaeones, and Irminones, but also separate from an eastern group which contained the Vandals and the Gutones, both in what is now Poland. (As already mentioned however, Livy said they spoke a language like that of the Scordisci.)

The theoretical descriptions of Germanic peoples by Tacitus, which have been very influential in modern times, may never have been commonly read or used in the Roman era. It is clear in any case that in later Roman times the Rhine frontier (or "Limes Germanicus"), the area where Caesar had first come in contact with Suevians and "Germani cisrhenani", was the normal "Germanic" area mentioned in writing. Walter Goffart has written that "the one incontrovertible Germanic thing" in the Roman era was "the two Roman provinces of 'Germania,' on the middle and lower course of the Rhine river" and: "Whatever 'Germania' had meant to Tacitus, it had narrowed by the time of St Jerome to an archaic or poetic term for the land normally called Francia". Edward James similarly wrote:
It seems clear that in the fourth century 'German' was no longer a term which included all western barbarians. [...] Ammianus Marcellinus, in the later fourth century, uses "Germania" only when he is referring to the Roman provinces of Upper Germany and Lower Germany; east of "Germania" are "Alamannia" and "Francia".

As an exceptional case, the poet Sidonius Apollinaris, living in what is now southern France, described the Burgundians of his time as speaking a "Germanic" tongue and being ""Germani"". Wolfram has proposed that this word was chosen not because of a comparison of languages, but because the Burgundians had come from the Rhine region, and even argued that the use of this word by Sidonius might be seen as evidence against Burgundians being speakers of East Germanic, given that the East Germanic-speaking Goths, also present in southern France at this time, were never described this way.

Far from the Rhine, the Gothic peoples in what is today Ukraine, and the Anglo-Saxons in the British Isles, were called Germanic in only one surviving classical text, by Zosimus (5th century), but this was an instance in which he mistakenly believed he was writing about Rhineland peoples. Otherwise, Goths and similar peoples such as the Gepids, were consistently described as Scythian.

In the Greek-speaking eastern Roman empire which continued to exist during the Middle Ages, the concept of "Germanic" was also lost or distorted. As explained by Walter Pohl, the late Roman equation of the Franks with the Germani led there to such non-classical contrasts as the French (West Franks) being "Germani" and the Germans (East Franks) being "Alamanni", or the Normans in Sicily being Franks, but the French being "Franks and also "Germani"". In the "Strategikon" of Maurice, written about 600, a contrast is made between three types of barbarian: Scythians, Slavs, and "blonde-haired" peoples such as the Franks and Langobards - apparently having no convenient name to cover them together.

Medieval writers in western Europe used Caesar's old geographical concept of "Germania", which, like the new Frankish and clerical jurisdictions of their time, used the Rhine as a frontier marker, although they did not commonly refer to any contemporary "Germani". For example, Louis the German ("") was named this way because he ruled east of the Rhine, and in contrast the kingdom west of the Rhine was still called "Gallia" (Gaul) in scholarly Latin.

Writers using Latin in West Germanic-speaking areas did recognize that those languages were related (Dutch, English, Lombardic, and German). To describe this fact they referred to "Teutonic" words and languages, seeing the nominative as a Latin translation of "Theodiscus", which was a concept that West Germanic speakers used to refer to themselves. It is the source of the modern words "Dutch", German "Deutsch", and Italian "Tedesco". Romance language speakers and others such as the Welsh were contrasted using words based on another old word, "Walhaz", the source of "Welsh", Wallach, Welsch, Walloon, etc., itself derived from the name of the Volcae, a Celtic group. Only a small number of writers were influenced by Tacitus, whose work was known at Fulda Abbey, and few used terminology such as "lingua Germanica" instead of "theudiscus sermo".

On the other hand, there were several more origin myths written after Jordanes (see above) which similarly connected some of the post Roman peoples to a common origin in Scandinavia. As pointed out by Walter Pohl, Paul the Deacon even implied that the Goths, like the Lombards, "descended from" "Germanic peoples", though it is unclear if they continued to be "Germanic" after leaving the north. Frechulf of Lisieux observed that some of his contemporaries believed that the Goths might belong to the ""nationes Theotistae"", like the Franks, and that both the Franks and the Goths might have come from Scandinavia. It is in this period, the 9th century Carolingian era, that scholars are also first recorded speculation about relationships between Gothic and West Germanic languages. Smaragdus of Saint-Mihiel believed the Goths spoke a "teodisca lingua" like the Franks, and Walafrid Strabo, calling it a "theotiscus sermo", was even aware of their Bible translation. However, though the similarities were noticed, Gothic would not have been intelligible to a West Germanic speaker.

The first detailed origins legend of the Anglo-Saxons was by Bede (died 735), and in his case he named the Angles and Saxons of Britain as peoples who once lived in "Germania", like, he says, the Frisians, Rugians, Danes, Huns, Old Saxons ("Antiqui Saxones") and the Bructeri. He even says that British people still call them, corruptly, ""Garmani"". As with Jordanes and the Gutones, there is other evidence, linguistic and archaeological, which is consistent with his scholarly account, although this does not prove that Bede's non-scholarly contemporaries had accurate knowledge of historical details.

In western Europe then, there was limited scholarly awareness of the Tacitean "Germanic peoples", and even their potential connection to the Goths, but much more common were adherence to Caesar's concept of the geographical meaning of "Germania" east of the Rhine, and a perception of similarities between some Germanic languages - though they were not given this name until much later.

The ethnic military kingdoms which formed in the western Roman empire (see below) each developed their own legends about their ethnic origins, the so-called "Origo gentis" stories. These often included an ancient connection to Romans or Trojans, as apparently in the origin stories of the Franks, Burgundians and English, and they also typically mentioned the wild east of "Scythia". However, Jordanes (6th century), who wrote the most detailed surviving Gothic origins story, did effectively propose a connection to northern regions which much earlier authors had described as the remotest parts of "Germania", and established a tradition of connecting the earliest origins of Goths and other peoples to Scandinavia, which was for him a distant and almost unknown island. He thus connected the Goths ("Gothi") not only with ancient Amazons, Trojans, Huns, and the similarly-named Getae, but also to the Baltic sea. Some modern writers, such as Wolfram and Heather, still see this as confirmed by the mention of similar sounding "Gutones" near the south Baltic coast in earlier authors such as Tacitus and Ptolemy. Others have noted that Jordanes himself believed the Goths would have left the region centuries before those writers, making the identification doubtful. Indeed, he or his sources must have derived many of the names of ancient peoples and places from reading old Latin and Greek authors.

Very influentially, Jordanes called Scandinavia a "womb of nations" ("vagina nationum"), asserting that many peoples came from there in prehistoric times. This idea influenced later origin legends including the Lombard origin story, written by Paul the Deacon (8th century) who opens his work with an explanation of the theory. During the Carolingian renaissance he and other scholars even sometimes used the Germanic terminology. (See below.) The Scandinavian origin theme was still influential in medieval times and has even been influential in early modern speculations about Germanic peoples, for example in proposals about the origins of not only Goths and Gepids, but also of Rugians and Burgundians.

The citing of Jordanes and similar writers to attempt to prove that the Goths were "Germanic" in more than language continues to arouse debate among scholars, because while his work is unreliable, the Baltic connection on its own is consistent with linguistic and archaeological evidence. However, Walter Goffart in particular has criticized the methodology of many modern scholars for using Jordanes and other origins stories as independent sources of real tribal memories, but only when it matches their beliefs arrived at in other ways.

During the Renaissance there was a rediscovery and renewed interest in secular writings of classical antiquity. By the late 15th century, Tacitus had become a focus of interest all around Europe, and, among other effects, this revolutionized ideas in Germany concerning the history of Germany itself. Tacitus continues to be an important influence in Germanic studies of antiquity, and is often read together with the "Getica" of Jordanes, who wrote much later.
Tacitus's ethnography won the attention it had formerly been denied because there now was a Germany, the "German nation" that had come into existence since the Carolingians, which Tacitus could now equip with a heaven-sent ancient dignity and pedigree.

In this context, in the 19th century, the famous folklorist and linguist Jacob Grimm helped popularize the concept of Germanic languages as well as of Indo-european languages. Apart from the well-known Grimm's Fairy Tales, collected with his brother Wilhelm, he published, for example, "Deutsche Mythologie" attempting to reconstruct Germanic mythology, and a German dictionary, "Deutsches Wörterbuch", with detailed etymological proposals attempting to reconstruct the oldest Germanic language. He also popularized a new idea of these Germanic speakers, especially those in Germany, as clinging valiantly to their supposed Germanic civilization over the centuries.

The subsequently popular modern assertion of strong cultural continuity between Roman-era "Germani" and medieval or modern Germanic speakers, especially Germans, assumed a strong connection between a family trees of language categories, and both cultural and racial heritages. The name of the newly defined language family, "Germanic", was long unpopular in other countries such as England, where the medieval "Teutonic" was seen as less potentially misleading. Similarly, in Denmark "Gothic" was sometimes used as a term for the language group uniting the "Germani" and the Goths, and a modified Gothonic was proposed by Gudmund Schütte and used locally.

This romanticist, nationalist approach has been rejected by scholars in its simplest forms since approximately World War II. For example, the once common habit of referring to Roman-era Germanic peoples as "Germans" is discouraged by modern historians, and modern Germans are no longer seen as the main successors of the "Germani". Not only are ideas associated with Nazism now criticized, but also other romanticized ideas about the Germanic peoples. For example, Guy Halsall has mentioned the popularity of the "view of the peoples of Germania as, essentially, proto-democratic communes of freemen". [Peter Heather]] has pointed out as well that the Marxist theory "that some of Europe's barbarians were ultimately responsible for moving Europe onwards to the feudal modern of production has also lost much of its force".

Further, some historians now question whether there was any unifying Germanic culture even in Roman times, and secondly whether there was any significant continuity at all apart from language, connecting the Roman era Germanic peoples with the mixed new ethnic groups who formed in late antiquity. Sceptics of such connections include Walter Goffart, and others associated with him and the University of Toronto. Goffart lists four "contentions" about how the Germanic terminology biases the conclusions of historians, and is therefore misleading:

On the other hand, the possibility of a small but significant "core of tradition" ("Traditionskern") surviving with the ruling classes of Roman Germanic peoples, in the societies of new medieval Germanic-speaking peoples such as the Franks, Alamanni, Anglo-Saxons, and Goths, continues to be defended by other historians. This "Traditionskern" concept is associated for example with the Vienna School of History, initiated by Reinhard Wenskus, and later represented by scholars such as Herwig Wolfram and Walter Pohl.

Peter Heather for example, continues to use the Germanic terminology but writes that concerning proposals of Germanic continuity, "all subsequent discussion has accepted and started from Wenskus's basic observations" and "the "Germani" in the first millenium were thus not closed groups with continuous histories". Heather however believes that such caution now often goes too far in denying any large scale movements of people in specific cases, as exemplified by Patrick Amory's explanation of the Ostrogoths and their Kingdom of Italy.

Another proponent of relatively significant continuity, Wolf Liebeschuetz, has argued that the shared use of Germanic languages by, for example, Anglo-Saxons and Goths, implies that they must have had more links to "Germania" than only language. While little concrete evidence has survived, Liebeschuetz proposes that the existence of Weregild laws, stipulating compensation payments to avoid blood feuds, must have been of Germanic origin because such laws were not Roman. Liebeschuetz also argues that recent sceptical scholars "deprive the ancient Germans and their constituent tribes of any continuous identity" and this is "important" because it makes European history a product of Roman history, not "a joint creation of Roman and Germans".

Archaeologists divide the area of Roman-era "Germania" into several Iron Age "material cultures". At the time of Caesar, all had been under the strong influence of the La Tène culture, an old culture in the south and west of "Germania", which is strongly associated with Celtic-speaking Gauls, including those in Gaul itself. These La Tène peoples, who included the "Germani cisrhenani", are generally considered unlikely to have spoken Germanic languages as defined today, though some may have spoken unknown related languages or Celtic dialects. To the north of these zones however, in southern Scandinavia and northern Germany, the archaeological cultures started to become more distinct from La Tène culture during the Iron Age.

Concerning Germanic speakers within these northern regions, the relatively well-defined Jastorf culture matches the areas described by Tacitus, Pliny the elder and Strabo as Suevian homelands near the lower River Elbe, and stretching east on the Baltic coast to the Oder river. The Suevian peoples are seen by scholars as early West Germanic speakers. There is no consensus about whether neighbouring cultures in Scandinavia, Poland, and northwestern Germany were also part of a Germanic (or proto-Germanic)-speaking community at first, but this group of cultures were related to each other, and in contact. To the west of the Elbe for example, on what is now the German North Sea coast, was the so-called between the Jastorf culture and the La Tène influenced cultures of the Lower Rhine. To the east in what is now northern Poland was the Oksywie culture, later becoming the Wielbark culture with the arrival of Jastorf influences, probably representing the entry of East Germanic speakers. Related also to these and the Jastorf culture was the Przeworsk culture in southern Poland. It began as strongly La Tène-influenced local culture, and apparently became at least partly Germanic-speaking.

The Jastorf culture came into direct contact with La Tène cultures on the upper Elbe and Oder rivers, believed to correspond to the Celtic-speaking peoples such as the Boii and Volcae described in this area by Roman sources. In the south of their range, the Jastorf and Przeworsk material cultures spread together, in several directions.

Unlike archaeologists today, Caesar, the originator of the idea of the Germanic peoples, believed that in prehistory, before his time, the Rhine had divided "Germani" from the Gauls. However, he observed that there must already have been significant movements in both directions, over the Rhine. Not only did he believe that the "Germani" had a long-standing tendency to make raids and group movements from the northeast, involving peoples such as the Cimbri long before him, and the Suevians in his own time, it was also his understanding that there had been a time when the movement went in the opposite direction:
And there was formerly a time when the Gauls excelled the Germans ["Germani"] in prowess, and waged war on them offensively, and, on account of the great number of their people and the insufficiency of their land, sent colonies over the Rhine. Accordingly, the Volcae Tectosages, seized on those parts of Germany which are the most fruitful [and lie] around the Hercynian forest, (which, I perceive, was known by report to Eratosthenes and some other Greeks, and which they call Orcynia), and settled there.

Modern archaeologists, having found no sign of such movements, see the Gaulish La Tène culture as native to what is now southern Germany, and the La Tène-influenced cultures on both sides of the Lower Rhine in this period as quite distinct from the Elbe Germanic peoples, well into Roman times. On the other hand, the account of Caesar finds broad agreement with the archaeological record of the Celtic La Tène culture first expanding to the north, influencing all cultures there, and then suddenly having a weaker influence in that area. Subsequently, the Jastorf culture expanded in all directions from the region between the lower Elbe and Oder rivers.

All Germanic languages derive from the Proto-Indo-European language (PIE), which is generally estimated to have been spoken between 4500 and 2500 BCE. They share distinctive characteristics which set them apart from other Indo-European sub-families of languages, such as Grimm's and Verner's law, the conservation of the PIE ablaut system in the Germanic verb system (notably in strong verbs), or the merger of the vowels "a" and "o" qualities ("ə", "a", "o" > "a;" "ā", "ō" > "ō"). During the Pre-Germanic linguistic period (2500–500 BCE), the proto-language has almost certainly been influenced by linguistic substrates still noticeable in the Germanic phonology and lexicon. The leading theory, suggested by archaeological and genetic evidence, postulates a diffusion of Indo-European languages from the Pontic–Caspian steppe towards Northern Europe during the third millennium BCE, via linguistic contacts and migrations from the Corded Ware culture towards modern-day Denmark, resulting in cultural mixing with the indigenous Funnelbeaker culture.

Between around 500 BCE and the beginning of the Common Era, archeological and linguistic evidence suggest that the "Urheimat" ('original homeland') of the Proto-Germanic language, the ancestral idiom of all attested Germanic dialects, was primarily situated in an area corresponding to the extent of the late Jastorf culture. One piece of evidence is the presence of early Germanic loanwords in the Finnic and Sámi languages (e.g. Finnic "kuningas", from Proto-Germanic "*kuningaz" 'king'; "rengas", from "*hringaz" ‘ring’; etc.), with the older loan layers possibly dating back to an earlier period of intense contacts between pre-Germanic and Finno-Permic (i.e. Finno-Samic) speakers. An archeological continuity can also be demonstrated between the Jastof culture and populations defined as Germanic by Roman sources.

Although Proto-Germanic is reconstructed dialect-free via the comparative method, it is almost certain that it was never a uniform proto-language. The late Jastorf culture occupied so much territory that it is unlikely that Germanic populations spoke a single dialect, and traces of early linguistic varieties have been highlighted by scholars. Sister dialects of Proto-Germanic itself certainly existed, as evidenced by some recorded Germanic proper names not following Grimm's law, and the reconstructed Proto-Germanic language was only one among several dialects spoken at that time by peoples identified as "Germanic" in Roman sources or archeological data.

Definite and comprehensive evidence of the use of Germanic lexical units occurred only after Caesar's conquest of Gaul in the 1st century BCE, after which contacts with Proto-Germanic speakers began to intensify. The "Alcis", a pair of brother gods worshipped by the Nahanarvali, are given by Tacitus as a Latinized form of "*alhiz" (a kind of 'stag'), and the word "sapo" ('hair dye') is certainly borrowed from Proto-Germanic "*saipwōn-" (English "soap)", as evidenced by the parallel Finnish loanword "saipio." The name of the "framea", described by Tacitus as a short spear carried by Germanic warriors, most likely derives from the compound "*fram-ij-an-" ('forward-going one'), as suggested by comparable semantical structures found in early runes (e.g., "raun-ij-az" 'tester', on a lancehead) and linguistic cognates attested in the later Old Norse, Old Saxon and Old High German languages: "fremja," "fremmian" and "fremmen" all meant 'to carry out'.

The origin of the Germanic runes remains controversial, although it has been stated that they bear a more formal resemblance to North Italic alphabets (especially the Camunic alphabet; 1st mill. BCE) than to Latin letters. They are not attested before the beginning of the Common Era in southern Scandinavia, and the connection between the two alphabets is therefore uncertain. In the absence of earlier evidence, it must be assumed that Proto-Germanic speakers living in "Germania" were members of preliterate societies. The only pre-Roman inscription that could be interpreted as Proto-Germanic, written in the Etruscan alphabet, has not been found in "Germania" but rather in the Venetic region. The inscription "harikastiteiva", engraved on the Negau helmet in the 3rd–2nd centuries BCE, possibly by a Germanic-speaking warrior involved in combat in northern Italy, has been interpreted by some scholars as "Harigasti Teiwǣ" ("*harja-gastiz" 'army-guest' + "*teiwaz" '(war-)god'), which could be an invocation to a war-god or a mark of ownership engraved by its possessor. The inscription "Fariarix" ("*farjōn-" 'ferry' + "*rīk-" 'ruler') carved on tetradrachms found in Bratislava (mid-1st c. BCE) may indicate the Germanic name of a Celtic ruler.

The earliest attested runic inscriptions (Vimose comb, Øvre Stabu spearhead), initially concentrated in modern Denmark and written with the Elder Futhark system, are dated to the second half of the 2nd century CE. Their language, named Primitive Norse, Proto-Norse, or similar terms, and still very close to Proto-Germanic, has been interpreted as a northern variant of the Northwest Germanic dialects and the ancestor of the Old Norse language of the Viking Age (8th–11th c. CE). Based upon its dialect-free character and shared features with West Germanic languages, some scholars have contended that it served as a kind of koiné language. The merging of unstressed Proto-Germanic vowels, attested in runic inscriptions from the 4th and 5th centuries CE, also suggests that Primitive Norse could not have been a direct predecessor of West Germanic dialects.

By the time Germanic speakers entered written history, their linguistic territory had stretched farther south, since a Germanic dialect continuum covered a region roughly located between the Rhine, the Vistula, the Danube, and southern Scandinavia during the first two centuries of the Common Era. Neighbouring language varieties diverged only slightly between each other in this continuum, but remote dialects were not necessarily mutually intelligible due to accumulated differences over the distance. East Germanic speakers dwelt on the Baltic sea coasts and islands, while speakers of the Northwestern dialects occupied territories in present-day Denmark and bordering parts of Germany at the earliest date that they can be identified.

In the 2nd and 3rd centuries CE, migrations of East Germanic "gentes" from the Baltic Sea coast southeastwards into the hinterland led to their separation from the dialect continuum. By the late 3rd century CE, linguistic divergences like the West Germanic loss of the final consonant "-z" had already occurred within the "residual" Northwest dialect continuum,"" which definitely ended after the 5th- and 6th-century migrations of Angles, Jutes and part of Saxon groups towards modern-day England.

Although they have certainly influenced academic views on ancient Germanic languages up until the 20th century, the traditional groupings given by contemporary authors such as Pliny and Tacitus are no longer regarded as reliable by modern linguists, who rather base their reasoning on the attested sound changes and shared mutations which occurred in geographically distant groups of dialects. The Germanic languages are traditionally divided between East, North and West Germanic branches. The modern prevailing view is that North and West Germanic were also encompassed in a larger subgroup called Northwest Germanic.


Further internal classifications are still debated among scholars, as it is unclear whether the internal features shared by several branches are due to early common innovations or to the later diffusion of local dialectal innovations. Although Old English and Old Frisian shared distinctive characteristics such as the Anglo-Frisian nasal spirant law, attested by the 6th century in inscriptions on both sides of the North Sea, and the use of the fuþorc system with additional runes to convey innovative and shared sound changes, it is unclear whether those common features are really inherited or have rather emerged by connections over the North Sea.

By the 1st century CE, the writings of Pliny the Elder, and Tacitus reported a division of Germanic peoples into large groupings. Tacitus, in his "Germania", specifically stated that one such division mentioned "in old songs" ("carminibus antiquis") derived three such groups from three brothers, sons of Mannus, who was son of an earth-born god, Tuisto. These terms are also sometimes used in older modern linguistic terminology, attempting to describe the divisions of later Germanic languages:

On the other hand, Tacitus wrote in the same passage that some believe that there are other groups which are just as old as these three, including "the Marsi, Gambrivii, Suevi, Vandilii". Of these, he discussed only the Suevi in detail, specifying that they were a very large grouping, with many peoples, with their own names. The largest, he said, was the Semnones near the Elbe, who "claim that they are the oldest and the noblest of the Suebi."

Pliny the Elder, somewhat similarly, named five races of Germani in his "Historia Naturalis", with the same basic three groups as Tacitus, plus two more eastern blocks of Germans, the Vandals, and further east the Bastarnae. He clarifies that the Istvaeones are near the Rhine, although he gives only one problematic example, the Cimbri. He also clarifies that the Suevi, though numerous, are actually in one of the three Mannus groups. His list:

These accounts and others from the period emphasize that the Suevi formed an especially large and powerful group. Tacitus speaks also of a geographical "Suevia" with two halves, one on either side of the Sudetes. The larger group that the Suevi were part of according to Pliny, the Hermiones, is mentioned in one other source: Pomponius Mela, in his slightly earlier "Description of the World", places "the farthest people of Germania, the Hermiones" somewhere to the east of the Cimbri and the Teutones, apparently on the Baltic. He did not mention Suevians.

Strabo, who focused mainly on "Germani" between the Elbe and Rhine, and does not mention the sons of Mannus, also set apart the names of "Germani" who are "not" Suevian, in two other groups, similarly implying three main divisions: "smaller German tribes, as the Cherusci, Chatti, Gamabrivi, Chattuarii, and next the ocean the Sicambri, Chaubi, Bructeri, Cimbri, Cauci, Caulci, Campsiani".

From the perspective of modern linguistic reconstructions, the classical ethnographers were not helpful in distinguishing two large groups that spoke types of Germanic very different from the Suevians and their neighbours, whose languages are the source of modern West Germanic.
The "Gothic peoples" in the territory of present-day Ukraine and Romania were seen by Graeco-Roman writers as culturally "Scythian", and not Germanic, and indeed some of them such as the Alans were clearly not Germanic-speaking either. Whether the Gothic-speaking peoples among them had any consciousness of their connections to other Germanic-speaking peoples is a subject of dispute between scholars.

Before Julius Caesar, Romans and Greeks had very little contact with northern Europe itself. Pytheas who travelled to Northern Europe some time in the late 4th century BCE was one of the only sources of information for later historians. The Romans and Greeks however had contact with northerners who came south.

The Bastarnae or Peucini are mentioned in historical sources going back as far as the 3rd century BCE through the 4th century CE. These Bastarnae were described by Greek and Roman authors as living in the territory east of the Carpathian Mountains north of the Danube's delta at the Black Sea. They were variously described as Celtic or Scythian, but much later Tacitus, in disagreement with Livy, said they were similar to the "Germani" in language. According to some authors then, they were the first "Germani" to reach the Greco-Roman world and the Black Sea area.

In 201–202 BCE, the Macedonians, under the leadership of King Philip V, conscripted the Bastarnae as soldiers to fight against the Roman Republic in the Second Macedonian War. They remained a presence in that area until late in the Roman Empire. The Peucini were a part of this people who lived on Peuce Island, at the mouth of the Danube on the Black Sea. King Perseus enlisted the service of the Bastarnae in 171–168 BCE to fight the Third Macedonian War. By 29 BCE, they were subdued by the Romans and those that remained presumably merged into various groups of Goths into the second century CE.

Another eastern people known from about 200 BCE and sometimes believed to be Germanic-speaking, are the Scirii, because they appear in a record in Olbia on the Black Sea which records that the city had been troubled by Scythians, Sciri and Galatians. There is a theory that their name, perhaps meaning pure, was intended to contrast with the Bastarnae, perhaps meaning mixed, or "bastards". Much later, Pliny the Elder placed them to the north near the Vistula together with an otherwise unknown people called the Hirrii. The Hirrii are sometimes equated with the Harii mentioned by Tacitus in this region, whom he considered to be Germanic Lugians. These names have also been compared to that of the Heruli, who are another people from the area of modern Ukraine, believed to have been Germanic. In later centuries the Scirii, like the Heruli, and many of the Goths, were among the peoples who allied with Attila and settled in the Middle Danube, Pannonian region.

Late in the 2nd century BCE, Roman and Greek sources recount the migrations of the far northern "Gauls", the Cimbri, Teutones and Ambrones. Caesar later classified them as Germanic. They first appeared in eastern Europe where some researchers propose they may have been in contact with the Bastarnae and Scordisci. In 113 BCE, they defeated the Boii at the Battle of Noreia in Noricum.

Their movements through parts of Gaul, Italy and Hispania resulted in the Cimbrian War between these groups and the Roman Republic, led primarily by its Consul, Gaius Marius.

In Gaul, a combined force of Cimbri and Teutoni and others defeated the Romans in the Battle of Burdigala (107 BCE) at Bordeaux, in the Battle of Arausio (105) at Orange in France, and in the Battle of Tridentum (102) at Trento in Italy. Their further incursions into Roman Italy were repelled by the Romans at the Battle of Aquae Sextiae (Aix-en-Provence) in 102 BCE, and the Battle of Vercellae in 101 BCE (in Vercelli in Piedmont).

One classical source, Gnaeus Pompeius Trogus, mentions the northern Gauls somewhat later, associating them with eastern Europe, saying that both the Bastarae and the Cimbri were allies of Mithridates VI.

Caesar campaigned in what is now France from 58-50 BCE, in the period of the late Roman Republic. As mentioned above, Caesar wrote about this campaign in a way which introduced the term "Germanic" to refer to peoples such as the Cimbri and Suevi.
Still in the 1st century BCE the term "Germani" was used by Strabo (see above) and Cicero in ways clearly influenced by Caesar. Of the peoples encountered by Caesar, the Tribocci, Vangiones, Nemetes and Ubii were all found later, on the east of the Rhine, along the new frontier of the Roman empire.

During the reign of Augustus from 27 BCE until 14 CE, the Roman empire became established in Gaul, with the Rhine as a border. This empire made costly campaigns to pacify and control the large region between the Rhine and Elbe. In the reign of his successor Tiberius it became state policy to leave the border at the Rhine, and expand the empire no further in that direction. The Julio-Claudian dynasty, the extended family of Augustus, paid close personal attention to management of this Germanic frontier, establishing a tradition followed by many future emperors. Major campaigns were led from the Rhine personally by Nero Claudius Drusus, step-son of Augustus, then by his brother the future emperor Tiberius; next by the son of Drusus, Germanicus (father of the future emperor Caligula and grandfather of Nero).

In 38 BCE, Marcus Vipsanius Agrippa, consul of Transalpine Gaul, became the second Roman to lead forces over the Rhine. In 31 BCE Gaius Carrinas repulsed an attack by Suevi from east of the Rhine. In 25 BCE Marcus Vinicius took vengeance on some "Germani" in "Germania", who had killed Roman traders. In 17/16 BCE at the Battle of Bibracte the Sugambri, Usipetes, and Tencteri crossed the Rhine and defeated the 5th legion under Marcus Lollius, capturing the legion's eagle.

From 13 BCE until 17 CE there were major Roman campaigns across the Rhine nearly every year, often led by members of the family of Augustus. First came the pacification of the Usipetes, Sicambri, and Frisians near the Rhine, then attacks increased further from the Rhine, on the Chauci, Cherusci, Chatti and Suevi (including the Marcomanni). These campaigns eventually reached and even crossed the Elbe, and in 5 CE Tiberius was able to show strength by having a Roman fleet enter the Elbe and meet the legions in the heart of "Germania". However, within this period two Germanic kings formed large anti-Roman alliances. Both of them had spent some of their youth in Rome:

Strabo, writing in this period in Greek, mentioned that apart from the area near the Rhine itself, the areas to the east were now inhabited by the Suevi, "who are also named Germans, but are superior both in power and number to the others, whom they drove out, and who have now taken refuge on this side the Rhine". Various peoples had fallen "prey to the flames of war".

The Julio-Claudian dynasty also recruited northern Germanic warriors, particularly men of the Batavi, as personal bodyguards to the Roman emperor, forming the so-called Numerus Batavorum. After the end of the dynasty, in 69 AD, the Batavian bodyguard were dissolved by Galba in 68 because of its loyalty to the old dynasty. The decision caused deep offense to the Batavi, and contributed to the outbreak of the Revolt of the Batavi in the following year which united "Germani" and Gauls, all connected to Rome but living both within the empire and outside it, over the Rhine. Their indirect successors were the "Equites singulares Augusti" which were, likewise, mainly recruited from the Germani. They were apparently so similar to the Julio-Claudians' earlier German Bodyguard that they were given the same nickname, the "Batavi". Gaius Julius Civilis, a Roman military officer of Batavian origin, orchestrated the Revolt. The revolt lasted nearly a year and was ultimately unsuccessful.

The Emperor Domitian of the Flavian dynasty faced attacks from the Chatti in Germania superior, with its capital at Mainz, a large group which had not been in the alliance of Arminius or Maroboduus. The Romans claimed victory by 84 CE, and Domitian also improved the frontier defenses of Roman "Germania", consolidating control of the "Agri Decumates", and converting "Germania Inferior" and "Germania Superior" into normal Roman provinces. In 89 CE the Chatti were allies of Lucius Antonius Saturninus in his failed revolt. Domitian, and his eventual successor Trajan, also faced increasing concerns about an alliance on the Danube of the Suevian Marcomanni and Quadi, with the neighbouring Sarmatian Iazyges; it was in this area that dramatic events unfolded over the next few generations. Trajan himself expanded the empire in this region, taking over Dacia.
The Marcomannic Wars during the time of Marcus Aurelius ended in approximately 180 CE. Dio Cassius called it the war against the "Germani", noting that "Germani" was the term used for people who dwell up in those parts (in the north). A large number of peoples from north of the Danube were involved, not all Germanic-speaking, and there is much speculation about what events or plans led to this situation. Many scholars believe causative pressure was being created by aggressive movements of peoples further north, for example with the apparent expansion of the Wielbark culture of the Vistula, probably representing Gothic peoples who may have pressured Vandal peoples towards the Danube.
Other peoples, perhaps not all of them Germanic, were involved in various actions—these included the Costoboci, the Hasdingi and Lacringi Vandals, the Varisci (or Naristi) and the Cotini (not Germanic according to Tacitus), and possibly also the Buri.

After these Marcomannic wars, the Middle Danube began to change, and in the next century the peoples living there tended to be referred to as Gothic, rather than Germanic.

By the early 3rd century AD, large new groupings of Germanic people appeared near the Roman frontier, though they were not strongly unified. The first of these conglomerations mentioned in the historical sources were the Alamanni (a term meaning "all men") who appear in Roman texts sometime in the 3rd century CE. These are believed to have been a mixture of mainly Suevian peoples, who coalesced in the Agri Decumates. Emperor Severus Alexander was killed by his own soldiers in 235 CE for paying for peace with the Alamanni, following which the anti-aristocratic general Maximinus Thrax was elected to be emperor by the Pannonian army. According to the notoriously unreliable Augustan History ("Historia Augusta"), he was born in Thrace or Moesia to a Gothic father and an Alanic mother,

Secondly, soon after the appearance of the Alamanni on the Upper Rhine, the Franks began to be mentioned as occupying the land at the bend of the lower Rhine. In this case, the collective name was new, but the original peoples who composed the group were largely local, and their old names were still mentioned occasionally. The Franks were still sometimes called "Germani" as well.
Thirdly, the Goths and other "Gothic peoples" from the area of today's Poland and Ukraine, many of whom were Germanic-speaking peoples, began to appear in records of this period.

In 260 CE, as the Roman Imperial Crisis of the Third Century reached its climax, Postumus, a Germanic soldier in Roman service, established the Gallic Empire, which claimed suzerainty over Germania, Gaul, Hispania and Britannia. Postumus was eventually assassinated by his own followers, after which the Gallic Empire quickly disintegrated. The traditional types of border battles with "Germani", Sarmatians and Goths continued on the Rhine and Danube frontiers after this.

In the 350s Julian campaigned against the Alamanni and Franks on the Rhine. One result was that Julian accepted that the Salian Franks could live within the empire, north of Tongeren.

By 369, the Romans appear to have ceded their large province of Dacia to the Tervingi, Taifals and Victohali.

Since its very beginning, the Roman empire had proactively kept the northern peoples and the potential danger they represented under control, just as Caesar had proposed. However, the ability to handle the barbarians in the old way broke down in the late 4th century and the western part of the empire itself broke down. In addition to the Franks on the Rhine frontier, and Suevian peoples such as the Alamanni, a sudden movement of eastern Germanic-speaking "Gothic peoples" now played an increasing role both inside and outside imperial territory.

The Gothic wars of the late 4th century saw a rapid series of major events: the entry of a large number of Goths in 376; the defeat of a major Roman army and killing of emperor Valens at the Battle of Adrianopolis in 378; and a subsequent major settlement treaty for the Goths which seems to have allowed them significant concessions compared to traditional treaties with barbarian peoples. While the eastern empire eventually recovered, the subsequent long-reigning western emperor Honorius (reigned 393-423) was unable to impose imperial authority over much of the empire for most of his reign. In contrast to the eastern empire, in the west the "attempts of its ruling class to use the Roman-barbarian kings to preserve the res publica failed".

The Gothic wars were affected indirectly by the arrival of the nomadic Huns from Central Asia in the Ukrainian region. Some Gothic peoples, such as the Gepids and the Greuthungi (sometimes seen as predecessors of the later Ostrogoths), joined the newly forming Hunnish faction, and played a prominent role in the Hunnic Empire, where Gothic became a lingua franca. Based on the description of Socrates Scholasticus, Guy Halsall has argued that the Hunnish hegemony developed after a major campaign by Valens against the Goths, which had caused great damage, but failed to achieve a decisive victory. Peter Heather has argued that Socrates should be rejected on this point, as inconsistent with the testimony of Ammianus.

The Gothic Thervingi, under the leadership of Athanaric, had in any case borne the impact of the campaign of Valens, and were also losers against the Huns, but clients of Rome. A new faction under leadership of Fritigern, a Christian, were given asylum inside the Roman Empire in 376 CE. They crossed the Danube and became "foederati". With the emperor occupied in the Middle East, the Tervingi were treated badly and becoming desperate; significant numbers of mounted Greuthungi, Alans and others were able to cross the river and support a Tervingian uprising leading to the massive Roman defeat at Adrianople.

Around 382, the Romans and the Goths now within the empire came to agreements about the terms under which the Goths should live. There is debate over the exact nature of such agreements, and for example whether they allowed the continuous semi-independent existence of pre-existing peoples; however the Goths do appear to have been allowed more privileges than in traditional settlements with such outside groups. One result of the comprehensive settlement was that the imperial army now had a larger number of Goths, including Gothic generals.

By 383 a new emperor, Theodosius I, was seen as victorious over the Goths and having brought the situation back under control. Goths were a prominent but resented part of the eastern military. The Greutungi and Alans had been settled in Pannonia by the western co-emperor Gratian (assassinated in 383) who was himself a Pannonian. Theodosius died 395, and was succeeded by his sons: Arcadius in the east, and Honorius, who was still a minor, in the west. The Western empire had however become destabilized since 383, with several young emperors including Gratian having previously been murdered. Court factions and military leaders in the east and west attempted to control the situation.

Alaric was a Roman military commander of Gothic background, who first appears in the record in the time of Theodosius. After the death of Theodosius, he became one of the various Roman competitors for influence and power in the difficult situation. The forces he led were described as mixed barbarian forces, and clearly included many other people of Gothic background, a phenomenon which had become common in the Balkans. In an important turning point for Roman history, during the factional turmoil, his army came to act increasingly as an independent political entity within the Roman empire, and at some point he came to be referred to as their king, probably around 401 CE, when he lost his official Roman title. This is the origin of the Visigoths, whom the empire later allowed to settle in what is now southwestern France. While military units had often had their own ethnic history and symbolism, this is the first time that such a group established a new kingdom. There is disagreement about whether Alaric or his family had a royal background, but there is no doubt that this kingdom was a new entity, very different from any previous Gothic kingdoms.

In the aftermath of the large-scale Gothic entries into the empire, the Germanic Rhine peoples, the Franks and Alemanni, became more secure in their positions in 395, when Stilicho made agreements with them; these treaties allowed him to withdraw the imperial forces from the Rhine frontier in order to use them in his conflicts with Alaric and the Eastern empire.

On the Danube, change was far more dramatic. In the words of Walter Goffart:
Between 401 and 411, four distinct groups of barbarians - different from Alaric's Goths - invaded Roman territory, all apparently on one-way journeys, in large-scale efforts to transpose themselves onto imperial soil and not just plunder and return home.

The reasons that these invasions apparently all dispersed from the same area, the Middle Danube, are uncertain. It is most often argued that the Huns must have already started moving west, and consequently pressuring the Middle Danube. Peter Heather for example writes that around 400, "a highly explosive situation was building up in the Middle Danube, as Goths, Vandals, Alans and other refugees from the Huns moved west of the Carpathians" into the area of modern Hungary on the Roman frontier.

Walter Goffart, in contrast, has pointed out that there is no clear evidence of new eastern groups arriving in the area immediately before the great movements, and so it remains possible that the Huns moved West after these large groups had left the Middle Danube. Goffart's suggestion is that the example of the Goths, such as those led by Alaric, had set an example leading to a "common perception, however indistinct, that warriors could improve their condition by forcing their existence on the attention of the Empire, demanding to be dealt with, and exacting a part in the imperial enterprise."

Whatever the chain of events, the Middle Danube later became the centre of Attila's loose empire containing many East Germanic people from the east, who remained there after the death of Attila. The makeup of peoples in that area, previously the home of the Germanic Marcomanni, Quadi and non-Germanic Iazyges, changed completely in ways which had a significant impact on the Roman empire and its European neighbours. Thereafter, though the new peoples ruling this area still included Germanic-speakers, as discussed above, they were not described by Romans as "Germani", but rather "Gothic peoples".


Motivated by the ensuing chaos in Gaul, in 406 the Roman army in Britain elected Constantine "III" as emperor and they took control there.

In 408, the eastern emperor Arcadius died, leaving a child as successor, and the west Roman military leader Stilicho was killed. Alaric, wanting a formal Roman command but unable to negotiate one, invaded Rome itself, twice, in 401 and 408.

Constantius III, who became "Magister militum" by 411, restored order step-by-step, eventually allowing the Visigoths to settle within the empire in southwest Gaul. He also committed to retaking control of Iberia, from the Rhine-crossing groups. When Constantius died in 421, having been co-emperor himself for one year, Honorius was the only emperor in the West. However, Honorius died in 423 without an heir. After this, the Western Roman empire steadily lost control of its provinces.

The Western Roman Empire declined gradually in the 5th and 6th centuries, and the eastern emperors had only limited control over events in Italy and the western empire. Germanic speakers, who by now dominated the Roman military in Europe, and lived both inside and outside the empire, played many roles in this complex dynamic. Notably, as the old territory of the western empire came to be ruled on a regional basis, the barbarian military forces, ruled now by kings, took over administration with differing levels of success. With some exceptions, such as the Alans and Bretons, most of these new political entities identified themselves with a Germanic-speaking heritage.

In the 420s, Flavius Aëtius was a general who successfully used Hunnish forces on several occasions, fighting Roman factions and various barbarians including Goths and Franks. In 429 he was elevated to the rank of "magister militum" in the western empire, which eventually allowed him to gain control of much of its policy by 433. One of his first conflicts was with Boniface, a rebellious governor of the province of Africa in modern Tunisia and Libya. Both sides sought an alliance with the Vandals based in southern Spain who had acquired a fleet there. In this context, the Vandal and Alan kingdom of North Africa and the western Mediterranean would come into being.

In the subsequent decades, the Franks and Alamanni tended to remain in small kingdoms but these began to extend deeper into the empire. In northern Gaul, a Roman military "King of Franks" also seems to have existed, Childeric I, whose successor Clovis I established dominance of the smaller kingdoms of the Franks and Alamanni, whom they defeated at the Battle of Zülpich in 496. 

Compared to Gaul, what happened in Roman Britain, which was similarly both isolated from Italy and heavily Romanized, is less clearly recorded. However the end result was similar, with a Germanic-speaking military class, the Anglo-Saxons, taking over administration of what remained of Roman society, and conflict between an unknown number of regional powers. While major parts of Gaul and Britain redefined themselves ethnically on the basis of their new rulers, as Francia and England, in England the main population also became Germanic-speaking. The exact reasons for the difference are uncertain, but significant levels of migration played a role.

In 476 Odoacer, a Roman soldier who came from the peoples of the Middle Danube in the aftermath of the Battle of Nedao, became King of Italy, removing the last of the western emperors from power. He was murdered and replaced in 493 by Theoderic the Great, described as King of the Ostrogoths, one of the most powerful Middle Danube peoples of the old Hun alliance. Theoderic had been raised up and supported by the eastern emperors, and his administration continued a sophisticated Roman administration, in cooperation with the traditional Roman senatorial class. Similarly, culturally Roman lifestyles continued in North Africa under the Vandals, in Savoy under the Burgundians, and within the Visigothic realm.

The Ostrogothic kingdom ended in 542 when the eastern emperor Justinian made a last great effort to reconquer the Western Mediterranean. The conflicts destroyed the Italian senatorial class, and the eastern empire was also unable to hold Italy for long. In 568 the Lombard king Alboin, a Suevian people who had entered the Middle Danubian region from the north conquering and partly absorbing the frontier peoples there, entered Italy and created the Italian Kingdom of the Lombards there. These Lombards now included Suevi, Heruli, Gepids, Bavarians, Bulgars, Avars, Saxons, Goths, and Thuringians. As Peter Heather has written these "peoples" were no longer peoples in any traditional sense.

Older accounts which describe a long period of massive movements of peoples and military invasions are oversimplified, and describe only specific incidents. According to Herwig Wolfram, the Germanic peoples did not and could not "conquer the more advanced Roman world" nor were they able to "restore it as a political and economic entity"; instead, he asserts that the empire's "universalism" was replaced by "tribal particularism" which gave way to "regional patriotism". The Germanic peoples who overran the Western Roman Empire probably numbered less than 100,000 people per group, including approximately 15,000-20,000 warriors. They constituted a tiny minority of the population in the lands over which they seized control.

Apart from the common history many of them had in the Roman military, and on Roman frontiers, a new and longer-term unifying factor for the new kingdoms was that by 500, the start of the Middle Ages, most of the old Western empire had converted to the same Rome-centred Catholic form of Christianity. A key turning point was the conversion of Clovis I in 508. Before this point, many of the Germanic kingdoms, such as those of the Goths and Burgundians, now adhered to Arian Christianity - a form of Christianity which they perhaps took up in the time of the Arian emperor Valens, but which was now considered a heresy.

In the centuries after 568, the Visigothic kingdom, by now centred in Spain, was ended by the Umayyad conquest of Hispania in the 8th century. Much of continental catholic Europe became part of a greater Francia under the Merovingian and then the Carolingian dynasty, which began with Pepin the Short, the son of Charles Martel. Charles, though not a king, reconsolidated the Frankish kingdom's dominance over Saxons, Frisians, Bavarians and Burgundians, and defeated the Umayyads at the 732 Battle of Tours. Pepin's son Charlemagne conquered the Lombards in 774, and in an important turning point in European history, was crowned as emperor by Pope Leo III in Rome on Christmas Day, 800 CE. This consolidated a shift in the power structure from the south to the north, and was also a strong symbolic link to Rome and the Roman Christianity. The core of the new empire included what is now France, Germany and the Benelux countries. The empire laid the foundations for the medieval and early modern "ancien regime", finally destroyed only by the French Revolution. The Frankish-Catholic way of doing politics and war and religion also had a strong effect upon all neighbouring regions, including what became England, Spain, Italy, Austria, and Bohemia.

The effect of old Germanic culture on this new Latin-using empire is a topic of dispute, because there was much continuity with the old Roman legal systems, and the increasingly important Christian religion. An example which is argued to show an influence of earlier Germanic culture is law. The new kingdoms created new law codes in Latin, with occasional Germanic words. These were Roman-influenced, and under strong church influence all law was increasingly standardized to accord with Christian philosophy, and old Roman law.

Germanic languages in western Europe no longer exist apart from the remaining West Germanic languages of England, the Frankish homelands near the Rhine–Meuse–Scheldt delta, and the large area between the Rhine and Elbe. With the splitting off of this latter area within the Frankish empire, the first ever political entity corresponding loosely to modern "Germany" came into existence.

In Eastern Europe the once relatively developed periphery of the Roman world collapsed culturally and economically, and this can be seen in the Germanic-associated archaeological evidence: in the area of today's southern Poland and Ukraine the collapse occurred not long after 400, and by 700 Germanic material culture was entirely west of the Elbe in the area where the Romans had been active since Caesar's time, and the Franks were now active. East of the Elbe was to become mainly Slavic-speaking.

Outside of the Roman-influenced zone, Germanic-speaking Scandinavia was in the Vendel period and eventually entered the Viking Age, with expansion to Britain, Ireland and Iceland in the west and as far as Russia and Greece in the east. Swedish Vikings, known locally as the Rus', ventured deep into Russia, where they founded the political entities of Kievan Rus'. They defeated the Khazar Khaganate and became the dominant power in Eastern Europe. The dominant language of these communities came to be East Slavic. By 900 CE the Vikings also secured a foothold on Frankish soil along the Lower Seine River valley in what became known as Normandy. On the other hand, the Scandinavian countries were, starting with Denmark, under the influence of Germany to their south, and also the lands where they had colonies. Bit by bit they became Christian, and organized themselves into Frankish- and Catholic-influenced kingdoms.

Caesar and Tacitus gave colorful descriptions of the Germanic peoples, but scholars note that these need to be viewed cautiously. For one thing, many of the tropes used, such as those concerning the red or blond hair, the blue eyes, and the undisciplined emotions of the Germanic peoples, were old ones that had long been used for any of the northern peoples such as Gauls. Secondly, the Germanic descriptions of both authors are recognized as having been intended to be both critical of Roman moral softness, and pushing for specific foreign policies.

Tacitus famously described the Germanic people as ethnically "unmixed", which had an influence on pre-1945 German racist nationalism. It was not necessarily meant to be purely positive:
For my own part, I agree with those who think that the tribes of Germany are free from all taint of inter-marriages with foreign nations, and that they appear as a distinct, unmixed race, like none but themselves. Hence, too, the same physical peculiarities throughout so vast a population. All have fierce blue eyes, red hair, huge frames, fit only for a sudden exertion. They are less able to bear laborious work. Heat and thirst they cannot in the least endure; to cold and hunger their climate and their soil inure them.

Modern scholars point out that one way of interpreting such remarks is that they are consistent with other comments by Tacitus indicating that the Germanic people lived very remotely, in unattractive countries, for example in the next part of the text:
Their country, though somewhat various in appearance, yet generally either bristles with forests or reeks with swamps; it is more rainy on the side of Gaul, bleaker on that of Noricum and Pannonia. It is productive of grain, but unfavourable to fruit-bearing trees; it is rich in flocks and herds, but these are for the most part undersized, and even the cattle have not their usual beauty or noble head. 

Archaeological research has revealed that the early Germanic peoples were primarily agricultural, although husbandry and fishing were important sources of livelihood depending on the nature of their environment. They carried out extensive trade with their neighbours, notably exporting amber, slaves, mercenaries and animal hides, and importing weapons, metals, glassware and coins in return. They eventually came to excel at craftsmanship, particularly metalworking. In many cases, ancient Germanic smiths and other craftsmen produced products of higher quality than those of the Romans.

Before Tacitus, Julius Caesar described the "Germani" and their customs in his "Commentarii de Bello Gallico", though in certain cases it is still a matter of debate if he refers to Northern Celtic peoples or clearly identified Germanic peoples. Caesar notes that the Gauls had earlier dominated and sent colonies into the lands of the Germans, but that the Gauls had since degenerated under the influence of Roman civilization, and now considered themselves inferior in military prowess.

[The Germani] have neither Druids to preside over sacred offices, nor do they pay great regard to sacrifices. They rank in the number of the gods those alone whom they behold, and by whose instrumentality they are obviously benefited, namely, the sun, fire, and the moon; they have not heard of the other deities even by report. Their whole life is occupied in hunting and in the pursuits of the military art; from childhood they devote themselves to fatigue and hardships. Those who have remained chaste for the longest time, receive the greatest commendation among their people; they think that by this the growth is promoted, by this the physical powers are increased and the sinews are strengthened. And to have had knowledge of a woman before the twentieth year they reckon among the most disgraceful acts; of which matter there is no concealment, because they bathe promiscuously in the rivers and [only] use skins or small cloaks of deer's hides, a large portion of the body being in consequence naked.

They do not pay much attention to agriculture, and a large portion of their food consists in milk, cheese, and flesh; nor has any one a fixed quantity of land or his own individual limits; but the magistrates and the leading men each year apportion to the groups and families, who have united together, as much land as, and in the place in which, they think proper, and the year after compel them to remove elsewhere.

In a 2013 book which reviewed studies up until then it was remarked that: "If and when scientists find ancient Y-DNA from men whom we can guess spoke Proto-Germanic, it is most likely to be a mixture of haplogroup I1, R1a1a, R1b-P312 and R1b-106". This was based purely upon those being the Y-DNA groups judged to be most commonly shared by speakers of Germanic languages today. However, as remarked in that book: "All of these are far older than Germanic languages and some are common among speakers of other languages too."











Convenience links, bilingual where possible:


</doc>
<doc id="12448" url="https://en.wikipedia.org/wiki?curid=12448" title="Ganges">
Ganges

The Ganges ( ) or Ganga ( , ) is a trans-boundary river of Asia which flows through India and Bangladesh. The river originates from the Gangotri Glacier of western Himalayas in the Indian state of Uttarakhand, and flows south and east through the Gangetic Plain of India and Bangladesh, eventually emptying into the Bay of Bengal.

The Ganges is a lifeline to millions who live along its course. It is a sacred river and worshipped as the goddess "Ganga" in Hinduism. It has been important historically; many former provincial or imperial capitals (such as Prayagraj, Dhaka, Baharampur, Bikrampur, Kampilya, Kannauj, Kara, Kashi, Kolkata, Murshidabad, Munger, Patliputra, and Sonargaon) have been located on its banks.

The Ganges is threatened by severe pollution. This poses a danger not only to humans but also to animals; the Ganges is home to approximately 140 species of fish and 90 species of amphibians. The river also contains reptiles and mammals, including critically endangered species such as the Gharial and South Asian river dolphin. The levels of fecal coliform bacteria from human waste in the river near Varanasi are more than a hundred times the Indian government's official limit. The Ganga Action Plan, an environmental initiative to clean up the river, has been considered a failure which is variously attributed to corruption, a lack of will in the government, poor technical expertise, environmental planning and a lack of support from the native religious authorities.

The upper phase of the river Ganges begins at the confluence of the Bhagirathi and Alaknanda rivers in the town of Devprayag in the Garhwal division of the Indian state of Uttarakhand. The Bhagirathi is considered to be the source in Hindu culture and mythology, although the Alaknanda is longer, and therefore, hydrologically the source stream. The headwaters of the Alakananda are formed by snow melt from peaks such as Nanda Devi, Trisul, and Kamet. The Bhagirathi rises at the foot of Gangotri Glacier, at Gomukh, at an elevation of and being mythologically referred to as residing in the matted locks of Shiva; symbolically Tapovan, which is a meadow of ethereal beauty at the feet of Mount Shivling, just away.

Although many small streams comprise the headwaters of the Ganges, the six longest and their five confluences are considered sacred. The six headstreams are the Alaknanda, Dhauliganga, Nandakini, Pindar, Mandakini and Bhagirathi. Their confluences, known as the Panch Prayag, are all along the Alaknanda. They are, in downstream order, Vishnuprayag, where the Dhauliganga joins the Alaknanda; Nandprayag, where the Nandakini joins; Karnaprayag, where the Pindar joins; Rudraprayag, where the Mandakini joins; and finally, Devprayag, where the Bhagirathi joins the Alaknanda to form the Ganges.

After flowing for through its narrow Himalayan valley, the Ganges emerges from the mountains at Rishikesh, then debouches onto the Gangetic Plain at the pilgrimage town of Haridwar. At Haridwar, a dam diverts some of its waters into the Ganges Canal, which irrigates the "Doab" region of Uttar Pradesh, whereas the river, whose course has been roughly southwest until this point, now begins to flow southeast through the plains of northern India.

The Ganges river follows a arching course passing through the cities of Kannauj, Farukhabad, and Kanpur. Along the way it is joined by the Ramganga, which contributes an average annual flow of about to the river. The Ganges joins the long River Yamuna and long underneath River Saraswati at the Triveni Sangam at Allahabad, (now Prayagraj) a confluence considered holy in Hinduism. At their confluence the Yamuna is larger than the Ganges contributing about 58.5% of the combined flow, with an average flow of .

Now flowing east, the river meets the long Tamsa River (also called "Tons"), which flows north from the Kaimur Range and contributes an average flow of about . After the Tamsa, the long Gomti River joins, flowing south from the Himalayas. The Gomti contributes an average annual flow of about . Then the long Ghaghara River (Karnali River), also flowing south from the Himalayas of Tibet through Nepal joins. The Ghaghara (Karnali), with its average annual flow of about , is the largest tributary of the Ganges by discharge. After the Ghaghara confluence, the Ganges is joined from the south by the long Son River, which contributes about . The long Gandaki River, then the long Kosi River, join from the north flowing from Nepal, contributing about and respectively. The Kosi is the third largest tributary of the Ganges by discharge, after Ghaghara (Karnali) and Yamuna. The Kosi merges into the Ganges near Kursela in Bihar.

Along the way between Prayagraj and Malda, West Bengal, the Ganges river passes the towns of Chunar, Mirzapur, Varanasi, Ghazipur, Ara, Patna, Chapra, Hajipur, Mokama, Munger, Sahibganj, Rajmahal, Bhagalpur, Ballia, Buxar, Simaria, Sultanganj, and Farakka. At Bhagalpur, the river begins to flow south-southeast and at Farakka, it begins its attrition with the branching away of its first distributary, the long Bhāgirathi-Hooghly, which goes on to become the Hooghly River. Just before the border with Bangladesh the Farakka Barrage controls the flow of Ganges, diverting some of the water into a feeder canal linked to the Hooghly for the purpose of keeping it relatively silt-free. The Hooghly River is formed by the confluence of the Bhagirathi River and Ajay River at Katwa, and Hooghly has a number of tributaries of its own. The largest is the Damodar River, which is long, with a drainage basin of . The Hooghly River empties into the Bay of Bengal near Sagar Island. Between Malda and the Bay of Bengal, the Hooghly river passes the towns and cities of Murshidabad, Nabadwip, Kolkata and Howrah.

After entering Bangladesh, the main branch of the Ganges river is known as the Padma. The Padma is joined by the Jamuna River, the largest distributary of the Brahmaputra. Further downstream, the Padma joins the Meghna River, the converged flow of Surma-Meghna river system taking on the Meghna's name as it enters the Meghna Estuary, which empties into the Bay of Bengal. Here it forms the Bengal Fan, the world's largest submarine fan, which alone accounts for 10–20% of the global burial of organic carbon.

The Ganges Delta, formed mainly by the large, sediment-laden flows of the Ganges and Brahmaputra rivers, is the world's largest delta, at about . It stretches along the Bay of Bengal.

Only the Amazon and Congo rivers have a greater average discharge than the combined flow of the Ganges, the Brahmaputra, and the Surma-Meghna river system. In full flood only the Amazon is larger.

The Indian subcontinent lies atop the Indian tectonic plate, a minor plate within the Indo-Australian Plate. Its defining geological processes commenced seventy-five million years ago, when, as a part of the southern supercontinent Gondwana, it began a northeastwards drift—lasting fifty million years—across the then unformed Indian Ocean. The subcontinent's subsequent collision with the Eurasian Plate and subduction under it, gave rise to the Himalayas, the planet's highest mountain ranges. In the former seabed immediately south of the emerging Himalayas, plate movement created a vast trough, which, having gradually been filled with sediment borne by the Indus and its tributaries and the Ganges and its tributaries, now forms the Indo-Gangetic Plain.

The Indo-Gangetic Plain is geologically known as a foredeep or foreland basin.

Major left-bank tributaries include Gomti River, Ghaghara River, Gandaki river, and Kosi river; major right-bank tributaries include Yamuna river, Son river, Punpun and Damodar.The hydrology of the Ganges River is very complicated, especially in the Ganges Delta region. One result is different ways to determine the river's length, its discharge, and the size of its drainage basin.

The name "Ganges" is used for the river between the confluence of the Bhagirathi and Alaknanda rivers, in the Himalayas, and the first bifurcation of the river, near the Farakka Barrage and the India-Bangladesh Border. The length of the Ganges is frequently said to be slightly over long, about , or. In these cases the river's source is usually assumed to be the source of the Bhagirathi River, Gangotri Glacier at Gomukh and its mouth being the mouth of the Meghna River on the Bay of Bengal. Sometimes the source of the Ganges is considered to be at Haridwar, where its Himalayan headwater streams debouch onto the Gangetic Plain.

In some cases, the length of the Ganges is given by its Hooghly River distributary, which is longer than its main outlet via the Meghna River, resulting in a total length of about , if taken from the source of the Bhagirathi, or , if from Haridwar to the Hooghly's mouth. In other cases the length is said to be about , from the source of the Bhagirathi to the Bangladesh border, where its name changes to "Padma".

For similar reasons, sources differ over the size of the river's drainage basin. The basin covers parts of four countries, India, Nepal, China, and Bangladesh; eleven Indian states, Himachal Pradesh, Uttarakhand, Uttar Pradesh, Madhya Pradesh, Chhattisgarh, Bihar, Jharkhand, Punjab, Haryana, Rajasthan, West Bengal, and the Union Territory of Delhi. The Ganges basin, including the delta but not the Brahmaputra or Meghna basins, is about , of which is in India (about 80%), in Nepal (13%), in Bangladesh (4%), and in China (3%). Sometimes the Ganges and Brahmaputra–Meghna drainage basins are combined for a total of about or . The combined Ganges-Brahmaputra-Meghna basin (abbreviated GBM or GMB) drainage basin is spread across Bangladesh, Bhutan, India, Nepal, and China.

The Ganges basin ranges from the Himalaya and the Transhimalaya in the north, to the northern slopes of the Vindhya range in the south, from the eastern slopes of the Aravalli in the west to the Chota Nagpur plateau and the Sunderbans delta in the east. A significant portion of the discharge from the Ganges comes from the Himalayan mountain system. Within the Himalaya, the Ganges basin spreads almost 1,200 km from the Yamuna-Satluj divide along the Simla ridge forming the boundary with the Indus basin in the west to the Singalila Ridge along the Nepal-Sikkim border forming the boundary with the Brahmaputra basin in the east. This section of the Himalaya contains 9 of the 14 highest peaks in the world over 8,000m in height, including Mount Everest which is the high point of the Ganges basin. The other peaks over 8,000m in the basin are Kangchenjunga, Lhotse, Makalu, Cho Oyu, Dhaulagiri, Manaslu, Annapurna and Shishapangma. The Himalayan portion of the basin includes the south-eastern portion of the state of Himachal Pradesh, the entire state of Uttarakhand, the entire country of Nepal and the extreme north-western portion of the state of West Bengal.

The discharge of the Ganges also differs by source. Frequently, discharge is described for the mouth of the Meghna River, thus combining the Ganges with the Brahmaputra and Meghna. This results in a total average annual discharge of about , or . In other cases the average annual discharges of the Ganges, Brahmaputra, and Meghna are given separately, at about for the Ganges, about for the Brahmaputra, and about for the Meghna.
The maximum peak discharge of the Ganges, as recorded at Hardinge Bridge in Bangladesh, exceeded . The minimum recorded at the same place was about , in 1997.

The hydrologic cycle in the Ganges basin is governed by the Southwest Monsoon. About 84% of the total rainfall occurs in the monsoon from June to September. Consequently, streamflow in the Ganges is highly seasonal. The average dry season to monsoon discharge ratio is about 1:6, as measured at Hardinge Bridge. This strong seasonal variation underlies many problems of land and water resource development in the region. The seasonality of flow is so acute it can cause both drought and floods. Bangladesh, in particular, frequently experiences drought during the dry season and regularly suffers extreme floods during the monsoon.

In the Ganges Delta many large rivers come together, both merging and bifurcating in a complicated network of channels. The two largest rivers, the Ganges and Brahmaputra, both split into distributary channels, the largest of which merge with other large rivers before themselves joining the Bay of Bengal. But this current channel pattern was not always the case. Over time the rivers in Ganges Delta have often changed course, sometimes altering the network of channels in significant ways.

Before the late 12th century the Bhagirathi-Hooghly distributary was the main channel of the Ganges and the Padma was only a minor spill-channel. The main flow of the river reached the sea not via the modern Hooghly River but rather by the Adi Ganga. Between the 12th and 16th centuries the Bhagirathi-Hooghly and Padma channels were more or less equally significant. After the 16th century the Padma grew to become the main channel of the Ganges. It is thought that the Bhagirathi-Hooghly became increasingly choked with silt, causing the main flow of the Ganges to shift to the southeast and the Padma River. By the end of the 18th century the Padma had become the main distributary of the Ganges. One result of this shift to the Padma was that the Ganges now joined the Meghna and Brahmaputra rivers before emptying into the Bay of Bengal. The present confluence of the Ganges and Meghna was formed very recently, about 150 years ago.

Also near the end of the 18th century, the course of the lower Brahmaputra changed dramatically, significantly altering its relationship with the Ganges. In 1787 there was a great flood on the Teesta River, which at the time was a tributary of the Ganges-Padma River. The flood of 1787 caused the Teesta to undergo a sudden change course, an avulsion, shifting east to join the Brahmaputra and causing the Brahmaputra to shift its course south, cutting a new channel. This new main channel of the Brahmaputra is called the Jamuna River. It flows south to join the Ganges-Padma. During ancient times, the main flow of the Brahmaputra was more easterly, passing by the city of Mymensingh and joining the Meghna River. Today this channel is a small distributary but retains the name Brahmaputra, sometimes Old Brahmaputra. The site of the old Brahmaputra-Meghna confluence, in the locality of Langalbandh, is still considered sacred by Hindus. Near the confluence is a major early historic site called Wari-Bateshwar.

In the rainy season of 1809, the lower channel of the Bhagirathi, leading to Kolkata, had been entirely shut; but in the following year it opened again and was nearly of the same size with the upper channel but both however suffered a considerable diminution, owing probably to the new communication opened below the Jalanggi on the upper channel.

The Late Harappan period, about 1900–1300 BCE, saw the spread of Harappan settlement eastward from the Indus River basin to the Ganges-Yamuna doab, although none crossed the Ganges to settle its eastern bank. The disintegration of the Harappan civilisation, in the early 2nd millennium BC, marks the point when the centre of Indian civilisation shifted from the Indus basin to the Ganges basin. There may be links between the Late Harappan settlement of the Ganges basin and the archaeological culture known as "Cemetery H" and the Indo-Aryan people of the Vedic period.

This river is the longest and the most sacred in India. But during the early Vedic Period and in the "Rigveda", the Indus and the Sarasvati River were given more spiritual importance, not the Ganges. But also, it is important to know that the later three Vedas gave much more importance to the Ganges, showing the change in cultural and religious views due to the events of that time. The Gangetic Plain became the centre of successive powerful states; from the Maurya Empire to the Mughal Empire.

The first European traveller to mention the Ganges was the Greek envoy Megasthenes (ca. 350–290 BCE). He did so several times in his work Indica: "India, again, possesses many rivers both large and navigable, which, having their sources in the mountains which stretch along the northern frontier, traverse the level country, and not a few of these, after uniting with each other, fall into the river called the Ganges. Now this river, which at its source is 30 stadia broad, flows from north to south, and empties its waters into the ocean forming the eastern boundary of the Gangaridai, a nation which possesses a vast force of the largest-sized elephants." (Diodorus II.37).

In 1951 a water sharing dispute arose between India and East Pakistan (now Bangladesh), after India declared its intention to build the Farakka Barrage. The original purpose of the barrage, which was completed in 1975, was to divert up to of water from the Ganges to the Bhagirathi-Hooghly distributary in order to restore navigability at the Port of Kolkata. It was assumed that during the worst dry season the Ganges flow would be around , thus leaving for the then East Pakistan. East Pakistan objected and a protracted dispute ensued. In 1996 a 30-year treaty was signed with Bangladesh. The terms of the agreement are complicated, but in essence they state that if the Ganges flow at Farakka was less than then India and Bangladesh would each receive 50% of the water, with each receiving at least for alternating ten-day periods. However, within a year the flow at Farakka fell to levels far below the historic average, making it impossible to implement the guaranteed sharing of water. In March 1997, flow of the Ganges in Bangladesh dropped to its lowest ever, . Dry season flows returned to normal levels in the years following, but efforts were made to address the problem. One plan is for another barrage to be built in Bangladesh at Pangsha, west of Dhaka. This barrage would help Bangladesh better utilise its share of the waters of the Ganges.

The Ganges is a sacred river to Hindus along every fragment of its length. All along its course, Hindus bathe in its waters, paying homage to their ancestors and to their gods by cupping the water in their hands, lifting it and letting it fall back into the river; they offer flowers and rose petals and float shallow clay dishes filled with oil and lit with wicks (diyas). On the journey back home from the Ganges, they carry small quantities of river water with them for use in rituals; Ganga Jal, literally "the water of the Ganges".

The Ganges is the embodiment of all sacred waters in Hindu mythology. Local rivers are said to be "like" the Ganges, and are sometimes called the local Ganges. The Godavari River of Maharashtra in Western India is called the Ganges of the South or the 'Dakshin Ganga'; the Godavari is the Ganges that was led by the sage Gautama to flow through Central India. The Ganges is invoked whenever water is used in Hindu ritual, and is therefore present in all sacred waters. In spite of this, nothing is more stirring for a Hindu than a dip in the actual river, which is thought to remit sins, especially at one of the famous tirthas such as Gangotri, Haridwar, Prayag, or Varanasi. The symbolic and religious importance of the Ganges is one of the few things that Hindus, even their skeptics, have agreed upon. Jawaharlal Nehru, a religious iconoclast himself, asked for a handful of his ashes to be thrown into the Ganges. "The Ganga," he wrote in his will, "is the river of India, beloved of her people, round which are intertwined her racial memories, her hopes and fears, her songs of triumph, her victories and her defeats. She has been a symbol of India's age-long culture and civilization, ever-changing, ever-flowing, and yet ever the same Ganga."

In late May or early June every year, Hindus celebrate the "karunasiri" and rise of the Ganges from earth to heaven. The day of the celebration, "Ganga Dashahara", the "dashami" (tenth day) of the waxing moon of the Hindu calendar month Jyestha, brings throngs of bathers to the banks of the river. A dip in the Ganges on this day is said to rid the bather of ten sins (dasha = Sanskrit "ten"; hara = to destroy) or alternatively, ten lifetimes of sins. Those who cannot journey to the river, however, can achieve the same results by bathing in any nearby body of water, which, for the true believer, takes on all the attributes of the Ganges.

The "karunasiri" is an old theme in Hinduism with a number of different versions of the story. In the Vedic version, Indra, the Lord of Swarga (Heaven) slays the celestial serpent, Vritra, releasing the celestial liquid, "soma", or the nectar of the gods which then plunges to the earth and waters it with sustenance.

In the Vaishnava version of the myth, the heavenly waters were then a river called "Vishnupadi" (Sanskrit: "from the foot of Vishnu"). As Lord Vishnu as the avatar Vamana completes his celebrated three strides —of earth, sky, and heaven— he stubs his toe on the vault of heaven, punches open a hole, and releases the "Vishnupadi", which until now had been circling around the cosmic egg. Flowing out of the vault, she plummets down to Indra's heaven, where she is received by Dhruva, once a steadfast worshipper of Vishnu, now fixed in the sky as the Pole star. Next, she streams across the sky forming the Milky Way and arrives on the moon. She then flows down earthwards to Brahma's realm, a divine lotus atop Mount Meru, whose petals form the earthly continents. There, the divine waters break up, with one stream, the Bhagirathi, flowing down one petal into Bharatvarsha (India) as the Ganges.

It is Shiva, however, among the major deities of the Hindu pantheon, who appears in the most widely known version of the "avatarana" story. Told and retold in the Ramayana, the Mahabharata and several Puranas, the story begins with a sage, Kapila, whose intense meditation has been disturbed by the sixty thousand sons of King Sagara. Livid at being disturbed, Kapila sears them with his angry gaze, reduces them to ashes, and dispatches them to the netherworld. Only the waters of the Ganges, then in heaven, can bring the dead sons their salvation. A descendant of these sons, King Bhagiratha, anxious to restore his ancestors, undertakes rigorous penance and is eventually granted the prize of Ganges's descent from heaven. However, since her turbulent force would also shatter the earth, Bhagiratha persuades Shiva in his abode on Mount Kailash to receive Ganges in the coils of his tangled hair and break her fall. Ganges descends, is tamed in Shiva's locks, and arrives in the Himalayas. She is then led by the waiting Bhagiratha down into the plains at Haridwar, across the plains first to the confluence with the Yamuna at Prayag and then to Varanasi, and eventually to Ganges Sagar, where she meets the ocean, sinks to the netherworld, and saves the sons of Sagara. In honour of Bhagirath's pivotal role in the "avatarana", the source stream of the Ganges in the Himalayas is named Bhagirathi, (Sanskrit, "of Bhagiratha").

As the Ganges had descended from heaven to earth, she is also considered the vehicle of "ascent", from earth to heaven. As the "Triloka-patha-gamini", (Sanskrit: "triloka"= "three worlds", "patha" = "road", "gamini" = "one who travels") of the Hindu tradition, she flows in heaven, earth, and the netherworld, and, consequently, is a "tirtha" or crossing point of all beings, the living as well as the dead. It is for this reason that the story of the "avatarana" is told at "Shraddha" ceremonies for the deceased in Hinduism, and Ganges water is used in Vedic rituals after death. Among all hymns devoted to the Ganges, there are none more popular than the ones expressing the worshipper's wish to breathe his last surrounded by her waters. The "Gangashtakam" expresses this longing fervently: O Mother! ... Necklace adorning the worlds! <br> Banner rising to heaven! <br> I ask that I may leave of this body on your banks,<br> Drinking your water, rolling in your waves, <br> Remembering your name, bestowing my gaze upon you.
No place along her banks is more longed for at the moment of death by Hindus than Varanasi, the Great Cremation Ground, or "Mahashmshana". Those who are lucky enough to die in Varanasi, are cremated on the banks of the Ganges, and are granted instant salvation. If the death has occurred elsewhere, salvation can be achieved by immersing the ashes in the Ganges. If the ashes have been immersed in another body of water, a relative can still gain salvation for the deceased by journeying to the Ganges, if possible during the lunar "fortnight of the ancestors" in the Hindu calendar month of Ashwin (September or October), and performing the "Shraddha" rites.

Hindus also perform "pinda pradana", a rite for the dead, in which balls of rice and sesame seed are offered to the Ganges while the names of the deceased relatives are recited. Every sesame seed in every ball thus offered, according to one story, assures a thousand years of heavenly salvation for the each relative. Indeed, the Ganges is so important in the rituals after death that the "Mahabharata", in one of its popular "ślokas", says, "If only (one) bone of a (deceased) person should touch the water of the Ganges, that person shall dwell honoured in heaven." As if to illustrate this truism, the "Kashi Khanda" (Varanasi Chapter) of the Skanda Purana recounts the remarkable story of "Vahika", a profligate and unrepentant sinner, who is killed by a tiger in the forest. His soul arrives before Yama, the Lord of Death, to be judged for the afterworld. Having no compensating virtue, Vahika's soul is at once dispatched to hell. While this is happening, his body on earth, however, is being picked at by vultures, one of whom flies away with a foot bone. Another bird comes after the vulture, and in fighting him off, the vulture accidentally drops the bone into the Ganges below. Blessed by this event, Vahika, on his way to hell, is rescued by a celestial chariot which takes him instead to heaven.

Hindus consider the waters of the Ganges to be both pure and purifying. Nothing reclaims order from disorder more than the waters of the Ganges. Moving water, as in a river, is considered purifying in Hindu culture because it is thought to both absorb impurities and take them away. The swiftly moving Ganges, especially in its upper reaches, where a bather has to grasp an anchored chain in order to not be carried away, is considered especially purifying. What the Ganges removes, however, is not necessarily physical dirt, but symbolic dirt; it wipes away the sins of the bather, not just of the present, but of a lifetime.

A popular paean to the Ganges is the "Ganga Lahiri" composed by the seventeenth century poet Jagannatha who, as legend has it, was turned out of his Hindu Brahmin caste for having an affair with a Muslim woman. Having attempted futilely to be rehabilitated within the Hindu fold, the poet finally appeals to Ganges, the hope of the hopeless. Along with his beloved, Jagannatha sits at the top of the flight of steps leading to the water at the famous "Panchganga" Ghat in Varanasi. As he recites each verse of the poem, the waters of the Ganges rise up one step, until in the end they envelop the lovers and carry them away. "I come to you as a child to his mother," begins the "Ganga Lahiri". I come as an orphan to you, moist with love. <br> I come without refuge to you, giver of sacred rest. <br> I come a fallen man to you, uplifter of all. <br> I come undone by disease to you, the perfect physician. <br> I come, my heart dry with thirst, to you, ocean of sweet wine. <br> Do with me whatever you will.It is Shiva's relationship with Ganga that is the best-known in Ganges mythology. Her descent, the "avatarana" is not a one time event, but a continuously occurring one in which she is forever falling from heaven into his locks and being forever tamed. Shiva, is depicted in Hindu iconography as "Gangadhara", the "Bearer of the Ganges", with Ganga, shown as a spout of water, rising from his hair. Ganga is the moving, restless, rolling energy in the form of which the otherwise recluse and unapproachable Shiva appears on earth. As water, this moving energy can be felt, tasted, and absorbed. The war-god Skanda addresses the sage Agastya in the "Kashi Khand" of the "Skanda Purana" in these words: One should not be amazed ... that this Ganges is really Power, for is she not the Supreme Shakti of the Eternal Shiva, taken in the form of water?<br> This Ganges, filled with the sweet wine of compassion, was sent out for the salvation of the world by Shiva, the Lord of the Lords. <br> Good people should not think this Triple-Pathed River to be like the thousand other earthly rivers, filled with water. 

The Ganges is also the mother, the "Ganga Mata" (Hindi: "mata" ="mother") of Hindu worship and culture, accepting all and forgiving all. Unlike other goddesses, she has no destructive or fearsome aspect, destructive though she might be as a river in nature. She is also a mother of gods and demigods. In the "Mahabharata", she is the wife of Shantanu, and the mother of heroic warrior-patriarch, Bhishma. When Bhishma is mortally wounded in battle, Ganga comes out of the water in human form and weeps uncontrollably over his body.

The Ganges is the distilled lifeblood of the Hindu tradition; of its divinities, holy books, and enlightenment. As such, her worship does not require the usual rites of invocation ("avahana") at the beginning and dismissal ("visarjana") at the end, required in the worship of other gods. Her divinity is immediate and everlasting.

Early in ancient Indian culture, the river Ganges was associated with fecundity, its redeeming waters and its rich silt providing sustenance to all who lived along its banks. A counterpoise to the dazzling heat of the Indian summer, the Ganges came to be imbued with magical qualities and to be revered in anthropomorphic form. By the 5th century CE, an elaborate mythology surrounded the Ganges, now a goddess in her own right, and a symbol for all rivers of India. Hindu temples all over India had statues and reliefs of the goddess carved at their entrances, symbolically washing the sins of arriving worshippers and guarding the gods within. As protector of the sanctum sanctorum, the goddess soon came to be depicted with several characteristic accessories: the "makara" (a crocodile-like undersea monster, often shown with an elephant-like trunk), the "kumbha" (an overfull vase), various overhead parasol-like coverings, and a gradually increasing retinue of humans.

Central to the goddess's visual identification is the "makara", which is also her "vahana", or mount. An ancient symbol in India, it pre-dates all appearances of the goddess Ganga in art. The "makara" has a dual symbolism. On the one hand, it represents the life-affirming waters and plants of its environment; on the other, it represents fear, both fear of the unknown which it elicits by lurking in those waters, and real fear which it instils by appearing in sight. The earliest extant unambiguous pairing of the "makara" with Ganga is at the Udayagiri Caves in Central India (circa 400 CE). Here, in the Cave V, flanking the main figure of Vishnu shown in his boar incarnation, two river goddesses, Ganga and Yamuna appear atop their respective mounts, "makara" and "kurma" (a turtle or tortoise).

The "makara" is often accompanied by a "gana", a small boy or child, near its mouth, as, for example, shown in the Gupta period relief from Besnagar, Central India, in the left-most frame above. The "gana" represents both posterity and development ("udbhava"). The pairing of the fearsome, life-destroying "makara" with the youthful, life-affirming "gana" speaks to two aspects of the Ganges herself. Although she has provided sustenance to millions, she has also brought hardship, injury, and death by causing major floods along her banks. The goddess Ganga is also accompanied by a dwarf attendant, who carries a cosmetic bag, and on whom she sometimes leans, as if for support. (See, for example, frames 1, 2, and 4 above.)

The "purna kumbha" or full pot of water is the second most discernible element of the Ganga iconography. Appearing first also in the relief in the Udayagiri Caves (5th century), it gradually appeared more frequently as the theme of the goddess matured. By the seventh century it had become an established feature, as seen, for example, in the Dashavatara temple, Deogarh, Uttar Pradesh (seventh century), the Trimurti temple, Badoli, Chittorgarh, Rajasthan, and at the Lakshmaneshwar temple, Kharod, Bilaspur, Chhattisgarh, (ninth or tenth century), and seen very clearly in frame 3 above and less clearly in the remaining frames. Worshipped even today, the full pot is emblematic of the formless Brahman, as well as of woman, of the womb, and of birth. Furthermore, The river goddesses Ganga and Saraswati were both born from Brahma's pot, containing the celestial waters.

In her earliest depictions at temple entrances, the goddess Ganga appeared standing beneath the overhanging branch of a tree, as seen as well in the Udayagiri caves. However, soon the tree cover had evolved into a "chatra" or parasol held by an attendant, for example, in the seventh-century Dasavatara temple at Deogarh. (The parasol can be clearly seen in frame 3 above; its stem can be seen in frame 4, but the rest has broken off.) The cover undergoes another transformation in the temple at Kharod, Bilaspur (ninth or tenth century), where the parasol is lotus-shaped, and yet another at the Trimurti temple at Badoli where the parasol has been replaced entirely by a lotus.

As the iconography evolved, sculptors, especially in central India, were producing animated scenes of the goddess, replete with an entourage and suggestive of a queen en route to a river to bathe. A relief similar to the depiction in frame 4 above, is described in as follows: A typical relief of about the ninth century that once stood at the entrance of a temple, the river goddess Ganga is shown as a voluptuously endowed lady with a retinue. Following the iconographic prescription, she stands gracefully on her composite "makara" mount and holds a water pot. The dwarf attendant carries her cosmetic bag, and a ... female holds the stem of a giant lotus leaf that serves as her mistress's parasol. The fourth figure is a male guardian. Often in such reliefs the "makara"'s tail is extended with great flourish into a scrolling design symbolizing both vegetation and water.

Kumbh Mela is a mass Hindu pilgrimage in which Hindus gather at the Ganges River. The normal Kumbh Mela is celebrated every 3 years, the "Ardh" (half) Kumbh is celebrated every six years at Haridwar and Prayag, the "Purna" (complete) Kumbh takes place every twelve years at four places (Prayag (Allahabad), Haridwar, Ujjain, and Nashik). The "Maha" (great) Kumbh Mela which comes after 12 'Purna Kumbh Melas', or 144 years, is held at Prayag (Allahabad).

The major event of the festival is ritual bathing at the banks of the river. Other activities include religious discussions, devotional singing, mass feeding of holy men and women and the poor, and religious assemblies where doctrines are debated and standardized. Kumbh Mela is the most sacred of all the pilgrimages. Thousands of holy men and women attend, and the auspiciousness of the festival is in part attributable to this. The sadhus are seen clad in saffron sheets with ashes and powder dabbed on their skin per the requirements of ancient traditions. Some, called "naga sanyasis", may not wear any clothes.

The Ganges and its all tributaries, especially the Yamuna, have been used for irrigation since ancient times. Dams and canals were common in gangetic plain by fourth century BCE. The Ganges-Brahmaputra-Meghna basin has a huge hydroelectric potential, on the order of 200,000 to 250,000 megawatts, nearly half of which could easily be harnessed. As of 1999, India tapped about 12% of the hydroelectric potential of the Ganges and just 1% of the vast potential of the Brahmaputra.

Megasthenes, a Greek ethnographer who visited India during the third century BCE when Mauryans ruled India described the existence of canals in the gangetic plain. Kautilya (also known as Chanakya), an advisor to Chandragupta Maurya, the founder of Maurya Empire, included the destruction of dams and levees as a strategy during war. Firuz Shah Tughlaq had many canals built, the longest of which, , was built in 1356 on the Yamuna River. Now known as the Western Yamuna Canal, it has fallen into disrepair and been restored several times. The Mughal emperor Shah Jahan built an irrigation canal on the Yamuna River in the early 17th century. It fell into disuse until 1830, when it was reopened as the Eastern Yamuna Canal, under British control. The reopened canal became a model for the Upper Ganges Canal and all following canal projects.

The first British canal in India—with no Indian antecedents—was the Ganges Canal built between 1842 and 1854.
Contemplated first by Col. John Russell Colvin in 1836, it did not at first elicit much enthusiasm from its eventual architect Sir Proby Thomas Cautley, who balked at idea of cutting a canal through extensive low-lying land in order to reach the drier upland destination. However, after the Agra famine of 1837–38, during which the East India Company's administration spent Rs. 2,300,000 on famine relief, the idea of a canal became more attractive to the company's budget-conscious Court of Directors. In 1839, the Governor General of India, Lord Auckland, with the Court's assent, granted funds to Cautley for a full survey of the swath of land that underlay and fringed the projected course of the canal. The Court of Directors, moreover, considerably enlarged the scope of the projected canal, which, in consequence of the severity and geographical extent of the famine, they now deemed to be the entire Doab region.

The enthusiasm, however, proved to be short lived. Auckland's successor as Governor General, Lord Ellenborough, appeared less receptive to large-scale public works, and for the duration of his tenure, withheld major funds for the project. Only in 1844, when a new Governor-General, Lord Hardinge, was appointed, did official enthusiasm and funds return to the Ganges canal project. Although the intervening impasse had seemingly affected Cautley's health and required him to return to Britain in 1845 for recuperation, his European sojourn gave him an opportunity to study contemporary hydraulic works in the United Kingdom and Italy. By the time of his return to India even more supportive men were at the helm, both in the North-Western Provinces, with James Thomason as Lt. Governor, and in British India with Lord Dalhousie as Governor-General. Canal construction, under Cautley's supervision, now went into full swing. A long canal, with another of branch lines, eventually stretched between the headworks in Haridwar, splitting into two branches below Aligarh, and its two confluences with the Yamuna (Jumna in map) mainstem in Etawah and the Ganges in Kanpur (Cawnpore in map). The Ganges Canal, which required a total capital outlay of £2.15 million, was officially opened in 1854 by Lord Dalhousie. According to historian Ian Stone: It was the largest canal ever attempted in the world, five times greater in its length than all the main irrigation lines of Lombardy and Egypt put together, and longer by a third than even the largest USA navigation canal, the Pennsylvania Canal.

A major barrage at Farakka was opened on 21 April 1975, It is located close to the point where the main flow of the river enters Bangladesh, and the tributary Hooghly (also known as Bhagirathi) continues in West Bengal past
Kolkata. This barrage, which feeds the Hooghly branch of the river by a long feeder canal, and its water flow management has been a long-lingering source of dispute with Bangladesh. Indo-Bangladesh Ganges Water Treaty signed in December 1996 addressed some of the water sharing issues between India and Bangladesh. There is Lav Khush Barrage across the river Ganges in Kanpur.

Tehri Dam was constructed on Bhagirathi River, tributary of the Ganges. It is located 1.5 km downstream of Ganesh Prayag, the place where Bhilangana meets Bhagirathi. Bhagirathi is called Ganges after Devprayag. Construction of the dam in an earthquake prone area was controversial.

Bansagar Dam was built on the Sone River, a tributary of the Ganges for both irrigation and hydroelectric power generation. Ganges flood waters along with Brahmaputra waters can be supplied to most of its right side basin area along with central and south India by constructing a coastal reservoir to store water on the Bay of Bengal sea area.

The Ganges Basin with its fertile soil is instrumental to the agricultural economies of India and Bangladesh. The Ganges and its tributaries provide a perennial source of irrigation to a large area. Chief crops cultivated in the area include rice, sugarcane, lentils, oil seeds, potatoes, and wheat. Along the banks of the river, the presence of swamps and lakes provides a rich growing area for crops such as legumes, chillies, mustard, sesame, sugarcane, and jute. There are also many fishing opportunities along the river, though it remains highly polluted. Also the major industrial towns of Unnao and Kanpur, situated on the banks of the river with the predominance of tanning industries add to the pollution. Kanpur is the largest city on the Ganges.

Tourism is another related activity. Three towns holy to Hinduism—Haridwar, Prayag (Allahabad), and Varanasi—attract millions of pilgrims to its waters to take a dip in the Ganges, which is believed to cleanse oneself of sins and help attain salvation. The rapids of the Ganges also are popular for river rafting, attracting adventure seekers in the summer months. Also, several cities such as Kanpur, Kolkata and Patna have developed riverfront walkways along the banks to attract tourists.

Human development, mostly agriculture, has replaced nearly all of the original natural vegetation of the Ganges basin. More than 95% of the upper Gangetic Plain has been degraded or converted to agriculture or urban areas. Only one large block of relatively intact habitat remains, running along the Himalayan foothills and including Rajaji National Park, Jim Corbett National Park, and Dudhwa National Park. As recently as the 16th and 17th centuries the upper Gangetic Plain harboured impressive populations of wild Asian elephants ("Elephas maximus"), Bengal tigers ("Panthera t. tigris"), Indian rhinoceros ("Rhinoceros unicornis"), gaurs ("Bos gaurus"), barasinghas ("Rucervus duvaucelii"), sloth bears ("Melursus ursinus") and Indian lions ("Panthera leo leo"). In the 21st century there are few large wild animals, mostly deer, wild boars, wildcats, and small numbers of Indian wolves, golden jackals, and red and Bengal foxes. Bengal tigers survive only in the Sundarbans area of the Ganges Delta. The Sundarbands freshwater swamp ecoregion, however, is nearly extinct. Threatened mammals in the upper Gangetic Plain include the tiger, elephant, sloth bear, and four-horned antelope ("Tetracerus quadricornis").

Many types of birds are found throughout the basin, such as myna, "Psittacula" parakeets, crows, kites, partridges, and fowls. Ducks and snipes migrate across the Himalayas during the winter, attracted in large numbers to wetland areas. There are no endemic birds in the upper Gangetic Plain. The great Indian bustard ("Ardeotis nigriceps") and lesser florican ("Sypheotides indicus") are considered globally threatened.

The natural forest of the upper Gangetic Plain has been so thoroughly eliminated it is difficult to assign a natural vegetation type with certainty. There are a few small patches of forest left, and they suggest that much of the upper plains may have supported a tropical moist deciduous forest with sal ("Shorea robusta") as a climax species.

A similar situation is found in the lower Gangetic Plain, which includes the lower Brahmaputra River. The lower plains contain more open forests, which tend to be dominated by "Bombax ceiba" in association with "Albizzia procera", "Duabanga grandiflora", and "Sterculia vilosa". There are early seral forest communities that would eventually become dominated by the climax species sal ("Shorea robusta"), if forest succession was allowed to proceed. In most places forests fail to reach climax conditions due to human causes. The forests of the lower Gangetic Plain, despite thousands of years of human settlement, remained largely intact until the early 20th century. Today only about 3% of the ecoregion is under natural forest and only one large block, south of Varanasi, remains. There are over forty protected areas in the ecoregion, but over half of these are less than . The fauna of the lower Gangetic Plain is similar to the upper plains, with the addition of a number of other species such as the smooth-coated otter ("Lutrogale perspicillata") and the large Indian civet ("Viverra zibetha").

It has been estimated that about 350 fish species live in the entire Ganges drainage, including several endemics. In a major 2007–2009 study of fish in the Ganges basin (including the river itself and its tributaries, but excluding the Brahmaputra and Meghna basins), a total of 143 fish species were recorded, including 10 non-native introduced species. The most diverse orders are Cypriniformes (barbs and allies), Siluriformes (catfish) and Perciformes (perciform fish), each comprising about 50%, 23% and 14% of the total fish species in the drainage.

There are distinct differences between the different sections of the river basin, but Cyprinidae is the most diverse throughout. In the upper section (roughly equalling the basin parts in Uttarakhand) more than 50 species have been recorded and Cyprinidae alone accounts for almost 80% those, followed by Balitoridae (about 15.6%) and Sisoridae (about 12.2%). Sections of the Ganges basin at altitudes above above sea level are generally without fish. Typical genera approaching this altitude are "Schizothorax", "Tor", "Barilius", "Nemacheilus" and "Glyptothorax". About 100 species have been recorded from the middle section of the basin (roughly equalling the sections in Uttar Pradesh and parts of Bihar) and more than 55% of these are in family Cyprinidae, followed by Schilbeidae (about 10.6%) and Clupeidae (about 8.6%). The lower section (roughly equalling the basin in parts of Bihar and West Bengal) includes major floodplains and is home to almost 100 species. About 46% of these are in the family Cyprinidae, followed by Schilbeidae (about 11.4%) and Bagridae (about 9%).

The Ganges basin supports major fisheries, but these have declined in recent decades. In the Allahabad region in the middle section of the basin, catches of carp fell from 424.91 metric tons in 1961–1968 to 38.58 metric tons in 2001–2006, and catches of catfish fell from 201.35 metric tons in 1961–1968 to 40.56 metric tons in 2001–2006. In the Patna region in the lower section of the basin, catches of carp fell from 383.2 metric tons to 118, and catfish from 373.8 metric tons to 194.48. Some of the fish commonly caught in fisheries include catla ("Catla catla"), golden mahseer ("Tor putitora"), tor mahseer ("Tor tor"), rohu ("Labeo rohita"), walking catfish ("Clarias batrachus"), pangas catfish ("Pangasius pangasius"), goonch catfish ("Bagarius"), snakeheads ("Channa"), bronze featherback ("Notopterus notopterus") and milkfish ("Chanos chanos").

The Ganges basin is home to about 30 fish species that are listed as threatened with the primary issues being overfishing (sometimes illegal), pollution, water abstraction, siltation and invasive species. Among the threatened species is the critically endangered Ganges shark ("Glyphis gangeticus"). Several fish species migrate between different sections of the river, but these movements may be prevented by the building of dams.

The main sections of the Ganges River are home to the gharial ("Gavialis gangeticus") and mugger crocodile ("Crocodylus palustris"), and the delta is home to the saltwater crocodile ("C. porosus"). Among the numerous aquatic and semi-aquatic turtles in the Ganges basin are the northern river terrapin ("Batagur baska"; only in the lowermost section of the basin), three-striped roofed turtle ("B. dhongoka"), red-crowned roofed turtle ("B. kachuga"), black pond turtle ("Geoclemys hamiltonii"), Brahminy river turtle ("Hardella thurjii"), Indian black turtle ("Melanochelys trijuga"), Indian eyed turtle ("Morenia petersi"), brown roofed turtle ("Pangshura smithii"), Indian roofed turtle ("Pangshura tecta"), Indian tent turtle ("Pangshura tentoria"), Indian flapshell turtle ("Lissemys punctata"), Indian narrow-headed softshell turtle ("Chitra indica"), Indian softshell turtle ("Nilssonia gangetica"), Indian peacock softshell turtle ("N. hurum") and Cantor's giant softshell turtle ("Pelochelys cantorii"; only in the lowermost section of Ganges basin). Most of these are seriously threatened.

The river's most famed faunal member is the freshwater Ganges river dolphin ("Platanista gangetica gangetica"), which has been declared India's national aquatic animal.

This dolphin used to exist in large schools near to urban centres in both the Ganges and Brahmaputra rivers, but is now seriously threatened by pollution and dam construction. Their numbers have now dwindled to a quarter of their numbers of fifteen years before, and they have become extinct in the Ganges' main tributaries. A recent survey by the World Wildlife Fund found only 3,000 left in the water catchment of both river systems.

The Ganges river dolphin is one of only five true freshwater dolphins in the world. The other four are the baiji ("Lipotes vexillifer") of the Yangtze River in China, now likely extinct; the Indus River dolphin of the Indus River in Pakistan; the Amazon river dolphin of the Amazon River in South America; and the Araguaian river dolphin (not considered a separate species until 2014) of the Araguaia–Tocantins basin in Brazil. There are several marine dolphins whose ranges include some freshwater habitats, but these five are the only dolphins who live only in freshwater rivers and lakes.

The Tibetan Plateau contains the world's third-largest store of ice. Qin Dahe, the former head of the China Meteorological Administration, said that the recent fast pace of melting and warmer temperatures will be good for agriculture and tourism in the short term; but issued a strong warning:

In 2007, the Intergovernmental Panel on Climate Change (IPCC), in its Fourth Report, stated that the Himalayan glaciers which feed the river, were at risk of melting by 2035. The IPCC has now withdrawn that prediction, as the original source admitted that it was speculative and the cited source was not a peer reviewed finding. In its statement, the IPCC stands by its general findings relating to the Himalayan glaciers being at risk from global warming (with consequent risks to water flow into the Gangetic basin). Many studies have suggested that the climate change will affect the water resources in the Ganges river basin including increased summer (monsoon) flow, and peak runoff could result in an increased risk of flooding.

The Ganges suffers from extreme pollution levels, caused by the 400 million people who live close to the river. Sewage from many cities along the river's course, industrial waste and religious offerings wrapped in non-degradable plastics add large amounts of pollutants to the river as it flows through densely populated areas. The problem is exacerbated by the fact that many poorer people rely on the river on a daily basis for bathing, washing, and cooking. The World Bank estimates that the health costs of water pollution in India equal three percent of India's GDP. It has also been suggested that eighty percent of all illnesses in India and one-third of deaths can be attributed to water-borne diseases.

Varanasi, a city of one million people that many pilgrims visit to take a "holy dip" in the Ganges, releases around 200 million liters of untreated human sewage into the river each day, leading to large concentrations of fecal coliform bacteria. According to official standards, water safe for bathing should not contain more than 500 fecal coliforms per 100 ml, yet upstream of Varanasi's ghats the river water already contains 120 times as much, 60,000 fecal coliform bacteria per 100 ml.

After the cremation of the deceased at Varanasi's ghats the bones and ashes are thrown into the Ganges. However, in the past thousands of uncremated bodies were thrown into the Ganges during cholera epidemics, spreading the disease. Even today, holy men, pregnant women, people with leprosy or chicken pox, people who have been bitten by snakes, people who have committed suicide, the poor, and children under 5 are not cremated at the ghats but are left to float free, in order to decompose in the waters. In addition, those who cannot afford the large amount of wood needed to incinerate the entire body, leave behind a lot of half burned body parts.

After passing through Varanasi, and receiving 32 streams of raw sewage from the city, the concentration of fecal coliforms in the river's waters rises from 60,000 to 1.5 million, with observed peak values of 100 million per 100 ml. Drinking and bathing in its waters therefore carries a high risk of infection.

Between 1985 and 2000, Rs. 10 billion, around US$226 million, or less than 4 cents per person per year, were spent on the Ganga Action Plan, an environmental initiative that was "the largest single attempt to clean up a polluted river anywhere in the world." The Ganga Action Plan has been described variously as a "failure", a "major failure".

According to one study, 
The Ganga Action Plan, which was taken on priority and with much enthusiasm, was delayed for two years. The expenditure was almost doubled. But the result was not very appreciable. Much expenditure was done over the political propaganda. The concerning governments and the related agencies were not very prompt to make it a success. The public of the areas was not taken into consideration. The releasing of urban and industrial wastes in the river was not controlled fully. The flowing of dirty water through drains and sewers were not adequately diverted. The continuing customs of burning dead bodies, throwing carcasses, washing of dirty clothes by washermen, and immersion of idols and cattle wallowing were not checked. Very little provision of public latrines was made and the open defecation of lakhs of people continued along the riverside. All these made the Action Plan a failure.

The failure of the Ganga Action Plan, has also been variously attributed to "environmental planning without proper understanding of the human–environment interactions," Indian "traditions and beliefs," "corruption and a lack of technical knowledge" and "lack of support from religious authorities."

In December 2009 the World Bank agreed to loan India US$1 billion over the next five years to help save the river. According to 2010 Planning Commission estimates, an investment of almost Rs. 70 billion (Rs. 70 billion, approximately US$1.5 billion) is needed to clean up the river.

In November 2008, the Ganges, alone among India's rivers, was declared a "National River", facilitating the formation of a National Ganga River Basin Authority that would have greater powers to plan, implement and monitor measures aimed at protecting the river.

In July 2014, the Government of India announced an integrated Ganges-development project titled "Namami Ganga" and allocated 2,037 crore for this purpose.

In March 2017 the High Court of Uttarakhand declared the Ganges River a legal "person", in a move that according to one newspaper, "could help in efforts to clean the pollution-choked rivers." , the ruling has been commented on in Indian newspapers to be hard to enforce, that experts do not anticipate immediate benefits, that the ruling is "hardly game changing," that experts believe "any follow-up action is unlikely," and that the "judgment is deficient to the extent it acted without hearing others (in states outside Uttarakhand) who have stakes in the matter."

The incidence of water-borne and enteric diseases—such as gastrointestinal disease, cholera, dysentery, hepatitis A and typhoid—among people who use the river's waters for bathing, washing dishes and brushing teeth is high, at an estimated 66% per year.

Recent studies by Indian Council of Medical Research (ICMR) say that the river is so full of killer pollutants that those living along its banks in Uttar Pradesh, Bihar and Bengal are more prone to cancer than anywhere else in the country. Conducted by the National Cancer Registry Programme under the ICMR, the study throws up shocking findings indicating that the river is thick with heavy metals and lethal chemicals that cause cancer. According to Deputy Director General of NCRP A. Nandkumar, the incidence of cancer was highest in the country in areas drained by the Ganges and stated that the problem would be studied deeply and with the findings presented in a report to the health ministry.

Apart from that, many NGOs have came forward to rejuvenate river Ganges. Vikrant Tongad, an Environmental specialist from SAFE Green filed a petition against Simbhaoli Sugar Mill (Hapur UP) to NGT. NGT slapped a fine of Rs. 5 crore to Sugar Mill also, a fine of 25 Lakhs to Gopaljee Dairy for discharging untreated effluents into the Simbhaoli drain.

Along with ever-increasing pollution, water shortages are getting noticeably worse. Some sections of the river are already completely dry. Around Varanasi, the river once had an average depth of , but in some places, it is now only .

Illegal mining in the Ganges river bed for stones and sand for construction work has long been a problem in Haridwar district, Uttarakhand, where it touches the plains for the first time. This is despite the fact that quarrying has been banned in Kumbh Mela area zone covering 140 km area in Haridwar.






</doc>
<doc id="12449" url="https://en.wikipedia.org/wiki?curid=12449" title="Mobile Suit Gundam Wing">
Mobile Suit Gundam Wing

Mobile Suit Gundam Wing, also known in Japan as , is a 1995 Japanese mecha anime series directed by Masashi Ikeda and written by Katsuyuki Sumizawa. It is the sixth installment in the "Gundam" franchise, taking place in the "After Colony" timeline. As with the original series, the plot of "Gundam Wing" centers on a war in the future (specifically the 2220s) between Earth and its orbital colonies in the Earth-Moon system.

The series aired in Japan on the terrestrial TV Asahi network. It ran for 49 episodes, beginning on April 7, 1995 and ending on March 29, 1996. It received multiple manga adaptations, as well as video games. Four original video animation (OVA) episodes were produced including a retelling of the series, "Operation Meteor", and a direct sequel, "". In 2010, Sumizawa started writing the novel "", another sequel to the series. While the series fared modestly well in Japan, it found greater success in the United States and popularized the "Gundam" franchise in the West.

In the distant future, Mankind has colonized space, with clusters of space colonies at each of the five Earth-Moon Lagrange points. Down on the Earth, the nations have come together to form the United Earth Sphere Alliance. This Alliance oppresses the colonies with its vast military might. The colonies wishing to be free, join together in a movement headed by the pacifist Heero Yuy. In the year After Colony 175, Yuy is shot dead by an assassin, forcing the colonies to search for other paths to peace. The assassination prompts five disaffected scientists from the Organization of the Zodiac, more commonly referred to as OZ, to turn rogue upon the completion of the mobile suit prototype Tallgeese.

The story of "Gundam Wing" begins in the year After Colony 195, with the start of "Operation Meteor": the scientists' plan for revenge against OZ. The operation involves five teenage boys, who have each been chosen and trained by each of the five scientists, then sent to Earth independently in extremely advanced mobile suits (one designed by each of the scientists) known as "Gundams" (called such because they are constructed from a rare and astonishingly durable material called Gundanium alloy, which can only be created in outer space). Each Gundam is sent from a different colony, and the pilots are initially unaware of each other's existence.

The series focuses primarily on the five Gundam pilots: Heero Yuy (an alias, not to be confused with the martyred pacifist), Duo Maxwell, Trowa Barton, Quatre Raberba Winner and Chang Wufei. Their mission is to use their Gundams to attack OZ directly, in order to rid the Alliance of its weapons and free the colonies from its oppressive rule. The series also focuses on Relena Peacecraft, heir to the pacifist Sanc Kingdom, who becomes an important political ally to the Gundam pilots (particularly Heero) over the course of the series.

The making of "Gundam Wing" was influenced by "Mobile Fighter G Gundam" with the idea of having five main characters. Originally, the series was meant to be titled "Gundam Meteor" after "Operation Meteor." Bandai suggested having a Gundam with the ability of transforming into a plane-like form. The writers worked together for one week conceptualizing the characters, mobile suits and first 40 episodes. Director Masashi Ikeda reacted to their work comparing it to the first "Gundam" series, "Zeta" and "G" all at once. The series was more focused on drama than mecha, which the staff credits as one of the reasons for the show's popularity within the female demographic.

Writer Katsuyuki Sumizawa expressed difficulties in the making of the story as opposed to his work in novels due to the fact he relayed duties to other members. However, the handling of the five characters was made easy due to the setting. Early sketches of the protagonists by Ikeda were handled by character designer Shuko Murase. He was cast due to his work with Ikeda in "Samurai Troopers". The director wanted the designs to appeal to the female demographic. Originally, Duo Maxwell was set as the protagonist but was replaced by Heero Yuy. The staff members noted Heero was too different from previous Gundam protagonists and were afraid he would be unpopular. The voice casting was more difficult to do than the ones from previous series due to the different atmosphere.

Following the series' ending, the staff members were asked by the studio to make a sequel due to its popularity. Neither Ikeda nor executive producer Hideyuki Tomioka intended to make a sequel for "Gundam Wing". However, Sumizawa was bothered by the finale as he felt the series ended abruptly. Tomioka asked Sumizawa if he could write a continuation which he agreed.

"Gundam Wing" was not the first series in the "Gundam" franchise to be dubbed and distributed in the U.S. (the compilation movie version of the original "Mobile Suit Gundam", as well as the OVAs "" and "", preceded it by about two years), but it is well known as the first "Gundam" series to be aired on American television. This dub was produced by Bandai Entertainment and the voice work was done by Ocean Productions. The series aired on Cartoon Network's weekday afternoon after-school programming block Toonami, premiering on March 6, 2000. In the first extended promo leading up to the series' premiere, voice actor Peter Cullen narrated the back story, evoking memories of "Voltron's" opening credits. The promo was said to be so riveting that Bandai decided to use it as the official promo for the series.

It was broadcast in two formats: an edited version shown in the daytime on Toonami and an uncut version shown past midnight as part of Toonami's "Midnight Run." Examples of the edits included the removal of blood, profanity, atheism, and the word "kill" being replaced with the word "destroy" (this was extended to Duo's nickname, "The God of Death," changed to "The Great Destroyer," forcing the alteration of two episode titles), though the word "death" was mostly left intact. All "Gundam Wing" episodes have been released to VHS and DVD in the U.S. Differences between the two video systems is that the VHS episodes contain the edited version while the DVD episodes contain the uncut version.

Due to the closure of Bandai Entertainment, the series was out-of-print for sometime. On October 11, 2014 at their 2014 New York Comic-Con panel, Sunrise announced they will be releasing all of the Gundam franchise, including "Gundam Wing" in North America though distribution from Right Stuf Inc., beginning in Spring 2015. Right Stuf released the series on Blu-ray and DVD in two sets in November 2017. In addition, a collector's edition set containing the complete series, "Endless Waltz", "Operation Meteor" and the "Frozen Teardrop" picture drama was released in December 2017.

After the series ended, four original video animation (OVA) episodes, compiling various scenes from the series along with a few minutes of new footage, were released in 1996 as "Gundam Wing: Operation Meteor" I and II. 

A three-part OVA titled "" was produced in 1997 as a sequel to the TV series; plot-wise, it brought the "After Colony" timeline to a close. The OVA was also notable for its massive redesigns of all the Gundams by Hajime Katoki, such as the Wing Gundam Zero's new "angel-winged" appearance. A compilation movie version of "Endless Waltz" (featuring additional footage, alterations of the music score and a different ending theme) was later released in Japan on August 1, 1998. "Endless Waltz" premiered on Cartoon Network in the U.S. on November 10, 2000. Both the OVA and movie versions of "Endless Waltz" were later released together on DVD. Right Stuf released both OVAs on Blu-ray and DVD in December 2017 (though "Operation Meteor" remains un-dubbed).

In addition to manga adaptations of the series and "Endless Waltz", several manga sidestories have also been produced. "" is a prequel, detailing the events leading up to series; the stories have been collected in a volume that also contains one brief open-ended interlude, "Preventer 5", that details an operation that occurs after "Endless Waltz". A coincident storyline to the series is presented in "". Several sequel manga, occurring between "Gundam Wing" and "Endless Waltz", have also been written: "Blind Target", "Ground Zero" and "Battlefield of Pacifists".

The "Gundam Wing", "Battlefield of Pacifists" and "Endless Waltz" manga series were published in English by Tokyopop, while "Blind Target", "Ground Zero" and "Episode Zero" were published by Viz Communications. Another sequel manga detailing the future of the colonies entitled "Tiel's Impulse" was printed in 1998 and has not been published in the United States.

In September 2010, "Gundam Ace" magazine began serializing a manga titled "New Mobile Report Gundam Wing Endless Waltz: The Glory of Losers" that retells the events of the anime while incorporating facts from "Episode Zero" and the novel "Frozen Teardrop". The manga also uses Hajime Katoki's Gundam redesigns from "Endless Waltz" and other subsequent media, instead of the original Kunio Okawara designs featured in the anime. Vertical published English editions of the manga volumes under the title "Mobile Suit Gundam Wing Endless Waltz: Glory of the Losers" from July 2017 to November 2019.

In early 2010, "Gundam Ace" magazine announced they would serialize a "New "Gundam Wing" Project". The project was eventually revealed to be a novel, titled "". Written by Katsuyuki Sumizawa, the novel begins a new timeline, following the "Mars Century" calendar ("MC") which was the successor of the previous "After Colony" calendar. According to an interview with the author, the novel spans backwards into the AC century and the Gundam pilots, Relena, and their children make appearances.

A fighting video game titled "" was developed by Natsume and released for the Super Famicom in Japan on March 29, 1996. A second fighting game titled "Shin Kidō Senki Gundam Wing: The Battle" was developed by Natsume and released for the PlayStation in Japan on October 11, 2002 as the 13th volume of the Simple Characters 2000 series. "Gundam Wing" characters and mecha have also appeared in several other video game series including "Super Robot Wars", "Gundam Battle Assault", "Another Century's Episode", "" and "".

Upon the series' debut in North America, "Gundam Wing" received a large roster of licensees for merchandise including wallscrolls, apparel, school supplies, skateboards, trading cards, model kits and action figures.




"Gundam Wing" was only a modest success in Japan during its initial run; it, along with "G Gundam", was the only "Gundam" series of the 1990s that managed an average television rating over four percent. It was ranked number two in "Animage" magazine's Anime Grand Prix in 1996 and was also ranked number 76 in the publication's list of the 100 most important anime of all time. The series is infamous within "dōjinshi" where authors tend to depict romantic relationships between several of the protagonists.

"Gundam Wing" was a greater success in North America, however, and is credited with single-handedly popularizing the "Gundam" franchise among Western audiences. Just over a week after its premiere on Cartoon Network on March 6, 2000, the series was the top rated program in all age groups. During the summer of 2000, it remained as the first or second top-rated show among kids and teens during its twelve airings per week on the Toonami block. "Gundam Wing" was ranked the 73rd best animated series by IGN, calling the series "so good that even those opposed to anime have to give the show its due credit".

 

 


</doc>
<doc id="12450" url="https://en.wikipedia.org/wiki?curid=12450" title="Gödel's completeness theorem">
Gödel's completeness theorem

Gödel's completeness theorem is a fundamental theorem in mathematical logic that establishes a correspondence between semantic truth and syntactic provability in first-order logic. It makes a close link between model theory that deals with what is true in different models, and proof theory that studies what can be formally proven in particular formal systems.

It was first proved by Kurt Gödel in 1929. It was then simplified in 1947, when Leon Henkin observed in his Ph.D. thesis that the hard part of the proof can be presented as the Model Existence Theorem (published in 1949). Henkin's proof was simplified by Gisbert Hasenjaeger in 1953.

There are numerous deductive systems for first-order logic, including systems of natural deduction and Hilbert-style systems. Common to all deductive systems is the notion of a formal deduction. This is a sequence (or, in some cases, a finite tree) of formulas with a specially-designated conclusion. The definition of a deduction is such that it is finite and that it is possible to verify algorithmically (by a computer, for example, or by hand) that a given sequence (or tree) of formulas is indeed a deduction.

A first-order formula is called logically valid if it is true in every structure for the language of the formula (i.e. for any assignment of values to the variables of the formula). To formally state, and then prove, the completeness theorem, it is necessary to also define a deductive system. A deductive system is called complete if every logically valid formula is the conclusion of some formal deduction, and the completeness theorem for a particular deductive system is the theorem that it is complete in this sense. Thus, in a sense, there is a different completeness theorem for each deductive system. A converse to completeness is soundness, the fact that only logically valid formulas are provable in the deductive system.

If some specific deductive system of first-order logic is sound and complete, then it is "perfect" (a formula is provable if and only if it is logically valid), thus equivalent to any other deductive system with the same quality (any proof in one system can be converted into the other).

We first fix a deductive system of first-order predicate calculus, choosing any of the well-known equivalent systems. Gödel's original proof assumed the Hilbert-Ackermann proof system.

The completeness theorem says that if a formula is logically valid then there is a finite deduction (a formal proof) of the formula.

Thus, the deductive system is "complete" in the sense that no additional inference rules are required to prove all the logically valid formulas. A converse to completeness is soundness, the fact that only logically valid formulas are provable in the deductive system. Together with soundness (whose verification is easy), this theorem implies that a formula is logically valid if and only if it is the conclusion of a formal deduction.

The theorem can be expressed more generally in terms of logical consequence. We say that a sentence "s" is a syntactic consequence of a theory "T", denoted formula_1, if "s" is provable from "T" in our deductive system. We say that "s" is a semantic consequence of "T", denoted formula_2, if "s" holds in every model of "T". The completeness theorem then says that for any first-order theory "T" with a well-orderable language, and any sentence "s" in the language of "T",

Since the converse (soundness) also holds, it follows that formula_2 iff formula_1, and thus that syntactic and semantic consequence are equivalent for first-order logic.

This more general theorem is used implicitly, for example, when a sentence is shown to be provable from the axioms of group theory by considering an arbitrary group and showing that the sentence is satisfied by that group.

Gödel's original formulation is deduced by taking the particular case of a theory without any axiom.

The completeness theorem can also be understood in terms of consistency, as a consequence of Henkin's model existence theorem. We say that a theory "T" is syntactically consistent if there is no sentence "s" such that both "s" and its negation ¬"s" are provable from "T" in our deductive system. The model existence theorem says that for any first-order theory "T" with a well-orderable language,

Another version, with connections to the Löwenheim–Skolem theorem, says:

Given Henkin's theorem, the completeness theorem can be proved as follows: If formula_9, then formula_10 does not have models. By the contrapositive of Henkin's theorem, then formula_10 is syntactically inconsistent. So a contradiction (formula_12) is provable from formula_10 in the deductive system. Hence formula_14, and then by the properties of the deductive system, formula_1.

The Model Existence Theorem and its proof can be formalized in the framework of Peano arithmetic. Precisely, we can systematically define a model of any consistent effective first-order theory "T" in Peano arithmetic by interpreting each symbol of "T" by an arithmetical formula whose free variables are the arguments of the symbol. (In many cases, we will need to assume, as a hypothesis of the construction, that "T" is consistent, since Peano arithmetic may not prove that fact.) However, the definition expressed by this formula is not recursive (but is, in general, Δ).

An important consequence of the completeness theorem is that it is possible to recursively enumerate the semantic consequences of any effective first-order theory, by enumerating all the possible formal deductions from the axioms of the theory, and use this to produce an enumeration of their conclusions. 

This comes in contrast with the direct meaning of the notion of semantic consequence, that quantifies over all structures in a particular language, which is clearly not a recursive definition.

Also, it makes the concept of "provability," and thus of "theorem," a clear concept that only depends on the chosen system of axioms of the theory, and not on the choice of a proof system.

Gödel's second incompleteness theorem (see Gödel's incompleteness theorems), another celebrated result, shows that there are inherent limitations in what can be achieved with formal proofs in mathematics. The name for the incompleteness theorem refers to another meaning of "complete" (see model theory – Using the compactness and completeness theorems): A theory "T " is complete (or decidable) if for every formula "f" in the language of "T" either formula_16 or formula_17.

Gödel's second incompleteness theorem states that in any consistent effective theory "T" containing Peano arithmetic (PA), a formula "C" like "Cformula_18" expressing the consistency of "T" cannot be proven within "T".

The completeness theorem implies the existence of a model of "T" in which the formula "C" is false. Such a model (precisely, the set of "natural numbers" it contains) is necessarily a non-standard model, as it contains the code number of a proof of a contradiction of "T".
But "T" is consistent when viewed from the outside. Thus this code number of a proof of contradiction of "T" must be a non-standard number.

In fact, the model of "any" theory containing PA obtained by the systematic construction of the arithmetical model existence theorem, is "always" non-standard with a non-equivalent provability predicate and a non-equivalent way to interpret its own construction, so that this construction is non-recursive (as recursive definitions would be unambiguous).

Also, there is no recursive non-standard model of PA.

The completeness theorem and the compactness theorem are two cornerstones of first-order logic. While neither of these theorems can be proven in a completely effective manner, each one can be effectively obtained from the other.

The compactness theorem says that if a formula φ is a logical consequence of a (possibly infinite) set of formulas Γ then it is a logical consequence of a finite subset of Γ. This is an immediate consequence of the completeness theorem, because only a finite number of axioms from Γ can be mentioned in a formal deduction of φ, and the soundness of the deductive system then implies φ is a logical consequence of this finite set. This proof of the compactness theorem is originally due to Gödel.

Conversely, for many deductive systems, it is possible to prove the completeness theorem as an effective consequence of the compactness theorem.

The ineffectiveness of the completeness theorem can be measured along the lines of reverse mathematics. When considered over a countable language, the completeness and compactness theorems are equivalent to each other and equivalent to a weak form of choice known as weak König's lemma, with the equivalence provable in RCA (a second-order variant of Peano arithmetic restricted to induction over Σ formulas). Weak König's lemma is provable in ZF, the system of Zermelo–Fraenkel set theory without axiom of choice, and thus the completeness and compactness theorems for countable languages are provable in ZF. However the situation is different when the language is of arbitrary large cardinality since then, though the completeness and compactness theorems remain provably equivalent to each other in ZF, they are also provably equivalent to a weak form of the axiom of choice known as the ultrafilter lemma. In particular, no theory extending ZF can prove either the completeness or compactness theorems over arbitrary (possibly uncountable) languages without also proving the ultrafilter lemma on a set of same cardinality.

The completeness theorem is a central property of first-order logic that does not hold for all logics. Second-order logic, for example, does not have a completeness theorem for its standard semantics (but does have the completeness property for Henkin semantics), and the set of logically-valid formulas in second-order logic is not recursively enumerable. The same is true of all higher-order logics. It is possible to produce sound deductive systems for higher-order logics, but no such system can be complete.

Lindström's theorem states that first-order logic is the strongest (subject to certain constraints) logic satisfying both compactness and completeness.

A completeness theorem can be proved for modal logic or intuitionistic logic with respect to Kripke semantics.

Gödel's original proof of the theorem proceeded by reducing the problem to a special case for formulas in a certain syntactic form, and then handling this form with an "ad hoc" argument.

In modern logic texts, Gödel's completeness theorem is usually proved with Henkin's proof, rather than with Gödel's original proof. Henkin's proof directly constructs a term model for any consistent first-order theory. James Margetson (2004) developed a computerized formal proof using the Isabelle theorem prover. Other proofs are also known.




</doc>
<doc id="12451" url="https://en.wikipedia.org/wiki?curid=12451" title="Global Boundary Stratotype Section and Point">
Global Boundary Stratotype Section and Point

A Global Boundary Stratotype Section and Point, abbreviated GSSP, is an internationally agreed upon reference point on a stratigraphic section which defines the lower boundary of a stage on the geologic time scale. The effort to define GSSPs is conducted by the International Commission on Stratigraphy, a part of the International Union of Geological Sciences. Most, but not all, GSSPs are based on paleontological changes. Hence GSSPs are usually described in terms of transitions between different faunal stages, though far more faunal stages have been described than GSSPs. The GSSP definition effort commenced in 1977. As of 2012, 64 of the 101 stages that need a GSSP have been formally defined.

A geologic section has to fulfill a set of criteria to be adapted as a GSSP by the ICS. The following list summarizes the criteria:


The Precambrian-Cambrian boundary GSSP at Fortune Head, Newfoundland is a typical GSSP. It is accessible by paved road and is set aside as a nature preserve. A continuous section is available from beds that are clearly Precambrian into beds that are clearly Cambrian. The boundary is set at the first appearance of a complex trace fossil "Treptichnus pedum" that is found worldwide. The Fortune Head GSSP is unlikely to be washed away or built over. Nonetheless, "Treptichnus pedum" is less than ideal as a marker fossil as it is not found in every Cambrian sequence, and it is not assured that it is found at the same level in every exposure. In fact, further eroding its value as a boundary marker, it has since been identified in strata 4m "below" the GSSP!
However, no other fossil is known that would be preferable. There is no radiometrically datable bed at the boundary at Fortune Head, but there is one slightly above the boundary in similar beds nearby.
These factors have led some geologists to suggest that this GSSP is in need of reassigning.

Once a GSSP boundary has been agreed upon, a "golden spike" is driven into the geologic section to mark the precise boundary for future geologists (though in practice the "spike" need neither be golden nor an actual spike). The first stratigraphic boundary was defined in 1977 by identifying the Silurian-Devonian boundary with a bronze plaque at a locality called Klonk, northeast of the village of Suchomasty in the Czech Republic. GSSPs are also sometimes referred to as Golden Spikes.

Because defining a GSSP depends on finding well-preserved geologic sections and identifying key events, this task becomes more difficult as one goes farther back in time. Before 630 million years ago, boundaries on the geologic timescale are defined simply by reference to fixed dates, known as "Global Standard Stratigraphic Ages".





</doc>
