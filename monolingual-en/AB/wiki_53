<doc id="18084" url="https://en.wikipedia.org/wiki?curid=18084" title="Long jump">
Long jump

The long jump is a track and field event in which athletes combine speed, strength and agility in an attempt to leap as far as possible from a take off point. Along with the triple jump, the two events that measure jumping for distance as a group are referred to as the "horizontal jumps". This event has a history in the Ancient Olympic Games and has been a modern Olympic event for men since the first Olympics in 1896 and for women since 1948.

At the elite level, competitors run down a runway (usually coated with the same rubberized surface as running tracks, crumb rubber also vulcanized rubber—known generally as an all-weather track) and jump as far as they can from a wooden board 20 cm or 8 inches wide that is built flush with the runway into a pit filled with finely ground gravel or sand. If the competitor starts the leap with any part of the foot past the foul line, the jump is declared a foul and no distance is recorded. A layer of plasticine is placed immediately after the board to detect this occurrence. An official (similar to a referee) will also watch the jump and make the determination. The competitor can initiate the jump from any point behind the foul line; however, the distance measured will always be perpendicular to the foul line to the nearest break in the sand caused by any part of the body or uniform. Therefore, it is in the best interest of the competitor to get as close to the foul line as possible. Competitors are allowed to place two marks along the side of the runway in order to assist them to jump accurately. At a lesser meet and facilities, the plasticine will likely not exist, the runway might be a different surface or jumpers may initiate their jump from a painted or taped mark on the runway. At a smaller meet, the number of attempts might also be limited to four or three.

Each competitor has a set number of attempts. That would normally be three trials, with three additional jumps being awarded to the best 8 or 9 (depending on the number of lanes on the track at that facility, so the event is equatable to track events) competitors. All legal marks will be recorded but only the longest legal jump counts towards the results. The competitor with the longest legal jump (from either the trial or final rounds) at the end of competition is declared the winner. In the event of an exact tie, then comparing the next best jumps of the tied competitors will be used to determine place. In a large, multi-day elite competition (like the Olympics or World Championships), a set number of competitors will advance to the final round, determined in advance by the meet management. A set of 3 trial round jumps will be held in order to select those finalists. It is standard practice to allow at a minimum, one more competitor than the number of scoring positions to return to the final round, though 12 plus ties and automatic qualifying distances are also potential factors. (For specific rules and regulations in United States Track & Field see Rule 185).

For record purposes, the maximum accepted wind assistance is two metres per second (m/s) (4.5 mph).

The long jump is the only known jumping event of Ancient Greece's original Olympics' pentathlon events. All events that occurred at the Olympic Games were initially supposed to act as a form of training for warfare. The long jump emerged probably because it mirrored the crossing of obstacles such as streams and ravines. After investigating the surviving depictions of the ancient event it is believed that unlike the modern event, athletes were only allowed a short running start. The athletes carried a weight in each hand, which were called halteres (between 1 and 4.5 kg). These weights were swung forward as the athlete jumped in order to increase momentum. It was commonly believed that the jumper would throw the weights behind him in midair to increase his forward momentum; however, halteres were held throughout the duration of the jump. Swinging them down and back at the end of the jump would change the athlete's center of gravity and allow the athlete to stretch his legs outward, increasing his distance. The jump itself was made from the "bater" ("that which is trod upon"). It was most likely a simple board placed on the stadium track which was removed after the event. The jumpers would land in what was called a "skamma" ("dug-up" area). The idea that this was a pit full of sand is wrong. Sand in the jumping pit is a modern invention. The "skamma" was simply a temporary area dug up for that occasion and not something that remained over time.

The long jump was considered one of the most difficult of the events held at the Games since a great deal of skill was required. Music was often played during the jump and Philostratus says that pipes at times would accompany the jump so as to provide a rhythm for the complex movements of the halteres by the athlete. Philostratus is quoted as saying, "The rules regard jumping as the most difficult of the competitions, and they allow the jumper to be given advantages in rhythm by the use of the flute, and in weight by the use of the halter." Most notable in the ancient sport was a man called Chionis, who in the 656 BC Olympics staged a jump of 7.05 metres (23 feet and 1.7 inches).

There has been some argument by modern scholars over the long jump. Some have attempted to recreate it as a triple jump. The images provide the only evidence for the action so it is more well received that it was much like today's long jump. The main reason some want to call it a triple jump is the presence of a source that claims there once was a fifty-five ancient foot jump done by a man named Phayllos.

The long jump has been part of modern Olympic competition since the inception of the Games in 1896. In 1914, Dr. Harry Eaton Stewart recommended the "running broad jump" as a standardized track and field event for women. However, it was not until 1948 that the women's long jump was added to the Olympic athletics programme.

There are five main components of the long jump: the approach run, the last two strides, takeoff, action in the air, and landing. Speed in the run-up, or approach, and a high leap off the board are the fundamentals of success. Because speed is such an important factor of the approach, it is not surprising that many long jumpers also compete successfully in sprints. A classic example of this long jump / sprint doubling are performances by Carl Lewis.

The objective of the approach is to gradually accelerate to a maximum controlled speed at takeoff. The most important factor for the distance travelled by an object is its velocity at takeoff – both the speed and angle. Elite jumpers usually leave the ground at an angle of twenty degrees or less; therefore, it is more beneficial for a jumper to focus on the speed component of the jump. The greater the speed at takeoff, the longer the trajectory of the center of mass will be. The importance of a takeoff speed is a factor in the success of sprinters in this event.

The length of the approach is usually consistent distance for an athlete. Approaches can vary between 12 and 19 strides on the novice and intermediate levels, while at the elite level they are closer to between 20 and 22 strides. The exact distance and number of strides in an approach depends on the jumper's experience, sprinting technique, and conditioning level. Consistency in the approach is important as it is the competitor's objective to get as close to the front of the takeoff board as possible without crossing the line with any part of the foot.

Inconsistent approaches are a common problem in the event. As a result, the approach is usually practiced by athletes about 6–8 times per jumping session (see Training below).

The objective of the last two strides is to prepare the body for takeoff while conserving as much speed as possible.

The penultimate stride is longer than the last stride. The competitor begins to lower his or her center of gravity to prepare the body for the vertical impulse. The final stride is shorter because the body is beginning to raise the center of gravity in preparation for takeoff.

The last two strides are extremely important because they determine the velocity with which the competitor will enter the jump.

The objective of the takeoff is to create a vertical impulse through the athlete's center of gravity while maintaining balance and control.

This phase is one of the most technical parts of the long jump. Jumpers must be conscious to place the foot flat on the ground, because jumping off either the heels or the toes negatively affects the jump. Taking off from the board heel-first has a braking effect, which decreases velocity and strains the joints. Jumping off the toes decreases stability, putting the leg at risk of buckling or collapsing from underneath the jumper. While concentrating on foot placement, the athlete must also work to maintain proper body position, keeping the torso upright and moving the hips forward and up to achieve the maximum distance from board contact to foot release.

There are four main styles of takeoff: the kick style, double-arm style, sprint takeoff, and the power sprint or bounding takeoff.

The kick style takeoff is where the athlete actively cycles the leg before a full impulse has been directed into the board then landing into the pit. This requires great strength in the hamstrings. This causes the jumper to jump to large distances.

The double-arm style of takeoff works by moving both arms in a vertical direction as the competitor takes off. This produces a high hip height and a large vertical impulse.

The sprint takeoff is the style most widely instructed by coaching staff. This is a classic single-arm action that resembles a jumper in full stride. It is an efficient takeoff style for maintaining velocity through takeoff.

The power sprint takeoff, or bounding takeoff, is one of the more common elite styles. Very similar to the sprint style, the body resembles a sprinter in full stride. However, there is one major difference. The arm that pushes back on takeoff (the arm on the side of the takeoff leg) fully extends backward, rather than remaining at a bent position. This additional extension increases the impulse at takeoff.

The "correct" style of takeoff will vary from athlete to athlete.
There are three major flight techniques for the long jump: the hang, the sail, and the hitch-kick. Each technique is to combat the forward rotation experienced from take-off but is basically down to preference from the athlete. It is important to note that once the body is airborne, there is nothing that the athlete can do to change the direction they are traveling and consequently where they are going to land in the pit. However, it can be argued that certain techniques influence an athlete's landing, which can affect the distance measured. For example, if an athlete lands feet first but falls back because they are not correctly balanced, a lower distance will be measured.

In the 1970s some jumpers used a forward somersault, including Tuariki Delamere who used it at the 1974 NCAA Championships, and who matched the jump of the then Olympic champion Randy Williams. The somersault jump has potential to produce longer jumps than other techniques because in the flip, no power is lost countering forward momentum, and it reduces wind resistance in the air. The front flip jump was subsequently banned due to fear of it being unsafe.

The long jump generally requires training in a variety of areas. These areas include: speed work, jumping, over distance running, weight training, plyometric training.

Speed work is essentially short distance speed training where the athlete would be running at top or near top speeds. The distances for this type of work would vary between indoor and outdoor season but are usually around 30–60 m for indoors and up to 100 m for outdoors.

Long Jumpers tend to practice jumping 1–2 times a week. Approaches, or run-throughs, are repeated sometimes up to 6–8 times per session.
Short approach jumps are common for jumpers to do, as it allows for them to work on specific technical aspects of their jumps in a controlled environment. Using equipment such as low hurdles and other obstacles are common in long jump training, as it helps the jumper maintain and hold phases of their jump. As a common rule, it is important for the jumper to engage in full approach jumps at least once a week, as it will prepare the jumper for competition.

Over-distance running workouts helps the athlete jump a further distance than their set goal. For example, having a 100 m runner practice by running 200 m repeats on a track. This is specifically concentrated in the season when athletes are working on building endurance. Specific over-distance running workouts are performed 1–2 times a week. This is great for building sprint endurance, which is required in competitions where the athlete is sprinting down the runway 3–6 times. Typical workouts would include 5×150 m. Preseason workouts may be longer, including workouts like 6×300 m.

During pre-season training and early in the competition season weight training tends to play a major role in the sport. It is customary for a long jumper to weight train up to 4 times a week, focusing mainly on quick movements involving the legs and trunk. Some athletes perform Olympic lifts in training. Athletes use low repetition and emphasize speed to maximize the strength increase while minimizing adding additional weight to their frame. Important lifts for a long jumper include the back squat, front squat, power cleans and hang cleans. The emphasis on these lifts should be on speed and explosive as those are crucial in the long jump take off phase.

Plyometrics, including running up and down stairs and hurdle bounding, can be incorporated into workouts, generally twice a week. This allows an athlete to work on agility and explosiveness. Other plyometric workouts that are common for long jumpers are box jumps. Boxes of various heights are set up spaced evenly apart and jumpers can proceed jumping onto them and off moving in a forward direction. They can vary the jumps from both legs to single jumps. Alternatively, they can set up the boxes in front of a high jump mat if allowed, and jump over a high jump bar onto the mat mimicking a landing phase of the jump. These plyometric workouts are typically performed at the end of a workout.

Bounding is any sort of continuous jumping or leaping. Bounding drills usually require single leg bounding, double-leg bounding, or some variation of the two. The focus of bounding drills is usually to spend as little time on the ground as possible and working on technical accuracy, fluidity, and jumping endurance and strength. Technically, bounding is part of plyometrics, as a form of a running exercise such as high knees and butt kicks.

Flexibility is an often forgotten tool for long jumpers. Effective flexibility prevents injury, which can be important for high-impact events such as the long jump. It also helps the athlete sprint down the runway.
Hip and groin injuries are common for long jumpers who may neglect proper warm-up and stretching.

Hurdle mobility drills are a common way that jumpers improve flexibility. Common hurdle drills include setting up about 5–7 hurdles at appropriate heights and having athletes walk over them in a continuous fashion. Other variations of hurdle mobility drills are used as well, including hurdle skips.
This is a crucial part of a jumper's training since they perform most exercises for a very short period of time and often aren't aware of their form and technique.
A common tool in many long jump workouts is the use of video taping. This enables the athlete to go back and watch their own progress as well as letting the athlete compare their own footage to that of some of the world-class jumpers.

Training styles, duration, and intensity vary immensely from athlete to athlete and are based on the experience and strength of the athlete as well as on their coaching style.

Track and field events have been selected as a main motif in numerous collectors' coins. One of the recent samples is the €10 Greek Long Jump commemorative coin, minted in 2003 to commemorate the 2004 Summer Olympics. The obverse of the coin portrays a modern athlete at the moment he is touching the ground, while the ancient athlete in the background is shown while starting off his jump, as he is seen on a black-figure vase of the 5th century BC.

The men's long jump world record has been held by just four individuals for the majority of time since the IAAF started to ratify records. The first mark recognized by the IAAF in 1912, the 1901 performance by Peter O'Connor, stood just short of 20 years (nine years as an IAAF record). After it was broken in 1921, the record changed hands six times until Jesse Owens set the record at the 1935 Big Ten track meet in Ann Arbor, Michigan, of that was not broken for 25 years and 2 months, until 1960, by Ralph Boston. Boston improved upon it and exchanged records with Igor Ter-Ovanesyan seven times over the next seven years. At the 1968 Summer Olympics Bob Beamon jumped , a jump not exceeded for 23 years, and which remains the second longest legal jump of all time; yet it has stood as the Olympic record for years. On 30 August 1991, Mike Powell of the United States set the current men's world record at the World Championships in Tokyo. It was in a dramatic showdown against Carl Lewis who also surpassed Beamon's record that day but his jump was wind-assisted (and thus not legal for record purposes). Powell's record has now stood for over years.

Some jumps over have been officially recorded. was recorded by Powell (wind-assisted +4.4) set at high altitude in Sestriere, Italy, in 1992. A potential world record of was recorded by Iván Pedroso, with a "legal" wind reading also in Sestriere, but the jump was not validated because videotape revealed someone was standing in front of the wind gauge, invalidating the reading (and costing Pedroso a Ferrari valued at $130,000—the prize for breaking the record at that meet). As mentioned above, Lewis jumped moments before Powell's record-breaking jump with the wind exceeding the maximum allowed. This jump remains the longest ever not to win an Olympic or World Championship gold medal, or any competition in general.

The women's world record has seen more consistent improvement, though the current record has stood longer than any long jump record by men or women. The longest to hold the record prior was by Fanny Blankers-Koen during World War II. who held it for 10 years. There have been three occasions where the record was tied or improved upon twice in the same competition. The current world record for women is held by Galina Chistyakova of the former Soviet Union who leapt in Leningrad on 11 June 1988, a mark that has stood for over years.


There are many more exceptionally long jumps in the history of long jumping that are not listed in the record books because of excessive wind from behind the jumper. The limit for the wind speed to allow a jump to enter the record books is 2 m/s. The following contains a list of other notable jumps in which the wind speed exceeded this limit.









</doc>
<doc id="18085" url="https://en.wikipedia.org/wiki?curid=18085" title="Luke (name)">
Luke (name)

Luke is a male given name, and less commonly, a surname.

The name Luke is the English form of the Latin name . It is derived from the Latin name "Lucius", and it either means "the great Lucius", or it is a shortened form of the Latin name. "Lucius" means "the bright one" or "the one born at dawn". 

Although the name is attested in ancient inscriptions, the best known historical use of the name is in the New Testament. The Gospel of Luke was written around 70 to 90 AD (the exact years are unknown), and was from here that the name was first popularized. Luke, who is credited with the authorship of the Gospel of Luke, was a physician who lived around 30 to 130 AD. Luke is also credited with the Book of Acts in the Bible, and also is mentioned by the Apostle Paul in some of Paul's letters to first-century churches.

The name is sometimes used as a nickname for Luther.

Luke is the 21st most popular name for new babies in England and Wales, the 43rd most popular name for new babies in the United States, and the 2,105th most common surname in the US, with 15,000 people (0.006%) sharing the surname.





</doc>
<doc id="18087" url="https://en.wikipedia.org/wiki?curid=18087" title="Lonsdaleite">
Lonsdaleite

Lonsdaleite (named in honour of Kathleen Lonsdale), also called hexagonal diamond in reference to the crystal structure, is an allotrope of carbon with a hexagonal lattice. In nature, it forms when meteorites containing graphite strike the Earth. The great heat and stress of the impact transforms the graphite into diamond, but retains graphite's hexagonal crystal lattice. Lonsdaleite was first identified in 1967 from the Canyon Diablo meteorite, where it occurs as microscopic crystals associated with diamond.

Hexagonal diamond has also been synthesized in the laboratory (1966 or earlier; published in 1967) by compressing and heating graphite either in a static press or using explosives. It has also been produced by chemical vapor deposition, and also by the thermal decomposition of a polymer, poly(hydridocarbyne), at atmospheric pressure, under argon atmosphere, at .

It is translucent, brownish-yellow, and has an index of refraction of 2.40 to 2.41 and a specific gravity of 3.2 to 3.3. Its hardness is theoretically superior to that of cubic diamond (up to 58% more), according to computational simulations, but natural specimens exhibited somewhat lower hardness through a large range of values (from 7 to 8 on Mohs hardness scale). The cause is speculated as being due to the samples having been riddled with lattice defects and impurities.

The property of lonsdaleite as a discrete material has been questioned, since specimens under crystallographic inspection showed not a bulk hexagonal lattice, but instead cubic diamond dominated by structural defects that include hexagonal sequences. A quantitative analysis of the X-ray diffraction data of lonsdaleite has shown that about equal amounts of hexagonal and cubic stacking sequences are present. Consequently, it has been suggested that "stacking disordered diamond" is the most accurate structural description of lonsdaleite. On the other hand, recent shock experiments with in situ X-ray diffraction show strong evidence for creation of relatively pure lonsdaleite in dynamic high-pressure environments such as meteorite impacts.

According to the traditional picture, Lonsdaleite has a hexagonal unit cell, related to the diamond unit cell in the same way that the hexagonal and cubic close packed crystal systems are related. The diamond structure can be considered to be made up of interlocking rings of six carbon atoms, in the chair conformation. In lonsdaleite, some rings are in the boat conformation instead. At the nanoscale dimensions cubic diamond is represented by diamondoids while hexagonal diamond is represented by wurtzoids. In diamond, all the carbon-to-carbon bonds, both within a layer of rings and between them, are in the staggered conformation, thus causing all four cubic-diagonal directions to be equivalent; while in lonsdaleite the bonds between layers are in the eclipsed conformation, which defines the axis of hexagonal symmetry.

Lonsdaleite is simulated to be 58% harder than diamond on the <100> face and to resist indentation pressures of 152 GPa, whereas diamond would break at 97 GPa. This is yet exceeded by IIa diamond's <111> tip hardness of 162 GPa.

Lonsdaleite occurs as microscopic crystals associated with diamond in several meteorites: Canyon Diablo, Kenna, and Allan Hills 77283. It is also naturally occurring in non-bolide diamond placer deposits in the Sakha Republic. Material with d-spacings consistent with Lonsdaleite has been found in sediments with highly uncertain dates at Lake Cuitzeo, in the state of Guanajuato, Mexico, by proponents of the controversial Younger Dryas impact hypothesis. Its presence in local peat deposits is claimed as evidence for the Tunguska event being caused by a meteor rather than by a cometary fragment.




</doc>
<doc id="18088" url="https://en.wikipedia.org/wiki?curid=18088" title="Labrador duck">
Labrador duck

The Labrador duck ("Camptorhynchus labradorius") was a North American bird; it has the distinction of being the first endemic North American bird species to become extinct after the Columbian Exchange, with the last known sighting occurring in 1878 in Elmira, New York. It was already a rare duck before European settlers arrived, and as a result of its rarity information on the Labrador duck is not abundant, although some, such as its habitat, characteristics, dietary habits and reasons behind its extinction, are known. There are 55 specimens of the Labrador duck preserved in museum collections worldwide.

The Labrador duck is considered a sea duck. A basic difference in the shape of the process of metacarpal I divides the sea ducks into two groups:
The position of the nutrient foramen of the tarsometatarsus also separates the two groups of sea ducks. In the first group, the foramen is lateral to the long axis of the lateral groove of the hypotarsus; in the second, the foramen is on or medial to the axis of that groove.

The Labrador duck was also known as the pied duck and skunk duck, the former being a vernacular name that it shared with the surf scoter and the common goldeneye (and even the American oystercatcher), a fact that has led to difficulties in interpreting old records of these species. Both names refer to the male's striking white/black piebald colouration. Yet another common name was sand shoal duck, referring to its habit of feeding in shallow water. The closest evolutionary relatives of the Labrador duck are apparently the scoters ("Melanitta").

A mitogenomic study of the placement of the Labrador duck found the species to be closely related to the Steller's eider as shown below.

The female plumage was grey. Although weakly patterned, the pattern was scoter-like. The male's plumage was black and white in an eider-like pattern, but the wings were entirely white except for the primaries. The trachea of the male was scoter-like. An expansion of the tracheal tube occurred at the anterior end, and two enlargements (as opposed to one enlargement as seen in scoters) were near the middle of the tube. The bulla was bony and round, puffing out from the left side. This asymmetrical and osseus bulla was unlike that of scoters; this bulla was similar to eiders and harlequin duck's bullae. The Labrador duck has been considered the most enigmatic of all North American birds.

The Labrador duck had an oblong head with small, beady eyes. Its bill was almost as long as its head. The body was short and depressed with short, strong feet that were far behind the body. The feathers were small and the tail was short and rounded. The Labrador duck belongs to a monotypic genus.

The Labrador duck migrated annually, wintering off the coasts of New Jersey and New England in the eastern United States, where it favoured southern sandy coasts, sheltered bays, harbors, and inlets, and breeding in Labrador and northern Quebec in the summer. John James Audubon's son reported seeing a nest belonging to the species in Labrador. Some believe that it may have laid its eggs on the islands in the Gulf of Saint Lawrence.The breeding biology of the Labrador duck is largely unknown.

The Labrador duck fed on small molluscs, and some fishermen reported catching it on fishing lines baited with mussels. The structure of the bill was highly modified from that of most ducks, having a wide, flattened tip with numerous lamellae inside. In this way, it is considered an ecological counterpart of the North Pacific/North Asian Steller's eider. The beak was also particularly soft and may have been used to probe through sediment for food.

Another, completely unrelated, duck with similar (but even more specialized) bill morphology is the Australian pink-eared duck, which feeds largely on plankton, but also mollusks; the condition in the Labrador duck probably resembled that in the blue duck most in outward appearance.
Its peculiar bill suggests it ate shellfish and crustaceans from silt and shallow water. The Labrador duck may have survived by eating snails.

The Labrador duck is thought to have been always rare, but between 1850 and 1870, populations waned further. Its extinction (sometime after 1878) is still not fully explained. Although hunted for food, this duck was considered to taste bad, rotted quickly, and fetched a low price. Consequently, it was not sought much by hunters. However, the eggs may have been overharvested, and it may have been subject to depredations by the feather trade in its breeding area, as well. Another possible factor in the bird's extinction was the decline in mussels and other shellfish on which they are believed to have fed in their winter quarters, due to growth of population and industry on the Eastern Seaboard. Although all sea ducks readily feed on shallow-water molluscs, no Western Atlantic bird species seems to have been as dependent on such food as the Labrador duck.

Another theory that was said to lead to their extinction was a huge increase of human influence on the coastal ecosystems in North America, causing the birds to flee their niches and find another habitat. These ducks were the only birds whose range was limited to the American coast of the North Atlantic, so changing niches was a difficult task. The Labrador duck became extinct in the late 19th century.





</doc>
<doc id="18089" url="https://en.wikipedia.org/wiki?curid=18089" title="Lettres de cachet">
Lettres de cachet

Lettres de cachet (; ) were letters signed by the king of France, countersigned by one of his ministers, and closed with the royal seal. They contained orders directly from the king, often to enforce arbitrary actions and judgments that could not be appealed.

In the case of organized bodies, 'lettres de cachet’ were issued for the purpose of preventing assembly or accomplishing some other definite act. The provincial estates were convoked (called to assembly) in this manner, and it was by a "lettre de cachet" (in this case, a "lettre de jussipri"), or by showing in person in a "lit de justice", that the king ordered a "parlement" to register a law despite that "parlement"s refusal to pass it.

The best-known "lettres de cachet", however, were penal, by which a subject was imprisoned without trial and without an opportunity of defense (after inquiry and due diligence by the "lieutenant de police") in a state prison or an ordinary jail, confinement in a convent or the General Hospital of Paris, transportation to the colonies, or expulsion to another part of the realm, or from the realm altogether. The "lettres" were mainly used against drunkards, troublemakers, prostitutes, squanderers of family fortune, or insane persons. The wealthy sometimes petitioned such "lettres" to dispose of inconvenient individuals, especially to prevent unequal marriages (nobles with commoners), or to prevent a scandal (the Lettre could prevent court cases that might otherwise dishonour a family).

In this respect, the "lettres de cachet" were a prominent symbol of the abuses of the "ancien régime" monarchy, and as such were suppressed during the French Revolution. In 1789 and 1790, all cases were revised by a commission which confirmed most of the sentences. Historian Claude Quétel has interpreted these confirmations as indicating that the Lettres were not as arbitrary and unjust as they have been represented after the Revolution, and he hence speaks of a "Légende noire".

The power to issue "lettres de cachet" was a royal privilege recognized by the French monarchic civil law that developed during the 13th century, as the Capetian monarchy overcame its initial distrust of Roman law. The principle can be traced to a maxim which furnished a text of the "Pandects" of Justinian: in their Latin version, ""Rex solutus est a legibus"", or "The king is released from the laws." "The French legal scholars interpreted the imperial office of the Justinian code in a generic way and arrived at the conclusion that every 'king is an emperor in his own kingdom,' that is, he possesses the prerogatives of legal absolutism that the "Corpus Juris Civilis" attributes to the Roman emperor."

This meant that when the king intervened directly, he could decide without heeding the laws, and even contrary to the laws. This was an early conception, and in early times the order in question was simply verbal; some letters patent of Henry III of France in 1576 state that François de Montmorency was "prisoner in our castle of the Bastille in Paris by verbal command" of the late king Charles IX.

In the 14th century the principle was introduced that the order should be written, and hence arose the "lettre de cachet". The "lettre de cachet" belonged to the class of "lettres closes", as opposed to "lettres patentes", which contained the expression of the legal and permanent will of the king, and had to be furnished with the seal of state affixed by the chancellor.

The "lettres de cachet", on the contrary, were signed simply by a secretary of state for the king; they bore merely the imprint of the king's privy seal, from which circumstance they were often called, in the 14th and 15th centuries, "lettres de petit signet" or "lettres de petit cachet", and were entirely exempt from the control of the chancellor.

While serving the government as a silent weapon against political adversaries or controversial writers and as a means of punishing culprits of high birth without the scandal of a lawsuit, the "lettres de cachet" had many other uses. They were employed by the police in dealing with prostitutes, and on their authority lunatics were shut up in hospitals and sometimes in prisons.

They were also often used by heads of families as a means of correction, for example, for protecting the family honour from the disorderly or criminal conduct of sons. The case of the Marquis de Sade (imprisoned 1777–1790 under a "lettre de cachet" obtained by his wealthy and influential mother-in-law) is a prominent example. Wives, too, took advantage of them to curb the profligacy of husbands and vice versa.

In reality, the secretary of state had a delegation and could issue them at his own discretion, and in most cases the king was unaware of their issue. In the 18th century it is certain that the letters were often issued blank, i.e. without containing the name of the person against whom they were directed; the recipient, or mandatary, filled in the name in order to make the letter effective.

Protests against the "lettres de cachet" were made continually by the "parlement" of Paris and by the provincial "parlements", and also by the Estates-General. In 1648, during the Fronde, the sovereign courts of Paris, by their "Arrêt d'Union", procured their momentary suppression in a kind of charter of liberties which they imposed upon the crown, but which was short-lived.

It was not until the reign of Louis XVI that a reaction against the abuse became clearly perceptible. At the beginning of that reign Malesherbes during his short ministry endeavoured to infuse some measure of justice into the system, and in March 1784 the baron de Breteuil, a minister of the king's household, addressed a circular to the intendants and the lieutenant of police with a view to preventing the most serious abuses connected with the issue of "lettres de cachet".

The Comte de Mirabeau wrote a scathing indictment of "lettres de cachet" while imprisoned in the dungeon of Vincennes (by "lettre de cachet" obtained by his father). The treatise was published after his liberation in 1782 under the title "Les Lettres de cachet et des prisons d'etat" and was widely read throughout Europe.

Besides the Bastille, there were thirty prisons in Paris by 1779 in which a person could be detained without trial. Convents were used for the same purpose.

They were reported to have been openly sold, in the reign of Louis XV, by the mistress of one of his ministers.

In Paris, in 1779, the Cour des Aides demanded their suppression, and in March 1788 the Parlement of Paris made some exceedingly energetic remonstrances, which are important for the light they throw upon old French public law. The crown, however, did not decide to lay aside this weapon, and in a declaration to the States-General in the royal session of June 23, 1789 (art. 15) it did not renounce it absolutely.

"Lettres de cachet" were abolished after the French Revolution by the Constituent Assembly, but Napoleon reestablished their penal equivalent by a political measure in the decree of 8 March 1801 on the state prisons. This is all the more striking, given that Napoleon had pushed for measures ensuring the rule of law in the codes of laws adopted under his rule. This action was one of the acts brought up against him by the senatus-consulte of 3 April 1814, which pronounced his fall "considering that he has violated the constitutional laws by the decrees on the state prisons."





</doc>
<doc id="18090" url="https://en.wikipedia.org/wiki?curid=18090" title="Lilia Podkopayeva">
Lilia Podkopayeva

Lilia Oleksandrivna Podkopayeva (; born August 15, 1978) is a Ukrainian former artistic gymnast. She is the 1995 world all-around champion, and the 1996 Olympic all-around and floor exercise champion. Often thought of as a complete athlete, Podkopayeva was known for combining power, style, and balletic grace.

In April 1993, Podkopayeva competed at the World Artistic Gymnastics Championships in Birmingham, England. She qualified for the vault final, but crashed on her first attempt and finished last with a score of 8.893.

At the 1994 World Championships in Brisbane, Australia, she placed sixth in the all-around with a score of 38.942. In event finals, she placed eighth on vault, scoring 9.424; fifth on uneven bars, scoring 9.350; and second on balance beam, scoring 9.737. In November 1994, at the World Team Championships in Dortmund, Germany, she contributed an all-around score of 38.099 toward the Ukrainian team's fifth-place finish.

The following year, Podkopayeva competed at the 1995 World Championships in Sabae, Japan. She helped Ukraine place fifth and qualify a full team to the 1996 Olympics. Podkopayeva then won the all-around final with a score of 39.248. In event finals, she placed first on vault (9.781), second on uneven bars (9.837), second on balance beam (9.837), and seventh on floor (9.087).

At the beginning of the year, Podkopayeva was seriously injured when she fell from the beam in practice, fracturing two ribs. However, in May, she competed at the European Championships in Birmingham, where she helped the Ukrainian team place third and won the individual all-around with a score of 39.205. In event finals, she placed third on balance beam (9.756), first on uneven bars (9.825), and first on floor (9.862).

In July, Podkopayeva competed at the 1996 Summer Olympics in Atlanta, Georgia. In the team final, she contributed a combined compulsory and optional score of 78.061 toward the Ukrainian team's fifth-place finish. She then won the all-around final with a score of 39.255. In event finals, she placed fifth on uneven bars (9.787), second on balance beam (9.825), and first on floor (9.887). She was the fourth gymnast to win the Olympic all-around title as the reigning world champion, and the only gymnast to win the all-around without winning a team medal. She was also the last female gymnast to win the all-around title and an event-final gold medal until Simone Biles in 2016.

Podkopayeva originally intended to continue competing after the 1996 Olympics, and she was named to the Ukrainian team for the 1997 World Championships. However, injuries forced her to sit out the competition and, later, to retire.

Vault: Round-off, back-handspring with 1/2 turn on – piked salto forward with 1/2 turn off (5.2 difficulty)

Floor: double front salto with 1/2 twist out (F)

In 2002, Podkopayeva started the Golden Lilia International Sports Festival, an exhibition featuring artistic and rhythmic gymnasts, acrobats, and dancers. She said, "It's important to us to show outstanding people and brightest talent so that the next generation can follow the best of the best."

In December 2004, she married a Ukrainian businessman Tymofiy Nahornyi. They have two children: Vadym, adopted in Ukraine in July 2006, and Karolina, born in November 2006. The couple divorced in 2009.

In 2005, Podkopayeva became a United Nations goodwill ambassador on HIV/AIDS in Ukraine. She is also an Ambassador of the Council of Europe for Sport, Tolerance, and Fair Play.

In 2007, she won Ukraine's "Dancing With the Stars" with partner Sergiy Kostetskyi. The next year, she represented Ukraine in the Eurovision Dance Contest. Along with partner Kyrylo Khytrov, she placed third in the competition.

In 2014, Podkopayeva did a gala event in Mexico, using similar choreography to the floor routine she performed in Atlanta, as well as doing back handsprings and round-offs.



</doc>
<doc id="18091" url="https://en.wikipedia.org/wiki?curid=18091" title="Lisbon">
Lisbon

Lisbon (; Portuguese: Lisboa; ) is the capital and the largest city of Portugal, with an estimated population of 505,526 within its administrative limits in an area of 100.05 km. Lisbon's urban area extends beyond the city's administrative limits with a population of around 2.8 million people, being the 10th-most populous urban area in the European Union. About 3 million people live in the Lisbon metropolitan area, which represents approximately 27% of the country's population. It is mainland Europe's westernmost capital city and the only one along the Atlantic coast. Lisbon lies in the western Iberian Peninsula on the Atlantic Ocean and the River Tagus. The westernmost portions of its metro area, the Portuguese Riviera, form the westernmost point of Continental Europe, culminating at Cabo da Roca.

Lisbon is recognised as an alpha-level global city because of its importance in finance, commerce, media, entertainment, arts, international trade, education and tourism. Lisbon is one of two Portuguese cities (alongside Porto) to be recognised as a global city. It is one of the major economic centres on the continent, with a growing financial sector and one of the largest container ports on Europe's Atlantic coast. Additionally, Humberto Delgado Airport served 29 million passengers in 2018, being the busiest airport in Portugal, the 3rd busiest in the Iberian Peninsula and the 20th busiest in Europe. The motorway network and the high-speed rail system of Alfa Pendular links the main cities of Portugal to Lisbon. The city is the 9th-most-visited city in Southern Europe, after Rome, Istanbul, Barcelona, Milan, Venice, Madrid, Florence and Athens, with 3,320,300 tourists in 2017. The Lisbon region has a higher GDP PPP per capita than any other region in Portugal. Its GDP amounts to US$96.3 billion and thus $32,434 per capita. The city occupies the 40th place of highest gross earnings in the world. Most of the headquarters of multinational corporations in Portugal are located in the Lisbon area. It is also the political centre of the country, as its seat of government and residence of the head of state.

Lisbon is one of the oldest cities in the world, and the second-oldest European capital city (after Athens), predating other modern European capitals by centuries. Julius Caesar made it a municipium called "Felicitas Julia", adding to the name "Olissipo". Ruled by a series of Germanic tribes from the 5th century, it was captured by the Moors in the 8th century. In 1147, the Crusaders under Afonso Henriques reconquered the city and since then it has been the political, economic and cultural center of Portugal.

Lisbon's name may have been derived from Proto-Celtic or Celtic "Olisippo", "Lissoppo", or a similar name which other visiting peoples like the ancient Phoenicians, Greeks and Romans adapted accordingly, such as the pre-Roman appellation for the Tagus River, "Lisso" or "Lucio". Classical authors writing in Latin and Greek, including Strabo, Solinus, and Martianus Capella, referred to popular legends that the city of Lisbon was founded by the mythical hero Ulysses (Odysseus). Lisbon's name was written "Ulyssippo" in Latin by the geographer Pomponius Mela, a native of Hispania. It was later referred to as "Olisippo" by Pliny the Elder and by the Greeks as "Olissipo" (Ὀλισσιπών) or "Olissipona" (Ὀλισσιπόνα).

Another claim repeated in non-academic literature is that the name of Lisbon could be traced back to Phoenician times, referring to a supposedly Phoenician term "Alis-Ubo", meaning "safe harbour". Although modern archaeological excavations show a Phoenician presence at this location since 1200BC, this folk etymology has no historical credibility.

Lisbon's name is commonly abbreviated as "LX" or "Lx", originating in an antiquated spelling of Lisbon as ‘‘Lixbõa’’. While the old spelling has since been completely dropped from usage and goes against modern language standards, the abbreviation is still commonly used.

During the Neolithic period, the region was inhabited by Pre-Celtic tribes, who built religious and funerary monuments, megaliths, dolmens and menhirs, which still survive in areas on the periphery of Lisbon. The Indo-European Celts invaded in the 1st millennium BC, mixing with the Pre-Indo-European population, thus giving rise to Celtic-speaking local tribes such as the Cempsi.

Although the first fortifications on Lisbon's Castelo hill are known to be no older than the 2nd century BC, recent archaeological finds have shown that Iron Age people occupied the site from the 8th to 6th centuries BC. This indigenous settlement maintained commercial relations with the Phoenicians, which would account for the recent findings of Phoenician pottery and other material objects. Archaeological excavations made near the Castle of São Jorge ("Castelo de São Jorge") and Lisbon Cathedral indicate a Phoenician presence at this location since 1200 BC, and it can be stated with confidence that a Phoenician trading post stood on a site now the centre of the present city, on the southern slope of Castle hill. The sheltered harbour in the Tagus River estuary was an ideal spot for an Iberian settlement and would have provided a secure harbour for unloading and provisioning Phoenician ships. The Tagus settlement was an important centre of commercial trade with the inland tribes, providing an outlet for the valuable metals, salt and salted-fish they collected, and for the sale of the Lusitanian horses renowned in antiquity.

According to a persistent legend, the location was named for the mythical Ulysses, who founded the city when he sailed westward to the ends of the known world.

Following the defeat of Hannibal in 202 BC during the Punic wars, the Romans determined to deprive Carthage of its most valuable possession: Hispania (the Iberian Peninsula). The defeat of Carthaginian forces by Scipio Africanus in Eastern Hispania allowed the pacification of the west, led by Consul Decimus Junius Brutus Callaicus. Decimus obtained the alliance of Olissipo (which sent men to fight alongside the Roman Legions against the northwestern Celtic tribes) by integrating it into the empire, as the "Municipium Cives Romanorum Felicitas Julia". Local authorities were granted self-rule over a territory that extended ; exempt from taxes, its citizens were given the privileges of Roman citizenship, and it was then integrated with the Roman province of Lusitania (whose capital was Emerita Augusta).

Lusitanian raids and rebellions during Roman occupation required the construction of a wall around the settlement. During Augustus' reign, the Romans also built a great theatre; the Cassian Baths (underneath "Rua da Prata"); temples to Jupiter, Diana, Cybele, Tethys and Idea Phrygiae (an uncommon cult from Asia Minor), in addition to temples to the Emperor; a large necropolis under "Praça da Figueira"; a large forum and other buildings such as insulae (multi-storied apartment buildings) in the area between Castle Hill and the historic city core. Many of these ruins were first unearthed during the mid-18th century (when the recent discovery of Pompeii made Roman archaeology fashionable among Europe's upper classes).

The city prospered as piracy was eliminated and technological advances were introduced, consequently "Felicitas Julia" became a center of trade with the Roman provinces of Britannia (particularly Cornwall) and the Rhine. Economically strong, Olissipo was known for its garum (a fish sauce highly prized by the elites of the empire and exported in amphorae to Rome), wine, salt, and horse-breeding, while Roman culture permeated the hinterland. The city was connected by a broad road to Western Hispania's two other large cities, Bracara Augusta in the province of Tarraconensis (Portuguese Braga), and Emerita Augusta, the capital of Lusitania. The city was ruled by an oligarchical council dominated by two families, the Julii and the Cassiae, although regional authority was administered by the Roman Governor of Emerita or directly by Emperor Tiberius. Among the majority of Latin speakers lived a large minority of Greek traders and slaves.

Olissipo, like most great cities in the Western Empire, was a center for the dissemination of Christianity. Its first attested Bishop was Potamius (c. 356), and there were several martyrs during the period of persecution of the Christians: Verissimus, Maxima, and Julia are the most significant examples. By the time of the Fall of Rome, Olissipo had become a notable Christian center.

Following the disintegration of the Western Roman Empire there were barbarian invasions; between 409 and 429 the city was occupied successively by Sarmatians, Alans and Vandals. The Germanic Suebi, who established a kingdom in Gallaecia (modern Galicia and northern Portugal), with its capital in "Bracara Augusta", also controlled the region of Lisbon until 585. In 585, the Suebi Kingdom was integrated into the Germanic Visigothic Kingdom of Toledo, which comprised all of the Iberian Peninsula: Lisbon was then called "Ulishbona".

On 6 August 711, Lisbon was taken by Muslim forces. These conquerors, who were mostly Berbers and Arabs from North Africa and the Middle East, built many mosques and houses, rebuilt the city wall (known as the "Cerca Moura") and established administrative control, while permitting the diverse population (Muladi, Mozarabs, Berbers, Arabs, Jews, "Zanj" and "Saqaliba") to maintain their socio-cultural lifestyles. Mozarabic was the native language spoken by most of the Christian population although Arabic was widely known as spoken by all religious communities. Islam was the official religion practised by the Arabs, Berbers, Zanj, Saqaliba and Muladi (muwalladun).

The Muslim influence is still visible in the Alfama district, an old quarter of Lisbon that survived the 1755 Lisbon earthquake: many place-names are derived from Arabic and the Alfama (the oldest existing district of Lisbon) was derived from the Arabic ""al-hamma".

For a brief time Lisbon was an independent Muslim kingdom known as the Taifa of Lisbon (1022–1094), before being conquered by the larger Taifa of Badajoz.

In 1108 Lisbon was raided and occupied by Norwegian crusaders led by Sigurd I on their way to the Holy Land as part of the Norwegian Crusade and occupied by crusader forces for three years. It was taken by the Moorish Almoravids in 1111.

In 1147, as part of the "Reconquista", crusader knights led by Afonso I of Portugal besieged and reconquered Lisbon. The city, with around 154,000 residents at the time, was returned to Christian rule. The reconquest of Portugal and re-establishment of Christianity is one of the most significant events in Lisbon's history, described in the chronicle "Expugnatione Lyxbonensi", which describes, among other incidents, how the local bishop was killed by the crusaders and the city's residents prayed to the Virgin Mary as it happened. Some of the Muslim residents converted to Roman Catholicism and most of those who did not convert fled to other parts of the Islamic world, primarily Muslim Spain and North Africa. All mosques were either completely destroyed or converted into churches. As a result of the end of Muslim rule, spoken Arabic quickly lost its place in the everyday life of the city and disappeared altogether.

With its central location, Lisbon became the capital city of the new Portuguese territory in 1255.
The first Portuguese university was founded in Lisbon in 1290 by King Denis I; for many years the "Studium Generale" ("General Study") was transferred intermittently to Coimbra, where it was installed permanently in the 16th century as the University of Coimbra.

In 1384, the city was besieged by King Juan I of Castille, as a part of the ongoing 1383–1385 Crisis. The result of the siege was a victory for the Portuguese led by Nuno Álvares Pereira.

During the last centuries of the Middle Ages, the city expanded substantially and became an important trading post with both Northern European and Mediterranean cities.

Most of the Portuguese expeditions of the Age of Discovery left Lisbon during the period from the end of the 15th century to the beginning of the 17th century, including Vasco da Gama's expedition to India in 1498. In 1506, 3,000 Jews were massacred in Lisbon. The 16th century was Lisbon's golden era: the city was the European hub of commerce between Africa, India, the Far East and later, Brazil, and acquired great riches by exploiting the trade in spices, slaves, sugar, textiles and other goods. This period saw the rise of the exuberant Manueline style in architecture, which left its mark in many 16th-century monuments (including Lisbon's Belém Tower and Jerónimos Monastery, which were declared UNESCO World Heritage Sites). A description of Lisbon in the 16th century was written by Damião de Góis and published in 1554.
The succession crisis of 1580, initiated a sixty-year period of dual monarchy in Portugal and Spain under the Spanish Habsburgs. This is referred to as the "Philippine Dominion" ("Domínio Filipino"), since all three Spanish kings during that period were called Philip ("Filipe"). In 1589 Lisbon was the target of an incursion by the English Armada led by Francis Drake, while Queen Elizabeth supported a Portuguese pretender in Antonio, Prior of Crato, but support for Crato was lacking and the expedition was a failure. The Portuguese Restoration War, which began with a coup d'état organised by the nobility and bourgeoisie in Lisbon and executed on 1 December 1640, restored Portuguese independence. The period from 1640 to 1668 was marked by periodic skirmishes between Portugal and Spain, as well as short episodes of more serious warfare until the Treaty of Lisbon was signed in 1668.

In the early 18th century, gold from Brazil allowed King John V to sponsor the building of several Baroque churches and theatres in the city. Prior to the 18th century, Lisbon had experienced several significant earthquakes – eight in the 14th century, five in the 16th century (including the 1531 earthquake that destroyed 1,500 houses and the 1597 earthquake in which three streets vanished), and three in the 17th century.

On 1 November 1755, the city was destroyed by another devastating earthquake, which killed an estimated 30,000 to 40,000 Lisbon residents of a population estimated at between 200,000 and 275,000, and destroyed 85 percent of the city's structures. Among several important buildings of the city, the Ribeira Palace and the Hospital Real de Todos os Santos were lost. In coastal areas, such as Peniche, situated about north of Lisbon, many people were killed by the following tsunami.

By 1755, Lisbon was one of the largest cities in Europe; the catastrophic event shocked the whole of Europe and left a deep impression on its collective psyche. Voltaire wrote a long poem, "Poême sur le désastre de Lisbonne", shortly after the quake, and mentioned it in his 1759 novel "Candide" (indeed, many argue that this critique of optimism was inspired by that earthquake). Oliver Wendell Holmes, Sr. also mentions it in his 1857 poem, "The Deacon's Masterpiece, or The Wonderful One-Hoss Shay."

After the 1755 earthquake, the city was rebuilt largely according to the plans of Prime Minister Sebastião José de Carvalho e Melo, the 1st Marquis of Pombal; the lower town began to be known as the "Baixa Pombalina" (Pombaline central district). Instead of rebuilding the medieval town, Pombal decided to demolish what remained after the earthquake and rebuild the city centre in accordance with principles of modern urban design. It was reconstructed in an open rectangular plan with two great squares: the "Praça do Rossio" and the "Praça do Comércio". The first, the central commercial district, is the traditional gathering place of the city and the location of the older cafés, theatres and restaurants; the second became the city's main access to the River Tagus and point of departure and arrival for seagoing vessels, adorned by a triumphal arch (1873) and monument to King Joseph I.

In the first years of the 19th century, Portugal was invaded by the troops of Napoléon Bonaparte, forcing Queen Maria I and Prince-Regent John (future John VI) to flee temporarily to Brazil. By the time the new King returned to Lisbon, many of the buildings and properties were pillaged, sacked or destroyed by the invaders.

During the 19th century, the Liberal movement introduced new changes into the urban landscape. The principal areas were in the "Baixa" and along the "Chiado" district, where shops, tobacconists shops, cafés, bookstores, clubs and theatres proliferated. The development of industry and commerce determined the growth of the city, seeing the transformation of the Passeio Público, a Pombaline era park, into the Avenida da Liberdade, as the city grew farther from the Tagus.

Lisbon was the site of the regicide of Carlos I of Portugal in 1908, an event which culminated two years later in the establishment of the First Republic.
The city refounded its university in 1911 after centuries of inactivity in Lisbon, incorporating reformed former colleges and other non-university higher education schools of the city (such as the "Escola Politécnica" – now "Faculdade de Ciências"). Today there are two public universities in the city (University of Lisbon and New University of Lisbon), a public university institute (ISCTE - Lisbon University Institute) and a polytechnic institute (IPL – Instituto Politécnico de Lisboa).

During World War II, Lisbon was one of the very few neutral, open European Atlantic ports, a major gateway for refugees to the U.S. and a haven for spies. More than 100,000 refugees were able to flee Nazi Germany via Lisbon.

During the Estado Novo regime (1926–1974), Lisbon was expanded at the cost of other districts within the country, resulting in nationalist and monumental projects. New residential and public developments were constructed; the zone of Belém was modified for the 1940 Portuguese Exhibition, while along the periphery new districts appeared to house the growing population. The inauguration of the bridge over the Tagus allowed rapid connection between both sides of the river.

Lisbon was the site of three revolutions in the 20th century. The first, the 5 October 1910 revolution, brought an end to the Portuguese monarchy and established the highly unstable and corrupt Portuguese First Republic. The 6 June 1926 revolution would see the end of that first republic and firmly establish the Estado Novo, or the Portuguese Second Republic, as the ruling regime.

The Carnation Revolution, which took place on 25 April 1974, ended the right-wing Estado Novo regime and reformed the country to become as it is today, the Portuguese Third Republic.

In the 1990s, many of the districts were renovated and projects in the historic quarters were established to modernise those areas, for instance, architectural and patrimonial buildings were renovated, the northern margin of the Tagus was re-purposed for leisure and residential use, the Vasco da Gama Bridge was constructed and the eastern part of the municipality was re-purposed for Expo '98 to commemorate the 500th anniversary of Vasco da Gama's sea voyage to India, a voyage that would bring immense riches to Lisbon and cause many of Lisbon's landmarks to be built.

In 1988, a fire in the historical district of Chiado saw the destruction of many 18th-century Pombaline style buildings. A series of restoration works has brought the area back to its former self and made it a high-scale shopping district.

The Lisbon Agenda was a European Union agreement on measures to revitalise the EU economy, signed in Lisbon in March 2000. In October 2007 Lisbon hosted the 2007 EU Summit, where an agreement was reached regarding a new EU governance model. The resulting Treaty of Lisbon was signed on 13 December 2007 and came into force on 1 December 2009.

Lisbon has been the site for many international events and programmes. In 1994, Lisbon was the European Capital of Culture. On 3 November 2005, Lisbon hosted the MTV European Music Awards. On 7 July 2007, Lisbon held the ceremony of the "New 7 Wonders Of The World" election, in the Luz Stadium, with live transmission for millions of people all over the world. Every two years, Lisbon hosts the Rock in Rio Lisboa Music Festival, one of the largest in the world.
Lisbon hosted the "NATO summit" (19–20 November 2010), a summit meeting that is regarded as a periodic opportunity for Heads of State and Heads of Government of NATO member states to evaluate and provide strategic direction for Alliance activities. The city hosts the Web Summit and is the head office for the Group of Seven Plus (G7+). In 2018 it hosted the Eurovision Song Contest for the first time as well as the Michelin Gala.

Lisbon is located at , situated at the mouth of the Tagus River and is the westernmost capital of a mainland European country.

The westernmost part of Lisbon is occupied by the Monsanto Forest Park, a urban park, one of the largest in Europe, and occupying 10% of the municipality.

The city occupies an area of , and its city boundaries, unlike those of most major cities, coincide with those of the municipality. The rest of the urbanised area of the Lisbon urban area, known generically as Greater Lisbon () includes several administratively defined cities and municipalities, in the north bank of the Tagus River. The larger Lisbon metropolitan area includes the Setúbal Peninsula to the south.

Lisbon has a Mediterranean climate (Köppen: "Csa") with mild, rainy winters and warm to hot, dry summers. The average annual temperature is , during the day and at night.
In the coldest month – January – the highest temperature during the day typically ranges from , the lowest temperature at night ranges from and the average sea temperature is . In the warmest month – August – the highest temperature during the day typically ranges from , the lowest temperature at night ranges from and the average sea temperature is .

Among European capitals, Lisbon ranks among those with the warmest winters and one of the mildest night time temperatures, with an average of in the coldest month, and in the warmest month. The minimum temperature recorded in Lisbon was in February 1956 and in January 1985. The maximum temperature recorded in Lisbon was on 4 August 2018.

Sunshine hours are 2,806 per year, from an average of 4.6 hours of sunshine duration per day in December to an average of 11.4 hours of sunshine duration per day in July. The annual average rainfall is , with November being the wettest month.

The municipality of Lisbon included 53 "freguesias" (civil parishes) until November 2012. A new law ("Lei n.º 56/2012") reduced the number of "freguesias" to the following 24:

Locally, Lisbon's inhabitants may commonly refer to the spaces of Lisbon in terms of historic "Bairros de Lisboa" (neighbourhoods). These communities have no clearly defined boundaries and represent distinctive quarters of the city that have in common a historical culture, similar living standards, and identifiable architectural landmarks, as exemplified by the "Bairro Alto", "Alfama", "Chiado", and so forth.

Although today it is quite central, it was once a mere suburb of Lisbon, comprising mostly farms and country estates of the nobility with their palaces. In the 16th century, there was a brook there which the nobles used to promenade in their boats. During the late 19th century, Alcântara became a popular industrial area, with many small factories and warehouses.

In the early 1990s, Alcântara began to attract youth because of the number of pubs and discothèques. This was mainly due to its outer area of mostly commercial buildings, which acted as barriers to the noise-generating nightlife (which acted as a buffer to the residential communities surrounding it). In the meantime, some of these areas began to become gentrified, attracting loft developments and new flats, which have profited from its river views and central location.

The riverfront of Alcântara is known for its nightclubs and bars. The area is commonly known as "docas" (docks), since most of the clubs and bars are housed in converted dock warehouses.

The oldest district of Lisbon, it spreads down the southern slope from the Castle of São Jorge to the River Tagus. Its name, derived from the Arabic "Al-hamma", means fountains or baths. During the Islamic invasion of Iberia, the Alfama constituted the largest part of the city, extending west to the Baixa neighbourhood. Increasingly, the Alfama became inhabited by fishermen and the poor: its fame as a poor neighbourhood continues to this day. While the 1755 Lisbon earthquake caused considerable damage throughout the capital, the Alfama survived with little damage, thanks to its compact labyrinth of narrow streets and small squares. 

It is a historical quarter of mixed-use buildings occupied by Fado bars, restaurants, and homes with small shops downstairs. Modernising trends have invigorated the district: old houses have been re-purposed or remodeled, while new buildings have been constructed. Fado, the typically Portuguese style of melancholy music, is common (but not obligatory) in the restaurants of the district.

The Mouraria, or Moorish quarter, is one of the most traditional neighborhoods of Lisbon, although most of its old buildings were demolished by the Estado Novo between the 1930s and the 1970s. It takes its name from the fact that after the reconquest of Lisbon, the Muslims who remained were confined to this part of the city. In turn, the Jews were confined to three neighbourhoods called "Judiarias"

Bairro Alto (literally "the upper quarter" in Portuguese) is an area of central Lisbon that functions as a residential, shopping and entertainment district; it is the center of the Portuguese capital's nightlife, attracting hipster youth and members of various music subcultures. Lisbon's Punk, Gay, Metal, Goth, Hip Hop and Reggae scenes all find a home in the "Bairro" with its many clubs and bars that cater to them. The crowds in the Bairro Alto are a multicultural mix of people representing a broad cross-section of modern Portuguese society, many of them being entertainment seekers and devotees of various music genres outside the mainstream, Fado, Portugal's national music, still survives in the midst of the new nightlife.

The heart of the city is the "Baixa" or city centre; the Pombaline Baixa is an elegant district, primarily constructed after the 1755 Lisbon earthquake, taking its name from its benefactor, Sebastião José de Carvalho e Melo, 1st Marquis of Pombal, who was the minister of Joseph I of Portugal (1750–1777) and a key figure during the Portuguese Enlightenment. Following the 1755 disaster, Pombal took the lead in rebuilding Lisbon, imposing strict conditions and guidelines on the construction of the city, and transforming the organic street plan that characterised the district before the earthquake into its current grid pattern. As a result, the Pombaline Baixa is one of the first examples of earthquake-resistant construction. Architectural models were tested by having troops march around them to simulate an earthquake. Notable features of Pombaline structures include the "Pombaline cage", a symmetrical wood-lattice framework aimed at distributing earthquake forces, and inter-terrace walls that were built higher than roof timbers to inhibit the spread of fires.
The parish of Beato stands out for the new cultural dynamics it has been experiencing in recent years. The manufacturing districts and the industrial facilities by the riverside docks are the place of choice for contemporary art galleries, iconic bars, and gourmet restaurants that simmer in the streets. This reality has not gone unnoticed by the national press, and Visão, TimeOut, or Jornal de Negócios have already made notice of this parish that hides treasures such as the National Museum of the Azulejo or the Palacio do Grilo.

Belém is famous as the place from which many of the great Portuguese explorers set off on their voyages of discovery. In particular, it is the place from which Vasco da Gama departed for India in 1497 and Pedro Álvares Cabral departed for Brazil in 1499. It is also a former royal residence and features the 17th – 18th-century Belém Palace, a former royal residence now occupied by the President of Portugal, and the Ajuda Palace, begun in 1802 but never completed.

Perhaps Belém's most famous feature is its tower, Torre de Belém, whose image is much used by Lisbon's tourist board. The tower was built as a fortified lighthouse late in the reign of Dom Manuel l (1515–1520) to guard the entrance to the port. It stood on a little island in right side of the Tagus, surrounded by water. Belém's other major historical building is the "Mosteiro dos Jerónimos" (Jerónimos Monastery), which the Torre de Belém was built partly to defend. Belém's most notable modern feature is the Padrão dos Descobrimentos (Monument to the Discoveries) built for the Portuguese World Fair in 1940. In the heart of Belém is the "Praça do Império": gardens centred upon a large fountain, laid out during World War II. To the west of the gardens lies the "Centro Cultural de Belém". Belém is one of the most visited Lisbon districts. Here is located the Estádio do Restelo, house of Belenenses.

The Chiado is a traditional shopping area that mixes old and modern commercial establishments, concentrated specially in the Rua do Carmo and the Rua Garrett. Locals as well as tourists visit the Chiado to buy books, clothing and pottery as well as to have a cup of coffee. The most famous café of Chiado is "A Brasileira", famous for having had poet Fernando Pessoa among its customers. The Chiado is also an important cultural area, with several museums and theatres, including the opera. Several buildings of the Chiado were destroyed in a fire in 1988, an event that deeply shocked the country. Thanks to a renovation project that lasted more than 10 years, coordinated by celebrated architect Siza Vieira, the affected area has now virtually recovered.

The ornate, late 18th-century Estrela Basilica is the main attraction of this district. The church with its large dome is located on a hill in what was at the time the western part of Lisbon and can be seen from great distances. The style is similar to that of the Mafra National Palace, late baroque and neoclassical. The façade has twin bell towers and includes statues of saints and some allegorical figures. São Bento Palace, the seat of the Portuguese parliament and the official residences of the Prime Minister of Portugal and the President of the Assembly of the Republic of Portugal, are in this district. Also in this district is Estrela Park, a favorite with families. There are exotic plants and trees, a duck pond, various sculptures, a children's playground, and many cultural events going on through the year, including outdoor cinema, markets, and music festivals.

Parque das Nações (Park of Nations) is the newest district in Lisbon; it emerged from an urban renewal program to host the 1998 World Exhibition of Lisbon, also known as Expo'98. The area suffered massive changes giving Parque das Nações a futuristic look. A long lasting legacy of the same, the area has become another commercial and higher-end residential area for the city.

Central in the area is the Gare do Oriente (Orient railway station), one of the main transport hubs of Lisbon for trains, buses, taxis, and the metro. Its glass and steel columns are inspired by Gothic architecture, lending the whole structure a visual fascination (especially in sunlight or when illuminated at night). It was designed by the architect Santiago Calatrava from Valencia, Spain. The Parque das Nações is across the street.

The area is pedestrian-friendly with new buildings, restaurants, gardens, the Casino Lisbon, the FIL building (International Exhibition and Fair), the Camões Theatre and the "Oceanário de Lisboa" (Lisbon Oceanarium), which is the second largest in the world. The district's Altice Arena has become Lisbon's "jack-of-all-trades" performance arena. Seating 20,000, it has staged events from concerts to basketball tournaments.

Fernando Medina is the current and 77th Mayor of Lisbon.

The city of Lisbon is rich in architecture; Romanesque, Gothic, Manueline, Baroque, Modern and Postmodern constructions can be found all over Lisbon. The city is also crossed by historical boulevards and monuments along the main thoroughfares, particularly in the upper districts; notable among these are the "Avenida da Liberdade" (Avenue of Liberty), "Avenida Fontes Pereira de Melo", "Avenida Almirante Reis" and "Avenida da República" (Avenue of the Republic).

Lisbon is home to numerous prominent museums and art collections, from all around the world. The National Museum of Ancient Art, which has one of the largest art collections in the world, and the National Coach Museum, which has the world's largest collection of royal coaches and carriages, are the two most visited museums in the city. Other notable national museums include the National Museum of Archaeology, the Museum of Lisbon, the National Azulejo Museum, the National Museum of Contemporary Art, and the National Museum of Natural History & Science.
Prominent private museums and galleries include the Gulbenkian Museum (run by the Calouste Gulbenkian Foundation, one of the wealthiest foundations in the world), which houses one of the largest private collections of antiquaries and art in the world, the Berardo Collection Museum, which houses the private collection of Portuguese billionaire Joe Berardo, the Museum of Art, Architecture and Technology, and the Museum of the Orient. Other popular museums include the Electricity Museum, the Ephemeral Museum, the Museu da Água, and the Museu Benfica, among many others.

Lisbon's Opera House, the "Teatro Nacional de São Carlos", hosts a relatively active cultural agenda, mainly in autumn and winter. Other important theatres and musical houses are the "Centro Cultural de Belém", the "Teatro Nacional D. Maria II", the Gulbenkian Foundation, and the "Teatro Camões".

The monument to "Christ the King" (Cristo-Rei) stands on the southern bank of the Tagus River, in Almada. With open arms, overlooking the whole city, it resembles the Corcovado monument in Rio de Janeiro, and was built after World War II, as a memorial of thanksgiving for Portugal's being spared the horrors and destruction of the war.

13 June is Lisbon´s holiday in honour of the city's saint, Anthony of Lisbon (). Saint Anthony, also known as "Saint Anthony of Padua", was a wealthy Portuguese bohemian who was canonised and made Doctor of the Church after a life preaching to the poor. Although Lisbon’s patron saint is Saint Vincent of Saragossa, whose remains are housed in the Sé Cathedral, there are no festivities associated with this saint.

Eduardo VII Park, the second largest park in the city following the "Parque Florestal de Monsanto" (Monsanto Forest Park), extends down the main avenue (Avenida da Liberdade), with many flowering plants and greenspaces, that includes the permanent collection of subtropical and tropical plants in the winter garden (). Originally named "Parque da Liberdade", it was renamed in honour of Edward VII of England who visited Lisbon in 1903.

Lisbon is home every year to the Lisbon Gay & Lesbian Film Festival, the Lisboarte, the DocLisboa – Lisbon International Documentary Film Festival, the Festival Internacional de Máscaras e Comediantes, the Lisboa Mágica – Street Magic World Festival, the Monstra – Animated Film Festival, the Lisbon Book Fair, the Peixe em Lisboa – Lisbon Fish and Flavours, and many others.

Lisbon has two sites listed by UNESCO as a World Heritage Site: Belém Tower and Jerónimos Monastery. Furthermore, in 1994, Lisbon was the European Capital of Culture and, in 1998, organised the Expo '98 ("1998 Lisbon World Exposition").

Lisbon is also home to the Lisbon Architecture Triennial, the Moda Lisboa (Fashion Lisbon), ExperimentaDesign – Biennial of Design and LuzBoa – Biennial of Light.

In addition, the mosaic Portuguese pavement ("Calçada Portuguesa") was born in Lisbon, in the mid-1800s. The art has since spread to the rest of the Portuguese Speaking world. The city remains one of the most expansive examples of the technique, nearly all walkways and even many streets being created and maintained in this style.

In May 2018, the city hosted the 63rd edition of the Eurovision Song Contest, after the victory of Salvador Sobral with the song ""Amar pelos dois"" in Kiev on 13 May 2017.

The historical population of the city was around 35,000 in 1300 AD. Up to 60,000 in 1400 AD, and rising to 70,000 in 1500 AD. Between 1528–1590 the population went from 70,000 to 120,000. The population was about 150,000 in 1600 AD, and almost 200,000 in 1700 AD.

The Lisbon metropolitan area incorporates two NUTS III (European statistical subdivisions): "Grande Lisboa" (Greater Lisbon), along the northern bank of the Tagus River, and "Península de Setúbal" (Setúbal Peninsula), along the southern bank. These two subdivisions make for the "Região de Lisboa" (Lisbon Region). The population density of the city itself is .

Lisbon has 552,700 inhabitants within the administrative center on the area of only 100.05 km Administratively defined cities that exist in the vicinity of the capital are in fact part of the metropolitan perimeter of Lisbon. The urban area has a population of 2,666,000 inhabitants, being the eleventh largest urban area in the European Union after Paris, London, Ruhr area, Madrid, Milan, Barcelona, Berlin, Rome, Naples and Athens. The whole metropolis of Lisbon (metropolitan area) has about 3 million inhabitants. According to official government data, the Lisbon metropolitan area has 3,121,876 inhabitants. Other sources also show a similar number, according to the Organisation for Economic Co-operation and Development – 2,797,612 inhabitants; according to the Department of Economic and Social Affairs of the United Nations – 2,890,000; according to the European Statistical Office Eurostat – 2,839,908; according to the Brookings Institution has 2,968,600 inhabitants.

The Lisbon region is the wealthiest region in Portugal and it is well above the European Union's GDP per capita average – it produces 45% of the Portuguese GDP. Lisbon's economy is based primarily on the tertiary sector. Most of the headquarters of multinationals operating in Portugal are concentrated in the Grande Lisboa Subregion, specially in the Oeiras municipality. The Lisbon metropolitan area is heavily industrialized, especially the south bank of the Tagus river (Rio Tejo).

The Lisbon region is rapidly growing, with GDP (PPP) per capita calculated for each year as follows: €22,745 (2004) – €23,816 (2005) – €25,200 (2006) – €26,100 (2007). The Lisbon metropolitan area had a GDP amounting to $96.3 billion, and $32,434 per capita.

The country's chief seaport, featuring one of the largest and most sophisticated regional markets on the Iberian Peninsula, Lisbon and its heavily populated surroundings are also developing as an important financial centre and a dynamic technological hub. Automobile manufacturers have erected factories in the suburbs, for example, AutoEuropa.

Lisbon has the largest and most developed mass media sector of Portugal, and is home to several related companies ranging from leading television networks and radio stations to major newspapers.

The Euronext Lisbon stock exchange, part of the pan-European Euronext system together with the stock exchanges of Amsterdam, Brussels and Paris, is tied with the New York Stock Exchange since 2007, forming the multinational NYSE Euronext group of stock exchanges.

Lisbonite industry has very large sectors in oil, as refineries are found just across the Tagus, textile mills, shipyards and fishing.

Before Portugal's sovereign debt crisis and an EU-IMF rescue plan, for the decade of 2010 Lisbon was expecting to receive many state funded investments, including building a new airport, a new bridge, an expansion of the Lisbon Metro underground, the construction of a mega-hospital (or central hospital), the creation of two lines of a TGV to join Madrid, Porto, Vigo and the rest of Europe, the restoration of the main part of the town (between the Marquês de Pombal roundabout and Terreiro do Paço), the creation of a large number of bike lanes, as well as modernization and renovation of various facilities.

Lisbon was the 18th most "livable city" in the world in 2015 according to lifestyle magazine "Monocle."

Tourism is also a significant industry; a 2018 report stated that the city receives an average of 4.5 million tourists per year. Hotel revenues alone generated €714.8 million in 2017, an increase of 18.7% over 2016.

"Lisboa" was elected the "World's Leading City Destination and World's Leading City Break Destination 2018".

The Lisbon Metro connects the city centre with the upper and eastern districts, and also reaches some suburbs that are part of the Lisbon metropolitan area, such as Amadora and Loures. It is the fastest way to get around the city and it provides a good number of interchanging stations with other types of transportation. From the Lisbon Airport station to the city centre it may take roughly 25 mins. As of 2018, the Lisbon Metro comprises four lines, identified by individual colours (blue, yellow, green and red) and 56 stations, with a total length of 44.2 km. Several expansion projects have been proposed, being the most recent the transformation of the Green Line into a circular line and the creation of two more stations (Santos and Estrela).

A traditional form of public transport in Lisbon is the tram. Introduced in 1901, electric trams were originally imported from the US, and called the "americanos". The earliest trams can still be seen in the Museu da Carris (the Public Transport Museum). Other than on the modern Line 15, the Lisbon tramway system still employs small (four wheel) vehicles of a design dating from the early twentieth century. These distinctive yellow trams are one of the tourist icons of modern Lisbon, and their size is well suited to the steep hills and narrow streets of the central city.

There are four commuter train lines departing from Lisbon: the Sintra, Azambuja, Cascais and Sado lines (operated by CP – Comboios de Portugal), as well as a fifth line to Setúbal (operated by Fertagus), which crosses the Tagus river via the 25 de Abril Bridge. The major railway stations are Santa Apolónia, Rossio, Gare do Oriente, Entrecampos, and Cais do Sodré.

The local bus service within Lisbon is operated by Carris.

There are other commuter bus services from the city (connecting cities outside Lisbon, and connecting these cities to Lisbon): Vimeca, Rodoviária de Lisboa, Transportes Sul do Tejo, Boa Viagem, Barraqueiro are the main ones, operating from different terminals in the city.

Lisbon is connected to its suburbs and throughout Portugal by an extensive motorway network. There are three circular motorways around the city; the 2ª Circular, the IC17 (CRIL), and the A9 (CREL).

The city is connected to the far side of the Tagus by two important bridges:

The foundations for a third bridge across the Tagus have already been laid, but the overall project has been postponed due to the economic crisis in Portugal and all of Europe.

Another way of crossing the river is by taking the ferry. The operator is Transtejo & Soflusa, which runs from different locations within the city: Cacilhas, Seixal, Montijo, Porto Brandão and Trafaria under the brand Transtejo and to Barreiro under the brand Soflusa.

Humberto Delgado Airport is located within the city limits. It is the headquarters and hub for TAP Portugal as well as a hub for Easyjet, Azores Airlines, Ryanair, EuroAtlantic Airways, White Airways, and Hi Fly. A second airport has been proposed, but the project has been put on hold because of the Portuguese and European economic crisis, and also because of the long discussion on whether a new airport is needed. However, the last proposal is military air base in Montijo that would be replaced by a civil airport. So, Lisbon would have two airports, the current airport in north and a new in the south of the city.

Cascais Aerodrome, 20 km West of the city centre, in Cascais, offers commercial domestic flights.

The average amount of time people spend commuting with public transit in Lisbon, for example to and from work, on a weekday is 59 min. 11.5% of public transit riders, ride for more than 2 hours every day. The average amount of time people wait at a stop or station for public transit is 14 min, while 23.1% of riders wait for over 20 minutes on average every day. The average distance people usually ride in a single trip with public transit is 6 km, while 10% travel for over 12 km in a single direction.

In Greater Lisbon area, particularly in the Portuguese Riviera, an area popular with expats and foreign nationals, there are numerous international schools, including the Carlucci American International School of Lisbon (only American school in Portugal), Saint Julian's School (British), Saint Dominic's International School (British), Deutsche Schule Lissabon (German), Instituto Español Giner de los Ríos (Spanish), and Lycée Français Charles Lepierre (French).

In the city, there are three public universities and a university institute. The University of Lisbon, which is the largest university in Portugal, was created in 2013 with the union of the Technical University of Lisbon and the Classical University of Lisbon (which was known as the University of Lisbon). The New University of Lisbon, founded in 1973, is another public university in Lisbon and is known internationally by its Nova School of Business and Economics (Nova SBE),its economics and management faculty. The third public university is Universidade Aberta. Additionally, there's ISCTE - Lisbon University Institute (founded in 1972), a university institute that provides degrees in all academic disciplines.

Major private institutions of higher education include the Portuguese Catholic University, focused on law and management, as well as the Lusíada University, the Universidade Lusófona, and the Universidade Autónoma de Lisboa, among others.

The total number of enrolled students in higher education in Lisbon was, for the 2007–2008 school year, of 125,867 students, of whom 81,507 in the Lisbon's public institutions.

Lisbon is home to Biblioteca Nacional de Portugal, the Portuguese national library, which has over 3 million books and manuscripts. The library has some rare books and manuscripts, such as an original Gutenberg Bible and original books by Erasmus, Christophe Platin and Aldus Manutius. Another relevant library is the Torre do Tombo National Archive, one of the most important archives in the world, with over 600 years and one of the oldest active Portuguese institutions. There are, among several others, the Arquivo Histórico Ultramarino and the Arquivo Histórico Militar.

Lisbon has a long tradition in sports. It hosted several matches, including the final, of the UEFA Euro 2004 championship. The city also played host to the final of the 2001 IAAF World Indoor Championships and the European Fencing Championships in 1983 and 1992, as well as the 2003 World Men's Handball Championship, and the 2008 European Judo Championships. From 2006 to 2008, Lisbon was the starting point for the Dakar Rally. The city hosted the 2014 and 2020 UEFA Champions League finals. In 2008 and 2016, the city hosted the European Triathlon Championships. Lisbon has a leg at the Volvo Ocean Race.

The city hosts three association football clubs in Portugal's highest league, the Primeira Liga. Sport Lisboa e Benfica, commonly known as simply "Benfica", has won 37 league titles in addition to two European Cups. Lisbon's second-most successful club is Sporting Clube de Portugal (commonly known as "Sporting" and often referred to as "Sporting Lisbon" abroad to prevent confusion with other teams with the same name), winner of 18 league titles and the UEFA Cup Winners' Cup. A third club, C.F. Os Belenenses (commonly "Belenenses" or "Belenenses Lisbon"), based in the Belém quarter, has solely won one league title. Other major clubs in Lisbon include Atlético, Casa Pia, and Oriental.

Lisbon has two UEFA category four stadiums; Benfica's Estádio da Luz ("Stadium of Light"), with a capacity of over 65,000 and Sporting's Estádio José Alvalade, with a capacity of over 50,000. There is also Belenenses' Estádio do Restelo, with a capacity of over 30,000. The Estádio Nacional, in nearby Oeiras, has a capacity of 37,000 and was used exclusively for Portuguese international football matches and cup finals until the construction of larger stadia in the city. It held the 1967 European Cup Final.

Other sports, such as basketball, futsal, handball, roller hockey, rugby union and volleyball are also popular; the latter's national stadium is in Lisbon. There are many other sport facilities in Lisbon, ranging from athletics, sailing, golfing to mountain-biking. Lisboa and Troia golf course are two of many stunning golf courses located in Lisbon. Every March the city hosts the Lisbon Half Marathon, while in September the Portugal Half Marathon.

Lisbon is part of the Union of Luso-Afro-Americo-Asiatic Capital Cities from 28 June 1985, establishing brotherly relations with the following cities:
Lisbon is part of the Union of Ibero-American Capital Cities from 12 October 1982 establishing brotherly relations with the following cities:
Lisbon has additional cooperation agreements with the following cities:




</doc>
<doc id="18093" url="https://en.wikipedia.org/wiki?curid=18093" title="Local Group">
Local Group

The Local Group is the galaxy group that includes the Milky Way. 
It has a total diameter of roughly , and a total mass of the order of .
It consists of two clusters of galaxies in a "dumbbell" shape: the Milky Way and its satellites form one lobe, and the Andromeda Galaxy and its satellites constitute the other. The two clusters are separated by about and move towards one another with a velocity of . The group itself is a part of the larger Virgo Supercluster, which may be a part of the Laniakea Supercluster.
The total number of galaxies in the Local Group is unknown as some are occluded by the Milky Way; however, at least 80 such objects are known (most of which are dwarf galaxies).

The two largest members, the Andromeda Galaxy and the Milky Way, are both spiral galaxies with masses of about solar masses each, and each have their own system of satellite galaxies:

The Triangulum Galaxy is the third-largest member of the Local Group, with a mass of approximately , and is the third spiral galaxy. It is unclear whether the Triangulum Galaxy is a companion of the Andromeda Galaxy, although the two galaxies experienced a close passage 2–4 billion years ago which triggered star formation across Andromeda's disk. The Pisces Dwarf Galaxy is equidistant from the Andromeda Galaxy and the Triangulum Galaxy, so it may be a satellite of either.

The membership of NGC 3109, with its companions Sextans A and the Antlia Dwarf Galaxy, is uncertain due to extreme distances from the center of the Local Group.
The other members of the group are likely gravitationally secluded from these large subgroups: IC 10, IC 1613, Phoenix Dwarf Galaxy, Leo A, Tucana Dwarf Galaxy, Cetus Dwarf Galaxy, Pegasus Dwarf Irregular Galaxy, Wolf–Lundmark–Melotte, Aquarius Dwarf Galaxy, and Sagittarius Dwarf Irregular Galaxy.

The term "The Local Group" was introduced by Edwin Hubble in Chapter VI of his 1936 book "The Realm of the Nebulae". There, he described it as "a typical small group of nebulae which is isolated in the general field" and delineated, by decreasing luminosity, its members to be M31, Milky Way, M33, Large Magellanic Cloud, Small Magellanic Cloud, M32, NGC 205, NGC 6822, NGC 185, IC 1613 and NGC 147. He also identified IC 10 as a possible part of the Local Group.





</doc>
<doc id="18094" url="https://en.wikipedia.org/wiki?curid=18094" title="Litre">
Litre

The litre (British and Commonwealth spelling) or liter (American spelling) (SI symbols L and l, other symbol used: ℓ) is a metric unit of volume. It is equal to 1 cubic decimetre (dm), 1000 cubic centimetres (cm) or 0.001 cubic metre. A cubic decimetre (or litre) occupies a volume of (see figure) and is thus equal to one-thousandth of a cubic metre.

The original French metric system used the litre as a base unit. The word "litre" is derived from an older French unit, the "litron", whose name came from Greek—where it was a unit of weight, not volume—via Latin, and which equalled approximately 0.831 litres. The litre was also used in several subsequent versions of the metric system and is accepted for use with the SI, although not an SI unit—the SI unit of volume is the cubic metre (m). The spelling used by the International Bureau of Weights and Measures is "litre", a spelling which is shared by almost all English-speaking countries. The spelling "liter" is predominantly used in American English.

One litre of liquid water has a mass of almost exactly one kilogram, because the kilogram was originally defined in 1795 as the mass of one cubic decimetre of water at the temperature of melting ice (). Subsequent redefinitions of the metre and kilogram mean that this relationship is no longer exact.

A litre is a cubic decimetre, which is the volume of a cube 10 centimetres × 10 centimetres × 10 centimetres (1 L ≡ 1 dm ≡ 1000 cm). Hence 1 L ≡ 0.001 m ≡ 1000 cm, and 1 m (i.e. a cubic metre, which is the SI unit for volume) is exactly 1000 L.

From 1901 to 1964, the litre was defined as the volume of one kilogram of pure water at maximum density (+4 °C) and standard pressure. The kilogram was in turn specified as the mass of the International Prototype of the Kilogram (a specific platinum/iridium cylinder) and was intended to be of the same mass as the 1 litre of water referred to above. It was subsequently discovered that the cylinder was around 28 parts per million too large and thus, during this time, a litre was about 1.000028 dm. Additionally, the mass–volume relationship of water (as with any fluid) depends on temperature, pressure, purity and isotopic uniformity. In 1964, the definition relating the litre to mass was superseded by the current one. Although the litre is not an SI unit, it is accepted by the CGPM (the standards body that defines the SI) for use with the SI. CGPM defines the litre and its acceptable symbols.

A litre is equal in volume to the millistere, an obsolete non-SI metric unit customarily used for dry measure.

Litres are most commonly used for items (such as fluids and solids that can be poured) which are measured by the capacity or size of their container, whereas cubic metres (and derived units) are most commonly used for items measured either by their dimensions or their displacements. The litre is often also used in some calculated measurements, such as density (kg/L), allowing an easy comparison with the density of water.

One litre of water has a mass of almost exactly one kilogram when measured at its maximal density, which occurs at about 4 °C. It follows, therefore, that 1000th of a litre, known as one millilitre (1 mL), of water has a mass of about 1 g; 1000 litres of water has a mass of about 1000 kg (1 tonne). This relationship holds because the gram was originally defined as the mass of 1 mL of water; however, this definition was abandoned in 1799 because the density of water changes with temperature and, very slightly, with pressure.

It is now known that the density of water also depends on the isotopic ratios of the oxygen and hydrogen atoms in a particular sample. Modern measurements of Vienna Standard Mean Ocean Water, which is pure distilled water with an isotopic composition representative of the average of the world's oceans, show that it has a density of at its point of maximum density (3.984 °C) under one standard atmosphere (760 Torr = 101.325 kPa) of pressure.

The litre, though not an official SI unit, may be used with SI prefixes. The most commonly used derived unit is the millilitre, defined as one-thousandth of a litre, and also often referred to by the SI derived unit name "cubic centimetre". It is a commonly used measure, especially in medicine, cooking and automotive engineering. Other units may be found in the table below, where the more often used terms are in bold. However, some authorities advise against some of them; for example, in the United States, NIST advocates using the millilitre or litre instead of the centilitre. There are two international standard symbols for the litre: L and l. In the United States the former is preferred because of the risk that (in some fonts) the letter and the digit may be confused.

One litre is slightly larger than a US liquid quart and slightly less than an imperial quart or one US dry quart. A mnemonic for its volume relative to an imperial pint is "a litre of water's a pint and three quarters"; this is very close, as a litre is actually 1.75975399 pints.

A litre is the volume of a cube with sides of 10 cm, which is slightly less than a cube of sides 4 inches (one-third of a foot). One cubic foot would contain exactly 27 such cubes (four inches on each side), making one cubic foot approximately equal to 27 litres. One cubic foot has an exact volume of 28.316846592 litres, which is 4.88% higher than the 27-litre approximation.

A litre of liquid water has a mass almost exactly equal to one kilogram. An early definition of the kilogram was set as the mass of one litre of water. Because volume changes with temperature and pressure, and pressure uses units of mass, the definition of a kilogram was changed. At standard pressure, one litre of water has a mass of 0.999975 kg at 4 °C, and 0.997 kg at 25 °C.

Originally, the only symbol for the litre was l (lowercase letter L), following the SI convention that only those unit symbols that abbreviate the name of a person start with a capital letter. In many English-speaking countries, however, the most common shape of a handwritten Arabic digit 1 is just a vertical stroke; that is, it lacks the upstroke added in many other cultures. Therefore, the digit "1" may easily be confused with the letter "l". In some computer typefaces, the two characters are barely distinguishable. This caused some concern, especially in the medical community.

As a result, L (uppercase letter L) was adopted as an alternative symbol for litre in 1979. The United States National Institute of Standards and Technology now recommends the use of the uppercase letter L, a practice that is also widely followed in Canada and Australia. In these countries, the symbol L is also used with prefixes, as in mL and μL, instead of the traditional ml and μl used in Europe. In the UK and Ireland, as well as the rest of Europe, lowercase "l" is used with prefixes, though whole litres are often written in full (so, "750 ml" on a wine bottle, but often "1 litre" on a juice carton). In 1990, the International Committee for Weights and Measures stated that it was too early to choose a single symbol for the litre.

Prior to 1979, the symbol came into common use in some countries; for example, it was recommended by South African Bureau of Standards publication M33 and Canada in the 1970s. This symbol can still be encountered occasionally in some English-speaking and European countries like Germany, and its use is ubiquitous in Japan and South Korea.

Fonts covering the CJK characters usually include not only the script small but also four precomposed characters: ㎕, ㎖, ㎗ and ㎘ for the microlitre, millilitre, decilitre and kilolitre.
The first name of the litre was "cadil"; standards are shown at the Musée des Arts et Métiers in Paris.

The litre was introduced in France in 1795 as one of the new "republican units of measurement" and defined as one cubic decimetre.
One litre of liquid water has a mass of almost exactly one kilogram, due to the gram being defined in 1795 as one cubic centimetre of water at the temperature of melting ice.
The original decimetre length was 44.344 "lignes", which was revised in 1798 to 44.3296 "lignes". This made the original litre of today's cubic decimetre. It was against this litre that the kilogram was constructed.

In 1879, the CIPM adopted the definition of the litre, with the symbol l (lowercase letter L).

In 1901, at the 3rd CGPM conference, the litre was redefined as the space occupied by 1 kg of pure water at the temperature of its maximum density (3.98 °C) under a pressure of 1 atm. This made the litre equal to about (earlier reference works usually put it at ).

In 1964, at the 12th CGPM conference, the original definition was reverted to, and thus the litre was once again defined in exact relation to the metre, as another name for the cubic decimetre, that is, exactly 1 dm.

In 1979, at the 16th CGPM conference, the alternative symbol L (uppercase letter L) was adopted. It also expressed a preference that in the future only one of these two symbols should be retained, but in 1990 said it was still too early to do so.

In spoken English, the symbol "mL" (for millilitre) can be pronounced as "mil". This can potentially cause confusion with some other measurement words such as:

However the context is usually sufficient hint — "mL" is a unit of volume; whereas the others are units of linear or angular measurement.

The abbreviation "cc" (for cubic centimetre, equal to a millilitre or mL) is a unit of the cgs system, which preceded the MKS system, which later evolved into the SI system. The abbreviation "cc" is still commonly used in many fields, including medical dosage and sizing for combustion engine displacement.

The microlitre (μL) has been known in the past as the lambda (λ), but this usage is now discouraged. In the medical field the microlitre is sometimes abbreviated as mcL on test results.

In the SI system, apart from prefixes for powers of 1000, use of the "centi" (10), "deci" (10), "deca" (10) and "hecto" (10) prefixes with litres is common. For example, in many European countries, the hectolitre is the typical unit for production and export volumes of beverages (milk, beer, soft drinks, wine, etc.) and for measuring the size of the catch and quotas for fishing boats; decilitres are common in Croatia, Switzerland and Scandinavia and often found in cookbooks, and restaurant and café menus; centilitres indicate the capacity of drinking glasses and of small bottles. In colloquial Dutch in Belgium, a "" and a "" (literally "twenty-fiver" and "thirty-threer") are the common beer glasses, the corresponding bottles mention 25 cL and 33 cL. Bottles may also be 75 cL or half size at 37.5 cL for "artisanal" brews or 70 cL for wines or spirits. Cans come in 25 cL, 33 cL and 50 cL. Similarly, alcohol shots are often marked in cL in restaurant menus, typically .

In countries where the metric system was adopted as the official measuring system after the SI standard was established, common usage eschews prefixes that are not powers of 1000. For example, in Canada, Australia, and New Zealand, consumer beverages are labelled almost exclusively using litres and millilitres. Hectolitres sometimes appear in industry, but centilitres and decilitres are rarely, if ever, used. An exception is in pathology, where for instance blood lead level may be measured in micrograms per decilitre. Larger volumes are usually given in cubic metres (equivalent to 1 kL), or thousands or millions of cubic metres.

Although kilolitres, megalitres, and gigalitres are commonly used for measuring water consumption, reservoir capacities and river flows, for larger volumes of fluids, such as annual consumption of tap water, lorry (truck) tanks, or swimming pools, the cubic metre is the general unit. It is also generally for all volumes of a non-liquid nature.



</doc>
<doc id="18095" url="https://en.wikipedia.org/wiki?curid=18095" title="Linguist (disambiguation)">
Linguist (disambiguation)

A linguist is a specialist in the scientific study of language.

Linguist may also refer to:



</doc>
<doc id="18096" url="https://en.wikipedia.org/wiki?curid=18096" title="Lavr Kornilov">
Lavr Kornilov

Lavr Georgiyevich Kornilov (, ; – 13 April 1918) was a Russian military intelligence officer, explorer, and general of Siberian Cossack origin in the Imperial Russian Army during World War I and the ensuing Russian Civil War. He is today best remembered for the Kornilov Affair, an unsuccessful endeavor in August/September 1917 that was intended to strengthen Alexander Kerensky's Provisional Government, but which led to Kerensky eventually having Kornilov arrested and charged with attempting a coup d'état, and ultimately undermined Kerensky's rule.

Kornilov escaped from jail in November 1917, and subsequently became the military commander of the anti-Bolshevik Volunteer Army which took the charge of anti- Bolshevik opposition in the south of Russia. He and his troops were badly outnumbered in many of their encounters, and he was killed by a shell on 13 April 1918 while laying siege to Ekaterinodar, the capital of the Kuban Soviet Republic.

One story relates how Kornilov was originally born as a Don Cossack Kalmyk named Lorya Dildinov and adopted in Ust-Kamenogorsk, Russian Turkestan (now Kazakhstan) by the family of his mother's brother, the Russian Cossack Khorunzhiy Georgy Nikolayevich Kornilov, whose wife was of Kazakh origin. But his sister wrote that he had not been adopted, had not been a Don Cossack, and that their mother had Polish and Altai Oirot descent. (Though their language was not a Kalmyk/Mongolian one, but because of their Asian race and their history in the Jungar Oirot (Kalmyk) state, Altai Oirots were called Altai Kalmyks by Russians. They were not Muslims or Kazakhs.) But Boris Shaposhnikov, who served with Pyotr Kornilov, the brother of Lavr, in 1903, mentioned the "Kyrgyz" ancestry of their mother - this name was usually used in reference to Kazakhs in 1903. Kornilov's Siberian Cossack father was a friend of Potanin (1835-1920), a prominent figure in the Siberian autonomy movement.

Kornilov entered military school in Omsk in 1885 and went on to study at the Mikhailovsky Artillery School in St. Petersburg in 1889. In August 1892 he was assigned as a lieutenant to the Turkestan Military District, where he led several exploration missions in Eastern Turkestan, Afghanistan and Persia, learned several Central Asian languages, and wrote detailed reports about his observations.

Kornilov returned to St. Petersburg to attend the Mykolayiv General Staff Academy and graduated as a captain in 1897. Again refusing a posting at St. Peterburg, he returned to the Turkestan Military District, where he resumed his duties as a military intelligence officer.

During the Russo-Japanese War of 1904-1905 Kornilov became the Chief of staff of the 1st Infantry Brigade, and was heavily involved in the Battle of Sandepu (January 1905) and the Battle of Mukden (February/March 1905). He was awarded the Order of St. George (4th class) for bravery and promoted to the rank of colonel.

Following the end of the war, Kornilov served as military attache in China from 1907 to 1911. He studied the Chinese language, travelled extensively (researching data on the history, traditions and customs of the Chinese, which he intended to use as material for a book about life in contemporary China), and regularly sent detailed reports to the General Staff and Foreign Ministry. Kornilov paid much attention to the prospects of cooperation between Russia and China in the Far East and met with the future president of China, Chiang Kai-shek. In 1910 Kornilov was recalled from Beijing but remained in St. Petersburg for only five months before departing for western Mongolia and Kashgar to examine the military situation along China's border with Russia. On 2 February 1911 he became Commander of the 8th Infantry Regiment of Estonia and was later appointed commander of the 9th Siberian Rifle Division, stationed in Vladivostok.

In 1914, at the start of World War I, Kornilov was appointed commander of the 48th Infantry Division, which saw combat in Galicia and the Carpathians. In 1915, he was promoted to the rank of major general. During heavy fighting, he was captured by the Austrians in April 1915, when his division became isolated from the rest of the Russian forces. After his capture, Field Marshal Conrad, the commander of the Austro-Hungarian Army, made a point of meeting him in person. As a major general, he was a high-value prisoner of war, but in July 1916 Kornilov managed to escape back to Russia and return to duty.

After the abdication of Tsar Nicholas II, he was given command of the Petrograd Military District in March 1917. On 8 March, Kornilov placed the Empress Alexandra and her children under house arrest at the Alexander Palace (Nicholas was still held at Stavka), replacing the Tsar's Escort and Combined Regiments of the Imperial Guard with 300 revolutionary troops. In July, after commanding the only successful front in the disastrous Russian offensive of June 1917, he became Supreme Commander-in-Chief of the Provisional Government's armed forces.

In the mass discontent following the July Days, the Russian populace grew highly skeptical about the Provisional Government's abilities to alleviate the economic distress and social resentment among the lower classes. Pavel Milyukov, the Kadet leader, describes the situation in Russia in late July as, "Chaos in the army, chaos in foreign policy, chaos in industry and chaos in the nationalist questions".
Kornilov, appointed commander-in-chief of the Russian army in July 1917, considered the Petrograd Soviet responsible for the breakdown in the military in recent times and believed that the Provisional Government lacked the power and confidence to dissolve the Petrograd Soviet. Following several ambiguous correspondences between Kornilov and Alexander Kerensky, Kornilov commanded an assault on the Petrograd Soviet.

Because the Petrograd Soviet was able to quickly gather a powerful army of workers and soldiers in defence of the Revolution, Kornilov's coup was an abysmal failure, and he was placed under arrest. The Kornilov Affair resulted in significantly increased distrust among Russians towards the Provisional Government.

After the alleged coup collapsed as his troops disintegrated, Kornilov and his fellow conspirators were placed under arrest in the Bykhov jail. On 19 November, a few weeks after the proclamation of Soviet power in Petrograd, they escaped from their confinement (eased by the fact that the jail was guarded by Kornilov's supporters) and made their way to the Don region, which was controlled by the Don Cossacks. Here they linked up with General Mikhail Alekseev. Kornilov became the military commander of the anti-Bolshevik Volunteer Army with Alekseev as the political chief.

The Kornilov Shock Detachment of the 8th Army was the most famous and longest-lived volunteer unit in the Russian Imperial Army. It was also the last regiment of the Russian Imperial Army and the first of the Volunteer Army. In late 1917, the Kornilov Shock Regiment, one of the crack units of the Volunteer Army, was named after him, as well as many other autonomous White Army formations, such as the Kuban Cossack Kornilov Horse Regiment. Kornilov's forces became recognizable for their Totenkopf insignia, which appeared on the regiment's flags, pennants, and soldiers' sleeve patches.

Even before the Red Army was formed, Lavr Kornilov promised, "the greater the terror, the greater our victories." He vowed that the goals of his forces must be fulfilled even if it was needed "to set fire to half the country and shed the blood of three-quarters of all Russians." In the Don region village of Lezhanka alone, bands of Kornilov's officers killed more than 500 people. On the other hand, Kornilov's adjutant recalled, that the general "loved only the [Russia] itself" and served it for all his life, having no time to think about political systems. The Bolsheviks for him were dangerous traitors, who ruined Russia's unity and had to be stopped.

On 24 February 1918, as Rostov and the Don Cossack capital of Novocherkassk fell to the Bolsheviks, Kornilov led the Volunteer Army on the epic 'Ice March' into the empty steppe towards the Kuban. Although badly outnumbered, he escaped destruction from pursuing Bolshevik forces and laid siege to Ekaterinodar, the capital of the Kuban Soviet Republic, on 10 April. However, in the early morning of 13 April, a Soviet shell landed on his farmhouse headquarters and killed him. He was buried in a nearby village.

A few days later, when the Bolsheviks gained control of the village, they unearthed Kornilov's coffin, dragged his corpse to the main square and burnt his remains on the local rubbish dump.




</doc>
<doc id="18100" url="https://en.wikipedia.org/wiki?curid=18100" title="L. L. Zamenhof">
L. L. Zamenhof

Ludwik Lejzer Zamenhof (; ; – ) was a Polish ophthalmologist, linguist and the inventor of the international language Esperanto, the most widely used constructed international auxiliary language in the world. 

Zamenhof first developed the language in 1873 while still in school. He grew up fascinated by the idea of a world without war. He believed that this could happen with the help of a new international auxiliary language. The language would be a tool to gather people together through neutral, fair, equitable communication. He successfully formed a community that continues today despite the World Wars of the 20th century. Also, it has developed like other languages, through the interaction and creativity of its users. 

In light of his achievements, and his support of intercultural dialogue, UNESCO selected Zamenhof as one of its eminent personalities of 2017, on the 100th anniversary of his death.

Zamenhof was born on , the son of Markus Zamenhof ( – ) and Rozalia (Sofer) Zamenhof (1839 – ), in the multi-ethnic city of Belostok in the Russian Empire (now Białystok in Poland). At that time the city was in the Grodno Governorate of the Russian Empire as a result of the 1807 Treaties of Tilsit. His parents were of Litvak Jewish descent. This group inhabited the former Grand Duchy of Lithuania. He appears to have been natively bilingual in Yiddish and Russian. His father was a teacher of German and French. From him, Zamenhof learned German, French and Hebrew. He also spoke some major languages of Białystok: Polish, Yiddish, Belarusian, and German. Polish became the native language of his children in Warsaw. In school he studied the classical languages Latin, Greek, Hebrew, and Aramaic. He later learned some English, though in his own words not very well. He had an interest in Lithuanian and Italian and learned Volapük when it came out in 1880. By that point his international language project was already well developed.

In addition to the Yiddish-speaking Jewish majority, the population of Białystok included Roman Catholic Poles and Eastern Orthodox Russians (mainly government officials), with smaller groups of Belarusians, Germans and other ethnic groups. Zamenhof was saddened and frustrated by the many quarrels among these groups. He supposed that the main reason for the hate and prejudice lay in the mutual misunderstanding caused by the lack of a common language. If such a language existed, Zamenhof postulated, it could play the role of a neutral communication tool between people of different ethnic and linguistic backgrounds.

As a student at secondary school in Warsaw, Zamenhof attempted to create an international language with a grammar that was rich, but complex. When he later studied English, he decided that the international language must have a simpler grammar. Apart from his parents' native languages Russian and Yiddish and his adopted language Polish, his projects were also aided by his mastery of German, a good passive understanding of Latin, Hebrew and French, and a basic knowledge of Greek, English and Italian.

By 1878, his project "Lingwe uniwersala" was finished. However, Zamenhof was too young then to publish his work. Soon after graduation he began to study medicine, first in Moscow, and later in Warsaw. In 1885, Zamenhof graduated from a university and began his practice as a doctor in Veisiejai. After 1886 he worked as an ophthalmologist in Płock and Vienna. While healing people there, he continued to work on his project of an international language.

For two years he tried to raise funds to publish a booklet describing the language, until he received the financial help from his future wife's father. In 1887, the book titled "Международный язык. Предисловие и полный учебникъ" (International language: Introduction and complete textbook) was published in Russian under the pseudonym "Doktoro Esperanto" (Doctor Hoper, or literally "Doctor One Who Hopes".). Zamenhof initially called his language "Lingvo internacia" (international language), but those who learned it began to call it "Esperanto" after his pseudonym, and this soon became the official name for the language. For Zamenhof, this language, far from being merely a communication tool, was a way to promote peaceful coexistence between people of different cultures.

In 1879 Zamenhof wrote the first grammar of Yiddish. It was partly published years later in the Yiddish magazine "Lebn un visnshaft". The complete original Russian text of this manuscript was only published in 1982, with parallel Esperanto translation by Adolf Holzhaus, in "L. Zamenhof, provo de gramatiko de novjuda lingvo" [An attempt at a grammar of neo-Jewish language], Helsinki, pp. 9–36. In this work, not only does he provide a review of Yiddish grammar, but also proposes its transition to the Latin script and other orthographic innovations. In the same period Zamenhof wrote some other works in Yiddish, including perhaps the first survey of Yiddish poetics (see p. 50 in the above-cited book).

In 1882 a wave of pogroms within the Russian Empire, including Congress Poland, motivated Zamenhof to take part in the early Zionist movement, the Hibbat Zion. He left the movement in 1887, and in 1901 published a statement in Russian with the title "Hillelism", in which he argued that the Zionist project could not solve the problems of the Jewish people.

In 1914 he declined an invitation to join a new organization of Jewish Esperantists, the TEHA. In his letter to the organizers, he said, "I am profoundly convinced that every nationalism offers humanity only the greatest unhappiness ... It is true that the nationalism of oppressed peoples – as a natural self-defensive reaction – is much more excusable than the nationalism of peoples who oppress; but, if the nationalism of the strong is ignoble, the nationalism of the weak is imprudent; both give birth to and support each other ..." The Hebrew Bible is among the many works that Zamenhof translated into Esperanto.

Zamenhof died in Warsaw on , possibly of a heart attack, and was buried at the Okopowa Street Jewish Cemetery. The farewell speech was delivered by the chief rabbi and preacher of the Great Synagogue in Warsaw, Samuel Abraham Poznański, who said: "There will be a time where the Polish soil and nation will understand what fame gave this great son of God to his homeland."

Zamenhof and his wife Klara Silbernik raised three children, a son, Adam, and two daughters, Zofia and Lidia. All three were murdered in the Holocaust.

Lidia Zamenhof in particular took a keen interest in Esperanto, and as an adult became a teacher of the language, traveling through Europe and to America to teach classes in it. Through her friendship with Martha Root, Lidia accepted Bahá'u'lláh and became a member of the Bahá'í faith. As one of its social principles, the Bahá'í faith teaches that an auxiliary world language should be selected by the representatives of all the world's nations.

Zamenhof's grandson, Louis-Christophe Zaleski-Zamenhof (Adam's son), lived in France from the 1960s until his death in 2019. As of 2020 Louis-Christophe's daughter, Margaret Zaleski-Zamenhof, is active in the Esperanto movement.

Besides his linguistic work, Zamenhof published a religious philosophy he called "Homaranismo" (the term in Esperanto, usually rendered as "humanitism" in English, sometimes rendered loosely as humanitarianism or humanism), based on the principles and teachings of Hillel the Elder. He said of Homaranismo: "It is indeed the object of my whole life. I would give up everything for it."

Zamenhof came from and lived a very-much multilingual life. His name is/was variously transliterated, depending on the language:

At his birth Zamenhof was given the Hebrew name "Eliezer" by his parents, the equivalent of the Latinized "Lazarus". However Zamenhof was born under Russian domination, and so his birth certificate records his name as "Leyzer Zamengov", using the Yiddish form of the forename and a russified version of his surname; many later Russian language documents also include the patronymic "Markovich", as is the custom in the language. His family name is of German origin and was originally written "Samenhof"; the spelling Zamenhof reflects the romanization of the Yiddish spelling , as well as the Esperanto and Polish spellings. (The German letter "z" is always pronounced [ts], while German "s" can be pronounced either like [s] or [z].)

In his adolescence he used both the Yiddish "Leyzer" and the Russian "Lazar".

While at university, Zamenhof began using the Russian name "Lyudovik" (also transcribed "Ludovic" or translated as "Ludwig") in place of "Lazar", possibly in honor of Francis Lodwick, who in 1652 had published an early conlang proposal. When his brother Leon became a doctor and started signing his name "Dr L. Zamenhof", Zamenhof reclaimed his birth name "Lazar" and from 1901 signed his name "Dr L. L. Zamenhof" to avoid confusion with his brother. The two L's do not seem to have specifically represented either name, and the order "Ludwik Lejzer" is a modern convention.

In 1905 Zamenhof received the Légion d'honneur for creating Esperanto. In 1910, Zamenhof was nominated for the Nobel Peace Prize, by four British Members of Parliament (including James O'Grady, Philip Snowden) and Professor Stanley Lane Poole. (The Prize was instead awarded to the International Peace Bureau.) On the occasion of the 5th Universala Kongreso de Esperanto in Barcelona, Zamenhof was made a Commander of the Order of Isabella the Catholic by King Alfonso XIII of Spain.

The minor planet 1462 Zamenhof is named in his honour. It was discovered on 6 February 1938, by Yrjö Väisälä. Hundreds of city streets, parks, and bridges worldwide have also been named after Zamenhof. In Lithuania, the best-known Zamenhof Street is in Kaunas, where he lived and owned a house for some time. There are others in Poland, the United Kingdom, France, Hungary, Croatia, the Czech Republic, Spain (mostly in Catalonia), Italy, Israel, Belgium and Brazil. There are Zamenhof Hills in Hungary and Brazil, and a Zamenhof Island in the Danube.

In some Israeli cities, street signs identify Esperanto's creator and give his birth and death dates, but refer to him solely by his Jewish name Eliezer (a variant of which, El'azar, is the origin of Lazarus). Zamenhof is honoured as a deity by the Japanese religion Oomoto, which encourages the use of Esperanto among its followers. Also, a genus of lichen has been named "Zamenhofia" in his honour.

Russian writer Nikolai Afrikanovich Borovko, who lived in Odessa, together with Vladimir Gernet, founded a branch of the first official Esperanto society Esrero in Russia. In the years 1896-97 N.A. Borovko became its chairman. Monument to L. Zamenhof installed in Odessa in an ordinary residential courtyard. Esperantist sculptor Nikolai Vasilyevich Blazhkov lived in this house, who in the early 60s brought a sculptural portrait into the courtyard, because the customs did not allow the sculpture to be sent to the Esperanto Congress in Vienna.

In Gothenburg, Sweden a public square is named Esperantoplatsen. 

In Italy, a few streets are named after Esperanto, including Largo Esperanto in Pisa.

In 1959, the UNESCO honoured Zamenhof in the occasion of his centenary. In 2015 it decided to support the celebration of the 100th anniversary of his death.

Zamenhof was nominated 12 times for the Nobel Peace Prize.

His birthday, 15 December, is celebrated annually as Zamenhof Day by users of Esperanto. On 15 December 2009, Esperanto's green-starred flag flew on the Google homepage to commemorate Zamenhof's 150th birthday.

The house of the Zamenhof family, dedicated to Ludwik Zamenhof, and the Białystok Esperanto Centre, are sites of the Jewish Heritage Trail in Białystok, which was opened in June 2008 by volunteers at The University of Białystok Foundation.

In 1960, Esperanto summer schools were established in Stoke-on-Trent in the United Kingdom by the Esperanto Association of Britain (EAB), which began to provide lessons and promote the language locally. There is a road named after Zamenhof in the city: Zamenhof Grove.

As Dr. Zamenhof was born on 15 December 1859, the Esperanto Society of New York gathers every December to celebrate Zamenhofa Tago (Zamenhof Day in Esperanto).

In Michael Chabon's alternate history novel "The Yiddish Policemen's Union", the main character lives in the Hotel Zamenhof, which uses Esperanto signage.






Biography of Zamenhof




</doc>
<doc id="18102" url="https://en.wikipedia.org/wiki?curid=18102" title="Linear map">
Linear map

In mathematics, a linear map (also called a linear mapping, linear transformation or, in some contexts, linear function) is a mapping between two modules (for example, two vector spaces) that preserves (in the sense defined below) the operations of addition and scalar multiplication. If a linear map is a bijection then it is called a linear isomorphism.

An important special case is when , in which case a linear map is called a (linear) "endomorphism" of . Sometimes the term linear operator refers to this case. In another convention, "linear operator" allows and to differ, while requiring them to be real vector spaces. Sometimes the term "linear function" has the same meaning as "linear map", while in analytic geometry it does not.

A linear map always maps linear subspaces onto linear subspaces (possibly of a lower dimension); for instance it maps a plane through the origin to a plane, straight line or point. Linear maps can often be represented as matrices, and simple examples include rotation and reflection linear transformations.

In the language of abstract algebra, a linear map is a module homomorphism. In the language of category theory, it is a morphism in the category of modules over a given ring.

Let and be vector spaces over the same field . 
A function is said to be a "linear map" if for any two vectors formula_1 and any scalar the following two conditions are satisfied:

Thus, a linear map is said to be "operation preserving". 
In other words, it does not matter whether the linear map is applied before (the right hand sides of the above examples) or after (the left hand sides of the examples) the operations of addition and scalar multiplication.

By the associativity of the addition operation denoted as +, for any vectors formula_2 and scalars formula_3 the following equality holds:

Denoting the zero elements of the vector spaces and by formula_5 and formula_6 respectively, it follows that formula_7 
Let and formula_8 in the equation for homogeneity of degree 1:

Occasionally, and can be vector spaces over different fields. 
It is then necessary to specify which of these ground fields is being used in the definition of "linear". 
If and are spaces over the same field as above, then we talk about -linear maps. 
For example, the conjugation of complex numbers is an ℝ-linear map ℂ → ℂ, but it is not ℂ-linear, where ℝ and ℂ are symbols representing the sets of real numbers and complex numbers, respectively.

A linear map with viewed as a one-dimensional vector space over itself is called a linear functional.

These statements generalize to any left-module formula_10 over a ring without modification, and to any right-module upon reversing of the scalar multiplication.


If "V" and "W" are finite-dimensional vector spaces and a basis is defined for each vector space, then every linear map from "V" to "W" can be represented by a matrix. This is useful because it allows concrete calculations. Matrices yield examples of linear maps: if "A" is a real matrix, then describes a linear map (see Euclidean space).

Let {v, …, v} be a basis for "V". Then every vector v in "V" is uniquely determined by the coefficients "c", …, "c" in the field R:

If is a linear map,

which implies that the function "f" is entirely determined by the vectors "f"(v), …, "f"(v). Now let be a basis for "W". Then we can represent each vector "f"(v) as

Thus, the function "f" is entirely determined by the values of "a". If we put these values into an matrix "M", then we can conveniently use it to compute the vector output of "f" for any vector in "V". To get "M", every column "j" of "M" is a vector

corresponding to "f"(v) as defined above. To define it more clearly, for some column "j" that corresponds to the mapping "f"(v),

where M is the matrix of "f". In other words, every column has a corresponding vector "f"(v) whose coordinates "a", …, "a" are the elements of column "j". A single linear map may be represented by many matrices. This is because the values of the elements of a matrix depend on the bases chosen.

The matrices of a linear transformation can be represented visually:


Such that starting in the bottom left corner formula_32 and looking for the bottom right corner formula_33, one would left-multiply—that is, formula_34. The equivalent method would be the "longer" method going clockwise from the same point such that formula_32 is left-multiplied with formula_36, or formula_37.

In two-dimensional space R linear maps are described by 2 × 2 real matrices. These are some examples:


The composition of linear maps is linear: if and are linear, then so is their composition . 
It follows from this that the class of all vector spaces over a given field "K", together with "K"-linear maps as morphisms, forms a category.

The inverse of a linear map, when defined, is again a linear map.

If and are linear, then so is their pointwise sum (which is defined by .

If is linear and "a" is an element of the ground field "K", then the map , defined by , is also linear.

Thus the set of linear maps from "V" to "W" itself forms a vector space over "K", sometimes denoted . 
Furthermore, in the case that , this vector space (denoted ) is an associative algebra under composition of maps, since the composition of two linear maps is again a linear map, and the composition of maps is always associative. 
This case is discussed in more detail below.

Given again the finite-dimensional case, if bases have been chosen, then the composition of linear maps corresponds to the matrix multiplication, the addition of linear maps corresponds to the matrix addition, and the multiplication of linear maps with scalars corresponds to the multiplication of matrices with scalars.

A linear transformation "f": "V" → "V" is an endomorphism of "V"; the set of all such endomorphisms End("V") together with addition, composition and scalar multiplication as defined above forms an associative algebra with identity element over the field "K" (and in particular a ring). The multiplicative identity element of this algebra is the identity map id: "V" → "V".

An endomorphism of "V" that is also an isomorphism is called an automorphism of "V". The composition of two automorphisms is again an automorphism, and the set of all automorphisms of "V" forms a group, the automorphism group of "V" which is denoted by Aut("V") or GL("V"). Since the automorphisms are precisely those endomorphisms which possess inverses under composition, Aut("V") is the group of units in the ring End("V").

If "V" has finite dimension "n", then End("V") is isomorphic to the associative algebra of all "n" × "n" matrices with entries in "K". The automorphism group of "V" is isomorphic to the general linear group GL("n", "K") of all "n" × "n" invertible matrices with entries in "K".

If "f" : "V" → "W" is linear, we define the kernel and the image or range of "f" by

ker("f") is a subspace of "V" and im("f") is a subspace of "W". The following dimension formula is known as the rank–nullity theorem:

The number dim(im("f")) is also called the "rank of f" and written as rank("f"), or sometimes, ρ("f"); the number dim(ker("f")) is called the "nullity of f" and written as null("f") or ν("f"). If "V" and "W" are finite-dimensional, bases have been chosen and "f" is represented by the matrix "A", then the rank and nullity of "f" are equal to the rank and nullity of the matrix "A", respectively.

A subtler invariant of a linear transformation formula_50 is the "co"kernel, which is defined as

This is the "dual" notion to the kernel: just as the kernel is a "sub"space of the "domain," the co-kernel is a "quotient" space of the "target."
Formally, one has the exact sequence

These can be interpreted thus: given a linear equation "f"(v) = w to solve,


The dimension of the co-kernel and the dimension of the image (the rank) add up to the dimension of the target space. For finite dimensions, this means that the dimension of the quotient space "W"/"f"("V") is the dimension of the target space minus the dimension of the image.

As a simple example, consider the map "f": R → R, given by "f"("x", "y") = (0, "y"). Then for an equation "f"("x", "y") = ("a", "b") to have a solution, we must have "a" = 0 (one constraint), and in that case the solution space is ("x", "b") or equivalently stated, (0, "b") + ("x", 0), (one degree of freedom). The kernel may be expressed as the subspace ("x", 0) < "V": the value of "x" is the freedom in a solution – while the cokernel may be expressed via the map "W" → R, formula_53 given a vector ("a", "b"), the value of "a" is the "obstruction" to there being a solution.

An example illustrating the infinite-dimensional case is afforded by the map "f": R → R, formula_54 with "b" = 0 and "b" = "a" for "n" > 0. Its image consists of all sequences with first element 0, and thus its cokernel consists of the classes of sequences with identical first element. Thus, whereas its kernel has dimension 0 (it maps only the zero sequence to the zero sequence), its co-kernel has dimension 1. Since the domain and the target space are the same, the rank and the dimension of the kernel add up to the same sum as the rank and the dimension of the co-kernel ( formula_55 ), but in the infinite-dimensional case it cannot be inferred that the kernel and the co-kernel of an endomorphism have the same dimension (0 ≠ 1). The reverse situation obtains for the map "h": R → R, formula_56 with "c" = "a". Its image is the entire target space, and hence its co-kernel has dimension 0, but since it maps all sequences in which only the first element is non-zero to the zero sequence, its kernel has dimension 1.

For a linear operator with finite-dimensional kernel and co-kernel, one may define "index" as:

namely the degrees of freedom minus the number of constraints.

For a transformation between finite-dimensional vector spaces, this is just the difference dim("V") − dim("W"), by rank–nullity. This gives an indication of how many solutions or how many constraints one has: if mapping from a larger space to a smaller one, the map may be onto, and thus will have degrees of freedom even without constraints. Conversely, if mapping from a smaller space to a larger one, the map cannot be onto, and thus one will have constraints even without degrees of freedom.

The index of an operator is precisely the Euler characteristic of the 2-term complex 0 → "V" → "W" → 0. In operator theory, the index of Fredholm operators is an object of study, with a major result being the Atiyah–Singer index theorem.

No classification of linear maps could hope to be exhaustive. The following incomplete list enumerates some important classifications that do not require any additional structure on the vector space.

Let and denote vector spaces over a field and let be a linear map.

Definition: is said to be "injective" or a "monomorphism" if any of the following equivalent conditions are true:

Definition: is said to be "surjective" or an "epimorphism" if any of the following equivalent conditions are true:

Definition: is said to be an "isomorphism" if it is both left- and right-invertible. This is equivalent to being both one-to-one and onto (a bijection of sets) or also to being both epic and monic, and so being a bimorphism.

If is an endomorphism, then:

Given a linear map which is an endomorphism whose matrix is "A", in the basis "B" of the space it transforms vector coordinates [u] as [v] = "A"[u]. As vectors change with the inverse of "B" (vectors are contravariant) its inverse transformation is [v] = "B"[v'].

Substituting this in the first expression

hence

Therefore, the matrix in the new basis is "A′" = "B""AB", being "B" the matrix of the given basis.

Therefore, linear maps are said to be 1-co- 1-contra-variant objects, or type (1, 1) tensors.

A "linear transformation" between topological vector spaces, for example normed spaces, may be continuous. 
If its domain and codomain are the same, it will then be a continuous linear operator. 
A linear operator on a normed linear space is continuous if and only if it is bounded, for example, when the domain is finite-dimensional. 
An infinite-dimensional domain may have discontinuous linear operators.

An example of an unbounded, hence discontinuous, linear transformation is differentiation on the space of smooth functions equipped with the supremum norm (a function with small values can have a derivative with large values, while the derivative of 0 is 0). 
For a specific example, converges to 0, but its derivative does not, so differentiation is not continuous at 0 (and by a variation of this argument, it is not continuous anywhere).

A specific application of linear maps is for geometric transformations, such as those performed in computer graphics, where the translation, rotation and scaling of 2D or 3D objects is performed by the use of a transformation matrix. Linear mappings also are used as a mechanism for describing change: for example in calculus correspond to derivatives; or in relativity, used as a device to keep track of the local transformations of reference frames.

Another application of these transformations is in compiler optimizations of nested-loop code, and in parallelizing compiler techniques.




</doc>
<doc id="18103" url="https://en.wikipedia.org/wiki?curid=18103" title="Leyden jar">
Leyden jar

A Leyden jar (or Leiden jar) is an antique electrical component which stores a high-voltage electric charge (from an external source) between electrical conductors on the inside and outside of a glass jar. It typically consists of a glass jar with metal foil cemented to the inside and the outside surfaces, and a metal terminal projecting vertically through the jar lid to make contact with the inner foil. It was the original form of the capacitor (also called "condenser").

Its invention was a discovery made independently by German cleric Ewald Georg von Kleist on 11 October 1745 and by Dutch scientist Pieter van Musschenbroek of Leiden (Leyden) in 1745–1746. The invention was named after the city.

The Leyden jar was used to conduct many early experiments in electricity, and its discovery was of fundamental importance in the study of electrostatics. It was the first means of accumulating and preserving electric charge in large quantities that could be discharged at the experimenter's will, thus overcoming a significant limit to early research into electrical conduction. Leyden jars are still used in education to demonstrate the principles of electrostatics.

The Ancient Greeks already knew that pieces of amber could attract lightweight particles after being rubbed. The amber becomes electrified by triboelectric effect, mechanical separation of charge in a dielectric. The Greek word for amber is ἤλεκτρον ("ēlektron") and is the origin of the word "electricity".

Around 1650, Otto von Guericke built a crude electrostatic generator: a sulphur ball that rotated on a shaft. When Guericke held his hand against the ball and turned the shaft quickly, a static electric charge built up. This experiment inspired the development of several forms of "friction machines", that greatly helped in the study of electricity.

The Leyden jar was effectively discovered independently by two parties: German deacon Ewald Georg von Kleist, who made the first discovery, and Dutch scientists Pieter van Musschenbroek and Andreas Cunaeus, who figured out how it worked only when held in the hand.

The Leyden jar is a high voltage device; it is estimated that at a maximum the early Leyden jars could be charged to 20,000 to 60,000 volts. The center rod electrode has a metal ball on the end to prevent leakage of the charge into the air by corona discharge. It was first used in electrostatics experiments, and later in high voltage equipment such as spark gap radio transmitters and electrotherapy machines. 

Ewald Georg von Kleist discovered the immense storage capability of the Leyden jar while working under a theory that saw electricity as a fluid, and hoped a glass jar filled with alcohol would "capture" this fluid. He was the deacon at the cathedral of Camin in Pomerania.

In October 1745 von Kleist tried to accumulate electricity in a small medicine bottle filled with alcohol with a nail inserted in the cork. He was following up on an experiment developed by Georg Matthias Bose where electricity had been sent through water to set alcoholic spirits alight. He attempted to charge the bottle from a large prime conductor (invented by Bose) suspended above his friction machine.

Kleist was convinced that a substantial electric charge could be collected and held within the glass which he knew would provide an obstacle to the escape of the 'fluid'. He received a significant shock from the device when he accidentally touched the nail through the cork while still cradling the bottle in his other hand. He communicated his results to at least five different electrical experimenters, in several letters from November 1745 to March 1746, but did not receive any confirmation that they had repeated his results, until April 1746. Daniel Gralath learned about Kleist's experiment from seeing the letter to Paul Swietlicki, written in November 1745. After Gralath's failed first attempt to reproduce the experiment in December 1745, he wrote to Kleist for more information (and was told that the experiment would work better if the tube half-filled with alcohol was used). Gralath (in collaboration with ) succeeded in getting the intended effect on 5 March 1746, holding a small glass medicine bottle with a nail inside in one hand, moving it close to an electrostatic generator, and then moving the other hand close to the nail. Kleist didn't understand the significance of his conducting hand holding the bottle—and both he and his correspondents were loath to hold the device when told that the shock could throw them across the room. It took some time before Kleist's student associates at Leyden worked out that the hand provided an essential element.

The Leyden jar's invention was long credited to Pieter van Musschenbroek, the physics professor at University of Leiden, who also ran a family foundry which cast brass cannonettes, and a small business ("De Oosterse Lamp" – "The Eastern Lamp") which made scientific and medical instruments for the new university courses in physics and for scientific gentlemen keen to establish their own 'cabinets' of curiosities and instruments.

Like Kleist, Musschenbroek was also interested in and attempting to repeat Bose's experiment. During this time, Andreas Cunaeus, a lawyer, came to learn about this experiment from visiting Musschenbroek's laboratory and Cunaeus attempted to duplicate the experiment at home with household items. Using a glass of beer, Cunaeus was unable to make it work. Cunaeus was the first to discover that the experimental setup could deliver a severe shock when he held his jar in his hand while charging it rather than placing it on an insulated stand, not realising that was the standard practice, thus making himself part of the circuit. He reported his procedure and experience to Allamand, Musschenbroek's colleague. Allamand and Musschenbroek also received severe shocks. Musschenbroek communicated the experiment in a letter from 20 January 1746 to René Antoine Ferchault de Réaumur, who was Musschenbroek's appointed correspondent at the Paris Academy. Abbé Nollet read this report, confirmed the experiment, and then read Musschenbroek's letter in a public meeting of the Paris Academy in April 1746 (translating from Latin to French). 
Musschenbroek's outlet in France for the sale of his company's 'cabinet' devices was the Abbé Nollet (who started building and selling duplicate instruments in 1735). Nollet then gave the electrical storage device the name "Leyden jar" and promoted it as a special type of flask to his market of wealthy men with scientific curiosity.
The "Kleistian jar" was therefore promoted as the "Leyden jar", and as having been discovered by Pieter van Musschenbroek and his acquaintance Andreas Cunaeus. Musschenbroek, however, never claimed that he had invented it, and some think that Cunaeus was mentioned only to diminish credit to him.

Within months after Musschenbroek's report about how to reliably create a Leyden jar, other electrical researchers were making and experimenting with their own Leyden jars. One interest was to see if the total possible charge could be increased. Johann Heinrich Winckler, whose first experience with a single Leyden jar was reported in a letter to the Royal Society on 29 May 1746, had connected three Leyden jars together in a kind of electrostatic battery on 28 July 1746. Daniel Gralath reported in 1747 that in 1746 he had conducted experiments with connecting two or three jars, probably in series. In 1748, Benjamin Franklin developed a system involving 11 panes of glass with thin lead plates glued on each side, and then connected together. He used the term "electrical battery" to describe his electrostatic battery in a 1749 letter about his electrical research in 1748. It is possible that Franklin's choice of the word "battery" was inspired by the humorous wordplay at the conclusion of his letter, where he wrote, among other things, about a salute to electrical researchers from a battery of guns. This is the first recorded use of the term "electrical battery". The multiple and rapid developments for connecting Leyden jars during the period 1746–1748 resulted in a variety of divergent accounts in secondary literature about who made the first "battery" by connecting Leyden jars, whether they were in series or parallel, and who first used the term "battery". The term was later used for combinations of multiple electrochemical cells, the modern meaning of the term "battery".

Starting in late 1756, Franz Aepinus, in a complicated interaction of cooperation and independent work with Johan Wilcke, developed an "air condenser", a variation on the Leyden jar, by using air rather than glass as the dielectric. This functioning apparatus, without glass, created a problem for Benjamin Franklin's explanation of the Leyden jar, which maintained that the charge was located in the glass.

Beginning in the late 18th century it was used in the Victorian medical field of electrotherapy to treat a variety of diseases by electric shock. By the middle of the 19th century, the Leyden jar had become common enough for writers to assume their readers knew of and understood its basic operation. Around the turn of the century it began to be widely used in spark-gap transmitters and medical electrotherapy equipment. By the early 20th century, improved dielectrics and the need to reduce their size and undesired inductance and resistance for use in the new technology of radio caused the Leyden jar to evolve into the modern compact form of capacitor.

A typical design consists of a glass jar with conducting tin foil coating the inner and outer surfaces. The foil coatings stop short of the mouth of the jar, to prevent the charge from arcing between the foils. A metal rod electrode projects through the stopper at the mouth of the jar, electrically connected by some means (usually a hanging chain) to the inner foil, to allow it to be charged. The jar is charged by an electrostatic generator, or other source of electric charge, connected to the inner electrode while the outer foil is grounded. The inner and outer surfaces of the jar store equal but opposite charges.

The original form of the device is just a glass bottle partially filled with water, with a metal wire passing through a cork closing it. The role of the outer plate is provided by the hand of the experimenter. Soon John Bevis found (in 1747) that it was possible to coat the exterior of the jar with metal foil, and he also found that he could achieve the same effect by using a plate of glass with metal foil on both sides. These developments inspired William Watson in the same year to have a jar made with a metal foil lining both inside and outside, dropping the use of water.

Early experimenters (such as Benjamin Wilson in 1746) reported that the thinner the dielectric and the greater the surface, the greater the charge that could be accumulated.

Further developments in electrostatics revealed that the dielectric material was not essential, but increased the storage capability (capacitance) and prevented arcing between the plates. Two plates separated by a small distance also act as a capacitor, even in a vacuum.
It was initially believed that the charge was stored in the water in early Leyden jars. In the 1700s American statesman and scientist Benjamin Franklin performed extensive investigations of both water-filled and foil Leyden jars, which led him to conclude that the charge was stored in the glass, not in the water. A popular experiment, due to Franklin, which seems to demonstrate this involves taking a jar apart after it has been charged and showing that little charge can be found on the metal plates, and therefore it must be in the dielectric. The first documented instance of this demonstration is in a 1749 letter by Franklin. Franklin designed a "dissectible" Leyden jar "(right)", which was widely used in demonstrations. The jar is constructed out of a glass cup nested between two fairly snugly fitting metal cups. When the jar is charged with a high voltage and carefully dismantled, it is discovered that all the parts may be freely handled without discharging the jar. If the pieces are re-assembled, a large spark may still be obtained from it.

This demonstration appears to suggest that capacitors store their charge inside their dielectric. This theory was taught throughout the 1800s. However, this phenomenon is a special effect caused by the high voltage on the Leyden jar. In the dissectible Leyden jar, charge is transferred to the surface of the glass cup by corona discharge when the jar is disassembled; this is the source of the residual charge after the jar is reassembled. Handling the cup while disassembled does not provide enough contact to remove all the surface charge. Soda glass is hygroscopic and forms a partially conductive coating on its surface, which holds the charge. Addenbrooke (1922) found that in a dissectible jar made of paraffin wax, or glass baked to remove moisture, the charge remained on the metal plates. Zeleny (1944) confirmed these results and observed the corona charge transfer.

Originally, the amount of capacitance was measured in number of 'jars' of a given size, or through the total coated area, assuming reasonably standard thickness and composition of the glass. A typical Leyden jar of one pint size has a capacitance of about 1 nF.

If a charged Leyden jar is discharged by shorting the inner and outer coatings and left to sit for a few minutes, the jar will recover some of its previous charge, and a second spark can be obtained from it. Often this can be repeated, and a series of 4 or 5 sparks, decreasing in length, can be obtained at intervals. This effect is caused by dielectric absorption.

In 1747–1748, Benjamin Franklin experimented with charging Leyden jars in series.




</doc>
<doc id="18109" url="https://en.wikipedia.org/wiki?curid=18109" title="Lennon Wall">
Lennon Wall

The Lennon Wall or John Lennon Wall is a wall in Prague, Czechia. Since the 1980s this once typical wall has been filled with John Lennon-inspired graffiti, lyrics from Beatles' songs, and designs relating to local and global causes.

Located in a small and secluded square across from the French Embassy, the wall had been decorated by love poems and short messages against the regime since 1960s. It received its first decoration connected to John Lennon, a symbol of freedom, western culture, and political struggle, following the 1980 assassination of John Lennon when an unknown artist painted a single image of the singer-songwriter and some lyrics.

In 1988, the wall was a source of irritation for Gustáv Husák's communist regime. Following a short-lived era of democratization and political liberalization known as the Prague Spring, the newly-installed communist government dismantled the reforms, inspiring anger and resistance. Young Czechs wrote their grievances on the wall and, according to a report of the time, this led to a clash between hundreds of students and security police on the nearby Charles Bridge. The liberalization movement these students followed was described as "Lennonism" (not to be confused with "Leninism"), and Czech authorities described participants variously as alcoholic, mentally deranged, sociopathic, and agents of Western free market capitalism.

The wall continuously undergoes change, and the original portrait of Lennon is long lost under layers of new paint. Even when the wall was repainted by authorities, by the next day it was again full of poems and flowers. Today, the wall represents a symbol of global ideals such as love and peace.

The wall is owned by the Sovereign Military Order of Malta, which allowed the graffiti, and is located at "Velkopřevorské náměstí" (Grand Priory Square), Malá Strana.

On 17 November 2014, the 25th anniversary of the Velvet Revolution, the wall was painted over in pure white by a group of art students, leaving only the text "wall is over" . The Knights of Malta initially filed a criminal complaint for vandalism against the students, which they later retracted after contacting them.
The wall mural is still there as of 23 July 2017. And the "Wall is Over" bit has been changed to "War Is Over", a song.

On 22 April 2019, Earth Day, the action group Extinction Rebellion repainted the entire wall with slogans demanding action from the Czech government on climate change. "KLIMATICKÁ NOUZE" was painted in large block print letters, which reads "climate emergency" in the Czech language. Members of the public were encouraged to add their own messages during the process, resulting in calls for action painted in several languages. A giant image of a skull was also painted. The repaint was carried out in a manner which allowed some of the existing artwork to be included on the new wall.

In July 2019, artists painted a memorial on the wall for Hong Kong democracy activist Marco Leung Ling-kit, who became known as a martyr and a symbol of hope for the 2019 anti-extradition bill protest movement. The image on the wall depicts the yellow raincoat he was wearing during the banner drop that eventually led to a fall from the building, along with some words of solidarity: "Hong Kong, Add oil."

On 4 August 2019 it was reported that the wall will be put under CCTV surveillance to block "unlawful graffiti" and combat the swaths of tourists that pass by it every day.

In October 2019, the Sovereign Military Order of Malta together with Prague 1 started the reconstruction of the Lennon Wall which lasted until November. They reacted thus to the recent situation of vandalism on the Wall and its surroundings connected to the overtourism which became unbearable this summer. The place should regain its respectable form which was going to be introduced on the occasion of the 30th anniversary of the Velvet Revolution in November as an open-air gallery with new rules. On 7 November 2019, the new face of the Lennon Wall as an open-air gallery was created and introduced to the public. Over 30 Czech and foreign professional artists gathered by the Czech designer Pavel Šťastný painted on the Wall. New rules of the Wall makes spraying no longer allowed, people can leave their messages connected to freedom and love only in the white free zones andy in more sensitive materials than sprays, e.g. pencil, marker or chalk. Cameras and police will monitor the wall to ensure the artistic portion is not defaced.

During the 2014 democracy protests in Hong Kong, a similar Lennon Wall appeared along the staircase outside of the Hong Kong Central Government Offices. Inspired by the original in Prague, many thousands of people posted colourful post-it notes expressing democratic wishes for Hong Kong. The wall was one of the major arts of the Umbrella Movement. Throughout the several months of occupations and protest, many efforts were made by different groups to ensure physical and digital preservation of the Hong Kong Lennon Wall.

Five years later, during the 2019–20 Hong Kong protests, the same wall was again created, with new post-it notes. Within days, dozens of post-it-note Lennon Walls had "blossomed everywhere" (遍地開花) throughout Hong Kong, including on Hong Kong Island itself, Kowloon, the New Territories, and on the many outlying islands. There are even some Lennon Walls located inside government offices, including RTHK and the Policy Innovation and Co-ordination Office. According to a crowd-sourced map of Hong Kong, there are over 150 Lennon Walls throughout the region.

On 21 September 2019, police in Hong Kong began tearing down Lennon Walls across the city to remove anti-government statements.

Lennon Walls have also appeared outside of Hong Kong in the cities of: Toronto, Vancouver BC, Calgary, Seoul, Tokyo, Berlin, London, Sydney, Manchester, Melbourne, Taipei, and Auckland.




</doc>
<doc id="18110" url="https://en.wikipedia.org/wiki?curid=18110" title="Los Angeles">
Los Angeles

Los Angeles (; ; ), officially the City of Los Angeles and often known by its initials L.A., is the largest city in California. With an estimated population of nearly four million people, it is the second-most populous city in the United States (after New York City) and the third-most populous city in North America (after Mexico City and New York City). Los Angeles is known for its Mediterranean climate, ethnic diversity, Hollywood entertainment industry, and its sprawling metropolis.

Los Angeles lies in a basin in Southern California, adjacent to the Pacific Ocean, with mountains as high as , and deserts. The city, which covers about , is the seat of Los Angeles County, the most populous county in the United States. The Los Angeles metropolitan area (MSA) is home to 13.1 million people, making it the second-largest metropolitan area in the nation after New York. Greater Los Angeles includes metro Los Angeles as well as the Inland Empire and Ventura County. It is the second-most populous U.S. combined statistical area, also after New York, with a 2015 estimate of 18.7 million people.

Home to the Chumash and Tongva, Los Angeles was claimed by Juan Rodríguez Cabrillo for Spain in 1542. The city was founded on September 4, 1781, by Spanish governor Felipe de Neve. It became a part of Mexico in 1821 following the Mexican War of Independence. In 1848, at the end of the Mexican–American War, Los Angeles and the rest of California were purchased as part of the Treaty of Guadalupe Hidalgo, and thus became part of the United States. Los Angeles was incorporated as a municipality on April 4, 1850, five months before California achieved statehood. The discovery of oil in the 1890s brought rapid growth to the city. The city was further expanded with the completion of the Los Angeles Aqueduct in 1913, which delivers water from Eastern California.

Los Angeles has a diverse economy and hosts businesses in a broad range of professional and cultural fields. It also has the busiest container port in the Americas. The Los Angeles metropolitan area also has a gross metropolitan product of $1.0 trillion (), making it the third-largest city by GDP in the world, after the Tokyo and New York City metropolitan areas. Los Angeles hosted the 1932 and 1984 Summer Olympics and will host the 2028 Summer Olympics.

The Los Angeles coastal area was settled by the Tongva ("Gabrieleños") and Chumash tribes. A Gabrieleño settlement in the area was called "iyáangẚ" (written "Yang-na" by the Spanish), meaning "poison oak place".

Maritime explorer Juan Rodríguez Cabrillo claimed the area of southern California for the Spanish Empire in 1542 while on an official military exploring expedition moving north along the Pacific coast from earlier colonizing bases of New Spain in Central and South America. Gaspar de Portolà and Franciscan missionary Juan Crespí, reached the present site of Los Angeles on August 2, 1769.

In 1771, Franciscan friar Junípero Serra directed the building of the Mission San Gabriel Arcángel, the first mission in the area. On September 4, 1781, a group of forty-four settlers known as "Los Pobladores" founded the pueblo they called . The present-day city has the largest Roman Catholic archdiocese in the United States. Two-thirds of the Mexican or (New Spain) settlers were mestizo or mulatto, a mixture of African, indigenous and European ancestry. The settlement remained a small ranch town for decades, but by 1820, the population had increased to about 650 residents. Today, the pueblo is commemorated in the historic district of Los Angeles Pueblo Plaza and Olvera Street, the oldest part of Los Angeles.

New Spain achieved its independence from the Spanish Empire in 1821, and the pueblo continued as a part of Mexico. During Mexican rule, Governor Pío Pico made Los Angeles Alta California's regional capital.

Mexican rule ended during the Mexican–American War: Americans took control from the Californios after a series of battles, culminating with the signing of the Treaty of Cahuenga on January 13, 1847.

Railroads arrived with the completion of the transcontinental Southern Pacific line to Los Angeles in 1876 and the Santa Fe Railroad in 1885. Petroleum was discovered in the city and surrounding area in 1892, and by 1923, the discoveries had helped California become the country's largest oil producer, accounting for about one-quarter of the world's petroleum output.

By 1900, the population had grown to more than 102,000, putting pressure on the city's water supply. The completion of the Los Angeles Aqueduct in 1913, under the supervision of William Mulholland, ensured the continued growth of the city. Because of clauses in the city's charter that prevented the City of Los Angeles from selling or providing water from the aqueduct to any area outside its borders, many adjacent cities and communities felt compelled to annex themselves into Los Angeles.

Los Angeles created the first municipal zoning ordinance in the United States. On September 14, 1908, the Los Angeles City Council promulgated residential and industrial land use zones. The new ordinance established three residential zones of a single type, where industrial uses were prohibited. The proscriptions included barns, lumber yards, and any industrial land use employing machine-powered equipment. These laws were enforced against industrial properties after-the-fact. These prohibitions were in addition to existing activities that were already regulated as nuisances. These included explosives warehousing, gas works, oil-drilling, slaughterhouses, and tanneries. Los Angeles City Council also designated seven industrial zones within the city. However, between 1908 and 1915, Los Angeles City Council created various exceptions to the broad proscriptions that applied to these three residential zones, and as a consequence, some industrial uses emerged within them. There are two differences from the 1908 Residence District Ordinance and later zoning laws in the United States. First, the 1908 laws did not establish a comprehensive zoning map as the 1916 New York City Zoning Ordinance did. Second, the residential zones did not distinguish types of housing; it treated apartments, hotels, and detached-single-family housing equally.

In 1910, Hollywood merged into Los Angeles, with 10 movie companies already operating in the city at the time. By 1921, more than 80 percent of the world's film industry was concentrated in LA. The money generated by the industry kept the city insulated from much of the economic loss suffered by the rest of the country during the Great Depression.

By 1930, the population surpassed one million. In 1932, the city hosted the Summer Olympics.

During World War II, Los Angeles was a major center of wartime manufacturing, such as shipbuilding and aircraft. Calship built hundreds of Liberty Ships and Victory Ships on Terminal Island, and the Los Angeles area was the headquarters of six of the country's major aircraft manufacturers (Douglas Aircraft Company, Hughes Aircraft, Lockheed, North American Aviation, Northrop Corporation, and Vultee). During the war, more aircraft were produced in one year than in all the pre-war years since the Wright brothers flew the first airplane in 1903, combined. Manufacturing in Los Angeles skyrocketed, and as William S. Knudsen, of the National Defense Advisory Commission put it, "We won because we smothered the enemy in an avalanche of production, the like of which he had never seen, nor dreamed possible."

Following the end of World War II, Los Angeles grew more rapidly than ever, sprawling into the San Fernando Valley. The expansion of the Interstate Highway System during the 1950s and 1960s helped propel suburban growth and signaled the demise of the city's electrified rail system, once the world's largest.

Previous to the 1950s, Los Angeles' name had multiple pronunciations, but the soft "G" pronunciation is universal today. Some early movies or video shows it pronounced with a hard "G" (). Sam Yorty was one of the last public figures who still used the hard "G" pronunciation.

Racial tensions led to the Watts riots in 1965, resulting in 34 deaths and over 1,000 injuries.

In 1969, California became the birthplace of the Internet, as the first ARPANET transmission was sent from the University of California, Los Angeles (UCLA) to the Stanford Research Institute in Menlo Park.

In 1973, Tom Bradley was elected as the city's first African American mayor, serving for five terms until retiring in 1993. Other events in the city during the 1970s included the Symbionese Liberation Army's South Central standoff in 1974 and the Hillside Stranglers murder cases in 1977–1978.

In 1984, the city hosted the Summer Olympic Games for the second time. Despite being boycotted by 14 Communist countries, the 1984 Olympics became more financially successful than any previous, and the second Olympics to turn a profit until then–the other, according to an analysis of contemporary newspaper reports, being the 1932 Summer Olympics, also held in Los Angeles.

Racial tensions erupted on April 29, 1992, with the acquittal by a Simi Valley jury of four Los Angeles Police Department (LAPD) officers captured on videotape beating Rodney King, culminating in large-scale riots.

In 1994, the 6.7 Northridge earthquake shook the city, causing $12.5 billion in damage and 72 deaths. The century ended with the Rampart scandal, one of the most extensive documented cases of police misconduct in American history.

In 2002, Mayor James Hahn led the campaign against secession, resulting in voters defeating efforts by the San Fernando Valley and Hollywood to secede from the city.

Los Angeles will host the 2028 Summer Olympics and Paralympic Games, making Los Angeles the third city to host the Olympics three times.

The city of Los Angeles covers a total area of , comprising of land and of water. The city extends for north-south and for east-west. The perimeter of the city is .

Los Angeles is both flat and hilly. The highest point in the city proper is Mount Lukens at , located at the northeastern end of the San Fernando Valley. The eastern end of the Santa Monica Mountains stretches from Downtown to the Pacific Ocean and separates the Los Angeles Basin from the San Fernando Valley. Other hilly parts of Los Angeles include the Mt. Washington area north of Downtown, eastern parts such as Boyle Heights, the Crenshaw district around the Baldwin Hills, and the San Pedro district.

Surrounding the city are much higher mountains. Immediately to the north lie the San Gabriel Mountains, which is a popular recreation area for Angelenos. Its high point is Mount San Antonio, locally known as Mount Baldy, which reaches . Further afield, the highest point in the Greater Los Angeles area is San Gorgonio Mountain, with a height of .

The Los Angeles River, which is largely seasonal, is the primary drainage channel. It was straightened and lined in of concrete by the Army Corps of Engineers to act as a flood control channel. The river begins in the Canoga Park district of the city, flows east from the San Fernando Valley along the north edge of the Santa Monica Mountains, and turns south through the city center, flowing to its mouth in the Port of Long Beach at the Pacific Ocean. The smaller Ballona Creek flows into the Santa Monica Bay at Playa del Rey.

Los Angeles is rich in native plant species partly because of its diversity of habitats, including beaches, wetlands, and mountains. The most prevalent plant communities are coastal sage scrub, chaparral shrubland, and riparian woodland. Native plants include: the California poppy, matilija poppy, toyon, Ceanothus, Chamise, Coast Live Oak, sycamore, willow and Giant Wildrye. Many of these native species, such as the Los Angeles sunflower, have become so rare as to be considered endangered. Although it is not native to the area, the official tree of Los Angeles is the Coral Tree ("Erythrina caffra") and the official flower of Los Angeles is the Bird of Paradise ("Strelitzia reginae"). Mexican Fan Palms, Canary Island Palms, Queen Palms, Date Palms, and California Fan Palms are common in the Los Angeles area, although only the last is native.

Los Angeles is subject to earthquakes because of its location on the Pacific Ring of Fire. The geologic instability has produced numerous faults, which cause approximately 10,000 earthquakes annually in Southern California, though most of them are too small to be felt. The strike-slip San Andreas Fault system is at the boundary between the Pacific Plate and the North American Plate, and is vulnerable to the "big one", a potentially large and damaging event after the San Francisco earthquake in 1906. The Los Angeles basin and metropolitan area are also at risk from blind thrust earthquakes. Major earthquakes that have hit the Los Angeles area include the 1933 Long Beach, 1971 San Fernando, 1987 Whittier Narrows, and the 1994 Northridge events. All but a few are of low intensity and are not felt. The USGS has released the UCERF California earthquake forecast, which models earthquake occurrence in California. Parts of the city are also vulnerable to tsunamis; harbor areas were damaged by waves from Aleutian Islands earthquake in 1946, Valdivia earthquake in 1960, Alaska earthquake in 1964, Chile earthquake in 2010 and Japan earthquake in 2011.

The city is divided into many different districts and neighborhoods, some of which were incorporated cities that merged with Los Angeles. These neighborhoods were developed piecemeal, and are well-defined enough that the city has signage marking nearly all of them.

The city's street patterns generally follow a grid plan, with uniform block lengths and occasional roads that cut across blocks. However, this is complicated by rugged terrain, which has necessitated having different grids for each of the valleys that Los Angeles covers. Major streets are designed to move large volumes of traffic through many parts of the city, many of which are extremely long; Sepulveda Boulevard is long, while Foothill Boulevard is over long, reaching as far east as San Bernardino. Drivers in Los Angeles suffer from one of the worst rush hour periods in the world, according to an annual traffic index by navigation system maker, TomTom. LA drivers spend an additional 92 hours in traffic each year. During the peak rush hour there is 80% congestion, according to the index.

Los Angeles is often characterized by the presence of low-rise buildings. Outside of a few centers such as Downtown, Warner Center, Century City, Koreatown, Miracle Mile, Hollywood, and Westwood, skyscrapers and high-rise buildings are not common. The few skyscrapers built outside of those areas often stand out above the rest of the surrounding landscape. Most construction is done in separate units, rather than wall-to-wall. That being said, Downtown Los Angeles itself has many buildings over 30 stories, with fourteen over 50 stories, and two over 70 stories, the tallest of which is the Wilshire Grand Center. Also, Los Angeles is increasingly becoming a city of apartments rather than single family dwellings, especially in the dense inner city and Westside neighborhoods.

Important landmarks in Los Angeles include the Hollywood Sign, Walt Disney Concert Hall, Capitol Records Building, the Cathedral of Our Lady of the Angels, Angels Flight, Grauman's Chinese Theatre, Dolby Theatre, Griffith Observatory, Getty Center, Getty Villa, Stahl House, the Los Angeles Memorial Coliseum, L.A. Live, the Los Angeles County Museum of Art, the Venice Canal Historic District and boardwalk, Theme Building, Bradbury Building, U.S. Bank Tower, Wilshire Grand Center, Hollywood Boulevard, Los Angeles City Hall, Hollywood Bowl, Battleship , Watts Towers, Staples Center, Dodger Stadium, and Olvera Street.

Los Angeles has a Mediterranean climate (Köppen "Csb" on the coast and most of downtown, "Csa" near the metropolitan region to the west), and receives just enough annual precipitation to avoid semi-arid climate ("BSh)", making the myth that the city has been built in a desert not be completely incorrect. Daytime temperatures are generally temperate all year round. In winter, they average around giving it a tropical feel although it is a few degrees too cool to be a true tropical climate on average due to cool night temperatures. Los Angeles has plenty of sunshine throughout the year, with an average of only 35 days with measurable precipitation annually.

Temperatures in the coastal basin exceed on a dozen or so days in the year, from one day a month in April, May, June and November to three days a month in July, August, October and to five days in September. Temperatures in the San Fernando and San Gabriel Valleys are considerably warmer. Temperatures are subject to substantial daily swings; in inland areas the difference between the average daily low and the average daily high is over . The average annual temperature of the sea is , from in January to in August. Hours of sunshine total more than 3,000 per year, from an average of 7 hours of sunshine per day in December to an average of 12 in July.

The Los Angeles area is also subject to phenomena typical of a microclimate, causing extreme variations in temperature in close physical proximity to each other. For example, the average July maximum temperature at the Santa Monica Pier is whereas it is in Canoga Park, away. The city, like much of the southern California coast, is subject to a late spring/early summer weather phenomenon called "June Gloom". This involves overcast or foggy skies in the morning that yield to sun by early afternoon.

Downtown Los Angeles averages of precipitation annually, mainly occurring between November and March, generally in the form of moderate rain showers, but sometimes as heavy rainfall during winter storms. Rainfall is usually higher in the hills and coastal slopes of the mountains because of orographic uplift. Summer days are usually rainless. Rarely, an incursion of moist air from the south or east can bring brief thunderstorms in late summer, especially to the mountains. The coast gets slightly less rainfall, while the inland and mountain areas get considerably more. Years of average rainfall are rare. The usual pattern is year to year variability, with a short string of dry years of rainfall, followed by one or two wet years with more than . Wet years are usually associated with warm water El Niño conditions in the Pacific, dry years with cooler water La Niña episodes. A series of rainy days can bring floods to the lowlands and mudslides to the hills, especially after wildfires have denuded the slopes.

Both freezing temperatures and snowfall are extremely rare in the city basin and along the coast, with the last occurrence of a reading at the downtown station being January 29, 1979; freezing temperatures occur nearly every year in valley locations while the mountains within city limits typically receive snowfall every winter. The greatest snowfall recorded in downtown Los Angeles was on January 15, 1932. While the most recent snowfall occurred in February 2019, the first snowfall since 1962. At the official downtown station, the highest recorded temperature is on September 27, 2010, while the lowest is , on January 4, 1949. During autumn and winter, Santa Ana winds sometimes bring much warmer and drier conditions to Los Angeles, and raise wildfire risk.

A Gabrielino settlement in the area was called "iyáangẚ" (written "Yang-na" by the Spanish), which has been translated as "poison oak place". "Yang-na" has also been translated as "the valley of smoke". Owing to geography, heavy reliance on automobiles, and the Los Angeles/Long Beach port complex, Los Angeles suffers from air pollution in the form of smog. The Los Angeles Basin and the San Fernando Valley are susceptible to atmospheric inversion, which holds in the exhausts from road vehicles, airplanes, locomotives, shipping, manufacturing, and other sources. The percentage of small particle pollution (the kind that penetrates into the lungs) coming from vehicles in the city can get as high as 55 percent.

The smog season lasts from approximately May to October. While other large cities rely on rain to clear smog, Los Angeles gets only of rain each year: pollution accumulates over many consecutive days. Issues of air quality in Los Angeles and other major cities led to the passage of early national environmental legislation, including the Clean Air Act. When the act was passed, California was unable to create a State Implementation Plan that would enable it to meet the new air quality standards, largely because of the level of pollution in Los Angeles generated by older vehicles. More recently, the state of California has led the nation in working to limit pollution by mandating low-emission vehicles. Smog is expected to continue to drop in the coming years because of aggressive steps to reduce it, which include electric and hybrid cars, improvements in mass transit, and other measures.

The number of Stage 1 smog alerts in Los Angeles has declined from over 100 per year in the 1970s to almost zero in the new millennium. Despite improvement, the 2006 and 2007 annual reports of the American Lung Association ranked the city as the most polluted in the country with short-term particle pollution and year-round particle pollution. In 2008, the city was ranked the second most polluted and again had the highest year-round particulate pollution. The city met its goal of providing 20 percent of the city's power from renewable sources in 2010. The American Lung Association's 2013 survey ranks the metro area as having the nation's worst smog, and fourth in both short-term and year-round pollution amounts.

Los Angeles is also home to the nation's largest urban oil field. There are more than 700 active oil wells within 1,500 feet of homes, churches, schools and hospitals in the city, a situation about which the EPA has voiced serious concerns.

The 2010 United States Census reported Los Angeles had a population of 3,792,621. The population density was 8,092.3 people per square mile (2,913.0/km). The age distribution was 874,525 people (23.1%) under 18, 434,478 people (11.5%) from 18 to 24, 1,209,367 people (31.9%) from 25 to 44, 877,555 people (23.1%) from 45 to 64, and 396,696 people (10.5%) who were 65 or older. The median age was 34.1 years. For every 100 females, there were 99.2 males. For every 100 females age 18 and over, there were 97.6 males.

There were 1,413,995 housing units—up from 1,298,350 during 2005–2009—at an average density of 2,812.8 households per square mile (1,086.0/km), of which 503,863 (38.2%) were owner-occupied, and 814,305 (61.8%) were occupied by renters. The homeowner vacancy rate was 2.1%; the rental vacancy rate was 6.1%. 1,535,444 people (40.5% of the population) lived in owner-occupied housing units and 2,172,576 people (57.3%) lived in rental housing units.

According to the 2010 United States Census, Los Angeles had a median household income of $49,497, with 22.0% of the population living below the federal poverty line.

According to the 2010 Census, the racial makeup of Los Angeles included: 1,888,158 Whites (49.8%), 365,118 African Americans (9.6%), 28,215 Native Americans (0.7%), 426,959 Asians (11.3%), 5,577 Pacific Islanders (0.1%), 902,959 from other races (23.8%), and 175,635 (4.6%) from two or more races. Hispanics or Latinos of any race were 1,838,822 persons (48.5%). Los Angeles is home to people from more than 140 countries speaking 224 different identified languages. Ethnic enclaves like Chinatown, Historic Filipinotown, Koreatown, Little Armenia, Little Ethiopia, Tehrangeles, Little Tokyo, Little Bangladesh, and Thai Town provide examples of the polyglot character of Los Angeles.

Non-Hispanic whites were 28.7% of the population in 2010, compared to 86.3% in 1940. The majority of the Non-Hispanic white population is living in areas along the Pacific coast as well as in neighborhoods near and on the Santa Monica Mountains from the Pacific Palisades to Los Feliz.

Mexican ancestry make up the largest ethnic group of Hispanics at 31.9% of the city's population, followed by those of Salvadoran (6.0%) and Guatemalan (3.6%) heritage. The Hispanic population has a long established Mexican-American and Central American community and is spread well-nigh throughout the entire city of Los Angeles and its metropolitan area. It is most heavily concentrated in regions around Downtown as East Los Angeles, Northeast Los Angeles and Westlake. Furthermore, a vast majority of residents in neighborhoods in eastern South Los Angeles towards Downey are of Hispanic origin.

The largest Asian ethnic groups are Filipinos (3.2%) and Koreans (2.9%), which have their own established ethnic enclaves−Koreatown in the Wilshire Center and Historic Filipinotown. Chinese people, which make up 1.8% of Los Angeles's population, reside mostly outside of Los Angeles city limits and rather in the San Gabriel Valley of eastern Los Angeles County, but make a sizable presence in the city, notably in Chinatown. Chinatown and Thaitown are also home to many Thais and Cambodians, which make up 0.3% and 0.1% of Los Angeles's population, respectively. The Japanese comprise 0.9% of LA's population, and have an established Little Tokyo in the city's downtown, and another significant community of Japanese Americans is in the Sawtelle district of West Los Angeles. Vietnamese make up 0.5% of Los Angeles's population. Indians make up 0.9% of the city's population.

The Los Angeles metropolitan area is home to a large population of Armenians, Assyrians, and Iranians, many of whom live in enclaves like Little Armenia and Tehrangeles.

African Americans have been the predominant ethnic group in South Los Angeles, which has emerged as the largest African American community in the western United States since the 1960s. The neighborhoods of South Los Angeles with highest concentration of African Americans include Crenshaw, Baldwin Hills, Leimert Park, Hyde Park, Gramercy Park, Manchester Square and Watts. Apart from South Los Angeles, neighborhoods in the Central region of Los Angeles, as Mid-City and Mid-Wilshire have a moderate concentration of African Americans as well.

According to a 2014 study by the Pew Research Center, Christianity is the most prevalently practiced religion in Los Angeles (65%). Perhaps owing to the fact of its founding by Franciscan friars of Roman Catholicism, the Roman Catholic Archbishop of Los Angeles leads the largest archdiocese in the country. Cardinal Roger Mahony oversaw construction of the Cathedral of Our Lady of the Angels, which opened in September 2002 in Downtown Los Angeles. Construction of the cathedral marked a coming of age of the city's Catholic, heavily Latino community. There are numerous Catholic churches and parishes throughout Los Angeles.

In 2011, the once common, but ultimately lapsed, custom of conducting a procession and Mass in honor of Nuestra Señora de los Ángeles, in commemoration of the founding of the City of Los Angeles in 1781, was revived by the Queen of Angels Foundation and its founder Mark Albert, with the support and approbation of the Archdiocese of Los Angeles as well as several civic leaders. The recently revived custom is a continuation of the original processions and Masses that commenced on the first anniversary of the founding of Los Angeles in 1782 and continued for nearly a century thereafter.

With 621,000 Jews in the metropolitan area (490,000 in city proper), the region has the second-largest population of Jews in the United States. Many of Los Angeles's Jews now live on the Westside and in the San Fernando Valley, though Boyle Heights once had a large Jewish population prior to World War II due to restrictive housing covenants. Major Orthodox Jewish neighborhoods include Hancock Park, Pico-Robertson, and Valley Village, while Jewish Israelis are well represented in the Encino and Tarzana neighborhoods, and Persian Jews in Beverly Hills. Many varieties of Judaism are represented in the greater Los Angeles area, including Reform, Conservative, Orthodox, and Reconstructionist. The Breed Street Shul in East Los Angeles, built in 1923, was the largest synagogue west of Chicago in its early decades; it is no longer in daily use as a synagogue and is being converted to a museum and community center. The Kabbalah Centre also has a presence in the city.

The International Church of the Foursquare Gospel was founded in Los Angeles by Aimee Semple McPherson in 1923 and remains headquartered there to this day. For many years, the church convened at Angelus Temple, which, when built, was one of the largest churches in the country.

Los Angeles has had a rich and influential Protestant tradition. The first Protestant service in Los Angeles was a Methodist meeting held in a private home in 1850 and the oldest Protestant church still operating, First Congregational Church, was founded in 1867. In the early 1900s the Bible Institute Of Los Angeles published the founding documents of the Christian Fundamentalist movement and the Azusa Street Revival launched Pentecostalism. The Metropolitan Community Church also had its origins in the Los Angeles area. Important churches in the city include First Presbyterian Church of Hollywood, Bel Air Presbyterian Church, First African Methodist Episcopal Church of Los Angeles, West Angeles Church of God in Christ, Second Baptist Church, Crenshaw Christian Center, McCarty Memorial Christian Church, and First Congregational Church.

The Los Angeles California Temple, the second-largest temple operated by The Church of Jesus Christ of Latter-day Saints, is on Santa Monica Boulevard in the Westwood neighborhood of Los Angeles. Dedicated in 1956, it was the first temple of The Church of Jesus Christ of Latter-day Saints built in California and it was the largest in the world when completed.

The Hollywood region of Los Angeles also has several significant headquarters, churches, and the Celebrity Center of Scientology.

Because of Los Angeles's large multi-ethnic population, a wide variety of faiths are practiced, including Buddhism, Hinduism, Islam, Zoroastrianism, Sikhism, Bahá'í, various Eastern Orthodox churches, Sufism, Shintoism, Taoism, Confucianism, Chinese folk religion and countless others. Immigrants from Asia for example, have formed a number of significant Buddhist congregations making the city home to the greatest variety of Buddhists in the world. The first Buddhist joss house was founded in the city in 1875. Atheism and other secular beliefs are also common, as the city is the largest in the Western U.S. Unchurched Belt.

The economy of Los Angeles is driven by international trade, entertainment (television, motion pictures, video games, music recording, and production), aerospace, technology, petroleum, fashion, apparel, and tourism. Other significant industries include finance, telecommunications, law, healthcare, and transportation. In the 2017 Global Financial Centres Index, Los Angeles was ranked as having the 19th most competitive financial center in the world, and sixth most competitive in United States (after New York City, San Francisco, Chicago, Boston, and Washington, D.C.).

One of the five major film studios, Paramount Pictures, is within the city limits, its location being part of the so-called "Thirty-Mile Zone" of entertainment headquarters in Southern California.

Los Angeles is the largest manufacturing center in the United States. The contiguous ports of Los Angeles and Long Beach together comprise the busiest port in the United States by some measures and the fifth-busiest port in the world, vital to trade within the Pacific Rim.

The Los Angeles metropolitan area has a gross metropolitan product of $1.0 trillion (), making it the third-largest economic metropolitan area in the world, after Tokyo and New York. Los Angeles has been classified an "alpha world city" according to a 2012 study by a group at Loughborough University.

The Department of Cannabis Regulation enforces cannabis legislation after the legalization of the sale and distribution of cannabis in 2016. , more than 300 existing cannabis businesses (both retailers and their suppliers) have been granted approval to operate in what is considered the nation's largest market.

, Los Angeles is home to three Fortune 500 companies: AECOM, CBRE Group, and Reliance Steel & Aluminum Co.

Los Angeles is often billed as the "Creative Capital of the World", because one in every six of its residents works in a creative industry and there are more artists, writers, filmmakers, actors, dancers and musicians living and working in Los Angeles than any other city at any other time in history.

The city's Hollywood neighborhood has become recognized as the center of the motion picture industry and the Los Angeles area is also associated as being the center of the television industry. The city is home to the major film studios as well as major record labels. Los Angeles plays host to the annual Academy Awards, the Primetime Emmy Awards, the Grammy Awards as well as many other entertainment industry awards shows. Los Angeles is the site of the USC School of Cinematic Arts, the oldest film school in the United States.The performing arts play a major role in Los Angeles's cultural identity. According to the USC Stevens Institute for Innovation, "there are more than 1,100 annual theatrical productions and 21 openings every week." The Los Angeles Music Center is "one of the three largest performing arts centers in the nation", with more than 1.3 million visitors per year. The Walt Disney Concert Hall, centerpiece of the Music Center, is home to the prestigious Los Angeles Philharmonic. Notable organizations such as Center Theatre Group, the Los Angeles Master Chorale, and the Los Angeles Opera are also resident companies of the Music Center. Talent is locally cultivated at premier institutions such as the Colburn School and the USC Thornton School of Music.

There are 841 museums and art galleries in Los Angeles County, more museums per capita than any other city in the U.S. Some of the notable museums are the Los Angeles County Museum of Art (the largest art museum in the Western United States), the Getty Center (part of the J. Paul Getty Trust, the world's wealthiest art institution), the Petersen Automotive Museum, the Huntington Library, the Natural History Museum, the Battleship Iowa, and the Museum of Contemporary Art. A significant number of art galleries are on Gallery Row, and tens of thousands attend the monthly Downtown Art Walk there.

The city of Los Angeles and its metropolitan area are the home of eleven top level professional sports teams, several of which play in neighboring communities but use Los Angeles in their name. These teams include the Los Angeles Dodgers and Los Angeles Angels of Major League Baseball (MLB), the Los Angeles Rams and Los Angeles Chargers of the National Football League (NFL), the Los Angeles Lakers and Los Angeles Clippers of the National Basketball Association (NBA), the Los Angeles Kings and Anaheim Ducks of the National Hockey League (NHL), the Los Angeles Galaxy and Los Angeles Football Club of Major League Soccer (MLS), and the Los Angeles Sparks of the Women's National Basketball Association (WNBA).

Other notable sports teams include the UCLA Bruins and the USC Trojans in the National Collegiate Athletic Association (NCAA), both of which are Division I teams in the Pac-12 Conference.
Los Angeles is the second-largest city in the United States but hosted no NFL team between 1995 and 2015. At one time, the Los Angeles area hosted two NFL teams: the Rams and the Raiders. Both left the city in 1995, with the Rams moving to St. Louis, and the Raiders moving back to their original home of Oakland. After 21 seasons in St. Louis, on January 12, 2016, the NFL announced the Rams would be moving back to Los Angeles for the 2016 NFL season. SoFi Stadium in Inglewood, California is under construction and will be completed by the 2020 season. Prior to 1995, the Rams played their home games in the Los Angeles Memorial Coliseum from 1946 to 1979 and the Raiders played their home games at the Los Angeles Memorial Coliseum from 1982 to 1994. The San Diego Chargers announced on January 12, 2017 they would relocate to Los Angeles and become the Los Angeles Chargers beginning in the 2017 NFL season and played at Dignity Health Sports Park in Carson, California for three seasons prior to the completion of SoFi Stadium.

Los Angeles has twice hosted the Summer Olympic Games: in 1932 and in 1984, and will host the games for a third time in 2028. Los Angeles will be the third city after London (1908, 1948 and 2012) and Paris (1900, 1924 and 2024) to host the Olympic Games three times. When the tenth Olympic Games were hosted in 1932, the former 10th Street was renamed Olympic Blvd. Super Bowls I and VII were also held in the city, as well as multiple FIFA World Cup games at the Rose Bowl in 1994, including the final. Los Angeles also hosted the Deaflympics in 1985 and Special Olympics World Summer Games in 2015.

Los Angeles boasts a number of sports venues, including Dodger Stadium, the Los Angeles Memorial Coliseum, Banc of California Stadium and the Staples Center. The Forum, SoFi Stadium, Dignity Health Sports Park, and the Rose Bowl are also in adjacent cities. The Los Angeles Wildcats (XFL) are tenants of Dignity Health Sports Park

Los Angeles is one of six North American cities to have won championships in all five of its major leagues (MLB, NFL, NHL, NBA and MLS), having completed the feat with the Kings' 2012 Stanley Cup title.

Los Angeles is a charter city as opposed to a general law city. The current charter was adopted on June 8, 1999, and has been amended many times. The elected government consists of the Los Angeles City Council and the mayor of Los Angeles, which operate under a mayor–council government, as well as the city attorney (not to be confused with the district attorney, a county office) and controller. The mayor is Eric Garcetti. There are 15 city council districts.

The city has many departments and appointed officers, including the Los Angeles Police Department (LAPD), the Los Angeles Board of Police Commissioners, the Los Angeles Fire Department (LAFD), the Housing Authority of the City of Los Angeles (HACLA), the Los Angeles Department of Transportation (LADOT), and the Los Angeles Public Library (LAPL).

The charter of the City of Los Angeles ratified by voters in 1999 created a system of advisory neighborhood councils that would represent the diversity of stakeholders, defined as those who live, work or own property in the neighborhood. The neighborhood councils are relatively autonomous and spontaneous in that they identify their own boundaries, establish their own bylaws, and elect their own officers. There are about 90 neighborhood councils.

Residents of Los Angeles elect supervisors for the 1st, 2nd, 3rd, and 4th supervisorial districts.

In the California State Assembly, Los Angeles is split between fourteen districts. In the California State Senate, the city is split between eight districts. In the United States House of Representatives, it is split among ten congressional districts.

In 1992, the city of Los Angeles recorded 1,092 murders. Los Angeles experienced a significant decline in crime in the 1990s and late 2000s and reached a 50-year low in 2009 with 314 homicides. This is a rate of 7.85 per 100,000 population—a major decrease from 1980 when a homicide rate of 34.2 per 100,000 was reported. This included 15 officer-involved shootings. One shooting led to the death of a SWAT team member, Randal Simmons, the first in LAPD's history. Los Angeles in the year of 2013 totaled 251 murders, a decrease of 16 percent from the previous year. Police speculate the drop resulted from a number of factors, including young people spending more time online.

In 2015, it was revealed that the LAPD had been under-reporting crime for eight years, making the crime rate in the city appear much lower than it really is.

The Dragna crime family and the Cohen crime family dominated organized crime in the city during the Prohibition era and reached its peak during the 1940s and 1950s with the battle of Sunset Strip as part of the American Mafia, but has gradually declined since then with the rise of various black and Hispanic gangs in the late 1960s and early 1970s.

According to the Los Angeles Police Department, the city is home to 45,000 gang members, organized into 450 gangs. Among them are the Crips and Bloods, which are both African American street gangs that originated in the South Los Angeles region. Latino street gangs such as the Sureños, a Mexican American street gang, and Mara Salvatrucha, which has mainly members of Salvadoran descent, all originated in Los Angeles. This has led to the city being referred to as the "Gang Capital of America".

There are three public universities within the city limits: California State University, Los Angeles (CSULA), California State University, Northridge (CSUN) and University of California, Los Angeles (UCLA).

Private colleges in the city include:


The community college system consists of nine campuses governed by the trustees of the Los Angeles Community College District:

There are numerous additional colleges and universities outside the city limits in the Greater Los Angeles area, including the Claremont Colleges consortium, which includes the most selective liberal arts colleges in the U.S., and the California Institute of Technology (Caltech), one of the top STEM-focused research institutions in the world.

Los Angeles Unified School District serves almost all of the city of Los Angeles, as well as several surrounding communities, with a student population around 800,000. After Proposition 13 was approved in 1978, urban school districts had considerable trouble with funding. LAUSD has become known for its underfunded, overcrowded and poorly maintained campuses, although its 162 Magnet schools help compete with local private schools.

Several small sections of Los Angeles are in the Las Virgenes Unified School District. The Los Angeles County Office of Education operates the Los Angeles County High School for the Arts. The Los Angeles Public Library system operates 72 public libraries in the city. Enclaves of unincorporated areas are served by branches of the County of Los Angeles Public Library, many of which are within walking distance to residents.

The Los Angeles metro area is the second-largest broadcast designated market area in the U.S. (after New York) with 5,431,140 homes (4.956% of the U.S.), which is served by a wide variety of local AM and FM radio and television stations. Los Angeles and New York City are the only two media markets to have seven VHF allocations assigned to them.As part of the region's aforementioned creative industry, the Big Four major broadcast television networks, ABC, CBS, FOX, and NBC, all have production facilities and offices throughout various areas of Los Angeles. All four major broadcast television networks, plus major Spanish-language networks Telemundo and Univision, also own and operate stations that both serve the Los Angeles market and serve as each network's West Coast flagship station: ABC's KABC-TV (Channel 7), CBS's KCBS-TV (Channel 2), Fox's KTTV-TV (Channel 11), NBC's KNBC-TV (Channel 4), MyNetworkTV's KCOP-TV (Channel 13), Telemundo's KVEA-TV (Channel 52), and Univision's KMEX-TV (Channel 34). The region also has three PBS stations, as well as KCET (Channel 28), the nation's largest independent public television station. KTBN (Channel 40) is the flagship station of the religious Trinity Broadcasting Network, based out of Santa Ana. A variety of independent television stations, such as KCAL-TV (Channel 9) and KTLA-TV (Channel 5), also operate in the area.

The major daily English-language newspaper in the area is the "Los Angeles Times". "La Opinión" is the city's major daily Spanish-language paper. "The Korea Times" is the city's major daily Korean language paper while "The World Journal" is the city and county's major Chinese newspaper. The "Los Angeles Sentinel" is the city's major African-American weekly paper, boasting the largest African-American readership in the Western United States. "Investor's Business Daily" is distributed from its LA corporate offices, which are headquartered in Playa del Rey.

There are also a number of smaller regional newspapers, alternative weeklies and magazines, including the "Los Angeles Register", Los Angeles Community News, (which focuses on coverage of the greater Los Angeles area), "Los Angeles Daily News" (which focuses coverage on the San Fernando Valley), "LA Weekly", "L.A. Record" (which focuses coverage on the music scene in the Greater Los Angeles Area), "Los Angeles Magazine", the "Los Angeles Business Journal", the "Los Angeles Daily Journal" (legal industry paper), "The Hollywood Reporter", "Variety" (both entertainment industry papers), and "Los Angeles Downtown News". In addition to the major papers, numerous local periodicals serve immigrant communities in their native languages, including Armenian, English, Korean, Persian, Russian, Chinese, Japanese, Hebrew, and Arabic. Many cities adjacent to Los Angeles also have their own daily newspapers whose coverage and availability overlaps into certain Los Angeles neighborhoods. Examples include "The Daily Breeze" (serving the South Bay), and "The Long Beach Press-Telegram".

Los Angeles arts, culture and nightlife news is also covered by a number of local and national online guides like "Time Out Los Angeles", "Thrillist", "Kristin's List", "DailyCandy", "Diversity News Magazine", "LAist", and "Flavorpill".

The city and the rest of the Los Angeles metropolitan area are served by an extensive network of freeways and highways. The Texas Transportation Institute, which publishes an annual Urban Mobility Report, ranked Los Angeles road traffic as the most congested in the United States in 2005 as measured by annual delay per traveler. The average traveler in Los Angeles experienced 72 hours of traffic delay per year according to the study. Los Angeles was followed by San Francisco/Oakland, Washington, D.C. and Atlanta, (each with 60 hours of delay). Despite the congestion in the city, the mean travel time for commuters in Los Angeles is shorter than other major cities, including New York City, Philadelphia and Chicago. Los Angeles's mean travel time for work commutes in 2006 was 29.2 minutes, similar to those of San Francisco and Washington, D.C.

Among the major highways that connect LA to the rest of the nation include Interstate 5, which runs south through San Diego to Tijuana in Mexico and north through Sacramento, Portland, and Seattle to the Canada–US border; Interstate 10, the southernmost east–west, coast-to-coast Interstate Highway in the United States, going to Jacksonville, Florida; and U.S. Route 101, which heads to the California Central Coast, San Francisco, the Redwood Empire, and the Oregon and Washington coasts.

The LA County Metropolitan Transportation Authority (LA County Metro) and other agencies operate an extensive system of bus lines, as well as subway and light rail lines across Los Angeles County, with a combined monthly ridership (measured in individual boardings) of 38.8 million . The majority of this (30.5 million) is taken up by the city's bus system, the second busiest in the country. The subway and light rail combined average the remaining roughly 8.2 million boardings per month. LA County Metro recorded over 397 million boardings for the 2017 calendar year, including about 285 million bus riders and about 113 million riding on rail transit. For the first quarter of 2018, there were just under 95 million system-wide boardings, down from about 98 million in 2017, and about 105 million in 2016. In 2005, 10.2% of Los Angeles commuters rode some form of public transportation. According to the 2016 American Community Survey, 9.2% of working Los Angeles (city) residents made the journey to work via public transportation.

The city's subway system is the ninth busiest in the United States and its light rail system is the country's busiest. The rail system includes the B and D subway lines, as well as the A, C, E, and L light rail lines. In 2016, the E Line was extended to the Pacific Ocean at Santa Monica. The Metro G and J lines are bus rapid transit lines with stops and frequency similar to those of light rail. , the total number of light rail stations is 93. The city is also central to the commuter rail system Metrolink, which links Los Angeles to all neighboring counties as well as many suburbs.

Besides the rail service provided by Metrolink and the Los Angeles County Metropolitan Transportation Authority, Los Angeles is served by inter-city passenger trains from Amtrak. The main rail station in the city is Union Station just north of Downtown.

In addition, the city directly contracts for local and commuter bus service through the Los Angeles Department of Transportation, or LADOT.

The main international and domestic airport serving Los Angeles is Los Angeles International Airport , commonly referred to by its airport code, LAX.

Other major nearby commercial airports include:


One of the world's busiest general-aviation airports is also in Los Angeles, Van Nuys Airport .

The Port of Los Angeles is in San Pedro Bay in the San Pedro neighborhood, approximately south of Downtown. Also called Los Angeles Harbor and WORLDPORT LA, the port complex occupies of land and water along of waterfront. It adjoins the separate Port of Long Beach.

The sea ports of the Port of Los Angeles and Port of Long Beach together make up the "Los Angeles/Long Beach Harbor". Together, both ports are the fifth busiest container port in the world, with a trade volume of over 14.2 million TEU's in 2008. Singly, the Port of Los Angeles is the busiest container port in the United States and the largest cruise ship center on the West Coast of the United States – The Port of Los Angeles's World Cruise Center served about 590,000 passengers in 2014.

There are also smaller, non-industrial harbors along Los Angeles's coastline. The port includes four bridges: the Vincent Thomas Bridge, Henry Ford Bridge, Gerald Desmond Bridge, and Commodore Schuyler F. Heim Bridge. Passenger ferry service from San Pedro to the city of Avalon on Santa Catalina Island is provided by Catalina Express.

As of January 2020, there are 41,290 homeless people in the City of Los Angeles, comprising roughly 62% of the homeless population of LA County. This is an increase of 14.2% over the previous year (with a 12.7% increase in the overall homeless population of LA County). The epicenter of homelessness in Los Angeles is the Skid Row neighborhood, which contains 8,000 homeless people, one of the largest stable populations of homeless people in the United States. The increased homeless population in Los Angeles has been attributed largely to lack of housing affordability. Almost 60 percent of the 82,955 people that became newly homeless in 2019 said their homelessness was because of economic hardship. In Los Angeles, black people are roughly four times more likely to experience homelessness, which has been partially attributed to systemic racism.

As home to Hollywood and its entertainment industry, numerous singers, actors, celebrities and other entertainers live in various districts of Los Angeles.

Los Angeles has 25 sister cities, listed chronologically by year joined:


In addition, Los Angeles has the following "friendship cities":










</doc>
<doc id="18111" url="https://en.wikipedia.org/wiki?curid=18111" title="Lepus (constellation)">
Lepus (constellation)

Lepus (, ) is a constellation lying just south of the celestial equator. Its name is Latin for hare. It is located below—immediately south—of Orion (the hunter), and is sometimes represented as a hare being chased by Orion or by Orion's hunting dogs.

Although the hare does not represent any particular figure in Greek mythology, Lepus was one of the 48 constellations listed by the 2nd-century astronomer Ptolemy, and it remains one of the 88 modern constellations.

Lepus is most often represented as a hare being hunted by Orion, whose hunting dogs (Canis Major and Canis Minor) pursue it. The constellation is also associated with the Moon rabbit.

Four stars of this constellation (α, β, γ, δ Lep) form a quadrilateral and are known as "‘Arsh al-Jawzā'", "the Throne of Jawzā'" or "Kursiyy al-Jawzā' al-Mu'akhkhar", "the Hindmost Chair of Jawzā'" and "al-Nihāl", "the Camels Quenching Their Thirst" in Arabic.

There are a fair number of bright stars, both single and double, in Lepus. Alpha Leporis, the brightest star of Lepus, is a white supergiant of magnitude 2.6, 1300 light-years from Earth. Its traditional name, Arneb ("أرنب" "’arnab"), means "hare" in Arabic. Beta Leporis, traditionally known as Nihal (Arabic for "quenching their thirst"), is a yellow giant of magnitude 2.8, 159 light-years from Earth. Gamma Leporis is a double star divisible in binoculars. The primary is a yellow star of magnitude 3.6, 29 light-years from Earth. The secondary is an orange star of magnitude 6.2. Delta Leporis is a yellow giant of magnitude 3.8, 112 light-years from Earth. Epsilon Leporis is an orange giant of magnitude 3.2, 227 light-years from Earth. Kappa Leporis is a double star divisible in medium aperture amateur telescopes, 560 light-years from Earth. The primary is a blue-white star of magnitude 4.4 and the secondary is a star of magnitude 7.4.

There are several variable stars in Lepus. R Leporis is a Mira variable star. It is also called "Hind's Crimson Star" for its striking red color and because it was named for John Russell Hind. It varies in magnitude from a minimum of 9.8 to a maximum of 7.3, with a period of 420 days. R Leporis is at a distance of 1500 light-years. The color intensifies as the star brightens. It can be as dim as magnitude 12 and as bright as magnitude 5.5. T Leporis is also a Mira variable observed in detail by ESO's Very Large Telescope Interferometer. RX Leporis is a semi-regular red giant that has a period of 2 months. It has a minimum magnitude of 7.4 and a maximum magnitude of 5.0.

There is one Messier object in Lepus, M79. It is a globular cluster of magnitude 8.0, 42,000 light-years from Earth. One of the few globular clusters visible in the Northern Celestial Hemisphere's winter, it is a Shapley class V cluster, which means that it has an intermediate concentration towards its center. It is often described as having a "starfish" shape. 

M79 was discovered in 1780 by Pierre Méchain.





</doc>
<doc id="18112" url="https://en.wikipedia.org/wiki?curid=18112" title="Lupus (constellation)">
Lupus (constellation)

Lupus is a constellation located in the deep Southern Sky. Its name is Latin for wolf. Lupus was one of the 48 constellations listed by the 2nd-century astronomer Ptolemy, and it remains one of the 88 modern constellations, although it was previously an asterism associated with the neighboring constellation Centaurus.

In ancient times, the constellation was considered an asterism within Centaurus, and was considered to have been an arbitrary animal, killed, or about to be killed, on behalf of, or for, Centaurus. An alternative visualization, attested by Eratosthenes, saw this constellation as a wineskin held by Centaurus. It was not separated from Centaurus until Hipparchus of Bithynia named it "Therion" (meaning beast) in the 2nd century BC. 

The Greek constellation is probably based on the Babylonian figure known as the Mad Dog (UR.IDIM). This was a strange hybrid creature that combined the head and torso of a man with the legs and tail of a lion (the cuneiform sign 'UR' simply refers to a large carnivore; lions, wolves and dogs are all included). It is often found in association with the sun god and another mythical being called the Bison-man, which is supposedly related to the Greek constellation of Centaurus.

In Arab Folk Astronomy, Lupus, together with Centaurus were collectively called الشماريخ "al-Shamareekh", meaning the dense branches of the date palm's fruit.

Later, in Islamic Medieval astronomy, it was named السبع "al-Sab'", which is a term used for any predatory wild beast (same as the Greek "Therion"), as a separate constellation, but drawn together with Centaurus. In some manuscripts of Al-Sufi's Book of Fixed Stars and celestial globes, it was drawn as a lion; in others, it is drawn as a wolf, both conforming to the "Sab"' name.

In Europe, no particular animal was associated with it until the Latin translation of Ptolemy's work identified it with the wolf.

Lupus is bordered by six different constellations, although one of them (Hydra) merely touches at the corner. The other five are Scorpius (the scorpion), Norma (the right angle), Circinus (the compass), Libra (the balance scale), and Centaurus (the centaur). Covering 333.7 square degrees and 0.809% of the night sky, it ranks 46th of the 88 modern constellations. The three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is "Lup". The official constellation boundaries are defined by a twelve-sided polygon ("illustrated in infobox"). In the equatorial coordinate system, the right ascension coordinates of these borders lie between and, while the declination coordinates are between −29.83° and −55.58°. The whole constellation is visible to observers south of latitude 34°N.

Overall, there are 127 stars within the constellation's borders brighter than or equal to apparent magnitude 6.5. In his book "Star Names and Their Meanings", R. H. Allen gave the names Yang Mun for Alpha Lupi, the brightest star in Lupus, and KeKwan for the blue giant Beta Lupi, both from Chinese. However, the first name is in error; both stars were part of a large Chinese constellation known in modern transliteration as Qíguān, the Imperial Guards.

Most of the brightest stars in Lupus are massive members of the nearest OB association, Scorpius–Centaurus.

Alpha Lupi is an ageing blue giant star of spectral type B1.5 III that is 460 ± 10 light-years distant from Earth. It is a Beta Cephei variable, pulsating in brightness by 0.03 of a magnitude every 7 hours and 6 minutes.

Towards the north of the constellation are globular clusters NGC 5824 and NGC 5986, and close by the dark nebula B 228. To the south are two open clusters, NGC 5822 and NGC 5749, as well as globular cluster NGC 5927 on the eastern border with Norma. On the western border are two spiral galaxies and the Wolf–Rayet planetary nebula IC 4406, containing some of the hottest stars in existence. IC 4406, also called the Retina Nebula, is a cylindrical nebula at a distance of 5,000 light-years. It has dust lanes throughout its center. Another planetary nebula, NGC 5882, is towards the center of the constellation. The transiting exoplanet Lupus-TR-3b lies in this constellation. The historic supernova SN 1006 is described by various sources as appearing on April 30 to May 1, 1006, in the constellation of Lupus.

ESO 274-1 is a spiral galaxy seen from edge-on that requires an amateur telescope with at least 12 inches of aperture to view. It can be found by using Lambda Lupi and Mu Lupi as markers, and can only be seen under very dark skies. It is 9 arcminutes by 0.7 arcminutes with a small, elliptical nucleus.





</doc>
<doc id="18113" url="https://en.wikipedia.org/wiki?curid=18113" title="Lyra">
Lyra

Lyra (; Latin for lyre, from Greek "λύρα") is a small constellation. It is one of 48 listed by the 2nd century astronomer Ptolemy, and is one of the 88 constellations recognized by the International Astronomical Union. Lyra was often represented on star maps as a vulture or an eagle carrying a lyre, and hence is sometimes referred to as Vultur Cadens or Aquila Cadens ("Falling Vulture" or "Falling Eagle"), respectively. Beginning at the north, Lyra is bordered by Draco, Hercules, Vulpecula, and Cygnus. Lyra is nearly overhead in temperate northern latitudes shortly after midnight at the start of summer. From the equator to about the 40th parallel south it is visible low in the northern sky during the same (thus winter) months.
Vega, Lyra's brightest star, is one of the brightest stars in the night sky, and forms a corner of the famed Summer Triangle asterism. Beta Lyrae is the prototype of a class of binary star known as Beta Lyrae variables. These binary stars are so close to each other that they become egg-shaped and material flows from one to the other. Epsilon Lyrae, known informally as the Double Double, is a complex multiple star system. Lyra also hosts the Ring Nebula, the second-discovered and best-known planetary nebula.

In Greek mythology, Lyra represents the lyre of Orpheus. Made by Hermes from a tortoise shell, given to Apollo as a bargain, it was said to be the first lyre ever produced. Orpheus's music was said to be so great that even inanimate objects such as trees, streams, and rocks could be charmed. Joining Jason and the Argonauts, his music was able to quell the voices of the dangerous Sirens, who sang tempting songs to the Argonauts.

At one point, Orpheus married Eurydice, a nymph. While fleeing from an attack by Aristaeus, she stepped on a snake that bit her, killing her. To reclaim her, Orpheus entered the Underworld, where the music from his lyre charmed Hades. Hades relented and let Orpheus bring Eurydice back, on the condition that he never once look back until outside. Unfortunately, near the very end, Orpheus faltered and looked back, causing Eurydice to be left in the Underworld forever. Orpheus spent the rest of his life strumming his lyre while wandering aimlessly through the land, rejecting all marriage offers from women.

There are two competing myths relating to the death of Orpheus. According to Eratosthenes, Orpheus failed to make a necessary sacrifice to Dionysus due to his regard for Apollo as the supreme deity instead. Dionysus then sent his followers to rip Orpheus apart. Ovid tells a rather different story, saying that women, in retribution for Orpheus's rejection of marriage offers, ganged up and threw stones and spears. At first, his music charmed them as well, but eventually their numbers and clamor overwhelmed his music and he was hit by the spears. Both myths then state that his lyre was placed in the sky by Zeus, and Orpheus' bones buried by the muses.

Vega and its surrounding stars are also treated as a constellation in other cultures. The area corresponding to Lyra was seen by the Arabs as a vulture or an eagle carrying a lyre, either enclosed in its wings, or in its beak. In Wales, Lyra is known as King Arthur's Harp ("Talyn Arthur"), and King David's harp. The Persian Hafiz called it the Lyre of Zurah.
It has been called the Manger of the Infant Saviour, Praesepe Salvatoris. In Australian Aboriginal astronomy, Lyra is known by the Boorong people in Victoria as the Malleefowl constellation. Lyra was known as Urcuchillay by the Incas and was worshipped as an animal deity.

Lyra is bordered by Vulpecula to the south, Hercules to the east, Draco to the north, and Cygnus to the west. Covering 286.5 square degrees, it ranks 52nd of the 88 modern constellations in size. It appears prominently in the northern sky during the Northern Hemisphere's summer, and the whole constellation is visible for at least part of the year to observers north of latitude 42°S. Its main asterism consists of six stars, and 73 stars in total are brighter than magnitude 6.5. The constellation's boundaries, as set by Eugène Delporte in 1930, are defined by a 17-sided polygon. In the equatorial coordinate system, the right ascension coordinates of these borders lie between and , while the declination coordinates are between and . The International Astronomical Union (IAU) adopted the three-letter abbreviation "Lyr" for the constellation in 1922.

German cartographer Johann Bayer used the Greek letters alpha through nu to label the most prominent stars in the constellation. English astronomer John Flamsteed observed and labelled two stars each as delta, epsilon, zeta and nu. He added pi and rho, not using xi and omicron as Bayer used these letters to denote Cygnus and Hercules on his map.

The brightest star in the constellation is Vega (Alpha Lyrae), a main-sequence star of spectral type A0Va. Only 7.7 parsecs distant, Vega is a Delta Scuti variable, varying between magnitudes −0.02 and 0.07 over 0.2 days. On average, it is the second-brightest star of a northern hemisphere (after Arcturus) and the fifth-brightest star in all, surpassed only by Arcturus, Alpha Centauri, Canopus, and Sirius. Vega was the pole star in the year 12,000 BCE, and will again become the pole star around 14,000 CE.

Vega is one of the most-magnificent of all stars, and has been called "arguably the next most important star in the sky after the Sun". Vega was the first star other than the Sun to be photographed, as well as the first to have a clear spectrum recorded, showing absorption lines for the first time. The star was the first single main-sequence star other than the Sun to be known to emit X-rays, and is surrounded by a circumstellar debris disk, similar to the Kuiper Belt. Vega forms one corner of the famous Summer Triangle asterism; along with Altair and Deneb, these three stars form a prominent triangle during the northern hemisphere summer.

Vega also forms one vertex of a much smaller triangle, along with Epsilon and Zeta Lyrae. Zeta forms a wide binary star visible in binoculars, consisting of an Am star and an F-type subgiant. The Am star has an additional close companion, bringing the total number of stars in the system to three. Epsilon is a more famous wide binary that can even be separated by the naked eye under good conditions. Both components are themselves close binaries which can be seen with telescopes to consist of A- and F-type stars, and a faint star was recently found to orbit component C as well, for a total of five stars.

In contrast to Zeta and Epsilon Lyrae, Delta Lyrae is an optical double, with the two stars simply lying along the same line of sight east of Zeta. The brighter and closer of the two, Delta Lyrae, is a 4th-magnitude red bright giant that varies semiregularly by around 0.2 magnitudes with a dominant period of 79 days, while the fainter Delta Lyrae is a spectroscopic binary consisting of a B-type primary and an unknown secondary. Both systems, however, have very similar radial velocities, and are the two brightest members of a sparse open cluster known as the Delta Lyrae cluster. South of Delta is Gamma Lyrae, a blue giant and the second-brightest star in the constellation. Around 190 parsecs distant, it has been referred to as a "superficially normal" star.

The final star forming the lyre's figure is Beta Lyrae, also a binary composed of a blue bright giant and an early B-type star. In this case, the stars are so close together that the larger giant is overflowing its Roche lobe and transferring material to the secondary, forming a semidetached system. The secondary, originally the less massive of the two, has accreted so much mass that it is now substantially more massive, albeit smaller, than the primary, and is surrounded by a thick accretion disk. The plane of the orbit is aligned with Earth and the system thus shows eclipses, dropping nearly a full magnitude from its 3rd-magnitude baseline every 13 days, although its period is increasing by around 19 seconds per year. It is the prototype of the Beta Lyrae variables, eclipsing semidetached binaries of early spectral types in which there are no exact onsets of eclipses, but rather continuous changes in brightness.
Another easy-to-spot variable is the bright R Lyrae, north of the main asterism. Also known as 13 Lyrae, it is a 4th-magnitude red giant semiregular variable that varies by several tenths of a magnitude. Its periodicity is complex, with several different periods of varying lengths, most notably one of 46 days and one of 64 days. Even further north is FL Lyrae, a much fainter 9th-magnitude Algol variable that drops by half a magnitude every 2.18 days during the primary eclipse. Both components are main-sequence stars, the primary being late F-type and the secondary late G-type. The system was one of the first main-sequence eclipsing binaries containing G-type star to have its properties known as well as the better-studied early-type eclipsing binaries.

At the very northernmost edge of the constellation is the even fainter V361 Lyrae, an eclipsing binary that does not easily fall into one of the traditional classes, with features of Beta Lyrae, W Ursae Majoris, and cataclysmic variables. It may be a representative of a very brief phase in which the system is transitioning into a contact binary. It can be found less than a degree away from the naked-eye star 16 Lyrae, a 5th-magnitude A-type subgiant located around 37 parsecs distant.

The brightest star not included in the asterism and the westernmost cataloged by Bayer or Flamsteed is Kappa Lyrae, a typical red giant around 73 parsecs distant. Similar bright orange or red giants include the 4th-magnitude Theta Lyrae, Lambda Lyrae, and HD 173780. Lambda is located just south of Gamma, Theta is positioned in the east, and HD 173780, the brightest star in the constellation with no Bayer or Flamsteed designation, is more southernly. Just north of Theta and of almost exactly the same magnitude is Eta Lyrae, a blue subgiant with a near-solar metal abundance. Also nearby is the faint HP Lyrae, a post-asymptotic giant branch (AGB) star that shows variability. The reason for its variability is still a mystery: first cataloged as an eclipsing binary, it was theorized to be an RV Tauri variable in 2002, but if so, it would be by far the hottest such variable discovered.

In the extreme east is RR Lyrae, the prototype of the large class of variables known as RR Lyrae variables, which are pulsating variables similar to Cepheids, but are evolved population II stars of spectral types A and F. Such stars are usually not found in a galaxy's thin disk, but rather in the galactic halo. Such stars serve as standard candles, and thus are a reliable way to calculate distances to the globular clusters in which they reside. RR Lyrae itself varies between magnitudes 7 and 8 while exhibiting the Blazhko effect. The easternmost star designated by Flamsteed, 19 Lyrae, is also a small-amplitude variable, an Alpha Canum Venaticorum variable with a period of just over one day.

Another evolved star is the naked-eye variable XY Lyrae, a red bright giant just north of Vega that varies between 6th and 7th magnitudes over a period of 120 days. Also just visible to the naked eye is the peculiar classical Cepheid V473 Lyrae. It is unique in that it is the only known Cepheid in the Milky Way to undergo periodic phase and amplitude changes, analogous to the Blazhko effect in RR Lyrae stars. At 1.5 days, its period was the shortest known for a classical Cepheid at the time of its discovery. W and S Lyrae are two of the many Mira variables in Lyra. W varies between 7th and 12th magnitudes over approximately 200 days, while S, slightly fainter, is a silicate carbon star, likely of the . Another evolved star is EP Lyrae, a faint RV Tauri variable and an "extreme example" of a post-AGB star. It and a likely companion are surrounded by a circumstellar disk of material.

Rather close to Earth at a distance of only is Gliese 758. The sunlike primary star has a brown dwarf companion, the coldest to have been imaged around a sunlike star in thermal light when it was discovered in 2009. Only slightly farther away is V478 Lyrae, an eclipsing RS Canum Venaticorum variable whose primary star shows active starspot activity.

One of the most peculiar systems in Lyra is MV Lyrae, a nova-like star consisting of a red dwarf and a white dwarf. Originally classified as a VY Sculptoris star due to spending most time at maximum brightness, since around 1979 the system has been dominantly at minimum brightness, with periodic outbursts. Its nature is still not fully understood. Another outbursting star is AY Lyrae, an SU Ursae Majoris-type dwarf nova that has undergone several superoutbursts. Of the same type is V344 Lyrae, notable for an extremely short period between superoutbursts coupled with one of the highest amplitudes for such a period. The true nova HR Lyrae flared in 1919 to a maximum magnitude of 6.5, over 9.5 magnitudes higher than in quiescence. Some of its characteristics are similar to those of recurring novae.

M57, also known as the "Ring Nebula" and NGC 6720, has a diameter of one light-year and is at a distance of 2,000 light-years from Earth. It is one of the best known planetary nebulae and the second to be discovered; its integrated magnitude is 8.8. It was discovered in 1779 by Antoine Darquier, 15 years after Charles Messier discovered the Dumbbell Nebula. Astronomers have determined that it is between 6,000 and 8,000 years old; it is approximately one light-year in diameter. The outer part of the nebula appears red in photographs because of emission from ionized hydrogen. The middle region is colored green; doubly ionized oxygen emits greenish-blue light. The hottest region, closest to the central star, appears blue because of emission from helium. The central star itself is a white dwarf with a temperature of 120,000 kelvins. In telescopes, the nebula appears as a visible ring with a green tinge; it is slightly elliptical because its three-dimensional shape is a torus or cylinder seen from a slight angle. It can be found halfway between Gamma Lyrae and Beta Lyrae.

Another planetary nebula in Lyra is Abell 46. The central star, V477 Lyrae, is an eclipsing post-common-envelope binary, consisting of a white dwarf primary and an oversized secondary component due to recent accretion. The nebula itself is of relatively low surface brightness compared to the central star, and is undersized for the primary's mass for reasons not yet fully understood.

NGC 6791 is a cluster of stars in Lyra. It contains three age groups of stars: 4 billion year-old white dwarfs, 6 billion year-old white dwarfs and 8 billion year-old normal stars.

NGC 6745 is an irregular spiral galaxy in Lyra that is at a distance of 208 million light-years. Several million years ago, it collided with a smaller galaxy, which created a region filled with young, hot, blue stars. Astronomers do not know if the collision was simply a glancing blow or a prelude to a full-on merger, which would end with the two galaxies incorporated into one larger, probably elliptical galaxy.

A remarkable long-duration gamma-ray burst was GRB 050525A, which flared in 2005. The afterglow re-brightened at 33 minutes after the original burst, only the third found to exhibit such an effect in the timeframe, and unable to be completely explained by known phenomena. The light curve observed over the next 100 days was consistent with that of a supernova or even a hypernova, dubbed SN 2005nc. The host galaxy proved elusive to find at first, although it was subsequently identified.

In orbit around the orange subgiant star HD 177830 is one of the earliest exoplanets to be detected. A jovian-mass planet, it orbits in an eccentric orbit with a period of 390 days. A second planet closer to the star was discovered in 2011. Visible to the naked eye are HD 173416, a yellow giant hosting a planet over twice the mass of Jupiter discovered in 2009; and HD 176051, a low-mass binary star containing another high-mass planet. Just short of naked-eye visibility is HD 178911, a triple system consisting of a close binary and a visually separable sunlike star. The sunlike star has a planet with over 6 Jupiter masses discovered in 2001, the second found in a triple system after that of 16 Cygni.

One of the most-studied exoplanets in the night sky is TrES-1b, in orbit around the star GSC 02652-01324. Detected from a transit of its parent star, the planet has around 3/4 the mass of Jupiter, yet orbits its parent star in only three days. The transits have been reported to have anomalies multiple times. Originally thought to be possibly due to the presence of an Earth-like planet, it is now accepted that the irregularities are due to a large starspot. Also discovered by the transit method is WASP-3b, with 1.75 times the mass of Jupiter. At the time of its discovery, it was one of the hottest known exoplanets, in orbit around the F-type main-sequence star WASP-3. Similar to TrES-1b, irregularities in the transits had left open the possibility of a second planet, although this now appears unlikely as well.

Lyra is one of three constellations (along with neighboring Cygnus and Draco) to be in the Kepler Mission's field of view, and as such it contains many more known exoplanets than most constellations. One of the first discovered by the mission is Kepler-7b, an extremely low-density exoplanet with less than half the mass of Jupiter, yet nearly 1.5 times the radius. Almost as sparse is Kepler-8b, only slightly more massive and of a similar radius. The Kepler-20 system contains five known planets; three of them are only slightly smaller than Neptune, and two while the other two are some of the first Earth-sized exoplanets to be discovered. Kepler-37 is another star with an exoplanet discovered by Kepler; the planet is the smallest known extrasolar planet known as of February 2013.

In April 2013, it was announced that of the five planets orbiting Kepler-62, at least two—Kepler-62e and Kepler-62f—are within the boundaries of the habitable zone of that star, where scientists think liquid water could exist, and are both candidates for being a solid, rocky, earth-like planet. The exoplanets are 1.6 and 1.4 times the diameter of Earth respectively, with their star Kepler-62 at a distance of 1,200 light-years.




</doc>
<doc id="18115" url="https://en.wikipedia.org/wiki?curid=18115" title="Legnica">
Legnica

Legnica (, , ) is a city in southwestern Poland, in the central part of Lower Silesia, on the Kaczawa River (left tributary of the Oder) and the Czarna Woda. Between 1 June 1975 and 31 December 1998 Legnica was the capital of the Legnica Voivodeship. It is currently the seat of the county and since 1992 the city has been the seat of a Diocese. As of 2019, Legnica had a population of 99,350 inhabitants.

The city was first referenced in chronicles dating from the year 1004, although previous settlements could be traced back to the 7th century. The name "Legnica" was mentioned in 1149 under High Duke of Poland Bolesław IV the Curly. Legnica was most likely the seat of Bolesław and it became the residence of the High Dukes that ruled the Duchy of Legnica from 1248 until 1675. Legnica is a city over which the Piast dynasty reigned the longest, for about 700 years, from the time of ruler Mieszko I of Poland after the creation of the Polish state in the 10th century, until 1675 and the death of the last Piast duke George William. Legnica is one of the historical burial sites of Polish monarchs and consorts.

Legnica became renowned for the fierce battle that took place at Legnickie Pole near the city on 9 April 1241 during the first Mongol invasion of Poland. The Christian coalition under the command of the Polish Duke Henry II the Pious, supported by nobles, knights, and mercenaries, was decisively defeated by the Mongols. This, however, was a turning point in the war as the Mongols, having killed Henry II, halted their advance into Europe and retreated to Hungary through Moravia.

During the High Middle Ages, Legnica was one of the most important cities of Central Europe, having a population of nearly 16,000 inhabitants. The city began to rapidly develop after the sudden discovery of gold in the Kaczawa River between Legnica and the town of Złotoryja. In 1675 it was incorporated into Habsburg ruled Kingdom of Bohemia. In 1742 the city was annexed by the Kingdom of Prussia after King Frederick the Great's victory over Austria in the War of the Austrian Succession. Subsequently, it was part of German Empire from 1871, and later Weimar Republic and Nazi Germany until the end of World War II, when majority of Lower Silesia east of the Neisse (Nysa), was transferred to Poland under border changes promulgated at the Potsdam Conference in 1945, when Poland was granted the Recovered Territories.

Legnica is an economic, cultural and academic centre in Lower Silesia, together with Wrocław. The city is renowned for its varied architecture, spanning from early medieval to modern period, and its preserved Old Town with the Piast Castle, one of the largest in Poland. According to the Foreign direct investment ranking (FDI) from 2016, Legnica is one of the most progressive high-income cities in the Silesian region.

 Legnica has 102,708 inhabitants and is the third largest city in the voivodeship (after Wrocław and Wałbrzych) and 38th in Poland. It also constitutes the southernmost and the largest urban center of a copper deposit ("Legnicko-Głogowski Okręg Miedziowy") with agglomeration of 448,617 inhabitants. Legnica is the largest city of the conurbation and is a member of the Association of Polish Cities.

Archaeological research conducted in eastern Legnica in late 1970s, showed the existence of a bronze foundry and the graves of three metallurgists. The find indicates a time interval about year 1000 BC.

A settlement of the Lusatian culture people existed in the 8th century B.C. After invasions of Celts beyond upper Danube basin, the area of Legnica and north foothills of Sudetes was infiltrated by Celtic settlers and traders.

Tacitus and Ptolemy recorded the ancient nation of Lugii (Lygii) in the area, and mentioned their town of Lugidunum, which has been attributed to both Legnica and Głogów.

Slavic Lechitic tribes moved into the area in the 8th century.

The city was first officially mentioned in chronicles from 1004, although settlement dates to the 7th century. Dendrochronological research proves that during the reign of Mieszko I of Poland, a new fortified settlement was built here in a style typical of the early Piast dynasty. It is mentioned in 1149 when the High Duke of Poland Bolesław IV the Curly funded a chapel at the St. Benedict monastery. Legnica was the most likely place of residence for Bolesław and it became the residence of the High Dukes of Poland in 1163 and was the seat of a principality ruled from 1248 until 1675.
Legnica became famous for the battle that took place at Legnickie Pole near the city on 9 April 1241 during the First Mongol invasion of Poland. The Christian army of the Polish duke Henry II the Pious of Silesia, supported by feudal nobility, which included in addition to Poles, Bavarian miners and military orders and Czech troops, was decisively defeated by the Mongols. The Mongols killed Henry and destroyed his forces, then turned south to rejoin the rest of the Mongol armies, which were massing at the Plain of Mohi in Hungary via Moravia against a coalition of King Bela IV and his armies, and Bela's Kipchak allies.
After the war, nonetheless, the city was developing rapidly. In 1258 at the church of St. Peter, a parish school was established, probably the first of its kind in Poland. Around 1278 a Dominican monastery was founded by Bolesław II the Horned, who was buried there as the only monarch of Poland to be buried in Legnica. Already by 1300 there was a city council in Legnica. Duke Bolesław III the Generous granted new trade privileges in 1314 and 1318 and allowed the construction of a town hall, and in 1337 the first waterworks were built. In the years 1327–1380 a new Gothic church of Saint Peter (today's Cathedral) was erected in place of the old one, and is one of Legnica's landmarks since. Also by the 14th century the city walls were erected. In 1345 the first coins were produced in the local mint. In 1374, the potters' guild was founded, as one of the oldest in Silesia. Queen consort of Poland Hedwig of Sagan died in Legnica in 1390 and was buried in the local collegiate church, which has not survived to this day.

As the capital of the Duchy of Legnica at the beginning of the 14th century, Legnica was one of the most important cities of Central Europe, having a population of nearly 16,000 residents. The city began to expand quickly after the discovery of gold in the Kaczawa River between Legnica and Złotoryja (Goldberg).
Unfortunately, such a growth rate can not be maintained long. Shortly after the city reached its maximum population increase, wooden buildings which had been erected during this period of rapid growth were devastated by a huge fire. The fire decreased the number of inhabitants in the city and halted any significant further development for many decades.

Legnica, along with other Silesian duchies, became a vassal of the Kingdom of Bohemia during the 14th century and was included within the multi-ethnic Holy Roman Empire, however remained ruled by local dukes of the Polish Piast dynasty. In 1454, a local rebellion prevented Legnica from falling under direct rule of the Bohemian kings. In 1505, Duke Frederick II of Legnica met in Legnica with the Duke of nearby Głogów, Sigismund I the Old, the future king of Poland.

The Protestant Reformation was introduced in the duchy as early as 1522 and the population became Lutheran. In 1526, a Protestant university was established in Legnica, which, however, was closed in 1529. In 1528 the first printing house in Legnica was established. After the death of King Louis II of Hungary and Bohemia at Mohács in 1526, Legnica became a fief of the Habsburg Monarchy of Austria. The first map of Silesia was made by native son Martin Helwig. The city suffered during the Thirty Years' War. In 1633 a plague epidemic broke out, and in 1634 the Austrian army destroyed the suburbs.

In 1668 Duke of Legnica Christian presented his candidacy to the Polish throne, however, in the 1669 Polish–Lithuanian royal election he wasn't chose as King. In 1676, Legnica passed to direct Habsburg rule after the death of the last Silesian Piast duke and the last Piast duke overall, George William (son of Duke Christian), despite the earlier inheritance pact by Brandenburg and Silesia, by which it was to go to Brandenburg. The last Piast Duke was buried in the St. John's church in Legnica in 1676.

Silesian aristocracy was trained at the Liegnitz Ritter-Akademie, established in the early 18th century. One of two main routes connecting Warsaw and Dresden ran through the city in the 18th century and Kings Augustus II the Strong and Augustus III of Poland traveled that route many times. The postal milestone of King Augustus II comes from that period.
In 1742 most of Silesia, including Liegnitz, became part of the Kingdom of Prussia after King Frederick the Great's defeat of Austria in the War of the Austrian Succession. In 1760 during the Seven Years' War, Liegnitz was the site of the Battle of Liegnitz when Frederick's army defeated an Austrian army led by Laudon.

During the Napoleonic Wars and Polish national liberation fights, in 1807 Polish uhlans were stationed in the city, and in 1813, the Prussians, under Field Marshal Blücher, defeated the French forces of MacDonald in the Battle of Katzbach (Kaczawa) nearby. After the administrative reorganization of the Prussian state following the Congress of Vienna, Liegnitz and the surrounding territory ("Landkreis Liegnitz") were incorporated into the Regierungsbezirk (administrative district) of Liegnitz, within the Province of Silesia on 1 May 1816. Along with the rest of Prussia, the town became part of the German Empire in 1871 during the unification of Germany. On 1 January 1874 Liegnitz became the third city in Lower Silesia (after Breslau and Görlitz) to be raised to an urban district, although the district administrator of the surrounding "Landkreis" of Liegnitz continued to have his seat in the city. Its military garrison was home to Königsgrenadier-Regiment Nr. 7 a military unit formed almost exclusively out of Polish soldiers.

The census of 1910 gave Liegnitz's population as 95.86% German, 0.15% German and Polish, 1.27% Polish, 2.26% Wendish, and 0.19% Czech. On 1 April 1937 parts of the "Landkreis" of Liegnitz communities of Alt Beckern, Groß Beckern, Hummel, Liegnitzer Vorwerke, Pfaffendorf und Prinkendorf were incorporated into the city of Liegnitz. After the Treaty of Versailles following World War I, Liegnitz was part of the newly created Province of Lower Silesia from 1919 to 1938, then of the Province of Silesia from 1938 to 1941, and again of the Province of Lower Silesia from 1941 to 1945. After the Nazis came to power in Germany, as early as 1933, a boycott of local Jewish premises was ordered, and in 1938 the synagogue was burned down. During World War II, the Germans established two forced labour camps in the city, as well as two prisoner of war labor subcamps of the prisoner of war camp located in Żagań (then "Sagan").

After the defeat of Nazi Germany during World War II, Liegnitz and all of Silesia east of the Neisse was transferred to Poland following the Potsdam Conference in 1945. The German population was expelled from the city between 1945 and 1947 and it was repopulated with Poles, many of whom were expelled from pre-war eastern Poland after its annexation by the Soviet Union. Also Greeks, refugees of the Greek Civil War, settled in Legnica in 1950. As the medieval Polish name "Lignica" was considered archaic, the town was renamed Legnica. The transfer to Poland decided at Potsdam in 1945 was officially recognized by East Germany in 1950, by West Germany under Chancellor Willy Brandt in the Treaty of Warsaw signed in 1970, and finally by the reunited Germany by the Two Plus Four Agreement in 1990. By 1990 only a handful of Polonized Germans, prewar citizens of Liegnitz, remained of the pre-1945 German population. In 2010 the city celebrated the 65th anniversary of the "return of Legnica to Poland" and its liberation from the Nazis.
The city was only partly damaged in World War II. In June 1945 Legnica was briefly the capital of the Lower Silesian (Wrocław) Voivodship, after the administration was moved there from Trzebnica and before it was finally moved to Wrocław. In 1947, the Municipal Library was opened, in 1948 a piano factory was founded, and in the years 1951-1959 Poland's first copper smelter was built in Legnica. After 1965 most parts of the preserved old town with its town houses were demolished, the historical layout was abolished, and the city was rebuilt in modern form.

From 1945 to 1990, during the Cold War, the headquarters of the Soviet forces in Poland, the so-called Northern Group of Forces, was located in the city. This fact had a strong influence on the life of the city. For much of the period, the city was divided into Polish and Soviet areas, with the latter closed to the public. These were first established in July 1945, when the Soviets forcibly ejected newly arrived Polish inhabitants from the parts of the city they wanted for their own use. The ejection was perceived by some as a particularly brutal action, and rumours circulated exaggerating its severity, though no evidence of anyone being killed in the course of it has come to light. In April 1946 city officials estimated that there were 16,700 Poles, 12,800 Germans, and 60,000 Soviets in Legnica. In October 1956, the largest anti-Soviet demonstrations in Lower Silesia took place in Legnica. The last Soviet units left the city in 1993.

In 1992 the Roman Catholic Diocese of Legnica was established, Tadeusz Rybak became the first bishop of Legnica. New local newspapers and a radio station were founded in the 1990s. In 1997, Legnica was visited by Pope John Paul II. The city suffered in the 1997 Central European flood.

Legnica is a city with rich historical architecture, ranging from Romanesque and Gothic through the Renaissance and Baroque to Historicist styles. Among the landmarks of Legnica are:

There is also a monument of Pope John Paul II and a postal milestone of King Augustus II the Strong from 1725 in Legnica.

In the 1950s and 1960s the local copper and nickel industries became a major factor in the economic development of the area. Legnica houses industrial plants belonging to KGHM Polska Miedź, one of the largest producers of copper and silver in the world. The company owns a large copper mill on the western outskirts of town. There is a Special Economic Zone in Legnica, where Lenovo was going to open a factory in summer 2008.

Legnica is a regional academic center with seven universities enrolling approximately 16,000 students.
Legnica is noted for its parks and gardens, and has seven hundred hectares of green space, mostly along the banks of the Kaczawa; the Tarninow district is particularly attractive.

To the south of Legnica is the A4 motorway. Legnica has also a district, which is a part of national road no 3. The express road S3 building has been planned nearby.

In the city there are 20 regular bus lines, 1 belt-line, 2 night lines and 3 suburban.

The town has an airport (airport code EPLE) with a 1600-metre runway, the remains of a former Soviet air base, but it is () in a poor state and not used for commercial flights.

Until the winter of 2003, the longest train service in Poland ran from Katowice to Legnica (via Kędzierzyn-Koźle, Nysa, and Jaworzyna Śląska).


In recent years Legnica has been frequently used as a film set for the following films as a result of its well preserved German-built old town, proximity to Germany and low costs:
"Przebacz" (dir. M. Stacharski) – 2005
"Anonyma – Eine Frau in Berlin" (dir. M. Färberböck) – 2007
"Wilki" (dir. F. Fromm) – 2007
"Little Moscow" (dir. W. Krzystek) – 2008
"Moje życie" (dir. D. Zahavi) – 2008[2]
"Die Wölfe" (dir. F.Fromm) – 2009

Legnica tends to be a left-of-center town with a considerable influence of workers' unions. The Municipal Council of Legnica ("Rada miejska miasta Legnica") is the legislative branch of the local government and is composed of 25 members elected in local elections every five years. The mayor or town president ("Prezydent miasta") is the executive branch of the local government and is directly elected in the same municipal elections.

Members of Parliament (Sejm) elected from Legnica-Jelenia Gora constituency:


Legnica is twinned with:

Legnica and its then ruler Count Conrad figures prominently in the alternate history series "The Crosstime Engineer", set in the period of 1230 to 1270, by Leo Frankowski.



</doc>
<doc id="18119" url="https://en.wikipedia.org/wiki?curid=18119" title="Liverpool F.C.">
Liverpool F.C.

Liverpool Football Club is a professional football club in Liverpool, England, that competes in the Premier League, the top tier of English football. Domestically, the club has won nineteen League titles, seven FA Cups, a record eight League Cups and fifteen FA Community Shields. In international competitions, the club has won six European Cups, more than any other English club, three UEFA Cups, four UEFA Super Cups (also English records) and one FIFA Club World Cup.

Founded in 1892, the club joined the Football League the following year and has played at Anfield since its formation. Liverpool established itself as a major force in English and European football in the 1970s and 1980s, when Bill Shankly, Bob Paisley, Joe Fagan and Kenny Dalglish led the club to a combined eleven League titles and four European Cups. Liverpool won two further European Cups in 2005 and 2019 under the management of Rafael Benítez and Jürgen Klopp, respectively, the latter of whom led Liverpool to a nineteenth League title in 2020, the club's first during the Premier League era.

One of the most widely supported teams in the world, in 2019, Liverpool was the world's seventh highest-earning football club, with an annual revenue of €604 million, and the world's eighth most valuable football club, valued at $2.183 billion. Liverpool has long-standing rivalries with Manchester United and Everton. The team changed from red shirts and white shorts to an all-red home strip in 1964 which has been used ever since. The club's anthem is "You'll Never Walk Alone".

The club's supporters have been involved in two major tragedies: the Heysel Stadium disaster, where escaping fans were pressed against a collapsing wall at the 1985 European Cup Final in Brussels, with 39 people – mostly Italians and Juventus fans – dying, after which English clubs were given a five-year ban from European competition; and the Hillsborough disaster in 1989, where 96 Liverpool supporters died in a crush against perimeter fencing, which led to the elimination of fenced standing terraces in favour of all-seater stadiums in the top two tiers of English football.

Liverpool F.C. was founded following a dispute between the Everton committee and John Houlding, club president and owner of the land at Anfield. After eight years at the stadium, Everton relocated to Goodison Park in 1892 and Houlding founded Liverpool F.C. to play at Anfield. Originally named "Everton F.C. and Athletic Grounds Ltd" (Everton Athletic for short), the club became Liverpool F.C. in March 1892 and gained official recognition three months later, after The Football Association refused to recognise the club as Everton. The team won the Lancashire League in its debut season, and joined the Football League Second Division at the start of the 1893–94 season. After finishing in first place the club was promoted to the First Division, which it won in 1901 and again in 1906.

Liverpool reached its first FA Cup Final in 1914, losing 1–0 to Burnley. It won consecutive League championships in 1922 and 1923, but did not win another trophy until the 1946–47 season, when the club won the First Division for a fifth time under the control of ex-West Ham Utd centre half George Kay. Liverpool suffered its second Cup Final defeat in 1950, playing against Arsenal. The club was relegated to the Second Division in the 1953–54 season. Soon after Liverpool lost 2–1 to non-league Worcester City in the 1958–59 FA Cup, Bill Shankly was appointed manager. Upon his arrival he released 24 players and converted a boot storage room at Anfield into a room where the coaches could discuss strategy; here, Shankly and other "Boot Room" members Joe Fagan, Reuben Bennett, and Bob Paisley began reshaping the team.

The club was promoted back into the First Division in 1962 and won it in 1964, for the first time in 17 years. In 1965, the club won its first FA Cup. In 1966, the club won the First Division but lost to Borussia Dortmund in the European Cup Winners' Cup final. Liverpool won both the League and the UEFA Cup during the 1972–73 season, and the FA Cup again a year later. Shankly retired soon afterwards and was replaced by his assistant, Bob Paisley. In 1976, Paisley's second season as manager, the club won another League and UEFA Cup double. The following season, the club retained the League title and won the European Cup for the first time, but it lost in the 1977 FA Cup Final. Liverpool retained the European Cup in 1978 and regained the First Division title in 1979. During Paisley's nine seasons as manager Liverpool won 20 trophies, including three European Cups, a UEFA Cup, six League titles and three consecutive League Cups; the only domestic trophy he did not win was the FA Cup.

Paisley retired in 1983 and was replaced by his assistant, Joe Fagan. Liverpool won the League, League Cup and European Cup in Fagan's first season, becoming the first English side to win three trophies in a season. Liverpool reached the European Cup final again in 1985, against Juventus at the Heysel Stadium. Before kick-off, Liverpool fans breached a fence which separated the two groups of supporters, and charged the Juventus fans. The resulting weight of people caused a retaining wall to collapse, killing 39 fans, mostly Italians. The incident became known as the Heysel Stadium disaster. The match was played in spite of protests by both managers, and Liverpool lost 1–0 to Juventus. As a result of the tragedy, English clubs were banned from participating in European competition for five years; Liverpool received a ten-year ban, which was later reduced to six years. Fourteen Liverpool fans received convictions for involuntary manslaughter.

Fagan had announced his retirement just before the disaster and Kenny Dalglish was appointed as player-manager. During his tenure, the club won another three league titles and two FA Cups, including a League and Cup "Double" in the 1985–86 season. Liverpool's success was overshadowed by the Hillsborough disaster: in an FA Cup semi-final against Nottingham Forest on 15 April 1989, hundreds of Liverpool fans were crushed against perimeter fencing. Ninety-four fans died that day; the 95th victim died in hospital from his injuries four days later and the 96th died nearly four years later, without regaining consciousness. After the Hillsborough disaster there was a government review of stadium safety. The resulting Taylor Report paved the way for legislation that required top-division teams to have all-seater stadiums. The report ruled that the main reason for the disaster was overcrowding due to a failure of police control.

Liverpool was involved in the closest finish to a league season during the 1988–89 season. Liverpool finished equal with Arsenal on both points and goal difference, but lost the title on total goals scored when Arsenal scored the final goal in the last minute of the season.

Dalglish cited the Hillsborough disaster and its repercussions as the reason for his resignation in 1991; he was replaced by former player Graeme Souness. Under his leadership Liverpool won the 1992 FA Cup Final, but their league performances slumped, with two consecutive sixth-place finishes, eventually resulting in his dismissal in January 1994. Souness was replaced by Roy Evans, and Liverpool went on to win the 1995 Football League Cup Final. While they made some title challenges under Evans, third-place finishes in 1996 and 1998 were the best they could manage, and so Gérard Houllier was appointed co-manager in the 1998–99 season, and became the sole manager in November 1998 after Evans resigned. In 2001, Houllier's second full season in charge, Liverpool won a "Treble": the FA Cup, League Cup and UEFA Cup. Houllier underwent major heart surgery during the 2001–02 season and Liverpool finished second in the League, behind Arsenal. They won a further League Cup in 2003, but failed to mount a title challenge in the two seasons that followed.

Houllier was replaced by Rafael Benítez at the end of the 2003–04 season. Despite finishing fifth in Benítez's first season, Liverpool won the 2004–05 UEFA Champions League, beating A.C. Milan 3–2 in a penalty shootout after the match ended with a score of 3–3. The following season, Liverpool finished third in the Premier League and won the 2006 FA Cup Final, beating West Ham United in a penalty shootout after the match finished 3–3. American businessmen George Gillett and Tom Hicks became the owners of the club during the 2006–07 season, in a deal which valued the club and its outstanding debts at £218.9 million. The club reached the 2007 UEFA Champions League Final against Milan, as it had in 2005, but lost 2–1. During the 2008–09 season Liverpool achieved 86 points, its highest Premier League points total, and finished as runners up to Manchester United.

In the 2009–10 season, Liverpool finished seventh in the Premier League and failed to qualify for the Champions League. Benítez subsequently left by mutual consent and was replaced by Fulham manager Roy Hodgson. At the start of the 2010–11 season Liverpool was on the verge of bankruptcy and the club's creditors asked the High Court to allow the sale of the club, overruling the wishes of Hicks and Gillett. John W. Henry, owner of the Boston Red Sox and of Fenway Sports Group, bid successfully for the club and took ownership in October 2010. Poor results during the start of that season led to Hodgson leaving the club by mutual consent and former player and manager Kenny Dalglish taking over. In the 2011–12 season, Liverpool secured a record 8th League Cup success and reached the FA Cup final, but finished in eighth position, the worst league finish in 18 years; this led to the sacking of Dalglish. He was replaced by Brendan Rodgers, whose Liverpool team in the 2013–14 season mounted an unexpected title charge to finish second behind champions Manchester City and subsequently return to the Champions League, scoring 101 goals in the process, the most since the 106 scored in the 1895–96 season. Following a disappointing 2014–15 season, where Liverpool finished sixth in the league, and a poor start to the following campaign, Rodgers was sacked in October 2015.

Rodgers was replaced by Jürgen Klopp. Liverpool reached the finals of the Football League Cup and UEFA Europa League in Klopp's first season, finishing as runner-up in both competitions. The club finished second in the 2018–19 season with 97 points, losing only one game: a points record for a non-title winning side. Klopp took Liverpool to successive Champions League finals in 2018 and 2019, with the club defeating Tottenham Hotspur 2–0 to win the 2019 UEFA Champions League Final. Liverpool beat Flamengo of Brazil in the final 1–0 to win the FIFA Club World Cup for the first time. Liverpool then went on to win the 2019–20 Premier League, winning their first title in thirty years. The club set multiple records in the season, including winning the league with seven games remaining making it the earliest any team has ever won the title, amassing a club record 99 points, and achieving a joint-record 32 wins in a top flight season.

For much of Liverpool's history its home colours have been all red, but when the club was founded its kit was more like the contemporary Everton kit. The blue and white quartered shirts were used until 1894, when the club adopted the city's colour of red. The city's symbol of the liver bird was adopted as the club's badge in 1901, although it was not incorporated into the kit until 1955. Liverpool continued to wear red shirts and white shorts until 1964, when manager Bill Shankly decided to change to an all red strip. Liverpool played in all red for the first time against Anderlecht, as Ian St. John recalled in his autobiography:

The Liverpool away strip has more often than not been all yellow or white shirts and black shorts, but there have been several exceptions. An all grey kit was introduced in 1987, which was used until the 1991–92 centenary season, when it was replaced by a combination of green shirts and white shorts. After various colour combinations in the 1990s, including gold and navy, bright yellow, black and grey, and ecru, the club alternated between yellow and white away kits until the 2008–09 season, when it re-introduced the grey kit. A third kit is designed for European away matches, though it is also worn in domestic away matches on occasions when the current away kit clashes with a team's home kit. Between 2012 and 2015, the kits were designed by Warrior Sports, who became the club's kit providers at the start of the 2012–13 season. In February 2015, Warrior's parent company New Balance announced it would be entering the global football market, with teams sponsored by Warrior now being outfitted by New Balance. The only other branded shirts worn by the club were made by Umbro until 1985, when they were replaced by Adidas, who produced the kits until 1996 when Reebok took over. They produced the kits for 10 years before Adidas made the kits from 2006 to 2012. Nike will become the club's official kit supplier from the 2020–21 season.

Liverpool was the first English professional club to have a sponsor's logo on its shirts, after agreeing a deal with Hitachi in 1979. Since then the club has been sponsored by Crown Paints, Candy, Carlsberg and Standard Chartered. The contract with Carlsberg, which was signed in 1992, was the longest-lasting agreement in English top-flight football. The association with Carlsberg ended at the start of the 2010–11 season, when Standard Chartered Bank became the club's sponsor.

The Liverpool badge is based on the city's liver bird, which in the past had been placed inside a shield. In 1992, to commemorate the centennial of the club, a new badge was commissioned, including a representation of the Shankly Gates. The next year twin flames were added at either side, symbolic of the Hillsborough memorial outside Anfield, where an eternal flame burns in memory of those who died in the Hillsborough disaster. In 2012, Warrior Sports' first Liverpool kit removed the shield and gates, returning the badge to what had adorned Liverpool shirts in the 1970s; the flames were moved to the back collar of the shirt, surrounding the number 96 for the number who died at Hillsborough.

Anfield was built in 1884 on land adjacent to Stanley Park. 
Situated 2 miles (3 km) from Liverpool city centre, it was originally used by Everton before the club moved to Goodison Park after a dispute over rent with Anfield owner John Houlding. Left with an empty ground, Houlding founded Liverpool in 1892 and the club has played at Anfield ever since. The capacity of the stadium at the time was 20,000, although only 100 spectators attended Liverpool's first match at Anfield.

The Kop was built in 1906 due to the high turnout for matches and was called the Oakfield Road Embankment initially. Its first game was on 1 September 1906 when the home side beat Stoke City 1–0. In 1906 the banked stand at one end of the ground was formally renamed the Spion Kop after a hill in KwaZulu-Natal. The hill was the site of the Battle of Spion Kop in the Second Boer War, where over 300 men of the Lancashire Regiment died, many of them from Liverpool. At its peak, the stand could hold 28,000 spectators and was one of the largest single-tier stands in the world. Many stadiums in England had stands named after Spion Kop, but Anfield's was the largest of them at the time; it could hold more supporters than some entire football grounds.

Anfield could accommodate more than 60,000 supporters at its peak and had a capacity of 55,000 until the 1990s, when, following recommendations from the "Taylor Report", all clubs in the Premier League were obliged to convert to all-seater stadiums in time for the 1993–94 season, reducing its capacity to 45,276. The findings of the report precipitated the redevelopment of the Kemlyn Road Stand, which was rebuilt in 1992, coinciding with the centenary of the club, and was known as the Centenary Stand until 2017 when it was renamed the Kenny Dalglish Stand. An extra tier was added to the Anfield Road end in 1998, which further increased the capacity of the ground but gave rise to problems when it was opened. A series of support poles and stanchions were inserted to give extra stability to the top tier of the stand after movement of the tier was reported at the start of the 1999–2000 season.

Because of restrictions on expanding the capacity at Anfield, Liverpool announced plans to move to the proposed Stanley Park Stadium in May 2002. Planning permission was granted in July 2004, and in September 2006, Liverpool City Council agreed to grant Liverpool a 999-year lease on the proposed site. Following the takeover of the club by George Gillett and Tom Hicks in February 2007, the proposed stadium was redesigned. The new design was approved by the Council in November 2007. The stadium was scheduled to open in August 2011 and would hold 60,000 spectators, with HKS, Inc. contracted to build the stadium. Construction was halted in August 2008, as Gillett and Hicks had difficulty in financing the £300 million needed for the development. In October 2012, BBC Sport reported that Fenway Sports Group, the new owners of Liverpool FC, had decided to redevelop their current home at Anfield stadium, rather than building a new stadium in Stanley Park. As part of the redevelopment the capacity of Anfield was to increase from 45,276 to approximately 60,000 and would cost approximately £150m. When construction was completed on the new Main stand the capacity of Anfield was increased to 54,074. This £100 million expansion added a third tier to the stand. This was all part of a £260 million project to improve the Anfield area. Jurgen Klopp the manager at the time described the stand as "impressive."

Liverpool is one of the best supported clubs in the world. The club states that its worldwide fan base includes more than 200 officially recognised Supporters Clubs in at least 50 countries. Notable groups include Spirit of Shankly. The club takes advantage of this support through its worldwide summer tours, which has included playing in front of 101,000 in Michigan, U.S., and 95,000 in Melbourne, Australia. Liverpool fans often refer to themselves as Kopites, a reference to the fans who once stood, and now sit, on the Kop at Anfield. In 2008 a group of fans decided to form a splinter club, A.F.C. Liverpool, to play matches for fans who had been priced out of watching Premier League football.

The song "You'll Never Walk Alone", originally from the Rodgers and Hammerstein musical "Carousel" and later recorded by Liverpool musicians Gerry and the Pacemakers, is the club's anthem and has been sung by the Anfield crowd since the early 1960s. It has since gained popularity among fans of other clubs around the world. The song's title adorns the top of the Shankly Gates, which were unveiled on 2 August 1982 in memory of former manager Bill Shankly. The "You'll Never Walk Alone" portion of the Shankly Gates is also reproduced on the club's crest.

The club's supporters have been involved in two stadium disasters. The first was the 1985 Heysel Stadium disaster, in which 39 Juventus supporters were killed. They were confined to a corner by Liverpool fans who had charged in their direction; the weight of the cornered fans caused a wall to collapse. UEFA laid the blame for the incident solely on the Liverpool supporters, and banned all English clubs from European competition for five years. Liverpool was banned for an additional year, preventing it from participating in the 1990–91 European Cup, even though it won the League in 1990. Twenty-seven fans were arrested on suspicion of manslaughter and were extradited to Belgium in 1987 to face trial. In 1989, after a five-month trial in Belgium, 14 Liverpool fans were given three-year sentences for involuntary manslaughter; half of the terms were suspended.

The second disaster took place during an FA Cup semi-final between Liverpool and Nottingham Forest at Hillsborough Stadium, Sheffield, on 15 April 1989. Ninety-six Liverpool fans died as a consequence of overcrowding at the Leppings Lane end, in what became known as the Hillsborough disaster. In the following days "The Sun" newspaper published an article entitled "The Truth", in which it claimed that Liverpool fans had robbed the dead and had urinated on and attacked the police. Subsequent investigations proved the allegations false, leading to a boycott of the newspaper by Liverpool fans across the city and elsewhere; many still refuse to buy "The Sun" 30 years later. Many support organisations were set up in the wake of the disaster, such as the Hillsborough Justice Campaign, which represents bereaved families, survivors and supporters in their efforts to secure justice.

Liverpool's longest-established rivalry is with fellow Liverpool team Everton, against whom they contest the Merseyside derby. The rivalry stems from Liverpool's formation and the dispute with Everton officials and the then owners of Anfield. The Merseyside derby is one of the few local derbies which do not enforce fan segregation, and hence has been known as the "friendly derby". Since the mid-1980s, the rivalry has intensified both on and off the field and, since the inception of the Premier League in 1992, the Merseyside derby has had more players sent off than any other Premier League game. It has been referred to as "the most ill-disciplined and explosive fixture in the Premier League". In terms of support within the city, the number of Liverpool fans outweigh Everton supporters by a ratio of 2:1.

Liverpool's rivalry with Manchester United stems from the cities' competition in the Industrial Revolution of the 19th century. Connected by the world’s first inter-city railway, by road Liverpool and Manchester are separated by approximately 30 miles (48 km) along the East Lancs Road. Ranked the two biggest clubs in England by "France Football" magazine, Liverpool and Manchester United are the most successful English teams in both domestic and international competitions, and both clubs have a global fanbase. Viewed as one of the biggest rivalries in world football, it is considered the most famous fixture in English football. The two clubs alternated as champions between 1964 and 1967, and Manchester United became the first English team to win the European Cup in 1968, followed by Liverpool's four European Cup victories. Despite the 39 league titles and nine European Cups between them the two rivals have rarely been successful at the same time – Liverpool's run of titles in the 1970s and 1980s coincided with Manchester United's 26-year title drought, and United's success in the Premier League-era likewise coincided with Liverpool's 30-year title drought, and the two clubs have finished first and second in the league only five times. Such is the rivalry between the clubs they rarely do transfer business with each other. The last player to be transferred between the two clubs was Phil Chisnall, who moved to Liverpool from Manchester United in 1964.

As the owner of Anfield and founder of Liverpool, John Houlding was the club's first chairman, a position he held from its founding in 1892 until 1904. John McKenna took over as chairman after Houlding's departure. McKenna subsequently became President of the Football League. The chairmanship changed hands many times before John Smith, whose father was a shareholder of the club, took up the role in 1973. He oversaw the most successful period in Liverpool's history before stepping down in 1990. His successor was Noel White who became chairman in 1990. In August 1991 David Moores, whose family had owned the club for more than 50 years became chairman. His uncle John Moores was also a shareholder at Liverpool and was chairman of Everton from 1961 to 1973. Moores owned 51 percent of the club, and in 2004 expressed his willingness to consider a bid for his shares in Liverpool.

Moores eventually sold the club to American businessmen George Gillett and Tom Hicks on 6 February 2007. The deal valued the club and its outstanding debts at £218.9 million. The pair paid £5,000 per share, or £174.1m for the total shareholding and £44.8m to cover the club's debts. Disagreements between Gillett and Hicks, and the fans' lack of support for them, resulted in the pair looking to sell the club. Martin Broughton was appointed chairman of the club on 16 April 2010 to oversee its sale. In May 2010, accounts were released showing the holding company of the club to be £350m in debt (due to leveraged takeover) with losses of £55m, causing auditor KPMG to qualify its audit opinion. The group's creditors, including the Royal Bank of Scotland, took Gillett and Hicks to court to force them to allow the board to proceed with the sale of the club, the major asset of the holding company. A High Court judge, Mr Justice Floyd, ruled in favour of the creditors and paved the way for the sale of the club to Fenway Sports Group (formerly New England Sports Ventures), although Gillett and Hicks still had the option to appeal. Liverpool was sold to Fenway Sports Group on 15 October 2010 for £300m.

Liverpool has been described as a global brand; a 2010 report valued the club's trademarks and associated intellectual property at £141m, an increase of £5m on the previous year. Liverpool was given a brand rating of AA (Very Strong). In April 2010 business magazine "Forbes" ranked Liverpool as the sixth most valuable football team in the world, behind Manchester United, Real Madrid, Arsenal, Barcelona and Bayern Munich; they valued the club at $822m (£532m), excluding debt. Accountants Deloitte ranked Liverpool eighth in the Deloitte Football Money League, which ranks the world's football clubs in terms of revenue. Liverpool's income in the 2009–10 season was €225.3m. According to a 2018 report by Deloitte, the club had an annual revenue of €424.2 million for the previous year, and "Forbes" valued the club at $1.944 billion. In 2018, annual revenue increased to €513.7 million, and "Forbes" valued the club at $2.183 billion. In 2019 revenue increased to €604 million (£533 million) according to Deloitte, with the club breaching the half a billion pounds mark.

In April 2020, the owners of the club came under fire from fans and the media for deciding to furlough all non-playing staff during the COVID-19 pandemic. In response to this, the club made a U-turn on the decision and apologised for their initial decision.

Liverpool featured in the first edition of BBC's "Match of the Day", which screened highlights of their match against Arsenal at Anfield on 22 August 1964. The first football match to be televised in colour was between Liverpool and West Ham United, broadcast live in March 1967. Liverpool fans featured in the Pink Floyd song "Fearless", in which they sang excerpts from "You'll Never Walk Alone". To mark the club's appearance in the 1988 FA Cup Final, Liverpool released the "Anfield Rap", a song featuring John Barnes and other members of the squad.

A docudrama on the Hillsborough disaster, written by Jimmy McGovern, was screened in 1996. It featured Christopher Eccleston as Trevor Hicks, who lost two teenage daughters in the disaster, went on to campaign for safer stadiums and helped to form the Hillsborough Families Support Group. Liverpool featured in the film "The 51st State", in which ex-hitman Felix DeSouza (Robert Carlyle) is a keen supporter of the team and the last scene takes place at a match between Liverpool and Manchester United. The club also featured in children's television show "Scully", about a young boy who tries to gain a trial with Liverpool.

Since the establishment of the club in 1892, 45 players have been club captain of Liverpool F.C. Andrew Hannah became the first captain of the club after Liverpool separated from Everton and formed its own club. Alex Raisbeck, who was club captain from 1899 to 1909, was the longest serving captain before being overtaken by Steven Gerrard who served 12 seasons as Liverpool captain starting from the 2003–04 season. The present captain is Jordan Henderson, who in the 2015–16 season replaced Gerrard who moved to LA Galaxy.


Source:

Source:


Source:

Liverpool's first trophy was the Lancashire League, which it won in the club's first season. In 1901, the club won its first League title, while the nineteenth and most recent was in 2020. Its first success in the FA Cup was in 1965. In terms of the number of trophies won, Liverpool's most successful decade was the 1980s, when the club won six League titles, two FA Cups, four League Cups, one Football League Super Cup, five Charity Shields (one shared) and two European Cups.

The club has accumulated more top-flight wins and points than any other English team. Liverpool also has the highest average league finishing position (3.3) for the 50-year period to 2015 and second-highest average league finishing position for the period 1900–1999 after Arsenal, with an average league placing of 8.7.

Liverpool are the most successful British club in international football with fourteen trophies, having won the European Cup/UEFA Champions League, UEFA's premier club competition, six times, an English record and only surpassed by Real Madrid and A.C. Milan. Liverpool's fifth European Cup win, in 2005, meant that the club was awarded the trophy permanently and was also awarded a multiple-winner badge. Liverpool also hold the English record of three wins in the UEFA Cup, UEFA's secondary club competition. In 2019, the club won the FIFA Club World Cup for the first time, and also became the first English club to win the international treble of Club World Cup, Champions League and UEFA Super Cup.











</doc>
<doc id="18120" url="https://en.wikipedia.org/wiki?curid=18120" title="Lysosome">
Lysosome

A lysosome () is a membrane-bound organelle found in many animal cells. They are spherical vesicles that contain hydrolytic enzymes that can break down many kinds of biomolecules. A lysosome has a specific composition, of both its membrane proteins, and its lumenal proteins. The lumen's pH (~4.5–5.0) is optimal for the enzymes involved in hydrolysis, analogous to the activity of the stomach. Besides degradation of polymers, the lysosome is involved in various cell processes, including secretion, plasma membrane repair, apoptosis, cell signaling, and energy metabolism.

Lysosomes act as the waste disposal system of the cell by digesting in use materials in the cytoplasm, from both inside and outside the cell. Material from outside the cell is taken-up through endocytosis, while material from the inside of the cell is digested through autophagy. The sizes of the organelles vary greatly—the larger ones can be more than 10 times the size of the smaller ones. They were discovered and named by Belgian biologist Christian de Duve, who eventually received the Nobel Prize in Physiology or Medicine in 1974.

Lysosomes are known to contain more than 60 different enzymes, and have more than 50 membrane proteins. Enzymes of the lysosomes are synthesised in the rough endoplasmic reticulum and exported to the Golgi apparatus upon recruitment by a complex composed of CLN6 and CLN8 proteins. The enzymes are trafficked from the Golgi apparatus to lysosomes in small vesicles, which fuse with larger acidic vesicles. Enzymes destined for a lysosome are specifically tagged with the molecule mannose 6-phosphate, so that they are properly sorted into acidified vesicles.

In 2009, Marco Sardiello and coworkers discovered that the synthesis of most lysosomal enzymes and membrane proteins is controlled by transcription factor EB (TFEB), which promotes the transcription of nuclear genes. Mutations in the genes for these enzymes are responsible for more than 50 different human genetic disorders, which are collectively known as lysosomal storage diseases. These diseases result from an accumulation of specific substrates, due to the inability to break them down. These genetic defects are related to several neurodegenerative disorders, cancers, cardiovascular diseases, and aging-related diseases.

Lysosomes should not be confused with liposomes, or with micelles.

Christian de Duve, the chairman of the Laboratory of Physiological Chemistry at the Catholic University of Louvain in Belgium, had been studying the mechanism of action of a pancreatic hormone insulin in liver cells. By 1949, he and his team had focused on the enzyme called glucose 6-phosphatase, which is the first crucial enzyme in sugar metabolism and the target of insulin. They already suspected that this enzyme played a key role in regulating blood sugar levels. However, even after a series of experiments, they failed to purify and isolate the enzyme from the cellular extracts. Therefore, they tried a more arduous procedure of cell fractionation, by which cellular components are separated based on their sizes using centrifugation.

They succeeded in detecting the enzyme activity from the microsomal fraction. This was the crucial step in the serendipitous discovery of lysosomes. To estimate this enzyme activity, they used that of the standardized enzyme acid phosphatase and found that the activity was only 10% of the expected value. One day, the enzyme activity of purified cell fractions which had been refrigerated for five days was measured. Surprisingly, the enzyme activity was increased to normal of that of the fresh sample. The result was the same no matter how many times they repeated the estimation, and led to the conclusion that a membrane-like barrier limited the accessibility of the enzyme to its substrate, and that the enzymes were able to diffuse after a few days (and react with their substrate). They described this membrane-like barrier as a "saclike structure surrounded by a membrane and containing acid phosphatase."

It became clear that this enzyme from the cell fraction came from membranous fractions, which were definitely cell organelles, and in 1955 De Duve named them "lysosomes" to reflect their digestive properties. The same year, Alex B. Novikoff from the University of Vermont visited de Duve's laboratory, and successfully obtained the first electron micrographs of the new organelle. Using a staining method for acid phosphatase, de Duve and Novikoff confirmed the location of the hydrolytic enzymes of lysosomes using light and electron microscopic studies. de Duve won the Nobel Prize in Physiology or Medicine in 1974 for this discovery.

Originally, De Duve had termed the organelles the "suicide bags" or "suicide sacs" of the cells, for their hypothesized role in apoptosis. However, it has since been concluded that they only play a minor role in cell death.

Lysosomes contain a variety of enzymes, enabling the cell to break down various biomolecules it engulfs, including peptides, nucleic acids, carbohydrates, and lipids (lysosomal lipase). The enzymes responsible for this hydrolysis require an acidic environment for optimal activity.

In addition to being able to break down polymers, lysosomes are capable of fusing with other organelles & digesting large structures or cellular debris; through cooperation with phagosomes, they are able to conduct autophagy, clearing out damaged structures. Similarly, they are able to break-down virus particles or bacteria in phagocytosis of macrophages.

The size of lysosomes varies from 0.1 μm to 1.2 μm. With a pH ranging from ~4.5–5.0, the interior of the lysosomes is acidic compared to the slightly basic cytosol (pH 7.2). The lysosomal membrane protects the cytosol, and therefore the rest of the cell, from the degradative enzymes within the lysosome. The cell is additionally protected from any lysosomal acid hydrolases that drain into the cytosol, as these enzymes are pH-sensitive and do not function well or at all in the alkaline environment of the cytosol. This ensures that cytosolic molecules and organelles are not destroyed in case there is leakage of the hydrolytic enzymes from the lysosome.

The lysosome maintains its pH differential by pumping in protons (H ions) from the cytosol across the membrane via proton pumps and chloride ion channels. Vacuolar-ATPases are responsible for transport of protons, while the counter transport of chloride ions is performed by ClC-7 Cl/H antiporter. In this way a steady acidic environment is maintained.

It sources its versatile capacity for degradation by import of enzymes with specificity for different substrates; cathepsins are the major class of hydrolytic enzymes, while lysosomal alpha-glucosidase is responsible for carbohydrates, and lysosomal acid phosphatase is necessary to release phosphate groups of phospholipids.

Many components of animal cells are recycled by transferring them inside or embedded in sections of membrane. For instance, in endocytosis (more specifically, macropinocytosis), a portion of the cell's plasma membrane pinches off to form vesicles that will eventually fuse with an organelle within the cell. Without active replenishment, the plasma membrane would continuously decrease in size. It is thought that lysosomes participate in this dynamic membrane exchange system and are formed by a gradual maturation process from endosomes.

The production of lysosomal proteins suggests one method of lysosome sustainment. Lysosomal protein genes are transcribed in the nucleus in a process that is controlled by transcription factor EB (TFEB). mRNA transcripts exit the nucleus into the cytosol, where they are translated by ribosomes. The nascent peptide chains are translocated into the rough endoplasmic reticulum, where they are modified. Lysosomal soluble proteins exit the endoplasmic reticulum via COPII-coated vesicles after recruitment by the EGRESS complex (ER-to-Golgi relaying of enzymes of the lysosomal system), which is composed of CLN6 and CLN8 proteins. COPII vesicles then deliver lysosomal enzymes to the Golgi apparatus, where a specific lysosomal tag, mannose 6-phosphate, is added to the peptides. The presence of these tags allow for binding to mannose 6-phosphate receptors in the Golgi apparatus, a phenomenon that is crucial for proper packaging into vesicles destined for the lysosomal system.

Upon leaving the Golgi apparatus, the lysosomal enzyme-filled vesicle fuses with a late endosome, a relatively acidic organelle with an approximate pH of 5.5. This acidic environment causes dissociation of the lysosomal enzymes from the mannose 6-phosphate receptors. The enzymes are packed into vesicles for further transport to established lysosomes. The late endosome itself can eventually grow into a mature lysosome, as evidenced by the transport of endosomal membrane components from the lysosomes back to the endosomes.

As the endpoint of endocytosis, the lysosome also acts as a safeguard in preventing pathogens from being able to reach the cytoplasm before being degraded. Pathogens often hijack endocytotic pathways such as pinocytosis in order to gain entry into the cell. The lysosome prevents easy entry into the cell by hydrolyzing the biomolecules of pathogens necessary for their replication strategies; reduced Lysosomal activity results in an increase in viral infectivity, including HIV. In addition, AB toxins such as cholera hijack the endosomal pathway while evading lysosomal degradation.

Lysosomes are involved in a group of genetically inherited deficiencies, or mutations called lysosomal storage diseases (LSD), inborn errors of metabolism caused by a dysfunction of one of the enzymes. The rate of incidence is estimated to be 1 in 5,000 births, and the true figure expected to be higher as many cases are likely to be undiagnosed or misdiagnosed. The primary cause is deficiency of an acid hydrolase. Other conditions are due to defects in lysosomal membrane proteins that fail to transport the enzyme, non-enzymatic soluble lysosomal proteins. The initial effect of such disorders is accumulation of specific macromolecules or monomeric compounds inside the endosomal–autophagic–lysosomal system. This results in abnormal signaling pathways, calcium homeostasis, lipid biosynthesis and degradation and intracellular trafficking, ultimately leading to pathogenetic disorders. The organs most affected are brain, viscera, bone and cartilage.

There is no direct medical treatment to cure LSDs. The most common LSD is Gaucher's disease, which is due to deficiency of the enzyme glucocerebrosidase. Consequently, the enzyme substrate, the fatty acid glucosylceramide accumulates, particularly in white blood cells, which in turn affects spleen, liver, kidneys, lungs, brain and bone marrow. The disease is characterized by bruises, fatigue, anaemia, low blood platelets, osteoporosis, and enlargement of the liver and spleen. As of 2017, enzyme replacement therapy is available for treating 8 of the 50-60 known LDs.

The most severe and rarely found, lysosomal storage disease is inclusion cell disease.

Metachromatic leukodystrophy is another lysosomal storage disease that also affects sphingolipid metabolism.

Dysfunctional lysosome activity is also heavily implicated in the biology of aging, and age-related diseases such as Alzheimer's, Parkinson's, and cardiovascular disease. 

Weak bases with lipophilic properties accumulate in acidic intracellular compartments like lysosomes. While the plasma and lysosomal membranes are permeable for neutral and uncharged species of weak bases, the charged protonated species of weak bases do not permeate biomembranes and accumulate within lysosomes. The concentration within lysosomes may reach levels 100 to 1000 fold higher than extracellular concentrations. This phenomenon is called lysosomotropism, "acid trapping" or "proton pump" effect. The amount of accumulation of lysosomotropic compounds may be estimated using a cell-based mathematical model.

A significant part of the clinically approved drugs are lipophilic weak bases with lysosomotropic properties. This explains a number of pharmacological properties of these drugs, such as high tissue-to-blood concentration gradients or long tissue elimination half-lifes; these properties have been found for drugs such as haloperidol, levomepromazine, and amantadine. However, high tissue concentrations and long elimination half-lives are explained also by lipophilicity and absorption of drugs to fatty tissue structures. Important lysosomal enzymes, such as acid sphingomyelinase, may be inhibited by lysosomally accumulated drugs. Such compounds are termed FIASMAs (functional inhibitor of acid sphingomyelinase) and include for example fluoxetine, sertraline, or amitriptyline.

Ambroxol is a lysosomotropic drug of clinical use to treat conditions of productive cough for its mucolytic action. Ambroxol triggers the exocytosis of lysosomes via neutralization of lysosomal pH and calcium release from acidic calcium stores. Presumably for this reason, Ambroxol was also found to improve cellular function in some disease of lysosomal origin such as Parkinson's or lysosomal storage disease.

Impaired lysosome function is prominent in systemic lupus erythematosus preventing macrophages and monocytes from degrading neutrophil extracellular traps and immune complexes. The failure to degrade internalized immune complexes stems from chronic mTORC2 activity, which impairs lysosome acidification. As a result, immune complexes in the lysosome recycle to the surface of macrophages causing an accumulation of nuclear antigens upstream of multiple lupus-associated pathologies.

By scientific convention, the term lysosome is applied to these vesicular organelles only in animals, and the term vacuole is applied to those in plants, fungi and algae (some animal cells also have vacuoles). Discoveries in plant cells since the 1970s started to challenge this definition. Plant vacuoles are found to be much more diverse in structure and function than previously thought. Some vacuoles contain their own hydrolytic enzymes and perform the classic lysosomal activity, which is autophagy. These vacuoles are therefore seen as fulfilling the role of the animal lysosome. Based on de Duve's description that "only when considered as part of a system involved directly or indirectly in intracellular digestion does the term lysosome describe a physiological unit", some botanists strongly argued that these vacuoles are lysosomes. However, this is not universally accepted as the vacuoles are strictly not similar to lysosomes, such as in their specific enzymes and lack of phagocytic functions. Vacuoles do not have catabolic activity and do not undergo exocytosis as lysosomes do.

The word "lysosome" (, ) is New Latin that uses the combining forms "lyso-" (referring to lysis and derived from the Latin "lysis", meaning "to loosen", via Ancient Greek λύσις [lúsis]), and "-some", from "soma", "body", yielding "body that lyses" or "lytic body". The adjectival form is "lysosomal". The forms "*lyosome" and "*lyosomal" are much rarer; they use the "lyo-" form of the prefix but are often treated by readers and editors as mere unthinking replications of typos, which has no doubt been true as often as not.




</doc>
<doc id="18121" url="https://en.wikipedia.org/wiki?curid=18121" title="Leg spin">
Leg spin

Leg spin is a type of spin bowling in cricket. A leg spinner bowls right-arm with a wrist spin action. The leg spinner's normal delivery causes the ball to spin from right to left (from the bowler's perspective) in the cricket pitch when the ball bounces. For a right-handed batsman, that is away from the leg side, and this is where it gets the name leg break, meaning it breaks away from the leg. The turn is mostly when the ball pitches.

Leg spinners bowl mostly leg breaks, varying them by adjusting the line and length, and amount of side spin versus topspin of the deliveries. Leg spinners also typically use variations of flight by sometimes looping the ball in the air, allowing any cross-breeze and the aerodynamic effects of the spinning ball to cause the ball to dip and drift before bouncing and spinning (usually called ‘turning’) sharply. Leg spinners also bowl other types of delivery, which spin differently, such as the googly.

The terms 'leg spin', 'leg spinner', 'leg break' and 'leggie' are used in slightly different ways by different .

The bowlers with the second and third highest number of wickets in the history of Test cricket, Shane Warne and Anil Kumble, were leg spinners. One famous example of leg spin is Warne's Ball of the Century.

In the 1970s and 1980s it was thought that leg spin would disappear from the game due to the success of West Indian, and later Australian teams, exclusively using fast bowlers. During this time Abdul Qadir of Pakistan was the highest-profile leg spinner in the world and is sometimes credited with "keeping the art alive". However, leg spin has again become popular with cricket fans and a successful part of cricket teams, driven largely by the success of Shane Warne, beginning with his spectacular Ball of the Century to Mike Gatting in 1993.

A left-handed bowler who bowls with the same (wrist spin) action as a leg spinner is known as a left-arm unorthodox spin bowler. The ball itself spins in the opposite direction.

The same kind of trajectory, which spins from right to left on pitching, when performed by a left-arm bowler is known as left-arm orthodox spin bowling.

As with all spinners, leg spinners bowl the ball far more slowly (70–90 km/h or 45–55 mph) than fast bowlers. The fastest leg spinners will sometimes top 100 km/h (60 mph). While very difficult to bowl accurately, good leg spin is considered one of the most threatening types of bowling to bat against for a right-handed batsman, since the flight and sharp turn make the ball's movement extremely hard to read, and the turn away from the right-handed batsman is more dangerous than the turn into the right-handed batsman generated by an off spinner. Any miscalculation can result in an outside edge off the bat and a catch going to the wicket-keeper or slip fielders. Alternatively, for a ball aimed outside the leg stump, the breaking may be so sharp that the ball goes behind a right-handed batsman and hits the stumps – the batsman is then said (informally) to be "bowled around his legs". A left-handed batsman has less difficulty facing leg spin bowling, because the ball moves in towards the batsman's body, meaning the batsman's legs are usually in the path of the ball if it misses the bat or takes an edge. This makes it difficult for the bowler to get the batsman out bowled or caught from a leg break.

Leg spin: Some sources make the term 'leg spin' synonymous with leg break, implying that other deliveries bowled by a leg spinner do not count as 'leg spin'. However, other sources use the term 'leg spin' more widely, to include all deliveries bowled by a leg spinner, including non-leg break deliveries. 

Leg break: In the definition of a leg break, some sources actually include the bowler being a leg spinner, which implies that only leg spinners can bowl leg breaks; all leg breaks are bowled by leg spinners. Other sources do not include the bowler being a leg spinner in the definition of a leg break, and say a leg break is simply a delivery that spins from the legside to the offside, and so can also be bowled by other types of bowler. In this case, leg breaks are (only) mostly bowled by leg spinners.

Leg spinner: The term leg spinner can be used to mean either the bowler or the leg break delivery.

Leggie: The term leggie can also be used to mean either the bowler or the leg break delivery.

A leg break is bowled by holding the cricket ball in the palm of the hand with the seam running across under all the fingers. As the ball is released, the wrist is rotated to the left and the ball flicked by the ring finger, giving the ball an anti-clockwise spin as seen from behind.

To grip the ball for a leg-spinning delivery, the ball is placed into the palm with the seam parallel to the palm. The first two fingers then spread and grip the ball, and the third and fourth fingers close together and rest against the side of the ball. The first bend of the third finger should grasp the seam. The thumb resting against the side is up to the bowler but should impart no pressure. When the ball is bowled, the third finger will apply most of the spin. The wrist is cocked as it comes down by the hip, and the wrist moves sharply from right to left as the ball is released, adding more spin. The ball is tossed up to provide flight. The batsman will see the hand with the palm facing towards them when the ball is released.

Players listed below have been included as they meet specific criteria which the general cricketing public would recognise as having achieved significant success in the art of leg spin bowling. For example: leading wicket-takers, and inventors of new deliveries.


Highly skilled leg spin bowlers are also able to bowl deliveries that behave unexpectedly, including the googly, which turns the opposite way to a normal leg break and the topspinner, which does not turn but dips sharply and bounces higher than other deliveries. A few leg spinners such as Abdul Qadir, Anil Kumble, Shane Warne and Mushtaq Ahmed have also mastered the flipper, a delivery that like a topspinner goes straight on landing, but floats through the air before skidding and keeping low, often dismissing batsmen leg before wicket or bowled. Another variation in the arsenal of some leg spinners is the slider, a leg break pushed out of the hand somewhat faster, so that it does not spin as much, but travels more straight on.




</doc>
<doc id="18123" url="https://en.wikipedia.org/wiki?curid=18123" title="Lisp machine">
Lisp machine

Lisp machines are general-purpose computers designed to efficiently run Lisp as their main software and programming language, usually via hardware support. They are an example of a high-level language computer architecture, and in a sense, they were the first commercial single-user workstations. Despite being modest in number (perhaps 7,000 units total as of 1988), Lisp machines commercially pioneered many now-commonplace technologies, including effective garbage collection, laser printing, windowing systems, computer mice, high-resolution bit-mapped raster graphics, computer graphic rendering, and networking innovations such as Chaosnet. Several firms built and sold Lisp machines in the 1980s: Symbolics (3600, 3640, XL1200, MacIvory, and other models), Lisp Machines Incorporated (LMI Lambda), Texas Instruments (Explorer and MicroExplorer), and Xerox (Interlisp-D workstations). The operating systems were written in Lisp Machine Lisp, Interlisp (Xerox), and later partly in Common Lisp.

Artificial intelligence (AI) computer programs of the 1960s and 1970s intrinsically required what was then considered a huge amount of computer power, as measured in processor time and memory space. The power requirements of AI research were exacerbated by the Lisp symbolic programming language, when commercial hardware was designed and optimized for assembly- and Fortran-like programming languages. At first, the cost of such computer hardware meant that it had to be shared among many users. As integrated circuit technology shrank the size and cost of computers in the 1960s and early 1970s, and the memory needs of AI programs began to exceed the address space of the most common research computer, the DEC PDP-10, researchers considered a new approach: a computer designed specifically to develop and run large artificial intelligence programs, and tailored to the semantics of the Lisp language. To keep the operating system (relatively) simple, these machines would not be shared, but would be dedicated to single users.

In 1973, Richard Greenblatt and Thomas Knight, programmers at Massachusetts Institute of Technology (MIT) Artificial Intelligence Laboratory (AI Lab), began what would become the MIT Lisp Machine Project when they first began building a computer hardwired to run certain basic Lisp operations, rather than run them in software, in a 24-bit tagged architecture. The machine also did incremental (or "Arena") garbage collection. More specifically, since Lisp variables are typed at runtime rather than compile time, a simple addition of two variables could take five times as long on conventional hardware, due to test and branch instructions. Lisp Machines ran the tests in parallel with the more conventional single instruction additions. If the simultaneous tests failed, then the result was discarded and recomputed; this meant in many cases a speed increase by several factors. This simultaneous checking approach was used as well in testing the bounds of arrays when referenced, and other memory management necessities (not merely garbage collection or arrays).

Type checking was further improved and automated when the conventional byte word of 32-bits was lengthened to 36-bits for Symbolics 3600-model Lisp machines and eventually to 40-bits or more (usually, the excess bits not accounted for by the following were used for error-correcting codes). The first group of extra bits were used to hold type data, making the machine a tagged architecture, and the remaining bits were used to implement CDR coding (wherein the usual linked list elements are compressed to occupy roughly half the space), aiding garbage collection by reportedly an order of magnitude. A further improvement was two microcode instructions which specifically supported Lisp functions, reducing the cost of calling a function to as little as 20 clock cycles, in some Symbolics implementations.

The first machine was called the CONS machine (named after the list construction operator codice_1 in Lisp). Often it was affectionately referred to as the "Knight machine", perhaps since Knight wrote his master's thesis on the subject; it was extremely well received. It was subsequently improved into a version called CADR (a pun; in Lisp, the codice_2 function, which returns the second item of a list, is pronounced or , as some pronounce the word "cadre") which was based on essentially the same architecture. About 25 of what were essentially prototype CADRs were sold within and without MIT for ~$50,000; it quickly became the favorite machine for hacking- many of the most favored software tools were quickly ported to it (e.g. Emacs was ported from ITS in 1975). It was so well received at an AI conference held at MIT in 1978 that Defense Advanced Research Projects Agency (DARPA) began funding its development.

In 1979, Russell Noftsker, being convinced that Lisp machines had a bright commercial future due to the strength of the Lisp language and the enabling factor of hardware acceleration, proposed to Greenblatt that they commercialize the technology. In a counter-intuitive move for an AI Lab hacker, Greenblatt acquiesced, hoping perhaps that he could recreate the informal and productive atmosphere of the Lab in a real business. These ideas and goals were considerably different from those of Noftsker. The two negotiated at length, but neither would compromise. As the proposed firm could succeed only with the full and undivided assistance of the AI Lab hackers as a group, Noftsker and Greenblatt decided that the fate of the enterprise was up to them, and so the choice should be left to the hackers.

The ensuing discussions of the choice divided the lab into two factions. In February 1979, matters came to a head. The hackers sided with Noftsker, believing that a commercial venture fund-backed firm had a better chance of surviving and commercializing Lisp machines than Greenblatt's proposed self-sustaining start-up. Greenblatt lost the battle.

It was at this juncture that Symbolics, Noftsker's enterprise, slowly came together. While Noftsker was paying his staff a salary, he had no building or any equipment for the hackers to work on. He bargained with Patrick Winston that, in exchange for allowing Symbolics' staff to keep working out of MIT, Symbolics would let MIT use internally and freely all the software Symbolics developed. A consultant from CDC, who was trying to put together a natural language computer application with a group of West-coast programmers, came to Greenblatt, seeking a Lisp machine for his group to work with, about eight months after the disastrous conference with Noftsker. Greenblatt had decided to start his own rival Lisp machine firm, but he had done nothing. The consultant, Alexander Jacobson, decided that the only way Greenblatt was going to start the firm and build the Lisp machines that Jacobson desperately needed was if Jacobson pushed and otherwise helped Greenblatt launch the firm. Jacobson pulled together business plans, a board, a partner for Greenblatt (one F. Stephen Wyle). The newfound firm was named "LISP Machine, Inc." (LMI), and was funded by CDC orders, via Jacobson.

Around this time Symbolics (Noftsker's firm) began operating. It had been hindered by Noftsker's promise to give Greenblatt a year's head start, and by severe delays in procuring venture capital. Symbolics still had the major advantage that while 3 or 4 of the AI Lab hackers had gone to work for Greenblatt, a solid 14 other hackers had signed onto Symbolics. Two AI Lab people were not hired by either: Richard Stallman and Marvin Minsky. Stallman, however, blamed Symbolics for the decline of the hacker community that had centered around the AI lab. For two years, from 1982 to the end of 1983, Stallman worked by himself to clone the output of the Symbolics programmers, with the aim of preventing them from gaining a monopoly on the lab's computers.

Regardless, after a series of internal battles, Symbolics did get off the ground in 1980/1981, selling the CADR as the LM-2, while Lisp Machines, Inc. sold it as the LMI-CADR. Symbolics did not intend to produce many LM-2s, since the 3600 family of Lisp machines was supposed to ship quickly, but the 3600s were repeatedly delayed, and Symbolics ended up producing ~100 LM-2s, each of which sold for $70,000. Both firms developed second-generation products based on the CADR: the Symbolics 3600 and the LMI-LAMBDA (of which LMI managed to sell ~200). The 3600, which shipped a year late, expanded on the CADR by widening the machine word to 36-bits, expanding the address space to 28-bits, and adding hardware to accelerate certain common functions that were implemented in microcode on the CADR. The LMI-LAMBDA, which came out a year after the 3600, in 1983, was compatible with the CADR (it could run CADR microcode), but hardware differences existed. Texas Instruments (TI) joined the fray when it licensed the LMI-LAMBDA design and produced its own variant, the TI Explorer. Some of the LMI-LAMBDAs and the TI Explorer were dual systems with both a Lisp and a Unix processor. TI also developed a 32-bit microprocessor version of its Lisp CPU for the TI Explorer. This Lisp chip also was used for the MicroExplorer – a NuBus board for the Apple Macintosh II (NuBus was initially developed at MIT for use in Lisp machines).

Symbolics continued to develop the 3600 family and its operating system, Genera, and produced the Ivory, a VLSI implementation of the Symbolics architecture. Starting in 1987, several machines based on the Ivory processor were developed: boards for Suns and Macs, stand-alone workstations and even embedded systems (I-Machine Custom LSI, 32 bit address, Symbolics XL-400, UX-400, MacIvory II; in 1989 available platforms were Symbolics XL-1200, MacIvory III, UX-1200, Zora, NXP1000 "pizza box"). Texas Instruments shrank the Explorer into silicon as the MicroExplorer which was offered as a card for the Apple Mac II. LMI abandoned the CADR architecture and developed its own K-Machine, but LMI went bankrupt before the machine could be brought to market. Before its demise, LMI was working on a distributed system for the LAMBDA using Moby space.

These machines had hardware support for various primitive Lisp operations (data type testing, CDR coding) and also hardware support for incremental garbage collection. They ran large Lisp programs very efficiently. The Symbolics machine was competitive against many commercial super minicomputers, but was never adapted for conventional purposes. The Symbolics Lisp Machines were also sold to some non-AI markets like computer graphics, modeling, and animation.

The MIT-derived Lisp machines ran a Lisp dialect named Lisp Machine Lisp, descended from MIT's Maclisp. The operating systems were written from the ground up in Lisp, often using object-oriented extensions. Later, these Lisp machines also supported various versions of Common Lisp (with Flavors, New Flavors, and Common Lisp Object System (CLOS)).

Bolt, Beranek and Newman (BBN) developed its own Lisp machine, named Jericho, which ran a version of Interlisp. It was never marketed. Frustrated, the whole AI group resigned, and were hired mostly by Xerox. So, Xerox Palo Alto Research Center had, simultaneously with Greenblatt's own development at MIT, developed their own Lisp machines which were designed to run InterLisp (and later Common Lisp). The same hardware was used with different software also as Smalltalk machines and as the Xerox Star office system. These included the Xerox 1100, "Dolphin" (1979); the Xerox 1132, "Dorado"; the Xerox 1108, "Dandelion" (1981); the Xerox 1109, "Dandetiger"; and the Xerox 1186/6085, "Daybreak". The operating system of the Xerox Lisp machines has also been ported to a virtual machine and is available for several platforms as a product named "Medley". The Xerox machine was well known for its advanced development environment (InterLisp-D), the ROOMS window manager, for its early graphical user interface and for novel applications like NoteCards (one of the first hypertext applications).

Xerox also worked on a Lisp machine based on reduced instruction set computing (RISC), using the 'Xerox Common Lisp Processor' and planned to bring it to market by 1987, which did not occur.

In the mid-1980s, Integrated Inference Machines (IIM) built prototypes of Lisp machines named Inferstar.

In 1984–85 a UK firm, Racal-Norsk, a joint subsidiary of Racal and Norsk Data, attempted to repurpose Norsk Data's ND-500 supermini as a microcoded Lisp machine, running CADR software: the Knowledge Processing System (KPS).

There were several attempts by Japanese manufacturers to enter the Lisp machine market: the Fujitsu Facom-alpha mainframe co-processor, NTT's Elis, Toshiba's AI processor (AIP) and NEC's LIME. Several university research efforts produced working prototypes, among them are Kobe University's TAKITAC-7, RIKEN's FLATS, and Osaka University's EVLIS.

In France, two Lisp Machine projects arose: M3L at Toulouse Paul Sabatier University and later MAIA.

In Germany Siemens designed the RISC-based Lisp co-processor COLIBRI.

With the onset of the "AI winter" and the early beginnings of the microcomputer revolution, which would sweep away the minicomputer and workstation makers, cheaper desktop PCs soon could run Lisp programs even faster than Lisp machines, with no use of special purpose hardware. Their high profit margin hardware business eliminated, most Lisp machine makers had gone out of business by the early 90s, leaving only software based firms like Lucid Inc. or hardware makers who had switched to software and services to avoid the crash. , besides Xerox, Symbolics is the only Lisp machine firm still operating, selling the Open Genera Lisp machine software environment and the Macsyma computer algebra system.

Several attempts to write open-source emulators for various Lisp Machines have been made: CADR Emulation, Symbolics L Lisp Machine Emulation, the E3 Project (TI Explorer II Emulation), Meroko (TI Explorer I), and Nevermore (TI Explorer I). On 3 October 2005, the MIT released the CADR Lisp Machine source code as open source.

In September 2014, Alexander Burger, developer of PicoLisp, announced PilMCU, an implementation of PicoLisp in hardware.

The Bitsavers' PDF Document Archive has PDF versions of the extensive documentation for the Symbolics Lisp Machines, the TI Explorer and MicroExplorer Lisp Machines and the Xerox Interlisp-D Lisp Machines.

Domains using the Lisp machines were mostly in the wide field of artificial intelligence applications, but also in computer graphics, medical image processing, and many others.

The main commercial expert systems of the 80s were available: Intellicorp's Knowledge Engineering Environment (KEE), Knowledge Craft, from The Carnegie Group Inc., and ART (Automated Reasoning Tool) from Inference Corporation.

Initially the Lisp machines were designed as personal workstations for software development in Lisp. They were used by one person and offered no multi-user mode. The machines provided a large, black and white, bitmap display, keyboard and mouse, network adapter, local hard disks, more than 1 MB RAM, serial interfaces, and a local bus for extension cards. Color graphics cards, tape drives, and laser printers were optional.

The processor did not run Lisp directly, but was a stack machine with instructions optimized for compiled Lisp. The early Lisp machines used microcode to provide the instruction set. For several operations, type checking and dispatching was done in hardware at runtime. For example, only one addition operation could be used with various numeric types (integer, float, rational, and complex numbers). The result was a very compact compiled representation of Lisp code.

The following example uses a function that counts the number of elements of a list for which a predicate returns codice_3.
The disassembled machine code for above function (for the Ivory microprocessor from Symbolics):
Command: (disassemble (compile #'example-count))

The operating system used virtual memory to provide a large address space. Memory management was done with garbage collection. All code shared a single address space. All data objects were stored with a tag in memory, so that the type could be determined at runtime. Multiple execution threads were supported and termed "processes". All processes ran in the one address space.

All operating system software was written in Lisp. Xerox used Interlisp. Symbolics, LMI, and TI used Lisp Machine Lisp (descendant of MacLisp). With the appearance of Common Lisp, Common Lisp was supported on the Lisp Machines and some system software was ported to Common Lisp or later written in Common Lisp.

Some later Lisp machines (like the TI MicroExplorer, the Symbolics MacIvory or the Symbolics UX400/1200) were no longer complete workstations, but boards designed to be embedded in host computers: Apple Macintosh II and SUN 3 or 4.

Some Lisp machines, such as the Symbolics XL1200, had extensive graphics abilities using special graphics boards. These machines were used in domains like medical image processing, 3D animation, and CAD.







</doc>
<doc id="18125" url="https://en.wikipedia.org/wiki?curid=18125" title="Links (web browser)">
Links (web browser)

Links is an open source text and graphic web browser with a pull-down menu system. It renders complex pages, has partial HTML 4.0 support (including tables and frames and support for multiple character sets such as UTF-8), supports color and monochrome terminals and allows horizontal scrolling.

It is intended for users who want to retain many typical elements of graphical user interfaces (pop-up windows, menus etc.) in a text-only environment.

The original version of Links was developed by Mikuláš Patočka in the Czech Republic. His group "Twibright Labs" later developed version 2 of the Links browser, that displays graphics, renders fonts in different sizes (with spatial anti-aliasing), but does not support JavaScript any more (it used to, up to version 2.1pre28). The resulting browser is very fast, but it does not display many pages as they were intended. The graphical mode works even on Unix systems without the X Window System or any other window environment, using either SVGALib or the framebuffer of the system's graphics card.

The graphics stack has several peculiarities unusual for a web browser. The fonts displayed by Links are not derived from the system, but compiled into the binary as grayscale bitmaps in Portable Network Graphics (PNG) format. This allows the browser to be one executable file independent of the system libraries. However this increases the size of the executable to about 5 MB.

The fonts are anti-aliased without hinting and for small line pitch an artificial sharpening is employed to increase legibility. Subpixel sampling further increases legibility on LCD displays. This allowed Links to have anti-aliased fonts at a time when anti-aliased font libraries were uncommon.

All graphic elements (images and text) are first converted from given gamma space (according to known or assumed gamma information in PNG, JPEG etc.) through known user gamma setting into a 48 bits per pixel photometrically linear space where they are resampled with bilinear resampling to the target size, possibly taking aspect ratio correction into account. Then the data are passed through high-performance restartable dithering engine which is used regardless of monitor bit depth, i.e., also for 24 bits per pixel colour. This Floyd-Steinberg dithering engine takes into account the gamma characteristics of the monitor and uses 768 KiB of dithering tables to avoid time expensive calculations. A technique similar to self-modifying code, function templates, is used to maximize the speed of the dithering engine without using assembly language optimization, which is non-portable.

Images which are scaled down also use subpixel sampling on LCD to increase level of detail.

The reason for this high quality processing is: provide proper realistic up and down sampling of images, and photorealistic display regardless of the monitor gamma, without colour fringing caused by 8-bit gamma correction built into the X server. It also increases the perceived colour depth over 24 bits per pixel.

Links has graphics drivers for the X Server, Linux framebuffer, svgalib, OS/2 PMShell and AtheOS GUI. This allows it to run in graphics mode even on platforms which don't have X Server.

"Experimental/Enhanced Links" (ELinks) is a fork of Links led by Petr Baudis. It is based on Links 0.9. It has a more open development and incorporates patches from other Links versions (such as additional extension scripting in Lua) and from Internet users.

"Hacked Links" is another version of the Links browser which has merged some of Elinks' features into Links 2.

Andrey Mirtchovski has ported it to Plan 9 from Bell Labs. It is considered a good browser on that operating system, though some users have complained about its inability to cut and paste with the Plan 9 snarf buffer.

, the last release of Hacked Links is that of July 9, 2003 with some further changes unreleased.

Links was also ported to run on the Sony PSP platform as PSPRadio by Rafael Cabezas with the last version (2.1pre23_PSP_r1261) released on February 6, 2007.

The BeOS port was updated by François Revol who also added GUI support. It also runs on Haiku.



</doc>
<doc id="18126" url="https://en.wikipedia.org/wiki?curid=18126" title="Learning object">
Learning object

A learning object is "a collection of content items, practice items, and assessment items that are combined based on a single learning objective". The term is credited to Wayne Hodgins, and dates from a working group in 1994 bearing the name. The concept encompassed by 'Learning Objects' is known by numerous other terms, including: content objects, chunks, educational objects, information objects, intelligent objects, knowledge bits, knowledge objects, learning components, media objects, reusable curriculum components, nuggets, reusable information objects, reusable learning objects, testable reusable units of cognition, training components, and units of learning.

The core idea of the use of learning objects is characterized by the following: discoverability, reusability, and interoperability. To support discoverability, learning objects are described by Learning Object Metadata, formalized as IEEE 1484.12 Learning object metadata. To support reusability, the IMS Consortium proposed a series of specifications such as the IMS Content package. And to support interoperability, the U.S. military's Advanced Distributed Learning organization created the Sharable Content Object Reference Model. Learning objects were designed in order to reduce the cost of learning, standardize learning content, and to enable the use and reuse of learning content by learning management systems.

The Institute of Electrical and Electronics Engineers (IEEE) defines a learning object as "any entity, digital or non-digital, that may be used for learning, education or training".

Chiappe defined Learning Objects as: "A digital self-contained and reusable entity, with a clear educational purpose, with at least three internal and editable components: content, learning activities and elements of context. The learning objects must have an external structure of information to facilitate their identification, storage and retrieval: the metadata."

The following definitions focus on the relation between learning object and digital media. RLO-CETL, a British inter-university Learning Objects Center, defines "reusable learning objects" as "web-based interactive chunks of e-learning designed to explain a stand-alone learning objective". Daniel Rehak and Robin Mason define it as "a digitized entity which can be used, reused or referenced during technology supported learning".

Adapting a definition from the Wisconsin Online Resource Center, Robert J. Beck suggests that learning objects have the following key characteristics:


The following is a list of some of the types of information that may be included in a learning object and its metadata:

One of the key issues in using learning objects is their identification by search engines or content management systems. This is usually facilitated by assigning descriptive learning object metadata. Just as a book in a library has a record in the card catalog, learning objects must also be tagged with metadata. The most important pieces of metadata typically associated with a learning object include:

A mutated learning object is, according to Michael Shaw, a learning object that has been "re-purposed and/or re-engineered, changed or simply re-used in some way different from its original intended design". Shaw also introduces the term "contextual learning object", to describe a learning object that has been "designed to have specific meaning and purpose to an intended learner". This may be useful if the intent involves just-in-time learning and the individual needs of individual learners.

Before any institution invests a great deal of time and energy into building high-quality e-learning content (which can cost over $10,000 per classroom hour), it needs to consider how this content can be easily loaded into a Learning Management System. It is possible for example, to package learning objects with SCORM specification and load it in Moodle Learning Management System or Desire2Learn Learning Environment.

If all of the properties of a course can be precisely defined in a common format, the content can be serialized into a standard format such as XML and loaded into other systems. When it is considered that some e-learning courses need to include video, mathematical equations using MathML, chemistry equations using CML and other complex structures, the issues become very complex, especially if the systems needs to understand and validate each structure and then place it correctly in a database.

In 2001, David Wiley criticized learning object theory in his paper, The Reusability Paradox which is summarized by D'Arcy Norman as, "If a learning object is useful in a particular context, by definition it is not reusable in a different context. If a learning object is reusable in many contexts, it isn’t particularly useful in any." 
In Three Objections to Learning Objects and E-learning Standards, Norm Friesen, Canada Research Chair in E-Learning Practices at Thompson Rivers University, points out that the word "neutrality" in itself implies "a state or position that is antithetical ... to pedagogy and teaching."


Innayah: Creating An Audio Script with Learning Object, unpublished, 2013.



</doc>
<doc id="18129" url="https://en.wikipedia.org/wiki?curid=18129" title="List of Labour parties">
List of Labour parties

The name Labour (or Labor) Party, or similar, is used by political parties around the world, particularly in countries of the Commonwealth of Nations. They are usually, but not exclusively, social-democratic or democratic-socialist and traditionally allied to trade unions and the labour movement. Many labour parties are members of the Socialist International and/or participants of the Progressive Alliance.



</doc>
<doc id="18130" url="https://en.wikipedia.org/wiki?curid=18130" title="Louisiana">
Louisiana

Louisiana (, ) is a state in the Deep South region of the South Central United States. It is the 19th-smallest by area and the 25th most populous of the 50 U.S. states. Louisiana is bordered by the state of Texas to the west, Arkansas to the north, Mississippi to the east, and the Gulf of Mexico to the south. A large part of its eastern boundary is demarcated by the Mississippi River. Louisiana is the only U.S. state with political subdivisions termed parishes, which are equivalent to counties. The state's capital is Baton Rouge, and its largest city is New Orleans.

Much of the state's lands were formed from sediment washed down the Mississippi River, leaving enormous deltas and vast areas of coastal marsh and swamp. These contain a rich southern biota; typical examples include birds such as ibis and egrets. There are also many species of tree frogs, and fish such as sturgeon and paddlefish. In more elevated areas, fire is a natural process in the landscape and has produced extensive areas of longleaf pine forest and wet savannas. These support an exceptionally large number of plant species, including many species of terrestrial orchids and carnivorous plants. Louisiana has more Native American tribes than any other southern state, including four that are federally recognized, ten that are state recognized, and four that have not received recognition.

Some Louisiana urban environments have a multicultural, multilingual heritage, being so strongly influenced by a mixture of 18th-century French, Italian, Haitian, Spanish, Native American, and African cultures that they are considered to be exceptional in the U.S. Before the American purchase of the territory in 1803, the present-day State of Louisiana had been both a French colony and for a brief period a Spanish one. In addition, colonists imported numerous African people as slaves in the 18th century. Many came from peoples of the same region of West Africa, thus concentrating their culture. In the post-Civil War environment, Anglo-Americans increased the pressure for Anglicization, and in 1921, English was for a time made the sole language of instruction in Louisiana schools before a policy of multilingualism was revived in 1974. There has never been an official language in Louisiana, and the state constitution enumerates "the right of the people to preserve, foster, and promote their respective historic, linguistic, and cultural origins".

Like other states in the Deep South region, Louisiana frequently ranks low in terms of health, education, and development, and high in measures of poverty. In 2018, Louisiana was ranked as the least healthy state in the country, with high levels of drug-related deaths and excessive alcohol consumption, while it has had the highest homicide rate in the United States since at least the 1990s.

Louisiana was named after Louis XIV, King of France from 1643 to 1715. When René-Robert Cavelier, Sieur de La Salle claimed the territory drained by the Mississippi River for France, he named it . The suffix ana (or ane) is a Latin suffix that can refer to "information relating to a particular individual, subject, or place". Thus, roughly, Louis + ana carries the idea of "related to Louis". Once part of the French Colonial Empire, the Louisiana Territory stretched from present-day Mobile Bay to just north of the present-day Canada–United States border, including a small part of what is now the Canadian provinces of Alberta and Saskatchewan.

The Gulf of Mexico did not exist 250 million years ago when there was but one supercontinent, Pangea. As Pangea split apart, the Atlantic Ocean and Gulf of Mexico opened. Louisiana slowly developed, over millions of years, from water into land, and from north to south. The oldest rocks are exposed in the north, in areas such as the Kisatchie National Forest. The oldest rocks date back to the early Cenozoic Era, some 60 million years ago. The history of the formation of these rocks can be found in D. Spearing's "Roadside Geology of Louisiana".

The youngest parts of the state were formed during the last 12,000 years as successive deltas of the Mississippi River: the Maringouin, Teche, St. Bernard, Lafourche, the modern Mississippi, and now the Atchafalaya. The sediments were carried from north to south by the Mississippi River.

In between the Tertiary rocks of the north, and the relatively new sediments along the coast, is a vast belt known as the Pleistocene Terraces. Their age and distribution can be largely related to the rise and fall of sea levels during past ice ages. In general, the northern terraces have had sufficient time for rivers to cut deep channels, while the newer terraces tend to be much flatter.

Salt domes are also found in Louisiana. Their origin can be traced back to the early Gulf of Mexico when the shallow ocean had high rates of evaporation. There are several hundred salt domes in the state; one of the most familiar is Avery Island, Louisiana. Salt domes are important not only as a source of salt; they also serve as underground traps for oil and gas.

Louisiana is bordered to the west by Texas; to the north by Arkansas; to the east by Mississippi; and to the south by the Gulf of Mexico.

The state may properly be divided into two parts, the uplands of the north, and the alluvial along the coast. The alluvial region includes low swamp lands, coastal marshlands and beaches, and barrier islands that cover about . This area lies principally along the Gulf of Mexico and the Mississippi River, which traverses the state from north to south for a distance of about and empties into the Gulf of Mexico; the Red River; the Ouachita River and its branches; and other minor streams (some of which are called bayous).

The breadth of the alluvial region along the Mississippi is from 10 to 60 miles (15 to 100 km), and along the other rivers, the alluvial region averages about 10 miles (15 km) across. The Mississippi River flows along a ridge formed by its natural deposits (known as a levee), from which the lands decline toward a river beyond at an average fall of six feet per mile (3 m/km). The alluvial lands along other streams present similar features.

The higher and contiguous hill lands of the north and northwestern part of the state have an area of more than . They consist of prairie and woodlands. The elevations above sea level range from 10 feet (3 m) at the coast and swamp lands to 50 and 60 feet (15–18 m) at the prairie and alluvial lands. In the uplands and hills, the elevations rise to Driskill Mountain, the highest point in the state only 535 feet (163 m) above sea level. From 1932 to 2010 the state lost 1,800 square miles due to rises in sea level and erosion. The Louisiana Coastal Protection and Restoration Authority (CPRA) spends around $1 billion per year to help shore up and protect Louisiana shoreline and land in both federal and state funding.

Besides the waterways already named, there are the Sabine, forming the western boundary; and the Pearl, the eastern boundary; the Calcasieu, the Mermentau, the Vermilion, Bayou Teche, the Atchafalaya, the Boeuf, Bayou Lafourche, the Courtableau River, Bayou D'Arbonne, the Macon River, the Tensas, Amite River, the Tchefuncte, the Tickfaw, the Natalbany River, and a number of other smaller streams, constituting a natural system of navigable waterways, aggregating over long.

The state also has political jurisdiction over the approximately -wide portion of subsea land of the inner continental shelf in the Gulf of Mexico. Through a peculiarity of the political geography of the United States, this is substantially less than the -wide jurisdiction of nearby states Texas and Florida, which, like Louisiana, have extensive Gulf coastlines.

The southern coast of Louisiana in the United States is among the fastest-disappearing areas in the world. This has largely resulted from human mismanagement of the coast (see Wetlands of Louisiana). At one time, the land was added to when spring floods from the Mississippi River added sediment and stimulated marsh growth; the land is now shrinking. There are multiple causes.

Artificial levees block spring flood water that would bring fresh water and sediment to marshes. Swamps have been extensively logged, leaving canals and ditches that allow salt water to move inland. Canals dug for the oil and gas industry also allow storms to move sea water inland, where it damages swamps and marshes. Rising sea waters have exacerbated the problem. Some researchers estimate that the state is losing a landmass equivalent to 30 football fields every day. There are many proposals to save coastal areas by reducing human damage, including restoring natural floods from the Mississippi. Without such restoration, coastal communities will continue to disappear. And as the communities disappear, more and more people are leaving the region. Since the coastal wetlands support an economically important coastal fishery, the loss of wetlands is adversely affecting this industry.

Louisiana has a humid subtropical climate (Köppen climate classification "Cfa"), with long, hot, humid summers and short, mild winters. The subtropical characteristics of the state are due to its low latitude, low lying topography, and the influence of the Gulf of Mexico, which at its farthest point is no more than away.

Rain is frequent throughout the year, although from April to September is slightly wetter than the rest of the year, which is the state's wet season. There is a dip in precipitation in October. In summer, thunderstorms build during the heat of the day and bring intense but brief, tropical downpours. In winter, rainfall is more frontal and less intense.

Summers in southern Louisiana have high temperatures from June through September averaging or more, and overnight lows averaging above . At times, temperatures in the 90s F, combined with dew points in the upper 70s F, create sensible temperatures over . The humid, thick, jungle-like heat in southern Louisiana is a famous subject of countless stories and movies.

Temperatures are generally warm in the winter in the southern part of the state, with highs around New Orleans, Baton Rouge, the rest of south Louisiana, and the Gulf of Mexico averaging . The northern part of the state is mildly cool in the winter, with highs averaging . The overnight lows in the winter average well above freezing throughout the state, with the average near the Gulf and an average low of in the winter in the northern part of the state.

On occasion, cold fronts from low-pressure centers to the north, reach Louisiana in winter. Low temperatures near occur on occasion in the northern part of the state but rarely do so in the southern part of the state. Snow is rare near the Gulf of Mexico, although residents in the northern parts of the state might receive a dusting of snow a few times each decade. Louisiana's highest recorded temperature is in Plain Dealing on August 10, 1936, while the coldest recorded temperature is at Minden on February 13, 1899.

Louisiana is often affected by tropical cyclones and is very vulnerable to strikes by major hurricanes, particularly the lowlands around and in the New Orleans area. The unique geography of the region, with the many bayous, marshes and inlets, can result in water damage across a wide area from major hurricanes. The area is also prone to frequent thunderstorms, especially in the summer.

The entire state averages over 60 days of thunderstorms a year, more than any other state except Florida. Louisiana averages 27 tornadoes annually. The entire state is vulnerable to a tornado strike, with the extreme southern portion of the state slightly less so than the rest of the state. Tornadoes are more common from January to March in the southern part of the state, and from February through March in the northern part of the state.



Owing to its location and geology, the state has high biological diversity. Some vital areas, such as southwestern prairie, have experienced a loss in excess of 98 percent. The pine flatwoods are also at great risk, mostly from fire suppression and urban sprawl. There is not yet a properly organized system of natural areas to represent and protect Louisiana's biological diversity. Such a system would consist of a protected system of core areas linked by biological corridors, such as Florida is planning.

Louisiana contains a number of areas which, to varying degrees, prevent people from using them. In addition to National Park Service areas and a United States National Forest, Louisiana operates a system of state parks, state historic sites, one state preservation area, one state forest, and many Wildlife Management Areas.

One of Louisiana's largest government-owned areas is Kisatchie National Forest. It is some 600,000 acres in area, more than half of which is flatwoods vegetation, which supports many rare plant and animal species. These include the Louisiana pinesnake and red-cockaded woodpecker. The system of government-owned cypress swamps around Lake Pontchartrain is another large area, with southern wetland species including egrets, alligators, and sturgeon. At least 12 core areas would be needed to build a "protected areas system" for the state; these would range from southwestern prairies, to the Pearl River Floodplain in the east, to the Mississippi River alluvial swamps in the north.

Historic or scenic areas managed, protected, or otherwise recognized by the National Park Service include:


Louisiana operates a system of 22 state parks, 17 state historic sites and one state preservation area.

Louisiana has 955,973 acres, in four ecoregions under the wildlife management of the Louisiana Department of Wildlife and Fisheries. The Nature Conservancy also owns and manages a set of natural areas.

The Louisiana Natural and Scenic Rivers System provides a degree of protection for 51 rivers, streams and bayous in the state. It is administered by the Louisiana Department of Wildlife and Fisheries.

The Louisiana Department of Transportation and Development is the state government organization in charge of maintaining public transportation, roadways, bridges, canals, select levees, floodplain management, port facilities, commercial vehicles, and aviation which includes 69 airports.

The Intracoastal Waterway is an important means of transporting commercial goods such as petroleum and petroleum products, agricultural produce, building materials and manufactured goods.

In 2011, Louisiana ranked among the five deadliest states for debris/litter-caused vehicle accidents per total number of registered vehicles and population size. Figures derived from the NHTSA show at least 25 persons in Louisiana were killed per year in motor vehicle collisions with non-fixed objects, including debris, dumped litter, animals and their carcasses.

Louisiana was inhabited by Native Americans for many millennia before the arrival of Europeans in the 16th century. During the Middle Archaic period, Louisiana was the site of the earliest mound complex in North America and one of the earliest dated, complex constructions in the Americas, the Watson Brake site near present-day Monroe. An 11-mound complex, it was built about 5400 BP (3500 BC). The Middle Archaic sites of Caney and Frenchman's Bend have also been securely dated to 5600–5000 BP (3700–3100 BC), demonstrating that seasonal hunter-gatherers organized to build complex earthwork constructions in present-day northern Louisiana. These discoveries overturned previous assumptions in archaeology that such complex mounds were built only by cultures of more settled peoples who were dependent on maize cultivation. The Hedgepeth Site in Lincoln Parish is more recent, dated to 5200–4500 BP (3300–2600 BC).
Nearly 2,000 years later, Poverty Point was built; it is the largest and best-known Late Archaic site in the state. The city of modern-day Epps developed near it. The Poverty Point culture may have reached its peak around 1500 BC, making it the first complex culture, and possibly the first tribal culture in North America. It lasted until approximately 700 BC.

The Poverty Point culture was followed by the Tchefuncte and Lake Cormorant cultures of the Tchula period, local manifestations of Early Woodland period. The Tchefuncte culture were the first people in the area of Louisiana to make large amounts of pottery. These cultures lasted until AD 200. The Middle Woodland period started in Louisiana with the Marksville culture in the southern and eastern part of the state, reaching across the Mississippi River to the east around Natchez and the Fourche Maline culture in the northwestern part of the state. The Marksville culture was named after the Marksville Prehistoric Indian Site in Avoyelles Parish.
These cultures were contemporaneous with the Hopewell cultures of present-day Ohio and Illinois, and participated in the Hopewell Exchange Network. Trade with peoples to the southwest brought the bow and arrow. The first burial mounds were built at this time. Political power began to be consolidated, as the first platform mounds at ritual centers were constructed for the developing hereditary political and religious leadership.

By 400 the Late Woodland period had begun with the Baytown culture, Troyville culture, and Coastal Troyville during the Baytown Period and were succeeded by the Coles Creek cultures. Where the Baytown peoples built dispersed settlements, the Troyville people instead continued building major earthwork centers. Population increased dramatically and there is strong evidence of a growing cultural and political complexity. Many Coles Creek sites were erected over earlier Woodland period mortuary mounds. Scholars have speculated that emerging elites were symbolically and physically appropriating dead ancestors to emphasize and project their own authority.

The Mississippian period in Louisiana was when the Plaquemine and the Caddoan Mississippian cultures developed, and the peoples adopted extensive maize agriculture, cultivating different strains of the plant by saving seeds, selecting for certain characteristics, etc. The Plaquemine culture in the lower Mississippi River Valley in western Mississippi and eastern Louisiana began in 1200 and continued to about 1600. Examples in Louisiana include the Medora Site, the archaeological type site for the culture in West Baton Rouge Parish whose characteristics helped define the culture, the Atchafalaya Basin Mounds in St Mary Parish, the Fitzhugh Mounds in Madison Parish, the Scott Place Mounds in Union Parish, and the Sims Site in St Charles Parish.

Plaquemine culture was contemporaneous with the Middle Mississippian culture that is represented by its largest settlement, the Cahokia site in Illinois east of St. Louis, Missouri. At its peak Cahokia is estimated to have had a population of more than 20,000. The Plaquemine culture is considered ancestral to the historic Natchez and Taensa peoples, whose descendants encountered Europeans in the colonial era.

By 1000 in the northwestern part of the state, the Fourche Maline culture had evolved into the Caddoan Mississippian culture. The Caddoan Mississippians occupied a large territory, including what is now eastern Oklahoma, western Arkansas, northeast Texas, and northwest Louisiana. Archaeological evidence has demonstrated that the cultural continuity is unbroken from prehistory to the present. The Caddo and related Caddo-language speakers in prehistoric times and at first European contact were the direct ancestors of the modern Caddo Nation of Oklahoma of today. Significant Caddoan Mississippian archaeological sites in Louisiana include Belcher Mound Site in Caddo Parish and Gahagan Mounds Site in Red River Parish.

Many current place names in Louisiana, including Atchafalaya, Natchitouches (now spelled Natchitoches), Caddo, Houma, Tangipahoa, and Avoyel (as Avoyelles), are transliterations of those used in various Native American languages.

The first European explorers to visit Louisiana came in 1528 when a Spanish expedition led by Pánfilo de Narváez located the mouth of the Mississippi River. In 1542, Hernando de Soto's expedition skirted to the north and west of the state (encountering Caddo and Tunica groups) and then followed the Mississippi River down to the Gulf of Mexico in 1543. Spanish interest in Louisiana faded away for a century and a half.

In the late 17th century, French and French Canadian expeditions, which included sovereign, religious and commercial aims, established a foothold on the Mississippi River and Gulf Coast. With its first settlements, France laid claim to a vast region of North America and set out to establish a commercial empire and French nation stretching from the Gulf of Mexico to Canada.

In 1682, the French explorer Robert Cavelier de La Salle named the region Louisiana to honor King Louis XIV of France. The first permanent settlement, Fort Maurepas (at what is now Ocean Springs, Mississippi, near Biloxi), was founded in 1699 by Pierre Le Moyne d'Iberville, a French military officer from Canada. By then the French had also built a small fort at the mouth of the Mississippi at a settlement they named La Balise (or La Balize), "seamark" in French. By 1721 they built a wooden lighthouse-type structure here to guide ships on the river.

A royal ordinance of 1722—following the Crown's transfer of the Illinois Country's governance from Canada to Louisiana—may have featured the broadest definition of Louisiana: all land claimed by France south of the Great Lakes between the Rocky Mountains and the Alleghenies. A generation later, trade conflicts between Canada and Louisiana led to a more defined boundary between the French colonies; in 1745, Louisiana governor general Vaudreuil set the northern and eastern bounds of his domain as the Wabash valley up to the mouth of the Vermilion River (near present-day Danville, Illinois); from there, northwest to "le Rocher" on the Illinois River, and from there west to the mouth of the Rock River (at present day Rock Island, Illinois). Thus, Vincennes and Peoria were the limit of Louisiana's reach; the outposts at Ouiatenon (on the upper Wabash near present-day Lafayette, Indiana), Chicago, Fort Miamis (near present-day Fort Wayne, Indiana), and Prairie du Chien, Wisconsin, operated as dependencies of Canada.

The settlement of Natchitoches (along the Red River in present-day northwest Louisiana) was established in 1714 by Louis Juchereau de St. Denis, making it the oldest permanent European settlement in the modern state of Louisiana. The French settlement had two purposes: to establish trade with the Spanish in Texas via the Old San Antonio Road, and to deter Spanish advances into Louisiana. The settlement soon became a flourishing river port and crossroads, giving rise to vast cotton kingdoms along the river that were worked by imported African slaves. Over time, planters developed large plantations and built fine homes in a growing town. This became a pattern repeated in New Orleans and other places, although the commodity crop in the south was primarily sugar cane.
Louisiana's French settlements contributed to further exploration and outposts, concentrated along the banks of the Mississippi and its major tributaries, from Louisiana to as far north as the region called the Illinois Country, around present-day St. Louis, Missouri. The latter was settled by French colonists from Illinois.

Initially, Mobile and then Biloxi served as the capital of La Louisiane. Recognizing the importance of the Mississippi River to trade and military interests, and wanting to protect the capital from severe coastal storms, France developed New Orleans from 1722 as the seat of civilian and military authority south of the Great Lakes. From then until the United States acquired the territory in the Louisiana Purchase of 1803, France and Spain jockeyed for control of New Orleans and the lands west of the Mississippi.

In the 1720s, German immigrants settled along the Mississippi River, in a region referred to as the German Coast.

France ceded most of its territory to the east of the Mississippi to Great Britain in 1763, in the aftermath of Britain's victory in the Seven Years' War (generally referred to in North America as the French and Indian War). The rest of Louisiana, including the area around New Orleans and the parishes around Lake Pontchartrain, had become a colony of Spain by the Treaty of Fontainebleau (1762). The transfer of power on either side of the river would be delayed until later in the decade.

In 1765, during Spanish rule, several thousand French-speaking refugees from the region of Acadia (now Nova Scotia, New Brunswick, and Prince Edward Island, Canada) made their way to Louisiana after having been expelled from their homelands by the British during the French and Indian War. They settled chiefly in the southwestern Louisiana region now called Acadiana. The governor Luis de Unzaga y Amézaga, eager to gain more settlers, welcomed the Acadian refugees, the ancestors of Louisiana's Cajuns.

Spanish Canary Islanders, called Isleños, emigrated from the Canary Islands of Spain to Louisiana under the Spanish crown between 1778 and 1783.

In 1800, France's Napoleon Bonaparte reacquired Louisiana from Spain in the Treaty of San Ildefonso, an arrangement kept secret for two years.

Jean-Baptiste Le Moyne, Sieur de Bienville brought the first two African slaves to Louisiana in 1708, transporting them from a French colony in the West Indies. In 1709, French financier Antoine Crozat obtained a monopoly of commerce in La Louisiane, which extended from the Gulf of Mexico to what is now Illinois. "That concession allowed him to bring in a cargo of blacks from Africa every year," the British historian Hugh Thomas wrote. Physical conditions, including disease, were so harsh there was high mortality among both the colonists and the slaves, resulting in continuing demand and importation of slaves.

Starting in 1719, traders began to import slaves in higher numbers; two French ships, the "Du Maine" and the "Aurore", arrived in New Orleans carrying more than 500 black slaves coming from Africa. Previous slaves in Louisiana had been transported from French colonies in the West Indies. By the end of 1721, New Orleans counted 1,256 inhabitants, of whom about half were slaves.

In 1724, the French government issued a law called the Code Noir ("Black Code" in English) which "regulate[d] the interaction of whites [blancs] and blacks [noirs] in its colony of Louisiana (which was much larger than the current state of Louisiana). The law consisted of 57 articles, which regulated religion in the colony, outlawed "interracial" marriages (those between people of different skin color, the varying shades of which were also defined by law), restricted manumission, outlined legal punishment of slaves for various offenses, and defined some obligations of owners to their slaves. The main intent of the French government was to assert control over the slave system of agriculture in Louisiana and to impose restrictions on slaveowners there. In practice, the Code Noir was exceedingly difficult to enforce from afar. Some priests continued to perform interracial marriage ceremonies, for example, and some slaveholders continued to manumit slaves without permission while others punished slaves brutally.

Article II of the Code Noir of 1724 required owners to provide their slaves with religious education in the state religion, Roman Catholicism. Sunday was to be a day of rest for slaves. On days off, slaves were expected to feed and take care of themselves. During the 1740s economic crisis in the colony, owners had trouble feeding their slaves and themselves. Giving them time off also effectively gave more power to slaves, who started cultivating their own gardens and crafting items for sale as their own property. They began to participate in the economic development of the colony while at the same time increasing independence and self-subsistence.

Article VI of the Code Noir forbade mixed marriages, forbade but did little to protect slave women from rape by their owners, overseers or other slaves. On balance, the Code benefitted the owners but had more protections and flexibility than did the institution of slavery in the southern Thirteen Colonies.

The Louisiana Black Code of 1806 made the cruel punishment of slaves a crime, but owners and overseers were seldom prosecuted for such acts.

Fugitive slaves, called maroons, could easily hide in the backcountry of the bayous and survive in small settlements. The word "maroon" comes from the Spanish "cimarron", meaning "fugitive cattle".

In the late 18th century, the last Spanish governor of the Louisiana territory wrote:

Truly, it is impossible for lower Louisiana to get along without slaves and with the use of slaves, the colony had been making great strides toward prosperity and wealth.

When the United States purchased Louisiana in 1803, it was soon accepted that enslaved Africans could be brought to Louisiana as easily as they were brought to neighboring Mississippi, though it violated U.S. law to do so. Despite demands by United States Rep. James Hillhouse and by the pamphleteer Thomas Paine to enforce existing federal law against slavery in the newly acquired territory, slavery prevailed because it was the source of great profits and the lowest-cost labor.

At the start of the 19th century, Louisiana was a small producer of sugar with a relatively small number of slaves, compared to Saint-Domingue and the West Indies. It soon thereafter became a major sugar producer as new settlers arrived to develop plantations. William C. C. Claiborne, Louisiana's first United States governor, said African slave labor was needed because white laborers "cannot be had in this unhealthy climate". Hugh Thomas wrote that Claiborne was unable to enforce the abolition of the African slave trade, which the U.S. and Great Britain adopted in 1808. The United States continued to protect the domestic slave trade, including the coastwise trade—the transport of slaves by ship along the Atlantic Coast and to New Orleans and other Gulf ports.

By 1840, New Orleans had the biggest slave market in the United States, which contributed greatly to the economy of the city and of the state. New Orleans had become one of the wealthiest cities, and the third largest city, in the nation. The ban on the African slave trade and importation of slaves had increased demand in the domestic market. During the decades after the American Revolutionary War, more than one million enslaved African Americans underwent forced migration from the Upper South to the Deep South, two thirds of them in the slave trade. Others were transported by their owners as slaveholders moved west for new lands.

With changing agriculture in the Upper South as planters shifted from tobacco to less labor-intensive mixed agriculture, planters had excess laborers. Many sold slaves to traders to take to the Deep South. Slaves were driven by traders overland from the Upper South or transported to New Orleans and other coastal markets by ship in the coastwise slave trade. After sales in New Orleans, steamboats operating on the Mississippi transported slaves upstream to markets or plantation destinations at Natchez and Memphis.

Spanish occupation of Louisiana lasted from 1769 to 1800. Beginning in the 1790s, waves of immigration took place from Saint-Domingue, following a slave rebellion that started in 1791. Over the next decade, thousands of migrants landed in Louisiana from the island, including ethnic Europeans, free people of color, and African slaves, some of the latter brought in by each free group. They greatly increased the French-speaking population in New Orleans and Louisiana, as well as the number of Africans, and the slaves reinforced African culture in the city. The process of gaining independence in Saint-Domingue was complex, but uprisings continued. In 1803, France pulled out its surviving troops from the island, having suffered the loss of two-thirds sent to the island two years before, mostly to yellow fever. In 1804, Haiti, the second republic in the western hemisphere, proclaimed its independence, achieved by slave leaders.

Pierre Clément de Laussat (Governor, 1803) said: "Saint-Domingue was, of all our colonies in the Antilles, the one whose mentality and customs influenced Louisiana the most."

When the United States won its independence from Great Britain in 1783, one of its major concerns was having a European power on its western boundary, and the need for unrestricted access to the Mississippi River. As American settlers pushed west, they found that the Appalachian Mountains provided a barrier to shipping goods eastward. The easiest way to ship produce was to use a flatboat to float it down the Ohio and Mississippi Rivers to the port of New Orleans, where goods could be put on ocean-going vessels. The problem with this route was that the Spanish owned both sides of the Mississippi below Natchez.

Napoleon's ambitions in Louisiana involved the creation of a new empire centered on the Caribbean sugar trade. By the terms of the Treaty of Amiens of 1802, Great Britain returned ownership of the islands of Martinique and Guadeloupe to the French. Napoleon looked upon Louisiana as a depot for these sugar islands, and as a buffer to U.S. settlement. In October 1801 he sent a large military force to take back Saint-Domingue, then under control of Toussaint Louverture after a slave rebellion.
When the army led by Napoleon's brother-in-law Leclerc was defeated, Napoleon decided to sell Louisiana.
Thomas Jefferson, third president of the United States, was disturbed by Napoleon's plans to re-establish French colonies in America. With the possession of New Orleans, Napoleon could close the Mississippi to U.S. commerce at any time. Jefferson authorized Robert R. Livingston, U.S. Minister to France, to negotiate for the purchase of the City of New Orleans, portions of the east bank of the Mississippi, and free navigation of the river for U.S. commerce. Livingston was authorized to pay up to $2 million.

An official transfer of Louisiana to French ownership had not yet taken place, and Napoleon's deal with the Spanish was a poorly kept secret on the frontier. On October 18, 1802, however, Juan Ventura Morales, Acting Intendant of Louisiana, made public the intention of Spain to revoke the right of deposit at New Orleans for all cargo from the United States. The closure of this vital port to the United States caused anger and consternation. Commerce in the west was virtually blockaded. Historians believe the revocation of the right of deposit was prompted by abuses by the Americans, particularly smuggling, and not by French intrigues as was believed at the time. President Jefferson ignored public pressure for war with France, and appointed James Monroe a special envoy to Napoleon, to assist in obtaining New Orleans for the United States. Jefferson also raised the authorized expenditure to $10 million.

However, on April 11, 1803, French Foreign Minister Talleyrand surprised Livingston by asking how much the United States was prepared to pay for the entirety of Louisiana, not just New Orleans and the surrounding area (as Livingston's instructions covered). Monroe agreed with Livingston that Napoleon might withdraw this offer at any time (leaving them with no ability to obtain the desired New Orleans area), and that approval from President Jefferson might take months, so Livingston and Monroe decided to open negotiations immediately. By April 30, they closed a deal for the purchase of the entire Louisiana territory of for 60 million Francs (approximately $15 million).

Part of this sum, $3.5 million, was used to forgive debts owed by France to the United States. The payment was made in United States bonds, which Napoleon sold at face value to the Dutch firm of Hope and Company, and the British banking house of Baring, at a discount of 87½ per each $100 unit. As a result, France received only $8,831,250 in cash for Louisiana. English banker Alexander Baring conferred with Marbois in Paris, shuttled to the United States to pick up the bonds, took them to Britain, and returned to France with the money—which Napoleon used to wage war against Baring's own country.
When news of the purchase reached the United States, Jefferson was surprised. He had authorized the expenditure of $10 million for a port city, and instead received treaties committing the government to spend $15 million on a land package which would double the size of the country. Jefferson's political opponents in the Federalist Party argued the Louisiana purchase was a worthless desert, and that the Constitution did not provide for the acquisition of new land or negotiating treaties without the consent of the Senate. What really worried the opposition was the new states which would inevitably be carved from the Louisiana territory, strengthening Western and Southern interests in Congress, and further reducing the influence of New England Federalists in national affairs. President Jefferson was an enthusiastic supporter of westward expansion, and held firm in his support for the treaty. Despite Federalist objections, the U.S. Senate ratified the Louisiana treaty on October 20, 1803.

By statute enacted on October 31, 1803, President Thomas Jefferson was authorized to take possession of the territories ceded by France and provide for initial governance. A transfer ceremony was held in New Orleans on November 29, 1803. Since the Louisiana territory had never officially been turned over to the French, the Spanish took down their flag, and the French raised theirs. The following day, General James Wilkinson accepted possession of New Orleans for the United States. A similar ceremony was held in St. Louis on March 9, 1804, when a French tricolor was raised near the river, replacing the Spanish national flag. The following day, Captain Amos Stoddard of the First U.S. Artillery marched his troops into town and had the American flag run up the fort's flagpole. The Louisiana territory was officially transferred to the United States government, represented by Meriwether Lewis.

The Louisiana Territory, purchased for less than three cents an acre, doubled the size of the United States overnight, without a war or the loss of a single American life, and set a precedent for the purchase of territory. It opened the way for the eventual expansion of the United States across the continent to the Pacific.

Shortly after the United States took possession, the area was divided into two territories along the 33rd parallel north on March 26, 1804, thereby organizing the Territory of Orleans to the south and the District of Louisiana (subsequently formed as the Louisiana Territory) to the north.

Louisiana became the eighteenth U.S. state on April 30, 1812; the Territory of Orleans became the State of Louisiana and the Louisiana Territory was simultaneously renamed the Missouri Territory. An area known as the Florida Parishes was soon annexed into the state of Louisiana on April 14, 1812.

From 1824 to 1861, Louisiana moved from a political system based on personality and ethnicity to a distinct two-party system, with Democrats competing first against "Whigs", then "Know Nothings", and finally only other Democrats.

According to the 1860 census, 331,726 people were enslaved, nearly 47% of the state's total population of 708,002. The strong economic interest of elite whites in maintaining the slave society contributed to Louisiana's decision to secede from the Union on January 26, 1861. It followed other Southern states in seceding after the election of Abraham Lincoln as president of the United States. Louisiana's secession was announced on January 26, 1861, and it became part of the Confederate States of America.

The state was quickly defeated in the Civil War, a result of Union strategy to cut the Confederacy in two by seizing the Mississippi. Federal troops captured New Orleans on April 25, 1862. Because a large part of the population had Union sympathies (or compatible commercial interests), the federal government took the unusual step of designating the areas of Louisiana under federal control as a state within the Union, with its own elected representatives to the U.S. Congress.

Following the Civil War and emancipation of slaves, violence rose in the South as the war was carried on by insurgent private and paramilitary groups. Initially state legislatures were dominated by former Confederates, who passed Black Codes to regulate freedmen and generally refused to give the vote. They refused to extend voting rights to African Americans who had been free before the war and had sometimes obtained education and property (as in New Orleans.) Following the Memphis riots of 1866 and the New Orleans riot the same year, the Fourteenth Amendment was passed that provided suffrage and full citizenship for freedmen. Congress passed the Reconstruction Act, establishing military districts for those states where conditions were considered the worst, including Louisiana. It was grouped with Texas in what was administered as the Fifth Military District.

African Americans began to live as citizens with some measure of equality before the law. Both freedmen and people of color who had been free before the war began to make more advances in education, family stability and jobs. At the same time, there was tremendous social volatility in the aftermath of war, with many whites actively resisting defeat and the free labor market. White insurgents mobilized to enforce white supremacy, first in Ku Klux Klan chapters.

By 1877, when federal forces were withdrawn, white Democrats in Louisiana and other states had regained control of state legislatures, often by paramilitary groups such as the White League, which suppressed black voting through intimidation and violence. Following Mississippi's example in 1890, in 1898, the white Democratic, planter-dominated legislature passed a new constitution that effectively disenfranchised people of color, by raising barriers to voter registration, such as poll taxes, residency requirements and literacy tests. The effect was immediate and long lasting. In 1896, there were 130,334 black voters on the rolls and about the same number of white voters, in proportion to the state population, which was evenly divided.

The state population in 1900 was 47% African-American: a total of 652,013 citizens. Many in New Orleans were descendants of Creoles of color, the sizeable population of free people of color before the Civil War. By 1900, two years after the new constitution, only 5,320 black voters were registered in the state. Because of disfranchisement, by 1910 there were only 730 black voters (less than 0.5 percent of eligible African-American men), despite advances in education and literacy among blacks and people of color. Blacks were excluded from the political system and also unable to serve on juries. White Democrats had established one-party Democratic rule, which they maintained in the state for decades deep into the 20th century until after congressional passage of the 1965 Voting Rights Act provided federal oversight and enforcement of the constitutional right to vote.

In the early decades of the 20th century, thousands of African Americans left Louisiana in the Great Migration north to industrial cities for jobs and education, and to escape Jim Crow society and lynchings. The boll weevil infestation and agricultural problems cost many sharecroppers and farmers their jobs. The mechanization of agriculture also reduced the need for laborers. Beginning in the 1940s, blacks went West to California for jobs in its expanding defense industries.

During some of the Great Depression, Louisiana was led by Governor Huey Long. He was elected to office on populist appeal. His public works projects provided thousands of jobs to people in need, and he supported education and increased suffrage for poor whites, but Long was criticized for his allegedly demogogic and autocratic style. He extended patronage control through every branch of Louisiana's state government. Especially controversial were his plans for wealth redistribution in the state. Long's rule ended abruptly when he was assassinated in the state capitol in 1935.

Mobilization for World War II created jobs in the state. But thousands of other workers, black and white alike, migrated to California for better jobs in its burgeoning defense industry. Many African Americans left the state in the Second Great Migration, from the 1940s through the 1960s to escape social oppression and seek better jobs. The mechanization of agriculture in the 1930s had sharply cut the need for laborers. They sought skilled jobs in the defense industry in California, better education for their children, and living in communities where they could vote.

On November 26, 1958, at Chennault Air Force Base, a USAF B-47 bomber with a nuclear weapon on board developed a fire while on the ground. The aircraft wreckage and the site of the accident were contaminated after a limited explosion of non-nuclear material.

In the 1950s the state created new requirements for a citizenship test for voter registration. Despite opposition by the States Rights Party, downstate black voters had begun to increase their rate of registration, which also reflected the growth of their middle classes. In 1960 the state established the Louisiana State Sovereignty Commission, to investigate civil rights activists and maintain segregation.

Despite this, gradually black voter registration and turnout increased to 20% and more, and it was 32% by 1964, when the first national civil rights legislation of the era was passed. The percentage of black voters ranged widely in the state during these years, from 93.8% in Evangeline Parish to 1.7% in Tensas Parish, for instance, where there were white efforts to suppress the vote in the black-majority parish.

Violent attacks on civil rights activists in two mill towns were catalysts to the founding of the first two chapters of the Deacons for Defense and Justice in late 1964 and early 1965, in Jonesboro and Bogalusa, respectively. Made up of veterans of World War II and the Korean War, they were armed self-defense groups established to protect activists and their families. Continued violent white resistance in Bogalusa to blacks trying to use public facilities in 1965, following passage of the Civil Rights Act of 1964, caused the federal government to order local police to protect the activists. Other chapters were formed in Louisiana, Mississippi, and Alabama.

By 1960 the proportion of African Americans in Louisiana had dropped to 32%. The 1,039,207 black citizens were still suppressed by segregation and disfranchisement. African Americans continued to suffer disproportionate discriminatory application of the state's voter registration rules. Because of better opportunities elsewhere, from 1965 to 1970, blacks continued to migrate out of Louisiana, for a net loss of more than 37,000 people. Based on official census figures, the African-American population in 1970 stood at 1,085,109, a net gain of more than 46,000 people compared to 1960. During the latter period, some people began to migrate to cities of the New South for opportunities. Since that period, blacks entered the political system and began to be elected to office, as well as having other opportunities.

On May 21, 1919, the Nineteenth Amendment to the United States Constitution, giving women full rights to vote, was passed at a national level, and was made the law throughout the United States on August 18, 1920. Louisiana finally ratified the amendment on June 11, 1970.

Due to its location on the Gulf Coast, Louisiana has regularly suffered the effects of tropical storms and damaging hurricanes. On August 29, 2005, New Orleans and many other low-lying parts of the state along the Gulf of Mexico were hit by the catastrophic Hurricane Katrina. It caused widespread damage due to breaching of levees and large-scale flooding of more than 80% of the city. Officials had issued warnings to evacuate the city and nearby areas, but tens of thousands of people, mostly African Americans, stayed behind, many of them stranded. Many people died and survivors suffered through the damage of the widespread floodwaters.

In August 2016, an unnamed storm dumped trillions of gallons of rain on southern Louisiana, including the cities of Denham Springs, Baton Rouge, Gonzales, St. Amant and Lafayette, causing catastrophic flooding. An estimated 110,000 homes were damaged and thousands of residents were displaced.

Gulf of Mexico 'dead zone' off the coast of Louisiana is the largest recurring hypoxic zone in the United States. It was in 2017, the largest ever recorded.

The United States Census Bureau estimates that the population of Louisiana was 4,648,794 on July 1, 2019, a 2.55% increase since the 2010 United States Census. The population density of the state is 104.9 people per square mile.

The center of population of Louisiana is located in Pointe Coupee Parish, in the city of New Roads.

According to the 2010 United States Census, 5.4% of the population age5 and older spoke Spanish at home, up from 3.5% in 2000; and 4.5% spoke French (including Louisiana French and Louisiana Creole), down from 4.8% in 2000.

According to U.S. census estimates, the population of Louisiana in 2014 was:

The major ancestry groups of Louisiana are African American (30.4%), French (16.8%), American (9.5%), German (8.3%), Irish (7.5%), English (6.6%), Italian (4.8%) and Scottish (1.1%).

As of 2011, 49.0% of Louisiana's population younger than age1 were minorities.

The largest denominations by number of adherents in 2010 were the Catholic Church with 1,200,900; Southern Baptist Convention with 709,650; and the United Methodist Church with 146,848. Non-denominational Evangelical Protestant congregations had 195,903 members.

As in other Southern states, the majority of Louisianians, particularly in the north of the state, belong to various Protestant denominations, with Protestants comprising 57% of the state's adult population. Protestants are concentrated in the northern and central parts of the state and in the northern tier of the Florida Parishes. Because of French and Spanish heritage, and their descendants the Creoles, and later Irish, Italian, Portuguese and German immigrants, southern Louisiana and the greater New Orleans area are predominantly Catholic.

Since Creoles were the first settlers, planters and leaders of the territory, they have traditionally been well represented in politics. For instance, most of the early governors were Creole Catholics. Because Catholics still constitute a significant fraction of Louisiana's population, they have continued to be influential in state politics. The high proportion and influence of the Catholic population makes Louisiana distinct among Southern states.

Jewish communities are established in the state's larger cities, notably New Orleans and Baton Rouge. The most significant of these is the Jewish community of the New Orleans area. In 2000, before the 2005 Hurricane Katrina, its population was about 12,000. Louisiana was among the southern states with a significant Jewish population before the 20th century; Virginia, South Carolina, and Georgia also had influential Jewish populations in some of their major cities from the 18th and 19th centuries. The earliest Jewish colonists were Sephardic Jews who immigrated with English colonists from London. Later in the 19th century, German Jews began to immigrate, followed by those from eastern Europe and the Russian Empire in the late 19th and early 20th centuries.

Prominent Jews in Louisiana's political leadership have included Whig (later Democrat) Judah P. Benjamin (1811–1884), who represented Louisiana in the U.S. Senate before the American Civil War and then became the Confederate secretary of state; Democrat-turned-Republican Michael Hahn who was elected as governor, serving 1864–1865 when Louisiana was occupied by the Union Army, and later elected in 1884 as a U.S. congressman; Democrat Adolph Meyer (1842–1908), Confederate Army officer who represented the state in the U.S. House of Representatives from 1891 until his death in 1908; Republican secretary of state Jay Dardenne (1954–), and Republican (Democrat before 2011) attorney general Buddy Caldwell (1946–).

The total gross state product in 2010 for Louisiana was $213.6 billion, placing it 24th in the nation. Its per capita personal income is $30,952, ranking 41st in the United States.

In 2014, Louisiana was ranked as one of the most small business friendly states, based on a study drawing upon data from more than 12,000 small business owners.

The state's principal agricultural products include seafood (it is the biggest producer of crawfish in the world, supplying approximately 90%), cotton, soybeans, cattle, sugarcane, poultry and eggs, dairy products, and rice. Industry generates chemical products, petroleum and coal products, processed foods and transportation equipment, and paper products. Tourism is an important element in the economy, especially in the New Orleans area.

The Port of South Louisiana, located on the Mississippi River between New Orleans and Baton Rouge, is the largest volume shipping port in the Western Hemisphere and 4th largest in the world, as well as the largest bulk cargo port in the world.

New Orleans, Shreveport, and Baton Rouge are home to a thriving film industry. State financial incentives since 2002 and aggressive promotion have given Louisiana the nickname "Hollywood South". Because of its distinctive culture within the United States, only Alaska is Louisiana's rival in popularity as a setting for reality television programs. In late 2007 and early 2008, a film studio was scheduled to open in Tremé, with state-of-the-art production facilities, and a film training institute.
Tabasco sauce, which is marketed by one of the United States' biggest producers of hot sauce, the McIlhenny Company, originated on Avery Island.

Louisiana has three personal income tax brackets, ranging from 2% to 6%. The sales tax rate is 4%: a 3.97% Louisiana sales tax and a .03% Louisiana Tourism Promotion District sales tax. Political subdivisions also levy their own sales tax in addition to the state fees. The state also has a use tax, which includes 4% to be distributed by the Department of Revenue to local governments. Property taxes are assessed and collected at the local level. Louisiana is a subsidized state, receiving $1.44 from the federal government for every dollar paid in.

Tourism and culture are major players in Louisiana's economy, earning an estimated $5.2 billion per year. Louisiana also hosts many important cultural events, such as the World Cultural Economic Forum, which is held annually in the fall at the New Orleans Morial Convention Center.

As of July 2017, the state's unemployment rate was 5.3%.

Louisiana taxpayers receive more federal funding per dollar of federal taxes paid compared to the average state. Per dollar of federal tax collected in 2005, Louisiana citizens received approximately $1.78 in the way of federal spending. This ranks the state fourth highest nationally and represents a rise from 1995 when Louisiana received $1.35 per dollar of taxes in federal spending (ranked seventh nationally). Neighboring states and the amount of federal spending received per dollar of federal tax collected were: Texas ($0.94), Arkansas ($1.41), and Mississippi ($2.02). Federal spending in 2005 and subsequent years since has been exceptionally high due to the recovery from Hurricane Katrina.
Tax Foundation.

Louisiana is rich in petroleum and natural gas. Petroleum and gas deposits are found in abundance both onshore and offshore in State-owned waters. In addition, vast petroleum and natural gas reserves are found offshore from Louisiana in the federally administered Outer Continental Shelf (OCS) in the Gulf of Mexico. According to the Energy Information Administration, the Gulf of Mexico OCS is the largest U.S. petroleum-producing region. Excluding the Gulf of Mexico OCS, Louisiana ranks fourth in petroleum production and is home to about two percent of the total U.S. petroleum reserves.

Louisiana's natural gas reserves account for about five percent of the U.S. total. The recent discovery of the Haynesville Shale formation in parts of or all of Caddo, Bossier, Bienville, Sabine, De Soto, Red River, and Natchitoches parishes have made it the world's fourth largest gas field with some wells initially producing over 25 million cubic feet of gas daily.

Louisiana was the first site of petroleum drilling over water in the world, on Caddo Lake in the northwest corner of the state. The petroleum and gas industry, as well as its subsidiary industries such as transport and refining, have dominated Louisiana's economy since the 1940s. Beginning in 1950, Louisiana was sued several times by the U.S. Interior Department, in efforts by the federal government to strip Louisiana of its submerged land property rights. These control vast stores of reservoirs of petroleum and natural gas.

When petroleum and gas boomed in the 1970s, so did Louisiana's economy. The Louisiana economy as well as its politics of the last half-century cannot be understood without thoroughly accounting for the influence of the petroleum and gas industries. Since the 1980s, these industries' headquarters have consolidated in Houston, but many of the jobs that operate or provide logistical support to the U.S. Gulf of Mexico crude-oil-and-gas industry remained in Louisiana .

In 1849, the state moved the capital from New Orleans to Baton Rouge. Donaldsonville, Opelousas, and Shreveport have briefly served as the seat of Louisiana state government. The Louisiana State Capitol and the Louisiana Governor's Mansion are both located in Baton Rouge. The Louisiana Supreme Court, however, did not move to Baton Rouge but remains headquartered in New Orleans.

The current Louisiana governor is Democrat John Bel Edwards. The current United States senators are Republicans John Neely Kennedy and Bill Cassidy. Louisiana has six congressional districts and is represented in the U.S. House of Representatives by five Republicans and one Democrat. Louisiana had eight votes in the Electoral College for the 2012 election. It lost one House seat due to stagnant population growth in the 2010 Census.

Louisiana is divided into 64 parishes (the equivalent of counties in most other states).

Most parishes have an elected government known as the Police Jury, dating from the colonial days. It is the legislative and executive government of the parish, and is elected by the voters. Its members are called Jurors, and together they elect a president as their chairman.

A more limited number of parishes operate under home rule charters, electing various forms of government. This include mayor–council, council–manager (in which the council hires a professional operating manager for the parish), and others.

The Louisiana political and legal structure has maintained several elements from the times of French and Spanish governance. One is the use of the term "parish" (from the French: "paroisse") in place of "county" for administrative subdivision. Another is the legal system of civil law based on French, German, and Spanish legal codes and ultimately Roman law, as opposed to English common law.

Louisiana's civil law system is what the majority of nations in the world use, especially in Europe and its former colonies, excluding those that derive from the British Empire. However, it is incorrect to equate the Louisiana Civil Code with the Napoleonic Code. Although the Napoleonic Code and Louisiana law draw from common legal roots, the Napoleonic Code was never in force in Louisiana, as it was enacted in 1804, after the United States had purchased and annexed Louisiana in 1803.

While the Louisiana Civil Code of 1808 has been continuously revised and updated since its enactment, it is still considered the controlling authority in the state. Differences are found between Louisianan civil law and the common law found in the other U.S. states. While some of these differences have been bridged due to the strong influence of common law tradition, the civil law tradition is still deeply rooted in most aspects of Louisiana private law. Thus property, contractual, business entities structure, much of civil procedure, and family law, as well as some aspects of criminal law, are still based mostly on traditional Roman legal thinking.

In 1997, Louisiana became the first state to offer the option of a traditional marriage or a covenant marriage. In a covenant marriage, the couple waives their right to a "no-fault" divorce after six months of separation, which is available in a traditional marriage. To divorce under a covenant marriage, a couple must demonstrate cause. Marriages between ascendants and descendants, and marriages between collaterals within the fourth degree (i.e., siblings, aunt and nephew, uncle and niece, first cousins) are prohibited. Same-sex marriages were prohibited by statute, but the Supreme Court declared such bans unconstitutional in 2015, in its ruling in "Obergefell v. Hodges". Same-sex marriages are now performed statewide. Louisiana is a community property state.

From 1898 to 1965, a period when Louisiana had effectively disfranchised most African Americans and many poor whites by provisions of a new constitution, this was essentially a one-party state dominated by white Democrats. Elites had control in the early 20th century, before populist Huey Long came to power as governor. In multiple acts of resistance, blacks left behind the segregation, violence and oppression of the state and moved out to seek better opportunities in northern and western industrial cities during the Great Migrations of 1910–1970, markedly reducing their proportion of population in Louisiana. The franchise for whites was expanded somewhat during these decades, but blacks remained essentially disfranchised until after the civil rights movement of the mid-20th century, gaining enforcement of their constitutional rights through passage by Congress of the Voting Rights Act of 1965.

Since the 1960s, when civil rights legislation was passed under President Lyndon Johnson to protect voting and civil rights, most African Americans in the state have affiliated with the Democratic Party. In the same years, many white social conservatives have moved to support Republican Party candidates in national, gubernatorial and statewide elections. In 2004, David Vitter was the first Republican in Louisiana to be popularly elected as a U.S. senator. The previous Republican senator, John S. Harris, who took office in 1868 during Reconstruction, was chosen by the state legislature under the rules of the 19th century.

Louisiana is unique among U.S. states in using a system for its state and local elections similar to that of modern France. All candidates, regardless of party affiliation, run in a nonpartisan blanket primary (or "jungle primary") on Election Day. If no candidate has more than 50% of the vote, the two candidates with the highest vote totals compete in a runoff election approximately one month later. This run-off method does not take into account party identification; therefore, it is not uncommon for a Democrat to be in a runoff with a fellow Democrat or a Republican to be in a runoff with a fellow Republican.

Congressional races have also been held under the jungle primary system. All other states (except Washington, California, and Maine) use single-party primaries followed by a general election between party candidates, each conducted by either a plurality voting system or runoff voting, to elect senators, representatives, and statewide officials. Between 2008 and 2010, federal congressional elections were run under a closed primary system—limited to registered party members. However, upon the passage of House Bill 292, Louisiana again adopted a nonpartisan blanket primary for its federal congressional elections.

Louisiana has six seats in the U.S. House of Representatives, five of which are currently held by Republicans and one by a Democrat. The state lost a House seat at the end of the 112th Congress due to stagnant population growth as recorded by the 2010 United States Census. Louisiana is not classified as a "swing state" for future presidential elections, as since the late 20th century, it has regularly supported Republican candidates. The state's two U.S. senators are Bill Cassidy (R) John Neely Kennedy (R).

Louisiana's statewide police force is the Louisiana State Police. It began in 1922 with the creation of the Highway Commission. In 1927, a second branch, the Bureau of Criminal Investigations, was formed. In 1932, the State Highway Patrol was authorized to carry weapons.

On July 28, 1936, the two branches were consolidated to form the Louisiana Department of State Police; its motto was "courtesy, loyalty, service". In 1942, this office was abolished and became a division of the Department of Public Safety, called the Louisiana State Police. In 1988, the Criminal Investigation Bureau was reorganized. Its troopers have statewide jurisdiction with power to enforce all laws of the state, including city and parish ordinances. Each year, they patrol over 12 million miles (20 million km) of roadway and arrest about 10,000 impaired drivers. The State Police are primarily a traffic enforcement agency, with other sections that delve into trucking safety, narcotics enforcement, and gaming oversight.

The elected sheriff in each parish is the chief law enforcement officer in the parish. They are the keepers of the local parish prisons, which house felony and misdemeanor prisoners. They are the primary criminal patrol and first responder agency in all matters criminal and civil. They are also the official tax collectors in each parish. The sheriffs are responsible for general law enforcement in their respective parishes. Orleans Parish is an exception, as the general law enforcement duties fall to the New Orleans Police Department. Before 2010, Orleans parish was the only parish to have two sheriff's offices. Orleans Parish divided sheriffs' duties between criminal and civil, with a different elected sheriff overseeing each aspect. In 2006, a bill was passed which eventually consolidated the two sheriff's departments into one parish sheriff responsible for both civil and criminal matters.

In 2015, Louisiana had a higher murder rate (10.3 per 100,000) than any other state in the country for the 27th straight year. Louisiana is the only state with an annual average murder rate (13.6 per 100,000) at least twice as high as the U.S. annual average (6.6 per 100,000) during that period, according to Bureau of Justice Statistics from FBI Uniform Crime Reports. In a different kind of criminal activity, the "Chicago Tribune" reports that Louisiana is the most corrupt state in the United States.

According to the "Times Picayune", Louisiana is the prison capital of the world. Many for-profit private prisons and sheriff-owned prisons have been built and operate here. Louisiana's incarceration rate is nearly five times Iran's, 13 times China's and 20 times Germany's. Minorities are incarcerated at rates disproportionate to their share of the state's population.

The New Orleans Police Department began a new sanctuary policy to "no longer cooperate with federal immigration enforcement" beginning on February 28, 2016.

The judiciary of Louisiana is defined under the Constitution and law of Louisiana and is composed of the Louisiana Supreme Court, the Louisiana Circuit Courts of Appeal, the District Courts, the Justice of the Peace Courts, the Mayor's Courts, the City Courts, and the Parish Courts. The chief justice of the Louisiana Supreme Court is the chief administrator of the judiciary. Its administration is aided by the Judiciary Commission of Louisiana, the Louisiana Attorney Disciplinary Board, and the Judicial Council of the Supreme Court of Louisiana.

Louisiana has more than 9,000 soldiers in the Louisiana Army National Guard, including the 225th Engineer Brigade and the 256th Infantry Brigade. Both these units have served overseas during the War on Terror. The Louisiana Air National Guard has more than 2,000 airmen, and its 159th Fighter Wing has likewise seen combat.

Training sites in the state include Camp Beauregard near Pineville, Camp Villere near Slidell, Camp Minden near Minden, England Air Park (formerly England Air Force Base) near Alexandria, Gillis Long Center near Carville, and Jackson Barracks in New Orleans.

Louisiana is home to several notable public and private colleges and universities, which include Louisiana State University in Baton Rouge and Tulane University in New Orleans. Louisiana State University is the largest and most comprehensive university in Louisiana. Tulane University is a major private research university and the wealthiest university in Louisiana with an endowment over $1.1 billion. Tulane is also highly regarded for its academics nationwide, ranked fortieth on "U.S. News & World Report's" 2018 list of best national universities.

Louisiana's two oldest and largest HBCUs (Historically black colleges and universities) are Southern University in Baton Rouge and Grambling State University in Grambling. Both these Southwestern Athletic Conference (SWAC) schools compete against each other in football annually in the much anticipated Bayou Classic during Thanksgiving weekend in the Mercedes-Benz Superdome.

The Louisiana Science Education Act is a controversial law passed by the Louisiana Legislature on June 11, 2008, and signed into law by Governor Bobby Jindal on June 25. The act allows public school teachers to use supplemental materials in the science classroom which are critical of established science on such topics as the theory of evolution and global warming.

In 2000, of all of the states, Louisiana had the highest percentage of students in private schools. Danielle Dreilinger of "The Times Picayune" wrote in 2014 that "Louisiana parents have a national reputation for favoring private schools." The number of students in enrolled in private schools in Louisiana declined by 9% from circa 2000-2005 until 2014, due to the proliferation of charter schools, the 2008 recession and Hurricane Katrina. Ten parishes in the Baton Rouge and New Orleans area had a combined 17% decline in private school enrollment in that period. This prompted private schools to lobby for school vouchers.

Louisiana's school voucher program is known as the Louisiana Scholarship Program. It was available in the New Orleans area beginning in 2008 and in the rest of the state beginning in 2012. In 2013 the number of students using school vouchers to attend private schools was 6,751, and for 2014 it was projected to over 8,800. As per a ruling from Ivan Lemelle, a U.S. district judge, the federal government has the right to review the charter school placements to ensure they do not further racial segregation.

Louisiana is nominally the least populous state with more than one major professional sports league franchise: the National Basketball Association's New Orleans Pelicans and the National Football League's New Orleans Saints.

Louisiana has 12 collegiate NCAA Division I programs, a high number given its population. The state has no NCAA Division II teams and only two NCAA Division III teams. The LSU Tigers football team has won 11 Southeastern Conference titles, six Sugar Bowls and four national championships.

Each year New Orleans plays host to the Sugar Bowl, the Bayou Classic, and the New Orleans Bowl college football games, and Shreveport hosts the Independence Bowl. Also, New Orleans has hosted the Super Bowl a record seven times, as well as the BCS National Championship Game, NBA All-Star Game and NCAA Men's Division I Basketball Championship.

The Zurich Classic of New Orleans, is a PGA Tour golf tournament held since 1938. The Rock 'n' Roll Mardi Gras Marathon and Crescent City Classic are two road running competitions held at New Orleans.

As of 2016, Louisiana was the birthplace of the most NFL players per capita for the eighth year in a row.

Louisiana is home to many, especially notable are the distinct culture of the Louisiana Creoles, typically people of color, descendants of free mixed-race families of the colonial and early statehood periods.

The French colony of "La Louisiane" struggled for decades to survive. Conditions were harsh, the climate and soil were unsuitable for certain crops the colonists knew, and they suffered from regional tropical diseases. Both colonists and the slaves they imported had high mortality rates. The settlers kept importing slaves, which resulted in a high proportion of native Africans from West Africa, who continued to practice their culture in new surroundings. As described by historian Gwendolyn Midlo Hall, they developed a marked Afro-Creole culture in the colonial era.

At the turn of the 18th century and in the early 1800s, New Orleans received a major influx of white and mixed-race refugees fleeing the violence of the Haitian Revolution, many of whom brought their slaves with them. This added another infusion of African culture to the city, as more slaves in Saint-Domingue were from Africa than in the United States. They strongly influenced the African-American culture of the city in terms of dance, music and religious practices.

Creole culture is an amalgamation of French, African, Spanish (and other European), and Native American cultures. Creole comes from the Portuguese word "crioulo"; originally it referred to a colonist of European (specifically French) descent who was born in the New World, in comparison to immigrants from France. The oldest Louisiana manuscript to use the word "Creole", from 1782, applied it to a slave born in the French colony. But originally it referred more generally to the French colonists born in Louisiana.

Over time, there developed in the French colony a relatively large group of Creoles of Color ("gens de couleur libres"), who were primarily descended from African slave women and French men (later other Europeans became part of the mix, as well as some Native Americans.) Often the French would free their concubines and mixed-race children, and pass on social capital to them. They might educate sons in France, for instance, and help them enter the French Army for a career. They also settled capital or property on their mistresses and children. The free people of color gained more rights in the colony and sometimes education; they generally spoke French and were Roman Catholic. Many became artisans and property owners. Over time, the term "Creole" became associated with this class of Creoles of Color, many of whom achieved freedom long before the Civil War.

Wealthy French Creoles generally maintained town houses in New Orleans as well as houses on their large sugar plantations outside town along the Mississippi River. New Orleans had the largest population of free people of color in the region; they could find work there and created their own culture, marrying among themselves for decades.

The ancestors of Cajuns immigrated mostly from west central France to New France, where they settled in the Atlantic provinces of New Brunswick, Nova Scotia and Prince Edward Island, known originally as Acadia. After the British defeated France in the French and Indian War (Seven Years' War) in 1763, France ceded its territory east of the Mississippi River to Britain. The British forcibly separated families and evicted them from Acadia because they refused to vow loyalty to the new British regime. The Acadians were deported to England, New England, and France. Some escaped the British remained in French Canada.

Others scattered, to France, Canada, Mexico, or the Falkland Islands. Many Acadian refugees settled in south Louisiana in the region around Lafayette and the LaFourche Bayou country. They developed a distinct rural culture there, different from the French Creole colonists of New Orleans. Intermarrying with others in the area, they developed what was called Cajun music, cuisine and culture. Until the 1970s, the term "Cajun" was considered somewhat derogatory.

A third distinct culture in Louisiana is that of the Isleños. Its members are descendants of colonists from the Canary Islands who settled in Spanish Louisiana between 1778 and 1783 and intermarried with other communities such as Frenchman, Acadians, Creoles, Spaniards, and other groups, mainly through the 19th and early 20th centuries.

In Louisiana, the Isleños originally settled in four communities which included Galveztown, Valenzuela, Barataria, and San Bernardo. Of those settlements, Valenzuela and San Bernardo were the most successful as the other two were plagued with both disease and flooding. The large migration of Acadian refugees to Bayou Lafourche led to the rapid gallicization of the Valenzuela community while the community of San Bernardo (Saint Bernard) was able to preserve much of its unique culture and language into the 21st century. This being said, the transmission of Spanish and other customs has completely halted in St. Bernard with those having competency in Spanish being octogenarians.

Through the centuries, the various Isleño communities of Louisiana have kept alive different elements of their Canary Islander heritage while also adopting and building upon the customs and traditions of the communities that surround them. Today two heritage associates exist for the communities: Los Isleños Heritage and Cultural Society of St. Bernard as well as the Canary Islanders Heritage Society of Louisiana. The Fiesta de los Isleños is celebrated annually in St. Bernard Parish which features heritage performances from local groups and the Canary Islands.

According to a 2010 study by the Modern Language Association, among persons five years old and older, 91.26% of Louisiana residents speak only English at home, 3.45% speak French (standard French, French Creole, or Cajun French), 3.30% speak Spanish, and 0.59% speak Vietnamese.

Historically, Native American peoples in the area at the time of European encounter were seven tribes distinguished by their languages: Caddo, Tunica, Natchez, Houma, Choctaw, Atakapa, and Chitimacha. Of these, only Tunica, Caddo and Choctaw still have living native speakers, although several other tribes are working to teach and revitalize their languages. Other Native American peoples migrated into the region, escaping from European pressure from the east. Among these were Alabama, Biloxi, Koasati, and Ofo peoples.

Starting in the 1700s, French colonists began to settle along the coast and founded New Orleans. They established French culture and language institutions. They imported thousands of slaves from tribes of West Africa, who spoke several different languages. In the creolization process, the slaves developed a Louisiana Creole dialect incorporating both French and African forms, which colonists adopted to communicate with them, and which persisted beyond slavery. In the 20th century, there were still people of mixed race, particularly, who spoke Louisiana Creole French.

During the 19th century after the Louisiana Purchase by the United States, English gradually gained prominence for business and government due to the shift in population with settlement by numerous Americans who were English speakers. Many ethnic French families continued to use French in private. Slaves and some free people of color also spoke Louisiana Creole French. The State Constitution of 1812 gave English official status in legal proceedings, but use of French remained widespread. Subsequent state constitutions reflect the diminishing importance of French. The 1868 constitution, passed during the Reconstruction era before Louisiana was re-admitted to the Union, banned laws requiring the publication of legal proceedings in languages other than English. Subsequently, the legal status of French recovered somewhat, but it never regained its pre-Civil War prominence.

Several unique dialects of French, Creole, and English are spoken in Louisiana. Dialects of the French language are: Colonial French and Houma French. Louisiana Creole French is the term for one of the Creole languages. Two unique dialects developed of the English language: Louisiana English, a French-influenced variety of English in which dropping of postvocalic /r/ is common ; and what is informally known as Yat, which resembles the New York City dialect sometimes with southern influences, particularly that of historical Brooklyn. Both accents were influenced by large communities of immigrant Irish and Italians, but the Yat dialect, which developed in New Orleans, was also influenced by French and Spanish.
Colonial French was the dominant language of white settlers in Louisiana during the French colonial period; it was spoken primarily by the French Creoles (native-born). In addition to this dialect, the mixed-race people and slaves developed Louisiana Creole, with a base in West African languages. The limited years of Spanish rule at the end of the 18th century did not result in widespread adoption of the Spanish language. French and Louisiana Creole are still used in modern-day Louisiana, often in family gatherings. English and its associated dialects became predominant after the Louisiana Purchase of 1803, after which the area became dominated by numerous English speakers. In some regions, English was influenced by French, as seen with Louisiana English. Colonial French, although mistakenly named Cajun French by some Cajuns, has persisted alongside English.

Renewed interest in the French language in Louisiana has led to the establishment of Canadian-modeled French immersion schools, as well as bilingual signage in the historic French neighborhoods of New Orleans and Lafayette. In addition to private organizations, since 1968 the state has maintained the Council for the Development of French in Louisiana (CODOFIL), which promotes use of the French language in the state's tourism, economic development, culture, education and international relations. 

In 2018, Louisiana became the first US state to join the Organisation internationale de la Francophonie as an observer.






</doc>
<doc id="18131" url="https://en.wikipedia.org/wiki?curid=18131" title="Los Angeles International Airport">
Los Angeles International Airport

Los Angeles International Airport , commonly referred to as LAX (with each of its letters pronounced individually), is the primary international airport serving Los Angeles and its surrounding metropolitan area.

LAX is located in the Westchester neighborhood of Los Angeles, southwest of Downtown Los Angeles, with the commercial and residential areas of Westchester to the north, the city of El Segundo to the south and the city of Inglewood to the east. LAX is the closest airport to the Westside and the South Bay. 

Owned and operated by Los Angeles World Airports (LAWA), an agency of the government of Los Angeles, formerly known as the Department of Airports, the airport covers of land. LAX has four parallel runways. 

In 2019, LAX handled 88,068,013 passengers, making it the world's third busiest and the United States' second busiest airport following Hartsfield–Jackson Atlanta International Airport. As the largest and busiest international airport on the U.S. West Coast, LAX is a major international gateway to the United States, and also serves a connection point for passengers traveling internationally. The airport holds the record for the world's busiest origin and destination airport, since relative to other airports, many more travelers begin or end their trips in Los Angeles than use it as a connection. It is also the only airport to rank among the top five U.S. airports for both passenger and cargo traffic.

LAX serves as a major hub or focus city for more passenger airlines than any other airport in the United States. While LAX is the busiest airport in the Greater Los Angeles Area, several other airports, including Hollywood Burbank Airport, John Wayne Airport, Long Beach Airport, as well as Ontario International Airport, also serve the area.

In 1928, the Los Angeles City Council selected in the southern part of Westchester for a new airport. The fields of wheat, barley and lima beans were converted into dirt landing strips without any terminal buildings. It was named Mines Field for William W. Mines, the real estate agent who arranged the deal. The first structure, Hangar No. 1, was erected in 1929 and is in the National Register of Historic Places.
Mines Field opened as the airport of Los Angeles in 1930 and the city purchased it to be a municipal airfield in 1937. The name became Los Angeles Airport in 1941 and Los Angeles International Airport in 1949. In the 1930s the main airline airports were Burbank Airport (then known as Union Air Terminal, and later Lockheed) in Burbank and the Grand Central Airport in Glendale. (In 1940 the airlines were all at Burbank except for Mexicana's three departures a week from Glendale; in late 1946 most airline flights moved to LAX, but Burbank always retained a few.)

Mines Field did not extend west of Sepulveda Boulevard; Sepulveda was rerouted circa 1950 to loop around the west ends of the extended east–west runways (now runways 25L and 25R), which by November 1950 were long. A tunnel was completed in 1953 allowing Sepulveda Boulevard to revert to straight and pass beneath the two runways; it was the first tunnel of its kind. For the next few years the two runways were long.

Before the 1930s, existing airports used a two-letter abbreviation based on the weather stations at the airports. At that time, "LA" served as the designation for Los Angeles Airport. But with the rapid growth in the aviation industry the designations expanded to three letters in 1947, and "LA" became "LAX." "LAX" is also used for the Port of Los Angeles in San Pedro and by Amtrak for Union Station in downtown Los Angeles.

The distinctive white Googie Theme Building, designed by Pereira & Luckman architect Paul Williams and constructed in 1961 by Robert E. McKee Construction Co., resembles a flying saucer that has landed on its four legs. A restaurant with a sweeping view of the airport is suspended beneath two arches that form the legs. The Los Angeles City Council designated the building a Los Angeles Historic-Cultural Monument in 1992. A $4 million renovation, with retro-futuristic interior and electric lighting designed by Walt Disney Imagineering, was completed before the Encounter Restaurant opened there in 1997 but is no longer in business. Visitors are able to take the elevator up to the observation deck of the "Theme Building", which had previously been closed after the September 11, 2001 attacks for security reasons. A memorial to the victims of the 9/11 attacks is located on the grounds, as three of the four hijacked planes were originally destined for LAX. The Bob Hope USO expanded and relocated to the first floor of the Theme Building in 2018.

24R/06L and 24L/06R (designated the North Airfield Complex) are north of the airport terminals, and 25R/07L and 25L/07R (designated the South Airfield Complex) are south of the airport terminals.
Since 1972, Los Angeles World Airports has adopted the "Preferential Runway Use Policy" to minimize noise. During daylight hours (0630 to 0000), the normal air traffic pattern is the "Westerly Operations" plan, named for the prevailing west winds. Under "Westerly Operations", departing aircraft take off to the west, and arriving aircraft approach from the east. To reduce noise from arriving aircraft during night hours (0000 to 0630), the air traffic pattern becomes "Over-Ocean Operations". Under "Over-Ocean", departing aircraft continue to take off to the west, but arriving aircraft approach from the west unless otherwise required to approach from the east due to reduced visibility or easterly winds. As the name implies, "Easterly Operations" is used when prevailing winds have shifted to originate from the east, typically during inclement weather and Santa Ana conditions. Under "Easterly Operations", departing aircraft take off to the east, and arriving aircraft approach from the west.

The "inboard" runways (06R/24L and 07L/25R, closest to the central terminal area) are preferred for departures, and the "outboard" runways are preferred for arrivals. During noise-sensitive hours (2200 to 0700) and "Over-Ocean Operations", the "inboard" runways are used preferentially, with arrivals shifting primarily to 06R/24L and departures from 07L/25R. Historically, over 90% of flights have used the "inboard" departures and "outboard" arrivals scheme.

During westbound operations during the daytime, airplanes parked on the north complex tend to use Runway 6R/24L for almost all departures, and airplanes parked on the south complex use Runway 7L/25R for all departures requiring the left turn, and Runway 24L if they are making an immediate right turn. For arrivals, flights coming from the north tend to use Runway 6L/24R, and flights coming from the south tend to use Runway 7R/25L. For flights having a long final westbound, it could depend.

The South Airfield Complex tends to see more operations than the North, due to a larger number of passenger gates and air cargo operations. Runways in the North Airfield Complex are separated by . Plans have been advanced and approved to increase the separation by , which would allow a central taxiway between runways, despite opposition from residents living north of LAX. The separation between the two runways in the South Airfield Complex has already increased by to accommodate a central taxiway.

During westbound operations during the daytime, airplanes taking off to the west with an eastbound destination will generally depart the south runways and make a left turn over the Palos Verdes Peninsula, due to terrain and airspace conflicts with the nearby Santa Monica Airport and Burbank Airport. Meanwhile, northbound flights primarily depart the north runways, climbing over the Santa Monica Bay. Westbound flights may depart either complex, as air traffic demands dictate.

LAX has nine passenger terminals with a total of 132 gates arranged in the shape of the letter U or a horseshoe that are identified by numbers except for the Tom Bradley International Terminal. The Midfield Satellite Concourse North, an expansion for international flights reached through the Tom Bradley Terminal, is scheduled to open by the summer of 2020. There are of cargo facilities at LAX, as well as a heliport operated by Bravo Aviation.

LAWA currently has several plans to modernize LAX. These include terminal and runway improvements, which will enhance the passenger experience, reduce overcrowding, and provide airport access to the latest class of very large passenger aircraft; this would bring LAX's total gates from 132 to 165. At a cost of $14 billion.

These improvements include:


It is the world's fourth-busiest airport by passenger traffic and eleventh-busiest by cargo traffic, serving over 87 million passengers and 2 million tons of freight and mail in 2018. It is the busiest airport in the state of California, and the second-busiest airport by passenger boardings in the United States. In terms of international passengers, the second busiest airport for international traffic in the United States, behind only JFK in New York City.
The number of aircraft movements (landings and takeoffs) was 700,362 in 2017, the third most of any airport in the world.

Shuttles operate to and from the terminals, providing frequent service for connecting passengers. However, connecting passengers who use these shuttles must leave and then later reenter security. Tunnels connect between terminals 4, 5, 6, 7, and 8, and an above-ground connector between and terminal 4 opened in February 2016. People don't generally have to leave and reenter through security checkpoints.

The closest bus stops to the terminals are the pair of opposites on Sepulveda Boulevard and Century Boulevard, served by Metro 117, Torrance 8, Metro 232, Commuter Express 574, Metro 102 to USC and the Metro E line, and Metro 40 to Los Angeles Union Station (owl service only).

In addition, out of a number of bus systems, many routes (local, rapid and express) of the LACMTA Metro 232 to Long Beach, Line 8 of Torrance Transit, Line 109 of Beach Cities Transit, the Santa Monica Big Blue Bus system's Line 3 and Rapid 3 via Lincoln Boulevard to Santa Monica and the Culver CityBus's Line 6 and Rapid 6 via Sepulveda Blvd to Culver City and UCLA, LADOT Commuter Express 438 to Downtown LA (Monday-Friday Rush hours AM) and Commuter Express 439 to Downtown LA (Monday-Friday Rush hours PM), all make stops at the LAX Transit Center in Parking Lot C. on 96th St., where shuttle bus "C" offers free connections to and from every LAX terminal, and at the C Line, where shuttle bus "G" connects to and from the terminals.

The Taiwanese airline China Airlines operates a bus service from LAX to Monterey Park and Rowland Heights. This service is only available for China Airlines customers.

The FlyAway Bus is a nonstop motorcoach/shuttle service run by the LAWA, which provides scheduled service between LAX and Downtown Los Angeles (Union Station), the San Fernando Valley (Van Nuys), Hollywood, and Long Beach. The shuttle service stops at every LAX terminal. The service hours vary based on the line. All lines use the regional system of High Occupancy Vehicle lanes to expedite their trips. The Los Angeles Union Station service and a late-night branch of Metro Local route 40 are the only direct transit links between the airport and Downtown Los Angeles.

Discontinued routes for the FlyAway include West Los Angeles (Westwood), Santa Monica, and Irvine.

Shuttle bus "G" offers a free connection to and from the Aviation/LAX station on the Los Angeles Metro Rail C Line. Upon opening, the Crenshaw/LAX Line Aviation/Century station is planned to serve as the shuttle bus transfer until the Automated People Mover opens.

The LAX automated people mover (APM) is an electric train system currently under construction by LAWA. The LAX APM will be in traveling distance and will have six stations serving the central area, terminals 1–8, and the Tom Bradley International Terminal.

Once leaving the three terminal stations, heading east, the first station is a ground transportation parking structure called the "Intermodal Transportation Facility-West" that will serve employee parking, surrounding hotel access and long term airport parking. The next station will be a second car/bus/bike transport facility called the "Intermodal Transport Facility-East" as well as LA Metro Rail's platform, the under construction ground infill transit transfer station on the LAX/Crenshaw Metro Line. At this multi-station stop, the first (floor) level will be ground transportation. The second level will be a bridge from the main hub to the light rail platform and APM platform. The third level will be the APM platform. The last stop on the APM will be a rental car hub station called the Consolidated Rent-A-Car-Center (CONRAC). All the car rental companies and rentals will be here. The APM was designed to decrease the need for shuttle bus services and reduce traffic within the terminals World Way.
The APM will have nine total trains, each operating in four car sets with capacity of containing up to 200 passengers. The APM will operate every two minutes, with a ten minute end-to-end travel time. LAWA has split the project in three phases. The project has been approved and the construction and operating bidding process was commenced. Three firms submitted bids and LAWA announced scoring for the project would be based on "technical merit, visual appeal, user experience and price". LAWA proposed a public private partnership wherein a private sector partner would responsible for the construction and operation of the people mover. Los Angeles City Council gave final approval on April 11, 2018 to "LAX Integrated Express Solutions". The joint bid that included manufacturer Bombardier Transportation at 4.895 Billion over 30 years to build and operate. The three phase project is estimated to cost $5.5 billion, and have a completion date of 2023.

LAX's terminals are immediately west of the interchange between Century Boulevard and Sepulveda Boulevard (State Route 1). Interstate 405 can be reached to the east via Century Boulevard. Interstate 105 is to the south via Sepulveda Boulevard, through the Airport Tunnel that crosses under the airport runways.

Arriving passengers take a shuttle or walk to the LAXit waiting area near Terminal 1 for taxi or ride-share pickups. Taxicab services are operated by nine city-authorized taxi companies and regulated by Authorized Taxicab Supervision Inc. (ATS). ATS queues up taxis at the LAXit waiting area.

A number of private shuttle companies also offer limousine and bus services to LAX Airport.

The airport also functioned as a joint civil-military facility, providing a base for the United States Coast Guard and its Coast Guard Air Station Los Angeles facility, operating four HH-65 Dolphin helicopters, which covers Coast Guard operations in various Southern California locations, including Catalina Island. Missions include search and rescue (SAR), law enforcement, aids to navigation support (such as operating lighthouses) and various military operations. In addition, Coast Guard helicopters assigned to the air station deploy to Coast Guard cutters.

The air station relocated by May 18, 2016 from LAX to accommodate the planned improvements for LAX's midfield, including the Midfield Satellite Concourse North (MSC North) terminal. The air station moved to U.S. Navy's Naval Air Station Point Mugu, part of the Naval Base Ventura County (NBVC) in Point Mugu.

The Flight Path Learning Center is a museum located at 6661 Imperial Highway and was formerly known as the "West Imperial Terminal". This building used to house some charter flights (e.g. Condor Airlines, Martinair Holland, World Airways) and regular scheduled flights by MGM Grand Air. It sat empty for 10 years until it was re-opened as a learning center for LAX.

The center contains information on the history of aviation, several pictures of the airport, as well as aircraft scale models, flight attendant uniforms, and general airline memorabilia such as playing cards, china, magazines, signs, even a TWA gate information sign. The museum also offers school tours and a guest speaker program.

The museum's library contains an extensive collection of rare items such as aircraft manufacturer company newsletters/magazines, technical manuals for both military and civilian aircraft, industry magazines dating back to World War II and before, historic photographs and other invaluable references on aircraft operation and manufacturing.

The museum has on display "The Spirit of Seventy-Six," which is a DC-3 (DC-3-262, Serial No. 3269). After being in commercial airline service, the plane served as a corporate aircraft for Union Oil Company for 32 years. The plane was built in the Douglas Aircraft Company plant in Santa Monica in January 1941, which was a major producer of both commercial and military aircraft.

The museum claims to be "the only aviation museum and research center situated at a major airport and the only facility with a primary emphasis on contributions of civil aviation to the history and development of Southern California". There are other museums at major airports, however, including the Udvar-Hazy Center of the National Air and Space Museum adjacent to Washington Dulles Airport, the Royal Thai Air Force Museum at Don Mueang Airport, the Suomen ilmailumuseo (Finnish Aviation Museum) at Helsinki-Vantaa Airport, the Frontiers of Flight Museum at Dallas Love Field, the Tulsa Air and Space Museum & Planetarium at Tulsa International Airport and others.

The airport has the administrative offices of Los Angeles World Airports.

Continental Airlines once had its corporate headquarters on the airport property. At a 1962 press conference in the office of Mayor of Los Angeles Sam Yorty, Continental Airlines announced that it planned to move its headquarters to Los Angeles in July 1963. In 1963 Continental Airlines headquarters moved to a two-story, $2.3 million building on the grounds of the airport. The July 2009 "Continental Magazine" issue stated that the move "underlined Continental Airlines western and Pacific orientation". On July 1, 1983 the airline's headquarters were relocated to the America Tower in the Neartown area of Houston.

In addition to Continental Airlines, Western Airlines and Flying Tiger Line also had their headquarters at LAX.

During its history there have been numerous incidents, but only the most notable are summarized below:









The "Imperial Hill" area in El Segundo is a prime location for aircraft spotting, especially for takeoffs. Part of the Imperial Hill area has been set aside as a city park, Clutter's Park.

Another popular spotting location sits under the final approach for runways 24 L&R on a lawn next to the Westchester In-N-Out Burger on Sepulveda Boulevard. This is one of the few remaining locations in Southern California from which spotters may watch such a wide variety of low-flying commercial airliners from directly underneath a flight path.

One can also do aircraft spotting at a small park in the take-off pattern that (normally) goes out over the Pacific. The park is on the East side of the street Vista Del Mar from where it takes its name, Vista Del Mar Park.

At 12:51 p.m. on Friday, September 21, 2012, a Shuttle Carrier Aircraft carrying the Space Shuttle "Endeavour" landed at LAX on runway 25L. An estimated 10,000 people saw the shuttle land. Interstate 105 was backed up for miles at a standstill. Imperial Highway was shut down for spectators. It was quickly taken off the Shuttle Carrier Aircraft, a modified Boeing 747, and was moved to a United Airlines hangar. The shuttle spent about a month in the hangar while it was prepared to be transported to the California Science Center.

Numerous films and television shows have been set or filmed partially at LAX, at least partly due to the airport's proximity to Hollywood studios and Los Angeles. Film shoots at the Los Angeles airports, including LAX, produced $590 million for the Los Angeles region from 2002 to 2005.





</doc>
<doc id="18133" url="https://en.wikipedia.org/wiki?curid=18133" title="La Tène culture">
La Tène culture

The La Tène culture (; ) was a European Iron Age culture.
It developed and flourished during the late Iron Age (from about 450 BCE to the Roman conquest in the 1st century BCE), succeeding the early Iron Age Hallstatt culture without any definite cultural break, under the impetus of considerable Mediterranean influence from the Greeks in pre-Roman Gaul, the Etruscans, and Golasecca culture.

La Tène culture's territorial extent corresponded to what is now France, Belgium, Switzerland, Austria, Southern Germany, the Czech Republic, parts of Northern Italy, Slovenia and Hungary, as well as adjacent parts of the Netherlands, Slovakia, Croatia, Transylvania (western Romania), and Transcarpathia (western Ukraine).
The Celtiberians of western Iberia shared many aspects of the culture, though not generally the artistic style. To the north extended the contemporary Pre-Roman Iron Age of Northern Europe, including the Jastorf culture of Northern Germany.

Centered on ancient Gaul, the culture became very widespread, and encompasses a wide variety of local differences. It is often distinguished from earlier and neighbouring cultures mainly by the La Tène style of Celtic art, characterized by curving "swirly" decoration, especially of metalwork.

It is named after the type site of La Tène on the north side of Lake Neuchâtel in Switzerland, where thousands of objects had been deposited in the lake, as was discovered after the water level dropped in 1857. La Tène is the type site and the term archaeologists use for the later period of the culture and art of the ancient Celts, a term that is firmly entrenched in the popular understanding, but presents numerous problems for historians and archaeologists.

Extensive contacts through trade are recognized in foreign objects deposited in elite burials; stylistic influences on La Tène material culture can be recognized in Etruscan, Italic, Greek, Dacian and Scythian sources. Date-able Greek pottery and analysis employing scientific techniques such as dendrochronology and thermoluminescence help provide date ranges for an absolute chronology at some La Tène sites.

La Tène history was originally divided into "early", "middle" and "late" stages based on the typology of the metal finds (Otto Tischler 1885), with the Roman occupation greatly disrupting the culture, although many elements remain in Gallo-Roman and Romano-British culture. A broad cultural unity was not paralleled by overarching social-political unifying structures, and the extent to which the material culture can be linguistically linked is debated. The art history of La Tène culture has various schemes of periodization.

The archaeological period is now mostly divided into four sub-periods, following Paul Reinecke.

The preceding final phase of the Hallstatt culture, HaD, c. 650–450 BC, was also widespread across Central Europe, and the transition over this area was gradual, being mainly detected through La Tène style elite artefacts, which first appear on the western edge of the old Hallstatt region.Though there is no agreement on the precise region in which La Tène culture first developed, there is a broad consensus that the centre of the culture lay on the northwest edges of Hallstatt culture, north of the Alps, within the region between in the West the valleys of the Marne and Moselle, and the part of the Rhineland nearby. In the east the western end of the old Hallstatt core area in modern Bavaria, Austria and Switzerland formed a somewhat separate "eastern style Province" in the early La Tène, joining with the western area in Alsace.
In 1994 a prototypical ensemble of elite grave sites of the early 5th century BCE was excavated at Glauberg in Hesse, northeast of Frankfurt-am-Main, in a region that had formerly been considered peripheral to the La Tène sphere. The site at La Tène itself was therefore near the southern edge of the original "core" area (as is also the case for the Hallstatt site for its core).

The establishment of a Greek colony, soon very successful, at Massalia (modern Marseilles) on the Mediterranean coast of France led to great trade with the Hallstatt areas up the Rhone and Saone river systems, and early La Tène elite burials like the Vix Grave in Burgundy contain imported luxury goods along with artifacts produced locally. Most areas were probably controlled by tribal chiefs living in hilltop forts, while the bulk of the population lived in small villages or farmsteads in the countryside.

By 500 BCE the Etruscans expanded to border Celts in north Italy, and trade across the Alps began to overhaul trade with the Greeks, and the Rhone route declined. Booming areas included the middle Rhine, with large iron ore deposits, the Marne and Champagne regions, and also Bohemia, although here trade with the Mediterranean area was much less important. Trading connections and wealth no doubt played a part in the origin of the La Tène style, though how large a part remains much discussed; specific Mediterranean-derived motifs are evident, but the new style does not depend on them.

Barry Cunliffe notes localization of La Tène culture during the 5th century BCE when there arose "two zones of power and innovation: a Marne – Moselle zone in the west with trading links to the Po Valley via the central Alpine passes and the Golasecca culture, and a Bohemian zone in the east with separate links to the Adriatic via the eastern Alpine routes and the Venetic culture".

From their homeland, La Tène culture expanded in the 4th century BCE to more of modern France, Germany, and Central Europe, and beyond to Hispania, northern and central Italy, the Balkans, and even as far as Asia Minor, in the course of several major migrations. La Tène style artefacts start to appear in Britain around the same time, and Ireland rather later. The style of "Insular La Tène" art is somewhat different and the artefacts are initially found in some parts of the islands but not others. Migratory movements seem at best only partly responsible for the diffusion of La Tène culture there, and perhaps other parts of Europe.

By about 400 BCE, the evidence for Mediterranean trade becomes sparse; this may be because the expanding Celtic populations began to migrate south and west, coming into violent conflict with the established populations, including the Etruscans and Romans. 
The settled life in much of the La Tène homelands also seems to have become much more unstable and prone to wars. In about 387 BCE, the Celts under Brennus defeated the Romans and then sacked Rome, establishing themselves as the most prominent threats to the Roman homeland, a status they would retain through a series of Roman-Gallic wars until Julius Caesar's final conquest of Gaul in 58-50 BCE. The Romans prevented the Celts from reaching very far south of Rome, but on the other side of the Adriatic Sea groups passed through the Balkans to reach Greece, where Delphi was attacked in 279 BCE, and Asia, where Galatia was established as a Celtic area of Anatolia. By this time,the La Tène style was spreading to the British Isles, though apparently without any significant movements in population.

After about 275 BCE, Roman expansion into the La Tène areal began, at first with the conquest of Gallia Cisalpina.
The conquest of Celtic Gaul began in 121 BCE and was complete with the Gallic Wars of the 50s BCE.
Gaulish culture now quickly assimilated to Roman culture, giving rise to the hybrid Gallo-Roman culture of Late Antiquity.

La Tène metalwork in bronze, iron and gold, developing technologically out of Hallstatt culture, is stylistically characterized by inscribed and inlaid intricate spirals and interlace, on fine bronze vessels, helmets and shields, horse trappings and elite jewelry, especially the neck rings called torcs and elaborate clasps called "fibulae". It is characterized by elegant, stylized curvilinear animal and vegetal forms, allied with the Hallstatt traditions of geometric patterning.

The Early Style of La Tène art and culture mainly featured static, geometric decoration, while the transition to the Developed Style constituted a shift to movement-based forms, such as triskeles. Some subsets within the Developed Style contain more specific design trends, such as the recurrent serpentine scroll of the Waldalgesheim Style 

Initially La Tène people lived in open settlements that were dominated by the chieftains’ hill forts. The development of towns—"oppida"—appears in mid-La Tène culture. La Tène dwellings were carpenter-built rather than of masonry. La Tène peoples also dug ritual shafts, in which votive offerings and even human sacrifices were cast. Severed heads appear to have held great power and were often represented in carvings. Burial sites included weapons, carts, and both elite and household goods, evoking a strong continuity with an afterlife.

Elaborate burials also reveal a wide network of trade. In Vix, France, an elite woman of the 6th century BCE was buried with a very large bronze "wine-mixer" made in Greece. Exports from La Tène cultural areas to the Mediterranean cultures were based on salt, tin, copper, amber, wool, leather, furs and gold. 
Artefacts typical of the La Tène culture were also discovered in stray finds as far afield as Scandinavia, Northern Germany, Poland and in the Balkans. It is therefore common to also talk of the "La Tène period" in the context of those regions even though they were never part of the La Tène culture proper, but connected to its core area via trade.

The bearers of the La Tène culture were the people known as Celts or Gauls to ancient ethnographers.
Ancient Celtic culture had no written literature of its own, but rare examples of epigraphy in the Greek or Latin alphabets
exist allowing the fragmentary reconstruction of Continental Celtic.

Current knowledge of this cultural area is derived from three sources comprising archaeological evidence, Greek and Latin literary records, and ethnographical evidence suggesting some La Tène artistic and cultural survivals in traditionally Celtic regions of far western Europe. 
Some of the societies that are archaeologically identified with La Tène material culture were identified by Greek and Roman authors from the 5th century onwards as "Keltoi" ("Celts") and "Galli" ("Gauls"). Herodotus (iv.49) correctly placed "Keltoi" at the source of the Ister/Danube, in the heartland of La Tène material culture: "The Ister flows right across Europe, rising in the country of the Celts".

Whether the usage of classical sources means that the whole of La Tène culture can be attributed to a unified Celtic people is difficult to assess; archaeologists have repeatedly concluded that language, material culture, and political affiliation do not necessarily run parallel. Frey (2004) notes that in the 5th century, "burial customs in the Celtic world were not uniform; rather, localised groups had their own beliefs, which, in consequence, also gave rise to distinct artistic expressions".

The La Tène type site is on the northern shore of Lake Neuchâtel, Switzerland, where the small river Thielle, connecting to another lake, enters the Lake Neuchâtel.
In 1857, prolonged drought lowered the waters of the lake by about 2 m. 
On the northernmost tip of the lake, between the river and a point south of the village of Epagnier (), Hansli Kopp, looking for antiquities for Colonel Frédéric Schwab, discovered several rows of wooden piles that still reached up about 50 cm into the water. From among these, Kopp collected about forty iron swords.

The Swiss archaeologist Ferdinand Keller published his findings in 1868 in his influential first report on the Swiss pile dwellings ("Pfahlbaubericht"). In 1863 he interpreted the remains as a Celtic village built on piles. Eduard Desor, a geologist from Neuchâtel, started excavations on the lakeshore soon afterwards. He interpreted the site as an armory, erected on platforms on piles over the lake and later destroyed by enemy action. Another interpretation accounting for the presence of cast iron swords that had not been sharpened, was of a site for ritual depositions.

With the first systematic lowering of the Swiss lakes from 1868 to 1883, the site fell completely dry. In 1880, Emile Vouga, a teacher from Marin-Epagnier, uncovered the wooden remains of two bridges (designated "Pont Desor" and "Pont Vouga") originally over 100 m long, that crossed the little Thielle River (today a nature reserve) and the remains of five houses on the shore. After Vouga had finished, F. Borel, curator of the Marin museum, began to excavate as well. In 1885 the canton asked the Société d'Histoire of Neuchâtel to continue the excavations, the results of which were published by Vouga in the same year.

All in all, over 2500 objects, mainly made from metal, have been excavated in La Tène. Weapons predominate, there being 166 swords (most without traces of wear), 270 lanceheads, and 22 shield bosses, along with 385 brooches, tools, and parts of chariots. Numerous human and animal bones were found as well. The site was used from the 3rd century, with a peak of activity around 200 BCE and abandonment by about 60 BCE. Interpretations of the site vary. Some scholars believe the bridge was destroyed by high water, while others see it as a place of sacrifice after a successful battle (there are almost no female ornaments).

An exhibition marking the 150th anniversary of the discovery of the La Tène site opened in 2007 at the Musée Schwab in Biel/Bienne, Switzerland, moving to move to Zürich in 2008 and Mont Beuvray in Burgundy in 2009.

A genetic study published in "PLOS One" in December 2018 examined 45 individuals buried at a La Téne necropolis in Urville-Nacqueville, France. The people buried there were identified as Gauls. The mtDNA of the examined individuals belonged primarily to haplotypes of H and U. They were found to be carrying a large amount of steppe ancestry, and to have been closely related to peoples of the preceding Bell Beaker culture, suggesting genetic continuity between Bronze Age and Iron Age France. Significant gene flow with Great Britain and Iberia was detected. The results of the study partially supported the notion that French people are largely descended from the Gauls. 

A genetic study published in the "Journal of Archaeological Science" in October 2019 examined 43 maternal and 17 paternal lineages for the La Téne necropolis in Urville-Nacqueville, France, and 27 maternal and 19 paternal lineages for La Téne tumulus of Gurgy ‘Les Noisats’ near modern Paris, France. The examined individuals displayed strong genetic resemamblance to peoples of the earlier Yamnaya culture, Corded Ware culture and Bell Beaker culture.. They carried a diverse set of maternal lineages associated with steppe ancestry. The paternal lineages were on the other hand characterized by a "striking homogeneity", belonging entirely to haplogroup R and R1b, both of whom are associated with steppe ancestry. The evidence suggested that the Gauls of the La Téne culture were patrilineal and patrilocal, which is in agreement with archaeological and literary evidence.

A genetic study published in the "Proceedings of the National Academy of Sciences of the United States of America" in June 2020 examined the remains of 25 individuals ascribed to the La Tène culture. The 9 samples of Y-DNA extracted were determined to belong to haplogroup I1, R1b1a1a2 (3 samples), R1b1a1a2a1a2c1a1a1a1a1, R1b1, R1b1a1a, E1b1b and R. The 25 samples of mtDNA extracted was determined to belong to various subclades of haplogroup H, HV, U, K, J, V and W. The examined individuals of the Hallstatt culture and La Tène culture were genetically highly homogenous and displayed continuity with the earlier Bell Beaker culture. They carried about 50% steppe-related ancestry.

Some sites are:
See .

Some outstanding La Tène artifacts are:




</doc>
<doc id="18135" url="https://en.wikipedia.org/wiki?curid=18135" title="Lorenz curve">
Lorenz curve

In economics, the Lorenz curve is a graphical representation of the distribution of income or of wealth. It was developed by Max O. Lorenz in 1905 for representing inequality of the wealth distribution.

The curve is a graph showing the proportion of overall income or wealth assumed by the bottom "x"% of the people, although this is not rigorously true for a finite population (see below). It is often used to represent income distribution, where it shows for the bottom "x"% of households, what percentage ("y"%) of the total income they have. The percentage of households is plotted on the "x"-axis, the percentage of income on the "y"-axis. It can also be used to show distribution of assets. In such use, many economists consider it to be a measure of social inequality.

The concept is useful in describing inequality among the size of individuals in ecology and in studies of biodiversity, where the cumulative proportion of species is plotted against the cumulative proportion of individuals. It is also useful in business modeling: e.g., in consumer finance, to measure the actual percentage "y"% of delinquencies attributable to the "x"% of people with worst risk scores.

 Data from 2005.
Points on the Lorenz curve represent statements such as, "the bottom 20% of all households have 10% of the total income."

A perfectly equal income distribution would be one in which every person has the same income. In this case, the bottom "N"% of society would always have "N"% of the income. This can be depicted by the straight line "y" = "x"; called the "line of perfect equality."

By contrast, a perfectly unequal distribution would be one in which one person has all the income and everyone else has none. In that case, the curve would be at "y" = 0% for all "x" < 100%, and "y" = 100% when "x" = 100%. This curve is called the "line of perfect inequality."

The Gini coefficient is the ratio of the area between the line of perfect equality and the observed Lorenz curve to the area between the line of perfect equality and the line of perfect inequality. The higher the coefficient, the more unequal the distribution is. In the diagram on the right, this is given by the ratio "A"/("A+B"), where "A" and "B" are the areas of regions as marked in the diagram.

The Lorenz curve is a probability plot (a P–P plot) comparing the distribution of a parameter in a population against a hypothetical uniform distribution of that parameter. It can usually be represented by a function "L"("F"), where "F", the cumulative portion of the population, is represented by the horizontal axis, and "L", the cumulative portion of the total wealth or income, is represented by the vertical axis.

For a population of size "n", with a sequence of values "y", "i" = 1 to "n", that are indexed in non-decreasing order ( "y" ≤ "y"), the Lorenz curve is the continuous piecewise linear function connecting the points ( "F", "L" ), "i" = 0 to "n", where "F" = 0, "L" = 0, and for "i" = 1 to "n":

For a discrete probability function "f"("y"), let "y", "i" = 1 to "n", be the points with non-zero probabilities indexed in increasing order ( "y" < "y"). The Lorenz curve is the continuous piecewise linear function connecting the points ( "F", "L" ), "i" = 0 to "n", where "F" = 0, "L" = 0, and for "i" = 1 to "n":

For a probability density function "f"("x") with the cumulative distribution function "F"("x"), the Lorenz curve "L" is given by:

where formula_8 denotes the average. The Lorenz curve "L(F)" may then be plotted as a function parametric in x: "L(x)" vs. "F(x)". In other contexts, the quantity computed here is known as the length biased (or size biased) distribution; it also has an important role in renewal theory.

Alternatively, for a cumulative distribution function "F"("x") with inverse "x"("F"), the Lorenz curve "L"("F") is directly given by:

The inverse "x"("F") may not exist because the cumulative distribution function has intervals of constant values. However, the previous formula can still apply by generalizing the definition of "x"("F"):

For an example of a Lorenz curve, see Pareto distribution.

A Lorenz curve always starts at (0,0) and ends at (1,1).

The Lorenz curve is not defined if the mean of the probability distribution is zero or infinite.

The Lorenz curve for a probability distribution is a continuous function. However, Lorenz curves representing discontinuous functions can be constructed as the limit of Lorenz curves of probability distributions, the line of perfect inequality being an example.

The information in a Lorenz curve may be summarized by the Gini coefficient and the Lorenz asymmetry coefficient.

The Lorenz curve cannot rise above the line of perfect equality. 

If the variable being measured cannot take negative values, the Lorenz curve:
Note however that a Lorenz curve for net worth would start out by going negative due to the fact that some people have a negative net worth because of debt.

The Lorenz curve is invariant under positive scaling. If X is a random variable, for any positive number "c" the random variable "c" X has the same Lorenz curve as X.

The Lorenz curve is flipped twice, once about F = 0.5 and once about "L" = 0.5, by negation. If X is a random variable with Lorenz curve "L"("F"), then −X has the Lorenz curve:

The Lorenz curve is changed by translations so that the equality gap "F" − "L"("F") changes in proportion to the ratio of the original and translated means. If X is a random variable with a Lorenz curve "L"("F") and mean "μ", then for any constant "c" ≠ −"μ", X + "c" has a Lorenz curve defined by:

For a cumulative distribution function "F"("x") with mean "μ" and (generalized) inverse "x"("F"), then for any "F" with 0 < "F" < 1 :





</doc>
<doc id="18136" url="https://en.wikipedia.org/wiki?curid=18136" title="Literate programming">
Literate programming

Literate programming is a programming paradigm introduced by Donald Knuth in which a computer program is given an explanation of its logic in a natural language, such as English, interspersed with snippets of macros and traditional source code, from which compilable source code can be generated. The approach is used in scientific computing and in data science routinely for reproducible research and open access purposes. Literate programming tools are used by millions of programmers today.

The literate programming paradigm, as conceived by Knuth, represents a move away from writing computer programs in the manner and order imposed by the computer, and instead enables programmers to develop programs in the order demanded by the logic and flow of their thoughts. Literate programs are written as an uninterrupted exposition of logic in an ordinary human language, much like the text of an essay, in which macros are included to hide abstractions and traditional source code.

Literate programming (LP) tools are used to obtain two representations from a literate source file: one suitable for further compilation or execution by a computer, the "tangled" code, and another for viewing as formatted documentation, which is said to be "woven" from the literate source. While the first generation of literate programming tools were computer language-specific, the later ones are language-agnostic and exist above the programming languages.

Literate programming was first introduced by Knuth in 1984. The main intention behind this approach was to treat a program as literature understandable to human beings. This approach was implemented at Stanford University as a part of research on algorithms and digital typography. This implementation was called "WEB" by Knuth since he believed that it was one of the few three-letter words of English that hadn't already been applied to computing. However, it correctly resembles the complicated nature of software delicately pieced together from simple materials.

Literate programming is writing out the program logic in a human language with included (separated by a primitive markup) code snippets and macros. Macros in a literate source file are simply title-like or explanatory phrases in a human language that describe human abstractions created while solving the programming problem, and hiding chunks of code or lower-level macros. These macros are similar to the algorithms in pseudocode typically used in teaching computer science. These arbitrary explanatory phrases become precise new operators, created on the fly by the programmer, forming a "meta-language" on top of the underlying programming language.

A preprocessor is used to substitute arbitrary hierarchies, or rather "interconnected 'webs' of macros", to produce the compilable source code with one command ("tangle"), and documentation with another ("weave"). The preprocessor also provides an ability to write out the content of the macros and to add to already created macros in any place in the text of the literate program source file, thereby disposing of the need to keep in mind the restrictions imposed by traditional programming languages or to interrupt the flow of thought.

According to Knuth,
literate programming provides higher-quality programs, since it forces programmers to explicitly state the thoughts behind the program, making poorly thought-out design decisions more obvious. Knuth also claims that literate programming provides a first-rate documentation system, which is not an add-on, but is grown naturally in the process of exposition of one's thoughts during a program's creation. The resulting documentation allows the author to restart his own thought processes at any later time, and allows other programmers to understand the construction of the program more easily. This differs from traditional documentation, in which a programmer is presented with source code that follows a compiler-imposed order, and must decipher the thought process behind the program from the code and its associated comments. The meta-language capabilities of literate programming are also claimed to facilitate thinking, giving a higher "bird's eye view" of the code and increasing the number of concepts the mind can successfully retain and process. Applicability of the concept to programming on a large scale, that of commercial-grade programs, is proven by an edition of TeX code as a literate program.

Knuth also claims that Literate Programming can lead to easy porting of software to multiple environments, and even cites the implementation of TeX as an example.

Literate programming is very often misunderstood to refer only to formatted documentation produced from a common file with both source code and comments – which is properly called documentation generation – or to voluminous commentaries included with code. This is the converse of literate programming: well-documented code or documentation extracted from code follows the structure of the code, with documentation embedded in the code; while in literate programming, code is embedded in documentation, with the code following the structure of the documentation.

This misconception has led to claims that comment-extraction tools, such as the Perl Plain Old Documentation or Java Javadoc systems, are "literate programming tools". However, because these tools do not implement the "web of abstract concepts" hiding behind the system of natural-language macros, or provide an ability to change the order of the source code from a machine-imposed sequence to one convenient to the human mind, they cannot properly be called literate programming tools in the sense intended by Knuth.

In 1986, Jon Bentley asked Knuth to demonstrate the concept of literate programming by writing a program in WEB. Knuth came up with an 8-pages long monolithic listing that was published together with a critique by Douglas McIlroy of Bell Labs. McIlroy praised intricacy of Knuth's solution, his choice of a data structure (Frank M. Liang's hash trie), but noted that more practical, much faster to implement, debug and modify solution of the problem takes only six lines of shell script by reusing standard Unix utilities. McIlroy concluded:

McIlroy later admitted that his critique was unfair, since he criticized Knuth's program on engineering grounds, while Knuth's purpose was only to demonstrate the literate programming technique. In 1987, "Communications of the ACM" published a followup article which illustrated literate programming with a C program that combined artistic approach of Knuth with engineering approach of McIlroy, with a critique by John Gilbert.

Implementing literate programming consists of two steps:


Weaving and tangling are done on the same source so that they are consistent with each other.

A classic example of literate programming is the literate implementation of the standard Unix codice_1 word counting program. Knuth presented a CWEB version of this example in Chapter 12 of his "Literate Programming" book. The same example was later rewritten for the noweb literate programming tool. This example provides a good illustration of the basic elements of literate programming.

The following snippet of the codice_1 literate program shows how arbitrary descriptive phrases in a natural language are used in a literate program to create macros, which act as new "operators" in the literate programming language, and hide chunks of code or other macros. The mark-up notation consists of double angle brackets ("codice_3") that indicate macros, the "codice_4" symbol which indicates the end of the code section in a noweb file. The "codice_5" symbol stands for the "root", topmost node the literate programming tool will start expanding the web of macros from. Actually, writing out the expanded source code can be done from any section or subsection (i.e. a piece of code designated as "codice_6", with the equal sign), so one literate program file can contain several files with machine source code.

The purpose of wc is to count lines, words, and/or characters in a list of files. The
number of lines in a file is .../more explanations/

Here, then, is an overview of the file wc.c that is defined by the noweb program wc.nw:

We must include the standard I/O definitions, since we want to send formatted output
to stdout and stderr.

The unraveling of the chunks can be done in any place in the literate program text file, not necessarily in the order they are sequenced in the enclosing chunk, but as is demanded by the logic reflected in the explanatory text that envelops the whole program.

Macros are not the same as "section names" in standard documentation. Literate programming macros can hide any chunk of code behind themselves, and be used inside any low-level machine language operators, often inside logical operators such as "codice_7", "codice_8" or "codice_9". This is illustrated by the following snippet of the codice_1 literate program.
The present chunk, which does the counting, was actually one of
the simplest to write. We look at each character and change state if it begins or ends
a word.

In fact, macros can stand for any arbitrary chunk of code or other macros, and are thus more general than top-down or bottom-up "chunking", or than subsectioning. Knuth says that when he realized this, he began to think of a program as a "web" of various parts.

In a noweb literate program besides the free order of their exposition, the chunks behind macros, once introduced with "codice_11", can be grown later in any place in the file by simply writing "codice_6" and adding more content to it, as the following snippet illustrates ("plus" is added by the document formatter for readability, and is not in the code).

If we made these variables local to main, we would have to do this initialization
explicitly; however, C globals are automatically zeroed. (Or rather,``statically
zeroed." (Get it?)

The documentation for a literate program is produced as part of writing the program. Instead of comments provided as side notes to source code a literate program contains the explanation of concepts on each level, with lower level concepts deferred to their appropriate place, which allows for better communication of thought. The snippets of the literate codice_1 above show how an explanation of the program and its source code are interwoven. Such exposition of ideas creates the flow of thought that is like a literary work. Knuth wrote a "novel" which explains the code of the interactive fiction game Colossal Cave Adventure.


The first published literate programming environment was WEB, introduced by Knuth in 1981 for his TeX typesetting system; it uses Pascal as its underlying programming language and TeX for typesetting of the documentation. The complete commented TeX source code was published in Knuth's "TeX: The program", volume B of his 5-volume "Computers and Typesetting". Knuth had privately used a literate programming system called DOC as early as 1979. He was inspired by the ideas of Pierre-Arnoul de Marneffe. The free CWEB, written by Knuth and Silvio Levy, is WEB adapted for C and C++, runs on most operating systems and can produce TeX and PDF documentation.

There are various other implementations of the literate programming concept (some of them don't have macros and hence violate the order of human logic principle):

Other useful tools include

% here text describing the function:
fact 0 = 1
fact (n+1) = (n+1) * fact n
here more text

comp :: (beta -> gamma) -> (alpha -> beta) -> (alpha -> gamma)





</doc>
<doc id="18137" url="https://en.wikipedia.org/wiki?curid=18137" title="Logistic map">
Logistic map

The logistic map is a polynomial mapping (equivalently, recurrence relation) of degree 2, often cited as an archetypal example of how complex, chaotic behaviour can arise from very simple non-linear dynamical equations. The map was popularized in a 1976 paper by the biologist Robert May, in part as a discrete-time demographic model analogous to the logistic equation first created by Pierre François Verhulst.
Mathematically, the logistic map is written

where is a number between zero and one that represents the ratio of existing population to the maximum possible population. The values of interest for the parameter (sometimes also denoted ) are those in the interval .
This nonlinear difference equation is intended to capture two effects:

However, as a demographic model the logistic map has the pathological problem that some initial conditions and parameter values (for example, if ) lead to negative population sizes. This problem does not appear in the older Ricker model, which also exhibits chaotic dynamics.

The case of the logistic map is a nonlinear transformation of both the bit-shift map and the case of the tent map.

The image below shows the amplitude and frequency content of some logistic map iterates for parameter values ranging from 2 to 4.

By varying the parameter , the following behavior is observed:


For any value of there is at most one stable cycle. If a stable cycle exists, it is globally stable, attracting almost all points. Some values of with a stable cycle of some period have infinitely many unstable cycles of various periods.

The bifurcation diagram at right summarizes this. The horizontal axis shows the possible values of the parameter while the vertical axis shows the set of values of visited asymptotically from almost all initial conditions by the iterates of the logistic equation with that value.
The bifurcation diagram is a self-similar: if we zoom in on the above-mentioned value and focus on one arm of the three, the situation nearby looks like a shrunk and slightly distorted version of the whole diagram. The same is true for all other non-chaotic points. This is an example of the deep and ubiquitous connection between chaos and fractals.

The relative simplicity of the logistic map makes it a widely used point of entry into a consideration of the concept of chaos. A rough description of chaos is that chaotic systems exhibit a great sensitivity to initial conditions—a property of the logistic map for most values of between about 3.57 and 4 (as noted above). A common source of such sensitivity to initial conditions is that the map represents a repeated folding and stretching of the space on which it is defined. In the case of the logistic map, the quadratic difference equation describing it may be thought of as a stretching-and-folding operation on the interval .

The following figure illustrates the stretching and folding over a sequence of iterates of the map. Figure (a), left, shows a two-dimensional Poincaré plot of the logistic map's state space for , and clearly shows the quadratic curve of the difference equation (). However, we can embed the same sequence in a three-dimensional state space, in order to investigate the deeper structure of the map. Figure (b), right, demonstrates this, showing how initially nearby points begin to diverge, particularly in those regions of corresponding to the steeper sections of the plot.

This stretching-and-folding does not just produce a gradual divergence of the sequences of iterates, but an exponential divergence (see Lyapunov exponents), evidenced also by the complexity and unpredictability of the chaotic logistic map. In fact, exponential divergence of sequences of iterates explains the connection between chaos and unpredictability: a small error in the supposed initial state of the system will tend to correspond to a large error later in its evolution. Hence, predictions about future states become progressively (indeed, exponentially) worse when there are even very small errors in our knowledge of the initial state. This quality of unpredictability and apparent randomness led the logistic map equation to be used as a pseudo-random number generator in early computers.

Since the map is confined to an interval on the real number line, its dimension is less than or equal to unity. Numerical estimates yield a correlation dimension of (Grassberger, 1983), a Hausdorff dimension of about 0.538 (Grassberger 1981), and an information dimension of approximately 0.5170976 (Grassberger 1983) for (onset of chaos). Note: It can be shown that the correlation dimension is certainly between 0.4926 and 0.5024.

It is often possible, however, to make precise and accurate statements about the "likelihood" of a future state in a chaotic system. If a (possibly chaotic) dynamical system has an attractor, then there exists a probability measure that gives the long-run proportion of time spent by the system in the various regions of the attractor. In the case of the logistic map with parameter and an initial state in , the attractor is also the interval and the probability measure corresponds to the beta distribution with parameters and . Specifically, the invariant measure is

Unpredictability is not randomness, but in some circumstances looks very much like it. Hence, and fortunately, even if we know very little about the initial state of the logistic map (or some other chaotic system), we can still say something about the distribution of states arbitrarily far into the future, and use this knowledge to inform decisions based on the state of the system.

Although exact solutions to the recurrence relation are only available in a small number of cases, a closed-form upper bound on the logistic map is known when . There are two aspects of the behavior of the logistic map that should be captured by an upper bound in this regime: the asymptotic geometric decay with constant , and the fast initial decay when is close to 1, driven by the term in the recurrence relation. The following bound captures both of these effects:

The special case of can in fact be solved exactly, as can the case with ; however, the general case can only be predicted statistically. 
The solution when is,

where the initial condition parameter is given by

For rational , after a finite number of iterations maps into a periodic sequence. But almost all are irrational, and, for irrational , never repeats itself – it is non-periodic. This solution equation clearly demonstrates the two key features of chaos – stretching and folding: the factor shows the exponential growth of stretching, which results in sensitive dependence on initial conditions, while the squared sine function keeps folded within the range .

For an equivalent solution in terms of complex numbers instead of trigonometric functions is

where is either of the complex numbers

with modulus equal to 1. Just as the squared sine function in the trigonometric solution leads to neither shrinkage nor expansion of the set of points visited, in the latter solution this effect is accomplished by the unit modulus of .

By contrast, the solution when is

for . Since for any value of other than the unstable fixed point 0, the term goes to 0 as goes to infinity, so goes to the stable fixed point .

For the case, from almost all initial conditions the iterate sequence is chaotic. Nevertheless, there exist an infinite number of initial conditions that lead to cycles, and indeed there exist cycles of length for "all" integers . We can exploit the relationship of the logistic map to the dyadic transformation (also known as the "bit-shift map") to find cycles of any length. If follows the logistic map and follows the "dyadic transformation"

then the two are related by a homeomorphism

The reason that the dyadic transformation is also called the bit-shift map is that when is written in binary notation, the map moves the binary point one place to the right (and if the bit to the left of the binary point has become a "1", this "1" is changed to a "0"). A cycle of length 3, for example, occurs if an iterate has a 3-bit repeating sequence in its binary expansion (which is not also a one-bit repeating sequence): 001, 010, 100, 110, 101, or 011. The iterate 001001001… maps into 010010010..., which maps into 100100100..., which in turn maps into the original 001001001...; so this is a 3-cycle of the bit shift map. And the other three binary-expansion repeating sequences give the 3-cycle 110110110… → 101101101… → 011011011… → 110110110.… Either of these 3-cycles can be converted to fraction form: for example, the first-given 3-cycle can be written as → → → . Using the above translation from the bit-shift map to the formula_10 logistic map gives the corresponding logistic cycle 0.611260467… → 0.950484434… → 0.188255099… → 0.611260467.… We could similarly translate the other bit-shift 3-cycle into its corresponding logistic cycle. Likewise, cycles of any length can be found in the bit-shift map and then translated into the corresponding logistic cycles.

However, since almost all numbers in are irrational, almost all initial conditions of the bit-shift map lead to the non-periodicity of chaos. This is one way to see that the logistic map is chaotic for almost all initial conditions.

The number of cycles of (minimal) length for the logistic map with (tent map with ) is a known integer sequence : 2, 1, 2, 3, 6, 9, 18, 30, 56, 99, 186, 335, 630, 1161…. This tells us that the logistic map with has 2 fixed points, 1 cycle of length 2, 2 cycles of length 3 and so on. This sequence takes a particularly simple form for prime : . For example: 2 ⋅  = 630 is the number of cycles of length 13. Since this case of the logistic map is chaotic for almost all initial conditions, all of these finite-length cycles are unstable.

Universality of one-dimensional maps with parabolic maxima and Feigenbaum constants formula_11,formula_12 is well visible with map proposed as a toy 
model for discrete laser dynamics: 
formula_13,
where formula_14 stands for electric field amplitude, formula_15 is laser gain as bifurcation parameter. 

The gradual increase of formula_15 at interval formula_17 changes dynamics from regular to chaotic one with qualitatively the same bifurcation diagram as those for logistic map.





</doc>
<doc id="18138" url="https://en.wikipedia.org/wiki?curid=18138" title="Levant">
Levant

The Levant () is an approximate historical geographical term referring to a large area in the Eastern Mediterranean region of Western Asia. In its narrowest sense, it is equivalent to the historical region of Syria, which included present-day Syria, Lebanon, Jordan, Israel, Palestine and most of Turkey south-east of the middle Euphrates. In its widest historical sense, the Levant included all of the Eastern Mediterranean with its islands; that is, it included all of the countries along the Eastern Mediterranean shores, extending from Greece to Cyrenaica in eastern Libya.

The term entered English in the late 15th century from French. It derives from the Italian "Levante", meaning "rising", implying the rising of the Sun in the east, and is broadly equivalent to the term "al-Mashriq" (, ), meaning "the eastern place, where the Sun rises". 

In the 13th and 14th centuries, the term "levante" was used for Italian maritime commerce in the Eastern Mediterranean, including Greece, Anatolia, Syria-Palestine, and Egypt, that is, the lands east of Venice. Eventually the term was restricted to the Muslim countries of Syria-Palestine and Egypt. In 1581, England set up the Levant Company to monopolize commerce with the Ottoman Empire. The name "Levant States" was used to refer to the French mandate over Syria and Lebanon after World War I. This is probably the reason why the term "Levant" has come to be used more specifically to refer to modern Syria, Lebanon, Palestine, Israel, Jordan, and Cyprus. Some scholars mistakenly believed that it derives from the name of Lebanon. Today the term is often used in conjunction with prehistoric or ancient historical references. It has the same meaning as "Syria-Palestine" or "Ash-Shaam" (, ), the area that is bounded by the Taurus Mountains of Turkey in the North, the Mediterranean Sea in the west, and the north Arabian Desert and Mesopotamia in the east. Typically, it does not include Anatolia (also called Asia Minor), the Caucasus Mountains, or any part of the Arabian Peninsula proper. Cilicia (in Asia Minor) and the Sinai Peninsula (Asian Egypt) are sometimes included.

As a name for the contemporary region, several dictionaries consider Levant to be archaic today. Both the noun "Levant" and the adjective "Levantine" are now commonly used to describe the ancient and modern culture area formerly called Syro-Palestinian or Biblical: archaeologists now speak of the Levant and of Levantine archaeology; food scholars speak of Levantine cuisine; and the Latin Christians of the Levant continue to be called Levantine Christians.

The Levant has been described as the "crossroads of western Asia, the eastern Mediterranean, and northeast Africa", and the "northwest of the Arabian plate". The populations of the Levant share not only the geographic position, but cuisine, some customs, and history. They are often referred to as "Levantines".

The term "Levant" appears in English in 1497, and originally meant the East or "Mediterranean lands east of Italy". It is borrowed from the French "levant" "rising", referring to the rising of the sun in the east, or the point where the sun rises. The phrase is ultimately from the Latin word "levare," meaning 'lift, raise'. Similar etymologies are found in Greek Ἀνατολή ("Anatolē", "cf." Anatolia), in Germanic "Morgenland" (literally, "morning land"), in Italian (as in "Riviera di Levante", the portion of the Liguria coast east of Genoa), in Hungarian "Kelet", in Spanish and Catalan "Levante" and "Llevant", ("the place of rising"), and in Hebrew (, "mizrah", "east"). Most notably, "Orient" and its Latin source "oriens" meaning "east", is literally "rising", deriving from Latin "orior" "rise".

The notion of the Levant has undergone a dynamic process of historical evolution in usage, meaning, and understanding. While the term "Levantine" originally referred to the European residents of the eastern Mediterranean region, it later came to refer to regional "native" and "minority" groups.

The term became current in English in the 16th century, along with the first English merchant adventurers in the region; English ships appeared in the Mediterranean in the 1570s, and the English merchant company signed its agreement ("capitulations") with the Ottoman Sultan in 1579. The English Levant Company was founded in 1581 to trade with the Ottoman Empire, and in 1670 the French was founded for the same purpose. At this time, the Far East was known as the "Upper Levant".

In early 19th-century travel writing, the term sometimes incorporated certain Mediterranean provinces of the Ottoman empire, as well as independent Greece (and especially the Greek islands). In 19th-century archaeology, it referred to overlapping cultures in this region during and after prehistoric times, intending to reference the place instead of any one culture. The French mandate of Syria and Lebanon (1920–1946) was called the Levant states.

Today, "Levant" is the term typically used by archaeologists and historians with reference to the history of the region. Scholars have adopted the term Levant to identify the region due to it being a "wider, yet relevant, cultural corpus" that does not have the "political overtones" of Syria-Palestine. The term is also used for modern events, peoples, states or parts of states in the same region, namely Cyprus, Egypt, Iraq, Israel, Jordan, Lebanon, Palestine, Syria, and Turkey are sometimes considered Levant countries (compare with Near East, Middle East, Eastern Mediterranean and Western Asia). Several researchers include the island of Cyprus in Levantine studies, including the Council for British Research in the Levant, the UCLA Near Eastern Languages and Cultures department, "Journal of Levantine Studies" and the UCL Institute of Archaeology, the last of which has dated the connection between Cyprus and mainland Levant to the early Iron Age. Archaeologists seeking a neutral orientation that is neither biblical nor national have used terms such as Levantine archaeology and archaeology of the Southern Levant.

While the usage of the term "Levant" in academia has been restricted to the fields of archeology and literature, there is a recent attempt to reclaim the notion of the Levant as a category of analysis in political and social sciences. Two academic journals were launched in the early 2010s using the word: the "Journal of Levantine Studies", published by the Van Leer Jerusalem Institute and "The Levantine Review", published by Boston College.

The word "Levant" has been used in some translations of the term "ash-Shām" as used by the organization known as ISIL, ISIS, and other names, though there is disagreement as to whether this translation is accurate.

The largest religious group in the Levant are the Muslims and the largest cultural-linguistic group are Arabs, due to the Muslim conquest of the Levant in the 7th century and subsequent Arabization of the region. Other large ethnic groups in the Levant include Jews, Kurds, Turks, Turkmens, Assyrians and Armenians.

The majority of Muslim Levantines are Sunni with Alawi and Shia minorities. There are also Jews, Christians, Yazidi Kurds, Druze, and other smaller sects. 

Until the establishment of the modern State of Israel in 1948, Jews lived throughout the Levant alongside Muslims and Christians; since then, almost all have been expelled from their homes and sought refuge in Israel.

There are many Levantine Christian groups such as Greek, Oriental Orthodox (mainly Syriac Orthodox, Coptic, Georgian, and Maronite), Roman Catholic, Nestorian, and Protestant. Armenians mostly belong to the Armenian Apostolic Church. There are Levantines or Franco-Levantines who are mostly Roman Catholic. There are also Circassians, Turks, Samaritans, and Nawars. There are Assyrian peoples belonging to the Assyrian Church of the East (autonomous) and the Chaldean Catholic Church (Catholic).

In addition, this region has a number of sites that are of religious significance, such as Al-Aqsa Mosque, the Church of the Holy Sepulchre, and the Western Wall in Jerusalem.

Most populations in the Levant speak Levantine Arabic (, ), usually classified as the varieties North Levantine Arabic in Lebanon, Syria, and parts of Turkey, and South Levantine Arabic in Palestine and Jordan. Each of these encompasses a spectrum of regional or urban/rural variations. In addition to the varieties normally grouped together as "Levantine", a number of other varieties and dialects of Arabic are spoken in the Levant area, such as Levantine Bedawi Arabic and Mesopotamian Arabic.

Among the languages of Israel, the official language is Hebrew; Arabic was until July 19, 2018, also an official language. The Arab minority, in 2018 about 21% of the population of Israel, speaks a dialect of Levantine Arabic essentially indistinguishable from the forms spoken in the Palestinian territories.

Of the languages of Cyprus, the majority language is Greek, followed by Turkish (in the north). Two minority languages are recognized: Armenian, and Cypriot Maronite Arabic, a hybrid of mostly medieval Arabic vernaculars with strong influence from contact with Greek, spoken by approximately 1000 people.

Some communities and populations speak Aramaic, Greek, Armenian, Circassian, French, or English.

Overlapping regional designations

Subregional designations

Others

"Other places in the east of a larger region"





</doc>
<doc id="18139" url="https://en.wikipedia.org/wiki?curid=18139" title="League of Nations mandate">
League of Nations mandate

A League of Nations mandate was a legal status for certain territories transferred from the control of one country to another following World War I, or the legal instruments that contained the internationally agreed-upon terms for administering the territory on behalf of the League of Nations. These were of the nature of both a treaty and a constitution, which contained minority rights clauses that provided for the rights of petition and adjudication by the International Court. 

The mandate system was established under Article 22 of the Covenant of the League of Nations, entered into force on 28 June 1919. With the dissolution of the League of Nations after World War II, it was stipulated at the Yalta Conference that the remaining Mandates should be placed under the trusteeship of the United Nations, subject to future discussions and formal agreements. Most of the remaining mandates of the League of Nations (with the exception of South-West Africa) thus eventually became United Nations Trust Territories.

Two governing principles formed the core of the Mandate System, being non-annexation of the territory and its administration as a “sacred trust of civilisation” to develop the territory for the benefit of its native people.

The mandate system was established by Article 22 of the Covenant of the League of Nations, drafted by the victors of World War I. The article referred to territories which after the war were no longer ruled by their previous sovereign, but their peoples were not considered "able to stand by themselves under the strenuous conditions of the modern world". The article called for such people's tutelage to be "entrusted to advanced nations who by reason of their resources, their experience or their geographical position can best undertake this responsibility".

All of the territories subject to League of Nations mandates were previously controlled by states defeated in World War I, principally Imperial Germany and the Ottoman Empire. The mandates were fundamentally different from the protectorates in that the Mandatory power undertook obligations to the inhabitants of the territory and to the League of Nations.

The process of establishing the mandates consisted of two phases:

The divestiture of Germany's overseas colonies, along with three territories disentangled from its European homeland area (the Free City of Danzig, Memel Territory, and Saar), was accomplished in the Treaty of Versailles (1919), with the territories being allotted among the Allies on 7 May of that year. Ottoman territorial claims were first addressed in the Treaty of Sèvres (1920) and finalised in the Treaty of Lausanne (1923). The Turkish territories were allotted among the Allied Powers at the San Remo conference in 1920.

The League of Nations decided the exact level of control by the Mandatory power over each mandate on an individual basis. However, in every case the Mandatory power was forbidden to construct fortifications or raise an army within the territory of the mandate, and was required to present an annual report on the territory to the Permanent Mandates Commission of the League of Nations.

The mandates were divided into three distinct groups based upon the level of development each population had achieved at that time.

The first group, or "Class A mandates", were territories formerly controlled by the Ottoman Empire that were deemed to "... have reached a stage of development where their existence as independent nations can be provisionally recognized subject to the rendering of administrative advice and assistance by a Mandatory until such time as they are able to stand alone. The wishes of these communities must be a principal consideration in the selection of the Mandatory."

The second group of mandates, or "Class B mandates", were all former (German territories) in West and Central Africa which were deemed to require a greater level of control by the mandatory power: "...the Mandatory must be responsible for the administration of the territory under conditions which will guarantee freedom of conscience and religion." The mandatory power was forbidden to construct military or naval bases within the mandates.

The "Class C mandates", including South West Africa and certain of the South Pacific Islands, were considered to be "best administered under the laws of the Mandatory as integral portions of its territory"

According to the Council of the League of Nations, meeting of August 1920: "draft mandates adopted by the Allied and Associated Powers would not be definitive until they had been considered and approved by the League ... the legal title held by the mandatory Power must be a double one: one conferred by the Principal Powers and the other conferred by the League of Nations,"

Three steps were required to establish a Mandate under international law:
(1) The Principal Allied and Associated Powers confer a mandate on one of their number or on a third power; (2) the principal powers officially notify the council of the League of Nations that a certain power has been appointed mandatory for such a certain defined territory; and (3) the council of the League of Nations takes official cognisance of the appointment of the mandatory power and informs the latter that it [the council] considers it as invested with the mandate, and at the same time notifies it of the terms of the mandate, after ascertaining whether they are in conformance with the provisions of the covenant."

The U.S. State Department "Digest of International Law" says that the terms of the Treaty of Lausanne provided for the application of the principles of state succession to the "A" Mandates. The Treaty of Versailles (1920) provisionally recognised the former Ottoman communities as independent nations. It also required Germany to recognise the disposition of the former Ottoman territories and to recognise the new states laid down within their boundaries. The terms of the Treaty of Lausanne (1923) required the newly created states that acquired the territory detached from the Ottoman Empire to pay annuities on the Ottoman public debt and to assume responsibility for the administration of concessions that had been granted by the Ottomans. The treaty also let the States acquire, without payment, all the property and possessions of the Ottoman Empire situated within their territory. The treaty provided that the League of Nations was responsible for establishing an arbitral court to resolve disputes that might arise and stipulated that its decisions were final.

A disagreement regarding the legal status and the portion of the annuities to be paid by the "A" mandates was settled when an Arbitrator ruled that some of the mandates contained more than one State:The difficulty arises here how one is to regard the Asiatic countries under the British and French mandates. Iraq is a Kingdom in regard to which Great Britain has undertaken responsibilities equivalent to those of a Mandatory Power. Under the British mandate, Palestine and Transjordan have each an entirely separate organization. We are, therefore, in the presence of three States sufficiently separate to be considered as distinct Parties. France has received a single mandate from the Council of the League of Nations, but in the countries subject to that mandate, one can distinguish two distinct States: Syria and the Lebanon, each State possessing its own constitution and a nationality clearly different from the other.

After the United Nations was founded in 1945 and the League of Nations was disbanded, all but one of the mandated territories that remained under the control of the mandatory power became United Nations trust territories, a roughly equivalent status. In each case, the colonial power that held the mandate on each territory became the administering power of the trusteeship, except that Japan, which had been defeated in World War II, lost its mandate over the South Pacific islands, which became a "strategic trust territory" known as the Trust Territory of the Pacific Islands under United States administration.

The sole exception to the transformation of the League of Nations mandates into UN trusteeships was that South Africa refused to place South-West Africa under trusteeship. Instead, South Africa proposed that it be allowed to annex South-West Africa, a proposal rejected by the United Nations General Assembly. The International Court of Justice held that South Africa continued to have international obligations under the mandate for South-West Africa. The territory finally attained independence in 1990 as Namibia, after a long guerrilla war of independence against the apartheid regime.

Nearly all the former League of Nations mandates had become sovereign states by 1990, including all of the former United Nations Trust Territories with the exception of a few successor entities of the gradually dismembered Trust Territory of the Pacific Islands (formerly Japan's South Pacific Trust Mandate). These exceptions include the Northern Mariana Islands which is a commonwealth in political union with the United States with the status of unincorporated organised territory. The Northern Mariana Islands does elect its own governor to serve as territorial head of government, but it remains a U.S. territory with its head of state being the President of the United States and federal funds to the Commonwealth administered by the Office of Insular Affairs of the United States Department of the Interior.

Remnant Micronesia and the Marshall Islands, the heirs of the last territories of the Trust, attained final independence on 22 December 1990. (The UN Security Council ratified termination of trusteeship, effectively dissolving trusteeship status, on 10 July 1987). The Republic of Palau, split off from the Federated States of Micronesia, became the last to get its independence effectively on 1 October 1994.




</doc>
<doc id="18142" url="https://en.wikipedia.org/wiki?curid=18142" title="Loudon Classic">
Loudon Classic

The Loudon Classic, held at the New Hampshire Motor Speedway (formerly Bryar Motorsport Park and New Hampshire International Speedway) is the longest running motorcycle race in the United States, and is held every year on Father's Day. While it is popularly known as Laconia, the location of the race was moved from Belknap Recreation Area to Loudon in 1964.


</doc>
<doc id="18143" url="https://en.wikipedia.org/wiki?curid=18143" title="Lincoln, New Hampshire">
Lincoln, New Hampshire

Lincoln is a town in Grafton County, New Hampshire, United States. It is the second-largest town by area in New Hampshire. The population was 1,662 at the 2010 census. The town is home to the New Hampshire Highland Games and to a portion of Franconia Notch State Park. Set in the White Mountains, large portions of the town are within the White Mountain National Forest. The Appalachian Trail crosses in the northeast. Lincoln is the location of the Loon Mountain ski resort and associated recreation-centered development.

The primary settlement in town, where 993 people resided at the 2010 census, is defined as the Lincoln census-designated place (CDP) and is located along New Hampshire Route 112 east of Interstate 93. The town also includes the former village sites of Stillwater and Zealand (sometimes known as Pullman) in the town's remote eastern and northern sections respectively, which are now within the White Mountain National Forest.

In 1764, Colonial Governor Benning Wentworth granted to a group of approximately 70 land investors from Connecticut. Lincoln was named after Henry Fiennes Pelham-Clinton, 2nd Duke of Newcastle, 9th Earl of Lincoln – a cousin of the Wentworth governors. He held the position of comptroller of customs for the port of London under George II and George III, which was important to trade between America and England.

The town was settled about 1782. The 1790 census indicates that it had 22 inhabitants. Rocky soil yielded poor farming, but the area's abundant timber, combined with water power to run sawmills on the Pemigewasset River and its East Branch, helped Lincoln develop into a center for logging. By 1853, the Merrimack River Lumber Company was operating. The railroad transported freight, and increasingly brought tourists to the beautiful mountain region. In 1892, James Everell Henry (1831–1912) bought approximately of virgin timber and established a logging enterprise at what is today the center of Lincoln. In 1902, he built a pulp and paper mill. He erected the Lincoln House hotel in 1903, although a 1907 fire would nearly raze the community. Until he died in 1912, Henry controlled his company town, installing relatives in positions of civic authority.

In 1917, Henry's heirs sold the business to the Parker Young Company, which in turn sold it to the Marcalus Manufacturing Company in 1946. Franconia Paper took over in 1950, producing 150 tons of paper a day until bankruptcy in 1971, at which time new river classification standards discouraged further papermaking in Lincoln.

Tourism is today the principal business. Nearby Loon Mountain has long drawn skiers, and in recent years has attempted to convert itself into a four-season attraction. The Flume is one of the most visited attractions in the state. Discovered in 1808, it is a natural canyon extending at the base of Mount Liberty. Walls of Conway granite rise to a height of and are only apart.

According to the United States Census Bureau, the town has a total area of , of which is land and is water, comprising 0.43% of the town. It is the second-largest town in area in New Hampshire, after Pittsburg.

Lincoln is drained by the Pemigewasset River and its East Branch. Lincoln lies almost fully within the Merrimack River watershed, with the western edge of town in the Connecticut River watershed. Kancamagus Pass, elevation , is on the Kancamagus Highway at the eastern boundary. The highest point in Lincoln is either the summit of Mount Carrigain, at above sea level, plus or minus , or the summit of Mount Bond at .

As of the census of 2010, there were 1,662 people, 794 households, and 439 families residing in the town. There were 2,988 housing units, of which 2,194, or 73.4%, were vacant. 2,083 of the vacant units were for seasonal or recreational use. The racial makeup of the town was 96.9% white, 0.3% African American, 0.1% Native American, 1.7% Asian, 0.0% Native Hawaiian or Pacific Islander, 0.3% some other race, and 0.6% from two or more races. 1.7% of the population were Hispanic or Latino of any race.

Of the 794 households, 21.5% had children under the age of 18 living with them, 43.1% were headed by married couples living together, 7.8% had a female householder with no husband present, and 44.7% were non-families. 37.0% of all households were made up of individuals, and 13.4% were someone living alone who was 65 years of age or older. The average household size was 2.09, and the average family size was 2.75.

In the town, 18.7% of the population were under the age of 18, 6.8% were from 18 to 24, 19.4% from 25 to 44, 34.8% from 45 to 64, and 20.4% were 65 years of age or older. The median age was 48.5 years. For every 100 females, there were 105.2 males. For every 100 females age 18 and over, there were 103.3 males.

For the period 2011-2015, the estimated median annual income for a household was $37,095, and the median income for a family was $55,326. Male full-time workers had a median income of $31,106 versus $27,381 for females. The per capita income for the town was $24,109. 21.0% of the population and 9.1% of families were below the poverty line. 20.2% of the population under the age of 18 and 8.6% of those 65 or older were living in poverty.





</doc>
<doc id="18145" url="https://en.wikipedia.org/wiki?curid=18145" title="List of laser applications">
List of laser applications

Many scientific, military, medical and commercial laser applications have been developed since the invention of the laser in 1958. The coherency, high monochromaticity, and ability to reach extremely high powers are all properties which allow for these specialized applications.

In science, lasers are used in many ways, including:

Lasers may also be indirectly used in spectroscopy as a micro-sampling system, a technique termed Laser ablation (LA), which is typically applied to ICP-MS apparatus resulting in the powerful LA-ICP-MS.

The principles of laser spectroscopy are discussed by Demtröder.

Most types of laser are an inherently pure source of light; they emit near-monochromatic light with a very well defined range of wavelengths. By careful design of the laser components, the purity of the laser light (measured as the "linewidth") can be improved more than the purity of any other light source. This makes the laser a very useful source for spectroscopy. The high intensity of light that can be achieved in a small, well collimated beam can also be used to induce a nonlinear optical effect in a sample, which makes techniques such as Raman spectroscopy possible. Other spectroscopic techniques based on lasers can be used to make extremely sensitive detectors of various molecules, able to measure molecular concentrations in the parts-per-10 (ppt) level. Due to the high power densities achievable by lasers, beam-induced atomic emission is possible: this technique is termed Laser induced breakdown spectroscopy (LIBS).

Heat treating with lasers allows selective surface hardening against wear with little or no distortion of the component. Because this eliminates much part reworking that is currently done, the laser system's capital cost is recovered in a short time. An inert, absorbent coating for laser heat treatment has also been developed that eliminates the fumes generated by conventional paint coatings during the heat-treating process with CO2 laser beams.

One consideration crucial to the success of a heat treatment operation is control of the laser beam irradiance on the part surface. The optimal irradiance distribution is driven by the thermodynamics of the laser-material interaction and by the part geometry.

Typically, irradiances between 500-5000 W/cm^2 satisfy the thermodynamic constraints and allow the rapid surface heating and minimal total heat input required. For general heat treatment, a uniform square or rectangular beam is one of the best options. For some special applications or applications where the heat treatment is done on an edge or corner of the part, it may be better to have the irradiance decrease near the edge to prevent melting.

Research shows that scientists may one day be able to induce rain and lightning storms (as well as micro-manipulating some other weather phenomena) using high energy lasers. Such a breakthrough could potentially eradicate droughts, help alleviate weather related catastrophes, and allocate weather resources to areas in need.

When the Apollo astronauts visited the moon, they planted retroreflector arrays to make possible the Lunar Laser Ranging Experiment. Laser beams are focused through large telescopes on Earth aimed toward the arrays, and the time taken for the beam to be reflected back to Earth measured to determine the distance between the Earth and Moon with high accuracy.

Some laser systems, through the process of mode locking, can produce extremely brief pulses of light - as short as picoseconds or femtoseconds (10 - 10 seconds). Such pulses can be used to initiate and analyze chemical reactions, a technique known as "photochemistry". The short pulses can be used to probe the process of the reaction at a very high temporal resolution, allowing the detection of short-lived intermediate molecules. This method is particularly useful in biochemistry, where it is used to analyse details of protein folding and function.

Laser barcode scanners are ideal for applications that require high speed reading of linear codes or stacked symbols.

A technique that has recent success is "laser cooling". This involves atom trapping, a method where a number of atoms are confined in a specially shaped arrangement of electric and magnetic fields. Shining particular wavelengths of light at the ions or atoms slows them down, thus "cooling" them. As this process is continued, they all are slowed and have the same energy level, forming an unusual arrangement of matter known as a Bose–Einstein condensate.

Some of the world's most powerful and complex arrangements of multiple lasers and optical amplifiers are used to produce extremely high intensity pulses of light of extremely short duration, e.g. laboratory for laser energetics, National Ignition Facility, GEKKO XII, Nike laser, Laser Mégajoule, HiPER. These pulses are arranged such that they impact pellets of tritium–deuterium simultaneously from all directions, hoping that the squeezing effect of the impacts will induce atomic fusion in the pellets. This technique, known as "inertial confinement fusion", so far has not been able to achieve "breakeven", that is, so far the fusion reaction generates less power than is used to power the lasers, but research continues.

Confocal laser scanning microscopy and Two-photon excitation microscopy make use of lasers to obtain blur-free images of thick specimens at various depths. Laser capture microdissection use lasers to procure specific cell populations from a tissue section under microscopic visualization.

Additional laser microscopy techniques include harmonic microscopy, four-wave mixing microscopy and interferometric microscopy.

Military uses of lasers include applications such as target designation and ranging, defensive countermeasures, communications and directed energy weapons.

A laser weapon is directed-energy weapon based on lasers.

Defensive countermeasure applications can range from compact, low power infrared countermeasures to high power, airborne laser systems. IR countermeasure systems use lasers to confuse the seeker heads on infrared homing missiles.

Some weapons simply use a laser to disorient a person. One such weapon is the Thales Green Laser Optical Warner.

Laser guidance is a technique of guiding a missile or other projectile or vehicle to a target by means of a laser beam.

Another military use of lasers is as a "laser target designator". This is a low-power laser pointer used to indicate a target for a precision-guided munition, typically launched from an aircraft. The guided munition adjusts its flight-path to home in to the laser light reflected by the target, enabling a great precision in aiming. The beam of the laser target designator is set to a pulse rate that matches that set on the guided munition to ensure munitions strike their designated targets and do not follow other laser beams which may be in use in the area. The laser designator can be shone onto the target by an aircraft or nearby infantry. Lasers used for this purpose are usually infrared lasers, so the enemy cannot easily detect the guiding laser light.

The laser has in most firearms applications been used as a tool to enhance the targeting of other weapon systems. For example, a "laser sight" is a small, usually visible-light laser placed on a handgun or a rifle and aligned to emit a beam parallel to the barrel. Since a laser beam has low divergence, the laser light appears as a small spot even at long distances; the user places the spot on the desired target and the barrel of the gun is aligned (but not necessarily allowing for bullet drop, windage, distance between the direction of the beam and the axis of the barrel, and the target mobility while the bullet travels).

Most laser sights use a red laser diode. Others use an infrared diode to produce a dot invisible to the naked human eye but detectable with night vision devices. The firearms adaptive target acquisition module LLM01 laser light module combines visible and infrared laser diodes. In the late 1990s, green diode pumped solid state laser (DPSS) laser sights (532 nm) became available. Modern laser sights are small and light enough for attachment to firearms.

A non-lethal laser weapon was developed by the U.S. Air Force to temporarily impair an adversary's ability to fire a weapon or to otherwise threaten enemy forces. This unit illuminates an opponent with harmless low-power laser light and can have the effect of dazzling or disorienting the subject or causing them to flee. Several types of dazzlers are now available, and some have been used in combat.

There remains the possibility of using lasers to blind, since this requires such lower power levels, and is easily achievable in a man-portable unit. However, most nations regard the deliberate permanent blinding of the enemy as forbidden by the rules of war (see Protocol on Blinding Laser Weapons). Although several nations have developed blinding laser weapons, such as China's ZM-87, none of these are believed to have made it past the prototype stage.

In addition to the applications that cross over with military applications, a widely known law enforcement use of lasers is for lidar to measure the speed of vehicles.

A holographic weapon sight uses a laser diode to illuminate a hologram of a reticle built into a flat glass optical window of the sight. The user looks through the optical window and sees a cross hair reticle image superimposed at a distance on the field of view.


Industrial laser applications can be divided into two categories depending on the power of the laser: material processing and micro-material processing.

In material processing, lasers with average optical power above 1 kilowatt are used mainly for industrial materials processing applications. Beyond this power threshold there are thermal issues related to the optics that separate these lasers from their lower-power counterparts. Laser systems in the 50-300W range are used primarily for pumping, plastic welding and soldering applications. Lasers above 300W are used in brazing, thin metal welding, and sheet metal cutting applications. The required brightness (as measured in by the beam parameter product) is higher for cutting applications than for brazing and thin metal welding. High power applications, such as hardening, cladding, and deep penetrating welding, require multiple kW of optical power, and are used in a broad range of industrial processes.

Micro material processing is a category that includes all laser material processing applications under 1 kilowatt. The use of lasers in Micro Materials Processing has found broad application in the development and manufacturing of screens for smartphones, tablet computers, and LED TVs.

A detailed list of industrial and commercial laser applications includes:



In surveying and construction, the laser level is affixed to a tripod, leveled and then spun to illuminate a horizontal plane. The laser beam projector employs a rotating head with a mirror for sweeping the laser beam about a vertical axis. If the mirror is not self-leveling, it is provided with visually readable level vials and manually adjustable screws for orienting the projector. A staff carried by the operator is equipped with a movable sensor, which can detect the laser beam and gives a signal when the sensor is in line with the beam (usually an audible beep). The position of the sensor on the graduated staff allows comparison of elevations between different points on the terrain.

A tower-mounted laser level is used in combination with a sensor on a wheel tractor-scraper in the process of land laser leveling to bring land (for example, an agricultural field) to near-flatness with a slight grade for drainage. The laser line level was invented in 1996 by Steve J. Orosz, Jr.[1] This type of level does not require a heavy motor to create the illusion of a line from a dot, rather, it uses a lens to transform the dot into a line.

Laser beams are used to disperse birds from agricultural land, industrial sites, rooftops and from airport runways. Birds tend to perceive the laser beam as a physical stick. By moving the laser beam towards the birds, they get scared and fly away. On the market are manual operated laser torches or automated robots to move the laser beam automatically.




</doc>
<doc id="18148" url="https://en.wikipedia.org/wiki?curid=18148" title="Left-arm orthodox spin">
Left-arm orthodox spin

Left-arm orthodox spin, also known as slow left-arm orthodox spin bowling, is a type of left-arm finger off spin bowling in the sport of cricket. 
Left-arm orthodox spin is bowled by a left-arm bowler using the fingers to spin the ball from right to left of the cricket pitch (from the bowler's perspective).

Left arm orthodox spin bowlers generally attempt to drift the ball in the air into a right-handed batsman, and then turn it away from the batsman (towards off-stump) upon landing on the pitch. The drift and turn in the air are attacking techniques. The stock delivery of a left-arm orthodox spin bowler is the left-arm orthodox spinner.

The major variations of a left-arm orthodox spin bowler are the topspinner (which turns less and bounces higher in the cricket pitch), the arm ball (which does not turn at all, drifts into a right-handed batsman in the direction of the bowler's arm movement; also called a 'floater') and the left-arm spinner's version of a doosra (which turns the other way).


</doc>
<doc id="18151" url="https://en.wikipedia.org/wiki?curid=18151" title="Laser construction">
Laser construction

A laser is constructed from three principal parts:


The "pump source" is the part that provides energy to the laser system. Examples of pump sources include electrical discharges, flashlamps, arc lamps, light from another laser, chemical reactions and even explosive devices. The type of pump source used principally depends on the "gain medium", and this also determines how the energy is transmitted to the medium. A helium–neon (HeNe) laser uses an electrical discharge in the helium-neon gas mixture, a Nd:YAG laser uses either light focused from a xenon flash lamp or diode lasers, and excimer lasers use a chemical reaction.

The "gain medium" is the major determining factor of the wavelength of operation, and other properties, of the laser. "Gain media" in different materials have linear spectra or wide spectra. "Gain media" with wide spectra allow tuning of the laser frequency. There are hundreds if not thousands of different gain media in which laser operation has been achieved (see list of laser types for a list of the most important ones). The gain medium is excited by the pump source to produce a population inversion, and it is in the gain medium where spontaneous and stimulated emission of photons takes place, leading to the phenomenon of optical gain, or amplification.

Examples of different gain media include:

The "optical resonator", or "optical cavity", in its simplest form is two parallel mirrors placed around the gain medium, which provide feedback of the light. The mirrors are given optical coatings which determine their reflective properties. Typically, one will be a high reflector, and the other will be a partial reflector. The latter is called the output coupler, because it allows some of the light to leave the cavity to produce the laser's output beam.

Light from the medium, produced by spontaneous emission, is reflected by the mirrors back into the medium, where it may be amplified by stimulated emission. The light may reflect from the mirrors and thus pass through the gain medium many hundreds of times before exiting the cavity. In more complex lasers, configurations with four or more mirrors forming the cavity are used. The design and alignment of the mirrors with respect to the medium is crucial for determining the exact operating wavelength and other attributes of the laser system.

Other optical devices, such as spinning mirrors, modulators, filters, and absorbers, may be placed within the optical resonator to produce a variety of effects on the laser output, such as altering the wavelength of operation or the production of pulses of laser light.

Some lasers do not use an optical cavity, but instead rely on very high optical gain to produce significant amplified spontaneous emission (ASE) without needing feedback of the light back into the gain medium. Such lasers are said to be superluminescent, and emit light with low coherence but high bandwidth. Since they do not use optical feedback, these devices are often not categorized as lasers.





</doc>
<doc id="18152" url="https://en.wikipedia.org/wiki?curid=18152" title="Logical conjunction">
Logical conjunction

In logic, mathematics and linguistics, And (∧) is the truth-functional operator of logical conjunction; the "and" of a set of operands is true if and only if "all" of its operands are true. The logical connective that represents this operator is typically written as or .

formula_1 is true if and only if formula_2 is true and formula_3 is true.

An operand of a conjunction is a conjunct.

The term "logical conjunction" is also used for the greatest lower bound in lattice theory.

Related concepts in other fields are:


And is usually denoted by an infix operator: in mathematics and logic, it is denoted by ', ' or '; in electronics, '; and in programming languages, codice_1, codice_2, or codice_3. In Jan Łukasiewicz's prefix notation for logic, the operator is K, for Polish "koniunkcja".

Logical conjunction is an operation on two logical values, typically the values of two propositions, that produces a value of "true" if and only if both of its operands are true.

The conjunctive identity is true, which is to say that AND-ing an expression with true will never change the value of the expression. In keeping with the concept of vacuous truth, when conjunction is defined as an operator or function of arbitrary arity, the empty conjunction (AND-ing over an empty set of operands) is often defined as having the result true.

The truth table of formula_1:

In systems where logical conjunction is not a primitive, it may be defined as
or

As a rule of inference, conjunction introduction is a classically valid, simple argument form. The argument form has two premises, "A" and "B". Intuitively, it permits the inference of their conjunction.

or in logical operator notation:

Here is an example of an argument that fits the form "conjunction introduction":

Conjunction elimination is another classically valid, simple argument form. Intuitively, it permits the inference from any conjunction of either element of that conjunction.

...or alternatively,

In logical operator notation:

...or alternatively,

A conjunction formula_14 is be proven false by establishing either formula_15 or formula_16. 
In terms of the object language, this reads

This formula can be seen as a special case of

when formula_19 is a false proposition.

If formula_2 implies formula_16, then both formula_15 as well as formula_2 prove the conjunction false:
In other words, a conjunction can actually be proven false just by knowing about the relation of its conjuncts and not necessary about their truth values.

This formula can be seen as a special case of

when formula_19 is a false proposition.

Either of the above are constructively valid proofs by contradiction.

commutativity: yes
associativity: yes
distributivity: with various operations, especially with "or"

idempotency: yes<br>
monotonicity: yes
truth-preserving: yes<br>
When all inputs are true, the output is true.
falsehood-preserving: yes<br>
When all inputs are false, the output is false.
Walsh spectrum: (1,-1,-1,1)

Nonlinearity: 1 (the function is bent)

If using binary values for true (1) and false (0), then "logical conjunction" works exactly like normal arithmetic multiplication.

In high-level computer programming and digital electronics, logical conjunction is commonly represented by an infix operator, usually as a keyword such as "codice_4", an algebraic multiplication, or the ampersand symbol codice_1 (sometimes doubled as in codice_2). Many languages also provide short-circuit control structures corresponding to logical conjunction.

Logical conjunction is often used for bitwise operations, where codice_7 corresponds to false and codice_8 to true:


The operation can also be applied to two binary words viewed as bitstrings of equal length, by taking the bitwise AND of each pair of bits at corresponding positions. For example:


This can be used to select part of a bitstring using a bit mask. For example, codice_19  =  codice_20 extracts the fifth bit of an 8-bit bitstring.

In computer networking, bit masks are used to derive the network address of a subnet within an existing network from a given IP address, by ANDing the IP address and the subnet mask.

Logical conjunction "codice_4" is also used in SQL operations to form database queries.

The Curry–Howard correspondence relates logical conjunction to product types.

The membership of an element of an intersection set in set theory is defined in terms of a logical conjunction: "x" ∈ "A" ∩ "B" if and only if ("x" ∈ "A") ∧ ("x" ∈ "B"). Through this correspondence, set-theoretic intersection shares several properties with logical conjunction, such as associativity, commutativity, and idempotence.

As with other notions formalized in mathematical logic, the logical conjunction "and" is related to, but not the same as, the grammatical conjunction "and" in natural languages.

English "and" has properties not captured by logical conjunction. For example, "and" sometimes implies order having the sense of "then". For example, "They got married and had a child" in common discourse means that the marriage came before the child.

The word "and" can also imply a partition of a thing into parts, as "The American flag is red, white, and blue." Here it is not meant that the flag is "at once" red, white, and blue, but rather that it has a part of each color.



</doc>
<doc id="18153" url="https://en.wikipedia.org/wiki?curid=18153" title="Logical connective">
Logical connective

In logic, a logical connective (also called a logical operator, sentential connective, or sentential operator) is a symbol or word used to connect two or more sentences (of either a formal or a natural language) in a grammatically valid way, such that the value of the compound sentence produced depends only on that of the original sentences and on the meaning of the connective.

The most common logical connectives are binary connectives (also called dyadic connectives) which join two sentences which can be thought of as the function's operands. Also commonly, negation is considered to be a unary connective.

Logical connectives along with quantifiers are the two main types of logical constants used in formal systems such as propositional logic and predicate logic. Semantics of a logical connective is often, but not always, presented as a truth function.

A logical connective is similar to but not equivalent to a conditional operator.

In the grammar of natural languages two sentences may be joined by a grammatical conjunction to form a "grammatically" compound sentence. Some but not all such grammatical conjunctions are truth functional. For example, consider the following sentences:

The words "and" and "so" are "grammatical" conjunctions joining the sentences (A) and (B) to form the compound sentences (C) and (D). The "and" in (C) is a "logical" connective, since the truth of (C) is completely determined by (A) and (B): it would make no sense to affirm (A) and (B) but deny (C). However, "so" in (D) is not a logical connective, since it would be quite reasonable to affirm (A) and (B) but deny (D): perhaps, after all, Jill went up the hill to fetch a pail of water, not because Jack had gone up the hill at all.

Various English words and word pairs express logical connectives, and some of them are synonymous. Examples are:

In formal languages, truth functions are represented by unambiguous symbols. These symbols are called "logical connectives", "logical operators", "propositional operators", or, in classical logic, "truth-functional connectives". See well-formed formula for the rules which allow new well-formed formulas to be constructed by joining other well-formed formulas using truth-functional connectives.

Logical connectives can be used to link more than two statements, so one can speak about "-ary logical connective".

Commonly used logical connectives include

Alternative names for biconditional are "iff", "xnor", and "bi-implication".

For example, the meaning of the statements "it is raining" and "I am indoors" is transformed when the two are combined with logical connectives. For statement "P" = "It is raining" and "Q" = "I am indoors":

It is also common to consider the "always true" formula and the "always false" formula to be connective:


Some authors used letters for connectives at some time of the history: u. for conjunction (German's "und" for "and") and o. for disjunction (German's "oder" for "or") in earlier works by Hilbert (1904); N"p for negation, K"pq for conjunction, D"pq for alternative denial, A"pq for disjunction, X"pq for joint denial, C"pq for implication, E"pq" for biconditional in Łukasiewicz (1929); cf. Polish notation.

Such a logical connective as converse implication "←" is actually the same as material conditional with swapped arguments; thus, the symbol for converse implication is redundant. In some logical calculi (notably, in classical logic) certain essentially different compound statements are logically equivalent. A less trivial example of a redundancy is the classical equivalence between and . Therefore, a classical-based logical system does not need the conditional operator "→" if "¬" (not) and "∨" (or) are already in use, or may use the "→" only as a syntactic sugar for a compound having one negation and one disjunction.

There are sixteen Boolean functions associating the input truth values and with four-digit binary outputs. These correspond to possible choices of binary logical connectives for classical logic. Different implementations of classical logic can choose different functionally complete subsets of connectives.

One approach is to choose a "minimal" set, and define other connectives by some logical form, as in the example with the material conditional above.
The following are the minimal functionally complete sets of operators in classical logic whose arities do not exceed 2:

Another approach is to use with equal rights connectives of a certain convenient and functionally complete, but "not minimal" set. This approach requires more propositional axioms, and each equivalence between logical forms must be either an axiom or provable as a theorem.

The situation, however, is more complicated in intuitionistic logic. Of its five connectives, {∧, ∨, →, ¬, ⊥}, only negation "¬" can be reduced to other connectives (see details). Neither conjunction, disjunction, nor material conditional has an equivalent form constructed of the other four logical connectives.

Some logical connectives possess properties which may be expressed in the theorems containing the connective. Some of those properties that a logical connective may have are:


For classical and intuitionistic logic, the "=" symbol means that corresponding implications "…→…" and "…←…" for logical compounds can be both proved as theorems, and the "≤" symbol means that "…→…" for logical compounds is a consequence of corresponding "…→…" connectives for propositional variables. Some many-valued logics may have incompatible definitions of equivalence and order (entailment).

Both conjunction and disjunction are associative, commutative and idempotent in classical logic, most varieties of many-valued logic and intuitionistic logic. The same is true about distributivity of conjunction over disjunction and disjunction over conjunction, as well as for the absorption law.

In classical logic and some varieties of many-valued logic, conjunction and disjunction are dual, and negation is self-dual, the latter is also self-dual in intuitionistic logic. 

As a way of reducing the number of necessary parentheses, one may introduce precedence rules: ¬ has higher precedence than ∧, ∧ higher than ∨, and ∨ higher than →. So for example, formula_36 is short for formula_37.

Here is a table that shows a commonly used precedence of logical operators.

However, not all compilers use the same order; for instance, an ordering in which disjunction is lower precedence than implication or bi-implication has also been used. Sometimes precedence between conjunction and disjunction is unspecified requiring to provide it explicitly in given formula with parentheses. The order of precedence determines which connective is the "main connective" when interpreting a non-atomic formula.

A truth-functional approach to logical operators is implemented as logic gates in digital circuits. Practically all digital circuits (the major exception is DRAM) are built up from NAND, NOR, NOT, and transmission gates; see more details in Truth function in computer science. Logical operators over bit vectors (corresponding to finite Boolean algebras) are bitwise operations.

But not every usage of a logical connective in computer programming has a Boolean semantic. For example, lazy evaluation is sometimes implemented for and , so these connectives are not commutative if either or both of the expressions , have side effects. Also, a conditional, which in some sense corresponds to the material conditional connective, is essentially non-Boolean because for codice_1 the consequent Q is not executed if the antecedent P is false (although a compound as a whole is successful ≈ "true" in such case). This is closer to intuitionist and constructivist views on the material conditional, rather than to classical logic's ones.




</doc>
<doc id="18154" url="https://en.wikipedia.org/wiki?curid=18154" title="Propositional calculus">
Propositional calculus

Propositional calculus is a branch of logic. It is also called propositional logic, statement logic, sentential calculus, sentential logic, or sometimes zeroth-order logic. It deals with propositions (which can be true or false) and relations between propositions, including the construction of arguments based on them. Compound propositions are formed by connecting propositions by logical connectives. Propositions that contain no logical connectives are called atomic propositions.

Unlike first-order logic, propositional logic does not deal with non-logical objects, predicates about them, or quantifiers. However, all the machinery of propositional logic is included in first-order logic and higher-order logics. In this sense, propositional logic is the foundation of first-order logic and higher-order logic.

Logical connectives are found in natural languages. In English for example, some examples are "and" (conjunction), "or" (disjunction), "not" (negation) and "if" (but only when used to denote material conditional).

The following is an example of a very simple inference within the scope of propositional logic:

Both premises and the conclusion are propositions. The premises are taken for granted, and with the application of modus ponens (an inference rule), the conclusion follows.

As propositional logic is not concerned with the structure of propositions beyond the point where they can't be decomposed any more by logical connectives, this inference can be restated replacing those "atomic" statements with statement letters, which are interpreted as variables representing statements:

The same can be stated succinctly in the following way:

When is interpreted as "It's raining" and as "it's cloudy" the above symbolic expressions can be seen to correspond exactly with the original expression in natural language. Not only that, but they will also correspond with any other inference of this "form", which will be valid on the same basis this inference is.

Propositional logic may be studied through a formal system in which formulas of a formal language may be interpreted to represent propositions. A system of axioms and inference rules allows certain formulas to be derived. These derived formulas are called theorems and may be interpreted to be true propositions. A constructed sequence of such formulas is known as a "derivation" or "proof" and the last formula of the sequence is the theorem. The derivation may be interpreted as proof of the proposition represented by the theorem.

When a formal system is used to represent formal logic, only statement letters (usually capital roman letters such as formula_2, formula_3 and formula_7) are represented directly. The natural language propositions that arise when they're interpreted are outside the scope of the system, and the relation between the formal system and its interpretation is likewise outside the formal system itself.

In classical truth-functional propositional logic, formulas are interpreted as having precisely one of two possible truth values, the truth value of "true" or the truth value of "false". The principle of bivalence and the law of excluded middle are upheld. Truth-functional propositional logic defined as such and systems isomorphic to it are considered to be zeroth-order logic. However, alternative propositional logics are also possible. For more, see Other logical calculi below.

Although propositional logic (which is interchangeable with propositional calculus) had been hinted by earlier philosophers, it was developed into a formal logic (Stoic logic) by Chrysippus in the 3rd century BC and expanded by his successor Stoics. The logic was focused on propositions. This advancement was different from the traditional syllogistic logic, which was focused on terms. However, most of the original writings were lost and the propositional logic developed by the Stoics was no longer understood later in antiquity. Consequently, the system was essentially reinvented by Peter Abelard in the 12th century.

Propositional logic was eventually refined using symbolic logic. The 17th/18th-century mathematician Gottfried Leibniz has been credited with being the founder of symbolic logic for his work with the calculus ratiocinator. Although his work was the first of its kind, it was unknown to the larger logical community. Consequently, many of the advances achieved by Leibniz were recreated by logicians like George Boole and Augustus De Morgan—completely independent of Leibniz.

Just as propositional logic can be considered an advancement from the earlier syllogistic logic, Gottlob Frege's predicate logic can be also considered an advancement from the earlier propositional logic. One author describes predicate logic as combining "the distinctive features of syllogistic logic and propositional logic." Consequently, predicate logic ushered in a new era in logic's history; however, advances in propositional logic were still made after Frege, including natural deduction, truth trees and truth tables. Natural deduction was invented by Gerhard Gentzen and Jan Łukasiewicz. Truth trees were invented by Evert Willem Beth. The invention of truth tables, however, is of uncertain attribution.

Within works by Frege and Bertrand Russell, are ideas influential to the invention of truth tables. The actual tabular structure (being formatted as a table), itself, is generally credited to either Ludwig Wittgenstein or Emil Post (or both, independently). Besides Frege and Russell, others credited with having ideas preceding truth tables include Philo, Boole, Charles Sanders Peirce, and Ernst Schröder. Others credited with the tabular structure include Jan Łukasiewicz, Ernst Schröder, Alfred North Whitehead, William Stanley Jevons, John Venn, and Clarence Irving Lewis. Ultimately, some have concluded, like John Shosky, that "It is far from clear that any one person should be given the title of 'inventor' of truth-tables.".

In general terms, a calculus is a formal system that consists of a set of syntactic expressions ("well-formed formulas"), a distinguished subset of these expressions (axioms), plus a set of formal rules that define a specific binary relation, intended to be interpreted as logical equivalence, on the space of expressions.

When the formal system is intended to be a logical system, the expressions are meant to be interpreted as statements, and the rules, known to be "inference rules", are typically intended to be truth-preserving. In this setting, the rules, which may include axioms, can then be used to derive ("infer") formulas representing true statements—from given formulas representing true statements.

The set of axioms may be empty, a nonempty finite set, or a countably infinite set (see axiom schema). A formal grammar recursively defines the expressions and well-formed formulas of the language. In addition a semantics may be given which defines truth and valuations (or interpretations).

The language of a propositional calculus consists of

A "well-formed formula" is any atomic formula, or any formula that can be built up from atomic formulas by means of operator symbols according to the rules of the grammar.

Mathematicians sometimes distinguish between propositional constants, propositional variables, and schemata. Propositional constants represent some particular proposition, while propositional variables range over the set of all atomic propositions. Schemata, however, range over all propositions. It is common to represent propositional constants by , , and , propositional variables by , , and , and schematic letters are often Greek letters, most often , , and .

The following outlines a standard propositional calculus. Many different formulations exist which are all more or less equivalent, but differ in the details of:

Any given proposition may be represented with a letter called a 'propositional constant', analogous to representing a number by a letter in mathematics (e.g., ). All propositions require exactly one of two truth-values: true or false. For example, let be the proposition that it is raining outside. This will be true () if it is raining outside, and false otherwise ().


It is very helpful to look at the truth tables for these different operators, as well as the method of analytic tableaux.

Propositional logic is closed under truth-functional connectives. That is to say, for any proposition , is also a proposition. Likewise, for any propositions and , is a proposition, and similarly for disjunction, conditional, and biconditional. This implies that, for instance, is a proposition, and so it can be conjoined with another proposition. In order to represent this, we need to use parentheses to indicate which proposition is conjoined with which. For instance, is not a well-formed formula, because we do not know if we are conjoining with or if we are conjoining with . Thus we must write either to represent the former, or to represent the latter. By evaluating the truth conditions, we see that both expressions have the same truth conditions (will be true in the same cases), and moreover that any proposition formed by arbitrary conjunctions will have the same truth conditions, regardless of the location of the parentheses. This means that conjunction is associative, however, one should not assume that parentheses never serve a purpose. For instance, the sentence does not have the same truth conditions of , so they are different sentences distinguished only by the parentheses. One can verify this by the truth-table method referenced above.

Note: For any arbitrary number of propositional constants, we can form a finite number of cases which list their possible truth-values. A simple way to generate this is by truth-tables, in which one writes , , ..., , for any list of propositional constants—that is to say, any list of propositional constants with entries. Below this list, one writes rows, and below one fills in the first half of the rows with true (or T) and the second half with false (or F). Below one fills in one-quarter of the rows with T, then one-quarter with F, then one-quarter with T and the last quarter with F. The next column alternates between true and false for each eighth of the rows, then sixteenths, and so on, until the last propositional constant varies between T and F for each row. This will give a complete listing of cases or truth-value assignments possible for those propositional constants.

The propositional calculus then defines an "argument" to be a list of propositions. A valid argument is a list of propositions, the last of which follows from—or is implied by—the rest. All other arguments are invalid. The simplest valid argument is modus ponens, one instance of which is the following list of propositions:

This is a list of three propositions, each line is a proposition, and the last follows from the rest. The first two lines are called premises, and the last line the conclusion. We say that any proposition follows from any set of propositions formula_9, if must be true whenever every member of the set formula_9 is true. In the argument above, for any and , whenever and are true, necessarily is true. Notice that, when is true, we cannot consider cases 3 and 4 (from the truth table). When is true, we cannot consider case 2. This leaves only case 1, in which is also true. Thus is implied by the premises.

This generalizes schematically. Thus, where and may be any propositions at all,

Other argument forms are convenient, but not necessary. Given a complete set of axioms (see below for one such set), modus ponens is sufficient to prove all other argument forms in propositional logic, thus they may be considered to be a derivative. Note, this is not true of the extension of propositional logic to other logics like first-order logic. First-order logic requires at least one additional rule of inference in order to obtain completeness.

The significance of argument in formal logic is that one may obtain new truths from established truths. In the first example above, given the two premises, the truth of is not yet known or stated. After the argument is made, is deduced. In this way, we define a deduction system to be a set of all propositions that may be deduced from another set of propositions. For instance, given the set of propositions formula_12, we can define a deduction system, , which is the set of all propositions which follow from . Reiteration is always assumed, so formula_13. Also, from the first element of , last element, as well as modus ponens, is a consequence, and so formula_14. Because we have not included sufficiently complete axioms, though, nothing else may be deduced. Thus, even though most deduction systems studied in propositional logic are able to deduce formula_15, this one is too weak to prove such a proposition.

A propositional calculus is a formal system formula_16, where:



The "language" of formula_18, also known as its set of "formulas", "well-formed formulas", is inductively defined by the following rules:


Repeated applications of these rules permits the construction of complex formulas. For example:


Let formula_40, where formula_17, formula_42, formula_28, formula_29 are defined as follows:





Let formula_61, where formula_17, formula_42, formula_28, formula_29 are defined as follows:


In the following example of a propositional calculus, the transformation rules are intended to be interpreted as the inference rules of a so-called "natural deduction system". The particular system presented here has no initial points, which means that its interpretation for logical applications derives its theorems from an empty axiom set.


Our propositional calculus has eleven inference rules. These rules allow us to derive other true formulas given a set of formulas that are assumed to be true. The first ten simply state that we can infer certain well-formed formulas from other well-formed formulas. The last rule however uses hypothetical reasoning in the sense that in the premise of the rule we temporarily assume an (unproven) hypothesis to be part of the set of inferred formulas to see if we can infer a certain other formula. Since the first ten rules don't do this they are usually described as "non-hypothetical" rules, and the last one as a "hypothetical" rule.

In describing the transformation rules, we may introduce a metalanguage symbol formula_73. It is basically a convenient shorthand for saying "infer that". The format is formula_74, in which is a (possibly empty) set of formulas called premises, and is a formula called conclusion. The transformation rule formula_74 means that if every proposition in is a theorem (or has the same truth value as the axioms), then is also a theorem. Note that considering the following rule Conjunction introduction, we will know whenever has more than one formula, we can always safely reduce it into one formula using conjunction. So for short, from that time on we may represent as one formula instead of a set. Another omission for convenience is when is an empty set, in which case may not appear.


One of the main uses of a propositional calculus, when interpreted for logical applications, is to determine relations of logical equivalence between propositional formulas. These relationships are determined by means of the available transformation rules, sequences of which are called "derivations" or "proofs".

In the discussion to follow, a proof is presented as a sequence of numbered lines, with each line consisting of a single formula followed by a "reason" or "justification" for introducing that formula. Each premise of the argument, that is, an assumption introduced as an hypothesis of the argument, is listed at the beginning of the sequence and is marked as a "premise" in lieu of other justification. The conclusion is listed on the last line. A proof is complete if every line follows from the previous ones by the correct application of a transformation rule. (For a contrasting approach, see proof-trees).


Interpret formula_113 as "Assuming , infer ". Read formula_114 as "Assuming nothing, infer that implies ", or "It is a tautology that implies ", or "It is always true that implies ".

We now prove the same theorem formula_115 in the axiomatic system by Jan Łukasiewicz described above, which is an example of a classical propositional calculus systems, or a Hilbert-style deductive system for propositional calculus.

The axioms are:

And the proof is as follows:

The crucial properties of this set of rules are that they are "sound" and "complete". Informally this means that the rules are correct and that no other rules are required. These claims can be made more formal as follows.
Note that the proofs for the soundness and completeness of the propositional logic are not themselves proofs in propositional logic ; these are theorems in ZFC used as a metatheory to prove properties of propositional logic.

We define a "truth assignment" as a function that maps propositional variables to true or false. Informally such a truth assignment can be understood as the description of a possible state of affairs (or possible world) where certain statements are true and others are not. The semantics of formulas can then be formalized by defining for which "state of affairs" they are considered to be true, which is what is done by the following definition.

We define when such a truth assignment satisfies a certain well-formed formula with the following rules:

With this definition we can now formalize what it means for a formula to be implied by a certain set of formulas. Informally this is true if in all worlds that are possible given the set of formulas the formula also holds. This leads to the following formal definition: We say that a set of well-formed formulas "semantically entails" (or "implies") a certain well-formed formula if all truth assignments that satisfy all the formulas in also satisfy .

Finally we define "syntactical entailment" such that is syntactically entailed by if and only if we can derive it with the inference rules that were presented above in a finite number of steps. This allows us to formulate exactly what it means for the set of inference rules to be sound and complete:

Soundness: If the set of well-formed formulas "syntactically" entails the well-formed formula then "semantically" entails .

Completeness: If the set of well-formed formulas "semantically" entails the well-formed formula then "syntactically" entails .

For the above set of rules this is indeed the case.

Notational conventions: Let be a variable ranging over sets of sentences. Let and range over sentences. For " syntactically entails " we write " proves ". For " semantically entails " we write " implies ".

We want to show: (if proves , then implies ).

We note that " proves " has an inductive definition, and that gives us the immediate resources for demonstrating claims of the form "If proves , then ...". So our proof proceeds by induction.
Notice that Basis Step II can be omitted for natural deduction systems because they have no axioms. When used, Step II involves showing that each of the axioms is a (semantic) logical truth.

The Basis steps demonstrate that the simplest provable sentences from are also implied by , for any . (The proof is simple, since the semantic fact that a set implies any of its members, is also trivial.) The Inductive step will systematically cover all the further sentences that might be provable—by considering each case where we might reach a logical conclusion using an inference rule—and shows that if a new sentence is provable, it is also logically implied. (For example, we might have a rule telling us that from "" we can derive " or ". In III.a We assume that if is provable it is implied. We also know that if is provable then " or " is provable. We have to show that then " or " too is implied. We do so by appeal to the semantic definition and the assumption we just made. is provable from , we assume. So it is also implied by . So any semantic valuation making all of true makes true. But any valuation making true makes " or " true, by the defined semantics for "or". So any valuation which makes all of true makes " or " true. So " or " is implied.) Generally, the Inductive step will consist of a lengthy but simple case-by-case analysis of all the rules of inference, showing that each "preserves" semantic implication.

By the definition of provability, there are no sentences provable other than by being a member of , an axiom, or following by a rule; so if all of those are semantically implied, the deduction calculus is sound.

We adopt the same notational conventions as above.

We want to show: If implies , then proves . We proceed by contraposition: We show instead that if does not prove then does not imply . If we show that there is a model where does not hold despite being true, then obviously does not imply . The idea is to build such a model out of our very assumption that does not prove .

Thus every system that has modus ponens as an inference rule, and proves the following theorems (including substitutions thereof) is complete:

The first five are used for the satisfaction of the five conditions in stage III above, and the last three for proving the deduction theorem.

As an example, it can be shown that as any other tautology, the three axioms of the classical propositional calculus system described earlier can be proven in any system that satisfies the above, namely that has modus ponens as an inference rule, and proves the above eight theorems (including substitutions thereof). Indeed, out of the eight theorems, the last two are two of the three axioms; the third axiom, formula_124, can be proven as well, as we now show. 

For the proof we may use the hypothetical syllogism theorem (in the form relevant for this axiomatic system), since it only relies on the two axioms that are already in the above set of eight theorems.
The proof then is as follows:

We now verify that the classical propositional calculus system described earlier can indeed prove the required eight theorems mentioned above. We use several lemmas proven here:
We also use the method of the hypothetical syllogism metatheorem as a shorthand for several proof steps.







If a formula is a tautology, then there is a truth table for it which shows that each valuation yields the value true for the formula. Consider such a valuation. By mathematical induction on the length of the subformulas, show that the truth or falsity of the subformula follows from the truth or falsity (as appropriate for the valuation) of each propositional variable in the subformula. Then combine the lines of the truth table together two at a time by using "( is true implies ) implies (( is false implies ) implies )". Keep repeating this until all dependencies on propositional variables have been eliminated. The result is that we have proved the given tautology. Since every tautology is provable, the logic is complete.

An interpretation of a truth-functional propositional calculus formula_174 is an assignment to each propositional symbol of formula_174 of one or the other (but not both) of the truth values truth (T) and falsity (F), and an assignment to the connective symbols of formula_174 of their usual truth-functional meanings. An interpretation of a truth-functional propositional calculus may also be expressed in terms of truth tables.

For formula_177 distinct propositional symbols there are formula_178 distinct possible interpretations. For any particular symbol formula_179, for example, there are formula_180 possible interpretations:
For the pair formula_179, formula_184 there are formula_185 possible interpretations:

Since formula_174 has formula_191, that is, denumerably many propositional symbols, there are formula_192, and therefore uncountably many distinct possible interpretations of formula_174.

If and are formulas of formula_174 and formula_195 is an interpretation of formula_174 then the following definitions apply:


Some consequences of these definitions:


It is possible to define another version of propositional calculus, which defines most of the syntax of the logical operators by means of axioms, and which uses only one inference rule.

Let , , and stand for well-formed formulas. (The well-formed formulas themselves would not contain any Greek letters, but only capital Roman letters, connective operators, and parentheses.) Then the axioms are as follows:


The inference rule is modus ponens:

Let a demonstration be represented by a sequence, with hypotheses to the left of the turnstile and the conclusion to the right of the turnstile. Then the deduction theorem can be stated as follows:

This deduction theorem (DT) is not itself formulated with propositional calculus: it is not a theorem of propositional calculus, but a theorem about propositional calculus. In this sense, it is a meta-theorem, comparable to theorems about the soundness or completeness of propositional calculus.

On the other hand, DT is so useful for simplifying the syntactical proof process that it can be considered and used as another inference rule, accompanying modus ponens. In this sense, DT corresponds to the natural conditional proof inference rule which is part of the first version of propositional calculus introduced in this article.

The converse of DT is also valid:
in fact, the validity of the converse of DT is almost trivial compared to that of DT:

The converse of DT has powerful implications: it can be used to convert an axiom into an inference rule. For example, the axiom AND-1,
can be transformed by means of the converse of the deduction theorem into the inference rule
which is conjunction elimination, one of the ten inference rules used in the first version (in this article) of the propositional calculus.

The following is an example of a (syntactical) demonstration, involving only axioms and :

Prove: formula_229 (Reflexivity of implication).

Proof:

The preceding alternative calculus is an example of a Hilbert-style deduction system. In the case of propositional systems the axioms are terms built with logical connectives and the only inference rule is modus ponens. Equational logic as standardly used informally in high school algebra is a different kind of calculus from Hilbert systems. Its theorems are equations and its inference rules express the properties of equality, namely that it is a congruence on terms that admits substitution.

Classical propositional calculus as described above is equivalent to Boolean algebra, while intuitionistic propositional calculus is equivalent to Heyting algebra. The equivalence is shown by translation in each direction of the theorems of the respective systems. Theorems formula_238 of classical or intuitionistic propositional calculus are translated as equations formula_239 of Boolean or Heyting algebra respectively. Conversely theorems formula_240 of Boolean or Heyting algebra are translated as theorems formula_241 of classical or intuitionistic calculus respectively, for which formula_242 is a standard abbreviation. In the case of Boolean algebra formula_240 can also be translated as formula_244, but this translation is incorrect intuitionistically.

In both Boolean and Heyting algebra, inequality formula_245 can be used in place of equality. The equality formula_240 is expressible as a pair of inequalities formula_245 and formula_248. Conversely the inequality formula_245 is expressible as the equality formula_250, or as formula_251. The significance of inequality for Hilbert-style systems is that it corresponds to the latter's deduction or entailment symbol formula_73. An entailment

is translated in the inequality version of the algebraic framework as

Conversely the algebraic inequality formula_245 is translated as the entailment

The difference between implication formula_257 and inequality or entailment formula_245 or formula_256 is that the former is internal to the logic while the latter is external. Internal implication between two terms is another term of the same kind. Entailment as external implication between two terms expresses a metatruth outside the language of the logic, and is considered part of the metalanguage. Even when the logic under study is intuitionistic, entailment is ordinarily understood classically as two-valued: either the left side entails, or is less-or-equal to, the right side, or it is not.

Similar but more complex translations to and from algebraic logics are possible for natural deduction systems as described above and for the sequent calculus. The entailments of the latter can be interpreted as two-valued, but a more insightful interpretation is as a set, the elements of which can be understood as abstract proofs organized as the morphisms of a category. In this interpretation the cut rule of the sequent calculus corresponds to composition in the category. Boolean and Heyting algebras enter this picture as special categories having at most one morphism per homset, i.e., one proof per entailment, corresponding to the idea that existence of proofs is all that matters: any proof will do and there is no point in distinguishing them.

It is possible to generalize the definition of a formal language from a set of finite sequences over a finite basis to include many other sets of mathematical structures, so long as they are built up by finitary means from finite materials. What's more, many of these families of formal structures are especially well-suited for use in logic.

For example, there are many families of graphs that are close enough analogues of formal languages that the concept of a calculus is quite easily and naturally extended to them. Indeed, many species of graphs arise as "parse graphs" in the syntactic analysis of the corresponding families of text structures. The exigencies of practical computation on formal languages frequently demand that text strings be converted into pointer structure renditions of parse graphs, simply as a matter of checking whether strings are well-formed formulas or not. Once this is done, there are many advantages to be gained from developing the graphical analogue of the calculus on strings. The mapping from strings to parse graphs is called "parsing" and the inverse mapping from parse graphs to strings is achieved by an operation that is called "traversing" the graph.

Propositional calculus is about the simplest kind of logical calculus in current use. It can be extended in several ways. (Aristotelian "syllogistic" calculus, which is largely supplanted in modern logic, is in "some" ways simpler – but in other ways more complex – than propositional calculus.) The most immediate way to develop a more complex logical calculus is to introduce rules that are sensitive to more fine-grained details of the sentences being used.

First-order logic (a.k.a. first-order predicate logic) results when the "atomic sentences" of propositional logic are broken up into terms, variables, predicates, and quantifiers, all keeping the rules of propositional logic with some new ones introduced. (For example, from "All dogs are mammals" we may infer "If Rover is a dog then Rover is a mammal".) With the tools of first-order logic it is possible to formulate a number of theories, either with explicit axioms or by rules of inference, that can themselves be treated as logical calculi. Arithmetic is the best known of these; others include set theory and mereology. Second-order logic and other higher-order logics are formal extensions of first-order logic. Thus, it makes sense to refer to propositional logic as ""zeroth-order logic"", when comparing it with these logics.

Modal logic also offers a variety of inferences that cannot be captured in propositional calculus. For example, from "Necessarily " we may infer that . From we may infer "It is possible that ". The translation between modal logics and algebraic logics concerns classical and intuitionistic logics but with the introduction of a unary operator on Boolean or Heyting algebras, different from the Boolean operations, interpreting the possibility modality, and in the case of Heyting algebra a second operator interpreting necessity (for Boolean algebra this is redundant since necessity is the De Morgan dual of possibility). The first operator preserves 0 and disjunction while the second preserves 1 and conjunction.

Many-valued logics are those allowing sentences to have values other than "true" and "false". (For example, "neither" and "both" are standard "extra values"; "continuum logic" allows each sentence to have any of an infinite number of "degrees of truth" between "true" and "false".) These logics often require calculational devices quite distinct from propositional calculus. When the values form a Boolean algebra (which may have more than two or even infinitely many values), many-valued logic reduces to classical logic; many-valued logics are therefore only of independent interest when the values form an algebra that is not Boolean.

Finding solutions to propositional logic formulas is an NP-complete problem. However, practical methods exist (e.g., DPLL algorithm, 1962; Chaff algorithm, 2001) that are very fast for many useful cases. Recent work has extended the SAT solver algorithms to work with propositions containing arithmetic expressions; these are the SMT solvers.





</doc>
<doc id="18155" url="https://en.wikipedia.org/wiki?curid=18155" title="Lazy evaluation">
Lazy evaluation

In programming language theory, lazy evaluation, or call-by-need is an evaluation strategy which delays the evaluation of an expression until its value is needed (non-strict evaluation) and which also avoids repeated evaluations (sharing). The sharing can reduce the running time of certain functions by an exponential factor over other non-strict evaluation strategies, such as call-by-name, which repeatedly evaluate the same function, blindly, regardless whether the function can be memoized.

However, for lengthy operations, it would be more appropriate to perform before any time-sensitive operations, such as handling user inputs in a video game.

The benefits of lazy evaluation include: 

Lazy evaluation is often combined with memoization, as described in Jon Bentley's "Writing Efficient Programs". After a function's value is computed for that parameter or set of parameters, the result is stored in a lookup table that is indexed by the values of those parameters; the next time the function is called, the table is consulted to determine whether the result for that combination of parameter values is already available. If so, the stored result is simply returned. If not, the function is evaluated and another entry is added to the lookup table for reuse.

Lazy evaluation can lead to reduction in memory footprint, since values are created when needed. However, lazy evaluation is difficult to combine with imperative features such as exception handling and input/output, because the order of operations becomes indeterminate. Lazy evaluation can introduce memory leaks.

The opposite of lazy evaluation is eager evaluation, sometimes known as strict evaluation. Eager evaluation is the evaluation strategy employed in most programming languages.

Lazy evaluation was introduced for lambda calculus by Christopher Wadsworth and employed by the Plessey System 250 as a critical part of a Lambda-Calculus Meta-Machine, reducing the resolution overhead for access to objects in a capability-limited address space. For programming languages, it was independently introduced by Peter Henderson and James H. Morris and by Daniel P. Friedman and David S. Wise.

Delayed evaluation is used particularly in functional programming languages. When using delayed evaluation, an expression is not evaluated as soon as it gets bound to a variable, but when the evaluator is forced to produce the expression's value. That is, a statement such as codice_1 (i.e. the assignment of the result of an expression to a variable) clearly calls for the expression to be evaluated and the result placed in codice_2, but what actually is in codice_2 is irrelevant until there is a need for its value via a reference to codice_2 in some later expression whose evaluation could itself be deferred, though eventually the rapidly growing tree of dependencies would be pruned to produce some symbol rather than another for the outside world to see.

Delayed evaluation has the advantage of being able to create calculable infinite lists without infinite loops or size matters interfering in computation. For example, one could create a function that creates an infinite list (often called a "stream") of Fibonacci numbers. The calculation of the "n"-th Fibonacci number would be merely the extraction of that element from the infinite list, forcing the evaluation of only the first n members of the list.

For example, in the Haskell programming language, the list of all Fibonacci numbers can be written as:
In Haskell syntax, "codice_5" prepends an element to a list, codice_6 returns a list without its first element, and codice_7 uses a specified function (in this case addition) to combine corresponding elements of two lists to produce a third.

Provided the programmer is careful, only the values that are required to produce a particular result are evaluated. However, certain calculations may result in the program attempting to evaluate an infinite number of elements; for example, requesting the length of the list or trying to sum the elements of the list with a fold operation would result in the program either failing to terminate or running out of memory.

In almost all common "eager" languages, "if" statements evaluate in a lazy fashion.
evaluates (a), then if and only if (a) evaluates to true does it evaluate (b), otherwise it evaluates (c). That is, either (b) or (c) will not be evaluated. Conversely, in an eager language the expected behavior is that
will still evaluate (e) when computing the value of f(d, e) even though (e) is unused in function f. However, user-defined control structures depend on exact syntax, so for example
(i) and (j) would both be evaluated in an eager language. While in a lazy language,
(i) or (j) would be evaluated, but never both.

Lazy evaluation allows control structures to be defined normally, and not as primitives or compile-time techniques. If (i) or (j) have side effects or introduce run time errors, the subtle differences between (l) and (l') can be complex. It is usually possible to introduce user-defined lazy control structures in eager languages as functions, though they may depart from the language's syntax for eager evaluation: Often the involved code bodies (like (i) and (j)) need to be wrapped in a function value, so that they are executed only when called.

Short-circuit evaluation of Boolean control structures is sometimes called "lazy".

Many languages offer the notion of "infinite data-structures". These allow definitions of data to be given in terms of infinite ranges, or unending recursion, but the actual values are only computed when needed. Take for example this trivial program in Haskell:
numberFromInfiniteList :: Int -> Int
numberFromInfiniteList n = infinity !! n - 1

main = print $ numberFromInfiniteList 4
In the function numberFromInfiniteList, the value of infinity is an infinite range, but until an actual value (or more specifically, a specific value at a certain index) is needed, the list is not evaluated, and even then it is only evaluated as needed (that is, until the desired index.)

A compound expression might be in the form "EasilyComputed or LotsOfWork" so that if the easy part gives true a lot of work could be avoided. For instance, suppose a large number N is to be checked to determine if it is a prime number and a function IsPrime(N) is available, but alas, it can require a lot of computation to evaluate. Perhaps "N=2 or [Mod(N,2)≠0 and IsPrime(N)]" will help if there are to be many evaluations with arbitrary values for N.

A compound expression might be in the form "SafeToTry and Expression" whereby if "SafeToTry" is false there should be no attempt at evaluating the "Expression" lest a run-time error be signalled, such as divide-by-zero or index-out-of-bounds, etc. For instance, the following pseudocode locates the last non-zero element of an array:
Should all elements of the array be zero, the loop will work down to L = 0, and in this case the loop must be terminated without attempting to reference element zero of the array, which does not exist.

In computer windowing systems, the painting of information to the screen is driven by "expose events" which drive the display code at the last possible moment. By doing this, windowing systems avoid computing unnecessary display content updates.

Another example of laziness in modern computer systems is copy-on-write page allocation or demand paging, where memory is allocated only when a value stored in that memory is changed.

Laziness can be useful for high performance scenarios. An example is the Unix mmap function, which provides "demand driven" loading of pages from disk, so that only those pages actually touched are loaded into memory, and unneeded memory is not allocated.

MATLAB implements "copy on edit", where arrays which are copied have their actual memory storage replicated only when their content is changed, possibly leading to an "out of memory" error when updating an element afterwards instead of during the copy operation.

Some programming languages delay evaluation of expressions by default, and some others provide functions or special syntax to delay evaluation. In Miranda and Haskell, evaluation of function arguments is delayed by default. In many other languages, evaluation can be delayed by explicitly suspending the computation using special syntax (as with Scheme's "codice_8" and "codice_9" and OCaml's "codice_10" and "codice_11") or, more generally, by wrapping the expression in a thunk. The object representing such an explicitly delayed evaluation is called a "lazy future." Raku uses lazy evaluation of lists, so one can assign infinite lists to variables and use them as arguments to functions, but unlike Haskell and Miranda, Raku does not use lazy evaluation of arithmetic operators and functions by default.

In lazy programming languages such as Haskell, although the default is to evaluate expressions only when they are demanded, it is possible in some cases to make code more eager—or conversely, to make it more lazy again after it has been made more eager. This can be done by explicitly coding something which forces evaluation (which may make the code more eager) or avoiding such code (which may make the code more lazy). "Strict" evaluation usually implies eagerness, but they are technically different concepts.

However, there is an optimisation implemented in some compilers called strictness analysis, which, in some cases, allows the compiler to infer that a value will always be used. In such cases, this may render the programmer's choice of whether to force that particular value or not, irrelevant, because strictness analysis will force strict evaluation.

In Haskell, marking constructor fields strict means that their values will always be demanded immediately. The codice_12 function can also be used to demand a value immediately and then pass it on, which is useful if a constructor field should generally be lazy. However, neither of these techniques implements "recursive" strictness—for that, a function called codice_13 was invented.

Also, pattern matching in Haskell 98 is strict by default, so the codice_14 qualifier has to be used to make it lazy.

In Python 2.x the codice_15 function computes a list of integers. The entire list is stored in memory when the first assignment statement is evaluated, so this is an example of eager or immediate evaluation:

»> r = range(10)
»> print r
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
»> print r[3]
3
In Python 3.x the codice_15 function returns a special range object which computes elements of the list on demand. Elements of the range object are only generated when they are needed (e.g., when codice_17 is evaluated in the following example), so this is an example of lazy or deferred evaluation:
»> r = range(10)
»> print(r)
range(0, 10)
»> print(r[3])
3

In Python 2.x is possible to use a function called codice_18 which returns an object that generates the numbers in the range on demand. The advantage of codice_19 is that generated object will always take the same amount of memory.
»> r = xrange(10)
»> print(r)
xrange(10)
»> lst = [x for x in r]
»> print(lst)
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
From version 2.2 forward, Python manifests lazy evaluation by implementing iterators (lazy sequences) unlike tuple or list sequences. For instance (Python 2):

»> numbers = range(10)
»> iterator = iter(numbers)
»> print numbers
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
»> print iterator
<listiterator object at 0xf7e8dd4c>
»> print iterator.next()
0

In the .NET Framework it is possible to do lazy evaluation using the class System.Lazy<T>. The class can be easily exploited in F# using the lazy keyword, while the force method will force the evaluation. There are also specialized collections like Microsoft.FSharp.Collections.Seq that provide built-in support for lazy evaluation. 

let fibonacci = Seq.unfold (fun (x, y) -> Some(x, (y, x + y))) (0I,1I)
fibonacci |> Seq.nth 1000

In C# and VB.NET, the class System.Lazy<T> is directly used. 

public int Sum()

Or with a more practical example: 

// recursive calculation of the n'th fibonacci number
public int Fib(int n)

public void Main()

Another way is to use the yield keyword: 

// eager evaluation 
public IEnumerable<int> Fibonacci(int x)

// lazy evaluation 
public IEnumerable<int> LazyFibonacci(int x)





</doc>
<doc id="18156" url="https://en.wikipedia.org/wiki?curid=18156" title="Lemuridae">
Lemuridae

Lemuridae is a family of strepsirrhine primates native to Madagascar and the Comoros Islands. They are represented by the Lemuriformes in Madagascar with one of the highest concentration of the lemurs. One of five families commonly known as lemurs. These animals were once thought to be the evolutionary predecessors of monkeys and apes, but this is no longer considered correct.

Lemurids are medium-sized arboreal primates, ranging from 32 to 56 cm in length, excluding the tail, and weighing from 0.7 to 5 kg. They have long, bushy tails and soft, woolly fur of varying coloration. The hindlegs are slightly longer than the forelegs, although not enough to hamper fully quadrupedal movement (unlike the sportive lemurs). Most species are highly agile, and regularly leap several metres between trees. They have a good sense of smell and binocular vision. Unlike most other lemurs, all but one species of lemurid (the ring-tailed lemur) lack a tapetum lucidum, a reflective layer in the eye that improves night vision. Historically among mammals, activity cycles are either strictly diurnal or nocturnal, however, these can widely vary across species. Lemur activity has in general evolved from nocturnal to diurnal. Some lemurs are also cathemeral, an activity pattern where an animal is neither strictly diurnal nor nocturnal.

Lemurids are herbivorous, eating fruit, leaves, and, in some cases, nectar. For the most part, they have the dental formula: . A lemur's diet is one that is not restricted since their diet consists of frugivory, granivory, folivory, insectivory, omnivory, and gumnivory foods. Some Subfossil records have contributed to the knowledge of the currently extant lemurs from the Holocene by showing the changes in their dental records in habitats near human activity. This demonstrates that lemur species such as the lemur "catta" and the common brown lemur were forced to switch their primary diet to a group of secondary food sources.

With most lemurids, the mother gives birth to one or two young after a gestation period of between 120 and 140 days, depending on species. The ruffed lemur species are the only lemurids that have true litters, consisting of anywhere from two to six offspring. They are generally sociable animals, living in groups of up to thirty individuals in some species. In some cases, such as the ring-tailed lemur, the groups are long-lasting, with distinct dominance hierarchies, while in others, such as the common brown lemur, the membership of the groups varies from day to day, and seems to have no clear social structure.

Some of the lemur traits include low basal metabolic rate, highly seasonal breeders, adaptations to unpredictable climate and female dominance. Female dominance amongst lemurs is when the females are sexually monomorphic and have priority access to food. Lemurs live in groups of 11 to 17 animals, where females tend to stay within their natal groups and the males migrate. Male lemurs are competitive to win their mates which causes instability among the other organisms. Lemurs are able to mark their territory by using scents from local areas.

A number of lemur species are considered threatened; two species are critically endangered, one species is endangered, and five species are rated as vulnerable.

The highly seasonal dry deciduous forest of Madagascar alternates between dry and wet seasons, making it uniquely suitable for lemurs. Lemur species diversity increases as the number of tree species in an area increase and is also higher in forests that have been disturbed over undisturbed areas. Evidence from the Subfossil records show that many of the now extinct lemurs actually lived in much drier climates than the currently extant lemurs.

The family Lemuridae contains 21 extant species in five genera.

FAMILY LEMURIDAE

This family was once broken into two subfamilies, Hapalemurinae (bamboo lemurs and the greater bamboo lemur) and Lemurinae (the rest of the family), but molecular evidence and the similarity of the scent glands have since placed the ring-tailed lemur with the bamboo lemurs and the greater bamboo lemur.

Lemur species in the genus "Eulemur" are known to interbreed, despite having dramatically different chromosome numbers. Red-fronted (2N=60) and collared (2N=50–52) brown lemurs were found to hybridize at Berenty Reserve, Madagascar.



</doc>
<doc id="18157" url="https://en.wikipedia.org/wiki?curid=18157" title="Lucent">
Lucent

Lucent Technologies, Inc., was an American multinational telecommunications equipment company headquartered in Murray Hill, New Jersey, in the United States. It was established on September 30, 1996, through the divestiture of the former AT&T Technologies business unit of AT&T Corporation, which included Western Electric and Bell Labs.

Lucent was merged with Alcatel SA of France on December 1, 2006, forming Alcatel-Lucent. Alcatel-Lucent was absorbed by Nokia in January 2016.

Lucent means "light-bearing" in Latin. The name was applied in 1996 at the time of the split from AT&T.

The name was widely criticised, as the logo was to be, both internally and externally. Corporate communications and business cards included the strapline 'Bell Labs Innovations' in a bid to retain the prestige of the internationally famous research lab, within a new business under an as-yet unknown name.

This same linguistic root also gives Lucifer, "the light bearer" (from lux, 'light', and ferre, 'to bear'), who is also a character in Dante's epic poem "Inferno". Shortly after the Lucent renaming in 1996, Lucent's Plan 9 project released a development of their work as the Inferno OS in 1997. This extended the 'Lucifer' and Dante references as a series of punning names for the components of Inferno - Dis, Limbo, Charon and Styx (9P Protocol). When the rights to Inferno were sold in 2000, the company Vita Nuova Holdings was formed to represent them. This continues the Dante theme, although moving away from his "Divine Comedy" to the poem "La Vita Nuova".

The Lucent logo, the Innovation Ring, was designed by Landor Associates, a prominent San Francisco-based branding consultancy. One source inside Lucent says that the logo is a Zen Buddhist symbol for "eternal truth", the Enso, turned 90 degrees and modified. Another source says it represents the mythic ouroboros, a snake holding its tail in its mouth. Lucent's logo also has been said to represent constant re-creating and re-thinking. Carly Fiorina picked the logo because her mother was a painter and she rejected the sterile geometric logos of most high tech companies.

After the logo was compared in the media to the ring a coffee mug leaves on paper, a "Dilbert" comic strip showed Dogbert as an overpaid consultant designing a new company logo; he takes a piece of paper that his coffee cup was sitting on and calls it the "Brown Ring of Quality". A telecommunication commentator referred to the logo as "a big red zero" and predicted financial losses.

One of the primary reasons AT&T Corporation chose to spin off its equipment manufacturing business was to permit it to profit from sales to competing telecommunications providers; these customers had previously shown reluctance to purchase from a direct competitor. Bell Labs brought prestige to the new company, as well as the revenue from thousands of patents.

At the time of its spinoff, Lucent was placed under the leadership of Henry Schacht, who was brought in to oversee its transition from an arm of AT&T into an independent corporation. Richard McGinn, who was serving as President and COO, succeeded Schacht as CEO in 1997 while Schacht remained chairman of the board. Lucent became a "darling" stock of the investment community in the late 1990s, and its split-adjusted spinoff price of $7.56/share rose to a high of $84. Its market capitalization reached a high of $258 billion, and it was at the time the most widely held company with 5.3 million shareholders.

In 1997, Lucent acquired Milpitas-based voicemail market leader Octel Communications Corporation for $2.1 billion, a move which immediately rendered the Business Systems Group profitable. By 1999 Lucent stock continued to soar and in that year Lucent acquired Ascend Communications, an Alameda, California–based manufacturer of communications equipment for US$24 billion. Lucent held discussions to acquire Juniper Networks but decided instead to build its own routers.

In 1997, Lucent acquired Livingston Enterprises Inc. for $650 million in stock. Livingston was known most for the creation of the RADIUS protocol and their PortMaster product that was used widely by dial-up internet service providers.

In 1995, Carly Fiorina led corporate operations. In that capacity, she reported to Lucent chief executive Henry B. Schacht. She played a key role in planning and implementing the 1996 initial public offering of a successful stock and company launch strategy. Under her guidance, the spin-off raised 3 billion.

Later in 1996, Fiorina was appointed president of Lucent's consumer products sector, reporting to president and chief operating officer Rich McGinn. In 1997, she was named group president for Lucent's 19 billion global service-provider business, overseeing marketing and sales for the company's largest customer segment. That year, Fiorina chaired a 2.5 billion joint venture between Lucent's consumer communications and Royal Philips Electronics, under the name Philips Consumer Communications (PCC). The focus of the venture was to bring both companies to the top three in technology, distribution, and brand recognition.

Ultimately, the project struggled and dissolved a year later after it garnered only 2% market share in mobile phones. Losses were at $500 million on sales of $2.5 billion. As a result of the failed joint venture, Philips announced the closure of one-quarter of the company's 230 factories worldwide, and Lucent closed down its wireless handset portion of the venture. Analysts suggested that the joint venture's failure was due to a combination of technology and management problems. Upon the end of the joint venture, PCC sent 5,000 employees back to Philips, many of which were laid off, and 8,400 employees back to Lucent.

Under Fiorina, the company added 22,000 jobs and revenues seemed to grow from 19 billion to 38 billion. However, the real cause of Lucent spurring sales under Fiorina was by lending money to their own customers. According to "Fortune" magazine, "In a neat bit of accounting magic, money from the loans began to appear on Lucent’s income statement as new revenue while the dicey debt got stashed on its balance sheet as an allegedly solid asset". Lucent's stock price grew 10-fold.

At the start of 2000, Lucent's "private bubble" burst, while competitors like Nortel Networks and Alcatel were still going strong; it would be many months before the rest of the telecom industry bubble collapsed. Previously Lucent had 14 straight quarters where it exceeded analysts' expectations, leading to high expectations for the 15th quarter, ending Dec. 31, 1999. On January 6, 2000, Lucent made the first of a string of announcements that it had missed its quarterly estimates, as CEO Rich McGinn grimly announced that Lucent had run into special problems during that quarter—including disruptions in its optical networking business—and reported flat revenues and a big drop in profits. That caused the stock to plunge by 28%, shaving $64 billion off of the company's market capitalization. When it was later revealed that it had used dubious accounting and sales practices to generate some of its earlier quarterly numbers, Lucent fell from grace. It was said that "Rich McGinn couldn't accept Lucent's fall from its early triumphs." He described himself once as imposing "audacious" goals on his managers, believing the stretch for performance would produce dream results. Henry Schacht defended the corporate culture that McGinn created and also noted that McGinn did not sell any Lucent shares while serving as CEO. In November 2000, the company disclosed to the Securities and Exchange Commission that it had a $125 million accounting error for the third quarter of 2000, and by December 2000 it reported it had overstated its revenues for its latest quarter by nearly $700 million. Although no wrongdoing was found on his part, McGinn was forced to resign as CEO and he was replaced by Schacht on an interim basis. Subsequently, its CFO, Deborah Hopkins, left the company in May 2001 with Lucent's stock at $9.06 whereas at the time she was hired it was at $46.82.

In 2001 there were merger discussions between Lucent and Alcatel, which would have seen Lucent acquired at its current market price without a premium; the newly combined entity would have been headquartered in Murray Hill. However, these negotiations collapsed when Schacht insisted on an equal 7-7 split of the merged company's board of directors, while Alcatel chief executive officer Serge Tchuruk wanted 8 of the 14 board seats for Alcatel due to it being in a stronger position. The failure of the merger talks caused Lucent's share price to collapse, and by October 2002 the stock price had bottomed at 55 cents per share.

Patricia Russo, formerly Lucent's EVP of the Corporate Office who then left for Eastman Kodak to serve as COO, was named permanent Chairman and CEO of Lucent in 2002, succeeding Schacht who remained on the Board of Directors.

In April 2000, Lucent sold its Consumer Products unit to VTech and Consumer Phone Services. In October 2000, Lucent spun off its Business Systems arm into Avaya, Inc., and in June 2002, it spun off its microelectronics division into Agere Systems. The spinoffs of enterprise networking and wireless, the industry's key growth businesses from 2003 onward, meant that Lucent no longer had the capacity to serve this market.

Lucent was reduced to 30,500 employees, down from about 165,000 employees at its zenith. The layoffs of so many experienced employees meant that the company was in a weakened position and unable to reestablish itself when the market recovered in 2003. By early 2003, Lucent's market value was $15.6 billion (which includes $6.8 billion of current value for two companies that Lucent had recently spun off, Avaya and Agere Systems), making the shares worth around $2.13, a far cry from its dotcom bubble peak of around $84, when Lucent was worth $258 billion.

Lucent continued to be active in the areas of telephone switching, optical, data and wireless networking.

On April 2, 2006, Lucent announced a merger agreement with Alcatel, which was 1.5 times the size of Lucent. Serge Tchuruk became non-executive chairman, and Russo served as CEO of the newly merged company, Alcatel-Lucent, until they were both forced to resign at the end of 2008. The merger failed to produce the expected synergies, and there were significant write-downs of Lucent's assets that Alcatel purchased.

Lucent was divided into several core groups:

The Murray Hill anechoic chamber, built in 1940, is the world's oldest wedge-based anechoic chamber. The interior room measures approximately high by wide by deep. The exterior concrete and brick walls are about thick to keep outside noise from entering the chamber. The chamber absorbs over 99.995% of the incident acoustic energy above 200 Hz. At one time the Murray Hill chamber was cited in the Guinness Book of World Records as the world's quietest room. It is possible to hear the sounds of skeletal joints and heart beats very prominently.

The Murray Hill facility was the global headquarters for Lucent Technologies. The Murray Hill facility also has the largest copper-roof in the world. When Lucent Technologies was experiencing financial troubles in 2000 and 2001, one out of every three fluorescent lights was turned off in the facility. The same was done in the Naperville, Illinois, and Allentown, Pennsylvania, facilities for a while. The facility had a cricket field and featured a nearby station from which enthusiasts could control RC airplanes and helicopters.



</doc>
<doc id="18158" url="https://en.wikipedia.org/wiki?curid=18158" title="Lupercalia">
Lupercalia

Lupercalia was an ancient, possibly pre-Roman pastoral annual festival, observed in the city of Rome from the 13th to the 15th of February to avert evil spirits and purify the city, releasing health and fertility. Lupercalia was also called "dies Februatus", after the instruments of purification called "februa", which gave February "(Februarius)" its name.

The festival was later known as Februa ("Purifications" or "Purgings") after the ' which was used on the day. It was also known as ' and gave its name to Juno Februalis, Februlis, or Februata in her role as its patron deity; to a god called Februus, and to February ('), the month during which it occurred. Ovid connects ' to an Etruscan word for "purging". Some sources connect the Latin word for fever ("") with the same idea of purification or purging, due to the sweating commonly seen in association with fevers.

The name "Lupercalia" was believed in antiquity to evince some connection with the Ancient Greek festival of the Arcadian Lykaia, a wolf festival (, "lýkos"; ), and the worship of "Lycaean Pan", assumed to be a Greek equivalent to Faunus, as instituted by Evander. Justin describes a cult image of "the Lycaean god, whom the Greeks call Pan and the Romans Lupercus", as nude, save for a goatskin girdle. It stood in the Lupercal, the cave where tradition held that Romulus and Remus were suckled by the she-wolf (Lupa). The cave lay at the foot of the Palatine Hill, on which Romulus was thought to have founded Rome.

The rites were confined to the Lupercal cave, the Palatine Hill, and the Forum, all of which were central locations in Rome's foundation myth. Near the cave stood a sanctuary of Rumina, goddess of breastfeeding; and the wild fig-tree ("Ficus Ruminalis") to which Romulus and Remus were brought by the divine intervention of the river-god Tiberinus; some Roman sources name the wild fig tree "caprificus", literally "goat fig". Like the cultivated fig, its fruit is pendulous, and the tree exudes a milky sap if cut, which makes it a good candidate for a cult of breastfeeding.

The Lupercalia had its own priesthood, the "Luperci" ("brothers of the wolf"), whose institution and rites were attributed either to the Arcadian culture-hero Evander, or to Romulus and Remus, erstwhile shepherds who had each established a group of followers. The "Luperci" were young men ("iuvenes"), usually between the ages of 20 and 40. They formed two religious "collegia" (associations) based on ancestry; the "Quinctiliani" (named after the "gens" Quinctia) and the "Fabiani" (named after the "gens" Fabia). Each college was headed by a "magister". In 44 BC, a third college, the "Juliani", was instituted in honor of Julius Caesar; its first "magister" was Mark Antony. The college of "Juliani" disbanded or lapsed following Caesar's assassination, and was not re-established in the reforms of his successor, Augustus. In the Imperial era, membership of the two traditional "collegia" was opened to "iuvenes" of equestrian status.

At the Lupercal altar, a male goat (or goats) and a dog were sacrificed by one or another of the "Luperci", under the supervision of the Flamen dialis, Jupiter's chief priest. An offering was also made of salted mealcakes, prepared by the Vestal Virgins. After the blood sacrifice, two "Luperci" approached the altar. Their foreheads were anointed with blood from the sacrificial knife, then wiped clean with wool soaked in milk, after which they were expected to smile and/or laugh.

The sacrificial feast followed, after which the Luperci cut thongs (known as "") from the flayed skin of the animal, and ran with these, naked or near-naked, along the old Palatine boundary, in an anticlockwise direction around the hill. In Plutarch's description of the Lupercalia, written during the early Empire,
...many of the noble youths and of the magistrates run up and down through the city naked, for sport and laughter striking those they meet with shaggy thongs. And many women of rank also purposely get in their way, and like children at school present their hands to be struck, believing that the pregnant will thus be helped in delivery, and the barren to pregnancy.
The "Luperci" completed their circuit of the Palatine, then returned to the "Lupercal" cave. 
The Februa was of ancient and possibly Sabine origin. After February was added to the Roman calendar, Februa occurred on its fifteenth day (""). Of its various rituals, the most important came to be those of the Lupercalia. The Romans themselves attributed the instigation of the Lupercalia to Evander, a culture hero from Arcadia who was credited with bringing the Olympic pantheon, Greek laws and alphabet to Italy, where he founded the city of Pallantium on the future site of Rome, 60 years before the Trojan War.

Lupercalia was celebrated in parts of Italy and Gaul; "Luperci" are attested by inscriptions at Velitrae, Praeneste, Nemausus (modern Nîmes) and elsewhere. The ancient cult of the Hirpi Sorani ("wolves of Soranus", from Sabine "hirpus" "wolf"), who practiced at Mt. Soracte, north of Rome, had elements in common with the Roman Lupercalia.

Descriptions of the Lupercalia festival of 44 BC attest to its continuity; Julius Caesar used it as the backdrop for his (possibly staged) public refusal of a golden crown offered to him by Mark Antony. The Lupercal cave was restored or rebuilt by Augustus, and has been speculated to be identical with a grotto discovered in 2007, below the remains of Augustus' residence; according to scholarly consensus, the grotto is a nymphaeum, not the Lupercal. The Lupercalia festival is marked on a calendar of 354 alongside traditional and Christian festivals. Despite the banning in 391 of all non-Christian cults and festivals, the Lupercalia was celebrated by the nominally Christian populace on a regular basis into the reign of the emperor Anastasius. Pope Gelasius I (494–96) claimed that only the "vile rabble" were involved in the festival and sought its forceful abolition; the Senate protested that the Lupercalia was essential to Rome's safety and well-being. This prompted Gelasius' scornful suggestion that "If you assert that this rite has salutary force, celebrate it yourselves in the ancestral fashion; run nude yourselves that you may properly carry out the mockery".

There is no contemporary evidence to support the popular notions that Gelasius abolished the Lupercalia, or that he, or any other prelate, replaced it with the Feast of the Purification of the Blessed Virgin Mary. A literary association between the Lupercalia and the romantic elements of Saint Valentine's Day dates back to Chaucer and poetic traditions of courtly love.

Horace's Ode III, 18 alludes to the Lupercalia. The festival or its associated rituals gave its name to the Roman month of February ("") and thence to the modern month. The Roman god Februus personified both the month and purification, but seems to postdate both.

William Shakespeare's play "Julius Caesar" begins during the Lupercalia. Mark Antony is instructed by Caesar to strike his wife Calpurnia, in the hope that she will be able to conceive.

Research published in 2019 suggests that the word Leprechaun derives from "Lupercus".

In the second season of the Netflix series "Chilling Adventures of Sabrina" the witches celebrate Lupercalia.





</doc>
<doc id="18162" url="https://en.wikipedia.org/wiki?curid=18162" title="Lists of atheists">
Lists of atheists

Atheism is, in a broad sense, the lack of belief in the existence of deities. In a narrower sense, atheism is simply the absence of belief that any deities exist. This is a compilation of the various lists of atheists with articles in Wikipedia. Living persons in these lists are people whose atheism is relevant to their notable activities or public life, and who have publicly identified themselves as atheists.






</doc>
<doc id="18163" url="https://en.wikipedia.org/wiki?curid=18163" title="List of Buddhists">
List of Buddhists

This is a list of notable Buddhists, encompassing all the major branches of the religion (i.e. in Buddhism), and including interdenominational and eclectic Buddhist practitioners. This list includes both formal teachers of Buddhism, and people notable in other areas who are publicly Buddhist or who have espoused Buddhism.

Individuals are grouped by nationality, except in cases where their influence was felt elsewhere. Gautama Buddha and his immediate disciples ('Buddhists') are listed separately from later Indian Buddhist thinkers, teachers and contemplatives.


Clergy

Laity












For Theravada, Bhikkhu(male) and Bhikkhuni(female) mean monk in Pali (Theravada use Pali language for studying Tripitaka)



American

Chinese

European

Japanese

Korean

Malaysian

Taiwanese

Vietnamese














</doc>
<doc id="18166" url="https://en.wikipedia.org/wiki?curid=18166" title="List of agnostics">
List of agnostics

Listed here are persons who have identified themselves as theologically agnostic. Also included are individuals who have expressed the view that the veracity of a god's existence is unknown or inherently unknowable.












</doc>
<doc id="18167" url="https://en.wikipedia.org/wiki?curid=18167" title="Linked list">
Linked list

In computer science, a linked list is a linear collection of data elements whose order is not given by their physical placement in memory. Instead, each element points to the next. It is a data structure consisting of a collection of nodes which together represent a sequence. In its most basic form, each node contains: data, and a reference (in other words, a "link") to the next node in the sequence. This structure allows for efficient insertion or removal of elements from any position in the sequence during iteration. More complex variants add additional links, allowing more efficient insertion or removal of nodes at arbitrary positions. A drawback of linked lists is that access time is linear (and difficult to pipeline). Faster access, such as random access, is not feasible. Arrays have better cache locality compared to linked lists.

Linked lists are among the simplest and most common data structures. They can be used to implement several other common abstract data types, including lists, stacks, queues, associative arrays, and S-expressions, though it is not uncommon to implement those data structures directly without using a linked list as the basis.

The principal benefit of a linked list over a conventional array is that the list elements can be easily inserted or removed without reallocation or reorganization of the entire structure because the data items need not be stored contiguously in memory or on disk, while restructuring an array at run-time is a much more expensive operation. Linked lists allow insertion and removal of nodes at any point in the list, and allow doing so with a constant number of operations by keeping the link previous to the link being added or removed in memory during list traversal.

On the other hand, since simple linked lists by themselves do not allow random access to the data or any form of efficient indexing, many basic operations—such as obtaining the last node of the list, finding a node that contains a given datum, or locating the place where a new node should be inserted—may require iterating through most or all of the list elements. The advantages and disadvantages of using linked lists are given below. Linked list are dynamic, so the length of list can increase or decrease as necessary. Each node does not necessarily follow the previous one physically in the memory.


Linked lists were developed in 1955–1956 by Allen Newell, Cliff Shaw and Herbert A. Simon at RAND Corporation as the primary data structure for their Information Processing Language. IPL was used by the authors to develop several early artificial intelligence programs, including the Logic Theory Machine, the General Problem Solver, and a computer chess program. Reports on their work appeared in IRE Transactions on Information Theory in 1956, and several conference proceedings from 1957 to 1959, including Proceedings of the Western Joint Computer Conference in 1957 and 1958, and Information Processing (Proceedings of the first UNESCO International Conference on Information Processing) in 1959. The now-classic diagram consisting of blocks representing list nodes with arrows pointing to successive list nodes appears in "Programming the Logic Theory Machine" by Newell and Shaw in Proc. WJCC, February 1957. Newell and Simon were recognized with the ACM Turing Award in 1975 for having "made basic contributions to artificial intelligence, the psychology of human cognition, and list processing".
The problem of machine translation for natural language processing led Victor Yngve at Massachusetts Institute of Technology (MIT) to use linked lists as data structures in his COMIT programming language for computer research in the field of linguistics. A report on this language entitled "A programming language for mechanical translation" appeared in Mechanical Translation in 1958.

LISP, standing for list processor, was created by John McCarthy in 1958 while he was at MIT and in 1960 he published its design in a paper in the Communications of the ACM, entitled "Recursive Functions of Symbolic Expressions and Their Computation by Machine, Part I". One of LISP's major data structures is the linked list.

By the early 1960s, the utility of both linked lists and languages which use these structures as their primary data representation was well established. Bert Green of the MIT Lincoln Laboratory published a review article entitled "Computer languages for symbol manipulation" in IRE Transactions on Human Factors in Electronics in March 1961 which summarized the advantages of the linked list approach. A later review article, "A Comparison of list-processing computer languages" by Bobrow and Raphael, appeared in Communications of the ACM in April 1964.

Several operating systems developed by Technical Systems Consultants (originally of West Lafayette Indiana, and later of Chapel Hill, North Carolina) used singly linked lists as file structures. A directory entry pointed to the first sector of a file, and succeeding portions of the file were located by traversing pointers. Systems using this technique included Flex (for the Motorola 6800 CPU), mini-Flex (same CPU), and Flex9 (for the Motorola 6809 CPU). A variant developed by TSC for and marketed by Smoke Signal Broadcasting in California, used doubly linked lists in the same manner.

The TSS/360 operating system, developed by IBM for the System 360/370 machines, used a double linked list for their file system catalog. The directory structure was similar to Unix, where a directory could contain files and other directories and extend to any depth.

Each record of a linked list is often called an 'element' or 'node'.

The field of each node that contains the address of the next node is usually called the 'next link' or 'next pointer'. The remaining fields are known as the 'data', 'information', 'value', 'cargo', or 'payload' fields.

The 'head' of a list is its first node. The 'tail' of a list may refer either to the rest of the list after the head, or to the last node in the list. In Lisp and some derived languages, the next node may be called the 'cdr' (pronounced "could-er") of the list, while the payload of the head node may be called the 'car'.

Singly linked lists contain nodes which have a data field as well as 'next' field, which points to the next node in line of nodes. Operations that can be performed on singly linked lists include insertion, deletion and traversal.

The following code demonstrates how to add a new node with data "value" to the end of a singly linked list:
node addNode(node head, int value) {

In a 'doubly linked list', each node contains, besides the next-node link, a second link field pointing to the 'previous' node in the sequence. The two links may be called 'forward('s') and 'backwards', or 'next' and 'prev'('previous').

A technique known as XOR-linking allows a doubly linked list to be implemented using a single link field in each node. However, this technique requires the ability to do bit operations on addresses, and therefore may not be available in some high-level languages.
Many modern operating systems use doubly linked lists to maintain references to active processes, threads, and other dynamic objects. A common strategy for rootkits to evade detection is to unlink themselves from these lists.

In a 'multiply linked list', each node contains two or more link fields, each field being used to connect the same set of data records in a different order of same set(e.g., by name, by department, by date of birth, etc.). While doubly linked lists can be seen as special cases of multiply linked list, the fact that the two and more orders are opposite to each other leads to simpler and more efficient algorithms, so they are usually treated as a separate case.

In the last node of a list, the link field often contains a null reference, a special value is used to indicate the lack of further nodes. A less common convention is to make it point to the first node of the list; in that case, the list is said to be 'circular' or 'circularly linked'; otherwise, it is said to be 'open' or 'linear'. It is a list where the last pointer points to the first node.

In the case of a circular doubly linked list, the first node also points to the last node of the list.

In some implementations an extra 'sentinel' or 'dummy' node may be added before the first data record or after the last one. This convention simplifies and accelerates some list-handling algorithms, by ensuring that all links can be safely dereferenced and that every list (even one that contains no data elements) always has a "first" and "last" node.

An empty list is a list that contains no data records. This is usually the same as saying that it has zero nodes. If sentinel nodes are being used, the list is usually said to be empty when it has only sentinel nodes.

The link fields need not be physically part of the nodes. If the data records are stored in an array and referenced by their indices, the link field may be stored in a separate array with the same indices as the data records.

Since a reference to the first node gives access to the whole list, that reference is often called the 'address', 'pointer', or 'handle' of the list. Algorithms that manipulate linked lists usually get such handles to the input lists and return the handles to the resulting lists. In fact, in the context of such algorithms, the word "list" often means "list handle". In some situations, however, it may be convenient to refer to a list by a handle that consists of two links, pointing to its first and last nodes.

The alternatives listed above may be arbitrarily combined in almost every way, so one may have circular doubly linked lists without sentinels, circular singly linked lists with sentinels, etc.

As with most choices in computer programming and design, no method is well suited to all circumstances. A linked list data structure might work well in one case, but cause problems in another. This is a list of some of the common tradeoffs involving linked list structures.

A "dynamic array" is a data structure that allocates all elements contiguously in memory, and keeps a count of the current number of elements. If the space reserved for the dynamic array is exceeded, it is reallocated and (possibly) copied, which is an expensive operation.

Linked lists have several advantages over dynamic arrays. Insertion or deletion of an element at a specific point of a list, assuming that we have indexed a pointer to the node (before the one to be removed, or before the insertion point) already, is a constant-time operation (otherwise without this reference it is O(n)), whereas insertion in a dynamic array at random locations will require moving half of the elements on average, and all the elements in the worst case. While one can "delete" an element from an array in constant time by somehow marking its slot as "vacant", this causes fragmentation that impedes the performance of iteration.

Moreover, arbitrarily many elements may be inserted into a linked list, limited only by the total memory available; while a dynamic array will eventually fill up its underlying array data structure and will have to reallocate—an expensive operation, one that may not even be possible if memory is fragmented, although the cost of reallocation can be averaged over insertions, and the cost of an insertion due to reallocation would still be amortized O(1). This helps with appending elements at the array's end, but inserting into (or removing from) middle positions still carries prohibitive costs due to data moving to maintain contiguity. An array from which many elements are removed may also have to be resized in order to avoid wasting too much space.

On the other hand, dynamic arrays (as well as fixed-size array data structures) allow constant-time random access, while linked lists allow only sequential access to elements. Singly linked lists, in fact, can be easily traversed in only one direction. This makes linked lists unsuitable for applications where it's useful to look up an element by its index quickly, such as heapsort. Sequential access on arrays and dynamic arrays is also faster than on linked lists on many machines, because they have optimal locality of reference and thus make good use of data caching.

Another disadvantage of linked lists is the extra storage needed for references, which often makes them impractical for lists of small data items such as characters or boolean values, because the storage overhead for the links may exceed by a factor of two or more the size of the data. In contrast, a dynamic array requires only the space for the data itself (and a very small amount of control data). It can also be slow, and with a naïve allocator, wasteful, to allocate memory separately for each new element, a problem generally solved using memory pools.

Some hybrid solutions try to combine the advantages of the two representations. Unrolled linked lists store several elements in each list node, increasing cache performance while decreasing memory overhead for references. CDR coding does both these as well, by replacing references with the actual data referenced, which extends off the end of the referencing record.

A good example that highlights the pros and cons of using dynamic arrays vs. linked lists is by implementing a program that resolves the Josephus problem. The Josephus problem is an election method that works by having a group of people stand in a circle. Starting at a predetermined person, one may count around the circle "n" times. Once the "n"th person is reached, one should remove them from the circle and have the members close the circle. The process is repeated until only one person is left. That person wins the election. This shows the strengths and weaknesses of a linked list vs. a dynamic array, because if the people are viewed as connected nodes in a circular linked list, then it shows how easily the linked list is able to delete nodes (as it only has to rearrange the links to the different nodes). However, the linked list will be poor at finding the next person to remove and will need to search through the list until it finds that person. A dynamic array, on the other hand, will be poor at deleting nodes (or elements) as it cannot remove one node without individually shifting all the elements up the list by one. However, it is exceptionally easy to find the "n"th person in the circle by directly referencing them by their position in the array.

The list ranking problem concerns the efficient conversion of a linked list representation into an array. Although trivial for a conventional computer, solving this problem by a parallel algorithm is complicated and has been the subject of much research.

A balanced tree has similar memory access patterns and space overhead to a linked list while permitting much more efficient indexing, taking O(log n) time instead of O(n) for a random access. However, insertion and deletion operations are more expensive due to the overhead of tree manipulations to maintain balance. Schemes exist for trees to automatically maintain themselves in a balanced state: AVL trees or red-black trees.

While doubly linked and circular lists have advantages over singly linked linear lists, linear lists offer some advantages that make them preferable in some situations.

A singly linked linear list is a recursive data structure, because it contains a pointer to a "smaller" object of the same type. For that reason, many operations on singly linked linear lists (such as merging two lists, or enumerating the elements in reverse order) often have very simple recursive algorithms, much simpler than any solution using iterative commands. While those recursive solutions can be adapted for doubly linked and circularly linked lists, the procedures generally need extra arguments and more complicated base cases.

Linear singly linked lists also allow tail-sharing, the use of a common final portion of sub-list as the terminal portion of two different lists. In particular, if a new node is added at the beginning of a list, the former list remains available as the tail of the new one—a simple example of a persistent data structure. Again, this is not true with the other variants: a node may never belong to two different circular or doubly linked lists.

In particular, end-sentinel nodes can be shared among singly linked non-circular lists. The same end-sentinel node may be used for "every" such list. In Lisp, for example, every proper list ends with a link to a special node, denoted by codice_1 or codice_2, whose codice_3 and codice_4 links point to itself. Thus a Lisp procedure can safely take the codice_3 or codice_4 of "any" list.

The advantages of the fancy variants are often limited to the complexity of the algorithms, not in their efficiency. A circular list, in particular, can usually be emulated by a linear list together with two variables that point to the first and last nodes, at no extra cost.

Double-linked lists require more space per node (unless one uses XOR-linking), and their elementary operations are more expensive; but they are often easier to manipulate because they allow fast and easy sequential access to the list in both directions. In a doubly linked list, one can insert or delete a node in a constant number of operations given only that node's address. To do the same in a singly linked list, one must have the "address of the pointer" to that node, which is either the handle for the whole list (in case of the first node) or the link field in the "previous" node. Some algorithms require access in both directions. On the other hand, doubly linked lists do not allow tail-sharing and cannot be used as persistent data structures

A circularly linked list may be a natural option to represent arrays that are naturally circular, e.g. the corners of a polygon, a pool of buffers that are used and released in FIFO ("first in, first out") order, or a set of processes that should be time-shared in round-robin order. In these applications, a pointer to any node serves as a handle to the whole list.

With a circular list, a pointer to the last node gives easy access also to the first node, by following one link. Thus, in applications that require access to both ends of the list (e.g., in the implementation of a queue), a circular structure allows one to handle the structure by a single pointer, instead of two.

A circular list can be split into two circular lists, in constant time, by giving the addresses of the last node of each piece. The operation consists in swapping the contents of the link fields of those two nodes. Applying the same operation to any two nodes in two distinct lists joins the two list into one. This property greatly simplifies some algorithms and data structures, such as the quad-edge and face-edge.

The simplest representation for an empty "circular" list (when such a thing makes sense) is a null pointer, indicating that the list has no nodes. Without this choice, many algorithms have to test for this special case, and handle it separately. By contrast, the use of null to denote an empty "linear" list is more natural and often creates fewer special cases.

Sentinel node may simplify certain list operations, by ensuring that the next or previous nodes exist for every element, and that even empty lists have at least one node. One may also use a sentinel node at the end of the list, with an appropriate data field, to eliminate some end-of-list tests. For example, when scanning the list looking for a node with a given value "x", setting the sentinel's data field to "x" makes it unnecessary to test for end-of-list inside the loop. Another example is the merging two sorted lists: if their sentinels have data fields set to +∞, the choice of the next output node does not need special handling for empty lists.

However, sentinel nodes use up extra space (especially in applications that use many short lists), and they may complicate other operations (such as the creation of a new empty list).

However, if the circular list is used merely to simulate a linear list, one may avoid some of this complexity by adding a single sentinel node to every list, between the last and the first data nodes. With this convention, an empty list consists of the sentinel node alone, pointing to itself via the next-node link. The list handle should then be a pointer to the last data node, before the sentinel, if the list is not empty; or to the sentinel itself, if the list is empty.

The same trick can be used to simplify the handling of a doubly linked linear list, by turning it into a circular doubly linked list with a single sentinel node. However, in this case, the handle should be a single pointer to the dummy node itself.

When manipulating linked lists in-place, care must be taken to not use values that you have invalidated in previous assignments. This makes algorithms for inserting or deleting linked list nodes somewhat subtle. This section gives pseudocode for adding or removing nodes from singly, doubly, and circularly linked lists in-place. Throughout we will use "null" to refer to an end-of-list marker or sentinel, which may be implemented in a number of ways.

Our node data structure will have two fields. We also keep a variable "firstNode" which always points to the first node in the list, or is "null" for an empty list.

Traversal of a singly linked list is simple, beginning at the first node and following each "next" link until we come to the end:

The following code inserts a node after an existing node in a singly linked list. The diagram shows how it works. Inserting a node before an existing one cannot be done directly; instead, one must keep track of the previous node and insert a node after it.

Inserting at the beginning of the list requires a separate function. This requires updating "firstNode".

Similarly, we have functions for removing the node "after" a given node, and for removing a node from the beginning of the list. The diagram demonstrates the former. To find and remove a particular node, one must again keep track of the previous element.

Notice that codice_7 sets codice_8 to codice_9 when removing the last node in the list.

Since we can't iterate backwards, efficient codice_10 or codice_11 operations are not possible. Inserting to a list before a specific node requires traversing the list, which would have a worst case running time of O(n). 

Appending one linked list to another can be inefficient unless a reference to the tail is kept as part of the List structure, because we must traverse the entire first list in order to find the tail, and then append the second list to this. Thus, if two linearly linked lists are each of length formula_1, list appending has asymptotic time complexity of formula_2. In the Lisp family of languages, list appending is provided by the codice_12 procedure.

Many of the special cases of linked list operations can be eliminated by including a dummy element at the front of the list. This ensures that there are no special cases for the beginning of the list and renders both codice_13 and codice_7 unnecessary. In this case, the first useful data in the list will be found at codice_15.

In a circularly linked list, all nodes are linked in a continuous circle, without using "null." For lists with a front and a back (such as a queue), one stores a reference to the last node in the list. The "next" node after the last node is the first node. Elements can be added to the back of the list and removed from the front in constant time.

Circularly linked lists can be either singly or doubly linked.

Both types of circularly linked lists benefit from the ability to traverse the full list beginning at any given node. This often allows us to avoid storing "firstNode" and "lastNode", although if the list may be empty we need a special representation for the empty list, such as a "lastNode" variable which points to some node in the list or is "null" if it's empty; we use such a "lastNode" here. This representation significantly simplifies adding and removing nodes with a non-empty list, but empty lists are then a special case.

Assuming that "someNode" is some node in a non-empty circular singly linked list, this code iterates through that list starting with "someNode":

Notice that the test "while node ≠ someNode" must be at the end of the loop. If the test was moved to the beginning of the loop, the procedure would fail whenever the list had only one node.

This function inserts a node "newNode" into a circular linked list after a given node "node". If "node" is null, it assumes that the list is empty.

Suppose that "L" is a variable pointing to the last node of a circular linked list (or null if the list is empty). To append "newNode" to the "end" of the list, one may do

To insert "newNode" at the "beginning" of the list, one may do

Languages that do not support any type of reference can still create links by replacing pointers with array indices. The approach is to keep an array of records, where each record has integer fields indicating the index of the next (and possibly previous) node in the array. Not all nodes in the array need be used. If records are also not supported, parallel arrays can often be used instead.

As an example, consider the following linked list record that uses arrays instead of pointers:

A linked list can be built by creating an array of these structures, and an integer variable to store the index of the first element.

Links between elements are formed by placing the array index of the next (or previous) cell into the Next or Prev field within a given element. For example:

In the above example, codice_16 would be set to 2, the location of the first entry in the list. Notice that entry 3 and 5 through 7 are not part of the list. These cells are available for any additions to the list. By creating a codice_17 integer variable, a free list could be created to keep track of what cells are available. If all entries are in use, the size of the array would have to be increased or some elements would have to be deleted before new entries could be stored in the list.

The following code would traverse the list and display names and account balance:

When faced with a choice, the advantages of this approach include:

This approach has one main disadvantage, however: it creates and manages a private memory space for its nodes. This leads to the following issues:
For these reasons, this approach is mainly used for languages that do not support dynamic memory allocation. These disadvantages are also mitigated if the maximum size of the list is known at the time the array is created.

Many programming languages such as Lisp and Scheme have singly linked lists built in. In many functional languages, these lists are constructed from nodes, each called a "cons" or "cons cell". The cons has two fields: the "car", a reference to the data for that node, and the "cdr", a reference to the next node. Although cons cells can be used to build other data structures, this is their primary purpose.

In languages that support abstract data types or templates, linked list ADTs or templates are available for building linked lists. In other languages, linked lists are typically built using references together with records.

When constructing a linked list, one is faced with the choice of whether to store the data of the list directly in the linked list nodes, called "internal storage", or merely to store a reference to the data, called "external storage". Internal storage has the advantage of making access to the data more efficient, requiring less storage overall, having better locality of reference, and simplifying memory management for the list (its data is allocated and deallocated at the same time as the list nodes).

External storage, on the other hand, has the advantage of being more generic, in that the same data structure and machine code can be used for a linked list no matter what the size of the data is. It also makes it easy to place the same data in multiple linked lists. Although with internal storage the same data can be placed in multiple lists by including multiple "next" references in the node data structure, it would then be necessary to create separate routines to add or delete cells based on each field. It is possible to create additional linked lists of elements that use internal storage by using external storage, and having the cells of the additional linked lists store references to the nodes of the linked list containing the data.

In general, if a set of data structures needs to be included in linked lists, external storage is the best approach. If a set of data structures need to be included in only one linked list, then internal storage is slightly better, unless a generic linked list package using external storage is available. Likewise, if different sets of data that can be stored in the same data structure are to be included in a single linked list, then internal storage would be fine.

Another approach that can be used with some languages involves having different data structures, but all have the initial fields, including the "next" (and "prev" if double linked list) references in the same location. After defining separate structures for each type of data, a generic structure can be defined that contains the minimum amount of data shared by all the other structures and contained at the top (beginning) of the structures. Then generic routines can be created that use the minimal structure to perform linked list type operations, but separate routines can then handle the specific data. This approach is often used in message parsing routines, where several types of messages are received, but all start with the same set of fields, usually including a field for message type. The generic routines are used to add new messages to a queue when they are received, and remove them from the queue in order to process the message. The message type field is then used to call the correct routine to process the specific type of message.

Suppose you wanted to create a linked list of families and their members. Using internal storage, the structure might look like the following:

To print a complete list of families and their members using internal storage, we could write:

Using external storage, we would create the following structures:

To print a complete list of families and their members using external storage, we could write:

Notice that when using external storage, an extra step is needed to extract the record from the node and cast it into the proper data type. This is because both the list of families and the list of members within the family are stored in two linked lists using the same data structure ("node"), and this language does not have parametric types.

As long as the number of families that a member can belong to is known at compile time, internal storage works fine. If, however, a member needed to be included in an arbitrary number of families, with the specific number known only at run time, external storage would be necessary.

Finding a specific element in a linked list, even if it is sorted, normally requires O("n") time (linear search). This is one of the primary disadvantages of linked lists over other data structures. In addition to the variants discussed above, below are two simple ways to improve search time.

In an unordered list, one simple heuristic for decreasing average search time is the "move-to-front heuristic", which simply moves an element to the beginning of the list once it is found. This scheme, handy for creating simple caches, ensures that the most recently used items are also the quickest to find again.

Another common approach is to "index" a linked list using a more efficient external data structure. For example, one can build a red-black tree or hash table whose elements are references to the linked list nodes. Multiple such indexes can be built on a single list. The disadvantage is that these indexes may need to be updated each time a node is added or removed (or at least, before that index is used again).

A random access list is a list with support for fast random access to read or modify any element in the list. One possible implementation is a skew binary random access list using the skew binary number system, which involves a list of trees with special properties; this allows worst-case constant time head/cons operations, and worst-case logarithmic time random access to an element by index. Random access lists can be implemented as persistent data structures.

Random access lists can be viewed as immutable linked lists in that they likewise support the same O(1) head and tail operations.

A simple extension to random access lists is the min-list, which provides an additional operation that yields the minimum element in the entire list in constant time (without mutation complexities).

Both stacks and queues are often implemented using linked lists, and simply restrict the type of operations which are supported.

The skip list is a linked list augmented with layers of pointers for quickly jumping over large numbers of elements, and then descending to the next layer. This process continues down to the bottom layer, which is the actual list.

A binary tree can be seen as a type of linked list where the elements are themselves linked lists of the same nature. The result is that each node may include a reference to the first node of one or two other linked lists, which, together with their contents, form the subtrees below that node.

An unrolled linked list is a linked list in which each node contains an array of data values. This leads to improved cache performance, since more list elements are contiguous in memory, and reduced memory overhead, because less metadata needs to be stored for each element of the list.

A hash table may use linked lists to store the chains of items that hash to the same position in the hash table.

A heap shares some of the ordering properties of a linked list, but is almost always implemented using an array. Instead of references from node to node, the next and previous data indexes are calculated using the current data's index.

A self-organizing list rearranges its nodes based on some heuristic which reduces search times for data retrieval by keeping commonly accessed nodes at the head of the list.




</doc>
<doc id="18168" url="https://en.wikipedia.org/wiki?curid=18168" title="Logic gate">
Logic gate

A logic gate is an idealized or physical electronic device implementing a Boolean function, a logical operation performed on one or more binary inputs that produces a single binary output. Depending on the context, the term may refer to an ideal logic gate, one that has for instance zero rise time and unlimited fan-out, or it may refer to a non-ideal physical device (see Ideal and real op-amps for comparison).

Logic gates are primarily implemented using diodes or transistors acting as electronic switches, but can also be constructed using vacuum tubes, electromagnetic relays (relay logic), fluidic logic, pneumatic logic, optics, molecules, or even mechanical elements. With amplification, logic gates can be cascaded in the same way that Boolean functions can be composed, allowing the construction of a physical model of all of Boolean logic, and therefore, all of the algorithms and mathematics that can be described with Boolean logic.

Logic circuits include such devices as multiplexers, registers, arithmetic logic units (ALUs), and computer memory, all the way up through complete microprocessors, which may contain more than 100 million gates. In modern practice, most gates are made from MOSFETs (metal–oxide–semiconductor field-effect transistors).

Compound logic gates AND-OR-Invert (AOI) and OR-AND-Invert (OAI) are often employed in circuit design because their construction using MOSFETs is simpler and more efficient than the sum of the individual gates.

In reversible logic, Toffoli gates are used.

A functionally complete logic system may be composed of relays, valves (vacuum tubes), or transistors. The simplest family of logic gates uses bipolar transistors, and is called resistor–transistor logic (RTL). Unlike simple diode logic gates (which do not have a gain element), RTL gates can be cascaded indefinitely to produce more complex logic functions. RTL gates were used in early integrated circuits. For higher speed and better density, the resistors used in RTL were replaced by diodes resulting in diode–transistor logic (DTL). Transistor–transistor logic (TTL) then supplanted DTL. As integrated circuits became more complex, bipolar transistors were replaced with smaller field-effect transistors (MOSFETs); see PMOS and NMOS. To reduce power consumption still further, most contemporary chip implementations of digital systems now use CMOS logic. CMOS uses complementary (both n-channel and p-channel) MOSFET devices to achieve a high speed with low power dissipation.

For small-scale logic, designers now use prefabricated logic gates from families of devices such as the TTL 7400 series by Texas Instruments, the CMOS 4000 series by RCA, and their more recent descendants. Increasingly, these fixed-function logic gates are being replaced by programmable logic devices, which allow designers to pack many mixed logic gates into a single integrated circuit. The field-programmable nature of programmable logic devices such as FPGAs has reduced the 'hard' property of hardware; it is now possible to change the logic design of a hardware system by reprogramming some of its components, thus allowing the features or function of a hardware implementation of a logic system to be changed. Other types of logic gates include, but are not limited to:
Electronic logic gates differ significantly from their relay-and-switch equivalents. They are much faster, consume much less power, and are much smaller (all by a factor of a million or more in most cases). Also, there is a fundamental structural difference. The switch circuit creates a continuous metallic path for current to flow (in either direction) between its input and its output. The semiconductor logic gate, on the other hand, acts as a high-gain voltage amplifier, which sinks a tiny current at its input and produces a low-impedance voltage at its output. It is not possible for current to flow between the output and the input of a semiconductor logic gate.

Another important advantage of standardized integrated circuit logic families, such as the 7400 and 4000 families, is that they can be cascaded. This means that the output of one gate can be wired to the inputs of one or several other gates, and so on. Systems with varying degrees of complexity can be built without great concern of the designer for the internal workings of the gates, provided the limitations of each integrated circuit are considered.

The output of one gate can only drive a finite number of inputs to other gates, a number called the 'fan-out limit'. Also, there is always a delay, called the 'propagation delay', from a change in input of a gate to the corresponding change in its output. When gates are cascaded, the total propagation delay is approximately the sum of the individual delays, an effect which can become a problem in high-speed circuits. Additional delay can be caused when many inputs are connected to an output, due to the distributed capacitance of all the inputs and wiring and the finite amount of current that each output can provide.

The binary number system was refined by Gottfried Wilhelm Leibniz (published in 1705), influenced by the ancient "I Ching"s binary system. Leibniz established that using the binary system combined the principles of arithmetic and logic.

In an 1886 letter, Charles Sanders Peirce described how logical operations could be carried out by electrical switching circuits. Eventually, vacuum tubes replaced relays for logic operations. Lee De Forest's modification, in 1907, of the Fleming valve can be used as a logic gate. Ludwig Wittgenstein introduced a version of the 16-row truth table as proposition 5.101 of "Tractatus Logico-Philosophicus" (1921). Walther Bothe, inventor of the coincidence circuit, got part of the 1954 Nobel Prize in physics, for the first modern electronic AND gate in 1924. Konrad Zuse designed and built electromechanical logic gates for his computer Z1 (from 1935–38). 

From 1934 to 1936, NEC engineer Akira Nakashima introduced switching circuit theory in a series of papers showing that two-valued Boolean algebra, which he discovered independently, can describe the operation of switching circuits. His work was later cited by Claude E. Shannon, who elaborated on the use of Boolean algebra in the analysis and design of switching circuits in 1937. Using this property of electrical switches to implement logic is the fundamental concept that underlies all electronic digital computers. Switching circuit theory became the foundation of digital circuit design, as it became widely known in the electrical engineering community during and after World War II, with theoretical rigor superseding the "ad hoc" methods that had prevailed previously.

Metal-oxide-semiconductor (MOS) logic originates from the MOSFET (metal-oxide-semiconductor field-effect transistor), invented by Mohamed M. Atalla and Dawon Kahng at Bell Labs in 1959. They first demonstrated both PMOS logic and NMOS logic in 1960. Both types were later combined and adapted into complementary MOS (CMOS) logic by Chih-Tang Sah and Frank Wanlass at Fairchild Semiconductor in 1963.

Active research is taking place in molecular logic gates.

There are two sets of symbols for elementary logic gates in common use, both defined in ANSI/IEEE Std 91-1984 and its supplement ANSI/IEEE Std 91a-1991. The "distinctive shape" set, based on traditional schematics, is used for simple drawings and derives from United States Military Standard MIL-STD-806 of the 1950s and 1960s. It is sometimes unofficially described as "military", reflecting its origin. The "rectangular shape" set, based on ANSI Y32.14 and other early industry standards as later refined by IEEE and IEC, has rectangular outlines for all types of gate and allows representation of a much wider range of devices than is possible with the traditional symbols. The IEC standard, IEC 60617-12, has been adopted by other standards, such as EN 60617-12:1999 in Europe, BS EN 60617-12:1999 in the United Kingdom, and DIN EN 60617-12:1998 in Germany.

The mutual goal of IEEE Std 91-1984 and IEC 60617-12 was to provide a uniform method of describing the complex logic functions of digital circuits with schematic symbols. These functions were more complex than simple AND and OR gates. They could be medium scale circuits such as a 4-bit counter to a large scale circuit such as a microprocessor.

IEC 617-12 and its successor IEC 60617-12 do not explicitly show the "distinctive shape" symbols, but do not prohibit them. These are, however, shown in ANSI/IEEE 91 (and 91a) with this note: "The distinctive-shape symbol is, according to IEC Publication 617, Part 12, not preferred, but is not considered to be in contradiction to that standard." IEC 60617-12 correspondingly contains the note (Section 2.1) "Although non-preferred, the use of other symbols recognized by official national standards, that is distinctive shapes in place of symbols [list of basic gates], shall not be considered to be in contradiction with this standard. Usage of these other symbols in combination to form complex symbols (for example, use as embedded symbols) is discouraged." This compromise was reached between the respective IEEE and IEC working groups to permit the IEEE and IEC standards to be in mutual compliance with one another.

A third style of symbols, DIN 40700 (1976), was in use in Europe and is still widely used in European academia, see the logic table in .

In the 1980s, schematics were the predominant method to design both circuit boards and custom ICs known as gate arrays. Today custom ICs and the field-programmable gate array are typically designed with Hardware Description Languages (HDL) such as Verilog or VHDL.

Output comparison of 1-input logic gates.
Output comparison of 2-input logic gates.
Charles Sanders Peirce (during 1880–81) showed that NOR gates alone (or alternatively NAND gates alone) can be used to reproduce the functions of all the other logic gates, but his work on it was unpublished until 1933. The first published proof was by Henry M. Sheffer in 1913, so the NAND logical operation is sometimes called Sheffer stroke; the logical NOR is sometimes called "Peirce's arrow". Consequently, these gates are sometimes called "universal logic gates".

By use of De Morgan's laws, an "AND" function is identical to an "OR" function with negated inputs and outputs. Likewise, an "OR" function is identical to an "AND" function with negated inputs and outputs. A NAND gate is equivalent to an OR gate with negated inputs, and a NOR gate is equivalent to an AND gate with negated inputs.

This leads to an alternative set of symbols for basic gates that use the opposite core symbol ("AND" or "OR") but with the inputs and outputs negated. Use of these alternative symbols can make logic circuit diagrams much clearer and help to show accidental connection of an active high output to an active low input or vice versa. Any connection that has logic negations at both ends can be replaced by a negationless connection and a suitable change of gate or vice versa. Any connection that has a negation at one end and no negation at the other can be made easier to interpret by instead using the De Morgan equivalent symbol at either of the two ends. When negation or polarity indicators on both ends of a connection match, there is no logic negation in that path (effectively, bubbles "cancel"), making it easier to follow logic states from one symbol to the next. This is commonly seen in real logic diagrams – thus the reader must not get into the habit of associating the shapes exclusively as OR or AND shapes, but also take into account the bubbles at both inputs and outputs in order to determine the "true" logic function indicated.

A De Morgan symbol can show more clearly a gate's primary logical purpose and the polarity of its nodes that are considered in the "signaled" (active, on) state. Consider the simplified case where a two-input NAND gate is used to drive a motor when either of its inputs are brought low by a switch. The "signaled" state (motor on) occurs when either one OR the other switch is on. Unlike a regular NAND symbol, which suggests AND logic, the De Morgan version, a two negative-input OR gate, correctly shows that OR is of interest. The regular NAND symbol has a bubble at the output and none at the inputs (the opposite of the states that will turn the motor on), but the De Morgan symbol shows both inputs and output in the polarity that will drive the motor.

De Morgan's theorem is most commonly used to implement logic gates as combinations of only NAND gates, or as combinations of only NOR gates, for economic reasons.

Logic gates can also be used to store data. A storage element can be constructed by connecting several gates in a "latch" circuit. More complicated designs that use clock signals and that change only on a rising or falling edge of the clock are called edge-triggered "flip-flops". Formally, a flip-flop is called a bistable circuit, because it has two stable states which it can maintain indefinitely. The combination of multiple flip-flops in parallel, to store a multiple-bit value, is known as a register. When using any of these gate setups the overall system has memory; it is then called a sequential logic system since its output can be influenced by its previous state(s), i.e. by the "sequence" of input states. In contrast, the output from combinational logic is purely a combination of its present inputs, unaffected by the previous input and output states.

These logic circuits are known as computer memory. They vary in performance, based on factors of speed, complexity, and reliability of storage, and many different types of designs are used based on the application.

A three-state logic gate is a type of logic gate that can have three different outputs: high (H), low (L) and high-impedance (Z). The high-impedance state plays no role in the logic, which is strictly binary. These devices are used on buses of the CPU to allow multiple chips to send data. A group of three-states driving a line with a suitable control circuit is basically equivalent to a multiplexer, which may be physically distributed over separate devices or plug-in cards.

In electronics, a high output would mean the output is sourcing current from the positive power terminal (positive voltage). A low output would mean the output is sinking current to the negative power terminal (zero voltage). High impedance would mean that the output is effectively disconnected from the circuit.

Since the 1990s, most logic gates are made in CMOS (complementary metal oxide semiconductor) technology that uses both NMOS and PMOS transistors. Often millions of logic gates are packaged in a single integrated circuit.

There are several logic families with different characteristics (power consumption, speed, cost, size) such as: RDL (resistor–diode logic), RTL (resistor-transistor logic), DTL (diode–transistor logic), TTL (transistor–transistor logic) and CMOS. There are also sub-variants, e.g. standard CMOS logic vs. advanced types using still CMOS technology, but with some optimizations for avoiding loss of speed due to slower PMOS transistors.

Non-electronic implementations are varied, though few of them are used in practical applications. Many early electromechanical digital computers, such as the Harvard Mark I, were built from relay logic gates, using electro-mechanical relays. Logic gates can be made using pneumatic devices, such as the Sorteberg relay or mechanical logic gates, including on a molecular scale. Logic gates have been made out of DNA (see DNA nanotechnology) and used to create a computer called MAYA (see MAYA-II). Logic gates can be made from quantum mechanical effects (though quantum computing usually diverges from boolean design; see quantum logic gate). Photonic logic gates use nonlinear optical effects.

In principle any method that leads to a gate that is functionally complete (for example, either a NOR or a NAND gate) can be used to make any kind of digital logic circuit. Note that the use of 3-state logic for bus systems is not needed, and can be replaced by digital multiplexers, which can be built using only simple logic gates (such as NAND gates, NOR gates, or AND and OR gates).



</doc>
<doc id="18171" url="https://en.wikipedia.org/wiki?curid=18171" title="Linear search">
Linear search

In computer science, a linear search or sequential search is a method for finding an element within a list. It sequentially checks each element of the list until a match is found or the whole list has been searched.

A linear search runs in at worst linear time and makes at most comparisons, where is the length of the list. If each element is equally likely to be searched, then linear search has an average case of comparisons, but the average case can be affected if the search probabilities for each element vary. Linear search is rarely practical because other search algorithms and schemes, such as the binary search algorithm and hash tables, allow significantly faster searching for all but short lists.

A linear search sequentially checks each element of the list until it finds an element that matches the target value. If the algorithm reaches the end of the list, the search terminates unsuccessfully.

Given a list of elements with values or records , and target value , the following subroutine uses linear search to find the index of the target in .


The basic algorithm above makes two comparisons per iteration: one to check if equals "T", and the other to check if still points to a valid index of the list. By adding an extra record to the list (a sentinel value) that equals the target, the second comparison can be eliminated until the end of the search, making the algorithm faster. The search will reach the sentinel if the target is not contained within the list.


If the list is ordered such that , the search can establish the absence of the target more quickly by concluding the search once exceeds the target. This variation requires a sentinel that is greater than the target.

For a list with "n" items, the best case is when the value is equal to the first element of the list, in which case only one comparison is needed. The worst case is when the value is not in the list (or occurs only once at the end of the list), in which case "n" comparisons are needed.

If the value being sought occurs "k" times in the list, and all orderings of the list are equally likely, the expected number of comparisons is

For example, if the value being sought occurs once in the list, and all orderings of the list are equally likely, the expected number of comparisons is formula_2. However, if it is "known" that it occurs once, then at most "n" - 1 comparisons are needed, and the expected number of comparisons is 

(for example, for "n" = 2 this is 1, corresponding to a single if-then-else construct).

Either way, asymptotically the worst-case cost and the expected cost of linear search are both O("n").

The performance of linear search improves if the desired value is more likely to be near the beginning of the list than to its end. Therefore, if some values are much more likely to be searched than others, it is desirable to place them at the beginning of the list.

In particular, when the list items are arranged in order of decreasing probability, and these probabilities are geometrically distributed, the cost of linear search is only O(1). 

Linear search is usually very simple to implement, and is practical when the list has only a few elements, or when performing a single search in an un-ordered list.

When many values have to be searched in the same list, it often pays to pre-process the list in order to use a faster method. For example, one may sort the list and use binary search, or build an efficient search data structure from it. Should the content of the list change frequently, repeated re-organization may be more trouble than it is worth.

As a result, even though in theory other search algorithms may be faster than linear search (for instance binary search), in practice even on medium-sized arrays (around 100 items or less) it might be infeasible to use anything else. On larger arrays, it only makes sense to use other, faster search methods if the data is large enough, because the initial time to prepare (sort) the data is comparable to many linear searches.



</doc>
<doc id="18172" url="https://en.wikipedia.org/wiki?curid=18172" title="Land mine">
Land mine

A land mine is an explosive device concealed under or on the ground and designed to destroy or disable enemy targets, ranging from combatants to vehicles and tanks, as they pass over or near it. Such a device is typically detonated automatically by way of pressure when a target steps on it or drives over it, although other detonation mechanisms are also sometimes used. A land mine may cause damage by direct blast effect, by fragments that are thrown by the blast, or by both.

The use of land mines is controversial because of their potential as indiscriminate weapons. They can remain dangerous many years after a conflict has ended, harming civilians and the economy. 78 countries are contaminated with land mines and 15,000–20,000 people are killed every year while countless more are maimed. Approximately 80% of land mine casualties are civilian, with children as the most affected age group. Most killings occur in times of peace. With pressure from a number of campaign groups organised through the International Campaign to Ban Landmines, a global movement to prohibit their use led to the 1997 Convention on the Prohibition of the Use, Stockpiling, Production and Transfer of Anti-Personnel Mines and on their Destruction, also known as the "Ottawa Treaty". To date, 164 nations have signed the treaty, but these do not include China, the Russian Federation, and the United States.

In the Anti-Personnel Mine Ban Convention (also known as the Ottawa Treaty) and the Protocol on Mines, Booby-Traps and Other Devices, a "mine" is defined as a "munition designed to be placed under, on or near the ground or other surface area and to be exploded by the presence, proximity or contact of a person or vehicle." Similar in function is the "booby-trap", which the Protocol defines as "any device or material which is designed, constructed or adapted to kill or injure and which functions unexpectedly when a person disturbs or approaches an apparently harmless object or performs an apparently safe act." Such actions might include opening a door or picking up an object. Normally, mines are mass-produced and placed in groups, while booby traps are improvised and deployed one at a time. Also, booby traps can be non-explosive devices such as the punji stick. Overlapping both categories is the "improvised explosive device" (IED), which is "a device placed or fabricated in an improvised manner incorporating explosive material, destructive, lethal, noxious, incendiary, pyrotechnic materials or chemicals designed to destroy, disfigure, distract or harass. They may incorporate military stores, but are normally devised from non-military components." Some meet the definition of mines or booby traps and are also referred to as improvised, artisanal or locally manufactured mines. Other types of IED are remotely activated, so are not considered mines.

"Remotely delivered mines" are dropped from an aircraft or carried by devices such as artillery shells or rockets. Another type of remotely delivered explosive is the "cluster munition", a device that releases several submunitions ("bomblets") over a large area. If they do not explode, they are referred to as "unexploded ordnance" (UXO), along with unexploded artillery shells and other explosive devices that were not manually placed (that is, mines and booby traps are not UXOs). "Explosive remnants of war" (ERW) include UXO and "abandoned explosive ordnance" (AXO), devices that were never used and were left behind after a conflict.

Land mines are divided into two types: anti-tank mines, which are designed to disable tanks or other vehicles; and anti-personnel mines, which are designed to injure or kill people.

The history of land mines can be divided up into three main phases: In the ancient world, buried spikes provided many of the same functions as modern mines. Mines using gunpowder as the explosive were used from the Ming Dynasty to the American Civil War. Subsequently, high explosives were developed and used in land mines.

Some fortifications in the Roman Empire were surrounded by a series of hazards buried in the ground. These included "goads", foot-long pieces of wood with iron hooks on their ends; "lilia" (lilies, so named after their appearance), which were pits in which sharpened logs were arranged in a five-point pattern; and "abatis", fallen trees with sharpened branches facing outwards. As with modern land mines, they were "victim-operated", often concealed, and formed zones that were wide enough so that the enemy could not do much harm from outside, but were under fire (from spear throws, in this case) if they attempted to remove the obstacles. A notable use of these defenses was by Julius Caesar in the Battle of Alesia. His forces were besieging Vercingetorix, the leader of the Gauls, but Vercingetorix managed to send for reinforcements. To maintain the siege and defend against the reinforcements, Caesar formed a line of fortifications on both sides, and they played an important role in his victory. Lilies were also used by Scots against the English at the Battle of Bannockburn in 1314, and by Germans at the Battle of Passchendaele in the First World War.

A more easily deployed defense used by the Romans was the caltrop, a weapon about 12–15 cm across with four sharp spikes that are oriented so that when it is thrown on the ground, one spike always points up. As with modern antipersonnel mines, caltrops are designed to disable soldiers rather than kill them; they are also more effective in stopping mounted forces, who lack the advantage of being able to carefully scrutinize each step they take (though forcing foot-mounted forces to take the time to do so has benefits in and of itself). They were used by the Jin Dynasty in China at the Battle of Zhongdu to slow down the advance of Genghis Khan's army; Joan of Arc was wounded by one in the Siege of Orléans; in Japan they are known as tetsu-bishu and were used by ninjas from the fourteenth century onwards. Caltrops are still strung together and used as roadblocks in some modern conflicts.

Starting in the ninth century, the Chinese began centuries of experiments that resulted in gunpowder, an explosive mixture of sulfur, charcoal and potassium nitrate. Gunpowder was first used in battle in the thirteenth century. An "enormous bomb", credited to Lou Qianxia, was used in 1277 by the Chinese at the Battle of Zhongdu, although it probably had little effect. Gunpowder was difficult to use in mines because it is hygroscopic, easily absorbing water from the atmosphere, and when wet it is no longer explosive.

A 14th-century military treatise, the "Huolongjing" (Fire Dragon Manual), describes hollow cast iron cannonball shells filled with gunpowder. The wad of the mine was made of hard wood, carrying three different fuses in case of defective connection to the touch hole. These fuses were long and lit by hand, so they required carefully timed calculation of enemy movements.

The "Huolongjing" also describes land mines that were set off by enemy movement. A nine-foot length of bamboo was waterproofed by wrapping it in cowhide and covering it with oil. It was filled with compressed gunpowder and lead or iron pellets, sealed with wax and concealed in a trench. The triggering mechanism was not fully described until the early 17th century. When the enemy stepped onto hidden boards, they dislodge a pin, causing a weight to fall. A cord attached to the weight was wrapped around a drum attached to two steel wheels; when the weight fell, the wheels struck sparks against flint, igniting a set of fuses to multiple mines. A similar mechanism was used in the first wheellock musket in Europe as sketched by Leonardo da Vinci around 1500 AD.

Another victim-operated device was the "underground sky-soaring thunder", which lured bounty hunters with halberds, pikes, and lances planted in the ground. If they pulled on one of these weapons, the butt end disturbed a bowl underneath and a slow-burning incandescent material in the bowl ignited the fuses.

The fuse mechanisms for the above devices were cumbersome and unreliable. By the time Europeans arrived in China, landmines were largely forgotten.

At Augsburg in 1573, three centuries after the Chinese invented the first pressure-operated mine, a German military engineer by the name of Samuel Zimmermann invented the "Fladdermine" (flying mine). It consisted of a few pounds of black powder buried near the surface and was activated by stepping on it or tripping a wire that made a flintlock fire. Such mines were deployed on the slope in front of a fort. They were used during the Franco-Prussian War but were probably not very effective because a flintlock does not work for long when left untended.

Another device, the fougasse, was not victim-operated or mass-produced, but it was a precursor of modern fragmentation mines and the claymore mine. If consisted of a cone-shape hole with gunpowder at the bottom, covered either by rocks and scrap iron ("stone fougasse") or mortar shells, similar to large black powder hand grenades ("shell fougasse"). It was triggered by a flintlock connected to a tripwire on the surface. It could sometimes cause heavy casualties but required high maintenance due to the susceptibility of black powder to dampness. Consequently, it was mainly employed in the defenses of major fortifications, in which role it used in several European wars of the eighteenth century and the American Revolution.

One of the greatest limitations of early land mines was the unreliable fuses and their susceptibility to dampness. This changed with the invention of the safety fuse. Later, "Command initiation", the ability to detonate a charge immediately instead of waiting several minutes for a fuse to burn, became possible after electricity was developed. An electrical current sent down a wire could ignite the charge with a spark. The Russians claim first use of this technology in the Russo-Turkish War of 1828–1829, and with it the fougasse remained useful until it was superseded by the claymore in the 1960s.

Victim-activated mines were also unreliable because they relied on a flintlock to ignite the explosive. The percussion cap, developed in the early 19th century, made them much more reliable, and pressure-operated mines were deployed on land and sea in the Crimean War (1853–1856).

During the American Civil War, the Confederate brigadier general Gabriel J. Rains deployed thousands of "torpedoes" consisting of artillery shells with pressure caps, beginning with the Battle of Yorktown in 1862. As a Captain, Rains had earlier employed explosive booby traps during the Seminole Wars in Florida in 1840. Over the course of the war, mines only caused a few hundred casualties, but they had a large effect on morale and slowed down the advance of Union troops. Many on both sides considered the use of mines barbaric, and in response, generals in the Union Army forced Confederate prisoners to remove the mines.

Starting in the 19th century, more powerful explosives than gunpowder were developed, often for non-military reasons such as blasting train tunnels in the Alps and Rockies. Guncotton, up to four times more powerful than gunpowder, was invented by Christian Schonbein in 1846. It was dangerous to make until Frederick Augustus Abel developed a safe method in 1865. From the 1870s to the First World War, it was the standard explosive used by the British military.

In 1847, Ascanio Sobrero invented nitroglycerine to treat angina pectoris and it turned out to be a much more powerful explosive than guncotton. It was very dangerous to use until Alfred Nobel found a way to incorporate it in a solid mixture called dynamite and developed a safe detonator. Even then, dynamite needed to be stored carefully or it could form crystals that detonated easily. Thus, the military still preferred guncotton.

In 1863, the German chemical industry developed trinitrotoluene (TNT). This had the advantage that it was difficult to detonate, so it could withstand the shock of firing by artillery pieces. It was also advantageous for land mines for several reasons: it was not detonated by the shock of shells landing nearby; it was lightweight, unaffected by damp, and stable under a wide range of conditions; it could be melted to fill a container of any shape, and it was cheap to make. Thus, it became the standard explosive in mines after the First World War.

In their colonial conflicts, the British had fewer scruples about using mines than the Americans had in the Civil War. The British used mines in the Siege of Khartoum to hold off a much larger Sudanese Mahdist force for ten months. In the end, however, the town was taken and the British massacred. In the Boer War (1899–1903), they succeeded in holding Mafeking against Boer forces with the help of a mixture of real and fake minefields; and they laid mines alongside railroad tracks to discourage sabotage.

In the Russo-Japanese War of 1904–1905, both sides used land and sea mines, although the effect on land mainly affected morale. The naval mines were far more effective, destroying several battleships.

One sign of the increasing power of explosives used in land mines was that, by the First World War, they burst into about 1,000 high-velocity fragments; in the Franco-Prussian War (1870), it had only been 20 to 30 fragments. Nevertheless, antipersonnel mines were not a big factor in the war because machine guns, barbed wire and rapid-fire artillery were far more effective defenses. An exception was in Africa (now Tanzania and Namibia) where the warfare was much more mobile.

Towards the end of the war, the British started to use tanks to break through trench defenses. The Germans responded with anti-tank guns and mines. Improvised mines gave way to mass-produced mines consisting of wooden boxes filled with guncotton, and minefields were standardized to stop masses of tanks from advancing.

Between World Wars, the future Allies did little work on land mines, but the Germans developed a series of anti-tank mines, the "Tellermines" (plate mines). They also developed the "Schrapnell mine" (also known as the S-mine), the first bouncing mine. When triggered, this jumped up to about waist height and exploded, sending thousands of steel balls in all directions. Triggered by pressure, trip wires or electronics, it could harm soldiers within an area of about 2800 square feet.

Tens of millions of mines were laid in the Second World War, particularly in the deserts of North Africa and the steppes of Eastern Europe, where the open ground favored tanks. However, the first country to use them was Finland. They were defending against a much larger Soviet force with over 6,000 tanks, twenty times the number the Finns had; but they had terrain that was broken up by lakes and forests, so tank movement was restricted to roads and tracks. Their defensive line, the Mannerheim Line, integrated these natural defenses with mines, including simple fragmentation mines mounted on stakes.

While the Germans were advancing rapidly using "blitzkrieg" tactics, they did not make much use of mines. After 1942, however, they were on the defensive and became the most inventive and systematic users of mines. Their production shot up and they began inventing new types of mines as the Allies found ways to counter the existing ones. To make it more difficult to remove antitank mines, they surrounded them with S-mines and added anti-handling devices that would explode when soldiers tried to lift them. They also took a formal approach to laying mines and they kept detailed records of the locations of mines.

In the Second Battle of El Alamein in 1942, the Germans prepared for an Allied attack by laying about half a million mines in two fields running across the entire battlefield and five miles deep. Nicknamed the Devil's gardens, they were covered by 88 mm anti-tank guns and small-arms fire. The Allies prevailed, but at the cost of over half their tanks; 20 percent of the losses were caused by mines.

The Soviets learned the value of mines from their war with Finland, and when Germany invaded, they made heavy use of them, manufacturing over 67 million. At the Battle of Kursk, which put an end to the German advance, they laid over a million mines in eight belts with an overall depth of 35 kilometres.

Mines forced tanks to slow down and wait for soldiers to go ahead and remove the mines. The main method of breaching minefields involved prodding the dirt with a bayonet or stick at an angle of 30 degrees (to avoid putting pressure on the top of the mine and detonating it). Since all mines at the beginning of the war had metal casings, metal detectors could be used to speed up the locating of mines. A Polish officer, Józef Kosacki, developed a portable mine detector known as the Polish mine detector. To counter the detector, Germans developed mines with wooden casings, the Schu-mine 42 (antipersonnel) and Holzmine 42 (anti-tank). Effective, cheap and easy to make, the "schu" mine became the most common mine in the war. Mine casings were also made of glass, concrete and clay. The Russians developed a mine with a pressed-cardboard casing, the PMK40, and the Italians made an anti-tank mine out of bakelite. In 1944, the Germans created the Topfmine, an entirely non-metallic mine. They ensured that they could detect their own mines by covering them with radioactive sand, but the Allies did not find this out until after the war.

Several mechanical methods for clearing mines were tried. Heavy rollers attached to tanks or cargo trucks, but they did not last long and their weight made the tanks considerably slower. Tanks and bulldozers pushed ploughs that in turn pushed aside any mines to a depth of 30 cm. The Bangalore torpedo, a long thin tube filled with explosives, was invented in 1912 and used to clear barbed wire. Larger versions such as the Snake and the Conger were developed but were not very effective. One of the best options was the flail, which chains with weights on the end attached to rotating drums. The first version, the Scorpion, was attached to the Matilda tank and used in the Second Battle of El Alamein. The Crab, attached to the Sherman tank, was faster (2 kilometers per hour); it was used during D-Day and the aftermath.

During the Cold War, the members of NATO were concerned about massive armored attacks by the Soviet Union. They planned for a minefield stretching across the entire West German border, and developed new types of mine. The British designed an anti-tank mine, the Mark 7, to defeat rollers by detonating the second time it was pressed. It also had a 0.7-second delay so the tank would be directly over the mine. They also developed the first scatterable mine, the No. 7 ("Dingbat"). The Americans used the M6 antitank mine and tripwire-operated bouncing antipersonnel mines such as the M2 and M16.

In the Korean War, land mine use was dictated by the steep terrain, narrow valleys, forest cover and lack of developed roads. This made tanks less effective and more easily stopped by mines. However, mines laid near roads were often easy to spot. In response to this problem, the US developed the M24, a mine that was placed off to the side of the road. When triggered by a tripwire, it fired a rocket. However, the mine was not available until after the war.

The Chinese had a lot of success with massed infantry attacks. The extensive forest cover limited the range of machine guns, but anti-personnel mines were effective. However, mines were poorly recorded and marked, often becoming as much a hazard to allies as enemies. Tripwire-operated mines were not defended by pressure mines; the Chinese were often able to disable them and reuse them against UN forces.

Looking for more destructive mines, the Americans developed the Claymore, a directional fragmentation mine that hurls steel balls in a 60 degree arc at a lethal speed of 1,200 metres per second. They also developed a pressure-operated mine, the M14 ("toe-popper"). These, too, were ready too late for the Korean war.
In 1948, the British developed the No. 6 antipersonnel mine a minimum-metal mine with a narrow diameter, making it difficult to detect with metal detectors or prodding. Its three-pronged pressure piece inspired the nickname "Carrot Mine". However, it was unreliable in wet conditions. In the 1960s the Canadians developed a similar, but more reliable mine, the C3A1 ("Elsie") and the British army adopted it. The British also developed the L9 Bar Mine, a wide anti-tank mine with a rectangular shape, which covered more area, allowing a minefield to be laid four times as fast as previous mines. They also upgraded the Dingbat to the Ranger, a plastic mine that was fired from a truck-mounted discharger that could fire 72 mines at a time.

In the 1950s, the US Operation Doan Brook studied the feasibility of delivering mines by air. This led to three types of air-delivered mine. Wide Area Anti-Personnel Mines (WAAPMs) were small steel spheres that discharged tripwires when they hit the ground; each dispenser held 540 mines. The BLU-43 Dragontooth was small and had a flattened W shape to slow its descent, while the Gravel mine was larger. Both were packed by the thousand into bombs. All three were designed to inactivate after a period of time, but any that failed to activate presented a safety challenge. Over 37 million Gravel mines were produced between 1967 and 1968, and when they were dropped in places like Vietnam their locations were unmarked and unrecorded. A similar problem was presented by unexploded cluster munitions.

The next generation of scatterable mines arose in response to the increasing mobility of war. The Germans developed the Skorpion system, which scattered AT2 mines from a tracked vehicle. The Italians developed a helicopter delivery system that could rapidly switch between SB-33 anti-personnel mines and SB-81 anti-tank mines. The US developed a range of systems called the Family of Scatterable Mines (FASCAM) that could deliver mines by fast jet, artillery, helicopter and ground launcher.

In the First World War, the Germans developed a device, nicknamed the “Yperite Mine” by the British, that they left behind in abandoned trenches and bunkers. It was detonated by a delayed charge, spreading mustard gas (“Yperite”). In the Second World War they developed a modern chemical mine, the Spruh-Buchse 37 (Bounding Gas Mine 37), but never used it. The United States developed the M1 chemical mine , which used mustard gas, in 1939; and the M23 chemical mine, which used the VX nerve agent, in 1960. The Soviets developed the KhF, a "bounding chemical mine". The French had chemical mines and the Iraqis were believed to have them before the invasion of Kuwait. In 1997, the Chemical Weapons Convention came into force, prohibiting the use of chemical weapons and mandating their destruction. As of 30 April 2019, 97% of the declared stockpiles of chemical weapons were destroyed.

For a few decades during the Cold War, the U.S. developed atomic demolition munitions, often referred to as nuclear land mines. These were portable nuclear bombs that could be placed by hand, and could be detonated remotely or with a timer. Some of these were deployed in Europe. Governments in West Germany, Turkey and Greece wanted to have nuclear minefields as a defense against attack from the Warsaw Pact. However, such weapons were politically and tactically infeasible, and by 1989 the last of these munitions was retired. The British also had a project, codenamed Blue Peacock, to develop nuclear mines to be buried in Germany; the project was cancelled in 1958.

A conventional land mine consists of a casing that is mostly filled with the main charge. It has a firing mechanism such as a pressure plate; this triggers a detonator or igniter, which in turn sets off a booster charge. There may be additional firing mechanisms in anti-handling devices.

A land mine can be triggered by a number of things including pressure, movement, sound, magnetism and vibration. Anti-personnel mines commonly use the pressure of a person's foot as a trigger, but tripwires are also frequently employed. Most modern anti-vehicle mines use a magnetic trigger to enable it to detonate even if the tires or tracks did not touch it. Advanced mines are able to sense the difference between friendly and enemy types of vehicles by way of a built-in signature catalog. This will theoretically enable friendly forces to use the mined area while denying the enemy access.

Many mines combine the main trigger with a touch or tilt trigger to prevent enemy engineers from defusing it. Land mine designs tend to use as little metal as possible to make searching with a metal detector more difficult; land mines made mostly of plastic have the added advantage of being very inexpensive.

Some types of modern mines are designed to self-destruct, or chemically render themselves inert after a period of weeks or months to reduce the likelihood of civilian casualties at the conflict's end. These self-destruct mechanisms are not absolutely reliable, and most land mines laid historically are not equipped in this manner.

There is a common misperception that a landmine is armed by stepping on it and only triggered by stepping off, providing tension in movies. In fact the initial pressure trigger will detonate the mine, as they are designed to kill or maim, not to make someone stand very still until it can be disarmed.

Anti-handling devices detonate the mine if someone attempts to lift, shift or disarm it. The intention is to hinder deminers by discouraging any attempts to clear minefields. There is a degree of overlap between the function of a boobytrap and an anti-handling device insofar as some mines have optional fuze pockets into which standard pull or pressure-release boobytrap firing devices can be screwed. Alternatively, some mines may mimic a standard design, but actually be specifically intended to kill deminers, such as the MC-3 and PMN-3 variants of the PMN mine. Anti-handling devices can be found on both anti-personnel mines and anti-tank mines, either as an integral part of their design or as improvised add-ons. For this reason, the standard render safe procedure for mines is often to destroy them on site without attempting to lift them.

Anti-tank mines were created not long after the invention of the tank in the First World War. At first improvised, purpose-built designs were developed. Set off when a tank passes, they attack the tank at one of its weaker areas — the tracks. They are designed to immobilize or destroy vehicles and their occupants. In U.S. military terminology destroying the vehicles is referred to as a catastrophic kill while only disabling its movement is referred to as a mobility kill.

Anti-tank mines are typically larger than anti-personnel mines and require more pressure to detonate. The high trigger pressure, normally requiring prevents them from being set off by infantry or smaller vehicles of lesser importance. More modern anti-tank mines use shaped charges to focus and increase the armor penetration of the explosives.

Anti-personnel mines are designed primarily to kill or injure people, as opposed to vehicles. They are often designed to injure rather than kill in order to increase the logistical support (evacuation, medical) burden on the opposing force. Some types of anti-personnel mines can also damage the tracks or wheels of armored vehicles.

In the asymmetric warfare conflicts and civil wars of the 21st century, improvised explosives, known as IEDs, have partially supplanted conventional landmines as the source of injury to dismounted (pedestrian) soldiers and civilians. IEDs are used mainly by insurgents and terrorists against regular armed forces and civilians. The injuries from the anti-personnel IED were recently reported in BMJ Open to be far worse than with landmines resulting in multiple limb amputations and lower body mutilation.

Land mines were designed for two main uses: 

Land mines are currently used in large quantities mostly for this first purpose, thus their widespread use in the demilitarized zones (DMZs) of likely flashpoints such as Cyprus, Afghanistan and Korea. As of 2013, the only governments that still laid land mines were Myanmar in its internal conflict, and Syria in its civil war.

In military science, minefields are considered a defensive or harassing weapon, used to slow the enemy down, to help deny certain terrain to the enemy, to focus enemy movement into kill zones, or to reduce morale by randomly attacking material and personnel. In some engagements during World War II, anti-tank mines accounted for half of all vehicles disabled.

Since combat engineers with mine-clearing equipment can clear a path through a minefield relatively quickly, mines are usually considered effective only if covered by fire.

The extents of minefields are often marked with warning signs and cloth tape, to prevent friendly troops and non-combatants from entering them. Of course, sometimes terrain can be denied using dummy minefields. Most forces carefully record the location and disposition of their own minefields, because warning signs can be destroyed or removed, and minefields should eventually be cleared. Minefields may also have marked or unmarked safe routes to allow friendly movement through them.

Placing minefields without marking and recording them for later removal is considered a war crime under Protocol II of the Convention on Certain Conventional Weapons, which is itself an annex to the Geneva Conventions.

Artillery and aircraft scatterable mines allow minefields to be placed in front of moving formations of enemy units, including the reinforcement of minefields or other obstacles that have been breached by enemy engineers. They can also be used to cover the retreat of forces disengaging from the enemy, or for interdiction of supporting units to isolate front line units from resupply. In most cases these minefields consist of a combination of anti-tank and anti-personnel mines, with the anti-personnel mines making removal of the anti-tank mines more difficult. Mines of this type used by the United States are designed to self-destruct after a preset period of time, reducing the requirement for mine clearing to only those mines whose self-destruct system did not function. Some designs of these scatterable mines require an electrical charge (capacitor or battery) to detonate. After a certain period of time, either the charge dissipates, leaving them effectively inert or the circuitry is designed such that upon reaching a low level, the device is triggered, thus destroying the mine.

None of the conventional tactics and norms of mine warfare applies when they are employed in a guerrilla role:

Land mines were commonly deployed by insurgents during the South African Border War, leading directly to the development of the first dedicated mine-protected armoured vehicles in South Africa. Namibian insurgents used anti-tank mines to throw South African military convoys into disarray before attacking them. To discourage detection and removal efforts, they also laid anti-personnel mines directly parallel to the anti-tank mines. This initially resulted in heavy South African military and police casualties, as the vast distances of road network vulnerable to insurgent sappers every day made comprehensive detection and clearance efforts impractical. The only other viable option was the adoption of mine-protected vehicles which could remain mobile on the roads with little risk to their passengers even if a mine was detonated. South Africa is widely credited with inventing the v-hull, a vee-shaped hull for armoured vehicles which deflects mine blasts away from the passenger compartment.

During the ongoing Syrian Civil War, Iraqi Civil War (2014–2017) and Yemeni Civil War (2015–present) landmines have been used for both defensive and guerrilla purposes.

Minefields may be laid by several means. The preferred, but most labour-intensive, way is to have engineers bury the mines, since this will make the mines practically invisible and reduce the number of mines needed to deny the enemy an area. Mines can be laid by specialized mine-laying vehicles. Mine-scattering shells may be fired by artillery from a distance of several tens of kilometers.

Mines may be dropped from helicopters or airplanes, or ejected from cluster bombs or cruise missiles.

Anti-tank minefields can be scattered with anti-personnel mines to make clearing them manually more time-consuming; and anti-personnel minefields are scattered with anti-tank mines to prevent the use of armored vehicles to clear them quickly. Some anti-tank mine types are also able to be triggered by infantry, giving them a dual purpose even though their main and official intention is to work as anti-tank weapons.

Some minefields are specifically booby-trapped to make clearing them more dangerous. Mixed anti-personnel and anti-tank minefields, anti-personnel mines "under" anti-tank mines, and fuses separated from mines have all been used for this purpose. Often, single mines are backed by a secondary device, designed to kill or maim personnel tasked with clearing the mine.

Multiple anti-tank mines have been buried in stacks of two or three with the bottom mine fuzed, in order to multiply the penetrating power. Since the mines are buried, the ground directs the energy of the blast in a single direction—through the bottom of the target vehicle or on the track.

Another specific use is to mine an aircraft runway immediately after it has been bombed in order to delay or discourage repair. Some cluster bombs combine these functions. One example was the British JP233 cluster bomb which includes munitions to damage (crater) the runway as well as anti-personnel mines in the same cluster bomb. As a result of the anti-personnel mine ban it was withdrawn from British Royal Air Force service, and the last stockpiles of the mine were destroyed on 19 October 1999.

Metal detectors were first used for demining, after their invention by the Polish officer Józef Kosacki. His invention, known as the Polish mine detector, was used by the Allies alongside mechanical methods, to clear the German mine fields during the Second Battle of El Alamein when 500 units were shipped to Field Marshal Montgomery's Eighth Army.

The Nazis used captured civilians who were chased across minefields to detonate the explosives. According to Laurence Rees "Curt von Gottberg, the SS-Obergruppenführer who, during 1943, conducted another huge anti-partisan action called Operation Kottbus on the eastern border of Belarus, reported that 'approximately two to three thousand local people were blown up in the clearing of the minefields'."

Whereas the placing and arming of mines is relatively inexpensive and simple, the process of detecting and removing them is typically expensive, slow, and dangerous. This is especially true of irregular warfare where mines were used on an ad hoc basis in unmarked areas. Anti-personnel mines are most difficult to find, due to their small size and the fact that many are made almost entirely of non-metallic materials specifically to escape detection.

Manual clearing remains the most effective technique for clearing mine fields, although hybrid techniques involving the use of animals and robots are being developed. Animals are desirable due to their strong sense of smell, which is more than capable of detecting a land mine. Animals like rats and dogs can also differentiate between other metal objects and land mines because they can be trained to detect the explosive agent itself.

Other techniques involve the use of geo-location technologies. A joint team of researchers at the University of New South Wales and Ohio State University is working to develop a system based on multi-sensor integration.

The laying of land mines has inadvertently led to a positive development in the Falkland Islands. Mine fields laid near the sea during the Falklands War have become favorite places for penguins, which do not weigh enough to detonate the mines. Therefore, they can breed safely, free of human intrusion. These odd sanctuaries have proven so popular and lucrative for ecotourism that efforts exist to prevent removal of the mines.

The use of land mines is controversial because they are indiscriminate weapons, harming soldier and civilian alike. They remain dangerous after the conflict in which they were deployed has ended, killing and injuring civilians and rendering land impassable and unusable for decades. To make matters worse, many factions have not kept accurate records (or any at all) of the exact locations of their minefields, making removal efforts painstakingly slow. These facts pose serious difficulties in many developing nations where the presence of mines hampers resettlement, agriculture, and tourism. The International Campaign to Ban Landmines campaigned successfully to prohibit their use, culminating in the 1997 Convention on the Prohibition of the Use, Stockpiling, Production and Transfer of Anti-Personnel Mines and on their Destruction, known informally as the Ottawa Treaty.

The Treaty came into force on 1 March 1999. The treaty was the result of the leadership of the Governments of Canada, Norway, South Africa and Mozambique working with the "International Campaign to Ban Landmines", launched in 1992. The campaign and its leader, Jody Williams, won the Nobel Peace Prize in 1997 for its efforts.

The treaty does not include anti-tank mines, cluster bombs or claymore-type mines operated in command mode and focuses specifically on anti-personnel mines, because these pose the greatest long term (post-conflict) risk to humans and animals since they are typically designed to be triggered by any movement or pressure of only a few kilograms, whereas anti-tank mines require much more weight (or a combination of factors that would exclude humans). Existing stocks must be destroyed within four years of signing the treaty.

Signatories of the Ottawa Treaty agree that they will not use, produce, stockpile or trade in anti-personnel land mines. In 1997, there were 122 signatories; the Treaty has now been signed by 162 countries. As of early 2016, 162 countries have joined the Treaty. Thirty-six countries, including the People's Republic of China, the Russian Federation and the United States, which together may hold tens of millions of stockpiled antipersonnel mines, are not party to the Convention. Another 34 have yet to sign on. The United States did not sign because the treaty lacks an exception for the Korean Demilitarized Zone.

There is a clause in the treaty, Article 3, which permits countries to retain land mines for use in training or development of countermeasures. Sixty-four countries have taken this option.

As an alternative to an outright ban, 10 countries follow regulations that are contained in a 1996 amendment of Protocol II of the Convention on Conventional Weapons (CCW). The countries are China, Finland, India, Israel, Morocco, Pakistan, South Korea and the United States. Sri Lanka, which had adhered to this regulation announced in 2016, that it would join the Ottawa Treaty.

Before the Ottawa Treaty was adopted, the Arms Project of Human Rights Watch identified "almost 100 companies and government agencies in 48 countries" that had manufactured "more than 340 types of antipersonnel landmines in recent decades." Five to ten million mines were produced per year with a value of $50 to $200 million. The largest producers were probably China, Italy and the Soviet Union. The companies involved included giants such as Daimler-Benz, the Fiat Group, the Daewoo Group, RCA and General Electric.

As of 2017, the "Landmine & Cluster Munition Monitor" identified four countries that were "likely to be actively producing" land mines: India, Myanmar, Pakistan and South Korea. Another seven states reserved the right to make them but were probably not doing so: China, Cuba, Iran, North Korea, Russia, Singapore, and Vietnam.

Throughout the world there are millions of hectares that are contaminated with land mines.

From 1999 to 2017, the "Landmine Monitor" has recorded over 120,000 casualties from mines, IEDs and explosive remnants of war; it estimates that another 1,000 per year go unrecorded. The estimate for all time is over half a million. In 2017, at least 2,793 were killed and 4,431 injured. 87% of the casualties were civilians and 47% were children (less than 18 years old). The largest numbers of casualties were in Afghanistan (2,300), Syria (1,906), and Ukraine (429).

Natural disasters can have a significant impact on efforts to demine areas of land. For example, the floods that occurred in Mozambique in 1999 and 2000 may have displaced hundreds of thousands of land mines left from the war. Uncertainty about their locations delayed recovery efforts.

From a study by Asmeret Asefaw Berhe, land degradation caused by land mines "can be classified into five groups: access denial, loss of biodiversity, micro-relief disruption, chemical composition, and loss of productivity". The effects of an explosion depend on: "(i) the objectives and methodological approaches of the investigation; (ii) concentration of mines in a unit area; (iii) chemical composition and toxicity of the mines; (iv) previous uses of the land and (v) alternatives that are available for the affected populations."

The most prominent ecological issue associated with landmines (or fear of them) is denial of access to vital resources (where "access" refers to the ability to use resources, in contrast to "property", the right to use them). The presence and fear of presence of even a single landmine can discourage access for agriculture, water supplies and possibly conservation measures. Reconstruction and development of important structures such as schools and hospitals are likely to be delayed, and populations may shift to urban areas, increasing overcrowding and the risk of spreading diseases.

Access denial can have positive effects on the environment. When a mined area becomes a "no-man's land", plants and vegetation have a chance to grow and recover. For example, formerly arable lands in Nicaragua returned to forests and remained undisturbed after the establishment of landmines. Similarly, the Penguins of the Falkland Islands have benefited because they are not heavy enough to trigger the mines present. However, these benefits can only last as long as animals, tree limbs, etc. do not detonate the mines. In addition, long idle periods could "potentially end up creating or exacerbating loss of productivity", particularly within land of low quality.

Landmines can threaten biodiversity by wiping out vegetation and wildlife during explosions or demining. This extra burden can push threatened and endangered species to extinction. They have also been used by poachers to target endangered species. Displace people refugees hunt animals for food and destroy habitat by making shelters.

Shrapnel, or abrasions of bark or roots caused by detonated mines, can cause the slow death of trees and provide entry sites for wood-rotting fungi. When landmines make land unavailable for farming, residents resort to the forests to meet all of their survival needs. This exploitation furthers the loss of biodiversity.

Near mines that have exploded or decayed, soils tend to be contaminated, particularly with heavy metals. Products produced from the explosives, both organic and inorganic substances, are most likely to be "long lasting, water-soluble and toxic even in small amounts". They can be implemented either "directly or indirectly into soil, water bodies, microorganisms and plants with drinking water, food products or during respiration".

Toxic compounds can also find their way into bodies of water accumulate in land animals, fish and plants. They can act "as a nerve poison to hamper growth", with deadly effect.







</doc>
<doc id="18173" url="https://en.wikipedia.org/wiki?curid=18173" title="List of libertarian political parties">
List of libertarian political parties

Many countries and subnational political entities have libertarian parties. Although these parties may describe themselves as libertarian, their ideologies differ considerably and not all of them support all elements of libertarianism or classical liberalism.



</doc>
<doc id="18175" url="https://en.wikipedia.org/wiki?curid=18175" title="Loa">
Loa

Loa (, also written lwa as in Haitian Creole) are the spirits of Haitian Vodou and Louisiana Voodoo. They are also referred to as "mystères" and "the invisibles" and are intermediaries between Bondye (from French "Bon Dieu", meaning "good God")—the Supreme Creator, who is distant from the world—and humanity. Unlike saints or angels, however, they are not simply prayed to, they are served. They are each distinct beings with their own personal likes and dislikes, distinct sacred rhythms, songs, dances, ritual symbols, and special modes of service. Contrary to popular belief, the loa are not deities in and of themselves; they are intermediaries for, and dependent on, a distant Bondye.

The word "lwa" comes from Yoruba "olúwa" (meaning "lord" or "god").

The enslaved Fon and Ewe in Haiti and Louisiana syncretized the loa with the Catholic saints—vodoun altars will frequently display images of Catholic saints. For example, Papa Legba is syncretized with Saint Peter or Lazarus of Bethany.

Syncretism also works the other way in Haitian Vodou and many Catholic saints have become loa in their own right, most notably Philomena, the archangel Michael, Jude the Apostle, and John the Baptist.

In a ritual the loa are called down by the "houngan" (priest), "mambo" (priestess), or the "bokor" and the "caplata" (sorcerers and witches) to take part in the service, receive offerings, and grant requests. The loa arrive in the peristyle (ritual space) by mounting (possessing) a horse (ritualist) in Creole referred as "Chwal"—who is said to be "ridden". This can be quite a violent occurrence as the participant can flail about or convulse before falling to the ground, but some loa, such as Ayizan, will mount their "horses" very quietly.

Certain loa display very distinctive behavior by which they can be recognized, specific phrases, and specific actions. As soon as a loa is recognized, the symbols appropriate to them will be given to them. For example, Erzulie Freda will be given a glass of pink champagne, she is sprinkled with her perfumes, fine gifts of food will be presented to her or she even puts on her jewelry; Legba will be given his cane, straw hat, and pipe; Baron Samedi will often fall flat on the floor and the vodousants around him will dress him and prepare him as they do in a morgue with cotton in his nose.
Once the loa have arrived, fed, been served, and possibly given help or advice, they leave the peristyle. Certain loa can become obstinate, for example the Guédé are notorious for wanting just one more smoke, or one more drink, but it is the job of the houngan or mambo to keep the spirits in line while ensuring they are adequately provided for.

There are many families or ""nanchons"" (from "nations") of loa: Rada (also Radha), Petro (also Pethro, Petwo), Nago, Kongo, and Ghede (also Guede, or Gede), among others.

The Rada loa are generally older, as many of these spirits come from Africa and the kingdom of Dahomey. The Rada Loa are mainly water spirits and many of the Rada loa are served with a water. The Rada are "Cool" in the sense they are less aggressive than the Petro. They include Legba, Loko, Ayizan, Damballa Wedo and Ayida-Weddo, Maîtresse Mambo Erzulie Fréda Dahomey, La Sirène, and Agwé. Many of these spirits are served with white, sometimes in conjunction with another color. For example, Damballa may take white and green in some Vodou houses, or just white in others. Freda may take white and pink in one house, or pink and light blue in another. However, as a general rule of thumb, white is a color appropriate to all the Rada.

The Petro loa are generally the more fiery, occasionally aggressive and warlike loa, and are associated with Haiti and the New World. They include Ezili Dantor, Marinette, and Met Kalfu (Maitre Carrefour, "Master Crossroads"). Their traditional colour is red. As with the Rada, additional colors may be associated with individual Petro. Dantor will be served with red, but in different houses may additionally take navy blue, green, or gold.

Originating from the Congo region, these loa include the many Simbi loa. It also includes Marinette, a fierce and much feared female loa.

Originating from Yorubaland, this nation includes many of the Ogoun loa, most of whom use 'Ogou' as a sort of family name. Examples include Ogou Feray, a martial, solider lwa; Ogou Bdagris, a wiser general; Ogou Panama, often viewed as a pilot (and an example of how lwa can subdivide as the world changes); and Ogou Balendjo, who serves on the ship of the Rada ocean lwa Agwe.

The Guédé are the spirits of the unclaimed or unremembered dead, thus categorized separately from one's remembered ancestors. They are traditionally led by the Barons (La Croix, Samedi, Cimitière, Kriminel), and Maman Brigitte. The Ghede as a family are loud, rude (although rarely to the point of real insult), sexual, and usually a lot of fun. As those who have lived already, they have nothing to fear, and frequently will display how far past consequence and feeling they are when they come through in a service — eating glass, raw chillis, and anointing their sensitive areas with chilli rum, for example. Their traditional colors are black and purple. They are known for the "banda", a dance they perform that mimics sexual intercourse.




</doc>
<doc id="18178" url="https://en.wikipedia.org/wiki?curid=18178" title="Labour economics">
Labour economics

Labour economics seeks to understand the functioning and dynamics of the markets for wage labour. Labour is a commodity that supplied by labourers in exchange for a wage paid by demanding firms.

Labour markets or job markets function through the interaction of workers and employers. Labour economics looks at the suppliers of labour services (workers) and the demanders of labour services (employers), and attempts to understand the resulting pattern of wages, employment, and income. Labour markets are normally geographically bounded, but the rise of the internet has brought about a 'planetary labour market' in some sectors.

Labour is a measure of the work done by human beings. It is conventionally contrasted with such other factors of production as land and capital. Some theories focus on human capital (referring to the skills that workers possess, not necessarily their actual work). Labour is unique to study because it is a special type of good that cannot be separated from the owner (i.e. the work cannot be separated from the person who does it). A labour market is also different from other markets in that workers are the suppliers and firms are the demanders.

There are two sides to labour economics. Labour economics can generally be seen as the application of microeconomic or macroeconomic techniques to the labour market. Microeconomic techniques study the role of individuals and individual firms in the labour market. Macroeconomic techniques look at the interrelations between the labour market, the goods market, the money market, and the foreign trade market. It looks at how these interactions influence macro variables such as employment levels, participation rates, aggregate income and gross domestic product.

The Labour force (LF) is defined as the number of people of working age, who are either employed or actively looking for work (unemployed). The labour force participation rate (LFPR) is the number of people in the labour force divided by the size of the adult civilian non-institutional population (or by the population of working age that is not institutionalized), LFPR = LF/Population.

The non-labour force includes those who are not looking for work, those who are institutionalized (such as in prisons or psychiatric wards), stay-at-home spouses, children not of working age, and those serving in the military. The unemployment level is defined as the labour force minus the number of people currently employed. The unemployment rate is defined as the level of unemployment divided by the labour force. The employment rate is defined as the number of people currently employed divided by the adult population (or by the population of working age). In these statistics, self-employed people are counted as employed.

The skills required in a labour force can vary from individual to individual, as well as from firm to firm. Some firms have specific skills they are interested in, limiting the labour force to certain criteria. A firm requiring specific skills will help determine the size of the market.

Variables like employment level, unemployment level, labour force, and unfilled vacancies are called stock variables because they measure a quantity at a point in time. They can be contrasted with flow variables which measure a quantity over a duration of time. Changes in the labour force are due to flow variables such as natural population growth, net immigration, new entrants, and retirements. Changes in unemployment depend on inflows (non-employed people starting to look for jobs and employed people who lose their jobs that are looking for new ones) and outflows (people who find new employment and people who stop looking for employment). When looking at the overall macroeconomy, several types of unemployment have been identified, which can be separated into two categories of natural and unnatural unemployment.

"Natural Unemployment"


"Unnatural Unemployment"


Neoclassical economists view the labour market as similar to other markets in that the forces of supply and demand jointly determine the price (in this case the wage rate) and quantity (in this case the number of people employed).

However, the labour market differs from other markets (like the markets for goods or the financial market) in several ways. In particular, the labour market may act as a non-clearing market. While according to neoclassical theory most markets quickly attain a point of equilibrium without excess supply or demand, this may not be true of the labour market: it may have a persistent level of unemployment. Contrasting the labour market to other markets also reveals persistent compensating differentials among similar workers.

Models that assume perfect competition in the labour market, as discussed below, conclude that workers earn their marginal product of labour.

Households are suppliers of labour. In microeconomic theory, people are assumed to be rational and seeking to maximize their utility function. In the labour market model, their utility function expresses trade-offs in preference between leisure time and income from time used for labour. However, they are constrained by the hours available to them.

Let "w" denote the hourly wage, "k" denote total hours available for labour and leisure, "L" denote the chosen number of working hours, π denote income from non-labour sources, and "A" denote leisure hours chosen. The individual's problem is to maximise utility "U", which depends on total income available for spending on consumption and also depends on the time spent in leisure, subject to a time constraint, with respect to the choices of labour time and leisure time:

This is shown in the graph below, which illustrates the trade-off between allocating time to leisure activities and allocating it to income-generating activities. The linear constraint indicates that every additional hour of leisure undertaken requires the loss of an hour of labour and thus of the fixed amount of goods that that labour's income could purchase. Individuals must choose how much time to allocate to leisure activities and how much to working. This allocation decision is informed by the indifference curve labelled IC. The curve indicates the combinations of leisure and work that will give the individual a specific level of utility. The point where the highest indifference curve is just tangent to the constraint line (point A), illustrates the optimum for this supplier of labour services.

If consumption is measured by the value of income obtained, this diagram can be used to show a variety of interesting effects. This is because the absolute value of the slope of the budget constraint is the wage rate. The point of optimisation (point A) reflects the equivalency between the wage rate and the marginal rate of substitution of leisure for income (the absolute value of the slope of the indifference curve). Because the marginal rate of substitution of leisure for income is also the ratio of the marginal utility of leisure (MU) to the marginal utility of income (MU), one can conclude:

where "Y" is total income and the right side is the wage rate.
If the wage rate increases, this individual's constraint line pivots up from X,Y to X,Y. He/she can now purchase more goods and services. His/her utility will increase from point A on IC to point B on IC.
To understand what effect this might have on the decision of how many hours to work, one must look at the income effect and substitution effect.

The wage increase shown in the previous diagram can be decomposed into two separate effects. The pure income effect is shown as the movement from point A to point C in the next diagram. Consumption increases from Y to Y and – since the diagram assumes that leisure is a normal good – leisure time increases from X to X. (Employment time decreases by the same amount as leisure increases.)

But that is only part of the picture. As the wage rate rises, the worker will substitute away from leisure and into the provision of labour—that is, will work more hours to take advantage of the higher wage rate, or in other words substitute away from leisure because of its higher opportunity cost. This substitution effect is represented by the shift from point C to point B. The net impact of these two effects is shown by the shift from point A to point B. The relative magnitude of the two effects depends on the circumstances. In some cases, such as the one shown, the substitution effect is greater than the income effect (in which case more time will be allocated to working), but in other cases, the income effect will be greater than the substitution effect (in which case less time is allocated to working). The intuition behind this latter case is that the individual decides that the higher earnings on the previous amount of labour can be "spent" by purchasing more leisure.

If the substitution effect is greater than the income effect, an individual's supply of labour services will increase as the wage rate rises, which is represented by a positive slope in the labour supply curve (as at point E in the adjacent diagram, which exhibits a positive wage elasticity). This positive relationship is increasing until point F, beyond which the income effect dominates the substitution effect and the individual starts to reduce the number of labour hours he supplies (point G) as wage increases; in other words, the wage elasticity is now negative.

The direction of the slope may change more than once for some individuals, and the labour supply curve is different for different individuals.

Other variables that affect the labour supply decision, and can be readily incorporated into the model, include taxation, welfare, work environment, and income as a signal of ability or social contribution.

A firm's labour demand is based on its marginal physical product of labour (MPP). This is defined as the additional output (or physical product) that results from an increase of one unit of labour (or from an infinitesimal increase in labour). (See also Production theory basics.)

Labour demand is a derived demand; that is, hiring labour is not desired for its own sake but rather because it aids in producing output, which contributes to an employer's revenue and hence profits. The demand for an additional amount of labour depends on the Marginal Revenue Product (MRP) and the marginal cost (MC) of the worker. With a perfectly competitive goods market, the MRP is calculated by multiplying the price of the end product or service by the Marginal Physical Product of the worker. If the MRP is greater than a firm's Marginal Cost, then the firm will employ the worker since doing so will increase profit. The firm only employs however up to the point where MRP=MC, and not beyond, in neoclassical economic theory.

The MRP of the worker is affected by other inputs to production with which the worker can work (e.g. machinery), often aggregated under the term "capital". It is typical in economic models for greater availability of capital for a firm to increase the MRP of the worker, all else equal. Education and training are counted as "human capital". Since the amount of physical capital affects MRP, and since financial capital flows can affect the amount of physical capital available, MRP and thus wages can be affected by financial capital flows within and between countries, and the degree of capital mobility within and between countries.

According to neoclassical theory, over the relevant range of outputs, the marginal physical product of labour is declining (law of diminishing returns). That is, as more and more units of labour are employed, their additional output begins to decline.

Additionally, although the MRP is a good way of expressing an employer's demand, other factors such as social group formation can the demand, as well as the labour supply. This constantly restructures exactly what a labour market is, and leads way to cause problems for theories of inflation.

The marginal revenue product of labour can be used as the demand for labour curve for this firm in the short run. In competitive markets, a firm faces a perfectly elastic supply of labour which corresponds with the wage rate and the marginal resource cost of labour (W = S = MFC). In imperfect markets, the diagram would have to be adjusted because MFC would then be equal to the wage rate divided by marginal costs. Because optimum resource allocation requires that marginal factor costs equal marginal revenue product, this firm would demand L units of labour as shown in the diagram.

The demand for labour of this firm can be summed with the demand for labour of all other firms in the economy to obtain the aggregate demand for labour. Likewise, the supply curves of all the individual workers (mentioned above) can be summed to obtain the aggregate supply of labour. These supply and demand curves can be analysed in the same way as any other industry demand and supply curves to determine equilibrium wage and employment levels.

Wage differences exist, particularly in mixed and fully/partly flexible labour markets. For example, the wages of a doctor and a port cleaner, both employed by the NHS, differ greatly. There are various factors concerning this phenomenon. This includes the MRP of the worker. A doctor's MRP is far greater than that of the port cleaner. In addition, the barriers to becoming a doctor are far greater than that of becoming a port cleaner. To become a doctor takes a lot of education and training which is costly, and only those who excel in academia can succeed in becoming doctors. The port cleaner, however, requires relatively less training. The supply of doctors is therefore significantly less elastic than that of port cleaners. Demand is also inelastic as there is a high demand for doctors and medical care is a necessity, so the NHS will pay higher wage rates to attract the profession.

Some labour markets have a single employer and thus do not satisfy the perfect competition assumption of the neoclassical model above. The model of a monopsonistic labour market gives a lower quantity of employment and a lower equilibrium wage rate than does the competitive model.

In many real-life situations, the assumption of perfect information is unrealistic. An employer does not necessarily know how hard workers are working or how productive they are. This provides an incentive for workers to shirk from providing their full effort, called moral hazard. Since it is difficult for the employer to identify the hard-working and the shirking employees, there is no incentive to work hard and productivity falls overall, leading to the hiring of more workers and a lower unemployment rate.

One solution that is used to avoid a moral hazard is stock options that grant employees the chance to benefit directly from a firm's success. However, this solution has attracted criticism as executives with large stock-option packages have been suspected of acting to over-inflate share values to the detriment of the long-run welfare of the firm. Another solution, foreshadowed by the rise of temporary workers in Japan and the firing of many of these workers in response to the financial crisis of 2008, is more flexible job- contracts and -terms that encourage employees to work less than full-time by partially compensating for the loss of hours, relying on workers to adapt their working time in response to job requirements and economic conditions instead of the employer trying to determine how much work is needed to complete a given task and overestimating.

Another aspect of uncertainty results from the firm's imperfect knowledge about worker ability. If a firm is unsure about a worker's ability, it pays a wage assuming that the worker's ability is the average of similar workers. This wage under compensates high-ability workers which may drive them away from the labour market as well as at the same time attracting low-ability workers. Such a phenomenon, called adverse selection, can sometimes lead to market collapse.

One way to combat adverse selection, firms will try to use signalling, pioneered by Michael Spence, whereby employers could use various characteristics of applicants differentiate between high-ability or low-ability workers. One common signal used is education, whereby employers assume that high-ability workers will have higher levels of education. Employers can then compensate high-ability workers with higher wages. However, signalling does not always work, and it may appear to an external observer that education has raised the marginal product of labour, without this necessarily being true.

One of the major research achievements of the 1990-2010 period was the development of a framework with dynamic search, matching, and bargaining.

At the micro level, one sub-discipline eliciting increased attention in recent decades is analysis of internal labour markets, that is, "within" firms (or other organisations), studied in personnel economics from the perspective of personnel management. By contrast, external labour markets "imply that workers move somewhat fluidly between firms and wages are determined by some aggregate process where firms do not have significant discretion over wage setting." The focus is on "how firms establish, maintain, and end employment relationships and on how firms provide incentives to employees," including models and empirical work on incentive systems and as constrained by economic efficiency and risk/incentive tradeoffs relating to personnel compensation.

Inequality and discrimination in the workplace can have many effects on workers.

In the context of labour economics, inequality is usually referring to the unequal distribution of earning between households. Inequality is commonly measured by economists using the Gini coefficient. This coefficient does not have a concrete meaning but is more used as a way to compare inequality across regions. The higher the Gini coefficient is calculated to be the larger inequality exists in a region. Over time, inequality has, on average, been increasing. This is due to numerous factors including labour supply and demand shifts as well as institutional changes in the labour market. On the shifts in labour supply and demand, factors include demand for skilled workers going up more than the supply of skilled workers and relative to unskilled workers as well as technological changes that increase productivity; all of these things cause wages to go up for skilled labour while unskilled worker wages stay the same or decline. As for the institutional changes, a decrease in union power and a declining real minimum wage, which both reduce unskilled workers wages, and tax cuts for the wealthy all increase the inequality gap between groups of earners.

As for discrimination, it is the difference in pay that can be attributed to the demographic differences between people, such as gender, race, ethnicity, religion, sexual orientation, etc, even though these factors do not affect the productivity of the worker. Many regions and countries have enacted government policies to combat discrimination, including discrimination in the workplace. Discrimination can be modelled and measured in numerous ways. The oaxaca decomposition is a common method used to calculate the amount of discrimination that exists when wages differ between groups of people. This decomposition aims to calculate the difference in wages that occurs because of differences in skills versus the returns to those skills. A way of modelling discrimination in the workplace when dealing with wages are Gary Becker's taste models. Using taste models, employer discrimination can be thought of as the employer not hiring the minority worker because of their perceived cost of hiring that worker is higher than that of the cost of hiring a non-minority worker, which causes less hiring of the minority. Another taste model is for employee discrimination, which does not cause a decline in the hiring of minorities, but instead causes a more segregated workforce because the prejudiced worker feels that they should be paid more to work next to the worker they are prejudiced against or that they are not paid an equal amount as the worker they are prejudiced against. One more taste model involves customer discrimination, whereby the employers themselves are not prejudiced but believe that their customers might be, so therefore the employer is less likely to hire the minority worker if they are going to interact with customers that are prejudiced. There are many other taste models other than these that Gary Becker has made to explain discrimination that causes differences in hiring in wages in the labour market.

Many sociologists, political economists, and heterodox economists claim that labour economics tends to lose sight of the complexity of individual employment decisions. These decisions, particularly on the supply side, are often loaded with considerable emotional baggage and a purely numerical analysis can miss important dimensions of the process, such as social benefits of a high income or wage rate regardless of the marginal utility from increased consumption or specific economic goals.

From the perspective of mainstream economics, neoclassical models are not meant to serve as a full description of the psychological and subjective factors that go into a given individual's employment relations, but as a useful approximation of human behaviour in the aggregate, which can be fleshed out further by the use of concepts such as information asymmetry, transaction costs, contract theory etc.

Also missing from most labour market analyses is the role of unpaid labour such as unpaid internships where workers with little or no experience are allowed to work a job without pay so that they can gain experience in a particular profession. Even though this type of labour is unpaid it can nevertheless play an important part in society if not abused by employers. The most dramatic example is child raising. However, over the past 25 years an increasing literature, usually designated as the economics of the family, has sought to study within household decision making, including joint labour supply, fertility, child-raising, as well as other areas of what is generally referred to as home production.

The labour market, as institutionalised under today's market economic systems, has been criticised, especially by both mainstream socialists and anarcho-syndicalists, who utilise the term wage slavery as a pejorative for wage labour. Socialists draw parallels between the trade of labour as a commodity and slavery. Cicero is also known to have suggested such parallels.

According to Noam Chomsky, analysis of the psychological implications of wage slavery goes back to the Enlightenment era. In his 1791 book "On the Limits of State Action", classical liberal thinker Wilhelm von Humboldt explained how "whatever does not spring from a man's free choice, or is only the result of instruction and guidance, does not enter into his very nature; he does not perform it with truly human energies, but merely with mechanical exactness" and so when the labourer works under external control, "we may admire what he does, but we despise what he is." Both the Milgram and Stanford experiments have been found useful in the psychological study of wage-based workplace relations.

The American philosopher John Dewey posited that until "industrial feudalism" is replaced by "industrial democracy," politics will be "the shadow cast on society by big business". Thomas Ferguson has postulated in his investment theory of party competition that the undemocratic nature of economic institutions under capitalism causes elections to become occasions when blocs of investors coalesce and compete to control the state.

As per anthropologist David Graeber, the earliest wage labour contracts we know about were in fact contracts for the rental of chattel slaves (usually the owner would receive a share of the money, and the slave, another, with which to maintain his or her living expenses.) Such arrangements, according to Graeber, were quite common in New World slavery as well, whether in the United States or Brazil. C. L. R. James argued that most of the techniques of human organisation employed on factory workers during the industrial revolution were first developed on slave plantations.

Additionally, Marxists posit that labour-as-commodity, which is how they regard wage labour, provides an absolutely fundamental point of attack against capitalism. "It can be persuasively argued," noted one concerned philosopher, "that the conception of the worker's labour as a commodity confirms Marx's stigmatisation of the wage system of private capitalism as 'wage-slavery;' that is, as an instrument of the capitalist's for reducing the worker's condition to that of a slave, if not below it."




</doc>
<doc id="18179" url="https://en.wikipedia.org/wiki?curid=18179" title="Lammas">
Lammas

Lammas Day (Anglo-Saxon "hlaf-mas", "loaf-mass"), also known as Loaf Mass Day, is a Christian holiday celebrated in some English-speaking countries in the Northern Hemisphere on 1 August. The name originates from the word "loaf" in reference to bread and "Mass" in reference to the primary Christian liturgy celebrating Holy Communion. It is a festival in the liturgical kalendar to mark the blessing of the First Fruits of harvest, with a loaf of bread being brought to the church for this purpose.

On Loaf Mass Day, it is customary to bring to a Christian church a loaf made from the new crop, which began to be harvested at Lammastide, which falls at the halfway point between the summer solstice and autumn September equinox. Christians also have church processions to bakeries, where those working therein are blessed by Christian clergy.

Lammas has coincided with the feast of St. Peter in Chains, commemorating St. Peter's miraculous deliverance from prison, but in the liturgical reform of 1969, the feast of St. Alphonsus Liguori was transferred to this day, the day of St. Alphonsus' death.

While Loaf Mass Day is traditionally a Christian holy day, Lughnasadh is celebrated by Neopagans around the same time.

Ann Lewin explains a key practice of the Christian feast of Lammas (Loaf Mass Day) and its importance in the Christian Calendar in relation to other feasts of the Church Year:
In The Church of England, a Protestant denomination that is the mother church of the Anglican Communion, during the celebration of the Mass, "The Lammas loaf, or part of it, may be used as the bread of the Eucharist, or the Lammas loaf and the eucharistic bread may be kept separate."

The loaf is blessed, and in Anglo-Saxon England it might be employed afterwards in protective rituals: a book of Anglo-Saxon charms directed that the Lammas bread be broken into four bits, which were to be placed at the four corners of the barn, to protect the garnered grain.

In many parts of England, tenants were bound to present freshly harvested wheat to their landlords on or before the first day of August. In the "Anglo-Saxon Chronicle", where it is referred to regularly, it is called "the feast of first fruits". The blessing of first fruits was performed annually in both the Eastern Christian and Western Christian Churches on the first or the sixth of August (the latter being the feast of the Transfiguration of Christ).

In medieval times the feast was sometimes known in England and Scotland as the "Gule of August", but the meaning of "gule" is unclear. Ronald Hutton suggests following the 18th-century Welsh clergyman antiquary John Pettingall that it is merely an Anglicisation of ', the Welsh name of the "feast of August". The "OED" and most etymological dictionaries give it a more circuitous origin similar to "gullet"; from Old French ', a diminutive of ', "throat, neck," from Latin ' "throat".

Several antiquaries beginning with John Brady offered a back-construction to its being originally known as "Lamb-mass", under the undocumented supposition that tenants of the Cathedral of York, dedicated to St. Peter ad Vincula, of which this is the feast, would have been required to bring a live lamb to the church, or, with John Skinner, "because Lambs then grew out of season." This is a folk etymology, of which "OED" notes that it was "subsequently felt as if from ".

For many villeins, the wheat must have run low in the days before Lammas, and the new harvest began a season of plenty, of hard work and company in the fields, reaping in teams. Thus there was a spirit of celebratory play.

In the medieval agricultural year, Lammas also marked the end of the hay harvest that had begun after Midsummer. At the end of hay-making a sheep would be loosed in the meadow among the mowers, for him to keep who could catch it.

In Shakespeare's "Romeo and Juliet" (1.3.19) it is observed of Juliet, "Come Lammas Eve at night shall she [Juliet] be fourteen." Since Juliet was born Lammas eve, she came before the harvest festival, which is significant since her life ended before she could reap what she had sown and enjoy the bounty of the harvest, in this case full consummation and enjoyment of her love with Romeo.

Another well-known cultural reference is the opening of "The Battle of Otterburn": "It fell about the Lammas tide when the muir-men win their hay".

William Hone speaks in "The Every-Day Book" (1838) of a later festive Lammas day sport common among Scottish farmers near Edinburgh. He says that they "build towers...leaving a hole for a flag-pole in the centre so that they may raise their colours." When the flags over the many peat-constructed towers were raised, farmers would go to others' towers and attempt to "level them to the ground." A successful attempt would bring great praise. However, people were allowed to defend their towers, and so everyone was provided with a "tooting-horn" to alert nearby country folk of the impending attack and the battle would turn into a "brawl." According to Hone, more than four people had died at this festival and many more were injured. At the day's end, races were held, with prizes given to the townspeople.

Lughnasadh is the name used for one of the eight sabbats in the Neopagan Wheel of the Year. It is the first of the three autumn harvest festivals, the other two being the autumn equinox (also called Mabon) and Samhain. In the Northern Hemisphere it takes place around 1 August, while in the Southern Hemisphere it is celebrated around 1 February.

Lammas is one of the Scottish quarter days.

"Lammas leaves" or "Lammas growth" refers to a second crop of leaves produced in high summer by some species of trees in temperate countries to replace those lost to insect damage. They often differ slightly in shape, texture and/or hairiness from the earlier leaves.

A low-impact development project at Tir y Gafel, Glandwr, Pembrokeshire, Lammas Ecovillage, is a collective initiative for nine self-built homes. It was the first such project to obtain planning permission based on a predecessor of what is now the sixth national planning guidance for sustainable rural communities originally proposed by the One Planet Council.

Exeter in Devon is one of the few towns in England that still celebrates its Lammas Fair and has a processional custom which stretches back over 900 years, led by the Lord Mayor. During the fair a white glove on a pole decorated with garlands is raised above the Guildhall. The fair now takes place on the first Thursday in July.

The "Doctor Who" serial "The Image of the Fendahl" takes place on Lammas Eve.

In the "Inspector Morse" episode "Day of the Devil", Lammas Day is presented as a Satanic (un)holy day, "the Devil's day".

Katherine Kurtz's alternate World War II fantasy "history" takes its title, "Lammas Night", from pagan tradition surrounding the first of August and the Divine Right of Kings.

The English football club Staines Lammas F.C. is named after the festival.

The Song "Corn Rigs" by Paul Giovanni, from the soundtrack to the 1973 film The Wicker Man, takes place "upon a Lammas Night."




</doc>
<doc id="18182" url="https://en.wikipedia.org/wiki?curid=18182" title="Longmeadow, Massachusetts">
Longmeadow, Massachusetts

Longmeadow is a town in Hampden County, Massachusetts, in the United States. The population was 15,784 at the 2010 census.

Longmeadow was first settled in 1644, and officially incorporated October 17, 1783. The town was originally farmland within the limits of Springfield. It remained relatively pastoral until the street railway was built , when the population tripled over a fifteen-year period. After Interstate 91 was built in the wetlands on the west side of town, population tripled again between 1960 and 1975.

During the 19th and early 20th centuries, Longmeadow was best known as the site from which Longmeadow brownstone was mined. Several famous American buildings, including Princeton University's Neo-Gothic library, are made of Longmeadow brownstone. In 1894, the more populous and industrialized "East Village" portion of the town containing the brownstone quarries split off to become East Longmeadow.

Designed by famed golf course architect Donald Ross in 1922, the Longmeadow Country Club was the proving ground for golf equipment designed and manufactured by the Spalding Co. of Chicopee. Bobby Jones, a consultant for Spalding, was a member in standing at LCC and made a number of his instructional films at LCC in the 1930s.

Longmeadow is located in the western part of the state, just south of the city of Springfield, and is bordered on the west by the Connecticut River and Agawam, to the east by East Longmeadow, and to the south by Enfield, Connecticut. It extends approximately north to south and east to west. It is approximately north of Hartford.

More than 30% of the town is permanent open space. Conservation areas on the west side of town include more than bordering the Connecticut River. The area supports a wide range of wildlife including deer, beaver, wild turkeys, foxes, and eagles. Springfield's Forest Park, which at is the largest city park in New England, forms the northern border of the town. The private Twin Hills and public Franconia golf courses, plus town athletic fields and conservation land, cover nearly 2/3 of the eastern border of the town. Two large public parks, the Longmeadow Country Club, and three conservation areas account for the bulk of the remaining formal open space. Almost 20% of the houses in town are in proximity to a "dingle", a tree-lined steep-sided sandy ravine with a wetland at the bottom that provides a privacy barrier between yards.

Longmeadow has a town common, commonly referred to as "The Green", located along U.S. Route 5 on the west side of town. It is about long. Roughly 100 houses date back before 1900, most of which are in the historic district, are located near the town green. Longmeadow's Town Green is a historic district on the National Register of Historic Places, and it is surrounded by a number of buildings dating back to the 18th and 19th centuries. Longmeadow is unique as the town green has maintained its residential purpose and has resisted commercial pressure. The current function as listed by the National Register of Historic Places is domestic and landscape. The current sub-function as listed by the National Register of Historic Places is park and single dwelling. Houses along the photogenic main street (Longmeadow Street) are set back farther than in most towns of similar residential density. The town has three recently remodeled elementary schools, two secondary schools, and one high school. The commercial center of town is an area called "The Longmeadow Shops", including restaurants and clothing stores.

According to the United States Census Bureau, the town has a total area of , of which are land and , or 5.34%, are water.

As of the census of 2000, there were 15,633 people, 5,734 households, and 4,432 families residing in the town. The population density was . There were 5,879 housing units at an average density of . The racial makeup of the town was 95.42% White, 0.69% African American, 0.05% Native American, 2.90% Asian, 0.06% Pacific Islander, 0.26% from other races, and 0.62% from two or more races. Hispanic or Latino of any race were 1.09% of the population.

There were 5,734 households, out of which 37.1% had children under the age of 18 living with them, 69.1% were married couples living together, 6.4% had a female householder with no husband present, and 22.7% were non-families. 20.4% of all households were made up of individuals, and 14.0% had someone living alone who was 65 years of age or older. The average household size was 2.66 and the average family size was 3.09.

In the town, the population was spread out, with 26.8% under the age of 18, 4.6% from 18 to 24, 22.0% from 25 to 44, 28.7% from 45 to 64, and 17.8% who were 65 years of age or older. The median age was 43 years. For every 100 females, there were 87.7 males. For every 100 females age 18 and over, there were 82.0 males.

The median income for a household in the town was $109,586, and the median income for a family was $115,578. Males had a median income of $68,238 versus $40,890 for females. The per capita income for the town was $48,949. About 1.0% of families and 2.1% of the population were below the poverty line, including 0.3% of those under age 18 and 8.3% of those age 65 or over.

The town is chartered as an Open Town Meeting form of government. The town government also consists of a Select Board with five members, elected by the town. The public school system is governed by the School Committee. The School Committee is made up of seven voting members elected by the town, the superintendent of schools, two assistant-superintendents, a secretary, and a student representative.

The Longmeadow public school system operates six schools. Blueberry Hill School, Center School, and Wolf Swamp Road School are K−5 elementary schools. Williams Middle School and Glenbrook Middle School serve grades 6–8. Longmeadow High School serves all students in the town between grades 9 and 12. The town's elementary schools have been recently rebuilt, statements of interest for improvements to the two middle schools and Longmeadow High School were filed with the Massachusetts School Building Authority in 2007. In 2010, the voters of Longmeadow approved a 2.5% budget override to support the construction of a new $78 million high school. The town received an estimated $34 million in state funds to be used towards the new construction The new High School was completed and opened to students on February 26, 2013. After students and faculty had moved into the new school, the demolition of the old school was begun. The demolition was completed by June 2013. The school had its grand opening in September 2013 with both the brand new school and renovated business & administration wing open.

Longmeadow also hosts two private parochial schools, the Lubavitcher Yeshiva Academy (LYA) and St. Mary's Academy. LYA was established in 1946 in response to the Greater Springfield Jewish community's need for a quality Jewish day school. In 1999, LYA became the first Jewish day school to be accredited by the New England Association of Schools and Colleges (NEASC). The more than 90 students that the school serves each year from across the spectrum of Jewish life include orthodox, conservative, reform, and unaffiliated families. St. Mary's School, located behind St. Mary's Church, serves Catholic students grades Pre-K through Grade 8.

Approximately 50% of the students at Longmeadow High School participate in the music program. The choruses have won numerous gold medals at the MICCA competition. The jazz ensemble has won numerous gold medals as well, but no longer competes. The honors chorus "Lyrics" has won numerous awards and has traveled to many places around the world on tours, such as Italy and Sweden. The wind ensemble and symphony orchestra have had the honor of performing in Indianapolis, Boston (Boston Symphony Hall), and New York (Carnegie Hall). In 2010, Longmeadow was awarded The American Prize in Orchestral Performance. The music program's crowning achievement has been receiving three national Grammy Awards based on the high level of excellence maintained throughout all groups in the music program.

Longmeadow also contains the 46-acre primary campus for Bay Path University, a private undergraduate and graduate institution.




</doc>
<doc id="18183" url="https://en.wikipedia.org/wiki?curid=18183" title="Body relative direction">
Body relative direction

Body relative directions (also known as egocentric coordinates) are geometrical orientations relative to a body such as a human person's. 
The most common ones are: left and right; forward(s) and backward(s); up and down.
They form three pairs of orthogonal axes.

Since definitions of left and right based on the geometry of the natural environment are unwieldy, in practice, the meaning of relative direction words is conveyed through tradition, acculturation, education, and direct reference. One common definition of up and down uses gravity and the planet Earth as a frame of reference. Since there is a very noticeable force of gravity acting between the Earth and any other nearby object, down is defined as that direction which an object moves in reference to the Earth when the object is allowed to fall freely. Up is then defined as the opposite direction of down. Another common definition uses a human body, standing upright, as a frame of reference. In that case, up is defined as the direction from feet to head, perpendicular to the surface of the Earth. In most cases, up is a directionally oriented position generally opposite to that of the pull of gravity.
In situations where a common frame of reference is needed, it is most common to use an egocentric view. A simple example is road signage. Another example is stage blocking, where "stage left" "stage right" are, by convention, defined from the point of view of actors facing the audience. "Upstage" and "downstage" do not follow gravity but by convention mean away from and towards the audience. An example of a non-egocentric view is page layout, where the relative terms "upper half" "left margin," etc. are defined in terms of the observer but employed in reverse for a type compositor, returning to an egocentric view. In medicine and science, where precise definitions are crucial, relative directions (left and right) are the sides of the organism, not those of the observer. The same is true in heraldry, where left and right in a coat of arms is treated as if the shield were being held by the armiger. To avoid confusion, Latin terminology is employed: "dexter" and "sinister" for right and left. Proper right and proper left are terms mainly used to describe artistic images, and overcome the potential confusion that a figure's "own" right or "proper right" hand is on the left hand as the viewer sees it from the front.

Forward and backward may be defined by referring to an object's or person's motion. Forward is defined as the direction in which the object is moving. Backward is then defined as the opposite direction to forward. Alternatively, 'forward' may be the direction pointed by the observer's nose, defining 'backward' as the direction from the nose to the sagittal border in the observer's skull. With respect to a ship 'forward' would indicate the relative position of any object lying in the direction the ship is pointing. For symmetrical objects, it is also necessary to define forward and backward in terms of expected direction. Many mass transit trains are built symmetrically with paired control booths, and definitions of forward, backward, left, and right are temporary.

Given significant distance from the magnetic poles, one can figure which hand is which using a magnetic compass and the sun. Facing the sun, before noon, the north pointer of the compass points to the "left" hand. After noon, it points to the "right".

 A right-hand rule is one common way to relate three principal directions. For many years a fundamental question in physics was whether a left-hand rule would be equivalent. Many natural structures, including human bodies, follow a certain "handedness", but it was widely assumed that nature did not distinguish the two possibilities. This changed with the discovery of parity violations in particle physics. If a sample of cobalt-60 atoms is magnetized so that they spin counterclockwise around some axis, the beta radiation resulting from their nuclear decay will be preferentially directed opposite that axis. Since counter-clockwise may be defined in terms of up, forward, and right, this experiment unambiguously differentiates left from right using only natural elements: if they were reversed, or the atoms spun clockwise, the radiation would follow the spin axis instead of being opposite to it.

Bow, stern, port, and starboard, fore and aft are nautical terms that convey an impersonal relative direction in the context of the moving frame of persons aboard a ship. The need for impersonal terms is most clearly seen in a rowing shell where the majority of the crew face aft ("backwards"), hence the oars to their right are actually on the port side of the boat. Rowers eschew the terms left, right, port and starboard in favor of stroke-side and bow-side. The usage derives from the tradition of having the stroke (the rower closest to the stern of the boat) oar on the port side of the boat.

Most human cultures use relative directions for reference, but there are exceptions. Australian Aboriginal peoples like the Guugu Yimithirr, Kaiadilt and Thaayorre have no words denoting the egocentric directions in their language; instead, they exclusively refer to cardinal directions, even when describing small-scale spaces. For instance, if they wanted someone to move over on the car seat to make room, they might say "move a bit to the east". To tell someone where exactly they left something in their house, they might say, "I left it on the southern edge of the western table." Or they might warn a person to "look out for that big ant just north of your foot". Other peoples "from Polynesia to Mexico and from Namibia to Bali" similarly have predominantly "geographic languages". American Sign Language makes heavy use of geographical direction through absolute orientation.

Left-right discrimination (LRD) refers to a person's ability to differentiate between left and right. The inability to accurately differentiate between left and right is known as left-right confusion (LRC). According to research performed by John R. Clarke of Drexel University, LRC affects approximately 15% of the population. People who suffer from LRC can typically perform daily navigational tasks, such as driving according to road signs or following a map, but may have difficulty performing actions that require a precise understanding of directional commands, such as ballroom dancing.

Data regarding LRC prevalence is primarily based on behavioral studies, self-assessments, and surveys. Gormley and Brydges found that in a group of 800 adults, 17% of women and 9% of men reported difficulty differentiating between left and right. Such studies suggest that women are more prone to LRC than men, with women reporting higher rates of LRC in both accuracy and speed of response.

The Bergen Left-Right Discrimination (BLRD) test is designed to measure individual performance in LRD accuracy. However, this test has been criticized for incorporating tasks that require the use of additional strategies, such as mental rotation (MR). Because men have been shown to consistently outperform women in MR tasks, tests involving the use of this particular strategy may present alternative cognitive demands and lead to inaccurate assessment of LRD performance. An extended version of the BLRD test was designed to allow for differential evaluation of LRD and MR abilities, in which subtests were created with either high or low demands on mental rotation. Results from these studies did not find sex differences in LRD performance when mental rotation demands were low. Another study found that sex differences in left-right discrimination existed in terms of self-reported difficulty, but not in actual tested ability.

Alternatively, studies focused on LRD as a phenomenon distinct from MR concluded that there are sex differences present in LRD. Scientists controlled for MR demands, potential menstrual cycle effects, and other hormone fluctuations, and determined that the neurocognitive mechanisms that support LRD are different for men and women. This research revealed that inferior parietal and right angular gyrus activation were correlated with LRD performance in both men and women. Women also demonstrated increased prefrontal activation, but did not exhibit greater bilateral activation. Additionally, no correlation was found between LRD accuracy and brain activation, or between brain activation and reaction time, for either sex. These results indicate that there are sex differences in the neurocognitive mechanisms underlying LRD performance; however, findings did not suggest that women are more prone to LRC than men.

Humans are constantly making decisions about spatial relations; however, some spatial relations, such as left-right, are commonly confused, while other spatial relations, such as up-down, above-below, and front-back, are seldom, if ever, mistaken. The ability to categorize and compartmentalize space is an essential tool for navigating this 3D world; an ability shown to develop in early infancy. Infant ability to visually match above-below and left-right relations appears to diminish in early toddlerhood, as language acquisition may complicate verbal labeling. Children learn to verbally discriminate between above-below relations around the age of three, and learn left-right linguistic labels between the ages of six and seven; however, these classifications may only exist in the linguistic context. In other words, children may learn the terms for left and right without having developed a cognitive representation to allow for the accurate application of such spatial distinctions.

Research seeks to explain the neural activity associated with left-right discrimination, attempting to identify differences in the encoding, consolidation, and retrieval of left-right versus above-below relations. One study found that neural activity patterns for left-right and above-below distinctions are represented differently in the brain, leading to the theory that these spatial judgements are supported by separate cognitive mechanisms. Experiments used magnetoencephalography (MEG) to record neural activity during a computerized nonverbal task, examining left-right and above-below differences in encoding and working memory. Results showed differences in neural activity patterns in the right cerebellum, right superior temporal gyrus, and left temporoparietal junction during the encoding phase, and indicated differential neural activity in the inferior parietal, right superior temporal, and right cerebellum regions in the working memory tests.

Although some individuals may struggle with LRD more than others, discriminating between left and right in the face of distraction has been shown to impair even the most proficient individual's ability to accurately differentiate between the two. This issue is of particular importance to medical students, clinicians and health care professionals, where distraction in the workplace and LRD inaccuracy can lead to severe consequences, including laterality errors and wrong-side surgeries. Laterality errors in the field of aviation may also lead to equally devastating results, for example, causing a major airline crash.

Distraction has a significant impact on LRD accuracy, and the type of distraction can alter the magnitude of these effects. For example, cognitive distraction, which occurs when an individual is not directly focused on the task at hand, has a more profound effect on LRD performance than auditory distraction, such as the presence of continuous ambient noise. Additionally, in the field of health care, it has been noted that mental rotation is often involved in making left-right distinctions, such as when a medical practitioner is facing their patient and must adjust for the opposite left-right relations.



</doc>
<doc id="18184" url="https://en.wikipedia.org/wiki?curid=18184" title="Lizard">
Lizard

Lizards are a widespread group of squamate reptiles, with over 6,000 species, ranging across all continents except Antarctica, as well as most oceanic island chains. The group is paraphyletic as it excludes the snakes and Amphisbaenia; some lizards are more closely related to these two excluded groups than they are to other lizards. Lizards range in size from chameleons and geckos a few centimeters long to the 3 meter long Komodo dragon.

Most lizards are quadrupedal, running with a strong side-to-side motion. Others are legless, and have long snake-like bodies. Some such as the forest-dwelling "Draco" lizards are able to glide. They are often territorial, the males fighting off other males and signalling, often with brightly colours, to attract mates and to intimidate rivals. Lizards are mainly carnivorous, often being sit-and-wait predators; many smaller species eat insects, while the Komodo eats mammals as big as water buffalo.

Lizards make use of a variety of antipredator adaptations, including venom, camouflage, reflex bleeding, and the ability to sacrifice and regrow their tails.

The adult length of species within the suborder ranges from a few centimeters for chameleons such as "Brookesia micra" and geckos such as "Sphaerodactylus ariasae" to nearly in the case of the largest living varanid lizard, the Komodo dragon. Most lizards are fairly small animals.

Lizards typically have rounded torsos, elevated heads on short necks, four limbs and long tails, although some are legless. Lizards and snakes share a movable quadrate bone, distinguishing them from the rhynchocephalians, which have more rigid diapsid skulls. Some lizards such as chameleons have prehensile tails, assisting them in climbing among vegetation.

As in other reptiles, the skin of lizards is covered in overlapping scales made of keratin. This provides protection from the environment and reduces water loss through evaporation. This adaptation enables lizards to thrive in some of the driest deserts on earth. The skin is tough and leathery, and is shed (sloughed) as the animal grows. Unlike snakes which shed the skin in a single piece, lizards slough their skin in several pieces. The scales may be modified into spines for display or protection, and some species have bone osteoderms underneath the scales.

The dentitions of lizards reflect their wide range of diets, including carnivorous, insectivorous, omnivorous, herbivorous, nectivorous, and molluscivorous. Species typically have uniform teeth suited to their diet, but several species have variable teeth, such as cutting teeth in the front of the jaws and crushing teeth in the rear. Most species are pleurodont, though agamids and chameleons are acrodont.

The tongue can be extended outside the mouth, and is often long. In the beaded lizards, whiptails and monitor lizards, the tongue is forked and used mainly or exclusively to sense the environment, continually flicking out to sample the environment, and back to transfer molecules to the vomeronasal organ responsible for chemosensation, analogous to but different from smell or taste. In geckos, the tongue is used to lick the eyes clean: they have no eyelids. Chameleons have very long sticky tongues which can be extended rapidly to catch their insect prey.

Three lineages, the geckos, anoles, and chameleons, have modified the scales under their toes to form adhesive pads, highly prominent in the first two groups. The pads are composed of millions of tiny setae (hair-like structures) which fit closely to the substrate to adhere using van der Waals forces; no liquid adhesive is needed. In addition, the toes of chameleons are divided into two opposed groups on each foot (zygodactyly), enabling them to perch on branches as birds do.

Aside from legless lizards, most lizards are quadrupedal and move using gaits with alternating movement of the right and left limbs with substantial body bending. This body bending prevents significant respiration during movement, limiting their endurance, in a mechanism called Carrier's constraint. Several species can run bipedally, and a few can prop themselves up on their hindlimbs and tail while stationary. Several small species such as those in the genus "Draco" can glide: some can attain a distance of , losing in height. Some species, like geckos and chameleons, adhere to vertical surfaces including glass and ceilings. Some species, like the common basilisk, can run across water.

Lizards make use of their senses of sight, touch, olfaction and hearing like other vertebrates. The balance of these varies with the habitat of different species; for instance, skinks that live largely covered by loose soil rely heavily on olfaction and touch, while geckos depend largely on acute vision for their ability to hunt and to evaluate the distance to their prey before striking. Monitor lizards have acute vision, hearing, and olfactory senses. Some lizards make unusual use of their sense organs: chameleons can steer their eyes in different directions, sometimes providing non-overlapping fields of view, such as forwards and backwards at once. Lizards lack external ears, having instead a circular opening in which the tympanic membrane (eardrum) can be seen. Many species rely on hearing for early warning of predators, and flee at the slightest sound.

As in snakes and many mammals, all lizards have a specialised olfactory system, the vomeronasal organ, used to detect pheromones. Monitor lizards transfer scent from the tip of their tongue to the organ; the tongue is used only for this information-gathering purpose, and is not involved in manipulating food.

Some lizards, particularly iguanas, have retained a photosensory organ on the top of their heads called the parietal eye, a basal ("primitive") feature also present in the tuatara. This "eye" has only a rudimentary retina and lens and cannot form images, but is sensitive to changes in light and dark and can detect movement. This helps them detect predators stalking it from above.

Until 2006 it was thought that the Gila monster and the Mexican beaded lizard were the only venomous lizards. However, several species of monitor lizards, including the Komodo dragon, produce powerful venom in their oral glands. Lace monitor venom, for instance, causes swift loss of consciousness and extensive bleeding through its pharmacological effects, both lowering blood pressure and preventing blood clotting. Nine classes of toxin known from snakes are produced by lizards. The range of actions provides the potential for new medicinal drugs based on lizard venom proteins.

Genes associated with venom toxins have been found in the salivary glands on a wide range of lizards, including species traditionally thought of as non-venomous, such as iguanas and bearded dragons. This suggests that these genes evolved in the common ancestor of lizards and snakes, some 200 million years ago (forming a single clade, the Toxicofera). However, most of these putative venom genes were "housekeeping genes" found in all cells and tissues, including skin and cloacal scent glands. The genes in question may thus be evolutionary precursors of venom genes.

Recent studies (2013 and 2014) on the lung anatomy of the savannah monitor and green iguana found them to have a unidirectional airflow system, which involves the air moving in a loop through the lungs when breathing. This was previously thought to only exist in the archosaurs (crocodilians and birds). This may be evidence that unidirectional airflow is an ancestral trait in diapsids.

As with all amniotes, lizards rely on internal fertilisation and copulation involves the male inserting one of his hemipenes into the female's cloaca. The majority of species are oviparous (egg laying). The female deposits the eggs in a protective structure like a nest or crevice or simply on the ground. Depending on the species, clutch size can vary from 4–5 percent of the females body weight to 40–50 percent and clutches range from one or a few large eggs to dozens of small ones. 

In most lizards, the eggs have leathery shells to allow for the exchange of water, although more arid-living species have calcified shells to retain water. Inside the eggs, the embryos use nutrients from the yolk. Parental care is uncommon and the female usually abandons the eggs after laying them. Brooding and protection of eggs does occur in some species. The female prairie skink uses respiratory water loss to maintain the humidity of the eggs which facilitates embryonic development. In lace monitors, the young hatch close to 300 days, and the female returns to help them escape the termite mound were the eggs were laid.

Around 20 percent of lizard species reproduce via viviparity (live birth). This is particularly common in Anguimorphs. Viviparous species give birth to relatively developed young which look like miniature adults. Embryos are nourished via a placenta-like structure. A minority of lizards have parthenogenesis (reproduction from unfertilised eggs). These species consist of all females who reproduce asexually with no need for males. This is known in occur in various species of whiptail lizards. Parthenogenesis was also recorded in species that normally reproduce sexually. A captive female Komodo dragon produced a clutch of eggs, despite being separated from males for over two years.

Sex determination in lizards can be temperature-dependent. The temperature of the eggs' micro-environment can determine the sex of the hatched young: low temperature incubation produces more females while higher temperatures produce more males. However, some lizards have sex chromosomes and both male heterogamety (XY and XXY) and female heterogamety (ZW) occur.

The majority of lizard species are active during the day, though some are active at night, notably geckos. As ectotherms, lizards have a limited ability to regulate their body temperature, and must seek out and bask in sunlight to gain enough heat to become fully active.

Most social interactions among lizards are between breeding individuals. Territoriality is common and is correlated with species that use sit-and-wait hunting strategies. Males establish and maintain territories that contain resources which attract females and which they defend from other males. Important resources include basking, feeding, and nesting sites as well as refuges from predators. The habitat of a species affects the structure of territories, for example, rock lizards have territories atop rocky outcrops. Some species may aggregate in groups, enhancing vigilance and lessening the risk of predation for individuals, particularly for juveniles. Agonistic behaviour typically occurs between sexually mature males over territory or mates and may involve displays, posturing, chasing, grappling and biting.

Lizards signal both to attract mates and to intimidate rivals. Visual displays include body postures and inflation, push-ups, bright colours, mouth gapings and tail waggings. Male anoles and iguanas have dewlaps or skin flaps which come in various sizes, colours and patterns and the expansion of the dewlap as well as head-bobs and body movements add to the visual signals. Some species have deep blue dewlaps and communicate with ultraviolet signals. Blue-tongued skinks will flash their tongues as a threat display. Chameleons are known to change their complex colour patterns when communicating, particularly during agonistic encounters. They tend to show brighter colours when displaying aggression and darker colours when they submit or "give up".

Several gecko species are brightly coloured; some species tilt their bodies to display their coloration. In certain species, brightly coloured males turn dull when not in the presence of rivals or females. While it is usually males that display, in some species females also use such communication. In the bronze anole, head-bobs are a common form of communication among females, the speed and frequency varying with age and territorial status. Chemical cues or pheromones are also important in communication. Males typically direct signals at rivals, while females direct them at potential mates. Lizards may be able to recognise individuals of the same species by their scent.

Acoustic communication is less common in lizards. Hissing, a typical reptilian sound, is mostly produced by larger species as part of a threat display, accompanying gaping jaws. Some groups, particularly geckos, snake-lizards, and some iguanids, can produce more complex sounds and vocal apparatuses have independently evolved in different groups. These sounds are used for courtship, territorial defense and in distress, and include clicks, squeaks, barks and growls. The mating call of the male tokay gecko is heard as "tokay-tokay!". Tactile communication involves individuals rubbing against each other, either in courtship or in aggression. Some chameleon species communicate with one another by vibrating the substrate that they are standing on, such as a tree branch or leaf.

Lizards are found worldwide, excluding the far north and Antarctica, and some islands. They can be found in elevations from sea level to . They prefer warmer, tropical climates but are adaptable and can live in all but the most extreme environments. Lizards also exploit a number of habitats; most primarily live on the ground, but others may live in rocks, on trees, underground and even in water. The marine iguana is adapted for life in the sea.

The majority of lizard species are predatory and the most common prey items are small, terrestrial invertebrates, particularly insects. Many species are sit-and-wait predators though others may be more active foragers. Chameleons prey on numerous insect species, such as beetles, grasshoppers and winged termites as well as spiders. They rely on persistence and ambush to capture these prey. An individual perches on a branch and stays perfectly still, with only its eyes moving. When an insect lands, the chameleon focuses its eyes on the target and slowly moves towards it before projecting its long sticky tongue which, when hauled back, brings the attach prey with it. Geckos feed on crickets, beetles, termites and moths.

Termites are an important part of the diets of some species of Autarchoglossa, since, as social insects, they can be found in large numbers in one spot. Ants may form a prominent part of the diet of some lizards, particularly among the lacertas. Horned lizards are also well known for specializing on ants. Due to their small size and indigestible chitin, ants must be consumed in large amounts, and ant-eating lizards have larger stomachs than even herbivorous ones. Species of skink and alligator lizards eat snails and their power jaws and molar-like teeth are adapted for breaking the shells.

Larger species, such as monitor lizards, can feed on larger prey including fish, frogs, birds, mammals and other reptiles. Prey may be swallowed whole and torn into smaller pieces. Both bird and reptile eggs may also be consumed as well. Gila monsters and beaded lizards climb trees to reach both the eggs and young of birds. Despite being venomous, these species rely on their strong jaws to kill prey. Mammalian prey typically consists of rodents and leporids; the Komodo dragon can kill prey as large as water buffalo. Dragons are prolific scavengers, and a single decaying carcass can attract several from away. A dragon is capable of consuming a carcass in 17 minutes.

Around 2 percent of lizard species, including many iguanids, are herbivores. Adults of these species eat plant parts like flowers, leaves, stems and fruit, while juveniles eat more insects. Plant parts can be hard to digest, and, as they get closer to adulthood, juvenile iguanas eat faeces from adults to acquire the microflora necessary for their transition to a plant-based diet. Perhaps the most herbivorous species is the marine iguana which dives to forage for algae, kelp and other marine plants. Some non-herbivorous species supplement their insect diet with fruit, which is easily digested.

Lizards have a variety of antipredator adaptations, including running and climbing, venom, camouflage, tail autotomy, and reflex bleeding.

Lizards exploit a variety of different camouflage methods. Many lizards are disruptively patterned. In some species, such as Aegean wall lizards, individuals vary in colour, and select rocks which best match their own colour to minimise the risk of being detected by predators. The Moorish gecko is able to change colour for camouflage: when a light-coloured gecko is placed on a dark surface, it darkens within an hour to match the environment. The chameleons in general use their ability to change their coloration for signalling rather than camouflage, but some species such as Smith's dwarf chameleon do use active colour change for camouflage purposes.
The flat-tail horned lizard's body is coloured like its desert background, and is flattened and fringed with white scales to minimise its shadow.

Many lizards, including geckos and skinks, are capable of shedding their tails (autotomy). The detached tail, sometimes brilliantly coloured, continues to writhe after detaching, distracting the predator's attention from the fleeing prey. Lizards partially regenerate their tails over a period of weeks. Some 326 genes are involved in regenerating lizard tails. The fish-scale gecko "Geckolepis megalepis " sheds patches of skin and scales if grabbed.

Many lizards attempt to escape from danger by running to a place of safety; for example, wall lizards can run up walls and hide in holes or cracks. Horned lizards adopt differing defences for specific predators. They may play dead to deceive a predator that has caught them; attempt to outrun the rattlesnake, which does not pursue prey; but stay still, relying on their cryptic coloration, for "Masticophis" whip snakes which can catch even swift prey. If caught, some species such as the greater short-horned lizard puff themselves up, making their bodies hard for a narrow-mouthed predator like a whip snake to swallow. Finally, horned lizards can squirt blood at cat and dog predators from a pouch beneath its eyes, to a distance of about ; the blood tastes foul to these attackers.

The earliest known fossil remains of a lizard belong to the iguanian species "Tikiguania estesi", found in the Tiki Formation of India, which dates to the Carnian stage of the Triassic period, about 220 million years ago. However, doubt has been raised over the age of "Tikiguania" because it is almost indistinguishable from modern agamid lizards. The "Tikiguania" remains may instead be late Tertiary or Quaternary in age, having been washed into much older Triassic sediments. Lizards are most closely related to the Rhynchocephalia, which appeared in the Late Triassic, so the earliest lizards probably appeared at that time. Mitochondrial phylogenetics suggest that the first lizards evolved in the late Permian. It had been thought on the basis of morphological data that iguanid lizards diverged from other squamates very early on, but molecular evidence contradicts this.

Mosasaurs probably evolved from an extinct group of aquatic lizards known as aigialosaurs in the Early Cretaceous. Dolichosauridae is a family of Late Cretaceous aquatic varanoid lizards closely related to the mosasaurs.

The position of the lizards and other Squamata among the reptiles was studied using fossil evidence by Rainer Schoch and Hans-Dieter Sues in 2015. Lizards form about 60% of the extant non-avian reptiles.
Both the snakes and the Amphisbaenia (worm lizards) are clades deep within the Squamata (the smallest clade that contains all the lizards), so "lizard" is paraphyletic.
The cladogram is based on genomic analysis by Wiens and colleagues in 2012 and 2016. Excluded taxa are shown in upper case on the cladogram.

In the 13th century, lizards were recognized in Europe as part of a broad category of "reptiles" that consisted of a miscellany of egg-laying creatures, including "snakes, various fantastic monsters, […], assorted amphibians, and worms", as recorded by Vincent of Beauvais in his "Mirror of Nature". The seventeenth century saw changes in this loose description. The name Sauria was coined by James Macartney (1802); it was the Latinisation of the French name "Sauriens", coined by Alexandre Brongniart (1800) for an order of reptiles in the classification proposed by the author, containing lizards and crocodilians, later discovered not to be each other's closest relatives. Later authors used the term "Sauria" in a more restricted sense, i.e. as a synonym of Lacertilia, a suborder of Squamata that includes all lizards but excludes snakes. This classification is rarely used today because Sauria so-defined is a paraphyletic group. It was defined as a clade by Jacques Gauthier, Arnold G. Kluge and Timothy Rowe (1988) as the group containing the most recent common ancestor of archosaurs and lepidosaurs (the groups containing crocodiles and lizards, as per Mcartney's original definition) and all its descendants. A different definition was formulated by Michael deBraga and Olivier Rieppel (1997), who defined Sauria as the clade containing the most recent common ancestor of Choristodera, Archosauromorpha, Lepidosauromorpha and all their descendants. However, these uses have not gained wide acceptance among specialists.
Suborder Lacertilia (Sauria) – (lizards) 

Lizards have frequently evolved convergently, with multiple groups independently developing similar morphology and ecological niches. "Anolis" ecomorphs have become a model system in evolutionary biology for studying convergence. Limbs have been lost or reduced independently over two dozen times across lizard evolution, including in the Anniellidae, Anguidae, Cordylidae, Dibamidae, Gymnophthalmidae, Pygopodidae, and Scincidae; snakes are just the most famous and species-rich group of Squamata to have followed this path.

Most lizard species are harmless to humans. Only the largest lizard species, the Komodo dragon, which reaches in length and weighs up to , has been known to stalk, attack, and, on occasion, kill humans. An eight-year-old Indonesian boy died from blood loss after an attack in 2007.

Numerous species of lizard are kept as pets, including bearded dragons, iguanas, anoles, and geckos (such as the popular leopard gecko).

Lizards appear in myths and folktales around the world. In Australian Aboriginal mythology, Tarrotarro, the lizard god, split the human race into male and female, and gave people the ability to express themselves in art. A lizard king named Mo'o features in Hawaii and other cultures in Polynesia. In the Amazon, the lizard is the king of beasts, while among the Bantu of Africa, the god Unkulunkulu sent a chameleon to tell humans they would live forever, but the chameleon was held up, and another lizard brought a different message, that the time of humanity was limited. A popular legend in Maharashtra tells the tale of how a common Indian monitor, with ropes attached, was used to scale the walls of the fort in the Battle of Sinhagad. In the Bhojpuri speaking region of India and Nepal, there is a belief among children that, on touching Skunk's tail three (or five) time with the shortest finger gives money. 

Green iguanas are eaten in Central America, where they are sometimes referred to as "chicken of the tree" after their habit of resting in trees and their supposedly chicken-like taste, while spiny-tailed lizards are eaten in Africa. In North Africa, "Uromastyx" species are considered "dhaab" or 'fish of the desert' and eaten by nomadic tribes.

Lizards such as the Gila monster produce toxins with medical applications. Gila toxin reduces plasma glucose; the substance is now synthesised for use in the anti-diabetes drug exenatide (Byetta). Another toxin from Gila monster saliva has been studied for use as an anti-Alzheimer's drug.

Lizards in many cultures share the symbolism of snakes, especially as an emblem of resurrection. This may have derived from their regular moulting. The motif of lizards on Christian candle holders probably alludes to the same symbolism.
According to Jack Tresidder, in Egypt and the Classical world they were beneficial emblems, linked with wisdom. In African, Aboriginal and Melanesian folklore they are linked to cultural heroes or ancestral figures.




</doc>
<doc id="18185" url="https://en.wikipedia.org/wiki?curid=18185" title="List of deists">
List of deists

This is a partial list of people who have been categorized as Deists, the belief in a deity based on natural religion only, or belief in religious truths discovered by people through a process of reasoning, independent of any revelation through scriptures or prophets. They have been selected for their influence on Deism, or for their fame in other areas.



</doc>
<doc id="18187" url="https://en.wikipedia.org/wiki?curid=18187" title="Book of Leviticus">
Book of Leviticus

The Book of Leviticus () is the third book of the Torah and of the Old Testament; scholars generally agree that it developed over a long period of time, reaching its present form during the Persian Period between 538–332 BC.

Most of its chapters (1–7, 11–27) consist of God's speeches to Moses, which God commands Moses to repeat to the Israelites. This takes place within the story of the Israelites' Exodus after they escaped Egypt and reached Mt. Sinai (Exodus 19:1). The Book of Exodus narrates how Moses led the Israelites in building the Tabernacle (Exodus 35–40) with God's instructions (Exodus 25–31). Then in Leviticus, God tells the Israelites and their priests how to make offerings in the Tabernacle and how to conduct themselves while camped around the holy tent sanctuary. Leviticus takes place during the month or month-and-a-half between the completion of the Tabernacle (Exodus 40:17) and the Israelites' departure from Sinai (Numbers 1:1, 10:11).

The instructions of Leviticus emphasize ritual, legal and moral practices rather than beliefs. Nevertheless, they reflect the world view of the creation story in Genesis 1 that God wishes to live with humans. The book teaches that faithful performance of the sanctuary rituals can make that possible, so long as the people avoid sin and impurity whenever possible. The rituals, especially the sin and guilt offerings, provide the means to gain forgiveness for sins (Leviticus 4–5) and purification from impurities (Leviticus 11–16) so that God can continue to live in the Tabernacle in the midst of the people.

The English name Leviticus comes from the Latin "Leviticus," which is in turn from the Greek Λευιτικόν, "Leuitikon", referring to the priestly tribe of the Israelites, “Levi.” The Greek expression is in turn a variant of the rabbinic Hebrew "torat kohanim", "law of priests", as many of its laws relate to priests.

In Hebrew the book is called "Vayikra" (), from the opening of the book, "va-yikra" "And He <nowiki>[</nowiki>God<nowiki>]</nowiki> called."

The outlines from commentaries are similar, though not identical; compare those of Wenham, Hartley, Milgrom, and Watts.

I. Laws on sacrifice (1:1–7:38)
II. Institution of the priesthood (8:1–10:20)
III. Uncleanliness and its treatment (11:1–15:33)
IV. Day of Atonement: purification of the tabernacle from the effects of uncleanliness and sin (ch. 16)

V. Prescriptions for practical holiness (the Holiness Code, chs. 17–26)
VI. Redemption of votive gifts (ch. 27)

Chapters 1–5 describe the various sacrifices from the sacrificers' point of view, although the priests are essential for handling the blood. Chapters 6–7 go over much the same ground, but from the point of view of the priest, who, as the one actually carrying out the sacrifice and dividing the "portions", needs to know how to do this. Sacrifices are between God, the priest, and the offerers, although in some cases the entire sacrifice is a single portion to God—i.e., burnt to ashes.

Chapters 8–10 describe how Moses consecrates Aaron and his sons as the first priests, the first sacrifices, and God's destruction of two of Aaron's sons for ritual offenses. The purpose is to underline the character of altar priesthood (i.e., those priests with power to offer sacrifices to God) as an Aaronite privilege, and the responsibilities and dangers of their position.

With sacrifice and priesthood established, chapters 11–15 instruct the lay people on purity (or cleanliness). Eating certain animals produces uncleanliness, as does giving birth; certain skin diseases (but not all) are unclean, as are certain conditions affecting walls and clothing (mildew and similar conditions); and genital discharges, including female menses and male gonorrhea, are unclean. The reasoning behind the food rules are obscure; for the rest the guiding principle seems to be that all these conditions involve a loss of "life force", usually but not always blood.

Leviticus 16 concerns the Day of Atonement. This is the only day on which the High Priest is to enter the holiest part of the sanctuary, the holy of holies. He is to sacrifice a bull for the sins of the priests, and a goat for the sins of the laypeople. The priest is to send a second goat into the desert to "Azazel", bearing the sins of the whole people. Azazel may be a wilderness-demon, but its identity is mysterious.

Chapters 17–26 are the Holiness code. It begins with a prohibition on all slaughter of animals outside the Temple, even for food, and then prohibits a long list of sexual contacts and also child sacrifice. The "holiness" injunctions which give the code its name begin with the next section: there are penalties for the worship of Molech, consulting mediums and wizards, cursing one's parents and engaging in unlawful sex. Priests receive instruction on mourning rituals and acceptable bodily defects. The punishment for blasphemy is death, and there is the setting of rules for eating sacrifices; there is an explanation of the calendar, and there are rules for sabbatical and Jubilee years; there are rules for oil lamps and bread in the sanctuary; and there are rules for slavery. The code ends by telling the Israelites they must choose between the law and prosperity on the one hand, or, on the other, horrible punishments, the worst of which will be expulsion from the land.

Chapter 27 is a disparate and probably late addition telling about persons and things serving as dedication to the Lord and how one can redeem, instead of fulfill, vows.

The majority of scholars have concluded that the Pentateuch received its final form during the Persian period (538–332 BC). Nevertheless, Leviticus had a long period of growth before reaching that form.

The entire composition of the book of Leviticus is Priestly literature. Most scholars see chapters 1–16 (the Priestly code) and chapters 17–26 (the Holiness code) as the work of two related schools, but while the Holiness material employs the same technical terms as the Priestly code, it broadens their meaning from pure ritual to the theological and moral, turning the ritual of the Priestly code into a model for the relationship of Israel to God: as the tabernacle, which is apart from uncleanliness, becomes holy by the presence of the Lord, so He will dwell among Israel when Israel receives purification (becomes holy) and separates from other peoples. The ritual instructions in the Priestly code apparently grew from priests giving instruction and answering questions about ritual matters; the Holiness code (or H) used to be a separate document, later becoming part of Leviticus, but it seems better to think of the Holiness authors as editors who worked with the Priestly code and actually produced Leviticus as we now have it.

Many scholars argue that the rituals of Leviticus have a theological meaning concerning Israel's relationship with its God. Jacob Milgrom was especially influential in spreading this view. He maintained that the priestly regulations in Leviticus expressed a rational system of theological thought. The writers expected them to be put into practice in Israel's temple, so the rituals would express this theology as well, as well as ethical concern for the poor. Milgrom also argued that the book's purity regulations (chaps. 11–15) have a basis in ethical thinking. Many other interpreters have followed Milgrom in exploring the theological and ethical implications of Leviticus's regulations (e.g. Marx, Balentine), though some have questioned how systematic they really are. Ritual, therefore, is not taking a series of actions for their own sake, but a means of maintaining the relationship between God, the world, and humankind.

The main function of the priests is service at the altar, and only the sons of Aaron are priests in the full sense. (Ezekiel also distinguishes between altar-priests and lower Levites, but in Ezekiel the altar-priests are sons of Zadok instead of sons of Aaron; many scholars see this as a remnant of struggles between different priestly factions in First Temple times, finding resolution by the Second Temple into a hierarchy of Aaronite altar-priests and lower-level Levites, including singers, gatekeepers and the like).

In chapter 10, God kills Nadab and Abihu, the oldest sons of Aaron, for offering "strange incense". Aaron has two sons left. Commentators have read various messages in the incident: a reflection of struggles between priestly factions in the post–Exilic period (Gerstenberger); or a warning against offering incense outside the Temple, where there might be the risk of invoking strange gods (Milgrom). In any case, there has been a pollution of the sanctuary by the bodies of the two dead priests, leading into the next theme, holiness.

Ritual purity is essential for an Israelite to be able to approach Yahweh and remain part of the community. Uncleanliness threatens holiness; Chapters 11–15 review the various causes of uncleanliness and describe the rituals which will restore cleanliness; one is to maintain cleanliness through observation of the rules on sexual behaviour, family relations, land ownership, worship, sacrifice, and observance of holy days.

Yahweh dwells with Israel in the holy of holies. All of the priestly ritual focuses on Yahweh and the construction and maintenance of a holy space, but sin generates impurity, as do everyday events such as childbirth and menstruation; impurity pollutes the holy dwelling place. Failure to ritually purify the sacred space could result in God leaving, which would be disastrous.

Through sacrifice, the priest "makes atonement" for sin and the offerer receives forgiveness (but only if God accepts the sacrifice—forgiveness comes only from God). Atonement rituals involve the pouring or sprinkling of blood as the symbol of the life of the victim: the blood has the power to wipe out or absorb the sin. The two-part division of the book structurally reflects the role of atonement: chapters 1–16 call for the establishment of the institution for atonement, and chapters 17–27 call for the life of the atoned community in holiness.

The consistent theme of chapters 17–26 is in the repetition of the phrase, "Be holy, for I the Lord your God am holy." Holiness in ancient Israel had a different meaning than in contemporary usage: it might have been regarded as the "god-ness" of God, an invisible but physical and potentially dangerous force. Specific objects, or even days, can be holy, but they derive holiness from being connected with God—the seventh day, the tabernacle, and the priests all derive their holiness from God. As a result, Israel had to maintain its own holiness in order to live safely alongside God.

The need for holiness is for the possession of the Promised Land (Canaan), where the Jews will become a holy people: "You shall not do as they do in the land of Egypt where you dwelt, and you shall not do as they do in the land of Canaan to which I am bringing you...You shall do my ordinances and keep my statutes...I am the Lord, your God" (ch. 18:3).

Leviticus, as part of the Torah, became the law book of Jerusalem's Second Temple as well as of the Samaritan temple. Evidence of its influence is evident among the Dead Sea Scrolls, which included fragments of seventeen manuscripts of Leviticus dating from the third to the first centuries BC. Many other Qumran scrolls cite the book, especially the Temple Scroll and 4QMMT.

Jews and Christians have not observed Leviticus's instructions for animal offerings since the first century AD. Because of the destruction of the temple in Jerusalem in 70 AD, Jewish worship has focused on prayer and the study of Torah. Nevertheless, Leviticus constitutes a major source of Jewish law and is traditionally the first book children learn in the Rabbinic system of education. There are two main Midrashim on Leviticus—the halakhic one (Sifra) and a more aggadic one (Vayikra Rabbah).

The New Testament, particularly the Epistle to the Hebrews, uses ideas and images from Leviticus to describe Christ as the high priest who offers his own blood as a sin offering. Therefore, Christians do not make animal offerings either, as Gordon Wenham summarized: "With the death of Christ the only sufficient 'burnt offering' was offered once and for all, and therefore the animal sacrifices which foreshadowed Christ's sacrifice were made obsolete."

Christians generally have the view that the New Covenant supersedes (i.e., replaces) the Old Testament's ritual laws, which includes many of the rules in Leviticus. Christians therefore have usually not observed Leviticus' rules regarding diet, purity, and agriculture. Christian teachings have differed, however, as to where to draw the line between ritual and moral regulations. 

In "Homilies on Leviticus" Origen expounds on the qualities of priests: to be perfect in everything, strict, wise and to examine themselves individually, forgive sins, and convert sinners (by words and by doctrine).





Online versions of Leviticus:


Related article:

Brief introduction


</doc>
<doc id="18188" url="https://en.wikipedia.org/wiki?curid=18188" title="L. Frank Baum">
L. Frank Baum

His works anticipated such century-later commonplaces as television, augmented reality, laptop computers ("The Master Key"), wireless telephones ("Tik-Tok of Oz"), women in high-risk and action-heavy occupations ("Mary Louise in the Country"), and the ubiquity of advertising on clothing ("Aunt Jane's Nieces at Work"). 

Baum was born in Chittenango, New York, in 1856 into a devout Methodist family. He had German, Scots-Irish and English ancestry. He was the seventh of nine children of Cynthia Ann (née Stanton) and Benjamin Ward Baum, only five of whom survived into adulthood. "Lyman" was the name of his father's brother, but he always disliked it and preferred his middle name "Frank".

His father succeeded in many businesses, including barrel-making, oil drilling in Pennsylvania, and real estate. Baum grew up on his parents' expansive estate called Rose Lawn, which he fondly recalled as a sort of paradise. Rose Lawn was located in Mattydale, New York. Frank was a sickly, dreamy child, tutored at home with his siblings. From the age of 12, he spent two miserable years at Peekskill Military Academy but, after being severely disciplined for daydreaming, he had a possibly psychogenic heart attack and was allowed to return home.

Baum started writing early in life, possibly prompted by his father buying him a cheap printing press. He had always been close to his younger brother Henry (Harry) Clay Baum, who helped in the production of "The Rose Lawn Home Journal". The brothers published several issues of the journal, including advertisements from local businesses, which they gave to family and friends for free. By the age of 17, Baum established a second amateur journal called "The Stamp Collector", printed an 11-page pamphlet called "Baum's Complete Stamp Dealers' Directory", and started a stamp dealership with friends.

At 20, Baum took on the national craze of breeding fancy poultry. He specialized in raising the Hamburg chicken. In March 1880, he established a monthly trade journal, "The Poultry Record", and in 1886, when Baum was 30 years old, his first book was published: "The Book of the Hamburgs: A Brief Treatise upon the Mating, Rearing, and Management of the Different Varieties of Hamburgs".

Baum had a flair for being the spotlight of fun in the household, including during times of financial difficulties. His selling of fireworks made the Fourth of July memorable. His skyrockets, Roman candles, and fireworks filled the sky, while many people around the neighborhood would gather in front of the house to watch the displays. Christmas was even more festive. Baum dressed as Santa Claus for the family. His father would place the Christmas tree behind a curtain in the front parlor so that Baum could talk to everyone while he decorated the tree without people managing to see him. He maintained this tradition all his life.

Baum embarked on his lifetime infatuation—and wavering financial success—with the theater. A local theatrical company duped him into replenishing their stock of costumes on the promise of leading roles coming his way. Disillusioned, Baum left the theater — temporarily — and went to work as a clerk in his brother-in-law's dry goods company in Syracuse. This experience may have influenced his story "The Suicide of Kiaros", first published in the literary journal "The White Elephant". A fellow clerk one day was found locked in a store room dead, probably from suicide.

Baum could never stay away long from the stage. He performed in plays under the stage names of Louis F. Baum and George Brooks. In 1880, his father built him a theater in Richburg, New York, and Baum set about writing plays and gathering a company to act in them. "The Maid of Arran" proved a modest success, a melodrama with songs based on William Black's novel "A Princess of Thule". Baum wrote the play and composed songs for it (making it a prototypical musical, as its songs relate to the narrative), and acted in the leading role. His aunt Katharine Gray played his character's aunt. She was the founder of Syracuse Oratory School, and Baum advertised his services in her catalog to teach theater, including stage business, play writing, directing, translating (French, German, and Italian), revision, and operettas.

On November 9, 1882, Baum married Maud Gage, a daughter of Matilda Joslyn Gage, a famous women's suffrage and feminist activist. While Baum was touring with "The Maid of Arran", the theater in Richburg caught fire during a production of Baum's ironically titled parlor drama "Matches", destroying the theater as well as the only known copies of many of Baum's scripts, including "Matches", as well as costumes.

In July 1888, Baum and his wife moved to Aberdeen, Dakota Territory where he opened a store called "Baum's Bazaar". His habit of giving out wares on credit led to the eventual bankrupting of the store, so Baum turned to editing the local newspaper "The Aberdeen Saturday Pioneer" where he wrote the column "Our Landlady". Following the death of Sitting Bull at the hands of Indian agency police, Baum urged the wholesale extermination of all America's native peoples in a column that he wrote on December 20, 1890 (full text below). On January 3, 1891 he returned to the subject in an editorial response to the Wounded Knee Massacre:

The Pioneer has before declared that our only safety depends upon the total extirmination of the Indians. Having wronged them for centuries, we had better, in order to protect our civilization, follow it up by one more wrong and wipe these untamed and untamable creatures from the face of the earth.

Baum's description of Kansas in "The Wonderful Wizard of Oz" is based on his experiences in drought-ridden South Dakota. During much of this time, Matilda Joslyn Gage was living in the Baum household. While Baum was in South Dakota, he sang in a quartet which included James Kyle, who became one of the first Populist (People's Party) Senators in the U.S.

Baum's newspaper failed in 1891, and he, Maud, and their four sons moved to the Humboldt Park section of Chicago, where Baum took a job reporting for the "Evening Post". Beginning in 1897, he founded and edited a magazine called "The Show Window", later known as the "Merchants Record and Show Window", which focused on store window displays, retail strategies and visual merchandising. The major department stores of the time created elaborate Christmastime fantasies, using clockwork mechanisms that made people and animals appear to move. The former "Show Window" magazine is still currently in operation, now known as "VMSD" magazine (visual merchandising + store design), based in Cincinnati. In 1900, Baum published a book about window displays in which he stressed the importance of mannequins in drawing customers. He also had to work as a traveling salesman.

In 1897, he wrote and published "Mother Goose in Prose", a collection of Mother Goose rhymes written as prose stories and illustrated by Maxfield Parrish. "Mother Goose" was a moderate success and allowed Baum to quit his sales job (which had had a negative impact on his health). In 1899, Baum partnered with illustrator W. W. Denslow to publish "Father Goose, His Book", a collection of nonsense poetry. The book was a success, becoming the best-selling children's book of the year.

In 1900, Baum and Denslow (with whom he shared the copyright) published "The Wonderful Wizard of Oz" to much critical acclaim and financial success. The book was the best-selling children's book for two years after its initial publication. Baum went on to write thirteen more novels based on the places and people of the Land of Oz.

Two years after "Wizard" publication, Baum and Denslow teamed up with composer Paul Tietjens and director Julian Mitchell to produce a musical stage version of the book under Fred R. Hamlin. Baum and Tietjens had worked on a musical of "The Wonderful Wizard of Oz" in 1901 and based closely upon the book, but it was rejected. This stage version opened in Chicago in 1902 (the first to use the shortened title "The Wizard of Oz"), then ran on Broadway for 293 stage nights from January to October 1903. It returned to Broadway in 1904, where it played from March to May and again from November to December. It successfully toured the United States with much of the same cast, as was done in those days, until 1911, and then became available for amateur use. The stage version starred Anna Laughlin as Dorothy Gale, alongside David C. Montgomery and Fred Stone as the Tin Woodman and Scarecrow respectively, which shot the pair to instant fame.

The stage version differed quite a bit from the book, and was aimed primarily at adults. Toto was replaced with Imogene the Cow, and Tryxie Tryfle (a waitress) and Pastoria (a streetcar operator) were added as fellow cyclone victims. The Wicked Witch of the West was eliminated entirely in the script, and the plot became about how the four friends were allied with the usurping Wizard and were hunted as traitors to Pastoria II, the rightful King of Oz. It is unclear how much control or influence Baum had on the script; it appears that many of the changes were written by Baum against his wishes due to contractual requirements with Hamlin. Jokes in the script, mostly written by Glen MacDonough, called for explicit references to President Theodore Roosevelt, Senator Mark Hanna, Rev. Andrew Danquer, and oil magnate John D. Rockefeller. Although use of the script was rather free-form, the line about Hanna was ordered dropped as soon as Hamlin got word of his death in 1904.

Beginning with the success of the stage version, most subsequent versions of the story, including newer editions of the novel, have been titled "The Wizard of Oz", rather than using the full, original title. In more recent years, restoring the full title has become increasingly common, particularly to distinguish the novel from the Hollywood film.

Baum wrote a new Oz book, "The Marvelous Land of Oz", with a view to making it into a stage production, which was titled "The Woggle-Bug", but Montgomery and Stone balked at appearing when the original was still running. The Scarecrow and Tin Woodman were then omitted from this adaptation, which was seen as a self-rip-off by critics and proved to be a major flop before it could reach Broadway. He also worked for years on a musical version of "Ozma of Oz", which eventually became "The Tik-Tok Man of Oz". This did fairly well in Los Angeles, but not well enough to convince producer Oliver Morosco to mount a production in New York. He also began a stage version of "The Patchwork Girl of Oz", but this was ultimately realized as a film".

With the success of "Wizard" on page and stage, Baum and Denslow hoped for further success and published "Dot and Tot of Merryland" in 1901. The book was one of Baum's weakest, and its failure further strained his faltering relationship with Denslow. It was their last collaboration. Baum worked primarily with John R. Neill on his fantasy work beginning in 1904, but Baum met Neill few times (all before he moved to California) and often found Neill's art not humorous enough for his liking. He was particularly offended when Neill published "The Oz Toy Book: Cut-outs for the Kiddies" without authorization.

Baum reportedly designed the chandeliers in the Crown Room of the Hotel del Coronado; however, that attribution has yet to be corroborated. Several times during the development of the Oz series, Baum declared that he had written his last Oz book and devoted himself to other works of fantasy fiction based in other magical lands, including "The Life and Adventures of Santa Claus" and "Queen Zixi of Ix". However, he returned to the series each time, persuaded by popular demand, letters from children, and the failure of his new books. Even so, his other works remained very popular after his death, with "The Master Key" appearing on "St. Nicholas Magazine"'s survey of readers' favorite books well into the 1920s.

In 1905, Baum declared plans for an Oz amusement park. In an interview, he mentioned buying Pedloe Island off the coast of California to turn it into an Oz park. However, there is no evidence that he purchased such an island, and no one has ever been able to find any island whose name even resembles Pedloe in that area. Nevertheless, Baum stated to the press that he had discovered a Pedloe Island off the coast of California and that he had purchased it to be "the Marvelous Land of Oz," intending it to be "a fairy paradise for children." Eleven year old Dorothy Talbot of San Francisco was reported to be ascendant to the throne on March 1, 1906, when the Palace of Oz was expected to be completed. Baum planned to live on the island, with administrative duties handled by the princess and her all-child advisers. Plans included statues of the Scarecrow, Tin Woodman, Jack Pumpkinhead, and H.M. Woggle-Bug, T.E. Baum abandoned his Oz park project after the failure of "The Woggle-Bug", which was playing at the Garrick Theatre in 1905.
Because of his lifelong love of theatre, he financed elaborate musicals, often to his financial detriment. One of Baum's worst financial endeavors was his "The Fairylogue and Radio-Plays" (1908), which combined a slideshow, film, and live actors with a lecture by Baum as if he were giving a travelogue to Oz. However, Baum ran into trouble and could not pay his debts to the company who produced the films. He did not get back to a stable financial situation for several years, after he sold the royalty rights to many of his earlier works, including "The Wonderful Wizard of Oz". This resulted in the M.A. Donahue Company publishing cheap editions of his early works with advertising which purported that Baum's newer output was inferior to the less expensive books that they were releasing. He claimed bankruptcy in August 1911 . However, Baum had shrewdly transferred most of his property into Maud's name, except for his clothing, his typewriter, and his library (mostly of children's books, such as the fairy tales of Andrew Lang, whose portrait he kept in his study)—all of which, he successfully argued, were essential to his occupation. Maud handled the finances anyway, and thus Baum lost much less than he could have.

Baum made use of several pseudonyms for some of his other non-Oz books. They include:

Baum also anonymously wrote "The Last Egyptian: A Romance of the Nile". He continued theatrical work with Harry Marston Haldeman's men's social group The Uplifters, for which he wrote several plays for various celebrations. He also wrote the group's parodic by-laws. The group also included Will Rogers, but was proud to have had Baum as a member and posthumously revived many of his works despite their ephemeral intent. Many of these play's titles are known, but only "The Uplift of Lucifer" is known to survive (it was published in a limited edition in the 1960s). Prior to that, his last produced play was "The Tik-Tok Man of Oz" (based on "Ozma of Oz" and the basis for "Tik-Tok of Oz"), a modest success in Hollywood that producer Oliver Morosco decided did not do well enough to take to Broadway. Morosco, incidentally, quickly turned to film production, as did Baum.

In 1914, Baum started his own film production company The Oz Film Manufacturing Company, which came as an outgrowth of the Uplifters. He served as its president and principal producer and screenwriter. The rest of the board consisted of Louis F. Gottschalk, Harry Marston Haldeman, and Clarence R. Rundel. The films were directed by J. Farrell MacDonald, with casts that included Violet MacMillan, Vivian Reed, Mildred Harris, Juanita Hansen, Pierre Couderc, Mai Welles, Louise Emmons, J. Charles Haydon, and early appearances by Harold Lloyd and Hal Roach. Silent film actor Richard Rosson appeared in one of the films (Rosson's younger brother Harold Rosson was the cinematographer on "The Wizard of Oz", released in 1939). After little success probing the unrealized children's film market, Baum acknowledged his authorship of "The Last Egyptian" and made a film of it (portions of which are included in "Decasia"), but the Oz name had become box office poison for the time being, and even a name change to Dramatic Feature Films and transfer of ownership to Frank Joslyn Baum did not help. Baum invested none of his own money in the venture, unlike "The Fairylogue and Radio-Plays", but the stress probably took its toll on his health.

On May 5, 1919, Baum suffered a stroke. The following day he slipped into a coma but briefly awoke and spoke his last words to his wife, "Now we can cross the Shifting Sands." Frank died on May 6, 1919. He was buried in Glendale's Forest Lawn Memorial Park Cemetery.

His final Oz book, "Glinda of Oz", was published on July 10, 1920, a year after his death. The Oz series was continued long after his death by other authors, notably Ruth Plumly Thompson, who wrote an additional twenty-one Oz books.

Baum's avowed intentions with the Oz books and his other fairy tales was to retell tales such as those which are found in the works of the Brothers Grimm and Hans Christian Andersen, make them in an American vein, update them, avoid stereotypical characters such as dwarfs or genies, and remove the association of violence and moral teachings. His first Oz books contained a fair amount of violence, but it decreased as the series progressed; in "The Emerald City of Oz", Ozma objects to the use of violence, even to the use of violence against the Nomes who threaten Oz with invasion. His introduction is often cited as the beginning of the sanitization of children's stories, although he did not do a great deal more than eliminate harsh moral lessons.

Another traditional element that Baum intentionally omitted was the emphasis on romance. He considered romantic love to be uninteresting to young children, as well as largely incomprehensible. In "The Wonderful Wizard of Oz", the only element of romance lay in the background of the Tin Woodman and his love for Nimmie Amee, which explains his condition and it does not otherwise affect the tale, and that of Gayelette and the enchantment of the Winged monkeys. The only other stories with such elements were "The Scarecrow of Oz" and "Tik-Tok of Oz", both based on dramatizations, which Baum regarded warily until his readers accepted them.

Sally Roesch Wagner of The Matilda Joslyn Gage Foundation has published a pamphlet titled "The Wonderful Mother of Oz" describing how Matilda Gage's feminist politics were sympathetically channeled by Baum into his Oz books. Much of the politics in the Republican "Aberdeen Saturday Pioneer" dealt with trying to convince the populace to vote for women's suffrage. Baum was the secretary of Aberdeen's Woman's Suffrage Club. Susan B. Anthony visited Aberdeen and stayed with the Baums. Nancy Tystad Koupal notes an apparent loss of interest in editorializing after Aberdeen failed to pass the bill for women's enfranchisement.

Some of Baum's contacts with suffragists of his day seem to have inspired much of his second Oz story "The Marvelous Land of Oz". In this story, General Jinjur leads the girls and women of Oz in a revolt, armed with knitting needles; they succeed and make the men do the household chores. Jinjur proves to be an incompetent ruler, but a female advocating gender equality is ultimately placed on the throne. His Edith Van Dyne stories depict girls and young women engaging in traditionally masculine activities, including the "Aunt Jane's Nieces", "The Flying Girl" and its sequel, and his girl sleuth Josie O'Gorman from The Bluebird Books.

During the period surrounding the 1890 Ghost Dance movement and Wounded Knee Massacre, Baum wrote two editorials about Native Americans for the "Aberdeen Saturday Pioneer" which have provoked controversy in recent times because of his assertion that the safety of white settlers depended on the wholesale genocide of American Indians. Sociologist Robert Venables has argued that Baum was not using sarcasm in the editorials.

The first piece was published on December 20, 1890, five days after the killing of the Lakota Sioux holy man, Sitting Bull. The piece opined that with Sitting Bull's death, "the nobility of the Redskin" had been extinguished, and that the safety of the frontier would not be established until there was "total annihilation" of the remaining Native Americans, who, he claimed, lived as "miserable wretches." Baum said that their extermination should not be regretted, and that that their elimination would "do justice to the manly characteristics" of the early Native Americans. 

Baum wrote a second editorial following the Wounded Knee Massacre on December 29, 1890, being published on January 3, 1891. Baum alleged that the weak leadership of General Nelson A. Miles over the Native Americans had led to a "terrible loss of blood" to American soldiers, in a "battle" which had been a disgrace to the Department of War. He found that the "disaster" could have easily been prevented with proper preparations. Baum reiterated that he believed, due to the history of mistreatment of Native Americans, that extermination of the "untamed and untamable" tribes was necessary to protect American settlers. Baum ended the editorial with the following anecdote: "An eastern contemporary, with a grain of wisdom in its wit, says that 'when the whites win a fight, it is a victory, and when the Indians win it, it is a massacre.'"

These two editorials have haunted his modern legacy. In 2006, two descendants of Baum apologized to the Sioux nation for any hurt that their ancestor had caused.

The short story "The Enchanted Buffalo" claims to be a legend of a tribe of bison, and states that a key element made it into legends of Native American tribes. Baum mentions his characters' distaste for a Hopi snake dance in "Aunt Jane's Nieces and Uncle John", but also deplores the horrible situation of Indian Reservations. "Aunt Jane's Nieces on the Ranch" has a hard-working Mexican present himself as an exception to counter Anglo stereotypes of Mexican laziness. Baum's mother-in-law and Woman's Suffrage leader Matilda Joslyn Gage had great influence over Baum's views. Gage was initiated into the Wolf Clan and admitted into the Iroquois Council of Matrons for her outspoken respect and sympathy for Native American people; it would seem unlikely that Baum could have harbored animosity for them in his mature years.

Numerous political references to the "Wizard" appeared early in the 20th century. Henry Littlefield, an upstate New York high school history teacher, wrote a scholarly article which was the first full-fledged interpretation of the novel as an extended political allegory of the politics and characters of the 1890s. Special attention was paid to the Populist metaphors and debates over silver and gold. Baum was a Republican and avid supporter of Women's Suffrage, and it is thought that he did not support the political ideals of either the Populist movement of 1890–1892 or the Bryanite-silver crusade of 1896–1900. He published a poem in support of William McKinley.

Since 1964, many scholars, economists, and historians have expanded on Littlefield's interpretation, pointing to multiple similarities between the characters (especially as depicted in Denslow's illustrations) and stock figures from editorial cartoons of the period. Littlefield himself wrote to "The New York Times" letters to the editor section spelling out that his theory had no basis in fact, but that his original point was "not to label Baum, or to lessen any of his magic, but rather, as a history teacher at Mount Vernon High School, to invest turn-of-the-century America with the imagery and wonder I have always found in his stories."

Baum's newspaper had addressed politics in the 1890s, and Denslow was an editorial cartoonist as well as an illustrator of children's books. A series of political references is included in the 1902 stage version, such as references by name to the President, to a powerful senator, and to John D. Rockefeller for providing the oil needed by the Tin Woodman. Scholars have found few political references in Baum's Oz books after 1902.

Baum himself was asked whether his stories had hidden meanings, but he always replied that they were written to "please children".

Baum was originally a Methodist, but he joined the Episcopal Church in Aberdeen to participate in community theatricals. Later, he and his wife were encouraged by Matilda Joslyn Gage to become members of the Theosophical Society in 1892. Baum's beliefs are often reflected in his writing. The only mention of a church in his Oz books is the porcelain one which the Cowardly Lion breaks in the Dainty China Country in "The Wonderful Wizard of Oz". The Baums sent their older sons to "Ethical Culture Sunday School" in Chicago, which taught morality, not religion.



1921's "The Royal Book of Oz" was posthumous attributed to Baum but was entirely the work of Ruth Plumly Thompson.





</doc>
<doc id="18189" url="https://en.wikipedia.org/wiki?curid=18189" title="Lake Ladoga">
Lake Ladoga

Lake Ladoga ( or ; [earlier in Finnish "Nevajärvi"]; ; ) is a freshwater lake located in the Republic of Karelia and Leningrad Oblast in northwestern Russia, in the vicinity of Saint Petersburg. 

It is the largest lake located entirely in Europe, the second largest lake after Baikal in Russia, and the 14th largest freshwater lake by area in the world. "Ladoga Lacus", a methane lake on Saturn's moon Titan, is named after the lake.

In one of Nestor's chronicles from the 12th century a lake called "the Great Nevo" is mentioned, a clear link to the Neva River and possibly further to Finnish "nevo" 'sea' or "neva" 'bog, quagmire'. 

Ancient Norse sagas and Hanseatic treaties both mention a city made of lakes named Old Norse "Aldeigja" or "Aldoga". Since the beginning of the 14th century this hydronym was commonly known as "Ladoga". According to T. N. Jackson, it can be taken "almost for granted that the name of Ladoga first referred to the river, then the city, and only then the lake". Therefore, he considers the primary hydronym Ladoga to originate in the eponymous inflow to the lower reaches of the Volkhov River whose early Finnic name was "Alodejoki" (corresponding to modern ) 'river of the lowlands'.

The Germanic toponym ("Aldeigja" ~ "Aldoga") was soon borrowed by the Slavic population and transformed by means of the Old East Slavic metathesis "ald- → lad-" to . The Old Norse intermediary word between Finnish and Old East Slavic word is fully supported by archeology, since the Scandinavians first appeared in Ladoga in the early 750s, that is, a couple of decades before the Slavs.

Other hypotheses about the origin of the name derive it from 'wave' and 'wavy', or from the Russian dialectal word алодь, meaning 'open lake, extensive water field'. Eugene Helimski by contrast, offers an etymology rooted in German. In his opinion, the primary name of the lake was 'old source', associated to the open sea, in contrast to the name of the Neva River (flowing from Lake Ladoga) which would derive from the German expression for 'the new'. Through the intermediate form "*Aldaugja", came about, referring to the city of Ladoga.

The lake has an average surface area of 17,891 km (excluding the islands). Its north-to-south length is 219 km and its average width is 83 km; the average depth is 51 m, although it reaches a maximum of 230 m in the north-western part. Basin area: 276,000 km, volume: 837 km (earlier estimated as 908 km). There are around 660 islands, with a total area of about 435 km. Ladoga is, on average, 5 m above sea level. Most of the islands, including the famous Valaam archipelago, Kilpola and Konevets, are situated in the northwest of the lake.

Separated from the Baltic Sea by the Karelian Isthmus, it drains into the Gulf of Finland via the Neva River.

Lake Ladoga is navigable, being a part of the Volga-Baltic Waterway connecting the Baltic Sea with the Volga River. The Ladoga Canal bypasses the lake in the south, connecting the Neva to the Svir.

The basin of Lake Ladoga includes about 50,000 lakes and 3,500 rivers longer than 10 km. About 85% of the water inflow is due to tributaries, 13% is due to precipitation, and 2% is due to underground waters.

Geologically, the Lake Ladoga depression is a graben and syncline structure of Proterozoic age (Precambrian). This "Ladoga–Pasha structure", as it known, hosts Jotnian sediments. During the Pleistocene glaciations the depression was partially stripped of its sedimentary rock fill by glacial overdeepening. During the Last Glacial Maximum, about 17,000 years BP, the lake served likely as a channel that concentrated ice of the Fennoscandian Ice Sheet into an ice stream that fed glacier lobes further east. 

Deglaciation following the Weichselian glaciation took place in the Lake Ladoga basin between 12,500 and 11,500 radiocarbon years BP. Lake Ladoga was initially part of the Baltic Ice Lake (70–80 m. above present sea level), a historical freshwater stage of Baltic Sea. It is possible, though not certain, that Ladoga was isolated from it during regression of the subsequent Yoldia Sea brackish stage (10,200–9,500 BP). The isolation threshold should be at Heinjoki to the east of Vyborg, where the Baltic Sea and Ladoga were connected by a strait or a river outlet at least until the formation of the River Neva, and possibly even much later, until the 12th century AD or so.

At 9,500 BP, Lake Onega, previously draining into the White Sea, started emptying into Ladoga via the River Svir. Between 9,500 and 9,100 BP, during the transgression of Ancylus Lake, the next freshwater stage of the Baltic, Ladoga certainly became part of it, even if they hadn't been connected immediately before. During the Ancylus Lake subsequent regression, around 8,800 BP Ladoga became isolated.

Ladoga slowly transgressed in its southern part due to uplift of the Baltic Shield in the north. It has been hypothesized, but not proven, that waters of the Litorina Sea, the next brackish-water stage of the Baltic, occasionally invaded Ladoga between 7,000 and 5,000 BP. Around 5,000 BP the waters of the Saimaa Lake penetrated Salpausselkä and formed a new outlet, River Vuoksi, entering Lake Ladoga in the northwestern corner and raising its level by 1–2 m.

The River Neva originated when the Ladoga waters at last broke through the threshold at Porogi into the lower portions of Izhora River, then a tributary of the Gulf of Finland, between 4,000 and 2,000 BP. Dating of some sediments in the northwestern part of Lake Ladoga suggests it happened at 3,100 radiocarbon years BP (3,410–3,250 calendar years BP).
The Ladoga is rich with fish. 48 forms (species and infra specific taxa) of fish have been encountered in the lake, including roach, carp bream, zander, European perch, ruffe, endemic variety of smelt, two varieties of "Coregonus albula" (vendace), eight varieties of "Coregonus lavaretus", a number of other Salmonidae as well as, albeit rarely, endangered Atlantic sturgeon (formerly confused with European sea sturgeon). Commercial fishing was once a major industry but has been hurt by overfishing. After the war, between 1945–1954, the total annual catch increased and reached a maximum of 4,900 tonnes. However, unbalanced fishery led to the drastic decrease of catch in 1955–1963, sometimes to 1,600 tonnes per year. Trawling has been forbidden in Lake Ladoga since 1956 and some other restrictions were imposed. The situation gradually recovered, and in 1971–1990 the catch ranged between 4,900 and 6,900 tonnes per year, about the same level as the total catch in 1938. Fish farms and recreational fishing are developing. 

It has its own endemic ringed seal subspecies known as the Ladoga seal.

Since the beginning of the 1960s Ladoga has become considerably eutrophicated.

Nizhnesvirsky Natural Reserve is situated along the shore of Lake Ladoga immediately to the north of the mouth of the River Svir.

The Ladoga has a population of Arctic char that is genetically close to the chars of Lake Sommen and Lake Vättern in southern Sweden.

In the Middle Ages, the lake formed a vital part of the trade route from the Varangians to the Eastern Roman Empire, with the Norse emporium at Staraya Ladoga defending the mouth of the Volkhov since the 8th century. In the course of the Swedish–Novgorodian Wars, the area was disputed between the Novgorod Republic and Sweden. In the early 14th century, the fortresses of Korela (Kexholm) and Oreshek (Nöteborg) were established along the banks of the lake.

The ancient Valaam Monastery was founded on the island of Valaam, the largest in Lake Ladoga, abandoned between 1611–1715, magnificently restored in the 18th century, and evacuated to Finland during the Winter War in 1940. In 1989 the monastic activities in the Valaam were resumed. Other historic cloisters in the vicinity are the Konevets Monastery, which sits on the Konevets island, and the Alexander-Svirsky Monastery, which preserves fine samples of medieval Muscovite architecture.

During the Ingrian War, a fraction of the Ladoga coast was occupied by Sweden. In 1617, by the Treaty of Stolbovo, the northern and western coast was ceded by Russia to Sweden. In 1721, after the Great Northern War, it was restitutioned to Russia by the Treaty of Nystad. In the 18th century, the Ladoga Canal was built to bypass the lake which was prone to winds and storms that destroyed hundreds of cargo ships.

Later, from around 1812–1940 the lake was shared between Finland and Russia. According to the conditions of the 1920 Tartu Peace Treaty militarization of the lake was severely restricted. However, both Soviet Russia and Finland had flotillas in Ladoga (see also Finnish Ladoga Naval Detachment). After the Winter War (1939–40) according to the Moscow Peace Treaty, Ladoga, previously shared with Finland, became an internal basin of the Soviet Union.

During the Continuation War (1941–44) not only Finnish and Soviet, but also German and Italian vessels operated there (see also Naval Detachment K and Regia Marina). Under these circumstances, during much of the Siege of Leningrad (1941–44), Lake Ladoga provided the only access to the besieged city as a section of the eastern shore remained in Soviet hands. Supplies were transported into Leningrad with trucks on winter roads over the ice, the "Road of Life", and by boat in the summer. After World War II, Finland lost the Karelia region again to the USSR, and all Finnish citizens were evacuated from the ceded territory. Ladoga became an internal Soviet basin once again. The northern shore, Ladoga Karelia with the town of Sortavala, is now part of the Republic of Karelia. The western shore, Karelian Isthmus, became part of Leningrad Oblast.





</doc>
<doc id="18190" url="https://en.wikipedia.org/wiki?curid=18190" title="Language family">
Language family

A language family is a group of languages related through descent from a common "ancestral language" or "parental language", called the proto-language of that family. The term "family" reflects the tree model of language origination in historical linguistics, which makes use of a metaphor comparing languages to people in a biological family tree, or in a subsequent modification, to species in a phylogenetic tree of evolutionary taxonomy. Linguists therefore describe the "daughter languages" within a language family as being "genetically related".

According to "Ethnologue" there are 7,117 living human languages distributed in 142 different language families. A "living language" is simply one that is currently used as the primary form of communication of a group of people. There are also many dead languages, or languages which have no native speakers living, and extinct languages, which have no native speakers and no descendant languages. Finally, there are some languages that are insufficiently studied to be classified, and probably some which are not even known to exist outside their respective speech communities.

Membership of languages in a language family is established by research in comparative linguistics. Sister languages are said to descend "genetically" from a common ancestor. Speakers of a language family belong to a common speech community. The divergence of a proto-language into daughter languages typically occurs through geographical separation, with the original speech community gradually evolving into distinct linguistic units. Individuals belonging to other speech communities may also adopt languages from a different language family through the language shift process.

Genealogically related languages present shared retentions; that is, features of the proto-language (or reflexes of such features) that cannot be explained by chance or borrowing (convergence). Membership in a branch or group within a language family is established by shared innovations; that is, common features of those languages that are not found in the common ancestor of the entire family. For example, Germanic languages are "Germanic" in that they share vocabulary and grammatical features that are not believed to have been present in the Proto-Indo-European language. These features are believed to be innovations that took place in Proto-Germanic, a descendant of Proto-Indo-European that was the source of all Germanic languages.

Language families can be divided into smaller phylogenetic units, conventionally referred to as "branches" of the family because the history of a language family is often represented as a tree diagram. A family is a monophyletic unit; all its members derive from a common ancestor, and all attested descendants of that ancestor are included in the family. (Thus, the term "family" is analogous to the biological term "clade".) 

Some taxonomists restrict the term "family" to a certain level, but there is little consensus in how to do so. Those who affix such labels also subdivide branches into "groups", and groups into "complexes". A top-level (i.e., the largest) family is often called a "phylum" or "stock". The closer the branches are to each other, the closer the languages will be related. This means if a branch off of a proto-language is 4 branches down and there is also a sister language to that fourth branch, then the two sister languages are more closely related to each other than to that common ancestral proto-language.

The term "macrofamily" or "superfamily" is sometimes applied to proposed groupings of language families whose status as phylogenetic units is generally considered to be unsubstantiated by accepted historical linguistic methods. For example, the Celtic, Germanic, Slavic, Italic, and Indo-Iranian language families are branches of a larger Indo-European language family. There is a remarkably similar pattern shown by the linguistic tree and the genetic tree of human ancestry 
that was verified statistically. Languages interpreted in terms of the putative phylogenetic tree of human languages are transmitted to a great extent vertically (by ancestry) as opposed to horizontally (by spatial diffusion).

Some close-knit language families, and many branches within larger families, take the form of dialect continua in which there are no clear-cut borders that make it possible to unequivocally identify, define, or count individual languages within the family. However, when the differences between the speech of different regions at the extremes of the continuum are so great that there is no mutual intelligibility between them, as occurs in Arabic, the continuum cannot meaningfully be seen as a single language. 

A speech variety may also be considered either a language or a dialect depending on social or political considerations. Thus, different sources, especially over time, can give wildly different numbers of languages within a certain family. Classifications of the Japonic family, for example, range from one language (a language isolate with dialects) to nearly twenty—until the classification of Ryukyuan as separate languages within a Japonic language family rather than dialects of Japanese, the Japanese language itself was considered a language isolate and therefore the only language in its family.

Most of the world's languages are known to be related to others. Those that have no known relatives (or for which family relationships are only tentatively proposed) are called language isolates, essentially language families consisting of a single language. An example is Basque. In general, it is assumed that language isolates have relatives or had relatives at some point in their history but at a time depth too great for linguistic comparison to recover them.

A language isolated in its own branch within a family, such as Albanian and Armenian within Indo-European, is often also called an isolate, but the meaning of the word "isolate" in such cases is usually clarified with a modifier. For instance, Albanian and Armenian may be referred to as an "Indo-European isolate". By contrast, so far as is known, the Basque language is an absolute isolate: it has not been shown to be related to any other language despite numerous attempts. Another well-known isolate is Mapudungun, the Mapuche language from the Araucanían language family in Chile. A language may be said to be an isolate currently but not historically if related but now extinct relatives are attested. The Aquitanian language, spoken in Roman times, may have been an ancestor of Basque, but it could also have been a sister language to the ancestor of Basque. In the latter case, Basque and Aquitanian would form a small family together. (Ancestors are not considered to be distinct members of a family.)

A proto-language can be thought of as a mother language (not to be confused with a mother tongue, which is one that a specific person has been exposed to from birth), being the root which all languages in the family stem from. The common ancestor of a language family is seldom known directly since most languages have a relatively short recorded history. However, it is possible to recover many features of a proto-language by applying the comparative method, a reconstructive procedure worked out by 19th century linguist August Schleicher. This can demonstrate the validity of many of the proposed families in the list of language families. For example, the reconstructible common ancestor of the Indo-European language family is called "Proto-Indo-European". Proto-Indo-European is not attested by written records and so is conjectured to have been spoken before the invention of writing.

Shared innovations, acquired by borrowing or other means, are not considered genetic and have no bearing with the language family concept. It has been asserted, for example, that many of the more striking features shared by Italic languages (Latin, Oscan, Umbrian, etc.) might well be "areal features". However, very similar-looking alterations in the systems of long vowels in the West Germanic languages greatly postdate any possible notion of a proto-language innovation (and cannot readily be regarded as "areal", either, since English and continental West Germanic were not a linguistic area). In a similar vein, there are many similar unique innovations in Germanic, Baltic and Slavic that are far more likely to be areal features than traceable to a common proto-language. But legitimate uncertainty about whether shared innovations are areal features, coincidence, or inheritance from a common ancestor, leads to disagreement over the proper subdivisions of any large language family.

A sprachbund is a geographic area having several languages that feature common linguistic structures. The similarities between those languages are caused by language contact, not by chance or common origin, and are not recognized as criteria that define a language family. An example of a sprachbund would be the Indian subcontinent.

The concept of language families is based on the historical observation that languages develop dialects, which over time may diverge into distinct languages. However, linguistic ancestry is less clear-cut than familiar biological ancestry, in which species do not crossbreed. It is more like the evolution of microbes, with extensive lateral gene transfer: Quite distantly related languages may affect each other through language contact, which in extreme cases may lead to languages with no single ancestor, whether they be creoles or mixed languages. In addition, a number of sign languages have developed in isolation and appear to have no relatives at all. Nonetheless, such cases are relatively rare and most well-attested languages can be unambiguously classified as belonging to one language family or another, even if this family's relation to other families is not known.



</doc>
<doc id="18194" url="https://en.wikipedia.org/wiki?curid=18194" title="Looe Island">
Looe Island

Looe Island (, meaning "island of the monk's enclosure"), also known as St George's Island, and historically St Michael's Island is a small island a mile from the mainland town of Looe off Cornwall, England.

According to local legend, Joseph of Arimathea landed here with the Christ Child. Some scholars, including Glyn Lewis, suggest the island could be Ictis, the location described by Diodorus Siculus as a centre for the tin trade in pre-Roman Britain.

The island is now owned and managed by the Cornwall Wildlife Trust charity where access is carefully managed for the benefit of wildlife and landing is only possible via the Cornwall Wildlife Trust authorized boatman. The waters around the island are a marine nature reserve and form part of the Looe Voluntary Marine Conservation Area (VMCA). First established in 1995, the Looe VCMA covers nearly 5 km of coastline and aims to protect the coastal and marine wildlife around Looe.

People have been living on Looe Island since the Iron Age. Evidence of early habitation includes pieces of Roman amphorae as well as stone boat anchors and Roman coins. A number of late prehistoric or Romano-British finds have been made in the vicinity of the island, including a large bronze ingot found by divers south of Looe Island, which has led a number of people to suggest the island is possibly Ictis, the tin trading island seen by Pytheas in the 4th century BC and recalled by Diodorus Siculus in the 1st century BC. A small hoard of eight late Roman coins was recovered in 2008. These coins were recovered from one of the shallow ditches forming a ‘pear shaped enclosure’ which encompassed the top of Looe Island and the later Christian chapel site. All eight coins date to the late 3rd or early 4th century AD.

In the Dark Ages, the island was used a seat of early Christian settlement. The child Jesus was believed to have visited the Island with his uncle, Joseph of Arimathea, who traded with the Cornish tin traders. Looe Island was already a place of pilgrimage for early Christians before the creation of this story and a small thatched roofed chapel was built there during this time.

In the later medieval period, the island came under the overall control of Glastonbury Abbey, with the Prior of Lammana being directly responsible for its governance; the island's chapel was under the care of two Benedictine monks until 1289 when the property was sold to a local landowner. The priory was replaced by a domestic chapel served by a secular priest until the Dissolution of the Monasteries in 1536 when it became property of the Crown. From the 13th to the 16th centuries it was known as St Michael's Island but after the dissolution of the monasteries, it was rededicated in 1594 as St George's Island.

Through the 17th and 18th centuries the island was used by smugglers to avoid the British Government's revenue cutters out of Plymouth and Falmouth. The Old Guildhall Museum in Looe hold information and research about the smuggling families of Looe Island and information is also available in the more recent publications about the island.

During the Second World War, Looe Island was for a time renamed as ‘H.M.S  St. George’, following the dropping of a probable parachute mine which resulted in a large crater in the summit. It was believed the island was mistaken for an Allied ship. The incident was recorded in The Cornish Times under the headline "‘H.M.S  St. George. Nazi  Airman’s  Direct Hit Off Looe –  Another “Success” for  the  Luftwaffe"’. The article continued "‘H.M.S St. George is still riding peacefully at  her anchorage in Looe Bay, after being bombed recently by a Nazi air-raider in what would seem to have been and attempt to sink her. Although St. George has occupied the same berth for millennia, and is as well-known to inhabitants and visitors to Looe as  the palms of their hands, no one has determined to what particular class of battleship she belongs, indeed all are  familiar with the shapely  hulk lying seaward of Hannafore as Looe Island  (or, cartographically St. Georges Island)’" .

In the 20th century, Looe island was owned (and inhabited) by two sisters, Babs and Evelyn Atkins, who wrote two books: "We Bought An Island" and its sequel "Tales From Our Cornish Island" . They chronicle the purchase of the island and what it was like to live there. Evelyn died in 1997 at the age of 87; Babs continued to live on the island until her death in 2004, at the age of 86. On her death, the island was bequeathed to the Cornwall Wildlife Trust; it will be preserved as a nature reserve in perpetuity. The adjoining islet, formerly known as Little Island, now renamed Trelawny Island and connected by a small bridge, was bequeathed by Miss Atkins back to the Trelawny family, who previously owned Looe Island from 1743 to 1921.

Situated in the English Channel, about one mile from East Looe in the direction of Polperro, it is about in area and a mile (1.6 km) in circumference. Its highest point is above sea level. Looe Island, like much of south west England, has a mild climate with frost and snow being rare.

The island is owned and managed by the Cornwall Wildlife Trust. This is a non-profit-making venture, the landing fees and other income being devoted to conserving the island's natural environment and providing facilities. The island is open during the summer to day visitors arriving by the Trust's boat. After a short welcome talk visitors are directed to the small visitor centre from where they can pick up a copy of the self-guided trail. Visitors have some two hours on the island and all trips are subject to tides and weather/sea state. While it is normally accessible only by the Cornwall Wildlife Trust's boat, at extremely low spring tides it is possible for the journey to be made by foot across the slippery, seaweed-covered rocky sea floor. However you have to remain on the beach and promptly head back to the mainland.

In 2008, Channel 4's archaeology series "Time Team" visited the island to carry out an investigation into its early Christian history. They excavated the sites of Christian chapels built on both the island and on the mainland opposite. During their dig they found the remains of a Benedictine chapel that was built in c.1139 by monks from Glastonbury Abbey, a reliquary, graves and the remains of much earlier Anglo-Romano places of worship built of wood with dating evidence suggesting use by Christians before the reign of Constantine the Great.

In 1994/95 Andrew Hugill composed Island Symphony, an electro-acoustic piece utilising sampled sounds sourced over the net plus recorded natural sounds from the island itself.





</doc>
<doc id="18195" url="https://en.wikipedia.org/wiki?curid=18195" title="LaTeX">
LaTeX

LaTeX ( or ), stylized within the system as LaTeX, is a software system for document preparation. When writing, the writer uses plain text as opposed to the formatted text found in "What You See Is What You Get" word processors like Microsoft Word, LibreOffice Writer and Apple Pages. The writer uses markup tagging conventions to define the general structure of a document (such as article, book, and letter), to stylise text throughout a document (such as bold and italics), and to add citations and cross-references. A TeX distribution such as TeX Live or MikTeX is used to produce an output file (such as PDF or DVI) suitable for printing or digital distribution.

LaTeX is widely used in academia for the communication and publication of scientific documents in many fields, including mathematics, statistics, computer science, engineering, physics, economics, linguistics, quantitative psychology, philosophy, and political science. It also has a prominent role in the preparation and publication of books and articles that contain complex multilingual materials, such as Sanskrit and Greek. LaTeX uses the TeX typesetting program for formatting its output, and is itself written in the TeX macro language.

LaTeX can be used as a standalone document preparation system, or as an intermediate format. In the latter role, for example, it is sometimes used as part of a pipeline for translating DocBook and other XML-based formats to PDF. The typesetting system offers programmable desktop publishing features and extensive facilities for automating most aspects of typesetting and desktop publishing, including numbering and cross-referencing of tables and figures, chapter and section headings, the inclusion of graphics, page layout, indexing and bibliographies.

Like TeX, LaTeX started as a writing tool for mathematicians and computer scientists, but even from early in its development, it has also been taken up by scholars who needed to write documents that include complex math expressions or non-Latin scripts, such as Arabic, Devanagari and Chinese.

LaTeX is intended to provide a high-level, descriptive markup language that accesses the power of TeX in an easier way for writers. In essence, TeX handles the layout side, while LaTeX handles the content side for document processing. LaTeX comprises a collection of TeX macros and a program to process LaTeX documents, and because the plain TeX formatting commands are elementary, it provides authors with ready-made commands for formatting and layout requirements such as chapter headings, footnotes, cross-references and bibliographies.

LaTeX was originally written in the early 1980s by Leslie Lamport at SRI International. The current version is LaTeX2e (stylised as LaTeX2ε), as of 1994. LaTeX is free software and is distributed under the LaTeX Project Public License (LPPL).

LaTeX attempts to follow the design philosophy of separating presentation from content, so that authors can focus on the content of what they are writing without attending simultaneously to its visual appearance. In preparing a LaTeX document, the author specifies the logical structure using simple, familiar concepts such as "chapter", "section", "table", "figure", etc., and lets the LaTeX system handle the formatting and layout of these structures. As a result, it encourages the separation of the layout from the content — while still allowing manual typesetting adjustments whenever needed. This concept is similar to the mechanism by which many word processors allow styles to be defined globally for an entire document, or the use of Cascading Style Sheets in styling HTML documents.

The LaTeX system is a markup language that handles typesetting and rendering, and can be arbitrarily extended by using the underlying macro language to develop custom macros such as new environments and commands. Such macros are often collected into "packages," which could then be made available to address some specific typesetting needs such as the formatting of complex mathematical expressions or graphics (e.g., the use of the codice_1 environment provided by the codice_2 package to produce aligned equations).

In order to create a document in LaTeX, you first write a file, say codice_3, using your preferred text editor. Then you give your codice_3 file as input to the TeX program (with the LaTeX macros loaded), which prompts TeX to write out a file suitable for onscreen viewing or printing. This write-format-preview cycle is one of the chief ways in which working with LaTeX differs from the What-You-See-Is-What-You-Get (WYSIWYG) style of document editing. It is similar to the code-compile-execute cycle known to computer programmers. Today, many LaTeX-aware editing programs make this cycle a simple matter through the pressing a single key, while showing the output preview on the screen beside the input window. Some online LaTeX editors even automatically refresh the preview, while other online tools provide incremental editing in-place, mixed in with the preview in a streamlined single window.

The example below shows the input to LaTeX and the corresponding output from the system:

Note how the equation for formula_1 (highlighted in the example code) was typeset by the markup:

where the square root is denoted by "codice_5", and the fractions by "codice_6".

The characters 'T', 'E', and 'X' in the name come from the Greek capital letters tau, epsilon, and chi, as the name of TeX derives from the ('skill', 'art', 'technique'); for this reason, TeX's creator Donald Knuth promotes its pronunciation as () (that is, with a voiceless velar fricative as in Modern Greek, similar to the ch in loch). Lamport remarks that "TeX is usually pronounced "tech", making "lah"-teck, lah-"teck", and "lay"-teck the logical choices; but language is not always logical, so "lay-tecks" is also possible."

The name is traditionally printed in running text with a special typographical logo: LaTeX.
In media where the logo cannot be precisely reproduced in running text, the word is typically given the unique capitalization "LaTeX". Alternatively, the TeX, LaTeX and XeTeX logos can also be rendered via pure CSS and XHTML for use in graphical web browsers — by following the specifications of the internal codice_7 macro.

As a macro package, LaTeX provides a set of macros for TeX to interpret. There are many other macro packages for TeX, including Plain TeX, GNU Texinfo, AMSTeX, and ConTeXt.

When TeX "compiles" a document, it follows (from the user's point of view) the following processing sequence: Macros → TeX → Driver → Output. Different implementations of each of these steps are typically available in TeX distributions. Traditional TeX will output a DVI file, which is usually converted to a PostScript file. More recently, Hàn Thế Thành and others have written a new implementation of TeX called pdfTeX, which also outputs to PDF and takes advantage of features available in that format. The XeTeX engine developed by Jonathan Kew, on the other hand, merges modern font technologies and Unicode with TeX.

The default font for LaTeX is Knuth's Computer Modern, which gives default documents created with LaTeX the same distinctive look as those created with plain TeX. XeTeX allows the use of OpenType and TrueType (that is, outlined) fonts for output files.

There are also many editors for LaTeX, some of which are offline, source-code-based while others are online, partial-WYSIWYG-based. For more, see Comparison of TeX editors.

LaTeX documents (codice_8) can be opened with any text editor. They consist of plain text and do not contain hidden formatting codes or binary instructions. Additionally, TeX documents can be shared by rendering the LaTeX file to Rich Text Format (codice_9) or XML. This can be done using the free software programs LaTeX2RTF or TeX4ht. LaTeX can also be rendered to PDF files using the LaTeX extension pdfLaTeX. LaTeX files containing Unicode text can be processed into PDFs with the codice_10 package, or by the TeX extensions XeLaTeX and LuaLaTeX.

LaTeX has become the de facto standard to typeset mathematical expression in scientific documents. Hence, there are several conversion tools focusing on mathematical LaTeX expressions, such as converters to MathML or Computer Algebra System.

LaTeX is typically distributed along with plain TeX under a free software license: the LaTeX Project Public License (LPPL). The LPPL is not compatible with the GNU General Public License, as it requires that modified files must be clearly differentiable from their originals (usually by changing the filename); this was done to ensure that files that depend on other files will produce the expected behavior and avoid dependency hell. The LPPL is DFSG compliant as of version 1.3. As free software, LaTeX is available on most operating systems, which include UNIX (Solaris, HP-UX, AIX), BSD (FreeBSD, macOS, NetBSD, OpenBSD), Linux (Red Hat, Debian, Arch, Gentoo), Windows, DOS, RISC OS, AmigaOS and Plan9.

LaTeX2e is the current version of LaTeX, since it replaced LaTeX 2.09 in 1994. , LaTeX3, which started in the early 1990s, is under a long-term development project. Planned features include improved syntax, hyperlink support, a new user interface, access to arbitrary fonts and a new documentation.

There are numerous commercial implementations of the entire TeX system. System vendors may add extra features like additional typefaces and telephone support. LyX is a free, WYSIWYM visual document processor that uses LaTeX for a back-end. TeXmacs is a free, WYSIWYG editor with similar functionalities as LaTeX, but with a different typesetting engine. Other WYSIWYG editors that produce LaTeX include Scientific Word on MS Windows., and BaKoMa TeX on Windows, Mac and Linux.

A number of community-supported TeX distributions are available, including TeX Live (multi-platform), teTeX (deprecated in favor of TeX Live, UNIX), fpTeX (deprecated), MiKTeX (Windows), proTeXt (Windows), MacTeX (TeX Live with the addition of Mac specific programs), gwTeX (Mac OS X) (deprecated), OzTeX (Mac OS Classic), AmigaTeX (no longer available), PasTeX (AmigaOS, available on the Aminet repository), and Auto-Latex Equations (Google Docs add-on that supports MathJax LaTeX commands).

LaTeX was created in the early 1980s by Leslie Lamport, when he was working at SRI. He needed to write TeX macros for his own use, and thought that with a little extra effort he could make a general package usable by others. Peter Gordon, an editor at Addison-Wesley, convinced him to write a LaTeX user's manual for publication (Lamport was initially skeptical that anyone would pay money for it); it came out in 1986 and sold hundreds of thousands of copies. Meanwhile, Lamport released versions of his LaTeX macros in 1984 and 1985. On 21 August 1989, at a TeX Users Group (TUG) meeting at Stanford, Lamport agreed to turn over maintenance and development of LaTeX to Frank Mittelbach. Mittelbach, along with Chris Rowley and Rainer Schöpf, formed the LaTeX3 team; in 1994, they released LaTeX 2e, the current standard version, and continue working on LaTeX3.




</doc>
<doc id="18196" url="https://en.wikipedia.org/wiki?curid=18196" title="List of saints">
List of saints

This is an incomplete list of Christian saints in alphabetical order by Christian name, but, where known and given, a surname, location, or personal attribute (included as part of the name) may affect the ordering.

One list says there are 1000 canonized Roman Catholic saints (who have been through the formal institutional process of canonization), although some give numbers in the thousands. (Pope John Paul II alone canonized 110 individuals, plus many group canonizations such as 110 martyr saints of China, 103 Korean martyrs, 117 Vietnamese martyrs, Mexican Martyrs, Spanish martyrs and French revolutionary martyrs.) Among the Eastern Orthodox and Oriental Orthodox Communions, the numbers may be even higher, since there is no fixed process of "canonization" and each individual jurisdiction within the two Orthodox communions independently maintains parallel lists of saints that have only partial overlap. Note that 78 popes are considered saints.

The Anglican Communion recognizes pre-Reformation saints, as does the United Methodist Church. Persons who have led lives of celebrated sanctity or missionary zeal are included in the Calendar of the Prayer Book "without thereby enrolling or commending such persons as saints of the Church". Similarly, any individuals commemorated in the Lutheran calendar of saints will be listed as well.

Wikipedia contains calendars of saints for particular denominations, listed by the day of the year on which they are traditionally venerated, as well as a chronological list of saints and blesseds, listed by their date of death.

 "Common Worship" has "Commemoration".





</doc>
<doc id="18198" url="https://en.wikipedia.org/wiki?curid=18198" title="Lebesgue measure">
Lebesgue measure

In measure theory, a branch of mathematics, the Lebesgue measure, named after French mathematician Henri Lebesgue, is the standard way of assigning a measure to subsets of "n"-dimensional Euclidean space. For "n" = 1, 2, or 3, it coincides with the standard measure of length, area, or volume. In general, it is also called n"-dimensional volume, n"-volume, or simply volume. It is used throughout real analysis, in particular to define Lebesgue integration. Sets that can be assigned a Lebesgue measure are called Lebesgue-measurable; the measure of the Lebesgue-measurable set "A" is here denoted by "λ"("A").

Henri Lebesgue described this measure in the year 1901, followed the next year by his description of the Lebesgue integral. Both were published as part of his dissertation in 1902.

The Lebesgue measure is often denoted by "dx", but this should not be confused with the distinct notion of a volume form.

Given a subset formula_1, with the length of interval formula_2 given by formula_3, the Lebesgue outer measure formula_4 is defined as

The Lebesgue measure is defined on the Lebesgue "σ"-algebra, which is the collection of all sets formula_6 which satisfy the "Carathéodory criterion" which requires that for every formula_7,

For any set in the Lebesgue "σ"-algebra, its Lebesgue measure is given by its Lebesgue outer measure formula_9.

Sets that are not included in the Lebesgue "σ"-algebra are not Lebesgue-measurable. Such sets do exist (e.g. Vitali sets), i.e., the Lebesgue "σ"-algebra's containment in the power set of formula_10 is strict.

The first part of the definition states that the subset formula_6 of the real numbers is reduced to its outer measure by coverage by sets of open intervals. Each of these sets of intervals formula_12 covers formula_6 in the sense that when the intervals are combined together by union, they contain formula_6. The total length of any covering interval set can easily overestimate the measure of formula_6, because formula_6 is a subset of the union of the intervals, and so the intervals may include points which are not in formula_6. The Lebesgue outer measure emerges as the greatest lower bound (infimum) of the lengths from among all possible such sets. Intuitively, it is the total length of those interval sets which fit formula_6 most tightly and do not overlap.

That characterizes the Lebesgue outer measure. Whether this outer measure translates to the Lebesgue measure proper depends on an additional condition. This condition is tested by taking subsets formula_19 of the real numbers using formula_6 as an instrument to split formula_19 into two partitions: the part of formula_19 which intersects with formula_6 and the remaining part of formula_19 which is not in formula_6: the set difference of formula_19 and formula_6. These partitions of formula_19 are subject to the outer measure. If for all possible such subsets formula_19 of the real numbers, the partitions of formula_19 cut apart by formula_6 have outer measures whose sum is the outer measure of formula_19, then the outer Lebesgue measure of formula_6 gives its Lebesgue measure. Intuitively, this condition means that the set formula_6 must not have some curious properties which causes a discrepancy in the measure of another set when formula_6 is used as a "mask" to "clip" that set, hinting at the existence of sets for which the Lebesgue outer measure does not give the Lebesgue measure. (Such sets are, in fact, not Lebesgue-measurable.)


The Lebesgue measure on R has the following properties:


All the above may be succinctly summarized as follows:

The Lebesgue measure also has the property of being "σ"-finite.

A subset of R is a "null set" if, for every ε > 0, it can be covered with countably many products of "n" intervals whose total volume is at most ε. All countable sets are null sets.

If a subset of R has Hausdorff dimension less than "n" then it is a null set with respect to "n"-dimensional Lebesgue measure. Here Hausdorff dimension is relative to the Euclidean metric on R (or any metric Lipschitz equivalent to it). On the other hand, a set may have topological dimension less than "n" and have positive "n"-dimensional Lebesgue measure. An example of this is the Smith–Volterra–Cantor set which has topological dimension 0 yet has positive 1-dimensional Lebesgue measure.

In order to show that a given set "A" is Lebesgue-measurable, one usually tries to find a "nicer" set "B" which differs from "A" only by a null set (in the sense that the symmetric difference ("A" − "B") formula_53("B" − "A") is a null set) and then show that "B" can be generated using countable unions and intersections from open or closed sets.

The modern construction of the Lebesgue measure is an application of Carathéodory's extension theorem. It proceeds as follows.

Fix . A box in R is a set of the form
where , and the product symbol here represents a Cartesian product. The volume of this box is defined to be

For "any" subset "A" of R, we can define its outer measure "λ"*("A") by:

We then define the set "A" to be Lebesgue-measurable if for every subset "S" of R,

These Lebesgue-measurable sets form a "σ"-algebra, and the Lebesgue measure is defined by for any Lebesgue-measurable set "A".

The existence of sets that are not Lebesgue-measurable is a consequence of a certain set-theoretical axiom, the axiom of choice, which is independent from many of the conventional systems of axioms for set theory. The Vitali theorem, which follows from the axiom, states that there exist subsets of R that are not Lebesgue-measurable. Assuming the axiom of choice, non-measurable sets with many surprising properties have been demonstrated, such as those of the Banach–Tarski paradox.

In 1970, Robert M. Solovay showed that the existence of sets that are not Lebesgue-measurable is not provable within the framework of Zermelo–Fraenkel set theory in the absence of the axiom of choice (see Solovay's model).

The Borel measure agrees with the Lebesgue measure on those sets for which it is defined; however, there are many more Lebesgue-measurable sets than there are Borel measurable sets. The Borel measure is translation-invariant, but not complete.

The Haar measure can be defined on any locally compact group and is a generalization of the Lebesgue measure (R with addition is a locally compact group).

The Hausdorff measure is a generalization of the Lebesgue measure that is useful for measuring the subsets of R of lower dimensions than "n", like submanifolds, for example, surfaces or curves in R and fractal sets. The Hausdorff measure is not to be confused with the notion of Hausdorff dimension.

It can be shown that there is no infinite-dimensional analogue of Lebesgue measure.



</doc>
<doc id="18201" url="https://en.wikipedia.org/wiki?curid=18201" title="Lake Champlain">
Lake Champlain

Lake Champlain (; ; Abenaki: "Pitawbagok"; ) is a natural freshwater lake in North America mainly within the borders of the United States (in the states of Vermont and New York) but also across the Canada–U.S. border into the Canadian province of Quebec.

The New York portion of the Champlain Valley includes the eastern portions of Clinton County and Essex County. Most of this area is part of the Adirondack Park. There are recreational facilities in the park and along the relatively undeveloped coastline of Lake Champlain. The cities of Plattsburgh, New York and Burlington, Vermont are on the lake's western and eastern shores, respectively, and the Town of Ticonderoga, New York is in the region's southern part. The Quebec portion is in the regional county municipalities of Le Haut-Richelieu and Brome-Missisquoi. There are a number of islands in the lake; the largest include Grand Isle, Isle La Motte, and North Hero, all part of Grand Isle County, Vermont.

The Champlain Valley is the northernmost unit of a landform system known as the Great Appalachian Valley, which stretches between Quebec, Canada, to the north, and Alabama, US, to the south. The Champlain Valley is a physiographic section of the larger Saint Lawrence Valley, which in turn is part of the larger Appalachian physiographic division.

Lake Champlain is one of numerous large lakes scattered in an arc through Labrador, in Canada, the northern United States, and the Northwest Territories of Canada. It is the thirteenth largest lake by area in the US. Approximately in area, the lake is long and across at its widest point, and has a maximum depth of approximately . The lake varies seasonally from about above mean sea level.

Lake Champlain is in the Lake Champlain Valley between the Green Mountains of Vermont and the Adirondack Mountains of New York, drained northward by the Richelieu River into the St. Lawrence River at Sorel-Tracy, Quebec, northeast and downstream of Montreal, Quebec. It also receives the waters from the Lake George, so its basin collects waters from the northwestern slopes of the Green Mountains and the northernmost eastern peaks of the Adirondack Mountains.

Lake Champlain drains nearly half of Vermont, and approximately 250,000 people get their drinking water from the lake.

The lake is fed in Vermont by the LaPlatte, Lamoille, Missisquoi, Poultney, and Winooski rivers, along with Lewis Creek, Little Otter Creek, and Otter Creek. In New York, it is fed by the Ausable, Boquet, Great Chazy, La Chute, Little Ausable, Little Chazy, Salmon, and Saranac rivers, along with Putnam Creek. In Quebec, it is fed by the Pike River.

It is connected to the Hudson River by the Champlain Canal.

Parts of the lake freeze each winter, and in some winters the entire lake surface freezes, referred to as "closing". In July and August, the lake temperature reaches an average of .

The Chazy Reef is an extensive Ordovician carbonate rock formation that extends from Tennessee to Quebec and Newfoundland. It occurs in prominent outcropping at Goodsell Ridge, Isle La Motte, the northernmost island in Lake Champlain.

The oldest reefs are around "The Head" of the south end of the island; slightly younger reefs are found at the Fisk Quarry, and the youngest (the famous coral reefs) are in fields to the north. Together, these three sites provide a unique narrative of events that took place over 450 million years ago in the ocean in the Southern Hemisphere, long before Lake Champlain's emergence 20,000 years ago.

The lake has long acted as a border between indigenous nations much as it is today between the states of New York and Vermont. The lake is located at the frontier between Abenaki and Mohawk (Iroquois Confederacy) traditional territories. The official toponym for the lake according to the orthography established by the Grand Council of Wanab-aki Nation is Pitawbagok (alternative orthographies include Petonbowk and Bitawbagok), meaning 'middle lake', 'lake in between' or 'double lake'.

The Mohawk name in modern orthography as standardized in 1993 is Kaniatarakwà:ronte, meaning "a bulged lake" or “lake with a bulge in it." An alternate name is Kaniá:tare tsi kahnhokà:ronte (phonetic English spelling "Caniaderi Guarunte"), meaning 'door of the country' or 'lake to the country'. The lake is an important eastern gateway to Iroquois Confederacy lands.

The lake was named after the French explorer Samuel de Champlain, who encountered it in July 1609. While the ports of Burlington, Vermont, Port Henry, New York, and Plattsburgh, New York today are primarily used by small craft, ferries, and lake cruise ships, they were of substantial commercial and military importance in the 18th and 19th centuries.

New France allocated concessions all along lake Champlain to French settlers and built forts to defend the waterways. In colonial times, Lake Champlain was used as a water (or, in winter, ice) passage between the Saint Lawrence and Hudson valleys. Travelers found it easier to journey by boats and sledges on the lake rather than go overland on unpaved and frequently mud-bound roads. The lake's northern tip at Saint-Jean-sur-Richelieu, Quebec (known as St. John in colonial times under British rule), is a short distance from Montreal, Quebec. The southern tip at Whitehall (Skenesborough in revolutionary times) is a short distance from Saratoga, Glens Falls, and Albany, New York.

Forts were built at Ticonderoga and Crown Point (Fort St. Frederic) to control passage on the lake in colonial times. Important battles were fought at Ticonderoga in 1758 and 1775. During the Revolutionary War, the British and Americans conducted a frenetic shipbuilding race through the spring and summer of 1776, at opposite ends of the lake, and fought a significant naval engagement on October 11 at the Battle of Valcour Island. While it was a tactical defeat for the Americans, and the small fleet led by Benedict Arnold was almost destroyed, the Americans gained a strategic victory; the British invasion was delayed long enough so the approach of winter prevented the fall of these forts until the following year. In this period, the Continental Army gained strength and was victorious at Saratoga.

At the start of the Revolutionary War, British forces occupied the Champlain Valley. However, it did not take long for rebel leaders to realize the importance of controlling Lake Champlain. Early in the war, the colonial militias attempted to expel the British from Boston; however, this undertaking could not be achieved without heavy artillery. The British forts at Ticonderoga and Crown Point, on Lake Champlain, were known to have ample supplies of artillery and were weakly manned by the British. Thus, the colonial militias devised a plan to take control of the two forts and bring the guns back to the fight in Boston.
The necessity of controlling the two forts at Ticonderoga and Crown Point placed Lake Champlain as a strategic arena during the Revolutionary War. By taking control of these forts, Americans not only gained heavy artillery, but control of a vast water highway, as well: Lake Champlain provided a direct invasion route to British Canada. However, had the British controlled the lake, they could have divided the colonies of New England and further depleted the Continental Army.

The Continental Army's first offensive action took place in May 1775, three weeks after the Battles of Lexington and Concord. Ethan Allen, accompanied by 200 Green Mountain Boys, was ordered to capture Fort Ticonderoga and retrieve supplies for the fight in Boston. Benedict Arnold shared the command with Allen, and in early May 1775, they captured Fort Ticonderoga, Crown Point, and the southern Loyalist settlement of Skenesborough. As a result of Allen's offensive attack on the Champlain Valley in 1775, the American forces controlled the Lake Champlain waterway.

The Continental Army realized the strategic advantage of controlling Lake Champlain, as it leads directly to the heart of Quebec. Immediately after taking Forts Ticonderoga and Crown Point, the Americans began planning an attack on British Canada. The American siege of Quebec was a two-pronged assault and occurred throughout the winter of 1775–1776. Brigadier General Richard Montgomery led the first assault up the Champlain Valley into Canada, while Benedict Arnold led a second army to Quebec via the Maine wilderness.

Despite the strategic advantage of controlling a direct route to Quebec by way of the Champlain Valley, the American siege of British Canada during the winter of 1775 failed. The Continental Army mistakenly assumed they would receive support from the Canadians upon their arrival at Quebec. This was not the case, and the rebel army struggled to take Quebec with diminishing supplies, support, and harsh northern winter weather.

The Continental Army was forced to camp outside Quebec's walls for the winter, with reinforcements from New York, Pennsylvania, Massachusetts, New Hampshire, and Connecticut allowing the soldiers to maintain their siege of the city. The reinforcements traveled hundreds of miles (kilometres) up the frozen Lake Champlain and St. Lawrence River, but were too late and too few to influence a successful siege of Quebec. In May 1776, with the arrival of a British convoy carrying 10,000 British and Hessian troops to Canada, the Continental forces retreated back down the Champlain Valley to reevaluate their strategy.
"I know of no better method than to secure the important posts of Ticonderoga and Crown Point, and by building a number of armed vessels to command the lakes, otherwise the forces now in Canada will be brought down upon us as quick as possible, having nothing to oppose them… They will doubtless try to construct some armed vessels and then endeavor to penetrate the country toward New York." (Brigadier General John Sullivan to George Washington, June 24, 1776).

Both British and American forces spent the summer of 1776 building their naval fleets, at opposite ends of Lake Champlain. By the October 1776, the Continental Army had 16 operating naval vessels on Lake Champlain, a great increase to the four small ships they had at the beginning of the summer. General Benedict Arnold commanded the American naval fleet on Lake Champlain, which was composed of volunteers and soldiers drafted from the Northern Army. With great contrast to the Continental navy, experienced Royal Navy officers, British seamen, and Hessian artillerymen manned the British fleet on Lake Champlain. By the end of the summer of 1776, the opposing armies were prepared to battle over the strategic advantage of controlling Lake Champlain.

On October 11, 1776, the British and American naval fleets met on the western side of Valcour Island, on Lake Champlain. American General Benedict Arnold established the location, as it provided the Continental fleet with a natural defensive position. The British and American vessels engaged in combat for much of the day, only stopping due to the impending nightfall.

After a long day of combat, the American fleet was in worse shape than the experienced British Navy. Upon ceasefire, Arnold called a council of war with his fellow officers, proposing to escape the British fleet via rowboats under the cover of night. As the British burned Arnold's flagship, the "Royal Savage," to the east, the Americans rowed past the British lines.

The following morning, the British learned of the Americans' escape and set out after the fleeing Continental vessels. On October 13, the British fleet caught up to the struggling American ships near Split Rock Mountain. With no hope of fighting off the powerful British navy, Arnold ordered his men to run their five vessels aground in Ferris Bay, Panton, Vermont. The depleted Continental army escaped on land back to Fort Ticonderoga and Mount Independence; however, they no longer controlled the Lake Champlain waterway.

The approaching winter of 1776–1777 restricted British movement along the recently controlled Lake Champlain. As the British abandoned Crown Point and returned to Canada for the winter, the Americans reduced their garrisons in the Champlain Valley from 13,000 to 2,500 soldiers.

In early 1777, British General John Burgoyne led 8,000 troops from Canada, down Lake Champlain, and into the Champlain Valley. The goal of this invasion was to divide the New England colonies, thus forcing the Continental Army into a separated fight on multiple fronts. Lake Champlain provided Burgoyne with protected passage deep into the American colonies. Burgoyne's army reached Fort Ticonderoga and Mount Independence in late June 1777. During the night of July 5, the American forces fled Ticonderoga as the British took control of the fort. However, Burgoyne's southern campaign did not go uncontested.

On October 7, 1777, American General Horatio Gates, who occupied Bemis Heights, met Burgoyne's army at the Second Battle of Freeman's Farm. At Freeman's Farm, Burgoyne's army suffered its final defeat and ended their invasion south into the colonies. Ten days later, on October 17, 1777, British General Burgoyne surrendered his army at Saratoga. This defeat was instrumental to the momentum of the Revolutionary War, as the defeat of the British army along the Champlain-Hudson waterway convinced France to ally with the American army.

Following the failed British campaign led by General Burgoyne, the British still maintained control over the Champlain waterway for the duration of the Revolutionary War. The British used the Champlain waterway to supply raids across the Champlain Valley from 1778 to 1780, and Lake Champlain permitted direct transportation of supplies from the British posts at the northern end of the lake.

With the end of the Revolutionary War in 1783, the British naval fleet on Lake Champlain retreated up to St. John's. However, British troops garrisoned at Fort Dutchman's Point (North Hero, Vermont) and Fort au Fer (Champlain, New York) on Lake Champlain, did not leave until the 1796 Jay Treaty.

Eager to take back control of Lake Champlain following the end of the Revolutionary War, Americans flocked to settle the Champlain Valley. Many individuals emigrated from Massachusetts and other New England colonies, such as Salmon Dutton, a settler of Cavendish, Vermont. Dutton emigrated in 1782 and worked as a surveyor, town official, and toll road owner. His home had a dooryard garden, typical of mid-19th century New England village homes, and his experience settling in the Champlain Valley depicts the industries and lifestyles surrounding Lake Champlain following the Revolutionary War.

Similar to the experience of Salmon Dutton, former colonial militia Captain Hezekiah Barnes settled in Charlotte, Vermont, in 1787. Following the war, Barnes also worked as a road surveyor; he also established an inn and trading post in Charlotte, along the main trade route from Montreal down Lake Champlain. Barnes's stagecoach inn was built in traditional Georgian style, with 10 fireplaces and a ballroom on the interior, and a wraparound porch on the outside. In 1800, Continental Army Captain Benjamin Harrington established a distillery business in Shelburne, Vermont, which supplied his nearby inn. Furthermore, Captain Stevens and Jeremiah Trescott built a water-powered sawmill in South Royalton, Vermont, in the late 1700s. These individual accounts shed light on the significance of Lake Champlain during the post-Revolutionary War period.

During the War of 1812, British and American forces faced each other in the Battle of Lake Champlain, also known as the Battle of Plattsburgh, fought on September 11, 1814. This ended the final British invasion of the northern states during the War of 1812. It was fought just prior to the signing of the Treaty of Ghent, and the American victory denied the British any leverage to demand exclusive control over the Great Lakes or territorial gains against the New England states.

Three US Naval ships have been named after this battle: , , and a cargo ship used during World War I.

Following the War of 1812, the U.S. Army began construction on "Fort Blunder", an unnamed fortification built at the northernmost end of Lake Champlain to protect against attacks from British Canada. Its nickname came from a surveying error: the initial phase of construction on the fort turned out to be taking place on a point north of the Canada–U.S. border. Once this error was spotted, construction was abandoned. Locals scavenged materials used in the abandoned fort for use in their homes and public buildings.

By the Webster-Ashburton Treaty of 1842, the Canada–U.S. border was adjusted northward to include the strategically important site of "Fort Blunder" on the US side. In 1844, work was begun to replace the remains of the 1812-era fort with a massive new Third System masonry fortification, known as Fort Montgomery. Portions of this fort are still standing.

In the early 19th century, the construction of the Champlain Canal connected Lake Champlain to the Hudson River system, allowing north–south commerce by water from New York City to Montreal and Atlantic Canada.

In 1909, 65,000 people celebrated the 300th anniversary of the French discovery of the lake. Attending dignitaries included President William Howard Taft, along with representatives from France, Canada, and the United Kingdom.

In 1929, then-New York Governor Franklin Roosevelt and Vermont Governor John Weeks dedicated the first bridge to span the lake, built from Crown Point to Chimney Point. This bridge lasted until December 2009. Severe deterioration was found, and the bridge was demolished and replaced with the Lake Champlain Bridge, which opened in November 2011.

On February 19, 1932, boats were able to sail on Lake Champlain. It was the first time the lake was known to be free of ice during the winter at that time.

Lake Champlain briefly became the nation's sixth Great Lake on March 6, 1998, when President Clinton signed Senate Bill 927. This bill, which was led by U.S. Senator Patrick Leahy of Vermont and reauthorized the National Sea Grant Program, contained a line declaring Lake Champlain to be a Great Lake. This status enabled its neighboring states to apply for additional federal research and education funds allocated to these national resources. However, following a small uproar, the Great Lake status was rescinded on March 24 (although New York and Vermont universities continue to receive funds to monitor and study the lake).

In 1609, Samuel de Champlain wrote that he saw a lake monster long, as thick as a man's thigh, with silver-gray scales a dagger could not penetrate. The alleged monster had jaws with sharp and dangerous teeth. Native Americans claimed to have seen similar monsters long. This mysterious creature is likely the original Lake Champlain monster. The monster has been memorialized in sports teams' names and mascots, i.e., the Vermont Lake Monsters and Champ, the mascot of the state's minor league baseball team. A Vermont Historical Society publication recounts the story and offers possible explanations for accounts of the so-called monster: "floating logs, schools of large sturgeons diving in a row, or flocks of black birds flying close to the water."

A pollution prevention, control, and restoration plan for Lake Champlain was first endorsed in October 1996 by the governors of New York and Vermont, and the regional administrators of the United States Environmental Protection Agency (EPA). In April 2003, the plan was updated, and Quebec signed onto it. The plan is being implemented by the Lake Champlain Basin Program and its partners at the state, provincial, federal, and local levels. Renowned as a model for interstate and international cooperation, its primary goals are to reduce phosphorus inputs to Lake Champlain, reduce toxic contamination, minimize the risks to humans from water-related health hazards, and control the introduction, spread, and impact of non-native nuisance species to preserve the integrity of the Lake Champlain ecosystem.

Senior staff who helped organize the Environmental Protection Agency in 1970 recall that International Paper was one of the first companies to call upon the brand new agency, because it was being pushed by both New York and Vermont with regard to a discharge of pollution into Lake Champlain.

Agricultural and urban runoff from the watershed or drainage basin is the primary source of excess phosphorus, which exacerbates algae blooms in Lake Champlain. The most problematic blooms have been cyanobacteria, commonly called blue-green algae, in the northeastern part of the Lake, primarily Missisquoi Bay.

To reduce phosphorus runoff to this part of the lake, Vermont and Quebec agreed to reduce their inputs by 60% and 40%, respectively, by an agreement signed in 2002. While agricultural sources (manure and fertilizers) are the primary sources of phosphorus (about 70%) in the Missisquoi basin, runoff from developed land and suburbs is estimated to contribute about 46% of the phosphorus runoff basin-wide to Lake Champlain, and agricultural lands contributed about 38%.

In 2002, the cleanup plan noted that the lake had the capacity to absorb of phosphorus each year. In 2009, a judge noted that were still flowing in annually, more than twice what the lake could handle. Sixty municipal and industrial sewage plants discharge processed waste from the Vermont side.

In 2008, the EPA expressed concerns to the State of Vermont that the Lake's cleanup was not progressing fast enough to meet the original cleanup goal of 2016. The state, however, cites its Clean and Clear Action Plan as a model that will produce positive results for Lake Champlain.

In 2007, Vermont banned phosphates for dishwasher use starting in 2010. This will prevent an estimated from flowing into the lake. While this represents 0.6% of the phosphate pollution, it took US$1.9 million to remove the pollutant from treated wastewater, an EPA requirement.

Despite concerns about pollution, Lake Champlain is safe for swimming, fishing, and boating. It is considered a world-class fishery for salmonid species (Lake trout and Atlantic salmon) and bass. About 81 fish species live in the lake, and more than 300 bird species rely on it for habitat and as a resource during migrations.

By 2008, at least six institutions were monitoring lake water health:

In 2001, scientists estimated that farming contributed 38% of the phosphorus runoff. By 2010, results of environmentally conscious farming practices, enforced by law, had made any positive contribution to lake cleanliness. A federally funded study was started to analyze this problem and to arrive at a solution.

Biologists have been trying to control lampreys in the lake since 1985 or earlier. Lampreys are native to the area but have expanded in population to such an extent that they wounded nearly all lake trout in 2006 and 70–80% of salmon. The use of pesticides against the lamprey has reduced their casualties of other fish to 35% of salmon and 31% of lake trout. The goal was 15% of salmon and 25% of lake trout.

The federal and state governments originally budgeted US$18 million for lake programs for 2010. This was later supplemented by an additional US$6.5 million from the federal government.

In 2010, the estimate of cormorant population, now classified as a nuisance species because they take so much of the lake fish, ranged from 14,000 to 16,000. A Fish and Wildlife commissioner said the ideal population would be 3,300 or about . Cormorants had disappeared from the lake (and all northern lakes) due to the use of DDT in the 1940s and 1950s, which made their eggs more fragile and reduced breeding populations.

Ring-billed gulls are also considered a nuisance, and measures have been taken to reduce their population. Authorities are trying to encourage the return of black crowned night herons, cattle egrets, and great blue herons, which disappeared during the time DDT was being widely used.

In 1989, UNESCO designated the area around Lake Champlain as the Champlain-Adirondack Biosphere Reserve.

The Alburgh Peninsula (also known as the Alburgh Tongue), extending south from the Quebec shore of the lake into Vermont, and Province Point, the southernmost tip of a small promontory approximately in size a few miles (kilometres) to the northeast of the town of East Alburgh, Vermont, are connected by land to the rest of the state only via Canada. This is a distinction shared with the state of Alaska, Point Roberts, Washington, and the Northwest Angle in Minnesota. All of these are practical exclaves of the United States contiguous with Canada. Unlike the other cases, highway bridges across the lake provide direct access to the Alburgh peninsula from within the United States (from three directions). 

Two roadways cross over the lake, connecting Vermont and New York:


In 2009, the bridge had been used by 3,400 drivers per day, and driving around the southern end of the lake added two hours to the trip. Ferry service was re-established to take some of the traffic burden. On December 28, 2009, the bridge was destroyed by a controlled demolition. A new bridge was rapidly constructed by a joint state commitment, opening on November 7, 2011.


North of Ticonderoga, New York, the lake widens appreciably; ferry service is operated by the Lake Champlain Transportation Company at:

While the old bridge was being demolished and the new one constructed, Lake Champlain Transportation
Company operated a free, 24-hour ferry from just south of the bridge to Chimney
Point in Vermont at the expense of the states of New York and Vermont at a cost to the states of about $10 per car.

The most southerly crossing is the Fort Ticonderoga Ferry, connecting Ticonderoga, New York with Shoreham, Vermont, just north of the historic fort.

Four significant railroad crossings were built over the lake. As of 2016, only one remains.

Now called Colchester Park, the main three-mile (5 km) causeway has been adapted and preserved as a recreation area for cyclists, runners, and anglers. Two smaller marble rock-landfill causeways were also erected as part of this line that connected Grand Isle to North Hero, and spanned from North Hero to Alburgh.


Lake Champlain has been connected to the Erie Canal via the Champlain Canal since the canal's official opening September 9, 1823, the same day as the opening of the Erie Canal from Rochester on Lake Ontario to Albany. It connects to the St. Lawrence River via the Richelieu River, with the Chambly Canal bypassing rapids on the river since 1843. Together with these waterways the lake is part of the Lakes to Locks Passage. The Lake Champlain Seaway, a project to use the lake to bring ocean-going ships from New York City to Montreal, was proposed in the late 19th century and considered as late as the 1960s, but rejected for various reasons. The lake is also part of the 740-mile Northern Forest Canoe Trail, which begins in Old Forge, New York, and ends in Fort Kent, Maine.

Burlington, Vermont (pop. 42,217, 2010 Census) is the largest city on the lake. The 2nd and 3rd most populated cities/towns are Plattsburgh, New York, and South Burlington, Vermont, respectively. The fourth-largest community is the town of Colchester.

Lake Champlain contains roughly 80 islands, three of which comprise four entire Vermont towns (most of Grand Isle County). The largest islands:


All active navigational aids on the American portion of the lake are maintained by USCG Burlington station, along with those on international Lake Memphremagog to the east.
Aids to navigation on the Canadian portion of the lake are maintained by the Canadian Coast Guard.

There are a number of parks in the Lake Champlain region in both New York and Vermont.

Those on the New York side of the lake include: Point Au Roche State Park, which park grounds have hiking and cross country skiing trails, and a public beach; and the Ausable Point State Park. The Cumberland Bay State Park is located on Cumberland Head, with a campground, city beach, and sports fields.

There are various parks along the lake on the Vermont side, including Sand Bar State Park in Milton, featuring a natural sand beach, swimming, canoe and kayak rentals, food concession, picnic grounds and a play area. At , Grand Isle State Park contains camping facilities, a sand volleyball court, a nature walk trail, a horseshoe pit and a play area. Button Bay State Park in Ferrisburgh features campsites, picnic areas, a nature center and a swimming pool. Burlington's Waterfront Park is a revitalized industrial area.

Coast Guard Station Burlington provides "Search and Rescue, Law Enforcement and Ice Rescue services 24 hours a day, 365 days a year." Services are also provided by local, and state, and federal governments bordering on the lake, including the U.S. Border Patrol, Royal Canadian Mounted Police, Vermont State Police, New York State Police Marine Detail, and Vermont Fish and Wildlife wardens.




</doc>
<doc id="18203" url="https://en.wikipedia.org/wiki?curid=18203" title="Lambda calculus">
Lambda calculus

Lambda calculus (also written as λ-calculus) is a formal system in mathematical logic for expressing computation based on function abstraction and application using variable binding and substitution. It is a universal model of computation that can be used to simulate any Turing machine. It was introduced by the mathematician Alonzo Church in the 1930s as part of his research into the foundations of mathematics.

Lambda calculus consists of constructing lambda terms and performing reduction operations on them. In the simplest form of lambda calculus, terms are built using only the following rules:
producing expressions such as: (λ"x".λ"y".(λ"z".(λ"x"."z x") (λ"y"."z y")) ("x y")). Parentheses can be dropped if the expression is unambiguous. For some applications, terms for logical and mathematical constants and operations may be included.

The reduction operations include:

If De Bruijn indexing is used, then α-conversion is no longer required as there will be no name collisions. If repeated application of the reduction steps eventually terminates, then by the Church–Rosser theorem it will produce a β-normal form.

Variable names are not needed if using a universal lambda function, such as Iota and Jot, which can create any function behavior by calling it on itself in various combinations.

Lambda calculus is Turing complete, that is, it is a universal model of computation that can be used to simulate any Turing machine. Its namesake, the Greek letter lambda (λ), is used in lambda expressions and lambda terms to denote binding a variable in a function.

Lambda calculus may be "untyped" or "typed". In typed lambda calculus, functions can be applied only if they are capable of accepting the given input's "type" of data. Typed lambda calculi are "weaker" than the untyped lambda calculus, which is the primary subject of this article, in the sense that "typed lambda calculi can express less" than the untyped calculus can, but on the other hand typed lambda calculi allow more things to be proven; in the simply typed lambda calculus it is, for example, a theorem that every evaluation strategy terminates for every simply typed lambda-term, whereas evaluation of untyped lambda-terms need not terminate. One reason there are many different typed lambda calculi has been the desire to do more (of what the untyped calculus can do) without giving up on being able to prove strong theorems about the calculus.

Lambda calculus has applications in many different areas in mathematics, philosophy, linguistics, and computer science. Lambda calculus has played an important role in the development of the theory of programming languages. Functional programming languages implement the lambda calculus. Lambda calculus is also a current research topic in Category theory.

The lambda calculus was introduced by mathematician Alonzo Church in the 1930s as part of an investigation into the foundations of mathematics. The original system was shown to be logically inconsistent in 1935 when Stephen Kleene and J. B. Rosser developed the Kleene–Rosser paradox.

Subsequently, in 1936 Church isolated and published just the portion relevant to computation, what is now called the untyped lambda calculus. In 1940, he also introduced a computationally weaker, but logically consistent system, known as the simply typed lambda calculus.

Until the 1960s when its relation to programming languages was clarified, the lambda calculus was only a formalism. Thanks to Richard Montague and other linguists' applications in the semantics of natural language, the lambda calculus has begun to enjoy a respectable place in both linguistics and computer science.

There is a bit of controversy over the reason for Church's use of the Greek letter lambda (λ) as the notation for function-abstraction in the lambda calculus, perhaps in part due to conflicting explanations by Church himself. According to Cardone and Hindley (2006):

By the way, why did Church choose the notation “λ”? In [an unpublished 1964 letter to Harald Dickson] he stated clearly that it came from the notation “formula_1” used for class-abstraction by Whitehead and Russell, by first modifying “formula_1” to “∧formula_3” to distinguish function-abstraction from class-abstraction, and then changing “∧” to “λ” for ease of printing.

This origin was also reported in [Rosser, 1984, p.338]. On the other hand, in his later years Church told two enquirers that the choice was more accidental: a symbol was needed and λ just happened to be chosen.

Dana Scott has also addressed this controversy in various public lectures.
Scott recounts that he once posed a question about the origin of the lambda symbol to Church's son-in-law John Addison, who then wrote his father-in-law a postcard:

Dear Professor Church,

Russell had the iota operator, Hilbert had the epsilon operator. Why did you choose lambda for your operator?

According to Scott, Church's entire response consisted of returning the postcard with the following annotation: "eeny, meeny, miny, moe".

Computable functions are a fundamental concept within computer science and mathematics. The lambda calculus provides a simple semantics for computation, enabling properties of computation to be studied formally. The lambda calculus incorporates two simplifications that make this semantics simple.
The first simplification is that the lambda calculus treats functions "anonymously", without giving them explicit names. For example, the function 
can be rewritten in "anonymous form" as 
(read as "a tuple of and is mapped to formula_6"). Similarly, 
can be rewritten in anonymous form as
where the input is simply mapped to itself.

The second simplification is that the lambda calculus only uses functions of a single input. An ordinary function that requires two inputs, for instance the formula_9 function, can be reworked into an equivalent function that accepts a single input, and as output returns "another" function, that in turn accepts a single input. For example, 
can be reworked into 
This method, known as currying, transforms a function that takes multiple arguments into a chain of functions each with a single argument.

Function application of the formula_9 function to the arguments (5, 2), yields at once
whereas evaluation of the curried version requires one more step
to arrive at the same result.

The lambda calculus consists of a language of lambda terms, which is defined by a certain formal syntax, and a set of transformation rules, which allow manipulation of the lambda terms. These transformation rules can be viewed as an equational theory or as an operational definition.

As described above, all functions in the lambda calculus are anonymous functions, having no names. They only accept one input variable, with currying used to implement functions with several variables.

The syntax of the lambda calculus defines some expressions as valid lambda calculus expressions and some as invalid, just as some strings of characters are valid C programs and some are not. A valid lambda calculus expression is called a "lambda term".

The following three rules give an inductive definition that can be applied to build all syntactically valid lambda terms:
Nothing else is a lambda term. Thus a lambda term is valid if and only if it can be obtained by repeated application of these three rules. However, some parentheses can be omitted according to certain rules. For example, the outermost parentheses are usually not written. See "Notation", below.

An abstraction formula_31 is a definition of an anonymous function that is capable of taking a single input formula_3 and substituting it into the expression formula_25. 
It thus defines an anonymous function that takes formula_3 and returns formula_25. For example, formula_36 is an abstraction for the function formula_37 using the term formula_38 for formula_25. The definition of a function with an abstraction merely "sets up" the function but does not invoke it. The abstraction binds the variable formula_3 in the term formula_25.

An application formula_42 represents the application of a function formula_25 to an input formula_29, that is, it represents the act of calling function formula_25 on input formula_29 to produce formula_47.

There is no concept in lambda calculus of variable declaration. In a definition such as formula_48 (i.e. formula_49), the lambda calculus treats formula_21 as a variable that is not yet defined. The abstraction formula_48 is syntactically valid, and represents a function that adds its input to the yet-unknown formula_21.

Bracketing may be used and may be needed to disambiguate terms. For example, formula_53 and formula_54 denote different terms (although they coincidentally reduce to the same value). Here, the first example defines a function whose lambda term is the result of applying x to the child function, while the second example is the application of the outermost function to the input x, which returns the child function. Therefore, both examples evaluate to the identity function formula_55.

In lambda calculus, functions are taken to be 'first class values', so functions may be used as the inputs, or be returned as outputs from other functions.

For example, formula_55 represents the identity function, formula_8, and formula_58 represents the identity function applied to formula_21. Further, formula_60 represents the constant function formula_61, the function that always returns formula_21, no matter the input. In lambda calculus, function application is regarded as left-associative, so that formula_63 means formula_64.

There are several notions of "equivalence" and "reduction" that allow lambda terms to be "reduced" to "equivalent" lambda terms.

A basic form of equivalence, definable on lambda terms, is alpha equivalence. It captures the intuition that the particular choice of a bound variable, in an abstraction, does not (usually) matter.
For instance, formula_55 and formula_66 are alpha-equivalent lambda terms, and they both represent the same function (the identity function). 
The terms formula_3 and formula_21 are not alpha-equivalent, because they are not bound in an abstraction.
In many presentations, it is usual to identify alpha-equivalent lambda terms.

The following definitions are necessary in order to be able to define β-reduction:

The free variables of a term are those variables not bound by an abstraction. The set of free variables of an expression is defined inductively:

For example, the lambda term representing the identity formula_55 has no free variables, but the function formula_78 has a single free variable, formula_21.

Suppose formula_25, formula_29 and formula_82 are lambda terms and formula_3 and formula_21 are variables.
The notation formula_85 indicates substitution of formula_82 for formula_3 in formula_25 in a "capture-avoiding" manner. This is defined so that:

For example, formula_100, and formula_101.

The freshness condition (requiring that formula_21 is not in the free variables of formula_82) is crucial in order to ensure that substitution does not change the meaning of functions.
For example, a substitution is made that ignores the freshness condition: formula_104. This substitution turns the constant function formula_105 into the identity formula_55 by substitution.

In general, failure to meet the freshness condition can be remedied by alpha-renaming with a suitable fresh variable.
For example, switching back to our correct notion of substitution, in formula_107 the abstraction can be renamed with a fresh variable formula_108, to obtain formula_109, and the meaning of the function is preserved by substitution.

The β-reduction rule states that an application of the form formula_110 reduces to the term formula_111. The notation formula_112 is used to indicate that formula_113 β-reduces to formula_114.
For example, for every formula_29, formula_116. This demonstrates that formula_117 really is the identity.
Similarly, formula_118, which demonstrates that formula_119 is a constant function.

The lambda calculus may be seen as an idealised version of a functional programming language, like Haskell or Standard ML.
Under this view, β-reduction corresponds to a computational step. This step can be repeated by additional β-reductions until there are no more applications left to reduce. In the untyped lambda calculus, as presented here, this reduction process may not terminate.
For instance, consider the term formula_120.
Here formula_121.
That is, the term reduces to itself in a single β-reduction, and therefore the reduction process will never terminate.

Another aspect of the untyped lambda calculus is that it does not distinguish between different kinds of data.
For instance, it may be desirable to write a function that only operates on numbers. However, in the untyped lambda calculus, there is no way to prevent a function from being applied to truth values, strings, or other non-number objects.

Lambda expressions are composed of:

The set of lambda expressions, Λ, can be defined inductively:


Instances of rule 2 are known as "abstractions" and instances of rule 3 are known as "applications".

To keep the notation of lambda expressions uncluttered, the following conventions are usually applied:

The abstraction operator, λ, is said to bind its variable wherever it occurs in the body of the abstraction. Variables that fall within the scope of an abstraction are said to be "bound". In an expression λ"x"."M", the part λ"x" is often called "binder", as a hint that the variable "x" is getting bound by appending λ"x" to "M". All other variables are called "free". For example, in the expression λ"y"."x x y", "y" is a bound variable and "x" is a free variable. Also a variable is bound by its nearest abstraction. In the following example the single occurrence of "x" in the expression is bound by the second lambda: λ"x"."y" (λ"x"."z x").

The set of "free variables" of a lambda expression, "M", is denoted as FV("M") and is defined by recursion on the structure of the terms, as follows:

An expression that contains no free variables is said to be "closed". Closed lambda expressions are also known as "combinators" and are equivalent to terms in combinatory logic.

The meaning of lambda expressions is defined by how expressions can be reduced.

There are three kinds of reduction:

We also speak of the resulting equivalences: two expressions are "α-equivalent", if they can be α-converted into the same expression. β-equivalence and η-equivalence are defined similarly.

The term "redex", short for "reducible expression", refers to subterms that can be reduced by one of the reduction rules. For example, (λ"x"."M") "N" is a β-redex in expressing the substitution of "N" for "x" in "M". The expression to which a redex reduces is called its "reduct"; the reduct of (λ"x"."M") "N" is "M"["x" := "N"].

If "x" is not free in "M", λ"x"."M x" is also an η-redex, with a reduct of "M".

α-conversion, sometimes known as α-renaming, allows bound variable names to be changed. For example, α-conversion of λ"x"."x" might yield λ"y"."y". Terms that differ only by α-conversion are called "α-equivalent". Frequently, in uses of lambda calculus, α-equivalent terms are considered to be equivalent.

The precise rules for α-conversion are not completely trivial. First, when α-converting an abstraction, the only variable occurrences that are renamed are those that are bound to the same abstraction. For example, an α-conversion of λ"x".λ"x"."x" could result in λ"y".λ"x"."x", but it could "not" result in λ"y".λ"x"."y". The latter has a different meaning from the original. This is analogous to the programming notion of variable shadowing.

Second, α-conversion is not possible if it would result in a variable getting captured by a different abstraction. For example, if we replace "x" with "y" in λ"x".λ"y"."x", we get λ"y".λ"y"."y", which is not at all the same.

In programming languages with static scope, α-conversion can be used to make name resolution simpler by ensuring that no variable name masks a name in a containing scope (see α-renaming to make name resolution trivial).

In the De Bruijn index notation, any two α-equivalent terms are syntactically identical.

Substitution, written "M"["V" := "N"], is the process of replacing all "free" occurrences of the variable "V" in the expression "M" with expression "N". Substitution on terms of the lambda calculus is defined by recursion on the structure of terms, as follows (note: x and y are only variables while M and N are any lambda expression):

To substitute into an abstraction, it is sometimes necessary to α-convert the expression. For example, it is not correct for (λ"x"."y")["y" := "x"] to result in λ"x"."x", because the substituted "x" was supposed to be free but ended up being bound. The correct substitution in this case is λ"z"."x", up to α-equivalence. Substitution is defined uniquely up to α-equivalence.

β-reduction captures the idea of function application. β-reduction is defined in terms of substitution: the β-reduction of (λ"V"."M") "N" is "M"["V" := "N"].

For example, assuming some encoding of 2, 7, ×, we have the following β-reduction: (λ"n"."n" × 2) 7 → 7 × 2.

β-reduction can be seen to be the same as the concept of "local reducibility" in natural deduction, via the Curry–Howard isomorphism.

η-reduction expresses the idea of extensionality, which in this context is that two functions are the same if and only if they give the same result for all arguments. η-reduction converts between λ"x"."f" "x" and "f" whenever "x" does not appear free in "f".

η-reduction can be seen to be the same as the concept of "local completeness" in natural deduction, via the Curry–Howard isomorphism.

For the untyped lambda calculus, β-reduction as a rewriting rule is neither strongly normalising nor weakly normalising.

However, it can be shown that β-reduction is confluent when working up to α-conversion (i.e. we consider two normal forms to be equal if it is possible to α-convert one into the other).

Therefore, both strongly normalising terms and weakly normalising terms have a unique normal form. For strongly normalising terms, any reduction strategy is guaranteed to yield the normal form, whereas for weakly normalising terms, some reduction strategies may fail to find it.

The basic lambda calculus may be used to model booleans, arithmetic, data structures and recursion, as illustrated in the following sub-sections.

There are several possible ways to define the natural numbers in lambda calculus, but by far the most common are the Church numerals, which can be defined as follows:
and so on. Or using the alternative syntax presented above in "Notation":

A Church numeral is a higher-order function—it takes a single-argument function "f", and returns another single-argument function. The Church numeral "n" is a function that takes a function "f" as argument and returns the "n"-th composition of "f", i.e. the function "f" composed with itself "n" times. This is denoted "f" and is in fact the "n"-th power of "f" (considered as an operator); "f" is defined to be the identity function. Such repeated compositions (of a single function "f") obey the laws of exponents, which is why these numerals can be used for arithmetic. (In Church's original lambda calculus, the formal parameter of a lambda expression was required to occur at least once in the function body, which made the above definition of 0 impossible.)

One way of thinking about the Church numeral "n", which is often useful when analysing programs, is as an instruction 'repeat "n" times'. For example, using the PAIR and NIL functions defined below, one can define a function that constructs a (linked) list of "n" elements all equal to "x" by repeating 'prepend another "x" element' "n" times, starting from an empty list. The lambda term is
By varying what is being repeated, and varying what argument that function being repeated is applied to, a great many different effects can be achieved.

We can define a successor function, which takes a Church numeral "n" and returns "n" + 1 by adding another application of "f", where '(mf)x' means the function 'f' is applied 'm' times on 'x':
Because the "m"-th composition of "f" composed with the "n"-th composition of "f" gives the "m"+"n"-th composition of "f", addition can be defined as follows:
PLUS can be thought of as a function taking two natural numbers as arguments and returning a natural number; it can be verified that
and
are β-equivalent lambda expressions. Since adding "m" to a number "n" can be accomplished by adding 1 "m" times, an alternative definition is:
Similarly, multiplication can be defined as
Alternatively
since multiplying "m" and "n" is the same as repeating the add "n" function "m" times and then applying it to zero.
Exponentiation has a rather simple rendering in Church numerals, namely
The predecessor function defined by PRED "n" = "n" − 1 for a positive integer "n" and PRED 0 = 0 is considerably more difficult. The formula
can be validated by showing inductively that if "T" denotes (λ"g".λ"h"."h" ("g" "f")), then T(λ"u"."x") = (λ"h"."h"("f"("x"))) for "n" > 0. Two other definitions of PRED are given below, one using conditionals and the other using pairs. With the predecessor function, subtraction is straightforward. Defining
SUB "m" "n" yields "m" − "n" when "m" > "n" and 0 otherwise.

By convention, the following two definitions (known as Church booleans) are used for the boolean values TRUE and FALSE:
Then, with these two lambda terms, we can define some logic operators (these are just possible formulations; other expressions are equally correct):
We are now able to compute some logic functions, for example:

and we see that AND TRUE FALSE is equivalent to FALSE.

A "predicate" is a function that returns a boolean value. The most fundamental predicate is ISZERO, which returns TRUE if its argument is the Church numeral 0, and FALSE if its argument is any other Church numeral:
The following predicate tests whether the first argument is less-than-or-equal-to the second:
and since "m" = "n", if LEQ "m" "n" and LEQ "n" "m", it is straightforward to build a predicate for numerical equality.

The availability of predicates and the above definition of TRUE and FALSE make it convenient to write "if-then-else" expressions in lambda calculus. For example, the predecessor function can be defined as:
which can be verified by showing inductively that "n" (λ"g".λ"k".ISZERO ("g" 1) "k" (PLUS ("g" "k") 1)) (λ"v".0) is the add "n" − 1 function for "n" > 0.

A pair (2-tuple) can be defined in terms of TRUE and FALSE, by using the Church encoding for pairs. For example, PAIR encapsulates the pair ("x","y"), FIRST returns the first element of the pair, and SECOND returns the second.

A linked list can be defined as either NIL for the empty list, or the PAIR of an element and a smaller list. The predicate NULL tests for the value NIL. (Alternatively, with NIL := FALSE, the construct "l" (λ"h".λ"t".λ"z".deal_with_head_"h"_and_tail_"t") (deal_with_nil) obviates the need for an explicit NULL test).

As an example of the use of pairs, the shift-and-increment function that maps ("m", "n") to ("n", "n" + 1) can be defined as
which allows us to give perhaps the most transparent version of the predecessor function:

There is a considerable body of programming idioms for lambda calculus. Many of these were originally developed in the context of using lambda calculus as a foundation for programming language semantics, effectively using lambda calculus as a low-level programming language. Because several programming languages include the lambda calculus (or something very similar) as a fragment, these techniques also see use in practical programming, but may then be perceived as obscure or foreign.

In lambda calculus, a library would take the form of a collection of previously defined functions, which as lambda-terms are merely particular constants. The pure lambda calculus does not have a concept of named constants since all atomic lambda-terms are variables, but one can emulate having named constants by setting aside a variable as the name of the constant, using abstraction to bind that variable in the main body, and apply that abstraction to the intended definition. Thus to use "f" to mean "M" (some explicit lambda-term) in "N" (another lambda-term, the "main program"), one can say
Authors often introduce syntactic sugar, such as let, to permit writing the above in the more intuitive order
By chaining such definitions, one can write a lambda calculus "program" as zero or more function definitions, followed by one lambda-term using those functions that constitutes the main body of the program.

A notable restriction of this let is that the name "f" is not defined in "M", since "M" is outside the scope of the abstraction binding "f"; this means a recursive function definition cannot be used as the "M" with let. The more advanced letrec syntactic sugar construction that allows writing recursive function definitions in that naive style instead additionally employs fixed-point combinators.

Recursion is the definition of a function using the function itself. Lambda calculus cannot express this as directly as some other notations: all functions are anonymous in lambda calculus, so we can't refer to a value which is yet to be defined, inside the lambda term defining that same value. However, recursion can still be achieved by arranging for a lambda expression to receive itself as its argument value, for example in  (λ"x"."x" "x") "E".

Consider the factorial function F("n") recursively defined by

In the lambda expression which is to represent this function, a "parameter" (typically the first one) will be assumed to receive the lambda expression itself as its value, so that calling it – applying it to an argument – will amount to recursion. Thus to achieve recursion, the intended-as-self-referencing argument (called "r" here) must always be passed to itself within the function body, at a call point:

The self-application achieves replication here, passing the function's lambda expression on to the next invocation as an argument value, making it available to be referenced and called there.

This solves it but requires re-writing each recursive call as self-application. We would like to have a generic solution, without a need for any re-writes:

Given a lambda term with first argument representing recursive call (e.g. G here), the "fixed-point" combinator FIX will return a self-replicating lambda expression representing the recursive function (here, F). The function does not need to be explicitly passed to itself at any point, for the self-replication is arranged in advance, when it is created, to be done each time it is called. Thus the original lambda expression (FIX G) is re-created inside itself, at call-point, achieving self-reference.

In fact, there are many possible definitions for this FIX operator, the simplest of them being:

In the lambda calculus, Y "g"  is a fixed-point of "g", as it expands to:

Now, to perform our recursive call to the factorial function, we would simply call (Y G) "n",  where "n" is the number we are calculating the factorial of. Given "n" = 4, for example, this gives:

Every recursively defined function can be seen as a fixed point of some suitably defined function closing over the recursive call with an extra argument, and therefore, using Y, every recursively defined function can be expressed as a lambda expression. In particular, we can now cleanly define the subtraction, multiplication and comparison predicate of natural numbers recursively.

Certain terms have commonly accepted names :
Several of these have direct applications in the "elimination of abstraction" that turns lambda terms into combinator calculus terms.

If "N" is a lambda-term without abstraction, but possibly containing named constants (combinators), then there exists a lambda-term "T"("x","N") which is equivalent to λ"x"."N" but lacks abstraction (except as part of the named constants, if these are considered non-atomic). This can also be viewed as anonymising variables, as "T"("x","N") removes all occurrences of "x" from "N", while still allowing argument values to be substituted into the positions where "N" contains an "x". The conversion function "T" can be defined by:
In either case, a term of the form "T"("x","N") "P" can reduce by having the initial combinator I, K, or S grab the argument "P", just like β-reduction of (λ"x"."N") "P" would do. I returns that argument. K throws the argument away, just like (λ"x"."N") would do if "x" has no free occurrence in "N". S passes the argument on to both subterms of the application, and then applies the result of the first to the result of the second.

The combinators B and C are similar to S, but pass the argument on to only one subterm of an application (B to the "argument" subterm and C to the "function" subterm), thus saving a subsequent K if there is no occurrence of "x" in one subterm. In comparison to B and C, the S combinator actually conflates two functionalities: rearranging arguments, and duplicating an argument so that it may be used in two places. The W combinator does only the latter, yielding the B, C, K, W system as an alternative to SKI combinator calculus.

A typed lambda calculus is a typed formalism that uses the lambda-symbol (formula_122) to denote anonymous function abstraction. In this context, types are usually objects of a syntactic nature that are assigned to lambda terms; the exact nature of a type depends on the calculus considered (see Kinds of typed lambda calculi). From a certain point of view, typed lambda calculi can be seen as refinements of the untyped lambda calculus but from another point of view, they can also be considered the more fundamental theory and "untyped lambda calculus" a special case with only one type.

Typed lambda calculi are foundational programming languages and are the base of typed functional programming languages such as ML and Haskell and, more indirectly, typed imperative programming languages. Typed lambda calculi play an important role in the design of type systems for programming languages; here typability usually captures desirable properties of the program, e.g. the program will not cause a memory access violation.

Typed lambda calculi are closely related to mathematical logic and proof theory via the Curry–Howard isomorphism and they can be considered as the internal language of classes of categories, e.g. the simply typed lambda calculus is the language of Cartesian closed categories (CCCs).

A function "F": N → N of natural numbers is a computable function if and only if there exists a lambda expression "f" such that for every pair of "x", "y" in N, "F"("x")="y" if and only if "f" "x" = "y",  where "x" and "y" are the Church numerals corresponding to "x" and "y", respectively and = meaning equivalence with β-reduction. This is one of the many ways to define computability; see the Church–Turing thesis for a discussion of other approaches and their equivalence.

There is no algorithm that takes as input any two lambda expressions and outputs TRUE or FALSE depending on whether or not the two expressions are equivalent. More precisely, no computable function can decide the equivalence. This was historically the first problem for which undecidability could be proven. As usual for such a proof, "computable" means computable by any model of computation that is Turing complete.

Church's proof first reduces the problem to determining whether a given lambda expression has a "normal form". A normal form is an equivalent expression that cannot be reduced any further under the rules imposed by the form. Then he assumes that this predicate is computable, and can hence be expressed in lambda calculus. Building on earlier work by Kleene and constructing a Gödel numbering for lambda expressions, he constructs a lambda expression "e" that closely follows the proof of Gödel's first incompleteness theorem. If "e" is applied to its own Gödel number, a contradiction results.

As pointed out by Peter Landin's 1965 paper "A Correspondence between ALGOL 60 and Church's Lambda-notation", sequential procedural programming languages can be understood in terms of the lambda calculus, which provides the basic mechanisms for procedural abstraction and procedure (subprogram) application.

For example, in Lisp the "square" function can be expressed as a lambda expression as follows:
The above example is an expression that evaluates to a first-class function. The symbol codice_1 creates an anonymous function, given a list of parameter names, codice_2 – just a single argument in this case, and an expression that is evaluated as the body of the function, codice_3. Anonymous functions are sometimes called lambda expressions.

For example, Pascal and many other imperative languages have long supported passing subprograms as arguments to other subprograms through the mechanism of function pointers. However, function pointers are not a sufficient condition for functions to be first class datatypes, because a function is a first class datatype if and only if new instances of the function can be created at run-time. And this run-time creation of functions is supported in Smalltalk, JavaScript, and more recently in Scala, Eiffel ("agents"), C# ("delegates") and C++11, among others.

Whether a term is normalising or not, and how much work needs to be done in normalising it if it is, depends to a large extent on the reduction strategy used. The distinction between reduction strategies relates to the distinction in functional programming languages between eager evaluation and lazy evaluation.


Applicative order is not a normalising strategy. The usual counterexample is as follows: define Ω = ωω where ω = λ"x"."xx". This entire expression contains only one redex, namely the whole expression; its reduct is again Ω. Since this is the only available reduction, Ω has no normal form (under any evaluation strategy). Using applicative order, the expression KIΩ = (λ"x".λ"y"."x") (λ"x"."x")Ω is reduced by first reducing Ω to normal form (since it is the rightmost redex), but since Ω has no normal form, applicative order fails to find a normal form for KIΩ.

In contrast, normal order is so called because it always finds a normalising reduction, if one exists. In the above example, KIΩ reduces under normal order to "I", a normal form. A drawback is that redexes in the arguments may be copied, resulting in duplicated computation (for example, (λ"x"."xx") ((λ"x"."x")"y") reduces to ((λ"x"."x")"y") ((λ"x"."x")"y") using this strategy; now there are two redexes, so full evaluation needs two more steps, but if the argument had been reduced first, there would now be none).

The positive tradeoff of using applicative order is that it does not cause unnecessary computation, if all arguments are used, because it never substitutes arguments containing redexes and hence never needs to copy them (which would duplicate work). In the above example, in applicative order (λ"x"."xx") ((λ"x"."x")"y") reduces first to (λ"x"."xx")"y" and then to the normal order "yy", taking two steps instead of three.

Most "purely" functional programming languages (notably Miranda and its descendants, including Haskell), and the proof languages of theorem provers, use "lazy evaluation", which is essentially the same as call by need. This is like normal order reduction, but call by need manages to avoid the duplication of work inherent in normal order reduction using "sharing". In the example given above, (λ"x"."xx") ((λ"x"."x")"y") reduces to ((λ"x"."x")"y") ((λ"x"."x")"y"), which has two redexes, but in call by need they are represented using the same object rather than copied, so when one is reduced the other is too.

While the idea of β-reduction seems simple enough, it is not an atomic step, in that it must have a non-trivial cost when estimating computational complexity. To be precise, one must somehow find the location of all of the occurrences of the bound variable "V" in the expression "E", implying a time cost, or one must keep track of these locations in some way, implying a space cost. A naïve search for the locations of "V" in "E" is "O"("n") in the length "n" of "E". This has led to the study of systems that use explicit substitution. Sinot's director strings offer a way of tracking the locations of free variables in expressions.

The Church–Rosser property of the lambda calculus means that evaluation (β-reduction) can be carried out in "any order", even in parallel. This means that various nondeterministic evaluation strategies are relevant. However, the lambda calculus does not offer any explicit constructs for parallelism. One can add constructs such as Futures to the lambda calculus. Other process calculi have been developed for describing communication and concurrency.

In Lévy's 1988 paper "Sharing in the Evaluation of lambda Expressions", he defines a notion of optimal sharing, such that no work is "duplicated". For example, performing a β-reduction in normal order on (λ"x"."xx") (II) reduces it to II (II). The argument II is duplicated by the application to the first lambda term. If the reduction was done in an applicative order first, we save work because work is not duplicated: (λ"x"."xx") (II) reduces to (λ"x"."xx") I. On the other hand, using applicative order can result in redundant reductions or even possibly never reduce to normal form. For example, performing a β-reduction in normal order on (λ"f".f I) (λy.(λ"x"."xx") (y I)) yields (λy.(λ"x"."xx") (y I)) I, (λ"x"."xx") (II) which we know we can do without duplicating work. Doing the same but in applicative order yields (λ"f".f I) (λy.y I (y I)), (λy.y I (y I)) I, I I (I I), and now work is duplicated.

Lévy shows the existence of lambda terms where there "does not exist" a sequence of reductions which reduces them without duplicating work. The below lambda term is such an example.

It is composed of three similar terms, x=((λg. ... ) (λh.y)) and y=((λf. ...) (λw.z) ), and finally z=λw.(h(w(λy.y))). There are only two possible β-reductions to be done here, on x and on y. Reducing the outer x term first results in the inner y term being duplicated, and each copy will have to be reduced, but reducing the inner y term first will duplicate its argument z, which will cause work to be duplicated when the values of h and w are made known. Incidentally, the above term reduces to the identity function (λy.y), and is constructed by making wrappers which make the identity function available to the binders g=λh..., f=λw..., h=λx.x (at first), and w=λz.z (at first), all of which are applied to the innermost term λy.y.

The precise notion of duplicated work relies on noticing that after the first reduction of I I is done, the value of the other I I can be determined, because they have the same structure (and in fact they have exactly the same values), and result from a common ancestor. Such similar structures can each be assigned a label that can be tracked across reductions. If a name is assigned to the redex that produces all the resulting II terms, and then all duplicated occurrences of II can be tracked and reduced in one go. However, it is not obvious that a redex will produce the II term. Identifying the structures that are similar in different parts of a lambda term can involve a complex algorithm and can possibly have a complexity equal to the history of the reduction itself.

While Lévy defines the notion of optimal sharing, he does not provide an algorithm to do it. In Vincent van Oostrom, Kees-Jan van de Looij, and Marijn Zwitserlood's paper "Lambdascope: Another optimal implementation of the lambda-calculus", they provide such an algorithm by transforming lambda terms into interaction nets, which are then reduced. Roughly speaking, the resulting reduction is optimal because every term that would have the same labels as per Lévy's paper would also be the same graph in the interaction net. In the paper, they mention that their prototype implementation of Lambdascope performs as well as the "optimised" version of the reference optimal higher order machine BOHM.

More details can be found in the short article About the efficient reduction of lambda terms.

The fact that lambda calculus terms act as functions on other lambda calculus terms, and even on themselves, led to questions about the semantics of the lambda calculus. Could a sensible meaning be assigned to lambda calculus terms? The natural semantics was to find a set "D" isomorphic to the function space "D" → "D", of functions on itself. However, no nontrivial such "D" can exist, by cardinality constraints because the set of all functions from "D" to "D" has greater cardinality than "D", unless "D" is a singleton set.

In the 1970s, Dana Scott showed that, if only continuous functions were considered, a set or domain "D" with the required property could be found, thus providing a model for the lambda calculus.

This work also formed the basis for the denotational semantics of programming languages.

These extensions are in the lambda cube:

These formal systems are extensions of lambda calculus that are not in the lambda cube:

These formal systems are variations of lambda calculus:

These formal systems are related to lambda calculus:

Monographs/textbooks for graduate students:

"Some parts of this article are based on material from FOLDOC, used with ."



</doc>
<doc id="18208" url="https://en.wikipedia.org/wiki?curid=18208" title="Lossy compression">
Lossy compression

In information technology, lossy compression or irreversible compression is the class of data encoding methods that uses inexact approximations and partial data discarding to represent the content. These techniques are used to reduce data size for storing, handling, and transmitting content. The different versions of the photo of the cat to the right show how higher degrees of approximation create coarser images as more details are removed. This is opposed to lossless data compression (reversible data compression) which does not degrade the data. The amount of data reduction possible using lossy compression is much higher than through lossless techniques.

Well-designed lossy compression technology often reduces file sizes significantly before degradation is noticed by the end-user. Even when noticeable by the user, further data reduction may be desirable (e.g., for real-time communication, to reduce transmission times, or to reduce storage needs). The most widely used lossy compression algorithm is the discrete cosine transform (DCT), first published by Nasir Ahmed, T. Natarajan and K. R. Rao in 1974. Recently, a new family of sinusoidal-hyperbolic transform functions, which have comparable properties and performance with DCT, have been proposed for lossy compression.

Lossy compression is most commonly used to compress multimedia data (audio, video, and images), especially in applications such as streaming media and internet telephony. By contrast, lossless compression is typically required for text and data files, such as bank records and text articles. It can be advantageous to make a master lossless file which can then be used to produce additional copies from. This allows one to avoid basing new compressed copies off of a lossy source file, which would yield additional artifacts and further unnecessary information loss.

It is possible to compress many types of digital data in a way that reduces the size of a computer file needed to store it, or the bandwidth needed to transmit it, with no loss of the full information contained in the original file. A picture, for example, is converted to a digital file by considering it to be an array of dots and specifying the color and brightness of each dot. If the picture contains an area of the same color, it can be compressed without loss by saying "200 red dots" instead of "red dot, red dot, ...(197 more times)..., red dot."

The original data contains a certain amount of information, and there is a lower limit to the size of file that can carry all the information. Basic information theory says that there is an absolute limit in reducing the size of this data. When data is compressed, its entropy increases, and it cannot increase indefinitely. As an intuitive example, most people know that a compressed ZIP file is smaller than the original file, but repeatedly compressing the same file will not reduce the size to nothing. Most compression algorithms can recognize when further compression would be pointless and would in fact increase the size of the data.

In many cases, files or data streams contain more information than is needed for a particular purpose. For example, a picture may have more detail than the eye can distinguish when reproduced at the largest size intended; likewise, an audio file does not need a lot of fine detail during a very loud passage. Developing lossy compression techniques as closely matched to human perception as possible is a complex task. Sometimes the ideal is a file that provides exactly the same perception as the original, with as much digital information as possible removed; other times, perceptible loss of quality is considered a valid trade-off for the reduced data.

The terms 'irreversible' and 'reversible' are preferred over 'lossy' and 'lossless' respectively for some applications, such as medical image compression, to circumvent the negative implications of 'loss'. The type and amount of loss can affect the utility of the images. Artifacts or undesirable effects of compression may be clearly discernible yet the result still useful for the intended purpose. Or lossy compressed images may be 'visually lossless', or in the case of medical images, so-called Diagnostically Acceptable Irreversible Compression (DAIC) may have been applied.

Some forms of lossy compression can be thought of as an application of transform coding, which is a type of data compression used for digital images, digital audio signals, and digital video. The transformation is typically used to enable better (more targeted) quantization. Knowledge of the application is used to choose information to discard, thereby lowering its bandwidth. The remaining information can then be compressed via a variety of methods. When the output is decoded, the result may not be identical to the original input, but is expected to be close enough for the purpose of the application.

The most common form of lossy compression is a transform coding method, the discrete cosine transform (DCT), which was first published by Nasir Ahmed, T. Natarajan and K. R. Rao in 1974. DCT is the most widely used form of lossy compression, for popular image compression formats (such as JPEG), video coding standards (such as MPEG and H.264/AVC) and audio compression formats (such as MP3 and AAC).

In the case of audio data, a popular form of transform coding is perceptual coding, which transforms the raw data to a domain that more accurately reflects the information content. For example, rather than expressing a sound file as the amplitude levels over time, one may express it as the frequency spectrum over time, which corresponds more accurately to human audio perception. While data reduction (compression, be it lossy or lossless) is a main goal of transform coding, it also allows other goals: one may represent data more accurately for the original amount of space – for example, in principle, if one starts with an analog or high-resolution digital master, an MP3 file of a given size should provide a better representation than a raw uncompressed audio in WAV or AIFF file of the same size. This is because uncompressed audio can only reduce file size by lowering bit rate or depth, whereas compressing audio can reduce size while maintaining bit rate and depth. This compression becomes a selective loss of the least significant data, rather than losing data across the board. Further, a transform coding may provide a better domain for manipulating or otherwise editing the data – for example, equalization of audio is most naturally expressed in the frequency domain (boost the bass, for instance) rather than in the raw time domain.

From this point of view, perceptual encoding is not essentially about "discarding" data, but rather about a "better representation" of data. Another use is for backward compatibility and graceful degradation: in color television, encoding color via a luminance-chrominance transform domain (such as YUV) means that black-and-white sets display the luminance, while ignoring the color information. Another example is chroma subsampling: the use of color spaces such as YIQ, used in NTSC, allow one to reduce the resolution on the components to accord with human perception – humans have highest resolution for black-and-white (luma), lower resolution for mid-spectrum colors like yellow and green, and lowest for red and blues – thus NTSC displays approximately 350 pixels of luma per scanline, 150 pixels of yellow vs. green, and 50 pixels of blue vs. red, which are proportional to human sensitivity to each component.

Lossy compression formats suffer from generation loss: repeatedly compressing and decompressing the file will cause it to progressively lose quality. This is in contrast with lossless data compression, where data will not be lost via the use of such a procedure. Information-theoretical foundations for lossy data compression are provided by rate-distortion theory. Much like the use of probability in optimal coding theory, rate-distortion theory heavily draws on Bayesian estimation and decision theory in order to model perceptual distortion and even aesthetic judgment.

There are two basic lossy compression schemes:


In some systems the two techniques are combined, with transform codecs being used to compress the error signals generated by the predictive stage.

The advantage of lossy methods over lossless methods is that in some cases a lossy method can produce a much smaller compressed file than any lossless method, while still meeting the requirements of the application. Lossy methods are most often used for compressing sound, images or videos. This is because these types of data are intended for human interpretation where the mind can easily "fill in the blanks" or see past very minor errors or inconsistencies – ideally lossy compression is transparent (imperceptible), which can be verified via an ABX test. Data files using lossy compression are smaller in size and thus cost less to store and to transmit over the Internet, a crucial consideration for streaming video services such as Netflix and streaming audio services such as Spotify.

A study conducted by the Audio Engineering Library concluded that lossy compression formats such as MP3s have distinct effects on timbral and emotional characteristics, tending to strengthen negative emotional qualities and weaken positive ones. The study further noted that the trumpet is the instrument most affected by compression, while the horn is least.

When a user acquires a lossily compressed file, (for example, to reduce download time) the retrieved file can be quite different from the original at the bit level while being indistinguishable to the human ear or eye for most practical purposes. Many compression methods focus on the idiosyncrasies of human physiology, taking into account, for instance, that the human eye can see only certain wavelengths of light. The psychoacoustic model describes how sound can be highly compressed without degrading perceived quality. Flaws caused by lossy compression that are noticeable to the human eye or ear are known as compression artifacts.

The compression ratio (that is, the size of the compressed file compared to that of the uncompressed file) of lossy video codecs is nearly always far superior to that of the audio and still-image equivalents.


An important caveat about lossy compression (formally transcoding), is that editing lossily compressed files causes digital generation loss from the re-encoding. This can be avoided by only producing lossy files from (lossless) originals and only editing (copies of) original files, such as images in raw image format instead of JPEG. If data which has been compressed lossily is decoded and compressed losslessly, the size of the result can be comparable with the size of the data before lossy compression, but the data already lost cannot be recovered. When deciding to use lossy conversion without keeping the original, one should remember that format conversion may be needed in the future to achieve compatibility with software or devices (format shifting), or to avoid paying patent royalties for decoding or distribution of compressed files.

By modifying the compressed data directly without decoding and re-encoding, some editing of lossily compressed files without degradation of quality is possible. Editing which reduces the file size as if it had been compressed to a greater degree, but without more loss than this, is sometimes also possible.

The primary programs for lossless editing of JPEGs are codice_1, and the derived codice_2 (which also preserves Exif information), and Jpegcrop (which provides a Windows interface).

These allow the image to be
While unwanted information is destroyed, the quality of the remaining portion is unchanged.

Some other transforms are possible to some extent, such as joining images with the same encoding (composing side by side, as on a grid) or pasting images (such as logos) onto existing images (both via Jpegjoin), or scaling.

Some changes can be made to the compression without re-encoding:

The freeware Windows-only IrfanView has some lossless JPEG operations in its codice_3 plugin.

Metadata, such as ID3 tags, Vorbis comments, or Exif information, can usually be modified or removed without modifying the underlying data.

One may wish to downsample or otherwise decrease the resolution of the represented source signal and the quantity of data used for its compressed representation without re-encoding, as in bitrate peeling, but this functionality is not supported in all designs, as not all codecs encode data in a form that allows less important detail to simply be dropped. Some well-known designs that have this capability include JPEG 2000 for still images and H.264/MPEG-4 AVC based Scalable Video Coding for video. Such schemes have also been standardized for older designs as well, such as JPEG images with progressive encoding, and MPEG-2 and MPEG-4 Part 2 video, although those prior schemes had limited success in terms of adoption into real-world common usage. Without this capacity, which is often the case in practice, to produce a representation with lower resolution or lower fidelity than a given one, one needs to start with the original source signal and encode, or start with a compressed representation and then decompress and re-encode it (transcoding), though the latter tends to cause digital generation loss.

Another approach is to encode the original signal at several different bitrates, and then either choose which to use (as when streaming over the internet – as in RealNetworks' "SureStream" – or offering varying downloads, as at Apple's iTunes Store), or broadcast several, where the best that is successfully received is used, as in various implementations of hierarchical modulation. Similar techniques are used in mipmaps, pyramid representations, and more sophisticated scale space methods. Some audio formats feature a combination of a lossy format and a lossless correction which when combined reproduce the original signal; the correction can be stripped, leaving a smaller, lossily compressed, file. Such formats include MPEG-4 SLS (Scalable to Lossless), WavPack, OptimFROG DualStream, and DTS-HD Master Audio in lossless (XLL) mode).





Researchers have (semi-seriously) performed lossy compression on text by either using a thesaurus to substitute short words for long ones, or generative text techniques, although these sometimes fall into the related category of lossy data conversion.

A general kind of lossy compression is to lower the resolution of an image, as in image scaling, particularly decimation. One may also remove less "lower information" parts of an image, such as by seam carving. Many media transforms, such as Gaussian blur, are, like lossy compression, irreversible: the original signal cannot be reconstructed from the transformed signal. However, in general these will have the same size as the original, and are not a form of compression. Lowering resolution has practical uses, as the NASA New Horizons craft will transmit thumbnails of its encounter with Pluto-Charon before it sends the higher resolution images. Another solution for slow connections is the usage of Image interlacing which progressively defines the image. Thus a partial transmission is enough to preview the final image, in a lower resolution version, without creating a scaled and a full version too.


(Wayback Machine copy)


</doc>
<doc id="18209" url="https://en.wikipedia.org/wiki?curid=18209" title="Lossless compression">
Lossless compression

Lossless compression is a class of data compression algorithms that allows the original data to be perfectly reconstructed from the compressed data. By contrast, lossy compression permits reconstruction only of an approximation of the original data, though usually with greatly improved compression rates (and therefore reduced media sizes).

By operation of the pigeonhole principle, no lossless compression algorithm can efficiently compress all possible data. For this reason, many different algorithms exist that are designed either with a specific type of input data in mind or with specific assumptions about what kinds of redundancy the uncompressed data are likely to contain.

Lossless data compression is used in many applications. For example, it is used in the ZIP file format and in the GNU tool gzip. It is also often used as a component within lossy data compression technologies (e.g. lossless mid/side joint stereo preprocessing by MP3 encoders and other lossy audio encoders).

Lossless compression is used in cases where it is important that the original and the decompressed data be identical, or where deviations from the original data would be unfavourable. Typical examples are executable programs, text documents, and source code. Some image file formats, like PNG or GIF, use only lossless compression, while others like TIFF and MNG may use either lossless or lossy methods. Lossless audio formats are most often used for archiving or production purposes, while smaller lossy audio files are typically used on portable players and in other cases where storage space is limited or exact replication of the audio is unnecessary.

Most lossless compression programs do two things in sequence: the first step generates a "statistical model" for the input data, and the second step uses this model to map input data to bit sequences in such a way that "probable" (e.g. frequently encountered) data will produce shorter output than "improbable" data.

The primary encoding algorithms used to produce bit sequences are Huffman coding (also used by DEFLATE) and arithmetic coding. Arithmetic coding achieves compression rates close to the best possible for a particular statistical model, which is given by the information entropy, whereas Huffman compression is simpler and faster but produces poor results for models that deal with symbol probabilities close to 1.

There are two primary ways of constructing statistical models: in a "static" model, the data is analyzed and a model is constructed, then this model is stored with the compressed data. This approach is simple and modular, but has the disadvantage that the model itself can be expensive to store, and also that it forces using a single model for all data being compressed, and so performs poorly on files that contain heterogeneous data. "Adaptive" models dynamically update the model as the data is compressed. Both the encoder and decoder begin with a trivial model, yielding poor compression of initial data, but as they learn more about the data, performance improves. Most popular types of compression used in practice now use adaptive coders.

Lossless compression methods may be categorized according to the type of data they are designed to compress. While, in principle, any general-purpose lossless compression algorithm ("general-purpose" meaning that they can accept any bitstring) can be used on any type of data, many are unable to achieve significant compression on data that are not of the form for which they were designed to compress. Many of the lossless compression techniques used for text also work reasonably well for indexed images.

These techniques take advantage of the specific characteristics of images such as the common phenomenon of contiguous 2-D areas of similar tones.
Every pixel but the first is replaced by the difference to its left neighbor. This leads to small values having a much higher probability than large values.
This is often also applied to sound files, and can compress files that contain mostly low frequencies and low volumes.
For images, this step can be repeated by taking the difference to the top pixel, and then in videos, the difference to the pixel in the next frame can be taken.

A hierarchical version of this technique takes neighboring pairs of data points, stores their difference and sum, and on a higher level with lower resolution continues with the sums. This is called discrete wavelet transform. JPEG2000 additionally uses data points from other pairs and multiplication factors to mix them into the difference. These factors must be integers, so that the result is an integer under all circumstances. So the values are increased, increasing file size, but hopefully the distribution of values is more peaked. 

The adaptive encoding uses the probabilities from the previous sample in sound encoding, from the left and upper pixel in image encoding, and additionally from the previous frame in video encoding. In the wavelet transformation, the probabilities are also passed through the hierarchy.

Many of these methods are implemented in open-source and proprietary tools, particularly LZW and its variants. Some algorithms are patented in the United States and other countries and their legal usage requires licensing by the patent holder. Because of patents on certain kinds of LZW compression, and in particular licensing practices by patent holder Unisys that many developers considered abusive, some open source proponents encouraged people to avoid using the Graphics Interchange Format (GIF) for compressing still image files in favor of Portable Network Graphics (PNG), which combines the LZ77-based deflate algorithm with a selection of domain-specific prediction filters. However, the patents on LZW expired on June 20, 2003.

Many of the lossless compression techniques used for text also work reasonably well for indexed images, but there are other techniques that do not work for typical text that are useful for some images (particularly simple bitmaps), and other techniques that take advantage of the specific characteristics of images (such as the common phenomenon of contiguous 2-D areas of similar tones, and the fact that color images usually have a preponderance of a limited range of colors out of those representable in the color space).

As mentioned previously, lossless sound compression is a somewhat specialized area. Lossless sound compression algorithms can take advantage of the repeating patterns shown by the wave-like nature of the data – essentially using autoregressive models to predict the "next" value and encoding the (hopefully small) difference between the expected value and the actual data. If the difference between the predicted and the actual data (called the "error") tends to be small, then certain difference values (like 0, +1, −1 etc. on sample values) become very frequent, which can be exploited by encoding them in few output bits.

It is sometimes beneficial to compress only the differences between two versions of a file (or, in video compression, of successive images within a sequence). This is called delta encoding (from the Greek letter Δ, which in mathematics, denotes a difference), but the term is typically only used if both versions are meaningful outside compression and decompression. For example, while the process of compressing the error in the above-mentioned lossless audio compression scheme could be described as delta encoding from the approximated sound wave to the original sound wave, the approximated version of the sound wave is not meaningful in any other context.

No lossless compression algorithm can efficiently compress all possible data (see the section Limitations below for details). For this reason, many different algorithms exist that are designed either with a specific type of input data in mind or with specific assumptions about what kinds of redundancy the uncompressed data are likely to contain.

Some of the most common lossless compression algorithms are listed below.





See this list of lossless video codecs.

Cryptosystems often compress data (the "plaintext") "before" encryption for added security. When properly implemented, compression greatly increases the unicity distance by removing patterns that might facilitate cryptanalysis. However, many ordinary lossless compression algorithms produce headers, wrappers, tables, or other predictable output that might instead make cryptanalysis easier. Thus, cryptosystems must utilize compression algorithms whose output does not contain these predictable patterns.

Genetics compression algorithms (not to be confused with genetic algorithms) are the latest generation of lossless algorithms that compress data (typically sequences of nucleotides) using both conventional compression algorithms and specific algorithms adapted to genetic data. In 2012, a team of scientists from Johns Hopkins University published the first genetic compression algorithm that does not rely on external genetic databases for compression. HAPZIPPER was tailored for HapMap data and achieves over 20-fold compression (95% reduction in file size), providing 2- to 4-fold better compression much faster than leading general-purpose compression utilities.

Genomic sequence compression algorithms, also known as DNA sequence compressors, explore the fact that DNA sequences have characteristic properties, such as inverted repeats. The most successful compressors are XM and GeCo. For eukaryotes XM is slightly better in compression ratio, though for sequences larger than 100 MB its computational requirements are impractical.

Self-extracting executables contain a compressed application and a decompressor. When executed, the decompressor transparently decompresses and runs the original application. This is especially often used in demo coding, where competitions are held for demos with strict size limits, as small as 1k.
This type of compression is not strictly limited to binary executables, but can also be applied to scripts, such as JavaScript.

Lossless compression algorithms and their implementations are routinely tested in head-to-head benchmarks. There are a number of better-known compression benchmarks. Some benchmarks cover only the data compression ratio, so winners in these benchmarks may be unsuitable for everyday use due to the slow speed of the top performers. Another drawback of some benchmarks is that their data files are known, so some program writers may optimize their programs for best performance on a particular data set. The winners on these benchmarks often come from the class of context-mixing compression software.

Matt Mahoney, in his February 2010 edition of the free booklet "Data Compression Explained", additionally lists the following:

The Compression Ratings website published a chart summary of the "frontier" in compression ratio and time.

The Compression Analysis Tool is a Windows application that enables end users to benchmark the performance characteristics of streaming implementations of LZF4, DEFLATE, ZLIB, GZIP, BZIP2 and LZMA using their own data. It produces measurements and charts with which users can compare the compression speed, decompression speed and compression ratio of the different compression methods and to examine how the compression level, buffer size and flushing operations affect the results.

Lossless data compression algorithms cannot guarantee compression for all input data sets. In other words, for any lossless data compression algorithm, there will be an input data set that does not get smaller when processed by the algorithm, and for any lossless data compression algorithm that makes at least one file smaller, there will be at least one file that it makes larger. This is easily proven with elementary mathematics using a counting argument, as follows:


Any lossless compression algorithm that makes some files shorter must necessarily make some files longer, but it is not necessary that those files become "very much" longer. Most practical compression algorithms provide an "escape" facility that can turn off the normal coding for files that would become longer by being encoded. In theory, only a single additional bit is required to tell the decoder that the normal coding has been turned off for the entire input; however, most encoding algorithms use at least one full byte (and typically more than one) for this purpose. For example, DEFLATE compressed files never need to grow by more than 5 bytes per 65,535 bytes of input.

In fact, if we consider files of length N, if all files were equally probable, then for any lossless compression that reduces the size of some file, the expected length of a compressed file (averaged over all possible files of length N) must necessarily be "greater" than N. So if we know nothing about the properties of the data we are compressing, we might as well not compress it at all. A lossless compression algorithm is useful only when we are more likely to compress certain types of files than others; then the algorithm could be designed to compress those types of data better.

Thus, the main lesson from the argument is not that one risks big losses, but merely that one cannot always win. To choose an algorithm always means implicitly to select a "subset" of all files that will become usefully shorter. This is the theoretical reason why we need to have different compression algorithms for different kinds of files: there cannot be any algorithm that is good for all kinds of data.

The "trick" that allows lossless compression algorithms, used on the type of data they were designed for, to consistently compress such files to a shorter form is that the files the algorithms are designed to act on all have some form of easily modeled redundancy that the algorithm is designed to remove, and thus belong to the subset of files that that algorithm can make shorter, whereas other files would not get compressed or even get bigger. Algorithms are generally quite specifically tuned to a particular type of file: for example, lossless audio compression programs do not work well on text files, and vice versa.

In particular, files of random data cannot be consistently compressed by any conceivable lossless data compression algorithm: indeed, this result is used to "define" the concept of randomness in algorithmic complexity theory.

It's provably impossible to create an algorithm that can losslessly compress any data. While there have been many claims through the years of companies achieving "perfect compression" where an arbitrary number "N" of random bits can always be compressed to "N" − 1 bits, these kinds of claims can be safely discarded without even looking at any further details regarding the purported compression scheme. Such an algorithm contradicts fundamental laws of mathematics because, if it existed, it could be applied repeatedly to losslessly reduce any file to length 0. Allegedly "perfect" compression algorithms are often derisively referred to as "magic" compression algorithms for this reason.

On the other hand, it has also been proven that there is no algorithm to determine whether a file is incompressible in the sense of Kolmogorov complexity. Hence it's possible that any particular file, even if it appears random, may be significantly compressed, even including the size of the decompressor. An example is the digits of the mathematical constant "pi", which appear random but can be generated by a very small program. However, even though it cannot be determined whether a particular file is incompressible, a simple theorem about incompressible strings shows that over 99% of files of any given length cannot be compressed by more than one byte (including the size of the decompressor).

Abstractly, a compression algorithm can be viewed as a function on sequences (normally of octets). Compression is successful if the resulting sequence is shorter than the original sequence (and the instructions for the decompression map). For a compression algorithm to be lossless, the compression map must form an injection from "plain" to "compressed" bit sequences.

The pigeonhole principle prohibits a bijection between the collection of sequences of length "N" and any subset of the collection of sequences of length "N"−1. Therefore, it is not possible to produce a lossless algorithm that reduces the size of every possible input sequence.

Most everyday files are relatively 'sparse' in an information entropy sense, and thus, most lossless algorithms a layperson is likely to apply on regular files compress them relatively well. This may, through misapplication of intuition, lead some individuals to conclude that a well-designed compression algorithm can compress "any" input, thus, constituting a "magic compression algorithm".

Real compression algorithm designers accept that streams of high information entropy cannot be compressed, and accordingly, include facilities for detecting and handling this condition. An obvious way of detection is applying a raw compression algorithm and testing if its output is smaller than its input. Sometimes, detection is made by heuristics; for example, a compression application may consider files whose names end in ".zip", ".arj" or ".lha" uncompressible without any more sophisticated detection. A common way of handling this situation is quoting input, or uncompressible parts of the input in the output, minimizing the compression overhead. For example, the zip data format specifies the 'compression method' of 'Stored' for input files that have been copied into the archive verbatim.

Mark Nelson, in response to claims of magic compression algorithms appearing in comp.compression, has constructed a 415,241 byte binary file of highly entropic content, and issued a public challenge of $100 to anyone to write a program that, together with its input, would be smaller than his provided binary data yet be able to reconstitute it without error.

The FAQ for the comp.compression newsgroup contains a challenge by Mike Goldman offering $5,000 for a program that can compress random data. Patrick Craig took up the challenge, but rather than compressing the data, he split it up into separate files all of which ended in the number "5", which was not stored as part of the file. Omitting this character allowed the resulting files (plus, in accordance with the rules, the size of the program that reassembled them) to be smaller than the original file. However, no actual compression took place, and the information stored in the names of the files was necessary to reassemble them in the correct order in the original file, and this information was not taken into account in the file size comparison. The files themselves are thus not sufficient to reconstitute the original file; the file names are also necessary. Patrick Craig agreed that no meaningful compression had taken place, but argued that the wording of the challenge did not actually require this. A full history of the event, including discussion on whether or not the challenge was technically met, is on Patrick Craig's web site.




</doc>
<doc id="18210" url="https://en.wikipedia.org/wiki?curid=18210" title="Larry Niven">
Larry Niven

Laurence van Cott Niven (; born April 30, 1938) is an American science fiction writer. His best-known works are "Ringworld" (1970), which received Hugo, Locus, Ditmar, and Nebula awards, and, with Jerry Pournelle, "The Mote in God's Eye" (1974) and "Lucifer's Hammer" (1977). The Science Fiction and Fantasy Writers of America named him the 2015 recipient of the Damon Knight Memorial Grand Master Award. His work is primarily hard science fiction, using big science concepts and theoretical physics. It also often includes elements of detective fiction and adventure stories. His fantasy includes the series "The Magic Goes Away", rational fantasy dealing with magic as a non-renewable resource.

Niven was born in Los Angeles. He is a great-grandson of Edward L. Doheny, an oil tycoon who drilled the first successful well in the Los Angeles City Oil Field in 1892, and also was subsequently implicated in the Teapot Dome scandal. He briefly attended the California Institute of Technology and graduated with a Bachelor of Arts in mathematics (with a minor in psychology) from Washburn University in Topeka, Kansas in 1962. He also completed a year of graduate work in mathematics at the University of California, Los Angeles. On September 6, 1969, he married Marilyn Joyce "Fuzzy Pink" Wisowaty, a science fiction and Regency literature fan.

Niven is the author of numerous science fiction short stories and novels, beginning with his 1964 story "The Coldest Place". In this story, the coldest place concerned is the dark side of Mercury, which at the time the story was written was thought to be tidally locked with the Sun (it was found to rotate in a 2:3 resonance after Niven received payment for the story, but before it was published).

Algis Budrys said in 1968 that Niven becoming a top writer despite the New Wave was evidence that "trends are for second-raters". In addition to the Nebula award in 1970 and the Hugo and Locus awards in 1971 for "Ringworld", Niven won the Hugo Award for Best Short Story for "Neutron Star" in 1967. He won the same award in 1972, for "Inconstant Moon", and in 1975 for "The Hole Man". In 1976, he won the Hugo Award for Best Novelette for "The Borderland of Sol".

Niven has written scripts for three science fiction television series: the original "Land of the Lost" series; "", for which he adapted his early story "The Soft Weapon"; and "The Outer Limits", for which he adapted his story "Inconstant Moon" into an episode of the same name.

Niven has also written for the DC Comics character Green Lantern, including in his stories hard science fiction concepts such as universal entropy and the redshift effect.

He has included limited psi gifts (mind over matter) in some characters in his stories; like Gil Hamilton's psychic arm which can only reach as far as a corporeal arm could, though it can, for example, reach through solid materials and manipulate objects on the other side, and through videophone screens, or Matt Keller's ability to make people not notice him.

Several of his stories predicted the black market in transplant organs ("organlegging").

Many of Niven's stories—sometimes called the Tales of Known Space—take place in his Known Space universe, in which humanity shares the several habitable star systems nearest to the Sun with over a dozen alien species, including the aggressive feline Kzinti and the very intelligent but cowardly Pierson's Puppeteers, which are frequently central characters. The "Ringworld" series is part of the Tales of Known Space, and Niven has shared the setting with other writers since a 1988 anthology, "The Man-Kzin Wars" (Baen Books, jointly edited with Jerry Pournelle and Dean Ing). There have been several volumes of short stories and novellas.

Niven has also written a logical fantasy series "The Magic Goes Away", which utilizes an exhaustible resource called "mana" to power a rule-based "technological" magic. "The Draco Tavern" series of short stories take place in a more light-hearted science fiction universe, and are told from the point of view of the proprietor of an omni-species bar. The whimsical "Svetz" series consists of a collection of short stories, "The Flight of the Horse", and a novel, "Rainbow Mars", which involve a nominal time machine sent back to retrieve long-extinct animals, but which travels, in fact, into alternative realities and brings back mythical creatures such as a Roc and a Unicorn. Much of his writing since the 1970s has been in collaboration, particularly with Jerry Pournelle and Steven Barnes, but also Brenda Cooper and Edward M. Lerner.

One of Niven's best known humorous works is "Man of Steel, Woman of Kleenex", in which he uses real-world physics to underline the difficulties of Superman and a human woman (Lois Lane or Lana Lang) mating.

Niven appeared in the 1980 science documentary film "Target... Earth?"

In Niven's novel "Ringworld", he envisions a Ringworld: a band of material, roughly a million miles wide, of approximately the same diameter as Earth's orbit, rotating around a star. The idea originated in Niven's attempts to imagine a more efficient version of a Dyson sphere, which could produce the effect of surface gravity through rotation. Given that spinning a Dyson sphere would result in the atmosphere pooling around the equator, the Ringworld removes all the extraneous parts of the structure, leaving a spinning band landscaped on the sun-facing side, with the atmosphere and inhabitants kept in place through centrifugal force and high perimeter walls (rim walls). After publication of "Ringworld", Dan Alderson and Ctein, two friends told Niven that the Ringworld was dynamically unstable such that if the center of rotation drifts away from the central sun, gravitational forces will not "re-center" it, thus allowing the ring to eventually contact the sun and be destroyed. Niven used this as a core plot element in the sequel novel, "The Ringworld Engineers".

This idea proved influential, serving as an alternative to a full Dyson sphere that required fewer assumptions (such as artificial gravity) and allowed a day/night cycle to be introduced (through the use of a smaller ring of "shadow squares", rotating between the ring and its sun). This was further developed by Iain M. Banks in his Culture series, which features about ringworld–size megastructures called Orbitals that orbit a star rather than encircling it entirely (actual "Rings" and Dyson "Spheres" are also mentioned but are much rarer). Alastair Reynolds also uses ringworlds in his 2008 novel "House of Suns". The Ringworld-like namesake of the "Halo" video game series is the eponymous Halo megastructure/superweapon.

In the trading card game, the card Nevinyrral's Disk uses his name, spelled backwards. This tribute was paid because the game's system where mana from lands is used to power spells was inspired by his book The Magic Goes Away.

According to author Michael Moorcock, in 1967, Niven was among those Science Fiction Writers of America members who voiced opposition to the Vietnam War. However, in 1968 Niven's name appeared in a pro-war ad in "Galaxy Science Fiction".

Niven was an adviser to Ronald Reagan on the creation of the Strategic Defense Initiative antimissile policy, as part of the Citizens' Advisory Council on National Space Policy – as covered in the BBC documentary "Pandora's Box" by Adam Curtis. 

In 2007, Niven, in conjunction with a group of science fiction writers known as SIGMA, led by Pournelle, began advising the U.S. Department of Homeland Security as to future trends affecting terror policy and other topics.

Larry Niven is also known in science fiction fandom for "Niven's Law": "There is no cause so right that one cannot find a fool following it." Over the course of his career Niven has added to this first law a list of Niven's Laws which he describes as "how the Universe works" as far as he can tell.




</doc>
<doc id="18212" url="https://en.wikipedia.org/wiki?curid=18212" title="Linux distribution">
Linux distribution

A Linux distribution (often abbreviated as distro) is an operating system made from a software collection that is based upon the Linux kernel and, often, a package management system. Linux users usually obtain their operating system by downloading one of the Linux distributions, which are available for a wide variety of systems ranging from embedded devices (for example, OpenWrt) and personal computers (for example, Linux Mint) to powerful supercomputers (for example, Rocks Cluster Distribution).

A typical Linux distribution comprises a Linux kernel, GNU tools and libraries, additional software, documentation, a window system (the most common being the X Window System), a window manager, and a desktop environment.

Most of the included software is free and open-source software made available both as compiled binaries and in source code form, allowing modifications to the original software. Usually, Linux distributions optionally include some proprietary software that may not be available in source code form, such as binary blobs required for some device drivers.

A Linux distribution may also be described as a particular assortment of application and utility software (various GNU tools and libraries, for example), packaged together with the Linux kernel in such a way that its capabilities meet the needs of many users. The software is usually adapted to the distribution and then packaged into software packages by the distribution's maintainers. The software packages are available online in so-called repositories, which are storage locations usually distributed around the world. Beside glue components, such as the distribution installers (for example, Debian-Installer and Anaconda) or the package management systems, there are only very few packages that are originally written from the ground up by the maintainers of a Linux distribution.

Almost six hundred Linux distributions exist, with close to five hundred out of those in active development. Because of the huge availability of software, distributions have taken a wide variety of forms, including those suitable for use on desktops, servers, laptops, netbooks, mobile phones and tablets, as well as minimal environments typically for use in embedded systems. There are commercially-backed distributions, such as Fedora (Red Hat), openSUSE (SUSE) and Ubuntu (Canonical Ltd.), and entirely community-driven distributions, such as Debian, Slackware, Gentoo and Arch Linux. Most distributions come ready to use and pre-compiled for a specific instruction set, while some distributions (such as Gentoo) are distributed mostly in source code form and compiled locally during installation.

Linus Torvalds developed the Linux kernel and distributed its first version, 0.01, in 1991. Linux was initially distributed as source code only, and later as a pair of downloadable floppy disk images one bootable and containing the Linux kernel itself, and the other with a set of GNU utilities and tools for setting up a file system. Since the installation procedure was complicated, especially in the face of growing amounts of available software, distributions sprang up to simplify this.

Early distributions included the following:

The two oldest and still active distribution projects started in 1993. The SLS distribution was not well maintained, so in July 1993 a new distribution, called Slackware and based on SLS, was released by Patrick Volkerding. Also dissatisfied with SLS, Ian Murdock set to create a free distribution by founding Debian, which had its first release in December 1993.

Users were attracted to Linux distributions as alternatives to the DOS and Microsoft Windows operating systems on IBM PC compatible computers, Mac OS on the Apple Macintosh, and proprietary versions of Unix. Most early adopters were familiar with Unix from work or school. They embraced Linux distributions for their low (if any) cost, and availability of the source code for most or all of the software included.

As of 2017, Linux has become more popular in server and embedded devices markets than in the desktop market. For example, Linux is used on over 50% of web servers, whereas its desktop market share is about 3.7%.

Many Linux distributions provide an installation system akin to that provided with other modern operating systems. On the other hand, some distributions, including Gentoo Linux, provide only the binaries of a basic kernel, compilation tools, and an installer; the installer compiles all the requested software for the specific architecture of the user's computer, using these tools and the provided source code.

Distributions are normally segmented into "packages". Each package contains a specific application or service. Examples of packages are a library for handling the PNG image format, a collection of fonts or a web browser.

The package is typically provided as compiled code, with installation and removal of packages handled by a package management system (PMS) rather than a simple file archiver. Each package intended for such a PMS contains meta-information such as a package description, version, and "dependencies". The package management system can evaluate this meta-information to allow package searches, to perform an automatic upgrade to a newer version, to check that all dependencies of a package are fulfilled, and/or to fulfill them automatically.

Although Linux distributions typically contain much more software than proprietary operating systems, it is normal for local administrators to also install software not included in the distribution. An example would be a newer version of a software application than that supplied with a distribution, or an alternative to that chosen by the distribution (for example, KDE Plasma Workspaces rather than GNOME or vice versa for the user interface layer). If the additional software is distributed in source-only form, this approach requires local compilation. However, if additional software is locally added, the "state" of the local system may fall out of synchronization with the state of the package manager's database. If so, the local administrator will be required to take additional measures to ensure the entire system is kept up to date. The package manager may no longer be able to do so automatically.

Most distributions install packages, including the kernel and other core operating system components, in a predetermined configuration. Few now require or even permit configuration adjustments at first install time. This makes installation less daunting, particularly for new users, but is not always acceptable. For specific requirements, much software must be carefully configured to be useful, to work correctly with other software, or to be secure, and local administrators are often obliged to spend time reviewing and reconfiguring assorted software.

Some distributions go to considerable lengths to specifically adjust and customize most or all of the software included in the distribution. Not all do so. Some distributions provide configuration tools to assist in this process.

By replacing "everything" provided in a distribution, an administrator may reach a "distribution-less" state: everything was retrieved, compiled, configured, and installed locally. It is possible to build such a system from scratch, avoiding a distribution altogether. One needs a way to generate the first binaries until the system is "self-hosting". This can be done via compilation on another system capable of building binaries for the intended target (possibly by cross-compilation). For example, see Linux From Scratch.

In broad terms, Linux distributions may be:

The diversity of Linux distributions is due to technical, organizational, and philosophical variation among vendors and users. The permissive licensing of free software means that any user with sufficient knowledge and interest can customize an existing distribution or design one to suit his or her own needs.

Rolling Linux distributions are kept updated using small and frequent updates. Software contained in a rolling distribution's software stack is usually standard release, though.

Rolling releases can be either:


The terms "partially rolling" and "partly rolling" (along with synonyms "semi-rolling" and "half-rolling"), "fully rolling", "truly rolling" and "optionally rolling" are all standard terms used by software developers and users.

Repositories of rolling distributions usually contains very recent software releases – often the latest stable software releases available. They have pseudo-releases and installation media that are simply a snapshot of the software distribution at the time of the release of the installation image. Typically, a rolling release operating system installed from an older installation medium can be fully updated post-installation to a current state.

There are pros and cons to both standard release and rolling release software development methodologies.

In terms of the software development process, standard releases require significant development effort being spent on keeping old versions up to date due to propagating bug fixes back to the newest branch, versus focusing more on the newest development branch. Also, unlike rolling releases, standard releases require more than one code branch to be developed and maintained, which increases the software development and software maintenance workload of the software developers and software maintainers.

On the other hand, software features and technology planning are easier in standard releases due to a better understanding of upcoming features in the next version(s) rather than simply the whim of the developers at any given time. Software release cycles can also be synchronized with those of major upstream software projects, such as desktop environments.

As far as the user experience, standard releases are often viewed as more stable and bug-free since software conflicts can be more easily addressed and the software stack more thoroughly tested and evaluated, during the software development cycle. For this reason, they tend to be the preferred choice in enterprise environments and mission-critical tasks.

However, rolling releases offer more current software which can also provide increased stability and fewer software bugs along with the additional benefits of new features, greater functionality, faster running speeds, and improved system and application security. Regarding software security, the rolling release model can have advantages in timely security updates, fixing system or application security bugs and vulnerabilities, that standard releases may have to wait till the next release for or patch in various versions. In a rolling release distribution, where the user has "chosen" to run it as a highly dynamic system, the constant flux of software packages can introduce new unintended vulnerabilities.

A "live" distribution is a Linux distribution that can be booted from removable storage media such as optical discs or USB flash drives, instead of being installed on and booted from a hard disk drive. The portability of installation-free distributions makes them advantageous for applications such as demonstrations, borrowing someone else's computer, rescue operations, or as installation media for a standard distribution.

When the operating system is booted from a read-only medium such as a CD or DVD, any user data that needs to be retained between sessions cannot be stored on the boot device but must be written to another storage device, such as a USB flash drive or a hard disk drive.

Many Linux distributions provide a "live" form in addition to their conventional form, which is a network-based or removable-media image intended to be used only for installation; such distributions include SUSE, Ubuntu, Linux Mint, MEPIS and Fedora. Some distributions, including Knoppix, Puppy Linux, Devil-Linux, SuperGamer, SliTaz GNU/Linux and , are designed primarily for live use. Additionally, some minimal distributions can be run directly from as little space as one floppy disk without the need to change the contents of the system's hard disk drive.

The website DistroWatch lists many Linux distributions, and displays some of the ones that have the most web traffic on the site. The Wikimedia Foundation released an analysis of the browser User Agents of visitors to WMF websites until 2015, which includes details of the most popular Operating System identifiers, including some Linux distributions. Many of the popular distributions are listed below.




Whether Google's Android counts as a Linux distribution is a matter of definition. It uses the Linux kernel, so the Linux Foundation and Chris DiBona, Google's open source chief, agree that Android is a Linux distribution; others, such as Google engineer Patrick Brady, disagree by noting the lack of support for many GNU tools in Android, including glibc.

Other non-GNU distributions include Cyanogenmod, its fork LineageOS, Android-x86 and recently Tizen and Mer/Sailfish OS.

Lightweight Linux distributions are those that have been designed with support for older hardware in mind, allowing older hardware to still be used productively, or, for maximum possible speed in newer hardware by leaving more resources available for use by applications. Examples include Tiny Core Linux, Puppy Linux and Slitaz.

Other distributions target specific niches, such as:


The Free Standards Group is an organization formed by major software and hardware vendors that aims to improve interoperability between different distributions. Among their proposed standards are the Linux Standard Base, which defines a common ABI and packaging system for Linux, and the Filesystem Hierarchy Standard which recommends a standard filenaming chart, notably the basic directory names found on the root of the tree of any Linux filesystem. Those standards, however, see limited use, even among the distributions developed by members of the organization.

The diversity of Linux distributions means that not all software runs on all distributions, depending on what libraries and other system attributes are required. Packaged software and software repositories are usually specific to a particular distribution, though cross-installation is sometimes possible on closely related distributions.

The process of constantly switching between distributions is often referred to as "distro hopping". Virtual machines such as VirtualBox and VMware Workstation virtualize hardware allowing users to test live media on a virtual machine. Some websites like DistroWatch offer lists of popular distributions, and link to screenshots of operating systems as a way to get a first impression of various distributions.

There are tools available to help people select an appropriate distribution, such as several versions of the Linux Distribution Chooser, and the universal package search tool "whohas". There are easy ways to try out several Linux distributions before deciding on one: Multi Distro is a Live CD that contains nine space-saving distributions.

There are several ways to install a Linux distribution. Nowadays, the most common method of installing Linux is by booting from a live USB memory stick, which can be created by using a USB image writer application and the ISO image, which can be downloaded from the various Linux distribution websites. DVD disks, CD disks, network installations and even other hard drives can also be used as "installation media".

Early Linux distributions were installed using sets of floppies but this has been abandoned by all major distributions. Nowadays most distributions offer CD and DVD sets with the vital packages on the first disc and less important packages on later ones. They usually also allow installation over a network after booting from either a set of floppies or a CD with only a small amount of data on it.

New users tend to begin by partitioning a hard drive in order to keep their previously installed operating system. The Linux distribution can then be installed on its own separate partition without affecting previously saved data.

In a Live CD setup, the computer boots the entire operating system from CD without first installing it on the computer's hard disk. Some distributions have a Live CD "installer", where the computer boots the operating system from the disk, and then proceeds to install it onto the computer's hard disk, providing a seamless transition from the OS running from the CD to the OS running from the hard disk.

Both servers and personal computers that come with Linux already installed are available from vendors including Hewlett-Packard, Dell and System76.

On embedded devices, Linux is typically held in the device's firmware and may or may not be consumer-accessible. 

Anaconda, one of the more popular installers, is used by Red Hat Enterprise Linux, Fedora (which uses the Fedora Media Writer) and other distributions to simplify the installation process. Debian, Ubuntu and many others use Debian-Installer.

Some distributions let the user install Linux on top of their current system, such as WinLinux or coLinux. Linux is installed to the Windows hard disk partition, and can be started from inside Windows itself.

Virtual machines (such as VirtualBox or VMware) also make it possible for Linux to be run inside another OS. The VM software simulates a separate computer onto which the Linux system is installed. After installation, the virtual machine can be booted as if it were an independent computer.

Various tools are also available to perform full dual-boot installations from existing platforms without a CD, most notably:


Some specific proprietary software products are not available in any form for Linux. As of September 2015, the Steam gaming service has 1,500 games available on Linux, compared to 2,323 games for Mac and 6,500 Windows games. Emulation and API-translation projects like Wine and CrossOver make it possible to run non-Linux-based software on Linux systems, either by emulating a proprietary operating system or by translating proprietary API calls (e.g., calls to Microsoft's Win32 or DirectX APIs) into native Linux API calls. A virtual machine can also be used to run a proprietary OS (like Microsoft Windows) on top of Linux.

Computer hardware is usually sold with an operating system other than Linux already installed by the original equipment manufacturer (OEM). In the case of IBM PC compatibles the OS is usually Microsoft Windows; in the case of Apple Macintosh computers it has always been a version of Apple's OS, currently macOS; Sun Microsystems sold SPARC hardware with the Solaris installed; video game consoles such as the Xbox, PlayStation, and Wii each have their own proprietary OS. This limits Linux's market share: consumers are unaware that an alternative exists, they must make a conscious effort to use a different operating system, and they must either perform the actual installation themselves, or depend on support from a friend, relative, or computer professional.

However, it is possible to buy hardware with Linux already installed. Lenovo, Hewlett-Packard, Dell, Affordy, Purism, and System76 all sell general-purpose Linux laptops, and custom-order PC manufacturers will also build Linux systems (but possibly with the Windows key on the keyboard). Fixstars Solutions (formerly Terra Soft) sells Macintosh computers and PlayStation 3 consoles with Yellow Dog Linux installed.

It is more common to find embedded devices sold with Linux as the default manufacturer-supported OS, including the Linksys NSLU2 NAS device, TiVo's line of personal video recorders, and Linux-based cellphones (including Android smartphones), PDAs, and portable music players. 

The current Microsoft Windows license lets the manufacturer determine the refund policy. With previous versions of Windows, it was possible to obtain a refund if the manufacturer failed to provide the refund by litigation in the small claims courts. On 15 February 1999, a group of Linux users in Orange County, California held a "Windows Refund Day" protest in an attempt to pressure Microsoft into issuing them refunds. In France, the Linuxfrench and AFUL (French speaking Libre Software Users' Association) organizations along with free software activist Roberto Di Cosmo started a "Windows Detax" movement, which led to a 2006 petition against "racketiciels" (translation: Racketware) with 39,415 signatories and the DGCCRF branch of the French government filing several complaints against bundled software. On March 24, 2014, a new international petition was launched by AFUL on the Avaaz platform, translated into several languages and supported by many organizations around the world.

There are no official figures on popularity, adoption, downloads or installed base of Linux distributions.

There are also no official figures for the total number of Linux systems, partly due to the difficulty of quantifying the number of PCs running Linux (see Desktop Linux#Measuring adoption), since many users download Linux distributions. Hence, the sales figures for Linux systems and commercial Linux distributions indicate a much lower number of Linux systems and level of Linux adoption than is the case; this is mainly due to Linux being free and open source software that can be downloaded free of charge. A Linux Counter Project had kept track of a running guesstimate of the number of Linux systems, but did not distinguish between rolling release and standard release distributions. It ceased operation in August of 2018, though a few related blog posts were created through October 2018.

Desktop usage statistical reports for particular Linux distributions have been collected and published in January of 2020 by the Linux Hardware Project.




</doc>
