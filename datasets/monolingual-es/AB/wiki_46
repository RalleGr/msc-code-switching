<doc id="41663" url="https://es.wikipedia.org/wiki?curid=41663" title="Fermentación alcohólica">
Fermentación alcohólica

La fermentación alcohólica es un proceso biológico de fermentación en plena ausencia de oxígeno (- O), originado por la actividad de algunos microorganismos que procesan los hidratos de carbono (por regla general, azúcares: por ejemplo, la glucosa, la fructosa, la sacarosa, es decir, cualquier sustancia que tenga la forma empírica de la glucosa, es decir, una hexosa) para obtener como productos finales: un alcohol en forma de etanol (cuya fórmula química es: CH-CH-OH), dióxido de carbono (CO) en forma de gas y moléculas de adenosín trifosfato (ATP) que consumen los propios microorganismos en su metabolismo celular energético anaerobio. El etanol resultante se emplea en la elaboración de algunas bebidas alcohólicas, tales como el vino, la cerveza, la sidra, el cava, etc. En la actualidad ha empezado a sintetizarse también etanol mediante la fermentación a nivel industrial a gran escala para ser empleado como biocombustible.

La fermentación alcohólica tiene como finalidad biológica proporcionar energía anaeróbica a los microorganismos unicelulares (levaduras) en ausencia de oxígeno a partir de la glucosa. En el proceso, las levaduras obtienen energía disociando las moléculas de glucosa y generan como desechos alcohol y CO. Las levaduras y bacterias causantes de este fenómeno son microorganismos muy habituales en las frutas y cereales y contribuyen en gran medida al sabor de los productos fermentados (véase evaluación sensorial). Una de las principales características de estos microorganismos es que viven en ambientes completamente carentes de oxígeno, máxime durante la reacción química, y es por ello que la fermentación alcohólica es un proceso anaerobio o anaeróbico.

La humanidad emplea la fermentación alcohólica desde tiempos inmemoriales para la elaboración de cerveza (empleando cereales) y del vino (empleando el fruto de la vid: la uva en forma de mosto) fundamentalmente. Los griegos atribuían el descubrimiento de la fermentación al dios Dionisio. Algunos procesos similares como el de la destilación alcohólica ya surgen en el año 1150 de la mano de Arnau de Vilanova. Fue un elemento más a considerar en el desarrollo histórico de la alquimia durante la Edad Media.

En el año 1764 se identificó el gas CO resultante de la fermentación por el químico MacBride y en 1766 Cavendish lo describió como: «el gas existente en la atmósfera» determinando además la proporción de dióxido de carbono con respecto al azúcar empleado en el proceso, que rondaba el 57%. En esta época se empezó a descubrir, gracias a observaciones científicas, que la fermentación alcohólica se producía también en substancias «no dulces». Antoine Lavoisier hizo experimentos en 1789 determinando las cantidades de los elementos intervinientes en la fermentación (carbono, oxígeno e hidrógeno). Con el advenimiento de los descubrimientos químicos en el año 1815 el investigador francés Joseph Louis Gay-Lussac fue el primero en determinar una reacción de fermentación obteniendo etanol a partir de glucosa, a pesar de este logro los fundamentos de la fermentación alcohólica eran completamente desconocidos. Existe durante el siglo XIX un debate científico por establecer la «hipótesis de la fermentación». Durante los años 1830s los químicos Jöns Jakob Berzelius y Justus von Liebig desarrollaron una teoría mecanicista que explica la fermentación, teorías que estaban en contraposición con las creencias de Louis Pasteur en el año 1857 que se fundamentaba en la «teoría vitalista» como explicación de los mecanismos básicos de la fermentación, fue el mismo Pasteur que en el año 1875 demostró que la fermentación era un proceso anaeróbico (en ausencia de oxígeno).

En el año 1818 Erxleben, De La Tour en Francia, Schwann y Kützing en Alemania (1837) descubren que las levaduras (organismos microscópicos unicelulares) son la causa del proceso, pero no fue hasta que Eduard Buchner en el año 1897 descubre que la enzima zimasa es la responsable final de la fermentación alcohólica trabajo por el que recibe el . Este descubrimiento atrajo el interés de otros científicos, entre ellos Harden y Young quienes en el año 1904 mostraron que la zimasa perdía sus propiedades fermentativas bajo condiciones de diálisis, demostrando que la fermentación dependía de una sustancia de bajo peso molecular que se quedaba retenida en los finos poros de la membrana de la diálisis. La fermentación podía bajo estas circunstancias volver a ser restablecida añadiendo simplemente de nuevo las levaduras, esta substancia descubierta por Harden y Young se denominó cozimasa, y fue eventualmente encontrada como una mezcla de iones fosfatados, difosfato de tiamida y NAD. Sin embargo la caracterización de la cozimasa no fue completada hasta el año 1935. El bioquímico Otto Heinrich Warburg en conjunción con Hans von Euler-Chelpin descubren en el año 1929 que el cofactor nicotinamida adenina dinucleótido (NADH) juega un papel muy importante en el proceso interno de la fermentación. En 1937, los investigadores Erwin Negelein y Hans Joachim Wulff comprueban que mediante la cristalización de los subproductos de la fermentación la enzima alcohol deshidrogenasa es protagonista en algunos sub-procesos realizando un papel importante.

Los descubrimientos posteriores a partir del periodo que va desde mediados del siglo XX hasta comienzos del siglo XXI se centran exclusivamente en la mejora de los procesos de fermentación alcohólica y conciernen más a la optimización del rendimiento industrial bien sea mediante una buena selección de cepas de levaduras, de una temperatura de funcionamiento óptima, de como realizar fermentación en un proceso continuo: biorreactores.

La fermentación alcohólica se puede considerar (desde una perspectiva humana) como un proceso bioquímico para la obtención de etanol, que por otras vías se ha obtenido gracias a procedimientos químicos industriales, como por ejemplo mediante la reacción de oxidación de eteno. La finalidad de la fermentación etílica (desde una perspectiva microbiana) es la obtención de energía para la supervivencia de los organismos unicelulares anaeróbicos.
Las bebidas alcohólicas se producen a partir de diferentes sustratos, dependiendo de la región geográfica y sus riquezas. Las materias primas pueden ser azúcares simples como los presentes en el jugo de uva, o de alto peso molecular, como el almidón de los granos de cebada. Existen dos tipos de bebidas alcohólicas, las que se obtienen directamente por fermentación de los diferentes sustratos y las destiladas, producidas por destilación del producto de fermentación.
El proceso principal por el cual se transforma el mosto en vino es la fermentación alcohólica, la cual consiste en la transformación de azúcares en alcohol etílico y anhídrido carbónico. La fermentación alcohólica es la base de la vinificación, sin embargo, su importancia no radica únicamente en la obtención de etanol a partir de los azúcares, sino que además durante el proceso fermentativo se van a formar una gran cantidad de productos secundarios que influyen en la calidad y tipicidad del vino. Más adelante, se pueden apreciar algunos de los compuestos que influyen en la tipicidad del vino

Las levaduras son simones tan perfectos como el original (generalmente de forma esférica) de un tamaño que ronda los 2 a 4 μm y que están presentes de forma natural en algunos productos como las frutas, cereales y verduras. Son lo que se denominan: organismos anaeróbicos facultativos, es decir que pueden desarrollar sus funciones biológicas sin oxígeno. Se puede decir que el 96% de la producción de etanol la llevan a cabo hongos microscópicos, diferentes especies de levaduras, entre las que se encuentran principalmente "Saccharomyces cerevisiae", "Kluyveromyces fragilis", "Torulaspora" y "Zymomonas mobilis". Los microorganismos responsables de la fermentación son de tres tipos: bacterias, mohos y levaduras. Cada uno de estos microorganismos posee una característica propia sobre la fermentación que son capaces de provocar. En algunos casos son capaces de proporcionar un sabor característico al producto final (como en el caso de los vinos o cervezas). A veces estos microorganismos no actúan solos, sino que cooperan entre sí para la obtención del proceso global de fermentación. Las propias levaduras se han empleado a veces en la alimentación humana como un subproducto industrial. Se ha descubierto que en algunos casos es mejor inmovilizar (reducir el movimiento) de algunas levaduras para que pueda atacar enzimáticamente mejor y con mayor eficiencia sobre el substrato de hidratos de carbono evitando que los microorganismos se difundan facilitando su recuperación (los biocatalizadores suelen ser caros), para ello se emplean 'fijadores' como agar, alginato de calcio, astillas de madera de bálsamo, etcétera.

Algunas cepas de bacterias tienen eficiencias de fermentación altas sin necesidad de fijación, incluso a relativas velocidades de movilidad, tal y como puede ser el caso de Zymomonas mobilis (cuyo genoma completo se hizo público en el año 2005). Sin embargo, esta bacteria no se ha empleado industrialmente para la fermentación de la cerveza y de la sidra por proporcionar sabores y olores desagradables. No obstante posee una alta resistencia a sobrevivir a concentraciones elevadas de etanol, lo que la convierte en una bacteria ideal en la generación de etanol para usos no comestibles (como puede ser biocombustibles). El biólogo Lindner en el año 1928 fue el primero en describir la bacteria "Zymomonas mobilis" (conocida en honor de su descubridor como "Z. lindneri", "Thermobacterium mobile" o "Pseudomonas lindneri"). Una de las características de esta bacteria es que emplea la vía Entner-Doudoroff para el metabolismo de la glucosa, en lugar de la más habitual vía de Embden-Meyerhoff-Parnas.

Cuando el medio es rico en azúcar (como puede ser el caso de las melazas o siropes), la transformación del mismo en alcohol hace que la presencia de una cierta concentración (generalmente expresada en grados brix) afecte a la supervivencia de levaduras no pudiendo realizar la fermentación en tal medio (las altas concentraciones de azúcar frenan los procesos osmóticos de las membranas de las células). Aunque hay distintos tipos de levaduras con diferentes tolerancias a las concentraciones de azúcares y de etanol, el límite suele estar en torno a los 14 de alcohol para las levaduras del vino, por ejemplo. Los azúcares empleados en la fermentación suelen ser: dextrosa, maltosa, sacarosa y lactosa (azúcar de la leche). Los microorganismos 'atacan' específicamente a cada una de los hidratos de carbono, siendo la maltosa la más afectada por las levaduras. Otros factores como el número de levaduras (contadas en el laboratorio, o la industria, a veces mediante cámaras de Neubauer).

Algunos enzimas participan en la fermentación, como puede ser la diastasa o la invertasa. Aunque la única responsable de convertir los hidratos de carbono en etanol y dióxido de carbono es la zimasa. La zimasa es la responsable final de dirigir la reacción bioquímica que convierte la glucosa en etanol. La idea de que una sustancia albuminoide específica desarrollada en la célula de la levadura llega a producir la fermentación fue ya expuesta en el año 1858 por Moritz Traube como la "teoría enzimática o fermentativa" y, más tarde, ha sido defendida por Felix Hoppe-Seyler hasta llegar al descubrimiento de Eduard Buchner que llegó a hacer la fermentación sin la intervención de células y hongos de levadura.

La glucólisis es la primera etapa de la fermentación, lo mismo que en la respiración celular, y al igual que esta necesita de enzimas para su completo funcionamiento. A pesar de la complejidad de los procesos bioquímicos una forma esquemática de la reacción química de la fermentación alcohólica puede describirse como una glicólisis (en la denominada "vía Embden-Meyerhof-Parnes") de tal forma que puede verse como participa inicialmente una molécula de hexosa:

CHO + 2 P + 2 ADP + 2 NADH + 2H → 2 CH-CHOH + 2 CO + 2 ATP + 2 NAD
Se puede ver que la fermentación alcohólica es desde el punto de vista energético una reacción exotérmica, se libera una cierta cantidad de energía. La fermentación alcohólica produce gran cantidad de CO, que es la que provoca que el cava (al igual que el Champagne y algunos vinos) tengan burbujas. Este CO (denominado en la edad media como "gas vinorum") pesa más que el aire, y puede llegar a crear bolsas que desplazan el oxígeno de los recipientes donde se produce la fermentación. Por ello es necesario ventilar bien los espacios dedicados a tal fin. En las bodegas de vino, por ejemplo, se suele ir con una vela encendida y colocada a la altura de la cintura, para que en el caso de que la vela se apague, se pueda salir inmediatamente de la bodega. La liberación del dióxido de carbono es a veces "tumultuosa" y da la sensación de hervir, de ahí proviene el nombre de fermentación, palabra que en castellano tiene por etimología del latín "fervere".

Un cálculo realizado sobre la reacción química muestra que el etanol resultante es casi un 51% del peso, los rendimientos obtenidos en la industria alcanzan el 7%. Se puede ver igualmente que la presencia de fósforo (en forma de fosfatos), es importante para la evolución del proceso de fermentación. La fermentación alcohólica se produce por regla general antes que la fermentación maloláctica, aunque existen procesos de fermentación específicos en los que ambas fermentaciones tienen lugar al mismo tiempo. La presencia de azúcares asimilables superiores a una concentración sobre los 0,16 g/L produce invariablemente la formación de alcohol etílico en proceso de crecimiento de levadura ("Saccharomyces cerevisiae") incluso en presencia de exceso de oxígeno (aeróbico), este es el denominado efecto Crabtree, este efecto es tenido en cuenta a la hora de estudiar y tratar de modificar la producción de etanol durante la fermentación.

Si bien el proceso completo ("vía Embden-Meyerhof-Parnes") descrito simplificado anteriormente explica los productos resultantes de la fermentación etílica de una hexosa, cabe destacar que el proceso se puede detallar en una glicólisis previa gobernada por un conjunto de enzimas en la que se obtiene 2 piruvato tal y como se describe a continuación:
La reacción química se describe como la reducción de dos moléculas de Nicotinamida adenina dinucleótido (NAD) de NADH (forma reducida del NAD) con un balance final de dos moléculas de ADP que finalmente por la reacción general mostrada anteriormente se convierten en ATP (adenosín trifosfato). Otros compuestos trazados en menores proporciones que se encuentran presentes tras la fermentación son: el ácido succínico, el glicerol, el ácido fumárico.

En más detalle durante la fermentación etílica en el interior de las levaduras, la vía de la glucólisis es idéntica a la producida en el eritrocito (con la excepción del piruvato que se convierte finalmente en etanol). En primer lugar el piruvato se descarboxila mediante la acción de la piruvato descarboxilasa para dar como producto final acetaldehído liberando por ello dióxido de carbono (CO) a partir de iones del hidrógeno (H) y electrones del NADH. Tras esta operación el NADH sintetizado en la reacción bioquímica catalizada por el GADHP se vuelve a oxidar por el alcohol deshidrogenasa, regenerando NAD para la continuación de la glucólisis y sintetizando al mismo tiempo etanol. Se debe considerar que el etanol va aumentando de concentración durante el proceso de fermentación y debido a que es un compuesto tóxico, cuando su concentración alcanza aproximadamente un 12% de volumen las levaduras tienden a morir. Esta es una de las razones fundamentales por las que las bebidas alcohólicas (no destiladas) no alcanzan valores superiores a los 20% de concentración de etanol.

La fermentación alcohólica es un proceso anaeróbico exergónico (libera energía) y moléculas de ATP necesarias para el funcionamiento metabólico de las levaduras (seres unicelulares). Debido a las condiciones de ausencia de oxígeno durante el bioproceso, la respiración celular de la cadena del ADP en ATP queda completamente bloqueada, siendo la única fuente de energía para las levaduras la glicólisis de la glucosa con la formación de moléculas de ATP mediante la fosforilación a nivel de sustrato. El balance a nivel molecular del proceso se puede decir que genera 2 moléculas de ATP por cada molécula de glucosa. Si se compara este balance con el de la respiración celular se verá que se generan 38 moléculas de ATP. A pesar de ello parece ser suficiente energía para los organismos anaeróbicos. La energía libre de Gibbs (entalpía libre) de la reacción de fermentación etílica muestra un valor de ΔG de -234.6 kJ mol (en un entorno de acidez neutra pH igual a 7) este valor negativo de la energía libre de Gibbs indica que: desde el punto de vista termodinámico la fermentación etílica es un proceso químico espontáneo

La determinación de los factores que limitan la glucólisis fermentativa del etanol son complejos debido a la interrelación existente y a la naturaleza de los parámetros intervinientes durante el proceso de fermentación. Algunos de ellos se deben tener en cuenta en la fermentación alcohólica industrial. En las limitaciones que surgen durante el proceso se pueden enumerar algunos de los más importantes como son:

La fermentación etílica ha sufrido algunas transformaciones con el objeto de aumentar la eficiencia química del proceso. Una de las mejoras más estudiadas en la industria es la posibilidad de realizar la fermentación alcohólica continua con el objeto de obtener mayores cantidades de etanol. Hoy en día el procesamiento industrial de algunas bebidas alcohólicas como puede ser el vino o la cerveza se realizan en ambientes controlados capaces de ofrecer a un ritmo apropiado de estos productos de consumo al mercado. Esta vía ofrece una amplia materia de investigación en temas de eficiencia de bioreactores, empleando para ello teoría de sistemas de control (el problema desde el punto de vista de ingeniería de sistemas es altamente no lineal y oscilatorio). Otra vía de investigación acerca de la mejora de los procesos industriales es la mejora de las cepas de levaduras (como puede ser la Zymomonas Mobilis que ofrece ventajas en los procesos continuos de fermentación), permitiendo la convivencia de una mayor densidad de las mismas durante la producción. Los métodos de fermentación continua se empezaron a patentar en la década de los 50s y desde entonces han hecho que la industria de las bebidas alcohólicas haya experimentado un crecimiento apreciable. Una de las características de la fermentación etílica industrial es la selección adecuada de las levaduras a inocular en el proceso de fermentación con el objeto de aumentar el rendimiento de la producción.

La fermentación industrial típica es esencialmente un proceso que se produce en un recipiente llamado fermentador o en general, biorreactor, mediante el cual determinados sustratos que componen el medio de cultivo (levaduras) son transformadas mediante la reacción microbiana en metabolitos y biomasa. Estos contenedores son herméticos y permiten retirar mediante canalizaciones apropiadas el dióxido de carbono resultante. Durante el proceso los microorganismos van aumentando de concentración en el transcurso de la reacción al mismo tiempo que el medio va modificando sus propiedades químicas y se forman productos nuevos como consecuencia de las reacciones anabólicas.

La fermentación alcohólica con la emisión de ciertas cantidades de etanol se produce de forma espontánea en la naturaleza siempre que se encuentre un azúcar y una atmósfera pobre de oxígeno, es por esta razón que ocurre espontáneamente en el interior de algunas frutas que se puede decir sufren un proceso de maduración anaeróbica, tal y como puede ser el melón curado que muestra olor a alcohol, o los mismos cocos. Un aspecto de la fermentación alcohólica natural o espontánea se puede dar en ciertas frutas como el de la vid, en una fase inicial en la que las uvas se incluyen en las "cubas madre" de acero inoxidable y se produce la denominada "fermentación tumultuosa" encargada de hacer aparecer las primeras trazas de etanol.

Una de las fermentaciones naturales más habituales en las frutas y que se emplea en los procesos de vinificación de algunos vinos es la denominada Maceración carbónica. Este tipo de fermentación causa a veces intoxicaciones etílicas a los insectos que se alimentan de las frutas maduras (véase: "abejas y elementos tóxicos").
Las fermentaciones específicas son manipuladas por el hombre con el objeto de obtener el etanol en ciertas bebidas. Para ello se emplean principalmente los azúcares de las frutas, los cereales y de la leche. La producción de estas bebidas es en la mayoría de los casos local debido a la disponibilidad de los substratos, por ejemplo en los países mediterráneos la uva es frecuente y por lo tanto la fermentación del vino también, el mismo patrón puede hacerse con otros materiales como el arroz en Asia o el maíz en Latinoamérica. De esta forma la tradición de los procesos de fermentado se han asociado a las diversas etnias o grupos sociales.

La fermentación del vino es de las más conocidas y estudiadas por afectar a una industria muy extendida y con gran solera ("véase": Historia del vino). En el caso del vino las levaduras responsables de la vinificación son unos hongos microscópicos que se encuentran de forma natural en los hollejos de las uvas (generalmente en una capa en forma de polvo blanco fino que recubre la piel de las uvas ("vitis vinifera l.") y que se denomina "pruina"). Los vinos deben tener una cantidad de alcohol debido a la fermentación de al menos un 9% en volumen. Con la excepción de los vinos verdes como puede ser el chacolí que pueden tener una graduación inferior. La fermentación alcohólica del vino es muy antigua y ya en la Biblia se hacen numerosas referencias al proceso. Las especies de levaduras empleadas en la elaboración del vino suelen ser por regla general las Saccharomyces cerevisiae aunque a veces también se emplean la S. bayanus y la S. oviformis, aunque en muchas variedades de vides la Kloeckera apiculata y la Metschnikowia pulcherrima son levaduras endógenas capaces de participar en las primeras fases de la fermentación. Para frenar la aparición de bacterias indeseables y otros organismos limitantes de la fermentación se suele esterilizar el mosto a veces con dióxido de azufre (SO) antes del proceso.

La elaboración del vino pasa por una fermentación alcohólica de la fruta de la vid en unos recipientes (hoy en día elaborados en acero inoxidable) en lo que se denomina fermentación tumultuosa debido a gran ebullición que produce durante un periodo de 10 días aproximadamente (llegando hasta aproximadamente unas dos semanas). Tras esta fermentación 'principal' en la industria del vino se suele hacer referencia a una fermentación secundaria que se produce en otros contenedores empleados en el trasiego del vino joven (tal y como puede ser en las botellas de vino). Los vinos blancos fermentan a temperaturas relativamente bajas de 10º-15 °C y los vinos tintos a temperaturas mayores de 20º-30 °C. A veces se interrumpe voluntariamente la fermentación etílica en el vino por diversas causas, una de las más habituales es que haya alcanzado la densidad alcohólica establecida por la ley. En otros casos por el contrario se activa de forma voluntaria el proceso de fermentado mediante la adición de materiales azucarados, este fenómeno recibe el nombre de chaptalización y está muy regulado en los países productores de vino.

La cerveza es una bebida alcohólica producida por la fermentación alcohólica mezcla de algunos cereales (en forma de malta) mezclados con agua. Los cereales empleados son por regla general: cebada, centeno, trigo, etc. El contenido de la cerveza ya se reglamentó en Europa en la famosa ley alemana de la Reinheitsgebot que data del año 1516. Las levaduras empleadas en el proceso de fermentación de la cerveza se dedican a trabajar contra la maltosa y por regla general suelen depender de las características del producto cervecero final que se desee obtener, por ejemplo se suele emplear la "Saccharomyces cerevisiae" para elaborar cervezas de tipo ale y la "saccharomyces carlsbergensis" que sirve para la elaboración de la cerveza tipo lager (Generalmente de color rubio) y la Stout (Cerveza oscura de alto contenido alcohólico generalmente más dulce, un ejemplo: Guinness). El proceso de fermentación en la cerveza en las cubas de fermentación ronda entre los 5 y 9 días.

La industria cervecera ha seleccionado durante siglos las cepas de levaduras para que se adaptaran al proceso de elaboración de cerveza, logrando una gran variedad de las mismas. Durante el proceso se le añade lúpulo ("Humulus lupulus") con el objeto de saborizar, aromatizar y controlar las reacciones enzimáticas durante el proceso de elaboración de la cerveza. El proceso de fermentación de la cerveza se produce en un medio ácido que suele oscilar entre los pH 3,5 y 5,6. Por regla general la fermentación de la cerveza se regula mediante la regulación de la temperatura de la fermentación del mosto de malta.

Existen en la elaboración de la cerveza dos tipos fundamentales de fermentación etílica, dependiendo del lugar físico donde se realiza la fermentación en la cuba madre, la razón de esta fermentación se debe a la estructura química de la capa celular de la levadura y a la propiedad floculante de las levaduras de la cerveza:

En los países asiáticos la abundancia natural del arroz debido a las características climáticas permite que se pueda emplear en la elaboración de fermentaciones alcohólicas en forma de bebida como es el sake (conocida en Japón como ), así como el vino de arroz. Los principales microorganismos empleados en la elaboración de estas bebidas alcohólicas a base de arroz son el Aspergillus oryzae, el Lactobacillus sakei, el Leuconostoc mesenteroides var. sake y la Saccharomyces sake. La fermentación se toma un periodo que va desde los 30 a los 40 días. El sake tiene tres fases de elaboración: la "koji", la "motto" y la "moromi" que se realiza en la denominada fermentación de estado sólido.

En el sake, aparte de una concentración de entre 15 y 20% de etanol producto de la fermentación, los principales componentes responsables de su sabor característico son: ácido succínico (500 a 700 mg/L), ácido málico (200 a 400 mg/L), ácido cítrico (100 a 500 mg/L), ácido acético (50 a 200 mg/L), isoamil alcohol (70 a 250 mg/L), n-propanol (120 mg/L), 2-fenil etanol (75 mg/L), isobutanol (65 mg/L), etilacetato (50 a 120 mg/L), etilcaproato (10 mg/L) e isoamil acetato (10 mg/L). Estos metabolitos también pueden encontrarse en cervezas y la mayoría de vinos ya que provienen de la fermentación alcohólica. También hay que añadir a estos componentes el eti-lleucinato, que es el que contribuye en mayor medida al aroma del saké. No obstante, la concentración de todos estos compuestos en el Saké es significantemente mayor. No hay que olvidar la presencia de ácido láctico (0,3 a 0,5 mg/L) que es casi enteramente fruto de la actividad de las bacterias fermentadoras acidolácticas presentes durante la "etapa del moto" (etapa inicial en la cuba de fermentación). También se detecta, aunque en concentraciones menores, una variedad de aminoácidos. La presencia de estos tiende a ser la mínima posible, ya que le dan al Saké un sabor desagradable.

Se han llevado a cabo gran cantidad de mejoras genéticas de las cepas de Saccharomyces sake con tal de incrementar la presencia de algunos de estos metabolitos (como es el caso del fenil etanol, el isoamil alcohol o el etilcaproato), al igual que reducir la de otros (aminoácidos, etilcarbamato, urea). También se han dado el caso de cepas diseñadas para mejorar la productividad, ya sea disminuyendo la formación de espuma, el incremento de tolerancia al etanol o la no proliferación de cepas productoras de toxinas. Los productos fermentados de arroz no son exclusivos de Japón, se puede encontrar en diversas culturas del mundo como puede ser: el binburán (Filipinas), el pachwai (en la India se denomina como 'cerveza de arroz'), el arrack (el denominado عرق, "‛araq" es muy popular en Oriente Medio frecuentemente destilado), el rakshi (bebida elaborada con arroz y mijo en el Nepal), etc. siendo algunas de estas bebidas destiladas.

La leche por regla general sufre una fermentación láctica (la mayoría de los productos lácteos) que produce algunas bebidas alcohólicas. El proceso es alimentado por la lactosa (azúcar natural de la leche) y por la enzima lactasa que segregan algunas levaduras específicas (véase cultivos lácticos). La fermentación láctica y etílica es muy sensible a la temperatura y suele denominarse fermentación heteroláctica. Entre las bebidas lácteas que han sufrido una fermentación etílica se encuentra una bebida denominada koumiss (muy popular en países de Asia Central como en Kazajistán) que se elabora mediante la adición de sacarosa (azúcar de caña) a la leche pasteurizada y suele proporcionar bebidas de bajo contenido alcohólico, oscila entre un 1% y un 3%, el microorganismo responsable de este proceso es Lactobacillus bulgaricus. Se denomina a veces como: "vino de leche" y posee un aspecto grisáceo. En estas bebidas lácteas la fermentación láctica se produce al mismo tiempo que la alcohólica, cooperando ambas en un complejo proceso interrelacionado. Otra de las bebidas es el kéfir, muy popular en los países del Cáucaso y Asia Central, que contiene una cierta cantidad de etanol, que puede oscilar entre un 0,040% y un 0,300%, su bajo contenido se debe a las relativamente altos niveles de pH que paran el proceso fermentativo alcohólico.

Algunos alimentos fermentados poseen ciertas cantidades de etanol debido a pequeñas reacciones de fermentación etílica que se realizan durante la fermentación del alimento, las diferentes culturas del mundo emplean de una forma u otra esta fermentación como identificación cultural, debido quizás a que se suele emplear alguna fruta o verdura propia de la región. Uno de los ejemplos es el nattō de la culinaria japonesa. Una de las bebidas más populares en los pueblos de Europa del Norte es la hidromiel elaborada con agua y miel fermentadas cuya solera se remonta a la época de los vikingos, de la misma forma se elabora el tej etíope.

Las fermentaciones realizadas con azúcar de caña en los vinos azucarados como puede ser el basi filipino, el japonés "shoto sake". Los vinos de palma elaborados con la hoja de la palmera, algunos como puede ser el "ogogoro" de Nigeria, el "tuba" de Filipinas, el "kalu" de la India. El pulque de México elaborado con la fermentación alcohólica del zumo de la agave tequilana (en la que participa la bacteria "Zymomonas mobilis"), algunas bebidas similares son el colonche (o el nochoctli) elaborados de la fermentación de cactus. En México son conocidas también el tesgüino elaborado con la fermentación del maíz, el tibicos, la tuba. Una bebida que se hace a partir de la panela es una variante del guarapo que es una bebida alcohólica producto de la fermentación alcohólica del "agua de panela", muy popular en Colombia. El kenyan urwaga que es una bebida efervescente elaborado de bananas típico en Ruanda, similar es el mwenge de Uganda elaborado similarmente con sorgo y bananas. Las fermentaciones de maíz que elaboran la Chicha, a veces denominada tepache, en Colombia. De la misma forma ocurre con la fermentación de la manzana en la sidra (muy popular en países como España, Francia, Gran Bretaña) y en el apfelwein(Alemán), bebida muy popular en Alemania y los países del norte y centro de Europa, así como en algunas zonas del Cantábrico.

Una de las actividades lucrativas de algunas personas es la fermentación etílica casera, se trata de un proceso químico de baja eficiencia y del que se obtiene etanol en cantidades relativamente altas. El equipo básico para realizar la fermentación de forma casera puede consistir en las siguientes piezas:

Se suele comercializar para poder hacer la mezcla inicial diferentes productos con levaduras deshidratadas en su interior, la elección del producto dependerá fundamentalmente del tipo de azúcar empleado. Las levaduras deshidratadas deben pasar un periodo de hidratación de unas horas antes de ser añadido al substrato. Se debe considerar que la fermentación debe empezar aproximadamente a las 10 horas de componer el sistema y suele durar entre dos y cuatro días. A veces se incluyen además esencias diversas que se añaden en la elaboración final de estas bebidas caseras con el objeto de aromatizar o proporcionar diferentes sabores. En el kit de desarrollo debe incluirse un termómetro y un densímetro.

Este proceso es normalmente asociado el proceso de destilación casera para aumentar la pureza del alcohol resultante, permitiendo de esta manera producir aguardientes y otras bebidas de alto contenido alcohólico.

El empleo principal de los procesos de fermentación por parte del ser humano ha ido dirigido, desde muy antiguo, a la producción de etanol destinado a la elaboración de bebidas alcohólicas diversas. Esta situación cambió en el siglo XX ya que desde la crisis del petróleo de los '70 los estudios e investigaciones acerca de posibles combustibles alternativos ha sido de gran interés para los gobiernos de todo mundo. Dentro de los estudios de biotecnología se ha intentado emplear el etanol resultante de la fermentación alcohólica de los desechos agrícolas (biomasa)) en la obtención de biocombustibles (bioetanol) empleados en los motores de vehículos. Se ha intentado centrar los estudios en los reactores de fermentación continua con la esperanza de poder obtener no sólo grandes cantidades de etanol, sino que se aumente la eficiencia de los mismos. La investigación acerca de los substratos más adecuados, así como el empleo de levaduras de alto rendimiento es objeto de 
constante estudio. El etanol fue uno de las fuentes energéticas de combustible que más demanda mundial genera a comienzos del siglo XXI (con la excepción del petróleo), en el año 2004 los Estados Unidos produjeron más de 12.5 × 10 litros de etanol lo que supone un 17% de incremento sobre el año 2003. No obstante la generación de CO durante el proceso pone en alarma acerca de su uso, debido a las consecuencias que puede traer para el cambio climático.

Los usos del etanol en la industria son amplios y van desde la elaboración de productos cosméticos, productos de limpieza, etc. Se ha investigado la posibilidad de emplear la fermentación etílica en el tratamiento de los vertederos de basura logrando de esta forma biocombustible, los estudios no han arrojado aplicaciones concluyentes. No obstante el empleo de la fermentación alcohólica tiene un éxito potencial en el tratamiento de los residuos de la industria alimenticia. Un proceso industrial muy investigado a comienzos del siglo XXI es la fermentación en estado sólido empleada en la biomedicación y en la biodegradación de productos de desecho, la transformación biológica de residuos agroindustriales, en la producción de compuestos bioactivos, de enzimas, de ácidos orgánicos, biopesticidas, biocombustibles y compuestos aromáticos, entre otros.

Los efectos de la fermentación etílica se derivan de los productos resultantes del proceso que son liberados de una forma u otra al medio ambiente: el etanol y el dióxido de carbono. Los efectos de la fermentación dependerán de como se trate cada uno de estos subproductos. Uno de los efectos más sorprendentes se encuentra en la contaminación etílica existente en algunos insectos que se alimentan de frutas y del néctar de las flores, un ejemplo claro son las abejas (véase abejas y elementos tóxicos). De la misma forma puede intoxicar a los pájaros que se alimentan de algunas bayas maduras ya parcialmente fermentadas. La fermentación alcohólica en pequeña escala se produce de la misma forma en las raíces de algunas plantas que son regadas de manera muy frecuente, la falta de aireación del terreno hace que las condiciones anaeróbicas que necesitan las levaduras actúen pudiendo envenenar el suelo mediante un aumento de la concentración de etanol lo que se traduce en una disminución de la capacidad de producción de las mismas.

Otro aspecto importante es el efecto que produce en el cuerpo humano el consumo reiterado en los humanos de bebidas alcohólicas procedentes de la fermentación etílica (véase efectos del alcohol en el cuerpo) ya que el etanol es una potente droga psicoactiva con un nivel de efectos secundarios además de la adicción que genera su consumo habitual. Los lugares donde se realiza la fermentación de algunas bebidas alcohólicas (generalmente sótanos) suelen ser peligrosos ya que el dióxido de carbono 'desplaza' al oxígeno pudiendo causar asfixia a las personas que se encuentren en estos lugares.



</doc>
<doc id="41670" url="https://es.wikipedia.org/wiki?curid=41670" title="Clavícula">
Clavícula

La clavícula es un hueso de longitud considerable, con forma de "S" itálica, situado en la parte anterosuperior del tórax de los vertebrados . Junto con la escápula forman la cintura escapular .Se puede palpar por toda su longitud y se extiende del esternón al acromion de la escápula, siguiendo una dirección oblicua lateral y posterior. Se considera el único medio de unión entre el miembro superior y el tórax.

A pesar de su aspecto, similar al de un hueso largo, posee una estructura semejante a la de un hueso plano, ya que carece de un canal medular propiamente dicho.

Posee forma de "S" itálica y presenta:


La clavícula es el primer hueso largo en osificarse (por medio de la osificación intramembranosa), empezando durante la quinta o sexta semana de gestación a partir de los centros de osificación primarios medial y lateral que están cercanos en el cuerpo de la clavícula. Los extremos de la clavícula pasan más adelante por una fase cartilaginosa (osificación endocondral). Los cartílagos forman zonas de crecimiento similares a las que se encuentran en otros huesos largos. En el extremo externo aparece un centro de osificación secundario y forma una epífisis con aspecto de platillo que comienza a fusionarse con el cuerpo (diáfisis) entre los 18 y los 25 años de edad y que se fusiona por completo entre los 25 y 31 años. Ésta es la última de las epífisis de los huesos largos en fusionarse. Una epífisis todavía más pequeña y con forma de platillo puede estar presente en el extremo acromial de la clavícula; no se la debe confundir con una fractura. En ocasiones, la fusión de los dos centros de osificación de la clavícula falla; como resultado, se forma un defecto óseo entre los tercios medial y lateral de la clavícula. Conocer esta malformación congénita evita el diagnóstico erróneo de fractura en una clavícula normal. Cuando existen dudas, se toman radiografías de ambas clavículas, ya que este defecto suele ser bilateral (Ger y cols., 1996).

Cara superior:
Se halla justo por debajo de la piel y del músculo platisma (que significa lámina plana en griego). Es lisa en casi toda su extensión salvo algunas rugosidades inconstantes que marcan las zonas de inserción. Se insertan varios músculos como:


Cara inferior:
La cara inferior se encuentra excavada en su parte media por una depresión alargada para el músculo subclavio, limitado por crestas o labios para la inserción de la aponeurosis clavipectoral. Hacia la parte media se observa un agujero nutricio. En la extremidad esternal existe una pequeña superficie rugosa, la impresión del ligamento costoclavicular o tuberosidad costal donde se inserta dicho ligamento. Cerca de la extremidad acromial existe un conjunto de pequeñas rugosidades conocido como "tuberosidad del ligamento coracoclavicular" (coracoidea), donde se insertan los ligamentes conoideo y trapezoideo, normalmente la línea de inserción del ligamento conoideo está enteramente ocupada por una saliente marcada llamada tubérculo conoideo, también se encuentra un reparo llamado línea trapezoidea, que dispuesto anterolateralmente, se relaciona con la extensión del ligamento trapezoide.
Se insertan:


Borde anterior:
En sus dos tercios mediales es grueso, convexo, ligeramente áspero y sirve de inserción para el músculo pectoral mayor, su tercio lateral es cóncavo y delgado, también presenta asperezas donde se insertan los fascículos anteriores del deltoides.

Borde posterior:
Es grueso, cóncavo y liso en sus dos tercios mediales; lateralmente es convexo y rugoso y sirve para la inserción de los fascículos claviculares del trapecio, y el músculo esternocleidohioideo, en la parte medial.

Extremidad acromial: También llamada extremidad lateral o externa. Aplanada de superior a inferior; presenta una superficie articular elíptica para el borde interno del acromión, por lo general esta cara mira un poco hacia abajo y afuera, por lo que la clavícula tiende a desplazarse por encima del acromion.

Extremidad esternal:
Es la parte más voluminosa del hueso. Se le conoce también como interna. Presenta en una superficie articular triangular que se prolonga con la porción vecina de la cara inferior del hueso formando un ángulo diedro saliente, el cual se articula con el esternón y el primer cartílago costal. Superoposteriormente a la superficie articular se encuentra cubierta de rugosidades producidas por inserciones del disco articular y de los ligamentos.

La forma de la clavícula varía en mayor medida que la de prácticamente todos los otros huesos largos. A veces es perforada por un ramo del nervio supraclavicular. La clavícula de los trabajadores manuales es más gruesa y curva, y los lugares de inserción muscular se encuentran más acentuados. La clavícula derecha es más fuerte que la izquierda y generalmente más corta.

Es un hueso de Osificación intramembranosa y dermal. Al final de la cuarta semana, en el embrión humano, aparece el primer nivel de osificación. El segundo nivel se origina hacia los veinte años en su extremo externo, aproximadamente al año de su aparición se acopla al resto del hueso.

La clavícula aparece por primera vez como parte del esqueleto de peces primitivos, donde se asociaba con el pecho y con un hueso vertical llamado "cleithrum", aunque en los peces cartilaginosos y la gran mayoría de peces modernos se encuentra ausente.
Los primeros tetrápodos mantuvieron este hueso, con la adición de la interclavícula. El "cleithrum" desapareció tempranamente en reptiles, y también la interclavícula en los placentarios aunque se preservó en los reptiles y monotremas.

En muchos mamíferos, también las clavículas han sido reducidas o eliminadas, como en el caso de los ungulados y los mamíferos acuáticos, para permitir a la escápula una mayor libertad de movimiento, útil en animales veloces. En los dinosaurios y pájaros, las clavículas y la interclavícula se han fusionado en un hueso en forma de horquilla, la fúrcula (aves), o huesito de los deseos.





</doc>
<doc id="41673" url="https://es.wikipedia.org/wiki?curid=41673" title="Atlas (hueso)">
Atlas (hueso)

El atlas es el nombre que recibe el hueso más alto de toda la columna vertebral, siendo este la primera vértebra cervical (C1). Esta vértebra, que al articularse con el hueso occipital sostiene la cabeza, recibió su nombre al ser comparada con el titán Atlas quien como castigo tenía que sostener el cielo sobre sus hombros en la mitología griega.

Por delante se encuentra el arco más corto del hueso y en las masas laterales se observa que en la cara superior presenta una superficie que tradicionalmente se ha descrito como en forma de suela de zapato, conocida como "cavidad glenoidea". En el atlas podemos distinguir, entre otros, el arco anterior, arco posterior, dos masas laterales, tubérculo anterior, tubérculo posterior y apófisis transversas.

El arco anterior se une por sus dos raíces (izquierda y derecha) con las caras anteriores de las masas laterales y así describe una curva cuya concavidad es posterior. Cuenta con un borde superior, el cual se une al occipital por medio del ligamento (membrana) atlanto-occipital anterior, el borde inferior se une con el axis por medio del ligamento atlanto-axial anterior. Dicho arco presenta una cara anterior en la cual observamos en la línea media una saliente: el tubérculo anterior del atlas, donde toman inserción ciertos músculos de la región prevertebral. La cara posterior del arco anterior es cóncava en su totalidad, localizamos en la línea media una depresión en forma ovalada, con su eje mayor en sentido vertical, se llama fosita odontoidea y como su nombre indica en ella se articula la apófisis odontoides del axis (más exactamente la cara anterior de dicha apófisis odontoides), participando así en la articulación atlanto-axial medial anterior.

El arco posterior es más largo que el anterior, se implanta mediante sus dos raíces en las caras posteriores de las masas laterales, describe una curva de concavidad anterior. Su borde superior sirve de inserción al ligamento (membrana) atlanto-occipital posterior. En su borde inferior se inserta el ligamento atlanto-axial posterior, al cual se le puede considerar el primero en la serie de los ligamentos amarillos de la columna vertebral. 

La cara anterior del arco posterior es cóncava, forma la pared posterior del foramen vertebral a este nivel, sin embargo el arco anterior no forma el límite anterior del foramen vertebral en el ser vivo pues debido a la presencia del proceso odontoideo del axis y del ligamento transverso del atlas tenemos que la médula espinal se halla en contacto por su cara anterior con la articulación atlanto-axial medial, lo anterior es de vital importancia pues en caso de alguna fractura a nivel de dicha articulación, el «diente» del axis hace protrusión en el conducto raquídeo y justo en ese trayecto la médula espinal hace transición con la médula oblongada, la cual puede resultar lesionada y debido a la presencia del centro cardiorrespiratorio se produce una muerte súbita. La cara posterior presenta en la línea media el tubérculo posterior el cual puede o no ser bífido, en él se presentan las inserciones de varios músculos de la región nucal, el recto posterior menor de la cabeza, por ejemplo.

Las masas laterales se asemejan de cierta forma a un cubo, por lo que se les estudian 6 caras. En la cara anterior se implanta el arco anterior. En la cara posterior se implanta el arco posterior. La cara medial constituye la pared lateral del foramen vertebral, en su tercio anterior encontramos un tubérculo, en dicho tubérculo toma inserción el ligamento transverso del atlas. La cara superior tiene forma de suela de zapato o cacahuate, es la cavidad glenoidea, mira hacia arriba y medialmente, cóncava en todos los sentidos, recibe al cóndilo occipital correspondiente. La cara inferior mira hacia abajo y medialmente, se articula con la apófisis articular superior del axis. 

La cara lateral presenta la apófisis transversa, que cuenta con dos raíces (anterior y posterior) por medio de las cuales se une a la masa lateral propiamente, presentan dichas apófisis el agujero transverso, por donde pasa la arteria vertebral, terminan en un tubérculo. Justo por encima de la unión del arco posterior con la masa lateral hallamos un surco, el surco de la arteria vertebral, la cual después de abandonar el agujero transverso hace una curva y se coloca en dicho surco para después perforar la membrana atlanto-occipital posterior y entrar así al conducto raquídeo.




</doc>
<doc id="41674" url="https://es.wikipedia.org/wiki?curid=41674" title="Axis">
Axis

El término axis puede referirse a:


</doc>
<doc id="41676" url="https://es.wikipedia.org/wiki?curid=41676" title="Húmero">
Húmero

El Húmero (en latín, "humerus") es el hueso más largo de las extremidades superiores en el ser humano. Forma parte del esqueleto apendicular superior y se ubica en la región del brazo.

Se articula en su porción superior con la escápula, por medio de la articulación del hombro (o articulación glenohumeral) y en la inferior con el cúbito y el radio, por medio de la articulación del codo (o articulación humeroradioulnar). El extremo proximal del húmero tiene la cabeza, cuellos quirúrgico y anatómico y tubérculos mayor y menor.

La palabra se deriva del latín: humerus, umerus que significa brazo, el hombro y está lingüísticamente relacionado al gótico ams = hombro y ōmos del griego.













En el hombro, la cabeza del húmero se articula con la cavidad glenoidea de la escápula formando la articulación del hombro. La articulación contiene al labrum glenoideo, y es reforzada por los ligamentos glenohumerales, el ligamento coracohumeral y el ligamento humeral transverso.

Más distalmente, en el codo, el cóndilo del húmero se articula con la cabeza del radio y la tróclea del húmero se articula con la escotadura troclear del cúbito para formar la articulación del codo. El húmero participa en las dos articulaciones que conforman la articulación del codo:


La articulación radio cubital superior no pertenece a la articulación del codo.

A lo largo del húmero, se encuentran insertos veinticinco músculos.











En fósiles de anfibios primitivos, las extremidades superiores e inferiores, tenían pocas articulaciones, haciendo que sus húmeros sean muy cortos debido al poco tamaño de sus extremidades. En la mayoría de los tetrápodos sobrevivientes, sin embargo, el húmero tiene una forma similar a la de los seres humanos. En muchos reptiles y algunos mamíferos primitivos, la extremidad inferior incluye un gran agujero, o la apertura, en la que los nervios y los vasos sanguíneos pasan.




</doc>
<doc id="41679" url="https://es.wikipedia.org/wiki?curid=41679" title="Cúbito">
Cúbito

El cúbito o ulna es un hueso largo, paralelo al radio, situado entre la tróclea humeral y el carpo. Se encuentra en la parte interna del antebrazo; se articula superiormente con el húmero y el radio, y por la parte inferior con el radio y con los huesos del carpo. Tiene un cuerpo y dos extremidades.

No es exactamente rectilíneo, presenta una curvatura ligera de concavidad anterior. Describe una S itálica en el plano verticotransversal, cóncava hacia dentro en su parte superior y hacia fuera en la inferior. Tiene mayor volumen hacia arriba que hacia abajo, es prismático triangular en sus tres cuartas partes superiores e irregularmente cilíndrico en su cuarto inferior.

Presenta tres caras y tres bordes.

Posee la apófisis posterosuperior, el olécranon, que constituye la prominencia dorsal del codo, y otra en la región anterior: la apófisis coronoides. Ventral al olécranon se ubica la incisura troclear o cavidad sigmoidea mayor que se articula con la tróclea humeral y lateral en la epífisis superior se ubica la incisura radial o cavidad sigmoidea menor que sirve para articular con el radio.

Es ligeramente curvada, más voluminosa por arriba que por abajo. Posee tres caras (anterior, posterior y medial) y tres márgenes (anterior, posterior y lateral)

Presenta dos eminencias, una es la cabeza del cubito, que presenta la circunferencia articular radial que se articula con el radio, y otra es el proceso estiloides de ubicación medial y posterior. Entre ambas, en la cara inferior, hay un canal en el que se inserta el disco articular que separa al cubito de los huesos del carpo.



</doc>
<doc id="41681" url="https://es.wikipedia.org/wiki?curid=41681" title="Clúster de alta disponibilidad">
Clúster de alta disponibilidad

Un clúster de alta disponibilidad es un conjunto de dos o más máquinas que se caracterizan por mantener una serie de servicios compartidos y por estar constantemente monitorizándose entre sí. 

No hay que confundir un clúster de alta disponibilidad con un clúster de alto rendimiento. El segundo es una configuración de equipos diseñado para proporcionar capacidades de cálculo mucho mayores que la que proporcionan los equipos individuales (véanse por ejemplo los sistemas de tipo Cluster Beowulf), mientras que el primer tipo de clúster está diseñado para garantizar el funcionamiento ininterrumpido de ciertas aplicaciones.

Podemos dividirlo en dos clases:


En un sistema real, si falla uno de los componentes, es reparado o sustituido por un nuevo componente. Si este nuevo componente falla, es sustituido por otro, y así sucesivamente. El componente fijo se considera en el mismo estado que un nuevo componente. Durante su vida útil, uno de los componentes pueden ser considerado en uno de estos estados: funcionando o en reparación. El estado funcionando indica que el componente está operacional y el en reparación significa que ha fallado y todavía no ha sido sustituido por un nuevo componente. 

En caso de defectos, el sistema va funcionando en modo reparación, y cuando se hace la sustitución volverá al estado funcionando. Por lo tanto, podemos decir que el sistema tiene durante su vida, una media de tiempo para presentar fallas (MTTF) y un tiempo medio de reparación (MTTR). Su tiempo de la vida es una sucesión de MTTFs y MTTRs, a medida que este va fallando y siendo reparado. El tiempo de vida útil del sistema es la suma de MTTFs en ciclos MTTF + MTTR ya vividos. 

En forma simplificada, se dice que la disponibilidad de un sistema es la relación entre la duración de la vida útil de este sistema y de su tiempo total de vida. Esto puede ser representado por la fórmula de abajo: 

Disponibilidad = MTTF / (MTTF + MTTR) 

En la evaluación de una solución de alta disponibilidad, es importante tener en cuenta si en la medición de MTTF son vistos como fallas las posibles paradas planificadas.



</doc>
<doc id="41699" url="https://es.wikipedia.org/wiki?curid=41699" title="Motor">
Motor

Un motor es la parte "sistemática" de una máquina capaz de hacer funcionar el sistema, transformando algún tipo de energía (eléctrica, de combustibles fósiles, etc.), en energía mecánica capaz de realizar un trabajo. En los automóviles este efecto es una fuerza que produce el movimiento.
Existen diversos tipos, siendo de los más comunes los siguientes :

En los aerogeneradores, las centrales hidroeléctricas o los reactores nucleares también se transforma algún tipo de energía en otro. Sin embargo, la palabra "motor" se reserva para los casos en los cuales el resultado inmediato es energía mecánica.

Los motores eléctricos utilizan la inducción electromagnética que produce la electricidad para producir movimiento, según sea la constitución del motor: núcleo con cable arrollado, sin cable arrollado, monofásico, trifásico, con imanes permanentes o sin ellos; la potencia depende del calibre del alambre, las vueltas del alambre y la tensión eléctrica aplicada.


En ciertas ocasiones la palabra "motor" es utilizada para referirse a entidades que desarrollan determinadas tareas y no "trabajo" en el sentido físico. Este uso es particularmente visible en informática, donde son comunes términos como motor de búsqueda, "motor SQL" o "motor de juegos". Como en muchos otros términos de la jerga informática, suele emplearse su equivalente en idioma inglés, "engine", especialmente en algunos países de Latino-américa.

También suele denominarse como motor de juego o "Game Engine" a una serie de rutinas de programación que permiten el diseño, la creación y la representación de un videojuego.

Como novedad, cabe citar la re-utilización del motor de explosión entre otras piezas de coches como material para construir obras artísticas de alta calidad. Se trata de arte reciclado y sostenible.



</doc>
<doc id="41702" url="https://es.wikipedia.org/wiki?curid=41702" title="WarGames: Defcon 1">
WarGames: Defcon 1

Wargames es un juego de acción y estrategia de 1998 para PlayStation y PC. Está basado en la película Juegos de guerra de 1983. Es un juego en tercera persona y tiene dos perspectivas de juego:

W.O.P.R.

N.O.R.A.D
En total son 30 misiones de intensa batalla y combate, esta lucha comienza en el 2003.
Cuando las máquinas obtienen una mayor inteligencia y tienen ambición de conquistar el 
mundo. Las máquinas también llamadas WOPR (War Operation Programmed Response), luchan 
contra los humanos también llamados NORAD (North American Air Defense Command). Creado 
por Interactive Studios

En 1983 se creía que sería así la tercera guerra mundial, NORAD con las demás naciones
tienen que salvar a la humanidad de los WOPR, en las misiones debes destruir a todos 
los enemigos o a sus bases, los objetivos se dan después de terminar los anteriores o sino pierdes, a través de un e-mail se dan los objetivos.



Tanto las unidades WOPR y NORAD, casi por las últimas Misiones, podían crear estas unidades Especiales. Tenían gran poder de ataque contra otras unidades de infantería y Podías Tomar bases enemigas.



Es cuando las unidades se acercan a un Command center (NORAD) o a un Command Complex (WOPR) o al Centro computarizado, Wopr y Norad pueden usar cualquiera, con la intensio de poder mejorar los 3 principales Estadísticas de todas las unidades ARMOR, SPEED y FIREPOWER, así como uno se podía subir las estadísticas, el enemigo también te debilitaba. Los Hacker también podían revelar partes del mapa Aleatoriamente. Luego viene el Transport helicopter (NORAD) o la Shuttle (WOPR).

Las Órdenes del juego son muy simples 

Todas las unidades pueden hacerlas

Solo los Scout Drones y Jeeps pueden hacerlo, tirando una lata de humo

Todas las Unidades pero deben estar cerca de un lugar de Hacking

Solo las Banshees o los Stealth Tanks, con círculo

Solo los APC y los WarHorses, deben estar junto a unas tropas, con círculo


En Wargames hay Defcon que es el peligro del nivel. Sube: Cuando destruyes enemigos o edificios del otro. Baja: Cuando bombardeas o dejas pasar el tiempo.


Invisibilidad Infinita: Cuando estés en un Stealth Tank o Banshee presiona círculo y mantén aplastado el botón hasta que el poder sea de menos 0% (-1%)

Excelente en el último nivel



</doc>
<doc id="41704" url="https://es.wikipedia.org/wiki?curid=41704" title="Intestino">
Intestino

El intestino (del latín: "intestinus") es la porción del tubo digestivo que se encuentra entre el estómago y el ano. Su función principal es absorber los nutrientes y el agua que se ingieren durante el proceso de alimentación.

Se divide en dos partes: intestino delgado e intestino grueso. 

La mayor parte de la absorción de los alimentos se produce a través de la pared del intestino delgado. Para aumentar la superficie de absorción y facilitar el proceso, la mucosa tiene pequeñas proyecciones que reciben el nombre de vellosidades intestinales, cada una de las cuales contiene a su vez pequeños pliegues que se llaman microvellosidades. Cada vellosidad dispone de vasos sanguíneos y linfáticos mediante los cuales las sustancias absorbidas pasan a la sangre y la linfa y se distribuyen a otras partes del organismo. 

El intestino grueso tiene entre otras funciones la reabsorción del agua, lo que produce la compactación de los residuos para formar las heces que son expulsadas a través del ano durante el proceso de defecación. En el interior del intestino grueso existen gran cantidad de bacterias beneficiosas que se conocen en conjunto como flora intestinal, las cuales sintetizan la vitamina K y algunas vitaminas del complejo B.

Cuando los alimentos salen del estómago se han transformado en una especie de papilla que se denomina quimo. El quimo transcurre a través del intestino delgado durante un periodo de tiempo aproximado de entre 4 y 6 horas. En ese plazo se mezcla con las secreciones del páncreas que produce diversas enzimas que hacen posible el proceso de la digestión. El avance del quimo tiene lugar gracias a los movimientos activos del intestino provocados por la contracción coordinada del músculo liso que se encuentra en su pared. Estos movimientos son de varios tipos: 

El tiempo que tardan los restos alimentarios en atravesar el intestino grueso es variable, oscilando alrededor de las 15 horas. Se producen varios tipos de movimientos de la pared, principalmente los siguientes:



</doc>
<doc id="41706" url="https://es.wikipedia.org/wiki?curid=41706" title="FPS">
FPS

El término FPS, es el acrónimo del concepto frames per second, que en español significa fotogramas por segundo, aunque también se puede conocer como frame rate. Consiste en la velocidad a la que un videojuego o vídeo muestra los cuadros o fotogramas, decir, el número de imágenes que muestra por segundo.




</doc>
<doc id="41708" url="https://es.wikipedia.org/wiki?curid=41708" title="Hueso pisiforme">
Hueso pisiforme

El hueso pisiforme (en forma de guisante) es un hueso sesamoideo de la muñeca, par, corto, esponjoso, cuboideo, con cuatro caras de las cuales una es articular, y dos extremos, superior e inferior.
Es el cuarto hueso de la primera fila del carpo.
Sus cuatro caras son: Externa, interna, anterior y posterior.
En la cara externa va a presentar un canal longitudinal para dar paso a la arteria cubital y un ramo profundo del nervio cubital.
En la cara interna va a dar inserción al ligamento lateral interno de la articulación de la muñeca.
En la cara anterior va a prestar inserción al músculo aductor del meñique y al músculo cubital anterior.
Y por último en la cara posterior se va articular con el hueso piramidal.


</doc>
<doc id="41709" url="https://es.wikipedia.org/wiki?curid=41709" title="Hueso piramidal">
Hueso piramidal

El hueso piramidal es un hueso de la muñeca, par, corto, esponjoso, en forma de pirámide, con seis caras, de las cuales tres son articulares.
Articula superiormente con el pisiforme, lateralmente (en relación con el plano sagital) con el semilunar y distalmente con el ganchoso.
Es un hueso de la primera fila del carpo; se articula con el pisiforme, semilunar y ganchoso.
Para tener una mayor idea de su ubicación se podría decir que es el tercero en el carpo así el orden seria: escafoides, semilunar y piramidal.


</doc>
<doc id="41711" url="https://es.wikipedia.org/wiki?curid=41711" title="Hueso ganchoso">
Hueso ganchoso

El hueso ganchoso o Hamato es un hueso de la muñeca, par, corto y esponjoso, de forma piramidal, con seis caras, de las cuales cuatro son articulares.

Es el cuarto hueso, de radial hacia ulnar, de la segunda fila del carpo. Se articula con el piramidal, grande del carpo, semilunar y cuarto y quinto metacarpianos. Es el último de la segunda fila. En su cara anterior se levanta una larga apófisis unciforme, en forma de gancho, en cuyo vértice se fija el ligamento anterior del carpo. Su cara posterior es rugosa. Su cara superior, articular parece más bien un borde obtuso, para el semilunar. Su cara inferior posee dos carillas para los dos últimos metacarpianos. Su cara externa es articular para el hueso grande. Su cara interna, articular también en casi toda su extensión para el piramidal.




</doc>
<doc id="41713" url="https://es.wikipedia.org/wiki?curid=41713" title="Hueso grande">
Hueso grande

El hueso grande es un hueso de la muñeca, par, corto y esponjoso, cuboideo, formado por tres porciones: cabeza, cuello y cuerpo, con seis caras, de las cuales cuatro son articulares.

Es el tercer hueso de la segunda fila del carpo. Se articula con el escafoides, semilunar, trapezoide, ganchoso y segundo, tercer y cuarto metacarpianos.


</doc>
<doc id="41714" url="https://es.wikipedia.org/wiki?curid=41714" title="Al Gore">
Al Gore

Albert Arnold Gore, también conocido como «Al» Gore, Jr. (Washington D. C., 31 de marzo de 1948) es un político, economista y filántropo estadounidense que sirvió como el 45°. (1993-2001) bajo el mandato del presidente Bill Clinton. Fue el del Partido Demócrata para la elección presidencial de 2000 y perdió contra George W. Bush, a pesar de ganar el voto popular. Después del servicio público, permaneció prominente como autor y activista medioambiental. Ha fundado varias organizaciones sin ánimo de lucro, incluida la Alianza para la Protección del Clima, y ha recibido el premio Nobel de la Paz por su activismo sobre el cambio climático.

Gore fue un funcionario electo durante 24 años. Fue congresista de Tennessee (1977–85) y de 1985 a 1993 sirvió como uno de los senadores del estado. Trabajó como vicepresidente durante la administración Clinton entre 1993 y 2001. En la elección presidencial de 2000, Gore ganó el voto popular pero perdió en el Colegio Electoral frente al republicano George W. Bush. Un controvertido litigio electoral sobre un recuento de votos en Florida fue resuelta por la Corte Suprema, la cual falló 5–4 a favor de Bush.

Gore es el fundador y actual presidente de la Alianza para la Protección de Clima, el cofundador y presidente de la Generation Investment Management y la ahora difunta red de Current TV, un miembro del Consejo de administración de Apple Inc. y un asesor sénior de Google. Gore es también un socio en la firma de capital de riesgo Kleiner Perkins Caufield & Byer y encabeza su grupo de soluciones de cambio climático. Ha servido como profesor invitado en la Universidad Estatal de Tennessee Central, la Escuela de Posgrado de Periodismo de la Universidad de Columbia, la Universidad Fisk y la Universidad de California, Los Ángeles. Sirvió en el Consejo de administración de World Resources Institute.

Gore ha recibido varios premios que incluyen el (junto al Grupo Intergubernamental de Expertos sobre el Cambio Climático, 2007), un (2009) por su libro "Una verdad incómoda", un Primetime Emmy por Current TV (2007) y un Premio Webby (2005). Gore fue también el tema del documental (2007) "Una verdad incomoda" de 2006. En 2007 fue nombrado segunda Persona del Año 2007 por la revista "Time".

Gore nació el 31 de marzo de 1948 en Washington, D.C., el segundo de dos hijos de Albert Gore Sr., un representante de los Estados Unidos que más tarde sirvió durante 18 años como senador estadounidense de Tennessee, y Pauline (LaFon) Gore, una de las primeras mujeres en graduarse de la Facultad de Derecho de la Universidad Vanderbilt. Gore es descendiente de inmigrantes escoceses-irlandeses que se establecieron por primera vez en Virginia a mediados del siglo XVII y se mudaron a Tennessee después de la Guerra de Independencia. Su hermana mayor, Nancy LaFon Gore, murió de cáncer de pulmón.

Durante el año escolar vivía con su familia en The Fairfax Hotel en la sección Embassy Row en Washington D.C.. Durante los meses de verano, trabajaba en la granja familiar en Carthage, Tennessee, donde los Gore cultivaban tabaco y heno y criaban ganado.

Gore asistió a la Escuela St. Albans, un día de preparación universitaria independiente y un internado para niños en Washington, D.C., de 1956 a 1965, una prestigiosa escuela secundaria para la Ivy League. Fue el capitán del equipo de fútbol, lanzó disco para el equipo de atletismo y participó en baloncesto, arte y gobierno. Se graduó 25º en una clase de 51, aplicó a Harvard y fue aceptado.

Gore conoció a Mary Elizabeth «Tipper» Aitcheson en su fiesta de graduación de St. Albans en 1965. Era de la cercana escuela de St. Agnes. Tipper siguió a Gore a Boston para asistir a la universidad, y se casaron en la Catedral Nacional de Washington el 19 de mayo de 1970.

Tienen cuatro hijos: Karenna Gore (n. 1973), Kristin Carlson Gore (n. 1977), Sarah LaFon Gore (n. 1979) y Albert Arnold Gore III (n. 1982).

En junio de 2010 (poco después de comprar una nueva casa), los Gore anunciaron en un correo electrónico a sus amigos que después de «una consideración larga y cuidadosa», habían tomado la decisión mutua de separarse. En mayo de 2012, se informó que Gore comenzó a salir con Elizabeth Keadle de California.

Inició su carrera como político en 1976, cuando fue elegido por Tennessee al Congreso de los Estados Unidos. Fue elegido para el Senado en 1984, y reelegido una vez más en 1990. Su candidatura para la nominación demócrata a la presidencia en 1988 no tuvo éxito.

En 1992 Al Gore publica el ya clásico "Earth in the Balance: Ecology and Human Spirit", en el cual plantea una revolución ecológica necesaria para el siglo XXI. Posteriormente, Al Gore se ha transformado en uno de los líderes ecológicos más importantes a nivel mundial.
Acompañado en la fórmula por Joseph Lieberman, Gore fue candidato por el Partido Demócrata a la Casa Blanca para las elecciones de noviembre de 2000, siendo el candidato que más votos obtuvo, medio millón más que George W. Bush y muy por delante de Ralph Nader y Pat Buchanan.
Sin embargo, su oponente republicano, George W. Bush, ganó en número de colegiados. Muy importante para este resultado fue que Bush obtuvo oficialmente unos cientos de votos más en Florida, estado clave para el recuento por lo ajustado de los resultados. La validez de estos resultados fue muy discutida, entre otros motivos porque en varias mesas se presentaban papeletas que podían propiciar equívocos, porque no se permitió el voto a numerosos ciudadanos de Florida por sus antecedentes penales, y porque se pusieron graves trabas a votantes cuyo nombre y apellidos coincidiesen con los de los ciudadanos vetados por sus antecedentes. A pesar de todo, tras unas semanas de sucesivos recuentos y apelaciones judiciales, Gore desistió y reconoció a Bush como ganador.

Tras perder las elecciones de 2000, Gore se convirtió en profesor de periodismo por algunos meses, y después volvió a dar conferencias sobre ecologismo. En septiembre de 2002 condenó fuertemente la política de Bush en Irak, denominándola "una distracción" y acusando a Bush de dañar la imagen de Estados Unidos en el extranjero.
Tras levantar una gran expectación, no se presentó a las primarias demócratas de 2004, pero apoyó la candidatura fallida de Howard Dean.

Bill Clinton y Gore habían mantenido una distancia pública informal durante ocho años, pero se reunieron para los medios en agosto de 2009. Clinton había arreglado la liberación de dos mujeres periodistas que fueron retenidas como rehenes en Corea del Norte. Las mujeres eran empleadas de Current TV de Gore. En mayo de 2018, formó parte del comité del gobierno indio para coordinar las celebraciones de un año del 150 aniversario del nacimiento de Mahatma Gandhi, que comenzaron el 2 de octubre de 2019.

A partir de 2002, Gore comenzó a criticar públicamente a la administración Bush. En un discurso del 23 de septiembre que pronunció ante el Commonwealth Club de California, Gore criticó a Bush y al Congreso por la prisa por la guerra antes del estallido de las hostilidades en Irak. Comparó esta decisión con la Guerra del Golfo Pérsico (por la cual Gore había votado) al declarar: «En 1991, fui uno de los pocos demócratas en el Senado de los Estados Unidos que votó a favor de la resolución que respalda la Guerra del Golfo Pérsico... Pero observe las diferencias entre la resolución que se votó en 1991 y la que esta administración propone que el Congreso vote en 2002. Las circunstancias son real y completamente diferentes. Para revisar brevemente algunos de ellos: en 1991, Irak había cruzado una frontera internacional, invadió una nación soberana vecina y anexó su territorio. Ahora, por el contrario, en 2002, no ha habido tal invasión». En un discurso pronunciado en 2004, durante las elecciones presidenciales, Gore acusó a George W. Bush de traicionar al país utilizando los ataques del 11 de septiembre como justificación para la invasión de Irak. Al año siguiente, Gore dio un discurso que cubrió muchos temas, incluido lo que llamó «fanáticos religiosos» que afirman tener un conocimiento especial de la voluntad de Dios en la política estadounidense. Gore declaró: «Incluso afirman que aquellos de nosotros que no estamos de acuerdo con su punto de vista estamos librando una guerra contra las personas de fe». Después del huracán Katrina en 2005, Gore alquiló dos aviones para evacuar a 270 personas de Nueva Orleans y criticó la respuesta de la administración Bush al huracán. En 2006, Gore criticó el uso de escuchas telefónicas domésticas por parte de Bush sin una orden judicial. Un mes después, en un discurso pronunciado en el Foro Económico de Jeddah, Gore criticó el tratamiento hacia los árabes en los Estados Unidos después de declarar el 11 de septiembre: «Lamentablemente ha habido abusos terribles y está mal ... Quiero que sepas que no representa los deseos o sentimientos de la mayoría de los ciudadanos de mi país». El libro de 2007 de Gore, "The Assault on Reason", es un análisis de lo que Gore llama «vaciar el mercado de ideas» en el discurso cívico durante la administración Bush. Atribuye este fenómeno a la influencia de la televisión y argumenta que pone en peligro la democracia estadounidense. Por el contrario, argumenta Gore, Internet puede revitalizar y finalmente «redimir la integridad de la democracia representativa». En 2008, Gore argumentó en contra de la prohibición del matrimonio entre personas del mismo sexo en su sitio web Current TV, al decir: «Creo que los hombres y mujeres homosexuales deberían tener los mismos derechos que los hombres y mujeres heterosexuales para hacer contratos, tener derechos de visita al hospital y unirse en matrimonio». En una entrevista de 2009 con CNN, Gore comentó sobre las críticas del exvicepresidente Dick Cheney a la . Refiriéndose a su propia crítica anterior de las administraciones de Bush, Gore declaró: «Esperé dos años después de dejar el cargo para hacer declaraciones que fueron críticas, y luego de la política... Ya sabes, hablas de alguien que no debería estar hablando de hacer que el país sea menos seguro, invadir un país que no nos atacó y que no representa una amenaza grave para nosotros».

Si bien Gore ha criticado a Bush por su respuesta a Katrina, no ha hablado públicamente sobre su parte en la evacuación de 270 pacientes el 3 y 4 de septiembre de 2005, del Hospital Charity en Nueva Orleans a Tennessee. El 1 de septiembre, el Dr. David Kline —quien había operado al hijo de Gore, Albert—, neurocirujano del Hospital Charity, contactó a Gore a través de Greg Simon de FasterCures. Kline informó a Gore y Simon de las condiciones alarmantes en el hospital y les pidió a Gore y Simon que lo arreglaran. En el compromiso financiero personal de Gore, dos aerolíneas proporcionaron un avión con un vuelo posteriormente suscrito por Larry Flax. Los vuelos fueron realizados por tripulaciones voluntarias de la aerolínea y atendidos médicamente por el primo de Gore, el coronel retirado Dar LaFon y el médico de familia Dr. Anderson Spickard, y fueron acompañados por Gore y Albert III. Gore usó su influencia política para acelerar los derechos de aterrizaje en Nueva Orleans.
La gente especulaba que Gore sería un candidato para las elecciones presidenciales de 2004 (una calcomanía, «¡Reeligir a Gore en 2004!» era popular). Sin embargo, el 16 de diciembre de 2002, Gore anunció que no competiría en 2004. Si bien Gore consideró seriamente desafiar a Bush en 2004, los ataques del 11 de septiembre y el posterior aumento estratosférico en la popularidad del presidente Bush como resultado de su respuesta a estos ataques fueron factores importantes en la decisión de Gore de diciembre de 2002 de no volver a presentarse en 2004. A pesar de que Gore se retiró de la contienda, un puñado de sus seguidores formaron una campaña nacional para reclutarlo para que compitiera. Un observador concluyó que era «Al Gore quien tiene la mejor oportunidad de derrotar al presidente en ejercicio», y señaló que «de los 43 presidentes, solo tres han sido descendientes directos de ex presidentes»: John Quincy Adams, Benjamin Harrison y George W. Bush, que «los tres ganaron el cargo solo después de ... anomalías en el Colegio Electoral», que los dos primeros fueron derrotados por reelección en una reacción populista, y finalmente eso «Los hombres que primero perdieron ante la progenie presidencial y luego los vencieron» (es decir, Andrew Jackson y Grover Cleveland) «cada uno ganó una especie de inmortalidad: colocar su imagen en una unidad de moneda estadounidense», y que Gore debería responder a esta llamada de la historia. El proyecto de movimiento, sin embargo, no logró convencer a Gore de que participara.

La posibilidad de una candidatura de Gore surgió nuevamente entre 2006 y principios de 2008 a la luz de las próximas elecciones presidenciales de 2008. Aunque Gore frecuentemente declaró que «no tenía planes de contender», no rechazó la posibilidad de una futura participación en la política que llevó a especular que podría participar. Esto se debió en parte a su mayor popularidad después del lanzamiento del documental de 2006, "An Inconvenient Truth". El director de la película, Davis Guggenheim, declaró que después del lanzamiento, «En todas partes donde voy con él, lo tratan como una estrella de rock».

Gore ha estado involucrado en los problemas ambientales desde 1976, cuando en su primer año de congresista, llevó a cabo las "primeras audiencias en el Congreso sobre el cambio climático y audiencias copropuestas sobre residuos tóxicos y el calentamiento global"." Continuó hablando sobre el tema a lo largo de década de 1980, y todavía está activo en la comunidad ambiental. Era conocido como uno de los "demócratas Atari", más tarde llamado los "demócratas verdes, políticos que ven temas como el aire limpio, el agua limpia y el calentamiento global como la clave para futuras victorias de su partido".

En 1990, el senador Gore presidió una conferencia de tres días con los legisladores de más de 42 Países que buscaron crear un "Plan Marshall Global", "bajo el cual las naciones Industrializadas ayudarían a los países menos desarrollados a crecer económicamente a la vez que aún se protege el medio ambiente. A los finales de 1990, Gore presionó fuertemente la adopción del Protocolo de Kioto, que exige reducciones en las emisiones de gases invernadero. Se le opuso el Senado, quien aprobó por unanimidad (95-0) la Resolución Byrd–Hagel (S. Res. 98), que declaraba que la opinión del Senado era que los Estados Unidos no debía firmar ningún protocolo que no incluyera objetivos vinculantes y fechas para las naciones en desarrollo además de las industrializadas o "resultaría en un daño serio a la economía de los Estados Unidos".

En 2004 cofundó Generation Investment Management, compañía que presidió. Unos años después, Gore fundó también The Alliance for Climate Protection, una organización que luego lanzaría la campaña "We". Gore se volvió miembro en una agencia de capital de riesgo, Kleiner Perkins Caufield & Byers, en la que encabeza el grupo de soluciones al cambio climático. También ayudó a organizar los conciertos benéficos "Live Earth".

El 24 de mayo de 2006 se estrenó "una verdad incómoda", luego de que la productora, Laurie David, asistiera a la charla sobre cambio climático que dio el filántropo en Nueva York en 2004. David propuso a Gore adaptar la presentación que había hecho en público, para el cine. 

Además de aumentar la conciencia sobre el calentamiento global, el documental ganó dos Oscars y fue todo un éxito en la industria cinematográfica.

En 2013, Gore se volvió vegano. Anteriormente había admitido que "Es absolutamente correcto que la intensidad creciente de la carne de las dietas a lo largo del mundo es uno de los asuntos conectados a la crisis global. No solo por el [dióxido de carbono] involucrado, sino también debido al agua consumida en el proceso" y algunos especulan que su adopción de esta dieta es relacionado con su postura medioambiental. En una entrevista de 2014, Gore dijo "Hace un año cambié mi dieta a una dieta vegana, realmente solo para experimentar y ver cómo era. [...] Me siento mejor, así que he continuado con ella y probablemente la continúe por el resto de mi vida".

La participación de Gore en los problemas ambientales ha sido criticada. Por ejemplo, se le ha tildado de "millonario del carbono" y acusado de lucrar con su activismo; acusación que ha negado y ha dicho, entre otras cosas, que está orgulloso de demostrar con acciones lo que ha apoyado durante unos 30 años. Un "think tank" derechista de Washington D.C. y un congresista republicano, entre otros, han afirmado que Gore tiene un conflicto de interés por defender subsidios a las tecnologías de energía verde en las que tiene una inversión personal. Además, ha sido criticado por tener un consumo energético sobre el promedio en el uso de jets privados y múltiples casas grandes, una de las cuales se informó en 2007 que usaba gran cantidad de electricidad. El portavoz de Gore respondió que los Gore usan energía renovable, que es más cara que la regular, y que la casa de Tennesse en cuestión había sido modernizada para hacerla energéticamente más eficiente.

Se ha cuestionado la información de "Una verdad incómoda". En un caso judicial de 2007, un juez británico dijo que "sin duda [...] la película fue ampliamente correcta" y que sus "cuatro hipótesis científicas principales [...] están apoyadas por una vasta cantidad de investigación", y confirmó nueve de una "larga lista" de supuestos errores presentados a la corte. Falló que el filme podía mostrarse a los escolares británicos si las notas de guía dada a los profesores fueran modificadas para equilibrar las posturas políticas unilaterales de la película. La portavoz de Gore respondió en 2007 que el tribunal había confirmado la tesis fundamental del documental y su uso como una herramienta educativa. En 2009, un entrevistador le preguntó a Gore sobre el reto del tribunal británico y los nueve "errores" y Gore respondió "el fallo fue a mi favor".

A finales de 1980 y la década de 1990, Gore fue criticado por su participación en pedir a la EPA controles de polución menos estrictos para el río Pigeon.

Organizaciones, incluida People for the Ethical Treatment of Animals (PETA), criticaron a Gore por no defender el vegetarianismo como una forma en que las personas reduzcan su huella de carbono. Gore está de acuerdo en que la producción de carne contribuye a incrementar las emisiones de carbono, pero no quería ir "tan lejos como [...] decir que todo el mundo debería convertirse en vegetariano". Dijo que aunque no era un vegetariano, había "reducido intensamente" su consumo de carne.

Cuando Bjørn Lomborg le pidió debatir si el gasto en salud y educación debía tener prioridad sobre limitar las emisiones de carbono, Gore respondió que no lo haría debido a que la "comunidad científica ha pasado por esto en el mayor detalle. Desde hace mucho que hemos pasado el tiempo cuando debíamos pretender que este es un problema 'por un lado, por el otro'. [...] No es un asunto de teoría o conjetura".

Gore ha sido galardonado con varios premios, incluido el Premio Nobel de la Paz (junto al Grupo Intergubernamental de Expertos sobre el Cambio Climático) «por sus esfuerzos para construir y diseminar un mayor conocimiento sobre el cambio climático causado por el hombre y poner las bases para la toma de las medidas que sean necesarias para contrarrestar ese cambio» en 2007, un Primetime Emmy Award para Current TV en 2007, un Webby Award en 2005 y el Premio Príncipe de Asturias de Cooperación Internacional. También fue protagonista del documental "Una verdad incómoda" (2006), que ganó el Óscar al mejor documental en 2007 y escribió el libro "", que ganó un en 2009.

El presidente Barack Obama alabó a Gore por fomentar la causa de la paz.







</doc>
<doc id="41728" url="https://es.wikipedia.org/wiki?curid=41728" title="Hueso escafoides (carpo)">
Hueso escafoides (carpo)

El hueso escafoides es un hueso de la muñeca, par, corto, esponjoso, de forma cuboidea, con seis caras de las cuales tres son articulares. Su nombre procede del griego "σκαφοειδής", unión de los vocablos "σκάφη" ("skaphé", 'barca') y "εἶδος" ("éidos", 'forma').

Es el primer hueso externo de la primera fila del carpo. Se articula con el radio, hueso semilunar, hueso grande, hueso trapezoide y hueso trapecio.

Cabe mencionar por tanto todos los huesos formadores de la muñeca:

En conjunto forman el macizo del carpo, el cual tiene forma cuadrangular, por lo que se observa en él 2 caras y 4 bordes; la cara anterior es una especie de canal por donde pasan los músculos flexores y la arteria radial.

Es alargado de arriba abajo, y de adentro afuera, hallándose excavado por su cara interna para adaptarse al semilunar y al hueso grande, su cara superior es convexa y se articula con la faceta triangular del radio, la cara inferior, también es convexa presenta dos facetas articulares para el trapecio y el trapezoide, lo anterior lleva una prolongación externa o tubérculo del escafoides, donde se inserta el ligamento lateral externo de la articulación de la muñeca, la cara posterior es rugosa y más pequeña que las otras. La cara interna tiene dos superficies articulares, la superior, plana y más pequeña, se articula con el semilunar, en tanto que la inferior es cóncava y se articula con la cabeza del hueso grande, la cara externa posee una escotadura, limitada en parte por el tubérculo del escafoides y que deja paso a la arteria radial

Es el hueso del carpo que se fractura con más frecuencia.

La fractura de escafoides es típica de las recepciones con las manos de fuertes tiros de balón en el fútbol. Pero sobre todo se producen con las caídas apoyando la mano sobre el suelo. Su diagnóstico es difícil de realizar, porque las lesiones pueden no ser visibles en las radiografías que se efectúan rutinariamente y de inmediato tras la caída. Hay que realizar unas radiografías con proyecciones especiales que permitirán observar o descubrir la parte del hueso afectada, así como visualizar más precisamente el trazo de fractura. Si las imágenes radiológicas no son del todo suficientes o son muy sospechosas de fractura, puede realizarse o prescribirse un escáner para ponerlas de relieve.

En caso de duda, es preferible colocar una inmovilización (yeso completo o férula de escayola) para inmovilizar la zona durante aproximadamente unos 10 a 12 días. Pasado este tiempo, se puede realizar un nuevo control radiográfico, momento en el que en muchas ocasiones se pone de manifiesto la fractura, tras la reabsorción ósea que se produce en el foco durante los primeros días. El inconveniente de este método es el retraso en caso de no existir ninguna fractura y tratarse sólo de una simple lesión articular o ligamentaria o de un esguince. Por ello, la inmovilización prolongada no está recomendada en ausencia de patología que lo justifique, y en ese caso es conveniente la rehabilitación rápida por un fisioterapeuta.

La utilización de técnicas de imagen médica moderna (escáner o resonancia magnética) permite salir de dudas más rápidamente. Aun así su uso en primera instancia, no forma parte todavía de los protocolos actuales. Deberían incluirse, pues aunque costosas, permiten evitar inmovilizaciones inútiles y disminuir los costes para la sociedad (más notablemente los días de baja laboral).

En caso de una fractura, cuatro métodos son aplicables:


Las técnicas aplicables dependen del tipo de fractura y de su localización sobre el hueso. Para las fracturas sin desplazar, principalmente aquellas que afectan el cuerpo del escafoides la técnica percutánea tiende a implantarse. Esa intervención se realiza mediante anestesia local, sin hospitalización y dura aproximadamente unos 20 a 30 minutos.

Sus resultados son excelentes, y la duración de la inmovilización consecutiva se reduce a unas dos semanas (contra las 8 a 12 sin intervención).

Muchos servicios hospitalarios trabajan actualmente sobre la mejora de la técnica percutánea, con la utilización de CAO (Cirugía Asistida por Ordenador), permitiendo mejorar la precisión de la intervención.

El escafoides es un hueso de forma cuboidal que se caracteriza porque su irrigación llega por su parte más estrecha. De esa forma, es muy frecuente que en una fractura de ese hueso se rompan los vasos sanguíneos. Es por ese motivo, que en muchas ocasiones su recuperación requiere de una operación quirúrgica y rehabilitación. Cabe decir que su fractura no implica siempre la fractura de los vasos sanguíneos, éste puede fracturarse ligeramente por su parte superior sin implicar más problemática que la unión del mismo.

Las fracturas de escafoides no diagnosticadas y no tratadas a tiempo, entrañan sistemáticamente complicaciones, necesitando tratamientos muy largos y complicados. 
Por ello, no hay que dejar de realizar los exámenes necesarios para salir de toda duda en caso de fractura, así como explicar al paciente todas las opciones de tratamiento posibles así como sus ventajas y los riesgos eventuales.


</doc>
<doc id="41736" url="https://es.wikipedia.org/wiki?curid=41736" title="Ramen">
Ramen

El (pronunciado aproximadamente r`a:mEn, o <nowiki>['ɽaːmɛɴ]</nowiki>) es un plato japonés. Si bien cada región de Japón tiene su propia receta de ramen, la preparación básica consiste en distintos tipos de fideos japoneses servidos en un caldo preparado comúnmente a base de carne, miso y salsa de soja así como diferentes guarniciones como rebanadas de carne de cerdo (char siu - チャーシュ), algas (nori - 海苔), menma (メンマ) y cebolleta (negi - 葱).

La etimología de la palabra ramen es un tema de debate. Una hipótesis es que ramen es la pronunciación japonesa de la china 拉麵 (la mian), que significa "estirar fideos." Una segunda hipótesis propone 老麺 (laomian, "fideos viejos") como la forma original, mientras que otro afirma que fue inicialmente 卤麺 (lǔmiàn), fideos cocinados en una salsa espesa con almidón. Una cuarta hipótesis es 捞面 (lāomiàn, "lo mein"): 捞 significa "desenterrar" y se refiere al método de cocinar estos fideos, sumergiéndolos en agua hirviendo antes de dragado para arriba con una cesta de alambre.

Hasta la década de 1950, en Japón el ramen se llamaba "soba shina" (支那 そば, literalmente "soba chino"), pero hoy "chūka soba" (中華 そば, que también significa "soba chino") o simplemente "ramen" es un nombre más común. 

En 1900, los restaurantes que servían comida china —de Cantón y Shanghái— ofrecieron un plato de fideos de ramen simple (cortados en vez de separados manualmente), con pocos ingredientes, y un caldo con un sabor de sal y huesos de cerdo.

Muchos chinos tenían puestos ambulantes y vendían ramen y dumplings a los trabajadores. Sin embargo, algunos puestos aún usan un tipo de cuerno musical llamado cuerno de un "charumera" (チャルメラ, desde el "charamela" portugués) para anunciar su presencia.

Sin embargo, es tras la II Guerra Mundial cuando el ramen comienza su andadura en Japón. En los años 50's del siglo XX se comienza a elaborar en la ciudad de Hokkaidō el "Sapporo ramen". Este plato se hizo muy popular y rápidamente la palabra ramen pasó al uso común.

El 25 de agosto de 1958, Momofuku Andō, fundador y presidente de Nissin Foods, lanzó al mercado japonés el "chicken ramen", la primera sopa instantánea de fideos.

Pero es en los años 80 cuando este plato pasa de ser considerado una mera guarnición a convertirse en una comida normal tanto para gente joven como mayor. Finalmente, a principios de los años 90 el ramen experimenta un "boom" en todo el país, especialmente en las enormes ciudades, que pondrían su nombre como marca local: Hakata (Fukuoka), Kagoshima, Kumamoto, Onomichi, Wakayama, Kitakata, Sapporo, Hakodate, etc. El ramen fue considerado algo más que un capricho gastronómico pasajero y se convirtió en un auténtico fenómeno social e incluso mediático: algunos medios de comunicación llegaron a crear programas dedicados exclusivamente a este plato.

Hoy en día, el ramen se ha integrado con tal fuerza en la gastronomía japonesa que en Taiwán se considera un producto netamente japonés y básico en la dieta de dicho país. Suele consumirse en establecimientos de comida rápida, en puestos ambulantes o en casa, siendo uno de los alimentos más baratos que se pueden conseguir.

Antes de que el término "ramen" se popularizara en Japón, los japoneses se referían a este plato como "Shina-soba" o "Chuka-soba", literalmente, "sopa de fideos chinos". La palabra "ramen" nace, probablemente, de la forma artesanal en que se elaboran estos fideos; es decir, de la unión de los caracteres chinos "ra" (estirar) y "men" (fideo).

Los ingredientes más importantes del ramen son los "men" (麺) o fideos, la sopa, y el "gu" o acompañamiento que se añade al plato.

El fideo se elabora con harina de trigo, agua, sal y kansui. En ocasiones, se utiliza huevo en lugar de kansui para darle a la pasta su característico color amarillo. También, se utiliza la sémola, en lugar de harina de maíz, para elaborar los fideos.

Aun cuando muchos consideran que lo más importante del ramen es el tipo de fideo, la manera más fácil de diferenciar las variantes es por la sopa en la que se sirve la pasta. Las más características son:





De éstas se desprende una variedad mayor, aunque generalmente la única diferencia es lo que se utiliza como "gu".

Son muy variados los ingredientes de acompañamiento y la mayoría de las veces se deja a la elección del consumidor. Las opciones más comunes son huevos hervidos, "menma" o "shinachiku" (支那竹) (encurtido de tronco de bambú muy joven), "nori", "wakame", rebanadas de cerdo, "chashū" (叉焼 o 焼豚), "negi" (cebollín), naruto, "kimuchi" y verduras hervidas.

Existe un museo dedicado exclusivamente al ramen. Se trata del Museo del ramen de Shin-Yokohama, ubicado en la ciudad de Yokohama y en el que se exponen los diversos utensilios que se han utilizado a lo largo de la historia para confeccionar estos fideos. El museo también cuenta con muestras de todas las variedades de ramen que existen, así como un parque que recrea una ciudad típica de los años 50 en la que se pueden visitar recreaciones de los distintos tipos de restaurantes de ramen que se crearon en aquella época.




</doc>
<doc id="41738" url="https://es.wikipedia.org/wiki?curid=41738" title="Tartagal">
Tartagal

Tartagal es una ciudad del norte de Argentina, en la provincia de Salta. Está situada en el noreste de la provincia, en el Departamento General José de San Martín, del cual es cabecera. Por su economía, es la tercera ciudad en importancia de la provincia, después de Orán. Se destaca como un centro de extracción petrolera y gasífera, además de contar con una fuerte extracción en el sector maderero.
En esta región también se encuentra la selva de las Yungas la cual tiene gran variedad de flora y fauna. La más importante destacar es que aquí todavía no está extinto el guacamayo verde en vida silvestre.

Se encuentra ubicada a 365 km de la capital provincial, Salta, 57 km de la frontera con Bolivia (por lo que se la considera una ciudad fronteriza), 103 de la frontera con Paraguay, y 1736 de Buenos Aires. Tartagal está conectada con el resto de la provincia y del país por medio de la Ruta Nacional 34 ya que no cuenta con aeropuerto.

Aloja una sede regional de la Universidad Nacional de Salta y de la Universidad Católica de Salta.

La localidad adopta el nombre de Tartagal debido a la gran cantidad de plantas de tártago que se encuentran en la zona con cuyas semillas se produce el aceite de ricino.

El lugar en donde se encuentra la ciudad era llamado por los nativos de la zona "Ñancahuasu" (río de las Corzuelas). A fines del siglo XIX, el Ejército Argentino lanza la Conquista del Chaco, con la cual el Estado Nacional domina a los pobladores originarios y extiende su autoridad en la zona, la que pasa a formar parte de la provincia de Salta.

Luego se extienden los ferrocarriles llevando cientos de trabajadores al entonces pueblo, que terminarían fijando allí residencia y comenzando un paulatino desarrollo urbano; al crearse la Estación del F.F.C.C. General Belgrano, se la bautizó con el nombre de Manuela Pedraza. Pero el lugar rápidamente adopta el nombre de Tartagal, por la gran cantidad de plantas de tártago, con cuyas semillas se produce el aceite de ricino.

A principios del siglo XX se descubrieron importantes yacimientos de petróleo; la cuenca representa el 25% de la producción total del país y cerca del 16% de la producción total de gas.

Simultáneamente a la llegada de vías y durmientes, la ciudad recibió una fuerte corriente migratoria desde el vecino país del norte, debido a la instalación en la zona de las oficinas de la Standard Oil Company, luego conocida por el nombre de ESSO, empresa seducida por el descubrimiento de las cuencas petrolíferas y de la extracción de los hidrocarburos.

La empresa nacional Yacimientos Petrolíferos Fiscales (YPF), fundada por el presidente Hipólito Yrigoyen en la década de 1920 y fuertemente valorizada durante los gobiernos de Juan Domingo Perón entre los años 40 y 50, fue desplazando a la Standard Oil, tanto en términos de producción como en términos de impacto social, ya que aseguraba trabajo, seguridad en el aspecto previsional, educación para los hijos de los trabajadores y decenas de beneficios que dignificaron la vida de los obreros, sin contar el flujo comercial que impactó positivamente en la zona.

En 1992, el presidente Carlos Menem decidió privatizar la exploración, extracción y exportación de petróleo y gas, que de esta forma pasaron principalmente a manos de la española Repsol. La privatización fue un duro golpe para la ciudad. El 90% de los antiguos trabajadores de la YPF estatal fueron despedidos, y miles de personas emigraron de la ciudad. En 1999 y en 2002-2003 la ciudad fue escenario de graves y violentos conflictos sociales como resultado del desempleo.

A principios de 2006 una crecida del río Tartagal provocó importantes destrozos, y el 9 de febrero de 2009 la situación se repitió causando al menos 2 muertos, 6 desaparecidos y graves daños en la infraestructura de la ciudad. Esta segunda catástrofe provocó la visita de la presidenta Cristina Fernández de Kirchner, que destinó una importante suma en dinero para la restauración de obras públicas y para ayudar a los damnificados.

El clima de Tartagal es del tipo clima subtropical húmedo con invierno seco ("Cwa") , de acuerdo con la clasificación climática de Köppen. 
La composición social de Tartagal se caracteriza por su diversidad cultural. En este municipio habitan Ocho etnias aborígenes: wichís (o weenhayek), chiriguanos, chanés, quechuas, chorotes, chulupíes y aymaras y Tobas Otro elemento importante de su conformación social es el componente migratorio que se suma a su población; por su cercanía a Bolivia, un alto porcentaje de sus habitantes son de origen boliviano.
Tartagal fue el principal destino de la inmigración de la población campesino-ganadera del oriente (comúnmente conocidos como "chaqueños") Que se afincaron, al igual que los aborígenes, en barrios periféricos de la ciudad.
También cuenta con importantes comunidades extranjeras: sirio-libanesas, paraguayas, españolas, entre las principales.
Tartagal tiene una población heterogénea y muchos matices culturales.

El último censo del año 2010, determinó que la ciudad de Tartagal cuenta con una población de aproximadamente 64.530 habitantes, siendo de este modo la tercera ciudad más poblada de la provincia, solo superada por la Capital provincial y por la ciudad de San Ramón de la Nueva Orán.


La sismicidad del área de Salta es frecuente y de intensidad baja, y un silencio sísmico de terremotos medios a graves cada 40 años.



</doc>
<doc id="41739" url="https://es.wikipedia.org/wiki?curid=41739" title="Siringomielia">
Siringomielia

La siringomielia es un trastorno en el cual se forma un quiste dentro de la médula espinal. Este quiste se conoce como siringe o "syrinx". Con el tiempo, el syrinx se expande y alarga, destruyendo el centro de la médula espinal. Puesto que la médula espinal conecta el cerebro con los nervios de las extremidades, este daño causa dolores, debilidad y rigidez en la espalda, los hombros, los brazos o las piernas. Otros síntomas pueden incluir dolores de cabeza (cefalea) y pérdida de la capacidad de sentir calor o frío extremos, especialmente en las manos. Cada paciente tiene una combinación distinta de síntomas.

Cerca de 21 mil personas en Estados Unidos sufren de siringomielia. Otras enfermedades comparten los síntomas iniciales de la siringomielia. En el pasado, esto ha dificultado el diagnóstico. Sin embargo, con la resonancia magnética nuclear ha aumentado notablemente el número de casos de siringomielia diagnosticados en las etapas iniciales del trastorno.

La cavidad siringomiélica o quiste intramedular puede ser por una causa conocida (traumática, tumoral o infecciosa) o, más frecuentemente, desconocida o idiopática.

Una serie de lesiones pueden obstruir el flujo normal del líquido cefalorraquídeo y redirigirlo hacia la médula espinal. Esto da lugar a la formación del "syrinx" o siringe, el cual se llena de líquido cefalorraquídeo. Las diferencias de presión a lo largo de la médula espinal hacen que el líquido se mueva dentro del quiste. Se cree que este movimiento continuo del líquido da lugar al crecimiento del quiste y causa daños adicionales a la médula espinal.

Estudios recientes afirman que las alteraciones del líquido cefalorraquídeo existían, pero eran de tan escasa magnitud y no podían explicar por sí solas las importantes lesiones que aparecían. Otra de las posibles causas atribuidas, relacionadas con la porción de cráneo que alberga el cerebelo también fue descartada, ya que la literatura científica no ha encontrado hasta el momento diferencia de tamaño en el cráneo de pacientes con siringomielia frente a los catalogados como normales.

El concepto convencional de la siringomielia idiopática considera que la enfermedad es debida a la existencia de una cavidad quística llena de líquido cefalorraquídeo (LCR) procedente del conducto del epéndimo (Gardner) o del espacio perirraticular (Williams). Actualmente existe un nuevo concepto que interpreta que esta enfermedad es debida a la tracción del filum terminal y la cavidad quística intramedular está llena de líquido intersticial o plasma, procedente de la necrosis del tejido centromedular espinal causado por la isquemia, originada a su vez por la tracción de un filum terminal más tenso de lo normal. Que puede llegar hasta la fiscalización del quiste, y sólo a partir de este momento se llena de LCR.

Los síntomas comienzan generalmente al inicio de la edad adulta. Los síntomas del trastorno tienden a desarrollarse lentamente, aunque puede iniciarse repentinamente al toser o hacer fuerza. Si no se trata quirúrgicamente, la siringomielia a menudo conduce a una debilidad progresiva en los brazos y las piernas, pérdida de sensibilidad en las manos y dolores crónicos e intensos.

Un tratamiento se basa en la sección quirúrgica del filum terminale. La sección de este ligamento consiste en una pequeña apertura del hueso sacro, al final de la espalda donde no existe el problema de alterar la mecánica de la columna vertebral, aunque puede provocar dolor pélvico crónico. No es una intervención exenta de riesgos y posibles complicaciones. Una vez visualizado el filum terminale este se secciona con técnicas microquirúrgicas.

La mayoría de los síntomas se deben a la lesión irreversible del tejido nervioso, y éste no es capaz de reemplazarlo; sin embargo, parece ser que en la siringomielia idiopática la sección del filum terminale detiene la enfermedad. El quiste resultado de la necrosis celular queda igual, pero puede desaparecer cuando espontáneamente se abre el espacio que rodea la médula espinal o lo hace hacia el centro de ella donde existe un conducto, el conducto ependimario, que comunica el centro de la médula con las cavidades cerebrales.

La sección del filum terminale provoca dos efectos beneficiosos: detiene la muerte de los tejidos debido a la tracción de la médula, y disminuye el efecto masa del quiste al relajar la médula espinal.





</doc>
<doc id="41740" url="https://es.wikipedia.org/wiki?curid=41740" title="Aeróbic">
Aeróbic

Aeróbic o aerobic es un tipo de gimnasia que se realiza al son de la música, en un salón o al aire libre. El aeróbic reúne todos los beneficios del ejercicio aeróbico, además de ejercitar capacidades físicas como la flexibilidad, coordinación, orientación, ritmo, etc. El ritmo de las sesiones de aeróbic varía en función de la edad del público que lo practica. Las canciones utilizadas marcan la intensidad en cada momento de la clase. El aeróbic también debe incluir ejercicios de calentamiento y estiramientos. Existen otras modalidades de este deporte, como la practicada en la piscina (puede denominarse aeróbic acuático), la que incorpora una plataforma de baja altura (step), o la que combina ejercicios aeróbicos con tonificación muscular.

En el año 1968, el doctor Kenneth H. Cooper introdujo un tipo de ejercicio físico para entrenar el corazón y los pulmones ; puso la primera piedra sobre el concepto de aeróbic en los Estados Unidos. Su libro "Aerobics" (Aeróbicos) condujo al entrenamiento gimnástico de los ejercicios aeróbicos. Las primeras prácticas de aeróbic están relacionadas con el ámbito militar, puesto que el doctor Kenneth H. Cooper era médico de la Fuerza Aérea de los Estados Unidos de América. Hasta principios de los años noventa el aeróbic no se convirtió en la popular actividad que es hoy en día.


El ejercicio aeróbico reduce la grasa subcutánea y la localizada entre los músculos, aquella que se utiliza como combustible o fuente principal de energía.




</doc>
<doc id="41742" url="https://es.wikipedia.org/wiki?curid=41742" title="Gimnasia aeróbica">
Gimnasia aeróbica

La gimnasia aeróbica, antes conocida como aeróbic deportivo, es una disciplina de la gimnasia en la que se ejecuta una rutina de 1 minuto con movimientos de alta intensidad derivados del aeróbic tradicional además de una serie de elementos de dificultad. Esta rutina debe demostrar movimientos continuos, flexibilidad, fuerza y una perfecta ejecución en los elementos de dificultad.

La gimnasia aeróbica se empezó a difundir por diversos países, gracias, en parte, al aporte de algunas personas famosas como la actriz Jane Fonda o Sidney Rome, que tras descubrir el sentido lúdico de este tipo de ejercicio, pero también sus extraordinarios efectos para el organismo, decidieron contribuir en la tarea de darlo a conocer.

Los orígenes de la aeróbica tal y como la entendemos en la actualidad, podemos situarlos en el año 1968. En este año apareció publicado por primera vez en Estados Unidos un libro titulado "Aerobics" o Aeróbicos. Su autor el Doctor Kenneth H. Cooper, médico de las fuerzas armadas estadounidenses, expone en la obra, el programa de entrenamiento que él mismo diseñó para los miembros de las fuerzas armadas de su país. Sin embargo, algunas fuentes atribuyen el término "aerobic" a Pasteur (Francia 1875).

El programa del Dr. Kenneth consistía en llevar a cabo esfuerzos durante periodos de tiempo prolongado, con el fin de aumentar el rendimiento y la resistencia de quienes lo realizaban, disminuyendo así el porcentaje de riesgo a sufrir enfermedades cardíacas y respiratorias, tales como infarto o la arteriosclerosis. En este primer tratado sobre la aeróbica, se predican las excelencias de este ejercicio y se defiende la práctica de un ejercicio físico de baja y mediana intensidad, cuyo objetivo fundamental es el desarrollo del sistema cardiovascular.
En 1969 Jackie Sorensen propone a Kenneth H. Cooper la posibilidad de utilizar la gimnasia aeróbica como método de entrenamiento gimnástico para las esposas de los militares norteamericanos en una base de Puerto Rico, frente a la tradicional gimnasia de mantenimiento.
Tras el éxito de "Aerobics" Kenneth publicó en 1970 un segundo tratado sobre la aeróbica adaptado a personas mayores de 35 años titulado "The new aerobics", decir, la Nueva Aeróbica y un tercero adaptado especialmente para mujeres titulado "Aerobics for Women" en castellano, Aeróbicos para Mujeres.
A partir de este programa inicial, creado por el que se considera el padre de la aeróbica, apareció primero en Estados Unidos y posteriormente en otros países del mundo la moda del jogging, o el trote, que es la forma más popular de practicar un entrenamiento aeróbico de resistencia.

Con el paso de los años se pensó en la posibilidad de combinar música y elementos de disciplinas diferentes: jogging, jazz, gimnasia, baile, y crear así algo nuevo. El resultado de esta combinación es lo que se ha denominado danza aeróbica (o aerobic dance), que consiste en bailar al ritmo de la música pero de una manera aeróbica, es decir, siguiendo los principios básicos que debe cumplir todo ejercicio aeróbico.
Jackie Sorensen funda el año 1970 en New Jersey el "Aerobic Dancing Inc." primer estudio donde se ofrecen clases de aeróbicos al público en general.

A principios de los 80 el aerobic Dance llega a Europa donde desde 1969 se practicaba la Danza Jazz sobre la que más tarde Judi Sheppard fundaría una modalidad denominada Jazzercise. Así mismo Monika Becman había creado la Gimnasia Jazz con base en la gimnasia moderna y nacida por la necesidad de utilizar la música como factor educativo en sus clases de educación física.

Pero aunque a simple vista este tipo de terapias pueden parecer iguales a la aeróbica, en muchos estudios se ha tratado erróneamente de atribuirles la paternidad de este ejercicio. Aunque muchas terapias utilicen música y se basen en la realización de un ejercicio físico, sólo la aeróbica contiene un objetivo básico e indispensable que es el hecho de realizar un entrenamiento gimnástico seguro y eficaz, utilizando únicamente la energía proveniente del sistema aeróbico de producción de energía. Aunque en el Aerobic Dance se utilice la música y se baile con ella, su origen no proviene del baile, sino del entrenamiento de ejercicios aeróbicos.

Hoy día la danza aeróbica posee innumerables seguidores en todo el mundo. En 1988 la aeróbica era el tercer deporte más practicado en los Estados Unidos pasando a ocupar el segundo lugar un año después.

La palabra aeróbic literalmente significa “con oxígeno” o “en presencia de oxígeno”, el ejercicio aeróbico es una actividad que utiliza los grandes grupos musculares para mantener una intensidad deseada durante un periodo de tiempo largo, de forma rítmica.

El aeróbic deportivo debe demostrar movimientos continuos, flexibilidad, fuerza, potencia, agilidad, coordinación, ritmo, sentido musical y expresión, con utilización de los movimientos característicos de la disciplina (combinaciones coreográficas de brazos y piernas de alta intensidad y gran complejidad).


El ejercicio se puntuará según 3 funciones
Se evalúa:

Se evalúa:

Se evalúan los elementos de dificultad realizados durante la rutina. El máximo en la categoría de "seniors" es de 10 elementos. Esta categoría puede realizar mínimo 1 elemento por cada familia, y con un valor mínimo de 0.3


Cada elemento tiene un valor, desde 0.1 hasta 1 punto.
Por ej: Wenson push up tiene un valor de 0,3.

Se aplican penalizaciones en determinados casos, como por ejemplo al salirse de la pista, no durar el ejercicio el tiempo reglamentario, etc.

Dentro de las penalizaciones también se encuentran aquellas referentes a vestuario inadecuado; por ejemplo, los hombres no pueden usar mangas largas en su vestuario, el tipo de tela no puede ser del tipo desnudo, no se pueden usar transparencias, ni vestuarios con aditamentos extras como plumas, o exceso de adornos ni el pelo suelto.



</doc>
<doc id="41744" url="https://es.wikipedia.org/wiki?curid=41744" title="Mucopolisacaridosis">
Mucopolisacaridosis

Las mucopolisacaridosis (MPS por su sigla en inglés) son un grupo de enfermedades metabólicas hereditarias causadas por la ausencia o el mal funcionamiento de ciertas enzimas necesarias para el procesamiento de moléculas llamadas glicosoaminoglicanos o glucosaminglucanos, que son cadenas largas de hidratos de carbono presentes en cada una de nuestras células que ayudan a construir los huesos, cartílagos, tendones, córneas, la piel, el tejido conectivo y el tejido hematopoyético.

Las personas que padecen de mucopolisacaridosis no producen suficientes cantidades de una de las 11 enzimas requeridas para transformar estas cadenas de azúcar y proteínas en moléculas más sencillas, o producen enzimas que no funcionan correctamente. Al pasar el tiempo, estos glicosaminoglicanos se acumulan en las células, la sangre y el tejido conectivo. Esto produce daños celulares permanentes y progresivos que afectan el aspecto y las capacidades físicas, los órganos y el funcionamiento del organismo del individuo y, en la mayoría de los casos, el desarrollo mental.

La acumulación de mucopolisacáridos o glicosaminoglicanos (dermatán sulfato, heparán sulfato, queratán sulfato y condroitín sulfato) se produce en los lisosomas de las células de diferentes órganos como el hígado, bazo, vasos sanguíneos.

Existen varios tipos de mucopolisacaridosis; entre los más representativos están:




</doc>
<doc id="41745" url="https://es.wikipedia.org/wiki?curid=41745" title="Anencefalia">
Anencefalia

La anencefalia es un defecto en la fusión de varios sitios de cierre del tubo neural (el 2 para el merocráneo y el 2 y 4 para el holocráneo) en el proceso de neurulación durante la embriogénesis. Ocurre cuando el extremo encefálico o cabeza del tubo neural no logra cerrarse, generalmente entre el 23º y el 26º día del embarazo, dando como resultado una malformación cerebral congénita caracterizada por la ausencia parcial o total del cerebro, cráneo y cuero cabelludo.
Aunque los hemisferios cerebrales pueden desarrollarse bajo esta condición, cualquier tejido cerebral expuesto es posteriormente destruido. Esto produce una masa fibrótica y hemorrágica de neuronas y célula glial al igual que una corteza cerebral no funcional. Adicionalmente el tronco del encéfalo y el cerebelo son escatimados. Debido a estas anormalidades tan severas, la base del cráneo y los huesos faciales no muestran un desarrollo promedio ni casi promedio. El hueso frontal casi siempre está ausente y el tejido cerebral es anormal. 

La anencefalia se divide en dos subcategorías: la más suave conocida como meroacrania, la cual describe un defecto pequeño en la cámara craneal cubierta por el área cerebrovascular y la más severa conocida como holoacrania donde el cerebro está completamente ausente.

En los niños que nacen con anencefalia la caja craneal no se ha cerrado, no existe la bóveda craneal y faltan en mayor o menor medida distintas estructuras y partes relevantes de los huesos craneales, de las meninges, de cuero cabelludo, de la corteza cerebral y del encéfalo. En estas condiciones, los recién nacidos son inconscientes, además de ciegos, sordos, e insensibles al dolor. La actividad suele reducirse a la respiratoria y a la presencia de algunos reflejos elementales. El tronco del encéfalo está desarrollado solo en un 25% de los casos y de manera muy rudimentaria. Presentan además un pobre desarrollo de la hipófisis. La expectativa de vida al nacer es solo de unos pocos días u horas tras el nacimiento. En raros casos, algunos individuos pueden sobrevivir varios años. 

Esta condición es uno de los trastornos menos comunes del sistema nervioso central fetal. Su frecuencia varía entre 1 y 2 por cada 1000 nacimientos. El trastorno afecta a las mujeres más a menudo que a los hombres en una proporción de 3-4:1. Se observa algo parecido entre grupos étnicos donde hay mayor prevalencia en poblaciones caucásicas comparado con otras poblaciones.

Se desconocen las causas de la anencefalia. Aunque se cree que la dieta de la madre y la ingestión de vitaminas pueden desempeñar un papel importante, los científicos afirman que existen muchos otros factores relacionados. Investigaciones recientes incluyen dentro de las posibles causas ingestión de drogas antiepilepsia durante el embarazo, agresión mecánica, contacto con pesticidas, factores ambientales, radiación, deficiencia en factores de transcripción involucrados en el cierre del tubo neural asociada a niveles bajos de ácido fólico (Vitamina B9 hidrosoluble) y anomalías cromosomales del tipo aneuploidía o trisomía. 

La anencefalia ha sido bastante controversial ya que se cree que su patología puede ser provocada por otras rutas ajenas al cierre del tubo neural. Existe una hipótesis alternativa donde la enfermedad se debe a una anormalidad mesénquimal primaria donde el cerebro se pierde secundariamente debido a daños causados por su posición expuesta dentro del útero. 

No existe cura o tratamiento estándar para la anencefalia y el pronóstico para los individuos afectados es pobre. La mayoría de los pacientes no sobreviven la infancia. Si el niño no nace muerto, por lo general fallece algunas horas o días después del nacimiento. La anencefalia se puede diagnosticar a menudo durante el embarazo mediante la medición del nivel de alfa feto proteína o AFP (el cual es abruptamente elevado) en el fluido amniótico mediante amniocentesis o a través de una prueba de ultrasonido entre la 10ª y la 14ª semana de embarazo.











</doc>
<doc id="41746" url="https://es.wikipedia.org/wiki?curid=41746" title="Colpocefalia">
Colpocefalia

La colpocefalia es un trastorno en el cual se evidencia un crecimiento anormal de las astas occipitales - la porción posterior de los ventrículos laterales (las cavidades o compartimientos) del cerebro-. Este crecimiento anormal sucede cuando ocurre un subdesarrollo o una falta de espesamiento en la materia blanca del cerebro posterior. La microcefalia (cabeza anormalmente pequeña) y el retraso mental son característicos de una colpocefalia. Otras condiciones incluyen anormalidades motrices, espasmos musculares y convulsiones.

Aunque la causa es desconocida, los investigadores creen que el trastorno resulta de un problema intrauterino que ocurre entre el segundo y sexto mes de embarazo. La colpocefalia se puede diagnosticar en una fase avanzada del embarazo, aunque a menudo se diagnostica erróneamente como hidrocefalia (una acumulación excesiva del líquido cerebroespinal en el cerebro). Puede ser diagnosticada más exactamente después del nacimiento cuando se evidencian muestras de retraso mental, microcefalia y convulsiones.

No hay tratamiento definitivo para la colpocefalia. Medicamentos anticonvulsivos se pueden administrar para prevenir convulsiones y los médicos suelen prevenir contracturas (la contracción o acortamiento de músculos). El pronóstico para los individuos con colpocefalia depende de la gravedad de las condiciones asociadas y del grado de desarrollo anormal del cerebro. La educación especial puede beneficiar a algunos niños.

Véase también: Trastornos encefálicos



</doc>
<doc id="41747" url="https://es.wikipedia.org/wiki?curid=41747" title="Holoprosencefalia">
Holoprosencefalia

La holoprosencefalia constituye un amplio espectro de malformaciones del cráneo y la cara debidas a una anormalidad compleja del desarrollo del cerebro que tienen en común la ausencia del desarrollo del prosencéfalo, que es el lóbulo frontal del cerebro del embrión. Durante el desarrollo normal se forma el lóbulo frontal y la cara comienza a desarrollarse en la quinta y sexta semana del embarazo. La holoprosencefalia es causada por la falta de división del lóbulo frontal del cerebro del embrión para formar los hemisferios cerebrales bilaterales (las mitades izquierda y derecha del cerebro), causando defectos en el desarrollo de la cara y en la estructura y el funcionamiento del cerebro.

Aunque las causas de la mayoría de los casos de holoprosencefalia son de origen teratogénico, los investigadores saben que aproximadamente la mitad de todos los casos se deben a causas cromosómicas. Las anomalías cromosómicas, tales como el síndrome de Patau (trisomía 13), el síndrome de Edwards (trisomía 18), el síndrome de Meckel-Gruber y ciertas triploidías se han podido asociar con la holoprosencefalia. Los hijos de madres diabéticas y la ingesta elevada de alcohol en esta parte del desarrollo embrionario (ya que destruye las células de la línea media de estructuras craneofaciales) tienen un riesgo mayor de padecer el trastorno.

Existen tres clases de holoprosencefalia, basados en la separación del prosencéfalo: 




La holoprosencefalia, denominada anteriormente como anencefalia, consiste en una gama de defectos o malformaciones del cerebro y de la cara. En el extremo más grave de este espectro se encuentran los casos que involucran malformaciones serias del cerebro, malformaciones tan graves que son incompatibles con la vida y a menudo causan la muerte intrauterina espontánea. En el otro extremo del espectro están los individuos con los defectos faciales-que pueden afectar los ojos, la nariz y el labio superior-y el desarrollo normal o casi normal del cerebro. Pueden ocurrir convulsiones o discapacidad intelectual.

El más grave de los defectos (o anomalías) faciales es la ciclopía, caracterizado por el desarrollo de un solo ojo, que se ubica generalmente en el área ocupada normalmente por la raíz de la nariz, y la ausencia de la nariz o una nariz en la forma de una probóscide (un apéndice tubular) situada por encima del ojo.

La etmocefalia es la anomalía facial menos común. Consiste en una probóscide que separa ojos muy juntos, ausencia de la nariz y microftalmía (tamaño anormalmente pequeño de uno o ambos ojos).

La cebocefalia es otra anomalía facial caracterizada por una nariz pequeña y aplastada con un solo orificio nasal situada debajo de unos ojos subdesarrollados y muy juntos.

La anomalía facial menos grave es el labio leporino, también llamado agenesia premaxilar.

No existe tratamiento para la holoprosencefalia y el pronóstico para los individuos que la padecen es pobre. La mayoría de los que sobreviven no muestran signos de desarrollo significativos. Para los niños que sobreviven, el tratamiento es sintomático (es decir, alivia sólo los síntomas y no las causas del trastorno). Es posible que una mejora en el monitoreo de embarazos de madres diabéticas pueda ayudar a prevenir la holoprosencefalia. No obstante, no existen medios de prevención primaria.




</doc>
<doc id="41748" url="https://es.wikipedia.org/wiki?curid=41748" title="Hidranencefalia">
Hidranencefalia

La hidranencefalia es una condición poco común en la cual los hemisferios cerebrales están ausentes y son sustituidos por sacos llenos de líquido cerebroespinal. 

Por lo general, el cerebelo y el tallo cerebral se forman normalmente. Un bebé con hidranencefalia puede parecer normal al nacer. El tamaño de la cabeza y los reflejos espontáneos del niño tales como aspirar, tragar, llorar y el movimiento de los brazos y las piernas pueden parecer todos normales. Sin embargo, unas semanas después el niño comienza a sentirse irritable y muestra un aumento en la tonicidad o firmeza del músculo (hipertonía).

Después de varios meses de vida pueden comenzar las convulsiones y la hidrocefalia (acumulación excesiva de líquido en el cerebro). Otros síntomas pueden incluir problemas visuales, ausencia de crecimiento, sordera, ceguera, cuadriparesis espástica (parálisis) y retraso mental.

La hidranencefalia es una forma extrema de porencefalia (caracterizado por un quiste o cavidad en los hemisferios cerebrales) y puede ser causado por problemas o lesiones vasculares, infecciones o trastornos traumáticos después de la 12ª semana de embarazo.

El diagnóstico se puede retrasar varios meses debido a que el comportamiento inicial del bebé puede parecer relativamente normal. La transiluminación es una prueba en la cual se pasa luz a través de los tejidos del cuerpo y generalmente sirve para confirmar el diagnóstico. Algunos niños pueden tener anomalías adicionales en el nacimiento incluyendo convulsiones, mioclonias (movimientos involuntarios rápidos y repentinos) y problemas respiratorios.

No existe tratamiento estándar para la hidranencefalia. El tratamiento es sintomático y de apoyo. La hidrocefalia se puede tratar con una derivación (shunt). La expectativa de vida para los niños con hidranencefalia es baja. La muerte ocurre generalmente antes del primer año de edad. Sin embargo, en raros casos, algunos niños con hidranencefalia pueden sobrevivir durante varios años.




</doc>
<doc id="41749" url="https://es.wikipedia.org/wiki?curid=41749" title="Megaloencefalia">
Megaloencefalia

La megaloencefalia, es un trastorno en el que existe un cerebro anormalmente grande, pesado y con mal funcionamiento. No debe confundirse con la macrocefalia, que es un crecimiento anormal de la cabeza, pero no necesariamente del cerebro. Por definición, el peso del cerebro es mayor que el promedio correspondiente a la edad y el sexo del bebé o del niño. El crecimiento de la cabeza puede hacerse evidente en el nacimiento o la cabeza puede llegar a ser anormalmente grande en los primeros años de vida. El crecimiento de la cabeza puede hacerse evidente en el nacimiento o la cabeza puede llegar a ser anormalmente grande en los primeros años de vida. El caso más importante de esta enfermedad es Joaquín Gimenez con una cabeza más grande que su cuerpo. El diámetro de esta es de 50cm y aumenta cada año.

Se cree que la megaloencefalia está relacionada con un problema en la regulación de la reproducción o proliferación de las células. En un desarrollo normal, la proliferación de las neuronas - el proceso en el cual las células nerviosas se dividen para formar nuevas generaciones de células - se regula para generar el número correcto de células en el lugar apropiado y en el tiempo justo.

Los síntomas de megaloencefalia pueden incluir retrasos en el desarrollo , trastornos convulsivos, disfunciones córticoespinales (de la corteza del cerebro y la médula espinal) y convulsiones. La megaloencefalia afecta a los varones más a menudo que a las niñas.

El pronóstico para los individuos con megaloencefalia depende en gran parte de las causas subyacentes y de trastornos neurológicos relacionados. El tratamiento es sintomático. La megaloencefalia puede conducir a una enfermedad llamada macrocefalia.

La megaloencefalia unilateral o hemimegaloencefalia es una malformación poco común caracterizada por el crecimiento anormal de un hemisferio del cerebro. Los niños con este trastorno pueden tener una cabeza grande, a veces asimétrica. Sufren a menudo de convulsiones intratables y de retraso mental. El pronóstico para los pacientes con hemimegaloencefalia es grave.




</doc>
<doc id="41750" url="https://es.wikipedia.org/wiki?curid=41750" title="Microcefalia">
Microcefalia

La microcefalia es un trastorno neurológico en el que la circunferencia de la cabeza es más pequeña que la circunferencia promedio para la edad y el sexo del niño. Se define como una circunferencia de cabeza más de dos desviaciones típicas menos de lo normal según el sexo y la edad. Algunos académicos la definen como tres desviaciones en la circunferencia de la cabeza. La microcefalia puede ser congénita o puede producirse en los primeros años de vida. El trastorno puede provenir de una amplia variedad de condiciones que provocan un crecimiento alterado del cerebro o de síndromes relacionados con alteraciones cromosómicas. Se sospecha que la fiebre del Zika causa microcefalia.

Los niños con microcefalia nacen con una cabeza de tamaño reducido. Posteriormente, la cabeza deja de crecer mientras que la cara continúa desarrollándose normalmente, lo que produce que el niño tenga la cabeza pequeña, la cara grande, la frente en retroceso y el cuero cabelludo blando y a menudo arrugado. A medida que el niño crece, la pequeñez del cráneo se vuelve más obvia, aunque todo el cuerpo generalmente también presenta peso insuficiente y enanismo. El desarrollo de las funciones motrices y del habla puede verse afectado. La hiperactividad y el retraso mental son comunes, aunque el grado de cada uno varía. También pueden producirse convulsiones. La capacidad motora puede verse afectada; las afecciones varían de torpeza en algunos casos a cuadriplejia espástica (parálisis).

A excepción de la cirugía para la craneosinostosis, por lo general no hay ningún tratamiento para agrandar la cabeza del paciente o revertir las complicaciones de la microcefalia. El tratamiento se centra en las técnicas para gestionar la condición del paciente. Los programas de intervención en la infancia, que incluyen terapia del lenguaje, terapia física y ocupacional pueden ayudar al niño a fortalecer sus capacidades.

Ciertas complicaciones de la microcefalia, tales como convulsiones o hiperactividad, pueden ser tratadas con medicamentos.

En general, la esperanza de vida para los individuos con microcefalia se reduce y el pronóstico para la función normal del cerebro es pobre. Aproximadamente solo el 15% de los pacientes con microcefalia desarrollan una inteligencia normal. Los pronósticos de vida para los pacientes que sufren microcefalia, suelen variar y depender de la presencia y evolución de otras enfermedades existentes hoy en día. El cuidado que los familiares y el equipo medico y psicológico procuren, afectarán al pronóstico de vida.

Desde noviembre de 2015, el Ministerio de Salud en Brasil ha emitido informes de alerta respecto a una posible conexión entre la enfermedad y un notable incremento de casos de nacimientos con microcefalia en el noreste de Brasil. Esto se debe al aumento de casos de microcefalia coincidente con la aparición del virus zika: En 2015 hubo 4120 casos de microcefalia entre recién nacidos en Brasil, vinculados con la contracción del virus zika por la madre, según el Ministerio de Salud de este país. Anteriormente, la media era de apenas 160 casos al año.
Incluso países como Colombia, Ecuador, El Salvador y Jamaica han aconsejado a las mujeres que eviten quedar embarazadas hasta el término de la epidemia (octubre de 2016 - 2018). Si bien la OMS afirma que aún no hay pruebas científicas de un vínculo entre el virus y la microcefalia., el 3 de marzo de 2016 científicos de Brasil confirmaron mediante pruebas con células humanas que el virus Zika ataca el sistema nervioso durante la gestación. El 25 de julio de 2016 nació en Barcelona el primer bebé de España con microcefalia a causa del virus del Zika.

El volumen intracraneal, como es de esperar por su relación con el tamaño del cerebro, afecta también a esta patología.




</doc>
<doc id="41751" url="https://es.wikipedia.org/wiki?curid=41751" title="Macrocefalia (medicina)">
Macrocefalia (medicina)

La macrocefalia es una alteración en la cual la circunferencia de la cabeza es más grande que el promedio correspondiente a la edad y el sexo del bebé o del niño.

Es un término descriptivo más que de diagnóstico y es una característica de una variedad de trastornos. 

La macrocefalia también puede ser hereditaria. Aunque una forma de macrocefalia se puede relacionar con la discapacidad intelectual, en aproximadamente la mitad de los casos el desarrollo mental es normal. La macrocefalia puede ser causada por un cerebro agrandado o hidrocefalia. Puede ser asociada a otros trastornos tales como el enanismo, autismo, la neurofibromatosis y la esclerosis tuberosa.

En cuanto a la frecuencia de esta patología, no existen datos estadísticos específicos acerca de su prevalencia en la población general. 
A pesar de esto, es una condición médica que puede presentarse en aproximadamente un 5% de las personas, afectado de forma mayoritaria al sexo masculino.

La característica clínica más definitoria de la macrocefalia es la presencia de un tamaño incrementado de la cabeza. Concretamente, puede observarse un perímetro craneal superior a lo esperado para el sexo y grupo de edad de la persona afectada. 

En este sentido, este tipo de anomalía estructural va a provocar otra serie de signos y síntomas significativos, como las crisis convulsivas, el retraso generalizado del desarrollo, la presencia de déficits cognitivos, alteración de la marcha, cefaleas recurrentes, náuseas y vómitos, somnolencia, hipertensión intracraneal, etc.

Las causas etiológicas de la macrocefalia pueden ser diversas, algunas de ellas están relacionadas con las patologías cerebrales y alteración del líquido cefalorraquídeo (LCR), mientras que otras están relacionadas con anomalías óseas. 

La macrocefalia es una condición médica, que gracias a rasgos estructurales característicos, puede ser detectada durante la gestación, a través de las ecografías rutinarias.

Sin embargo, no siempre es observable en estas fases, por lo que la presencia de rasgos susceptibles de diagnóstico deben ser examinados a través de la exploración física craneal, análisis neurológico y pediátrico o empleando diversas pruebas complementarias (Resonancia magnética, rayos X, punción lumbar, etc).

A pesar de que no existe un tratamiento curativo para la macrocefalia, se han descrito diversas intervenciones terapéuticas para el control sintomatológico.

Por lo tanto, en función de la causa etiológica se podan emplear diversos abordajes farmacológicos, fundamentalmente para el tratamiento de las complicaciones médicas y además, abordajes no farmacológicos (rehabilitación neuropsicológica, estimulación temprana, educación especial, etc), para el abordaje de las posibles secuelas neurológicas y cognitivas.

El pronóstico médico de las personas que padecen macrocefalia depende fundamentalmente de la causa de esta patología y de la gravedad del cuadro clínico asociado. 

En algunos casos, es posible detectar un curso clínico benigno, con signos y síntomas muy sutiles, por lo tanto, podrán desarrollarse de forma eficiente en todas las áreas, tanto física como cognitiva.

Sin embargo, en otros muchos casos, las complicaciones médicas generan importantes patologías médicas, por lo que será necesario una intervención terapéutica individualizada para asegurar la integridad física de la persona afectada y por otro lado, permitir que alcance un nivel funcional eficiente e independiente.

El volumen intracraneal, como es de esperar por su relación con el tamaño del cerebro, afecta también a esta patología.




</doc>
<doc id="41752" url="https://es.wikipedia.org/wiki?curid=41752" title="Esperando al Mesías">
Esperando al Mesías

Esperando al Mesías es una película argentina del año dirigida por Daniel Burman y protagonizada por Daniel Hendler, Enrique Piñeyro, Héctor Alterio, Melina Petriella, Stefania Sandrelli, Imanol Arias y Dolores Fonzi entre otros. La película fue coproducida entre Argentina, España e Italia.

El joven Ariel, un chico judío que vive junto a su padre y manejan una cafetería, es incapaz de vivir librementre porque cuestiona constantemente su identidad. Casualmente conoce a Santamaría, un desocupado, ex bancario, vagabundo que vive de buscar documentos en la basura que devuelve a sus propietarios a pagamento de pequeñas sumas de dinero. Ambos asistirán al derrumbe de proyectos personales, familias, perspectivas. A través de sus ojos tendremos otra visión de las cosas que nos rodean, otra perspectiva de nuestras vida acosada diariamente por crisis existenciales.




</doc>
<doc id="41753" url="https://es.wikipedia.org/wiki?curid=41753" title="Neurofibromatosis">
Neurofibromatosis

La neurofibromatosis es un trastorno genético del sistema nervioso que afecta principalmente al desarrollo y crecimiento de los tejidos de las células neurales (nerviosas). 
Fue descubierta por Friedrich Daniel von Recklinghausen 

Este trastorno ocasiona tumores que crecen en los nervios y produce otras anormalidades tales como cambios en la piel y deformidades en los huesos. Las neurofibromatosis ocurren en ambos sexos. Se transmiten a la descendencia de forma autosómica dominante. Los científicos han clasificado los trastornos como neurofibromatosis tipo 1 (NF1) y neurofibromatosis tipo 2 (NF2), cada una con una alteración en un cromosoma diferente (17 y 22, respectivamente). Existen otros tipos o variantes de neurofibromatosis, pero éstas no han sido definidas aún.

La neurofibromatosis tipo 1 o Enfermedad de Von Recklinghausen fue descrita por vez primera en 1882 por Friedrich Daniel von Recklinghausen, un patólogo alemán. Desde entonces, está claro no tan sólo que las neurofibromatosis son una de las enfermedades genéticas más comunes, sino también que hay diversas expresiones diferentes de la enfermedad. La forma descrita por Von Recklinghausen es, con diferencia, la más común, llegando aproximadamente al 85% de los casos.

La NF1 es el tipo más común de neurofibromatosis, la cual ocurre aproximadamente en 1 de cada 4.000 personas en Estados Unidos. Aunque muchas personas afectadas heredan este trastorno, entre el 30 y el 50 por ciento de los nuevos casos surgen espontáneamente mediante mutación (cambios) en los genes de una persona. Una vez que ha ocurrido este cambio, el gen mutante puede pasarse a generaciones sucesivas.

Con anterioridad, la NF1 se conocía como neurofibromatosis periférica (o neurofibromatosis de von Recklinghausen), debido a que algunos de los síntomas, tales como manchas en la piel y tumores, parecían estar limitados a los nervios exteriores o al sistema nervioso periférico de la persona afectada. Este nombre ya no es técnicamente exacto debido a que ahora se sabe que en la NF1 ocurren tumores del sistema nervioso central.

Es una alteración genética que provoca en los afectados un crecimiento descontrolado de tumores en casi todo el organismo, de forma irregular. Este crecimiento está provocado por la falta de un "supresor" de crecimiento tumoral. Son típicas las manchas "café con leche" (en la piel), nódulos de Lisch (en el ojo), displasias (en los huesos largos), schwannoma (en los nervios), cataratas, etcétera. Existen 2 tipos de (NF): 

Se caracteriza por la aparición de manchas "café con leche" y afectación en el sistema nervioso periférico (gliomas ópticos), si bien con el paso del tiempo pueden afectarse todos los tejidos y en otros casos la afectación es mínima.

Donde predominan los tumores en nervios craneales, como los nervios auditivos (VIII par), gliomas, meningiomas, etcétera.

En la NF 1 la mutación se encuentra en el cromosoma 17, mientras que en la NF 2 la mutación se da en el cromosoma 22.
La herencia es autosómica dominante, lo que quiere decir que con tener un gen alterado de alguno de los padres aparecerá la enfermedad; asimismo, existe un riesgo del 50% de transmitir la enfermedad a cada uno de los hijos. Hasta el momento se han descrito más de 150 variaciones en la mutación del gen.
Existe también la mutación espontánea "de novo" donde los padres no tienen ninguna alteración cromosómica, se conocen casos de mutaciones "de novo" en varios hijos por lo que se habla de mutaciones en células germinales. En el momento actual se considera que el 50% de los casos diagnosticados de NF son de mutación espontánea.

Los primeros síntomas pueden aparecer en la infancia, como las manchas "café con leche" o pecas en la axila, neurofibromas subcutáneos y el crecimiento de lesiones que tienen distintas evoluciones. No se conoce exactamente por qué unos desarrollan la enfermedad muy pronto y otras personas no; incluso en el seno de la misma familia, el desarrollo tiene una velocidad de crecimiento totalmente distinta y los primeros síntomas pueden aparecer a los 40 o 50 años o incluso más. Se dan familias con hijos poco afectados y padres con gran afectación y al contrario, padre solo con manchas e hijos con mayor afectación. También se dan casos de familias con gliomas que se reabsorben con el paso del tiempo y lo llamativo es que le ocurre lo mismo al hijo. Es importante saber que en la adolescencia y en los embarazos las lesiones sufren cambios importantes en cuanto a tamaño y cantidad.

Para diagnosticar a un paciente afectado con esta enfermedad, desde el punto de vista clínico debe cumplir unos criterios diagnósticos y está estipulado que deben cumplir dos o más de los que se detallan a continuación:


Neurofibromatosis 1. Las posibles complicaciones, también denominadas criterios menores, aparecen en un número inferior de casos. A algunas de ellas sólo se las supone asociadas con la NF porque se encuentran con más frecuencia en afectados, y otras son consecuencia directa de la enfermedad. Ninguna de ellas por sí sola es indicación de NF1. Las más comunes son:


Neurofibromatosis 2. Como consecuencia de los múltiples tumores que en el sistema nervioso produce la NF2, a menudo se presentan otras complicaciones, la mayoría de las cuales están relacionadas con la pérdida de la funcionalidad de las vías nerviosas. Hay que tener en cuenta que, si bien los tumores son benignos, pueden producirse en tal número y localización que hacen que su extirpación sea muy difícil, y no exenta de consecuencias. A veces es complicado determinar si es mejor extirpar o no. Las más comunes son:


En ambos tipos de NF se destacan: 










Actualmente no hay cura, solo tratamientos paliativos. Debido a las múltiples manifestaciones de la enfermedad, se recomienda que los afectados lleven un seguimiento por parte de médicos especialistas, para tratar posibles complicaciones. En ocasiones se recurre a la cirugía para extirpar tumores que comprimen órganos u otras estructuras. Menos del 10% desarrolla tumores malignos que deben ser tratados con quimioterapia.






</doc>
<doc id="41754" url="https://es.wikipedia.org/wiki?curid=41754" title="Viruela">
Viruela

La viruela (del latín "variola": pústula pequeña) fue una enfermedad infecciosa grave, contagiosa y con un alto riesgo de muerte, causada por el virus "Variola virus". El último caso de contagio natural se diagnosticó en octubre de 1977 y en 1980 la Organización Mundial de la Salud (OMS) certificó la erradicación de la enfermedad en todo el planeta. Sus principales características eran una elevada tasa de mortalidad para quienes padeciesen la enfermedad, de alrededor de un 30 %, con tasas especialmente elevadas en bebés y las cicatrices por todo el cuerpo, y en algunos casos ceguera, que dejaba a quienes sobrevivían.

Los síntomas iniciales incluían cuadros de fiebre y vómitos, seguidos en días posteriores de la formación de llagas en la boca y erupciones cutáneas. Al cabo de unos días, las erupciones cutáneas se convertían en protuberancias cargadas de denso líquido con un característico hundimiento en el centro. Con la evolución de la enfermedad, las protuberancias se convertían en pústulas y después en costras, las cuales se caían y dejaban las características cicatrices en la piel. La enfermedad se propagaba a través del contacto de personas sanas con personas contagiadas o mediante el intercambio de objetos contaminados con el virus responsable de la enfermedad. La principal vía de prevención consistió en inocular la vacuna desarrollada contra la viruela, mientras que para su tratamiento una vez contraída la enfermedad existían antivirales específicos, aunque de efectividad escasa.

Se desconoce el origen de la viruela, pero existen evidencias de su existencia en una época muy temprana, pues se han hallado restos en momias egipcias datadas del siglo III a. C. La enfermedad se propagó a lo largo de la historia a través de brotes periódicos: en la Europa del siglo XVIII se estima que unas 400 000 personas morían cada año por viruela y un tercio de los supervivientes desarrollaba ceguera. Se estima que solo en el siglo XX, la viruela mató hasta 300 millones de personas y a 500 millones en sus últimos 100 años de existencia. En 1967, apenas una década antes de su último registro, se registraron 15 millones de casos.

Parece ser que en China alrededor del siglo XVI se comenzó una forma primitiva de inoculación de la viruela para mitigar sus efectos. Europa adoptó esta práctica hacia la primera mitad del siglo XVIII, pero no fue hasta 1796 cuando se creó la primera vacuna moderna contra la viruela, gracias a Edward Jenner. En 1958, la Unión Soviética propuso a la OMS una campaña mundial para erradicar la enfermedad y desde 1967 se intensificaron los esfuerzos para eliminar la viruela con campañas masivas de vacunación, hasta certificar oficialmente su final en 1980. Se considera a la viruela una de las dos únicas enfermedades infecciosas que el ser humano ha logrado erradicar, junto a la peste bovina, erradicada oficialmente en 2011.

Según la forma clínica de presentación de la viruela, se clasifica en: 

La viruela era causada por el virus variola que surgió en las poblaciones humanas en torno al año 10000 a. C. Durante varios siglos, sucesivas epidemias devastaron a la población. Era una enfermedad tan letal que en algunas culturas antiguas estaba prohibido dar nombre a los niños hasta que contrajesen la enfermedad y sobreviviesen a ella. Su tasa de mortalidad llegó a ser hasta de un 30 % de los pacientes infectados.

En la India se creía que la viruela se debía a la bendición de la diosa de la viruela Shitalá (la Fría), y cuando alguna persona se enfermaba acudían a adorarla (con lo que la epidemia se expandía con más velocidad). Aún hoy, a los bebés en la India se los llama genéricamente "kumará" ('fácil muerte', siendo "ku", 'fácil', y "mará", 'muerte').

La viruela fue una enfermedad devastadora en la Europa del siglo XVIII, que se extendía en forma de epidemia matando y desfigurando a millones de personas. Es probable que el siglo XVIII fuera una época especialmente terrible debido a la presencia de la viruela en Europa, ya que la tasa de población creció de manera desmesurada haciendo más fácil la propagación de la enfermedad.

Después de afectar durante milenios al Viejo Mundo, durante la Conquista de América fue contagiada por los recién llegados a los indígenas, que carecían totalmente de defensas ante esa enfermedad desconocida para ellos, causando un colapso demográfico en las poblaciones nativas. En 1520, apareció entre los mexicas durante el sitio de Tenochtitlán, provocando además la muerte de Cuitláhuac. Entre los incas la viruela acabó con el sapa inca Huayna Capac, provocó la guerra civil previa a la aparición hispana y causó un desastre demográfico en el Tahuantinsuyo, que antes de la llegada de los conquistadores europeos contaba con 14 millones de habitantes, mientras hacia el siglo XVIII la población autóctona se redujo a 1,5 millones. En Chile, detuvo el avance de los mapuches tras la muerte de Valdivia. En la península ibérica, provocó la muerte del rey Luis I durante una de las graves epidemias sucedidas en el siglo XVIII en Europa.

Durante cientos de años han ocurrido ocasionalmente epidemias de viruela, sin embargo, después de un exitoso programa de vacunación mundial promovido por la Unión Soviética se logró erradicar la enfermedad. En los Estados Unidos, el último caso de viruela se registró en 1949, mientras que el último caso ocurrido en forma natural en el mundo fue en Somalia en 1977. Una vez que la enfermedad se erradicó en todo el mundo, se suspendió la vacunación habitual de toda la población porque ya no había necesidad de prevenirla. Excepto por las reservas en dos laboratorios, el virus variola está eliminado. Dichas muestras se mantienen en estado criogénico en el Instituto VECTOR de Novosibirsk (Rusia) y en el Centro de Control de Enfermedades de Atlanta (Estados Unidos). Grupos de biólogos han insistido en eliminar ese par de muestras para prevenir que, por un accidente no deseado, alguna de ellas salga del estado de congelación en que se encuentran. Esto no se ha llevado a cabo debido a que el virus como tal nunca fue entendido por completo y se sabía muy poco sobre la forma en que mutaba; aunque se logró dar con la vacuna, su elaboración se hizo de manera empírica, sin conocer con detalle la estructura del virus o su forma de infección; por esta razón, se decidió conservar estas dos únicas muestras.

En China se practicaba la inoculación como medio de prevención de la viruela desde al menos el , por entonces un monje taoísta de Emeishan (provincia de Sichuán) llevó el método a la capital del imperio a petición del primer ministro Wang Dan. 

Siglos más tarde, la británica "lady" Montagu (1689-1762) en un viaje a Turquía observó cómo los circasianos que se pinchaban con agujas impregnadas en pus de viruela de las vacas no contraían nunca la enfermedad. Entonces inoculó a sus hijos y, a su regreso a Inglaterra, repitió y divulgó el procedimiento entre otras personas, siendo este uno de los mayores aportes a la introducción de la inoculación en Occidente.
El éxito obtenido no fue suficiente para evitarle la oposición de la clase médica que siguió desconfiando del método, hasta que el científico Edward Jenner (1749-1823), casi noventa años más tarde, desarrollara finalmente la vacuna.

No obstante, la utilización de inoculaciones con pus de viruela también registra antecedentes históricos en Sudamérica. El fraile juandediano nacido en lo que actualmente es Chile, Pedro Manuel Chaparro, religioso que posteriormente iniciaría sus estudios de medicina, en 1765 inició inoculaciones sistemáticas con pus de pústulas de los variolosos para prevenir la viruela. Esta acción fue tan acertada que de cinco mil personas inoculadas (vale decir el equivalente a una ciudad completa del siglo XVIII), ninguna falleció. 

No se conoce el método utilizado por Chaparro, pero hay algunos datos en el libro "Inoculación de las Viruelas", publicado en Lima en 1778 por fray Domingo de Soria, jandeliano, que había trabajado con Chaparro en Valdivia en 1766. En este libro, cuyo apartado titulado "Parecer que dio el doctor Don Cosme Bueno sobre la representación que hace el Padre Fray Domingo de Soria para poner en práctica la inoculación de las viruelas" su autor, el doctor Cosme Bueno termina del siguiente modo:En vista de todo lo que llevo expuesto, soy de dictamen que puede V. Exc. permitir la Inoculación de las Viruelas como un medio, que sirve para librar muchas vidas, con tal que para el acierto guarden las reglas arriba referidas. Lima y Dicienbre (sic) 20 de 1777. Lorenzo Quiñones, en 1797, describe el método usado en el Perú y que debe haber sido muy similar al utilizado por Chaparro:

Se describe que, entre el 3º y 4º día de la inoculación, aparece una inflamación, con vesículas y pústulas, seguidas de malestar general, alza térmica y aparición de una viruela atenuada en todo el cuerpo, de evolución sorprendentemente benigna y, de modo excepcional, grave y mortal. El proceso terminaba en quince a dieciséis días y dejaba inmunidad frente a la viruela.

En 1796 Edward Jenner inició lo que posteriormente daría lugar a la vacuna: un ensayo con muestras de pústula de la mano de una granjera infectada por el virus de la viruela bovina, y lo inoculó a un niño de ocho años. Tras un período de siete días el muchacho presentó malestar. Pocos días después, Jenner volvió a realizar varios pinchazos superficiales de la temida viruela, que el muchacho no llegó a desarrollar.

En 1798 Jenner publicó su trabajo ("An Inquiry into the Causes and Effects of the Variolae Vaccinae, a Disease Known by the Name of Cow Pox"), donde acuñó el término latino "variolae vaccine" (viruela de la vaca), de esta manera Jenner abrió las puertas a la vacunación. En este sentido, Jenner es considerado una figura de enorme relevancia en la Historia de la Medicina, si bien cabe decir que sus métodos de experimentación serían inaceptables hoy en día por contravenir los principios de la ética médica.

Francisco Javier Balmis y Berenguer (1753-1819) fue pionero en el estudio de las aplicaciones de la vacuna, en particular de la viruela, dirigiendo junto con José Salvany y Lleopard, la Real Expedición Filantrópica de la Vacuna (1803-1814), que contó con el permiso y apoyo del rey Carlos IV, y que es reconocida como un hito en la historia de la medicina al aplicar vacunas a lo largo del entonces Imperio español.

Durante años, cada país realizaba sus propias campañas de vacunación hasta que en 1958, Víktor Zhdánov, el viceministro de Salud de la Unión Soviética, propuso a la Asamblea Mundial de la Salud una iniciativa global conjunta para erradicar la viruela. La propuesta fue aprobada en 1959 bajo el nombre de "resolución WHA11.54". La erradicación de la enfermedad, que entonces afectaba a casi dos millones de personas cada año, se transformó en el principal objetivo de la OMS.

En la década de 1950 la Organización Panamericana de la Salud logró por primera vez eliminarla de todo el continente americano. En 1967, bajo el liderazgo de Karel Raška, se inició una poderosa campaña de vacunación, llegándose a combatir 15 millones de casos en 31 países. La versión "Variola major" fue detectada por última vez en Bangladés en octubre de 1975 en la niña de dos años Rahima Banu. El 26 de octubre de 1977, se divulgó el último caso de viruela (versión "Variola minor") contraída de manera natural, en la localidad de Merca (Somalia) por un hombre de 23 años llamado Ali Maow Maalin. 

En 1978, y debido a un accidente de mala manipulación del virus en un laboratorio de Gran Bretaña, la fotógrafa médica Janet Parker contrajo el virus y murió el 11 de septiembre de dicho año, significando la última muerte humana registrada por este virus en el mundo.

Oficialmente se guardaron solo dos muestras del virus, que fueron puestas en estado criogénico en dos laboratorios: una en el Centro para el Control y Prevención de Enfermedades (CDC) de Atlanta, Estados Unidos, y otra en el Centro Estatal de Virología y Biotecnología VECTOR («Instituto VECTOR») de Novosibirsk en Rusia.

El 8 de mayo de 1980, la XXXIII Asamblea de la OMS aceptó el "Informe final de la Comisión Global para la certificación de la erradicación de la viruela". Esto provocó que el gobierno británico destruyera su muestra y confiara la defensa sanitaria de su pueblo a los Estados Unidos de América. Actualmente el debate es si destruir o no las últimas cepas del virus.

Según un acuerdo firmado entre los Estados Unidos y la Unión Soviética en 1990, la destrucción del virus debería haber ocurrido antes del fin del año 1993.

Poco después de este tiempo el doctor Brian Mahy, a la sazón conductor de un equipo de investigadores de seis países del CDC, reconoció que la destrucción de los virus depositados en Estados Unidos y Rusia no constituye una garantía total: «Siempre es posible que un virus de viruela haya estado deliberadamente conservado en algún lugar del mundo por gobiernos o grupos sociales con el fin de contar con esa arma biológica».

Aunque el doctor Mahy y su equipo abogaban por la destrucción del virus, este mismo reconocimiento es el principal argumento usado por el doctor Wolfgang Joklik y su equipo compuesto por investigadores estadounidenses, rusos y británicos (Universidad de Duke) para oponerse a la destrucción: «La destrucción del virus aislado bajo vigilancia en los laboratorios de Atlanta y Moscú no quita la amenaza de la viruela en el mundo».

De hecho, recientemente se ha constatado la existencia de cepas del virus congeladas en momias siberianas de fallecidos por la enfermedad.

Con respecto a la erradicación de la enfermedad, hay un efecto que no hace deseable que se guarden muestras del virus: la humanidad no solamente ha perdido la inmunidad al virus, sino que tampoco tiene ya memoria genética. Ante un eventual escape o —principalmente— hasta en un ataque biológico, el tiempo de reacción de la industria y la consecuente vacunación mundial no sería suficientemente rápido como para evitar la muerte de cientos de millones de personas.

La vacuna no contiene el virus de la viruela. Se conservaba una reserva periódicamente renovada de unos cuatro millones de dosis de vacunas con fines defensivos. A partir de 2001, el gobierno de los Estados Unidos de América tomó medidas para que hubiera suficiente existencia de vacunas como para inmunizar a toda su población.

Desde la erradicación de la enfermedad no se ha producido vacuna para la población sino solamente han sido vacunados miembros del cuerpo militar de Estados Unidos ante las campañas militares de Irak, enfrentando efectos secundarios . Existen reservas estratégicas para la población civil en los Estados Unidos. Sobre su tratamiento, desde su erradicación se han desarrollado fármacos que parecen arrojar resultados positivos en animales y experimentos de laboratorio. Antivirales como el cidofovir y el brincidofovir parecen ser efectivos contra el virus, mientras que el tecovirimat parece seguro en personas sanas (efectos secundarios menores), pero por razones evidentes no se ha probado su efectividad contra la viruela en humanos. Este último está, a pesar de lo anterior, aprobado como tratamiento para la viruela por la FDA de EE.UU.

La enfermedad se considera erradicada desde 1980.

Para que la viruela se contagie de una persona a otra, se requiere un contacto directo y prolongado, cara a cara. La viruela también puede transmitirse por medio del contacto directo con fluidos corporales infectados o con objetos contaminados, tales como sábanas, fundas o ropa. Rara vez el virus de la viruela se ha propagado transportado por el aire en sitios cerrados como edificios, autobuses y trenes. Los seres humanos eran los únicos portadores naturales del virus de la viruela. No se conocen casos de viruela transmitidos por insectos o animales.

Una persona con viruela puede ser contagiosa cuando comienza la fiebre (fase pródromo), pero alcanza su máxima capacidad para contagiar cuando comienza la erupción. Por lo general, en esta etapa la persona infectada está muy enferma y no puede desplazarse en su comunidad. La persona infectada es contagiosa hasta que desaparece la última costra de viruela.
Comúnmente se indicaba a los pacientes que no debían rascarse los granos o costras ocasionadas por la viruela porque dicha práctica dejaba marcas en la piel.

La viruela es provocada por el "variola virus".




</doc>
<doc id="41755" url="https://es.wikipedia.org/wiki?curid=41755" title="Cianuro">
Cianuro

El cianuro es un anión monovalente de representación CN. El mismo contiene el grupo cianuro (:C≡N:), formado por un átomo de carbono y un átomo de nitrógeno unidos por un enlace triple.

Los compuestos orgánicos que poseen grupo funcional -C≡N adosado a un residuo alquilo son denominados nitrilos según la nomenclatura IUPAC. Se puede encontrar como cianuro de hidrógeno (o ácido cianhídrico) ya sea en fase acuosa (HCN(ac)) o como parte de moléculas de gas (HCN(g)), formando compuestos como el cloruro de cianógeno (CNCl) y el bromuro de cianógeno (CNBr), o encontrarse en complejos cristalinos tetraédricos como el cianuro de sodio (NaCN) y el cianuro de potasio (KCN). Es utilizado en el ámbito industrial, minero, en la galvanoplastia de electrodeposición de zinc, oro, cobre y especialmente plata y de uso en la producción de plásticos de base acrílica. Es muy tóxico, potencialmente mortal.

Se describe con un olor fuerte a castañas o almendras amargas, pero no siempre emana olor y no todas las personas pueden detectarlo, pues está comprobado que la capacidad de detectarlo está en un gen recesivo asociado al cromosoma X femenino. Además el límite de detección del olor es muy cercano a la concentración donde comienza a ser tóxico.

El cianuro de hidrógeno [H-C≡N(g)] o ácido cianhídrico [H-C≡N(ac)], ácido prúsico, metanonitrilo o formonitrilo es un compuesto químico cuya fórmula es: HCN. La disolución de cianuro de hidrógeno en agua es llamada ácido cianhídrico. El cianuro de hidrógeno puro es un líquido incoloro, muy venenoso y altamente volátil, que hierve a 26 °C, es ligeramente ácido y sus sales son conocidas como cianuros; es miscible con el agua, dando el ácido cianhídrico que es un ácido débil (pKa 9.3), el cual es un líquido incoloro con un olor característico a almendras amargas, en el Cuadro 1 se presentan propiedades físicas de algunos cianuros.

Cuadro 1. Propiedades físicas de algunos cianuros

El término cianuro en general se refiere a todos los compuestos del cianuro que pueden ser determinados como el ion CN. El enlace triple C≡N es fácilmente hidrolizado por álcalis fuertes ácido fórmico y amoníaco, una temperatura más alta favorece estas reacciones .

Los cianuros metálicos pueden ser representados por la fórmula general , donde "M" es un metal y "x" es el número de grupos ciano, el cual depende del número de valencia de . Dependiendo del tipo de metales, algunos complejos de cianuros pueden disolverse en agua formando iones metálicos e iones de cianuro de acuerdo con el siguiente modelo general:

formula_1

En disolución los complejos metal-cianuro formados pueden destruirse para formar otro complejo, la sustitución depende de las constantes de formación respectivas, Cuadro 2 Los iones metálicos en disolución también pueden formar complejos con el cianuro que luego pueden precipitar generalmente como complejos hidróxido insolubles.

Cuadro 2. Constantes de formación de algunos complejos metal-CN
Es potencialmente letal, actuando como tóxico a través de la inhibición del complejo citocromo c oxidasa, y por ende bloqueando la cadena transportadora de electrones, sistema central del proceso de respiración celular. Por consecuencia, causa una baja en la producción de ATP intracelular, impidiendo la homeostasis de las células. Afecta también, al estar cargado negativamente, el traspaso de electrones por medio de canales, creando un ambiente positivo dentro de la célula. Esto produce una gran cantidad de cargas que generan suficiente energía como para que el AMP (Adenosín monofosfato) cíclico se pueda convertir en ADP (Adenosín difosfato), creando una sobreestimulación en varios procesos.

El principal efecto nocivo y letal de las diversas variedades de cianuro es el de impedir que el oxígeno portado por los glóbulos rojos pueda ser utilizado como aceptor de hidrógeno en el final de la cadena respiratoria intramitocondrial. En una autopsia, el cadáver presenta gran cantidad de oxígeno en las venas y una gran cantidad de ácido láctico, producto de la fermentación realizada por las células carentes de oxígeno.

Las sustancias químicas encontradas en productos hechos a base de acetonitrilo, utilizados para quitar uñas postizas principalmente, pueden liberar cianuro si se ingieren accidentalmente y como consecuencia producir la muerte por paro cardiorrespiratorio.

El cianuro no es persistente ni asfixiante, ya que en la naturaleza se destruye por acción de la luz solar (por medio del ozono), descomponiéndose por oxidación en gases de tipo COx y NOx. Creando cloratos y nitritos muy utilizados en la purificación del agua contaminada con plomo.

La Agencia de Protección del Medio Ambiente de EE. UU. (EPA) regula los niveles permitidos de cianuro en el agua potable por medio de sales de potasio. El nivel máximo de cianuro permitido en el agua potable es 0.2 partes de cianuro por millón de partes de agua (0.2 ppm). La Administración de Seguridad y Salud Ocupacional de U.E. (EU-OSHA, por sus siglas en inglés) ha establecido un límite para el cianuro de hidrógeno y la mayoría de las sales de cianuro de 10 partes de cianuro por un millón de partes de aire (10 ppm) en el aire del trabajo.

Para la destrucción industrial del cianuro se utilizan cuatro métodos: degradación natural, oxidación química, precipitación y biodegradación. Existen tecnologías de reutilización o reciclado. El uso industrial y minero del cianuro debe ajustarse a normas estrictas, como las que aconseja el Consejo Internacional de Metales y Medio Ambiente, con sede en Ontario, Canadá (2012).

Una de las principales preocupaciones para la salud y el ambiente relacionados con los productos químicos sintéticos es que no se descomponen rápidamente y por lo tanto, pueden acumularse en la cadena alimenticia; sin embargo, el cianuro se transforma en otras sustancias químicas menos tóxicas mediante procesos físicos, químicos y biológicos naturales, dado que el cianuro se oxida cuando es expuesto al aire o a otros oxidantes, se descompone y no persiste. Aunque es un veneno mortal cuando es ingerido en una dosis suficientemente elevada, no causa problemas crónicos en la salud o en el ambiente cuando está presente en concentraciones bajas. En el Cuadro 3 se presenta un resumen toxicológico del CN.

Cuadro 3. Resumen toxicológico del CN

El cianuro de hidrógeno se formó naturalmente en las primeras etapas del desarrollo de la vida sobre la tierra.
Su efectividad a bajas concentraciones es fulminante y mortal. También es conocido por su denominación militar "AN" (para el cianuro de hidrógeno) y CK (para el cloruro de cianógeno).

Es un producto que se encuentra habitualmente en la naturaleza en diversos microorganismos, insectos y en el estado de crecimiento de muchas plantas como un mecanismo de protección, como un alcaloide común, que los convierte en una fuente alimenticia poco atractiva durante ese periodo, para cierto tipo de animales herbívoros.

El cianuro está presente en forma natural en algunos alimentos como las almendras, las nueces, las castañas, la parte interna de las semillas de frutas como los melocotones, las ciruelas, los albaricoques, entre otros, el cazabe, la raíz de yuca y las pepitas de muchas otras frutas como la manzana, las peras o la uva. En ellos se encuentra con el nombre de "amigdalina", un compuesto de glucosa, benzaldehído y cianuro, en concentraciones que oscilan entre los 377 y los 2,50 mg por kg, y que bajo la acción de un fermento (emulsina) se descompone, produciendo ácido cianhídrico. También se da la generación antropogénica, como es el caso de los escapes de los automóviles, el humo de los cigarrillos o tabaco y en la sal industrial que se usa para derretir el hielo de los caminos.

El cianuro aparece también en los productos de combustión de materiales sintéticos tales como telas y plásticos.

Es un subproducto de la fabricación de fibras acrílicas o bien generado por la combinación de gas natural (previo proceso de remoción del metil mercaptano) con amoníaco líquido. Su fabricación primaria es de 1,4 millones de toneladas y se produce en EE. UU., México, Singapur, China, Inglaterra, España y Alemania. La industria minera y del plástico en general consume el 82% del cianuro producido en el mundo, de dicho porcentaje tan solo un 18% es utilizado en minería y el otro 64% es utilizado en la industria para la fabricación de plásticos y derivados.

El cianuro se utiliza industrialmente desde 1889.

El cianuro de hidrógeno fue comercializado por la empresa alemana IG Farben, bajo el nombre de "Zyklon B", y se usaba como pesticida en los años veinte. Después, fue utilizado en la Segunda Guerra Mundial como arma química por los nazis. 

Según lo indican varios informes, es posible que el cianuro de hidrógeno gaseoso haya sido utilizado junto con otros agentes químicos contra los habitantes de la ciudad kurda de Halabja, al noreste de Irak, durante la Guerra Irán-Irak en la década de 1980. También existen denuncias contra Estados Unidos, que alegan que pudo haber sido utilizado en Vietnam junto con el Agente Naranja.

Las industrias de la minería de oro se encuentran entre las mayores consumidoras de cianuro debido a su alta afinidad con el metal. Después de que el metal precioso ha sido extraído del mineral, los cianuros se descargan como efluentes y como residuos de la mina.

Los cianuros provenientes de efluentes del molino de oro pueden clasificarse, grosso modo, en 3 categorías:


El cianuro llamado libre es el que se encuentra como HCN o CN, y son estás especies las que están clasificadas como las más tóxicas debido a su elevado potencial de inhibición metabólica, por otra parte los complejos los metal–cianuro (p. ej. y se consideran relativamente menos tóxicos. La toxicidad aguda de cada complejo metal-cianuro se relaciona con la facilidad con que el cianuro puede ser disociado a cianuro libre, por lo que comparativamente los complejos más débiles serán más peligrosos (tóxicos) que complejos más fuertes .

El método se basa en la destilación ácida a reflujo de la muestra a fin de provocar la volatilización de todas las formas de cianuro presentes en ella, como cianuro de hidrógeno (HCN), para luego condensarlas en una solución alcalina. La concentración de cianuro en esta solución se determina colorimétricamente por espectroscopia UV-VIS, mediante la conversión a CNCl por reacción con cloramina T a pH < 8. Después que la reacción se ha completado, el CNCl forma un compuesto de color rojo-azulado al adicionar ácido barbitúrico y piridina. El compuesto formado presenta una banda de absorción molecular entre 575 y 582 nm. El método colorimétrico es adecuado para concentraciones de cianuro hasta un límite inferior de 20µg/l (20ppb).

La determinación de cianuros por potenciometría directa con electrodo selectivo de cianuro la cual consiste en medir la concentración del ion cianuro libre con un electrodo de selectivo a [CN] a una fuerza iónica constante, para lo cual se traza una curva de calibración y se obtiene una ecuación de regresión al aplicar el Método de Mínimos Cuadrados. Finalmente la concentración de una muestra desconocida se determina por interpolación, utilizando la ecuación determinada .

La determinación de cianuro total ([CN]) en muestra líquidas, semilíquidas y sólidas constituye un problema para los laboratorios ambientales, ya que el método involucra la destilación en medio ácido de cianuro de hidrógeno gaseoso , el cual debe ser colectado en una disolución de hidróxido de sodio muy concentrada para imponer un pH de al menos 11 (debido a que el par ácido-base HCN/CN tiene un valor de pKa de 9.3).

El proceso de extracción implica la destrucción de los complejos metal-cianuro, la adición de MgCl y HSO para formar HCN el cual se recoge en sosa muy concentrada de acuerdo a las siguientes reacciones:

Reacción 1. Destrucción de los complejos metal-cianuro M(CN)

formula_2

Reacción 2. Formación del HCN por adición de HSO 

formula_3

Reacción 3. Formación NaCN

formula_4







</doc>
<doc id="41758" url="https://es.wikipedia.org/wiki?curid=41758" title="Tabún">
Tabún

El tabún es un arma química de guerra creada por el hombre y clasificada como un agente nervioso. Los agentes nerviosos son los agentes químicos de guerra más tóxicos y de más rápido efecto que se conocen. Son parecidos a los pesticidas (insecticidas) organofosforados debido a la forma en que actúan y a los efectos dañinos que producen. Sin embargo, los agentes nerviosos son mucho más potentes que los pesticidas organofosforados.

El tabún fue desarrollado originalmente como pesticida en 1936 en Alemania. También se conoce como "GA" y es un líquido claro, incoloro e insípido (sin sabor) que tiene un ligero olor a frutas. El tabun puede convertirse en vapor si se calienta y no se encuentra en forma natural en el ambiente.

El tabún, como muchos otros agentes nerviosos es un inhibidor de la colinesterasa casi irreversible, y provoca por lo tanto notables efectos colinérgicos. Los efectos comienzan a aparecer entre 0,5 a 2 minutos luego de la exposición al vapor, ya sea por contacto con la piel o al ser inhalado. Según el tipo de exposición (ya sea directa o indirecta) puede generar contracciones musculares, convulsiones, estados de coma y paralización del sistema respiratorio, provocando la muerte de la persona.

Los síntomas en orden normal de aparición son: Irritación nasal, presión en el pecho, visión borrosa o crepuscular debida a la miosis, hiperhidrosis y salivación excesiva (sialorrea), náuseas, vómitos, calambres y pérdida del control de esfínteres, temblores, sacudidas involuntarias, migraña, confusión, pérdida de la conciencia, coma, convulsiones y finalmente muerte por cese de la respiración. 

El Tabún logra efectos inhabilitantes entre uno a diez minutos, y efectos mortales antes de los 15 minutos desde su contacto o inhalación.



</doc>
<doc id="41759" url="https://es.wikipedia.org/wiki?curid=41759" title="Fosgeno">
Fosgeno

El fosgeno (COCl), del griego: "φωσ" ("phos"): "luz" y "γένος-ου" ("genos"): "generador", es un componente químico industrial utilizado para hacer plásticos y pesticidas. A temperatura ambiente (21 °C), el fosgeno es un gas venenoso. Si es enfriado y presurizado, el gas de fosgeno puede ser convertido en líquido, de forma que pueda ser transportado y almacenado. Cuando se libera fosgeno líquido, este se transforma rápidamente en gas que permanece cerca del suelo y se propaga con rapidez (es más denso que el aire y por esa razón se expande hacia áreas más bajas). Al fosgeno también se le conoce por su denominación militar “CG”.

El gas de fosgeno puede ser incoloro o puede verse como una nube que varía de blanca a amarilla pálida. En bajas concentraciones, tiene un olor agradable como a heno recién cortado o maíz verde, pero es posible que no todas las personas expuestas se den cuenta del olor. En altas concentraciones, el olor puede ser fuerte y desagradable.Este componente fue utilizado ampliamente durante la Primera Guerra Mundial como un agente asfixiante (que afecta el sistema pulmonar). Entre los agentes químicos utilizados en la guerra, el fosgeno fue el responsable del mayor número de muertes. No se encuentra en forma natural en el ambiente.

El fosgeno, por sí mismo, no es inflamable (no se enciende ni se quema con facilidad) pero es un comburente (puede causar que prendan las sustancias inflamables que hay a su alrededor).

El gas es utilizado en la industria para producir muchas otras sustancias químicas como los pesticidas. Puede formarse cuando ciertos compuestos están expuestos al calor, como en el caso de varios tipos de plásticos.

El fosgeno fue sintetizado en 1812 por vez primera por el químico amateur inglés John Davy (1790-1868) mediante la exposición de una mezcla de monóxido de carbono y cloro a la luz solar. Lo llamó "phosgene" en referencia a la utilización de la luz para promover la reacción; del griego, "phos" (luz) y "gene" (nacido). Se convirtió poco a poco en un elemento importante en la industria química a medida que avanzaba el siglo XIX, sobre todo en la fabricación de colorantes.

El fosgeno u oxicloruro de carbono, cuya fórmula química es COCl, es un gas generalmente incoloro y no inflamable, con un olor agradable, similar al del heno recién cortado. Es una sustancia química artificial, aunque pequeñas cantidades son formadas en la naturaleza a partir de la degradación de compuestos del cloro.

Se usa en la creación de tinturas, isocianatos, policarbonatos, cloruros ácidos, plaguicidas y, en otro orden de cosas, algunos medicamentos. Además es usado en la separación de algunos minerales. También fue usado como arma química en la Primera Guerra Mundial.

El fosgeno es un gas a temperatura ambiente, pero (en menor medida) también puede ser almacenado en estado líquido, bajo presión o refrigeración.

Cuando el fosgeno se libera al aire existe solamente como gas. Este gas se degrada en la atmósfera cuando reacciona con otras sustancias que se encuentran en el aire, mediante procesos generalmente lentos. En el aire, también reacciona con la humedad de la lluvia y de las nubes dando lugar a otras sustancias.

En el agua, reacciona y se degrada a otros productos. El fosgeno mezclado con agua que no se degrada, se evapora con el aire y forma la reacción del punto anterior.

Con respecto al medio terrestre, no suele adherirse al suelo. Una pequeña parte se evapora al aire, la otra parte baja al agua subterránea y la contamina. La mayor parte se degradará con la humedad.

El fosgeno es un producto no acumulativo en la cadena alimentaria.

El fosgeno existe en el aire en bajas concentraciones a las que estamos expuestos.

Este tóxico es liberado en la soldadura de metales que han sido limpiados con solventes clorados, los profesionales que se dedican a esta actividad son los que más riesgo de exposición tienen. Cuando se produce una temperatura aproximada de 120 °C en uno de esos disolventes se forma fosgeno y si el metal tiene alguna grasa, aproximadamente un 60% del disolvente, la temperatura de formación del fosgeno baja incluso a 70 °C).

TLV: (Valor umbral límite de exposición) = 0,1 ppm.

Afecta poco a la mucosa, por lo que sus efectos no se perciben hasta varias horas después de su inhalación. En presencia de agua, el fosgeno se descompone en ácido clorhídrico, lo que ocurre con facilidad en el interior del alvéolo pulmonar, lesionando el endotelio, provocando edema, sofocación, cianosis y expectoración serosa abundante. Lo puede llevar a la muerte por asfixia o "shock".

Al contacto con la piel y los ojos produce quemadura química y congelación, aunque es altamente improbable el contacto con fosgeno líquido.

En el caso en el que ya haya habido contacto con el fosgeno, se recomienda quitarse la ropa contaminada y aclararse la piel con abundante agua, enjuagarse los ojos y quitarse inmediatamente las lentes de contacto, siempre que sea posible. Si el tóxico se encuentra en suspensión y hay riesgo de ser inhalado, hay que abandonar el lugar y guardar reposo, para reducir al mínimo el consumo de oxígeno. Al afectado hay que suministrarle oxígeno, aunque en presencia de edema, este no puede exceder una concentración del 30 al 40%. Para prevenir o aliviar el edema hay que suministrar una solución glucosada hipertónica intravenosa. Ayuda administrar gluconato de calcio al 10% por vía intravenosa. Si no hay "shock", se puede practicar una sangría de entre 400 y 700 ml. Para la insuficiencia cardíaca hay que inyectar 0,125 mg de estrofantina por vía intravenosa. Para prevenir las infecciones pulmonares es altamente recomendable suministrar antibióticos. Para disminuir el riesgo de secuelas pulmonares hay que utilizar corticoides.



</doc>
<doc id="41766" url="https://es.wikipedia.org/wiki?curid=41766" title="Be Incorporated">
Be Incorporated

Be Incorporated fue la compañía desarrolladora del sistema operativo BeOS y la arquitectura de hardware BeBox. Fue fundada por el francés Jean-Louis Gassée, antiguo dirigente de Apple, en 1990. Sus valores fueron adquiridos por Palm, Inc. en 2001 (pasando posteriormente a PalmSource y de esta a Access Co.), al momento de su bancarrota.

Más tarde Be inició una acción legal contra Microsoft, la cual terminó el 5 de septiembre de 2003 con la paga de 23,2 millones de US dólares a Be.


</doc>
<doc id="41767" url="https://es.wikipedia.org/wiki?curid=41767" title="Malaria">
Malaria

La malaria (del italiano medieval "malaria") o paludismo (del latín "paludis", genitivo del nombre "palus", ‘ciénaga, pantano’ y de -ismo, en este caso acción o proceso patológico) es una enfermedad producida por parásitos del género "Plasmodium", y transmitida por mosquitos. Algunos estudios científicos sugieren que pudo haberse transmitido al ser humano a través de los gorilas occidentales. Es la primera enfermedad de importancia entre las enfermedades debilitantes. Más de 400 000 personas mueren al año por causa de la malaria, de los cuales unos 240 000 son niños.

En mayo de 2007, la Asamblea Mundial de la Salud decidió conmemorar el 25 de abril el "Día Mundial del Paludismo".

La enfermedad puede ser causada por una o por varias de las diferentes especies de "Plasmodium": "Plasmodium falciparum", "Plasmodium vivax", "Plasmodium malariae", "Plasmodium ovale" o "Plasmodium knowlesi", las tres primeras han sido reportadas en el continente americano. Los vectores de esta enfermedad son diversas especies del mosquito del género "Anopheles". Solo las hembras de los mosquitos se alimentan de sangre para poder madurar los huevos; los machos no pican y no pueden transmitir enfermedades, ya que únicamente se alimentan de néctares y jugos vegetales.

Las formas de contagio directo entre humanos son que una mujer embarazada lo transmita por vía placentaria al feto o por transfusiones sanguíneas de donantes que han padecido la enfermedad.

En regiones donde la malaria es altamente endémica, las personas se infectan tan a menudo que desarrollan la inmunidad adquirida, es decir, son portadores más o menos asintomáticos del parásito.

El primer intento de una vacuna sintética contra la malaria fue realizado en 1997 por el equipo de Manuel Elkin Patarroyo; los resultados fueron negativos en África y modestos en Suramérica por lo cual no se justificaron pruebas adicionales. En 2010, la vacuna aparecía catalogada como «inactiva» por la Organización Mundial de la Salud.

Alrededor del 40% de la población mundial vive en zonas afectadas por malaria, principalmente en los países más pobres. Los mosquiteros tratados con insecticida (MTI) previenen esta enfermedad de manera efectiva. Sin embargo, se han identificado ciertos obstáculos en cuanto al aumento de su uso.

Una revisión sistemática de diez estudios, nueve realizados en África y uno en la India, concluyó que la entrega gratuita de MTI aumenta ligeramente el número de propietarios, comparado con su provisión a precio de mercado o subvencionado. Asimismo, educar sobre el uso adecuado de MTI aumenta el número de personas que duermen bajo un mosquitero, comparado con un grupo de control que no recibió dicha educación. No se midieron efectos secundarios adversos. Por último, existe evidencia de una mejoría de la morbilidad por malaria como resultado del aumento de tenencia y uso de MTI, aunque estos hallazgos siguen siendo inciertos.

La malaria ha infectado a los humanos durante más de 50 000 años, y puede que haya sido un patógeno humano durante la historia entera de nuestra especie, hipótesis que también se apoya en la observación de especies cercanas a los parásitos humanos de la malaria en los chimpancés, pariente ancestral de los humanos. Además, se encuentran referencias de las peculiares fiebres periódicas de la malaria a lo largo de la historia, comenzando desde 2700 a. C. en China.

Los estudios científicos sobre la malaria hicieron su primer avance de importancia en 1880, cuando el médico militar francés Charles Louis Alphonse Laveran, trabajando en Argelia, observó parásitos dentro de los glóbulos rojos de personas con malaria. Propuso por ello que la malaria la causaba un protozoario, la primera vez que se identificó a un protozoario como causante de una enfermedad. Por este y otros descubrimientos subsecuentes, se le concedió el en 1907. Al protozoario en cuestión se le llamó "Plasmodium", por los científicos italianos Ettore Marchiafava y Angelo Celli. Al año siguiente Carlos Finlay, un médico hispano-cubano que trataba pacientes con fiebre amarilla en la Habana, sugirió que eran los mosquitos quienes transmitían la enfermedad de un humano a otro. Posteriormente, fue el británico Sir Ronald Ross, trabajando en la India, quien finalmente demostró en 1898 que la malaria era transmitida por los mosquitos. Lo probó al mostrar que ciertas especies del mosquito transmitían la malaria a pájaros, al conseguir aislar los parásitos de las glándulas salivales de mosquitos que se alimentaban de aves infectadas. Por su aporte investigador, Ross recibió el premio Nobel de Medicina en 1902. Después de renunciar al Servicio Médico de la India, Ross trabajó en la recién fundada Liverpool School of Tropical Medicine y dirigió los esfuerzos por controlar la malaria en Egipto, Panamá, Grecia y Mauricio. Los hallazgos de Finlay y Ross fueron confirmados luego por un comité médico dirigido por Walter Reed en 1900, y sus recomendaciones implementadas por William C. Gorgas en medidas de salud adoptadas durante la construcción del Canal de Panamá. Este trabajo salvó la vida de miles de trabajadores y ayudó a desarrollar los métodos usados en campañas de salud pública contra la malaria.

El primer tratamiento eficaz para la malaria fue la corteza del árbol "Cinchona", que contiene el alcaloide quinina. Este árbol crece en las colinas de los Andes, en particular en Perú. Los habitantes del Perú usaban el producto natural para controlar la malaria, y los Jesuitas introdujeron esta práctica en Europa durante los años 1640, donde fue aceptada con rapidez. Sin embargo, no fue sino hasta 1820 cuando la quinina, el ingrediente activo, fue extraída de la corteza y nombrada por los químicos franceses Pierre Joseph Pelletier y Joseph Bienaimé Caventou.

A comienzos del siglo XX, antes de los antibióticos, los pacientes con sífilis eran intencionalmente infectados con malaria para crear una fiebre, siguiendo las investigaciones de Julius Wagner-Jauregg. Al controlar la fiebre con quinina, los efectos tanto de la sífilis como la malaria podían ser minimizados. Algunos de los pacientes murieron por la malaria, pero el riesgo era preferible por encima de la casi segura muerte por sífilis.

A pesar de que en el estadio sanguíneo y en el mosquito del ciclo de vida de la malaria se estableció en el siglo XIX y a comienzos del siglo XX, solo en 1980 se observó la forma latente hepática del parásito. Este descubrimiento explicó finalmente por qué daba la impresión de que algunas personas se curaban de la enfermedad, para recaer años después de que el parásito hubiese desaparecido de su circulación sanguínea.

Durante la II Guerra Mundial el bando nazi planeó utilizarla como arma biológica mediante una bomba que esparciría mosquitos hembra con el protozoo en cuestión. Las pruebas dieron positivo, pero el bando aliado desbarató el avance del proyecto. 

Por otro lado, el valor medicinal de la planta Artemisia annua ha sido utilizado por los herbolarios chinos en su medicina tradicional durante 2000 años. En 1596, Las artemisininas de esta planta, descubiertas por la científica china Tu Youyou y sus compañeros en la década de 1970, se convirtieron en el tratamiento recomendado para la malaria por "P. falciparum", administrada en casos graves en combinación con otros antipalúdicos. Tu Youyou recibió el Premio Nobel 2015 en Fisiología o Medicina por su contribución a la investigación contra la malaria, ya que gracias a su trabajo se salvaron vidas y se mejoraron los tratamientos paliativos de las personas diagnosticadas.

Los síntomas son muy variados, empezando con fiebre, escalofríos, sudoración y dolor de cabeza. Además se puede presentar náuseas, vómitos, tos, heces con sangre, dolores musculares, ictericia, defectos de la coagulación sanguínea, shock, insuficiencia renal o hepática, trastornos del sistema nervioso central y coma.

La fiebre y los escalofríos son síntomas cíclicos, repitiéndose cada dos o tres días.

La reactivación debida a hipnozoítos suele ocurrir durante los tres primeros años (paludismo recidivante).

"P. falciparum" es el que produce la malaria más aguda y grave. Produce secuestro de hematíes en microcirculación venosa, evita el paso por el bazo y, por tanto, su destrucción. Produce malaria cerebral, con alteraciones en el nivel de conciencia, coma, convulsiones, hipoglucemia, hiperinsulinemia en adultos, acidosis metabólica, ictericia o hemorragias que son signos de mal pronóstico que requieren una actuación médica inmediata. La enfermedad es grave en niños y mujeres embarazadas.

La proteína I de la membrana eritrocitaria de "P. falciparum" (PfEMPI) se une a ligandos en las células endoteliales (CD36, tromboplastina, VCAM I, ICAM I Y E-selectina). Los eritrocitos infectados se agrupan en rosetas y se pegan a las células endoteliales, producen isquemia y causa las manifestaciones de la malaria cerebral.

También se estimula la producción de niveles muy elevados de citoquinas (IL1, TNF, INF) que estimulan la producción de óxido nítrico, produciendo daño celular. En la malaria cerebral maligna, los vasos cerebrales están taponados por eritrocitos parasitados. Aparecen hemorragias anulares relacionadas con hipoxia local, acompañadas de zonas inflamatorias llamadas granulomas de Dürck o de la malaria.

La OMS recomienda que antes de administrar el tratamiento se confirme el diagnóstico con métodos parasitológicos. Se utilizan la microscopía y las pruebas rápidas de detección de Ag en sangre para obtener los resultados en menos de una hora.

Se realiza mediante:

Permite el examen de una mayor cantidad de sangre en menos tiempo. Se pone una gota en el centro de la lámina y se hacen movimientos envolventes para romper los hematíes y que permita observar los parásitos. 

Puede utilizarse sangre venosa anticoagulada recogida en tubos con EDTA.

La inmunofluorescencia indirecta (IFI) y el inmunoensayo enzimático (ELISA) se emplean sobre todo en estudios epidemiológicos.

"P. falciparum": Los eritrocitos infectados no aumentan de tamaño, ni se deforman y están poliparasitados. Los gametocitos se ven en forma de banana. En sangre periférica no se observan esquizontes. Cuando están presentes son un signo de malaria complicada. "P. falciparum" se observa en el borde de la membrana de los eritrocitos y a esta posición se denomina “appliquée o accolée”. A veces se detectan gránulos rojizos llamados puntos de Mauer.

"P. malariae": Los eritrocitos son de tamaño normal o disminuido. El parásito adopta formas en “banda y en barra” dentro de los eritrocitos. El esquizonte presenta ocho merozoítos que se disponen “en roseta”. A veces aparecen los puntos de Ziemann como gránulos rojizos en el interior de la célula anfitriona.

"P. vivax": Los eritrocitos presentan un tamaño aumentado y contienen gránulos de color rosa (punteado de Schüffner positivo). Los esquizontes eritrocitarios suelen contener hasta 24 merozoítos y los esquizontes maduros presentan la hemozoína (pigmento palúdico).

"P. ovale": Los eritrocitos presentan un tamaño aumentado y presentan punteado de Schüffner positivo. El esquizonte maduro contiene la mitad de los merozíotos que el de "P vivax".

Se puede dar un diagnóstico diferencial entre malaria y la fiebre de Zika.

Paciente con parasitemia positiva y con uno de los siguientes síntomas o signos que indican riesgo de una complicación: Poliartralgia severa, alteraciones neurológicas hemoglobina por debajo de 7 g/dl, hiperparasitemia (definida como conteo de trofozoitos superior a 50 000 o la presencia de esquizontes (en el caso de "P. falciparum")), ictericia, disnea o taquipnea, disminución de la diuresis, coluria, vómitos a repetición o cualquier tipo de sangrado. La mortalidad de la malaria complicada sin tratamiento es cercana al 100 %.

Los métodos utilizados para prevenir el paludismo incluyen los medicamentos, la eliminación de los mosquitos y la prevención de las picaduras. A partir de 2020, existe una vacuna contra el paludismo (conocida como RTS,S) cuyo uso está autorizado. La presencia del paludismo en una zona requiere una combinación de alta densidad de población humana, alta densidad de población de mosquitos anofeles y altas tasas de transmisión de humanos a mosquitos y de mosquitos a humanos. Si cualquiera de estos factores se reduce lo suficiente, el parásito termina por desaparecer de esa zona, como ocurrió en América del Norte, Europa y partes del Oriente Medio. Sin embargo, a menos que el parásito sea eliminado de todo el mundo, podría restablecerse si las condiciones vuelven a una combinación que favorezca la reproducción del parásito.

El control de mosquitos se encarga de administrar la población de mosquitos para reducir su impacto en la salud humana y la economía.

Para la protección individual, los repelentes de insectos más eficaces se basan en el DEET o la picaridina.
Sin embargo, no hay pruebas suficientes de que los repelentes de mosquitos puedan prevenir la infección del paludismo. 

Los mosquiteros tratados con insecticidas y la fumigación residual de interiores han demostrado ser muy eficaces para prevenir el paludismo entre los niños en las zonas donde es común.

Los mosquiteros ayudan a mantener a los mosquitos alejados de las personas y a reducir las tasas de infección y la transmisión del paludismo. Los mosquiteros no son una barrera perfecta y a menudo se tratan con un insecticida diseñado para matar al mosquito antes de que éste tenga tiempo de encontrar una forma de pasar el mosquitero. Se estima que los mosquiteros tratados con insecticidas son dos veces más eficaces que los no tratados y ofrecen una protección superior al 70% en comparación con los que no tienen mosquiteros.

Se estima que las mosquiteras es una de las intervencionas más efectivas, ya que a un coste de menos de 5€ por mosquitera se protegen de media a 1.8 personas durante 3 años.

Entre 2000 y 2008, el uso de mosquiteros tratados con insecticidas salvó la vida de unos 250.000 niños en el África subsahariana. Se estima que en 2007 el 13% de los hogares de los países subsaharianos poseían mosquiteros tratados con insecticidas y que en 2008 el 31% de los hogares africanos poseían al menos un mosquitero tratado con insecticidas. En el año 2000, 1,7 millones (1,8%) de niños africanos que vivían en zonas del mundo donde la malaria es común estaban protegidos por un MTI. Esa cifra aumentó a 20,3 millones (18,5%) de niños africanos que utilizaban mosquiteros tratados con insecticidas en 2007, lo que dejó a 89,6 millones de niños desprotegidos[75] y a un 68% de niños africanos que utilizaban mosquiteros en 2015. La mayoría de los mosquiteros están impregnados con piretroides, una clase de insecticidas de baja toxicidad. Son más eficaces cuando se usan desde el anochecer hasta el amanecer. Se recomienda colgar un "mosquitero de cama" grande sobre el centro de la cama y meter los bordes debajo del colchón o asegurarse de que sea lo suficientemente grande como para tocar el suelo. Los mosquiteros tratados con insecticidas son beneficiosos para los resultados del embarazo en las regiones de África donde la malaria es endémica, pero se necesitan más datos en Asia y América Latina.

En áreas de alta resistencia a la malaria, el butóxido de piperonilo combinado con piretroides en ITN es efectivo para reducir las tasas de infección de la malaria.

Otra vía para detener la malaria en el mundo, que se ha utilizado extensamente en el pasado, es la utilización de insecticidas, como las piretrinas o el DDT. Se prohibió el uso de este último por sus posibles efectos en la salud y en la fauna, pero un grupo de científicos cree que debería revisarse esta prohibición tan estricta. Se considera ahora que un uso medido con fines sanitarios, distinto del uso masivo con fines económicos del que fue objeto en el pasado, es una buena opción para el control o erradicación de la malaria bajo condiciones muy controladas, limitándose al interior de las casas y tejados en las zonas donde esta enfermedad es endémica, según la OMS. Algunos grupos ambientalistas, como la Pesticide Action Network no están de acuerdo con esta medida.

Los defensores del uso del DDT, entre los que se incluyen científicos, estadísticos y ecologistas escépticos como Bjørn Lomborg, argumentan que este es un método eficaz contra la malaria; afirman que gracias a ella la malaria desapareció de Europa, donde era endémica en Grecia o Italia. En Sri Lanka, los casos de malaria descendieron desde 2 800 000 casos en 1948 a 17 en 1963; en la India, de 100 millones de casos en 1935, la cifra bajó a 300 000 en 1969. Bangladés fue declarada zona libre de malaria. Incluso circula la cifra que afirma que la prohibición del DDT ha causado 50 millones de muertes. Defienden su idoneidad basándose en la eficacia que le atribuyen, junto con el bajo coste de su aplicación y el hecho de que no tenga problemas de patentes. Precisamente algunos argumentan que los motivos últimos de la prohibición están en la propia industria, la cual, al acabar las patentes del DDT, quisieron imponer nuevos pesticidas con patente.

Sin embargo, los efectos del DDT en la salud humana y particularmente en trabajadores del programa de control de la malaria están ampliamente documentados. Se ha asociado a un aumento de síntomas neuropsiquiátricos y alteraciones neurológicas.

Las vacunas para la malaria están en desarrollo, no hay disponible todavía una vacuna completamente eficaz. Los primeros estudios prometedores que muestran la posibilidad de una vacuna contra el paludismo se realizaron en 1967 por la inmunización de ratones con esporozoitos atenuados por radiación, que brindan protección a alrededor del 60 % de los ratones posterior a la inyección de esporozoitos normales y viables. Desde la década de 1970, se ha producido un considerable esfuerzo para desarrollar estrategias de vacunación similares en los seres humanos.

Se han realizado muchos trabajos para intentar comprender los procesos inmunológicos que brindan protección después de la inmunización con esporozoitos irradiados. Tras el estudio de vacunación en ratones en 1967, se formuló la hipótesis de que los esporozoitos inyectados eran reconocidos por el sistema inmune, que a su vez creaba anticuerpos contra el parásito. Se determinó que el sistema inmunológico estaba creando anticuerpos contra la proteína circumsporozoito (CSP) que reviste a los esporozoitos. Además, los anticuerpos contra la CSP impidieron que los esporozoitos invadiesen hepatocitos. CSP, por lo tanto, fue elegida como la proteína más prometedora para desarrollar una vacuna contra la malaria. Es por estas razones históricas que las vacunas basadas en CSP son las más numerosas de todas las vacunas contra la malaria. 

Actualmente, existe una gran variedad de vacunas sobre la mesa. Vacunas pre-eritrocíticas (vacunas que se dirigen a los parásitos antes de que llegue a la sangre), en particular las vacunas basadas en CSP, forman el mayor grupo de investigación de la vacuna contra la malaria. En la lista de vacunas candidatas se incluyen: las que tratan de inducir inmunidad en la etapa de infección de la sangre, las que tratan de evitar las patologías más severas de la malaria evitando la adhesión del parásito a las vénulas de la sangre y a la placenta; y las vacunas que bloqueen la transmisión, que detendrían el desarrollo del parásito en el mosquito justo después de que el mosquito ha tomado sangre de una persona infectada. Es de esperar que la secuenciación del genoma de "P. falciparum" proporcionará objetivos para nuevos medicamentos o vacunas.

Se determinó que una persona puede protegerse de una infección por "P. falciparum" si recibe picaduras de más de 1000 mosquitos infectados por irradación.En general, se ha aceptado que no es adecuado tratar a las personas de riesgo con esta estrategia de vacunación, pero esto ha sido recientemente cuestionado por el trabajo que está realizando el doctor Stephen Hoffman, de Sanaria, uno de los principales investigadores que originalmente secuenció el genoma de "Plasmodium falciparum". Su trabajo más reciente ha girado en torno a la solución del problema de logística de la preparación y aislamiento de los parásitos equivalentes a 1000 mosquitos irradiados para el almacenamiento masivo y la inoculación de los seres humanos. La compañía ha recibido recientemente varias subvenciones multimillonarias de la Fundación Bill y Melinda Gates y el gobierno de los EE.UU. para iniciar los primeros estudios clínicos en 2007 y 2008. El Instituto de Investigación Biomédica de Seattle (SBRI), financiado por la Iniciativa Vacuna contra la Malaria asegura a los posibles voluntarios que "los ensayos clínicos no serán un riesgo para la vida. Si bien muchos voluntarios en Seattle realmente contraerán la enfermedad, la cepa clonada utilizada en los experimentos se puede curar, y no causa una forma recurrente de la enfermedad. Algunos de los participantes obtendrá drogas experimentales o vacunas, mientras que otros recibirán placebo".

La primera vacuna desarrollada objeto de ensayos de campo fue la SPf66, desarrollada por el científico colombiano Manuel Elkin Patarroyo en 1987, probada en una colonia de monos de la región amazónica, los "Aotus trivirgatus". Presenta una combinación de antígenos de los esporozoitos (utilizando repetición CS) y merozoitos del parásito. Durante la fase I de los ensayos se demostró una tasa de eficacia del 75% y la vacuna pareció ser bien tolerada por el sistema inmunogénico de los sujetos. Los ensayos de las fases IIb y III fueron menos prometedores, la eficacia cayó hasta situarse entre el 38,8% y el 60,2%. Un ensayo llevado a cabo en Tanzania en 1993 demostró una eficacia del 31% después de un año de seguimiento. Sin embargo, un estudio más reciente (aunque controvertido) realizado en Gambia no mostró ningún efecto. A pesar de los períodos de prueba relativamente largos y del número de estudios realizados, aún no se conoce la forma en que la vacuna SPf66 confiere inmunidad, por lo que sigue siendo una improbable solución a la malaria. El CSP fue la siguiente vacuna desarrollada que inicialmente parecía suficientemente prometedora como para someterse a los ensayos. También se basaba en las proteína circumsporozoito, pero además tenía la proteína recombinante (Asn-Ala-Pro15Asn-Val-Asp-Pro)2-Leu-Arg(R32LR) unida covalentemente a una toxina purificada de "Pseudomonas aeruginosa" (A9). Sin embargo, en una fase temprana se demostró una falta total de inmunidad protectora en los inoculados. El grupo de estudio utilizado en Kenia tuvo un 82% de incidencia de parasitemia, mientras que el grupo de control solo tuvo un 89% de incidencia. La vacuna tenía la intención de provocar una respuesta incrementada de linfocitos T en los que fueron expuestos, cosa que tampoco fue observada.

La vacuna se probó en más de 41 000 voluntarios en América Latina, donde a principios de 1994 fueron inoculados 45 voluntarios que demostraron que la vacuna induce una fuerte respuesta inmunitaria (entre un 40 y un 60% en los adultos, y hasta un 77% en los niños) contra la malaria, sin provocar efectos colaterales. Finalmente, luego de ser evaluada en Gambia, Tanzania y Tailandia, la vacuna demostró no tener la efectividad aspirada por el doctor Patarroyo, por lo cual se detuvo el proceso de fabricación y vacunación con la SPF66. 

La vacuna RTS,S/AS02A fue desarrollada por una alianza entre la PATH Malaria Vaccine Initiative (un concesionario de la Fundación Gates), la empresa farmacéutica GlaxoSmithKline, y el Walter Reed Army Institute of Research. En esta vacuna, una porción de CSP ha sido fundida con el "S antígeno" inmunogénico del virus de la hepatitis B; esta proteína recombinante se inyecta junto al potente adyuvante AS02A. En octubre de 2004, los investigadores de la RTS,S/AS02A anunciaron los resultados de un ensayo de fase IIb, indicando que la vacuna redujo el riesgo de infección en aproximadamente un 30% y la gravedad de la infección en más de un 50%. El estudio examinó más de 2000 niños de Mozambique. Los ensayos más recientes de la vacuna RTS,S/AS02A se han centrado en la seguridad y eficacia de su administración en la primera etapa de la infancia: En octubre de 2007, los investigadores anunciaron los resultados de los ensayos de las fases I / IIb realizados sobre 214 lactantes mozambiqueños de entre 10 y 18 meses, en los que la administración de tres dosis de vacuna llevó a un 62% de reducción de infecciones sin efectos secundarios graves salvo algo de dolor en el punto de inyección.[105] La investigación posterior demorará el lanzamiento comercial de esta vacuna hasta alrededor de 2012.

La revista The Lancet publicó el 16 de octubre de 2004 los resultados iniciales del mayor ensayo clínico de una vacuna contra la malaria en África.

En zonas endémicas se han creado estrategias para protegerse de la infestación.

Algunas mutaciones en los genes de la Hb confieren resistencia a la malaria.
Las personas heterocigotos para el rasgo de células falciformes (HbS) presentan protección frente a "P. falciparum", ya que el parásito crece mal debido a las bajas concentraciones de oxígeno. La HbC reduce la proliferación parasitaria.
La negatividad para el antígeno Duffy protege de la infección por "P. vivax", ya que necesita unirse a este Ag para introducirse en el hematíe.
El déficit G6PD provoca hemólisis debido al estrés oxidativo y está asociada al efecto protector de la malaria por "P. falciparum".

El viajero que presente fiebre en los tres meses siguientes a la exposición se considera una urgencia por la posibilidad de presentar malaria. Los viajeros presentan síntomas más graves que la población local, ya que estos han desarrollado cierto grado de inmunidad al estar expuestos al parásito, que ayuda a controlar la infección y disminuye la gravedad.

La técnica de los insectos estériles se está perfilando como un posible método de control de mosquitos. El progreso hacia insectos transgénicos, o genéticamente modificados, sugieren que las poblaciones de mosquitos silvestres podrían ser resistentes a la malaria. La investigación en el Imperial College de Londres creó el primer mosquito transgénico para el paludismo, con la primera especie resistente a Plasmodium, anunciado por un equipo de la Case Western Reserve University en Ohio, en 2002. El éxito de la sustitución de las poblaciones existentes con poblaciones genéticamente modificadas, se basa en un mecanismo de transmisión, como los elementos trasladables para permitir la herencia mendeliana de los genes de interés. 

Se está desarrollando un novedoso método que consiste en un pequeño dispositivo de 2 milímetros de diámetro que se inserta debajo de la piel. El desarrollo de este implante es el trabajo de Malaria Mission ( http://www.malariamission.org/ ), una iniciativa del grupo de investigación Salud Tropical de la Universidad de Navarra y la Clínica de Navarra, quienes actualmente buscan financiación de U$ 20 000 a través de https://www.indiegogo.com/projects/malaria-mission-help-us-fight-malaria-by-defeating-the-mosquitoes#gallery. El dispositivo consiste en un pequeño implante de silicona que libera ivermectina, una medicina segura y muy utilizada para combatir la malaria y otras infecciones parasitarias endémicas en las zonas tropicales, el medicamento se libera en pequeñas cantidades en el portador ayudándolo a combatir la enfermedad y a la vez hace que los mosquitos que pican al paciente mueran, ya que estos, no toleran los niveles de ivermictina contiene la sangre que acaban de beber de su huésped.

La educación en el reconocimiento de los síntomas de la malaria ha reducido el número de casos en algunas zonas del mundo en desarrollo hasta en un 20%. Reconocer la enfermedad en las primeras etapas también puede evitar que cause muertes. La educación también puede informar a la gente para cubrir más áreas de aguas estancadas. Por ejemplo, los tanques de agua son caldo de cultivo ideal para el parásito y el mosquito. Por lo tanto, una forma de reducir el riesgo de la transmisión entre las personas es eliminar los recipientes o tanques con agua estancada. Se trata de poner en la práctica en la mayoría en las zonas urbanas donde hay grandes centros de población y por lo tanto la transmisión sería más probable.

Otros métodos adicionales son:

Es menester mencionar que los esquemas antipalúdicos varían de país a país, debido a que se basan en estudios de resistencia a antimaláricos que se realizan de manera periódica, generalmente de acuerdo a un protocolo establecido por la agencia local de la Organización Mundial de la Salud. 
Se han observado resistencias de los parásitos a varios antipalúdicos. Las tasas de resistencia aumentan a medida que el uso de nuevos antipalúdicos también aumenta. La microscopía es el único método fiable para controlar la eficacia del tratamiento. Algunos de los fármacos que pueden emplearse son:









Si hay resistencias suele utilizarse atavacuona- proguanil y en la malaria grave producida por "P. falciparum" se emplea quinina + doxiciclina y artemeter (artemisina).

La malaria afecta a unos 200 millones de personas y provoca aproximadamente 400 000 muertes anuales, lo que representa una muerte cada 90 segundos. La gran mayoría de los casos ocurre en niños menores de 5 años; las mujeres embarazadas son también especialmente vulnerables. A pesar de los esfuerzos por reducir la transmisión e incrementar el tratamiento, ha habido muy poco cambio en las zonas que se encuentran en riesgo de la enfermedad desde 1992. De hecho, si la prevalencia de la malaria continúa en su curso de permanente aumento, la tasa de mortalidad puede duplicarse en los próximos veinte años. Las estadísticas precisas se desconocen porque muchos casos ocurren en áreas rurales, donde las personas no tienen acceso a hospitales o a recursos para garantizar cuidados de salud. Como consecuencia, la mayoría de los casos permanece indocumentada.

Aunque la coinfección de VIH con malaria ha incrementado la mortalidad, sigue siendo un problema menor que la combinación de VIH-tuberculosis.

La hembra del "Anopheles" infectada es portadora de los esporozoítos del "Plasmodium" en sus glándulas salivales. Si pica a alguien, los esporozoitos entran en la persona a través de la saliva del mosquito y migran al hígado por el torrente sanguíneo, donde se multiplican rápidamente dentro de las células hepáticas (los hepatocitos) mediante una división asexual múltiple, y se transforman en merozoitos que entran en el torrente sanguíneo. Allí infectan los eritrocitos y siguen multiplicándose, dando lugar a unas formas iniciales típicamente anulares (trofozoítos), formas en división asexual múltiple (merontes) y finalmente un número variable de merozoítos según la especie de "Plasmodium", que provoca la ruptura del eritrocito. Algunos merozoítos se transforman en unas células circulares relativamente grandes que son gametocitos femeninos y masculinos y dejan de multiplicarse, aunque en "P. falciparum" son más grandes que el propio eritrocito y tienen forma de búmeran, lo que ocasiona su ruptura.

Una hembra de "Anopheles" no infectada pica a un enfermo y adquiere los gametocitos, y así se inicia el ciclo sexual del "Plasmodium". Con la unión de los gametos en su intestino, la formación de un huevo, que es móvil, y que dará origen a un ooquiste que volverá a dividirse y dar esporozoitos listos para infectar nuevamente, al llegar a las glándulas salivales del mosquito.

En los humanos, las manifestaciones clínicas se deben a:

La ruptura de glóbulos rojos, que liberan merozoitos, que liberan sustancias que estimulan el hipotálamo, ocasionando repentinas crisis febriles, muy intensas, cada dos o tres días (al completarse el ciclo eritrocítico o asexual de "Plasmodium"), seguidas al cabo de unas horas de una brusca vuelta a una aparente normalidad. Este proceso va dejando al organismo exhausto, y en el caso de los niños pequeños hay una gran probabilidad de un desenlace fatal en ausencia de tratamiento.

El parásito evita el sistema inmunitario al permanecer intracelularmente en los hepatocitos y eritrocitos por enzimas existentes en la membrana celular eritrocitaria, aunque muchos eritrocitos parasitados se eliminan en el bazo. Para evitarlo, el parásito produce ciertas proteínas que se expresan en la superficie del eritrocito y causan su adherencia al endotelio vascular, especialmente en "Plasmodium falciparum": este es el factor principal de las complicaciones hemorrágicas de la malaria. Dichas proteínas son además altamente variables, y por lo tanto el sistema inmunitario no puede reconocerlas de forma efectiva, ya que cuando elabora un número de anticuerpos suficiente (al cabo de dos semanas o más), estos serán inútiles porque el antígeno ha cambiado.

El ciclo continúa cuando un mosquito ingiere sangre de un enfermo o portador, y con ello algunos gametocitos. En el intestino del mosquito estos se transforman en macrogametos (femeninos) y microgametos (masculinos), que se fusionan dando un cigoto móvil u oocineto. Este finalmente formará los esporozoítos que migran a las glándulas salivares del mosquito, completando el ciclo vital.

Las mujeres gestantes son especialmente atractivas para los mosquitos y la malaria en ellas es especialmente nefasta, dada la sensibilidad del feto (que no tiene un sistema inmunitario desarrollado) a la infección.

Se necesitan dos organismos anfitriones: mosquitos para las fases de reproducción sexual, y el ser humano y animales para la reproducción asexual. Existe una excepción con "Plasmodium vivax" y "Plasmodium ovale": cuando pica "Anopheles" se inyectan los esporozoitos, estos van al hígado, y algunos se quedan latentes en el interior de los hepatocitos y reciben el nombre de hipnozoítos. Hay un periodo de incubación largo, se reactivan, se replican y pueden dar clínica tras varios meses después.

"P. vivax", "P. ovale" y "P. malariae" causan anemia leve, bajos niveles de parasitemia, rotura esplénica y síndrome nefrótico. "P. falciparum" causa niveles elevados de parasitemia, insuficiencia renal, anemia grave, etc.

En España la malaria fue conocida casi siempre con el nombre de "tercianas" o "fiebre terciana" (de 3 días) benigna causada por el "Plasmodium vivax" y en menor grado la fiebre terciana maligna causada por el "Plasmodium falciparum" y la fiebre de cuatro días causada por el "Plasmodium malariae" fueron endémicas hasta la mitad del siglo XX. En 1943 se diagnosticaron unos 400 000 casos y se registraron 1307 muertes debidas a la malaria.

El último caso autóctono se registró en mayo de 1961. En 1964 España fue declarada libre de malaria y recibió el certificado oficial de erradicación.

Sin embargo, cada año se informa de casos procedentes principalmente de inmigrantes y turistas. El crecimiento del número de viajeros a países donde la malaria está presente y los viajes de inmigrantes donde la malaria es endémica aumentan los casos de malaria importada.

En 1967 hubo 21 casos, en 1995 hubo 263 y en 2004 hubo 351 casos.









</doc>
<doc id="41768" url="https://es.wikipedia.org/wiki?curid=41768" title="Hepatitis">
Hepatitis

La hepatitis es una enfermedad inflamatoria que afecta al hígado. Su causa puede ser infecciosa (viral, bacteriana, etc.), inmunitaria (por autoanticuerpos, hepatitis autoinmune) o tóxica (por ejemplo por alcohol, sustancia tóxicas o fármacos). También es considerada, dependiendo de su etiología, una enfermedad de transmisión sexual.

Hay virus específicos para la hepatitis (virus hepatotropos), es decir, aquellos que solo provocan hepatitis. Existen muchos virus: A, B, C, D, E, F y G. Los más importantes son los virus A, B, y C; en menor medida, el D y el E, siendo F y G los últimos descritos y los menos estudiados.

Otros virus no específicos son:

La hepatitis es una enfermedad de la que se conocen numerosas causas:





En circunstancias normales, no hay constancia de que ninguno de los virus de la hepatitis sea directamente citopático para los hepatocitos. Los datos disponibles sugieren que las manifestaciones clínicas y la evolución que siguen a la lesión hepática aguda propia de una hepatitis vírica son determinadas por las respuestas inmunitarias del paciente.

Todas las infecciones por virus de la hepatitis tienen un periodo de incubación largo:

Se transmite por vía entérica o fecal-oral (aguas residuales, alimentos o elementos lavados con estas aguas). Produce una enfermedad benigna y autolimitada, con un periodo de incubación de 2 a 6 semanas.

El HAV solo se reproduce en el hígado pero está presente además en bilis, heces y sangre al final del periodo de incubación. Su infecciosidad disminuye rápidamente una vez que la ictericia se hace evidente.
Sus síntomas son diarrea, dolor de estómago, pérdida de apetito, náuseas, cansancio y fiebre.

La hepatitis B es provocada por un virus de ADN que logra replicarse gracias a su ADN polimerasa con actividad adicional como transcriptasa inversa, y se transmite por vía parenteral. Se multiplica en el hígado pero puede estar presente fuera de él.
Sus partículas víricas son:




Tras la infección por el HBV el primer marcador que se encuentra en suero es el HBsAg, que se eleva antes de que la infección tenga expresión clínica (ictericia y otros síntomas) y disminuye y desaparece al cabo de 1 o 2 meses de la aparición de la ictericia, al tiempo que aumenta el anticuerpo contra el antígeno S (anti-HBs), que persiste indefinidamente y protege frente a la reinfección por el HBV.

Durante el intervalo en el que HBsAg está disminuyendo y el anti-HBs está aumentando, puede que las serologías den negativas por no alcanzar los umbrales necesarios para la detección. Este período se denomina "“ventana ciega”" y para no incurrir en un falso negativo podemos ayudarnos con la detección en suero del anticuerpo contra el HBcAg (IgM-antiHBc), que se eleva tras 1 o 2 semanas desde la aparición de HBsAg. Hay que tener en cuenta que no podemos encontrar en suero el propio antígeno HBcAg por carecer de péptido de señalización para hacerse soluble y estar por tanto integrado en la nucleocápside viral.

Hay que reseñar que gracias a la sensibilidad de las nuevas técnicas la ventana ciega se ha disminuido considerablemente.

El anti-HBc puede persistir en sangre más que el anti-HBs, una detección que solo muestra el anti-HBc como positivo no implica una replicación activa del virus, siendo lo más frecuente que sea un signo de una infección antigua por el HBV.

Para determinar si la infección es aguda o crónica se debe determinar el tipo de Ig del anticuerpo:
En cuanto al tercer marcador serológico, el HBeAg, aparece al mismo tiempo o poco después del HBsAg y cuando la actividad replicativa del virus es máxima. Disminuye poco después del aumento de actividad de las aminotransferasas y antes de que desaparezca HBsAg. Tras su desaparición comienzan a detectarse los anticuerpos anti HBeAg (anti-HBe).

La capacidad del paciente de dar una respuesta a la infección es la que produce el daño sobre el hígado. Hay personas que no se defienden bien del virus, no producen niveles efectivos de anticuerpos y mantienen los antígenos S como positivos durante mucho tiempo con transaminasas normales y casi sin sintomatología. Si albergan virus completos y no solo HBsAg, estos individuos son portadores asintomáticos capaces de contagiar la infección a otra persona.

Menos de un 5% de las hepatitis agudas por virus B llegan a cronificar.

La persona infectada con VHB puede sentirse como si tuviera gripe o no tener ningún síntoma. Con un análisis de sangre se puede saber si una persona tiene el virus. La VHB suele mejorar espontáneamente al cabo de algunos meses. Si no mejora, se denomina hepatitis B crónica, y dura toda la vida. La VHB crónica conduce a la cicatrización del hígado, insuficiencia hepática o cáncer de hígado.

Es un virus de RNA que se trasmite por vía parenteral. Expresa el antígeno HCAg (con mayúscula. No confundir con el HBcAg o antígeno core del virus B). Puede cronificar en aproximadamente el 80% de los casos.

Se ha demostrado la existencia de anticuerpos neutralizadores del HCV pero suelen ser de duración breve y no se ha comprobado que la infección por el HCV induzca inmunidad duradera frente a la reinfección. Estos anticuerpos se elevan durante la fase aguda y se detectan antes o después, dependiendo de la técnica empleada.

Para detectar el HCV se utiliza la detección del RNA del HCV por PCR. Detecta la presencia del RNA del virus C a pocos días de haber sufrido la exposición y mucho antes de que aumenten los niveles de anticuerpos anti-HCV.

No es un virus sino, un virusoide, (un tipo de virus satélite similar a un viroide que a diferencia de los virus no poseen proteínas ni lípidos, están formados por una cadena de ARN circular que no codifica proteínas). Se transmite por vía parenteral. Está totalmente ligado al HBV, de manera que ha aprendido a "esconderse" introduciendo su ARN circular dentro del Ag de superficie del HBV consiguiendo afectar de esta manera a los hepatocitos. Si HBV es negativo, HDV será también negativo. Por el contrario, si HBV resulta positivo, puede o no haber infección por HDV. Al depender por completo del HBV la duración de la infección por el virus D está completamente determinada por la del virus B, no pudiendo sobrepasarla.

Su nucleocápside expresa el antígeno D (HDAg), que es difícil de encontrar en suero. El anticuerpo neutralizador del HDAg se eleva de 30 a 40 días tras la aparición de los síntomas.

Pueden darse dos tipos de infección junto al HBV:


Es una infección producida por virus con RNA lineal y con trasmisión entérica (oral-fecal). Es una infección aguda que no cronifica. Se presenta en brotes epidémicos y es endémico en regiones de Asia, Oriente medio, norte de África y América Central. Actualmente existen evidencia de que es una zoonosis (se puede trasmitir de los animales a las personas). Su reservorio principal es el cerdo. Es una hepatitis mortal únicamente en mujeres embarazadas.
Se transmiten al igual que los HAV por vía enteral. Se detectan anticuerpos tipo IgM e IgG anti-HEV pero disminuyen muy rápido tras la infección aguda. No disponemos en clínica de marcadores serológicos. Como los HAV, nunca cronifican.

Diagnóstico de examen.

El virus de hepatitis G es un virus RNA de la familia flavivirus con una homología aminoacídica de 29% con el virus de hepatitis C. El virus G se transmite por vía parenteral, en forma similar a los virus de hepatitis B y C. Se diagnostica mediante la detección del RNA viral en suero. A pesar de su nombre, no hay clara evidencia de que este virus cause enfermedad hepática. Es posible que sea un agente asociado infrecuentemente a hepatitis aguda post-transfusional leve. No se ha demostrado asociación con hepatitis crónica, cirrosis hepática ni carcinoma hepatocelular.



Por tanto, ante un paciente con hepatitis aguda habrá que hacer una detallada historia de la ingesta de fármacos.

Entre los tóxicos se encuentran:

Anormalidad en el HLA tipo I de la superficie de los hepatocitos, o alteración en el sistema inmune post infecciones virales, pueden provocar una reacción autoinmune del tipo celular en contra del tejido hepático.

Las personas con hepatitis autoinmune con frecuencia padecen otras enfermedades autoinmunes asociadas, principalmente la enfermedad celíaca (que suele cursar con síntomas digestivos leves, intermitentes o incluso completamente ausentes), la diabetes tipo 1, la tiroiditis de Hashimoto y la enfermedad inflamatoria intestinal, entre otras.

Algunas alteraciones metabólicas pueden provocar daño por acumulación de sustancias a nivel de los diversos tejidos del organismo, entre ellos, el hígado. La hemocromatosis y la enfermedad de Wilson se caracterizan por provocar hepatitis.

La obstrucción prolongada por cálculos, cáncer o parásitos (fasciola hepática) puede provocar daño e inflamación a nivel del hígado.

Producido por la ingesta de alcohol. Resulta en el daño directo debido al estrés oxidativo a nivel de los hepatocitos. Su pronóstico es variable, yendo desde casos autolimitados hasta situaciones más severas.

La hepatitis isquémica es causada por la disminución en el flujo sanguíneo hacia los hepatocitos. usualmente es debido a la disminución en la presión sanguínea (shock) conocido también como shock hepático. Los pacientes con hepatitis isquémicas generalmente se encuentran en mal estado debido a la causa subyacente al shock (que puede ser de origen hepático, sangrado masivo o falla del corazón). Raramente, la hepatitis isquémica puede ser causada por problemas locales en los vasos sanguíneos (tales como trombosis o estenosis de la arteria hepática, la cual es la responsable de la llegada de los nutrientes al tejido hepático). En el perfil hepático se puede observar un aumento transitorio (hasta 10 días de duración) de las GOT y GPT, las cuales exceden los 1000 U/L. Es raro que exista insuficiencia hepática crónica secundaria a hepatitis isquémica.

En algunos casos, la deficiencia de alfa-1 antitripsina provoca acumulación de proteínas en el retículo endoplasmático provocando daño inflamatorio a nivel de los hepatocitos.

Hepatitis introducida en nuestro organismo, en la cual no interviene el consumo de alcohol.

Primera semana (periodo preictérico de síntomas prodrómicos). Este cuadro se presenta durante los primeros 5-6 días de la infección y en los que el paciente no suele estar diagnosticado:

A los 5-7 días:


Hepatitis anictérica: un 1% de los casos es una hepatitis anictérica que no presenta ictericia y debe diagnosticarse por la sintomatología inespecífica de anorexia y astenia junto con las pruebas complementarias.

Algunas hepatitis agudas pueden cronificarse, algunas menos frecuentemente pueden producir un Fallo Hepático Agudo o Masivo y otras evolucionan hacia la curación.

Fallo hepático agudo: en el que ocurren varios eventos. Uno de ellos es la disminución en la producción de albúmina y otras proteínas, lo que da lugar a una hipoalbuminemia, aunque se dé con más frecuencia en hepatitis crónicas y cirrosis.

Si aumenta la bilirrubina hasta cifras superiores a 3 mg (siendo lo normal 1 mg), los canalículos biliares se cerrarán y el drenaje se verá dificultado dando lugar a una hepatitis aguda colostática. Si la bilirrubina aumenta hasta 10-12 mg la ictericia será evidente.

Debido a la necrosis todos los pigmentos del hígado saldrán a sangre. También tendremos una alteración en la coagulación con un tiempo de protrombina alargado debido al déficit en la síntesis de los factores de coagulación.

Aparecen signos de encefalopatía hepática con inversión del ritmo del sueño (duerme de día y no por la noche), signos sutiles de pérdida de memoria, desorientación, temblor aleteante de fases distales o "flapping tremor", que puede desencadenarse en un paciente espontáneamente con una maniobra de hiperextensión. También da lugar a dismetrías, en el que el paciente está aparentemente normal pero le fallan los sistemas de coordinación. Se demuestra pidiendo al paciente que dibuje una estrella, obteniendo un dibujo amorfo como resultado.



Se incrementa también la fosfatasa alcalina por la colestasis por obstrucción biliar, aumenta la γ-glutamil-transpeptidasa (GGTP).

Las transaminasas nos dan una idea del alcance de la necrosis hepática, y por tanto de la hepatitis, mientras que otros parámetros señalan el estado de la función hepática.

Marcadores bioquímicos específicos: como la medida de la carga viral o de los anticuerpos generados por el organismo frente a ellos. Se detallarán en el estudio individual de cada tipo de virus.

El tratamiento principal es sintomático mientras que el específico dependerá de la causa subyacente. Es así como en las hepatitis virales agudas se utilizará medidas de soporte e hidratación, reservándose el uso de antivirales, hasta el momento se disponía casi exclusivamente de interferón y ribavirina, actualmente (desde el año 2011) existen ya aprobados inhibidores de polimerasa y proteasa para casos por Virus hepatitis C (principalmente por el gran porcentaje de pacientes que evolucionan a hepatitis crónica) mientras que en otros casos como por ejemplo, en la intoxicación por paracetamol se utiliza N-acetilcisteína.

En el caso de la hepatitis crónica que lleva a insuficiencia hepática, solamente se tratarán las complicaciones secundarias a ésta (hemorragia digestiva alta, ascitis, infecciones, etc.).




</doc>
<doc id="41774" url="https://es.wikipedia.org/wiki?curid=41774" title="Esternón">
Esternón

El hueso esternón () o quilla en algunos animales es un hueso del tórax, plano, impar, central y simétrico (por lo general), compuesto por varias piezas soldadas ("esternebras"). El esternón ayuda a proteger al corazón y los pulmones.

El esternón está formado por tres partes, el "mango" o "manubrio", el "cuerpo" y el "apófisis o proceso xifoides", que tiene una forma muy variable. El manubrio y el cuerpo se articulan en una sínfisis formando el llamado ángulo esternal (ángulo de Louis), la cual puede osificarse. El apéndice (o apófisis) xifoides tiene un tamaño indefinido (puede variar según la persona, la edad...) y experimenta una osificación a partir de los 40 años formándose una sínfisis donde antes había una sincondrosis esternoxifoidea. Tiene dos caras, la anterior y posterior; dos bordes laterales; y dos extremos, el superior o base y el inferior o vértice.

El esternón se encuentra en la parte media y anterior del tórax, se articula en su parte superior con las clavículas y en sus bordes laterales se articulan por una parte las costillas verdaderas mediante el cartílago esternocostoclavicular mientras que por otra se articulan las falsas mediante un solo cartílago, que se une a la 7ª, 8ª, 9ª y 10ª costilla.

La articulación del mango con el cuerpo es del tipo sínfisis y forma un ángulo bastante pronunciado (de 35° aproximadamente) llamado "ángulo de Louis" a la altura de la segunda costilla, la articulación más importante que realiza es con la primera costilla y con la clavícula formando el tipo de articulación denominada esternocostoclavicular que en huesos adultos puede llegar a osificarse y quedan totalmente unidas la primera costilla y el esternón, por lo tanto el mango posee dos superficies articulares para dichos huesos.

En la base se encuentra la escotadura esternal (o yugular), la cual funge como un borde libre. Es posible tocar este borde del esternón justo debajo de donde termina el cuello. A los lados se encuentran las escotaduras claviculares dónde se articulan las clavículas, una a cada lado.

En el cuerpo hay 3 estriaciones llamadas crestas que son una huella del periodo de osificación embrionario.

En cuanto a las diferencias de sexo el masculino suele ser más grande, alargado y estrecho.

Las escotaduras son los sitios de unión entre los cartílagos costales y el esternón.

Los cartílagos costales de las siete primeras costillas se unen con el esternón formando las articulaciones esternocostales. El cartílago costal de la segunda costilla se articula con el esternón en el ángulo esternal por lo que es fácil de localizar. La clavícula derecha se articula con la muesca esternal derecha y la clavícula izquierda se articulada con la muesca esternal izquierda , respectivamente.

Hay dos tipos de malformaciones en el esternón: pectus carinatum y pectus excavatum.

El esternón en la anatomía de los vertebrados, es un hueso plano que se encuentra en la parte media frontal de la caja torácica. Es de origen endocondral. Probablemente primero se desarrolló tempranamente en los tetrápodos como una extensión de la cintura escapular.; no se encuentra en los peces. En los anfibios y reptiles es típicamente una estructura en forma de escudo, a menudo compuesto enteramente de cartílago. Está ausente en las tortugas y serpientes. En las aves es un hueso relativamente grande y, por lo general, tiene la forma de una enorme quilla que sobresale, a la que están unidos los músculos utilizados en el vuelo. Solo en los mamíferos el esternón toma una forma alargada, y está segmentado como en los seres humanos.

En arácnidos, el esternón es la porción ventral (inferior) del cefalotórax. Consta de un esclerito, situado entre la coxa, frente al caparazón.



</doc>
<doc id="41776" url="https://es.wikipedia.org/wiki?curid=41776" title="Radio (hueso)">
Radio (hueso)

El radio ("radius") es un hueso situado en la parte lateral o externa del antebrazo, paralelo al cúbito. Por su morfología, se trata de un hueso largo, con forma de prisma y ligeramente curvo. Su extremo superior o proximal, más redondeado, conecta con la articulación del codo y el inferior o distal, más aplanado, con la articulación de la muñeca, en el lado más próximo al pulgar.

Presenta una curvatura externa generalmente poco pronunciada y otra interna de concavidad mirando al cúbito, mucho más acentuada. Tiene una forma prismática triangular, constando de tres caras y tres bordes:






En el extremo superior se observa una porción voluminosa y redondeada, llamada cabeza del radio ("caput radii"), con forma de cilindro. En la parte superior se presenta una depresión en forma de cúpula, llamada cavidad glenoidea del radio o fosita articular ("fovea articularis capitis radii") que se corresponde con el cóndilo del húmero y rodeada por una circunferencia articular ("circumferentia articularis"). La cabeza del radio es sostenida por una porción estrecha del hueso, el cuello del radio ("collum radii"). Debajo del cuello, en la parte anterointerna del hueso se levanta una eminencia ovoidea, en la cual se inserta el tendón inferior del bíceps: la tuberosidad bicipital del radio.

El extremo inferior o carpiano es la parte más voluminosa del hueso. Reviste en su conjunto la forma de una pirámide cuadrangular truncada y, por consiguiente, presenta seis caras: superior, inferior o carpiana, anterior, posterior, interna y posteroexterna.







El radio presta inserción a 12 músculos:

Cara anterior



Cara posterior




Cara externa



Apófisis estiloides del radio






</doc>
<doc id="41785" url="https://es.wikipedia.org/wiki?curid=41785" title="Hueso semilunar">
Hueso semilunar

El hueso semilunar es un hueso de la muñeca llamado así porque tiene la forma de media luna con la concavidad mirando hacia abajo. Es un hueso, par, corto, esponjoso, compacto, de forma cuboidea, semilunar, que parece una luna, con seis caras, de las cuales cuatro son articulares.

Las cuatro carillas articulares son:

De las dos carillas no articulares del semilunar, la "anterior" es convexa y la "posterior" plana. Una y otra son rugosas pero no se inserta en ellas ningún músculo.

Es el segundo hueso de la primera fila del carpo; se articula con el radio, escafoides, piramidal, ganchoso y grande.

"Este artículo incorpora material de la 6ª edición del Tratado de Anatomía Humana de L. Testut de 1912, que se encuentra en el dominio público."


</doc>
<doc id="41788" url="https://es.wikipedia.org/wiki?curid=41788" title="Antes de Cristo">
Antes de Cristo

El sintagma antes de Cristo, (abreviado normalmente como a. C. o a. de C.), se emplea para referirse y fechar los años y siglos anteriores a la era cristiana, que convencionalmente empieza con el nacimiento de Jesucristo.

Aunque existe controversia sobre el año de nacimiento de Jesucristo, esto no es importante para la utilización del término. Los pocos datos disponibles apuntan a que la fecha real podría estar situada entre el año 7 y el año 4 antes de Cristo.

Las abreviaturas creadas de acuerdo con las reglas de formación de abreviaturas son:


Se consideran incorrectas:

El adecuado empleo del punto abreviativo, el espacio y la mayúscula son muy importantes debido a que ayudan considerablemente a identificar las abreviaturas, y por consiguiente a diferenciarlas inequívocamente del resto de los métodos de abreviación, así como a distinguir y entender rápida y correctamente cada uno de sus elementos.

En esas fechas se utilizaba el sistema Ab urbe condita que fue posteriormente traducido al Calendario juliano proléptico. Cuando entró en vigor el calendario gregoriano las fechas anteriores a la entrada en vigor se mantuvieron como estaban. No obstante, puede ocurrir a veces que las fechas se traduzcan al Calendario gregoriano proléptico.




</doc>
<doc id="41791" url="https://es.wikipedia.org/wiki?curid=41791" title="Hueso nasal">
Hueso nasal

El hueso nasal ("hueso propio de la nariz") es un hueso de la cara, par, corto y compacto, en forma cuadrilátera, con dos caras (anterior y posterior) y cuatro bordes (superior, inferior, lateral o externo y medial o interno). Ambos huesos propios forman la raíz y el dorso o puente de la nariz. El borde medial de cada uno se articula con su homólogo, constituyendo la sutura internasal. El borde lateral (externo) se articula con la apófisis ascendente del maxilar superior. Su borde superior con el hueso frontal y su borde inferior con el cartílago nasal (o cartílago dorsal). Su cara interna se articula con la lámina perpendicular del etmoides, que forma parte del septo nasal.

Los huesos nasales se articulan con cuatro huesos: 

En primitivos peces óseos y tetrápodos, los huesos nasales son los más anterior de un conjunto de cuatro pares de huesos que forman la bóveda craneal, que son seguidos en secuencia por los frontales, los parietales, y los postparietales. Su forma en especies vivas es muy variable, dependiendo de la forma de la cabeza, pero generalmente forman el techo de la boca o del pico, que va desde las fosas nasales a una posición corta de las órbitas. En la mayoría de los animales, son generalmente, proporcionalmente mayor que en los seres humanos o los grandes simios, a causa de sus caras cortas. En las tortugas, inusualmente,los huesos nasales faltan, con los huesos prefrontales de la órbita de llegar hasta el final a las fosas nasales.


</doc>
<doc id="41800" url="https://es.wikipedia.org/wiki?curid=41800" title="Ciclón tropical">
Ciclón tropical

En meteorología, el término ciclón tropical se usa para referirse a un sistema tormentoso caracterizado por una circulación cerrada alrededor de un centro de baja presión que produce fuertes vientos y abundante lluvia. Los ciclones tropicales extraen su energía de la condensación de aire húmedo, produciendo fuertes vientos. Se distinguen de otras tormentas ciclónicas, como las bajas polares, por el mecanismo de calor que las alimenta, que las convierte en sistemas tormentosos de "núcleo cálido". Dependiendo de su fuerza un ciclón tropical puede llamarse depresión tropical, tormenta tropical, huracán y dependiendo de su localización se pueden llamar tifón (especialmente en las Islas Filipinas, Taiwán, China y Japón) o simplemente ciclón como en el Índico.

Su nombre se deriva de los trópicos y su naturaleza ciclónica. El término "tropical" se refiere tanto al origen geográfico de estos sistemas, que se forman casi exclusivamente en las regiones intertropicales del planeta, como a su formación en masas de aire tropical de origen marino. El término "ciclón" se refiere a la naturaleza ciclónica de las tormentas, con una rotación en el sentido contrario al de las agujas del reloj en el hemisferio norte y en el sentido de las agujas del reloj en el hemisferio sur.

Los ciclones se desarrollan sobre extensas superficies de agua cálida y cuando las condiciones atmosféricas alrededor de una débil perturbación en la atmósfera son favorables. A veces se forman cuando otros tipos de ciclones adquieren características tropicales.

Los ciclones tropicales son conducidos por vientos direccionales hacia la troposfera; si las condiciones continúan siendo favorables, la perturbación tropical se intensifica y puede llegar a desarrollarse un ojo, y pierden su fuerza cuando penetran en tierra o si las condiciones alrededor del sistema se deterioran este se disipa.

Los ciclones tropicales producen grandes daños en la zonas costeras mientras que regiones interiores y altas están relativamente a salvo de los daños, también producen lluvias torrenciales que a su vez pueden producir inundaciones y corrimientos de tierra y también provocan marejadas ciclónicas en áreas costeras y las cuales dependiendo de la geografía pueden producir inundaciones extensas a más de 40 km hacia el interior en llanuras litorales extensas y de pendiente escasa.

Aunque sus efectos en las poblaciones y barcos pueden ser catastróficos, los ciclones tropicales pueden reducir los efectos de una sequía. Además, transportan el calor de los trópicos a latitudes más templadas, lo que hace que sean un importante mecanismo de la circulación atmosférica global que mantiene en equilibrio la troposfera y mantiene relativamente estable y cálida la temperatura terrestre.

Los ciclones tropicales son áreas de baja presión atmosférica cerca de la superficie de la Tierra. Las presiones registradas en el centro de los ciclones tropicales están entre las más bajas registradas en la superficie terrestre al nivel del mar. Los ciclones tropicales se caracterizan y funcionan como núcleo cálido, que consiste en la expulsión de grandes cantidades de calor latente de vaporización que se eleva, lo que provoca la condensación del vapor de agua. Este calor se distribuye verticalmente alrededor del centro de la tormenta. Por ello, a cualquier altitud (excepto cerca de la superficie, donde la temperatura del agua determina la temperatura del aire) el centro del ciclón siempre es más cálido que su alrededor. Las principales partes de un ciclón son el ojo, la pared del ojo y las bandas lluviosas. Son como tornados pero en agua.

Todas las áreas de baja presión en superficie presentan una divergencia hacia arriba para formar una espiral nubosa de aire cálido que va ganando altura pero va perdiendo velocidad al expandirse. Debido a la rotación terrestre (que es el motor de lo que se conoce como efecto Coriolis) esta espiral ascendente gira en sentido anti horario en el hemisferio norte y horario en el hemisferio sur. Pero como las leyes físicas nos enseñan que a toda acción se opone una reacción de la misma intensidad pero de sentido contrario, la divergencia en altura de un ciclón tropical produce una convergencia en profundidad hacia la parte central del mismo que llega a la superficie con la máxima velocidad de giro al disminuir el radio de giro y concentrarse en un área reducida. Se trata del mismo proceso de aceleración que se produciría en un tobogán de las proporciones tan enormes de un ciclón tropical: el aire cálido de la banda nubosa ascendente forma una banda nubosa con el borde exterior situado a mayor altura que el interior. Así, los vientos que ascienden en las capas altas de un ciclón tropical se alejan del centro de la tormenta, pero empujan al aire frío localizado por encima de dicha banda nubosa hacia el centro del área ciclónica descendiendo por su mayor peso (aire frío más pesado) con una velocidad siempre creciente al reducirse su radio de giro con dicho descenso. En resumen, el modelo del proceso de formación de un ciclón es relativamente sencillo: se trata de dos espirales de rotación, una nubosa ascendente que se extiende hacia arriba y una superpuesta a la ascendente que desciende y se contrae hacia el centro. Lo que sucede es que la espiral descendente, como está formada por aire frío más pesado, no presenta nubes, intercalándose entre dos espirales ascendentes sucesivas. Cuando la espiral descendente llega al suelo en un tornado, se puede fotografiar desde el lado de mayor presión que es el que tiene menor nubosidad.

Para que los ciclones tropicales tengan esta característica de la producción de bandas de lluvia, es necesario que no exista una cizalladura vertical para mantener el núcleo cálido del centro de la tormenta.

Un ciclón tropical presenta un área de aire que circula en sentido descendente en el centro del mismo; si el área es lo suficientemente fuerte se puede desarrollar lo que se llama "ojo". Normalmente, en el ojo la temperatura es cálida y este se encuentra libre de nubes (sin embargo, el mar puede ser extremadamente violento). En el ojo del ciclón se registran las temperaturas más frías en superficie y las más cálidas en altura. Normalmente el ojo es de forma circular y puede variar desde los 3 a los 370 kilómetros de diámetro. En ocasiones, los ciclones tropicales maduros e intensos pueden presentar una curvatura hacia el interior en la parte superior de la pared del ojo, tomando un aspecto parecido al de un estadio de fútbol, por lo que a veces a este fenómeno se le denomina "efecto estadio".

Hay otros elementos que o bien rodean o bien cubren el ciclón. La nubosidad central densa ("Central Dense Overcast", CDO) es un área de densa actividad tormentosa cerca del centro del ciclón tropical; en ciclones débiles, la nubosidad central densa cubre el centro de circulación completamente, resultando en un ojo no visible. Contiene la pared del ojo y el ojo en sí mismo. El huracán clásico contiene una nubosidad central densa simétrica, lo cual significa que es perfectamente circular y redondo en todos sus lados.

La pared del ojo es una banda alrededor del ojo donde los vientos alcanzan las mayores velocidades, las nubes alcanzan la mayor altura y la precipitación es más intensa. El daño más grave debido a fuertes vientos ocurre mientras la pared del ojo de un huracán pasa sobre tierra. En los ciclones tropicales intensos hay un ciclo de reemplazo de la pared del ojo. Cuando los ciclones alcanzan un pico de intensidad, normalmente tienen una pared del ojo y un radio de las ráfagas de viento que contraen a un tamaño muy pequeño, alrededor de 10 o 25 kilómetros. Las bandas de lluvia externas se pueden organizar en un anillo de tormentas externo que se mueve lentamente hacia el interior y que roba la pared del ojo para captar su humedad y momento angular. Cuando la pared del ojo interno se debilita, el ciclón tropical también se debilita, los vientos más fuertes se debilitan y la presión en el centro aumenta. Al final del ciclo la pared del ojo externo reemplaza al interno completamente. La tormenta puede ser de la misma intensidad o incluso mayor una vez que el ciclo de reemplazo ha terminado. La tormenta vuelve a extenderse de nuevo y se forma un nuevo anillo externo para la nueva sustitución de la pared del ojo.

Una medida del tamaño de un ciclón tropical se obtiene midiendo la distancia desde su centro de circulación hasta la última isobara cerrada, también conocida como su "ROCI" (sigla que corresponde al inglés "Radius of Outermost Closed Isobar"). Si el radio es menor que dos grados de latitud o 222 kilómetros, entonces el ciclón se considera "muy pequeño" o "enano". Radios entre 3 y 6 grados de latitud o entre 333 y 666 kilómetros hacen que el ciclón sea considerado de "tamaño medio". Los ciclones "muy grandes" tienen radios mayores que 8 grados u 888 kilómetros. El uso de esta medida ha determinado que el tamaño medio de los ciclones tropicales del Noroeste del Pacífico es el mayor de todos, siendo aproximadamente el doble que el de los que se producen en el Atlántico. Otros métodos para determinar el tamaño de un ciclón tropical incluye la medida del radio de los vientos del vendaval y midiendo el radio al que su vorticidad relativa decrece a 1·10 s desde su centro.

Estructuralmente, un ciclón tropical es un gran sistema de nubes en rotación, viento y tormentas. Su fuente primaria de energía es la expulsión del calor de condensación del vapor de agua que se condensa a grandes altitudes, siendo el calor aportado por el Sol el que inicia el proceso de evaporación. Además, un ciclón tropical puede ser interpretado como una gigante máquina térmica vertical, mantenida por la mecánica y fuerzas físicas como la rotación y la gravedad terrestre.

En otro sentido, los ciclones tropicales pueden ser vistos como un tipo especial de complejo convectivo de mesoescala, que continúa desarrollándose a partir de una vasta fuente de humedad y calor. La condensación conduce a unas mayores velocidades del viento, ya que una pequeña fracción de la energía liberada se convierte en energía mecánica; los vientos más rápidos y presiones más bajas asociadas con ellos causan una mayor evaporación en superficie y de este modo incluso más evaporación. Mucha de la energía expulsada conduce las corrientes de aire, lo que aumenta la altura de las nubes, acelerando la condensación. Este bucle de retroalimentación positiva continúa mientras las condiciones sean favorables para el desarrollo del ciclón tropical. Factores como una ausencia continuada de equilibrio en la masa de distribución de aire también aportarían energía para mantener al ciclón. La rotación de la Tierra causa que el sistema gire, efecto conocido como el efecto Coriolis, dando una característica ciclónica y afectando a la trayectoria de la tormenta.

Lo que principalmente distingue a un ciclón tropical de otros fenómenos meteorológicos es la condensación como fuerza conductora. Dado que la convección es más fuerte en un clima tropical, esto define el dominio inicial del ciclón. Por contraste, frecuentemente los ciclones de media latitud obtienen su energía de los gradientes horizontales de temperatura preexistentes en la atmósfera. Para poder seguir alimentando su motor de calor, el ciclón tropical debe permanecer sobre agua cálida, que provee la humedad atmosférica necesaria. La evaporación se acelera por los vientos fuertes y se reduce por la presión atmosférica en la tormenta, resultando un bucle de alimentación positiva. Como consecuencia, cuando un ciclón tropical pasa sobre tierra su fuerza disminuye rápidamente.
Los niveles de ozono dan una pista sobre si una tormenta se desarrollará. El giro inicial de un ciclón tropical es débil y muchas veces cubierto por las nubes, y no siempre es fácil de detectar por los satélites que proveen imágenes de las nubes. Sin embargo, instrumentos como el "Total Ozone Mapping Spectrometer" pueden identificar cantidades de ozono que están relacionadas íntimamente con la formación, intensificación y movimiento de un ciclón. Como resultado, los niveles de ozono pueden ser muy útiles para determinar la ubicación del ojo. Las concentraciones naturales de ozono son más elevadas en la estratosfera. El aire más cercano a la superficie oceánica es menos rico en ozono. Rodeando al ojo, hay un anillo de potentes tormentas que absorben el aire húmedo y cálido de la superficie del océano, elevándolo kilómetros en la atmósfera, a veces hasta alcanzar la capa baja de la estratosfera. Este aire pobre en ozono reemplaza al aire rico en ozono provocando que las concentraciones en ozono disminuyan. El proceso se invierte a sí mismo en el ojo: el aire en altura se hunde hacia la superficie, infundiendo a la columna entera con ozono. Los niveles de ozono descendentes alrededor del ojo pueden ser una importante señal de que la tormenta se está fortaleciendo.
El paso de un ciclón tropical sobre el océano puede causar que las capas superficiales del mismo se enfríen de forma sustancial, lo que puede influir en el desarrollo del ciclón. Los ciclones tropicales enfrían el océano al actuar como "motores de calor" que transfieren el calor de la superficie del océano a la atmósfera a través de la evaporación. El enfriamiento también se produce por el ascenso de agua fría debido al efecto de succión del centro de bajas presiones de la tormenta. También puede existir un enfriamiento adicional como producto de las lluvias que pueden producirse en la superficie oceánica en un momento dado. La cobertura de nubes también puede desempeñar parte de esta función al actuar como escudo entre el océano y la luz directa del sol antes y algo después del paso de la tormenta. Todos estos efectos pueden combinarse para producir un descenso dramático de las temperaturas en un área considerable durante algunos días.

Los científicos del National Center for Atmospheric Research (EE. UU.) estiman que un huracán expulsa energía a razón de 50 a 200 trillones de vatios al día, aproximadamente la cantidad de energía liberada por la explosión de una bomba nuclear de 10 megatones cada 20 minutos, 70 veces la energía consumida por los humanos en todo el mundo o 200 veces la capacidad de producción de energía eléctrica de todo el mundo.

Mientras que el movimiento más evidente de las nubes es hacia el centro, los ciclones tropicales también desarrollan un flujo de nubes hacia el exterior a nivel superior (a gran altitud). Esto se origina del aire que ha liberado su humedad y es expulsado a gran altitud a través de la "chimenea" del motor de la tormenta. Este flujo produce cirros altos y delgados que giran en espiral lejos del centro. Los cirros pueden ser los primeros signos de que un huracán que se aproxima.

Hay siete regiones principales de formación de ciclones tropicales. Son el océano Atlántico, las zonas oriental, sur y occidental del océano Pacífico, así como el sudoeste, norte y sureste del océano Índico. A nivel mundial, cada año se forman una media de 80 ciclones tropicales.


Las siguientes áreas producen ciclones tropicales ocasionalmente.

La formación de ciclones tropicales es el tema de muchas investigaciones y todavía no se entiende perfectamente. Seis factores generales son necesarios para hacer posible la formación de ciclones tropicales, aunque ocasionalmente pueden desafiar a estos requisitos:


Solo ciertas perturbaciones atmosféricas pueden dar como resultando un ciclón tropical. Estas incluyen:


La mayoría de los ciclones tropicales se forman en una zona de actividad tormentosa llamada Discontinuidad Intertropical (ITF por su nombre en inglés), Zona de Convergencia Intertropical (ITCZ) o zona de bajas presiones del monzón. Otra fuente importante de inestabilidad atmosférica son las ondas tropicales, que causan sobre el 85 % de los ciclones tropicales intensos en el océano Atlántico, y la mayoría en la región del Pacífico este.

La mayoría de los ciclones tropicales se forman a una latitud entre 10 y 30º del ecuador, y un 87 % de los mismos se forman a menos de 20º de latitud, norte o sur. Debido a que el efecto Coriolis inicia y mantiene la rotación de los ciclones, estos raras veces se forman o se mueven hasta los 5º de latitud, donde el efecto Coriolis es muy débil. Sin embargo, es posible que se formen ciclones en esta región si hay otra fuente inicial de rotación; estas condiciones son extremadamente raras y se cree que tales tormentas se forman como mucho una vez cada siglo. Ejemplos de ciclones o tormentas tropicales en estas latitudes son la formación de la tormenta tropical Vamei en 2001 o el ciclón Agni en 2004.

A nivel mundial, los picos de actividad ciclónica tienen lugar hacia finales de verano, cuando la temperatura del agua es mayor. Sin embargo, cada región particular tiene su propio patrón de temporada. En una escala mundial, mayo es el mes menos activo, mientras que el más activo es septiembre.

En el Atlántico Norte, la temporada es diferente, teniendo lugar desde el 1 de junio al 30 de noviembre, alcanzando su mayor intensidad a finales de agosto y en septiembre. Estadísticamente, el pico de actividad de la temporada de huracanes en el Atlántico es el 10 de septiembre. El nordeste del océano Pacífico tiene un período de actividad más amplio, pero en un margen de tiempo similar al del Atlántico. El noroeste del Pacífico tiene ciclones tropicales durante todo el año, con un mínimo en febrero y marzo y un máximo de actividad a principios de septiembre. En la región del norte del Índico, las tormentas son más comunes desde abril a diciembre, con picos de intensidad en mayo y noviembre.

En el hemisferio sur, la actividad de ciclones tropicales comienza a finales de octubre y termina en mayo. El pico de actividad se registra desde mediados de febrero a principios de marzo.

Aunque los ciclones tropicales son grandes sistemas que generan una cantidad enorme de energía, su movimiento sobre la superficie se compara frecuentemente con el de las hojas arrastradas por una racha de viento. Es decir, los vientos de gran escala —las rachas en la atmósfera de la Tierra— son responsables del movimiento y manejo de los ciclones tropicales. La trayectoria del movimiento suele conocerse como "ruta" del ciclón tropical.

La mayor fuerza que afecta al recorrido de los sistemas tropicales en todas las áreas son los vientos que circulan en las zonas de alta presión. En el Atlántico Norte, los sistemas tropicales son llevados generalmente hacia el oeste, por los vientos que soplan de este a oeste al sur de las Bermudas, por la presencia de un área de alta presión persistente. También, en la región del Atlántico Norte donde se forman los huracanes, los vientos alisios, que son corrientes de viento principalmente con dirección oeste, llevan a las "ondas tropicales" (precursores de depresiones y ciclones tropicales) en esa dirección, desde la costa africana hacia el Caribe y Norteamérica.

La rotación de la Tierra también proporciona cierta aceleración (definida como "Aceleración de Coriolis" o efecto Coriolis). Esta aceleración provoca que los sistemas ciclónicos giren hacia los polos en ausencia de una corriente fuerte de giro (por ejemplo en el norte, la parte al norte del ciclón tiene vientos al oeste y la fuerza de Coriolis los empuja ligeramente en esa dirección. Así, los ciclones tropicales en el hemisferio norte, que habitualmente se mueven al oeste en sus inicios, giran al norte (y normalmente después son empujados al este), y los ciclones del hemisferio sur son desviados en esa dirección si no hay un sistema de fuertes presiones contrarrestando la aceleración de Coriolis. Esta aceleración también inicia la rotación ciclónica, pero no es la fuerza conductora que hace que aumente su velocidad. Estas velocidades se deben a la conservación del momento angular -el aire se capta en un área mucho más grande que el ciclón, por lo que la pequeña velocidad de rotación (originalmente proporcionada por la aceleración de Coriolis) aumenta rápidamente a medida que el aire entra en el centro de bajas presiones.

Finalmente, cuando un ciclón tropical se mueve en latitudes más altas, su recorrido general alrededor de un área de altas presiones puede desviarse significativamente por los vientos que se mueven en dirección a la zona de bajas presiones. Dicho cambio de dirección es conocido como "recurva". Un huracán moviéndose desde el Atlántico hacia el golfo de México, por ejemplo, recurvará al norte, y después al nordeste si encuentra vientos soplando en dirección nordeste hacia un sistema de bajas presiones sobre Norteamérica. Muchos ciclones tropicales a lo largo de la costa este de Norteamérica y en el golfo de México son llevados finalmente hacia el nordeste por las áreas de bajas presiones que se mueven sobre la misma.

Con su conocimiento sobre las fuerza que actúan en los ciclones tropicales y una gran cantidad de datos de satélites geosíncronos y otros sensores, los científicos han aumentado la fidelidad de las predicciones durante las décadas recientes, los ordenadores de alta capacidad de proceso y sofisticados programas de simulación permiten a los pronosticadores producir modelos numéricos que predicen los posibles recorridos de un ciclón tropical basándose en la posición futura y fuerza de los sistemas de altas y bajas presiones. Pero aunque los pronósticos son cada vez más exactos desde hace 20 años, los científicos aseguran que tienen muchos menos medios para predecir la intensidad. Lo atribuyen a la ausencia de mejoras en la predicción de intensidad debido a la complejidad de estos sistemas y a un entendimiento incompleto de los factores que afectan a su desarrollo.

Oficialmente, la "entrada en tierra" se produce cuando el centro de una tormenta (el centro del ojo, no su extremo), alcanza tierra. Naturalmente, las condiciones de tormenta pueden sentirse en la costa y en el interior mucho antes de la llegada. En realidad, para una tormenta moviéndose hacia el interior, las áreas de entrada en tierra experimentan la mitad de la misma antes de la llegada del centro del ojo. Para situaciones de emergencia, las acciones deberían programarse en relación a cuándo llegarán las rachas de viento más fuertes y no en relación a cuándo se produce la entrada.

Un ciclón tropical puede dejar de tener características tropicales de varias maneras:


Incluso después de que se diga que un ciclón tropical es extratropical o se ha disipado, puede tener todavía viento con una fuerza de tormenta tropical (u ocasionalmente fuerza de huracán) y descargar abundante lluvia. Cuando un ciclón tropical alcanza latitudes más altas o pasa sobre tierra puede unirse con un frente frío o desarrollarse a ciclón frontal, llamado también ciclón extratropical. En el océano Atlántico, estos ciclones pueden ser violentos e incluso conservar fuerza de huracán cuando alcanzan Europa como Tormentas de Viento Europeas.

En las décadas de 1960 y 1970, el gobierno de Estados Unidos intentó debilitar huracanes con su Proyecto Stormfury por medio del sembrado de tormentas seleccionadas con yoduro de plata. Se pensaba que el sembrado causaría que el agua superenfriada en las bandas de lluvia exteriores se congelasen, causando el colapso de la pared interior del ojo y, así, reducir los vientos. Los vientos del Huracán Debbie redujeron su fuerza un 30 por ciento, pero recuperaron su fuerza después de los dos intentos. En un episodio anterior, el desastre golpeó cuando un huracán, al este de Jacksonville, Florida, fue sembrado, cambiando repentinamente su curso y golpeando en Savannah, Georgia. Dado que había mucha incertidumbre sobre el comportamiento de estas tormentas, el gobierno federal no aprobaría las operaciones de "siembra" a menos que los huracanes tuvieran menos del 10 por ciento de posibilidades de hacer entrada en tierra en 48 horas. El proyecto fue cancelado después de que se descubriera que los ciclos de reemplazo del ojo ocurrían de forma natural en los huracanes fuertes, provocando dudas sobre los resultados de los experimentos anteriores. Hoy en día, se sabe que el yoduro de plata no tiene efecto porque la cantidad de agua fría en las bandas de lluvia de un ciclón tropical es demasiado baja.

A lo largo del tiempo se han sugerido otras aproximaciones, como enfriar el agua bajo un ciclón tropical remolcando icebergs a los océanos tropicales; tirando grandes cantidades de hielo en el ojo en las fases más tempranas, así el calor latente es absorbido por el hielo en la entrada (base del perímetro de la célula tormentosa) en vez de convertirse en energía cinética a grandes alturas; cubrir el océano con una sustancia que inhiba la evaporación; o golpeando el ciclón con armas nucleares (en esta última no se llevó a cabo porque la radiación sería esparcida rápidamente por el globo). Todas estas aproximaciones sufrieron el mismo problema: los ciclones tropicales son demasiado grandes para que cualquiera de ellas sea práctica.

Sin embargo, se ha sugerido que se puede cambiar el curso de una tormenta durante las primeras fases de su formación, tales como usando satélites para alterar las condiciones medioambientales, o, siendo más realistas, esparciendo una capa degradable de aceite sobre el océano que evitaría que el vapor de agua alimentase a la tormenta.

Los ciclones tropicales intensos son un desafío bastante particular para la observación. Al ser un peligroso fenómeno oceánico, las estaciones meteorológicas rara vez están disponibles en el lugar de la tormenta. Las observaciones a nivel de superficie solo se pueden realizar si la tormenta pasa sobre una isla o se sitúa en un área costera, o si, desafortunadamente, encuentra un barco en su camino. Incluso en estos casos, las mediciones en tiempo real solo son posibles en la periferia del ciclón, donde las condiciones son menos catastróficas.

Sin embargo es posible tomar mediciones "in situ", en tiempo real, enviando vuelos de reconocimiento especialmente equipados para introducirse en un ciclón. En la región atlántica, estos vuelos se realizan por medio de los Cazadores de huracanes del gobierno de Estados Unidos. Los aviones usados son el C-130 Hércules y el Orión WP-3D, ambos aviones de carga equipados con cuatro motores turbopropulsados. Estos aviones vuelan directamente en el ciclón y realizan mediciones directas y remotas. El avión también lanza sondas GPS en el ciclón. Miden temperatura, humedad, presión y especialmente, los vientos entre el nivel de vuelo y la superficie del océano.

En la observación de huracanes, ha comenzado una nueva era cuando una aerosonda pilotada remotamente fue lanzada al interior de la Tormenta Tropical Ophelia a su paso por la costa este de Virginia durante la temporada de huracanes en el Atlántico de 2005. Se ha convertido en una nueva forma de examinar tormentas en bajas latitudes, en las que los pilotos humanos raramente se atreven a internarse.

Los ciclones lejos de tierra son monitorizados por satélites meteorológicos que capturan imágenes visibles e infrarrojas desde el espacio, habitualmente en intervalos de quince a treinta minutos. Según se aproximan a tierra, pueden observarse desde superficie con un Radar Doppler. Los radares desempeñan un papel crucial alrededor de la entrada en tierra porque muestra la intensidad y ubicación de la tormenta minuto a minuto.

Recientemente, los investigadores académicos han comenzado a desplegar estaciones fortificadas para aguantar vientos huracanados. Los dos programas más grandes son el "Programa de Monitorización de la Costa de Florida" y el "Wind Engineering Mobile Instrumented Tower Experiment". Durante la entrada en tierra, la División de investigación de huracanes de la NOAA compara y verifica los datos del avión de reconocimiento, incluyendo datos como la velocidad del viento en la altura de vuelo y de las sondas GPS, con los datos sobre velocidad de vientos transmitida en tiempo real desde las estaciones atmosféricas erigidas a lo largo de la costa (además de otros datos relevantes para la investigación). El Centro Nacional de Huracanes usa los datos para evaluar las condiciones de entrada en tierra y verificar predicciones.

Los ciclones tropicales se clasifican de acuerdo a la fuerza de sus vientos, mediante la escala de huracanes de Saffir-Simpson. Basándose en esta escala, los huracanes "Categoría 1" serían los más débiles y los "Categoría 5" los más fuertes.

Para medir la intensidad del viento generalmente se usa la Escala de Beaufort, basada principalmente en el estado del mar, de sus olas y la fuerza del viento.

Las tormentas que alcanzan fuerza tropical reciben un nombre, para ayudar a la hora de formular demandas del seguro, ayudar a advertir a la gente de la llegada de una tormenta y además para indicar que se trata de fenómenos importantes que no deben ser ignorados. Estos nombres se toman de listas que varían de región a región y son renovadas cada pocos años. Las decisiones sobre dichas listas dependen de cada región, ya sea por comités de la Organización Meteorológica Mundial (a los que se llama normalmente para discutir muchos otros asuntos), o las oficinas meteorológicas involucradas en la predicción de tormentas.

Cada año, los nombres de tormentas que hayan sido especialmente destructivas (si ha habido alguna) son "retirados" y se eligen nuevos nombres para ocupar su lugar.

El IV Comité de Huracanes de la Asociación Regional de la OMM (Organización Meteorológica Mundial) selecciona los nombres para las tormentas de las regiones atlántica y pacífico central y este.

En el Atlántico, y Pacífico Norte y Este, los nombres masculinos y femeninos se asignan alternativamente en orden alfabético durante la temporada en curso. El "género" de la primera tormenta del año también alterna cada año: la primera tormenta de un año impar recibe nombre femenino, mientras que la primera de un año par, masculino. Se preparan con antelación seis listas de nombres y cada una se utiliza cada seis años. Se omiten las letras "Q", "U", "X", "Y" y "Z" — en el Atlántico; en el Pacífico solamente se omiten "Q" y "U" así el formato se acomoda a 21 o 24 tormentas "nombradas" en una temporada de huracanes. Los nombres de las tormentas pueden ser retirados tras la petición de los países afectados si han causado daños extensivos. Los países afectados deciden entonces un nombre de reemplazo del mismo género, y si es posible, de la misma etnia que el nombre que se retira.

Si hay más de 21 tormentas con nombre en la temporada atlántica, o más de 24 en la temporada del Pacífico Este, el resto de tormentas son nombradas usando las letras del alfabeto griego: la vigésimo segunda tormenta es llamada "Alfa", la vigésimo tercera, "Beta", y así sucesivamente. Fue necesario durante la temporada de 2005 cuando la lista se agotó. No hay precedente para una tormenta nombrada con una letra griega haya causado daño suficiente como para justificar su retirada, por lo que se desconoce cómo se manejará esta situación, con, por ejemplo, el Huracán Beta.

En la región del Pacífico Norte Central, los listados son mantenidos por el Centro de Huracanes del Pacífico Central en Honolulu. Se eligen cuatro listas de nombres en hawaiano y se usan de forma secuencial sin importar el año.

En el Pacífico Noroeste, las listas de nombres son mantenidas por el Comité de Tifones de la WMO. Se usan cinco listas de nombres, en la que cada una de las 14 naciones participantes aporta dos nombres a cada lista. Los nombres se usan según el orden de los países en inglés, secuencialmente, sin importar el año. Desde 1981, el sistema de numeración ha sido el sistema primario para identificar ciclones tropicales entre los miembros del Comité y todavía está en uso. Los números internacionales son asignados por la Agencia Meteorológica de Japón en el orden que se forma una tormenta tropical, mientras que también pueden asignarse otros números diferentes dependiendo de cada comité regional. El tifón "Songda" de septiembre de 2004, fue denominado internamente con el número 18 en Japón, y sin embargo en China fue con el 19. Internacionalmente, está registrado como el TY Sonda (0418), siendo "04" los dos últimos dígitos del año.

La Oficina de Meteorología Australiana mantiene tres listas de nombres, una para cada región (Oeste, Norte y Este). También existen listas para las regiones de Fiyi y Papúa Nueva Guinea.

El servicio meteorológico de las islas Seychelles mantiene una lista para el océano Índico Sudoeste. Allí, se usa una lista nueva cada año.

Durante varios cientos de años antes de la llegada de los europeos a las Indias, los huracanes eran nombrados según la festividad que se celebraba el día después en el que la tormenta golpeaba la región.

La práctica de dar nombres de personas fue introducida por Clement Lindley Wragge, un meteorólogo australiano a finales del siglo XIX. Usaba nombres de chicas, los nombres de los políticos que le habían ofendido o atacado, y nombre de la historia y la mitología.

Durante la Segunda Guerra Mundial, los ciclones tropicales solo recibían nombres femeninos, principalmente para ayudar a los pronosticadores, y en cierto modo, de una manera ad hoc. Adicionalmente, la novela escrita en 1941 por George R. Stewart "Storm" ayudó a popularizar el concepto de dar nombres a los ciclones tropicales

De 1950 a 1953, se usaron nombres del Alfabeto fonético aeronáutico. La convención moderna apareció como respuesta a la necesidad de realizar comunicaciones que no fuesen ambiguas entre barcos y aviones. Al aumentar el tráfico de transportes y las observaciones meteorológicas mejorar en número y calidad, varios tifones, huracanes o ciclones podían ser monitorizados al mismo tiempo. Para ayudar en su identificación, a principios de 1953 la práctica de nombrar sistemáticamente tormentas tropicales y huracanes fue iniciada por el Centro Nacional de Huracanes de Estados Unidos. Las nomenclaturas ahora son mantenidas por la Organización Meteorológica Mundial.

Para seguir con la costumbre del idioma inglés de referirse a objetos inanimados como bote, trenes, etc., usando el pronombre femenino "ella", los nombres usados eran exclusivamente femeninos. La primera tormenta del año era asignada con la letra "A", la segunda con la letra "B", etc. Sin embargo, dado que las tormentas tropicales y los huracanes son básicamente destructivos, algunas personas consideraron esta práctica como sexista. La Organización Meteorológica Mundial respondió a estas preocupaciones en 1979 con la introducción de nombres masculinos en la nomenclatura. También ese mismo año se inició la práctica de preparar listas de nombres antes del inicio de la temporada. Los nombres, son usualmente de origen inglés, francés o español en la región atlántica, dado que estos tres idiomas son los predominantes en la región donde las tormentas se forman habitualmente. En el hemisferio sur, los nombres masculinos hicieron su entrada en 1975.

En muchos casos, un ciclón tropical retiene su nombre durante toda su vida. Sin embargo, puede ser renombrado en varias ocasiones.


Un ciclón tropical maduro puede expulsar calor a razón de hasta 6x10 vatios. Los ciclones tropicales en el mar abierto causan grandes olas, lluvias torrenciales y fuertes vientos, rompiendo la navegación internacional y, en ocasiones, hundiendo barcos. Sin embargo, los efectos más devastadores de un ciclón tropical ocurren cuando cruzan las líneas costeras, haciendo entrada en tierra. Un ciclón tropical moviéndose sobre tierra puede hacer daño directo de cuatro maneras:


Frecuentemente, los efectos secundarios de un ciclón tropical son igualmente dañinos. Estos incluyen:


Aunque los ciclones pueden causar una gran cantidad de pérdidas humanas y materiales, pueden ser determinantes en los regímenes de precipitación de los lugares en los que impactan, y llevar lluvias muy necesarias a zonas que de otro modo serían desérticas. Los huracanes que se forman en el Pacífico Norte este, habitualmente aportan humedad a la región sudeste de Estados Unidos y partes de México. Japón recibe más de la mitad de sus precipitaciones anuales directamente de los tifones. El Huracán Camille evitó condiciones de sequía y terminó con el déficit de agua en gran parte de su recorrido.

Adicionalmente, la destrucción causada por Camille en la costa del Golfo estimuló el redesarrollo, incrementando sensiblemente el valor de la propiedad local. Por otro lado, el personal oficial encargado de responder en situaciones de catástrofe, aseguran que el redesarrollo motiva a la gente a no vivir en lugares que son claramente peligrosas en futuras tormentas. El Huracán Katrina es el ejemplo más obvio, ya que devastó la región que había sido revitalizada por Camile. Por supuesto, muchos residentes y negociantes han relocalizado sus negocios tierra adentro, lejos de la amenaza de futuros huracanes.

Los huracanes también ayudan a mantener el balance global de calor, desplazando calor y aire húmedo tropical a las latitudes medias y regiones polares. James Lovelock también ha realizado la hipótesis por la que, aumentando los nutrientes de la flora marina a los niveles de más cercanos a la superficie del océano, incrementarían también la actividad biológica en áreas donde la vida sería difícil por la pérdida de nutrientes según la profundidad del océano.

En el mar, los ciclones tropicales pueden revolver el agua, dejando una estela fresca a su paso, lo que provoca que la región sea menos favorable para un subsecuente ciclón tropical. En raras ocasiones, los ciclones tropicales pueden hacer lo contrario. En 2005, el Huracán Dennis arrastró agua cálida a su paso, contribuyendo a la formación del Huracán Emily, siendo así el primer precedente de formación de un huracán que posteriormente alcanzaría Categoría 5.

Si bien el número de tormentas en el Atlántico ha aumentado desde 1995, no parece haber señales de una tendencia a aumentar en el cómputo global; el número anual para todo el mundo, se sitúa en unos 90 ciclones tropicales.

Las tormentas atlánticas, se están volviendo más destructivas a nivel financiero, ya que, cinco de las diez tormentas más "caras" en Estados Unidos han ocurrido desde 1990. Esto puede atribuirse, en gran parte, al número de personas residentes en áreas costeras susceptibles, y al desarrollo masivo experimentado en la región desde la última oleada violenta de actividad en la década de los 60.

Frecuentemente, en parte por las amenazas de huracanes, muchas regiones costeras tenían una población escasa en los puertos más importantes, hasta la llegada del automóvil de clase turista, por lo tanto, las porciones más duras de tormentas golpeando la costa eran frecuentemente desmedidas. Los efectos combinados de la destrucción de barcos y las entradas en tierra lejos de núcleos urbanos limitaban severamente el número de huracanes intensos en el registro oficial antes de la era del avión de reconocimiento y la meteorología por satélite. Aunque el registro muestra un aumento distinto en el número y fuerza de huracanes intensos, por lo que los expertos analizan los datos anteriores sin tomarlos como certeza.

El número y fuerza de huracanes en el Atlántico puede experimentar un ciclo de 50 a 70 años. Aunque es más común desde 1995, entre 1970 y 1994 ocurrieron algunas temporadas cuya actividad fue superior a la media. Los huracanes más destructivos golpearon de forma frecuente entre 1926-60, incluyendo muchos "major hurricanes" en Nueva Inglaterra. En 1933 se registró un récord de 21 tormentas tropicales, que solo ha sido superado por la temporada de 2005. En las temporadas de 1900 a 1925, la formación de huracanes tropicales fue bastante infrecuente; sin embargo, muchas tormentas intensas se formaron entre 1870-1899. Durante la temporada de 1887, se formaron 19 tormentas tropicales, de las cuales 4 ocurrieron después del 1 de noviembre y 11 se convirtieron en huracanes. Entre los años 1840 a 1860 de nuevo se formaron pocos, pero muchos golpearon las costas a principios de 1800, incluyendo una tormenta en 1821 que entró directamente en Nueva York, y de la cual, algunos expertos meteorólogos, aseguran pudo tratarse de un huracán de categoría 4.

Estas temporadas de huracanes inusualmente activas, literalmente devoraron la cobertura de los satélites en la región atlántica, lo que permite a los pronosticadores ver todos los ciclones tropicales. Antes de que la era de los satélites comenzase en 1961, las tormentas o huracanes tropicales solo podían ser detectadas si un barco se encontraba con esos fenómenos de forma directa. El registro oficial, por lo tanto, seguramente carece de muchas tormentas en las que ningún barco experimentó vientos de galerna o huracanados, o bien no las reconocieron como tormentas tropicales (probablemente siendo comparados a un ciclón extra tropical a altas latitudes, una onda tropical o un breve chubasco), y al volver al puerto, no eran reportados.

Una pregunta frecuente es si el calentamiento global puede causar ciclones tropicales más frecuentes y violentos. Hasta ahora todos los climatólogos parecen estar de acuerdo en que una sola tormenta, o incluso una sola temporada, no puede ser atribuida a una única causa como el calentamiento global o incluso una variación natural. La pregunta es si existe una tendencia estadística que indique un aumento en la fuerza o frecuencia de los ciclones. La Administración Nacional Oceánica y Atmosférica de Estados Unidos dice en su guía de preguntas frecuentes sobre huracanes que "es altamente inverosímil que el calentamiento global pueda (o podrá) contribuir a un cambio drástico en el número o intensidad de los huracanes".

Respecto a la fuerza, hasta hace poco se había alcanzado una conclusión similar por consenso. Este consenso fue cuestionado por Kerry Emanuel. En un Artículo en "Nature", Emanuel afirmó que el potencial de destrucción de los huracanes, que combina fuerza, duración y frecuencia de los mismos "está altamente correlacionado con la temperatura del mar, reflejando señales climáticas bien documentadas, incluyendo oscilaciones multidecadales en el Atlántico Norte y Pacífico Norte y el calentamiento global". K. Emanuel además, predijo "un sustancial aumento en las pérdidas relacionadas con huracanes en el siglo veintiuno".

En términos similares, P.J. Webster y otras personas, publicaron un artículo en "Science" examinando "cambios en el número de ciclones tropicales, duración e intensidad" durante los últimos 35 años, un período para el que se disponen de datos por satélite. El hallazgo principal fue que mientras el número de ciclones "disminuyó en todas las regiones excepto el Atlántico Norte durante la última década", hubo un "gran incremento en el número y proporción de huracanes alcanzando categorías 4 y 5." Esto significa, que si bien el número general de ciclones había disminuido, el número de tormentas muy fuertes había aumentado.

Tanto Emanuel como Webster y otros, consideran que la temperatura del mar es una clave importante en el desarrollo de los ciclones. Es inevitable formularse la pregunta: ¿qué ha causado el aumento observado en las temperaturas de la superficie del mar? En el Atlántico, podría ser debido a la Oscilación Atlántica Multidecadal (AMO), un patrón de 50–70 años de variabilidad en la temperatura. Emanuel, sin embargo, descubrió que el aumento reciente estaba fuera del rango de las oscilaciones previas. Por lo tanto, tanto una variación natural (como la AMO) y el calentamiento global, podrían haber contribuido al calentamiento del Atlántico tropical durante las últimas décadas, pero por ahora, es imposible hacer una atribución exacta a cada apartado.

Mientras Emanuel analizaba la energía disipada anualmente, Webster y su grupo analizaban el, algo menos importante, porcentaje de huracanes en categorías 4 y 5, y descubrieron que este porcentaje había aumentado en 5 de las 6 regiones: Atlántico Norte, Pacífico Nordeste y Noreste, Pacífico Sur e Índico Norte y Sur. Dado que cada región podría estar sujeta a oscilaciones locales similares a la AMO, cualquier estadística individual para una región queda en el aire. Pero si las oscilaciones locales no están sincronizadas por alguna oscilación global no identificada todavía, la independencia de las regiones permite las pruebas estadísticas comunes que son mucho más concretas que cualquier prueba regional. Desgraciadamente, Webster no hizo dicha prueba.

Bajo la presunción de que las seis regiones son estadísticamente independientes para el efecto del calentamiento global, se realizó el t-test y se encontró que la hipótesis nula de que el calentamiento global no haya impactado en el porcentaje de huracanes de categoría 4 y 5, puede ser rechazada en un nivel de un 0,1%. Por lo tanto, solo hay una oportunidad entre mil de encontrar simultáneamente los seis aumentos observados en los porcentajes de huracanes de dichas categorías. Esta estadística necesita cierto ajuste, porque las variables a prueba no están distribuidas en variaciones iguales, pero puede dar incluso mejores evidencias de que se haya detectado el impacto del calentamiento global en la intensidad de los huracanes.

Los ciclones tropicales que causan destrucción masiva son, afortunadamente, raros, pero cuando suceden pueden causar daño en un rango de miles de millones de dólares y destrozar o acabar con miles de vidas.

El Ciclón Bhola, el más mortífero registrado, golpeó la zona altamente poblada del Delta del Ganges en el Pakistán Oriental (ahora Bangladés) el 13 de noviembre de 1970, como un ciclón tropical de Categoría 3. Se estima que acabó con la vida de 500.000 personas. La región del Índico Norte ha sido históricamente la más mortífera, con varias tormentas desde 1900 provocando más de 100.000 muertes, todas en Bangladesh

En la región atlántica, al menos tres tormentas han matado a más de 10.000 personas. El Huracán Mitch durante la Temporada de huracanes en el Atlántico de 1998 provocó severas inundaciones y deslizamientos de barro en Honduras, matando a 18.000 personas y cambiando tanto el aspecto del terreno que fue preciso realizar nuevos mapas del país. El Huracán de Galveston de 1900, que hizo entrada en tierra en Galveston (Texas) con una estimación de Categoría 4, y sin ningún aviso previo, acabó con la vida de 8.000 a 12.000 personas, cambió definitivamente la ciudad, que nunca volvió a ser lo que había sido antes, y sigue siendo el desastre natural más mortífero en la historia de Estados Unidos. La tormenta más mortífera registrada en el Atlántico fue el Gran Huracán de 1780, que mató a 22.000 personas en las Antillas.

La tormenta más intensa registrada fue el Tifón Tip en el Pacífico Nordeste en 1979, que alcanzó una presión mínima de tan solo 870 mbar y vientos máximos sostenidos de 305 km/h. Se debilitó antes de golpear en Japón. Tip no tiene en exclusiva el récord de vientos más rápidos registrados en un ciclón; El Huracán Wilma lo ostenta con velocidades de 320 km/h, durante la temporada de 2005 en el océano Atlántico. Aunque las velocidades registradas no se consideran totalmente ciertas, ya que los equipos suelen terminar destruidos en condiciones tan extremas, el huracán Camille fue la única tormenta que entró en tierra con tal intensidad, convirtiéndola, con 305 km/h como velocidad de vientos sostenidos y rachas de hasta 335 km/h, el ciclón tropical más fuerte al hacer entrada en tierra. En comparación, estas velocidades pueden encontrarse en el centro de un tornado intenso, pero Camille, como todos los ciclones tropicales, fue mucho más larga que cualquiera de los tornados más duraderos.

El Tifón Nancy en 1961 tenía un récord con vientos de hasta 345 km/h, pero investigaciones recientes indican que las velocidades medidas entre 1940 y 1960 eran más elevadas de lo que en realidad debían ser, y por tanto no se considera la tormenta con vientos más potentes registrados. De forma similar, una racha de viento medida a nivel de superficie, causada por el Tifón Paka en Guam con una intensidad de 380 km/h, que había sido confirmada, y hubiera sido la racha de viento no tornádica más fuerte registrada en la superficie de la Tierra, tuvo que ser rechazada ya que el anemómetro fue dañado por la tormenta.

Tip es también el ciclón más grande registrado, con una circulación de vientos de fuerza tropical en un campo de 1100 km de radio. El tamaño medio de un ciclón tropical es de "solo" 500 km. La tormenta más pequeña registrada fue la Tormenta tropical Marco en 2008, con tan solo 19 km de radio, que tocó tierra cerca de Veracruz en México.

El Huracán Iniki en 1992 fue la tormenta más poderosa que golpeó Hawái en los registros históricos, entrando en Kauai como huracán de categoría 4, matando a seis personas y causando tres mil millones de dólares en daños. Otros huracanes destructivos en el Pacífico son el Huracán Pauline y el Huracán Kenna.
El 26 de marzo de 2004, el Ciclón Catarina se convirtió en el primer huracán del Atlántico Sur. Otros ciclones anteriores en esa misma región, en 1991 y 2004 alcanzaron solo fuerza de tormenta tropical. Es altamente posible que antes de 1960 se formasen ciclones tropicales allí, pero no fueron observados hasta el comienzo de la era de los satélites atmosféricos en aquel año.

Un ciclón tropical no necesita ser especialmente fuerte para causar un daño difícil de olvidar. La Tormenta Tropical Thelma, en noviembre de 1991, mató a miles de personas en Filipinas y nunca llegó a ser tifón; el daño de Thelma se debió principalmente a las inundaciones y no a los vientos o marejada ciclónica. En 1982 la depresión tropical sin nombre, que posteriormente se convertiría en el Huracán Paul, causó la muerte de unas 1.000 personas en América Central debido al efecto de sus lluvias torrenciales.

El 29 de agosto de 2005 el Huracán Katrina hizo entrada en tierra en Luisiana y Misisipi. El Centro Nacional de Huracanes de EE.UU., en su revisión de agosto de la temporada de tormentas tropicales, aseguró que Katrina era, probablemente, el peor desastre natural en la historia del país. Actualmente se le asignan 1.604 muertes, principalmente de las inundaciones y consecuencias en Nueva Orleans, Luisiana. También se estima que causó daños por un valor de 75 mil millones de dólares. Antes del Katrina, el sistema más costoso en términos monetarios fue el Huracán Andrew en 1992 que causó unas pérdidas estimadas de 39 mil millones por los daños ocasionados en Florida.

El 23 de octubre de 2015 en el Océano Pacífico, cerca a la costa pacífica de México, el huracán Patricia alcanzó el récord de vientos sostenidos, alcanzando la velocidad de 325 km/h y ráfagas de hasta 400 km/h.

El 13 de agosto, el Centro Nacional de Huracanes (NHC) comenzó a supervisar una onda tropical en la costa occidental de África, la misma fue cobrando fuerza hasta alcanzar la categoría 4 y tras su paso por el Caribe empezó a debilitarse; hacia el 25 de agosto al entrar a territorio de Estados Unidos como había pronosticado el Centro Nacional de Huracanes, el Huracán Harvey tocó tierra en la costa de Texas con una fuerza de categoría 4 en la Escala de huracanes de Saffir-Simpson; el más violento de los últimos doce años que ha provocado intensas precipitaciones y vientos de más de 200 km por hora, y ha dejado perdidas estimadas –incluyendo daños materiales, salarios perdidos y negocios interrumpidos– alrededor de los 75.000 millones de dólares, sin embargo un cálculo de la firma de pronósticos meteorológicos AccuWeather dice que el total de pérdidas ocasionadas por Harvey podría llegar a 160.000 millones de dólares, lo que sobrepasaría los 118.000 millones que se estima se perdieron por el huracán Katrina. 

Los términos usados en los reportes meteorológicos para ciclones tropicales que tienen vientos en superficie iguales o superiores a 64 nudos o 32 m/s varían según la región:


Hay muchos otros nombres para los ciclones tropicales, incluyendo "bagyo", "baguió" o "baguio" en Filipinas, Willy-willy en el noroeste de Australia y "Taíno" en Haití.

La palabra "tifón" tiene dos posibles orígenes:

El término portugués tufão también está relacionado con tifón.

La palabra "huracán" es una voz taína, que proviene del nombre de la deidad de las tormentas. Erróneamente, algunos argumentan que esta voz fue incorporada de la lengua maya, sin embargo, se debe recordar que los españoles vivieron 30 años en La Española antes de llegar a México, y que durante este tiempo se registraron varios huracanes, destacándose los de junio de 1494, el del 3 de agosto de 1508, y otro del 10 de julio de 1509.

La palabra ciclón fue acuñada por el capitán Henry Piddington, quien la usaba para referirse a una tormenta que hizo añicos un carguero en Isla Mauricio en febrero de 1845.

Además de los ciclones tropicales, en la naturaleza hay otras dos clases de ciclones. Estos tipos de ciclones, conocidos como ciclones extratropicales y ciclones subtropicales, pueden ser etapas por las que un ciclón tropical pasa durante su formación o disipación.

Un ciclón extratropical es una tormenta que obtiene su energía de la diferencia de temperaturas en horizontal, lo cual es típico en latitudes más altas. Un ciclón tropical puede convertirse en extratropical según se mueve hacia latitudes más altas y su fuente de energía cambia del calor liberado por la condensación a las diferencias de temperatura entre masas de aire; además, aunque no es muy frecuente, un ciclón extratropical puede transformarse en una tormenta subtropical, y de ahí en un ciclón tropical, como ocurrió en el caso del Huracán Sandy. Desde el espacio se observa que las tormentas extratropicales tienen un patrón de nubes en forma de coma muy característico. Los ciclones extratropicales también pueden ser peligrosos cuando sus centros de bajas presiones producen fuertes vientos y mar alta.

Un ciclón subtropical es un sistema atmosférico que tiene ciertas características de un ciclón tropical y otras de un ciclón extratropical. Los ciclones subtropicales pueden aparecer en una amplia banda de latitudes, desde la Línea ecuatorial al paralelo 50°. Aunque las tormentas subtropicales rara vez atraen vientos de fuerza huracanada, pueden volverse tropicales según su núcleo se calienta. Desde un punto de vista operacional, no se considera que un ciclón tropical pueda convertirse en subtropical durante su transición extratropical.

En la cultura popular, los ciclones tropicales han aparecido en numerosos medios, como en el cine, la literatura, la televisión, la música o los videojuegos. Se han usado ciclones tropicales ficticios o basados en hechos reales. Por ejemplo, se cree que la novela de George R. Stewart, "Tormenta", publicada en 1941, ha tenido influencia a la hora de dar nombres femeninos a los ciclones tropicales del océano Pacífico. Otro ejemplo es el huracán de la película "La tormenta perfecta", que describe el hundimiento del pesquero Andrea Gail a causa de la Tempestad del Noreste de Halloween de 1991. También han aparecido huracanes en capítulos de series televisivas como "Los Simpson", "Invasión", "Padre de familia", "Seinfeld", "" y "Dawson's Creek". La película de 2004, "The Day After Tomorrow" incluye varias menciones a ciclones tropicales. El thriller histórico "Los hijos de la Diosa Huracán", (Grijalbo-Random House 2019), de la escritora Daína Chaviano, utiliza la existencia climática y mitológica de este fenómeno como hilo conductor de un argumento donde el huracán deviene presencia simbólica y alegórica del caos social y político que ha azotado a un país desde sus orígenes. 







</doc>
<doc id="41804" url="https://es.wikipedia.org/wiki?curid=41804" title="Gas mostaza">
Gas mostaza

Los gases mostaza son una familia de productos químicos empleados fundamentalmente como armas químicas, también conocidos como "iperita", de Ypres, ciudad belga donde los alemanes lo usaron por primera vez en 1915 durante la Primera Guerra Mundial. El gas mostaza fue sintetizado para acosar e incapacitar al enemigo y contaminar el campo de batalla. Viktor Meyer describe su síntesis a mediados de 1800, pero no fue quien lo descubrió, ni el primero en dar cuenta de sus efectos. El desarrollo de la producción de gas mostaza a gran escala se debe al químico alemán Wilhelm Steinkopf.

También se les denomina "agentes vesicantes", pues al contacto con el ser humano causan ampollas en la piel y las membranas mucosas, lo cual suele conllevar consecuencias como la muerte por asfixia agónica.

La mostaza sulfurada (bis(2-cloroetil)sulfano) es un tipo de agente químico utilizado como arma de guerra. La mostaza sulfurada también se conoce como gas mostaza o "agente mostaza” o por sus denominaciones militares H, HD y HT.

Suele manifestarse en fase gaseosa, pero también puede darse como líquido (de textura oleosa), o sólido. Como gas, algunas veces posee un olor parecido al ajo, a la cebolla o a la mostaza, y en otros casos no tiene olor. Como líquido y sólido, su color varía del amarillo claro al marrón. En todo caso, no se encuentra naturalmente en el ambiente.

Como arma de guerra, la mostaza sulfurada se utilizó por primera vez durante la Primera Guerra Mundial. Aunque en la actualidad no se destina a uso médico, hasta hace algunos años se utilizaba para el tratamiento de la psoriasis, una enfermedad cutánea.

Las mostazas nitrogenadas (bis-2-cloroetilaminas o β-haloalquilaminas) fueron producidas en los años 1920 y 1930, también como armas químicas de guerra. Fueron el primer caso registrado de uso de armas químicas contra población civil, pues en 1924, durante la Guerra del Rif (1921-1927), la aviación española arrojó bombas de gas mostaza, fosgeno y otros gases tóxicos, sobre los habitantes bereberes rifeños y sus aldeas. Son potentes irritantes que dañan la piel, ojos y vías respiratorias, entran en las células del cuerpo muy rápidamente y dañan el sistema inmunológico y la médula ósea.

En fase gaseosa puede oler a pescado, moho, jabón o frutas. Por debajo de 21 °C pasa a fase líquida, donde adopta un color claro, ámbar pálido o amarillo, y textura oleosa, y es inofensivo. Debido a ello, durante los inviernos de la Gran Guerra, los alemanes lanzaban proyectiles con mostaza nitrogenada líquida que, al caer sobre el campo de batalla, impregnaban a algunos soldados enemigos. Estos, desconocedores del peligro latente, se guarecían en las galerías y conductos de las trincheras donde, al evaporarse el agente químico, causaba la muerte a todo el que no escapase a tiempo al exterior. De forma natural no se encuentran en el ambiente.

También se conocen por sus denominaciones militares HN-1, HN-2 y HN-3.

Fueron los primeros agentes alquilantes con aplicación terapéutica. Se usan principalmente como antineoplásicos.

Las mostazas nitrogenadas son compuestos muy reactivos debido a que el nitrógeno, con su par de electrones no compartido, puede formar sales de aziridinio. Estas sales son especies fuertemente electrófilas que reaccionan con nucleófilos formando un enlace covalente. Debido a su estructura (bis-2-cloroetilaminas), cada molécula podrá dar lugar a dos enlaces covalentes.

Pueden reaccionar con el ADN ya que a que es rico en centros nucleofílicos, especialmente el átomo de nitrógeno de la posición 7 de la guanina. Constituye uno de los grupos más reactivos frente a electrófilos.

El fundamento químico de la alteración de la estructura del ADN por las β-haloalquilaminas se basa en la formación de enlaces covalentes cruzados con un resto de guanina de cada una de las hebras de ADN, produciéndose la distorsión correspondiente

HN- 1 fue diseñado originalmente para eliminar las verrugas, pero más tarde se identificó como un agente potencial de guerra química.

HN- 2 fue diseñado como un agente militar pero más tarde fue utilizado en el tratamiento del cáncer. Hoy en día ha sido reemplazado por otros agentes para el tratamiento del cáncer.

HN- 3 fue diseñado únicamente como un agente militar.

<nowiki>*</nowiki>Debido a que es más pesado que el aire, el vapor de la mostaza nitrogenada se asientan en las zonas bajas.

Tabla 1: vías de intoxicación en función del medio por mostazas nitrogenadas.

Los efectos para la salud causados por las mostazas nitrogenadas dependen de la cantidad a la que están expuestas las personas, la forma y el tiempo de exposición.

Por lo general, los signos y síntomas de la exposición no se producen inmediatamente. Dependiendo de la severidad de la exposición, los síntomas pueden aparecer tras varias horas.

Pueden producir los siguientes efectos en partes específicas del cuerpo:

La presencia de estos signos y síntomas no indica necesariamente que una persona haya estado expuesta a una mostaza nitrogenada.

La exposición a la mostaza nitrogenadas puede producir:
A partir de tercer/quinto día pueden aparecer síntomas de supresión de la médula ósea que desencadenan anemia, sangrado y un mayor riesgo de infección. En las situaciones más graves podrían llegar a ocasionar la muerte.

También se ha observado cáncer en animales tras exposiciones prolongadas o repetidas y existen evidencias de que causan leucemia en los seres humanos.


No existe antídoto para esta exposición. El tratamiento consiste en la eliminación del tóxico del organismo con la mayor rapidez posible y garantizar una atención médica. 



</doc>
<doc id="41806" url="https://es.wikipedia.org/wiki?curid=41806" title="Número ordinal (matemáticas)">
Número ordinal (matemáticas)

En matemáticas, un número ordinal es un número que denota la posición de un elemento perteneciente a una sucesión ordenada. Por ejemplo, en la sucesión "a" "b" "c" "d", el elemento "a" es el primero, "b" el segundo, "c" el tercero, etc. Los números ordinales pueden generalizarse para las sucesiones infinitas, introducidas por Georg Cantor en 1897. El concepto de número ordinal, propio de las matemáticas, es también un concepto lingüístico (que es aquel que precisa la Real Academia Española). En este sentido, es aquel numeral que expresa la idea de orden o sucesión. Tiene género ("primero" / "primera") y puede aparecer apocopado ("primer"). En el lenguaje corriente no se utilizan habitualmente sino hasta el 10 o 12, y para los superiores se usa el cardinal correspondiente: siglo diecinueve, Juan XXIII (veintitrés). Más adelante se detallan en su denominación más propia.

Los números ordinales son una generalización que amplía la secuencia de los números naturales 0, 1, 2, 3,… Por esa razón aunque los números ordinales son propiamente conjuntos inductivos, se denominan «números». Todos los ordinales constituyen una clase, denominada Ord. La conveniencia de esta generalización se sigue de la siguiente observación:
Los números naturales pueden emplearse con dos fines distintos:
Los números cardinales se pueden emplear para cuantificar el tamaño de un conjunto (finito o infinito), mientras que los números ordinales pueden emplearse para describir la posición de un elemento en una sucesión (finita o infinita). Cuando se trata de conjuntos finitos, los números naturales, los ordinales y los cardinales coinciden, es decir, son básicamente identificables. En el caso de conjuntos infinitos la situación es más complicada y hay que distinguir entre ordinales y cardinales (además, para conjuntos infinitos los números naturales no son de utilidad). El aspecto del tamaño de un conjunto se describe mediante números cardinales, que también fueron descubiertos por Cantor, mientras que el aspecto de la posición se generaliza mediante los números ordinales, los cuales analizaremos aquí.

En la teoría de conjuntos, los números naturales se suelen construir como conjuntos tales que cada número natural es el conjunto de todos los números naturales má pequeños:

Visto así, cada número natural es un conjunto bien ordenado: por ejemplo, el conjunto del 4 tiene los elementos 0, 1, 2 y 3, que por supuesto se ordenan 0 < 1 < 2 < 3, y éste es un buen orden. Un número natural es menor que otro si y solo si es un elemento del otro.

Bajo esta convención, se puede demostrar que todo conjunto "finito" bien ordenado es ordenadamente isomorfo a exactamente un número natural. Este isomorfismo motiva a generalizar esta construcció hacia los conjunto no finitos y sus correspondientes números que serían más grandes que cualquier número natural.

Se desea construir números ordinales como conjuntos bien ordenados especiales de forma que "todo" conjunto bien ordenado es ordenadamente isomorfo a exactamente un número ordinal. La siguiente definición mejora el enfoque de Cantor y fue propuesto inicialmente por John von Neumann:

Basándose en el axioma de regularidad, que puede enunciarse como: "«Todo conjunto no vacío “S” contiene un elemento “a” disjunto de “S”.»"

Nótese que los naturales, en la representación propuesta más arriba son los llamados ordinales finitos. Por ejemplo, 2 es un elemento de 4 = {0, 1, 2, 3}, y 2 es igual a {0, 1} por lo que también es un subconjunto de 4.

Se puede demostrar, aplicando inducción transfinita que todo conjunto bien ordenado es ordenadamente isomorfo a exactamente uno de estos ordinales.

Más aún, los elementos de cada ordinal son en sí mismos ordinales. Cuando se tienen dos ordinales "S" y "T", "S" es un elemento de "T" si y solo si "S" es un subconjunto propio de "T", y más aún, cuando "S" y "T" son distintos y "S" no es un elemento de "T", se cumple que "T" es un elemento de "S". De manera que todo conjunto de ordinales está totalmente ordenado y más aún, todo conjunto de ordinales es bien ordenado. Este último resultado es la generalización de la misma propiedad sobre los naturales, lo que permite enunciar y utilizar inducción transfinita para demostrar propiedades sobre ordinales.

Otra consecuencia es que todo ordinal S es un conjunto que contiene como elementos precisamente los ordinales más pequeños que S. Esta afirmación determina completamente la estructura de conjunto de cada ordinal en términos de otros ordinales. Ella es utilizada para demostrar muchas de las propiedades de estos números. Un ejemplo de ello es una importante caracterización de la relación de orden entre ordinales: todo conjunto de ordinales tiene un supremo, que es el ordinal obtenido como la unión de todos los ordinales del conjunto.
Otro ejemplo es el hecho que la colección de todos los ordinales no es un conjunto. Puesto que todo ordinal contiene únicamente ordinales, se cumple que todo elemento de la colección de todos los ordinales también es su subconjunto. Así, si esa colección fuera un conjunto, tendría que ser un ordinal también, por definición; entonces sería un elemento de él mismo, lo cual contradice el axioma de regularidad.


Los ordinales se utilizan comúnmente para realizar demostraciones de terminación de algoritmos. El sistema de ayuda a la demostración ACL2 permite utilizar números ordinales como cota de terminación de algoritmos y es capaz de realizar pruebas por inducción transfinita.


</doc>
<doc id="41810" url="https://es.wikipedia.org/wiki?curid=41810" title="VX">
VX

El VX es una sustancia extremadamente tóxica empleada como arma química y clasificada como agente nervioso. Los agentes nerviosos son los compuestos químicos más tóxicos y de más rápido efecto que se conocen. Es considerada como un arma de destrucción masiva por las Naciones Unidas en su Resolución 687. La producción y el almacenamiento de VX fue prohibida por la Convención sobre Armas Químicas de 1993.

El VX no tiene olor ni sabor, es un líquido oleoso e incoloro, que tarda en evaporarse, y que gracias a su baja volatilidad y a su viscosidad se mantiene adherido a una zona, lo cual lo hace potencialmente peligroso. Es sumamente mortal en estado líquido y aún más mortal si llega a un estado gaseoso/aerosol. El VX no se encuentra de forma natural en el ambiente debido a que fue desarrollado artificialmente.

Actualmente, las reservas mundiales de este agente neurotóxico han sido marcadas químicamente para ser detectadas (con el objetivo de evitar el tráfico terrorista), siendo el color azul asignado para las reservas de la OTAN y de color verde para los países del Pacto de Varsovia.

El nombre VX no es un nombre químico, es un nombre militar empleado por la OTAN para denominar este agente químico; el nombre químico de la molécula es "O-etildiisopropilaminoetilmetilfosfonotiolato".

Existen muchas formas de producir VX, una de ellas es mediante el método estadounidense denominado «Transester Process». Esto implica una serie de pasos, mediante el cual el tricloruro de fósforo es metilado para producir dicloruro metilfosfónico. El material resultante se hace reaccionar con etanol para formar un diéster. Este es entonces transesterificado con 2-diisopropilaminoetanol para producir el fosfonito mezclado. Por último, este precursor inmediato se hace reaccionar con azufre para formar VX.

Los primeros síntomas de la exposición percutánea (contacto con la piel) pueden ser espasmos musculares, irritación, quemaduras o la sudoración en el área de exposición. Algunos de los primeros síntomas que se produce al inhalar VX puede ser rinorrea (secreción nasal), sensación de opresión en el pecho con falta de aire (broncoconstricción), tos, dolores de cabeza, náuseas, vómitos, perdida de coordinación y hasta la muerte. El VX podría causar daño al sistema nervioso, causando entumecimiento, hormigueo o debilidad en las manos y los pies.

El VX es el segundo agente nervioso más tóxico que se ha sintetizado, solo superado por el soviético novichok. Se estima que la dosis letal (DL) para el ser humano, es alrededor de 10 miligramos a través del contacto con la piel, y la LCt por inhalación se estima unos 30 a 50 mg·min/m³.

Es un arma química de guerra creada por el hombre y clasificada como un agente nervioso. Estos son los agentes químicos de guerra más tóxicos y de más rápido efecto que se conocen.

Por la forma de actuar y los efectos que producen son parecidos a los pesticidas (insecticidas) organofosforados, sin embargo los agentes nerviosos son mucho más potentes.

Es un inhibidor casi irreversible de la acetilcolinesterasa (AChE), enzima que se encarga de hidrolizar al neurotransmisor acetilcolina. Al bloquear esta enzima impide que se degrade la acetilcolina liberada, produciendo un aumento en la concentración y en la duración de los efectos del neurotransmisor, apareciendo entonces los efectos nocivos.

Los efectos tóxicos normalmente aparecen cuando se inhibe más del 50% de la enzima AChE, mientras que la muerte aparece cuando se inhibe más del 90% de la enzima en el cerebro y en el diafragma. Además, las concentraciones de acetilcolina acumuladas en el cerebro dan lugar a la liberación de aminoácidos excitadores, que estimulan los receptores NMDA, produciendo la toxicidad neuronal.

El VX es el segundo más potente de todos los agentes nerviosos tras el novichok. La magnitud del envenenamiento depende de la cantidad de VX a la que se ha estado expuesto, la forma de exposición y la duración de la misma. Incluso en cantidades tan pequeñas como 10 miligramos ya es altamente tóxico e incluso letal, tanto si se ingiere como si se inhala.

De todos los agentes nerviosos es el menos volátil y es el que más tarda en evaporarse, por lo tanto permanece durante más tiempo en el ambiente siendo una amenaza tanto a corto como a largo plazo. En condiciones climáticas normales puede durar días en los objetos con los que ha estado en contacto y en condiciones muy frías puede durar meses.

Los síntomas pueden aparecer:
Los efectos incapacitantes ocurren de 1 a 10 minutos, y los efectos fatales pueden ocurrir de 4 a 42 horas. Además, los efectos sobre la memoria, la fatiga, irritabilidad, nerviosismo, pueden persistir hasta 6 semanas después de haberse recuperado de una exposición.

Las dosis potencialmente peligrosas para la vida son ligeramente más grandes que las que producen menos efectos. La muerte generalmente ocurre en los 15 minutos posteriores a la absorción de una dosis fatal.

En la tabla inferior se muestran las principales vías de exposición y los efectos según las dosis.
<nowiki>*</nowiki>Los valores son estimaciones de las dosis que producen efectos letales en un hombre de 70 kg. Las dosis efectivas de vapor se estiman para tiempos de exposición de 2-10 minutos.

Leyenda tabla:

EC (concentración efectiva; mg•min/m): Concentración a la que el gas debilita al 50% de la población expuesta de una manera específica.

IC (concentración incapacitante; mg•min/m): Concentración a la que el gas incapacita al 50% de la población expuesta.

LC (concentración letal; mg•min/m): Concentración a la que el gas mata al 50% de la población expuesta.

LD (dosis letal; mg): La dosis a la que una sustancia mata al 50% de la población expuesta.

RMV (volumen respirado por minuto; litros/min): Volumen de aire inhalado por minuto.

En función de la exposición se presentan los siguientes:
En exposición severa los síntomas pueden progresar a convulsiones, fallo respiratorio, coma e incluso la muerte.

Se observaron en ratas efectos cardiacos como arritmias y efectos inotrópicos positivos.

La mayoría de los efectos que producen los agentes nerviosos como el VX desaparecen a los meses de la exposición. Se observó a largo plazo alteraciones del sueño.

La recuperación de la exposición al VX es posible con tratamiento pero los antídotos que hay disponibles deben ser utilizados rápidamente para que sean eficaces. Por esta razón, el mejor camino a seguir es evitar la exposición:

La rápida acción del VX necesita tratamiento inmediato.

Exposición oral/parenteral:
Exposición inhalación:


Exposición ocular:
Exposición dérmica:

El VX fue desarrollado originalmente por unos químicos de Gran Bretaña en 1952. Cuando se fijaron que se encontraban ante un agente nervioso, enviaron muestras a EE. UU. en noviembre del mismo año.

Es posible que el VX y otros agentes nerviosos hayan sido utilizados en la confrontación química que tuvo lugar durante la guerra Irán-Iraq en la década de 1980.

El 23 de febrero de 2017, la policía de Malasia informó que se trataba de la sustancia usada para asesinar a Kim Jong-nam, político norcoreano y hermano paterno de Kim Jong-Un. En el aeropuerto Internacional de Kuala Lumpur dos mujeres se le acercaron por detrás y le taparon el rostro con un pañuelo impregnado en la sustancia.


.

</doc>
<doc id="41813" url="https://es.wikipedia.org/wiki?curid=41813" title="Ácido fólico">
Ácido fólico

El ácido fólico, folacina o ácido pteroilmonoglutámico (la forma aniónica se llama folato), conocido también como vitaminaB, es una vitamina hidrosoluble del complejo de vitaminaB, necesaria para la maduración de proteínas estructurales y hemoglobina (y por esto, transitivamente, de los glóbulos rojos); su insuficiencia en los humanos es muy rara. Los términos «fólico» y «folato» derivan su nombre de la palabra latina "folium", que significa ‘hoja vegetal’.

La actividad coenzimática del ácido fólico es el ácido tetrahidrofólico o THF (tetrahidrofolato).

El ácido fólico es efectivo en el tratamiento de ciertas anemias y la psilosis. Se encuentra en las vísceras de animales, verduras de hoja verde, legumbres, levadura de cerveza y en frutos secos y granos enteros, como las almendras, así como en alimentos enriquecidos. El ácido fólico se pierde en los alimentos conservados a temperatura ambiente y durante la cocción. A diferencia de otras vitaminas hidrosolubles, el ácido fólico se almacena en el hígado y no es necesario ingerirlo diariamente.

Las causas de su carencia son la mala alimentación y un déficit genético de hidratación del folato que es asintomático hasta que la mujer se queda embarazada.

Si la mujer tiene suficiente ácido fólico en el cuerpo antes de quedarse embarazada, esta vitamina puede prevenir deformaciones en la placenta que supondrían el aborto, defectos de nacimiento en el cerebro (anencefalia) y la columna vertebral (espina bífida) del bebé por mal cierre del tubo neural en los extremos cefálico y caudal respectivamente. La espina bífida, un defecto de nacimiento en la columna, puede producir la parálisis de la parte inferior del cuerpo, la falta de control del intestino y la vejiga, y dificultades en el aprendizaje. Si el feto sufre déficit de ácido fólico durante la gestación también puede padecer anemia megaloblástica, ser prematuro o presentar bajo peso al nacer. La madre puede sufrir eclampsia, un proceso que cursa con hipertensión y albuminuria. El ácido fólico también ayuda a mantener un útero sano.

En la década de 1920, los científicos creían que la deficiencia de folato y la anemia eran la misma condición. En 1931, la investigadora Lucy Wills hizo una observación clave que llevó a la identificación del folato como el nutriente necesario para prevenir la anemia durante el embarazo. Wills demostró que la anemia se podía revertir con levadura de cerveza. A finales de la década de 1930, el folato se identificó como la sustancia correctora de la levadura de cerveza. Fue aislado por primera vez en 1941 mediante su extracción de hojas de espinacas por Herschel K. Mitchell, Esmond E. Snell y Roger J. Williams. El término «fólico» proviene de la palabra latina (que significa ‘hoja vegetal’) porque se encuentra en vegetales de hojas verde oscuro. Los nombres históricos incluyen "L.casei", factor vitaminaB después de una investigación realizada en pollos, y vitaminaM después de una investigación realizada en monos.

Bob Stokstad aisló la forma cristalina pura en 1943 y pudo determinar su estructura química mientras trabajaba en los Laboratorios Lederle de la American Cyanamid Company. Este histórico proyecto de investigación, de obtención de ácido fólico en forma cristalina pura en 1945, fue realizado por el equipo denominado «chicos del ácido fólico», bajo la supervisión y orientación del director de Investigación Yellapragada Subbarao, en el Lederle Lab, en Pearl River, Nueva York. Esta investigación condujo posteriormente a la síntesis del antifolato aminopterina, que fue utilizado para tratar la leucemia infantil por Sidney Farber en 1948.

En las décadas de 1950 y 1960, los científicos comenzaron a descubrir los mecanismos bioquímicos de la acción del folato. En 1960, los investigadores relacionaron la deficiencia de folato con el riesgo de defectos del tubo neural. A fines de la década de 1990, los gobiernos de Estados Unidos y de Canadá decidieron que a pesar de los programas de educación pública y de la disponibilidad de suplementos de ácido fólico, aún existía un desafío para las mujeres en edad fértil para cumplir con las recomendaciones diarias de folato, que es cuando esos dos países implementaron programas de enriquecimiento con folato. En diciembre de 2018, 62 países exigieron la fortificación de alimentos con ácido fólico.

Se suele señalar que las legumbres (garbanzos, lentejas, etc.) y los vegetales de hoja verde como la espinaca, escarola, guisantes, alubias secas, cereales fortificados, frutos secos, semillas de girasol son fuentes ricas en ácido fólico. En realidad, el ácido fólico como tal no se encuentra en la naturaleza, sino que es un compuesto químico utilizado con fines terapéuticos por la industria farmacéutica. El ácido fólico incluye un grupo pteridínico sustituido unido a una molécula de ácido para-aminobenzoico, lo que constituye el ácido pteroico. A su vez, este se une a un resto de ácido glutámico por un enlace amídico. Los compuestos naturales están reducidos en su núcleo pteridínico (ácido tetrahidrofólico), suelen llevar grupos monocarbonados y son poliglutamatos. El número de restos de ácido glutámico puede variar entre dos y siete, y en todos los casos la unión es un enlace peptídico de tipo gamma. En el intestino humano se hidroliza por acción de la folil poliglutamato hidrolasa, a su forma monoglutámica, o ácido fólico, y así puede pasar a la sangre. Algunos cereales para el desayuno son fortificados con el 25 al 100% del requerimiento diario de ácido fólico. La carne es pobre en ácido fólico, pero sí se encuentra en el hígado de algunos animales, como la ternera, y también en el pescado azul.

Se recomienda el suministro de suplementos con altas dosis de ácido fólico en la pregestación y durante el primer trimestre del embarazo, ya que el folato sérico disminuye en los primeros tres meses de gestación.

El folato es necesario para la producción y mantenimiento de nuevas células. Esto es especialmente importante durante periodos de división y crecimiento celular rápido como en la infancia y embarazo. El folato es necesario para la replicación del ADN. Por esto, la deficiencia de folato dificulta la síntesis y división celular, afectando principalmente la médula ósea, un sitio de recambio celular rápido. Debido a que la síntesis de ARN y proteínas no se obstaculiza completamente, se forman células sanguíneas largas o sin forma regular llamadas megaloblastos, resultando en anemia megaloblástica. Tanto niños como adultos necesitan folato para producir células sanguíneas normales y prevenir la anemia.

La vitaminaB ayuda a convertir la vitaminaB en una de sus formas coenzimáticas y participa en la síntesis de ADN requerido para un rápido crecimiento celular. Del mismo modo, actúa como coenzima en la transferencia de grupos monocarbonados. Interactúa con la vitaminaB y la vitaminaC.

El ácido fólico no posee actividad coenzimática, pero sí su forma reducida, el ácido tetrahidrofólico, representado frecuentemente como FH o TFH. Actúa como transportador intermediario de grupos con un átomo de carbono, especialmente grupos formilo, que se precisa en la síntesis de purinas, compuestos que forman parte de los nucleótidos, sustancias presentes en el ADN y el ARN, y necesarias para su síntesis durante la fase S del ciclo celular, y por lo tanto para la división celular; también actúa en la transferencia de grupos metenilo y metileno. El ácido tetrahidrofólico también actúa en la ruta de las pirimidinas, al modificar el anillo de uridina para formar la tiamina al ceder un grupo metilo.


En la forma de una serie de componentes tetrahidrofolatos, el folato deriva como sustrato en un número de reacciones y también está involucrado en la síntesis de dTMP (2´-deoxitimidina-5-fosfato) a partir de dUMP (2´deoxiuridina-5-fosfato). Ayuda a convertir la vitaminaB en una de sus formas coenzimáticas y participa en la síntesis de ADN requerido para un rápido crecimiento celular.

Las vías que llevan a la formación de tetrahidrofolato (FH) comienza cuando el folato (F) es reducido a dihidrofolato (FH), el cual es entonces reducido a tetrahidrofolato (FH). La dihidrofolato reductasa cataliza, utilizando NADPH, ambos pasos.

Un número de drogas interfiere con la biosíntesis de ácido fólico o tetrahidrofolato. La mayoría son inhibidores de la dihidrofolato reductasa (como la trimetoprima y la pirimetamina), las sulfonamidas y las drogas utilizadas contra el cáncer como el metotrexato (ambas inhiben la folato reductasa y dihidrofolato reductasa).

El N5,N10-metilen tetrahidrofolato o metileno tetrahidrofolato (CHFH) es formado a partir del tetrahidrofolato con la adición de grupos metileno de uno de los carbonos donadores: formaldehído, serina o glicina. El N5-metil tetrahidrofolta o metil tetrahidrofolato (CHFH) puede ser formado desde el metileno tetrahidrofolato por reducción del grupo metileno mediante NADH; el N5-formil tetrahidrofolato o formal tetrahidrofolato (CH-FH) resulta de la oxidación del metileno tetrahidrofolato. Las formas N5 y N10-formil tetrahidrofolato son isómeros intercambiables en las células y la N10 puede formarse directamente desde el ác. fórmico, ATP y folato. La forma N5-forminino tetrahidrofolato se crea desde N5, N10-metilen tetrahidrofolato más amoníaco, o desde el folato y el ácido n-formiminoglutámico, que se crea a partir de la degradación de la histidina. Todas estas formas tienen un único propósito, cual es el de «entregar» diversas formas monocarbonadas (metil -CH3, metileno -CH2-, formil -CHO, formomino -CH=NH4 y metenil -CH=). 

Las coenzimas de vitaminaB (H4 folato) desempeñan un papel vital en el metabolismo del ADN a través de la síntesis de ADN a partir de sus precursores (timidina y purinas) y la síntesis del aminoácido metionina, que es necesario para la síntesis de un donante del grupo metilo utilizado en muchas reacciones biológicas. La adición de un grupo metilo (-CH3) (‘metilación’) en un número de puntos del ADN podría tener importancia en la prevención del cáncer.

Las coenzimas del folato son necesarias para el metabolismo de diversos aminoácidos importantes, como la síntesis de metionina a partir de la homocisteína. Por ello, la deficiencia de vitaminaB (folato) puede resultar en una síntesis decreciente de metionina y una acumulación de homocisteína, un factor de riesgo de enfermedades cardiacas, así como otras enfermedades crónicas.

La vitaminaB (ácido fólico) regula la cantidad de homocisteína en la sangre, aunque lo hacen también las vitaminasB y B (4). Se ha observado que es la B9 la que tiene el "mayor efecto" en la reducción del nivel basal de homocisteína en la sangre cuando no hay una deficiencia coexistente de vitaminaB ó vitaminaB. 

El estudio "NHANES III, 1988-91" (The National Health and Nutrition Examination Survey) y la "Investigación continua de ingesta de alimentos por individuos (CSFII 1994-96)", indicaron que la mayoría de adultos no consumen la cantidad adecuada de folato. Sin embargo; el programa de fortificación en Estados Unidos ha incrementado el contenido de ácido fólico comúnmente consumido en alimentos como cereales y granos y como resultado de esto, la mayoría de adultos ahora ingieren cantidades recomendadas de folato diario.

Una deficiencia de folato puede ocurrir cuando las necesidades del nutriente están aumentadas, cuando la ingesta diaria de folato es inadecuada y cuando el cuerpo excreta más folato de lo usual (pérdidas). Algunas investigaciones indican que la exposición a rayos ultravioleta incluyendo las cámaras de bronceado, puede conducir a deficiencia de ácido fólico. La evolución del color de la piel en humanos es particularmente controlada por la necesidad de tener un color oscuro en la piel para proteger el ácido fólico de los rayos ultravioleta.

La deficiencia de ácido fólico se manifiesta con diarreas, pérdida del apetito, pérdida de peso. Signos adicionales son debilidad, lengua dolorida, dolor de cabeza, taquicardia, irritabilidad y desórdenes de conducta.

Las mujeres con deficiencia de folato que están embarazadas, en su mayoría tienen niños de bajo peso al nacer, prematuros y con defectos del tubo neural. En adultos, la anemia (macrocítica, megaloblástica) es un signo avanzado de deficiencia de folato. En niños, la deficiencia de folato puede retardar el crecimiento.

El ácido fólico es importante en las mujeres embarazadas (edad fértil). La ingesta adecuada de folato durante el periodo preconcepcional, el tiempo justo antes y después de la concepción, ayuda a proteger al bebé contra un número de malformaciones congénitas incluyendo defectos del tubo neural. Los defectos del tubo neural resultan en una malformación de la espina (espina bífida), cráneo y cerebro (anencefalia). El riesgo de los defectos del tubo neural es significativamente reducido cuando el suplemento de ácido fólico es utilizado como consumo adicional a una dieta saludable antes y durante el primer mes seguido de la concepción. La ingestión de 400µg (microgramos) diarios de ácido fólico sintético de alimentos fortificados o suplementos ha sido sugerida para evitar estos defectos. La recomendación diaria o requerimientos diarios adecuados del folato en mujeres embarazadas es de 600-800µg, casi el doble recomendado que para mujeres no embarazadas.

Aunque no se conoce un nivel tóxico para el ácido fólico, sí que hay estudios que asocian el exceso de ácido fólico en el último trimestre del embarazo con que el niño por nacer desarrolle asma. Por ello la recomendación es tomar un suplemento alto en ácido fólico antes de quedar embarazada y en el primer trimestre, que es cuando su carencia sería más grave, sustituyéndolo en el segundo y tercer trimestre por un suplemento más moderado.

Es bien conocida la interacción entre vitaminaB y ácido fólico. El suplemento de ácido fólico puede corregir la anemia asociada a deficiencia de vitaminaB. Desafortunadamente, el ácido fólico no corrige los cambios en el sistema nervioso causados por la deficiencia de vitaminaB. Un daño nervioso permanente podría ocurrir teóricamente si la deficiencia de vitaminaB no es tratada. Por ende, los suplementos de ácido fólico no pueden exceder los 1000µg (microgramos) por día, ya que enmascara los síntomas de la deficiencia de vitaminaB.

El riesgo de toxicidad por ácido fólico es bastante bajo. El Instituto de medicina ha establecido una ingesta máxima tolerable de 1mg (miligramo) para adultos (hombres y mujeres) y un máximo de 800µg (microgramos) para mujeres embarazadas y lactantes menores de 18 meses de edad. Los suplementos de ácido fólico no deberían exceder el máximo tolerable para prevenir la deficiencia enmascarada de vitaminaB. Las investigaciones sugieren que niveles altos de ácido fólico pueden interferir con algunos tratamientos contra la malaria.

Desde que se descubrió la interacción entre la deficiencia de folato y los defectos del tubo neural, los gobiernos y organizaciones de salud a nivel mundial han intensificado las recomendaciones concernientes a la suplementación de ácido fólico para mujeres que intentan quedar embarazadas. Esto ha guiado a la introducción de la fortificación en muchos países, en los que el ácido fólico es adicionado a la harina con la intención de que cada uno se beneficie del aumento de los niveles de folato en sangre. Esto es controvertido, teniendo en cuenta la libertad sobre el consumo de folato y el efecto enmascarado de la fortificación del folato sobre la anemia perniciosa (deficiencia de vitaminaB). Sin embargo, la mayoría de los países de América del Norte y Sudamérica ahora fortifican su harina. En 1996, la Food and Drug Administration (FDA) de Estados Unidos publicó las regulaciones requeridas para la adición de ácido fólico a panes enriquecidos, cereales, harinas, harina de maíz, pastas, arroz y otros productos a base de granos.Esta norma se hizo efectiva en 1998 y fue específicamente dirigida a reducir el riesgo de defectos del tubo neural en recién nacidos.

Las concentraciones adecuadas de folato, vitaminaB o vitaminaB pueden disminuir los niveles en la circulación de homocisteína, un aminoácido normalmente encontrado en la sangre. Existe evidencia de que un elevado nivel de homocisteína en sangre es un factor independiente de riesgo para enfermedad cardiovascular e infarto. La evidencia sugiere que los altos niveles de homocisteína pueden dañar las arterias coronarias o facilitar que las plaquetas se agrupen y formen un coágulo. Sin embargo, no existe evidencia actualmente disponible que sugiera que los niveles de homocisteína reducidos por el consumo de ácido fólico, vitaminaB y vitaminaB pueda reducir el riesgo de enfermedad cardíaca.

El ácido fólico parece reducir el riesgo de infarto. Las revisiones indican que solo en algunos individuos el riesgo de infarto parece reducirse, pero no se ha establecido una recomendación definida con respecto a la suplementación más allá del diario recomendado actual, para prevenir un infarto.

La asociación entre el folato y el cáncer parece ser compleja. Se ha sugerido que el folato puede ayudar a prevenir el cáncer, por su participación en la síntesis, reparación y funcionamiento del ADN, nuestro mapa genético, y una deficiencia de folato puede resultar en daño al ADN que puede conducir al cáncer. Inversamente, se ha sugerido que el exceso de folato puede promover la iniciación del tumor. Aunque dietas altas en folato están asociadas con disminución del cáncer colorrectal, la asociación es más fuerte para el folato contenido en los alimentos que el proveniente de los suplementos. y un ensayo clínico realizado al azar en el 2007, encontró que los suplementos con folato no reducen el riesgo de adenomas colorectales. Un estudio prospectivo en 2006 de 81.922 suecos adultos encontró que dietas altas en folato proveniente de los alimentos fue asociada con un riesgo reducido de cáncer pancreático. La mayoría de estudios epidemiológicos sugieren que dietas altas en ácido fólico son asociadas con disminución del cáncer de seno, pero los resultados no son uniformemente consistentes: un ensayo grande de investigación del cáncer reportó un potente efecto dañino de la ingesta alta de folato sobre el riesgo de cáncer de seno, sugiriendo que la suplementación rutinaria de folato no debería ser usada como preventivo del cáncer de seno, pero el estudio sueco del 2007 encontró que una ingesta alta de folato fue asociada con una disminución de la incidencia del cáncer de seno posmenopáusico.

El folato es importante para que las células y tejidos se dividan rápidamente. Las células cancerígenas se dividen rápidamente, y las drogas que interfieren con el metabolismo del folato son usadas para el tratamiento del cáncer. El antifolato metotrexato es una droga frecuentemente usada para tratar el cáncer debido a que inhibe la producción de la forma activa, tetrahidrofolato. Desafortunadamente, el metrotexato puede ser tóxico produciendo efectos secundarios como inflamación del tracto digestivo, que dificulta la alimentación normal.

El ácido folínico es una forma del folato que puede ayudar a rescatar o revertir el efecto tóxico del metrotexato. No es lo mismo que el ácido fólico. Los suplementos del ácido fólico tienen establecidos pequeños roles en la quimioterapia del cáncer. Ha habido casos de efectos adversos severos por sustitución accidental de ácido fólico por ácido folínico en pacientes que reciben metrotexato como quimioterapia del cáncer.

Dosis bajas de metrotexato son usadas para tratar una amplia variedad de enfermedades no cancerosas como la artritis reumatoide, lupus, psoriasis, asma, sarcoidosis, cirrosis biliar primaria y enfermedad inflamatoria intestinal. Bajas dosis de metrotexato pueden disminuir las reservas de folato y causar efectos secundarios que son similares a la deficiencia de folato. Las dietas altas en ácido fólico como una suplementación pueden ayudar a disminuir los efectos secundarios del metrotexato, sin disminuir su efectividad. Cualquier persona que ingiera dosis bajas de metrotexato por problemas de salud, debe consultar con su médico acerca de la necesidad de suplementar con ácido fólico.

Algunas evidencias relacionan bajos niveles de folato con depresión. Existen algunas evidencias de ensayos controlados que sugieren que usar ácido fólico en adición a medicamentos antidepresivos puede tener beneficios.

En un estudio realizado durante tres años en 818 personas mayores de 50 años, sobre memoria a corto plazo, agilidad mental y fluidez verbal; se encontró mejoría en todas aquellas personas que ingirieron 800µg (microgramos) de ácido fólico diario que aquellos que tomaron solo placebo. El estudio fue reportado en The Lancet el 19 de enero de 2007.

El folato es necesario para la fertilidad tanto en hombres como mujeres. En los hombres, contribuye a la espermatogénesis. En las mujeres, por otra parte contribuye a la maduración del ovocito, implantación, en adición a los efectos generales del ácido fólico sobre el embarazo. Por ende, es necesario recibir suficientes cantidades a través de la dieta para evitar la infertilidad.





</doc>
<doc id="41814" url="https://es.wikipedia.org/wiki?curid=41814" title="Número (de pacientes) que es necesario tratar">
Número (de pacientes) que es necesario tratar

En bioestadística o en medicina basada en hechos, el número (de pacientes) que es necesario tratar o NNT (también conocido por los calcos "número necesario a tratar" y "número necesario para tratar") es el reciproco de la reducción del riesgo absoluto; es un valor o indicador específico para cada tratamiento. Describe la diferencia entre un tratamiento activo y un control (placebo u otro tratamiento) en lo que se refiere a lograr un resultado clínico concreto.

Un NNT de 1 significa que en todos los pacientes a los que se les da el tratamiento se produce un resultado favorable, a la vez que ningún paciente del grupo de comparación (placebo u otro tratamiento) tiene el resultado esperado.

Para que un NNT esté correctamente expresado, se debe hacer constar:

En farmacología y farmacoeconomía es otro procedimiento para obtener una aproximación más real de la eficacia que aporta un nuevo medicamento (beneficio sobre los pacientes). A partir de los datos de incidencia del evento objeto de estudio en el grupo control y grupo experimental del ensayo clínico aleatorizado se puede obtener el número necesario de pacientes que deben tomar un medicamento durante un tiempo determinado para que uno solo de ellos obtenga efectos beneficiosos (NNT) o se causen efectos adversos (NNH) – Number Needed to Treated / to Harm -.
De esta manera, y fundamentándose en criterios actuales de medicina basada en hechos, pueden calcularse el coste eficacia medio, coste eficacia incremental, análisis de sensibilidad y finalmente los resultados estimados (número de pacientes candidatos al tratamiento durante un periodo determinado) e impacto global sobre la economía del centro de salud, área de salud y hospital.

De esta manera el cálculo del NNT es un avance importante que permite estimar el esfuerzo que el médico debe realizar para obtener un resultado (diagnóstico y/o terapéutico). Este parámetro puede utilizarse como una medida de efectividad relativa clínica de diferentes intervenciones, pero para que todo esto sea cierto debemos tener en cuenta algunas consideraciones:

Teniendo en cuenta todas las premisas anteriores, el NNT puede ser un buen indicador de la efectividad de un tratamiento farmacológico, además si el estudio lo refiere y podemos calcular el NNH (número necesario de pacientes que hay que tratar para que 1 paciente sufra un evento adverso) se puede obtener la relación beneficio/riesgo del tratamiento empleado (NNT/NNH).

Asimismo, si añadimos los costes de la medicación durante el período necesario para evitar el evento se puede construir fácilmente un indicador de coste efectividad. El uso de este indicador sería bastante conveniente en atención primaria y permitiría establecer una lista guía en el que aparecieran ordenados los distintos costes efectividad de los medicamentos empleados para una misma patología.

En la siguiente tabla se muestra un ejemplo sobre la utilización del parámetro NNT como una medida más de efectividad de los medicamentos comparados en una patología concreta. Se trata de los datos de un ensayo clínico, sobre la eficacia de dos antibióticos utilizados en las exacerbaciones agudas de la bronquitis crónica (datos no inventados). Sin embargo, debemos apreciar que solo se tiene en cuenta los costes directos de la adquisición del medicamento.

El NNT (30,03) calculado nos indica que 31 pacientes tienen que tomar el medicamento A para evitar un evento respecto a los que toman el medicamento B. Por tanto, el coste de evitar un evento empleando el antibiótico A en vez del antibiótico B (coste efectividad incremental) sería de 1.054 €, es decir, lo que nos cuesta más que un solo paciente mejore con el tratamiento A si estaba tomando el tratamiento B.



</doc>
<doc id="41821" url="https://es.wikipedia.org/wiki?curid=41821" title="Cardinal">
Cardinal

Cardinal puede referirse a:


</doc>
<doc id="41822" url="https://es.wikipedia.org/wiki?curid=41822" title="Prostatitis">
Prostatitis

La prostatitis es una inflamación de la próstata. Comprende un conjunto de síndromes, enfermedades y trastornos funcionales que afectan a la próstata o al área perineal con una sintomatología similar y con una etiología en algunos casos desconocida.

Suele aparecer en adultos jóvenes o varones de edad media. Es la infección urinaria más frecuente en el varón entre la segunda y cuarta décadas de la vida.

Para el diagnóstico se recurre a análisis de orina, de sangre, tacto rectal con masaje prostático para la obtención de secreción prostática, ecografía transrectal de próstata y en pocos casos se recurre a la biopsia, TAC o RMN.

Existen distintos tipos de prostatitis:
La prostatitis aguda es un tipo de infección bacteriana aguda frecuente, que se diagnostica fácilmente y que suele responder bien al tratamiento antibiótico. El cuadro clínico se caracteriza por aparición súbita con fiebre alta, escalofríos o tiritonas, malestar general, lumbalgias e intensas molestias miccionales que pueden llegar a la retención aguda de orina.

En la orina es frecuente encontrar piuria, bacteriuria y hematuria. Al tacto rectal la próstata está blanda, dolorosa y congestiva; puede aparecer exudado purulento por meato uretral. Debe evitarse un tacto rectal agresivo por la posibilidad de una sepsis. En plasma el nivel de PSA suele estar elevado.

Los gérmenes comunes encontrados en los cultivos son "Escherichia coli", "Enterococo", "Klebsiella pneumoniae", "Proteus mirabilis", "Pseudomona aeruginosa" y "Staphylococcus aureus". La infección cede rápidamente con antibióticos que se deben mantener un tiempo relativamente largo entre seis y ocho semanas.

La prostatitis aguda bacteriana puede estar originada por una enfermedad de transmisión sexual, aunque también es muy frecuente en los pacientes con hiperplasia benigna de próstata, tras una infección urinaria.

Tiene una incidencia de 1-2 casos cada 10.000 varones.

La prostatitis crónica se caracteriza por síntomas que tienen un inicio insidioso con polaquiuria y urgencia miccional, sensación de “quemazón” uretral o disuria y a veces febrícula, a lo largo de meses en la mayoría de los pacientes.

A menudo hay enrojecimiento del meato uretral y de la mucosa circundante, y algo de secreción indicativa de uretritis. Muchos pacientes refieren chorro miccional fino y goteo postmiccional; dolor vago impreciso de variable intensidad y la sensación de frialdad o pesadez perineal es una manifestación común en estos pacientes. La localización que repiten es en el periné profundo, áreas inguinales, suprapúbico, escroto y pene; todo de manera muy vaga e imprecisa. El dolor al final de la eyaculación o la hemospermia también se repite en sus manifestaciones y puede alterar su vida sexual.

Al tacto rectal aparece una próstata blanda o fibrótica, a veces con cierta crepitación y consistencia granular debido a la presencia de gránulos. A veces en la gran mayoría de los pacientes el tacto rectal es normal. En la secreción prostática pueden aparecer leucocitos polimorfonucleares y macrófagos. A menudo también hay abundante descamado de células epiteliales de los acinis o ductos prostáticos. El masaje prostático produce una secreción de entre 0,1 y 1 cm³. Para evitar la contaminación de la uretra, se le pide al paciente que orine antes del masaje.

La secreción es exprimida y extendida sobre un porta, teñida y observada al microscopio.

La biopsia de próstata no está indicada en el diagnóstico del paciente sospechoso de prostatitis crónica, ya que ésta es usualmente focal y no palpable. Sí está indicada cuando se palpan áreas sospechosas (para diferenciar un tumor de una prostatitis crónica granulomatosa, por ejemplo).

La prostatitis bacteriana crónica se caracteriza por la presencia en la fracción prostática, orina postmasaje o semen, de una o más bacterias gramnegativas que no crecen en las fracciones inicial o media de la orina.

Los microorganismos identificados en la prostatitis bacteriana crónica son:

La prostatitis crónica puede deberse a una prostatitis bacteriana que no se ha curado bien, a una inflamación crónica de la próstata o al estrés (que contrae los músculos del suelo pélvico) y la actividad sexual irregular de forma continuada, con la retención de la eyaculación.

La prostatitis abacteriana es la presencia de polimorfonucleares en la secreción prostática visualizados al microscopio, con cultivos negativos.

La prostatodinia no presenta ni polimorfonucleares ni cultivo positivo. La mayoría de los pacientes que consultan al médico presentan prostatitis abacteriana y prostatodinia.

La prostatodinia es un síndrome de prostatitis en un varón joven en el que repetidas veces el exudado prostático es negativo para polimorfonucleares. Presenta sintomatología típica y ha seguido infinidad de tratamientos. Estos pacientes sufren de molestias en el periné, o dolor en pene, testículos, área perianal, escroto, suprapúbico, etc. durante la micción o fuera de ella. En estudios urodinámicos se observa una anormal contractura del esfínter externo –estriado– de la uretra, flujos miccionales bajos y disinergia detrusoresfínteriana (ausencia de relajación del esfínter durante la micción). Este trastorno se cree que está relacionado con una mialgia por tensión del suelo pelviano, dependiente del estímulo simpático. También llamado síndrome de la vejiga ansiosa, afecta a varones excesivamente ansiosos. Su patogenia no está completamente clara, pero se sabe que responden bien al tratamiento con a1-bloqueantes y que al suspender el mismo empeoran. No hay duda de que algunos individuos responden al estrés, ansiedad y depresión con dolor y malestar en el área genitourinaria.

Como la prostatitis aguda bacteriana es una bacteriemia de origen prostático, se debe tratar con antibióticos. Dado que generalmente se debe a bacilos gramnegativos, se opta por antibióticos bactericidas preferiblemente por vía intramuscular o intravenosa por tener una mejor biodisponibilidad: aminoglucósidos, cefalosporinas de tercera generación, monobactámicos, quinolonas fluoradas,y sulfas... Además del tratamiento etiológico, los antipiréticos, analgésicos y antiinflamatorios serán de gran utilidad. Hay que considerar que durante la inflamación aguda la barrera hematoprostática –membrana lipoepitelial– está alterada, por lo que la difusión de los antibióticos es buena. En 24-48 horas el cuadro clínico revertirá y tras un tratamiento de 12-14 días, la membrana lipoepitelial se recompondrá y difundirá entonces peor los antibióticos; será el momento en que haya que utilizar antibióticos con buena difusión prostática: quinolonas fluoradas orales y doxiciclina, para continuar el tratamiento durante 6-8 semanas más.

La ausencia de recuentos bacterianos significativos en cultivos fraccionados repetidos justifica no utilizar antibióticos. En estos casos medidas generales higiénico-dietéticas (evitar especias, picantes, alcohol, café, regularizar el tránsito intestinal, tratar el síndrome hemorroidal, higiene sexual, baños de asiento, etc.) ayudarán al bienestar del paciente. En muchos casos es de gran utilidad la asociación de antibióticos de buena difusión junto con los alfabloqueantes, y la termoterapia.

Según los hallazgos urodinámicos y excluyendo el resto de las prostatitis, el tratamiento consiste en el uso de relajantes de fibra muscular lisa uroselectivos: los a1-bloqueantes (alfuzosina, terazosina, doxazosina…). La asociación de ansiolíticos por vía oral aliviará al paciente al eliminar un componente fundamental en este tipo de enfermos. La pauta de tratamiento se mantendrá durante 6-8 semanas.

Dentro de las formas atípicas de la prostatitis, la prostatitis granulomatosa merece una atención especial. Su etiopatogenia no está claramente establecida. Se han implicado microorganismos como "Micobacterium tuberculosis", hongos (blastomicosis, coccidioidomicosis, cryptococcosis, histoplasmosis…). Hay que resaltar que el tacto rectal es muy sospechoso y se confunde con un carcinoma de próstata que sólo la biopsia diferenciará. También merece interés porque una gran parte de pacientes con tumores uroteliales vesicoprostáticos son tratados con inmunoterapia BCG (Bacilo de Calmette y Guerin) en instilaciones endovesicales que en la próstata originan una respuesta tipo granulomatoso.




</doc>
<doc id="41826" url="https://es.wikipedia.org/wiki?curid=41826" title="Dan Brown">
Dan Brown

Daniel «Dan» Brown (Exeter, Nuevo Hampshire, Estados Unidos, 22 de junio de 1964) es un escritor estadounidense conocido por la novela "El código Da Vinci" (2003) y otros títulos protagonizados por el personaje Robert Langdon.

Hijo de un matemático y una compositora de música sacra. Estudió secundaria en el instituto Phillips Exeter Academy, Class of 1982, y sus estudios universitarios en Amherst College. Como estudiante residió en Gijón (España) en el año de 1980, este traslado a España fue su primer viaje al extranjero estudiando en un instituto de dicha ciudad. Brown afirma que en 1985, un año antes de graduarse, estudió Historia del Arte en la Universidad de Sevilla, pero esta universidad declaró que no existen registros de que él hubiese sido estudiante en sus instalaciones, y que en caso de haberlo sido es probable que lo haya hecho como un estudiante itinerante en un simple curso de verano. Diplomado por el Amherst College, se dedicó a la música: produjo una grabación con canciones infantiles y fundó la empresa Dalliance, con la que grabó "Perspective". Su hermano Gregory W. Brown también estudió secundaria en Phillips Exeter Academy y realizó los estudios de música y composición en Amherst College, al igual que Dan. 

En 1991 se mudó a Hollywood, California, para continuar con su carrera de pianista y cantautor, mientras se ganaba la vida como profesor de inglés y español en un colegio de Beverly Hills. En la Academia Nacional de Compositores conoció a Blythe Newlon, una mujer quince años mayor, con quien contrajo matrimonio en 1997 después de varios años de convivencia. 

Regresaron a Nuevo Hampshire, donde continuó con su carrera musical y dando clases de inglés en Phillips Exeter Academy y de español en la Lincoln Akerman School. En 1993, además, grabó "Dan Brown" y en 1994 "Angels and demons", título que conservaría para su segunda novela.

Pero, todo cambió en el verano de 1993. Mientras estaba en una playa de Tahití, encontró olvidada en una tumbona la novela "La conspiración del juicio final" (1991), de Sidney Sheldon. Al regresar a Exeter, comenzó a trabajar en "Digital Fortress" ("La fortaleza digital"), su primera novela, en la que involucraba en la intriga a la Agencia de Seguridad Nacional (NSA). Este techno-thriller, aparecido en 1998, criticado por su superficialidad y deslices en el tratamiento tecnológico, tuvo un relativo éxito comercial.

En el año 2000 publica "Ángeles y demonios", donde aparece por primera vez el personaje Robert Langdon, profesor de simbología religiosa en la Universidad de Harvard que, investigando un misterioso símbolo, se encuentra con la secta de los Illuminati, hermandad que lleva siglos enfrentada a la Iglesia católica.

Al año siguiente aparece "Deception Point" (2001, traducida al español como "La conspiración"), libro que motoriza su trama con el descubrimiento de un extraño objeto en el Ártico por parte de un satélite (SOT) de la NASA. 

Langdon, el personaje clave de "Ángeles y demonios", es también el protagonista de la obra que lo convirtió en fenómeno mundial de superventas, "El código Da Vinci", un libro centrado en la búsqueda del significado real del Santo Grial.





Su primera novela tiene como protagonista a Susan Fletcher, una de las mejores criptógrafas de la NSA, que verá peligrar su vida con la llegada de un extraño código que, a primera vista, ni ella misma sabe descifrar. Paralelamente y sin que Susan lo sepa, su prometido, el traductor David Becker, es enviado por la NSA a Sevilla en busca de la clave para resolver el misterio, mientras es seguido de cerca por un implacable asesino a sueldo.

Su segunda novela es, a su vez, la primera de una serie de aventuras protagonizada por el profesor de simbología y arte religioso de Harvard, Robert Langdon. En este caso, el profesor Langdon y la científica del CERN Vittoria Vetra se verán envueltos en una carrera contra el tiempo por salvar al Vaticano de un atentado terrorista organizado por una hermandad secreta que se creía desaparecida, los Illuminati, que involucra una bomba de antimateria y el secuestro de cuatro cardenales "preferiti" en pleno cónclave papal.

Su tercera novela gira en torno a una red de conspiraciones que se desencadena tras el descubrimiento, por parte de la NASA, de un meteorito enterrado en la plataforma de hielo Milne (Canadá, cerca del Polo Norte) que parece presentar pruebas irrefutables de la existencia de vida extraterrestre. Su protagonista es la analista de inteligencia Rachel Sexton.

En su cuarta novela, la más popular, y, posiblemente, la más polémica de todas, Brown recupera al personaje de Robert Langdon, que ahora debe solucionar un misterio con la criptóloga Sophie Neveu, relacionado con una sociedad secreta conocida como el Priorato de Sion, de la que Leonardo da Vinci habría sido Gran Maestre, y la posible ubicación del Santo Grial. Langdon y Sophie parten en busca del Grial por distintas locaciones de París y Londres, mientras un monje albino asesino trabaja presuntamente a las órdenes del Opus Dei para mantener oculto el secreto.

En su quinta novela, trata el tema de la masonería
con el personaje de Robert Langdon como protagonista. Esta vez, deberá salvar la vida de un viejo amigo, Peter Solomon, y evitar que un secreto muy bien guardado caiga en malas manos, con la ayuda de la científica del Instituto de Ciencias Noéticas Katherine Solomon, hermana de Peter. 

Fue publicada el 15 de septiembre de 2009 en Estados Unidos y el 29 de octubre de 2009 en España.

Es su sexta novela y la cuarta protagonizada por el experto en simbología Robert Langdon.
En esta novela, Langdon despierta en un hospital de Florencia con una herida de bala en la cabeza y sin poder recordar nada de lo sucedido, por lo que se ve inmerso, junto a la misteriosa Sienna Brooks, en una persecución policial mientras intentan descifrar el plan de un científico transhumanista demente obsesionado con Dante Alighieri y la sobrepoblación mundial.

Quinta entrega de la serie Robert Langdon. El profesor Langdon acude al Museo Guggenheim Bilbao para conocer un gran secreto que debe desvelar Edmond Kirsch, uno de los alumnos más brillantes de Langdon años atrás y que será trascendental para la humanidad. En ese momento estalla el caos y el protagonista debe huir a Barcelona para buscar y descifrar las pistas que dan acceso al gran secreto que respondería a las dos preguntas que se ha hecho siempre la humanidad: ¿De dónde venimos? y ¿adónde vamos?. "Origen" se desarrolla íntegramente en España. Barcelona, Bilbao, Madrid y Sevilla (ciudad donde se ambientaba parte importante de "La fortaleza digital") son los escenarios principales. Se publicó en octubre de 2017.

Tres de las cinco novelas de la serie con el personaje de Robert Langdon han sido adaptadas al cine, todas por el director estadounidense Ron Howard y protagonizadas por Tom Hanks:




</doc>
<doc id="41830" url="https://es.wikipedia.org/wiki?curid=41830" title="Coque">
Coque

El coque es un combustible sólido formado por la destilación de carbón bituminoso calentado a temperaturas de 500 a 1100°C sin contacto con el aire. El proceso de destilación implica que el carbón se limpia de alquitrán, gases y agua. Este combustible o residuo se compone entre un 90 y un 95 % de carbono. El nitrógeno, oxígeno, azufre e hidrógeno están presentes en cantidades menores. Es poroso y de color negro a gris metálico. El coque se utiliza en grandes cantidades en altos hornos para la elaboración de hierro aprovechando de las siguientes reacciones químicas:

Además de carbón mineral se han usado otros materiales como turba, carbón vegetal y petróleo crudo para elaborar materiales llamados coque, en este último caso se trata de coque de petróleo. En cuanto a temperatura de producción existen dos tipos de coque: el coque de alta temperatura, formado entre los 900 y los 1100°C, y el de baja temperatura, formado entre los 500 y los 700°C.

El coque es un combustible que se utiliza en la industria de la fundición de aluminio, acero y otros metales.

Se sabe que por lo menos desde el siglo IX se empleaba coque para calentar y cocinar en China. En las primeras décadas del siglo XI los forjadores chinos de la cuenca del río Amarillo ya usaban coque en sus hornos, solucionando el problema de habitar una región con pocos árboles.
En cuanto a Europa se sabe que en 1603 el inventor inglés Hugh Plat observó que el carbón podría calcinarse de manera igual que se hace con la madera cuando se produce carbón vegetal. Este proceso no se puso en práctica en Inglaterra hasta 1642 cuando se empleó coque para tostar malta en Derbyshire. El proceso para producir coque extrayendo sus gases empezó alrededor del año 1800 aunque la fabricación de coque mediante métodos simples se conocía ya hace siglos. En la Inglaterra de la Revolución Industrial los primeros trenes a vapor funcionaban con coque como combustible lo que producía una gran cantidad de emisiones de gas. Esto provocó la aparición de legislación ambiental que obligaba a las locomotoras a "consumir su propio humo". Hasta la década de 1960 se usaba coque para calentar hogares pero desde entonces ha sido reemplazado en este uso por petróleo, gas natural y energía eléctrica.

Venezuela es un país que produce grandes cantidades de coque de la refinación de su petróleo que es pesado y extrapesado.

Para el año 2002 la tonelada de coque estaba en 2 dólares. En 2009 el coque tuvo su mayor precio al tener un promedio de 140 dólares la tonelada. En 2019, el precio de una tonelada de coque estaba entre los 63 y los 68 dólares estadounidenses. Un derivado del coque llamado Coque calcinado su producción le permite tener un precio diez veces superior comercialmente llegando a ser entre 350 y 600 dólares la tonelada.En noviembre de 2019 Venezuela exportó 26,000 toneladas de coque a Cuba a un precio promedio de 65 dólares la tonelada para un total de 1,700 millones de dólares




</doc>
<doc id="41833" url="https://es.wikipedia.org/wiki?curid=41833" title="Damas">
Damas

Las damas es un juego de mesa para dos contrincantes. El juego consiste en mover las piezas en diagonal a través de los cuadros negros (o blancos en algunas variantes) de un tablero de 64 o 100 cuadros. Si alguien no mata (captura), perderá esa pieza al jugar contrario a la intención obligatoria de capturar (comer) las piezas del jugador contrario, pasando por encima de dichas piezas.

Existen varias modalidades, con distintos tableros y número de piezas. La versión internacional, también llamada «damas polacas», está reglamentada por la Fédération Mondiale du Jeu de Dames () y se juega en un tablero de 10×10 cuadros con dos jugadores, que disponen de 20 piezas cada uno (un jugador dispone de piezas negras y el otro de piezas blancas).

Las piezas normales se mueven 1 cuadrado en diagonal, y si alcanzan el borde de la zona del enemigo se convierten en «reinas» o «damas», que se pueden mover en diagonal hacia cualquier lado los cuadros que se desee, luego está al moverse por primera vez en el siguiente turno no podrá moverse.

¿Cómo hacer empate (tablas)?


Las damas es un juego para dos personas en un tablero de 64 casillas de 8×8 celdas (el mismo que se utiliza para jugar al ajedrez). El tablero se coloca de manera que cada jugador tenga una casilla blanca en su parte inferior derecha.

Cada jugador dispone de 12 piezas de un mismo color (unas blancas y las otras negras) que al principio de la partida se colocan en las casillas negras de las tres filas más próximas a él. El objetivo del juego de damas es capturar las fichas del oponente o acorralarlas para que los únicos movimientos que puedan realizar sean los que lleven a su captura (excepto las damas rusas, la variante "poddavki", en la que gana quién se queda sin fichas o las que tiene están bloqueadas).

Se juega por turnos alternos. Empieza a jugar quien tiene las fichas claras (blancas). En su turno cada jugador mueve una pieza propia.

Las piezas se mueven (cuando no comen) una posición hacia delante (nunca hacia atrás) en diagonal a la derecha o a la izquierda, a una posición adyacente vacía.

Al momento de comer piezas del oponente, se pueden comer varias en un mismo turno de forma diagonal hacia la derecha e izquierda para adelante y para atrás. Soplar no es obligatorio. Es una decisión del jugador de turno.

Una partida de damas finaliza cuando se llega a una de estas dos situaciones:

La partida también puede terminar en tablas (empate) si ambos jugadores quedan con un número muy reducido de piezas, tal que por muchos movimientos que se hagan no se resolvería la partida. La dama/reina siempre tiene prioridad para comer antes que cualquiera otra ficha. También la dama solo se mueve un cuadro tras cada captura. Una pieza normal puede capturar a la dama final.

El 20 de julio de 2007, en un artículo publicado en la revista Science, se encontró la resolución matemática para el juego de damas, siendo su resultado el de tablas. Es decir, si ambos contrincantes juegan siempre la partida perfecta en base al análisis completo y perfecto, las tablas están garantizadas.

Chinook es el nombre del software creado por Jonathan Schaeffer, el primer programa que primero jugó a las damas a nivel de torneo, llegando a ganar al campeón del mundo de la época, Don Lafferty, que finalmente resolvió el desarrollo de la partida hacia el empate ineludiblemente.

Se trataba en este caso del juego de damas de 12+12 fichas. Chinook nunca se usó para el juego de damas internacional de 20+20 fichas que es un juego tan difícil como el ajedrez.


La dama, después de comer una ficha contraria, puede quedarse en el casillero que esta utilizaba.



Las damas rusas son iguales que las "pool checkers" con la diferencia que si en medio de una captura se llega a la última fila se corona y se sigue la captura como dama y que empiezan las blancas. Se juega en partes de la antigua Unión Soviética y en Israel tienen diferente modo de juego.

Variante de las damas rusas en la cual, utilizando las mismas reglas, el objetivo se invierte: vence quien consigue quedarse sin piezas o tener bloqueadas las que tiene.Generalmente estas versiones pierde/gana son practicadas en casi todos los juegos de damas, pero no se consideran más que un simple divertimento. Sin embargo en Rusia esta variante no solo tiene su propia denominación, sino que goza de prestigio y se celebran campeonatos del mismo modo que con la variante Shashki.

El juego de las damas de columna (torres, postes, damas de varios pisos, tours, "columnas", "damas de columna" e incluso "damas chinas", inglés: "column draughts, russian towers") es una variante de las damas, conocida en Rusia desde el siglo XIX, en la que el juego se lleva a cabo de acuerdo con las reglas habituales de las damas, pero con la diferencia de que la chica golpeada no se retira del campo de juego, y se recoge debajo de la figura que golpea (una dama o una torre).
Las torres se mueven a lo largo de la tabla, "obedeciendo" a la tabla superior. Al tomar la torre de ella, solo se quita la parte superior de la pantalla. Si debajo de la parte superior se encuentra un cheque de otro color que el disparo como resultado de la batalla, la torre se convierte en la torre del oponente. Las reglas de los movimientos de las damas simples y damas corresponden a las reglas de las damas rusas.
Sobre la base de las damas rusas, pero de acuerdo con las reglas de las damas inglesas, el campeón del mundo de ajedrez Emanuel Lasker desarrolló el juego de damas "Laska" y en 1911 publicó su descripción. Lasker mostró que las torres solo pueden ser "de doble capa": es decir, no puede haber alternancia de colores. También mostró que durante el juego, el número de figuras de juego se mantiene constante o disminuye. Las damas de columna son un objeto curioso para las Ciencias matemáticas: combinadores, teorías de juegos de parejas con suma cero, etc.
El interés analítico y de juego también son las bandejas de columna y las damas de dos vías de columna.

Las «damas turcas», de nombre original «dama», se juegan en las mismas zonas que las damas rusas y en Turquía. Es la más diferente de todas las variantes.

El tablero es de ocho por ocho casillas. Cada jugador tiene dieciséis piezas, que al principio están colocadas en la segunda y la tercera fila más próximas a cada uno.


Esta es una variante peculiar de las damas. Se juega entre 2, 4 o 6 jugadores, cada uno con un color diferente. El tablero también es cuadriculado (en el caso de ser 6 jugadores, el tablero es hexagonal), pero con muchas más casillas.

Cada jugador comienza la partida con sus piezas en la región de uno de los vértices del tablero y su objetivo es trasladar todas sus piezas a la región del vértice opuesto.

El movimiento de las piezas es el siguiente: en cada turno el jugador mueve una sola pieza, bien desplazando la pieza hacia una casilla adyacente vacía, o bien saltando sobre otras piezas, bien sean suyas o de otro jugador. El salto se podrá realizar siempre que la casilla final a donde va la pieza esté vacía, y al igual que las damas convencionales se pueden realizar múltiples saltos. En este juego no se comen piezas, simplemente se mueven saltando unas sobre otras. Es interesante realizar movimientos de varios saltos, pues así las piezas llegan antes al vértice opuesto.

Gana el jugador que coloca todas sus piezas en la región del vértice opuesto en primer lugar.

Ningún jugador puede situar piezas definitivamente en la región opuesta hasta no haber sacado todas sus piezas de su propia región.






</doc>
<doc id="41851" url="https://es.wikipedia.org/wiki?curid=41851" title="Nudo">
Nudo

El término nudo puede referirse a uno de los siguientes artículos de esta enciclopedia:










</doc>
<doc id="41854" url="https://es.wikipedia.org/wiki?curid=41854" title="Arcelor">
Arcelor

Arcelor, segunda siderúrgica mundial, es un grupo empresarial multinacional. Su "ticker" en la Bolsa de Madrid es LOR.

Es el primer productor mundial de productos planos y productos largos en acero. Es un operador destacado en todos sus principales mercados: automóvil, construcción, electrodomésticos, embalajes e industria general. 

Desarrolla sus actividades en cuatro sectores:

Arcelor nace de la integración de tres grupos siderúrgicos europeos: Aceralia, Arbed y Usinor. El proyecto de integración se materializó el 18 de febrero de 2002 con la cotización en Bolsa del nuevo grupo. Sus acciones se negocian en las Bolsas de París, Bruselas, Luxemburgo y Madrid. En 2003 su cifra de negocio superó los 25.900 millones de euros y el volumen de ventas de 40,2 millones de toneladas, empleando a más de 98.000 trabajadores en 60 países. En 2005 se decide que Aceralia, Arbed y Usinor dejen sus marcas comerciales para usar la de Arcelor. En 2006 anuncia su fusión con la rusa Severstal para contrarrestar la OPA de la anglo-india Mittal, dando lugar a la mayor empresa siderúrgica del planeta.

En España tiene plantas en Avilés, Gijón, Sestao, Echévarri, Lesaca y Legasa.

Después de subir el precio de su primera oferta un 45% finalmente y luego de muchas ofertas Mittal Steel logró hacerse con Arcelor mediante una OPA por 30.000 millones US$. El resultado de esta larga y costosa operación es ArcelorMittal, un nuevo coloso siderúrgico que cuadruplica la producción del segundo acerero mundial (Nippon Steel). Produce 116 millones de toneladas anuales de acero, para un volumen de negocio de 60.000 millones de euros y beneficio neto de 7.000 millones de euros con una plantilla de 310.000 trabajadores y el diez por ciento del mercado mundial.



</doc>
<doc id="41855" url="https://es.wikipedia.org/wiki?curid=41855" title="Howard Dean">
Howard Dean

Howard Dean (East Hampton, Nueva York; 17 de noviembre de 1948) es un político estadounidense, exgobernador del estado de Vermont desde 1991 a 2003 y fue aspirante del Partido Demócrata a la Casa Blanca.

Dean se graduó en medicina en 1971 en la Universidad Yale y obtuvo su diploma de médico en 1978. Fue elegido representante del Congreso de Estados Unidos por Vermont desde 1982 hasta 1986, año en el que fue elegido lugarteniente del Gobernador de Vermont.

Howard Dean mantuvo la doble faceta, como médico y político, hasta 1991, cuando la repentina muerte del gobernador republicano de Vermont, Richard Snelling, lo impulsó a buscar ese cargo. 

Fue uno de los primeros en anunciar su aspiración a la candidatura para las elecciones presidenciales de EE.UU. de 2004, concretamente el 31 de mayo de 2002. Atrajo la atención de muchos activistas con sus acusaciones directas al gobierno de Bush, principalmente en lo referido a su estrategia en política exterior y la guerra de Irak, así como con el uso de Internet para recolectar fondos de sus seguidores. Cuando todas las encuestas le daban un triunfo arrollador sobre sus nueve contrincantes demócratas, su máximo rival John Kerry dio la sorpresa al ganar el "caucus" de Iowa (el primer estado donde se celebran las primarias) y a partir de ahí, la candidatura de Dean fue decayendo. Obtuvo solo una victoria simbólica en Vermont después de haberse retirado de la lucha por la candidatura.

Dean plantea la responsabilidad financiera para llegar a la justicia social y aboga por una política con un nuevo talante diplomático en el marco internacional sin renunciar a unas fuerzas armadas modernas y fortalecidas; pretende recuperar la esencia progresista del Partido Demócrata, apoya el derecho al aborto, la utilización de drogas con fines terapéuticos, la unión civil entre homosexuales, la creación de una Seguridad Social para jubilados y limitar la aplicación de la pena de muerte para casos extremos. 

Finalmente, Dean fue el presidente del Comité Nacional Demócrata entre 2005 y 2009, en un momento en el que los demócratas mantuvieron el control en la Cámara de Representantes y del Senado.


</doc>
<doc id="41856" url="https://es.wikipedia.org/wiki?curid=41856" title="Escudo (heráldica)">
Escudo (heráldica)

El escudo o blasón, en heráldica, es el soporte físico del blasón, situado en el centro de las armerías.

El blasón, también puede entenderse como la descripción heráldica de un escudo de armas o armerías de una persona perteneciente a la nobleza medieval o a la iglesia católica (heráldica eclesiástica). Esta descripción heráldica puede extenderse a los ornamentos exteriores, elementos paraheráldicos que acompañan al escudo. El escudo representa el escudo que portaban los hombres de armas, como uno de los elementos de su panoplia de combate. 

Las armas (o cargas) se presentan generalmente sobre un escudo, 

El escudo se caracteriza por su forma geométrica y sus potenciales divisiones, o mesa de espera, en la que están representadas las armas. El escudo puede tomar diferentes formas de acuerdo con el origen de su representación.

La mesa de espera es la forma geométrica del escudo, de una de sus partes o, eventualmente, de una pieza honorable, en tanto que la superficie que espera sus armas (el campo, las piezas y muebles eventuales). La mesa de espera puede ser el objeto de una partición prevista en el caso de armas compuestas.

La mesa de espera designa igualmente el escudo del aspirante que viene de recibir su panoplia de combate, pero que aún no tiene compuestas sus armas. Su escudo está aún en espera de ser armado. Esta situación puede ser simbolizada por un escudo de plata (siendo aquí el blanco una ausencia, simbolizando el espacio a llenar) o mejor aún por un escudo de acero que simboliza a la vez la superficie de metal aún no pintada y su capacidad para servir de espejo metálico listo para reflejar la imagen del que se acerque.

En las grandes armas la mesa de espera puede corresponder también a un emplazamiento reservado para los ancestros cuyas armas no se conocen. En este caso, el espacio dejado en el color del fondo (papel no coloreado) o en acero.

La elaboración de un escudo armado comienza simbólicamente por el trazado de la mesa de espera.

Partiendo de la base fundada en la representación que tienen los escudos heráldicos, pueden dividirse estos en diferentes clases según sean las entidades por ellos representadas. La clasificación primera y más general que debe hacerse bajo este concepto consiste en distinguirlos de dos clases: simples y compuestos. 


Pero atendiendo más a la categoría de las personas físicas o morales significadas por los escudos, se forman de estos los tipos siguientes:

Los escudos de familia pueden recibirse por alguno de estos títulos:

Se llama acolado el escudo familiar propio de una mujer casada o viuda, cuando se pone junto al de su marido y bajo un mismo timbre (corona o yelmo) resultando un doble escudo y, por extensión, cualquier otro escudo unido de igual manera.

El escudo, es decir, el soporte material del blasón, no tiene el mismo diseño según el lugar o la época, y puede revestirse de formas más o menos fantásticas (ver diagrama).



El trazado de las figuras geométricas puede ser efectuado sea cual sea la forma del escudo (o más generalmente, para toda forma que sirva de mesa de espera). La posición de sus líneas debe estar ajustada a la forma de la mesa de espera, de manera que las nueve regiones obtenidas estén equilibradas.

Las principales líneas de partición permiten trazar las piezas honorables del escudo y posicionar los muebles.

Para situarse en el escudo, este se divide en 9 zonas llamadas "puntos del escudo". Estos puntos son identificados por sus nombres, que varían según los autores, a excepción del "punto del centro" (5) llamado también "corazón" o "abismo" (ver la expresión "Mise en abyme").

Otros dos "puntos", citados por todos, son el "punto de honor" (A) y el "ombligo" (Ω). Pero si para algunos se trata de una superficie equivalente a las primeras, montadas sobre dos zonas (ver diseño), para otros se trata de puntos con un sentido geométrico, situados entre las fronteras 2-5 y 5-8.

Sin importar los autores, hay una simetría de denominación entre 1 y 3, 4 y 6, 7 y 9 donde "diestra" corresponde a 1, 4 y 7, y "siniestra" a 3, 6 y 9. - En heráldica, izquierda ("siniestra") y derecha ("diestra") son las del escudo, no las del espectador.

Estas diferencias de vocabulario o de definiciones no tienen consecuencias prácticas para el blasonado - lo que probablemente explica por qué estas diferencias subsisten.

Se denomina esmalte del escudo a cualquiera de los colores, metales o forros del mismo. Propiamente empleados, solo existen dos metales: oro y plata; cinco esmaltes: gules (rojo), azur (azul), sable (negro), sinople (verde) y púrpura (morado); y dos forros, armiños y veros, que no se definen por su color sino por su forma. Los esmaltes y metales, al ser representados en blanco y negro o sobre grabados, están sujetos a unas convenciones para distinguirlos.

Las figuras son de dos tipos, piezas heráldicas y naturales. De entre las primeras destacan las "piezas honorables" que son jefe, palo, faja, cruz, banda, barra, sotuer, cabrio, bordura, orla, perla o palio, campaña o punta, jirón, quila, trechor, franco-cuartel, cantón, escusón y lambel. Hay además piezas honorables disminuidas, como comble, vergeta, divisa, jefe en divisa, trangle, trangle ondulado, burelas, gemelas, gemelas en banda, tercias, tres tercias, tercias en sotuer, cruz estrecha, filete en orla, filete en cruz, filetes vibrados, filiera, flanquis, estaye, cotiza, contracotiza, bastón, traversa y bastón Pery.

Las principales variedades de figuras naturales son astros, cuadrúpedos (león), aves (águila), peces, insectos, figuras humanas (o partes del cuerpo), figuras artificiales (castillos, cadenas, etc.), y figuras quiméricas (dragón, grifo, águila bicéfala, unicornio, anfisbena, etc.)

La heráldica tal como se la entiende en la actualidad, fue desconocida en la Antigüedad. Sin embargo, desde la Edad del Bronce existieron emblemas que identificaban a dioses, naciones e individuos. Primitivamente, el escudo solía reproducir el cuerpo del guerrero conteniendo la transcripción de los tatuajes que conmemoraban sus hazañas y éxitos, o los colores, enseñas, signos o estandartes con que se pintaban, vestían o presidían para distinguirse en la batalla del enemigo y no ser confundidos con él.


El uso del escudo, blasón o señal distintivo y hereditario de cada casa noble, más o menos cargado de figuras según la antigüedad y/o hazañas de la familia, se remonta o debe su origen a los torneos que Enrique I de Alemania llamado "el Pajarero" instituyó para entretener a la nobleza en el ejercicio de las armas en tiempo de paz en Gotinga el año 934 . Gattroi de Previlli, introdujo este uso en Francia alrededor del año 1036 , y que se generalizó a fines del siglo XI con motivo de las Cruzadas, extendiéndose mucho después al resto de Europa. A fin de que los varios jefes y/o señores de que se componían aquellas expediciones fuesen conocidos por sus súbditos o vasallos, se introdujo el uso de pintar o bordar cada uno en su estandarte las armas que había elegido. Estas insignias no pasaban por lo regular de padre a hijo hasta el año 1260 bajo el reinado de san Luis de Francia en que quedaron fijas y hereditarias en las familias . Se llamaron "escudos de armas" porque se llevaban encima de las armas y en las insignias militares.

En los reinos de España, el rey Alfonso VII de León empezó a sustituir la cruz que se utilizaba en sellos y escudos, por dos castillos y dos leones a cuarteles, aludiendo al nombre de sus dos principales reinos; Castilla y León ; conservando las mismas armas todos sus sucesores hasta los Reyes católicos que con la unión de las coronas de Aragón a las de Castilla y la nueva conquista del reino de Granada, las aumentaron de manera que habiendo recaído todas en la Casa de Austria se añadieron a ellas las más principales de los estados que poseía.

En el siglo XIX estas eran algunas de las armas de las casas reinantes y los estados europeos y americanos: 





</doc>
<doc id="41857" url="https://es.wikipedia.org/wiki?curid=41857" title="Armería">
Armería

El término armería puede designar:



</doc>
<doc id="41866" url="https://es.wikipedia.org/wiki?curid=41866" title="Mata de Alcántara">
Mata de Alcántara

Mata de Alcántara es un municipio español de la provincia de Cáceres, Extremadura.

Se encuentra a 18 kilómetros de la frontera con Portugal, en la penillanura del río Salor y en la margen izquierda del Tajo. Es de naturaleza paleozoica pizarrosa del silúrico, con algunas fajas de cuarcita y granitos. La altitud sobre el nivel del mar es de 332 metros.

Originalmente es el bosque mediterráneo, que ha sido modificado por el hombre mediante la eliminación de árboles y arbustos para su aprovechamiento agrícola (siembra de cereales), ganadero (oveja, vacas, cerdos) y forestal (carbón vegetal, leña, bellotas). La encina es la especie predominante en estas dehesas, ya que es el árbol que mejor se adapta a los suelos pobres y la meteorología extrema. Algunos ejemplares cuentan con más de 500 años de antigüedad. Junto a la encina aparecen alcornoques, en áreas de mayor humedad y pequeños árboles, como el galapero (peral silvestre) y el acebuche. Los arbustos representativos son el cantueso, la jara, la zarza y la escoba. En cuanto a la fauna, en las dehesas habitan una importante cantidad de aves, entre las que destacan la cigüeña blanca, la grulla, el milano negro, el rabilargo y las palomas torcaces. También existen mamíferos como el zorro, el conejo, el tejón y la jineta.
Históricamente las dehesas de Mata de Alcántara tienen mucha importancia porque eran terrenos públicos y sus aprovechamientos eran comunales y beneficiaban a toda la población. Se pueden destacar la dehesa boyal, donde encontramos un mirador de aves y el Galapero. 


Históricamente en las orillas de las riberas se instalaron molinos de agua para la producción de harina y se construyeron las charcas de Greña y Cueto para el ganado y la pesca. Sin embargo, esto no ha limitado la presencia de importantes especies vegetales y animales que conforman un paisaje muy frondoso en contraste con los ecosistemas que le rodean. La vegetación predominante es el denominado bosque de galería, con árboles de hoja caduca, como olmos, chopos y fresnos, arbustos como la adelfa, el mimbre o la zarza y pequeñas plantas como el helecho o el junco.

A la sombra de esta abundante vegetación aparece un importante catálogo de aves, tanto zancudas (cigüeña blanca y negra, garza, cigüeñuelas, garcetas) como anátidas (porrones, somormujos, ánades). Además especies como el jabalí o el ciervo aprovechan la ribera para acercarse a beber cuando otros acuíferos están secos. 
Riveros del Tajo

La presencia de un gran río como el Tajo, que atraviesa la comarca se traduce en la presencia de zonas de riveros que conforman un paisaje de alto valor ecológico, que ha llevado a que estas zonas sean declaradas ZEPAS (Zona de Especial Protección para Aves).
Como consecuencia del relieve accidentado y de las fuertes pendientes, el hombre no ha tenido acceso a esta zona, lo que ha servido para mantener gran número de especies vegetales y animales.

Sin embargo la construcción de embalses ha inundado las orillas haciendo desaparecer el bosque de ribera. La vegetación predominante en las laderas es la encina y el acebuche, en algunos casos de gran tamaño. En las zonas de menor pendiente el aprovechamiento ganadero limita el crecimiento de los árboles. Las orillas que no han sido inundadas conservan bosques de álamos, fresnos o chopos.

En cuanto a la fauna la falta de presencia humana ha favorecido la permanencia de especies emblemáticas como el águila imperial ibérica, la cigüeña negra, el buitre negro o el águila real, que aprovechan cantiles y árboles para construir sus nidos. Otras especies interesantes son el buitre leonado, la golondrina dáurica, el alimoche, la nutria y el lucio.

En Mata de Alcántara destaca la existencia de un comedero para buitres cercano a la población y que constituye un punto de encuentro fundamental para la supervivencia de estas aves.

Mata de Alcántara tiene un clima mediterráneo de tipo "Csa" (templado con verano seco y caluroso) según la clasificación climática de Köppen.

En el término municipal, existen diversos vestigios arqueológicos representados por varias tumbas antropomórficas situadas en las inmediaciones de la ermita de San Lorenzo. Pertenecen a la época medieval.

El origen de este pueblo está ligado a la Reconquista y a la Orden Militar de Alcántara. La conquista de estos territorios fue llevada a cabo por Alfonso IX de León, que toma Alcántara en 1213 y los entrega a la Orden para su defensa y organización. A partir de este momento, se utiliza el sistema de encomienda para repoblar la zona. 

Esta localidad sufrirá, al igual que los demás pueblos, los efectos de la inestabilidad política de la corona de Castilla y León en el siglo XV , hasta la llegada al trono de los Reyes Católicos. La Orden de Alcántara se ve afectada con una guerra civil entre sus principales mandatarios, repercutiendo en los pueblos sobre los que ejerce su jurisdicción. El siglo XVI es el siglo de desarrollo y crecimiento de esta zona. 

En los siglos XVII y XVIII sufrirá, los efectos de las guerras con Portugal, que se traducen en saqueos y pillajes por parte del enemigo. En los inicios del siglo XIX , con la invasión francesa y la guerra de la Independencia, La Mata, como los demás pueblos de la zona, se verá afectado con destrucciones y saqueos. El topónimo de La Mata existe desde 1229. 

En 1594 formaba parte de la Tierra de Alcántara en la Provincia de Trujillo con la denominación de La Mata

A la caída del Antiguo Régimen la localidad de constituye en municipio constitucional en la región de Extremadura, Partido Judicial de Alcántara, denominándose sucesivamente Mata y La Mata que en el censo de 1842 contaba con 200 hogares y 1096 vecinos.

A partir de la segunda mitad del siglo XIX es cuando oficialmente se la denomina Mata de Alcántara, aunque para los habitantes del pueblo sigue siendo La Mata.

Durante el siglo XX Mata de Alcántara, como otros pueblos de España, sufrirá los efectos negativos de la emigración, perdiendo en el periodo de 1950 a 1980, algo más del 70% de su población con las consecuencias socioeconómicas que esto conlleva.

Destaca en esta población la iglesia parroquial de Santa María de Gracia, esbelto edificio de sillería.Consta de cuatro naves que hacen la longitud de 52 varas, siendo la segunda y cuarta más largas que la primera y tercera. Las dos primeras tienen de altura 13 varas. Están abovedadas con piedra labrada de granito. Las otras dos tienen sólo ocho varas de altura, pero carecen de la bóveda, que ha sido sustituida por madera sobre la que descansa directamente el tejado. Las paredes, pila bautismal, arcos de entrada, coro, torre y escalera es todo de cantería labrada. Rodea a este edificio un atrio. En su construcción se observan claramente dos partes definidas. En el interior de este edificio resulta de interés el retablo mayor, que corresponde a finales del siglo XVI, un pequeño retablo en el muro del Evangelio con pinturas representando a San Bernardo y a San Francisco del siglo XVIII, así como restos de pintura mural del siglo XVI. Obra del gran arquitecto extremeño Pedro de Ibarra.

También se encuentran en el municipio las ermitas de San Lorenzo, San Pedro y San Sebastián.

El visitante puede observar el entorno natural de sus dehesas y de sus charcas, como la de Cuetos, en la Ribera de la Mata, con una importante riqueza faunística, especialmente aves, cigüeñas blanca y negra, garzas,grullas y ánades.

Se mantiene una exquisita gastronomía representada por platos tan típicos como la chanfaina, la berzas con buche, las tencas o las mormenteras.


El municipio ha tenido la siguiente evolución demográfica desde 1900:



</doc>
<doc id="41870" url="https://es.wikipedia.org/wiki?curid=41870" title="Marcian Hoff">
Marcian Hoff

Marcian Edward "Ted" Hoff (Rochester, Nueva York; 28 de octubre de 1937) es el co-inventor del microprocesador que contribuyó con la idea de arquitectura en 1969 para los circuitos integrados. Entró en Intel en 1968.

La idea que tuvo este joven ingeniero electrónico fue brillante, cambiando el paradigma que hasta entonces se tenía sobre el desarrollo de los circuitos electrónicos. Ted había sido asignado a un proyecto para producir un conector de doce "microchips" destinados a fabricar una nueva calculadora electrónica que iba a lanzar al mercado la compañía japonesa Busicom. Cada uno de los "chips", que requería la citada máquina, debería de tener una función distinta. Ese era el tipo de arquitectura de diseño que se venía utilizando habitualmente para este tipo de aparatos electrónicos: un "chip" efectuaría los cálculos; otro controlaría el teclado y otro mostraría los dígitos en la pantalla. Se trataba de una tarea muy compleja y delicada: algunos de los circuitos integrados contenían más de 5000 transistores y todos ellos debían de encajar con absoluta precisión dentro del dispositivo de la calculadora.

Cuando Hoff valoró el trabajo que debía llevarse a cabo, se temió que el costo total del citado conector para los circuitos integrados que se necesitaban excediera al presupuesto previsto por Busicom. De modo que Ted se apartó del plan original del cliente y adoptó un criterio de diseño completamente diferente: en vez de tratar de incorporar a la calculadora una docena de "chips" especializados, decidió crear un solo chip que tuviera diferentes funcionalidades. En realidad este nuevo dispositivo sería una unidad de procesamiento central, pero pudiendo realizar funciones diferentes, por los requerimientos necesarios para el aparato donde fuera a ser instalado. 

Dos años más tarde, la idea de Ted Hoff dio sus frutos cuando Federico Faggin dirigió el proyecto MCS-4, desde abril de 1970 hasta junio de 1971, aportando su diseño innovador que hizo posible la integración del 4004 en un único chip, e Intel dio a conocer su semiconductor 4004, el que fue el primer microprocesador del mundo, en 1971.


</doc>
<doc id="41873" url="https://es.wikipedia.org/wiki?curid=41873" title="Peroné">
Peroné

El peroné, también llamado fíbula, es un hueso de la parte inferior de la pierna, largo, par, asimétrico, formado por un cuerpo prismático circular, con tres caras (externa, interna y posterior), tres bordes (anterior y laterales) y dos extremos: superior o cabeza, donde se destaca la apófisis estiloides ("corresponde con el número 1 de la imagen") y el maléolo lateral.

Se encuentra en la parte externa de la pierna. Se articula por dentro con la tibia mediante una articulación diartrosis del tipo artrodias, formando junto con la tibia la pinza tibioperonea, y por abajo con el astrágalo, formando la articulación "tibioperoneoastragalina".

La palabra peroné se remonta a 1670, para describir un cierre o broche y se utilizó por primera vez en inglés ("fibula") para el hueso más pequeño en la pierna (1706). Se deriva del griego περόνη ("perónē"), "cierre", "broche". El hueso se llama así porque se asemeja a un broche, como un imperdible moderno.

El peroné se osifica a partir de tres centros, uno en la parte central, y otros dos en cada extremo. La osificación se inicia en el cuerpo en la octava semana de vida fetal, y se extiende hacia las extremidades. Al nacer los extremos son cartilaginosos.
La osificación se inicia en el extremo inferior en el segundo año, y en la parte superior sobre el cuarto año de vida. La epífisis inferior es la primera en osificarse, se une con el cuerpo sobre el año veinte; la epífisis superior se une sobre el vigésimo quinto año.

El suministro de sangre es importante en la planificación de transferencia de tejido libre porque el peroné es comúnmente utilizado para reconstruir la mandíbula. El eje se suministra en su tercio medio por una arteria nutricia grande de la arteria peronea. También se perfunde de su periostio que recibe muchas ramas pequeñas de la arteria peronea. La cabeza proximal y la epífisis son alimentados por una rama de la arteria tibial anterior. En la recolección de médula ósea del fémur siempre se toma del tercio medio y los extremos penetrando (proximal 4 cm y distal 6 cm)

Debido a que el peroné soporta relativamente poco peso en comparación con la tibia, normalmente es más estrecho que la tibia en todos los animales, salvo en los tetrápodos más primitivos. En muchos animales, aún se articula con la parte posterior de la extremidad inferior del fémur, pero esta característica con frecuencia se ha perdido (como en los seres humanos). En algunos animales, la reducción del peroné ha continuado aún más que en la especie humana, con la pérdida de la articulación tarsal, y, en casos extremos (tales como el caballo), hay fusión parcial con la tibia. 


</doc>
<doc id="41875" url="https://es.wikipedia.org/wiki?curid=41875" title="Tibia">
Tibia

La tibia es un hueso largo de forma prisma triangular, par, situado en la parte anterior e interna de la pierna; presenta dos curvaturas de sentido contrario: la superior, cóncava hacia fuera; otra inferior, cóncava hacia dentro (en forma de S itálica). Como todo hueso largo, presenta dos epífisis, dos metáfisis y una diáfisis. La epífisis proximal participa en la articulación de la rodilla, relacionándose con el fémur, mientras que la epífisis distal comparte la articulación del tobillo con la epífisis distal del peroné.
La tibia se encuentra medial al peroné con el que se articula en sus extremos proximal y distal. Asimismo, entre ambos huesos existe una membrana fibrosa denominada "membrana interósea" que aporta estabilidad a ambas articulaciones al formar una sindesmosis.

La tibia, es el hueso más fuerte de los dos huesos de la pierna debajo de la rodilla en los vertebrados. Conecta la rodilla con los huesos del tobillo. Es comúnmente reconocido como el más fuerte hueso de carga del cuerpo.

La tibia empieza a osificarse a partir de tres centros; una para el cuerpo y otros dos, para las extremidades. La osificación se inicia en el centro del cuerpo, alrededor de la séptima semana de vida fetal, y poco a poco se extiende hacia las extremidades.

El centro de la epífisis superior aparece antes o poco después del nacimiento en cerca de 34 semanas de gestación; toma una forma aplanada, y tiene un proceso en forma de lengüeta delgada delante, que forma la tuberosidad tibial; que por la epífisis inferior aparece en el segundo año.

La epífisis inferior se fusiona con la diáfisis tibial aproximadamente a los 18 años, y la superior se funde sobre el segundo año de vida.

De vez en cuando existen dos centros adicionales, uno para el proceso en forma de lengüeta de la epífisis superior, que forma la tuberosidad, y uno para el maléolo medial.

El extremo que se articula con el fémur es ancho y tiene dos cavidades glenoideas interna y externa ("facies articularis superior") que se articulan con los cóndilos del fémur. Tiene una cara superior plana denominada "platillo tibial", de donde emerge una eminencia entre las cavidades glenoideas nombrada espina de la tibia o eminencia intercóndila ("eminentia intercondylaris"). Esta eminencia encaja en la fosa intercondílea del fémur, está dividida por una escotadura en dos: tubérculo interno ("tuberculum intercondylare mediale") y tubérculo externo (tuberculum intercondylare laterale); hay dos superficies triangulares y rugosas llamadas superficies preespinal ("area intercondylaris anterior") y retroespinal ("area intercondylaris posterior"). Las dos cavidades glenoieas descansan entre dos masa voluminosas denominadas tuberosidades de la tibia; la tuberosidad interna o cóndilos medial ("condylus medialis") presenta atrás una impresión rugosa para el tendón directo del semimenbranoso, por delante un canal para el tendón horizontal del semimenbranoso. La tuberosidad externa o cóndilo lateral ("condylus lateralis") posee un carilla articular llamada carilla peronéa de hueso de la tibia ("facies articularis fibularis"). Las dos tuberosidades están separadas por una escotadura vertical por delante de esta hay una superficie triangular, rugosa y llena de agujeros debajo de esta se encuentra el tubérculo anterior o tuberosidad anterior ("tuberositas tibiae") del cual parte una cresta que termina en el tubérculo de Gerdy para la inserción del músculo tibial anterior.

Consta de tres bordes y tres caras:



Tiene forma de pirámide, en su parte inferior tiene el maléolo medial ("malleolus medialis") que es la parte ensanchada que también se puede palpar y es el sitio de unión con el astrágalo (facies articularis inferior). Entre la tibia y el peroné esta la membrana polopoi.

En la cara posterior de la tibia esta la línea sólea ("linea musculi solei"), que es el lugar de inserción para el músculo sóleo.

Se encuentra en la parte anterior e interna de la pierna, paralela y a un lado del peroné, la escatadura en superficie lateral del extremo inferior de la tibia ("incisura fibularis"), para el peroné. Con el astrágalo por abajo y con el peroné por fuera y arriba("facies articularis malleoli medialis").

La tibia toma su suministro de sangre arterial de dos fuentes: una arteria nutricia, como la fuente principal, y los vasos del periostio derivados de la arteria tibial anterior.




La estructura de la tibia en la mayoría de otros tetrápodos es esencialmente similar a la de los seres humanos. La tuberosidad de la tibia, una cresta a la que el ligamento rotuliano se une en los mamíferos, es en cambio el punto para el tendón del músculo cuádriceps en reptiles, aves y anfibios, que no tienen la rótula.




</doc>
<doc id="41882" url="https://es.wikipedia.org/wiki?curid=41882" title="Lámina basal">
Lámina basal

La lámina basal es una fina capa de matriz extracelular que separa el tejido epitelial y muchos tipos de células, como las fibras musculares o las células adiposas, del tejido conjuntivo. Suele confundirse con la membrana basal, pero en realidad forma parte de ella junto a la lámina reticular. Se encuentra constituida por proteínas fibrosas (elastina, colágeno, fibronectina), proteoglicanos y glicosaminoglucuronanos. Es de vital importancia en señalización celular la interacción que establece a través de la laminina con las integrinas.

Cuando aparece rodeando fibras musculares o adipocitos se la denomina lámina externa.

La lámina basal solo es observable con detalle a microscopio electrónico y está compuesta por una matriz electrodensa de entre 50 y 100 nm que consta a su vez de lámina lúcida y lámina densa.

Cuando hay una alteración en el crecimiento del tejido epitelial que produce la infiltración y rotura de la lámina basal se llama tumor invasivo o cáncer.



</doc>
<doc id="41887" url="https://es.wikipedia.org/wiki?curid=41887" title="Glándula sudorípara">
Glándula sudorípara

La glándula sudorípara es una glándula que está situada en la dermis reticular e hipodermis y consta de largos y delgados tubos, cerrados por el extremo inferior, donde se apelotonan, formando un ovillo. Por los poros que se abren al exterior, segregan el sudor, grasa sebácea líquida, con sabor salado, y una textura particular.

En dermatología las glándulas sudoríparas forman junto con las glándulas sebáceas, los folículos pilosos y las uñas, las llamadas faneras o "anexos cutáneos".

Las glándulas sudoríparas se dividen en dos grupos:
las glándulas sudoríparas ecrinas y las glándulas sudoríparas apócrinas. 

Están formadas por un glomérulo secretor y un conducto excretor largo que desemboca directamente en un orificio de la superficie de la piel.

Existen unas 600 glándulas sudoríparas por centímetro cuadrado de piel, con mayor concentración en palmas de las manos, plantas de los pies y región frontal de la cara.

El glomérulo se encuentra en la profundidad de la piel, cerca de la dermis.
La porción secretora o adenómero es de tipo acinar, con una luz estrecha, está formado por epitelio cúbico secretor.<br>
La zona basal del acino está formada por célula mioepiteliales contráctiles, una membrana basal y terminaciones nerviosas.<br>
El conducto es largo y está constituido por dos capas celulares: ductal luminal y 
ductal basal, no secretoras. 
Segregan un litro al día en condiciones basales y pueden perder hasta 10 litros en condiciones extremas.

Las glándulas sudoríparas desempeñan funciones importantes en el metabolismo hidroclorado, en la termorregulación por la evaporación del sudor y humedad de la superficie cutánea que también está relacionada con la prensión de los objetos con las manos.

El análisis de la distribución tridimensional de las fibras nerviosas, mostró que envuelven las capas de células mioepiteliales que rodean las porciones secretoras. En las glándulas exocrinas salivales, las fibras nerviosas se extienden hasta las células mioepiteliales en forma de estrella, pero no se envuelven en los acinos secretores. La disposición espacial de las fibras nerviosas en relación con las células mioepiteliales, sugiere que las múltiples células mioepiteliales de las glándulas sudoríparas contraen sincrónicamente sus porciones secretoras.<br>
El control de la producción del sudor por las glándulas sudoríparas ecrinas, lo realiza el sistema nervioso vegetativo simpático; al aumentar la actividad del sistema simpático, aumenta la cantidad de secreción de sudor.

Estas desembocan en el folículo pilosebáceo saliendo al exterior su contenido junto con el sebo. Están formadas por un gran lóbulo secretor y un conducto excretor dérmico que desemboca en el folículo pilosebáceo. Estas glándulas apocrinas están en involución y son poco importantes en el ser humano, son poco numerosas y se localizan en axila, periné, pubis, conducto auditivo externo y en el párpado. Estas glándulas son las encargadas de la secreción de las feromonas.<br>
La glándula mamaria es una glándula sudorípara apocrina modificada.

Las glándulas sudoríparas apocrinas producen sustancias que al ser descompuestas por bacterias son las responsables del olor característico de zonas como las axilas y los órganos sexuales. Los niños antes de la pubertad tienen un olor diferente a los adultos ya que no producen sudor apocrino y su secreción sebácea es menor.

Las glándulas sudoríparas contienen células madre con potencial regenerativo. Se demostró que las glándulas sudoríparas de ratón, albergan células madre en los conductos sudoríparos y los glomérulos secretores, que responden de manera diferencial a las lesiones y exhiben potenciales regenerativos distintos.<br>
La inervación parasimpática mantiene la población progenitora de las glándulas salivales en un estado indiferenciado, que es necesario para la organogénesis de la glándula.

La inflamación de una glándula sudorípara se llama hidradenitis.



</doc>
<doc id="41898" url="https://es.wikipedia.org/wiki?curid=41898" title="Tribu">
Tribu

Tribu es un concepto social, político y antropológico no enteramente definido y lleno de polémica. Dependiendo de autores, épocas y tendencias, el concepto de tribu tiene significados muy diversos y sirve a propósitos diferenciados. Surgen por tanto destacadas discrepancias entre los diversos científicos sociales como los antropólogos según el enfoque desde el cual se quiera obtener la definición exacta. El concepto de tribu ha sido utilizado así mismo para manipular la política de los sujetos colonizados y establecer subdivisiones o minimizar la importancia de las entidades socio-políticas principalmente en África y en Asia.

El fenómeno tribu urbana surge en la segunda mitad del siglo XX con la crisis de una modernidad industrializada, burocrática e individualista, que está dando paso a una reivindicación de contacto humano, físico y, sobre todo, de una nueva imagen de los jóvenes.
Llamamos tribu urbanas a las pandillas, bandas o simplemente agrupaciones de jóvenes y adolescentes, que se visten de modo parecido y llamativo, siguen hábitos comunes y se hacen visibles, sobre todo, en las grandes ciudades. Adolescentes y jóvenes ven en las tribus la posibilidad de encontrar una nueva vía de expresión, un modo de alejarse de la normalidad que no les satisface y, ante todo, la ocasión de intensificar sus vivencias personales y encontrar un núcleo gratificante de afectividad. Una especie de cobijo emotivo por oposición a la intemperie urbana contemporánea que, paradójicamente, les llevaba a la calle. Sus miembros acuden a ellas, entre otras cosas, para tener su propia expresividad, para sentir la cohesión con los otros, para encontrar apoyo sentimental y para compartir experiencias y actitudes con quienes consideran iguales. Una ocasión para la evasión de un mundo frío y tecnologizado que ha hecho de la distancia y el aislamiento su naturaleza propia.

El concepto de tribu se encuentra en las culturas judía y greco-latina; originariamente hacía referencia a un conjunto culturalmente homogéneo de familias con un antepasado común real o mítico. A su vez las tribus agrupadas podían constituir un conjunto cultural mayor asimilable al de protonación.

Marshall sugiere la siguiente definición: "grupo social asociado a la familia, junto con la autonomía de una nación". Un interaccionismo simbólico relevante entre los miembros y un claro lugar de socialización de los mismos, que debe perdurar por más de una generación y con parentescos y obligaciones comprobables por los observadores y documentado por ellos. Los artefactos, las tradiciones y evidencias, tales como una carta magna, un libro sagrado, un folclore y un idioma, para un territorio que fue históricamente delimitado.

El término tribu, tomado del vocabulario de las instituciones políticas de la Antigüedad que incluye otros términos para expresar la afiliación por nacimiento a un grupo (Benaveniste, 1969), fue utilizado en primer lugar por los evolucionistas del siglo XIX para designar la organización política de sociedades situadas en un determinado estadio de la evolución de la humanidad. Escapando al fracaso de los conceptos evolucionistas, sigue siendo usado en antropología, asociado a la aproximación funcionalista a las ciudades sin Estado, frecuentemente denominadas Sociedades Tribales. El término tribu se aplica de hecho a sociedades muy distintas en cuanto a su forma de mantener el orden social sin que exista una autoridad centralizada. Así, la tribu nuer es la mayor unidad política reunida, frente a otras unidades parecidas, y que regulan mediante el arbitraje sus diferencias internas (Evans-Pritchard, 1940). Esta definición subraya la dimensión territorial de la tribu, a la inversa de la definición evolucionista, que oponía organización tribal arcaica y organización territorial.

El término tribu aparece en la antigua Roma, cuando se agremian varias bandas, clanes o conjunto de personas emparentadas diferentes entre sí, pero que tienen la necesidad de formar una comunidad y crear instituciones para que sea posible la convivencia entre las personas que han decidido vivir juntas y unidas, conociendo las diferencias entre ellas y entre las tribus.

La palabra tribu ha originado del latín numerosos vocablos como:

Del latín "tribus", en referencia a la original división étnica tripartita de la Antigua Roma: Ramnes ("Ramnenses"), Tities ("Titienses") y "Luceres", que según Varrón se corresponderían con los latinos, los sabinos y los etruscos, respectivamente.

Ramnes viene de Rómulo, líder de los latinos, Tities por Tito Tacio, líder de los sabinos, y Luceres por Lucumon, líder del ejército etrusco, que habría ayudado a los latinos. Para Tito Livio, las tres tribus eran, de hecho, escuadrones de jinetes, en lugar de divisiones étnicas. Cada tribu aportaba cien jinetes, llamados "celeres" para formar las "Centurias inauguratae".

Tanto para evolucionistas como para funcionalistas, la tribu es un grupo social con una organización preestatal, basada en la agrupación de numerosas familias. Para los evolucionistas, estamos ante uno de los cuatro estadios esenciales que marcan la evolución de la sociedad: banda, tribu, jefatura y Estado, donde la relación con el territorio (inexistente, con respecto a las bandas y tribus, necesaria por lo que hace para entender a la jefatura y al Estado es clave por categorizarlas. El funcionalismo considera que la existencia o no de una asociación territorio/grupo social no es el hecho determinante, sino que se basa en si el orden social está fundado en un poder centralizado y existe segmentación social (jefatura y Estado) o el poder no está centralizado y no existe segmentación social (banda y tribu).

La generalización del uso del concepto de “tribu” a diferentes grupos sociales de cualquier parte del mundo hace aflorar contradicciones en cualquiera de las dos aproximaciones: en la Polinesia las tribus tienen una cierta segmentación social (aristocracia tribal) y poder central (el jefe de la tribu asume funciones ejecutivas, militares y económicas, además de las religiosas, que van más allá de las típicas de un “big man”;); en Nueva Zelanda las tribus ("iwi") son el resultado de la agregación de grupos de descendencia cognaticios ("hapu") con un territorio claramente delimitado; en la India los estudios etnográficos desarrollados entre 1881 y 1961 nos muestran que estamos ante unas 50.000 subcastas agrupadas en 3000 castas que dan lugar a 427 tribus, agrupación que no responde a ninguno de los dos ejes mencionados: se presume que su origen proviene de la evolución en la división del trabajo y de la intrusión del legislador brahman, que al codificarlo lo fijó. Por otra parte, en la sociedad árabe preislámica las tribus venían determinadas por hechos religiosos (como, por ejemplo, compartir sacrificios); en Siberia se basaban en uniones exogámicas de filiación patrilineal (intercambio de mujeres); en Japón una misma palabra ("zoku") designa tanto a familia como a tribu o raza; en Alaska las tribus estaban formadas por casas (que son agrupaciones diferentes de familias, también existentes en sociedades arcaicas de Guinea o Madagascar o en la Edad medieval de Europa o del Extremo Oriente) que mantenían una fuerte autonomía económica y política... Una verdadera constelación de significados bajo un concepto demasiado potente como para que pueda ser descrito de una única forma, sin olvidar que la aproximación a estas realidades se ha hecho muchas veces con ojos románticos que buscan (y por lo tanto, ven) el exotismo de aquello diferente. Otro aspecto que complica la conceptualitzación de tribu viene dado por la falta de teorías documentadas empíricamente que demuestren cómo las tribus evolucionan hacia las jefaturas.

Con todo, y teniendo en cuenta que ningún antropólogo ha podido ver en estado puro ni bandas ni tribus ni jefaturas, puesto que la antropología apareció mucho después del nacimiento del Estado, hay evidencias arqueológicas, relatos históricos y hechos actuales que permiten establecer una serie de hechos básicos asociables a las tribus: grupos sociales con producción no intensiva de alimentos (horticultura y pastoreo), poblados y grupos de filiación sin una estratificación social determinante (aunque, como pasa con los nuer de Sudán, cuando las tribus son muy grandes aparece otro tipo de segmentación denominado OLS: organización en linajes segmentarios, que apuntan a antepasados comunes), un gobierno central insuficiente como para forzar el cumplimiento de sus decisiones (como ejemplo del impacto que en la vida social tiene el carecer de un poder central fuerte, Bronislaw Malinowski describe con mucho detalle en el capítulo IV ("Canoas y Navegación") las extensas y prolijas negociaciones y reglamentaciones necesarias para la organización social del trabajo en estos grupos sociales categorizables como tribus,- que esta carencia hace imprescindibles en el momento en que los jefes de las tribus de las comunidades de Tobriand y Kitava piden construir una canoa para ellos), derecho basado en la consanguinidad y no en el contrato, y, finalmente, absoluta desigualdad de género.

En general en África se ha asimilado el concepto de tribu al de nación como en el caso de entidades sociopolíticas estatales como los Yorubá, los Mandinga, los Mossi, y centenares de conjuntos culturales y estatales que en ningún caso pueden ser considerados como tribu. Este tipo de definición peyorativa minimizaba la importancia de las entidades sociopolíticas africanas como forma de justificar la intervención del colonizador con un sistema supuestamente superior. Asimismo los antropólogos colonialistas hicieron uso del término como herramienta de división que justificaría las fronteras impuestas. Ese es el caso de la división del grupo cultural Fang en grupos menores atendiendo a criterios lingüísticos no científicos.

Una reciente definición del término en la página aportada por el antropólogo y defensor de los derechos indígenas, Stephen Corry, pone en relación el concepto de "tribu" con la adscripción "indígena" y se concentra en el componente diferencial de las formas de vida respecto a los modelos dominantes. El aporte de Corry es que los "pueblos indígenas tribales" preservan "formas de vida eminentemente autosuficientes", durante generaciones, que se distinguen de aquellas de la "sociedad mayoritaria", a la cual los sujetos "indígenas tribales" no se integran.

Como análisis crítico final, hace falta decir que la enorme dificultad que la Antropología ha encontrado en el momento de definir “tribu” pone de relieve las carencias reales de los fundamentos empíricos de la vía antropológica de su estudio.

"Tribus urbanas": Pandillas, bandas, o, simplemente, agrupaciones de jóvenes y adolescentes, que se visten de modo parecido y llamativo, siguen hábitos comunes y se hacen visibles, sobre todo, en las grandes ciudades.

Adolescentes y jóvenes suelen ver en las tribus la posibilidad de encontrar una nueva vía de expresión, un modo de alejarse de la normalidad que no les satisface, y, ante todo, la ocasión de intensificar sus vivencias personales y encontrar un núcleo gratificante de afectividad.
Se trataba, desde muchos puntos de vista, de una especie de cobijo emotivo por oposición a la "intemperie" urbana contemporánea que, paradójicamente, les lleva a la calle.

Nos encontrábamos, pues, ante un fenómeno profundo de la vida de la segunda mitad del siglo XX: la crisis de la modernidad industrializada, burocrática e individualista, que está dando paso a una reivindicación de contacto humano, de contacto físico y, sobre todo, de una nueva imagen de los jóvenes y para los jóvenes.




</doc>
<doc id="41912" url="https://es.wikipedia.org/wiki?curid=41912" title="Calcáneo">
Calcáneo

El calcáneo (del latín "Calcaneus" o "Calcaneum") es uno de los siete huesos del pie o tarso, corto, asimétrico e irregular. Ha tomado su nombre de "“calcare”," pisar, por ser el hueso que forma el talón. Su diámetro antero-posterior es el mayor. Consta de seis caras o lados: superior e inferior, laterales y anterior y posterior. Este hueso constituye el talón del pie.

Se encuentra en la fila posterior, dirigida de posterior hacia anterior junto al astrágalo y escafoides. Se articula con el astrágalo por craneal y con el cuboides por anterior. Constituye el primer punto de apoyo del pie durante la marcha, situándose en una de las zonas peor irrigadas del cuerpo y protegido por la almohadilla plantar de tejido adiposo o grasa plantar formada por columnas de tejido adiposo separadas por tabiques de tejido fibroso, la recubre plantarmente la aponeurosis plantar o fascia, esta grasa plantar tiene función amortiguadora, la cual está implicada en diversas enfermedades, como la fascitis o el espolón calcáneo.

La posición del calcáneo en relación al astrágalo (articulación subastragalina) y al suelo determinan la posición de retropié (parte posterior del pie formada por el astrágalo y el calcáneo) en varo, en valgo o neutra. Los retropiés varos y sobre todo, los retropiés valgos, son responsables de distintas enfermedades del aparato locomotor y contribuyen a que aparezcan alteraciones de la marcha normal fisiológica, con consecuencias clínicas importantes (dolor, sobrecargas, aplanamiento, fatiga muscular, juanetes, etc.) tanto a nivel de pie como a nivel del miembro inferior. De todo esto se deriva que su posicionamiento espacial es muy importante para contribuir a una marcha correcta y a la salud del resto del conjunto articular del pie.

Es un hueso que al ser cúbico posee 6 caras, cuyos detalles son:



</doc>
<doc id="41917" url="https://es.wikipedia.org/wiki?curid=41917" title="Baltasar Garzón">
Baltasar Garzón

Baltasar Garzón Real (Torres, Jaén, Andalucía; 26 de octubre de 1955) es un jurista español. Fue juez desde 1981 y magistrado del Juzgado Central de Instrucción n.º 5 de la Audiencia Nacional desde 1988 hasta 2012 (excepto desde mayo de 1993 hasta mayo de 1994), tuvo a su cargo la investigación de algunos de los delitos de mayor relevancia que se produjeron en España durante aquella época: crímenes contra la humanidad, terrorismo, terrorismo de Estado, narcotráfico, corrupción política y delincuencia económica.

Se presentó como candidato independiente a diputado en las listas del PSOE en 1993 y, al constituirse el ejecutivo, fue nombrado delegado del Gobierno en el Plan Nacional sobre Drogas, con rango de secretario de Estado.

El 22 de febrero de 2012 fue expulsado de la carrera judicial tras haber sido condenado por el Tribunal Supremo a once años de inhabilitación por un delito de prevaricación cometido durante la instrucción del caso Gürtel.

Desde entonces, ha ejercido, entre otros cargos, el de asesor del Tribunal Penal Internacional de La Haya o el de director de la defensa jurídica del fundador de Wikileaks, Julian Assange. El 29 de noviembre de 2012 recibió de manos de la presidenta de Argentina, Cristina Fernández de Kirchner, su documento de identidad de residente extranjero en Argentina. Allí fue coordinador de asesoramiento internacional en la secretaría de Derechos Humanos del Ministerio de Justicia, hasta que renunció al puesto en enero de 2016, tras el fin del mandato de Kirchner. En Colombia, asesoró a la Fiscalía General. En Ecuador fue designado coordinador de la Veeduría Internacional a la Reforma de la Justicia, cuyo informe final fue presentado el 13 de diciembre de 2012.

Es doctor honoris causa por la Universidad de Jaén, y por veinte universidades más en el mundo.

Actualmente es presidente del partido político Actúa.

Aprobó las oposiciones para juez en 1981 y su primer destino fue Valverde del Camino, en la provincia de Huelva. Posteriormente fue trasladado al Juzgado de Primera Instancia e Instrucción de Villacarrillo (Jaén). En 1983 ascendió a magistrado, siendo destinado al Juzgado de Primera Instancia e Instrucción n.º 3 de Almería. En 1987 fue nombrado inspector delegado para Andalucía del Consejo General del Poder Judicial y el 29 de enero de 1988 tomó posesión como magistrado del Juzgado Central de Instrucción n.º 5 de la Audiencia Nacional.

Baltasar Garzón dirigió importantes operaciones contra el tráfico de drogas, especialmente en Galicia. Con la operación Nécora, en 1990, desarticuló la organización liderada por Laureano Oubiña y, con la operación «Pitón» (1991), detuvo a los integrantes del llamado «clan de los Charlines» que operaba en las costas gallegas.

En relación con la operación «Nécora», durante una conferencia en 1994, el magistrado declaró que, a pesar de lo que se manifestaba desde algunos foros, con la legislación vigente en ese momento no se podía luchar eficazmente contra las organizaciones criminales, particularmente contra las redes de narcotraficantes, y se posicionó en una postura crítica hacia el Gobierno y las instituciones, afirmando que en estos aspectos el sistema fallaba "estrepitosamente". Poco antes, en otros medios y en relación con el mismo caso, el entonces presidente del Gobierno, Felipe González, había declarado que hubiera preferido una sentencia "más dura", y que la intención del ejecutivo a este respecto era "romper el espinazo" a las redes del narcotráfico.

El tribunal sentenciador de la operación «Nécora» dedicó cuarenta folios de la sentencia a analizar las escuchas telefónicas ordenadas por Garzón y lo censuró por haber ejercido «un control formal, pero no de fondo, de los pinchazos hechos por la policía». De hecho, la actuación de Garzón en esta operación fue criticada desde diversos ámbitos, ya que, además de no haberse incautado ni un solo gramo de droga, el 90% de los imputados terminó absuelto por falta de pruebas.

Ricardo Portabales, uno de los "arrepentidos" cuyo testimonio fue clave en la operación para imputar a Oubiña, declaró años después que la operación Nécora "fue un fraude", con el que supuestamente se habría visto obligado a colaborar por presiones de funcionarios adscritos a la investigación que le habrían preparado lo que tenía de declarar.

Tras su paso por la política en las listas electorales del PSOE, Garzón volvió a la Audiencia Nacional, donde sus investigaciones contra el llamado terrorismo de Estado contribuyeron también a denunciar las acciones de José Barrionuevo Peña, ministro de Interior del PSOE, con relación a los Grupos Antiterroristas de Liberación (GAL), la llamada "guerra sucia" contra el terrorismo.

Respecto al secuestro de Segundo Marey, caso por el que se dieron a conocer los GAL, Rafael Vera, condenado por el Tribunal Supremo, lo recurrió ante el Tribunal Europeo de Derechos Humanos, que dictó sentencia el 6 de enero de 2010.En dicha sentencia se afirma que "la imparcialidad del juez de instrucción Nº 5 de la Audiencia Nacional Española podría estar en entredicho" por las "relaciones personales conflictivas" y la "enemistad manifiesta" entre el demandante y el magistrado (Garzón)". Dicho Tribunal no condenó a España, pues otro juez, esta vez Eduardo Moner, del Tribunal Supremo, llevó a cabo una nueva instrucción.

Garzón ha investigado también a la organización terrorista Euskadi Ta Askatasuna (ETA) y lo que se considera su entorno:

En 1997 el juez de la Audiencia Nacional Javier Gómez de Liaño procesó a los dos máximos directivos del Grupo PRISA Jesús de Polanco y Juan Luis Cebrián, junto a todo el Consejo de Administración de Sogecable, por un presunto delito de apropiación indebida del dinero depositado por los abonados a Canal +. Al año siguiente Polanco lo denunció por prevaricación en la instrucción del caso, logrando que fuera condenado por dicho delito y apartado de la carrera judicial. Esta condena por prevaricación a Gómez de Liaño fue celebrada por Felipe González, Juan Luis Cebrián y Jesús Polanco con una cena en un restaurante de Madrid. En 2000 Liaño recibió un indulto del gobierno de José María Aznar que le permitió volver a la carrera judicial, con la condición de no incorporarse a la Audiencia Nacional durante 25 años. Finalmente, en julio de 2008 el Tribunal Europeo de Derechos Humanos, recordando «la importancia que para una sociedad democrática tiene la confianza que los tribunales deben inspirar a los justiciables», estimó que el juicio contra este juez diez años antes no había ofrecido la suficiente «apariencia de imparcialidad» y condenó al Estado español al pago de una multa de 5.000 euros por «daños morales».
La actuación de Baltasar Garzón en este caso Sogecable causó polémica, ya que el 3 de septiembre de 1997 dictó un auto en el que se abstenía de resolver la recusación que Juan Luis Cebrián había presentado contra Liaño, argumentado que había tenido conocimiento de una trama contra el presidente de PRISA, Polanco, urdida por Gómez de Liaño, el también juez Joaquín Navarro Estevan y el conocido abogado Antonio García Trevijano. En medio de un gran escándalo, el Tribunal Supremo abrió un sumario para investigar estos hechos y terminar archivándolo poco después. «La inconsistencia de su denuncia desembocó en el rápido archivo de la causa, pero el terreno quedó abonado para que prosperara la posterior querella [por prevaricación] de Polanco contra Liaño. La conducta de Garzón fue interpretada como un intento de aproximarse al grupo Prisa tras los duros ataques de los que había sido objeto por "El País" con motivo de su papel en los sumarios de los GAL. Garzón logró su propósito pero gran parte de los jueces y fiscales de la Audiencia Nacional reprobaron duramente su actitud, llegando en algunos casos hasta el extremo de retirarle el saludo».
El periodista de la Cadena SER, propiedad de PRISA, Carlos Carnicero afirmó que Garzón había pactado estas acusaciones suyas contra su hasta entonces amigo Gómez de Liaño en un desayuno en Nueva York con Antonio Navalón, Matías Cortés y Jaime García Añoveros, los tres estrechamente vinculados a Polanco y PRISA (García Añoveros incluso era miembro del Consejo de Administración del Grupo PRISA). «A partir de ese momento, Garzón recibió un trato exquisito por parte de "El País"». Según escribió el propio Gómez de Liaño «A pesar de la inconsistencia [...] de la recusación, lo que me hubiera permitido rechazarla [...] por fraude de ley y abuso de derecho, me pareció adecuado abrir el trámite, apartarme provisionalmente del asunto y dejar que fuera Baltasar Garzón [...] quien resolviera el incidente procesal. Estaba seguro de que la recusación no podría prosperar. [...] El objetivo de Baltasar era apartarme de la instrucción. Según se descubrió posteriormente, él había urdido el incidente de recusación con personas como el exministro de Hacienda y consejero de PRISA, Jaime García Añoveros, quien se aprestó a comparecer en el incidente en calidad de testigo para responder a una lista de preguntas que llevaba en la cartera. Todo demostraba que Baltasar estaba comprometido con el asunto y que cumplía sin rechistar el encargo encomendado.»

Garzón cobró fama internacional por promover una orden de arresto contra el exdictador chileno Augusto Pinochet por la muerte y tortura de ciudadanos españoles durante su mandato y por crímenes contra la Humanidad, basándose en el informe de la Comisión chilena de la verdad (1990-1991) y en el caso Caravana de la Muerte instruido en Chile por el juez Juan Guzmán Tapia.

Garzón asimismo abrió la posibilidad de que se levantaran en España cargos de delitos de lesa humanidad contra ciudadanos argentinos por la desaparición de ciudadanos españoles durante la dictadura argentina de 1976-1983. En ese marco, el 19 de abril de 2005, la Audiencia Nacional condenó al represor Adolfo Scilingo a 640 años de prisión.

No obstante, sus actuaciones en el caso argentino no están exentas de polémica, ya que informaciones periodísticas posteriores documentaron la negativa de Garzón a investigar aquellas complicidades y responsabilidades en la dictadura argentina llevadas a cabo por funcionarios españoles o personas radicadas en España. Asimismo, la organización Nuevos Derechos del Hombre, que lidera el dirigente de la Unión Cívica Radical Hipólito Solari Yrigoyen, criticó al gobierno argentino por su designación como asesor de la Cámara de Diputados de la Nación, ya que fue decisión de Garzón no extraditar a Argentina ni imputar al ex comisario de la Policía Federal Roberto Almirón, en el marco de la Causa Triple A instruida por el Juez Federal Norberto Oyarbide, advirtiendo Yrigoyen que también puso trabas a la extradición de María Estela Martínez de Perón.

En el año 1998, en el marco de la causa por los vuelos de la muerte, el Ministerio de Defensa español remitió a su juzgado un listado de altos oficiales españoles que acudieron a Argentina en plena dictadura para recibir entrenamiento y compartir experiencias. Además, Víctor Basterra, fotógrafo superviviente de la ex ESMA, declaró ante Garzón que entre sus captores se encontraba un ciudadano español, señalando al oficial de la armada española Coronel(R) Cristóbal Gil y Gil. En el caso de Gil y Gil, el magistrado solo lo llamó a declarar como testigo, pero en el caso del resto de los oficiales ni siquiera fueron citados. Abundando en estos hechos, el coronel español Amadeo Martínez Inglés, uno de los enviados a Argentina para el Curso de Estado Mayor en plena dictadura militar, declaró al diario argentino "Página 12": ""Cuando regresé a Madrid, tuve que hacer un informe exhaustivo y todo lo pasé a la división de inteligencia, que a su vez tuvo que haber informado al gobierno español. El gobierno español tuvo conocimiento, cuando regresé en diciembre del año 81 (de lo que pasaba en la Argentina). (El gobierno español) Vio todo lo que llegó a mí en un informe que se le pasó"." Martínez Inglés, que estaba en esa lista remitida por Defensa, tampoco fue citado a declarar, a pesar de la gravedad de sus manifestaciones.

El 26 de diciembre de 2003, en el marco del sumario 25/2003, Baltasar Garzón dictó auto de procesamiento contra Jamiel Abdullatif Al Banna y Omar Deghayes por presunto delito de integración en organización terrorista. En la misma fecha pidió su extradición a los Estados Unidos sin que se recibiera respuesta alguna durante los años 2004, 2005, 2006 y 2007. El 14 y el 19 de diciembre de 2007 cursó orden de detención europea contra dichos procesados ante su próxima llegada al Reino Unido. Ambos estaban acusados de pertenecer a la célula española de Al Qaeda.

El 5 de marzo de 2008, Garzón refirió, en un auto perteneciente al mismo sumario, que había recibido dos informes médicos suscritos por los doctores Fluxman y Bamber, adverados por los forenses del juzgado español, en los que se dictaminaban una serie de secuelas físicas y psíquicas derivadas de las torturas y malos tratos sufridos durante su encarcelamiento en varias prisiones militares estadounidenses, incluida la de Guantánamo. A la vista de tales informes y a pesar de que los hechos por los que tales procesados eran perseguidos en España se habían producido con anterioridad a su detención, dictaminó que las torturas sufridas durante años de detención irregular en total ausencia de las garantías mínimas exigibles en cualquier Estado de Derecho habían contaminado el procedimiento «[...] en relación con cualquier evidencia aparecida o que pudiera tener relación con los lugares en que se produjeron tales detenciones sin cargos [...]».

En el mismo fundamento jurídico reseñó lo dicho al respecto por la sentencia 829/06 de 20 de julio de la Sala Segunda del Tribunal Supremo: «[...] toda diligencia o actuación practicada en ese escenario debe ser declarada totalmente nula y, como tal, inexistente». Concluye el auto afirmando que «la estancia en condiciones de degradación y falta de derechos en las cárceles secretas y en Guantánamo ha producido un deterioro grave del estado mental de los procesados y hace imposible, por inhumana, continuar adelante con la orden europea de detención». Por el mismo razonamiento, revocó los autos de prisión, canceló las órdenes de detención y declaró concluso el sumario 25/2003.

En abril de 2009, el magistrado incoó diligencias previas con el fin de averiguar posibles responsabilidades penales contra militares de EE. UU. que estaban al frente de la base naval de Guantánamo (Cuba), a partir de las denuncias de cuatro ex prisioneros que estuvieron recluidos en este centro de detención.

No obstante, un informe de Amnistía Internacional del año 2008 reveló que Garzón había conocido de primera mano y desde el principio las torturas que se cometieron en Guantánamo contra las personas incluidas en el sumario 25/2003. De hecho, el juez dictó un auto el 5 de marzo de 2008 declarando concluso dicho sumario al haber apreciado que el grave deterioro sufrido por los procesados en Guantánamo y otras cárceles secretas estadounidenses hacían imposible la prosecución de la causa.

Según el informe, el Gobierno español envió en el año 2003 a varios funcionarios del Cuerpo Nacional de Policía a interrogar a cuatro detenidos en la base por una presunta pertenencia a Al Qaeda. A la vuelta del interrogatorio, los agentes informaron a Garzón que los detenidos carecían de cualquier clase de derecho. Amnistía reprocha en su informe que Garzón prosiguiera su imputación por hechos de terrorismo contra personas cuando parecía estar acreditada la existencia de torturas durante el procedimiento. El documento detalla que uno de los agentes enviados a Guantánamo declaró ante el juez que los interrogatorios a los detenidos tenían lugar en una especie de vagones que, según insinuó el policía, eran propicios para la tortura u otros malos tratos: ""…"están habilitados una especie de vagones también donde se llevan a estos hombres a los que se quiere interrogar, y bueno, el sitio sí es propicio para"..."", según declaró el agente 14620 el 23 de septiembre de 2003 ante Garzón. Por estos hechos, el Tribunal Supremo terminaría archivando la causa. No obstante, y en virtud de las declaraciones obtenidas de los detenidos en Guantánamo, Garzón siguió formulando imputaciones contra estos prisioneros y obviando los posibles actos de tortura.

Uno de los imputados por Garzón desde su estancia en Guantánamo, Omar Deghayes, declaró en una entrevista: “Primero nos dice que somos terroristas, que somos mala gente y de pronto un día cambia de parecer y nos pide autorización para encausar a Dick Cheney y George Bush. Me lo pidió a mí y otros como Jamil Abdul, los dos que supuestamente debíamos ser juzgados en España por él. Toda una locura”. En 2008 y consultado por los supuestos hechos de tortura de los que habrían sido víctimas sus imputados, manifestó: "No me consta que haya ninguna reclamación por este caso", a pesar de que realmente las conocía desde varios años antes.

El procedimiento abierto por Garzón se encuentra actualmente en manos del juez de la Audiencia Nacional Pablo Ruz

El 14 de diciembre de 2006, las representantes legales de la Associació per a la Recuperació de la Memòria Històrica de Mallorca presentaron una denuncia en el Juzgado Central de Instrucción nº 5 de la Audiencia Nacional, a la que siguieron otras del mismo tenor, donde se ponían de manifiesto hechos penalmente relevantes consistentes en torturas, desapariciones forzadas y ejecuciones ocurridas durante el franquismo, donde Baltasar Garzón, mediante una resolución fechada el 16 de octubre de 2008, se declaró competente para llevar adelante acciones judiciales conducentes a investigar las responsabilidades sobre estos hechos.

La decisión de Garzón fue recibida con entusiasmo por las organizaciones memorialistas impulsoras de estas denuncias, que incluso habían remitido al juez un censo parcial de nombres de más de 140.000 desaparecidos.

Sin embargo, esta resolución se tomaba en contra del criterio de la Fiscalía General del Estado, que argumentó que la Audiencia Nacional no era competente para tramitar este tipo de delitos. La asociación Jueces para la Democracia también advirtió que el camino adoptado por Garzón no se encuadraba en el cauce procesal adecuado.

Finalmente, Garzón se inhibió en favor de los jueces territoriales mediante un auto que las organizaciones memorialistas impulsoras advirtieron de "grave" para su causa, ya que obligaría a los familiares de víctimas del franquismo a repetir las denuncias iniciales ante los jueces del lugar, reprochando a Garzón no haber instrumentado el procedimiento previsto en el art. 304 de la Ley de Enjuiciamiento Criminal española, que dispone la opción del juez de elevar al Tribunal Supremo en casos de excepcional relevancia o gravedad las causas que por su interés y complejidad requieran la intervención del máximo órgano judicial español, nombrando para ello un juez especial encargado de la instrucción. Algunas entidades señalaron posibles "presiones políticas" para que Garzón tomara esta decisión, que en la práctica ponía fin a la causa ya que, según los denunciantes,  "no existen abogados con formación suficiente en derecho internacional para hacer frente a una avalancha procesal como la dispuesta por el juez titular del Juzgado de Instrucción Núm. 5, ni jueces que tengan conocimientos de derecho penal internacional para substanciar los casos respetando el debido proceso y el derecho penal europeo e internacional."

Posteriormente, el 28 de noviembre de 2008, el pleno de la Sala de lo Penal de la Audiencia Nacional declaró la incompetencia de Garzón en este caso por catorce votos contra tres.

El 27 de mayo de 2009, el Tribunal Supremo admitió a trámite una querella contra Baltasar Garzón presentada por José María Ruiz Puerta (líder del Partido por la Libertad y "el último presidente de CEDADE, el Círculo Español de Amigos de Europa, la organización nazi fundada en España en 1966"), ejerciendo como abogado del sindicato ultraderechista Manos Limpias, cuyo secretario general es Miguel Bernad Remón, acusándolo de prevaricación al haberse declarado competente en la investigación de los crímenes de la Guerra Civil y el franquismo sabiendo que no lo era. Desde 1997, Manos Limpias había planteado diecisiete querellas, denuncias y quejas contra Garzón, todas ellas desestimadas.

El 24 de junio de 2009, el Tribunal Supremo admitió otra querella de la asociación "Libertad e Identidad" presentada el 10 de marzo del mismo año contra Baltasar Garzón por prevaricación en el caso de las desapariciones durante la Guerra Civil y el franquismo y decidió acumularla a la presentada por Manos Limpias.

El 13 de enero de 2010, el Tribunal Supremo admitió a trámite una querella de Falange Española de las JONS contra Baltasar Garzón por los mismos hechos.

La decisión del Supremo fue adoptada, en contra del criterio de la fiscalía, por el presidente de la Sala Penal, Juan Saavedra Ruiz, y los magistrados Adolfo Prego, Joaquín Jiménez, Francisco Monterde Ferrer y Juan Ramón Berdugo Gómez de la Torre.

El Tribunal Supremo, mediante auto del magistrado instructor Luciano Varela de 7 de abril de 2010, estimó que procedía continuar el procedimiento por el delito de prevaricación contra Garzón, siendo recurrido dicho auto por el magistrado.

El 23 de abril de 2010, el magistrado instructor Varela decidió expulsar del proceso contra Garzón a Falange Española de las JONS, al no atender dicha formación dentro del plazo establecido al requerimiento que el mismo Varela ponía un día antes, en el cual la instaba a que corrigiera el escrito de acusación presentado, al considerar que incumplía "de manera notoria" las obligaciones procesales, al extenderse en múltiples «valoraciones» y no limitarse a la «descripción» de hechos.

El día 24 de abril, Garzón presentó ante el Tribunal Supremo un recurso de recusación contra el magistrado instructor Luciano Varela, acusándolo de tener «interés directo en el procedimiento y parcialidad en el mismo» y de haber realizado «una labor más próxima a una asesoría o consejo jurídico» al haber concedido un plazo a los querellantes para corregir una serie de defectos de sus escritos de acusación, hecho que definió como «dar oportunidades atípicas y extraprocesales» a una de las partes. En opinión de Garzón, «la intervención del instructor no se encuentra amparada en ningún precepto de la normativa procesal vigente y es manifiestamente ajena a las normas esenciales del procedimiento». El 3 de mayo, la Fiscalía del Tribunal Supremo presentó un escrito de rechazo a la recusación de Luciano Varela por parte de Garzón donde expresaba que era «absolutamente inviable por carecer de fundamentación y justificación alguna» y que, por esta razón, interesaba «la desestimación del incidente de recusación planteado». El día 6 de mayo de 2010 el Magistrado instructor de la Sala de lo Penal del Tribunal Supremo, Andrés Martínez Arrieta, dictó un auto donde no admitía a trámite el recurso de recusación planteado por Garzón.

Miles de personas participaron el 24 de abril de 2010 en las concentraciones y manifestaciones convocadas en toda España para denunciar la impunidad del franquismo y apoyar al juez Baltasar Garzón, convocadas por plataformas de reconocimiento a la Memoria Histórica.

El acto más multitudinario tuvo lugar en Madrid, donde los organizadores reconocieron que la asistencia a la marcha que transcurrió entre la puerta de Alcalá y la del Sol superó "con creces" sus expectativas más optimistas (calculaban unos 100.000 asistentes). El acto concluyó con la lectura de un manifiesto por parte del cineasta Pedro Almodóvar, la escritora Almudena Grandes y el poeta Marcos Ana, que pasó 23 años en las cárceles franquistas. En el texto, al que siguió un minuto de silencio por todas las víctimas del franquismo, se lamentaban "las consecuencias de un proceso que, en democracia, ensucia" la memoria de las víctimas del franquismo, "desprecia el dolor de sus hijos, de sus nietos y condena las aspiraciones de justicia de cientos de miles de familias españolas".

Mientras, en Barcelona fueron más de cuatro mil personas las que llenaron la plaza de San Jaime. La concentración convocada en Sevilla contó con la presencia de la madre y las hermanas de Garzón, natural de Jaén, donde también unas trescientas personas participaron en un acto de apoyo al juez, actos que se repitieron en localidades como Zaragoza, Murcia, Cáceres, Valladolid, León, Palma de Mallorca, Las Palmas, Santander, Valencia o Gijón, entre otras.

Los actos de apoyo a Garzón contaron con la presencia de numerosos políticos de los partidos de izquierda ―como Cayo Lara y Gaspar Llamazares (Izquierda Unida (España)), Pedro Zerolo (PSOE) o Joan Herrera (ICV)―, mientras que fueron duramente criticados por el PP, cuyo presidente, Mariano Rajoy, los calificó de campaña "brutal y antidemocrática" contra el Tribunal Supremo.

En la misma tarde se denunció el "doble rasero" de la Justicia Española, que investigó dictaduras como las de Chile y Argentina pero que encausaba a un juez por hacer lo mismo con el franquismo. En la misma línea, Ronald Gamarra, secretario ejecutivo de la Coordinadora Nacional de Derechos Humanos del Perú y abogado de la parte civil en el juicio contra el expresidente Alberto Fujimori, condenado por crímenes de lesa humanidad, mostró su sorpresa «de que los países no quieran a los jueces que justamente legitiman a su poder judicial, que son independientes y que prefieren el honor y la justicia al pasado vergonzoso».

Por otra parte, entre las personalidades que han entendido que algunas actuaciones de Garzón son merecedoras de imputación se encuentra Juan Carlos Rodríguez Ibarra, expresidente de la Junta de Extremadura, que ha acusado a Garzón de prevaricación tanto en los casos que tiene abiertos en el Tribunal Supremo, como sobre todo por la condena a Rafael Vera, que fue estudiada por el Tribunal Europeo de Derechos Humanos de Estrasburgo, si bien se desdijo posteriormente sobre su valoración sobre Garzón en relación con los crímenes del franquismo.

Mientras tanto, más de un centenar de antifascistas latinoamericanos reconocidos vinculados a organizaciones independentistas del País Vasco firmaron un documento en el que rechazaban el franquismo, pero no apoyaban a Garzón, al que acusaban de perseguir a los vascos, catalanes, gallegos y al gobierno de Venezuela.

Según el periódico "El Mundo", representantes de la Comisión Internacional de Juristas, de Amnistía Internacional y de Human Rights Watch, presentes en Madrid como observadores internacionales opinan «que se daña la imagen, que desde muchos países se tiene, de la justicia española». Así, el representante de Human Rights Watch señaló que «es la primera vez que se procesa a un juez por defender los derechos humanos; la primera vez en la UE que un juez es sometido al derecho penal por defender derechos humanos y perseguir crímenes internacionales». El consejero jurídico de Amnistía Internacional dijo que "la obligación de España y de cualquier Estado es perseguir cualquier violación de derechos humanos y no se puede juzgar a ningún juez por hacerlo", y pide que se desestimen las acusaciones contra Garzón para cerrar así "un proceso de naturaleza escandalosa". En este mismo sentido, un editorial de "The New York Times", fechado el 5 de febrero de 2012, afirmaba que «perseguirlo atenta contra la Justicia».

Por otra parte, algunos medios han comentado un posible doble rasero de Garzón, quien archivó en 1998 la querella contra Santiago Carrillo y, en cambio, abrió una investigación de los crímenes del franquismo. Este hecho ha sido mencionado también por el letrado de la acusación popular contra el juez Garzón por presunto delito de prevaricación por investigar los crímenes del franquismo.

El pleno extraordinario del Consejo General del Poder Judicial (CGPJ) decidió el 14 de mayo de 2010, por unanimidad, suspender cautelarmente en sus funciones a Baltasar Garzón, después de que el magistrado del Tribunal Supremo Luciano Varela acordara el 12 de mayo la apertura de juicio oral por la investigación de los crímenes del franquismo.

La suspensión estará vigente al menos hasta que el Tribunal Supremo, en el que Garzón tiene abiertas contra él otras dos causas, decida sobre la culpabilidad o la inocencia del juez, a quien se acusa de prevaricación. Al mismo tiempo, Carlos Dívar, Presidente del Consejo, convocó una reunión de urgencia de la Comisión Permanente del CGPJ para estudiar la solicitud de una comisión de servicios especiales presentada por Garzón para trasladarse al Tribunal Penal Internacional de La Haya como asesor de la Fiscalía.

La organización pro derechos humanos Human Rights Watch lamentó la suspensión cautelar del juez Baltasar Garzón:

El presidente de la Asociación Nacional para la Recuperación de la Memoria Histórica aseguró que la suspensión "motivo de mucha tristeza", en especial por el "ensañamiento" del magistrado Luciano Varela. La Federación Estatal de Foros por la Memoria calificó la suspensión como el resultado del "bajo perfil democrático del Estado español. Esto muestra que cualquiera que hable o se meta o investigue el franquismo será perseguido".

Antes de abandonar la Audiencia Nacional el mismo día 14 de mayo, varios jueces, magistrados y fiscales de la Audiencia Nacional pasaron a mostrar su solidaridad con el magistrado: los magistrados José Ricardo de Prada, Clara Bayarri, los jueces Santiago Pedraz y Fernando Andreu, y los fiscales Vicente González Mota, especializado en terrorismo, Daniel Campo, Ana Noé y María Dolores Delgado.

José Antonio Martín Pallín, magistrado del Tribunal Supremo, declaró que estaba muy triste y muy preocupado por el crédito democrático de España:

Por su parte, Carlos Jiménez Villarejo, exfiscal Anticorrupción señaló:

Las principales asociaciones españolas de jueces, Asociación Profesional de la Magistratura y Jueces para la Democracia, valoraron la decisión de suspender cautelarmente al juez Garzón como «la única» que se podía tomar de acuerdo con lo que marca la ley.

En los medios de comunicación más destacados de Estados Unidos y Europa que trataron la noticia, "The New York Times", bajo el título del editorial, «Una injusticia en España», señalaba el 15 de mayo que «a Garzón debería permitírsele regresar cuanto antes a su trabajo. España necesita una explicación honesta sobre su turbulento pasado, no la persecución de aquellos que tienen el coraje para demandarla». Por su parte, el británico "The Guardian" calificaba la separación de la judicatura como una «persecución por motivos políticos». El también británico, "The Times" señalaba a Garzón como «el juez de las cruzadas» y el diario francés "Le Figaro" lo calificaba de «superjuez», afirmando que en medios políticos y judiciales españoles se señalaba que, apartando a Garzón de la Audiencia Nacional, «se le acabarían todos los problemas».

Tiempo después la fundación José Saramago propondría a Baltasar Garzón para Premio Nobel de la Paz, «por estar involucrado en la defensa de los derechos humanos y por no haber bajado la cabeza ante ninguna artimaña, ni ningún poder, por haber seguido adelante y por haberse puesto en cualquier continente y país de parte de las víctimas».

El 7 de julio de 2011 es elegido miembro del Comité Europeo para la Prevención de la Tortura y los Tratos Inhumanos o Degradantes.

El 1 de marzo de 2012, en la apertura de las sesiones ordinarias del Congreso de la Nación Argentina, la presidenta de la Nación, Cristina Fernández de Kirchner, miró arriba a la derecha, hacia las gradas donde se hallaba el juez para decirle: «Agradezco a Baltasar Garzón que pusiera preso a Scilingo por los vuelos de la muerte». Garzón, flanqueado a su izquierda por Hebe de Bonafini y del otro lado a Estela de Carlotto, fue aplaudido de pie por todo el Congreso; el Poder Ejecutivo y miembros de la Corte de Justicia como Eugenio Zaffaroni.

El Tribunal Supremo absolvió a Baltasar Garzón el 27 de febrero de 2012. La sentencia dictaminó que el magistrado incurrió en un exceso interpretativo de las normas, pero que dicha conducta no constituyó delito de prevaricación. También resaltó que, mediante la incoación de la causa contra el franquismo, pretendió tutelar a personas víctimas de una lesión constatada fundamentando sus resoluciones en la cultura de la fuerza expansiva de la protección de los derechos humanos. Sin embargo, no tuvo en cuenta que dicha argumentación debía ajustarse al principio de legalidad recogido en el artículo 9.3 de la Constitución española.<ref name="101/2012"></ref>

La Audiencia Nacional, por orden del juez Garzón, abrió una investigación por una supuesta trama de corrupción que operaba en Madrid, Valencia y la Costa del Sol. A los implicados se les acusa de blanqueo de capitales, fraude fiscal, cohecho y tráfico de influencias. El nombre dado a la trama, Gürtel, está relacionado con el apellido de Francisco Correa principal sospechoso de encabezar la red. Actualmente hay 71 imputados relacionados con el Partido Popular.

Tras las peticiones de la Fiscalía y el Partido Popular, y los indicios hallados contra aforados (diputados, senadores y otros altos cargos políticos que no pueden ser juzgados por la Audiencia Nacional), el juez Garzón se inhibe del caso y cede la investigación de la presunta trama a los tribunales superiores de Valencia y Madrid, dejando un caso con 43 imputados vinculados al Partido Popular, aunque antes de hacerlo ordenó, a instancias de la Fiscalía Anticorrupción, las escuchas a las conversaciones entre los imputados y sus abogados, que fueron anuladas por el Tribunal Superior de Justicia de Madrid y posteriormente motivaron la presentación de una querella ante el Supremo por supuesta prevaricación y vulneración de la intimidad.
El Partido Popular —que había tratado, sin resultado, de recusar a Garzón como instructor del caso alegando "enemistad manifiesta contra el partido" e "interés directo e indirecto", luego se querelló por prevaricación contra él, siendo dicha querella desestimada— expresó en un comunicado que celebraba que la querella contra Garzón por las escuchas se admitiese a trámite.

El 25 de febrero de 2010, la Sala de lo Penal del Tribunal Supremo de España admitió a trámite la querella presentada por el abogado Ignacio Peláez, defensor del empresario José Luis Ulibarri, presidente del grupo Begar y propietario de Televisión Castilla y León, implicado por las escuchas del caso Gürtel. La querella estaba motivada en el hecho de que Garzón ordenara grabar las conversaciones de los presos encausados por dicha trama con sus abogados, por lo que entiendía que el juez habría podido incurrir en prevaricación y vulneración de la intimidad. Estas escuchas ya fueron anuladas por el Tribunal Superior de Justicia de Madrid al considerar que dicha intervención vulneraba "el derecho de defensa y el derecho a no declarar contra sí mismos y a no confesarse culpables, así como el derecho a un proceso público con todas las garantías".
El magistrado del Tribunal Supremo Alberto Jorge Barreiro, en su Auto de 19/10/2010afirma que Garzón ordenó las escuchas haciendo una interpretación de la ley "errónea, tanto desde el punto de vista gramatical como del sistemático y teleológico" y, sin motivación alguna, ante la "mera posibilidad" de que los letrados actuaran de "enlaces" de la trama de corrupción con el exterior y pese a no tener contra los abogados sospechas ciertas. Esta actuación "conducía, sin apenas escapatoria alguna, a la irremediable laminación del derecho de defensa" y con ello, Garzón "transmutó el ejercicio de este derecho fundamental en un instrumento idóneo para la autoincriminación de los imputados internos en prisión, desarbolando o desactivando cualquier estrategia defensiva que pudieran poner en práctica los letrados".

El 9 de febrero de 2012, el Tribunal Supremo condenó al juez Garzón por prevaricación de forma unánime con la pena de «11 años de inhabilitación especial para el cargo de juez o magistrado con pérdida definitiva del cargo que ostenta» (véase lasentencia). El pleno del Consejo General del Poder Judicial, convocado el 23 de febrero de 2012, ratificó, con el apoyo de 20 de sus 21 miembros, la expulsión de la carrera judicial del juez Garzón.

Los letrados José Luis Mazón y Antonio Panea, presentaron una querella contra Baltasar Garzón en relación con los cursos organizados por el Centro Rey Juan Carlos de la Universidad de Nueva York que el juez impartió entre 2005 y 2006, cuando se encontraba en la ciudad estadounidense disfrutando de un permiso de estudios. Previamente el juez había contactado a los responsables de distintas empresas españolas, entre las que se encontraban BSCH, BBVA, Telefónica y CEPSA, teniendo todas en común haber sido investigadas por supuestos delitos imputados a sus directivos en el juzgado en el que era titular o en otros de la Audiencia Nacional, solicitando 2 593 375 dólares para la realización de los cursos. No obstante las empresas aportaron una cuantía rebajada ya bien «por el carácter injustificado de los presupuestos económicos aportados» o por la «falta de seriedad en la descripción de los proyectos del convenio», obteniendo finalmente 1 237 000 dólares para la realización de los mismos. Según los querellantes, Garzón se habría beneficiado del dinero que el Banco Santander aportó para financiar los cursos. Al regresar de Estados Unidos y reincorporarse a sus labores profesionales, una de las querellas de las que se hizo cargo acusaba a varios directivos del Banco Santander de apropiación indebida de la sociedad SCI Gestión. En un auto del 27 de noviembre de 2006, el juez decidió archivar la causa, previo informe favorable del fiscal, y posterior confirmación de la Sala Penal de la Audiencia. La supuesta relación entre estos hechos fueron la base de la acusación para presentar una querella contra Garzón por presuntos delitos de prevaricación y cohecho.

Tanto el Banco Santander como la Universidad de Nueva York negaron que el banco efectuase ningún pago a Garzón, sino que fue esta Universidad, a través del Centro Rey Juan Carlos, la que pagó a Garzón por su participación en los cursos. Sin embargo, la universidad certificó que había recibido 302 000 dólares del banco en concepto de patrocinios que fueron gestionados por el citado centro pero afirmaba que «ninguno de estos gastos tomaron la forma de compensación directa o indirecta, en dinero o especie, al juez y su familia». Este hecho fue confirmado por Garzón durante su declaración como imputado ante el Tribunal Supremo el 15 de abril de 2010, donde explicó que durante 2005 y 2006 cobró aproximadamente 160 000 euros de dicha entidad dependiente de la Universidad de Nueva York, y no del Banco Santander, del que afirmó no haber percibido «ni un centavo». También contestó a las preguntas de los abogados querellantes al respecto de sus retribuciones dinerarias aclarando que viajó a Nueva York «sin saber entonces cuáles serían finalmente sus honorarios». Asimismo, expresó que el lenguaje cercano y el cometido de la carta que el juez remitió a Botín —en la cual la acusación estimó que Garzón le habría pedido dinero para la financiación de los cursos— fue «mal interpretada» y que nunca se dirigió al Santander «para pedir fondos». Junto a su declaración, el magistrado imputado aportó otras cartas enviadas a diferentes personalidades —como José Luis Rodríguez Zapatero, Mariano Rajoy, Rodrigo Rato o Esperanza Aguirre— en las que se despide con «un abrazo» o «un gran abrazo», así como otras a Felipe González y a Alberto Ruiz-Gallardón en las que habría usado un lenguaje similar.

El 9 de septiembre de 2010 el Magistrado del Tribunal Supremo Manuel Marchena ordenó a la Guardia Civil que investigara las cuentas, depósitos bancarios, declaraciones tributarias y las participaciones que Baltasar Garzón pudiera tener en cualquier entidad, para conocer con exactitud qué importe cobró de la Universidad de Nueva York durante su excedencia remunerada como Magistrado Juez de la Audiencia Nacional en los años 2005 y 2006, ante la imposibilidad de conocer dicho importe por las «inexactitudes y contradicciones» de Garzón y la «continua desatención y evasivas» de dicha Universidad.
El instructor afirmaba que existían indicios de que Garzón «impartió las instrucciones precisas» a sus contactos en la Universidad «para silenciar toda mención» a retribuciones en especie, como por ejemplo 21 650 euros para sufragar la matrícula de su hija en la Escuela Internacional de Naciones Unidas y 22 152 para los gastos de desplazamiento de él y su familia.

Finalmente, la querella fue archivada por el instructor al no apreciar indicios de extorsión y dado que a pesar de haber sido calificados de constitutivos de un delito de cohecho impropio, dicho delito habría prescrito.

Investigó a Jesús Gil, antiguo alcalde de Marbella y dueño del Club Atlético de Madrid, por corrupción.

En 2009, por solicitud del fiscal anticorrupción, Luis Pastor, ordenó el ingreso en prisión de dos ex altos cargos de la Generalidad de Cataluña durante el gobierno de Jordi Pujol —Lluís Prenafeta y Macià Alavedra, de Convergència i Unió—, del alcalde socialista de Santa Coloma de Gramanet, Bartomeu Muñoz, del exdiputado del PSC Luis García, y el concejal de Urbanismo de Santa Coloma, Manuel Dobarco, tras tomarles declaración en la Audiencia Nacional de Madrid, en relación con la Operación Pretoria contra la corrupción urbanística en Cataluña. En dicha operación se investigaba el fraude de 44.754.000 euros por parte de los ayuntamientos de Santa Coloma de Gramanet, Badalona y San Andrés de Llavaneras. Además aparecen como imputados, el empresario madrileño Manuel Carrillo, y los empresarios catalanes Josep Singla, y Lluís Casamitjana.

En relación con sus investigaciones al entorno de ETA, Pepe Rei —antiguo redactor jefe del diario vasco de ideología abertzale "Egin", y director de la desaparecida revista mensual Ardi Beltza—, y que fue procesado por el propio Garzón por su supuesta relación con ETA, publicó en 1999 el libro "Garzón. La otra cara".

El 9 de febrero de 2012, el Tribunal Supremo condenó a Baltasar Garzón por prevaricación de forma unánime por las escuchas ilegales durante la investigación del caso Gürtel con la pena de «11 años de inhabilitación especial para el cargo de juez o magistrado con pérdida definitiva del cargo que ostenta» (véase la sentencia).

El pleno del Consejo General del Poder Judicial, convocado el 23 de febrero de 2012 ratificó, con el apoyo de 20 de sus 21 miembros, la expulsión de la carrera judicial del juez Garzón.

El 18 de mayo de 2012 la asociación Magistrados Europeos para la Democracia y las Libertades (MEDEL), en representación de unos 15.000 jueces y fiscales de once países de la Unión Europea, presentó en el Ministerio de Justicia una petición de indulto para que se devolviera a Baltasar Garzón la condición de juez que perdió tras ser inhabilitado por el Tribunal Supremo en febrero de 2012 por ordenar las escuchas del "caso Gürtel". En el escrito presentado al ministro de Justicia Alberto Ruiz Gallardón, del gobierno del Partido Popular presidido por Mariano Rajoy, se considera la pena de 11 años de inhabilitación de una «severidad desproporcionada, indiscriminada y extraordinaria». La petición está firmada por el presidente de MEDEL, el portugués António Cluny, quien en unas declaraciones al diario El País afirmó:
Este expediente fue remitido, desde el Ministerio de Justicia al Tribunal Supremo, al cabo de poco más de un mes tras su presentación: el 29 de junio de 2012. No se solicitó que se acusara recibo de lo enviado. Después, transcurrió algo más de un año hasta que se descubrió que dicho expediente no había llegado al alto tribunal. Y ello a pesar de que se envió por correo postal y de que el Ministerio distaba del Supremo apenas 1500 metros. Alertada del incidente, el 9 de octubre de 2013 Justicia envió de nuevo la documentación y solicitó, esta vez sí, acuse de recibo. El Supremo, enterado por fin de la comunicación, dio traslado de la misma al ministerio público y al resto de las partes personadas. Finalizado el trámite, los informes del tribunal y de todas las partes, aunque no vinculantes, deben remitirse al ministro de Justicia y el Gobierno puede decidir libremente.

En 1993, tras varios contactos con miembros relevantes del PSOE como José Bono y Felipe González, Garzón tomó la decisión de abrir un paréntesis en su carrera en la judicatura y adentrarse en la política. Con fecha 2 de mayo se le concedió la excedencia voluntaria en la carrera judicial y pudo así presentarse por Madrid en las listas electorales del PSOE como independiente y número dos, justo detrás de Felipe González, obteniendo escaño.

Al constituirse el ejecutivo, fue nombrado delegado del Gobierno en el Plan Nacional sobre Drogas, con rango de secretario de Estado, dentro del recién fusionado Ministerio de Justicia, e Interior, con Juan Alberto Belloch como ministro. Sin embargo, el 6 de mayo de 1994 anunció su dimisión como delegado del Gobierno y tres días después renunció a su escaño. Garzón adujo como motivo "la actitud pasiva del presidente Felipe González respecto a la corrupción". Años después, afirmó que en esa época había considerado positivo y útil desarrollar una carrera política, pero que sin duda se equivocó, ya que pecó "de soberbia creyendo que yo podía hacer algo".

El miércoles, 19 de abril de 2017, Baltasar Garzón presentó junto con Gaspar Llamazares la nueva plataforma política "Actúa." Su objetivo principal es dar voz a “la izquierda que no se siente representada ni por los gestos mínimos del PSOE y su pacto con el PP ni tampoco por el maximalismo retórico de Podemos", si bien declararon que no se presentarían a las elecciones generales. En el acto participaron personalidades destacadas como la abogada Cristina Almeida, Federico Mayor Zaragoza (exdirector de la Unesco), el poeta Luis García Montero (excandidato a la Presidencia de la Comunidad de Madrid en 2015 por IU), y la periodista Teresa Aranguren.

Cuatro meses más tarde anunciaron el registro de dicha organización en el registro de Partidos Políticos del Ministerio del Interior, declarando que no descartaban presentarse a las próximas elecciones, si bien el principal motivo para registrarla como partido era adquirir la exclusividad de la marca.

En el año 2002 publicó su primer libro "Cuento de Navidad: es posible un mundo diferente". Es una obra que reúne el pensamiento de Baltasar Garzón acerca de los Derechos Humanos, la Justicia Universal y la Corte Penal Internacional, el terrorismo, los fundamentalismos religiosos, la inmigración, y los Derechos de los Pueblos Indígenas.

En febrero de 2005 publicó su segundo libro, "Un mundo sin miedo", en el que cuenta a modo de reflexión o bien como cartas dirigidas a sus tres hijos, Aurora, Baltasar y María, los puntos más destacables y polémicos de sus diecisiete años como juez de lucha contra el terrorismo, el crimen organizado y la impunidad. Expresa también su opinión acerca de temas de actualidad y revela datos (tanto de relevancia nacional como internacional) poco conocidos hasta entonces.

El 24 de febrero de 2006 presentó su tercer libro, "La lucha contra el terrorismo y sus límites".

En 2007 publicó "El alma de los verdugos", sobre los crímenes de la dictadura argentina.

Su última obra es "La línea del horizonte", donde reflexiona de forma muy personal sobre la impunidad y el olvido de determinadas injusticias y atrocidades, los fenómenos migratorios, la educación en un mundo globalizado, y otras cuestiones; con una mirada crítica, comparativa y visión de futuro.

Ha colaborado con un artículo en el libro de 2011, "Reacciona", coordinado por la periodista Rosa María Artal, y que pretende alertar de la crisis política que recorre las sociedades en la actualmente y en particular la sociedad española y de la necesidad de respuesta social a la corrupción, a los poderes financieros y económicos y a los poderes políticos, alejados cada vez más de la ciudadanía.

También de ese año es "La fuerza de la razón", editado por Debate.

Aparte de las anteriores, existen varias obras sobre Baltasar Garzón. La primera fue "Garzón, la ambición de un juez", con el subtítulo, "La cara oculta de un juez-estrella". La escribió en 1998 el periodista especializado en tribunales, Miguel Ángel de la Cruz. En este libro, publicado por Planeta, se dan claves para entender, por ejemplo, porque aceptó saltar a la política de la mano del PSOE. O si utilizó el caso GAL como venganza personal contra Felipe González. En la obra se dan también datos biográficos, sobre su trayectoria como juez y sobre su personalidad. Otra obra acerca de Garzón, cuya autora es la conocida periodista Pilar Urbano, titulada "". Se trata de una biografía autorizada que algunos sectores tacharon de hagiografía, pero que publicaba datos acerca de la vida e ideología del juez. En sus páginas, el exjuez acusaba al conocido abogado republicano, Antonio García-Trevijano, de ser el cerebro de la supuesta trama que destapó el llamado caso Sogecable y de estar preparando, junto con el juez Joaquín Navarro, una conspiración para derrocar a Juan Carlos I y proclamar una república. El libro fue motivo de polémica al existir una supuesta responsabilidad del juez en la revelación de secretos sumariales. Este hecho supuso la incoación de un expediente disciplinario por parte del Consejo General del Poder Judicial el 13 de febrero de 2001, para averiguar si el magistrado había incurrido en una falta muy grave por revelación de secretos, y que finalmente fue archivado por decisión unánime de la Comisión Disciplinaria de este consejo, atendiendo a los informes del instructor y del fiscal, al no considerar probado que revelara secretos.

En 2001, el periodista argentino Eduardo Anguita escribió "Sano juicio. Baltasar Garzón, algunos sobrevivientes y la lucha contra la impunidad en Latinoamérica".

En 2010, Isabel Coixet filmó el documental "Escuchando al juez Garzón".

En 2011, Sebastián Arabia filmó el documental "La tinta negra". que gira en torno al llamado caso Garzón y los crímenes del franquismo.

En 2012, el portal Llibertat.cat impulsó el documental "Operación Garzón", que documenta la actuación del exjuez en la operación contra 45 personas vinculadas al independentismo catalán en el año 1992, las cuales denunciaron hechos de torturas y malos tratos durante los procedimientos.

El 1 de julio de 2014 Diego Herchhoren contrató el dominio «www.baltasargarzon.es». Dicha página web, promovida por activistas de Argentina, Colombia y España, publicaba información que pretendía desacreditar la posición de Baltasar Garzón como defensor de los derechos humanos, tras una serie de escraches que se habían producido contra su persona en la capital argentina. Representado por su hijo, Baltasar Garzón Molina, presentó el 4 de septiembre de 2014 solicitud ante la entidad pública Red.es para que se cancelara dicho dominio por incumplimiento normativo en su asignación, argumentando que cuando el nombre de un dominio está compuesto por nombre y apellidos, estos deben tener una relación directa con el nombre del titular. La asignación del dominio fue cancelada el 25 de noviembre de 2014. A las pocas horas, el dominio «www.noagarzon.org» replicó el contenido.

Como curiosidad, en julio de 2006 un grupo de música pop homónimo, Garzón, usó fotografías del magistrado en su página web con fines publicitarios, incluía en el dominio la expresión «superjuez»; tras ser contactados por un representante legal del magistrado y amenazados con acciones legales, pasaron a llamarse «Grande Marlaska», en referencia al juez de la Audiencia Nacional Fernando Grande-Marlaska.





</doc>
<doc id="41925" url="https://es.wikipedia.org/wiki?curid=41925" title="Grupos Antiterroristas de Liberación">
Grupos Antiterroristas de Liberación

Los Grupos Antiterroristas de Liberación (GAL) fueron agrupaciones parapoliciales que practicaron terrorismo de Estado o «guerra sucia» contra la organización terrorista Euskadi Ta Askatasuna (ETA) y su entorno entre 1983 y 1987, a la orden de los dos primeros gobiernos de Felipe González. Durante el proceso judicial contra esta organización fue probado que estaba financiada por altos funcionarios del Ministerio del Interior.

Aunque combatían a ETA y «los intereses franceses en Europa», a estos últimos por responsabilizar a Francia de «acoger y permitir actuar a los terroristas en su territorio impunemente», también realizaron acciones indiscriminadas debido a las cuales fallecieron ciudadanos franceses sin adscripción política conocida.

La investigación periodística sobre los GAL se inició en 1987 en el periódico vasco "Deia" de la mano de los reporteros Ricardo Arques y Juan Carlos Urrutxurtu. Ese mismo año, y ya en "Diario 16" y a partir de fuentes oficiales del Ministerio de Interior del propio Gobierno de España, fue el propio Arques quien continuó la investigación junto con otros periodistas como Melchor Miralles o Pepe Rei. En 1989, a raíz del despido de Pedro J. Ramírez como director de "Diario 16" y de la posterior creación de "El Mundo", las investigaciones sobre el caso continuaron en este último periódico, dirigido y creado por Pedro J. Ramírez. Estas investigaciones pretendieron exponer a la opinión pública la organización, fuentes de financiación e implicaciones políticas de los GAL.

Un pequeño grupo de periodistas investigó y descubrió la “guerra sucia” utilizada por el Gobierno español presidido por Felipe González entre 1983 y 1987 para combatir el terrorismo de ETA. Se trata de los Grupos Antiterroristas de Liberación, un caso de terrorismo de estado. El objetivo de los llamados GAL era eliminar ETA y su estructura de apoyo mediante agrupaciones parapoliciales y sus acciones armadas. Aunque decían combatir a la banda terrorista, realizaron acciones indiscriminadas que ocasionaron la muerte de ciudadanos franceses sin adscripción política conocida. De hecho, los GAL responsabilizaban a Francia de “acoger y permitir actuar a los terroristas en su territorio impunemente”.

Los reporteros Ricardo Arques, Juan Carlos Urrutxurtu y Andoni Ortuzar fueron quienes empezaron esta investigación periodística para el periódico vasco "Deia". Arques continuó la investigación en "Diario 16" junto con otros profesionales como Pepe Rei o Melchor Miralles. En los años 90 ya existía el diario "El Mundo", dirigido y creado por Pedro J. Ramírez, y fue aquí donde las investigaciones continuaron hasta destapar más detalles del caso. Uno de los hechos más relevantes fue el descubrimiento de un zulo de los GAL en el suroeste de Francia gracias a los datos aportados por dichas fuentes. Este zulo fue el hilo conductor de la investigación, la cual logró abrir sumarios judiciales en España y Francia. La investigación culminó con penas de prisión para miembros del Ministerio del Interior por asesinato, secuestro, asociación ilícita, falsificación documental y/o malversación de fondos públicos. 

La investigación periodística consiguió, por un lado, tener un enorme impacto sobre la sociedad, que hasta entonces desconocía la existencia de los GAL para combatir a ETA. Los periodistas destaparon cómo existía una organización estructurada, financiada y dirigida por el ejecutivo de Felipe González que hizo . Por otro lado, el caso ha tenido consecuencias políticas y judiciales. La labor periodística permitió conocer la historia, ponerla en el debate político y llevarla a los tribunales, donde los jueces investigaron y acusaron a miembros del Ministerio del Interior con, en algunos casos, penas de prisión de más de cien años. Todo ello demuestra tanto la relevancia del caso como el impacto que finalmente tuvo.

En el desarrollo de la investigación, los periodistas relatan que sufrieron presiones para que finalmente no destaparan todos los detalles que iban descubriendo. De hecho, el mismo Miralles explica en un artículo en "El Mundo" que dejó "Diario 16" “por incompatibilidad moral y ética con un editor [...] que sucumbió a las presiones de Felipe González”. 

Melchor Miralles, uno de los periodistas investigadores, consiguió contactos con la dirección de los GAL y confeccionó un organigrama de la organización. De hecho, era él quien conseguía las informaciones principales del caso. Tanto Miralles como el resto de periodistas del equipo de investigación han denunciado fuertes presiones, amenazas de ETA y del GAL y críticas y difamaciones no solo de los poderes políticos, sino también de buena parte de los medios de comunicación y, al fin y al cabo, de compañeros de profesión. 

El caso de los GAL se destapó gracias a miles de días de investigación, 5.000 horas de viaje por Europa, África, América y Asia, 300 reuniones con protagonistas implicados directamente en el caso, 50 sumarios instruidos por jueces de España, Francia, Portugal, Italia y otros países de Europa, 100.000 páginas estudiadas, 7.000 fichas elaboradas… Todos estos datos aportados por la dirección de la investigación reflejan el método y las técnicas con los que se ha investigado.

Durante la dictadura de Franco y la Transición Española, con los gobiernos de Unión de Centro Democrático existieron diversas organizaciones que utilizaron prácticas terroristas para enfrentarse a ETA, como la Triple A, el Batallón Vasco Español (BVE), los Comandos Antimarxistas, los Grupos Armados Españoles y Antiterrorismo ETA (ATE). Algunos actuaban por libre, simplemente tolerados, mientras que otros tenían apoyos por parte de altas instancias del gobierno. También existían grupos que actuaban supuestamente integrando a algunos miembros del aparato de Cuerpos y Fuerzas de Seguridad de entonces que coordinaban las acciones y aleccionaban en las tácticas y el manejo de armas, funcionando como auténticos comandos antiterroristas de gran movilidad con colaboración de grupos armados internacionales (OAS, Triple A, ...).

El caso del atentado contra Antonio Cubillo, dirigente del MPAIAC (grupo terrorista independentista de las islas Canarias) en 1978, ha imputado a agentes con el apoyo directo del Ministerio del Interior español, o el del secuestro, tortura y simulación de ejecución del director del semanario "Doblón", José Antonio Martínez Soler en marzo de 1976 tras la publicación de un artículo denunciando la purga de mandos moderados de la Guardia Civil, causaron gran impacto en la opinión pública española e internacional por su implicación con fuerzas relacionadas con el aparato de represión del Estado.

Los incitaron a algunos periódicos a solicitar acciones de "guerra sucia" contra ETA o aplaudirlos cuando se habían cometido.

Los GAL estuvieron activos de 1983 a 1987 siendo responsables de veintisiete asesinatos. Actuaron principalmente en el País Vasco francés, aunque también llevaron a cabo secuestros, torturas y delitos económicos en algunas zonas de España. Sus atentados se dirigían contra militantes y simpatizantes de ETA, pero también afectaron personas que no tenían relación con el terrorismo, produciéndose entre este colectivo 10 víctimas mortales.

El secuestro y posterior asesinato de José Antonio Lasa y José Ignacio Zabala en octubre de 1983 y el secuestro de Segundo Marey poco tiempo después marcaron el inicio de la actividad de los GAL.
De todos los atentados perpetrados por los GAL durante los años ochenta, el más sangriento fue el ocurrido en el bar "Monbar" de Bayona en 1985, en el que murieron tiroteados cuatro militantes de ETA y un ciudadano francés resultó herido. Otra acción fue el asesinato de Mikel Goikoetxea Elorriaga "Txapela", uno de los más importantes miembros que ha tenido la banda.

En diciembre de 1983 Segundo Marey, ciudadano hispano-francés, fue confundido con un cabecilla de ETA y secuestrado por los GAL en la localidad francesa de Hendaya. Una hora después del secuestro fue detenido como sospechoso Pedro Sánchez, antiguo cabo de la Legión francesa. Marey fue liberado diez días después en territorio francés, a tres kilómetros del paso fronterizo de Dancharinea (Navarra).

El 4 de diciembre de 1987, Talbi Mohand y Jean-Pierre Echalier fueron juzgados y condenados a 12 y 8 años de prisión respectivamente por su secuestro. Sánchez había muerto en prisión, según Talbi envenenado. El miembro del GAL aseguró que habían entregado a Marey a policías españoles en Dancharinea, después de haber llamado a dos "teléfonos para urgencias" al conocer la detención de Sánchez. Uno de los teléfonos correspondía al Gobierno militar de Vizcaya y el otro a la jefatura superior de policía.

En enero de 1988 la Sala de lo Penal de la Audiencia Nacional encontró indicios delictivos en la actuación del subcomisario José Amedo, quien había sido implicado en los asesinatos del GAL en un juicio celebrado en Lisboa por unos mercenarios portugueses que aseguraban haber sido contratados por el subcomisario para atentar contra etarras en el sur de Francia. El juez de la Audiencia Nacional Baltasar Garzón se hizo cargo de las investigaciones, descubriendo según un informe del Ministerio de Interior que los viajes de Amedo a Portugal en 1986 fueron de carácter oficial y pagados con fondos reservados del Estado. En julio del mismo año Garzón dictó prisión incondicional para Amedo y el inspector Michel Domínguez como presuntos organizadores de los GAL, quienes fueron procesados en junio de 1989 por la Audiencia Nacional y condenados el 20 de septiembre del mismo año a 17 años, 4 meses y 1 día de prisión por cada uno de los seis asesinatos frustrados en los que participaron como autores por inducción, cinco de ellos en el atentado al bar "Batxoki", de Bayona (Francia) y el sexto en el bar "La Consolation", de San Juan de Luz. También recibieron penas menores por los delitos de asociación ilícita y de falsedad de documentos de identidad. El tribunal prefirió la tipificación del delito de asociación ilícita al de integración en la banda terrorista, lo que coincidía con la tesis del Ministerio del Interior que contemplaba los GAL como "grupos de delincuentes inconexos entre sí" y no como terroristas. El fallo indicaba que no fue posible determinar la estructura interna, la escala jerárquica ni las fuentes de financiación de los GAL, con lo que quedaba en suspenso la identidad de los jefes superiores de los dos agentes en esta trama.

El abogado defensor de los policías consideró que el tribunal había vulnerado "«de manera clara y rotunda el principio de presunción de inocencia»". Por otro lado, el abogado de la acción popular presentada por la Asociación contra la Tortura criticó la sentencia, especialmente el rechazo del tribunal a condenar a los acusados por integración en banda terrorista. "«Que la sentencia sostenga que Amedo y Domínguez defendían la estabilidad del sistema, aunque por métodos jurídicamente repudiables, significa negar la posibilidad del terrorismo del Estado.»"

El juez Baltasar Garzón, que en julio de 1993 reabrió el expediente sobre el secuestro de Segundo Marey para evitar que prescribiera, indagaba en los escándalos destapados sobre el desvío de fondos reservados en la investigación sobre el exjefe de la Guardia Civil, Luis Roldán, por si hubiera alguna referencia a Amedo, Rodríguez y los GAL. Su investigación de los fondos reservados había sido impedida desde la etapa de José Barrionuevo como Ministro de Interior, época en que Felipe González, presidente del gobierno, declaraba: "«Ni hay pruebas ni las habrá»". Frente a la negativa de Interior, Garzón obtuvo el apoyo que solicitó del Consejo General del Poder Judicial.

Julián Sancristóbal, gobernador civil de Vizcaya durante el secuestro de Segundo Marey, fue encarcelado en diciembre de 1994 acusado de asesinato frustrado, detención ilegal y malversación de fondos públicos, tres días después de que Amedo y Domínguez aportaran al juez Garzón información sobre aquel hecho. También fueron detenidos Francisco Álvarez, Miguel Planchuelo, y Julio Hierro, jefes directos de Amedo y Domínguez durante la época de los atentados de los GAL, y Francisco Saiz Oceja, jefe de la Brigada de la Policía Judicial de Bilbao. Los partidos políticos manifestaron su preocupación por las repercusiones políticas de la reapertura del caso GAL. Rodrigo Rato, portavoz del PP en el parlamento, declaró: "«No estamos ante un tema judicial y penal sino ante un tema político muy serio que puede afectar a instituciones muy importantes de nuestro sistema. Parece imprescindible que el Gobierno dé explicaciones al Congreso sin que sea obligado por la oposición»". José Luis Galán, abogado de la acusación popular del caso GAL vinculaba la detención de Sancristóbal con la financiación de los GAL con cargo a los fondos reservados "«Nosotros siempre hemos tenido la firme y vehemente sospecha de que Sancristóbal estaba muy cerca no sólo de la financiación, sino de la organización de los GAL»". El exministro de Interior José Barrionuevo expresó un rotundo apoyo a los detenidos: "«Todas estas personas, mientras yo fui ministro del Interior, tuvieron un comportamiento excelente, leal y meritorio para este país, y yo estoy con ellos y seguiré estando»".

En febrero de 1995 Amedo declaraba en una entrevista en Tele 5 que Sancristóbal acabaría por derrumbarse, y que revelaría todo lo que sabía sobre el GAL. Según decía el ex subcomisario, Sancristóbal le había dicho: "«Si van a por mí, hundiré al presidente»". El Partido Popular solicitaba que el Fiscal General del Estado informara sobre los GAL ante la comisión de Justicia e Interior. El 17 de febrero el juez Garzón decretó el ingreso en prisión incondicional comunicada y sin fianza de Rafael Vera, número dos de Interior y responsable de la lucha antiterrorista durante nueve años con los ministros José Barrionuevo y José Luis Corcuera, inculpado por malversación y evasión de capitales, por la presunta entrega de 200 millones de pesetas a las mujeres de Amedo y Domínguez y por el encubrimiento y financiación (con un millón de francos franceses, obtenidos de los fondos reservados) del secuestro de Segundo Marey en 1983. Mientras el Gobierno manifestaba «perplejidad y dolor» por el encarcelamiento de Vera, el líder de la oposición, José María Aznar, declaraba que «El Gobierno y su presidente tienen ahora ante la opinión pública mucha más responsabilidad política que antes». También ingresó en prisión Ricardo García Damborenea, exsecretario regional de los socialistas vizcaínos, en ese momento próximo al Partido Popular, acusado de detención ilegal y tentativa de asesinato por su presunta implicación en el secuestro de Marey.

El 20 de febrero, la sección tercera de lo Penal de la Audiencia Nacional acordó la reapertura del sumario principal de los GAL, conocido popularmente como caso "Amedo", sin limitar las posibilidades de investigación, y remitirlo al juez Baltasar Garzón. En sus razonamientos jurídicos la Sala decía textualmente que se reabría el caso con el fin de que "«el instructor practique las diligencias que estime oportunas, ante la aparición de nuevos elementos de investigación»" y recordando que el Fiscal General del Estado había apuntado la "«evidente conexidad de los hechos aparecidos en el sumario 17/89 (secuestro de Segundo Marey) con los instruidos en el 1/88 (caso Amedo)»". Desde el Ministerio de Interior se recomendaba dejar trabajar a los jueces, pero se otorgaba poca credibilidad a las declaraciones de Amedo.

El juez Baltasar Garzón ordenó en marzo de 1995 el ingreso en prisión del exjefe superior de Policía de Bilbao Miguel Planchuelo, acusado de los mismos seis asesinatos frustrados por los que fueron condenados Amedo y Rodríguez, por haber organizado y financiado los atentados de los GAL contra los bares «Batzoki» y «La Consolation», a lo que se añadía el delito continuado de malversación de fondos reservados. El exjefe del mando antiterrorista Francisco Álvarez quedaba en libertad por falta de pruebas. En mayo Amedo le entregó al juez Garzón una cinta con 20 minutos de una conversación con Sancristóbal que había grabado en secreto, en la que presumiblemente se daba a entender que Felipe González, así como Ricardo García Damborenea y los gobernadores civiles en el País Vasco estaban al tanto de los GAL.

En julio de 1995 una resolución de la Sección Primera de lo penal de la Audiencia Nacional confirma el auto de procesamiento de Rafael Vera, quien sale en libertad bajo fianza, bajo la consideración de que la alarma social por el caso había descendido. Miguel Planchuelo, exjefe superior de Policía de Bilbao, realizó una declaración ante Garzón en la que implicaba al exministro Barrionuevo en el secuestro de Marey y en las actividades de los GAL, quien al mantener su condición de aforado al entrar en la lista de miembros de la Diputación Permanente del Congreso sólo podía ser procesado por el Tribunal Supremo, siendo necesaria la autorización previa de la Cámara. El 19 de julio Francisco Álvarez, exjefe del Gabinete de Operaciones Especiales del Ministerio del Interior explicó al juez Garzón en privado la estructura de los GAL. Mencionó la existencia de cuatro GAL: el GAL verde, de la Guardia Civil; el azul, de la Policía; el marrón, del Cesid y el GAL francés, y explicó que la estructura de mando de los GAL y la de la lucha antiterrorista estaba relacionada. Al día siguiente García Damborenea declaró ante Garzón autoinculpándose en el secuestro de Segundo Marey. También implicó a Felipe González y otros altos dirigentes socialistas, a quienes acusaba de tener pleno conocimiento de las acciones de los GAL. Según García Damborenea, él mismo había hablado en varias ocasiones con González sobre la guerra sucia contra ETA. Felipe González negó todas las acusaciones de Damborenea, considerando que era una estrategia que buscaba implicar hasta el más alto nivel buscando una ley de punto final para el GAL, lo que calificó de «disparate». El 21 de julio el PSOE confirmó que González no quería volver a ser candidato a la presidencia, y anunció que su sucesor sería elegido en un comité nacional extraordinario que se celebraría en septiembre. Una semana después, el juez Garzón remitió a la Sala Segunda del Tribunal Supremo el sumario de los GAL, diciendo haber encontrado indicios delictivos en las actuaciones del presidente del Gobierno, Felipe González; los exministros Narcís Serra y José Barrionuevo, y el diputado socialista Txiki Benegas, basándose en el testimonio de García Damborenea.

En septiembre de 1995 la Sala Segunda del Supremo concedió la dedicación exclusiva para instruir el caso GAL al magistrado Eduardo Moner, quién decidió comprobar las imputaciones realizadas contra los cuatro aforados, especialmente contra Barrionuevo, antes de decidir sobre la solicitud de suplicatorio al Congreso para que autorizara la declaración de Barrionuevo como imputado. La Junta de Fiscales del Tribunal Supremo aseguraba en su informe que las imputaciones de García Damborenea contra el presidente del Gobierno no reunían «las condiciones de verosimilitud y fundamentación mínimamente precisas» para solicitar un suplicatorio en su contra. Sin embargo, las imputaciones de cuatro de los procesados contra Barrionuevo eran «precisas, reiteradas y concordantes». El 23 de noviembre de 1995 el Congreso aprobó por 204 votos a favor, 122 en contra y 10 abstenciones la autorización para que el Tribunal Supremo pudiera llamarle a comparecer como imputado en el caso GAL.

En agosto de 1996 el gobierno de José María Aznar negó a los jueces los papeles del Cesid que reclamaban para continuar la investigación de los distintos casos vinculados a los GAL argumentando que afectaban a la seguridad del Estado, postura contraria a la que defendía el Partido Popular desde la oposición, cuando acusaban al gobierno de González de escudarse en la seguridad del Estado para salvaguardar la propia. En marzo de 1997 la Sala Tercera del Tribunal Supremo, tras analizar los informes del Cesid, decidió desclasificar algunos de ellos, decisión recibida con satisfacción por los partidos políticos y otras fuerzas sociales, aunque se señaló que los documentos desclasificados ya eran conocidos. El gobierno de Aznar comunicó que acataría las decisiones que tomara el Tribunal Supremo.

Finalmente, desde julio de 1986, tras la masacre de la plaza de la República Dominicana en Madrid se aplicaron las expulsiones hacia España en virtud del procedimiento de urgencia absoluta. Este mecanismo puso en la frontera hasta diciembre a un total de 26 refugiados, aplicando un decreto de 1945 que permitía la expulsión inmediata de cualquier extranjero que constituyera "una amenaza para el orden público". Esta relación directa entre "poner fuera de la circulación a los matones del GAL" y que Francia no fuera "santuario del terrorismo", fue expuesta con franqueza en la primavera de 1986 por el nuevo ministro del Interior Charles Pasqua.

Tras los GAL nunca volvió a ser igual la situación de los refugiados ligados a ETA en el sur de Francia. Paddy Woodworth lo resumió perfectamente: si el motivo de su creación fue acabar con el santuario francés, los organizadores lo habían logrado pero si su objetivo había sido acabar con ETA "fracasó estrepitosamente". No disminuyeron las víctimas y no perdió un ápice del apoyo político en el País Vasco, sino que "fue a más gracias al penoso espectáculo que había dado la incipiente democracia española".

Independientemente de esos dos factores, los datos que se fueron conociendo sobre la forma en que se organizaron y financiaron estos grupos tuvieron efecto búmeran contra el gobierno socialista español, en especial a partir de 1994.

Así la especulación en torno al grado de conocimiento y participación del gobierno en las actuaciones ilegales del GAL jugaron un factor determinante en la derrota del PSOE durante las elecciones generales españolas (1996), tras las que González renunció al liderazgo del partido. El propio González ha sido acusado de estar tras la misteriosa figura del "Sr. X" (nombre con el que se refieren los medios de comunicación al hipotético dirigente del entramado GAL, cuya identidad real no ha trascendido), toda vez que el entonces Presidente del Gobierno declarase, en relación con los GAL, que "me enteré por la prensa". El PSOE siempre ha negado toda responsabilidad respecto a los GAL y González nunca ha sido acusado formalmente ante un tribunal por estos hechos. Sin embargo, durante su administración, González no permitió la investigación completa de los fondos reservados con los que se había financiado a los GAL.

El senado constituyó una comisión de investigación que no llegó a aprobar un informe final de conclusiones, pero aclaró la participación de fondos y cargos públicos que después establecieron los jueces.

Durante el gobierno de José María Aznar, los antiguos cargos socialistas encabezados por Felipe González reclamaron la liberación de Rafael Vera y de José Barrionuevo condenados por el Caso Marey. El gobierno de Aznar concedió el indulto parcial a Barrionuevo y Vera el año 1998.

Tras la investidura del gobierno de José Luis Rodríguez Zapatero en 2004, que supuso la vuelta al poder del PSOE, nuevamente diferentes dirigentes socialistas, con Felipe González al frente, reclamaron el indulto total para Rafael Vera y otros condenados, aunque sin éxito. Coincidiendo con el regreso del PSOE, en el mes de septiembre fue puesto en libertad el último preso importante ligado a estos grupos, el general Enrique Rodríguez Galindo aduciendo enfermedad.

En enero de 2010, el Tribunal Europeo de Derechos Humanos rechazó un recurso de Rafael Vera por posible violación de la presunción de inocencia y falta de imparcialidad en la fase de instrucción.

En 2016, en una entrevista Felipe González declaró que "Nunca hemos tenido peor resultado en el País Vasco pese a las cosas que hicimos... tá-pá-pá". Estas palabras suscitaron polémica por parte de quienes las interpretaron como una referencia a los GAL.

En sus cuatro años de historia, los GAL cometieron más de treinta acciones terroristas, matando e hiriendo a cerca de sesenta personas. Entre sus métodos habituales estaban la colocación de bombas en los coches, tiros en la nuca y ametrallamiento en los bares donde supuestamente se encontraban los etarras. Varias de sus víctimas no tenían ninguna relación aparente con ETA. En algunos de esos casos, los GAL reconocieron haber equivocado su objetivo o pidieron disculpas.






































Posteriormente a esa fecha (que comúnmente es aceptada como el fin "oficial" de los GAL), se siguieron produciendo esporádicos actos de guerra sucia:


Los condenados por el Tribunal Supremo en el "Caso Marey" fueron:

Los GAL han sido un tema polémico durante mucho tiempo. Antes de su creación y durante sus años de actuaciones, algunos periódicos (tales como "ABC" y "Diario 16") solicitaron actuaciones de "guerra sucia" contra ETA o elogiaron dichas actuaciones. El exgeneral Rodríguez Galindo dijo en su libro "Mi Vida contra ETA" que Pedro J. Ramírez (entonces director de "Diario 16") alentó en artículos y editoriales la idea de crear el GAL.

Juan María Bandrés, exdiputado de Euskadiko Ezkerra, se quejó de la pasividad de los partidos en relación con el GAL: "«Yo me sentía muy solo denunciando los crímenes de los GAL en el Congreso. En aquel tiempo, todos los partidos miraban a otro lado. Por eso, me parece un poco hipócrita que actúen ahora como fiscales quienes, si no aplaudían, se cruzaban de acera para no encarar el problema»".

También se ha alegado que en países del entorno europeo ha habido casos como el de los GAL.

En 1984 el empresario vizcaíno Luis Olarra declaró a la agencia Efe: "«Los atentados de los GAL son una réplica, yo creo que todavía suave, al terrorismo»". "«Solamente se puede combatir de forma eficaz el terrorismo con sus mismas armas y métodos, todo lo demás son pamplinas»".

En 1995, el teniente general José Antonio Sáenz de Santa María (que posteriormente estaría imputado por uno de los atentados del GAL aunque fue exculpado) hizo unas declaraciones ambiguas al periódico "El País" en relación con la "guerra sucia" en la que, entre otras cosas dijo: "«Le responderé con una máxima: En la lucha contraterrorista, hay cosas que no se deben hacer. Si se hacen, no se deben decir. Si se dicen, hay que negarlas. Creo que he contestado.»" "«Me parece obscena, claramente [la actitud de la derecha ante el caso GAL]. Porque es un aprovechamiento oportunista de una situación de Estado que tendría que ser motivo de pacto constitucional.»" "«Se puede actuar con la legalidad contra el terrorismo, pero en el filo de la legalidad. Unas veces, un poco por el borde de dentro y otras veces, un poco por el borde de fuera.»"

En 1995 el filósofo José Luis Aranguren dijo que la guerra sucia contra ETA fue "un ejercicio de legítima defensa colectivo". Más adelante, aseguró que sus palabras habían sido mal interpretadas y pidió disculpas por si se había expresado con torpeza.

Más adelante, algunas personas han señalado la incoherencia de justificar o aplaudir el asesinato de Osama Bin Laden y condenar el GAL. En relación con la muerte de Osama bin Laden, el entonces magistrado Baltasar Garzón dijo que "«Su muerte no está justificada desde el punto de vista del Derecho Internacional»". En este asunto, Garzón puso como ejemplo los GAL. "«Si esto hubiera sucedido en España, se habría abierto procedimiento a quien hubiera dado la orden y exigido responsabilidades»", manifestó.




</doc>
<doc id="41933" url="https://es.wikipedia.org/wiki?curid=41933" title="Metástasis">
Metástasis

La metástasis (del griego , «cambio de lugar») es el proceso de propagación de un foco canceroso a un órgano distinto de aquel en que se inició. Ocurre generalmente por vía sanguínea o linfática. Aproximadamente el 92% de las muertes por cánceres no detectados se deben a la metastatización de estos. En realidad, aunque es la más conocida, la metástasis no se limita solo a la propagación de células cancerosas, sino que se habla de metástasis cuando un émbolo desarrolla nuevamente el mismo proceso de origen (cáncer, infecciones) en el lugar donde se produce la embolia.

Los cánceres son capaces de propagarse por el cuerpo debido a dos mecanismos: invasión y metástasis. La invasión es la migración y la penetración directa de las células del cáncer en los tejidos vecinos. La metástasis es la capacidad de las células del cáncer de penetrar en los vasos sanguíneos y linfáticos, viajar a través de la circulación sanguínea, y después crecer en un nuevo foco (metástasis) en tejidos normales de otra parte del cuerpo.

Los tumores se clasifican como benignos o malignos, en dependencia de si pueden invadir localmente o metastatizar a órganos distantes. Los tumores benignos son aquellos que no pueden diseminarse por invasión o metástasis; por lo tanto crecen solo localmente. Los tumores malignos son los capaces de propagarse por invasión y metástasis. Por definición, el término "cáncer" se aplica solamente a los tumores malignos.

Cuando se diagnostican a los pacientes con cáncer, se debe conocer si su enfermedad está localizada o se ha diseminado a otros órganos distantes.

La causa principal de muerte de un paciente por cáncer son las metástasis. Debido a la capacidad de propagarse a otros tejidos y órganos, el cáncer es una enfermedad potencialmente mortal, por eso es de gran interés comprender cómo se producen las metástasis en un tumor maligno.

Las células del cáncer que se extienden a los ganglios linfáticos cercanos al tumor primario (ganglios linfáticos regionales) se llaman invasión ganglionar, adenopatías, ganglios linfáticos positivos o enfermedad regional. Las células del cáncer también pueden diseminarse a otras partes del cuerpo, distantes del tumor primario. Los médicos utilizan el término "enfermedad metastásica" o "enfermedad diseminada" para describir al cáncer que se extiende a otros órganos o a los ganglios linfáticos con excepción de los cercanos o regionales al tumor primario.

Cuando las células cancerosas se diseminan y forman un tumor nuevo, este se llama tumor secundario o metastásico. Las células del cáncer que forman el tumor secundario son como las del tumor original. Por ejemplo, si un cáncer de mama se disemina (metastatiza) al pulmón, el tumor secundario está formado de células malignas del cáncer de mama. La enfermedad en el pulmón es cáncer de mama metastásico y no cáncer de pulmón.

La metástasis se produce a través de una serie compleja de pasos, la cascada metastásica, en que las células cancerosas abandonan el lugar original del tumor y son transportadas a otras partes del cuerpo a través de la circulación sanguínea o linfática. La cascada metastásica se inicia con la ruptura de los límites naturales del tejido, la lámina basal, en caso de epiteliomas, mediante un proceso de invasión de la matriz extracelular. A la invasión sigue la intravasación, fenómeno por el que la célula tumoral se introduce en un vaso sanguíneo o linfático y procede a su circulación por el organismo. Procesos inflamatorios y de restricción de elasticidad, receptores de superficie celular determinan la detención de la célula tumoral en un capilar. Tras su detención la célula tumoral procede a su extravasación a la matriz conectiva perivascular, para proliferar en su nuevo asentamiento y formar una metástasis. Para invadir la matriz extracelular, las células malignas se separan del tumor primario se unen y degradan las proteínas de la matriz extracelular circundante, ya degradada por células inflamatorias , que separa el tumor de tejido colindante. En la matriz degradada, las células neoplásicas pueden moverse y escaparse de sus límites naturales establecidos durante el desarrollo embrionario. Cuando los cánceres metastatizan, viajan comúnmente a través del sistema linfático a los ganglios linfáticos próximos interpuestos en la línea de drenaje de la linfa.

La investigación de las condiciones necesarias para la metástasis del cáncer han descubierto que uno de los acontecimientos críticos requeridos para el crecimiento de los tumores y la producción de sus metástasis es el desarrollo de una nueva red de los vasos sanguíneos. Este proceso de formar nuevos vasos sanguíneos se llama angiogénesis.

La angiogénesis del tumor es la proliferación de una red de vasos sanguíneos que penetra en el tumor, le proporciona nutrientes, oxígeno y le retira los residuos. La angiogénesis tumoral puede estar favorecida por las propias células cancerosas, y por las células inflamatorias normales atraídas por el proceso neoplásico, que producen moléculas como la familia VEGF que generan señales en células del tejido normal circundante. Estas señales activan ciertos elementos el tejido huésped que responde con la activación del procesos que estimulan el crecimiento de nuevos vasos sanguíneos.

La transformación de una célula tumoral en una célula tumoral metastásica implica probablemente cambios genéticos transitorios o permanentes, que determinan la expresión de moléculas con acciones que favorecen o protegen los mecanismos necesarios para la metástasis. Aparentemente, la duda que había preocupado a los oncólogos durante siglos ("¿Cómo consigue el cáncer producir todos los complejos procesos necesarios para desarrollar una metástasis?") tiene una posible respuesta: no hace nada nuevo por sí mismo. El cáncer es un tejido alterado, pero que conserva todos los genes propios, normales o mutados, por lo que puede aprovechar para metastatizar mecanismos celulares normales, que debieran haberse inactivado luego de terminar el desarrollo embrionario.

Recientemente, en el 2004, investigadores del Instituto Tecnológico de Massachusetts (MIT) descubrieron que un gen localizado en el cromosoma 7 puede jugar un papel importante en la producción y propagación de metástasis a órganos distantes. La proteína producida por este gen controla la diferenciacion de tejidos embrionarios, pero normalmente se desactiva por completo una vez que el feto está ya formado.

El responsable de esta conducta es un gen que sintetiza una proteína llamada "twist", cuya función normal es controlar ciertos pasos de la diferenciacion tisular. Twist está muy activa en el desarrollo embrionario temprano, cuando dirige a los tejidos en formación, ayuda a organizarlos y les indica hacia dónde tienen que migrar. Cumplida su misión, la proteína twist queda inactiva por el resto de la vida del individuo.

Las investigaciones de 2004 demostraron que la proteína derivada de este gen no existe en las células normales de los tejidos adultos ni en el tumor primario, pero que está aparentemente activa en los tejidos metastásicos.

Algunos experimentos parecen demostrar que si se desactiva el gen responsable de sintetizar twist en algunas células consideradas metastásicas y se inoculan luego en animales de experimentación, estos desarrollan un tumor, pero ninguna metástasis. Si el tejido se inyecta sin desactivar el gen, el animal desarrollará el tumor primitivo y metástasis.

Los estudios acerca del papel que cumple el gen Twist están aún en sus comienzos. Hace pocos años que se ha empezado a descubrir sus funciones en unos pocos ejemplos tumorales y en un modelo de mosca de la fruta (Drosophila Melanogaster), más aún, solo en un tipo de cáncer (carcinoma de mama) y solamente en dos especies de vertebrados (los ratones y nosotros). El Dr.Robert Weinberg, descubridor del Gen Twist, afirma: "Hay muchos otros genes reguladores que tienen propiedades semejantes a las del Twist. Ellos juegan, sin duda alguna, roles similares e igualmente importantes en otros tipos de cánceres metastásicos".

Las metástatis corresponde siempre con un tumor primario, es decir un tumor que empezó con una célula o células malignas en otra parte del cuerpo. 
El uso de la inmunohistoquímica ha permitido que los patólogos den una identidad a muchas de estas metástasis. 

Las células de un tumor metastásico se parecen a las del tumor primario. Una vez que el tejido canceroso se examina al microscopio para determinar el tipo celular, un médico puede decir generalmente si ese tipo de célula ha sido encontrado normalmente en la parte del cuerpo del cual la muestra de tejido fue tomada.

Por ejemplo, las células del cáncer de mama se parecen igual si están encontradas en la mama o se han diseminado a otra parte del cuerpo. Así pues, si una muestra del tejido tomada de un tumor en el pulmón contiene las células que se parecen a las células de la mama, se diagnostica que el tumor del pulmón es un tumor secundario o metastásico. 

Los cánceres metastásicos se pueden diagnosticar al mismo tiempo que el tumor primario, meses, o años más adelante. Cuando un segundo tumor se encuentra en un paciente que se ha tratado de cáncer en el pasado, es más posible que sea una metástasis que otro tumor primario.

Cerca del 10% de pacientes con cáncer, se diagnostican de un tumor secundario, pero no se puede hallar ningún tumor primario, a pesar de pruebas diagnósticas complejas. Los médicos denominan al tumor primario desconocido u oculto, y dicen que el paciente padece de un cáncer de origen primario desconocido o metástasis de origen desconocido. En casos raros (por ejemplo melanoma) no se encuentra ningún tumor primario incluso en la autopsia. Por lo tanto se piensa que algunos tumores primarios pueden desaparecer totalmente, pero deja sus metástasis detrás.

Las localizaciones más frecuentes de las metástasis son los órganos más irrigados por la sangre como son el cerebro, los pulmones, el hígado, los huesos y las glándulas suprarrenales. La excepción a esta regla son los riñones y el propio corazón, pese a que por sus cavidades pasan muchos litros de sangre al día.

También existe la tendencia de ciertos tumores a diseminarse en determinados órganos. Por ejemplo el cáncer de próstata, aunque puede diseminarse en cualquier órgano, tiende a propagarse por los huesos. Igualmente el cáncer de colon, lo hace en el hígado y el cáncer de estómago en los ovarios en el caso de las mujeres, llamándose en este caso tumor de Krukenberg. 

Los cánceres que más metastatizan son los cánceres más frecuentes como el cáncer de mama, el cáncer de pulmón, el cáncer colorrectal.

Cuando el cáncer ha producido metástasis, se puede tratar con quimioterapia, radioterapia, terapia biológica, tratamiento hormonal, cirugía, o una combinación de estos. La elección del tratamiento depende generalmente del tipo de cáncer primario, del tamaño, la localización de la metástasis, la edad, la salud general del paciente y los tipos de tratamientos usados previamente. En los pacientes diagnosticados de metástasis de origen desconocido, sigue siendo posible tratar la enfermedad incluso cuando el tumor primario no puede ser localizado.

Cuando un cáncer presenta metástasis se encuentra en la fase o estado más avanzado (estado IV). Algunos tumores como el cáncer testicular y algunos linfomas pueden ser curables cuando se encuentra en enfermedad metastásica en la mayoría de los casos.




</doc>
<doc id="41940" url="https://es.wikipedia.org/wiki?curid=41940" title="Simbolismo">
Simbolismo

El simbolismo fue uno de los movimientos literarios más importantes de finales del siglo XIX. Tiene su origen en Francia y en Bélgica. En un manifiesto literario publicado en 1886, Jean Moréas definió este nuevo estilo como «"enemigo de la enseñanza, la declamación, la falsa sensibilidad y la descripción objetiva"». Para los simbolistas, el mundo es un misterio por descifrar, y el poeta debe para ello trazar las correspondencias ocultas que unen los objetos sensibles (por ejemplo, Rimbaud establece una correspondencia entre las vocales y los colores en su soneto "Vocales"). Para ello es esencial el uso de la sinestesia.

El movimiento tiene sus orígenes en "Las flores del mal", libro emblema de Charles Baudelaire. El escritor Edgar Allan Poe, a quien Baudelaire apreciaba en gran medida, influyó también decisivamente en el movimiento, proporcionándole la mayoría de imágenes y figuras literarias que utilizaría. La estética del simbolismo fue desarrollada por Stéphane Mallarmé y Paul Verlaine en la década de 1870. Para 1880, el movimiento había atraído toda una generación de jóvenes escritores cansados de los movimientos realistas.
Aunque el movimiento surge en Francia y Bélgica, se extendió a otras naciones. Asociado sobre todo a la literatura, cubre sin embargo también a escultores y pintores.

El simbolismo fue en sus comienzos una reacción literaria contra el naturalismo y el realismo, movimientos anti-idealistas que exaltaban la realidad cotidiana y la ubicaban por encima del ideal. Estos movimientos provocaron un fuerte rechazo en la juventud parisina, llevándolos a exaltar la espiritualidad, la imaginación y los sueños. El primer escritor en reaccionar fue el poeta francés Charles Baudelaire, hoy considerado padre de la lírica moderna y punto de partida de movimientos como el parnasianismo, el decadentismo, el modernismo y el simbolismo. Sus obras, entre las que destacan "Las flores del mal", "Los pequeños poemas en prosa" y "Los paraísos artificiales", fueron tan renovadoras que algunas de ellas fueron prohibidas por considerarse oscuras e inmorales, al retratar sin tapujos el uso de drogas, la sexualidad y el satanismo. El primer movimiento descendiente de esta ideología postromántica sería el parnasianismo.

Los simbolistas fueron separándose del parnasianismo porque no compartían la devoción de este por el verso perfecto. El Simbolismo se inclinaba más bien hacia el hermetismo, desarrollando un modelo de versificación más libre y desdeñando la claridad y objetividad del parnasianismo. No obstante, varias características parnasianas fueron acogidas, como su gusto por los juegos de palabras, la musicalidad en los versos y, más que nada, el lema de Théophile Gautier del "arte por el arte". Los movimientos quedaron completamente separados cuando Arthur Rimbaud y otros poetas se mofaron del estilo perfeccionista parnasiano, publicando varias parodias sobre el modo de escribir de sus más prominentes figuras.

Otros dos precursores del simbolismo fueron los franceses Arthur Rimbaud y Paul Verlaine. Estos dos poetas, que para esa época tenían una azarosa relación amorosa, fueron decisivos para el arranque del movimiento. Rimbaud, que contaba con 17 años, fue el más influyente, al buscar lo que llamó su "alquimia del verbo" en la cual trataba de convertirse en vidente por medio del "desarreglo de todos los sentidos". Con este pretexto pasó a sumirse, junto a Verlaine, en toda una ola de excesos. Vagabundeaba día y noche por las calles de París para luego presentarse en las reuniones literarias con la ropa sucia o en estado etílico, hechos que rápidamente le dieron mala fama y el sobrenombre de "enfant terrible". Sus obras más representativas fueron "Una temporada en el infierno" e "Iluminaciones".

En cuanto a Verlaine, su libro de crítica literaria "Los poetas malditos" se convirtió en el más influyente escrito dentro del Simbolismo hasta esa época, mostrando la verdadera esencia del movimiento. En él se exponían ensayos sobre Tristan Corbière, Arthur Rimbaud, Stéphane Mallarmé, Marceline Desbordes-Valmore, Villiers de L'Isle-Adam, y "Pobre Lelian" (anagrama del propio Verlaine), poetas que Verlaine bautizó como "malditos".

Verlaine expuso que dentro de su individual y única forma, el genio de cada uno de ellos había sido también su maldición, alejándolos del resto de personas y llevándolos de esta forma a abrazar el hermetismo y la idiosincrasia como formas de escritura. También fueron retratados como desiguales respecto a la sociedad, al llevar vidas trágicas y entregarse con frecuencia a tendencias autodestructivas; todo esto como consecuencia de sus dones literarios. El concepto de Verlaine del "poeta maldito" fue en parte tomado del poema de Baudelaire llamado "Bendición", que abre su libro Las flores del mal.

Después de esto, Paul Verlaine pasó a convertirse en el líder del decadentismo (movimiento literario hermano del Simbolismo) y Stéphane Mallarmé (1842–1898) pasó a ser la figura más representativa del Simbolismo, en especial después de publicar su libro "Una tirada de dados jamás abolirá el azar", creando un lenguaje hermético cercano al antiguo culteranismo español y a la sintaxis del inglés y reuniendo semana a semana a decenas de seguidores del movimiento en su casa.

La poesía simbolista busca vestir a la idea de una forma sensible, posee intenciones metafísicas, además intenta utilizar el lenguaje literario como instrumento cognoscitivo, por lo cual se encuentra impregnada de misterio y misticismo. Fue considerado en su tiempo por algunos como el lado oscuro del Romanticismo. En cuanto al estilo, basaban sus esfuerzos en encontrar una musicalidad perfecta en sus rimas, dejando a un segundo plano la belleza del verso. Intentaban encontrar lo que Charles Baudelaire denominó la teoría de las «correspondencias», las secretas afinidades entre el mundo sensible y el mundo espiritual. Para ello utilizaban determinados mecanismos estéticos, como la sinestesia.

Los simbolistas creían que el arte debía apuntar a capturar las verdades más absolutas, las cuales solo podían ser obtenidas por métodos indirectos y ambiguos. De esta forma, escribieron con un estilo altamente metafórico y sugestivo. El manifiesto simbolista, publicado por Jean Moréas, definía al Simbolismo como "enemigo de la enseñanza, la declamación, la falsa sensibilidad, la descripción objetiva" y señalaba que "su objetivo no está en sí mismo, sino en expresar el Ideal":
là des apparences sensibles destinées à représenter leurs affinités ésotériques avec des Idées primordiales"."

En contraste con la importancia que tuvo en la poesía, el Simbolismo tuvo una repercusión menor en la narrativa y el teatro. Aun así aparecieron novelas como "A contrapelo", de Joris-Karl Huysmans, que exploraba diversos temas relacionados con la estética simbolista. Esta novela, en la que casi no existe trama, expone los gustos decadentes del recluso y rebelde conde Des Esseintes. Oscar Wilde imitó esta novela en numerosos pasajes de su obra "El retrato de Dorian Gray". Otra obra importante en prosa simbolista es "Cuentos crueles" de Villiers de L'Isle-Adam.

En cuanto al teatro, el énfasis en la vida de ensueños y fantasías que promovían los simbolistas hizo difícil su completa aceptación por parte de críticos y corrientes contemporáneas. Sin embargo la obra "Axël", también de Villiers de L'Isle-Adam, fue definitivamente la obra teatral más influenciada por el Simbolismo. En la obra, después de un conflicto inicial, un príncipe y una princesa se enamoran y pasan horas haciendo maravillosos planes para el futuro. Pero luego, al aceptar que la vida jamás podría cumplir dichas ilusiones y expectativas, ambos se suicidan. Otra obra teatral con gran carga simbolista es la tragedia Salomé de Oscar Wilde.

El simbolismo literario hispano, con algunos importantes antecedentes peninsulares como Gustavo Adolfo Bécquer y Salvador Rueda, se subsumió en un movimiento más general conocido como Modernismo, que empezó en Hispanoamérica.

Se encuentra Simbolismo ya en los cubanos Julián del Casal y José Martí, en el colombiano José Asunción Silva, en el mexicano Manuel Gutiérrez Nájera y otros autores posrománticos americanos como el argentino Leopoldo Lugones,el uruguayo Julio Herrera y Reissig, Ricardo Jaimes Freyre, Amado Nervo, Salvador Díaz Mirón, Guillermo Valencia, o el peruano, José María Eguren; el nicaragüense Rubén Darío, gran introductor del Modernismo en España, lo asimiló y difundió.

En España lo cultivaron Antonio y Manuel Machado, Juan Ramón Jiménez, Francisco Villaespesa y Ramón Pérez de Ayala entre los más importantes.

Paralelamente a la preocupación del impresionismo por la pintura al aire libre contra el academicismo oficial y a los intentos de construcción científica de la pintura por el llamado puntillismo, se desarrolla una nueva concepción sobre la función y objeto de la pintura. Los simbolistas —cuyos precedentes se encuentran en William Blake, los nazarenos y los prerrafaelitas— propugnan una pintura de contenido poético.

El movimiento simbolista reacciona contra los valores del materialismo y del pragmatismo de la sociedad industrial, reivindicando la búsqueda interior y la verdad universal y para ello se sirven de los sueños que gracias a Freud ya no conciben únicamente como imágenes irreales, sino como un medio de expresión de la realidad.

El Simbolismo no pudo desarrollarse mediante un estilo unitario; por eso, se hace muy difícil definirlo de forma general. Es más bien un conglomerado de encuentros pictóricos individuales.

Necesitó desde un principio de un idioma pictórico abstractivo. En consecuencia, los pintores hicieron uso de un vocabulario de formas lineal y ornamental y de una composición del cuadro antinaturalista. Son especialmente estos elementos abstractivos y acentuados en la linealidad, así como las relaciones composicionales inmanentes al cuadro, los que hacen del Simbolismo el precursor del tan cercano Modernismo. En Gustave Moreau existe una visión particular sobre la belleza, el amor y la muerte. Pierre Puvis de Chavannes parece perpetuar la claridad y el rigor compositivo del clasicismo combinado con colores planos y claros. Sus obras parecen vacías de movimiento y de luz. Odilon Redon encamina sus esfuerzos hacia la representación de ideas, de tal manera que su obra se aproxima a lo que más tarde será la estética surrealista.

El Simbolismo es una tendencia que supera nacionalidades, límites cronológicos y estilos personales. Para complicar más la cuestión, el Simbolismo derivará en una aplicación bella y cotidiana de honda raigambre en el arte europeo de fines del siglo XIX y principios del XX: el Art Nouveau. El Simbolismo pretende restaurar significado al arte, que había quedado desprovisto de este con la revolución impresionista. Mientras que otros neoimpresionistas se inclinan por ramas científicas o políticas, el Simbolismo se decanta hacia una espiritualidad frecuentemente cercana a posiciones religiosas y místicas. La fantasía, la intimidad, la subjetividad exaltada sustituyen la pretenciosa objetividad de impresionistas y neo-impresionistas. Continúan con la intención romántica de expresar a través del color, y no quedarse solamente en la interpretación. Ahí encontramos el nexo de unión con el resto de neo-impresionistas, puesto que las teorías del color local y los efectos derivados de las yuxtaposiciones de primarios, complementarios, etc., les resultarán muy útiles a la hora de componer sus imágenes, muy emotivas, como en la casi violenta visión de la pasión amorosa que Klimt ofrece en su Dánae.

Los simbolistas encontraron un apoyo paralelo en los escritores: Charles Baudelaire, Jean Moréas, en contra del naturalismo descarnado de Zola. En cuanto a la escultura, Rodin fue el más cercano a sus planteamientos, y pese a todo, íntimamente ligado a los presupuestos del gran escultor impresionista Edgar Degas. Muy cercana a los planteamientos del Simbolismo, en cuyo seno se inscribe, se sitúa la Escuela de Pont-Aven, una de las primeras en definirse como tal. Pont-Aven es una pequeña localidad rural de la Bretaña francesa, a donde se dirigió en 1886 un grupo de pintores neo-impresionistas. El primero de todos fue Émile Bernard, que trataba de recuperar la integridad de lo rústico, de lo arcaico, en una región totalmente ajena a los avances de la vida moderna. Bernard cultivó un estilo muy personal de colores planos, perfectamente delimitados en contornos silueteados.

El Simbolismo posee una estética académica, y se presta más a las realizaciones escultóricas de vanguardia. Junto con Rodin destacan Aristide Maillol (1861–1944), que es el gran maestro de la escultura simbolista. "La noche, Isla de Francia, Flores en la pradera, Venus, Flora, El río". También destacan Adolf von Hildebrand, "Estatua ecuestre del príncipe regente", Medardo Rosso, "Niño enfermo, Cabeza de niño", Antoine Bourdelle, "Hércules arquero".

En el ámbito de la pintura, el simbolismo encuentra exponentes como Gustave Moreau (francés que nace en 1826 y muere en 1898). Sus pinturas más destacadas son "Júpiter y Semele", "Europa y el toro" y "los unicornios". También está el artista Odilon Redon, otro francés que nace en 1840 y fallece en 1915. Como obras importantes, hay que destacar "El carro de Apolo", "Druida" y "viejo alado con larga barba". Hay que destacar también a "Los Nabis", un grupo de tres artistas que son Félix Vallotton (suizo, 1865-1925) (obra: "La pelota"), Pierre Bonnard (francés, 1867-1947) (obra: "Mujeres en el jardín") y Edouard Vuillard (francés 1868-1940) (obras: "Jardines públicos" y "Los dos escolares") y finalmente con Néstor Martín-Fernández de la Torre desaparece el simbolismo tras su muerte, ya que él lo representaba siempre en todas sus pinturas.

Pictóricamente las características más relevantes son las siguientes:


Una de las novedades más importantes, a nivel temático, es el de la mujer fatal. Surge la unión entre el Eros y el Thanatos y en ello subyace una nueva relación entre sexos. 

A la pintura se la define con conceptos como ideista (de ideas), simbolista, sintética, subjetiva y decorativa.


Los simbolistas españoles estuvieron fuertemente influidos por el arte de los precursores, entre los que destacan Gustave Moreau, Pierre Puvis de Chavannes, Arnold Böcklin, Edward Burne-Jones y Rodolphe Bresdin.

Muchos se decantaron solamente con el auténtico exponente del Simbolismo. Odilon Redon, que cultivó un estilo de colores puros y una temática fantasiosa, buscaba una síntesis entre el sueño y la vida. Sin embargo, ya se habían manifestado estas ideas en el Gauguin de la Escuela de Pont-Aven y en sus seguidores.

Posteriormente, los Nabis, segunda generación simbolista, aspiraron a traducir estas ideas en forma de vida y en activas reformas. Al contrario que el impresionismo, escuela concreta y localizada básicamente en Francia, el Simbolismo fue un gran movimiento que también se extendió a España. Se difundió a partir de 1890, y adoptó diferentes interpretaciones. En Cataluña se destaca la obra de Juan Brull, Adrià Gual y del Santiago Rusiñol de mediados de los años de 1890. En el seno del Simbolismo tomó también cuerpo una tendencia que acentuaba ciertos trazos de sus figuraciones, lo que desequilibraba la representación objetivista de las cosas en un sentido fuertemente expresivo.

En Bélgica cabe señalar la obra de Jean Delville, Fernand Khnopff y William Degouve de Nuncques, en la línea del culto a lo misterioso. Esta tendencia, que tiene un precursor claro en el belga Félicien Rops, está representada por Jan Toorop, una de las figuras clave, junto a Klimt, del Simbolismo pictórico.

En Italia, por el contrario, el Simbolismo tuvo una fuerte base de minucioso realismo en la obra de Gaetano Previati, Giovanni Segantini y Pellizza da Volpedo.

También en Alemania el arte simbolista se caracterizó por una técnica muy realista, pero con una temática idealista; destaca aquí Ferdinand Hodler (suizo).

En los países escandinavos se caracteriza por una visión austera y una acusada expresión de la soledad, con artistas como Vilhelm Hammershøi, Harald Sohlberg, Thorárinn B. Thorláksson y Magnus Enckell. La excepción sería el fines Akseli Gallen-Kallela, inclinado hacia la mitología.

El simbolismo tuvo una marcada influencia en movimientos posteriores, como el Art nouveau o el surrealismo.


Desde 1873 la villa de Pont-Aven es frecuentada por los alumnos de la Escuela de Bellas Artes de París. En 1886 llega Gauguín y en 1888 se instala un grupo de pintores dispuestos a seguir sus enseñanzas al margen de la Academia. Participan en la exposición del Café Volpini en 1889. Ese mismo año, Gauguín marcha para Tahití y el grupo se desvanece.

Sus obras se caracterizan por el uso libre del color —pueden pintar la hierba roja si así lo sienten—, que se aplica en grandes manchas y con tintas planas. Utilizan el cloisonismo. El resultado es una obra altamente decorativa. En esta forma de pintar ha influido mucho el conocimiento del arte primitivo y las estampas japonesas. Existe una voluntad de sintetizar las formas. Son una síntesis entre el estilo impresionista y el simbolista por lo que pueden ser considerados simbolistas, por su espíritu.

Entre los pintores más destacados de Pont-Aven están Emile Bernard: "Bretones bailando en la pradera", Charles Laval: "Autorretrato", Meijer de Haan: "Bretonas tejiendo cáñamo", Paul Sérusier: "Naturaleza muerta con escalera", Émile Schuffenecker: "Los acantilados de Concarneau", Cuno Amiet, Louis Anquetin y Roderic O’Connor.

Los nabis son seguidores de las ideas estéticas de la escuela de Pont-Aven, pero no pertenecen a la Academia, o son desertores. Nabis significa profetas, en hebreo. Intentaron que el Impresionismo se acercase al Simbolismo, por lo que se les puede considerar simbolistas. Su concepción estética es fundamentalmente decorativa, por lo que lo que se plasma en el cuadro es un juego de sensaciones, más que una construcción intelectual.

Utilizan colores planos, con un gran sentido estético. Tienen una libertad absoluta a la hora de utilizar el color y las composiciones. Usaron todo tipo de materiales en sus cuadros, pintura, cola, cartón, etc., para diferenciar texturas, pero sin llegar al collage. Proyectaron vidrieras y usaron litografías y grabados para expresarse. 

Decoraron teatros, portadas de libros, revistas y cualquier cosa que les solicitasen, trabajando por encargo. Esto implicó, por un lado que sus obras fuesen ampliamente conocidas y por otro que no fuesen únicas, sino que se imprimían y repetían, dando a la obra de arte una nueva dimensión. La obra de arte deja de ser única, a pesar de ello no crearon escuela.

Entre los nabis destacan pintores como Pierre Bonnard: "Retrato de Nathanson y la señora Bonnard", Edouard Vuillard: "Autorretrato", Maurice Denis: "Paisaje con árboles verdes", Félix Vallotton: "La lectora", Ker Xavier Roussel: "Montones junto al mar", Henri-Gabriel Ibels, y Paul Ranson. También pueden considerarse nabís los tres grandes simbolistas, Gustave Moreau, Odilon Redon y Chavannes.





</doc>
<doc id="41942" url="https://es.wikipedia.org/wiki?curid=41942" title="Peste">
Peste

La peste es una enfermedad infectocontagiosa que afecta tanto a animales como a humanos. Está causada por la bacteria "Yersinia pestis". Es una de las enfermedades bacterianas más agresivas y provoca frecuentemente la muerte de la persona afectada si no se instaura el tratamiento antibiótico adecuado. Generalmente se transmite por picadura de pulgas infectadas procedentes de roedores, que originan bubones en ingles y axilas, cuadro clínico conocido como peste bubónica. Si la transmisión tiene lugar por vía respiratoria, se produce una forma particular de la enfermedad conocida con el nombre de peste neumónica. A la gran epidemia de peste que afectó a Europa a mediados del siglo XIV se la denomina en ocasiones como peste negra. Además de estos tipos de peste existe la peste septicémica, que es una infección de la sangre (causada por la Yersinia pestis), aunque esta variante solo se puede dar si se tienen una o las otras dos variantes.

A fecha de 2020, hay descritas veinte especies del género "Yersinia", de las cuales tres son patógenos humanos importantes. "Yersinia enterocolitica" y "Yersinia pseudotuberculosis" son patógenos entéricos que se adquieren habitualmente por ingestión de comida o agua contaminadas. La tercera especie, "Yersinia pestis", causa la peste. Aunque está estrechamente relacionada con "Y. pseudotuberculosis", "Y. pestis" ha sufrido cambios evolutivos que la han convertido en un patógeno transmitido por vectores capaz de producir niveles altos de bacteriemia en los huéspedes mamíferos.

"Y. pestis" es un cocobacilo aerobio gramnegativo que muestra una tinción bipolar con Gram, Giemsa y Wright. Miembro de la familia Yersiniaceae, crece bien en agar infusión cerebro-corazón, agar sangre o el agar MacConkey. En los dos últimos produce colonias pequeñas de 1-2 mm de diámetro tras incubarse a 37 ºC entre 24 y 48 horas; a las 72, las colonias en agar sangre pueden adoptar una morfología elevada e irregular similar a un huevo frito. "Y. pestis" no produce endosporas y, a diferencia de "Y. enterocolitica" y "Y. pseudotuberculosis", es inmóvil cuando se cultiva a temperaturas bajas. No fermenta la lactosa y es negativa para las pruebas del citrato, ureasa e indol.

Según demuestran estudios genéticos, "Y. pestis" evolucionó en tiempos recientes a partir de "Y. pseudotuberculosis". Para la transición desde un patógeno entérico a uno transmitido por pulgas, necesitó desarrollar la habilidad de sobrevivir en el intestino de estos animales y poder alcanzar altas concentraciones en la sangre de los huéspedes mamíferos. Estas características fueron obtenidas, en parte, a través de la adquisición de dos plásmidos que expresan distintos factores dependiendo de la temperatura corporal del organismo, pulga o mamífero, en el que se encuentre la bacteria. El plásmido pMT1/pFra, de 110 kilobases, codifica tanto la toxina murina de "Yersinia" (Ymt), necesaria para la colonización del intestino medio de la pulga, como el antígeno capsular o fracción 1 (F1), que inhibe la fagocitosis en mamíferos. Por otra parte, el plásmido pPCP1, de 9.5 kilobases, codifica una proteína activadora del plasminógeno (proteasa Pla) responsable de la actividad coagulasa y fibrinolisina dependiente de temperatura. Los orígenes de estos plásmidos son inciertos; sin embargo, aproximadamente la mitad de la secuencia de ADN del pMT1/pFra es similar a otro plásmido de la bacteria "Salmonella" Typhi.

Al igual que otras especies del género, "Y. pestis" tiene otro plásmido de aproximadamente 70 kilobases que media la expresión de factores de virulencia que previenen la producción de citocinas proinflamantorias, aumentan la resistencia a la fagocitosis y mejoran la supervivencia intracelular. Otros factores codificados por el cromosoma principal incluyen un potente lipopolisacárido y un factor de pigmentación, el locus de almacenamiento de hemina ("hms"), que regula la absorción de hierro y permite a la bacteria formar bloqueos en el intestino de las pulgas para incrementar la transmisión.

Las muestras de "Y. pestis" se pueden clasificar en tres biovares dependiendo de su capacidad para fermentar el glicerol y reducir el nitrato. Se ha postulado que estos —llamados Antigua, Medievalis y Orientalis— reflejan las cepas asociadas con la primera, segunda y tercera pandemia de peste, respectivamente. Varios estudios con métodos moleculares sugieren, sin embargo, que estos biovares no se correlacionan por completo con estas relaciones filogenéticas y que aunque Orientalis si está asociado con la tercera pandemia, el vínculo con los otros dos es dudoso.

Hoy en día, la peste continúa siendo una amenaza en zonas de África, Asia y América, incluido el oeste de los Estados Unidos. Hasta 2007, cuando se discontinuó la declaración obligatoria, se declaraban a la Organización Mundial de la Salud (OMS) entre 1000 y 6000 casos anuales en 25 países. Casi el 80 % se daban en África, el 15 %, en Asia y el resto, en América. Entre 2010 y 2015 solo se comunicaron unos 500 casos anuales a la OMS. No obstante, aún existe potencial para que se den brotes, especialmente en zonas rurales de Madagascar, Uganda y la República Democrática del Congo. En 2017, se produjo una epidemia de peste neumónica en Antananarivo, capital de Madagascar, en el que se identificaron más de 2700 casos sospechosos. Aunque las cifras verdaderas de infectados probablemente fueron mucho menores, el impacto social y económico fue considerable. La enfermedad puede reaparecer en zonas donde no se habían declarado casos durante décadas, como demostraron los brotes en Argelia de 2003 y en Libia de 2009.

El primer caso no importado de peste en los Estados Unidos se dio en San Francisco (California) en 1900. Inicialmente restringida a ciudades portuarias, permanece endémica en diecisiete estados entre las Grandes Llanuras y la costa del Pacífico. Se notificaron 437 casos en humanos entre 1970 y 2010 (unos diez por año), con sesenta muertes (14 % de mortalidad). Entre 2010 y 2016 hubo entre dos y dieciséis casos anuales. Aproximadamente, el 80 % ocurren en Nuevo México, Arizona y Colorado, mientras que el 10 % se dan en California. Predomina ligeramente en varones y más de la mitad de los afectados son menores de veinte años. La incidencia es mayor en nativos americanos e hispanos, aunque en términos absolutos los blancos no hispanos son mayoría. En las zonas endémicas, los factores de riesgo son estar en contacto con roedores y sus depredadores felinos y caninos, la presencia de fuentes de cobijo y alimento para roedores en los alrededores de los hogares y posiblemente no tratar las pulgas en perros y gatos domésticos. Durante el , el desarrollo urbano de las zonas endémicas ha propiciado un aumento de casos en algunas áreas y un cambio de tendencia en cuanto al nivel socioeconómico de los infectados, que se ha vuelto mayor. Los viajeros con peste pueden suponer un reto diagnóstico cuando no se encuentran en zonas endémicas (peste peripatética) y pueden generar preocupación sobre un posible ataque bioterrorista.

La epizootiología de la peste es compleja y aún no se ha comprendido por completo. Es, fundamentalmente, una enfermedad de los roedores transmitida por pulgas distribuida en focos endémicos a lo largo del mundo que pueden involucrar a distintas especies de huéspedes y vectores, cada una con su propia ecología. Quizá a causa de las condiciones climáticas, periódicamente suceden epizootias que se caracterizan por una expansión rápida de la enfermedad y gran mortalidad entre los roedores susceptibles. Esto promueve la dispersión de pulgas infectadas e incrementa el riesgo de transmisión a humanos, especialmente cuando están involucradas especies de roedores que viven cerca de las personas. A nivel mundial, las especies más preocupantes son la rata negra ("Rattus rattus"), la rata parda ("Rattus norvegicus") y sus pulgas, "Xenopsylla cheopis" y "Xenopsylla brasiliensis". En el oeste de los Estados Unidos las epizootias suelen ocurrir en "Spermophilus" spp., perritos de las praderas ("Cynomus" spp.) y "Tamias" spp., además de otras familias de roedores.

Se desconoce cómo sobrevive "Y. pestis" en la naturaleza entre epizootias. Una hipótesis sostiene que el organismo sigue circulando lentamente y sin ser detectado en ciclos enzoóticos que involucran a especies de roedores menos susceptibles a una infección fulminante. También se ha propuesto que, aunque la bacteria muere rápidamente en superficies inertes, podría ser capaz de sobrevivir en nichos en el suelo e infectar periódicamente a roedores que hurguen en él. La demostración de que "Y. pestis" puede reproducirse en el interior de algunas amebas de vida libre le ha dado un impulso a esta última hipótesis.

El ser humano puede infectarse con "Y. pestis" mediante picaduras de pulga, contacto directo con los tejidos o secreciones de animales contagiados o, raramente, por inhalación. La transmisión por pulgas es especialmente común durante epizootias, en las que mueren un gran número de roedores y estas deben buscar fuentes alternativas de sangre de la que alimentarse. Los cazadores pueden infectarse por inoculación directa al desollar o manipular cadáveres de roedores, conejos, liebres, gatos salvajes y coyotes infectados; esta forma de contagio está asociada con un riesgo aumentado de septicemia y muerte, quizá porque la bacteria, al provenir de un huésped de sangre caliente, expresa desde el primer momento el antígeno F1 y es más resistente a ser fagocitada. Se ha identificado también que el consumo de carne cruda de camellos, cabras y otros ungulados, que son susceptibles a la infección, ha sido el origen de pequeños brotes en el norte de África, Oriente Próximo y Asia Central. Los aerosoles generados al manipular animales infectados también pueden suponer un riesgo, como demuestra el caso de un biólogo estadounidense que desarrolló peste neumónica primaria después de hacerle la autopsia a un puma. Habitualmente, un humano no transmite la enfermedad a otro, aunque los que desarrollan peste neumónica pueden contagiar a contactos cercanos a través de gotas de Flügge.

Potencialmente, los animales domésticos también son una fuente de exposición al patógeno. Los gatos que comen roedores infectados desarrollan cuadros faríngeos que pueden contagiar a humanos mediante gotas de Flügge y causar peste neumónica primaria. Aunque parece menos probable que los perros infectados se muestren clínicamente enfermos, se ha descrito un caso de neumonía fulminante con transmisión a personas. Por otra parte, podrían exponer a sus dueños al transportar pulgas de roedores a los hogares, especialmente si estos los dejan dormir en sus camas. Las infecciones en laboratorios, antiguamente más comunes, son infrecuentes con los protocolos modernos. No obstante, en 2009 un investigador estadounidense murió de una sepsis causada por una cepa atenuada de "Y. pestis" que carecía de los genes necesarios para la absorción de hierro. Los estudios "post mortem" determinaron que padecía de una hemocromatosis no diagnosticada.

Las pulgas se infectan al alimentarse de la sangre de un huésped con bacteriemia. En el interior de este animal, de temperatura más fría que un mamífero, la bacteria expresa una variedad de factores que facilitan la reproducción, colonización y obstrucción del intestino medio. Las pulgas bloqueadas, privadas de sustento, se alimentan agresivamente, regurgitando bacterias en la picadura. Muchos de los bacilos inoculados son fagocitados por leucocitos polimorfonucleares; sin embargo, algunos son captados por células mononucleares y llevados a los ganglios linfáticos regionales. A 37 ºC, "Y. pestis" comienza a expresar el antígeno capsular (F1), lo que mejora su resistencia a la fagocitosis. En el ganglio, la bacteria estimula una respuesta inflamatoria intensa que se manifiesta clínicamente como un bubón. La observación al microscopio de este muestra un infiltrado de polimorfonucleares, necrosis hemorrágica con destrucción de la arquitectura normal y concentraciones altas de bacilos extracelulares. La bacteriemia es habitual y, si no se administra tratamiento específico, puede darse neumonía secundaria, coagulación intravascular diseminada, insuficiencia renal aguda y hasta un choque irreversible. El bloqueo de los vasos sanguíneos en las partes acras, más frías, que incluyen dedos, orejas y nariz, puede evolucionar a gangrena, un síntoma alarmante que podría ser el origen del término «peste negra». La patogenia de la peste neumónica se caracteriza por una fase proinflamatoria veloz y destructiva que resulta en una muerte rápida.

La peste adopta varias formas clínicas que dependen en parte de la forma de exposición al patógeno. En los Estados Unidos, del 80 % al 85 % de los enfermos presentan peste bubónica primaria, el 15 %, peste septicémica y entre el 1 % y el 3 %, peste neumónica u otras formas. El período de incubación suele durar entre dos y siete días, pero en la peste neumónica primaria puede llegar a ser de un solo día.

La peste bubónica resulta de la exposición cutánea a la bacteria y se caracteriza por la aparición repentina de fiebre alta, escalofríos, fatiga y cefalea. Durante el primer día tras el establecimiento de los síntomas, aparece un bubón en la ingle, axila o cuello. Miden entre 1 y 10 cm y elevan la piel circundante, que puede estar caliente y eritematosa. El enfermo es, asimismo, muy sensible a la palpación de la zona afectada. La peste bubónica se distingue de otras formas de linfadenitis por su aparición súbita, la intensidad de la inflamación del bubón y la ausencia habitual de lesiones cutáneas manifiestas o linfangitis ascendente asociada. Sin embargo, la observación cuidadosa distal al bubón puede descubrir una pápula o costra pequeña en el lugar de la picadura de la pulga. Menos frecuentemente, pueden aparecer escaras o úlceras que pueden confundirse con las del carbunco o la tularemia. El diagnóstico diferencial incluye la enfermedad por arañazo de gato, linfadenitis por estafilococos o estreptococos, tularemia, filariasis, hernia estrangulada, chancroide y otras enfermedades de transmisión sexual.

La peste septicémica se caracteriza por la rápida aparición de fiebre alta sin que haya un bubón u otros signos locales asociados. La enfermedad progresa rápidamente y evoluciona a la sepsis y el fallo multiorgánico en pocos días. No se suele considerar el diagnóstico hasta que se aísla "Y. pestis" de los hemocultivos. A veces, se dan síntomas gastrointestinales como náuseas, vómitos, diarrea o dolor abdominal que pueden complicar aún más la identificación de la causa. Debido a los retrasos en el diagnóstico y tratamiento, la tasa de mortalidad en los Estados Unidos es del 28 %, tres veces más que para la peste bubónica.

La peste neumónica tiene dos formas, primaria y secundaria, frecuentemente mortales y potencialmente contagiosas para los contactos cercanos. Es más común la secundaria, causada por la diseminación hematógena de la bacteria desde el bubón u otra fuente. Aproximadamente el 10 % de los enfermos de peste en los Estados Unidos desarrollan peste neumónica secundaria, habitualmente por el retraso en el tratamiento de la forma bubónica. Comienza como un proceso intersticial con tos productiva y esputo escaso, que normalmente comienza cinco o seis días después de los primeros síntomas. La radiografía de tórax revela infiltrados alveolares difusos casi siempre bilaterales y acompañados de derrame pleural. Sin tratamiento, el esputo se vuelve más copioso y, finalmente, sanguinolento; la muerte ocurre frecuentemente a los tres o cuatro días.

La forma primaria de la peste neumónica es un cuadro fulminante que resulta de la inhalación directa de la bacteria en los pulmones. Puede ocurrir al haber estado en contacto con otra persona con peste neumónica, exposición a animales con peste respiratoria o faríngea (especialmente gatos), infección en el laboratorio o, potencialmente, consecuencia de la liberación intencional de aerosoles con propósitos terroristas. Los síntomas comienzan entre uno y cuatro días después de la exposición; se instauran velozmente e incluyen fiebre, escalofríos, cefalea, malestar, signos generales de endotoxemia, taquipnea, disnea, hipoxia, dolor torácico, tos y hemoptisis. La radiografía de tórax muestra al principio una neumonía lobar que evoluciona a una consolidación densa y diseminación broncopulmonar a otros lóbulos del pulmón ipsilateral o contralateral. Normalmente, el esputo es purulento, aunque también puede ser acuoso, espumoso y copioso; asimismo, es posible que presente algo de sangre o que sea francamente hemorrágico, en cuyo caso podría contener grandes cantidades de bacilos. En cuanto a la histología, el espacio alveolar se muestra lleno de bacterias y células inflamatorias. La enfermedad casi siempre es letal sin tratamiento y la mortalidad es también alta cuando este se demora más de 24 horas tras el comienzo de los síntomas. Más o menos, el 25 % de los afectados por peste neumónica en los Estados Unidos desde 1950 han fallecido.

Para prevenir la transmisión de persona a persona, los pacientes sospechosos deben mantenerse en aislamiento. Debido a que el contagio requiere de un contacto estrecho, que típicamente ocurre cuando el enfermo está en un estadio avanzado de la enfermedad en el que tose grandes cantidades de esputo sanguinolento, no es necesario que el aislamiento deba hacerse bajo presión negativa y con filtros (no hay transmisión por aerosoles finos). El último brote confirmado con propagación entre personas en Estados Unidos ocurrió en Los Ángeles (California) en 1924 y desde entonces ha habido al menos nueve casos de peste neumónica primaria sin transmisión secundaria. Sin embargo, en 2014, tres personas desarrollaron peste neumónica primaria después de haber estado en contacto en un perro infectado. Aunque no pudo probarse, uno de los enfermos pudo haberse contagiado cuidando a un familiar afectado en el hospital.

La peste meníngea es una complicación rara que puede ocurrir de forma aguda o como una manifestación tardía de una peste bubónica tratada inadecuadamente. Los síntomas incluyen fiebre, dolor de cabeza, cambios sensoriales y meningismo. El líquido cefalorraquídeo (LCR) muestra pleocitosis con predominio de polimorfonucleares. Frecuentemente, también se observan bacterias al teñir el LCR con Gram o Wayson. Otra forma poco habitual es la peste faríngea, que se parece a la amigdalitis aguda. Los ganglios linfáticos cervicales anteriores suelen estar inflamados y se puede aislar "Y. pestis" de un cultivo de muestra faríngea o de la aspiración de un bubón cervical. La bacteria también puede colonizar la garganta sin producir síntomas en personas cercanas a enfermos de peste neumónica. Además, también se ha descrito un caso de osteomielitis que afectó al cráneo y los huesos largos.

Los hallazgos de laboratorio en personas con la peste son parecidos a los de otras infecciones graves por gramnegativos. Los leucocitos en sangre periférica están generalmente en el rango de los 10 000 a 25 000 células/mm³, con predominio de neutrófilos inmaduros. Pueden ocurrir reacciones leucemoides que eleven el recuento a las 50 000 células/mm³ o más. Las plaquetas pueden estar normales o bajas en los primeros estadios de la peste bubónica. La bacteriemia es común, el 27 % de los hemocultivos realizados al ingreso hospitalario fueron positivos en una serie de casos. Cuando no se trata de forma temprana, la bacteriemia se hace tan elevada que se observan bacilos teñidos bipolarmente en los frotis de sangre periférica, un hallazgo que apoya fuertemente el diagnóstico de peste y se asocia con un pronóstico desfavorable. Conforme la enfermedad avanza, puede aparecer coagulación intravascular diseminada, trombopenia, enzimas hepáticas elevadas y deterioro en la función renal.

Debería sospecharse el diagnóstico de peste en cualquier persona en una zona endémica con fiebre aguda y posible exposición a animales infectados o pulgas. Una medicina y exploración física adecuada es fundamental para dar un juicio clínico a tiempo; los retrasos y errores se asocian con mayor mortalidad. Es recomendable la toma temprana de muestras y el inicio del tratamiento antimicrobiano inmediatamente después. También debería tomarse una radiografía de tórax para descartar la neumonía. Las muestras biológicas a obtener dependerán de los signos y síntomas, destacan el hemocultivo, aspirado del bubón, esputo, lavado broncoalveolar, torunda de lesiones cutáneas o mucosa faríngea y el líquido cefalorraquídeo.

A las muestras se les puede hacer las tinciones de Gram, Giemsa o Wayson y ser examinadas al microscopio óptico. En el caso de la peste neumónica, la tinción y el cultivo del lavado bronquial o el esputo pueden llevar a un diagnóstico de presunción rápido. En la tinción de Wayson, "Y. pestis" aparece como un bacilo azul claro con cuerpos polares más oscuros con apariencia similar a un imperdible, algo característico de esta bacteria, pero no patognomónico. Si fuera posible, también debería usarse la inmunofluorescencia directa. Además, "Y. pestis" puede identificarse usando la reacción en cadena de la polimerasa (PCR).

En el laboratorio, el método de confirmación del diagnóstico preferido es el aislamiento de "Y. pestis" de tejidos o fluidos corporales. El cultivo, que debe conservarse entre cinco y siete días, es más adecuado en medios como el agar infusión de cerebro-corazón, agar sangre, agar chocolate o agar MacConkey. La bacteria se puede distinguir de otras por sus propiedades de tinción, características de crecimiento y el perfil bioquímico. Sin embargo, los sistemas automáticos fallan frecuentemente al identificar "Y. pestis" como otra especie, lo cual retrasa el diagnóstico. En los laboratorios de referencia, la confirmación se hace usando un bacteriófago específico de "Y. pestis".

En los pacientes con cultivos negativos, se puede corroborar la enfermedad con serología mediante la detección de anticuerpos contra el antígeno F1 por hemaglutinación pasiva. El test se considera positivo cuando el título de anticuerpos se cuadruplica en dos muestras de suero tomadas con tres o cuatro semanas de diferencia o cuando este es mayor que 1:128 en una persona no vacunada con síntomas compatibles. La seroconversión se produce habitualmente una semana o dos después del comienzo de la enfermedad, aunque algunas veces sucede durante la primera semana, más de tres semanas después e incluso en el 5 % de los casos no llega a haber seroconversión. Además, en 2003 se desarrolló una prueba rápida de cromatografía que puede realizarse en la cabecera del paciente.

En los casos mortales, pueden realizarse cultivos, inmunofluorescencia y estudios histológicos, incluida inmunohistoquímica en muestras de gánglios linfáticos, hígado, bazo, pulmones y médula ósea. El medio de Cary-Blair puede usarse para el transporte de torundas y tejidos para el cultivo.

Sin tratamiento, el 50 % de los enfermos de peste bubónica y casi todos los de las formas septicémica y neumónica fallecen. La antibioterapia debe iniciarse inmediatamente después de tomar muestra biológicas para el diagnóstico. Aunque las fluorquinolonas pueden ser una alternativa menos tóxica, la estreptomicina ha sido el fármaco de elección desde que se comenzó a usar en la década de 1940 y su administración temprana puede reducir la mortalidad de la peste bubónica a un 5 % o inferior. La pauta de administración de la estreptomicina es la inyección intramuscular dos veces al día de 15 mg/kg en adultos (con el máximo de 1 g) por siete días o, al menos, hasta tres días después de la remisión de la fiebre y otros síntomas. La mayor parte de los infectados mejoran rápidamente y están afebriles después de unos tres días de tratamiento. Ya que la estreptomicina es ototóxica y nefrotóxica, debe usarse con precaución en mujeres embarazadas, ancianos y personas con problemas de audición.

Basándose en estudios "in vitro", modelos animales y reportes de casos en humanos, la gentamicina se ha propuesto como una alternativa para el tratamiento de la peste, aunque esto no está aprobado por la Administración de Medicamentos y Alimentos de Estados Unidos (FDA). Un análisis retrospectivo realizado en Nuevo México entre 1985 y 1999 en 50 pacientes sugiere que la gentamicina, o la combinación de esta con doxiciclina, es al menos tan eficaz como la estreptomicina. Las 28 personas que recibieron gentamicina sobrevivieron sin sufrir complicaciones. En un ensayo clínico aleatorizado con 65 pacientes llevado a cabo en Tanzania, el 94 % de quienes recibieron gentamicina sobrevivieron. Este antibiótico se considera más seguro que la estreptomicina para su uso en niños y embarazadas.

En los enfermos con contraindicaciones para el uso de aminoglucósidos, las tetraciclinas son alternativas satisfactorias. La doxiciclina es el antibiótico de elección de este grupo para el tratamiento de la peste por la conveniencia de su administración, dos veces al día; la absorción rápida en el intestino delgado, y su capacidad superior para alcanzar concentraciones máximas en suero. El tratamiento debería iniciarse con una dosis de carga, oral o intravenosa dependiendo de la gravedad del cuadro; en adultos, 200 mg cada 12 horas el primer día de tratamiento permite alcanzar rápidamente una concentración en el plasma de 8 μm/mL (después se reduce la dosis a la mitad). La tetraciclina se suministra en adultos con una dosis de carga inicial de 2 g seguidos de la pauta normal de 2 g al día repartidos en cuatro tomas. Tanto la tetraciclina como la doxiciclina se pueden usar para completar una pauta terapéutica que comenzó con un aminoglucósido. Cuando se usan como fármaco principal, las tetraciclinas deben darse por entre siete y diez días o al menos hasta tres días después del fin de la fiebre y los demás síntomas.

El levofloxacino, el ciprofloxacino y el moxifloxacino están aprobados por la FDA para el tratamiento de la peste basándose en estudios de eficacia "in vitro" y en modelos animales, entre ellos el mono verde ("Chlorocebus sabaeus"). De todas formas, la información publicada sobre un posible tratamiento eficaz en la peste humana es limitada. En una pequeña serie de casos de Uganda seis pacientes de peste confirmada mediante cultivo, incluido uno con la forma neumónica secundaria, fueron tratados exitosamente con ciprofloxacino oral. Basándose en las indicaciones de la FDA y en las propiedades farmacocinéticas, debería usarse levofloxacino o cloranfenicol cuando sea importante lograr una concentración alta en los tejidos, como puede ocurrir en la peste meníngea, la pleuritis o la miocarditis. Pueden emplearse en monoterapia o en combinación con un aminoglucósido. El cloranfenicol se administra en una dosis de carga de 25-30 mg/kg seguida de la administración diaria de 50-60 mg/kg, dividida en cuatro dosis. Dependiendo de la respuesta del enfermo, puede reducirse a 25-30 mg/kg/día para minimizar el impacto de la supresión de la médula ósea, que es reversible. La aplasia medular asociada al consumo de cloranfenicol es tan infrecuente (se estima que ocurre en uno de cada 40 000 pacientes) que no debería ser un impedimento para su uso en personas enfermas gravemente de peste. El trimetoprim-sulfametoxazol (también conocido como cotrimoxazol) también se ha empleado en el tratamiento, aunque la respuesta puede ser tardía e incompleta, por lo que no se considera un agente de primera línea. No se recomienda la administración de penicilinas, cefalosporinas y macrólidos por su efecto escaso.

El aislamiento de cepas de "Y. pestis" resistentes a antibióticos es poco frecuente. Usualmente, estas solo lo son a un solo fármaco y no se han asociado con fracaso terapéutico. En 1995, se encontraron ejemplares con resistencias mediadas por plásmidos en dos muestras clínicas obtenidas en Madagascar, una era muy poco sensible a la estreptomicina y la otra, al cloranfenicol, ampicilina, tetraciclina, sulfonamidas y también a la estreptomicina. Sin embargo, ambos pacientes fueron tratados con un régimen de estreptomicina y cotrimoxazol y se recuperaron. Los estudios moleculares indicaron que los plásmidos de estas dos cepas eran muy diferentes entre sí y se piensa que surgieron de forma independiente, posiblemente por transferencia genética horizontal en el intestino de una pulga. No está claro si esta resistencia podría transferirse en la naturaleza en ausencia de consumo de antibióticos por las poblaciones salvajes de roedores y, hasta la fecha, estos han sido los únicos aislamientos de cepas resistentes de entre las miles de muestras clínicas recuperadas. No se conoce que hayan aparecido resistencias durante el tratamiento de la peste en humanos y no se han descrito recaídas tras haber seguido las pautas recomendadas de tratamiento.

Se debería monitorizar cuidadosamente el estado hemodinámico de los enfermos de peste y seguirse los protocolos para tratar el choque endotóxico en caso de que ocurriera. No hay evidencia de que los corticoides sean efectivos en el tratamiento. Los bubones suelen rebajarse durante la primera semana de tratamiento antibiótico, pero tardan varias más en desaparecer por completo; ocasionalmente, pueden agrandarse o volverse fluctuantes al tacto, lo que requeriría la realización de un drenaje.

Todos los casos sospechosos de peste deberían notificarse inmediatamente a la autoridad sanitaria competente para su asistencia en la confirmación del diagnóstico microbiológico, investigación epidemiológica y protección de la salud pública. Los afectados con infecciones no complicadas y que reciben un tratamiento temprano no suponen un peligro para otras personas. Aquellos con tos u otros signos de neumonía deberían ser puestos en aislamiento y atendidos con el material necesario para prevenir la transmisión por microgotas hasta que hayan pasado 48 horas desde el comienzo del tratamiento o hasta que el cultivo de esputo sea negativo. Cuando se esté en contacto directo con estas personas, los elementos de prevención incluyen mascarillas, guantes, bata y gafas protectoras. Los cultivos obtenidos del material clínico suelen ser negativos 24 horas después de haber comenzado el tratamiento. Los pacientes sin peste neumónica pueden ser atendidos con las precauciones estándar. Los fluidos potencialmente infecciosos deberían manipularse con guantes y previniendo la aerosolización, que puede ocurrir al dejar caer una muestra o al romperse su recipiente durante la centrifugación. Los especímenes de rutina pueden examinarse en un laboratorio con nivel de bioseguridad 2 (BSL-2), pero los cultivos deben ser manejados en una campana de presión negativa en un laboratorio de nivel de bioseguridad 3 (BSL-3).

Se pueden usar antibióticos para la quimioprofilaxis en personas que hayan podido estar expuestas al patógeno en los últimos siete días como familiares, cuidadores, otros individuos que hayan estado en contacto estrecho con un enfermo de peste neumónica o trabajadores de un laboratorio que hayan estado expuestos en un accidente en el que se haya podido generar un aerosol. La doxiciclina, cuya dosis en adultos es de 100 mg dos veces al día durante una semana, o el ciprofloxacino, 500 mg dos veces al día también durante una semana, son fármacos adecuados para este propósito.

Históricamente, dos vacunas han estado disponibles para uso humano, una inactivada y otra atenuada. A fecha de 2020, ninguna tenía licencia en los Estados Unidos, pero la segunda sí en Rusia. La vacuna inactivada no es efectiva en casos de exposición respiratoria y no tiene utilidad comparada con las medidas modernas de higiene y la quimioprofilaxis. No obstante, la preocupación por el bioterrismo y posibilidad de creación de cepas multirresistentes por ingeniería genética ha mantenido el interés por el desarrollo de nuevas vacunas. Estas candidatas se han producido a partir del antígeno F1 recombinante y el antígeno LcrV, ya sea como una mezcla o una fusión de estos. Ambos tipos de vacuna han mostrado resultados prometedores en modelos animales y se han evaluado en ensayos farmacológicos de fases I y II. Otros enfoques modernos son las vacunas de ADN; la expresión de antígenos protectores en bacterias, virus o plantas portadoras; la inmunización pasiva con anticuerpos monoclonales aerosolizados, y vacunas atenuadas basadas en "Y. pseudotuberculosis".

Entre las precauciones que pueden tomar las personas que viven en zonas endémicas para reducir su exposición a roedores y pulgas está la adecuación de los hogares, la retirada de comida, evitar que haya lugares donde los roedores se puedan cobijar, el uso de repelentes y aplicar insecticidas en las mascotas. Si se va a proceder al exterminio de roedores, debe fumigarse también contra las pulgas antes o durante la operación para evitar que estas se alimenten de humanos.

"Yersinia pestis" es un agente de clase I para los CDC de Estados Unidos, lo que refleja su potencial para usarse como un arma biológica. Este microorganismo se encuentra en el medio natural de muchas partes del mundo, es fácilmente manipulable en el laboratorio, incluso para la introducción de resistencias a antibióticos, y se ha usado y desarrollado en el pasado con propósitos bioterroristas. Además, su historia tiene un impacto cultural que amplifica su efecto para causar alarma social más allá de su impacto médico directo.

La liberación deliberada de "Y. pestis" se puede conseguir a través de varias rutas; sin embargo, la aerosolización se considera la más letal de todas y, por tanto, la más probable. La exposición al patógeno de esta forma causaría un brote de peste neumónica primaria, que es rápidamente mortal y tiene potencial para transmitirse entre personas. La Organización Mundial de la Salud ha estimado que la liberación de 50 kg de "Y. pestis" sobre una ciudad de cinco millones de habitantes podría generar 150 000 casos de la enfermedad y 36 000 muertes.

 

Se estima que a lo largo de la historia han muerto de peste más de 300 millones de personas, convirtiéndose así en una de las enfermedades infecciosas más letales. En términos generales se considera que han existido tres grandes pandemias de la enfermedad: la plaga de Justiniano que se desarrolló entre los siglos VI y VIII; la segunda pandemia que se ha llamado la peste negra produjo sucesivos brotes en Europa entre los siglos XIV y XVIII; y la tercera pandemia de peste, que surgió en China durante el siglo XIX.




A partir de la tercera década del siglo XX se produjo una disminución importante en la incidencia y gravedad de la enfermedad, debido a una mejor higiene, el aumento en la inmunidad de las ratas y los seres humanos, el desarrollo de los antibióticos, etc. A pesar de ello siguen existiendo focos enzoóticos en Asia, África y América. En el año 2003, se registraron a nivel mundial más de 2000 casos y alrededor de 180 muertes, la mayor parte en África. Otros países con casos declarados en el siglo XXI son: Estados Unidos, China, India, Vietnam y Mongolia. En 2017 se produjo un brote en Madagascar que provocó al menos 1200 casos y más de 100 fallecimientos.

A lo largo del tiempo numerosos escritores han hecho referencia a la peste. 

La Iliada de Homero empieza con los soldados confinados por la peste en un campamento ante las murallas de Troya.Tucídides habla de ella en "Las guerras del Peloponeso", siglo V a.C. 

Giovanni Boccaccio en el Decamerón inicia sus relatos con una descripción de la peste bubónica (la epidemia de peste negra que golpeó a Florencia en 1348), lo que justifica que un grupo de diez jóvenes (siete mujeres y tres hombres) que huyen de la plaga, se refugien en una villa en las afueras de Florencia. Boccacio pone en voz de un testigo de la peste: "Cuando todas las tumbas estuvieron llenas, fueron excavadas grandes zanjas en los cementerios de las iglesias, en las cuales las nuevas llegadas fueron colocadas por centenares, almacenadas grada sobre grada, como cargamento naval".
Daniel Defoe publicó en 1722 el "Diario del año de la peste", una novela sobre la peste de 1665 en Londres. José María Blanco White escribió sobre la peste de Sevilla en sus "Cartas desde España". También se habla de la peste en "El último hombre" de Mary Shelley (1826) y en "La peste escarlata" de Jack London (1912). Albert Camus nos retrata en la novela publicada en 1947, "La peste", el confinamiento de Orán. José Saramago nos habla de la peste en "Ensayo sobre la ceguera" (1995).




</doc>
<doc id="41946" url="https://es.wikipedia.org/wiki?curid=41946" title="Senado de Chile">
Senado de Chile

El Senado de la República de Chile es la cámara alta del poder legislativo de Chile, y junto a la Cámara de Diputadas y Diputados conforman las dos cámaras del Congreso Nacional. Su composición y atribuciones están establecidas en el capítulo V de la Constitución Política de Chile. Cada senador representa los intereses de su circunscripción, que son elegidos por votación popular. 

Los senadores duran 8 años en su cargo, pudiendo ser reelegido indefinidamente. Sin embargo, las elecciones se realizan cada cuatro años de manera alternada por regiones. En una elección se renuevan los que representan a las regiones de Tarapacá, Atacama, Valparaíso, Maule, La Araucanía, Aysén y Arica y Parinacota. Cuatro años después corresponde la elección de los senadores de las regiones de Antofagasta, Coquimbo, O’Higgins, Bío Bío, Los Lagos, Magallanes, Los Ríos, Ñuble y Región Metropolitana. De esta manera la cámara se renueva alternadamente cada 4 años. 

Sus funciones son participar en la elaboración de las leyes con la Cámara de Diputados y al Presidente de la República. Desde el 17 de marzo de 2020, la presidenta del Senado de Chile es la senadora Adriana Muñoz D'Albora.

El primer precedente de la existencia de un Senado en Chile data del periodo denominado Patria Vieja, durante el Gobierno de José Miguel Carrera. Este primer senado estaba compuesto, no por senadores sino por diputados. Eran 10 de los cuales existían propietarios y suplentes. Estos se elegían mediante suscripción.

Este Senado fue incorporado en el Reglamento Constitucional Provisorio de 1812, que se promulgó el 27 de octubre de 1812. Entre otras cosas se establecía que:
Entre finales de octubre y principios de noviembre de 1812 se iniciaron las suscripciones de los siete diputados propietarios que participarían en el senado. De estos, tres eran de Santiago de Chile, dos de la Provincia de Coquimbo y dos de la Provincia de Valparaíso. Los tres restantes que se adhirieron al primer hemiciclo senatorial fueron suplentes, completando un total de 10 diputados senatoriales.

La Inauguración del Primer Senado de Chile sucedió el 10 de noviembre de 1812, siendo su primer presidente el doctor Pedro Vivar y Azúa. Continuó en funciones hasta enero de 1814, ya en plena Guerra de la Independencia de Chile, y gracias a su acuerdo con el poder ejecutivo se sancionó la ley de Libertad de prensa y se crearon el Instituto Nacional y la primera Biblioteca Nacional. Asimismo otorgó a don José Miguel Carrera plenos poderes para dirigir las operaciones militares.

La Crisis Política surgida gracias a la Guerra de Independencia de Chile urgió a la necesidad de proclamar el nuevo Reglamento para el Gobierno Provisorio de 1814: Este redujo las facultades legislativas que antes poseía el senado y lo transformó en un órgano consultivo, similar a un Consejo de Estado.

En estricto rigor, este fue el primer senado donde sus miembros eran llamados "Senadores". Se Mantuvo la cantidad de Propietarios, que eran 7, pero se abolió la existencia de miembros suplentes. Además de esto, el nuevo Reglamento estableció que era el Director supremo de Chile quién designaba a los 7 senadores de entre una lista de 21 candidatos.

El 17 de marzo de 1814 nació el Senado Consultivo, compuesto también por 7 notables patriotas. Pero la guerra les impidió ejercer un buen desempeño legislativo. De este modo, tras el Desastre de Rancagua acontecido el 1 y 2 de octubre de 1814, comenzó el período de la Reconquista española que duró hasta 1817. En ese lapso no existió Senado ni Congreso alguno en Chile.

En 1818 se dio inicio al proceso llamado Patria Nueva. Durante el Gobierno de Bernardo O'Higgins se reinauguró el senado conforme a la Constitución de 1818 que establecía: De esta manera se estableció el senado como un órgano legislativo provisional, el que sin embargo, legisló hasta 1822.

Aunque el régimen o'higginista tuvo una marcada predominancia del Director Supremo de Chile, el Senado Conservador de la Patria Nueva tuvo una relevante participación en el reconocimiento internacional de la Independencia de Chile, como trató de lograrse en una convención realizada en la ciudad de Aquisgrán, entonces Francia. Se repuso la existencia de miembros suplentes, que eran 5, y se estableció una misma cantidad de "Senadores Propietarios". De esta manera había un total de 10 senadores. Todos eran designados por el Director Supremo.

En 1822 surgieron amplias críticas a la composición del Senado, debido principalmente, a que este se había erigido en plena Guerra de Independencia y mantuvo su estructura original sin proceder a la erección de los ""Diputados reunidos en Congreso"" que según la Constitución de 1818 era el organismo permanente de legislación. Esta necesidad desencadenó en la Constitución Política del Estado de Chile de 1822 que pretendía transformar al Senado en una rama de un Congreso Bicameral. La Convención Preparatoria tenía designada la tarea de conseguir la elección de diputados y senadores. sin embargo la estructura enmendada por la Constitución de 1822 nunca logró concretarse.

El "Senado Conservador y Legislador de 1823" o "Cuarto Senado" se estableció bajo la Constitución de 1823, y fue el segundo senado compuesto de miembros elegidos por el pueblo desde 1812. Se componía de nueve senadores elegidos en una única circunscripción nacional para un mandato de seis años, pudiendo reelegirse indefinidamente. Para ser senador, era necesario ser mayor de 30 años de edad, tener una propiedad no menor a cinco mil pesos, residencia los últimos tres años en el país y ser un ciudadano elegible.

A este senado se le transfirió el monopolio del poder legislativo, siendo parte de un parlamento asimétrico, donde la Cámara Nacional (cámara baja), carecía de predominancia en los procesos de formación de leyes. También se le confirió al senado la ratificación de los tratados internacionales, además de las leyes sobre impuestos y contribuciones. Como uno de los poderes más notables del Cuarto Senado, estaba la facultad de suspender de sus funciones al Director Supremo, lo que otorgó por vez primera una vía de control al poder ejecutivo.

El presidente del Senado bajo esta institucionalidad debía ser elegido directamente por el pueblo de entre los senadores elegidos.

Este senado vio sin embargo interrumpida sus funciones, debido a la alta volatibilidad en la contingencia política, ya a finales de 1823 se generó un nuevo Congreso Constituyente, que habiendo fracasado provocó el retorno del cuarto senado en 1824. Siguió ejerciendo la legislación hasta su disolución definitiva ese mismo año, siendo remplazado por el "Congreso General de la Nación" similar a una cámara baja unicameral.

Recién desde 1828 en adelante, el Senado se concibió como la rama de un Congreso bicameral.

Conforme a la Constitución Política de 1828 la Cámara de Senadores estaba compuesta por representantes de las Asambleas Provinciales, a razón de 2 senadores por provincia (16 en total), por 4 años, debido a esto se le denomina el "senado provincialista". La elección de los senadores se realizaba en las sesiones de cada Asamblea Provincial, y resultaban elegidos los dos con mayor cantidad de votos dentro de la pluralidad que cada bancada de asambleístas presentaba. Con este sistema, hubo un estrecho nexo entre el Senado y los gobiernos provinciales, que hacían representar sus intereses en esta cámara. La dificultad, sin embargo de constitución de estos parlamentos provinciales dificultó la elección de los senadores, variando su composición.

En cuanto a sus facultades, el Senado entre 1828 y 1833 carecía de facultades exclusivas con excepción de la emitir juicios políticos despachados por los diputados. En este sentido, la Cámara de Diputados obtuvo la predominancia legislativa y política, tanto por la elección indirecta de los senadores como por sus escasas atribuciones.

La Constitución Política de 1833 dispuso que el Senado estaría compuesto por 20 miembros que formaban parte de una lista nacional, los cuales serían elegidos indirectamente (mediante un sistema de electores) por un periodo de 9 años y podrían reelegirse indefinidamente. En cada provincia se elegían electores a razón de 3 por diputado.

Las reformas de 1874 permitieron que la elección fuese por votación directa y en representación de las provincias. Cada provincia pasaba a elegir un 1 senador por cada 3 diputados y fracción de 2. Además se rebajaba el periodo a 6 años reelegibles indefinidamente.

Con la Constitución Política de 1925, el Senado pasó a ser electo directamente por las 9 (1925) y posteriormente 10 (1967) agrupaciones provinciales por un periodo de 8 años, reelegibles indefinidamente. Cada agrupación provincial elegía 5 senadores. Cada 4 años se renovaba por mitades.

En el régimen político imperante bajo la Constitución Política de 1980, para analizar la composición del Senado hay que distinguir:

Las concepciones que tenían sobre la democracia los redactores de la Constitución condujeron a consagrar un sistema particular, susceptible de evitar los supuestos excesos del sufragio universal. El Senado quedaría compuesto no solo por los elegidos del pueblo (dos por cada región, 26 en total), sino también a modo de una cámara de sabios por ciertas autoridades, algunas designadas (por otras), otras que gozarían del cargo por derecho propio: senadores designados y senadores vitalicios, respectivamente.

Los "Senadores Designados" serían nueve senadores no electos por la nación, sino por diversas autoridades. Se designaban cada 8 años y, en caso de vacancia del escaño, fuere por muerte, por incapacidad o inhabilidad, este no era reemplazado, hasta el fin del periodo de ocho años que le correspondía.

Los "senadores vitalicios" serían senadores por derecho propio. Los expresidentes de la República que hubieren ejercido su cargo por el mandato constitucional completo tendrían por derecho propio el cargo de senador. Este tendría, además, la particularidad de ser un puesto vitalicio.

Originalmente había trece circunscripciones, correspondientes a las trece regiones del país; pero las reformas constitucionales aprobadas en 1989 permitieron dividir seis regiones en dos circunscripciones cada una (las regiones más pobladas), reforzando la institucionalidad democrática del Senado, al permitir un mayor número de senadores electos (pasando de 26 a 38), ya que se mantuvo la figura de los senadores designados y vitalicios.

El Senado durante este periodo llegó a estar compuesto por 38 senadores electos, 9 designados y 2 vitalicios. En total, 47 senadores (desde 1990 a 1998); 48 (1998 a 2000); 49 (2000 a 2002); y 48 (2002 a 2006).

Si bien algunos senadores designados poseyeron verdaderamente cierta "auctoritas", pero no siempre fue así. Como la expresión "senadores designados" pareció un tanto peyorativa, estos se dieron en llamar "senadores institucionales". Su número fue suficientemente relevante para que los gobiernos que se sucedieron desde 1990 debieran transigir con ellos para alcanzar las mayorías necesarias. Si bien, en un principio, estos constituyeron una bancada paralela a la de los grupos políticos, terminaron uniéndose a las bancadas políticas con quienes tenían afinidad.

Por otro lado, sólo dos expresidentes alcanzaron a desempeñar el cargo de senador vitalicio: Augusto Pinochet (de 1998 a 2002) y Eduardo Frei Ruiz-Tagle (de 2000 a 2006). Tras el retiro de la vida pública del primero, Frei fue el último en desempeñar dicho cargo.

En caso de la vacancia en un escaño, sea por muerte, renuncia o inhabilidad en el cargo, lo reemplazaba el compañero de lista al momento de la elección, a falta de este el partido proponía tres nombres a la cámara alta, y el que sacaba más votos era elegido, los independientes y los senadores institucionales no eran reemplazados.

Durante el gobierno de Ricardo Lagos, fue promulgada una reforma constitucional, luego de haber sido aprobada casi unánimemente por el Congreso Pleno. Estas reformas, que entraron en vigor el 11 de marzo de 2006, permitieron que el Senado estuviese exclusivamente integrado por miembros electos por el pueblo, eliminando los senadores designados y vitalicios. El número de senadores fue reducido así de 48 a 38 miembros. También se consagra la designación partidaria en caso de vacancia, sea por fallecimiento, renuncia, incapacidad o inhabilidad en el cargo, en el caso de que la vacancia la provocara un parlamentario independiente, el escaño queda vacío y no es reemplazado.

Hasta el año 2017, estos 38 senadores fueron electos directamente por 8 años a razón de 2 por cada una de las 19 circunscripciones senatoriales del país. Dicha forma de elección terminó con la reforma al sistema electoral, aprobada durante el segundo gobierno de la presidenta Michelle Bachelet.

A partir de la Reforma Constitucional de 2015, se estableció la elección de 50 senadores distribuidos en 15 circunscripciones. En la elección parlamentaria de 2017 se eligieron 23 senadores correspondientes a las circunscripciones I, II, IV, VI, IX, XI, XIV, mientras que en la se elegirán los restantes senadores para las circunscripciones III, V, VII, VIII, X, XII, XIII, XV y XVI, completando así la renovación total de la Cámara Alta, prevista por la reforma de 2015.

Al Senado corresponde, naturalmente, intervenir en el proceso de formación de las leyes en Chile. Tiene, además, las atribuciones indicadas en la Constitución, que le son exclusivas (artículo 49 de la Constitución de 1980):

Para ser electo, los senadores deben tener 35 años de edad (hasta 2006 eran 40 años). Pueden ser reelectos indefinidamente. La renovación del Senado se efectúa cada 8 años. Se alternan las regiones de número impar y en el siguiente periodo las regiones pares y la Región Metropolitana de Santiago.

En caso de vacancia de un escaño por muerte, incapacidad o inhabilidad, el reemplazo debe ser definido por la mesa directiva de su partido que pertenecía el parlamentario al momento de ser elegido. En el caso de que la vacancia la provocara un parlamentario independiente, el escaño queda vacío y no es reemplazado.

Los senadores perciben una remuneración por el desempeño de su cargo, denominada dieta parlamentaria, que de acuerdo al artículo 62 de la Constitución Política de la República, equivalente a la de un Ministro de Estado, incluidas todas las asignaciones que a estos correspondan. A 2016, el monto bruto mensual de la dieta, esto es, sin considerar los descuentos legales u obligatorios —impuestos e imposiciones de seguridad social—, asciende a CLP$ 9 121 806.

Por concepto de asignaciones, los senadores reciben $9 380 000; además cuentan con una asignación de $1 200 000 para transporte terrestre, 48 pasajes de avión de ida y vuelta al año para viajar a sus regiones, más otros 6 pasajes para todos los destinos nacionales. También disponen de $1 298 000 mensuales para bencina, peajes y reparación de los vehículos. Los senadores de las regiones de la zona centro del país, vale decir Valparaíso, O'Higgins, Maule y Metropolitana no disponen de pasajes para sus zonas, pero tienen 12 pasajes anuales para todos los destinos nacionales extendibles a otras personas, y un bono extra de $365 000 para combustible. Los senadores de la circunscripción de Valparaíso Costa tienen adicionalmente 4 pasajes anuales a Isla de Pascua.

La cámara alta cubre los gastos de secretarias personales para los senadores, el arriendo de oficinas en sus respectivas circunscripciones senatoriales, dos computadores de escritorio y uno portátil en comodato hasta el término de su período, y artículos de oficina. Estos gastos no debe superar los $6 564 892 mensuales. Para la contratación de asesores se les asignan $3 030 928 mensuales.

El Instituto Nacional de Deportes les da a los senadores una credencial para asistir gratis a los partidos del torneo nacional en el Estadio Nacional, con un acompañante. La ANFP les otorga un descuento de aproximadamente el 40 % para tres partidos internacionales. Los senadores disponen, asimismo, de estacionamientos gratis en el sector Anita Lizana del estadio.

El 11 de abril de 2012, fue aprobado el aumento de sus asignaciones en dos millones de pesos a partir del mes de mayo del mismo mayo. La polémica iniciativa fue solicitada por la ex mesa del Senado liderada por Guido Girardi, y la medida fue calificada públicamente por el diputado René Saffirio como una «provocación a la ciudadanía»; al día siguiente, la polémica aumentó al darse a conocer que la remuneración de los integrantes de la comisión de asignaciones, responsables de la aprobación de éstas, percibían un sueldo superior a los 10 millones de pesos.
Estas cifras no consideran asignaciones parlamentarias. Si éstas se tomasen en cuenta, algunas de las cifras totales de la tabla se verían aumentadas. Por ejemplo, para el caso de Chile, los ingresos de los senadores aumentarían a más del doble.

El Senado de Chile se constituye actualmente por 43 senadores.

Según la encuesta Adimark, durante todo el primer Gobierno de Sebastián Piñera, desde marzo de 2010 hasta la fecha, el Senado de Chile jamás ha contado con una aprobación ciudadana superior al 50 %. Por el contrario, su porcentaje de aprobación ha seguido una tendencia en general decreciente, alcanzando en abril, julio y agosto de 2012, así como en agosto y septiembre de 2013, un mínimo de 17 %. La baja del mes de abril coincidió con la aprobación del aumento que hicieron los senadores de sus asignaciones en dos millones de pesos. El porcentaje de reprobación, por su parte, ha seguido una tendencia en general creciente, que en agosto de 2012 alcanzó un máximo de 77 %.




</doc>
<doc id="41952" url="https://es.wikipedia.org/wiki?curid=41952" title="Acuerdo de Viernes Santo">
Acuerdo de Viernes Santo

El Acuerdo de Viernes Santo (en inglés: «Good Friday Agreement»), también llamado Acuerdo de Belfast, fue firmado en Belfast, Irlanda del Norte, el Viernes Santo de 1998 (10 de abril) por los gobiernos británico e irlandés y aceptado por la mayoría de los partidos políticos norirlandeses, para poner fin al Conflicto de Irlanda del Norte. También fue aprobado por el pueblo de Irlanda del Norte y la República de Irlanda mediante un referéndum en cada lugar.

En el proceso de negociación previo al acuerdo, y en la firma del mismo, fueron protagonistas los políticos y mediadores:


En mayo de 1998 se celebraron referenda por separado concernientes al Acuerdo de Belfast. El que se celebró en Irlanda del Norte se refería exclusivamente al Acuerdo, propugnando la aprobación o reprobación del mismo, mientras que la votación en la República de Irlanda se refería a la aprobación de la necesaria reforma para adecuar la Constitución irlandesa en línea con el Acuerdo. Para ello habían de reformarse los artículos 2 y 3 de dicho texto para eliminar la reclamación territorial que en ellos se hacía del Ulster.

El resultado de ambos fue una amplia mayoría en apoyo del Acuerdo, tal y como se muestra en la siguiente tabla:

Con los años, el acuerdo se ha revelado como de relativo éxito, habiendo contribuido a la paz y estabilidad en la región.

El 28 de julio de 2005, el IRA Provisional anunció el cese de la lucha armada. Oficialmente, el IRA se consideró desmantelado el 3 de septiembre de 2008, cuando su "Consejo Armado" ya no estaba operativo, según informó la Comisión Independiente de Control, añadiendo que no existía una estructura de líderes capaz de organizarse.




</doc>
<doc id="41961" url="https://es.wikipedia.org/wiki?curid=41961" title="Giardiasis">
Giardiasis

La giardiasis es una enfermedad diarreica ocasionada por "Giardia intestinalis" (conocido también como "Giardia lamblia"), parásito microscópico unicelular que vive en el intestino delgado de las personas en su porción anterior (duodeno) y se transmite en las heces de una persona o animal infectado. Este parásito está protegido por una cobertura exterior que le permite sobrevivir fuera del cuerpo y en el medio ambiente por largos períodos.

Durante las dos últimas décadas, "Giardia" se ha reconocido como una de las causas más comunes de la enfermedad transmitida por el agua (de beber y recreativa) en los humanos en los Estados Unidos; otras formas de contaminación son: comer frutas y verduras no lavadas de forma adecuada o que fueron cultivadas usando fertilizante contaminado, tener contacto con personas que no se lavan bien las manos o con cubiertos de personas infectadas ya que el cloro no inactiva al parásito. El parásito se encuentra en todas las regiones del mundo.

Es una parasitosis cosmopolita y predominante en niños, quienes por lo general son sintomáticos y, en casos crónicos, causa mala absorción y desnutrición. Los casos asintomáticos suelen darse en adultos.

Gran parte de los portadores son asintomáticos. En los pacientes en los cuales se producen síntomas, aparece una diarrea repentina de característica forma pastosa o líquida, amarilla, maloliente, con moco y acompañada por cólicos y malestar general. En la fase subaguda, la diarrea tiende a ser intermitente, en particular después de las comidas. 
Suele haber dolor abdominal, náuseas (deseos de vomitar), anorexia (pérdida de apetito), flatulencia (gases), meteorismo, aerogastria y pérdida de peso. Se han descrito otros síntomas relacionados con mecanismos de hipersensibilidad como rash, urticaria, habones. En niños con giardiasis crónica se percibe retraso en el crecimiento y síndrome de malabsorción con pérdida considerable de peso.

Ante la presencia de síntomas característicos y elementos epidemiológicos conclusivos, se suele hacer un examen de heces para poder observar los quistes ovoides de doble membrana bajo el microscopio, aunque éstos son visibles solo en aproximadamente el 50 % de los pacientes infectados, de lo cual se deduce que un examen negativo no excluye la infección por giardia. La sensibilidad aumenta si estos estudios se hacen seriados. El diagnóstico específico es el coproparasitoscópico (CPS), ya sea del método Faust (por flotación) o el del Lugol. Ocasionalmente se examina el jugo duodenal y con menos frecuencia se realiza una biopsia del duodeno.
También existe una prueba inmunitaria denominada ELISA, por inmunoensayo enzimático. Estas pruebas muestran una tasa de un 90 % o más de acierto en la detección.

Para certificar el buen resultado de la medicación en la giardiasis es necesario hacer un control de las heces después de 15 a 30 días de haber concluido el tratamiento. Frente a la presencia del parásito es aconsejable repetir el tratamiento, usando un medicamento diferente.



</doc>
<doc id="41962" url="https://es.wikipedia.org/wiki?curid=41962" title="Impétigo">
Impétigo

El impétigo es una enfermedad bacteriana infecciosa superficial de la piel que se presenta con mayor frecuencia en los niños. Se clasifica en impétigo primario cuando se trata de una invasión bacteriana directa a la piel anteriormente normal, o impétigo secundario o común, cuando la infección es secundaria a otras enfermedades cutáneas subyacentes que afectan la barrera cutánea, como la sarna o el eccema. El impétigo también se clasifica como bulloso o no bulloso. El impétigo bulloso presenta ampollas.

El impétigo es una enfermedad común, en particular en los niños pequeños. Es el tercer trastorno cutáneo más común en los niños después de la dermatitis/eccema y las verrugas virales. La incidencia máxima se da entre los dos y los cinco o seis años. Su prevalencia es mayor en países tropicales y subtropicales, y durante los meses de verano en otros países.

El impétigo se asocia con una higiene deficiente y suele coexistir con la escabiosis.

Entre las bacterias asociadas con el desarrollo de diversas infecciones de la piel, las más frecuentes son el Streptococcus pyogenes y el Staphylococcus aureus.

Los estreptococos del grupo A "(streptococcus pyogenes)" son la causa de impétigo más frecuente, aunque también pueden causarlo los serotipos C y G. Las cepas que producen impétigo son diferentes de las que producen infecciones en la garganta. El patrón genotípico "emm" del "Streptococcus pyogenes" que produce impétigo suele ser D, y el que produce infecciones de la garganta suele ser AC. El patrón E puede producir ambas infecciones.

Estas bacterias habitan en la piel y en la nariz. Cuando se producen erosiones o heridas, las bacterias penetran en la piel y provocan una infección. Las áreas infectadas muestran enrojecimiento, hinchazón y vesículas o ampollas, que van llenándose de pus y se rompen con facilidad, liberando su contenido, que al secarse origina costras de color miel.

Estas bacterias se propagan mediante contacto directo con el moco de la nariz o la garganta de las personas infectadas o mediante contacto con las heridas o lesiones de la piel. Las personas enfermas, tales como las que tienen infección de garganta o infecciones cutáneas, son más susceptibles de propagar la infección. Las personas que son portadoras de las bacterias no tienen síntomas y son mucho menos contagiosas. Es poco probable que los artículos caseros, tales como los platos, tazas o juguetes propaguen estas bacterias.

El impétigo se caracteriza por la aparición de vesículas o ampollas en la piel, que al romperse originan costras de color miel (melicéricas). Se puede afectar cualquier área cutánea del cuerpo, pero las lesiones del impétigo son más frecuentes en las zonas no cubiertas por la ropa, como la cara, la zona alrededor de la boca, la nariz, los oídos, los brazos y las piernas. No dejan cicatriz, pero pueden causar trastornos de la pigmentación que llegan a persistir meses. El impétigo puede afectar a cualquier persona de cualquier edad, pero es más frecuente en niños de 2 a 5 años.

El impétigo no bulloso, comienza con una mácula o pápula enrojecida que se convierte rápidamente en una vesícula. La vesícula se rompe fácilmente por la erosión y su contenido se seca dando lugar a una costra característica coloreada como la miel ("melicérica") la cual suele producir prurito. A partir de la primera lesión puede extenderse mediante autoinoculación. El impétigo no bulloso afecta principalmente la cara y la zona expuesta de las extremidades. Aun cuando no reciba tratamiento, esta variante de la enfermedad se resuelve sin dejar cicatriz en algunas semanas.

El impétigo bulloso afecta principalmente a los bebes recién nacidos, pero también se ve en otras edades. Es producido por el "S. aureus" productor de toxinas, siendo una variante localizada del síndrome de piel escaldada. Las vesículas superficiales aumentan rápidamente de tamaño, formando bullas flácidas con márgenes bien definidos y sin eritema circundante. Cuando la bulla se rompe, quedan costras amarillas rezumantes.

Existen varias enfermedades cuya presentación clínica puede confundirse con el impétigo:


Existen las siguientes alternativas de tratamiento:

Si no se trata, el impétigo puede originar diversas complicaciones, por ejemplo nefritis.

El tratamiento de las personas infectadas con un antibiótico por 24 horas o más tiempo elimina por lo general su capacidad de propagar la bacteria. Sin embargo, es importante completar el régimen completo de antibióticos tal como se les ha recetado.

El impétigo es una enfermedad infecciosa que se transmite a otras áreas de piel sana en la misma persona y a personas diferentes. Para prevenir su contagio y aparición deben cumplirse normas básicas de higiene como:

Es causado por "Staphylococcus intermedius". Es una afección leve que suele pasar inadvertida y cura espontáneamente. Afecta a animales jóvenes, con pústulas sobre las zonas de piel desprovistas de pelo. Las lesiones son indoloras, apruríticas y se rompen con facilidad dejando un exudado de color amarillento. 
Para su tratamiento se emplean sustancias antisépticas y, en los casos más graves, antibióticos. Es importante la corrección de factores de manejo y de alimentación.




</doc>
<doc id="41963" url="https://es.wikipedia.org/wiki?curid=41963" title="Shigelosis">
Shigelosis

La shigelosis es una forma de disentería, una enfermedad infecciosa ocasionada por un grupo de bacterias Gram negativas llamadas "Shigella".

Son patógenos exclusivamente humanos.

La transmisión es fecal-oral. La presencia de shigellas en alimentos o aguas es indicativo de contaminación fecal de los mismos.

La infección se puede producir a través de alimentos, agua, objetos o moscas que estén contaminados. Las shigellas requieren un bajo inóculo de bacterias para dar lugar a la gastroenteritis infecciosa (10-200 unidades formadoras de colonias).

Puede considerarse una enfermedad de transmisión sexual al transmitirse por contacto con las heces de la persona infectada, si se produce un contacto sexual de manera oral-anal.

La mayoría de las personas infectadas con shigella presentan: diarrea inflamatoria, fiebre elevada, dolor abdominal agudo, vómitos y náuseas un día o dos después de infectarse. La diarrea es a casi siempre mucosanguinolenta e inodora.

En algunas personas, se ha distribuido especialmente en los niños de corta edad y los ancianos, la diarrea puede ser tan grave que el paciente necesite ser hospitalizado. Una infección aguda con fiebre elevada también puede ir acompañada de ataques o convulsiones en niños menores de 2 años.

El tratamiento para la shigelosis consiste en la restitución de líquidos perdidos por el enfermo como consecuencia de la diarrea. La rehidratación oral es generalmente satisfactoria para la mayoría de los pacientes, pero ocasionalmente es necesario apelar a hidratación intravenosa en ciertos casos especiales. Sin antibióticos, la infección se resuelve entre 4 a 8 días para la mayoría de los casos. Las infecciones severas pueden durar de 3 hasta 6 semanas.

El uso de antibióticos como trimetoprim-sulfametoxazol, ciprofloxacino, norfloxacino y ampicilina, por lo general, se reserva para pacientes muy jóvenes o ancianos y aquellos con infecciones severas con gran pérdida de líquidos o donde hay un alto riesgo de contagio hacia otras personas. Algunas cepas de la bacteria han desarrollado resistencia a los antibióticos.




</doc>
<doc id="41964" url="https://es.wikipedia.org/wiki?curid=41964" title="Úlcera péptica">
Úlcera péptica

La úlcera péptica es una úlcera que afecta a la mucosa que recubre el estómago o el duodeno (la primera parte del intestino delgado). De acuerdo con su ubicación se clasifica en úlcera gástrica o úlcera duodenal, esta última mucho más frecuente. La úlcera péptica puede aparecer tanto en mujeres como en hombres desde la infancia hasta una edad avanzada. Se trata de una enfermedad común que afecta a una de cada 10 personas en algún momento de su vida. 

La causa de la úlcera es un desequilibrio entre los factores agresivos para la mucosa gastroduodenal y los defensivos. Entre los agentes agresivos los más importantes son la secreción de ácido gástrico que se realiza por las células parietales —secretoras de ácido clorhídrico—, la infección por la bacteria "Helicobacter pylori" (causante de la mayoría de los casos) y los tratamientos con medicamentos antiinflamatorios no esteroideos (AINE) como la aspirina y el ibuprofeno. Los factores protectores son la secreción gástrica de moco y bicarbonato, el flujo sanguíneo adecuado a la mucosa gastroduodenal, los mecanismos naturales de reparación de la mucosa y la secreción de prostaglandinas que estimulan la producción de moco y bicarbonato.

Una úlcera o "ulcus" es una lesión de la piel o membrana mucosa, crateriforme (con forma de un cráter, al perderse parte del tejido), y con escasa o nula tendencia a la cicatrización. Una úlcera péptica es aquella que afecta la mucosa que recubre el estómago o el duodeno (la primera parte del intestino delgado). Las úlceras pueden afectar tanto a las mujeres como a los hombres, sin importar su edad.

Una úlcera péptica es una lesión erosiva crónica del revestimiento del estómago o del duodeno, que es el principio del intestino delgado. La causa mayoritaria de la úlcera péptica es la infección bacteriana causada por "Helicobacter pylori", pero algunas úlceras son causadas por el uso prolongado de antiinflamatorios no esteroideos (AINE), como la aspirina (ácido acetilsalicílico). En contadas ocasiones, tumores cancerosos del estómago o del páncreas pueden causar úlceras. Las úlceras pépticas no son causadas por ningún tipo de alimentos muy condimentados pero sí son agravadas por ellos, lo mismo ocurre con el estrés, no es factor etiológico (causante) pero sí predisponente y agravante.

La úlcera péptica es una anomalía muy frecuente que afecta al 10 % de la población en algún momento de su vida. Sin embargo debido a los eficaces medicamentos que existen para tratarla, la mortalidad que produce es escasa, únicamente causa entre dos y tres fallecimientos por 100000 habitantes al año. La mayoría originados por complicaciones como hemorragias digestivas o perforación con peritonitis. En el pasado la mortalidad que causaba era considerablemente más alta. 

Existen algunas diferencias entre la úlcera gástrica y la duodenal. La primera es igual de frecuente en ambos sexos, mientras que la segunda se da en mayor proporción en los varones.

En relación a los distintos factores implicados en su etiología, se calcula que alrededor del 50 % de la población mundial adulta está infectados por el germen Helicobacter pylori y solamente entre el 10 y el 20 % de los infectados presenta úlcera péptica, por lo que debe considerarse que este germen no es el origen único de la enfermedad, sino únicamente uno de los muchos factores que están implicados en su aparición.

En relación a los medicamentos antiinflamatorios no esteroideos cuya utilización está muy generalizada para tratar el dolor articular, la cefalea o para descender la fiebre, alrededor del 25 % de las personas que los utilizan habitualmente pueden llegar a presentar úlcera péptica o algún trastorno relacionado y alrededor del 75 % de aquellos que han presentado una hemorragia digestiva han empleado este tipo de medicamentos poco antes de la aparición de esta complicación.

El síntoma más característico es la existencia de dolor que se localiza en la zona central y superior del abdomen (epigastrio). El dolor puede definirse como corrosivo y suele hacer su aparición entre 1 y 3 horas después de las comidas o por la noche durante las horas de sueño. Suele suceder tras la ingesta de alimentos, y seguir una evolución cíclica con exacerbaciones de semanas o meses de duración que se intercalan con periodos en los que no se manifiesta.

Otros síntomas frecuentes son la existencia de reflujo gastroesofágico, pirosis, ardores o acidez que desaparecen con la toma de algún agente alcalino como el bicarbonato o los antiácidos. También náuseas, vómitos y pérdida de peso. En algunos casos hasta sangrado.

Hay que tener en cuenta que este cortejo de manifestaciones no siempre están presentes. Algunas personas presentan tan solo un síntoma leve o ninguno. Muchos de estos síntomas son semiologías compartidas por otras afecciones como la gastritis erosiva, litiasis biliar, pancreatitis, cáncer de estómago, etc.

Los síntomas son variables, pues la hemorragia puede ser masiva y manifestarse en forma de vómitos con sangre (hematemesis) o bien como deposiciones de color negro y aspecto característico que se llaman melenas. A veces pasa inadvertida para el paciente y produce una anemia que progresa en el plazo de días o semanas.

Se trata de una complicación muy peligrosa que puede poner en peligro la vida del paciente, por lo cual ante su presencia o sospecha es preciso acudir urgentemente al médico. Generalmente es preciso realizar una endoscopia para comprobar con exactitud el punto de sangrado.

Es una grave complicación que se produce cuando la úlcera atraviesa totalmente la pared del estómago o duodeno. El contenido gástrico entra en contacto con el peritoneo y produce una peritonitis aguda.

Se manifiesta por un intenso dolor abdominal localizado en la porción superior del abdomen (epigastrio) que comienza de forma abrupta y se describe frecuentemente como "dolor en puñalada".

Si se confirma la presencia de esta complicación, es imprescindible la realización con carácter urgente de una intervención quirúrgica para cerrar la perforación. La cirugía más frecuente para su reparación consiste en realizar un Parche de Graham.

El píloro es la válvula que comunica el estómago con el intestino. Cuando existe una úlcera péptica situada cerca del píloro, puede ocurrir que los fenómenos de inflamación y cicatrización reiterados originen una obstrucción en esta estrecha zona. Ello ocasiona que el contenido del estómago tenga dificultad en seguir su camino natural hacia el duodeno y el intestino delgado para continuar la digestión.

El síntoma más característico de la obstrucción pilórica es el vómito retencionista de alimentos ingeridos entre 6 y 8 horas antes.

Se produce principalmente en las úlceras situadas en la cara posterior, las cuales pueden perforar lentamente la pared del estómago o duodeno y penetrar en órganos vecinos como páncreas, epiplón, vía biliar, hígado y colon. 

Cuando esto ocurre, el dolor cambia sus características clásicas, se hace más intenso y permanente. Aparecen nuevos síntomas dependiendo del órgano afectado, por ejemplo elevación de los niveles de amilasa en sangre si la penetración tiene lugar sobre el páncreas.

El diagnóstico se basa en la presencia de síntomas sugestivos y en la realización de pruebas complementarias que demuestren la lesión.

La técnica diagnóstica más eficaz es la endoscopia. Esta se realiza mediante el endoscopio, que es un tubo fino y flexible provisto de una luz y una pequeña cámara en la punta. Después de haberle dado un sedante al paciente, el médico introduce cuidadosamente el endoscopio por la boca de la persona y lo va haciendo descender por la garganta hasta llegar al esófago, estómago y duodeno. De esta manera, se puede observar directamente el revestimiento de estos órganos. El médico puede valerse del endoscopio para tomar fotos de las úlceras o para extraer un fragmento diminuto de tejido para examinarlo con el microscopio (biopsia).

Si se identifica una úlcera, el médico puede realizar pruebas para comprobar si el paciente está infectado con "H. pylori". Estos estudios pueden realizarse mediante pruebas de sangre, aliento y tejido. Las pruebas de sangre son las más comunes. Permiten detectar anticuerpos contra dicha bacteria. La prueba de aliento se usa principalmente después del tratamiento para ver si este dio resultado, pero se pueden usar también para el diagnóstico.

Si no es posible realizar la endoscopia, puede recurrirse a radiografías con contraste. Se da a beber al paciente un líquido de consistencia parecida al yeso (el contraste de bario está contraindicado si se sospecha de perforación ya que no es hidrosoluble, en ese caso se utilizará gastrografín). Gracias al mismo cualquier posible úlcera se ve más claramente en la radiografía. La radiología es una técnica que tiene menor sensibilidad y especificidad que la endoscopia y además no permite la toma de biopsias, por lo cual no está recomendada como primera opción diagnóstica.

Los inhibidores de la bomba de protones son agentes antisecretores potentes que actúan sobre las células parietales del estómago y disminuyen la producción de ácido mediante la inhibición de la enzima H+K+ATPasa, la cual expulsa los hidrogeniones (H+) a la luz gástrica, los cuales al unirse al ion cloro forman el ácido clorhídrico. Se recomienda administrarlos unas horas antes de la medicación o por la mañana en pacientes plurimedicados a lo largo del día 

Son más efectivos que los antagonitas H2 (cimetidina, ranitidina y análogos).

Actúan bloqueando los receptores H2 para la histamina e inhibiendo la secreción ácida, lo que facilita la cicatrización de las úlceras. Dentro de este grupo se incluyen la ranitidina, famotidina, cimetidina, nizatidina y roxatidina.

La ranitidina es uno de los más utilizados, su efecto antisecretor tiene una duración de 12 horas por lo que suele administrarse 2 veces al día. La famotidina se administra una vez al día por su mayor duración de acción.

Sucralfato, es el fármaco comercializado más efectivo cuando la úlcera ya está formada. Tiene mayor afinidad por la mucosa ulcerada favoreciendo la secreción de moco y disminuyendo la secreción ácida. Está indicado en el tratamiento de las úlceras estomacales y duodenales. Es compatible con otros IBP (inhibidores de la bomba de protones), a los cuales se asocia en los casos más graves pero se recomienda distanciar la administración entre 1-2 horas.

A diferencia de los IBP protege de sustancias irritantes exógenas y reduce la secreción de pepsina y HCl en menor grado.

El tratamiento generalmente entraña la combinación de antibióticos y un inhibidor de la secreción de ácido. El tipo de antibiótico recomendado puede diferir en regiones diferentes del mundo porque algunas áreas han comenzado a mostrar resistencia a antibióticos particulares. El uso de solo un tipo de antibiótico para tratar "H. pylori" no se recomienda.

En la actualidad, la forma más eficaz de tratar el problema consiste en administrar durante dos semanas lo que se conoce como terapia triple. Ésta exige tomar dos antibióticos para matar las bacterias y un supresor de la secreción de ácido. La terapia triple administrada durante dos semanas disminuye los síntomas ulcerosos, destruye las bacterias y evita la recurrencia de la úlcera en más de 90% de los pacientes.

Para cerciorarse de que el tratamiento ha destruido todas las bacterias "H. pylori", el médico puede efectuar una endoscopia de seguimiento o una prueba del aliento entre 1 y 12 meses después del diagnóstico para comprobar la evolución.


</doc>
<doc id="41965" url="https://es.wikipedia.org/wiki?curid=41965" title="Rotavirus">
Rotavirus

Rotavirus es un género de virus ARN bicatenario de la familia "Reoviridae" que es la causa más común de diarrea grave en niños de hasta 5 años y neonatos de distintas especies de mamíferos. Es uno de los varios virus que a menudo causan las infecciones denominadas gastroenteritis. En humanos, la gran mayoría de los infantes menores de 5 años de edad han sido infectados por el rotavirus al menos una vez. En bovinos, por ejemplo, la diarrea por rotavirus afecta a terneros en las primeras semanas de vida, lo que genera grandes pérdidas económicas.

Hay 8 grupos, denominadas: A, B, C, D, E, F, G y H. El rotavirus A, el más común, causa más del 90 % de las infecciones en humanos y animales. El virus se transmite por vía fecal-oral. Infecta y daña las células que recubren el intestino delgado y causa gastroenteritis.

El rotavirus es un virus de fácil resolución en pacientes sanos (aquellos que no están inmunocomprometidos), pero en todo el mundo aún mueren cada año cerca de 450.000 niños, la mayoría de ellos en países en vías de desarrollo, y casi dos millones más caen gravemente enfermos. En los bovinos, este virus forma parte del complejo Diarrea Neonatal del Ternero que puede afectar hasta el 70 % de esos animales.

La forma más eficaz de prevenir la infección por rotavirus es mediante la vacunación. En niños, ésta se realiza de manera obligatoria principalmente en países desarrollados, y también en algunos en vías de desarrollo como la Argentina. En bovinos, la estrategia de vacunación es inmunizar a la madre antes del parto para, luego, transmitir sus defensas al ternero al momento del nacimiento.

En 1943, Jacob Light y Horace Hodes demostraron que un agente filtrable en las heces de los niños con diarrea infecciosa también causaba diarrea en el ganado. Tres décadas más tarde, las muestras conservadas del agente demostraron que era un rotavirus. En los años siguientes, el virus inoculado en ratones demostró la relación entre el virus y las diarreas. En 1973, Ruth Bishop y sus compañeros describieron el virus relacionado con la gastroenteritis infantil.

En 1974, Thomas Henry Flewett sugirió el nombre de rotavirus tras observarlo por el microscopio electrónico, dónde vio que parecía una rueda ("rota"en latín); el nombre fue oficialmente reconocido por el Comité Internacional de Taxonomía de Virus cuatro años más tarde. En 1976, se describió el virus relacionado con otras especies. El virus fue reconocido como un agente infeccioso para los humanos y animales por todo el mundo. Los serotipos del rotavirus fueron descritos por primera vez en 1980, y al año siguiente, se lograba su obtención en cultivos celulares derivados de riñones de simios mediante la adición de tripsina (una enzima que se encuentra en el duodeno de los mamíferos y que se sabe que es esencial contra la replicación del rotavirus) en el medio de cultivo. La capacidad de hacer crecer el rotavirus en cultivos aceleró el ritmo de la investigación, y a mediados de la década de 1980 se empezaron a evaluar las primeras vacunas.

En 1998, el uso de la vacuna contra el rotavirus fue aprobada por los Estados Unidos. Se realizaron ensayos clínicos en Estados Unidos, Finlandia y Venezuela que tuvieron una efectividad del 80-100% en la prevención de la diarrea grave causada por el rotavirus A. No obstante, los investigadores detectaron efectos adversos serios estadísticamente significativos. El fabricante la retiró del mercado en 1999 cuando se descubrió que la vacuna podía haber contribuido a un aumento del riesgo de invaginación intestinal, un tipo de obstrucción intestinal, en uno de cada 12.000 niños vacunados. La experiencia provocó un intenso debate sobre los riesgos y beneficios relativos de la vacuna contra el rotavirus. En 2006, aparecieron dos nuevas vacunas contra el rotavirus A que demostraron ser seguras y efectivas en los niños, y en junio de 2009 la Organización Mundial de la Salud recomendó que la vacunación contra el rotavirus se incluyera en todos los programas nacionales de inmunización para brindar protección contra este virus.

La gastroenteritis por rotavirus es una enfermedad que puede ser tanto leve como grave y está caracterizada por: vómitos, diarrea acuosa y fiebre leve. Cuando un niño está infectado por el virus, hay un periodo de incubación de aproximadamente dos días antes de que aparezcan los síntomas. Estos suelen comenzar con vómitos seguidos de cuatro a ocho días de diarrea profusa. La deshidratación es más común en la infección por rotavirus que en la mayoría de las infecciones causadas por bacterias patógenas y es la causa más común de muerte relacionada con la infección por rotavirus.

Puede producirse un brote infeccioso por rotavirus A en cualquier momento de la vida: la primera, en general, produce síntomas, pero las infecciones posteriores suelen ser leves o asintomáticas, ya que el sistema inmunitario proporciona una cierta protección. Consecuentemente, las infecciones sintomáticas son más frecuentes en niños menores de dos años y disminuyen progresivamente con la edad. Las infecciones en bebés, aun siendo comunes, están a menudo asociadas con la enfermedad leve o asintomática; los síntomas más graves tienden a producirse en niños de seis meses a dos años de edad, ancianos y personas inmunodeprimidas. Debido a la inmunidad adquirida en la infancia, la mayoría de los adultos no son vulnerables al rotavirus; la gastroenteritis en adultos en general tiene una causa diferente del rotavirus, pero las infecciones asintomáticas pueden mantener la transmisión de la infección en la comunidad.

El rotavirus se transmite principalmente por vía fecal-oral, pero también se puede transmitir a través de las manos, superficies y objetos sucios, también se puede transmitir a través del sistema respiratorio. Los excrementos de una persona infectada pueden contener más de 10 billones de partículas infecciosas por gramo; resultando suficientes menos de 100 de estas partículas para infectar a otra persona.

El rotavirus es estable en el medio ambiente y se han encontrado muestras en estuarios a niveles tan altos como 1-5 partículas infecciosas por galón americano (3.78 litros). Las medidas sanitarias adecuadas para la eliminación de bacterias y parásitos parecen ser ineficaces en el control del rotavirus, puesto que la incidencia de la infección por rotavirus en los países con niveles sanitarios altos y bajos es similar.

La diarrea está causada por las múltiples actividades del virus. La malabsorción se debe a la destrucción de las células intestinales denominadas enterocitos. La proteína tóxica NSP4 del rotavirus interrumpe al transportador SGLT1 que interviene en la reabsorción del agua, al parecer, reduce la actividad de las disacaridasas y, posiblemente, activa los iones de calcio dependientes de los reflejos de la secreción del sistema nervioso entérico. Los enterocitos sanos segregan lactasa en el intestino delgado; la intolerancia a la leche causada por una deficiencia de lactasa es un síntoma de la infección por rotavirus, la cual puede persistir durante semanas. A una diarrea recurrente leve a menudo le sigue la reintroducción de la leche en la dieta del niño, debido a la fermentación bacteriana del disacárido lactosa en el intestino.

El diagnóstico del rotavirus normalmente es un diagnóstico de gastroenteritis como causa de diarrea grave. A la mayoría de los niños ingresados en hospitales por gastroenteritis se les hace el test del rotavirus A. El diagnóstico específico para la infección por rotavirus A se realiza buscando el virus en las heces de los niños a través de un ensayo por inmunoabsorción ligado a enzimas, ELISA por sus siglas en inglés. Hay varios equipos de prueba con licencia en el mercado que son sensibles, específicos y detectan todos los serotipos de rotavirus A. Otros métodos, como la visualización en el microscopio electrónico y la reacción en cadena de la polimerasa, se utilizan en los laboratorios de investigación. La transcripción inversa de la reacción en cadena de la polimerasa (RT-PCR) puede detectar e identificar todas las especies y serotipos de rotavirus humanos.

El tratamiento de la infección aguda por rotavirus no es específico y consiste en la gestión de los síntomas y, lo más importante, mantener la hidratación. Si no se trata, los niños pueden morir por una grave deshidratación. Dependiendo de la gravedad de la diarrea, el tratamiento consiste en rehidratar oralmente, dando al niño un exceso de agua para beber que contiene pequeñas cantidades de sales y azúcares o se administran líquidos por vía intravenosa por goteo o sonda nasogástrica, mientras se controlan los electrolitos del niño y el azúcar en sangre. Las infecciones por rotavirus raramente causan otras complicaciones y para un niño muy controlado, el pronóstico es excelente.

Hay ocho grupos de rotavirus, designadas como A, B, C, D, E, F y G. Los humanos solo pueden verse infectados por los tipos A, B y C, principalmente por el A. Todas las especies atacan a algún animal. Dentro del tipo A hay variaciones, llamadas serotipos. Al igual que con el virus de la gripe, se usa un sistema doble de clasificación, basado en dos tipos de proteínas de la cápside. La glucoproteína VP-7 define el tipo G y la proteína sensible a proteasas VP-4 define al tipo P. El tipo P se define como un número para el serotipo P y como un número entre corchetes para el genotipo P. Los serotipos G tienen una nomenclatura similar, siendo el número del serotipo G el mismo del genotipo G. Por ejemplo, la cadena Wa se denota como P1A[8]G1. Debido a que los dos genes que determinan el tipo G y el tipo P pueden transmitirse por separado, en la progenie del virus se encuentran diferentes combinaciones.

Los rotavirus (del lat. "rota": rueda) tienen una apariencia característica similar a una rueda, cuando es visualizado mediante microscopio electrónico. Los rotavirus son virus no envueltos (desnudos), en su capside se observan 3 capas (capa Externa, Media e Interna). El genoma está compuesto de 11 segmentos de ARN de doble-hebra, que codifican por seis proteínas estructurales y seis no estructurales (uno de sus segmentos codifica para 2 proteínas). El virus es estable en el medio ambiente. Pueden llegar a medir 76,5 nm de diámetro.

El virión está formado por seis proteínas (VP). Estas proteínas "estructurales" se llaman VP1, VP2, VP3, VP4, VP5 y VP6. Aparte de las proteínas "estructurales", hay seis más "no estructurales" (NSP), producidas únicamente en las células infectadas. Se denominan NSP1, NSP2, NSP3, NSP4, NSP5 y NSP6. Por lo menos seis de las doce proteínas codificadas por el genoma vírico llevan ARN asociado, y la función de estas proteínas en el rotavirus no están bien explicadas; se cree que están implicadas en la síntesis y empaquetamiento del ARN, transporte del ARNm hacia la zona de replicación del genoma y en la traslación de ARNm y regulación de la expresión génica.

La VP1 está situada en el núcleo del virus y es una ARN polimerasa. En una célula infectada produce los transcritos de ARNm para sintetizar las proteínas víricas y duplica el genoma para producir nuevas partículas víricas.

La VP2 forma parte de la capa más interna del virión y va unida al genoma de ARN.

La VP3 también forma parte de la capa interna del virión y es un enzima llamado guanilil transferasa. Es un enzima que produce la caperuza en 5' del ARN ("capping enzyme"), durante la modificación postranscripcional del ARN mensajero. Esta caperuza estabiliza el extremo 5' del mensajero e impide que sea atacado por nucleasas, enzimas que degradan ácidos nucleicos.

La VP4 está situada en la parte externa del virión y forma una protuberancia, que es capaz de unirse a los receptores celulares de la célula para entrar en su interior. La VP4 debe ser modificada por una proteasa intestinal, para dar lugar a VP5* y VP8*, antes de que la partícula vírica sea infecciosa. La estructura de VP4 determina la virulencia del virus y que sea de tipo P.

La VP6 es la proteína principal de la cápside. Es altamente antigénica y puede usarse para determinar la especie del rotavirus. Se usa en los ensayos clínicos para determinar la existencia de infección por rotavirus A.

La VP7 es una glucoproteína que forma parte de la capa externa del virión. Aparte de sus funciones estructurales, determina el tipo G de la cadena, y junto con VP4, está implicada en la respuesta inmunitaria al virus.

NSP1 es transcrita por el gen 5 y es una proteína no estructural de unión a ARN.

NSP2 es una proteína de unión a ARN, que se acumula en inclusiones citoplasmáticas (viroplasma) y es necesaria en la replicación del genoma.

NSP3 está unida a ARNm en las células infectadas y es la responsable de la finalización de la síntesis proteica celular.

NSP4 es una enterotoxina viral que induce diarrea y fue la primera enterotoxina viral que se descubrió.

NSP5 está codificada por el segmento 11 del genoma vírico del rotavirus A, y en las células infectadas se acumula en el viroplasma.

NSP6 es una proteína de unión a ácido nucleico es codificada por el gen 11, en un marco abierto de lectura desfasado.

Se replican principalmente en el intestino e infectan enterocitos de las vellosidades intestinales, lo que causa cambios funcionales y estructurales en el epitelio. Su triple capa proteica (no confundir con cápside) lo hace resistente al pH del estómago y a las enzimas digestivas del intestino.

El virus entra a las células mediante endocitosis mediada por receptores y forma una vesícula llamada endosoma. Proteínas en la tercera capa (VP7 y VP4) quebrantan la membrana del endosoma, creando una diferencia en la concentración de Calcio. Esto produce la ruptura de los trímeros de VP7 en una sola subunidad proteica, dejando la cobertura de VP2 y VP6 alrededor del ARN viral.

Los 11 segmentos de ARN bicatenario permanecen bajo la protección de dos cubiertas proteicas y la polimerasa de ARN crea transcritos de ARNm del genoma de ARN. Al permanecer en la cápside, el ARN viral evade la respuesta inmune de ARN interferente, una molécula de ARN que suprime la expresión de genes específicos, que es disparado por la presencia del ARN bicatenario.

Durante la infección, el rotavirus produce ARNm para la biosíntesis proteica y la replicación de genes. La mayor parte de las proteínas se acumulan en el viroplasma, donde el ARN es replicado y se ensamblan los viriones. El viroplasma se forma alrededor del núcleo celular pasadas 2 horas a partir de la infección, y consiste de fábricas virales que se cree están formadas por dos proteínas no estructurales: NSP5 y NSP2. La inhibición de NSP5 por el ARN interferente resulta en un marcado decrecimiento en la replicación del rotavirus. Los viriones migran al retículo endoplasmático donde obtienen su tercera capa formada por VP7 y VP4. La progenie es liberada de la célula por lisis

Los rotavirus propician gastroenteritis aguda y fuerte dolor abdominal. "Diarrea infantil", "diarrea invernal", "infección no bacterial aguda" y "gastroenteritis viral aguda" son los otros nombres con los que se denomina a este padecimiento. La dosis infectante se presume que es de 10-100 partículas virales infecciosas, ya que una persona con rotavirus frecuentemente excreta una gran cantidad de partículas virales: en el orden de (10-10 partículas infecciosas /ml de heces). La vía de contagio se da a través del contacto con manos, objetos o utensilios contaminados.
El período de incubación de la enfermedad por rotavirus es de aproximadamente 2 días pero no se sabe con certeza. La enfermedad está caracterizada por vómito y diarrea acuosa de 3 a 8 días, y fiebre con dolor abdominal ocurre con frecuencia. La inmunidad se produce después de la infección. Infecciones posteriores tienden a ser menos graves que la infección original.

Usualmente el desarrollo de la infección se resuelve espontáneamente.
La deshidratación aguda debida a la diarrea es una de las mayores complicaciones. Es aconsejable el uso de electrólitos, si bien es conveniente consultar previamente al médico.

La mejor manera de prevenirla es utilizar utensilios limpios, y lavarse las manos después de usar el baño. También hay que tener cuidado al manejar pañales para no propiciar un contagio posterior.

En el 2006, dos vacunas contra el rotavirus mostraron ser seguras y efectivas en los niños: Rotarix desarrollada por los laboratorios GlaxoSmithKline y es creada a base de virus vivos atenuados y RotaTeq desarrollada por los laboratorios Merck y es creada con virus recombinantes humanos y bovinos. Ambas se administran vía oral y contienen virus vivos atenuados. En 2006, la FDA aprobó RotaTeq para su uso en los Estados Unidos y anunció un precio de 187.50 para el régimen estándar de tres dosis. Por tanto, es una de las inmunizaciones infantiles más costosas, a pesar de los descuentos viene a ser una opción inalcanzable para los infantes del tercer mundo.Sin embargo la OMS recomienda fuertemente la inclusión de la vacuna contra rotavirus a los programas de inmunización en todas las regiones del mundo.
Una vacuna anterior, Rotashield desarrollada por Wyeth-Ayerst, fue retirada del mercado a finales de los 90 cuando se descubrió en casos muy raros estar vinculada a complicaciones graves de tipo oclusivo-intestinales.

Repetidas infecciones de rotavirus pueden incrementar el riesgo de desarrollar Celiaquía en niños generalmente susceptibles. Siempre se ha creído que las infecciones intestinales contribuyen a su desarrollo, un desorden digestivo común disparado por comer productos a base de trigo y otros alimentos que contienen la proteína gluten. Algunos estudios, sin embargo, han revisado el rol de los agentes infecciosos específicos en el desarrollo de la enfermedad. Como participantes de un estudio de los agentes ambientales desatadores de la enfermedad, 1931 niños del área metropolitana de Denver -quienes eran genéticamente susceptibles a la celiaquía- fueron monitorizados desde la infancia verificando si habían padecido rotavirus y el desarrollo de celiaquía posteriormente.

El rotavirus es una enfermedad infecciosa prevenible y altamente contagiosa, que puede llegar a ser mortal en los menores, si no es tratada a tiempo. Datos obtenidos por la OMS dicen "Las enfermedades diarreicas son la segunda mayor causa de muerte de niños menores de 5 años". Es importante resaltar que este tipo de infecciones son prevenibles y tratables; educando a padres y población en general en hábitos higiénico-diétetico, enfatizando en la vacunación, recordando que esta es gratuita y está al alcance de todos.



</doc>
<doc id="41968" url="https://es.wikipedia.org/wiki?curid=41968" title="Calpis">
Calpis

Calpis es una bebida de origen japonés no carbonatada, fabricada por , cuya sede central se encuentra en Shibuya, Tokio. La bebida tiene un cierto toque, parecido al de la leche, y ligero sabor ácido, similar al yogur natural o al de vainilla. Está compuesta por agua, leche desnatada y ácido láctico, y se produce mediante fermentación láctica.

La bebida es vendida como un concentrado que es mezclado con agua o en ocasiones leche justo antes del consumo. Una versión prediluída conocida como y otra que es carbonatada llamada también se encuentran disponibles. Se usa también para dar sabor al kakigōri y como un ingrediente de cocteles y del chuhai.

Salió por vez primera al mercado el 7 de julio de 1919. Ganó popularidad rápidamente en el Japón anterior a la guerra ya que en su forma concentrada se conservaba bien sin refrigeración. La imagen del paquete solían ser puntos blancos sobre un fondo azul hasta que los colores se invirtieron en el 1953. El tema original en el que se basaba era la Vía Láctea, que es una referencia al festival japonés de Tanabata en el 7 de julio, un momento tradicional considerado como el comienzo del verano. El Calpis se vendió por primera vez en ese día.

Hay muchas variedades de sabores. Estas variaciones incluyen, pero sin limitar, el sabor a fresa, uva, matcha, guayaba, mango, lichi, piña (disponible sólo en Okinawa), naranja, mikan (mandarina japonesa), melón, durazno (melocotón, no durillo), aloé, y con crema. Recientemente, Calpis está disponible en una manzana con sabor a "mezcla de la mañana," un 70% de calcio y reducida en calorías, y "El Calpis Premium", un extra-pre-condensada versión mixta del agua original Calpis. Otra innovación reciente es una versión dietética de Calpis Water llamado "Calpis Cero". En Japón y Taiwán se puede conseguir las versiones de muchas bebidas alcohólicas hechas con Calpis como "Calpis Sour" y "Calpis Bartime", un cóctel con sabor a fruta. 

La compañía produce una variedad de otras bebidas que van desde el café en lata hasta bebidas de yogur más nutritivas, como "Gun Gun Gurt". También pusieron a los productos hechos sobre la base de la bebida como "mantequilla Calpis" y "vinagre de Calpis". 

Calpis Co. Ltd. es el distribuidor japonés de los jugos Welch y el agua mineral francesa Evian. Hay un caramelo Calpis que ofrece la misma combinación de colores azul y blanco.

El nombre de Calpis proviene de la combinación de "cal" (calcio) y "pis" (del Sánscrito "sarpis" (gusto supremo), término que se utiliza para describir la esencia de las enseñanzas budistas.

El logotipo original de Calpis era una representación simplificada en blanco y negro de un hombre negro con grandes labios que bebe de un vaso con una pajilla. El logo fue desarrollado a partir de un cuadro pintado por un artista alemán que representa a una persona de raza negra con un sombrero panameño. El logotipo se creía que era racista por lo que el blanco y negro fue revertido y el logotipo fue cambiado por el típico vaso de Calpis.


</doc>
<doc id="41969" url="https://es.wikipedia.org/wiki?curid=41969" title="Primer ministro">
Primer ministro

Un primer ministro o ministro principal (del inglés, "prime minister") es un político que sirve como jefe del poder ejecutivo en algunos Estados como un cargo diferenciado del jefe de Estado.

En general es el jefe de Gobierno en el sistema parlamentario. En otros sistemas, como el semipresidencial, el primer ministro es el funcionario encargado de la Administración Pública. El jefe de Estado puede ser nominalmente su superior, pero en la realidad en muchos casos tiene funciones más bien de ceremonias y protocolo, siendo el primer ministro quien gobierna el Estado.

A menudo, un primer ministro ejerce sus funciones con un presidente o un monarca que se desempeña como jefe de Estado. El primer ministro es normalmente el líder del partido político que tiene la mayoría en el parlamento. Sus responsabilidades principales incluyen coordinar la actividad del gobierno, designar a varios oficiales del gobierno, y, conjuntamente con el jefe de Estado, la representación del gobierno de su país en el mundo. Los primeros ministros pueden recibir otras denominaciones oficiales diferentes dependiendo del país en el que gobiernen.

De acuerdo con las reglas gramaticales de la Real Academia Española, el femenino de «primer ministro» es «primera ministra».
También se encuentran referencias a «la primer ministra» o «la primera ministra». Un argumento que se ha dado es que «la primer» es incorrecto porque "primer" es apócope del adjetivo masculino; y que «la primera ministra» describe a la principal de las "mujeres" que integran el gabinete, cuando en realidad es la principal de "todos" los ministros, mujeres y hombres; entonces lo correcto sería «la primera ministra».

Se recomienda escribirlo con letras iniciales mayúsculas cuando se refiere a una persona concreta sin explicitar su nombre, así como en decretos, documentos oficiales y cartas dirigidas a la misma persona. El cargo se escribirá con minúsculas cuando preceda al nombre de quien lo ostenta, al igual que cuando se use el término en sentido genérico, sin referirse a ninguna persona en particular.




</doc>
<doc id="41972" url="https://es.wikipedia.org/wiki?curid=41972" title="Ultimate (deporte)">
Ultimate (deporte)

El Ultimate o Disco Volador es un deporte de equipo sin contacto y autoarbitrado que se juega con un disco volador (o Frisbee ™).
Dos equipos de siete jugadores compiten en un campo de juego de aproximadamente la misma longitud que un campo de fútbol, ​​pero más estrecho (100 x 37 m). En cada extremo del campo de juego hay una zona de ensayo de 18 x 37 m. Cada equipo defiende una zona de ensayo. Marcan un gol si uno de sus jugadores atrapa el disco en la zona final que defiendo el equipo contrario.

El jugador con el disco se llama el lanzador. El lanzador no puede correr con el disco. En cambio, se puede mover el disco pasando a sus compañeros de equipo en cualquier dirección.

El equipo defensivo obtiene la posesión del disco si un jugador del equipo que ataca no atrapa el pase de un compañero. Entonces el equipo defensivo se convierte en el equipo ofensivo y puede intentar anotar en la zona de anotación opuesta.

El objetivo del juego es llegar al marcador objetivo antes que el rival o ser el equipo con más goles marcados al término del tiempo. Se caracteriza principalmente por la ausencia de árbitros y por su principio de “"espíritu de juego"” (o espíritu deportivo) que deja en virtud de los propios jugadores el aplicar el reglamento de forma honesta y deportiva.

El terreno de juego es rectangular de césped natural o artificial, de 100 metros de largo × 37 metros de ancho, con una zona de anotación a cada lado del campo, el objetivo es coger el disco estando en la zona de anotación defendida por el equipo contrario a través de lanzamientos entre jugadores de modo similar al fútbol americano, pero los jugadores no pueden caminar ni correr mientras tienen el disco en las manos.

Sus principios se remontan al ámbito universitario estadounidense de los años 60. En Europa se introdujo a principios de los años 80. A nivel mundial hay unos 369 963 jugadores distribuidos en aproximadamente 5000 equipos. 

El organismo rector es la Federación Mundial del Disco Volador ("WFDF" por sus siglas en inglés), fundada en 1985 y conformada por asociaciones nacionales y sin miembros individuales, está a cargo de eventos como campeonatos mundiales, normativas, reglamento del juego y la estandarización de récords mundiales.

En 1976, docenas de universidades tenían equipos; en abril de ese año los jugadores organizaron el primer Torneo de ultimate, realizado en Yale. Rutgers se enfrentó al Rensselaer Polytechnic Institute (RPI), con un resultado de 26-23, en la final.

Para 1976, surgen nuevos equipos en el noreste de los Estados Unidos. Un solo torneo de eliminación de 16 equipos fue instalado en Amherst, Massachusetts, para incluir a 13 equipos de la costa este y a 3 del cercano oeste. Rutgers se tomó de nuevo el título luego de enfrentar a Hampshire College en las finales. Penn State y Princeton fueron los otros semifinalistas. Se le llamó el «Campeonato Nacional de Ultimate Frisbee». El ultimate ya empezaba a aparecer en Los Ángeles y en Santa Bárbara.

Penn State alojó los primeros 5 campeonatos regionales de ultimate frisbee. Había 5 representantes regionales, 3 universitarios y 2 clubs: Cornell University (noreste), Glassboro State (atlántico medio), Michigan State (medio), Orlando Fling (sur) y Santa Barbara Condors (oeste). Cada equipo jugó contra todos los demás en una ronda y la final se disputó entre los 2 primeros en la ronda anterior, la final fue entre Glassboro y Condors. Los Condors estaban invictos hasta este partido, pero de todas formas prevaleció Glassboro con un 19-18.

En 1979 y en 1980 se formó la Ultimate Players Association (UPA); organizó torneos regionales y corona un campeón nacional cada año desde 1979.

El juego ganó renombre con rapidez, se arraigó como alternativa a los juegos organizados tradicionales. El ultimate atrae un mayor número de atletas tradicionales y se eleva el nivel de la competencia.

En 1981 se formó la European Flying Disc Federation.

En 1984 se formó la World Flying Disc Federation, fue formada por la European Flying Disc Federation para internacionalizar el reglamento de los deportes con disco.

El deporte se popularizó también en Sudamérica, en especial en Venezuela, Colombia y Argentina. Más tarde lo haría en España.

Los primeros equipos españoles surgieron en la segunda mitad de los años 90. En 2001 se disputó su primer campeonato, con Patatas Bravas (ahora Bravas) como campeones.
Existe desde 2003 la Federación Española del Disco Volador, de la que depende el Ultimate.

La Federación renueva cada año un millar de fichas de jugadores, así como de 33 clubes (agosto 2019) que compiten en el Campeonato de España en las 2 modalidades deportivas, Beach Ultimate y Ultimate, en 3 categorías: mixta, masculina (o abierta) y femenina.
Los clubes campeones ganan la plaza para los Europeos de la modalidad en que ganaron el campeonato de España.

Desde hace años la selección Española acude a los eventos internacionales (europeos y mundiales) en las diferentes categorías.

La participación más reciente fue el pasado agosto donde la selección española mixta sub 20 logró la plata en los europeos celebrados en Wroclaw, Polonia.

Actualmente, este y otros hitos como las 7 medallas conseguidas en los Europeos de Beach Ultimate de 2019 celebrados en Portimao, han llevado a España a entrar en el top ten del ranking mundial.
Aun así, esto no es suficiente para que el COnsejo Superior de Deportes, que depende del Ministerio de CUltura y Deporte, reconozca esta modalidad como deportiva en España.
Además existe la modalidad "Iruña" (practicada en el madrileño parque del Retiro), en la que varía el sistema de puntuación ligeramente respecto a la versión federada, ya que en lugar de zonas de ensayo, se puntúa lanzando el disco directamente al árbol elegido como punto de marca (1 punto) o tocando el árbol de marca con el disco (2 puntos).

Ultimate Frisbee Costa Rica https://www.facebook.com/groups/UltimateFrisbeeCostaRica/ esta conformado por jugadores experimentados y novatos , Inicio con estudiantes de la UCR y los que venían de intercambio de Estados Unidos, empezaron hace unos 25 años atrás y algunos de esos jugadores aún se encuentran activos y cultivando el Ultimate Frisbee a los más nuevos e ir subiendo el nivel. 

Actualmente hay Torneos internos INFO en https://www.facebook.com/TorneoUltimateCR/ y el más importante es el Torneo Volcánico en el Tilajari donde llegan jugadores de todo el mundo por 3 días a disfrutar este Torneo Junto al Volcán Arenal ,una especial localidad con ambiente tropical húmedo de la zona de San Carlos óptimo para la practica de este deporte. En el Tercer tiempo del torneo se aprovecha para conocerse, interactuar, conocer y hacer amigos de la comunidad del Ultimate de todo el mundo.

Además hay torneos internos con equipos de todo el país como Strawberry Whites, MIB,Red Horses, Namú,Blue Rex, Lunáticos, Red Moustache. 

Costa Rica a competido Internacionalmente como equipo llamado LOS OSOS PEREZOSOS en países como Panamá, Colombia,Nicaragua, México, USA. 

Algunos de los Jugadores más Activos son: Gus,Mikito,Rommy,Nicky,Posta,SaxmanZu,Nahia,Thala,Xevian,Paola,Posta,Adolfo,Philip,Pablo,Nick,Sammy,Moritz,Ale,Parce,Puerta,Amanda,Eduardo,Victor,Efra, Paul,Jason,Javier, Mariano,Meli, Edgar,Papa, Richard,Carlos,Fabio,Andrés,Tomás,Michael,Miriam,Esteban,Erick,Paula,Victor,Leo,Nelita,Caro,Jose,Karla,Sam,Jonh, Israel,Barbara,Cheo, Fernando, Laura,Edu, entre otros que faltan mencionar. Tenemos jugadores Costarricenses y otros que viven en Costa Rica ,pero son de Colombia, Venezuela, Brasil, USA, Chile, Alemania,Canadá,Bermuda, China.

Los juegos y entrenamientos son

Domingo- Sabanas, Canchas de Béisbol -Estadio Namú de 4-6 p. m.

Lunes -Cancha de Santa Rosa 8-10 p. m.

Jueves- Cancha de Belen 8-10 p. m. 

Sábado - Cancha de Aranjuez FERIA VERDE de 9-12 a. m.

Más Info --- https://www.facebook.com/groups/UltimateFrisbeeCostaRica/

Venezuela fue el primer país hispanoamericano en participar en un campeonato mundial (Toronto 1991), también el primero en llevarse el premio al “espíritu de juego”, adjudicado en solo dos oportunidades. Es el país latinoamericano con más participaciones en campeonatos mundiales, de clubs o de naciones, con un total de siete (7) participaciones. En todas fue el mejor clasificado por la región con excelentes ubicaciones en la tabla general.

Ha exportado jugadores a equipos extranjeros de alta talla, como son Gregory Hoepp, Luis Eduardo Caballero “Liucho”, Pablo Saade, Hector Fulco, Juan Gabriel y Luis Novoa. Ellos integraron las filas del Miami Refugees, 3.º en el campeonato mundial Vancouver 1997 en la categoría "open", y campeón mundial Masters en Finlandia 2004. Mauricio Ortiz, integrante y pieza fundamental de los Vancouver Furious George, campeones nacionales canadienses y mundiales de clubes.

Todos estos jugadores salieron de las canteras de los equipos venezolanos Esperanza Up y Caobos Ultimate Club, urbanizaciones vecinas de la ciudad de Maracay, Estado Aragua. Venezuela cuenta con más de 50 equipos sólo en la categoría open, distribuidos por todo el país. La categoría femenina fue de las primeras en llevar representación al mundial de Hawái. También tiene las categorías junior y coed, ambas con divisiones universitaria o colegial.

La participación venezolana de este deporte es masiva; asiste con sus tambores a los campeonatos internacionales. Escuelas y liceos están desarrollando este deporte, como la U. E. “Santa Bárbara”, de El Tejero, estado Monagas, influenciada por el profesor Alexander Santil.

El ultímate en México empezó a tomar fuerza en los años ochenta en la Ciudad de México, donde se juntaban a jugar “Fútbol Frisbee” personas interesadas en el disco volador. Desde entonces ha crecido bastante el ultimate mexicano, aumentando el número de jugadores en el país y desarrollando clubes y selecciones nacionales que llegaron a participar en varios campeonatos mundiales, panamericanos u otro tipo de torneos internacionales (como el U.S. Open Club Championships o el Torneo Eterna Primavera en Colombia) de gran nivel. En la actualidad, la organización que se encarga de regir este deporte en el país es Ultimate México. UM divide el año en dos temporadas, una mixta (hombres y mujeres jugando en el mismo equipo) y una por ramas (femenil y varonil).

Normalmente, la temporada mixta comienza alrededor de los primeros meses del año y termina por mayo. Los torneos que se realizan durante esta temporada son: primera y segunda fecha del Circuito Nacional de Ultimate (CNU, por sus siglas) durante febrero y marzo, Regionales (regiones norte, centro y sur) durante abril y finalmente el torneo Nacional en el mes de mayo. Cabe notar que esta temporada suele contar con el mayor número de equipos.

Una vez terminada la temporada mixta, en el mes de junio inicia la temporada por ramas femenil y varonil. Esta constituye de tres CNUs, el primero en junio, el segundo en julio y el último en agosto. Después se llevan a cabo los torneos Regionales en septiembre u octubre y termina con el Nacional en octubre también.

Los CNUs pueden ser considerados como la pretemporada antes de los torneos más importantes (Regionales y el Nacional), pero también sirven para que UM pueda realizar un ranking previo a los torneos regionales conforme al desempeño de los equipos participantes. Sin embargo, también son útiles para que los equipos se preparen antes de sus respectivos torneos regionales, poniendo a prueba su físico, estrategia y técnica contra clubes de su propia región y/o de otra región. Además, los CNUs son realizados en distintas partes de la república, uno por cada de las tres regiones puestas por UM, que son norte, centro y sur. 

Por otro lado, los Regionales pueden ser vistos como el verdadero inicio de la temporada, pues es en esta parte de la temporada donde los equipos jugarán por su pase al torneo Nacional, que es el último torneo oficial de la temporada y el más importante.

Adicionalmente, en el mes de septiembre se realiza el Nacional Juniors, para jugadores jóvenes.

En 1998, Corey Tyrrell y Johan Morales unos estudiantes de intercambio de la universidad de los Andes, llegaron desde Minneapolis, Minnesota, empiezan a compartir sus conocimientos de ultímate frisbee con sus compañeros de universidad y vecinos, a tal punto que la universidad abre un curso de ultimate, el cual fue precursor de los primeros equipos del país, con los cuales se realizaron varios torneos internos. El deporte fue tomando cada vez más popularidad, pasó poco tiempo para que la universidad javeriana de Bogotá y la universidad de la sabana comenzaron con su propio proceso, fue tan rápido su desarrollo que este mismo año, patrocinados por la universidad de los Andes de Bogotá, Café Colombia y Pollo Frito Frisby, patrocinaron a un equipo conformado por estudiantes de la universidad de Los Andes, para representar a Colombia, en el campeonato mundial realizado este mismo año en la ciudad de Minneapolis Estados Unidos 

Después de esta experiencia mundialista, comenzó un movimiento constante que hoy en día sigue cogiendo más fuerza, en 1999 surgen equipos fuera de la universidad, y se lleva a cabo el campeonato CERROS en Bogotá, en Medellín este movimiento fue evolucionando de manera paralela, pero la mayor dificultad que se encontraba era la falta de conocimientos técnicos y tácticos acerca del ultímate, por lo cual se practica sin la mayoría de sus reglas y con gestos técnicos diferentes.

En agosto del 2000, se celebra el primer torneo de ultimate de oro, organizado por la universidad EAFIT, en la ciudad de Medellín, con la invitación especial de Mammoth, un equipo de Bogotá que dio cátedra de juego, por su técnica y su táctica, desde este torneo comienza un desarrollo integral de este deporte en las demás ciudades del país, como Ibagué, Cali, Manizales, Neiva y Bucaramanga (Torres, 2009)(salazar,2015)

Colombia suele ser sede de muchos torneos de ultimate; muchas de sus universidades y colegios practican el deporte como “oficial”. Colombia, a nivel mundial, logró la medalla de bronce en el Bejuco 2006, categoría Open, en Boston (Estados Unidos). Su participación más destacada fue en julio de 2010: la selección nacional de ultimate femenino, categoría Junior (sub-20), ganó por primera vez un mundial para Colombia; quedó primera también en el ranking del espíritu de juego, situación que nunca se había presentado en un mundial. 

Otros logros importantes para el ultimate colombiano se dieron en 2012. En el mundial junior, realizado en Dublín (Irlanda), las mujeres repitieron el título de 2010 como campeonas mundiales y alcanzaron el sexto puesto en el espíritu de juego; en la categoría Open fueron subcampeones y ganadores del espíritu de juego. El mismo año, se destacó la participación de Colombia en el mundial absoluto realizado en Japón, donde se hizo presente con 3 equipos (mixto, "open" y femenino). Santiago Montagno y Yina Cartagena se hicieron acreedores del premio a mejores jugadores del mundial en categorías mixto y femenino, respectivamente. En el 2016 los jóvenes sub17 quedaron subcampeones en el torneo europeo (EYUC) realizado en Gent, Bélgica.

En 2019 se realiza el Torneo Eterna Primavera (TEP Colombia) en la ciudad de Medellín donde se concentraron diferentes equipos de distintos países tanto nacionales como internacionales. 

La Liga Ultimate Chile nació en el otoño de 2012, para fomentar la participación de nuevos jugadores, elevar el nivel táctico y de juego, y promover la competitividad.

Actualmente, se juega bajo las reglas de la WFDF 2013, en la modalidad "open" con mínimo dos mujeres en cancha por cada equipo y siete jugadores en la línea. La Liga se realiza en las temporadas de otoño y primavera.
Tiene premiaciones:

Actualmente existen 5 clubes activos en Santiago:

El 

En la región de O'higgins, desde diciembre de 2015, comenzaron a reunirse a aprender y participar en los torneos de Chile, el grupo Keltehues - San Fernando. Es el primer equipo formado en la región y el segundo que se forma fuera de la capital. 

A la vez ya varios equipos han empezado a tener experiencia internacional, tanto en Argentina como en Colombia.

El ultimate también ha llegado a Centroamérica con la presencia de nuevos equipos en varios países del centro del continente americano:

Es en el año 2005 cuando Panamá asiste por primera vez a un torneo internacional: EAFIT de Medellín, Colombia. Desde ese momento se han llevado a cabo numerosos eventos competitivos para mantener activo el Ultimate Frisbee en Panamá. 

Algunos de los torneos y Ligas que se realizan todos los años son: Liga de Verano, Torneo Incidente, Torneo Nacional, Skirt Savage, Torneo de Playa, Torneo del Istmo, entre otros.

En la actualidad, Panamá presenta un rápido nivel de crecimiento en este deporte a nivel regional, gracias al trabajo en conjunto que realizan la Asociación Ultimate Frisbee Panamá (AUFP), los equipos que la integran:

Y la destacada labor que realizan las fundaciones sin fines de lucro, en pro de la difusión y enseñanza del Ultimate Frisbee para los niños y niñas de diferentes edades y clases sociales en todo el territorio nacional:

Panamá se perfila como una promesa del ultimate para el mundo, no solo como futuro anfitrión de los mejores y más competitivos torneos, sino también para demostrar que tiene un alto potencial de juego para exportar.

El Ultimate en Perú llegó alrededor de 2003 por un partido de pickup en Huaraz organizado por el Califorrnia Cafe. En estos mismos fechas existo también un partido en Lima en el colegio Roosevelt. Actualmente existe varias encuentros incluyendo el original encuentro de pickup en Huaraz y un equipo activo con participación Internacional en la ciudad de Lima, "Awankay", con una última participación en el Torneo Espíritu Sudaka 2017, celebrado en Cañuelas, Buenos Aires, Argentina.

El ultimate llegó a Uruguay en el año 2009 y desde entonces se trabaja en la difusión del deporte.

Se realizan 4 torneos anuales:




Actualmente hay cuatro equipos activos que participan de la liga, tres en la ciudad de Montevideo: Snowman, Fuego y Flama y el otro en la ciudad de Florida llamado Fénix.

Hay dos sistemas de reglas casi idénticas en uso común: las reglas de UPA usadas en Norteamérica y las reglas de WFDF usadas en el resto de las partes del mundo. Los dos sistemas de las reglas son iguales en casi todo, con algunas diferencias de menor importancia. Esta sección proporciona una descripción de las reglas que son comunes entre ambos sistemas. Para detalles más específicos vea las páginas oficiales de las organizaciones relevantes enumeradas al final del artículo. La página web de la Federación Española del Disco volador, tiene una traducción de las reglas al español.

El Ultimate es un deporte colectivo sin contacto jugado por dos equipos de siete personas cada uno.

El objetivo del juego es anotar puntos. Un punto es anotado cuando se recibe un pase dentro del área de anotación .

El disco volador es movido únicamente mediante pases o lanzamientos, pues al tirador no le es permitido caminar o correr con el disco.

Cuando un pase es incompleto, interceptado, bloqueado, tirado al suelo o hace contacto con una de las áreas fuera del terreno hay un cambio de posesión.

Para iniciar un partido uno de los dos equipos pone el disco en juego, lanzándolo lo más lejos posible, sin que éste abandone los límites del campo.

En el sitio donde el disco cae al suelo el equipo receptor obtiene la posesión del mismo y se convierte así en el equipo atacante; el otro equipo será por lo tanto el equipo defensor.

Se puede cambiar el jugador si hay una lesión.
El número de jugadores en Ultimate varía en función de la superficie, siendo la más popular sobre hierba, jugado por 7 jugadores en cada equipo. En Ultimate playa o en pista cubierta suele haber 5 jugadores por equipo. En partidos informales, el número de jugadores puede variar dependiendo del tipo de juego. No hay un límite en el número de sustituciones, pero solo se pueden hacer cuando alguno de los equipos anote un punto. Generalmente los equipos suelen tener entre 15 y 20 jugadores en su lista para un torneo importante. Una escasez de jugadores puede forzar a equipos a jugar el juego entero sin sustituciones, una condición conocida como salvaje.

Se juega usando un disco volador de 175 g; para algunos torneos nacionales e internacionales, solamente los discos que han sido aprobados por el cuerpo responsable de ese torneo pueden ser utilizados, y los instrumentos protectores reglamentarios para la participación del juego.

El objetivo del juego es hacer más puntos que el rival antes del final del partido. En ocasiones se establece un límite de puntos (generalmente 17) o de tiempo (generalmente 90 minutos) para el partido, a mitad de lo cual (9 ptos. o 45 minutos) hay un descanso. Se juega en playas y en canchas de hierba, tierra o interiores, solo y exclusivamente con un frisbee. No hay ningún arbitraje; los jugadores son los que se encargan de auto arbitrar el partido.

Los jugadores se alinean en el borde de sus zonas de anotación respectivas, y el equipo que inicia defendiendo realiza el lanzamiento inicial, o el pull, a los jugadores del equipo ofensivo para comenzar el juego. Los "pull" son normalmente lanzamientos largos que flotan, dando a la defensa tiempo de cruzar el campo y llegar a marcar al equipo atacante. El equipo que lanza para comenzar el juego es generalmente decidido mediante un sorteo, eligiendo uno de los lados del disco, y lanzando el disco hacia arriba como si fuera una moneda, el ganador, decide si ataca o defiende. Otra manera popular de realizar este sorteo es tomando un disco en cada equipo y lanzando de la misma manera ambos discos solo que en lugar de elegir una cara del disco se eligen “iguales” o “diferentes”. Si el jugador conjetura correctamente, su equipo consigue decidir si desean comenzar en ataque o defensa.

El disco se puede mover en cualquier dirección mediante pases a un compañero de equipo. El jugador que coge el disco no puede correr con él, solo puede girar en torno al pie de apoyo. Una idea falsa común es que un jugador debe elegir un pie como apoyo antes de que pueda lanzar el disco. De hecho, el jugador puede lanzar el disco antes de parar dentro de los primeros pasos después de que gane la posesión del disco. Un lanzador puede coger su propio lanzamiento si otro jugador toca el disco en el aire.

Sobre la recepción del disco, un jugador tiene diez segundos para pasarlo. Una vez que un marcador esté a 3 m del lanzador, puede iniciar una cuenta. Esto consiste en el llamado del marcador, "stalling" o contando, y después el conteo en intervalos de un segundo hasta diez. Si el lanzador no suelta el disco al primer sonido de la palabra «diez», entonces ocurrirá un cambio de posesión con un chequeo. Si durante el conteo, la defensa cambia de marcadores, el nuevo marcador debe comenzar una nueva cuenta en cero. En el caso de un Conteo, el una vez marcador, ahora jugador ofensivo, no tiene que tomar el disco después del chequeo. El ahora marcador, antes lanzador, le chequea el disco al nuevo lanzador. Si él o ella no quiere tomar el disco, el marcador "chequea" el disco colocándolo en el suelo y llamando “en juego” o “contando”.

Se anota un punto cuando un jugador coge un pase en la zona de anotación del equipo contrario. En la más vieja de las versiones de las reglas, solamente los jugadores ofensivos podrían anotar. Sin embargo, las reglas actuales de USA Ultimate y de WFDF permiten que un equipo defensivo anote interceptando un pase en la zona de anotación que están atacando. Este punto toma el nombre de " Callahan ". Recibe su nombre del jugador de ultimate Henry Callahan.

Después de que se anote un punto, los equipos intercambian extremos. El equipo que acaba de anotar en la zona de anotación donde anotó y el equipo de opuesto en la zona de anotación opuesta. El juego es reiniciado con un pull por el equipo que anota.

Razones para perder la posesión del disco:

El juego se debe detener por una de las siguientes razones:

Una violación ocurre cuando un jugador realiza una acción en contra del sistema de juego pero no inicia el contacto físico. Las violaciones comunes incluyen caminar con el disco ("Travel"), y el picking (que se mueve de una forma para obstruir el movimiento de cualquier jugador en el equipo defensivo).

Se permite a cada equipo poder pedir 2 tiempos muertos por cada medio tiempo del partido. Se considera el medio tiempo cuando uno de los equipos alcanza el marcador intermedio en la cuenta. Puesto que la mayoría de los juegos se juegan a los números impares, el número para media jornada se redondea hacia arriba. Por ejemplo, si el juego está a 15 puntos, la mitad viene cuando un equipo alcanza los 8 puntos.

Se permite a los equipos sustituir a jugadores después de anotación, lesión o tiempo muerto. No hay límite de sustituciones.

Algunas reglas adicionales se han introducido en Estados Unidos y Canadá que pueden sobreponer las reglas estándares y permitir opcionalmente los árbitros llamados observadores o veedores. Un observador puede resolver solamente un conflicto si los jugadores implicados piden su juicio. Aunque, en algunos casos, los observadores tienen la autoridad de hacer llamadas sin ser pedido: la línea del E.G. llama (determinarse fuera de los límites o de las metas) y las llamadas de los off-side (jugadores que cruzan su línea de la zona del final antes de que se haga el lanzamiento). Las malas conductas también las puede definir un observador por violaciones tales como: taunting agresivo, luchar, engaño, etc., y es evocadora del sistema de la tarjeta roja y amarilla; sin embargo, la mala conducta es extremadamente rara y sus ramificaciones no bien definidas. Los observadores también apoyan con hacer cumplir los límites de tiempo para el juego mismo y muchas partes dentro del juego.

La introducción de observadores es, en parte, una tentativa de la UPA de permitir que los juegos funcionen más suavemente y que lleguen a ser visiblemente más amistosos. Debido a la naturaleza del juego y a la naturaleza única del árbitro, los últimos juegos están a menudo conforme a paradas regulares y largas del juego. Este esfuerzo y la intensidad que se ha presentado en los niveles más altos de la competición han conducido a muchos miembros de la comunidad del Ultimate a lamentar de la pérdida del espíritu de juego. Debe ser visto que algunas de las diferencias entre el UPA y las reglas de WFDF reflejan una actitud que diferencia al espíritu.


</doc>
<doc id="41984" url="https://es.wikipedia.org/wiki?curid=41984" title="Colonización europea de América">
Colonización europea de América

La colonización europea de América empezó a finales del siglo XV después de que Cristóbal Colón llegara en 1492 con el apoyo de la Corona de Castilla. A partir de ahí, el Imperio español, el Imperio portugués, y desde comienzos del siglo XVII el Imperio británico (1608), Francia (1609) y los Países Bajos (1625), conquistaron y colonizaron una gran parte del territorio americano.. 

El Imperio español y el Imperio portugués fueron los primeros en realizar la conquista, y se asentaron principalmente en el sur de Norteamérica, Centroamérica y en el área andina de Sudamérica (Imperios azteca, Maya, Muisca e inca, respectivamente). España fue la potencia que mayor presencia colonial logró en América. En el Caribe, dominó sobre todo Cuba, La Española, Puerto Rico, Jamaica, incluyendo la península de Florida dentro de sus posesiones caribeñas. Desde los asentamientos antillanos, logró extenderse por todo el continente americano: en América del Norte llegó a derrotar al Imperio azteca, ubicado en una pequeña parte del actual México, donde fundó ciudades, además de formar una sociedad mestiza con tlaxcaltecas, tarascos, mixtecas, zapotecas y cientos de otras tribus indígenas. A partir de ahí se expandió por América Central, incorporando a la tribu de habla maya, así como a los pipiles, a los niquiranos y a los pueblos de habla ngäbe de Veragua (Panamá). Desde Panamá se emprendió la conquista de la zona andina de América del Sur hasta la zona central del actual Chile. Al mismo tiempo, en busca de la Sierra de la Plata y las tierras del Rey Blanco se fundaron ciudades en el estuario del Plata y sobre las márgenes de los ríos Paraná y Paraguay, siendo Asunción la más importante de ellas.

Portugal se apropió de la mayor parte de la franja costera atlántica de la parte norte de América del Sur, que más tarde originaría el Estado de Brasil. Inglaterra estableció trece colonias en la franja costera atlántica norteamericana, además de en algunas islas caribeñas. Francia ocupó la actual Guayana Francesa en Sudamérica (aún bajo su dominio), Luisiana en el Golfo de México, algunas islas del Caribe, y la región canadiense de Quebec. Holanda estableció colonias en Norteamérica (Nueva Ámsterdam que luego sería Nueva York), norte de América del Sur (Guyana neerlandesa, hoy Surinam) y algunos asentamientos en islas caribeñas (Antillas Neerlandesas y Aruba).

Fue poblada y ocupada en parte de su extensión, muy probablemente por culturas asiáticas que ingresaron al continente por el área de Beringia, en el norte. La población americana, realizó dos revoluciones neolíticas originarias, en Mesoamérica y en Norte Chico (Perú), que expandirían culturas agrocerámicas por todo el continente y generarían dos grandes centros de alta civilización.
Las culturas y civilizaciones en América surgieron y se desarrollaron sin contacto con las culturas y civilizaciones africanas, asiáticas y europeas, por lo que resulta adecuado hablar de la existencia de dos mundos: los llamados "mundo antiguo" (africano, asiático y europeo) y "nuevo mundo" (americano). Las culturas mesoamericanas habían denominado a la tierra que ellos alcanzaron a conocer con los nombres de Abya Yala o Cem Anahuac.

Se sabe de la existencia de los restos de un efímero asentamiento vikingo en el este canadiense.

La exploración y colonización española de América fue con diferencia la más importante de entre todas las europeas. En poco más de un siglo, la Corona de Castilla exploró, conquistó y pobló enormes territorios en el norte, centro y sur del continente americano. Desde Santo Domingo y posteriormente en Cuba se iniciaron grandes expediciones a tierra firme, que exploraron, cartografiaron y luego colonizaron amplios territorios. Tras la conquista de los reinos Azteca e Inca y el sometimiento de otros pueblos, los territorios españoles se organizaron en dos grandes virreinatos inicialmente; el de Nueva España, con capital en la Ciudad de México y el del Perú, gobernado desde Lima. Más tarde, con la expansión y asentamiento en el sur, se crearon los Virreinatos de Nueva Granada y de Río de la Plata. En algunos casos los pueblos aborígenes plantaron resistencia a los conquistadores, entre ellos cabe destacar a los Mapuches del centro de Argentina y Chile, que fueron declarados como nación independiente después de la prolongada Guerra de Arauco que costó el mayor número de vidas españolas en el Nuevo Mundo. Algunas regiones, como la Patagonia, el Gran Chaco, la Amazonía y los desiertos del norte de Mesoamérica no fueron completamente controladas por el Imperio Español.

La colonización fomentó el desarrollo de la agricultura, la minería, y el comercio, este último jurisdicción de la Casa de Contratación con sede en Sevilla. También dio lugar a la fundación de nuevas ciudades, la llegada de pobladores españoles y la introducción de esclavos procedentes del África subsahariana, especialmente en la región del Caribe. El interés de la Corona era tanto material como espiritual. La existencia de oro y plata atrajo a nuevos pobladores y fomentó muchas expediciones en distintas latitudes. Sin embargo, la Corona también impulsó la evangelización de los indígenas con el envío de incontables misioneros de distintas órdenes religiosas a América, los cuales construyeron iglesias, escuelas, hospitales y hasta universidades. La Universidad San Marcos de Lima fue fundada en 1551 por los dominicos y es la más antigua de América. También ese año se creó la Real y Pontificia Universidad de México, la segunda más antigua del continente.

La llegada de Cristóbal Colón a América está considerada como uno de los hechos más importantes de la historia universal por las consecuencias que tuvo y debe relacionarse con el primer viaje alrededor del mundo realizado por la tripulación de Fernando de Magallanes y Juan Sebastián Elcano pocos años después, que abrió paso a la conquista del mundo por parte de Europa.

La llegada de Cristóbal Colón supuso el inicio de la conquista de América, al llevarse a cabo la invasión de las islas de La Española (por los Colón y Nicolás de Ovando), Puerto Rico, Jamaica y Cuba (esta última por Diego Velázquez los monos se apoderaron seguidos por la de los Aztecas (por Hernán Cortés), la del Imperio Inca (por Francisco Pizarro), hasta su fin con las reales cédulas de Felipe II de reconocimiento de la conquista, pero a partir de ese momento comenzaría la llamada «colonización de América», con la intervención de neerlandeses, franceses e ingleses, que a diferencia de españoles, no procuraron evangelizar ni civilizar en el sentido positivo a los indígenas, ni construyendo infraestructura: villas, pueblos, ciudades, caminos, conventos e iglesias, sino que los demás europeos se enfocaron a comerciar con los indígenas, creando para ello puestos comerciales y factorías, especialmente desarrollando el trueque de objetos europeos por pieles de todo tipo de animales, causando una de las primeras catástrofes ecológicas del mundo moderno. 

La Monarquía hispánica por el contrario, procuró recrear las condiciones sociales, de sistema de producción y condiciones de trabajo (pero incorporando a los indígenas como mano de obra forzada) con casi las mismas condiciones políticas, ideológicas, religiosas de la España de su tiempo en los territorios del Nuevo Mundo.

Por otro lado el contagio de las enfermedades que los europeos portaron involuntariamente a América (viruela o tifus) produjo un descenso en la población americana. Igualmente enfermedades de América llegaron a Europa, como la en su día temida sífilis que diezmó la población europea desde las posesiones españolas de Italia en 1494.

Con la asimilación cultural y religiosa vino la introducción del idioma español y del portugués en sus respectivas zonas de influencia. La religión católica pasó a ser oficial. Con el tiempo, se generó por primera vez en la historia una gran población mestiza, tanto genética como culturalmente, por la convivencia de pueblos originarios, africanos subsaharianos y europeos.

La principal riqueza generada por los territorios españoles y colonias portuguesas en América fue la extracción del oro y la plata. En los primeros 150 años de conquista, 17 000 toneladas de plata y unas 200 toneladas de oro arribaron a España.

Otra importante consecuencia de la llegada de los europeos a América, fue la difusión mundial de los alimentos que habían sido desarrollados por las culturas americanas y que hoy se estima constituyen el 75% de los alimentos consumidos por la Humanidad, entre ellos el maíz, la batata, la calabaza, el tomate, el chocolate, el cacahuate o maní, la vainilla, los ajíes, la palta o aguacate, todos estos originarios de Mesoamérica, con justa razón nombrada por los conquistadores «el cuerno de la abundancia», y la papa (o patata como se denomina en algunas partes de España) originaria de los pueblos nativos de los Andes. Otros productos importantes desarrollados en América son la goma y el tabaco.

Por otro lado, los españoles primero y el resto de europeos después llevaran consigo a América animales tan útiles como los caballos, los burros, y demás ganado como las vacas castellanas, los bueyes, las ovejas y animales de granja como los cerdos, las gallinas, los conejos... Así como algunos árboles frutales, la cebada, la avena, el centeno y el trigo de la península ibérica y la caña de azúcar de la islas Canarias o Madeira, que tanto éxito tuvo en el Caribe o el mismísimo café de las colonias portuguesas en África.

La llegada de Colón a América causó también una gran expansión de la navegación y el comercio entre pueblos que se volvió mundial.

Los colonos ingleses en América terminaron organizando a partir de 1776 un nuevo tipo de sociedad a partir de conceptos novedosos como independencia, constitución, federalismo y dieron origen a los Estados Unidos que, en el siglo XX, reemplazaría a Gran Bretaña como potencia mundial dominante.

Lista de Posesiones:



El auge de la colonización portuguesa en América comenzó motivada por razones económicas y estratégicas. Por un lado las económicas a causa de la merma en las ganancias en el comercio con el Oriente y las posibilidades mercantiles del árbol de Brasil, de cuya corteza se producía un tinte rojo usado para teñir textiles. Por el otro estratégicas, por el temor a una invasión española o francesa de su territorio.

En 1530, la corona portuguesa expulsó a los franceses que rondaban las costas de Brasil, ya que eran tierras que pertenecían a Portugal desde 1500.

En 1533, el rey de Portugal, dividió el territorio de Brasil en 15 franjas o capitanías, de 150 millas de ancho cada una, lo que influyó en el carácter privado de la colonización portuguesa. Estas capitanías fueron repartidas u otorgadas a nobles portugueses de forma vitalicia y hereditaria a fin de obtener el mayor rendimiento con el mínimo de costos para la metrópoli. Los nobles que recibieron las mismas se comprometieron a evangelizar a los aborígenes, reclutar colonos, y a desarrollar económicamente la capitanía.

Durante 19 años la administración de las capitanías estuvo a cargo de los nobles, pero, en 1549, el rey nombró un gobernador general o "Capitán mayor" representante del rey que administraría toda la colonia. El propósito de este gobierno era que el rey de Portugal gobernara a Brasil con el asesoramiento del Consejo Ultramarino, además de unificar el gobierno colonial. Sin embargo, aunque se pretendió quitar poderes a los capitanes generales, realmente continuaron dominando la colonia. Ellos, perdieron solamente facultades políticas pero mantuvieron sus privilegios económicos y continuaron con la esclavitud indígena. Aun así, los indígenas no fueron suficientes para la mano de obra por lo que recurrieron al uso de esclavos africanos a partir de [1530].

Lista de Posesiones:


Los procesos de colonización francesa se iniciaron a principios del siglo XVII, siendo la primera colonia viable la de Quebec en 1608, fundada por Samuel de Champlain. Durante el siglo anterior, los franceses habían intentado infructuosamente posesionarse en territorio norteamericano y, a pesar de las dificultades, durante el siglo XVI los barcos pesqueros franceses visitaban con regularidad la costa atlántica del norte del continente. Esto venía motivado principalmente por la demanda de pieles en los mercados europeos y, por ello, los comerciantes franceses iniciaron un lucrativo negocio con los aborígenes.

A principios del siglo XVII, Francia fundó puestos comerciales en Nueva Escocia, Annapolis y Quebec (primera colonia francesa, fundada como parte de una factoría peletera) en la actual Canadá y no dudó en apoyar a sus aliados comerciales, la Confederación Huronesa, en sus guerras con otros pueblos indígenas del este de Norteamérica conocida como las Guerras de los Castores. Otra colonia francesa fue fundada en Montreal, desde donde comenzó la exploración de la zona de los Grandes Lagos y del río Misisipi.

A diferencia de los primeros colonos ingleses, que se quedaron en las costas y utilizaron intermediarios para comerciar con los indígenas, los franceses se adentraron en los bosques con la intención de ampliar las fronteras comerciales y religiosas con los nativos. Por ello, para la primera mitad del siglo XVIII había establecimientos franceses en Detroit, Niágara, Illinois y Nueva Orleans. Estos puestos le proporcionaron a Francia el control de un territorio que se extendía desde Canadá hasta Luisiana.

El gobierno francés también fomento el establecimiento de colonias en el Caribe: en el transcurso del siglo XVII, conquistó las islas de Saint Christopher, Saint Croix, San Bartolomé, Grenada, San Martín, Tortuga, Marie Galánte y la parte oeste de La Española que se llamó Saint Domingue (Haití).

La importancia de las colonias francesas fue básicamente económica y militar. Se encontraban cerca de las principales rutas de navegación españolas, lo que permitía interceptar sus barcos y establecer comercio. Las islas francesas tenían una economía basada en la producción y exportación de azúcar, algodón, cacao y tabaco. Por otro lado la mano de obra esclava también generaba grandes ganancias. Eventualmente las colonias francesas tuvieron mayor población esclava negra que población libre blanca, uno de los factores que favorecieron su prosperidad económica.

Originalmente las instituciones administrativas del régimen colonial francés se asemejaron a las del inglés, ya que los contratos comerciales de colonización otorgaban gran libertad a los "corredores de los bosques", como llamaban a los cazadores de pieles preciosas. Con el tiempo esto cambió, y se nombraron gobernadores que disfrutaron de prerrogativas similares a las capitanías generales del Brasil o los adelantados y primeros gobernadores de las colonias españolas. Sin embargo, para la segunda mitad del siglo XVII se impuso un régimen centralizado; más acorde con las ideas de Luis XIV, rey absolutista francés: Canadá fue convertida en provincia francesa, bajo el mando de un gobernador general supeditado al monarca, y el territorio fue dividido en señoríos que se otorgaron a nobles de la corte. Estos señoríos se subdividían en parroquias bajo la autoridad del cura o párroco y del jefe militar. Numerosos intendentes o funcionarios con poderes militares, fiscales y judiciales mantenían el rígido centralismo de la metrópoli francesa. Ese mismo régimen se impuso en las otras colonias francesas a partir de esta época.

Lista de Posesiones:


Después de la llegada del explorador Juan Cabot (John Cabot) a la península de Labrador, en 1497, la corona inglesa llevó otra expedición encabezada por Sir Walter Raleigh, quien intentó establecer colonias en la llanura oriental en América del norte y fundó fugazmente Virginia, en 1585, en homenaje a la reina Isabel. Aunque la primera colonia o población viable inglesa en América fue la fundación en Virginia de Jamestown, el 14 de mayo de 1607, en ese día, el capitán Edward Maria Wingfield, elegido presidente del Consejo de Gobierno el día anterior, escogió una sección de la isla Jamestown en el río James, unas 40 millas (67 kilómetros) tierra adentro de la costa del Océano Atlántico (fuera de vista de los españoles), como un buen lugar para un asentamiento fortificado.

Las Trece Colonias, un puñado de pueblos fundados por oleadas de inmigrantes ingleses entre los siglos XVII y XVIII, no poseían los rasgos del rígido sistema feudal europeo. Las colonias del noreste, estaban formadas inicialmente por puritanos que fundaron Massachusetts. En las colonias del sureste (Virginia, Carolina y Georgia), donde la población estaba compuesta por grandes y pequeños propietarios y esclavos, se había organizado un sistema de esclavitud, según el que unos 500.000 esclavos negros explotaban plantaciones de tabaco, algodón y azúcar.

Después del triunfo de Inglaterra sobre Francia en la Guerra de los Siete Años (1756-1763) en la que Inglaterra recibió gran ayuda de las colonias económica y militarmente, colaboración a pesar de la cual se crearon nuevos impuestos sobre el azúcar y subieron los ya existentes (sobre todo en el papel timbrado que en aquella época que era muy utilizado en la administración y en los actos notariales).

Al estallar la guerra colonial, los colonos tomaron consenso de su poder, el que usaron para oponerse al alza de impuestos decretada desde Inglaterra. La reyerta degeneró en la Guerra de la Independencia de los Estados Unidos (1776-1783).

Al principio los ejércitos ingleses parecían superiores pero, en 1779 se produjo una escalada en el conflicto: Francia y España decidieron entrar directamente en la guerra, convirtiéndose así la guerra de independencia en un conflicto internacional.

Más tarde Holanda también se une a la coalición formada por España y Francia, con ambiciones de ganar posiciones por el dominio de los mares. En 1783, Gran Bretaña reconocía la independencia.

Lista de Posesiones:


(*):Actualmente en posesión del Reino Unido.

Desde mediados del siglo XVI, comerciantes neerlandeses incursionaron en las colonias españolas de las Antillas, siendo el primer asentamiento la ciudad de Nueva Ámsterdam (actual Nueva York), fundada en 1625, estableciéndose posteriormente en las Antillas Menores (Curazao) y en zonas de Brasil de donde fueron expulsados en 1654. Aunque permanecieron en Surinam y parte de las Guyanas, donde desarrollaron durante los siglos XVII y XVIII una economía de plantación para abastecer de productos tropicales a Holanda. El desarrollo del sistema de plantación en estas colonias fue tan grande, que condujo a una de las mayores concentraciones de esclavos en el siglo XVII y a una feroz lucha de los esclavos por su libertad.

En América del Norte comenzaron su entrada para el 1609, cuando un navegante inglés al servicio de una compañía neerlandesa, navegó por el actual estado de Nueva York. Para 1621, la Compañía Neerlandesa de las Indias Occidentales había establecido puntos comerciales en las cercanías de los ríos Delaware y Connecticut como en Nueva York y Albany.

En cuanto al régimen administrativo implantado por los neerlandeses durante la época colonial se puede mencionar que en sus orígenes fue similar al inglés y al portugués dado el carácter de factorías o establecimientos comerciales que tuvieron sus efímeras colonias. Sin embargo, la colonia que durante varios años lograron establecer en Brasil fue gobernada por un miembro de la familia real. En las islas que conservó se estableció años después, un gobierno más subordinado a la Corona neerlandesa.

Al fin, las colonias holandesas en América fueron efímeras, ya que sus intentos fueron frustrados por ingleses y portugueses, de ahí que sólo permanecieran con algunas posesiones del Caribe. Holanda fundó pequeñas colonias estratégicas para su comercio pero no fueron duraderas.

En su intento por apoderarse de Brasil logró establecerse en Recife y otros puntos de la costa norte; sin embargo los portugueses mantuvieron su límite. En Norteamérica, la compañía Neerlandesa de las Indias Occidentales fundó Nueva Ámsterdam, hoy Nueva York.

Lista de Posesiones:


(*):Actualmente en posesión de Reino de los Países Bajos

La única colonización bajo iniciativa gubernamental que llevaron a cabo los alemanes en América fue un fallido intento de establecer una colonia en la actual Venezuela entre 1528 y 1556. La iniciativa correspondió a la importante familia banquera de los Welser, quienes recibieron las tierras de manos del emperador Carlos V, a su vez rey de España bajo el nombre de Carlos I. El dominio militar de los pueblos indígenas fue obra de Ambrosius Ehringer, conocido como Ambrosio Alfinger por los españoles, quien esperaba encontrar en el territorio la mítica El Dorado. Con el fin de explotar las minas de oro que se esperaba albergaba la zona, llegó a Klein-Venedig un número apreciable de mineros alemanes, a los que se unieron unos 4000 esclavos africanos encargados de cultivar caña de azúcar. Tras varias desavenencias con los españoles los Welser hubieron de ceder finalmente sus derechos y el territorio se integró en el Nuevo Reino de Granada.

Otros intentos fueron las iniciativas de Brandeburgo-Prusia de conseguir colonias en el Caribe en el siglo XVII y XVIII (lo más cercano fue la Isla de Peter) y el ducado de Hanau en conseguir dominios en la ; así como iniciativas del II Reich de conseguir dominios en un "Caribe alemán" para contrarrestar el poder de los emergentes EE. UU.

Por último la Alemania Oriental recibió el Cayo Ernest Thaelmann de Cuba, pero debido a la Reunificación alemana es que no lo reclamaron.

Lista de Posesiones y Pretensiones:


El Duque Fernando I de Médici hizo el único tentativo italiano de crear colonias en América. Para este objetivo el Gran Duque organizó en 1608 una expedición hacia el norte de Brasil, bajo el mando del capitán inglés Thornton.

Desafortunadamente Thornton, a su regreso del viaje preparativo en 1609 (había estado en el Amazonas), encontró muerto Fernando I y todo proyecto quedó anulado por el sucesor Cosimo II.

Sucesivamente, a partir de las primeras décadas del siglo XIX, hubo colonias de italianos en muchas naciones latinoamericanos, aunque nunca fueron controladas directamente por autoridades italianas como posesiones coloniales. La primera colonia de este tipo fue intentada por el italo-venezolano Luigi Castelli, que en 1841 quiso crear una colonia de toscanos en Venezuela para favorecer la agricultura local.

Lista de Pretensiones:


Después de la unión de Dinamarca y Noruega en 1536, la primera conservó las reclamaciones de la segunda sobre Groenlandia, que había poseído colonias en la isla hasta que éstas fueron destruidas a comienzos del siglo XV por un empeoramiento del clima (el comienzo de la "Pequeña Edad de Hielo"). En 1721 se volvieron a fundar colonias en la costa suroeste de Groenlandia y en la actualidad la isla continúa bajo soberanía danesa, aunque provista de autogobierno. Durante el restablecimiento del control danés se envió un gran número de misioneros que convirtieron la población autóctona inuit al Cristianismo.

Más al sur, en las Islas Vírgenes, la Compañía Danesa de las Indias Occidentales ocupó Saint Thomas en 1671, a la que se unieron Saint John en 1718 y Saint Croix en 1733, esta última adquirida a la Corona Francesa. Al contrario que en Groenlandia, la pesca tuvo un papel secundario en las Islas Vírgenes Danesas, donde la mayor parte de la economía giró en torno al cultivo y venta de caña de azúcar, en cuya producción se empleaban grandes cantidades de esclavos africanos. Estos compusieron pronto la mayor parte de la población, al mismo tiempo que los colonos neerlandeses y británicos dejaron en minoría a los daneses como principal nacionalidad europea de las islas. Las islas también sirvieron durante este tiempo como refugio para piratas.

Tras la abolición del comercio de esclavos en 1803 y su posesión en 1848, las islas cayeron en una crisis económica cada vez mayor y perdieron buena parte de su población. Tras varias décadas de negociaciones, Dinamarca vendió finalmente las tres islas a Estados Unidos en 1917.

Lista de Posesiones:


(*):Actualmente en posesión de Dinamarca

Siguiendo el ejemplo de otras potencias europeas, Suecia fundó una serie de pequeñas colonias en América del Norte y el Caribe a partir del siglo XVI. Los colonos procedieron fundamentalmente de las regiones de Savo y Kainuu, en Finlandia (parte de Suecia hasta 1809), por lo que la lengua común de las colonias fue el finés y no el sueco. Entre 1638 y 1655 los suecos establecieron las colonias de Nueva Suecia en el actual Delaware y Nuevo Estocolmo (hoy Bridgeport) y Swedesboro en lo que hoy es Nueva Jersey. Estas efímeras colonias fueron conquistadas finalmente por los neerlandeses, que las unieron al territorio de los Nuevos Países Bajos.

En el Caribe, Suecia controló también de forma efímera las islas de Saint-Barthélemy (1785-1878) y Guadalupe (1813-1814), que fueron cedidas finalmente a Francia, a quien pertenecen actualmente.

Lista de Poseiones:


La colonización rusa de América se desarrolló principalmente en el sur de Alaska (descubierta en 1732 por Ivan Fedorov), donde a finales del siglo XVIII se establecieron factorías peleteras. No obstante, los dominios rusos en América se extendieron también al resto de Alaska y sobre las islas Aleutianas y la costa noroeste de América, llegando por el sur hasta el norte de California, donde despertaron los recelos de los españoles. Estos ocuparon como consecuencia la costa oeste hasta Vancúver, limitando por tanto la influencia rusa a Alaska.

No obstante, la población de la zona nunca superó los 40 000 habitantes bajo gobierno ruso, siendo la gran mayoría de estos indígenas de la etnia aleutiana; algunos de estos, entre los que cabe destacar a Pedro el Aleutiano, se convirtieron al Cristianismo tras la llegada de misioneros desde Rusia. Finalmente, la poca rentabilidad de la colonia (en la que entonces se explotaban exclusivamente pieles animales) y las malas comunicaciones con el resto de Rusia determinaron su venta a Estados Unidos por $7 200 000 el 9 de abril de 1867. Con el dinero obtenido el zar esperaba reparar los daños causados por la Guerra de Crimea. De haber esperado un poco más, quizá sus súbditos hubiesen encontrado los valiosos yacimientos de oro y petróleo entre otros que aguardaban en el subsuelo de la colonia, y que fueron descubiertos por los estadounidenses a partir de 1890.

Lista de Posesiones:


Noruega estuvo unida a Dinamarca en 1536 hasta 1814, pero debido a la anexión sueca de Noruega, este último perdió todas sus colonias las cuales pasaron al Imperio colonial danés.Finalmente Noruega obtuvo su independencia en 1905, en el cual pudo obtener algunas colonias en este período.

Durante la exploración del noruego Otto Sverdrup entre 1898 y 1902 a las Islas Sverdrup. Este los reclamo para Noruega, pero no se mostró mucho interés por parte del gobierno hasta 1928 en el cual el gobierno noruego las empezó a reclamar y en 1930 fueron cedidas al Reino Unido.

Otra reclamación noruega fue Tierra de Erik el Rojo en la isla danesa de Groenlandia entre 1931 y 1933,en el cual la Corte Internacional de Justicia falló a favor de Dinamarca.

Lista de Posesiones:

Islas Sverdrup

Tierra de Erik el Rojo

Lista de Posesiones en la unión con Dinamarca:

Groenlandia

Vinland

Las colonias escocesas se desarrollaron principalmente en las costas de América del Norte (actuales territorios de Estados Unidos y Canadá) y otra en Panamá.

Lista de Posesiones:


Desde el comienzo de la colonización francesa de las Américas , los miembros de los Caballeros de Malta habían sido prominentes en Nueva Francia (debido a que la mayoría de sus integrantes eran aristócratas franceses). En 1635, Isaac de Razilly sugirió al Gran Maestre de la orden, Fra ' Antoine de Paule, que los Hospitalarios establecieran un priorato en Acadia; sin embargo, Paulle rechazó la idea. El siguiente Gran Maestre Juan de Lascaris-Castellar estaba más interesado en los asuntos coloniales. En 1642 o -43 fue nombrado padrino de un converso de Abenaki en Nueva Francia. Montmagny representó a Lascaris en el bautismo.

En 1651 Los Hospitalarios, con la aprobación del Gran Maestro Lascaris, compraron Saint-Christophe , junto con las dependencias de Saint Croix , Saint Barthélemy y Saint Martin. Construyeron fuertes e impresionantes fortificaciones en San Cristóbal junto con iglesias, caminos, un hospital,etc. Fuera de la capital, el gobierno hospitalario era más precario. El asentamiento en Saint Barthélemy sufrió un ataque de los caribes y los que no fueron asesinados abandonaron la isla,por lo que se envió un grupo de 30 hombres para reemplazarlos, que creció a 100 en 1664. En 1657 una rebelión derrocó al régimen hospitalario en St. Croix. Por lo que se envió un nuevo gobernador para restaurar el orden, construir fortificaciones y un monasterio, y comenzar a despejar gran parte de los bosques de la isla para la agricultura de plantaciones.

A principios de la década de 1660, crecía la frustración de que las colonias no estaban obteniendo ganancias. La Orden todavía debía dinero a Francia por la compra inicial de las islas, y en Malta los caballeros debatieron si deberían volver a venderlas, por lo que en 1665 las vendieron a la Compañía francesa de las Indias Occidentales.

El ducado de Curlandia fue el menor de los países europeos que tuvo colonias en América. La colonización curlandesa de América consistió en la creación de una colonia en Tobago, Nueva Curlandia, entre 1654 y 1659 y de nuevo entre 1660 y 1689. Curlandia se estableció como un ducado en 1561, vasallo feudal de la Confederación Polaco-Lituana, en la actual Letonia. Tenía una población de sólo 200 000 habitantes.

Bajo el duque Jacob Kettler, el ducado llegó a su máxima prosperidad. Durante sus viajes por Europa Occidental, Jacob se convirtió en un ferviente seguidor de las ideas mercantilistas. El trabajo en metal y la construcción de buques se desarrollaron. Se establecieron relaciones comerciales no sólo con países vecinos, sino también con Gran Bretaña, Francia, los Países Bajos, Portugal y otros. Kettler estableció una de las mayores flotas mercantes de Europa, con sus principales puertos en Windau (actualmente Ventspils) y Libau (actualmente Liepāja).

Lista de Posesiones:


Respecto a la manera en que los reinos europeos mencionados lograron la conquista de América, hay principalmente dos grupos:

En las zonas colonizadas por los españoles y portugueses se produciría una gran catástrofe demográfica de los indígenas de las zonas en las que se asentaron. La mayor parte de los indígenas murieron por el efecto de varias enfermedades (sobre todo la viruela y en menor medida el sarampión y las paperas, entre otras) contra las cuales no estaban protegidos. Asimismo los escasos conquistadores emprendieron guerras aliados con los pueblos originarios, que llamaron guerras ""justas"" bajo su ideario medieval, para sometimiento de otros pueblos, donde se produjeron gran cantidad de muertos tanto allí como después en las condiciones de trabajo y vida impuestas y de las guerras de conquista sobre las culturas Azteca, Inca, Muisca o Chibcha y los pueblos mapuche, ranquel y het, wichí, pazioca (Diaguita), guaraní, charrúa, de los abipones, chiriguanos, toba, arawak, etc.

Otra vez en las zonas colonizadas por ingleses y franceses se afirman las enfermedades que inicialmente también exterminaron a la mayor parte de los pueblos originarios. Pero esta vez en cambio, más tarde tras su independencia,las excolonias británicas y francesas utilizaron la guerra y las deportaciones masivas en los numerosos tratados con las poblaciones indígenas locales y que sistemáticamente fueron aislados por los gobiernos norteamericanos en las llamadas reservas indias para que no entorpecieran el desarrollo del país.

En el año 2006 un investigador estadounidense estima que en los primeros 130 años de la colonización europea murió el 90-95% de la población total originaria de América. Y justifica que esa fue la razón por la cual las potencias europeas debieron secuestrar millones de hombres y mujeres en África, para llevarlas como esclavos a América y reemplazar la mano de obra fallecida indígena. A pesar de esto "Los científicos descubrieron que, a pesar del hecho de que la colonización ocurrió hace siglos, los sudamericanos todavía conservan la herencia genética de las poblaciones nativas locales."



</doc>
<doc id="41985" url="https://es.wikipedia.org/wiki?curid=41985" title="Vernáculo">
Vernáculo

La palabra vernáculo significa propio del lugar o país de nacimiento de uno, nativo, especialmente cuando se refiere al lenguaje. Así, para la mayoría de los usuarios de la Wikipedia en español, el idioma vernáculo es el español o castellano.

El término es usado en el contexto del lenguaje cuando el idioma usado en un área del conocimiento es distinto a la lengua materna de los hablantes (y a esta última es a la que se le llama vernácula). La lengua «no vernácula» por excelencia fue durante varios siglos el latín, que era la lengua propia de los romanos. Luego tras la caída del imperio romano, mientras lenguas propias se desarrollaban en diferentes partes de lo que había sido el imperio, los escolásticos y la Iglesia siguieron usando el latín para los estudios; de hecho, la única versión autorizada por el Concilio de Trento de la Biblia, la "Vulgata", estaba en latín. La traducción de la Biblia a las lenguas vernáculas fue parte importante de la reforma protestante.

El latín era asimismo usado como la lingua franca de la ciencia hasta mediados o finales del siglo XVIII, cuando fue sustituido por el francés, y luego en algunas áreas por el alemán o el inglés, que es ahora la lengua que predomina en la comunicación científica. El uso del latín subsiste en algunas áreas, especialmente en la taxonomía vegetal, donde no solo los nombres sino también las descripciones oficiales de las especies u otros taxones se siguen publicando obligatoriamente en latín. No ocurre lo mismo en zoología, donde las descripciones nuevas se publican ya en lengua vernácula, aunque los nombres se siguen formando según las reglas del latín.

Para referirse a un nombre en lengua local, se prefiere el adjetivo «vernáculo» a «vulgar», por las connotaciones peyorativas de este último (vulgar es lo relativo al "vulgo").

La palabra proviene del latín "vernaculus", que significa "nacido en la casa de uno", proveniente de "vern", un esclavo nacido en la casa del amo. 


</doc>
<doc id="41986" url="https://es.wikipedia.org/wiki?curid=41986" title="Belleza">
Belleza

Belleza es una noción abstracta ligada a numerosos aspectos de la existencia humana. La belleza se estudia dentro de la disciplina filosófica de la estética, además de otras disciplinas como la historia, la sociología y la psicología social. 
Vulgarmente, la belleza se define como la característica de una cosa que a través de una experiencia sensorial (percepción) procura una sensación de placer o un sentimiento de satisfacción. Proviene de manifestaciones tales como la forma, el aspecto visual, el movimiento y el sonido, aunque también se la asocia, en menor medida, a los sabores y los olores. En esta línea y haciendo hincapié en el aspecto visual, Tomás de Aquino define lo bello como aquello que agrada a la vista ("quae visa placet").
La percepción de la «belleza» a menudo implica la interpretación de alguna entidad que está en equilibrio y armonía con la naturaleza, y puede conducir a sentimientos de atracción y bienestar emocional. Debido a que constituye una experiencia subjetiva, a menudo se dice que «la belleza está en el ojo del observador». Aunque tal relativismo es exagerado y suele asociarce a cosmovisiones y modas, lo concreto es que existen objetos y seres que dan la impresión de belleza ya desde su objetividad natural porque se corresponden con los requisitos naturales del "homo sapiens", por ejemplo: el sabor dulce es preferido al sabor amargo porque el amargo suele corresponder a tóxicos, lo mismo que la fragancia de muchas flores se prefiere naturalmente en gente psíquicamente sana al hedor pútrido.

Podría remontarse a la propia existencia de la humanidad como una de sus cualidades mentales. La escuela pitagórica vio una importante conexión entre las matemáticas y la belleza. En particular, notaron que los objetos que poseen simetría son más llamativos. La arquitectura griega clásica está basada en esta imagen de simetría y proporción. Platón realizó una abstracción del concepto y consideró la belleza una idea, de existencia independiente a la de las cosas bellas. Según la concepción platónica, la belleza en el mundo es visible por todos; no obstante, dicha belleza es tan solo una manifestación de la belleza verdadera, que reside en el alma y a la que solo podremos acceder si nos adentramos en su conocimiento. Consecuentemente, la belleza terrenal es la materialización de la belleza como idea, y toda idea puede convertirse en belleza terrenal por medio de su representación.

La belleza, generalmente, se ha asociado con el bien. De la misma manera, lo contrario de la belleza, que es la fealdad, a menudo se ha relacionado con el mal. A las brujas, por ejemplo, con frecuencia se les atribuyen rasgos físicos desagradables y personalidades repulsivas. Este contraste aparece representado en cuentos como "La bella durmiente", de Charles Perrault. En su obra "Las afinidades electivas," Goethe declara que la belleza humana actúa con mucha mayor fuerza sobre sentidos interiores que sobre los externos, de modo que lo que él contempla está exento del mal y sienta en armonía con él y con el mundo.

La simetría es importante porque da la impresión de que la persona creció con salud, sin defectos visibles. Algunos investigadores han sugerido que rasgos neonatales son intrínsecamente atractivos. La juventud en general se asocia con la belleza.

Hay pruebas que hacen intuir un rostro hermoso en el desarrollo infantil, y que las normas de atractivo son similares en culturas diferentes. El promedio, la simetría y el dimorfismo sexual para determinar la belleza pueden tener una base evolutiva. Los metaanálisis de la investigación empírica indican que las tres características producen atracción tanto en caras masculinas como en femeninas y a través de diferentes culturas. El atractivo facial puede ser una adaptación para la opción de compañero, posiblemente porque la simetría y la ausencia de defectos señalan aspectos importantes de la calidad física del compañero, como la salud. Es probable que estas preferencias sean simplemente instintos.

Los artistas griegos y romanos también tenían el estándar de belleza masculina en la civilización occidental. El romano ideal fue definido como un jefe alto, musculado, de piernas largas, con un pecho lleno de pelo grueso, una alta y amplia frente -un signo de inteligencia-, grandes ojos, una nariz fuerte y perfil perfecto, boca pequeña, y una mandíbula poderosa. Esta combinación de factores produciría una mirada impresionante de hermosa masculinidad. Con las excepciones notables del peso corporal y los estilos de moda, las normas de belleza han sido bastante constantes en el tiempo y el lugar.

En el chino antiguo se escribe un signo que significa "hermoso", pero hoy se combina con otros dos signos que significan "grande" y "oveja". Posiblemente, la oveja grande era representativa de belleza.

La cultura maya consideraba que tener estrabismo era bello, y para conseguirlo, las madres ponían jarras delante de los niños para que crecieran con este defecto; el concepto de belleza puede variar entre culturas.

La caracterización de una persona como «bella», ya sea de forma individual o por consenso de la comunidad, a menudo se basa en una combinación de "belleza interior", que incluye los factores psicológicos —tales como congruencia, elegancia, encanto, gracia, integridad, inteligencia y personalidad —, y "belleza exterior", es decir, atractivo físico, que incluye factores físicos —tales como juventud, medianidad, salud corporal, sensualidad y simetría—.

Comúnmente se mide la belleza externa con base en la opinión general o el consenso de un grupo de personas. Un ejemplo de ello son los concursos de belleza, como el de Miss Universo. La belleza interna, sin embargo, es más difícil de cuantificar. Un importante indicador de la belleza física es la «medianía». Cuando las imágenes de rostros humanos se promedian para formar una imagen compuesta, esta se acerca progresivamente cada vez más a la imagen «ideal» y se percibe como más atractiva. Este fenómeno se notó por primera vez en 1883, cuando Francis Galton, primo de Charles Darwin, construyó imágenes compuestas por superposición de fotografías de vegetarianos y delincuentes en búsqueda de una apariencia característica para cada uno de ellos. Al hacerlo, se percató de que las imágenes compuestas resultantes eran más atractivas en comparación con cualquiera de las fotografías individuales.

La investigación moderna sugiere también que las personas cuyos rasgos faciales son simétricos y poseen la proporción perfecta son más atractivas.

La fealdad es una propiedad de una persona o cosa que no es agradable de mirar. En muchas sociedades el juicio de ser considerado "feo" equivale a ser poco estético, repulsivo u ofensivo. Al igual que su opuesto, la belleza, la fealdad implica un juicio subjetivo y esta por lo menos en parte, en el "ojo del observador", tampoco se debe olvidar la influencia ejercida por la cultura del "observador". Así, la percepción de la fealdad puede ser errónea o miope, como en el cuento de "El patito feo" de Hans Christian Andersen.

A pesar de que la fealdad es normalmente considerada como una característica visible, también puede ser un atributo interno. Por ejemplo, una persona se puede considerar atractiva por fuera pero por dentro irreflexiva y cruel. También es posible estar de "mal humor", que es un estado interno de desagrado temporal.

La fealdad tiene su origen en la consideración del "ojo observador" y de la autoestima que se desarrolla en las personas al ver los estereotipos de hombres y mujeres agradables a nuestros sentidos de percepción.

En la Grecia clásica, uno de los temas principales de la primera mitad de la obra "Fedro" de Platón es la Belleza.



</doc>
<doc id="42009" url="https://es.wikipedia.org/wiki?curid=42009" title="Ley de Benford">
Ley de Benford

La ley de Benford (por el físico Frank Benford), también conocida como la ley del primer dígito, asegura que, en gran variedad de conjuntos de datos numéricos que existen en la vida real, la primera cifra es 1 con mucha más frecuencia que el resto de los números. Además, según crece este primer dígito, más probable es que se encuentre en la primera posición. La ley también asegura cierta frecuencia para los siguientes dígitos.

Esta ley se puede aplicar a muchos hechos relacionados con el mundo natural o con elementos sociales: facturas, artículos en revistas, números de puerta, precios, número de habitantes, tasas de mortalidad, longitud de los ríos, etcétera.

En 1881 el astrónomo y matemático Simon Newcomb observó que las primeras páginas de las tablas de logaritmos estaban manifiestamente más usadas que las finales. Dedujo que aparentemente los dígitos iniciales de los números (al menos los utilizados en su trabajo por quienes habían consultado las tablas) no son equiprobables, sino que el 1 aparece como dígito inicial más frecuente, seguido del 2, etc. hasta el 9 que es el menos frecuente. Mediante un breve e ingenioso razonamiento, aunque sin presentar realmente un argumento formal ni fórmula matemática, Newcomb enunció verbalmente una relación o ley logarítmica: “la ley de probabilidad de la ocurrencia de números es tal que las mantisas de sus logaritmos son equiprobables” de la que derivó probabilidades para el valor del primer dígito más significativo. Sin embargo, no presentó evidencia estadística para esta distribución de los dígitos.

En 1938, y de manera independiente, el físico Frank Benford observó el mismo fenómeno en las tablas de logaritmos y realizó una comprobación empírica sobre un total de 20.229 números agrupados en 20 muestras de gran diversidad: áreas fluviales, constantes y magnitudes físicas y químicas, funciones matemáticas e incluso números de direcciones de personas y tomados de portadas de revistas. A partir de los resultados empíricos Benford postuló una “ley de los números anómalos” para la probabilidad de que el primer dígito sea d. Esta ley logarítmica se conoce como “ley de Benford”.

Diremos que un conjunto de números cumple la ley de Benford si, al escribirlo en notación decimal, la primera cifra significativa es d con probabilidad formula_1. Con primera cifra significativa nos referimos al primer dígito (el más a la izquierda) distinto de 0. 

Podemos formular una ley para las dos primeras cifras: la probabilidad de que las dos primeras cifras no nulas sean igual a "n", con formula_2 es igual a formula_3. De un modo similar se puede enunciar una ley para las tres primeras cifras, para las cuatro primeras cifras, etc.

Para el caso de una sucesión formula_4, se dice que es Benford si cumple con las probabilidades antes descritas a largo plazo, es decir, si formula_5 para cada formula_6.

Las sucesiones surgidas de ecuaciones en recurrencia lineales cumplen (bajo hipótesis bastante generales) la ley de Benford. Esto en particular incluye a las sucesiones del tipo formula_7 (progresiones geométricas), siempre que formula_8 no sea una potencia de 10.

La ley de Benford es la única distribución de probabilidad para el primer dígito que resulta invariante por escalas. Esto significa que si tomamos un conjunto de datos que cumple con la ley de Benford y los multiplicamos a todos por una constante k, los números resultantes siguen verificando la ley. Recíprocamente, si un conjunto de números tiene esa propiedad sobre la aparición del primer dígito (la frecuencia de aparición de cada dígito como primera cifra significativa no cambia al multiplicarlos por una constante) entonces cumple la ley de Benford.

Para saber cuál es el primer dígito de un número n, lo que se hace es dividir a n entre 10 (donde k es el número de cifras que tiene n) y observar en cuál de los intervalos [1,2), [2,3), ..., [9,10) cae ese resultado. Se puede pensar en el resultado de esa división como una variable aleatoria con dominio [1,10). Una propiedad que caracteriza a la ley de Benford es la siguiente: una variable aleatoria X con recorrido [1,10) sigue la ley de Benford si y solo si formula_9 se distribuye uniformemente en [0,1].

La propiedad de invariancia de escala puede dar una explicación intuitiva para el porqué del cumplimiento de la ley de Benford para ciertos tipos de datos. Por ejemplo, si se mide la longitud de todos los ríos y arroyos del mundo, la frecuencia de aparición del primer dígito no debería ser distinta si se mide en metros, yardas, pies u otra medida de longitud. Como la única distribución que cumple con ser invariante respecto al cambio de escala, parecería lógico que sea la ley seguida por estos datos.

El hecho de que la primera cifra sea la cifra 1 con mayor frecuencia que las demás, puede ser entendido si se tiene en cuenta que se comienza a contar desde 1 (1, 2, 3...) hasta llegar al 9, momento en que cada cifra tiene la misma probabilidad. Pero de 10 a 19 solo se tiene como primera cifra el 1, y solo cuando se llega al 99 todos las cifras tendrán la misma probabilidad de nuevo.

Los tipos de muestras que lo cumplen pueden tener orígenes muy diferentes. En general para datos ordinales que en algún momento se acaban (números de casas), la distribución ya es exponencial. Para el número de la última casa de la calle, la distribución también es exponencial, así como para los valores de bolsa, y esto es sabido desde el concepto de exponencial. El asunto del primer número es tomar la distribución de la primera década (1-9), que será exponencial, y montar encima el de la primera década pero de un orden superior (10-90), y así consecutivamente. El conjunto total siempre resultará exponencial.

Por supuesto, existen listas que no cumplen dicha ley, pero parece ser que si se toman términos al azar de varias listas que no cumplan el criterio de Benford en número suficiente para formar otra lista heterogénea, esta si tiende a cumplirla, dada una longitud suficiente.

Mark Nigrini en su tesis doctoral (1992) da una idea de cómo utilizar la ley de Benford para encontrar engaños en las declaraciones al fisco. Continuaría luego escribiendo varios artículos sobre el tema. Esta aplicación fue la que dio "fama" a una ley estadística que hasta ese momento solo se veía como una curiosidad. Aplicaciones similares han sido realizadas para estudiar otras variables económicas. 
Otras aplicaciones han sido propuestas en diversas áreas, incluyendo genética y fraudes en elecciones (aunque la utilidad en este caso fue cuestionada).

Desde 2007 varios equipos y centros de investigación europeos con software, a petición de las grandes firmas auditoras multinacionales miembros de IRM, DGUV, ISACA, IEEE e IIA; se dedicaron a identificar los elementos de dato cuyos valores no cumplen de Ley de Benford mediante métodos y modelos, derivando vertientes con la Teoría del Caos (fractales), Teoría de Valores Extremos EVT, con modelos estocásticos y bayesianos como Sorensen-Dice y desde 2008 utilizando dendrogramas para con esta última aplicar y lanzar el método Carrion-Vasiliou-GG en varios países y sectores (banco, gobierno, servicios, comercio a detalle, registro civil, seguro social, salud comunitaria, etc) como procesos de auditoría forense y detección de sospechas, por ejemplo en el otorgamiento de cédulas de identidad o pasaportes, conteo en proceso electoral, compras o contrataciones púbicas, control anti lavado de activos y de evasión de impuestos, control anti dopaje deportivo entre otros, llegando a alcanzar más del 92% de exactitud contra los falsos positivos.

Posteriormente se sigue aplicando y retomando con las casas de software de auditoria (ACL, IDEA, ARBUTUS, IBM WATSON, PICALO, R, Python, la permanencia del módulo de la Ley de Benford con técnicas que afinen en la detección particular, para justificar en la práctica con los profesionales de auditoria e ingeniería al enfrentar con gran volumen de datos Bigdata como el método Carrion-Vasiliou-GG utilizando Dendrogramas, que motivó a software libre R poner a consideración en 2016 la nueva función getSuspects en su paquete benford.analysis para validación de datos y análisis forense con la Ley de Benford.



</doc>
<doc id="42010" url="https://es.wikipedia.org/wiki?curid=42010" title="Isótopo estable">
Isótopo estable

Un isótopo estable es un nucleido que no es radiactivo (a diferencia de los radionucleidos), por lo que no experimenta de forma espontánea decaimiento radiactivo.

Un elemento químico tiene uno o varios isótopos, de los cuales todos, algunos, o ninguno, pueden ser isótopos estables. Los isótopos que no son estables (radioisótopos), a diferencia de los estables, se desintegran para dar lugar a otros nucleidos emitiendo partículas o radiación electromagnética.

Se conocen unos 2500 nucleidos, de los cuales son estables menos de 300. La representación del número de neutrones (N) frente al número de protones (número atómico, Z) indicándose los isótopos estables se denomina carta de Segrè (diseñada por el físico Emilio Segrè).

Por ejemplo, el tecnecio no tiene ningún isótopo estable, mientras que el estaño tiene diez isótopos estables.

La región de estabilidad definida por esta gráfica es estrecha, cumpliéndose que para números de masa (A) pequeños el número de protones y de neutrones es similar, mientras que conforme aumenta A, la relación N/Z también aumenta (hasta un valor de aproximadamente 1,6).

Los nucleidos que están a la derecha de esta franja de estabilidad tienen demasiados protones para los neutrones que poseen, por lo que los núcleos se rompen por repulsión.

Los nucleidos que están a la izquierda tienen demasiados neutrones para los protones que poseen, produciéndose entonces un proceso de decaimiento que convierte neutrones en protones.

Se verifica que para Z=43, Z=61 o Z≥83 no hay ningún nucleido estable.

La fuerza nuclear fuerte es la encargada de mantener unido el núcleo atómico, a pesar de que la fuerza electromagnética haga que los elementos con el mismo signo de carga eléctrica (los protones, que tienen todos una carga positiva) se repelan. Sin embargo, la fuerza nuclear fuerte tiene un radio de acción muy pequeño, lo que explica que no se encuentren núcleos estables para Z≥83, ya que, al aumentar el número de protones, aumenta el tamaño del núcleo, por lo que la fuerza nuclear fuerte se ve sobrepasada por la fuerza electromagnética, que logra llegar a expulsar algún protón.

Los isótopos estables se emplean en:

La mayor parte de los nucleidos presentes en la naturaleza son estables (actualmente 254; véase la lista al final de este artículo). También son conocidos alrededor de otros 34 nucleidos más que son radiactivos con una vida media (también conocida) lo suficientemente larga como para estar también presentes en la naturaleza (hasta completar un total de 288 nucleidos "naturales"). Si la vida media de un nucleido es comparable o mayor que la edad de la Tierra (4 500 millones de años), una cantidad significativa habrá sobrevivido desde la formación del Sistema Solar, por lo que se denomina nucleido primordial, contribuyendo de ese modo a la composición isotópica natural de cada elemento químico. Radioisótopos presentes primordialmente se detectan fácilmente con vidas medias del orden de 700 millones de años (como por ejemplo el U), aunque algunos isótopos primordiales se han detectado con vidas medias tan cortas en términos relativos como 80 millones de años (por ejemplo, el Pu). Sin embargo, este es el límite actual de detección (el nucleido con la siguiente vida media más corta (niobio-92 con una vida media de 34,7 millones de años, aún no ha sido detectado en la naturaleza).

Muchos radioisótopos de origen natural (unos 51, para un total de alrededor de 339) presentan vidas medias inferiores a 80 millones de años, pero son generados en la actualidad como productos de los procesos de desintegración de nucleidos primordiales (por ejemplo, el radio a partir del uranio) o de reacciones energéticas en curso, como los nucleidos cosmogénicos producidos por el bombardeo de rayos cósmicos sobre los elementos presentes en la Tierra (por ejemplo, el carbono-14 generado a partir del nitrógeno).

Algunos isótopos que se clasifican como estables (es decir, en los que no se ha observado ningún tipo de radiactividad) se predice que tienen vidas medias muy largas (a veces, tan elevadas como 10 años o más). Si la vida media predicha cae en un rango experimentalmente accesible, tales isótopos pueden pasar de la lista de isótopo estables a la categoría radiactivos, una vez que se observa su actividad. Por ejemplo, el bismuto-209 y el tungsteno-180 fueron previamente consideradas como estables, pero en (2003) se detectó que presentaban actividad en partículas alfa. Sin embargo, los nucleidos no cambian su condición de primordiales cuando eventualmente se detecta que son radiactivos.

Se cree que los isótopos más estables presentes en la Tierra se formaron en procesos de nucleosíntesis, ya sea en el Big Bang, o en generaciones de estrellas que precedieron a la formación del Sistema Solar. Sin embargo, algunos isótopos estables también muestran variaciones de abundancia en la tierra como resultado de la desintegración de nucleidos radiactivos de larga vida. Estos subproductos del decaimiento radiactivo se denominan isótopos radiogénicos, con el fin de distinguirlos del grupo mucho mayor de isótopos 'no radiogénicos'.

La denominada isla de estabilidad revela un buen número de átomos de larga vida o incluso estables que son más pesados (y con más protones) que el plomo.

De los elementos químicos conocidos, 80 tienen al menos un nucleido estable. Estos comprenden los primeros 82 elementos desde el hidrógeno al plomo, con dos excepciones, el tecnecio (elemento 43) y prometio (elemento 61), que no tienen ningún isótopo estable. Con fecha de diciembre de 2011, había un total de 254 nucleidos "estables" conocidos. En esta definición, que un nucleido es "estable" significa que nunca se ha observado su decaimiento radiactivo en el contexto natural. Por lo tanto, estos elementos tienen vidas medias demasiado largas como para ser medidas por cualquier medio, sea directo o indirecto.

Los isótopos estables son:

Estos últimos 26 por lo tanto son denominados "elementos monoisotópicos". El número de isótopos estables para los elementos que tienen al menos un isótopo estable representa una media de 254/80 = 3,2, es decir, una media de aproximadamente tres isótopos estables por cada elemento estable.

La estabilidad de los isótopos se ve afectada por la relación entre el número de protones de neutrones de cada núcleo, y también por la presencia de ciertos "números mágicos" de neutrones o protones que representan contornos cerrados y completos desde el punto de vista cuántico. Estas "capas cuánticas" corresponden a un conjunto de niveles de energía dentro del modelo de capas del núcleo completas; como la capa completa de 50 protones para el estaño, que confiere una estabilidad inusual a este nucleido. Como en el caso del estaño, si el número atómico Z de un elemento coincide con un número mágico, entonces su número de isótopos estables tiende a aumentar.

Al igual que en el caso de los electrones, que tienen el estado de energía más bajo cuando se producen en pares en un determinado orbitales, los nucleones (tanto protones como neutrones) muestran un estado de energía más baja cuando su número es par en lugar de impar. Esta estabilidad tiende a impedir la desintegración beta (en dos etapas) de muchos nucleidos par-par en otro nucleido par-par de la misma masa, pero de menor energía (y por supuesto con dos protones más y dos neutrones menos), porque un procedimiento de descomposición de un solo paso tendría que pasar a través de un nucleido impar, con un pico de energía más alto. Esto lleva a un mayor número de nucleidos par-par estables, hasta tres para algunos números de masa, y hasta siete para algunos números atómicos (protones).

Por el contrario, de los 254 isótopos estables conocidos, solo cinco tienen un número impar de protones "y" un número impar de neutrones: hidrógeno-2 (deuterio), litio-6, boro-10, nitrógeno-14, y tántalo-180m. Además, solo cuatro nucleidos radiactivos impar-impar de origen natural tienen una vida media de más de mil millones de años: potasio-40, vanadio-50, lantano-138, y lutecio-176. Los nucleidos primordiales impar-impar son raros porque los núcleos impar-impar son muy inestables con respecto a la desintegración beta, debido a que los subproductos de desintegración resultantes son par-par, y por lo tanto están más fuertemente ligados debido a efectos de pareado nuclear.

Sin embargo, otro efecto de la inestabilidad de un número impar de cualquiera de los tipos de nucleones, es que los elementos impares tienden a tener menos isótopos estables. De los 26 elementos monoisotópicos (es decir, que solo tienen un único isótopo estable), todos menos uno tienen un número atómico impar (la única excepción a ambas reglas es el berilio). Todos estos elementos también tienen un número par de neutrones, con la única excepción que es de nuevo el berilio.

El recuento de los 254 nucleidos estables conocidos incluye el tantalio-180m, ya que a pesar del proceso de desintegración y la inestabilidad que implican de forma automática su condición de "metaestable", estos fenómenos aún no se han podido observar. Todos los isótopos "estables" (estables por observación, no en teoría) son los estados fundamentales de los núcleos, con la excepción de tantalio-180m, que es un isómero nuclear o estado excitado. El estado fundamental de este núcleo en particular (el Ta-180) es radiactivo, con una vida media relativamente corta de 8 horas. En contraste, la descomposición del isómero nuclear excitado es extremadamente improbable debido a las reglas de selección de spin-paridad. Se ha informado mediante observación directa de manera experimental que la vida media del Ta por radiación gamma debe ser superior a 10 años. Tampoco se han observado nunca otros modos posibles de desintegración del Ta (decaimiento beta, captura de electrones y desintegración alfa).

Se espera que una cierta mejora continua de la sensibilidad de los experimentos permitirá descubrir la presencia de signos de radiactividad muy leves (inestabilidad) de algunos isótopos que son considerados estables en la actualidad. Un ejemplo de un descubrimiento reciente: no fue hasta el año 2003 cuando se demostró que el bismuto-209 (el único isótopo de origen natural del bismuto) es muy ligeramente radiactivo. Antes de este descubrimiento, había predicciones teóricas de física nuclear según las que el bismuto-209 debería decaer muy lentamente por la emisión de partículas alfa. Estos cálculos fueron confirmados por las observaciones experimentales realizadas en el año 2003.

Esta es una tabla resumen de la lista de nucleidos. Téngase en cuenta que los números no son exactos y pueden variar ligeramente en el futuro, debido a que se efectúen nuevas detecciones de radiactividad en más nucleidos, o a que determinadas vidas medias se determinen con mayor precisión.

A continuación figura una Tabla Periódica con el número de isótopos estables de cada elemento:

A para la desintegración alfa, B para la desintegración beta, 2B para el decaimiento beta doble, E para la captura de electrones, 2E para la captura de electrones doble, IT para la transición isomérica, SF para la fisión espontánea.

<nowiki>*</nowiki> El tantalio-180m es un "isótopo metaestable" lo que significa que es un isómero nuclear excitado de tántalo-180 (ver: Isótopos de tántalo). Sin embargo, la vida media de este isómero nuclear es tan larga que nunca se ha observado su descomposición, y por lo tanto se comporta como un nucleido primordial "observacionalmente no radiactivo", como un isótopo menor de tantalio. Este es el único caso de un isómero nuclear que tiene una vida media tan larga que nunca se ha observado su decaimiento, por lo que se incluye en esta lista.

<nowiki>**</nowiki> El bismuto-209 se había considerado estable durante mucho tiempo, debido a su inusualmente larga vida media de más de 1,9 10 años, lo que es más de mil millones de veces la edad del universo .




</doc>
<doc id="42011" url="https://es.wikipedia.org/wiki?curid=42011" title="Museo del Prado">
Museo del Prado

El Museo Nacional del Prado, en Madrid, España, es uno de los más importantes del mundo, así como (el decimoctavo en 2013 entre los museos de arte). Singularmente rico en cuadros de maestros europeos de los siglos XVI al XIX, según el historiador del arte e hispanista Jonathan Brown «pocos se atreverían a poner en duda que es el museo más importante del mundo en pintura europea».

Su principal atractivo radica en la amplia presencia de Velázquez, el Greco, Goya (el artista más extensamente representado en el museo),Tiziano, Rubens y el Bosco, de los que posee las mejores y más extensas colecciones que existen a nivel mundial, a lo que hay que sumar destacados conjuntos de autores tan importantes como Murillo, Ribera, Zurbarán, Fra Angelico, Rafael, Veronese, Tintoretto, Patinir, Antonio Moro, Van Dyck o Poussin, por citar solo algunos de los más relevantes.

Alfonso E. Pérez Sánchez, antiguo director de la institución, afirmaba que «representa a los ojos del mundo lo más significativo de nuestra cultura y lo más brillante y perdurable de nuestra historia».

El inventario de bienes artísticos comprendía, a febrero de 2017, más de 35 000 objetos, desglosados en 8045 pinturas, 9561 dibujos, 5973 estampas y 34 matrices de estampación, 971 esculturas (además de 154 fragmentos), 1189 piezas de artes decorativas, 38 armas y armaduras, 2155 medallas y monedas, por encima de 15000 fotografías, 4 libros y 155 mapas.

Por endémicas limitaciones de espacio, el museo exhibía una selección de obras de máxima calidad (unas 900), por lo que era definido como «la mayor concentración de obras maestras por metro cuadrado». Con la ampliación de Rafael Moneo, inaugurada en 2007, se previó que la selección expuesta crecería en un 50 %, con unas 450 obras más. Además, en 2018 se reabrieron las salas del ático norte, tras lo cual el total de piezas expuestas ronda las 1700, y cuando se rehabilite el edificio del Salón de Reinos se colgarán en él entre 250 y 300 pinturas más.

Al igual que otros grandes museos europeos, como el Louvre de París y los Uffizi de Florencia, el Prado debe su origen a la afición coleccionista de las dinastías gobernantes a lo largo de varios siglos. Refleja los gustos personales de los reyes españoles y su red de alianzas y sus enemistades políticas, por lo que es una colección asimétrica; algunos artistas y estilos tienen un repertorio insuperable, y por el contrario otros se hallan representados nula o escasamente. Solo desde el siglo XX se procura, con resultados desiguales, solventar algunas ausencias.

El Prado no es un museo enciclopédico al estilo del Museo del Louvre, el Hermitage, el Metropolitan, la National Gallery de Londres, o incluso (a una escala mucho más reducida) el vecino Museo Thyssen-Bornemisza, que tienen obras de prácticamente todas las escuelas y épocas. Por el contrario, es una colección intensa y distinguida, formada esencialmente por unos pocos reyes aficionados al arte, donde muchas obras fueron creadas por encargo. El fondo procedente de la Colección Real se ha ido complementando con aportaciones posteriores, que apenas han modificado su perfil inicial, puesto que, a diferencia de lo habitual en las pinacotecas nacionales de otros países, los esfuerzos, más que a completar las faltas, han ido dirigidos a reforzar el núcleo esencial. 

Muchos expertos la consideran una colección «de pintores admirados por pintores», enseñanza inagotable para nuevas generaciones de artistas, desde Manet, Mary Cassatt, Renoir, Toulouse-Lautrec y Degas, que visitaron el museo en el siglo XIX, hasta Picasso, Matisse, Dalí, Francis Bacon y Antonio Saura, quien decía: «Este museo no es el más extenso, pero sí el más intenso».

Las escuelas pictóricas de España, Flandes e Italia (sobre todo Venecia) ostentan el protagonismo en el Prado, seguidas por el fondo francés, más limitado si bien con buenos ejemplos de Nicolas Poussin y Claudio de Lorena. La pintura alemana cuenta con un repertorio discontinuo, con cuatro obras maestras de Durero y múltiples retratos de Mengs como principales tesoros. Junto al breve repertorio de pintura británica, circunscrito casi al género del retrato, hay que mencionar la pintura holandesa, una sección no demasiado amplia pero que incluye a Rembrandt.

Aunque sean aspectos menos conocidos, el museo cuenta también con una importante sección de Artes decorativas (que incluye el "Tesoro del Delfín") y con una colección de esculturas, en la que destacan las greco-romanas.

Junto con el Museo Thyssen-Bornemisza y el Museo Nacional Centro de Arte Reina Sofía, el Museo Nacional del Prado forma el llamado "Triángulo del Arte", meca de numerosos turistas de todo el mundo. Esta área se enriquece con otras instituciones cercanas: el Museo Arqueológico Nacional, el Museo Nacional de Artes Decorativas, la Real Academia de Bellas Artes de San Fernando y otros pequeños museos.

El Prado es gobernado por un director (actualmente Miguel Falomir, en el cargo desde el año 2017), asistido por el Real Patronato del Museo. Su funcionamiento se rige por la Ley 46/2003, de 25 de noviembre, reguladora del Museo Nacional del Prado.

El edificio que alberga el Museo del Prado fue concebido inicialmente por José Moñino y Redondo, conde de Floridablanca y primer secretario de Estado del rey Carlos III, como Real Gabinete de Historia Natural, en el marco de una serie de instituciones de carácter científico (pensadas según la nueva mentalidad de la Ilustración) para la reurbanización del paseo llamado "Salón del Prado". Con este fin, Carlos III contó con uno de sus arquitectos predilectos, Juan de Villanueva, autor también del vecino Real Jardín Botánico y del Real Observatorio Astronómico, con los que formaba un conjunto conocido como la "Colina de las Ciencias".

El proyecto arquitectónico de la actual pinacoteca fue aprobado por Carlos III en 1786. Supuso la culminación de la carrera de Villanueva y una de las cimas del Neoclasicismo español, aunque dada la larga duración de las obras y avatares posteriores, el resultado definitivo se apartó un tanto del diseño inicial.

Las obras de construcción se desarrollaron durante los reinados de Carlos III y Carlos IV, quedando el edificio prácticamente finalizado a principios del siglo XIX. Pero la llegada de las tropas francesas a España y la Guerra de la Independencia dejaron su huella en él; se destinó a fines militares (cuartel de caballería) y cayó prácticamente en un estado de ruina; las planchas de plomo de los tejados fueron fundidas para la fabricación de balas.
Gracias únicamente al interés manifestado por Fernando VII y, sobre todo, por su segunda esposa, Isabel de Braganza, se inició, a partir de 1818, la recuperación del edificio, sobre la base de nuevos diseños del propio Villanueva, sustituido a su muerte por su discípulo Antonio López Aguado, con fondos aportados por el rey de su «bolsa personal» o «bolsillo secreto». 

El 19 de noviembre de 1819 se inauguró discretamente el Museo Real de Pinturas, denominación inicial de la institución. Se culminó así un proyecto esbozado ya en tiempos de Carlos IV: la fundación de un museo a la imagen del Louvre de París, que exhibiera las piezas más escogidas de la Colección Real. Contaba entonces con trescientos once cuadros, expuestos en tres salas, todos ellos de pintores de la escuela española, aunque almacenaba muchos más. En años sucesivos se fueron añadiendo nuevas salas, según se iban ejecutando los trabajos de terminación del edificio, y obras de arte.

Inicialmente el museo fue una dependencia más del Patrimonio de la Corona. Por este motivo, se recibieron muchos envíos desde los palacios y monasterios reales, pero también hubo algunas obras que posteriormente fueron expedidas a nuevas ubicaciones. Es el caso de "San Fernando ante la Virgen", de Luca Giordano, que en 1828 fue trasladado al Palacio de El Pardo.

Precisamente la vinculación de la colección a la Corona planteó un grave problema a la muerte de Fernando VII, por su división testamentaria entre Isabel II y su hermana, María Luisa Fernanda. La ejecución de dicho testamento fue aplazada hasta la mayoría de edad de Isabel. Ante la duda de si todos los bienes incluidos en los inventarios podían considerarse de la herencia libre del rey, se nombró una comisión, que en 1844 emitió un informe en el que, si bien reconoció que las disposiciones testamentarias a lo largo de la historia de los monarcas españoles eran demasiado imprecisas y variables como para permitir fijar una tradición, manifestó su oposición en cualquier caso a una división, por ser bienes que en su mayoría pertenecían a la Corona española desde épocas muy remotas. Por ello, propuso como solución:

Informe que fue aprobado por la reina, de conformidad con su madre y su hermana.

Tras el destronamiento en 1868 de Isabel II, el museo pasó a formar parte de los «bienes de la Nación» mediante la Ley de 18 de diciembre de 1869, que abolió el patrimonio de la Corona. Esta ley, no obstante, estableció un conjunto de bienes destinados al uso y servicio del monarca, pero entre ellos no incluyó al museo.

En 1872 se suprimió el Museo de la Trinidad, creado a partir de obras de arte requisadas en virtud de la "Ley de Desamortización" de Mendizábal (1836), y sus fondos fueron traspasados al Prado. Tras esta fusión, el Prado fue renombrado Museo Nacional de Pintura y Escultura, designación que hasta entonces había tenido el Museo de la Trinidad. Esta denominación se mantuvo hasta 1920, año en que por Real Decreto de 14 de mayo recibió oficialmente la actual de Museo Nacional del Prado, que era como se lo conocía habitualmente ya con anterioridad, por haberse construido el edificio en terrenos del antiguo Prado de los Jerónimos.

En las décadas posteriores se fueron integrando al Prado otras colecciones, entre las que destaca especialmente el Museo de Arte Moderno en 1971 —salvo su sección del , que se convertiría posteriormente en la base inicial del Museo Reina Sofía—. Otras colecciones que engrosaron la del Prado fueron las pinturas del Museo-Biblioteca de Ultramar, que habían sido traspasadas al Museo de Arte Moderno tras su disolución en 1908, y parte de la colección del Museo Iconográfico, efímero museo instalado provisionalmente en 1879 en el mismo edificio del Museo del Prado y que una década más tarde fue suprimido, repartiéndose sus fondos entre varios museos, incluido el Prado, bibliotecas y sedes de organismos oficiales. El ingreso de las colecciones de otros museos obligó a la institución a incrementar su política de difusión de fondos, mediante la creación de depósitos estables de obras de arte en otras instituciones públicas y privadas, en España y también en algunos casos en el exterior (embajadas y consulados).

Durante el y buena parte del el Prado vivió una situación de cierta precariedad, pues el Estado le destinó un apoyo y unos recursos insuficientes. Las deficientes medidas de seguridad, con una parte del personal del museo residiendo en él y montones de leña almacenados para las estufas, provocaron la alarma de algunos entendidos. Fue muy sonado el artículo de Mariano de Cavia publicado en 1891 en la portada de "El Liberal", que relataba un incendio que había arrasado el Prado. Solo al final del artículo se desvelaba que el suceso era ficticio; de modo que muchos madrileños se acercaron al lugar alarmados. La falsa noticia sirvió de aldabonazo para la adopción de algunas mejoras de urgencia.
Pero en 1918 sí se descubrió un daño real, el expolio del "Tesoro del Delfín", realizado por un empleado del propio museo, Rafael Coba. La mayoría de las piezas pudieron recuperarse, salvo once, pero treinta y cinco de ellas con desperfectos muy severos, despojadas de muchas de sus guarniciones de piedras y metales preciosos. El suceso, el más grave en la historia de la institución, le costó el puesto a su director, el pintor José Villegas Cordero, y supuso el cierre cautelar de los estudios que los artistas tenían en la pinacoteca. Fue el peor robo que ha sufrido el museo, pero también padeció en 1897 la sustracción de un boceto de Murillo, "Santa Ana enseñando a leer a la Virgen", y en 1961 otro ladrón intentó entrar al edificio por el tejado, aunque cayó al vacío y falleció. Llevaba preparado en un bolsillo un papel en el que dictaba las condiciones para la recuperación de los cuadros.

Una gran parte de las obras maestras del Prado fueron evacuadas durante la Guerra Civil, ante el temor de que los bombardeos del bando franquista destruyesen el edificio y su contenido. También fueron trasladadas cincuenta y cuatro obras del MAM, además de otras procedentes del Monasterio de El Escorial y algunas de particulares, como "La condesa de Chinchón", de Goya, propiedad entonces de los duques de Sueca, o "La condesa de Santovenia", de Eduardo Rosales, perteneciente en aquel momento al duque de la Torre, que la tenía depositada en el MAM. Sufrieron un largo periplo a lo largo de diversos lugares del levante español (Valencia, Cataluña) hasta llegar en tren a Ginebra, donde protagonizaron una exposición que generó interés internacional y atrajo 400.000 visitas, cifra formidable para la época. Tras su clausura se reintegraron al museo después de casi tres años de ausencia.

A pesar de diversas ampliaciones de alcance menor, el Prado sufría limitaciones de espacio, más graves a partir de los años 60, cuando el "boom" turístico disparó el número de visitantes. Poco a poco, la pinacoteca se adaptó a las nuevas exigencias técnicas; el sistema de filtrado y control del aire se instaló en los años 80, coincidiendo con la restauración de muchas pinturas de Velázquez. El tejado, construido con materiales dispares y mediante sucesivos remiendos, sufrió ocasionales goteras, hasta que en 1995 se convocó un concurso restringido para su remodelación integral, ganado por los arquitectos Dionisio Hernández Gil y Rafael Olalquiaga, ejecutándose las obras entre 1996 y 2001.

En 1995, un acuerdo parlamentario suscrito por los dos principales partidos de las Cortes, PP y PSOE, puso al museo a salvo de los vaivenes políticos y proporcionó la calma necesaria para un proceso de modernización, que incluía cambios jurídicos además de la ampliación. Esta, tras un controvertido concurso de ideas, fue adjudicada al arquitecto Rafael Moneo, ya bien conocido en estas lides por sus trabajos en el Museo Nacional de Arte Romano de Mérida y el Museo Thyssen-Bornemisza, entre otros. La ampliación se inauguró en octubre de 2007, tras cinco años de obras.

La dirección del Museo del Prado, desde su fundación hasta el momento presente se desarrolla en tres grandes etapas:

Desde sus inicios a principios del , el Museo del Prado ha contribuido de manera determinante al estudio y difusión de la pintura española, convirtiéndose además en un «museo para los pintores», lugar de aprendizaje e inspiración para las nuevas generaciones de artistas. Eduardo Rosales, Mariano Fortuny, Federico de Madrazo y Francisco Pradilla, entre muchos otros, conformaron un estilo propio bajo el influjo de las obras de Velázquez y Goya del Prado, como lo harían Ignacio Zuloaga y Joaquín Sorolla. Ya en décadas posteriores acudieron al museo dos jóvenes creadores que alcanzarían fama universal: Pablo Picasso y Salvador Dalí. También acudieron a la pinacoteca madrileña muchos de los artistas franceses más innovadores del realismo y del impresionismo, como Gustave Courbet, Léon Bonnat, Carolus-Duran, Pierre-Auguste Renoir, Edgar Degas, Toulouse-Lautrec, Auguste Rodin y Claude Monet; siendo el gran "valedor" del museo en esos años Édouard Manet, cuyos encendidos elogios a Velázquez hubieron de animar a que muchos de sus colegas emprendiesen viaje a Madrid. Entre los que lo hicieron, se cuentan los norteamericanos Mary Cassatt, Sargent y Chase; los dos últimos llegaron a pintar obras bajo influencia directa del maestro sevillano.

En el el magisterio de los tesoros del Prado ha atraído al museo a innumerables creadores; españoles como Gutiérrez Solana, Vázquez Díaz, Antonio Saura, Equipo Crónica, Ramón Gaya, Antonio López, Guillermo Pérez Villalta, Miquel Barceló y Eduardo Arroyo (quien publicó una peculiar guía del Prado en 2011, "Al pie del cañón") y también extranjeros, como Francis Bacon, Lucian Freud, Richard Hamilton, Andy Warhol, Wolf Vostell, Cy Twombly y Cai Guo-Qiang.

Convertido en un «lugar de memoria» y en la cara más amable y prestigiosa de España ante la comunidad internacional, el Museo del Prado es un punto de encuentro para muchas autoridades y demás personalidades de relieve que pasan por Madrid. Desde que a mediados del se generalizaron las visitas diplomáticas y el turismo, el Prado se incluye de manera recurrente en las agendas protocolarias de presidentes de gobierno, monarcas y demás autoridades extranjeras. Se pueden citar las visitas que efectuaron al museo Charles de Gaulle, Eva Perón (1947), Hussein de Jordania, Américo Tomás, Isabel II de Inglaterra, Diana de Gales, Beatriz de Holanda, Margaret Tatcher, François Mitterrand, Sandro Pertini, Helmut Schmidt, Mijail Gorbachov, Jimmy Carter, Henry Kissinger, Barack Obama, Nicolas Sarkozy y Carla Bruni, Kofi Annan y Alberto II de Mónaco. 

Son también numerosas las figuras de la música, el cine y el espectáculo que han visitado el Prado, especialmente desde que España empezó a albergar el rodaje de películas de Hollywood. Entre muchos nombres, destacan Giuseppe Verdi, Ava Gardner, Orson Welles, Anthony Mann, James Stewart, Ingrid Bergman, Lauren Bacall, Charlton Heston, Sophia Loren, Gina Lollobrigida, Anthony Quinn, María Félix, Robert Redford, Martin Scorsese, Woody Allen y Milos Forman. Otras celebridades que han visitado el Prado son Paul McCartney, el líder del grupo The Doors Jim Morrison (1971), Madonna, Michael Jackson y los demás componentes de The Jacksons (1978), Manolo Blahnik, Harrison Ford, Richard Gere, Sigourney Weaver, Kim Basinger, Sharon Stone, Tom Cruise, Johnny Depp, Russell Crowe, Pierce Brosnan, Hugh Jackman, Rob Morrow, Jake Gyllenhaal, Reese Witherspoon, Drew Barrymore, Cameron Diaz y Kirsten Dunst.

En 1960, el actor Vincent Price participó como narrador en una grabación de voz en la que describía 32 obras de arte del Prado. Esta grabación fue publicada en un disco de vinilo, y actualmente está disponible en YouTube. En 1961, Rita Hayworth y Rex Harrison rodaron en el museo algunas escenas de la comedia "El último chantaje" ("The Happy Thieves"), filme que narraba un intento de robo de "Los fusilamientos del 3 de mayo" de Goya. Son múltiples los filmes españoles y extranjeros relacionados, en mayor o menor medida, con el Prado.

La colección de pintura del museo sobrepasa las 8600 obras. De ellas, poco más de 3000 proceden de la Colección Real, algo más de 2000 del Museo de la Trinidad y el resto, más de 3500, del fondo denominado de Nuevas Adquisiciones, en el que se integran también las que realizó el Museo de la Trinidad y las pinturas que recibió en 1971 del Museo de Arte Moderno.

El núcleo original de las colecciones del Museo del Prado procede de la monarquía española. Los fueron coleccionistas de arte durante siglos, y repartieron sus adquisiciones y encargos por las numerosas residencias que acumularon en toda la península ibérica: el Alcázar de Madrid, el Palacio de El Pardo, la Torre de la Parada, el Buen Retiro, La Granja de San Ildefonso, Aranjuez, Palacio de la Zarzuela, así como los monasterios de Yuste y El Escorial.



En la formación de las colecciones del Museo del Prado, el antiguo Museo de la Trinidad representa el segundo gran núcleo, aunque la extensión, variedad y calidad de sus fondos fueran mucho menores que los de la Colección Real. Fue creado este museo, que se denominó "Nacional", como consecuencia de las Leyes de Desamortización de Mendizábal (1835-36), cuya magnitud y extensión creó en muchas personas una lógica preocupación por las obras de arte conservadas en las iglesias, monasterios y conventos suprimidos y convertidos en Bienes Nacionales. Como respuesta a esta inquietud, se decidió reunir en el antiguo convento de la Trinidad Calzada (del que el museo tomó su nombre), sito en la calle Atocha de Madrid y fundado por Felipe II, las obras de arte que guardaban estos institutos religiosos.

A esto se sumaron las colecciones propiedad del infante Sebastián Gabriel de Borbón, incautadas en represalia por su adscripción al bando carlista, aunque posteriormente se le devolvieron, en 1859, y no llegaron a incorporarse al Prado (si bien algunas acabaron ingresando años más tarde en el museo mediante adquisición, como el "Bodegón de caza, hortalizas y frutas", de Sánchez Cotán, comprado en 1991). Además, se fueron añadiendo numerosas adquisiciones de obras de arte contemporáneo realizadas por el Estado en las exposiciones que organizó primero la Academia de San Fernando y luego los certámenes conocidos como Exposiciones Nacionales de Bellas Artes, iniciadas en 1856. Con estos cuantiosos fondos, el museo fue inaugurado en 1838, aunque en condiciones bastante precarias, situación que se mantendrá durante toda la corta vida de este museo. La inmensa mayoría de las obras procedía de la propia provincia de Madrid y el resto de algunas provincias cercanas, como Ávila, Toledo, Segovia, Burgos y Valladolid, y se trataba sobre todo de grandes cuadros de altar u obras pequeñas de tipo devocional, incluyendo también algunas tallas religiosas. Casi todos los autores eran españoles, por lo que se pretendió articular la colección en torno a la creación de la llamada «Escuela española de pintura». A las piezas fundacionales se unieron algunas adquisiciones que el museo realizó más adelante, entre las que destacan "La Anunciación" de época italiana de el Greco y una serie de retratos de Goya.

El museo pronto recibió muchas críticas por el estado de conservación de las obras, por la falta de rigor en su presentación y por la escasa adecuación del espacio a sus usos. Esta situación se vio del todo agravada con la instalación en el mismo edificio del Ministerio de Fomento en 1849. Finalmente, se decidió disolverlo, incorporando sus fondos al Museo del Prado, en el año 1872, provocando en este una situación paradójica, pues si bien la colección de pintura de tipo religioso se vio completada de forma magnífica, por otro lado aumentó aún más la ya de por sí crónica saturación de espacios de que adolecía la institución, lo que dio inicio a la política de depósitos y cesiones que se ha mantenido hasta el presente (al Prado se incorporaron menos de 200 obras, mientras que 650 fueron depositadas en otras instituciones).
Entre los fondos que el extinto museo aportó al Prado destacan las series de la "Vida de San Pedro Mártir y de Santo Domingo de Guzmán", de Pedro Berruguete, procedentes del Real Monasterio de Santo Tomás de Ávila; "El triunfo de San Agustín", la obra más importante de Claudio Coello que tiene el museo, del convento de agustinos de Alcalá de Henares; las pinturas del retablo de las "Cuatro Pascuas" de la iglesia del Convento de San Pedro Mártir de Toledo, de Maíno, quizá la cima creativa de este artista; el retablo del "Colegio de doña María de Aragón", de Madrid, obra fundamental de el Greco; "La Fuente de la Gracia y triunfo de la Iglesia sobre la Sinagoga", del taller de los van Eyck (Monasterio de El Parral —Segovia—), así como otras obras de Goya, Alonso Cano, Francisco Rizi, Ambrosius Benson, Cajés, y representación de casi todos los pintores de la escuela madrileña del siglo XVII.

En el año 2004 se organizó una exposición mostrando los tesoros que, procedentes de este museo, se conservan en el Prado.

El Museo de Arte Moderno (M. A. M., o MAM) fue un Museo Nacional dedicado al arte de los siglos y que existió de 1894 a 1971, año en que sus colecciones de arte decimonónico fueron absorbidas por el Prado, mientras que las del permanecieron en el Museo Español de Arte Contemporáneo (MEAC), antecesor del actual Museo Reina Sofía.

Fue creado jurídicamente mediante un Real Decreto de 4 de agosto de 1894 y se ubicaba en el Palacio de Biblioteca y Museos Nacionales, sede asimismo de la Biblioteca Nacional y del Museo Arqueológico Nacional, ocupando el ángulo suroeste del mismo. La apertura oficial de sus instalaciones tuvo lugar en 1898.
Hasta la constitución del M. A. M. la colección pública de arte contemporáneo español fue responsabilidad también del propio Museo del Prado, que desde su primer catálogo, redactado por Luis Eusebi, se hacía eco de una sección unitaria denominada “Escuelas contemporáneas de España”, y más tarde simultaneó su labor de coleccionismo contemporáneo con el Museo de la Trinidad, que del mismo modo tenía en sus catálogos una “Galería de cuadros contemporáneos”, obras que procedían en este último caso de las adquisiciones que realizaba el Estado en las Exposiciones Nacionales de Bellas Artes así como de algunas donaciones. Sin embargo este último fue disuelto, integrándose en 1872 sus fondos en el Prado. Tras la apertura del Museo de Arte Moderno, el Museo del Prado continuó ingresando pintura del , española y europea, y exhibiéndola en sus salas. Entre los más importantes ingresos de pintura decimonónica ingresados en el Prado mientras el M. A. M. permaneció abierto destaca el conocido legado Ramón de Errazu, compuesto básicamente por pinturas del , que no salió del edificio Villanueva hasta después de 1971.

El Museo de Arte Moderno constaba de dos departamentos, pintura y escultura, marcando un Real Decreto de 26 de octubre de 1895 el límite cronológico en Goya, considerado el “último representante de la antigua pintura española”. Estableciendo un criterio de “carácter universal”, para entroncar el arte español con el de las “naciones cultas”, las colecciones debían comenzar en «la época en que las teorías estéticas puestas en práctica por David o Canova e introducidas en España a principios del presente siglo, cambiaron la corriente del arte nacional», es decir, a partir de José Madrazo y los otros discípulos españoles de David en cuanto a pintura y de José Álvarez Cubero y Antonio Solá en lo referente a la escultura.

Se realizó un único catálogo de las colecciones, el "Catálogo provisional del Museo de Arte Moderno", en 1899, del que se hizo una segunda edición un año más tarde y en el que figuraban seiscientos noventa y tres pinturas y dibujos y ochenta y ocho esculturas. En 1985 se publicó el "Catálogo de las pinturas del siglo XIX" del Museo del Prado, que unificaba las que el propio Museo del Prado había conservado en sus fondos durante la existencia del M. A. M., con las que habían estado allí expuestas, así como los depósitos en otras sedes hechos por ambas instituciones. En él aparecían piezas de cerca de un centenar de autores, figurando movimientos artísticos como el neoclasicismo, el romanticismo y el realismo, pero estando ausentes otros como el impresionismo y el postimpresionismo. La gran mayoría eran de artistas españoles, aunque también había unos pocos ejemplos de la obra de artistas de otros países, como el francés Jean-Louis-Ernest Meissonier, el neerlandés afincado en Gran Bretaña Lawrence Alma-Tadema o el belga Théo van Rysselberghe. Firmado por Joaquín de la Puente, solo se refería a las obras que físicamente se conservaban en el edificio del Casón del Buen Retiro, y no a las obras que todavía entonces quedaban en el de Villanueva ni, sobre todo, a los cuantiosos depósitos fuera del Prado.

Uno de los más graves problemas que sufrió el museo durante toda su existencia fue el de la falta de espacio. Por una parte llegó a atesorar un elevado número de obras, entre las que había muchas pinturas de gran formato, algo muy habitual en el género de la pintura de historia, uno de los más pujantes en la segunda mitad del . Por otro está el hecho de que tuviera que compartir el Palacio de Biblioteca y Museos Nacionales con varias instituciones más: la Biblioteca Nacional, el Museo Arqueológico Nacional, el Museo Nacional de Ciencias Naturales, el Archivo Histórico Nacional, la Junta de Iconografía Nacional y la Sociedad de Amigos del Arte. Ello hizo que le correspondiera solo una pequeña parte del mismo. El resultado fue que se puso en práctica una política de depósito de obras en museos provinciales y organismos administrativos oficiales —que en realidad había iniciado ya el propio Museo del Prado desde la incorporación del Museo de la Trinidad—, acabando la mayoría de los fondos fuera de la propia institución. Este es precisamente el origen de una parte importante del actual "Prado disperso". El único intento que se hizo para solventar esta situación fue la convocatoria en 1933 de un concurso nacional de arquitectura con el fin de dotar al museo de una nueva sede. Se seleccionó el proyecto de Fernando García Mercadal, que planteaba un edificio de una única altura, para cuya ubicación proponía la prolongación del paseo de la Castellana. Sin embargo nunca llegó a construirse.

Desde los inicios del Prado hubo interés por completar las colecciones mediante la adquisición de nuevas obras y de hecho a los pocos meses de inaugurarse, el 5 de abril de 1820, se compró la primera de ellas, "La Trinidad", de José de Ribera, por la que Fernando VII pagó 20 000 reales al pintor Agustín Esteve.

Las adquisiciones del museo han sido muy importantes en cuanto a calidad y número (más de 2300 obras sólo en el apartado de pinturas) y, como se ha señalado, han tenido lugar por diferentes vías. Por un lado, las donaciones, herencias y legados. Entre las obras recibidas gracias a ellos lo más frecuente ha sido siempre la pintura española, y Goya el autor cuya colección más se ha enriquecido de este modo. Por otro, la política de adquisición de obras de arte por parte del Estado, que ha tenido muchas veces como beneficiario al Prado. En este último aspecto es de destacar la modalidad del pago de impuestos mediante obras de arte, o dación, adoptada por la ley del Patrimonio Histórico Español de 1985 y que ha enriquecido las colecciones estatales de forma muy notable. Esta posibilidad, inspirada en la famosa «Ley Malraux» francesa, se podía aplicar en un primer momento al impuesto de sucesiones, extendiéndose a cualquier deuda tributaria en virtud de la Ley de Mecenazgo de 2002.

Las políticas encaminadas al engrandecimiento del Prado han tendido más a reforzar las colecciones existentes que a suplir las faltas. Se han incorporado así obras de Velázquez ("Ferdinando Brandani", antes conocido como "Retrato de hombre, el llamado barbero del Papa"), Goya o Valdés Leal, aunque también algunas de artistas con pobre presencia en las colecciones, como Lucas Cranach el Viejo (una muy destacable "Virgen con el Niño", dación del empresario Juan Abelló en 1988) o Juan de Flandes (su obra maestra "La Crucifixión", pintada para el retablo mayor de la catedral de Palencia, recibida en 2005 también como dación de pago de impuestos, en este caso de la empresa Ferrovial —siete millones de euros—). Otra adquisición en esta línea es la de "La Virgen de la granada", de Fra Angelico, comprada a la Casa de Alba en 2016 por dieciocho millones de euros.

Sería prolijo detallar todas las adquisiciones hechas por el museo en sus casi 200 años de existencia. En cuanto a los legados, el más destacable de épocas recientes fue el hecho por Manuel Villaescusa, en 1991. Con su importe, siete mil millones de pesetas, se compró un grupo de obras entre las que descuellan el "Bodegón de caza, hortalizas y frutas" de Sánchez Cotán, "Ciego tocando la zanfonía" de Georges de La Tour (pintor sin presencia en el museo hasta ese momento), "Una fábula" de el Greco y parte de "La condesa de Chinchón", de Goya, sufragado en su otra parte con fondos estatales. Esta última fue elegida en el año 2000 «"Acquisition of the Year"» («adquisición del año») a nivel mundial por la revista "Apollo" de Londres, como lo sería el cuadro de Fra Angelico en 2016.
Remontándonos en el tiempo, fueron también muy sobresalientes la donación del barón Frédéric Émile d'Erlanger (1881) y los legados de Ramón de Errazu (1904), Pablo Bosch (1915) y Pedro Fernández Durán (1931), así como la donación Cambó (1941) y la de Marius de Zayas (1943). El donativo del banquero belga Emile d'Erlanger consistió en la serie de "Pinturas negras" de la Quinta del Sordo, finca ubicada a orillas del río Manzanares que había pertenecido al propio Goya y que d'Erlanger había adquirido en 1873, haciendo pasar a lienzo las pinturas, que habían sido ejecutadas sobre las paredes de la misma casa. Tras intentar infructuosamente venderlas en París acabó por donarlas al Prado, casi como un modo de deshacerse de ellas, al constatar que, en aquella época, no eran excesivamente apreciadas.

El mexicano de raíces españolas (vasco-navarras y andaluzas) Ramón de Errazu legó en su testamento al museo veinte óleos y cinco acuarelas de artistas del , entre los que destacan Mariano Fortuny y Raimundo Madrazo y los franceses Ernest Meissonier (del que además donó en 1904 el "Retrato de una dama" al Museo de Arte Moderno y que acabó también en el Prado al absorber los fondos decimonónicos de aquel en 1971); y Paul Baudry, del que legó "La perla y la ola", uno de los desnudos más destacados de los que se pintaron en el París del Segundo Imperio, y que fue adquirido por la emperatriz Eugenia de Montijo tras ser expuesto en el Salón de 1863.

La del barcelonés Pablo Bosch fue una de las donaciones más importantes de la historia del museo. Entre las 89 obras procedentes de su colección (por la que había recibido sustanciosas ofertas del extranjero, especialmente de Alemania), destacan las piezas de pintores góticos españoles y de primitivos flamencos, además de una valiosa colección de monedas y medallas.

El legado del madrileño Fernández Durán comprendió una muy nutrida colección de dibujos, 2875, un tercio del total de los que tiene el museo, entre ellos dos debidos a la mano de Miguel Ángel, adscritos, con total seguridad, al maestro en 2003 (antes se atribuían a su escuela); y artes decorativas, así como cerca de un centenar de pinturas, entre ellas la "Virgen con el Niño", de Rogier van der Weyden —también conocida como "Madonna Durán—" y cinco cuadros de Goya, o al menos atribuidos a él, como el célebre "El coloso".

Es también muy destacable la donación de Cambó, que entregó en 1941 siete obras de su colección al Prado: tres de las cuatro tablas de "La historia de Nastagio degli Onesti", de Botticelli; dos pinturas que se atribuían a Taddeo Gaddi y que ahora se asignan al Maestro de la Madonna de la Misericordia; y una de Giovanni dal Ponte ("Las siete artes liberales"), con la intención de suplir las carencias de primitivos italianos de la pinacoteca nacional —la otra era un "Ángel músico" de Melozzo da Forlì, tenida durante años por una imitación, pero que actualmente se considera una copia del —. Aparte, había donado el año anterior al museo el "Bodegón con cacharros" de Francisco de Zurbarán. Por su parte, el mexicano Marius de Zayas donó en 1943 un importante conjunto de siete esculturas antiguas, que incluían una egipcia y otra mesopotámica, estas últimas depositadas desde 1979 en el Museo Arqueológico Nacional.

Otra destacada donación es la efectuada en 2013 por José Luis Várez Fisa (que ya previamente había donado sendas obras en 1970 y 1988), integrada por doce piezas medievales entre las que sobresalen dos tablas de Pedro Berruguete ("San Gregorio Magno y San Jerónimo" y "San Ambrosio y San Agustín") y especialmente la "Virgen de Tobed", tradicionalmente atribuida a Jaume Serra. Como agradecimiento el museo le ha dedicado una sala monográfica (la antigua 52A, que ha pasado a llamarse "Sala Várez Fisa", reabierta en diciembre de 2013), algo que el Prado no hacía desde los legados Ramón de Errazu, Bosch y Fernández Durán. Asimismo fue notable la realizada en 2015 por Plácido Arango, con veinticinco obras, veintiuna pinturas y la serie completa, cuatro litografías, de "Los toros de Burdeos" de Goya —ya en 1991 había donado otros ochenta grabados suyos, una primera edición completa de "Los caprichos—", complementada al año siguiente con una pintura adicional. En ella destacan las dos obras de Pedro de Campaña (Pieter Kempeneer), pintor del que se creía que hasta entonces el Prado no poseía ningún trabajo, "El sueño de San José", de Herrera el Mozo, posiblemente su mejor obra junto con "El triunfo de San Hermenegildo" (también del Prado), y los tres óleos de Zurbarán, en especial "San Francisco en oración".

También ha aportado varias obras importantes la Fundación Amigos del Museo, la última en 2011: "Visita de la reina María Amalia de Sajonia al Arco de Trajano en Benevento", del italiano Antonio Joli, donada por la navarra afincada en México Lucrecia Larregui de Aramburuzabala a través de la Fundación.
Con todo, quizá la obra más famosa que ingresó en el Prado en el fue el "Guernica", legado por su autor e ingresado en las colecciones en 1981. Esta pintura, que por su significado y trascendencia artística, es sin duda la pieza clave del arte contemporáneo, se exhibe hoy en el Museo Reina Sofía. Aparte de los mencionados, ha habido muchos otros legados y donaciones que han enriquecido muy considerablemente las colecciones, entre ellos los de la duquesa viuda de Pastrana, duquesa de Villahermosa, conde de Niebla, conde de Cartagena, duques de Tarifa y marqués de Casa-Torres, por citar sólo algunos de los más importantes.

Mediante suscripción popular, a iniciativa del naviero bilbaíno Horacio Echevarrieta, se adquirió en 1919 "La Virgen del caballero de Montesa", de Paolo de San Leocadio, por 100 000 pesetas (75 000 reunidas con la suscripción y el resto aportado por el Patronato del Museo). Ya en 1910 el pintor José Garnelo había organizado en su revista "Por el arte" una suscripción para adquirir "La Adoración de los Magos" de Hugo van der Goes (el "Retablo de Monforte") y evitar su marcha a Alemania, pero no logró recaudar más que 76 000 pesetas de las 1 268 000 necesarias y finalmente en 1914 la extraordinaria tabla fue vendida al Kaiser-Friedrich-Museum de Berlín (aunque tras la Segunda Guerra Mundial pasó a la Gemäldegalerie). Esta modalidad de adquisición permaneció en el olvido durante casi un siglo, pero en 2018 fue reactivada —rebautizada como «micromecenazgo»—, esta vez con pleno éxito, ya que se cubrió la totalidad del importe requerido merced a la contribución de casi seis mil quinientos donantes, lo que permitió incorporar a la colección una obra del francés Simon Vouet, "Retrato de niña con paloma".

Por la forma de dación (BBVA, veintiséis millones de euros, la de mayor importe realizada hasta ahora en España) entró en el Prado en el año 2006 parte de la "Colección Naseiro" de bodegones españoles, la mejor del mundo en su clase. De las casi cien pinturas de la colección, se incorporaron al museo cuarenta obras de diecinueve pintores diferentes, nueve de los cuales no estaban representados antes con cuadros de este género, y con ellas toda una faceta del arte español que había permanecido poco conocida para el gran público.

En cuanto a las compras con fondos propios y las adscripciones de obras adquiridas por el Estado, figuran piezas de la importancia del "Retrato ecuestre del duque de Lerma", de Rubens (1969) —adquirido para celebrar el sesquicentenario (150º aniversario) del museo—, el "Retrato de Jovellanos" por Goya (1974), el "Retrato de la Marquesa de Santa Cruz", del mismo autor (1986), o el "Retrato de Ferdinando Brandani", de Velázquez (2003). A ellas se sumó en 2010 "El vino de la fiesta de san Martín", una destacada sarga al temple de cola hasta entonces desconocida del pintor Pieter Brueghel el Viejo, adquirida por siete millones de euros (de los que dos y medio fueron aportados por el Prado de sus fondos propios), y en 2012 la tabla gótica "La Oración en el huerto con el donante Luis I de Orleans", comprada directamente por el museo por 850 000 euros. En enero de 2016 se compró una obra maestra de Fra Angelico, "La Virgen de la granada", hasta entonces perteneciente a la colección de la Casa de Alba, por dieciocho millones de euros, diez sufragados por el Ministerio de Educación, Cultura y Deporte, cuatro por la Fundación Amigos del Museo del Prado y otros tantos por el propio museo. Es una de las adquisiciones más relevantes del Prado a lo largo de su historia, por su calidad, perfecto estado de conservación y el refuerzo que supone en la colección del "Quattrocento" italiano. También esta compra ha merecido el reconocimiento de la revista "Apollo", que le otorgó su galardón «"Apollo Acquisition of the Year Award 2016"».

Con casi 4900 piezas, la sección de pintura española no solo es la más completa y nutrida del museo, constituyendo el núcleo central de sus fondos, sino que representa también la colección más importante numérica y cualitativamente que de esta escuela existe en el mundo. Cronológicamente abarca desde murales románicos del hasta los primeros años del .

Sus riquísimas colecciones incluyen pintura gótica, desde maestros anónimos a autores como Juan Rodríguez de Toledo, Nicolás Francés, Pedro Berruguete y los hispano flamencos Diego de la Cruz, Juan de Flandes y Fernando Gallego y en el ámbito de la Corona de Aragón Jaume Serra, Lluís Borrassà, Jaume Huguet, Pere Lembrí, Miguel Ximénez, Bartolomé Bermejo, Martín Bernat, Rodrigo y Francisco de Osona, Joan Reixach o Jacomart; el Renacimiento español, representado por Pedro Machuca, Alonso Berruguete, Juan de Juanes, Fernando Yáñez de la Almedina, o Juan Correa de Vivar; y el manierismo, con Luis de Morales, Blas de Prado, Pedro de Campaña y el protagonismo absoluto de el Greco, del que se exhibe el grupo de obras más numeroso de cuantos existen, incluyendo algunas de las más relevantes.

El período de mayor brillantez de la pintura española, el Barroco, cuenta con excelentes ejemplos de prácticamente todos los autores y géneros del momento, como Zurbarán, Ribera, Murillo, Juan de Valdés Leal, Maíno, Alonso Cano, Carreño, Ribalta, José Antolínez, Antonio de Pereda, Francisco Rizi, Herrera el Mozo, Juan Sánchez Cotán, Claudio Coello y, por encima de todos ellos, el gran maestro de la pintura hispana, Velázquez, el «rey» del museo en palabras del crítico francés del XIX Athanase-Louis Torterat, conde Clément de Ris, del que se expone una colección sin parangón en el mundo, integrada por la mayoría de sus obras maestras.

Del , destaca la extensísima colección de Goya, que comprende todos los períodos y facetas de su arte, con un total de ciento treinta y dos pinturas, algunas de autoría discutida, a las que suman otras cuatro recibidas en depósito. Relevantes son también los bodegones de Luis Meléndez y la variada colección de Luis Paret, considerado el mejor pintor español de estilo rococó.

La colección de pintura del está delimitada por las figuras de Goya y Picasso. Con algunas excepciones, se considera que forman parte de ella las obras de los autores fallecidos a partir de 1828, año de la muerte del fuendetodino, mientras que las de aquellos nacidos a partir de 1881, año del alumbramiento del malagueño, fueron adscritas al MNCARS por el Real Decreto 410/1995, de 17 de marzo. El "Catálogo general de pintura del siglo XIX en el Museo del Prado", de 2015, recogía un total de dos mil seiscientos noventa registros, incluidos los exiguos fondos de escuelas extranjeras.

El proceso de puesta en valor de esta colección culminó con la apertura en octubre de 2009 de doce salas en el edificio Villanueva, una de ellas rotatoria (la 60, designada como «Sala de presentación de colecciones del siglo XIX»), que acogen 176 piezas de este periodo (incluidas algunas de artistas de otros países). Aunque es común que se repita que se muestran por primera vez desde 1896 integradas con el resto de la colección, lo cierto es que desde 1905, en que se expusieron por primera vez las obras del legado Ramón de Errazu —tras esa donación otras más—, el Prado siempre exhibió algunas pinturas españolas del en el contexto de su colección. Junto a Goya se expuso tradicionalmente obra de Vicente López y existió una sala destinada a pinturas de la familia Madrazo (José, Federico y Raimundo), Esquivel (Antonio María) y Ferrant, entre otros. Solo durante doce años, los que mediaron entre el cierre del Casón y la apertura de las salas en el Edificio Villanueva (1997-2009), la pintura del quedó invisible en las salas del Prado (con la excepción de la exposición inaugural de la ampliación, en 2007).

Entre las últimas adquisiciones que han enriquecido la colección española destacan las compras de "La condesa de Chinchón", de Goya (2000), y "Ferdinando Brandani", de Velázquez (2003). Por otro lado, las dos mayores debilidades de la colección, la pintura medieval y los bodegones, han sido paliadas en parte en los últimos tiempos, especialmente la segunda, gracias principalmente en el caso de la primera a la donación Várez Fisa (2013) (a la que se une el depósito por el duque del Infantado del retablo de los "Gozos de Santa María"), y la otra a la compra parcial de la colección Naseiro (2006), a la que se suman algunas adquisiciones puntuales que han permitido incorporar a importantes bodegonistas hasta entonces ausentes, como la del "Bodegón de caza, hortalizas y frutas", de Sánchez Cotán (1991), y la del "Bodegón con granada y uvas", de Juan de Zurbarán (2015), así como reforzar subgéneros pobremente representados, como el de los bodegones con figuras del siglo XVII ("Vendedores de frutas", de Jerónimo Jacinto Espinosa (2008), "La gallinera", de Alejandro de Loarte (2011), o "Pícaro de cocina", de Francisco López Caro (2015, donación Arango)).

La colección de pintura italiana consta de más de mil obras y es sin duda uno de los grandes atractivos del museo, aun cuando adolezca de ciertas lagunas, sobre todo en lo referido a obras anteriores al . A pesar de que ya en tiempos de Juan II de Castilla la literatura italiana tuvo gran influencia en España, las novedades en el campo de las artes plásticas llegaron con retraso, siendo su presencia hasta el muy escasa. Ello fue debido en gran parte a la predilección tanto del propio rey como de su hija, Isabel la Católica, por la pintura flamenca, y es la causa de que la colección de "primitivos italianos" del museo sea muy reducida.
Son muy escasas, de este modo, las obras correspondientes al "Trecento", y al "Quattrocento", aunque buena parte de ellas son de gran calidad. El núcleo más importante lo componen las obras adquiridas a lo largo de la historia de la institución, desde "La Anunciación" de Fra Angelico, que el entonces director del Prado, Federico de Madrazo, consiguió en 1861 que el Monasterio de las Descalzas Reales cediera al museo a cambio de una copia ejecutada por él mismo; hasta las incorporadas en fechas recientes. La colección experimentó un notable incremento gracias a la donación Cambó, que incluyó dos tablillas dedicadas a la vida de san Eloy del Maestro de la Madonna della Misericordia (que Cambó adquirió como originales de Taddeo Gaddi), otra de Giovanni dal Ponte y, sobre todo, tres de las cuatro tablas de "La historia de Nastagio degli Onesti" de Botticelli.

El otro núcleo, mucho más reducido, corresponde a las obras procedentes de la Colección Real española, donde sobresale el "Tránsito de la Virgen" de Andrea Mantegna. El resto de obras corresponden a autores como Francesco Traini, de quien es una "Virgen con el Niño", la cual era el único ejemplo de pintura italiana anterior a 1450 dentro de la Colección Real.

A pesar de que la colección del museo ofrece un panorama limitado del arte italiano anterior a 1500, sí se precia de poseer auténticas obras maestras de tan importante capítulo de la Historia del Arte. Aparte de las obras maestras de Mantegna, Botticelli, o el excelente "Cristo muerto, sostenido por un ángel" de Antonello da Messina, adquirido en 1965, el conjunto más valioso lo constituyen las tres obras de Fra Angelico: una pequeña predela de un retablo dedicado a la vida de san Antonio Abad, y dos de sus obras maestras, "La Anunciación" y "La Virgen de la granada". La incorporación de esta última en 2016 reforzó de forma sobresaliente el conjunto de obras del "Quattrocento" italiano y situó a la institución como un punto importante para el conocimiento de la obra del pintor. Asimismo, hay sendas obras atribuidas a Amico Aspertini y su hermano Guido ("El rapto de las sabinas" y "La continencia de Escipión"), un tríptico de Antoniazzo Romano procedente del Museo de la Trinidad, y una "Virgen con el Niño entre dos santas" de Giovanni Bellini, aunque con amplia participación de taller.

La pintura del "Cinquecento" inicia el gran periodo de la pintura italiana en el Prado con algunas obras capitales de Rafael y su taller, especialmente de Giulio Romano y Giovanni Francesco Penni. El museo es una de las instituciones con mayor número de pinturas de los últimos años de producción del maestro, incluyendo obras tan relevantes como la "Virgen del pez", "El Pasmo de Sicilia", o la "Sagrada Familia con san Juan", llamada «la Perla» por Felipe IV, quien la consideró la pintura más preciada de su colección. La nutrida colección de obras de este artista (ocho pinturas, entre las autógrafas y las realizadas en mayor o menor parte por sus discípulos) da cuenta del prestigio del que disfrutaba en España, donde sus obras eran enormemente apreciadas y demandadas. Una de las lagunas más importantes del Prado es la carencia de ejemplos autógrafos de Leonardo da Vinci. Se cuenta con dos pinturas de su seguidor Bernardino Luini, aunque sin duda la obra más cercana al maestro es la singular copia de la "Gioconda". Oculto su fondo de paisaje durante décadas por un repinte negro, en 2012, tras su estudio y restauración, se determinó que había sido realizada de forma paralela y simultánea al original por uno de los discípulos del maestro. Otros nombres señalados de la plástica renacentista presentes con obras importantes son Sebastiano del Piombo, Dosso Dossi, Correggio, Andrea del Sarto y Federico Barocci, autores en el tránsito al Manierismo, apenas representado por un puñado de obras de Parmigianino, Bronzino o Francesco Salviati.
Mención aparte merece la pintura veneciana del , con amplísima presencia hasta el punto de constituir la mejor colección de la misma fuera de Italia. El artista central de la escuela, Tiziano, era el pintor favorito de Carlos V y Felipe II y, aunque varias de sus obras permanecen en el Monasterio de El Escorial, la representación en el Prado del cadorino supera las treinta pinturas. Para los primeros Habsburgo compuso algunas de sus obras maestras, como el "Retrato ecuestre de Carlos V en Mühlberg" o las "poesie" (poesías). Esta serie constaba de seis obras, aunque hubo otras dos que aparentemente nunca fueron enviadas, "Medea y Jasón" y "Acteón destrozado por los perros". De ellas, la única que sigue en España es la del Prado, "Venus y Adonis". Otros maestros como Tintoretto, Veronés, Lorenzo Lotto, Bonifazio Veronese, Palma el Joven, Moroni, Bernardino Licinio, Jacopo Bassano y sus hijos Francesco y Leandro, e incluso algunos precursores como Vincenzo Catena, están asimismo representados en la colección.
La pintura barroca italiana constituye uno de los núcleos más compactos del Prado, por la variedad de artistas y la calidad de las obras que podemos admirar. Las dos grandes tendencias pictóricas de la época, el "tenebrismo" y el "clasicismo boloñés", cuentan con buenas colecciones, en cuanto a la primera comenzando por el iniciador Caravaggio ("David vencedor de Goliat") y sus seguidores, como Orazio Gentileschi ("Moisés salvado de las aguas"), su hija Artemisia Gentileschi, Giovanni Battista Caracciolo (conocido como "Battistello"), Giovanni Serodine o Bernardo Cavallino. La presencia del clasicismo boloñés es asimismo nutrida, con cuadros de Annibale Carracci ("Venus, Adonis y Cupido", "Asunción de María"), Domenichino, Guido Reni ("Hipómenes y Atalanta"), Guercino, Giulio Cesare Procaccini, Alessandro Turchi y Giovanni Lanfranco. Incluso la tendencia del barroco decorativo cuenta con un singular ejemplo de Pietro da Cortona ("La Natividad", para cuyo soporte utilizó una pasta vítrea llamada venturina y que ha sido recientemente restaurada) y el excelente grupo de obras de Luca Giordano, que trabajó en España para el rey Carlos II. A todo lo señalado cabe añadir los ejemplos de otros importantes autores barrocos, como Francesco Furini, Salvatore Rosa, Orazio Borgianni, Michelangelo Cerquozzi, Mattia Preti, Andrea Sacchi, Carlo Maratta, Massimo Stanzione, Andrea Vaccaro, Bernardo Strozzi o Alessandro Magnasco.

La figura de Giambattista Tiepolo cierra el sugestivo capítulo de la pintura italiana en el Prado, junto a otros artistas que como él llegaron a España para decorar el nuevo Palacio Real de Madrid, como su hijo Giandomenico y Corrado Giaquinto. Todos ellos cuentan con una estimable, en calidad y cantidad, representación. Tristemente, faltan ejemplos de "vedutistas" como Canaletto y Francesco Guardi, bien representados en el vecino Museo Thyssen-Bornemisza, aunque el Prado sí posee ejemplos de Antonio Joli, Gaspare Vanvitelli (Caspar van Wittel) y Francesco Battaglioli. Y dentro del campo del "capricho arquitectónico" ("vedute ideate"), un grupo de pinturas de Giovanni Paolo Pannini así como una de Leonardo Coccorante.

La sección de pintura flamenca es la tercera del museo, tanto por cantidad (más de mil obras), como por calidad, solo por detrás de la española y casi al nivel de la italiana. Al igual que en el caso de ambas, gran parte de sus fondos proviene de la Colección Real. Comprende por un lado representantes de la pintura neerlandesa temprana, los mal llamados "primitivos flamencos", como Robert Campin (con cuatro obras de las aproximadamente veinte que se le atribuyen), Weyden ("El descendimiento de la cruz", "Madonna Durán"), Dieric Bouts, Petrus Christus y Hans Memling (tríptico de "La Adoración de los Magos"). También hay que señalar "La Fuente de la Gracia", realizada en el entorno de Jan van Eyck. El museo exhibe además la mejor colección a nivel mundial de el Bosco, que incluye tres de sus obras capitales: los trípticos de "El jardín de las delicias", "El carro de heno" y la "Adoración de los Magos". Proceden de la colección personal de Felipe II, tan aficionado a este pintor, que ordenó comprar cuantas obras suyas se pudiese.

Igualmente sobresalientes son las pinturas de Joachim Patinir, Marinus van Reymerswaele y Anthonis Mor van Dashorst (Antonio Moro) (las mayores colecciones de estos artistas), así como las dos de Pieter Brueghel el Viejo ("El triunfo de la Muerte" y "El vino de la fiesta de san Martín"), y otras de Gerard David, Jan Gossaert, Ambrosius Benson, Jan van Scorel, Quentin Metsys, Pieter Coecke van Aelst y Michel Coxcie.

La colección del supera las seiscientas obras, lo que hace de ella una de las mejores colecciones de pintura barroca flamenca del mundo, a la que tan solo se puede comparar quizá la del Museo de Historia del Arte de Viena. El Prado posee la más importante colección de Rubens, con unas noventa pinturas (la cifra concreta varía según las fuentes, puesto que la autoría de algunas de las obras está en discusión) y algunos dibujos. Felipe IV le encargó decenas de cuadros para decorar sus palacios y además fue el principal comprador en la almoneda realizada a su muerte con las obras que poseía en su estudio. El hecho de que muchas de las pinturas del Prado fueran un encargo directo de quien era el rey de uno de los países más poderosos de Europa en aquella época (además de su propio soberano) ha redundado por otra parte en que la ejecución de las mismas sea de una gran calidad media, contándose un buen número de ellas entre sus obras maestras. El museo tiene también más de veinticinco ejemplos de van Dyck, varios de Jacob Jordaens (incluyendo su "Autorretrato con su familia"), cuatro de los escasos bodegones de Clara Peeters y la serie de "Los Cinco Sentidos" pintada en colaboración por Jan Brueghel el Viejo (Brueghel de Velours) y Rubens. Los arropa un generoso muestrario de paisajes, escenas de caza, bodegones y demás temas de género de autores como Peter Snayers, Sebastian Vrancx, Joos de Momper, Alexander Adriaenssen, Osias Beert, Paul de Vos, Frans Snyders y Jan Fyt, así como un conjunto (acaso el mayor del mundo) de David Teniers el Joven, del que se exponen cerca de veinticinco obras. En cambio, la representación de los caravaggistas flamencos es muy corta, apenas dos obras de Theodoor Rombouts y sendas de Louis Finson, o Ludovicus Finsonius, Nicolas Régnier, Gerard Seghers y Adam de Coster.

Es la cuarta escuela nacional más extensamente representada, con más de trescientas pinturas, aunque a mucha distancia de las tres anteriores. Como en el caso italiano y flamenco, aquí las circunstancias históricas también ejercieron gran influencia, y la casi permanente beligerancia entre España y Francia a lo largo de los siglos y restringió los intercambios artísticos entre ambos países, a lo que se unieron las diferencias de gustos imperantes en cada uno de ellos.

Apenas existen ejemplos anteriores a 1600, aunque entre ellos figura una destacada tabla fechada entre 1405 y 1408, de autor anónimo, tal vez Colart de Laon, adquirida en mayo de 2012: "La Oración en el huerto con el donante Luis I de Orleans". Los siglos y cuentan por su parte con obras magistrales de Poussin, como "El Triunfo de David" y "El Parnaso"; de Claudio de Lorena se conserva un conjunto de paisajes sobresalientes, destacando también tres pinturas de Simon Vouet y cuatro de Sébastien Bourdon. El tenebrismo cuenta con ejemplos llamativos de Georges de La Tour, Nicolas Tournier y Valentin de Boulogne. Retratistas de los Borbones españoles, como Jean Ranc, Louis-Michel van Loo y Michel-Ange Houasse, así como de los Borbones franceses, como Hyacinthe Rigaud y Antoine-François Callet, tienen presencia junto a maestros rococós como Watteau y Boucher, y los pintores de paisajes Claude Joseph Vernet y Jean Pillement.

La colección de pintura francesa del Museo del Prado es sin duda uno de los aspectos de las colecciones menos estudiados hasta ahora. Existe un importante número de obras neoclásicas, entre ellas una de Merry-Joseph Blondel y varias de pintores por ahora desconocidos del entorno de J.-L. David que han de ofrecer en el futuro gratas sorpresas, además de una apreciable cantidad de ejemplos de los discípulos franceses de J. A. D. Ingres. Entre los fondos de la primera mitad del se incluye también un retrato de Carlos X de Francia por François Gérard. Hay asimismo obras de gran interés más modernas, de la segunda mitad del siglo, como los dos retratos femeninos de Ernest Meissonier, algo muy raro dentro de su producción, una famosa pintura de desnudo de Paul Baudry, "La perla y la ola", que perteneció a la emperatriz Eugenia de Montijo, un retrato de Félix-Henri Giacomotti, dos de Carolus-Duran, cuatro óleos de Léon Bonnat y un "Paisaje" atribuido a Alfred Sisley. Y, ya de principios del , un retrato de Paul Chabas y un paisaje de Henri Martin.

Pocas son las obras de pintura alemana conservadas en el Prado e históricamente en España en general (hasta la llegada de la colección Thyssen). A pesar de la fuerte relación de los Habsburgos españoles con el Sacro Imperio Romano Germánico, la mayoría de los monarcas hispanos se decantaron por otro tipo de pintura. A causa de ello esta colección es reducida en número, aunque de gran calidad.

Destaca sobre todo el grupo de cuatro obras maestras de Alberto Durero, entre ellas su icónico "Autorretrato con guantes" de 1498 y la pareja de tablas de "Adán y Eva". Del resto de obras, descuellan una "Virgen con el Niño Jesús, san Juanito y ángeles" y dos curiosas escenas de cacería, las tres de la mano de Lucas Cranach el Viejo (además, en 2001 se adquirió un "Retrato de Juan Federico "el Magnánimo"" que se creía autógrafo de Cranach, pero posteriormente considerado obra de taller); dos alegorías muy importantes de Hans Baldung Grien, "Las Edades y la Muerte" y "La Armonía o Las tres Gracias", una pequeña pintura de Adam Elsheimer, "Ceres en casa de Hécuba", y ya del , un nutrido grupo de obras, veintinueve (una de atribución dudosa), de Anton Raphael Mengs, que fue nombrado Primer Pintor del rey Carlos III y trabajó en la Corte entre 1761 y 1769 y de 1774 a 1776. Fundamentalmente se trata de retratos de la Familia Real (o de su entorno, como el "Retrato de José Nicolás de Azara", adquirido en 2012), aunque también hay un autorretrato, el "Retrato del padre jesuita Francesco Pepe" y algunas obras de asunto religioso. A ellos se suma una única pieza de Angelica Kauffmann: "Anna von Escher van Muralt", ingresada en 1926 con el legado Luis de Errazu; un "San Sebastián", de Gottlieb Schick, donado en 2015 por Pablo de Jevenois, y un retrato de la infanta Paz de Borbón por Franz von Lenbach, donado por el Ayuntamiento de Madrid.

La continua hostilidad (en muchas ocasiones guerra abierta) entre España y las Provincias Unidas tras la separación de éstas en 1581 dificultó extraordinariamente la llegada a España de pintura del de dicho país, el período de mayor esplendor de esta escuela, a lo que contribuyó además el rumbo tomado por la pintura neerlandesa tras la independencia, buscando un estilo propio que se apartaba y en muchos casos era incluso antagónico del ideal clasicista, lo que hizo que durante largo tiempo no resultara del gusto de los coleccionistas, no solo de España, sino también de otros países en los que el arte clásico seguía teniendo gran vigencia, como Francia e Italia. Así, mientras los coleccionistas españoles se inclinaban mayoritariamente por obras religiosas y mitológicas, en Holanda tuvieron un gran auge los géneros del paisaje, las marinas, los bodegones y las escenas costumbristas, adquiridos por una burguesía que deseaba de ese modo expresar su identificación con su tierra y con su estilo de vida. Todo ello redundó en que la colección del Museo del Prado no sea especialmente extensa, faltando además en ella nombres fundamentales como Johannes Vermeer y Frans Hals. La mayor parte de las obras que posee el Prado proceden de la Colección Real y casi todas fueron adquiridas ya en el , especialmente por parte de Felipe V y su segunda esposa, Isabel de Farnesio.

La pintura holandesa cuenta con cien obras, casi todas del , entre las que destaca un importante cuadro de Rembrandt: "Judit en el banquete de Holofernes", antes identificado como "Artemisa recibiendo las cenizas de Mausolo" o como "Sofonisba recibiendo la copa de veneno". Se trata de una de las obras maestras del periodo temprano de Rembrandt, que parece retratar a su mujer Saskia en la figura femenina principal.

El fondo holandés incluye también un bodegón de Pieter Claesz. y tres de Willem Claesz. Heda, los cuatro procedentes del legado Fernández Durán, y obras del también bodegonista Jan Davidszoon de Heem, un raro ejemplo de este género de Gabriël Metsu, un retrato de Gerard ter Borch, varias obras del costumbrista Adriaen van Ostade, el claroscurista Mathias Stomer, los paisajistas Herman van Swanevelt y Simon de Vlieger, el pintor de animales Paulus Potter, los italianizantes Salomon de Bray y Jan Both y una importante serie de Philips Wouwerman. Esta colección ha sido objeto de una exposición y de la publicación del primer catálogo razonado de la misma en diciembre de 2009.

La histórica rivalidad entre España y el Reino Unido, que arranca en el con la subida al trono de Isabel I de Inglaterra y su definitiva separación de la Iglesia de Roma, no contribuyó precisamente a facilitar la adquisición de obras de arte británicas por la Monarquía española (no obstante, en Madrid hay una representación relativamente amplia de esta escuela en el Museo Lázaro Galdiano, de fundación privada). Ello redundó en que la sección de pintura británica del Museo del Prado sea pequeña, tan solo veintiocho obras (además de otras dos de atribución dudosa) de dieciocho pintores (o veinte). Además es de escasa variedad, puesto que la gran mayoría son retratos realizados entre la segunda mitad del y la primera del , y está constituida por piezas de cierta calidad pero poco representativas, excepto en el caso de las de Thomas Lawrence. Los cuadros que hay llegaron mediante algunas compras y varias donaciones, dos a finales del siglo XIX y el resto en el XX.

La colección del Prado está compuesta por obras fechadas en la segunda mitad del y en el . Faltan en ella Joseph Wright of Derby, el destacado renovador William Hogarth y el visionario William Blake, así como los grandes nombres del paisajismo inglés (Turner, Constable), pero sí hay en cambio algunos ejemplos de la obra de los principales retratistas. En la nómina figuran, aparte del citado Lawrence, Thomas Gainsborough, Joshua Reynolds, George Romney, Francis Cotes, Henry Raeburn y John Hoppner, entre otros. Por otro lado, cuenta con cuatro vistas de distintos puntos de España del pintor del romanticismo David Roberts, que fueron adquiriéndose a lo largo del pasado siglo. Finalmente, del prerrafaelismo, ya en la época victoriana, el museo tiene un espectacular lienzo del neerlandés afincado en el Reino Unido Lawrence Alma-Tadema, "Escena pompeyana" o "La siesta", que ingresó en 1887 por donación de Ernesto Gambart.

Más reducida aún, apenas testimonial, es la presencia de pinturas del resto de las escuelas: hispanoamericana (más de una veintena, pero depositadas en el Museo de América), filipina, sueca (Adolf Ulrik Wertmüller, August Franzén, Bernhard Österman), danesa (Eberhard Keil -Monsù Bernardo-), estadounidense, centroeuropea... Respecto a la escuela portuguesa, pese a la cercanía geográfica y a la estrecha relación entre las monarquías española y lusa, especialmente en tiempos de los primeros Habsburgo, la presencia de pinturas de aquel país es ínfima, reduciéndose a seis obras, casi todas del o principios del . Las piezas más destacadas son las dos del , los óleos "Catalina de Austria, reina de Portugal, como Santa Catalina" (única obra firmada que se conoce de Domingo Carvalho) y "El rey don Sebastián de Portugal", de Cristóvão de Morais (en España también llamado Cristóbal de Morales).

"Véase: "

Ningún museo o colección en el mundo supera al Prado en cuanto a la representación de los siguientes artistas:

A diferencia de lo que ocurre en el campo de la pintura, en el de la obra sobre papel la colección del Prado está lejos de figurar entre las primeras del mundo. Es más, cuantitativamente, ni siquiera tiene la primacía entre las españolas, ya que sus fondos, más de 10000 dibujos y de 6000 estampas, se ven superados por los de la Biblioteca Nacional, 16000 dibujos y 100000 estampas sueltas (además de otras 600000 incluidas en libros), y los de la Real Academia de Bellas Artes de San Fernando, 15000 dibujos y 35000 grabados. Sin embargo, posee conjuntos de gran calidad, como prueba el que desde 2012 el museo sea miembro permanente del International Advisory Committee of Keepers of Public Collections of Graphic Art (Comité consultivo internacional de conservadores de colecciones públicas de arte gráfico), conocido como "Club de los 50 luxes", en el que están representados los más importantes gabinetes de dibujos y estampas a nivel mundial.

Durante mucho tiempo esta colección permaneció en el ostracismo, ni siquiera se estudiaban y publicaban, de manera sistemática, las piezas con las que se contaba, con la excepción de las de Goya. Así, los volúmenes del primer catálogo de los dibujos del museo no empezaron a publicarse hasta una fecha tan tardía como 1972 (y aún hoy, más de cuarenta años después, siguen pendientes dos de los volúmenes: el IV, que recogería los dibujos españoles del , y el VIII, dedicado a los dibujos de otras escuelas distintas de la española y la italiana), y para entonces la mayoría de las obras que recogían eran inéditas, carecían por completo de bibliografía previa. Sin embargo, a partir de entonces se fue tomando conciencia de que eran unos fondos que también merecían atención, y se comenzó a realizar exposiciones temporales, con obras del propio museo y de otras colecciones, y a efectuar algunas compras que cubrieran las muchas lagunas, especialmente con el legado Villaescusa.

Sobresale la colección de dibujos de Goya, más de quinientos veinte, la más amplia del mundo puesto que el total de sus dibujos conservados no llega al millar. Junto a ella, la colección de dibujos españoles del , con más de tres mil obras originales, es de extraordinaria importancia. Otros artistas españoles presentes en la colección son Juan Guas, con un dibujo sumamente raro, que representa la capilla mayor del Monasterio de San Juan de los Reyes de Toledo, por él diseñado; Francisco Pacheco "(Juicio Final)", Vicente Carducho, con un importante boceto, "La expulsión de los moriscos", Alonso Cano, José de Ribera, Murillo, Francisco Bayeu, Paret, con varios de sus mejores trabajos, y Fortuny, con un conjunto de más de ochenta obras que incluye varias acuarelas.

Las colecciones de dibujos extranjeros son menos nutridas y variadas, aunque incluyen notables ejemplos italianos, gracias fundamentalmente a Pedro Fernández Durán, que aportó al Prado unos mil seiscientos (de un legado total de dos mil setecientos ochenta y cinco). Los fondos más ricos son los de maestros boloñeses del , especialmente Guercino. Es una colección muy fragmentaria, apenas hay conjuntos extensos de un mismo autor, lo cual por un lado imposibilita estudiar en profundidad sus características y evolución, pero por otro ha permitido contar con representación de un grupo muy amplio de artistas, muchos de ellos ausentes en la colección de pintura, incluido Miguel Ángel, del que se conservan dos dibujos preparatorios para la Capilla Sixtina.

La presencia del resto de escuelas es reducida. Respecto a la francesa, hay alrededor de cuatrocientas hojas. La mayoría, unas doscientas cincuenta, ingresaron con el legado Fernández Durán, entre cuyos ejemplos destacados figuran un diseño de grandes dimensiones (1127 × 874 mm) de Laurent Pécheux, "El Juicio Final", y "Hombre con las manos unidas", de Théodore Géricault, preparatorio de su pintura "La balsa de la Medusa". En cuanto a las del norte, son destacables dos aguadas de colores de Rubens, además del "Manuscrito de principios artísticos de Rubens", o "Manuscrito Bordes", copia de un cuaderno original de Rubens perdido en un incendio, que incluye dos dibujos que muy probablemente fueron ejecutados por el propio maestro. También hay una amplia colección de Mengs.

La colección de estampas tiene menos importancia. Sus núcleos principales son Goya, el español (especialmente Carlos de Haes) y las estampas de reproducción, gran parte de ellas de obras del propio museo.

Del Gabinete depende también desde 2004 el fondo de fotografía histórica (anterior a 1939), antes en el Archivo del museo. A este conjunto inicial se unió en 2006 el grupo de fotografías que incluía la Colección y Biblioteca Madrazo, comprada por el Prado en ese año, y que actualmente constituye el núcleo de la colección. El interés de esta se centra, aunque no limita, en instantáneas relacionadas con la institución: su sede, sus colecciones y los artistas en ella presentes. Cronológicamente arranca en 1847, y cuenta con unos 15000 ejemplares.

La colección de escultura del museo comprende más de 900 obras, además de casi 200 fragmentos escultóricos. Procede en su mayor parte de las antiguas colecciones reales, aunque completada en épocas recientes con adquisiciones, legados y donaciones. Entre estas últimas destaca la de siete esculturas antiguas realizada en 1943 por el mexicano Marius de Zayas «como tributo de su familia a la Madre Patria», y la efectuada en 2000 por el pintor chileno Claudio Bravo, consistente en diecinueve esculturas greco-romanas. En cuanto a la escultura del procede en su mayor parte del extinto Museo de Arte Moderno, cuyos fondos decimonónicos pasaron al Prado en 1971.

Las primeras esculturas que se expusieron en el museo, que entonces aún conservaba su denominación inicial de Real Museo de Pinturas, fueron la pareja "Carlos IV, sedente", de Ramón Barba y "María Luisa de Parma, sedente", de José Álvarez Cubero, que fueron mostradas al público entre el 22 de enero y el 5 de febrero de 1827.

Es muy destacable el fondo de esculturas antiguas, sobre todo obras romanas, aunque también algunos originales griegos, que se adquirieron para decorar los Reales Sitios. Hay raros ejemplos de escultura griega arcaica, así como versiones muy importantes del Diadúmeno de Policleto, Venus púdica ("Venus del Delfín"), "Ariadna dormida" o la "Atenea Párthenos" de Fidias, copias romanas de los originales perdidos. Las obras romanas originales comprenden piezas tan destacadas como la "Apoteosis de Claudio" o el Grupo de San Ildefonso, obra maestra de la escultura imperial. Destacan también las "Musas" que pertenecieron a Cristina de Suecia, y que tras la última ampliación se ubican en el recibidor oval, bajo la sala de "Las Meninas".

El segundo grupo en importancia del fondo escultórico corresponde al Renacimiento y Manierismo. Hay ejemplos debidos a Juan de Bolonia, una "Venus" de Baccio Bandinelli (antiguamente creída de Bartolomeo Ammanati), un "Apolo" atribuido a Silvio Cosini, e incluso dos rarísimas tallas de el Greco, "Epimeteo y Pandora". Pero destaca de este periodo el conjunto de esculturas debidas a los broncistas milaneses Leone y Pompeo Leoni, entre ellas la célebre "Carlos V dominando el Furor", considerada la más importante escultura moderna de la colección del museo. De épocas posteriores, sobresalen las esculturas compradas en Italia por Velázquez.

En las salas que se abrieron en 2009 dedicadas al se incorporaron varias esculturas de este periodo. Entre los representados figuran José Álvarez Cubero, Ramón Barba, José Ginés, Antonio Solá, los hermanos Venancio y Agapito Vallmitjana, José Llimona, Jerónimo Suñol, Agustín Querol y Mariano Benlliure. 

Las obras de escultores extranjeros son escasas. Entre las italianas están "El pintor Mariano Fortuny y Marsal", busto realizado en bronce por la fonderie Barbedienne de París a partir de una terracota de Vincenzo Gemito, y dos esculturas antes atribuidas a Antonio Canova, "Venus y Marte", ahora adjudicada a su círculo, y "Hebe", que actualmente se considera realizada por su más brillante discípulo, Adamo Tadolini, copiando un original del maestro. Pero es especialmente destacable el busto "Isabel II, velada", la obra cumbre de Camillo Torreggiani, que esculpió asimismo el pedestal. Se trata de un alarde de virtuosismo técnico, en la línea de las figuras veladas que en el siglo anterior ejecutara el también italiano Antonio Corradini. 

De Fortuny hay asimismo otro busto, en barro cocido, modelado por su amigo el francés Prosper d'Épinay. También posee el museo una escultura de "Hermes", tradicionalmente considerada de la mano del danés Bertel Thorvaldsen y hoy asignada a su taller, una "Alegoría de la danza", tenida antes por obra del francés Albert-Ernest Carrier-Belleuse y actualmente adscrita a su círculo, y por último una reducción de "Amor y Psiquis", la obra más destacada del escultor sueco Johan Tobias Sergel, ejecutada por el propio maestro con la colaboración de su taller.

Por otra parte hay, pero sin exponer, cinco piezas de Ponciano Ponzano, cuatro de Miguel Blay, dos de Eduardo Barrón, y sendos mármoles del irlandés John Henry Foley, "Sir Charles Bennet Lawes Witteronge como Mercurio", y el italiano Antonio Tantardini, "Dos principitos en la cuna".

Aparte del "Tesoro del Delfín" también es muy notable la colección de piedras duras, una de las más importantes en todo el mundo. Además, la sección de Artes decorativas consta de diversos objetos que en gran parte de los casos se apartan de la línea expositiva del museo y que por tanto no se muestran habitualmente en sus salas -muchos de ellos están depositados en otras instituciones-, recibidos fundamentalmente a través de donaciones y legados, en especial el legado Fernández Durán. Estas colecciones comprenden tapices, bordados, armas, armaduras, muebles, vidrios, cristales, lacas, abanicos, platería, marfiles, cerámicas, lozas y porcelanas, así como un conjunto de ochocientas cuatro medallas de los siglos al y novecientas cuarenta y seis monedas autónomas españolas legado por Pablo Bosch.

El "Tesoro del Delfín" se denomina así por haber pertenecido a Luis de Francia, el Gran Delfín, que falleció durante una epidemia de viruela en 1711 sin haber llegado a reinar, siendo parte de él heredado al año siguiente por su segundo hijo, Felipe V de España. El primer Borbón español recibió ciento sesenta y nueve obras, un porcentaje no muy grande del total (seiscientas noventa y ocho inventariadas en 1689), pero que fueron seleccionadas entre las mejores de la colección. Sin embargo, casi todas las actualmente existentes están mutiladas por los robos producidos durante la invasión francesa y otro realizado a principios del , que además redujeron su número a ciento cuarenta y cuatro. De ellas, cuarenta y nueve están realizadas en cristal de roca y otras setenta y una en piedras duras (piedras semipreciosas como ágata, lapislázuli, calcedonia, jaspe, jade, serpentina o alabastro) y otros materiales, como conchas de nautilos. Las guarniciones son generalmente de oro, aunque también hay algunas de plata, tanto sobredorada como en su color, y frecuentemente van realzadas con ricos esmaltes y piedras finas (turquesas, amatistas, granates) y preciosas (diamantes, zafiros, esmeraldas y rubíes), además de perlas.

La mayor parte de las piezas son de los siglos y , de talleres parisinos e italianos (en el caso de las de cristal de roca, milaneses en concreto), aunque también hay ejemplares de la Antigua Roma, bizantinos, medievales e incluso de la Persia sasánida, el Imperio mogol y China.

Se muestran también varios de los estuches de cuero en los que se guardaban estas piezas y que se realizaron reproduciendo exteriormente su forma con el fin de poder identificarlas sin necesidad de abrirlos. En el montaje inaugurado en 2018 en el toro del ático norte se exponen también dos conjuntos que fueron separados del resto a finales del , un "Juego de café de laca" y un "Estuche con juego de utensilios para preparar piezas de caza (trousse de veneur)", y que han sido identificados en los últimos años, el primero en el Museo de América y el otro en el Museo Arqueológico Nacional.
La colección de piedras duras comprende tableros, consolas y paneles decorativos, tanto de manufacturas italianas (Talleres Papales de Roma y Granducales de Florencia —la "Galleria dei Lavori", también conocida como "Opificio delle Pietre Dure"—), como de la Real Fábrica del Buen Retiro, que además de dedicarse a la porcelana tenía también un taller dedicado a esta especialidad, el Real Laboratorio de Mosaicos y Piedras Duras del Buen Retiro (así como un obrador de marfiles, del que igualmente se cuenta con representación: dos relieves de mano de su director, el escultor italiano Andrea Pozzi). Estas piezas tienen su origen en la Antigua Roma, en el llamado "opus sectile", o taracea de mármoles y piedras duras polícromas, una técnica rara y costosa que vivió su apogeo durante la época del emperador Augusto y que fue recuperada a mediados del en Florencia y la propia Roma.

Dentro de esta colección destacan los dos tableros sostenidos por leones de bronce dorado, el "Tablero de mesa de Felipe II" y la "Mesa de don Rodrigo Calderón", exhibidos en la Galería central y restaurados en 2008. Los leones, cada uno de los cuales apoya una garra sobre una bola de caliza de color rojizo, fueron encargados por Velázquez durante su segundo viaje a Italia para decorar el Salón de los Espejos del antiguo Real Alcázar de Madrid, dado que a su cargo de pintor de cámara unía el de "Aposentador Real". El conjunto original se componía de doce, realizados entre 1651 y 1652, de los que el Prado posee siete. Otros cuatro se conservan en el Salón del Trono del Palacio Real de Madrid, mientras que el restante sufrió daños muy graves en el incendio del Alcázar de 1734 (el otro león que tiene el museo es una copia de 2004 que ha sustituido a otra de 1837 que se encontraba muy deteriorada). Su modelo fue un león de Flaminio Vacca de 1594, a su vez copia de uno del  d. C., ambos en aquella época en la Villa Medici de Roma. Fueron fundidos por Matteo Bonucelli da Lucca (también conocido en España como Matteo Bonarelli de Luca), fundidor ayudante de Bernini, y del que el Prado posee otras dos obras: la "Venus de la concha" y el famoso "Hermafrodita" que durante varias décadas estuvo expuesto en la sala de "Las meninas", este último un caso excepcional, ya que la copia resultó de tanta calidad que superó al original.

Las excepcionales vicisitudes del Prado, concebido primero como "Museo Real", elevado tras "La Gloriosa" a la categoría de "Museo Nacional", que absorbió en 1872 los fondos del disuelto Museo de la Trinidad; junto a las donaciones, adquisiciones, legados, que se han ido sucediendo desde la fundación en 1819, han hecho que los límites físicos del museo se vieran desbordados en muchas ocasiones.

Ya desde el mismo instante en que abrió sus puertas, el museo tuvo que dedicar más espacio a los almacenes que a la propia exposición de obras. Esta situación se vio más complicada con la llegada de los fondos del Museo de la Trinidad, excepcionalmente cuantiosos y formados por grandes pinturas de altar en muchos casos, difíciles de exponer y almacenar. Hay que tener en cuenta que el edificio del museo no se concibió para albergar colecciones de pintura, sino como Gabinete y Academia de Ciencias.

De este modo, durante buena parte de los siglos y se siguió la política de ceder a diversas instituciones, en régimen de préstamo temporal, algunos de los fondos que habitualmente no podían exponerse por falta de espacio. Y si grave fue siempre la escasez de espacios en el Prado, mucho peor aún fue la situación del Museo de Arte Moderno, cuyas piezas del pasaron al Prado en 1971. A la considerable abundancia de fondos, entre los que figuraba un buen número de pinturas de gran formato, se unía un espacio disponible realmente reducido, pues al tener que compartir el Palacio de Biblioteca y Museos Nacionales con dos instituciones de la importancia de la Biblioteca Nacional y el Museo Arqueológico Nacional, la parte que se le asignó del mismo fue muy pequeña.

Los depósitos no siempre siguieron criterios de pertinencia, ya que muchas de estas obras pasaron a museos provinciales o locales, pero otras acabaron en oficinas, iglesias e incluso despachos particulares. Y durante 113 años tampoco se realizó un control mínimamente riguroso, ya que mientras que el primero de los depósitos se efectuó en 1866, la revisión sistemática de los mismos no se inició hasta 1979, a raíz de un requerimiento realizado el año anterior por el Tribunal de Cuentas a través de la Fiscalía General del Reino. La labor, ardua y agravada por la gran dispersión de los fondos, corrió a cargo del Servicio de Depósitos de Obras de Arte del museo, creado al efecto y que se ocupa desde entonces de esta responsabilidad. Además se procedió a inspeccionar también el resto de obras pictóricas de la institución. Este proceso de comprobación de la totalidad de los fondos pictóricos del museo culminó en la década de 1990 con la publicación, en tres volúmenes, del "Inventario general de pinturas".

Un primer intento, fallido y limitado a las obras del MAM, se había realizado cuando este centro fue dividido en Museo Nacional de Arte del Siglo XIX y Museo Nacional de Arte Contemporáneo, y se procedió al reparto de las colecciones entre ambas instituciones. El director general de Bellas Artes, Gratiniano Nieto, señaló entonces que los registros de los depósitos se hallaban

Sin embargo, a pesar de las intenciones iniciales, el estudio provisional que se hizo, concluido en 1961, se realizó únicamente con base en la documentación interna, sin verificar el estado real de las piezas en las instituciones depositarias ni tomar fotografías de las mismas. El recuento provisional fue de mil ciento setenta y nueve obras depositadas en cuarenta y ocho instituciones españolas, y otras diez en dependencias estatales en el exterior.

En 2014 el museo tenía depositadas 3310 obras, repartidas entre 278 instituciones, en su mayor parte en territorio nacional y el resto en el extranjero, fundamentalmente en legaciones y consulados. Hay depósitos del Prado en todas las provincias españolas, con las únicas excepciones de Guadalajara, Vizcaya y la ciudad autónoma de Melilla. Dada la mencionada carencia de un control riguroso sobre estos fondos que hubo durante más de un siglo, a esa fecha había 885 piezas que permanecían ilocalizadas, en su gran mayoría (748) correspondientes a las colecciones heredadas del Museo de la Trinidad y del M. A. M., las cuales aun así suponían 540 menos que en 1978. A ellas se sumaron otras 57 piezas desaparecidas que figuraban entre las adscritas al Prado procedentes del Reina Sofía, en virtud de la reordenación de colecciones que ambos museos llevaron a cabo en 2016, dando cumplimiento al Real Decreto 410/1995, de 17 de marzo.

Teniendo la mayor parte de sus propios fondos sin exponer, es obvio que las obras de terceros que el museo acepta en depósito para exhibir en sus salas se circunscriben a piezas de muy alta calidad, siendo en consecuencia su número muy limitado.

Muchas de estas pinturas prestadas pertenecen a otros organismos públicos. Sin embargo, en contra de lo que se pudiera pensar, su permanencia en el museo no es tan segura ni la condición de préstamo un mero formalismo técnico. Así, en 2014 Patrimonio Nacional reclamó al Prado la devolución de cuatro capitales pinturas que llevan en él más de siete décadas, para exponerlas en su futuro Museo de Colecciones Reales. Además, ante la oposición de la pinacoteca tomó en represalia la decisión de denegar cualquier préstamo de obras para exposiciones temporales en el Prado, incluidos algunos que estaban ya comprometidos con anterioridad.

Entre ellas figuran obras tan significativas como la "Mesa de los pecados capitales", "El jardín de las delicias", ambas de El Bosco, "El descendimiento de la cruz", de van der Weyden, y "El Lavatorio", de Tintoretto. Las cuatro proceden del Monasterio de El Escorial e ingresaron en el Prado en 1939, cuando regresaron a España de vuelta de Ginebra, donde habían sido trasladadas durante la Guerra Civil. Dichas obras pertenecen realmente a Patrimonio Nacional y permanecen en el Prado en depósito ("El descendimiento" fue sustituido en El Escorial por una copia de Michel Coxcie propiedad del Prado).

Otra destacada pieza, incorporada recientemente (2005), es "San Jerónimo leyendo una carta", de Georges de La Tour, identificada por José Milicua en el Palacio de la Trinidad, entonces sede del Instituto Cervantes, donde figuraba como obra anónima, y que fue depositada por el entonces Ministerio de Trabajo y Asuntos Sociales. También están en depósito seis fragmentos de las pinturas murales de la ermita de San Baudelio de Berlanga que el Metropolitan dejó en depósito indefinido en 1957, a cambio del ábside de la iglesia de San Martín de Fuentidueña, un "San Jerónimo penitente" de el Greco y taller propiedad de la Comunidad de Madrid y tres tondos con alegorías de Goya, "La Agricultura", "El Comercio" y "La Industria", depositados en 1932 por el entonces Ministerio de Marina, en un intercambio de obras con el museo. Y desde 2013, por un periodo inicial de cinco años, "La Virgen de la Leche", de Pedro Berruguete, cedida por el Ayuntamiento de Madrid.

Entre los depósitos de particulares figuran la "Piedad", obra maestra de Sebastiano del Piombo, o "La mujer barbuda", de José de Ribera (desde 2004), cedidas ambas por la Casa de Medinaceli; y el óleo "Aníbal vencedor contempla por primera vez Italia desde los Alpes", de Goya, que quedará depositado durante seis años por la Fundación Selgas-Fagalde desde septiembre de 2011. Desde 2012, por un periodo de diez años, se exhibe en el museo el retablo de los "Gozos de Santa María" o "altar de los ángeles", de Jorge Inglés, la primera pintura hispanoflamenca castellana documentada de autor conocido, depositada por Íñigo de Arteaga y Martín, XIX duque del Infantado, y desde diciembre de 2013 tres obras cedidas en depósito durante cinco años por la familia Várez Fisa: "La oración en el huerto", de Paolo de San Leocadio, "Nacimiento de Cristo con un donante", de Fernando Llanos y "La Virgen con el Niño", de Juan de Flandes. Inicialmente formó parte también de este grupo el "Tríptico del Nacimiento de Jesús", del Maestro del tríptico del Zarzoso, pero al año siguiente fue comprado por el museo a los depositantes. Y desde 2016 está depositado por la American Friends of the Prado Museum un "Retrato de Felipe III" recientemente adscrito a Velázquez, posiblemente preparatorio de su desaparecida obra "La expulsión de los moriscos".

Algunas obras que estuvieron en depósito antiguamente fueron "El martirio de San Andrés", de Rubens, cedido entre 1978 y 1989 por la Fundación Carlos de Amberes, y durante dieciocho el "Retrato de Mariano Goya", de atribución discutida a su abuelo, depositado por el duque de Alburquerque. Entre 2004 y 2016 colgó en las salas del Prado el único retrato conservado en España de Sandro Botticelli, el "Retrato de Michele Marullo Tarcaniota", que perteneció a Cambó y que estuvo depositado por su única hija, Helena. Asimismo estuvo dos años una obra capital de El Greco, "La Asunción de la Virgen", lienzo central del retablo mayor de Santo Domingo el Antiguo de Toledo. En el pasó a manos del infante Sebastián Gabriel, y, a su muerte, a su viuda, la infanta María Cristina de Borbón y Borbón. Tras el fallecimiento de esta, sus herederos la ofrecieron en venta al Estado, y la llegaron a dejar depositada en el Prado en 1902, pero ante la falta de respuesta acabaron por retirarla en 1904. Finalmente terminó en el Art Institute of Chicago.

El edificio diseñado por Juan de Villanueva, en su concepción original, está formado por un cuerpo central terminado en ábside, al que flanquean dos galerías alargadas que terminan en pabellones cuadrados, uno a cada extremo. Dicho esquema fue ampliamente modificado, primero para adaptar al uso de pinacoteca un edificio que había sido concebido para Real Gabinete de Historia Natural (luego Museo Nacional de Ciencias Naturales) y Academia de Ciencias, y después en las sucesivas ampliaciones que se fueron realizando, y que afectaron sobre todo a la fachada que mira a la iglesia de los Jerónimos.

El cuerpo central destaca en planta y en alzado por un gran pórtico compuesto por seis columnas de orden toscano, un entablamento, una cornisa y un ático que lo remata. Esta fachada es el acceso principal, orientado hacia el paseo del Prado, y presenta la originalidad de no disponer sobre la columnata del característico frontón triangular, sino de uno con forma rectangular, adornado por un friso escultórico obra de Ramón Barba, representando una alegoría del rey Fernando VII como protector de las ciencias, las artes y la técnica. En su cara posterior, esta sección central termina en forma semicircular o absidal, de tal modo que su plano adopta forma basilical. Originariamente, dicha estancia abarcaba las dos plantas de altura, y a finales del se dividió en dos pisos. El inferior se dedicó inicialmente a escultura aunque en 1984 pasó a ser el auditorio-salón de actos, según proyecto de José María García de Paredes (el mismo arquitecto que hizo el Auditorio Nacional), y en la reforma de Moneo se transformó en recibidor (Sala de las Musas -Sala 0i-). La planta superior es la actual sala 12, presidida por "Las Meninas".

Las dos galerías laterales tienen dos plantas en altura. La inferior con unos ventanales profundos y alargados que acaban en arco de medio punto y la superior con una galería de columnas jónicas (en la actualidad hay un tercer piso retranqueado, obra posterior).

La fachada norte presenta un pórtico con dos columnas jónicas y sobre ellas un entablamento liso. Esta fachada corresponde a la segunda planta del edificio. Cuando se construyó el edificio, la primera planta quedaba, por ese lado, bajo el nivel del terreno, que por aquella época bajaba en una pequeña cuesta hasta el paseo del Prado, hasta que más tarde se desmontó este desnivel hasta ponerlo a la misma altura que el suelo real del monumento. Hubo que construir una escalinata para su acceso (1882).

La fachada sur (que da a la plaza de Murillo, frente al Jardín Botánico) está formada por un vano adintelado, de acceso al interior, y una "logia" o galería con seis columnas de orden corintio sobre las que se apoya un entablamento.

El interior del edificio es abovedado en sus salas centrales. El vestíbulo de la entrada norte está formado por una rotonda con ocho columnas jónicas cuya bóveda tiene decoración de casetones.

En el exterior, frente a la fachada principal, está ubicada la estatua de Velázquez, obra del escultor Aniceto Marinas, con pedestal de Vicente Lampérez (ambos autores realizaron su labor de manera gratuita). Tiene una dedicatoria: "Los artistas españoles, por iniciativa del Círculo de Bellas Artes, 1899." Sustituyó al Monumento a Daoíz y Velarde, de Antonio Solá, y se inauguró el día 14 de junio de ese mismo año, con la presencia de la Reina Regente y de Alfonso XIII. Fue una ceremonia muy emotiva en la que se rindió homenaje y reconocimiento al gran pintor Velázquez y a la pintura española. Además de los reyes acudieron al acto:

Existen además, junto a sus puertas principales, otros dos monumentos del , dedicados a Goya, obra del escultor valenciano Mariano Benlliure, y a Murillo, de Sabino de Medina, réplica de la que había realizado para la plaza del Museo en Sevilla, así como medallones en piedra representando a célebres artistas españoles (no solo pintores, sino también escultores y arquitectos) de diversas épocas, repartidos por la fachada occidental del edificio, la que da al paseo del Prado.

Entre las reformas más importantes del edificio concebido por Villanueva cabe citar, por orden cronológico, la de Narciso Pascual y Colomer, que diseñó la basílica y el ábside del cuerpo central (1853); la de Francisco Jareño, que desmontó la cuesta por la que se accedía a la fachada norte y creó una escalera monumental, abriendo ventanas en la parte baja (1882 y 1885); la de Fernando Arbós y Tremanti, que añadió una nueva crujía en la fachada este a cada lado del ábside (1911-1913 proyecto, 1914-1921, obra dirigida tras su fallecimiento en 1916 por Amós Salvador); la de Pedro Muguruza, entre 1943 y 1946, con una remodelación de la Galería central y una nueva escalera para la fachada norte (que contó con bastantes críticas, ya que destruyó la espléndida escalera ideada por Jareño), con la intención de dar más luz a la zona de la cripta (además con anterioridad, en 1925, había realizado la escalera central del edificio); y la de Chueca Goitia y Lorente, que añadieron dieciséis nuevas salas mediante la construcción de una nueva crujía en la fachada oriental contigua a la de Arbós (1952-1953 proyecto, 1954-1956 obra).

La incidencia en el Edificio Villanueva de la ampliación de 2007 tardó unos años en ser totalmente perceptible. El traslado de los almacenes y equipos científicos al "Cubo de Moneo" liberó 25 salas del edificio principal, que fueron acondicionadas gradualmente. Los responsables del museo estimaron en un 50% el incremento de obras expuestas, es decir, unas 450-500, que se podrán contemplar en nuevas salas del edificio Villanueva. En octubre de 2009 se abrieron los nuevos espacios dedicados al arte del , desde los últimos neoclásicos hasta Sorolla, incorporando tales corrientes artísticas, a menudo subestimadas, al discurso expositivo del museo. Este nuevo despliegue tuvo su siguiente hito en mayo de 2010, con las salas de pintura española medieval y del anterior a el Greco, que ocupan el lugar de las antiguas salas de exposiciones temporales de la planta baja de la rotonda, en la parte norte del edificio Villanueva, con una instalación que en su parte arquitectónica ha sido ideada por el mismo Rafael Moneo. En julio de 2011 se dio otro paso en la reordenación de la exhibición permanente: la Galería central se reabrió con obras de gran formato de la pintura veneciana del (Tiziano, Tintoretto, Veronés), de algunos maestros italianos del primer clasicismo (Annibale Carracci, Guido Reni, Orazio Gentileschi) y de pintura flamenca del Barroco (Rubens, dos de ellas en colaboración con Snyders y otra con van Dyck, aunque también se colgó una obra de van Dyck y posteriormente otra de Jacob Jordaens). Por otra parte, en junio de 2018 se reabrieron las salas del ático norte, en las que antiguamente estaba el taller de restauración y que posteriormente, tras una remodelación a cargo de Gustavo Torner, pasaron a exponer durante unos pocos años la colección de pintura europea del . Con la reordenación, siete de sus salas exponen pintura barroca flamenca, una de ellas dedicada monográficamente a la Torre de la Parada, otra la pintura holandesa, mientras que en el toro está instalado el "Tesoro del Delfín".

Finalmente, en 2020 está previsto culminar la dedicación integral del Edificio Villanueva a usos expositivos con la inauguración de la instalación de piezas de escultura clásica en la Galería jónica norte, y la reapertura de las salas del sótano, reacondicionadas tras el traslado del "Tesoro del Delfín" y que ahora mostrarán un módulo dedicado a la historia de la institución.

Siguiendo el proyecto de Rafael Moneo, cuya ejecución se inició en 2001, en 2007 se culminó la mayor ampliación del museo en sus casi doscientos años de historia. Esta ampliación no supuso cambios sustanciales para el Edificio Villanueva, y se plasmó en una prolongación hacia el claustro de los Jerónimos (el llamado "Cubo de Moneo") a fin de que el museo contase con espacio suficiente para sus crecientes necesidades. El incremento de la superficie disponible fue de 15 715 metros cuadrados, un 50 % más.
La conexión entre ambos edificios es subterránea (en el lado del Edificio Jerónimos), pues aprovecha y cubre el desnivel entre los Jerónimos (calle Ruiz de Alarcón) y el paseo del Prado. Las mejoras más visibles de esta intervención incidieron en la atención al visitante (vestíbulo, bar-restaurante, taquillas, tienda), la ampliación de los espacios expositivos, con cuatro nuevas salas para exposiciones temporales en dos plantas y la habilitación del claustro como sala de escultura; un auditorio nuevo y una sala de conferencias, así como otros espacios de uso interno (Área de Restauración —Taller, Gabinete de Documentación Técnica y Laboratorio de Análisis—, almacenes y el Gabinete de Dibujos y Estampas). Su inauguración tuvo lugar el 30 de octubre de 2007, con una muestra temporal de las piezas más significativas de la colección de pintura española del , que había permanecido almacenada durante diez años, desde el inicio de las obras en el Casón en 1997.

El hoy conocido como "Casón" es una de las dependencias del antiguo Palacio del Buen Retiro que han llegado a nuestros días. Concebido como "Salón de Bailes" de dicho palacio, quedó muy malparado tras la Guerra de la Independencia, tras ser ocupado y parcialmente destruido por las tropas francesas. La parte subsistente, ya como edificio autónomo y separado de lo que fue el antiguo palacio, fue objeto de varias reformas a lo largo del . Se le dotó entonces de monumentales fachadas neoclásicas, de las cuales la occidental, con escenográfica columnata, fue diseñada por Ricardo Velázquez Bosco (la oriental, frente al Parque del Retiro, es del discreto arquitecto Mariano Carderera). Durante este siglo el edificio tuvo diversos usos, llegando ser sede del "Estamento de Próceres" (precedente del actual Senado).

Ya en el , fue utilizado como sala de exposiciones, albergando varias de las más importantes que se concibieron tras el paréntesis de la Guerra Civil. Decidido ya su uso museal, quedó adscrito al Prado en 1971, albergando hasta 1997 la sección correspondiente al arte del , que acababa de verse extraordinariamente incrementada tras la adscripción de los fondos de esa época que habían pertenecido al extinto Museo de Arte Moderno, función muy acorde con su arquitectura decimonónica, pero de escaso atractivo para los visitantes, dada la separación del Casón del edificio Villanueva, y el desconocimiento general del arte español de esa época. Tal situación quedó paliada con la llegada del Guernica y otras pinturas muy representativas de la vanguardia pictórica española, como varias de Juan Gris. Tras la reordenación de las colecciones estatales de pintura y la creación del Museo Reina Sofía, se pensó en el Casón como espacio ideal para las exposiciones temporales del Prado. Finalmente, esas funciones y la pintura del han sido transferidas a la ampliación de Moneo y el edificio histórico, respectivamente. Tras ser sometido a una profunda reforma a principios del , que incluyó la restauración de la bóveda pintada por Luca Giordano en la sala central ("Alegoría del Toisón de Oro"), es desde 2009 la sede del "Centro de Estudios del Museo", la llamada "Escuela del Prado", que, siguiendo el modelo de la "École du Louvre", está dedicado a la investigación así como a la formación de especialistas en los diversos campos de la Historia del Arte. De este modo, el Casón alberga actualmente la Biblioteca del Museo del Prado, con la sala de lectura instalada en el salón principal bajo los frescos de Giordano. Recibió una aportación extraordinaria al donar el rey Juan Carlos I el importe íntegro del premio que le otorgó la Mutua Madrileña (750 000 €) al museo y destinarlo este a tal fin.

El Centro abrió sus puertas por primera vez el 9 de marzo de 2009. Cuenta con libros sobre pintura, dibujo e iconografía, escultura y artes decorativas, en un arco que abarca desde la Edad Media hasta el . Parte de ellos son catálogos de exposiciones, existiendo también un importante fondo antiguo (anterior a 1900), en buena medida gracias a las recientes adquisiciones de las bibliotecas Cervelló (2003), Madrazo (2006), Correa (2007) y Bordes (2014). También se han incorporado otras bibliotecas especializadas, como las de José Álvarez Lopera, Julián Gállego y Félix de Azúa. En total hay más de 70 000 libros y 1000 títulos de revistas, 200 de ellas vivas. En 1987 se inició la digitalización de los fondos, pudiendo accederse ya a la mayoría a través de terminales instalados en la sala de lectura, y desde 2012 también a través de la nueva sección Biblioteca digital de su página web, comenzando por la serie completa de catálogos generales de la colección de pinturas.

Uno de los principales programas que desarrolla es el de las Cátedras anuales, iniciadas en 2009. Por otro lado, en 2013 se implantó una nueva actividad, el Seminario Museo del Prado, también de carácter anual, concebido para completar la labor pedagógica con un curso dedicado a la teoría del arte.

Corresponde al ala principal (norte) del antiguo Palacio del Buen Retiro, y recibió su nombre por haber albergado originalmente el "Salón de Reinos" o de "Embajadores", donde el rey recibía a los dignatarios extranjeros. Dicho espacio se concibió como una escenográfica puesta en escena de la monarquía española, con grandes cuadros encargados por Felipe IV a los principales pintores de la época, entre ellos Velázquez ("La rendición de Breda" y los retratos ecuestres de Felipe III, la reina Margarita de Austria, Felipe IV, la reina Isabel de Borbón y el príncipe Baltasar Carlos), Juan Bautista Maíno ("La recuperación de Bahía") y Zurbarán (la serie de "Los trabajos de Hércules", "La Defensa de Cádiz contra los ingleses" y otro cuadro de batalla hoy perdido).

Tras la casi total destrucción del palacio (ver Casón del Buen Retiro) esta parte del mismo fue destinada a albergar el Museo del Ejército, y muy modificada para dicho fin. En el concurso internacional para la ampliación del Prado (1995-1996) ya se preveía la adscripción al mismo de este edificio, para lo cual se ordenó el traslado del Museo del Ejército al Alcázar de Toledo. La previsión inicial era licitar la obra en 2009 o 2010 y realizar la adjudicación, ejecución de trabajos y habilitación en el periodo 2010-2012, con un presupuesto de cuarenta y dos millones y medio de euros, destinándolo tanto a exposiciones temporales como a exhibir obras de la propia colección permanente del Prado. Sin embargo, la estimación final del coste de los trabajos necesarios se elevó por encima de los noventa millones y el proyecto, a pesar de estar contemplado en el Plan de Actuación 2009-2012, permaneció aplazado sin fecha. A causa de ello la reordenación de la colección se ejecutó finalmente sin contar con este edificio, cuya función cuando estuviera disponible (mostrar con mayor profundidad ciertas facetas de las colecciones o bien acoger muestras temporales) quedó sin concretar.

En febrero de 2015 la Dirección General de Bellas Artes resolvió desadscribirlo al Prado para usarlo como sala de exposiciones de fotografía, aunque posteriormente dicho plan quedó descartado, y en octubre de ese mismo año se formalizó su definitiva cesión (mutación demanial) al Prado, que a principios del año siguiente convocó un concurso internacional de proyectos para su rehabilitación y adecuación museística, intervención que dotará al museo de 2500 m² de espacio expositivo, un 16 % más, con un total de 5800 m² útiles. El fallo del concurso, al que se presentaron cuarenta y siete equipos, se hizo público en noviembre de ese año. La ganadora fue la unión temporal de empresas Foster + Partners-Rubio Arquitectura. Se preveía que las obras comenzaran en 2018, pero por falta de dotación presupuestaria no lo harán hasta finales del año siguiente. El coste de las obras será de cuarenta millones de euros, sufragados en un 75 % por el Estado y el 25 % restante por el museo, a los que hay que añadir los dos millones empleados en el concurso, la licitación y las catas.

Situado junto al Claustro de los Jerónimos, se trata de un edificio de factura contemporánea en el que estaban las oficinas de la empresa Aldeasa, hasta que fue adquirido en 1996 por la Dirección del Patrimonio del Estado, que lo adscribió al Prado para instalar en él las oficinas del museo, hasta entonces ubicadas en el ático sur del edificio Villanueva. En el espacio ganado, se habilitaron once nuevas salas; diez que acogen obras de Goya (entre ellas los cartones para tapices) y de contemporáneos españoles suyos, como Paret, Luis Meléndez, Vicente López y Maella, y una circular que se utilizó inicialmente como sala de exposiciones temporales de dibujos, luego, tras el traspaso de las actividades expositivas al Edificio Jerónimos, se habilitó como sala de bocetos y pinturas de gabinete españoles del siglo XVIII, y que tras la nueva remodelación de esa área inaugurada en julio de 2015 ha quedado sin uso.

La rehabilitación del conjunto de estas salas se hizo según proyecto del artista Gustavo Torner, que llevaba ocupándose del montaje de las salas del museo desde 1980, en particular las del ático norte, en las que, al igual que en estas, se encargó además del diseño arquitectónico.

Por otro lado, en el local del edificio contiguo, el del número 21 de la calle Ruiz de Alarcón, tiene su sede la Fundación Amigos del Museo.

En 2012 el Ministerio de Educación, Cultura y Deporte adscribió parcialmente al museo el edificio de la calle Pérez Ayuso número 20 de la capital, para instalar en él su nuevo almacén de marcos.

El edificio abulense conocido como Casa de Miguel del Águila, por quién mandó construirlo en 1546, o, más comúnmente, como Palacio de los Águila, fue legado con todo su contenido al Estado por su última propietaria privada, María Luisa Narváez y Macías, V duquesa de Valencia, fallecida en 1983, para la instalación en él de un museo. Inicialmente (1992) fue adscrito al Museo de Ávila, pero mediante un nuevo convenio de colaboración entre el entonces Ministerio de Educación y Cultura y la Junta de Castilla y León se cambió la adscripción, pasando a estar asignado al Museo del Prado. De este modo, este antiguo palacio de típica cantería abulense pasaba a ser la primera sede del Prado fuera de Madrid, destinada a acoger el Centro de Gestión de Depósitos (véase sección El «Prado disperso»).

Las labores para la adaptación a su nuevo uso se iniciaron en 2003, pero pasaron por muchas vicisitudes, incluido un contencioso entre el Ministerio y la empresa adjudicataria que acabó con la rescisión del contrato y la adjudicación a una nueva contratista. También hubo retrasos a causa del hallazgo de restos arqueológicos romanos, medievales y modernos, todo lo cual resultó en que las obras quedaran paralizadas durante años. Finalmente, en 2018 se decidió retomar el proyecto, con la previsión de que las obras se reiniciaran al año siguiente, pero destinándolo a nueva sede del Museo de Ávila, mientras que el Prado solo dispondrá de un espacio de 300 metros cuadrados en un edificio de nueva planta dentro del recinto, que acogerá la «Sala Prado», en la que se realizarán exposiciones temporales de larga duración de fondos de la pinacoteca nacional.

El museo está dotado de una plantilla de investigadores, y también colabora con investigadores externos en algunos proyectos. Además de catálogos razonados y catálogos de las exposiciones temporales, desde 1980 publica un "Boletín", actualmente con periodicidad anual, en el que se dan a conocer novedades sobre las colecciones.

El Prado cuenta con un Gabinete de Documentación Técnica —Gabinete Técnico— y un Laboratorio de Análisis, en los que se examinan las obras de su colección, como apoyo a proyectos de conservación/restauración o de investigación, y también algunas piezas ajenas a la institución, en virtud de acuerdos de colaboración o para estudiar potenciales adquisiciones. Además, a través de su Área de Educación, organiza cursos de alta especialización, congresos internacionales y simposios. La reciente creación del Centro de Estudios del Museo viene a reforzar la actuación del Prado en este campo (ver sección Casón del Buen Retiro).

El Museo Nacional del Prado lleva a cabo una intensa política de exposiciones temporales que revisa, conmemora y da a conocer los aspectos de la historia del arte que más estrechamente se relacionan con sus propios fondos, o que los complementan. Así, el Prado ha repasado a través de exposiciones los grandes núcleos de interés de sus colecciones, desde la pintura medieval hasta la del , pasando por muestras dedicadas a algunos de sus pintores más significativos como el Greco (a quien estuvo consagrada la primera exposición monográfica que realizó, en 1902), Murillo, Zurbarán, Ribera, Patinir, Durero, Tiziano, Tintoretto, Velázquez, o Goya, además de otras dedicadas a algunos de los coleccionistas más importantes relacionados con su historia, como Felipe II, Felipe IV, Cristina de Suecia, Carlos I de Inglaterra, Felipe V, o Ramón de Errazu. Aunque también las ha habido de artistas que no tienen representación o están escasamente representados a pesar de tratarse de destacados nombres de la historia del arte, como Vermeer, Rembrandt o Turner, así como presentaciones panorámicas de los fondos de otras grandes instituciones, como el Hermitage (2011-2012) o la Hispanic Society (2017).

El total de visitantes de las muestras celebradas en su sede fue de en 2019. La exposición más vista en la historia de la institución fue la antológica dedicada al Bosco en 2016 (589 000 visitantes). Aunque tradicionalmente se había dicho que la de Velázquez en 1990 había logrado 600 000, posteriormente el museo afirmó que había sido un error, al no haber entonces una contabilización precisa, y que la cifra real fue de 500 000. En cualquier modo, en la antológica velazqueña se vendieron más de 300 000 catálogos, lo que constituyó un récord mundial, que dejaron unos beneficios con los que al año siguiente se costeó parte de la compra del "Bodegón de caza, hortalizas y frutas" de Sánchez Cotán.

Desde abril de 2007 y en conexión con la apertura de la ampliación de la pinacoteca, que tendría lugar en noviembre de ese año, dio comienzo una nueva política de exposiciones que asume la exhibición de obras de artistas contemporáneos. Hasta ahora se ha celebrado ya una exposición de fotografías de museos de Thomas Struth, que se convirtió así en el primer artista vivo que expone en el Prado desde el , también se ha visto una selección de obras de artistas españolas en activo con las colecciones del Prado como referencia en común, un "happening" de Miquel Barceló acompañado del coreógrafo Josef Nadj, una de Cy Twombly inspirada en la batalla de Lepanto, y una antológica de Francis Bacon, que redefinen así la misión sustancial del Prado en la cultura española y le implican directamente en la acción del Estado sobre el arte actual.

Este nuevo rumbo del Museo ha suscitado importantes críticas por reconocidos expertos en el campo de la museología y la historia del arte. De hecho, se ha considerado que esta nueva programación podría afectar de algún modo al Real Decreto 410/1995, de 17 de marzo, que marca el límite de la actividad museística entre los dos grandes museos nacionales españoles de pintura y que señala que los artistas nacidos después de 1881, año del nacimiento de Picasso, corresponden salvo algunas excepciones que están especificadas en ese documento legal, al Museo Reina Sofía, cuya acción quedaría menoscabada por la del Prado.

En 2009 se inició una nueva modalidad dentro de este apartado con el programa "La obra invitada", microexposiciones limitadas generalmente a una única pieza pero especialmente destacada. Mediante él se han expuesto, entre otras, "La Magdalena penitente de la lamparilla, "o" Magdalena Terff", de Georges de La Tour, prestada por el Museo del Louvre, "La compañía del capitán Reijnier Reael" (Frans Hals, Rijksmuseum), "Las hijas de Edward Darley Boit" (Sargent, Museo de Bellas Artes de Boston), "El Descendimiento" (Caravaggio, Museos Vaticanos), "La acróbata de la bola" (Picasso, Museo Pushkin), "Retrato de un caballero" (Velázquez, Museo Metropolitano de Arte), "La Virgen con el Niño y ángeles", del "Díptico de Melun" de Jean Fouquet (Museo Real de Bellas Artes de Amberes), la custodia de la iglesia de san Ignacio de Bogotá, conocida como "La Lechuga" por el verde de sus 1485 esmeraldas, obra de José Galaz cedida por la Colección de Arte del Banco de la República, "San Juanito", de Miguel Ángel (Fundación Casa Ducal de Medinaceli) y "Don Pedro de Alcántara Téllez-Girón y Pacheco, IX duque de Osuna" (Frick Collection, Nueva York) y "La última comunión de San José de Calasanz" (Orden de las Escuelas Pías de la provincia de Betania), ambas de Goya.

Además hay conciertos, representaciones teatrales y se realizan proyecciones de largometrajes y documentales como complemento de las exposiciones, y también existen ciclos de conferencias, en muchos casos conectados igualmente con las muestras temporales. Asimismo desarrolla una amplia labor difusora del conocimiento de sus colecciones a través de ambiciosos programas educativos destinados a centros docentes fuera y dentro de la Comunidad de Madrid.

Los copistas (antiguamente denominados «copiantes») siempre han tenido abiertas las puertas del Prado desde su inicio. Dado que el enfoque con el que se creó el museo fue el de servir de instrumento de aprendizaje para los pintores, incluso al principio estuvieron privilegiados frente al público general, que solo podía acceder los miércoles, mientras que ellos y los estudiosos podían hacerlo todos los días no festivos.

En la década de 1960 llegó a haber cincuenta simultáneamente, pero desde entonces, con el fin de evitar molestias a los visitantes, se limitó su número a dieciséis. Por ese mismo motivo, hay obras para las que no se conceden permisos de copia: "Las meninas", "Las majas" y "El jardín de las delicias", así como aquellas que estén colgadas junto a una esquina o una puerta. Además, las copias, para cuya ejecución se otorga por lo general un plazo de entre seis y siete semanas, por motivos de seguridad han de diferir en al menos cinco centímetros en cada lado respecto al original. Entre los autores más demandados figuran Murillo, Velázquez, Goya, el Greco y Rubens.

Algunos de los pintores que han copiado obras en el museo han llegado a ser artistas ilustres, como Courbet, Franz von Lenbach, Sargent, Sorolla, Picasso, Sonia Delaunay, o Fortuny, del que precisamente el Prado posee sendas copias que realizó en sus salas del "Menipo" de Velázquez y de un "San Andrés" (P01078) de Ribera.

En el año 2017 los gastos ascendieron a 42,095 millones de euros. Por su parte, los ingresos fueron de 45,418 millones. De ellos, 19,637 procedieron de la venta de entradas, 7,370 de patrocinios y 13,396 de la aportación estatal. El porcentaje de autofinanciación fue del 66,9%.





En 2019 recibió el Premio Princesa de Asturias de Comunicación y Humanidades. Ese mismo año, la Real Academia de Bellas Artes de San Fernando le concedió su Medalla de Honor. También en 2019, el Área de Restauración del museo fue galardonada con el Premio Nacional de Restauración y Conservación de Bienes Culturales.







</doc>
<doc id="42014" url="https://es.wikipedia.org/wiki?curid=42014" title="Radioisótopo sintético">
Radioisótopo sintético

Los radioisótopos sintéticos son isótopos radiactivos que no se encuentran de forma natural en la Tierra, pero que se pueden crear mediante reacciones nucleares (algunos isótopos radiactivos pueden estar presentes de forma natural o bien ser preparados artificialmente).

Un ejemplo es el isótopo tecnecio-99 metaestable, Tc, que se obtiene por desintegración beta de Mo. Se emplea en medicina nuclear.


</doc>
<doc id="42029" url="https://es.wikipedia.org/wiki?curid=42029" title="Belleza (desambiguación)">
Belleza (desambiguación)

Belleza, puede hacer referencia a lo siguiente:


</doc>
<doc id="42030" url="https://es.wikipedia.org/wiki?curid=42030" title="María de Austria (Velázquez)">
María de Austria (Velázquez)

El retrato de María de Austria, Reina de Hungría fue pintado por Velázquez en 1630 y se conserva en el Museo del Prado.

María de Austria (1606 a 1646) era hija del rey Felipe III de España y de su esposa Margarita de Austria, hermana, pues, del siguiente rey, Felipe IV de España. Durante el reinado de este último, en 1631, María contrajo matrimonio con Fernando III de Habsburgo que era rey de Hungría y de Bohemia y que sería más tarde emperador de Alemania.

Se trata de una obra muy lograda en que el autor capta perfectamente la psicología de la futura emperatriz. Tal y como venía haciendo en retratos anteriores, Velázquez pinta sobre un fondo neutro para resaltar la figura. Todo está tratado con gran calidad: el traje verdoso, la lechuguilla (indumentaria) gris y sobre todo el cabello, realizado con gran esmero y detalle minucioso.

En 1630 el pintor Diego Velázquez se encontraba de viaje por Italia. Ya de regreso para España pasó los últimos tres meses de ese año en la ciudad italiana de Nápoles y fue durante esa estancia cuando realizó el retrato de María Ana de Austria, todavía infanta pues aún no había tenido lugar su casamiento con Fernando III. El objeto de hacer este retrato era el de traérselo consigo para España y entregárselo a Felipe IV como recuerdo de su hermana, a la que no volvería a ver. Desde la época del emperador Carlos I hubo la costumbre de pintar retratos de parentela entre los reyes y sus allegados, en la mayoría de los casos como presentación del personaje a otras personalidades, con motivo de futuras bodas o simplemente para recuerdo de familia.

Esta obra se encuentra actualmente en el Museo del Prado de Madrid.



</doc>
<doc id="42031" url="https://es.wikipedia.org/wiki?curid=42031" title="El martirio de San Andrés (Murillo)">
El martirio de San Andrés (Murillo)

El martirio de San Andrés es una obra de Bartolomé Esteban Murillo pintada entre 1675 y 1682, expuesta en el Museo del Prado.

El tono de la toda la composición recuerda a las obras de Peter Paul Rubens, especialmente a un "martirio de san andrés" realizado por el flamenco. Otra influencia para este cuadro es, sin lugar a dudas, "El martirio de San Felipe", del tenebrista José de Ribera.

La imagen de esta página representa el martirio de San Andrés que según cuenta un relato del siglo III, murió en Patras (Peloponeso, actualmente Grecia) atado a una cruz en forma de equis, tal y como se ve en la pintura. 

Es ésta una obra de encargo. Murillo no pintaba casi nunca este tipo de asuntos religiosos. Aquí se puede ver un estilo más colorista que en su primera etapa, influenciado en este caso por Rubens y Ribera.

En el centro y dominando el cuadro se ve a San Andrés en su cruz de aspa. A su alrededor se aprecia una gran iluminación y justo en el centro esa misma iluminación es amarillenta y parece que viene del cielo. Se adivinan en ella unos pequeños querubines. A la izquierda se ven unas mujeres en una escena muy realista. A la derecha hay unos caballos con sus jinetes y casi en primer plano se ve la grupa de uno de ellos. También nos presenta el pintor la presencia de un hombre con su perro. Este animal no falta nunca o casi nunca en las composiciones de Murillo. En este caso, el perro se gira hacia su amo, sin importarle nada la escena que están presenciando. El fondo del cuadro está muy desvanecido y a penas se intuyen unas arquitecturas al estilo del pintor Veronés. En todo el cuadro hay una atmósfera especial, técnica que el pintor adoptó en sus últimos años.



</doc>
<doc id="42032" url="https://es.wikipedia.org/wiki?curid=42032" title="Martirio de san Felipe (Ribera)">
Martirio de san Felipe (Ribera)

El Martirio de san Felipe es un lienzo del pintor español José de Ribera (1591-1652), una de las grandes obras dentro de su producción pictórica. Pertenece a la escuela española del siglo XVII. Estuvo instalado en el desaparecido Palacio del Buen Retiro (Madrid).

Durante un tiempo se pensó que representaba el martirio de san Bartolomé, pero no se encuentra aquí el gran cuchillo con el que se lo suele representar, alusivo a que fue desollado vivo. Por eso se acabó considerando que se trata de san Felipe.

La escena representa los preparativos para el martirio del santo, descrito en su leyenda por Santiago de la Vorágine. Según dicha leyenda, murió crucificado pero no sujeto por clavos sino amarrado con cuerdas. La composición de la escena está realizada geométricamente, sobre líneas diagonales y verticales. Ribera emplea aquí el escorzo de manera bastante violenta. El santo está pintado con una gran fuerza mística, en actitud de abandono, y con un estudio del desnudo magnífico. La luz ilumina su rostro, revelando sufrimiento y resignación. Los contrastes de luz y sombras de su cara potencian el dramatismo.

Los sayones que lo sujetan para izar el cuerpo se ven en primer término; uno de ellos ayuda sujetando las piernas. A la derecha hay un grupo de personas que curiosean la escena y parece que la comentan. A la izquierda, por el contrario, las personas que aparecen están ajenas a lo que sucede; en este grupo hay una mujer que sostiene en sus brazos un niño pequeño y que mira hacia el espectador, poniendo el contrapunto tierno y delicado a la crueldad que domina el resto de la escena. Algunos críticos han querido ver en esta figura una alegoría de la Caridad.

Es una obra de madurez del pintor, a juzgar por el tratamiento del colorido, los toques de pincel y el espléndido desnudo. Es menos caravagista que en obras anteriores, dotando al lienzo de mayor luminosidad. Se ha apuntado la posibilidad de que le hayan influido pintores más clasicistas como Guido Reni o Domenichino. El cromatismo se aleja de los tonos terrosos propios del barroco español, acercándose más a la influencia veneciana. El crítico Eugenio D'Ors llegó a decir de esta obra que por su vistosidad era «casi, casi, como un ballet ruso».

Se encontraba en el antiguo Alcázar de Madrid y se piensa que fue un encargo de Felipe IV, que quiso tener así a su patrón. En la actualidad se encuentra en el Museo del Prado de Madrid.



</doc>
<doc id="42036" url="https://es.wikipedia.org/wiki?curid=42036" title="Maxilar">
Maxilar

El hueso maxilar (denominado también maxila o maxilar superior) es un hueso de la cara, par, corto y de forma irregular cuadrilátera, con cuatro caras, interna y externa, cuatro bordes y cuatro ángulos. Es el hueso más importante del viscerocráneo.

En su interior se encuentra una cavidad, recubierta de mucosa y rellena de aire, denominada seno maxilar. Su inflamación, con acumulación de moco o material purulento da lugar a sinusitis.

Se encuentra en el centro de la cara, debajo del frontal y del etmoides. Se articula con estos huesos y con el maxilar superior del otro lado (contralateral), el cigomático (o malar o pómulo), el lagrimal (o lacrimal o unguis), el hueso propio de la nariz (o nasal), el vómer, la porción horizontal del hueso palatino y el cornete inferior (o concha nasal inferior).

El maxilar presenta un cuerpo y varias prolongaciones o procesos. Estos son: el proceso frontal, que articula con el hueso frontal, el proceso cigomático, que articula con el hueso cigomático, el proceso palatino, que constituye los dos tercios anteriores del paladar duro, y el proceso alveolar, donde se implantan los dientes.

Presenta una base mayor o interna que forma parte de la cavidad nasal, una base menor o externa que se articula con el hueso cigomático (o malar) y un reborde inferior, donde se alojan los dientes de la arcada superior.

Tiene tres apófisis (procesos): procesos frontales, para la escotadura frontal, procesos palatinos que se articula con la del lado opuesto y los procesos alveolares, para los dientes, poco desarrollado en la infancia y atrófico en la senilidad.
Tiene dos bases, una mayor y otra menor.

Otra estructura perteneciente a la base mayor es el canal lacrimonasal y un grupo de semiceldillas que se corresponden con sus homólogas de las masas laterales del etmoides, formando en conjunto las celdillas etmoidales.

Superficie rugosa que se articula con el malar, o hueso cigomático o pómulo.

El cuerpo tiene cuatro caras: una superior (orbitaria), una nasal, una posterior (infratemporal o cigomática) y una anterior (facial).

La cara orbitaria se ubica superior al cuerpo del hueso y forma parte del suelo de la cavidad orbitaria u órbita. Presenta un canal que pasa a convertirse en el conducto infraorbitario, y que se abre a la cara anterior o facial: el conducto infraorbitario, por el cual pasa el paquete vásculo-nerviosos infraorbitario (la arteria y nervio infraorbitario). Este conducto, antes de terminar, da en el espesor del hueso el canal dentario anterior que rodeando el orificio piriforme de las fosas nasales, llega al reborde alveolar donde da varias ramificaciones para alvéolos incisivos y caninos (paso de nervios y vasos dentarios anteriores).
Por su disposición se distinguen en la cara superior del maxilar tres bordes:

La cara nasal es medial al cuerpo de hueso y conforma la pared lateral de la cavidad nasal. Es recorrida por el conducto nasolagrimal. En su interior se ubica el seno maxilar.
Articula con la concha o cornete inferior, el cual delimita la salida del seno maxilar, adelante se articula con la cresta turbinal inferior, cubre el canal nasolagrimal convirtiéndolo en conducto nasolagrimal hacia atrás llega hasta la apófisis maxilar del palatino.

Denominada también tuberosidad del maxilar se ubica posterior al proceso cigomático y presenta la tuberosidad del maxilar. Presenta tres pequeños orificios que pasan a ser canales dentarios posteriores, permitiendo el paso de nervios y vasos dentarios posteriores. Esta tuberosidad forma parte de las fosas cigomática y pterigomaxilar, articulándose con el palatino y con las apófisis o los procesos pterigoides del esfenoides.

Limitada por arriba por el reborde orbitario, en su parte posterior por la cresta cigomático-alveolar, por abajo por el reborde alveolar y por delante por el orificio piriforme y la espina nasal.

Además presenta: fosita mirtiforme (músculo mirtiforme y haces del orbicular de los labios), limitada hacia afuera por eminencias caninas (inserción del músculo tranverso de la nariz) y fosa canina (músculo canino). y orificio suborbitario ubicado por debajo de la mitad del reborde orbitario.

=En otros animales=
Los maxilares están presentes en todos los vertebrados con esqueleto óseo. En la mayoría de los vertebrados, la parte más anterior de los maxilares, donde se encuentran los dientes incisivos, consiste en un par de huesos separados llamados premaxilares. Estos todavía se encuentran como huesos separados en el desarrollo hasta aproximadamente los cinco años de edad. Estos se fusionan con los maxilares en los humanos y algunos otros mamíferos. En los peces, anfibios y reptiles, tanto los premaxilares como los maxilares forman los lados externos de las quijadas, con los premaxilares formando el límite inferior de las narinas. En los mamíferos, en los cocodrilos y, parcialmente, en algunas tortugas, los huesos se curvan interiormente para formar el techo de la boca o paladar secundario.




</doc>
<doc id="42037" url="https://es.wikipedia.org/wiki?curid=42037" title="Cornete nasal inferior">
Cornete nasal inferior

El cornete inferior ("Concha nasalis inferior") es un hueso de la cara, par, formado cada uno por una lámina ósea compacta, con dos caras, interna y externa, dos bordes y dos extremos.

Se encuentra en la porción inferior de las fosas nasales. Se articula con el etmoides y maxilar superior por arriba, con el unguis por delante y con el palatino por detrás



Los dos extremos de la concha inferior son:

Uno y otro se aplican sobre las crestas anteroposteriores de estos dos huesos. Los dos extremos de la concha inferior son angulosos y terminan en punta: siempre se distingue el posterior por ser más afilado que el anterior.

El cornete inferior se articula con tres huesos:

Está formado exclusivamente por hueso compacto y delgado, y se halla enteramente tapizado por la mucosa nasal

Se origina de un solo centro de osificación, el cual se desarrolla muy tardíamente hacia el cuarto o quinto mes de vida extrauterina.
Compacta.

"Este artículo incorpora material de la 6ª edición del Tratado de Anatomía Humana de L. Testut de 1912, que se encuentra en el dominio público."


</doc>
<doc id="42043" url="https://es.wikipedia.org/wiki?curid=42043" title="Inductor">
Inductor

Un inductor, bobina o reactor es un componente pasivo de un circuito eléctrico que, debido al fenómeno de la autoinducción, almacena energía en forma de campo magnético.

Un inductor está constituido normalmente por una bobina de conductor, típicamente alambre o hilo de cobre esmaltado. Existen inductores con núcleo de aire o con núcleo hecho de material ferroso (por ejemplo, acero magnético), para incrementar su capacidad de magnetismo.

Los inductores también pueden estar construidos en circuitos integrados, usando el mismo proceso utilizado para realizar microprocesadores. En estos casos se usa, comúnmente, el aluminio como material conductor. Sin embargo, es raro que se construyan inductores dentro de los circuitos integrados; es mucho más práctico usar un circuito llamado "girador" que, mediante un amplificador operacional, hace que un condensador se comporte como si fuese un inductor.

El inductor consta de las siguientes partes:

También pueden fabricarse pequeños inductores, que se usan para frecuencias muy altas, con un conductor pasando a través de un cilindro de ferrita o granulado.

Sea una bobina o solenoide, constituido por un conductor de longitud "l" y sección "S", y que ha sido devanado en "N" espiras, por el que circula una corriente eléctrica "i"("t").

Aplicando la Ley de Biot-Savart que relaciona la inducción magnética, "B"("t"), con la causa que la produce, es decir, la corriente "i"("t") que circula por el solenoide, se obtiene que el flujo magnético "Φ"("t") que abarca es igual a: 

Si el flujo magnético es variable en el tiempo, se genera en cada espira, según la Ley de Faraday, una "fuerza electromotriz (f.e.m.)" de autoinducción que, según la Ley de Lenz, tiende a oponerse a la causa que la produce, es decir, a la variación de la corriente eléctrica que genera dicho flujo magnético. Por esta razón suele llamarse "fuerza contraelectromotriz". Esta tiene el valor:

A la expresión formula_3 se le denomina "coeficiente de autoinducción", "L", el cual relaciona la variación de corriente con la f.e.m. inducida y, como se puede ver, depende de la geometría de la bobina y del núcleo en la que está devanada. Se mide en henrios.

La bobina almacena energía en forma de campo magnético cuando aumenta la intensidad de corriente, devolviéndola cuando esta disminuye. Matemáticamente se puede demostrar que la energía formula_4, almacenada por una bobina con inductancia formula_5, que es recorrida por una corriente de intensidad formula_6, viene dada por:

De la formulación física de la bobina se ha extraído la expresión:

Suponiendo una bobina ideal, (figura 1), sin pérdidas de carga, aplicando la segunda Ley de Kirchhoff, se tiene que:

Es decir, en toda bobina eléctrica dentro de un circuito se produce en ella una caída de tensión:

Despejando la intensidad:
Si en el instante "t" = 0, la bobina está cargada con una corriente "I", esta se puede sustituir por una bobina descargada y una fuente de intensidad de valor i(0) = "I" en paralelo.

La corriente por la bobina y por tanto el flujo no pueden variar bruscamente ya que si no la tensión formula_12 debería hacerse infinita. Por eso al abrir un circuito en donde se halle conectada una bobina, siempre saltará un arco de corriente entre los bornes del interruptor que da salida a la corriente que descarga la bobina.

Cuando el inductor no es ideal porque tiene una resistencia interna en serie, la tensión aplicada es igual a la suma de la caída de tensión sobre la resistencia interna más la fuerza contra-electromotriz autoinducida.

En corriente alterna, una bobina ideal ofrece una resistencia al paso de la corriente eléctrica que recibe el nombre de reactancia inductiva, formula_13, cuyo valor viene dado por el producto de la pulsación (formula_14) por la inductancia, "L":

Si la pulsación está en radianes por segundo (rad/s) y la inductancia en henrios (H) la reactancia resultará en ohmios.

De acuerdo con la ley de Ohm circulará una corriente alterna que se verá retrasada 90° (formula_16) respecto a la tensión aplicada.

Al igual que las resistencias, las bobinas pueden asociarse en serie (figura 2), paralelo (figura 3) o de forma mixta. En estos casos, y siempre que no exista acoplamiento magnético, la inductancia equivalente para la asociación en serie vendrá dada por:
Para la asociación en paralelo tenemos:

Para la asociación mixta se procederá de forma análoga que con las resistencias.

Si se requiere una mayor comprensión del comportamiento reactivo de un inductor, es conveniente 
entonces analizar detalladamente la Ley de Lenz y comprobar de esta forma cómo se origina una reactancia de tipo inductiva, la cual nace debido a una oposición que le presenta el inductor o bobina a la variación de flujo magnético.

Una bobina ideal en corriente continua se comporta como un cortocircuito (conductor ideal), ya que al ser i("t") constante, es decir, no varía con el tiempo, no hay autoinducción de ninguna f.e.m.

Una bobina real en régimen permanente se comporta como una resistencia cuyo valor formula_20 (figura 6a) será el de su devanado.

En régimen transitorio, esto es, al conectar o desconectar un circuito con bobina, suceden fenómenos electromagnéticos que inciden sobre la corriente (ver circuitos serie RL y RC).

Al conectar una CA sinusoidal "v"("t") a una bobina aparecerá una corriente "i"("t"), también sinusoidal, esto es, variable, por lo que, como se comentó más arriba, aparecerá una fuerza contraelectromotriz, -"e"("t"), cuyo valor absoluto puede demostrase que es igual al de "v"("t"). Por tanto, cuando la corriente i("t") aumenta, e ("t") disminuye para dificultar dicho aumento; análogamente, cuando "i"("t") disminuye, "e"("t") aumenta para oponerse a dicha disminución. Esto puede apreciarse en el diagrama de la figura 4. Entre 0° y 90° la curva "i"("t") es negativa, disminuyendo desde su valor máximo negativo hasta cero, observándose que "e"("t") va aumentando hasta alcanzar su máximo negativo. Entre 90° y 180°, la corriente aumenta desde cero hasta su valor máximo positivo, mientras "e"("t") disminuye hasta ser cero. Desde 180° hasta los 360° el razonamiento es similar al anterior.
Dado que la tensión aplicada, "v"("t") es igual a -"e"("t"), o lo que es lo mismo, está desfasada 180° respecto de "e"("t"), resulta que la corriente "i"("t") queda retrasada 90° respecto de la tensión aplicada. Consideremos por lo tanto, una bobina "L", como la de la figura 1, a la que se aplica una tensión alterna de valor:

De acuerdo con la ley de Ohm circulará una corriente alterna, retrasada 90° (formula_16) respecto a la tensión aplicada (figura 5), de valor:

donde formula_24. Si se representa el valor eficaz de la corriente obtenida en forma polar:

Y operando matemáticamente:

formula_26

Por lo tanto, en los circuitos de CA, una bobina ideal se puede asimilar a una magnitud compleja sin parte real y parte imaginaria positiva:

En la bobina real, habrá que tener en cuenta la resistencia de su bobinado, "R", pudiendo ser su circuito equivalente o modelo, el que aparece en la figura 6b) o 6c) dependiendo del tipo de bobina o frecuencia de funcionamiento, aunque para análisis más precisos pueden utilizarse modelos más complejos que los anteriores.

Examinemos el comportamiento práctico de un inductor cuando se interrumpe el circuito que lo alimenta. En el dibujo de derecha aparece un inductor que se carga a través de una resistencia y un interruptor. El condensador dibujado en punteado representa las capacitancias parásitas del inductor. Está dibujado separado del inductor, pero en realidad forma parte de él, porque representa las capacidades parásitas de las vueltas del devanado entre ellas mismas. Todo inductor tiene capacidades parásitas, incluso los devanados especialmente concebidos para minimizarlas como el devanado en "nido de abejas".

A un cierto momento formula_28 el interruptor se abre. Si miramos la definición de inductancia:

vemos que, para que la corriente que atraviesa el inductor se detenga instantáneamente, seria necesario la aparición de una tensión infinita, y eso no puede suceder. Por esa razón la corriente continúa circulando a través de las capacidades parásitas de la bobina. Al principio, el único camino que tiene es a través las capacidades parásitas. La corriente continúa circulando a través la capacidad parásita, cargando negativamente el punto alto del condensador en el dibujo. 
Nos encontramos con un circuito LC que oscilará a una pulsación:

donde formula_31 es el valor equivalente de las capacidades parásitas. Si los aislamientos del devanado son suficientemente resistentes a las altas tensiones, y si el interruptor interrumpe bien el circuito, la oscilación continuará con una amplitud que se amortiguará debido a las pérdidas dieléctricas y resistivas de las capacidades parásitas y del conductor del inductor. Si además, el inductor tiene un núcleo ferromagnético, habrá también pérdidas en el núcleo.

Hay que ver que la tensión máxima (conocida como "sobretensión") de la oscilación puede ser muy grande, ya que el máximo de la tensión corresponde al momento en el cual toda la energía almacenada en la bobina <math>\scriptstyle


</doc>
<doc id="42050" url="https://es.wikipedia.org/wiki?curid=42050" title="Vientre frontal (músculo occipitofrontal)">
Vientre frontal (músculo occipitofrontal)

El músculo frontal ("") es un músculo "cutáneo" del cráneo. Algunos autores lo consideran la porción muscular anterior del músculo occipitofrontal. Se halla inervado por los filetes frontales de la rama temporofacial del nervio facial.

Tiene su origen en la galea aponeurótica y se inserta en la piel de manera superior al borde supraorbitario. Este músculo mueve el cuero cabelludo en sentido anterior, eleva las cejas y arruga horizontalmente la piel de la frente.

Si el músculo frontal se contrae aisladamente, conduce hacia adelante la aponeurosis epicranea, elevando la piel de las cejas. En la expresión de fisonomía el frontal es el músculo de la atención, y la manifiesta en sus diferentes grados. Desde la simple expresión de sorpresa hasta la admiración y el espanto. Este es un músculo cuyo objetivo es informar sus movimientos.


</doc>
<doc id="42059" url="https://es.wikipedia.org/wiki?curid=42059" title="Helena (mitología)">
Helena (mitología)

Helena (en griego antiguo: Ἑλένη), a veces conocida como Helena de Troya o Helena de Esparta, es un personaje de la mitología griega cuyo nombre tiene el significado de «tea» o «antorcha». Casi todos los mitógrafos clásicos aluden a su mito. Era considerada hija de Zeus y pretendida por muchos héroes debido a su gran belleza. Fue seducida o raptada por Paris, príncipe de Troya, lo que originó la guerra de Troya.

Zeus, transformado en cisne, sedujo a Leda y yació con ella la misma noche que Tindáreo, esposo de Leda y rey de Esparta. Como consecuencia de ello, Leda puso dos huevos; de uno nacieron Helena y Pólux, ambos inmortales (considerados hijos de Zeus), y del otro Clitemnestra y Cástor, mortales (considerados hijos de Tindáreo). De todas maneras, se consideraba a Cástor y Pólux como gemelos y se los conocía como Dioscuros. Otras hermanas de Helena fueron Timandra y Filónoe.

Otra tradición decía que Helena había nacido de la unión de Némesis y Zeus, transformados respectivamente en oca y cisne. El huevo que puso Némesis fue encontrado por un pastor que lo entregó a Leda. Del huevo nació Helena y Leda la cuidó como si fuera su auténtica madre.

En el santuario de las Leucípides de Esparta había un huevo colgado del techo y sostenido por cintas, se creía que éste era aquel en el que había dado a luz Leda.

Helena fue reconocida por su belleza desde que era una niña. Un día, mientras participaba danzando en un sacrificio en el santuario de Artemisa Ortia de Esparta, fue sorprendida y raptada por el héroe ateniense Teseo en compañía de su amigo Pirítoo. Tras capturarla, echaron a suertes la doncella, correspondiéndole a Teseo. Pero cuando Teseo volvió a Atenas, el pueblo ateniense no permitió la entrada de la muchacha en la ciudad, motivo por el que Teseo la condujo a Afidna, junto a su madre Etra. A continuación, Teseo y Pirítoo decidieron marchar al Hades para raptar a Perséfone con la intención de convertirla en consorte de Pirítoo. Durante la estancia en el Hades de Teseo y Pirítoo, los Dioscuros rescataron a Helena. A su vez tomaron como prisioneras a la madre de Teseo y a la hermana de Pirítoo, que condujeron hasta Esparta para convertirlas en esclavas de Helena.

Hay una tradición que dice que Helena y Teseo tuvieron como hija a Ifigenia, pero que, cuando Helena fue liberada por sus hermanos, ella decidió entregar su hija a su hermana Clitemnestra, que ya estaba casada con Agamenón. Pero la leyenda más extendida señalaba que Ifigenia era hija natural de Clitemnestra.

Cuando Helena llegó a la edad de casarse, tuvo muchos pretendientes que acudieron de toda Grecia, animados por la fama de su gran belleza y porque ella y su futuro esposo reinarían en Esparta. Tindáreo, temiendo provocar una guerra entre los pretendientes rechazados, siguió un consejo de Odiseo. A cambio, prometió a este su ayuda para conseguir a su sobrina Penélope como esposa.

El consejo de Odiseo consistía en arrancar a los pretendientes el juramento de acatar la decisión que se adoptase sobre quién sería el esposo de Helena y la obligación de acudir en auxilio del elegido si en algún momento su esposa le fuese seducida o raptada. Una vez realizado el juramento, Tindáreo eligió como marido de Helena a Menelao, hermano de Agamenón, rey de Micenas, que estaba casado con su otra hija, Clitemnestra. En otras versiones, fue la propia Helena la que eligió a Menelao.

Menelao y Helena tuvieron una hija, Hermíone y según algunos autores, también un hijo, Nicóstrato.

La diosa Afrodita había prometido al príncipe troyano Paris el amor de Helena como premio por haber decidido a su favor en el concurso de belleza que la había enfrentado a Hera y Atenea.

Paris fue a Esparta, donde fue recibido hospitalariamente por Menelao y Helena. Sin embargo, durante su estancia, Menelao tuvo que viajar a Creta para asistir al funeral por la muerte de su abuelo materno, Catreo.

Afrodita provocó que Helena se enamorase de Paris, y los amantes huyeron juntos de Esparta con el tesoro de Helena mientras Menelao se encontraba aún en Creta. Se unieron por primera vez en una isla de localización incierta llamada Cránae. Hera les envió una tempestad y, tras pasar por Chipre y Fenicia, llegaron a Troya. 

Otra versión señala que en realidad Helena no viajó con Paris a Troya sino que Zeus, Hera o Proteo formaron un espectro suyo, que fue lo que acompañó a Paris mientras la auténtica Helena fue trasladada a Egipto por Hermes. Se cree que la primera fuente de esta versión fue la palinodia compuesta por el poeta lírico Estesícoro, de la que quedan escasos fragmentos. Una leyenda añadía que el poeta había sido cegado por Helena (una vez que ella había sido divinizada) a causa de que anteriormente había compuesto un primer poema que la trataba muy desfavorablemente. Cuando Estesícoro compuso su palinodia, se le devolvió la vista. Un escolio atribuye a Estesícoro un comentario según el cual Afrodita hizo infieles a Helena y a sus hermanas Clitemnestra y Timandra para castigar a Tindáreo, que había olvidado ofrecer sacrificios a la diosa.

Otra tradición narra que Paris raptó a Helena y la llevó consigo por la fuerza.

Los mitógrafos discrepaban acerca de cómo fueron recibidos Helena y Paris cuando llegaron a Troya. Algunos decían que fueron mal recibidos por el pueblo, pero los hermanos de Paris y la reina Hécuba la recibieron favorablemente. Otros afirmaban que todos los troyanos se enamoraron de Helena e incluso el rey Príamo juró que nunca la dejaría marchar. Por su parte, la adivina Casandra vaticinó que Helena sería la ruina de la ciudad, pero no fue creída. 

Menelao, acompañado por una gran coalición de ejércitos comandados por los antiguos pretendientes de Helena y otros caudillos aqueos, zarpó hacia Troya en busca de su esposa. 

Antes del inicio de la guerra, Menelao y Odiseo fueron como embajadores a Troya para reclamar a Helena y el tesoro que se había llevado con ella, pero los troyanos se negaron a devolverla y los hubieran matado a no ser por la intervención de Antenor, anciano consejero troyano, a su favor. Por su parte, Partenio de Nicea señala en "Sufrimientos de amor" que los encargados de reclamar a Helena fueron Diomedes y Acamante. 

Heródoto ofrece una versión diferente: los troyanos aseguraban que no tenían en su poder a Helena ni sus tesoros y que todo ello estaba en Egipto con su rey Proteo. Los griegos creyeron que los troyanos se burlaban de ellos, pero cuando conquistaron por fin Troya, Helena no apareció, y entonces sí creyeron a los troyanos y Menelao fue enviado a Egipto en busca de su esposa. Heródoto se adhería personalmente a esta versión, argumentando que si Helena hubiera estado en Troya habría sido devuelta a los griegos porque ni Príamo ni el resto de los troyanos habrían aceptado correr el riesgo de la guerra solo para complacer a Paris. 

Algunos autores antiguos relatan que, durante la guerra, Afrodita y Tetis concertaron un encuentro entre Helena y Aquiles.

Helena es un personaje importante de la "Ilíada". Es estimada y respetada por el rey Príamo y por Héctor, mientras que los habitantes de Troya reconocen su belleza divina pero le atribuyen la causa de los males que padece su ciudad. Presenta los principales caudillos aqueos desde la torre de la ciudad a su suegro, Príamo, episodio conocido como teichoskopía. Desde allí presencia el duelo singular entre su anterior esposo, Menelao, y el príncipe Paris. Discute con Afrodita cuando la diosa la incita a que vaya junto a Paris una vez que ha concluido el duelo pero luego, por miedo a las amenazas de Afrodita, cede.

En la parte final del poema, Helena se lamenta por la muerte de su cuñado Héctor y señala que lleva ya veinte años en Troya.

Córito era un hijo que Paris había tenido con su anterior esposa: la ninfa Enone. Córito se enamoró de Helena y se decía que era un amor correspondido. Cuando Paris los descubrió, mató a Córito. Algunos mitógrafos, en cambio, señalaban que Córito era uno de los hijos de Helena y Paris. 

En el transcurso de la guerra, Paris murió y Helena fue obligada a contraer un nuevo matrimonio con Deífobo, otro de los hijos de Príamo. Por esta causa, otro hijo de Príamo, Héleno, que estaba enamorado de Helena, abandonó Troya. Como, igual que su hermana Casandra, tenía el don de la adivinación y Calcas, adivino de los griegos, sabía que conocía los oráculos que protegían la ciudad, Odiseo lo capturó, lo llevó al campamento y lo obligaron a revelar esos oráculos. 

Helena reconoció a Odiseo cuando él penetró en Troya como espía disfrazado de mendigo, pero no lo denunció. Los aqueos, para entrar en Troya, construyeron un caballo de madera y un puñado de guerreros destacados se escondieron en su interior. Los troyanos, ignorantes del contenido del caballo, lo introdujeron en su ciudad. Antes de que los guerreros salieran del caballo, la astuta Helena, conocedora del plan de los aqueos, dio varias vueltas a su alrededor acompañada de Deífobo, imitando las voces de las esposas de los guerreros griegos. Los aqueos estuvieron a punto de responder desde dentro del caballo y delatarse.

En algunas versiones, Helena fue la que agitó una antorcha desde su habitación durante la noche, que era la señal esperada por los aqueos: la de que las puertas de Troya iban a ser abiertas por los hombres que habían salido del caballo. 

La guerra terminó con el triunfo de la coalición aquea. Menelao mató a Deífobo y a punto estuvo también de matar a Helena, pero quedó deslumbrado y enamorado de nuevo por su hermosura y la perdonó. Algunos autores antiguos cuentan que fue la propia Helena la que mató a Deífobo y que Menelao perdonó a Helena cuando vio sus pechos desnudos. Tras un viaje de retorno accidentado en el que tuvieron que pasar una larga temporada en Egipto, ambos regresaron a Esparta. En el Ática hay una isla a la que se llamaba Isla de Helena, porque se creía que en ella había desembarcado durante su retorno a la Hélade. Tras este retorno, Helena y Menelao fueron padres de Nicóstrato, según algunos autores.

Helena aparece como personaje en la "Odisea", principalmente en el Canto IV. En el viaje realizado en busca de noticias de su padre Odiseo, Telémaco llega a Esparta, donde se entrevista con Helena y Menelao, que han vuelto a reinar allí. 

Homero afirma categóricamente que Helena tuvo como única descendiente a su hija Hermíone.

Helena ejerce de anfitriona junto con su esposo y recuerda algunos de los sucesos ocurridos en la guerra de Troya.

Existen múltiples versiones acerca del destino final de Helena. En algunas de ellas, Helena fue divinizada y enviada a los Campos Elíseos o a la isla de Leuce, en compañía de Menelao. Incluso existía una tradición que mencionaba que estaba en Leuce, pero casada con Aquiles. Se decía que Aquiles y Helena tuvieron allí un hijo que tenía alas: Euforión.

La tragedia "Orestes", obra de Eurípides, presentaba una variante de esta versión, en la que Orestes y su amigo Pílades habían decidido matar a Helena porque la consideraban causa del origen de sus males, ya que Orestes y su hermana Electra habían sido condenados a muerte por haber matado a su madre Clitemnestra. Pero no pudieron cumplir su propósito, porque Helena fue salvada y divinizada por Apolo. 

Sin embargo, otros insistían en que las tumbas de Helena y de Menelao se encontraban en el templo de Menelao en Terapne, cerca de Esparta. En este lugar se rendía culto a Helena. 

En una versión rodia, Polixo, esposa del caudillo aqueo Tlepólemo, simuló acoger a Helena en Rodas en su destierro de Esparta por los hijos de Menelao. Pólixo se vengó de la muerte de su esposo: tras disfrazar a sus criadas como Erinias para atormentar a la desterrada, hizo que Helena acabase por ahorcarse. Por ello, los rodios tienen en su isla un santuario de "Helena Dendrítide". Una versión alternativa de esta leyenda decía que Menelao, que viajaba con Helena desde Egipto y había hecho escala en Rodas, había podido ocultar a su esposa y había puesto los mejores ornamentos a la criada más hermosa. Polixo y los rodios, al confundir su identidad, la apedrearon y quemaron creyendo que se trataba de Helena.



















</doc>
<doc id="42060" url="https://es.wikipedia.org/wiki?curid=42060" title="Liguria">
Liguria

Liguria (en ligur: "Ligùria") es una de las veinte regiones que conforman la República Italiana. Su capital y ciudad más poblada es Génova. Está ubicada en Italia noroccidental, limitando al norte con Piamonte, al noreste con Emilia-Romaña, al este con Toscana, al sur con el mar de Liguria o golfo de Génova (mar Mediterráneo) y al oeste con Francia. Con 5422 km² es la tercera región menos extensa del país —por delante de Molise y Valle de Aosta, la menos extensa— y con 292 hab/km², la cuarta más densamente poblada, por detrás de Campania, Lombardía y Lacio. Forma parte de la Eurorregión Alpes-Mediterráneo.

Extendida entre las cadenas montañosas de los Alpes y de los Apeninos y el mar, la región se considera convencionalmente subdividida en dos partes delimitadas aproximadamente por la capital.

Su nombre deriva de la antigua población de los ligures, aunque en realidad los límites de la antigua Liguria eran bastante más extensos que los de la actual región e incluía toda la llanura piamontesa al sur del Po, la actual Lombardía suroccidental del Oltrepò pavese hasta la confluencia del río Ticino con el Po, las zonas de colinas y montañosas del Piacentino, la actual Lunigiana y el Nizzardo hasta el río Var.

Liguria limita con Francia al oeste, el Piamonte al norte y Emilia-Romaña y Toscana al este. Queda en la costa del mar de Liguria. Es una estrecha franja de tierra, encajada entre el mar y los Alpes y los Apeninos, es una extensión arqueada desde Ventimiglia hasta La Spezia y es una de las regiones más pequeñas de Italia. Su territorio es de 5.416,03 kilómetros cuadrados que se corresponden a 1,18 % de toda la superficie nacional. Su punto más alto es el Monte Saccarello (2201 m). Las montañas ocupan la mayor parte de la región, llegando a menudo hasta el mar con promontorios rocosos: 3.524,08 km de montaña (65 % del total) y 891,95 km de colinas (35 % del total).

La forma es la de una estrecha franja de tierra, de 7 a 35 km de ancho (respectivamente sobre Voltri y en las zonas de alta montaña alrededor de Imperia), de media alrededor de 240 km de largo, que queda en un semicírculo alrededor del mar de Liguria y con la convexidad hacia el norte; comprendida entre el mar y la vertiente de los Alpes Marítimos y los Apeninos septentrionales, que en algunos puntos cruza (por ejemplo en los montes Savona y de Génova). Algunas montañas se alzan por encima de los 2.000 msnm; la línea de vertiente recorre una altitud media de alrededor de 1.000 msnm.

La plataforma continental, que es muy estrecha, es tan inclinada que va hacia abajo casi inmediatamente hasta considerables profundidades marinas. El litoral tiene una longitud de 315 km. Excepto por los promontorios de Portovenere y Portofino en general no es muy recortada, y es a menudo alta. En la desembocadura de los mayores ríos hay pequeñas playas, pero no hay bahías profundas y radas naturales excepto los de Génova y La Spezia. Génova es el punto en el que se divide el litoral, aproximadamente, en la "Riviera" o Ribera de Poniente (Riviera de Poniente) y la "Riviera" o Ribera de Levante.
La Ribera de Poniente es el trozo de costa ligur comprendido entre Génova y la frontera francesa, cuenta con golfos, playas, pequeños pueblos de veraneo y también grandes extensiones de cultivos de hortalizas y flores. Aquí se encuentra Albenga, la ciudad principal de una vasta llanura intensamente cultivada y frecuentado centro de veraneo; Alassio, famosa por su playa y su moderno balneario y Sanremo, localidad de veraneo célebre y muy concurrida, sede de actos culturales, destacadamente el "Festival de la Canción". 

Por lo que se refiere a la Ribera de Levante, comprende la parte de costa ligur que va desde Génova al Golfo de La Spezia. También aquí hay playas, golfos y promontorios con numerosos puertos naturales. Entre los centros turísticos se encuentran Portofino, encerrado en una espléndida ensenada del promontorio poblado de árboles, que separa el golfo de Génova del de Tigullio; Rapallo, el centro balneario de Sestri Levante que se encuentra sobre un istmo que une la tierra firme con un promontorio rocoso y Cinqueterre, que son cinco pequeñas y sugestivas aldeas de pescadores ancladas en otras tantas ensenadas, entre la Punta del Mesco y la del Montenero. 

El anillo de colinas, que queda inmediatamente detrás de la costa, junto con la influencia benéfica del mar, son responsables del clima suave todo el año (con unas temperaturas medias en invierno de 7-10° y temperaturas en verano de 23°-24°) lo que hace que sea un lugar ameno incluso en pleno invierno.

La pluviosidad puede ser muy abundante a veces; montañas muy cercanas a la costa crean un efecto orográfico, de manera que Génova puede ser hasta 2000 mm de lluvia en un año; otras zonas en lugar muestra los valores normales de la zona mediterránea (500–800 mm). A pesar de la alta densidad de población, las maderas abarcan la mitad del área total. Las reservas naturales de Liguria abarcan el 12 % de toda la región, p.e. alrededor de 60.000 hectáreas de tierra, y están formados por una Reserva Nacional, seis grandes parques, dos parques menores y tres reservas naturales.

Restos del hombre de Neanderthal se descubrieron en la región de Loano, mientras que en Ventimiglia, en la cueva de "Balzi Rossi", se encontraron numerosos restos que recuerdan a los del hombre de Cro-Magnon. Según las fuentes escritas sobre los asentamientos de los ligures, la presencia de este pueblo de origen mediterráneo se remonta al I milenio a. C. en un vasto territorio que incluía la mayor parte de la Italia noroccidental. 

Durante la primera guerra púnica, los antiguos ligures fueron divididos, algunos de ellos se pusieron del lado de Cartago y una minoría con Roma, cuyos aliados incluyeron a los futuros genoveses. Después de la conquista romana de la región, la llamada "X regio Liguria", se creó en el reinado del emperador Augusto, cuando Liguria fue extendida desde la costa hasta las orillas del río Po. Grandes calzadas romanas fortalecieron la unidad territorial e incrementaron los intercambios y el comercio: via Aurelia y Julia Augusta en la costa, Postumia y Aemilia Scauri tierra adentro. Ciudades importantes se desarrollaron en la costa, de la que quedan evidencias en las ruinas de Albenga, Ventimiglia y Luni. Entre el siglo IV y el X, Liguria fue dominada por los bizantinos, los lombardos del rey Rotario (alrededor del 641) y los francos (alrededor de 774) y fue invadida por los sarracenos (según Arthur Hill Hassall, bajo ocupación y gobierno sarraceno desde h. 876 hasta h. 972) y los normandos. En el siglo X, una vez que decreció el peligro de los piratas, el territorio ligur fue dividido en tres marcas: Obertenga (al este), Arduinica (al oeste) y Aleramica (en el centro). En los siglos XI y XII las marcas se dividieron en feudos, y luego con el fortalecimiento del poder de los obispos, la estructura feudal comenzó a debilitarse parcialmente. Las principales ciudades ligures, especialmente en la costa, se convirtieron en ciudades-estado, sobre las que Génova pronto extendió su dominio. 

Entre el siglo XI (cuando los barcos genoveses tuvieron un papel importante en la primera cruzada, llevando caballeros y tropas a Oriente Próximo por un precio) y el siglo XV, la República de Génova experimentó un extraordinario éxito comercial y político (principalmente comercio de especias con Oriente) y fue la república marítima más poderosa del Mediterráneo desde el siglo XII hasta el XIV, como se prueba por la resistencia victoriosa contra el emperador Federico Barbarroja y por la presencia genovesa en los centros de poder durante la última fase del imperio bizantino. Tras la introducción del título de dogo vitalicio (1339) y la elección de Simón Boccanegra, Génova reanudó sus luchas contra el Marqués de Finale y los Condes de Laigueglia y conquistó de nuevo los territorios de Finale, Oneglia y Porto Maurizio. A pesar de sus éxitos militares y comerciales, Génova cayó presa de las facciones internas que presionaban en su estructura política.

Debido a su situación vulnerable, el gobierno de la república pasó a manos de la familia Visconti de Milán. Tras su expulsión por las fuerzas populares bajo el liderazgo de Boccanegra, la república permaneció en manos genovesas hasta 1396, cuando la inestabilidad interna llevó al dogo Antoniotto Adorno a entregar el título de Señor de Génova al rey de Francia. Los franceses fueron expulsados en 1409 y Liguria volvió a control de Milán en 1421, permaneciendo así hasta 1435. La alternancia entre el dominio francés y el milanés sobre la Liguria persistió hasta la primera mitad del siglo XVI. La influencia francesa cesó en 1528, cuando Andrea Doria se convirtió en el prestigioso aliado del poderoso rey de España e impuso un gobierno aristocrático que dio a la república una estabilidad relativa durante alrededor de 250 años.

El empobrecimiento de las rutas comerciales con Oriente Próximo forzaron a los notables ligures a implicarse, desde entonces, en la especulación financiera. La crisis internacional del siglo XVII, que acabó para Génova con el bombardeo (1684) por la flota del rey Luis XIV de Francia, restauró la influencia francesa sobre la república. Debido a esta influencia, el territorio ligur se vio atravesado por los ejércitos piamontés y austríaco cuando estos dos estados entraron en conflicto con Versalles. El límite se alcanzó con la ocupación austriaca de Génova en 1746. Las tropas de los Habsburgo fueron expulsadas por una insurrección popular en el mismo año. La primera campaña napoleónica en Italia marcó el final de la república secular que, por deseo del emperador, fue transformada en la República Ligur, según el modelo de la República Francesa. Después de la unión de Oneglia y Loano (1801), Liguria fue anexionada al Imperio Francés (1805) y dividida por Napoleón en tres departamentos: Montenotte, con capital en Savona, Génova y el departamento de los Apeninos, con capital en Chiavari.

Tras un breve período de independencia en 1814, el Congreso de Viena (1815) decidió que Liguria se anexionara al reino de Cerdeña. El alzamiento genovés contra la Casa de Saboya en 1821, que fue aplastada con gran derramamiento de sangre, suscitó los sentimientos nacionales de la población. Algunas de las más prestigiosas figuras del "«Risorgimento»" nacieron en Liguria (Mazzini, Garibaldi, Mameli, Lamberti, Bixio, entre otros). En los primeros años del siglo el crecimiento económico de la región fue notable: muchas industrias florecieron desde Imperia a La Spezia. Durante el período trágico de la Segunda Guerra Mundial Liguria experimentaron el hambre y dos años de ocupación por las tropas alemanas, contra quien la lucha de liberación fue la más efectiva de las de Italia, cuando las tropas aliadas finalmente llegaron, fueron bienvenidas por los partisanos que, en una insurrección exitosa, habían liberado la ciudad y aceptado la rendición del comando alemán local. Por este hecho la ciudad fue premiada con la medalla de oro al valor militar.

La densidad de población en Liguria es alta (casi 300 habitantes por kilómetro cuadrado en 2008), e inferior solo a las regiones de Campania, Lombardía y Lacio. En la Ciudad metropolitana de Génova, alcanza casi 500 habitantes por kilómetro cuadrado, mientras que en las provincias de Imperia y Savona es de menos de 200 habitantes por kilómetro cuadrado. La población de Liguria ha ido decayendo desde el año 1971 hasta 2001, más marcadamente en las ciudades de Génova, Savona y La Spezia. La pirámide de edad ahora parece más un "champiñón" que descansa sobre una frágil base. La tendencia negativa se ha interrumpido parcialmente solo en la última década cuando, después de una exitosa recuperación económica, la región ha atraído a constantes flujos de inmigrantes. Para 2008, el ISTAT calculó que vivían en Liguria 90 881 inmigrantes nacidos en el extranjero, lo que equivalía al 5,8 % de la población regional total.

Más del 80 % de la población regional vive permanentemente cerca de la costa, donde está las cuatro grandes ciudades por encima de los 50 000 habitantes: Génova (pop. 608 980), La Spezia (95 394), Savona (62 429) y Sanremo (56 880).

Liguria está dividida en una Ciudad metropolitana y tres Provincias:

El Gobierno Regional está presidido por el Gobernador, que es elegido por un término de cinco años, y está compuesto por el Presidente y los Ministros, que actualmente son 11, incluyendo un Vicepresidente.
El Consejo Regional está compuesto por 40 miembros y es elegido por un período de cinco años, pero, si el presidente sufre una moción de censura, dimite o muere, bajo la previsión "simul stabunt vel simul cadent" (introducida en 1999), también el Consejo se disolvería y habría una nueva elección.
En la última elección regional, que tuvo lugar el 31 de mayo de 2015, Giovanni Toti (Forza Italia) derrotó a Raffaella Paita (Partido Democrático).
Tanto a nivel nacional como local, Liguria es considerada una región cambiante, donde ninguna de las dos coaliciones es predominante.

En términos generales, la economía de Liguria está basada en aspectos particulares de los tres sectores productivos, generalmente relacionados entre sí. El sector primario se basa sustancialmente en una agricultura de calidad, con producciones específicas y con garantías de control particulares, pero también en la actividad de ganadería (tierra adentro) y de pesca a lo largo de la costa.

La industria ligur se asocia generalmente a los grandes centros productivos que surgieron en las periferias de los mayores centros urbanos como las capitales de provincia. Este aspecto ha contribuido al desarrollo de la actividad de los importantes puertos de Génova, La Spezia y Savona, que han impulsado el comercio marítimo, la construcción naval e incluso el turismo. 
La importación de materias primas a través de los puertos ha desarrollado aquí la industria siderúrgica, petroquímica, química y metalmecánica. 

A continuación la tabla que describe el PIB y el PIB per cápita, producido en Liguria desde el año 2000 a 2006:
A continuación la tabla que describe el PIB, producido en Liguria a los precios corrientes de mercado en el año 2006, expresado en millones de euros, subdividido entre las principales macro-actividades económicas:
La confrontación entre los datos regionales y el dato nacional, expresado en términos porcentuales, permite apreciar cómo la economía ligur está plenamente en una fase posindustrial, donde la industria pesa sobre el dato regional la mitad del dato nacional, trasladándose el peso económico sobre el sector de los servicios, comercio y turismo.

Su idioma vernáculo es el ligur, comúnmente llamado genovés por la importancia de esa variante y el prestigio literario y comercial que adquirió durante la Edad Media y hasta el siglo XIX como lengua náutica y mercantil.

En Liguria hay lugares declarados patrimonio de la Humanidad por la UNESCO: 

Durante la Edad Media la región acogió los influjos del arte francés, toscano y lombardo, incluso directamente, a través de las actividades de artistas como Giovanni Pisano y Giovanni di Balduccio en la escultura, Manfredino d'Alberto y Taddeo di Bartolo en la pintura, que trabajaron en Liguria durante temporadas más o menos largas.

El periodo barroco fue particularmente rico de fermentos nuevos: por Liguria pasaron artistas como Peter Paul Rubens, Van Dyck, aquí nacieron además pintores como Bernardo Strozzi, Orazio y Gregorio de Ferrari y Alejandro Magnasco.

Las montañas y los inclinados acantilados que se alzan sobre el mar Tirreno en la parte más septentrional del Mediterrénao. Este paisaje impresiona esta región dinámica e históricamente rica. La capital Génova, uno de los más importantes puertos en el Mediterrénao, era ya un estado marítimo poderoso en la Edad Media. Pueden encontrarse edificios impresionantes, elegantes mansiones e iglesias. En otras partes de Liguria, hay también numerosos tesoros históricos. Existe una vegetación mediterránea en las regiones montañosas de Portofino y Cinque Terre. Por otro lado, Portovenere es una pequeña joya en la costa mediterránea. San Remo es uno de los balnearios más famosos de Italia y el lugar donde se celebra anualmente un festival de música pop. Entre los monumentos, el monasterio benedictino de San Fructuoso.

En la capital hay diversos institutos de estudios superiores (públicos y privados), entre los cuales destacan por su excelencia la Universidad de los Estudios de Génova y el Instituto Italiano de Tecnología. Además de la Universidad que reúne once facultades, los otros institutos son por lo general de una sla facultad, y son respectivamente: gastronómico, arquitectónico, astronómico, tecnológico, hidrográfico, lingüístico, médico, de la Marina Mercante, artístico, musical, danza académica. A estos se deben añadir numerosas academias, dispersas por toda la región.

La Universidad de Génova con sedes didácticas también en Imperia, Pietra Ligure, Savona, Chiavari y La Spezia, tiene un total de 125 cursos de estudios de primer nivel y más de 90 de especialización. En el año académico 2002/2003 resultaban 40 000 inscritos.

En cuanto a los museos, cabe citar:

La cocina ligur toma la idea de la mayor parte de las recetas de la dieta mediterránea, unión culinaria entre los platos de mar con los productos de la tierra, todavía platos aparentemente simples son exaltados en sus sabores por el uso de las numerosas hierbas aromáticas como el romero, el tomillo, etc., que crecen espontáneamente sobre todo el territorio, típicos de la maquia mediterránea.

De Liguria procede una de las más típicas salsas italianas, el pesto, salsa que aliña las conocidas "trenette al pesto". El pescado es uno de los elementos principales de la cocina ligur, puesto que el mar ha sido parte de la cultura de la región desde sus comienzos. Entre los productos locales de gran aprecio está seguramente el aceite de oliva base y condimento de los principales platos de la gastronomía ligur. 

En la Ciudad metropolitana de Génova, la tradición vinícola es conformada sobre todo en la zona de Sestri Levante y en el Tigullio, con la principal producción vinícola de Bianchetta Genovese, de Moscato bianco, de Vermentino y de Ciliegiolo. Mayormente difundida entre los límites de la Ribera de Poniente con la Ribera de Levante son el Pigato y el Rossese.

En la provincia de Savona han obtenido el reconocimiento de D.O.C. (Denominación de Origen Controlada) el Pigato de Ortovero, el Vermentino y el Rossese de Campochiesa. Otros vinos, como Indicación Geográfica Típica (IGT) son el Lumassina, el "Buzzetto", la Granaccia de Quiliano, el Bianco di Calice Ligure, el "Mataosso" y el "Dolcetto delle Langhe Liguri".

En La Spezia las principales producciones vinícolas de la provincia son el Sciachetrà, excelente y famoso vino licoroso producido en las Cinque Terre, el DOC delle Cinque Terre, el "Levanto" y la "Vernaccia", procedentes de la Riviera spezzina y el Vermentino de las colinas de Luni y de Arcola.

Los dos principales equipos de fútbol de Liguria son el Genoa y la Sampdoria, que se enfrentan en el Derbi de Génova y han jugado gran parte de su historia en la Serie A de Italia. En tanto, el Spezia se encuentra actualmente en la Serie B.

En la región se han disputado además el Rally de San Remo, una carrera de automovilismo puntuable para el Campeonato Mundial de Rally, y la Milán-San Remo, uno de los cinco monumentos del ciclismo.





</doc>
<doc id="42061" url="https://es.wikipedia.org/wiki?curid=42061" title="Guernsey">
Guernsey

Guernsey (en francés: "Guernesey"), oficialmente Bailía de Guernsey (en inglés: "Bailiwick of Guernsey", en francés: "Bailliage de Guernesey"), es una dependencia de la Corona británica ubicada en el canal de la Mancha, al oeste de las costas de Normandía, Francia. El territorio comprende la isla de Guernsey (la mayor) y sus vecinas Alderney (2400 habitantes), Sark (610 habitantes) y Herm (60 habitantes), además de otras muy pequeñas, como Jethou, Brecqhou, Burhou, Lihou y otros islotes. El jefe de Estado, su duque, es la reina británica Isabel II del Reino Unido representada por el "teniente gobernador." Además existe un "Bailiff" o "bailío" con funciones parlamentarias y judiciales. Guernsey se integra en el archipiélago de las Islas del Canal, del cual también forma parte la bailía de Jersey.
Aunque su defensa es responsabilidad del Reino Unido la bailía no forma parte de él, sino que es posesión de la Corona británica. En consecuencia, aunque a efectos de desplazamientos está dentro de la Unión, no es parte de la Unión Europea.

Tiene una población de 65 345 personas y la capital es Saint Peter Port.

En el año 933, la isla fue tomada por el Ducado de Normandía, en el norte de Francia. Cuando en 1066 los normandos invadieron Inglaterra, Normandía e Inglaterra se unieron bajo una monarquía. Durante la Edad Media, Inglaterra perdió casi todas sus posesiones feudales en el continente europeo, pero ha conservado sus islas en el Canal de la Mancha, incluyendo Guernsey.

Como la isla de Jersey y las otras del canal de la Mancha, la economía de Guernsey se basa en los servicios financieros (está considerada como paraíso fiscal), el turismo y la agricultura. Un servicio de ferry conecta las islas con Gran Bretaña y Francia.

La población nativa tiene como lengua madre el francés, más exactamente un subdialecto del dialecto normando. Así, la población nativa suele llamar a su isla Dgèrnésiais. Sin embargo, en la actualidad la lengua más usada es el inglés.

El nombre "Guernsey" proviene del nórdico antiguo. "Guerns" tiene una etimología incierta, pudiendo significar 'verde, cuerno' o provenir de algún nombre personal. A su vez "ey" significa 'isla' en el nórdico antiguo.

Hacia el año 6000 AC, el ascenso del nivel del mar transformó lo que hasta entonces era un promontorio del continente europeo en las actuales Islas del Canal. Por aquellos tiempos, agricultores del Neolítico poblaron sus costas y construyeron dólmenes y menhires. En la isla hay tres menhires de gran interés arqueológico. El dolmen conocido como L'Autel du Dehus también contiene un deidad de dolmen conocido como Le Gardien du Tombeau.

Durante su migración a Bretaña, los británicos ocuparon las Islas Lenur (antiguo nombre de las islas del Canal) incluyendo a Sarnia o Lisia (Guernsey) y a Angia (Jersey). Anteriormente se pensaba que el nombre original de la Isla era Sarnia, pero la investigación reciente muestra que era el nombre latino para la isla de Sark. San Sampson, abad de Doll, en Bretaña, que vino del Reino de Gwent (Gales), introdujo el cristianismo en Guernsey.

En 933, las islas, que estaban bajo el control de Guillermo I, pasaron a depender directamente del Ducado de Normandía. La isla de Guernsey y otras islas del Canal representan los últimos restos del Ducado medieval de Normandía. En las islas, el tradicional título de Isabel II como jefe de Estado es del duque de Normandía.

Durante la Edad Media, la isla fue atacada en varias ocasiones por piratas franceses y fuerzas navales, especialmente durante la Guerra de los 100 años, cuando fue ocupada por Francia en varias ocasiones, la primera en 1339.

En 1372, la isla fue invadida por mercenarios aragoneses bajo el mando de Owain Lawgoch (recordado como Yvon de Gales), que estaba a servicio del rey francés. Lawgoch y sus mercenarios se recordaron más adelante en las leyendas de Guernsey como la invasión de las hadas de todo el mar.

En la guerra civil inglesa, Guernsey se puso del lado del parlamento, mientras que Jersey estaba con los seguidores de Carlos I de Inglaterra. La decisión de Guernsey estaba relacionada con la numerosa población calvinista y de otras iglesias de la Reforma Protestante, y con que Carlos I no había tomado parte en la liberación de unos marineros de la isla capturados por piratas berberiscos. No obstante, no había unidad en la isla, ya que había partidarios del rey.

En los siglos XVII y XVIII, durante las guerras con Francia y España, los navieros de Guernsey y los capitanes de mar explotaron su proximidad al continente europeo, solicitando patentes de corso.
El siglo XIX trajo una enorme prosperidad a la isla, debido a su éxito en el comercio marítimo global, y a la subida de la industria de piedra. William Le Lacheur estableció el comercio del café de Costa Rica con Europa, jugando un papel preponderante en el desarrollo económico de esta nación.

Durante la Primera Guerra Mundial, unos 3000 hombres de la isla desempeñaron servicios en la fuerza expedicionaria británica. De estos, cerca de 1000 sirvieron en el regimiento ligero real de la infantería de Guernsey, formado a partir de la milicia real de Guernsey en 1916.
En la Segunda Guerra Mundial, Guernsey fue ocupado por las tropas alemanas. Antes de la ocupación, evacuaron a muchos niños de Guernsey a Inglaterra para vivir con los parientes o los extranjeros durante la guerra. Algunos niños nunca volvieron con sus familias.

Durante la ocupación, algunas personas de Guernsey fueron deportadas por los alemanes a los campos en el sudoeste de Alemania, notablemente a Biberach an der Riß, e internadas en el campo de Lindele (“lager Lindele”). Había también un campo de concentración construido en Alderney donde confinaron a trabajadores forzados, predominantemente de Europa Oriental. Era el único campo de concentración construido en suelo británico y se conmemora en los monumentos bajo nombre del Alderney en francés: “Aurigny”.
Según algunos informes, Guernsey era la segunda isla más fuertemente guarnecida de la Europa ocupada durante la Segunda Guerra Mundial. La mayor parte de las fortificaciones alemanas aún hoy permanecen intactas y todas, a excepción de la batería de Mirus, están abiertas al público.

El parlamento de Guernsey, oficialmente llamados los Estados de Deliberación y presididos por el "Bailiff", están compuestos por 45 diputados, elegidos en distritos de uno o más representantes cada cuatro años. Hay también dos representantes de Alderney, una dependencia autónoma del Bailiwick, pero Sark, un señorío, no envía ningún representante. Hay también dos miembros no elegidos, ambos designados por el monarca como oficiales jurídicos y sin voto.

Un Proyecto de Ley es equivalente de un "bill" británico o de un "projet de loi" francés, y una ley es el equivalente de una "Act" del parlamento británico o de un "loi" francesa.

El Teniente Gobernador es el representante de la corona. La residencia oficial del Teniente Gobernador es la casa del gobierno. Desde el 18 de octubre de 2005 el titular es Fabian Malbon, nacido en Southsea, Portsmouth en 1946 y oficial naval entre 1965 y 2002 de la porción. Antes del retiro de la marina de guerra real era comandante en jefe del diputado de la flota.

Cada parroquia es administrada por una Douzaine (docena), formada por 'douzeniers' cada uno de los cuales se elige para un mandato de seis años. Dos 'douzeniers' son elegidos por los ciudadanos de la parroquia cada noviembre, uno de los cuales es el Doyen (Deán). Dos Constables (francés: Connétables) electos ejecutan las decisiones de la Douzaine.

La justicia se administra por la 'Royal Court of Guernsey' (francés: la 'Cour Royale de Guernesey') formada por el 'Bailiff' (francés: 'le Bailli'), como presidente y entre 12 y 16 'Jurats' (francés: 'Jurés-Justiciers de la Cour Royale') (elegidos por un colegio electoral: 'the States of Election / les États d'Élection'). Las apelaciones van a la 'Guernsey Court of Appeal' y, en su caso, al Comité Judicial del Consejo Privado del Reino Unido.

Varios países europeos tienen presencia consular en la isla. El consulado francés se ubica en la antigua residencia de Víctor Hugo, en Hauteville. Los consulados alemán y suizo se localizan en las inmediaciones del Credit Suisse Bank y el Fortis MeesPierson.

La Bailía de Guernsey es una jurisdicción separada en sí misma y, a su vez, es también tres subjurisdicciones separadas. No forma parte del Reino Unido y está separada de éste (pero no es completamente independiente de él). Las dos Bailías de Jersey y Guernsey juntas forman las Islas Anglonormandas o del Canal.

Los isleños nunca han tenido representación oficial en la Cámara de los Comunes del Parlamento Británico ni en el Parlamento Europeo. Los isleños que de alguna manera no estaban calificados ni tenían derecho por derecho propio a inscribirse en el registro de votantes y a votar en el Reino Unido en virtud de las Leyes de representación del pueblo como votantes en el extranjero, quedaron excluidos del referéndum sobre la adhesión del Reino Unido a la Unión Europea de 2016.

Ha surgido una posición constitucional única a medida que los sucesivos monarcas británicos han confirmado las libertades y privilegios de la Bailía, refiriéndose a menudo a las denominadas Constituciones del Rey Juan, un documento legendario que se supone que fue concedido por el Rey Juan después de 1204. En general, los gobiernos de la Bailía han tratado de evitar poner a prueba los límites de la constitución no escrita evitando el conflicto con los gobiernos británicos.

Guernsey está dividido en 10 parroquias: Castel, Forest, St Andrew, St Martin, Saint Peter Port, St Pierre du Bois, St Sampson y Torteval.

La más grande es Castel con 10,1 km², y la más poblada es Saint Peter Port con 16 488 habitantes.

La parte septentrional de la isla es llana y baja, mientras que la parte meridional se eleva hasta una meseta de unos 90 msnm.

La superficie es de 78 km². siendo la isla de Guernsey la más grande con 65 km². La población total es de casi 65 573 habitantes, teniendo una densidad de 836,3 hab/km².

El clima es templado con inviernos fríos y veranos templados. Los meses más calurosos son julio y agosto con temperaturas máximas promedio de 19 °C, llegando en ocasiones a los 24 °C. En promedio, febrero es el mes más frío, con una temperatura promedio de 6 °C. Raramente cae nieve, siendo febrero el mes más probable para que suceda este fenómeno. Las temperaturas descienden pocas veces de cero, a pesar de que los vientos fríos provenientes del Ártico y la humedad hacen que la sensación térmica sea muy baja. Los meses más lluviosos son diciembre (promedio de 107 mm), noviembre (promedio de 98 mm) y enero (promedio de 89 mm). En promedio, julio es el mes más soleado, con 258 horas de sol registradas; y diciembre, el que menos, cuenta con menos 52 horas de sol. El 50 % de los días son nublados.


El PIB ascendía al 1.500 millones de libras, en 2005 el gasto público fue de alrededor de 300 millones de libras.

Alrededor del 32 % del producto nacional bruto se apoya en los servicios financieros (banca, seguros y gestión de fondos). Otras fuentes tradicionales de ingreso son la agricultura, el turismo, la ingeniería y la horticultura, principalmente tomates y flores cortadas.

El número de desempleados es de tan solo 1 %.

La moneda local, la libra de Guernsey, se ha emitido por el Banco de Inglaterra, siguiendo las mismas reglas que para cualquier otra moneda moderna.

Guernsey ha sido un destino turístico desde al menos la época victoriana, con la primera guía turística publicada en 1834. En el siglo XIX, dos compañías ferroviarias (Londres y South Western Railway y Great Western Railway) dirigían barcos desde el territorio continental del Reino Unido hasta el puerto de San Pedro, con una recorrido hasta el único atraque conveniente. Esto se detuvo con el hundimiento del SS Stella en 1899.

Guernsey entra en la categoría de Britain in Bloom con la Parroquia de San Martín ganando la categoría de ciudad pequeña dos veces en 2006 y 2011, el Puerto de San Pedro gano además la categoría de costa grande en 2014 y San Pedro ganó el premio de costa pequeña en 2015. Herm ha ganado varias veces la categoría de Gran Bretaña en Bloom: en 2002, 2008 y 2012, Herm ganó el Premio de Oro de Gran Bretaña en Bloom.

La historia militar de la isla ha dejado varias fortificaciones, incluyendo el Castillo Cornet, el Fuerte Grey. las torres de Guernsey y una gran colección de fortificaciones alemanas con varios museos.

El uso de la rada frente al puerto de San Pedro por más de 100 cruceros al año está trayendo a la isla más de 100.000 pasajeros cada año.

El aeropuerto de Guernsey, en la isla de Guernsey, es el principal de esta dependencia de la corona británica. La mayoría de los vuelos son a otras islas del canal o al Reino Unido. Aurigny Air Services es la aerolínea comercial con un mayor número de vuelos desde el aeropuerto de Guernsey y la única con vuelos comerciales desde el aeropuerto de Alderney, en la isla homónima, que es el otro aeropuerto del Bailiazgo de Guernsey.

El único ferrocarril en funcionamiento del Bailiazgo de Guernsey es el ferrocarril de Alderney.

Existe un servicio público de autobuses en Guernsey.

Según el censo de julio de 2011 la población es de 65 068 habitantes, la media de edad es de 41,1 años para los hombres y 43,2 para las mujeres. La tasa de crecimiento anual es de 0,438 %, la esperanza de vida al nacer es de 79,5 años para los hombres y 84,95 años para las mujeres y el promedio de nacimientos por mujer es de 1,54. Los principales grupos étnicos son: británicos, normandos, portugueses, letones y sudafricanos.<ref name="CIA 02/11/2011"></ref>

El inglés es el idioma de uso general de la mayoría de la población, mientras que el guernésiais, el idioma normando de la isla, sólo lo habla con fluidez alrededor del 2% de la población (según el censo de 2001). Sin embargo, el 14% de la población afirma tener cierta comprensión del idioma. Hasta principios del siglo XX el francés era el único idioma oficial de la Bailía, y todas las escrituras de compraventa de bienes inmuebles en Guernsey se escribieron en francés hasta 1971. Los nombres de familia y de lugares reflejan esta herencia lingüística. George Métivier, un poeta, escribió en Guernesiais. La pérdida del idioma de la isla y la anglicización de su cultura, que comenzó en el siglo XIX y prosiguió inexorablemente durante un siglo, se aceleró bruscamente cuando la mayoría de los escolares de la isla fueron evacuados al Reino Unido por cinco años durante la ocupación alemana de 1940-45.

Victor Hugo escribió algunas de sus mejores obras mientras estuvo exiliado en Guernsey, incluido Les Misérables. Su antigua residencia en St Peter Port, Hauteville House, es ahora un museo administrado por la ciudad de París. En 1866, publicó una novela ambientada en la isla, "Travailleurs de la Mer" (Trabajadores del mar), que dedicó a la isla de Guernsey.

La novela más reconocida de un nativo de Guernsey es "The Book of Ebenezer Le Page," por GB Edwards. Además de ser una pieza de literatura muy aclamada, contiene numerosos detalles sobre la vida en Guernsey durante el siglo XX.

George Métivier, quien a menudo es considerado el poeta nacional de la isla, escribió en el idioma local guerneseyés. Otros escritores destacados de Guernsey son Denys Corbet, Tam Lenfestey, T. H. Mahy y Marjorie Ozanne.

La película "The Guernsey Literary and Potato Peel Pie Society" está ambientada en esta isla.

William De Vic Tupper Brock, conocido en español como Guillermo Tupper, nacido el 28 de abril de 1800. Héroe de la Independencia de Chile, participó en la Expedición Libertadora del Perú, la Campaña de Chiloé en 1826 y contra Hermanos Pincheira en 1827. Murió tras la Batalla de Lircay, el 17 de abril de 1830.

Guernsey fue el hogar del novelista francés Víctor Hugo desde 1855 hasta 1870. Aquí terminó de escribir "Los miserables" en 1862 y, cuatro años después, "Los trabajadores del mar", una novela dedicada a la isla y sus marineros.

El músico ganador de un Grammy, Mura Masa, nació en la Bailía de Guernsey.

El mayor exponente deportivo de este territorio es Matthew Le Tissier, un futbolista que vistió la elástica del Southampton Football Club entre los años 1986 y 2002, y además fue internacional con la selección de Inglaterra en 8 ocasiones, entre 1994 y 1997.

Guernsey participa en los Juegos insulares de carácter bienal, de los que fue anfitrión en 1987 y 2003 en Footes Lane. Guernsey también ha participado como país por derecho propio en los Juegos del Commonwealth desde 1970. Sus primeras medallas llegaron en 1982 con su primer oro en 1990.

En los eventos deportivos en los que Guernsey no tiene representación internacional, pero las Naciones Originarias Británicas compiten por separado, los isleños altamente calificados pueden optar por competir por cualquiera de las Naciones Originarias. Sin embargo, hay restricciones en los traslados posteriores para representar a otras naciones. El futbolista Matt Le Tissier, por ejemplo, podría haber jugado en los equipos de fútbol de Escocia o Gales, pero optó por jugar para Inglaterra.

El fútbol en Guernsey está dirigido por la Asociación de Fútbol de Guernsey. La máxima categoría del fútbol de Guernsey es la Liga FNB Priaulx, donde hay nueve equipos (Alderney, Belgrave Wanderers, Manzur, Northerners, Sylvans, St Martin's, Rovers, Rangers y Vale Recreation). El segundo nivel es la Liga Jackson. En la temporada 2011-12, se formó el Guernsey F.C., que entró en la primera división de la Liga de Condados Combinados, convirtiéndose en el primer club de las Islas del Canal que compite en las ligas inglesas. El 24 de marzo de 2012, Guernsey se convirtió cómodamente en campeón de división,ganando la Copa del Desafío de la Premier Combinada de Condados el 4 de mayo de 2012.

Guernsey fue declarada miembro afiliado por el Consejo Internacional de Críquet (ICC) en 2005 y miembro asociado en 2008. El equipo de críquet de Guernsey juega en la Liga Mundial de Críquet y en el Campeonato Europeo de Críquet, así como en la Liga de Críquet de Sussex.




</doc>
<doc id="42068" url="https://es.wikipedia.org/wiki?curid=42068" title="Hueso trapezoide">
Hueso trapezoide

El hueso trapezoide es un hueso de la muñeca, par, corto, esponjoso, con seis caras de las cuales cuatro son articulares.

Es el segundo hueso de la segunda fila del carpo; se articula con el hueso escafoides, segundo metacarpiano, hueso trapecio y hueso grande.


</doc>
<doc id="42075" url="https://es.wikipedia.org/wiki?curid=42075" title="Economía de Guyana">
Economía de Guyana

La economía de Guyana exhibió un crecimiento moderado en los últimos años, y se basa en gran medida en la agricultura y en las industrias extractivas. La economía depende en gran medida de la exportación de seis productos básicos - azúcar, oro, bauxita, camarón, madera y arroz - que representan casi el 60% del producto bruto interno y son muy sensibles a las condiciones climáticas adversas y las fluctuaciones en los precios internacionales de estos productos.

La economía hizo un progreso dramático después del programa de recuperación económica del presidente Hoyte en 1989. Como resultado de este programa, el producto bruto interno de Guyana creció un seis por ciento en 1991 después de 15 años de declive. El crecimiento fue consistentemente mayor al seis por ciento hasta 1995, año en el cual bajó a 5.1 por ciento. El gobierno reportó que la economía creció en una razón de 7.9 por ciento en 1996, 6.2 por ciento en 1997, y cayó en 1.3 por ciento en 1998. La razón de crecimiento en 1999 fue del 3 por ciento. La razón de crecimiento no oficial en 2000 fue de 0.5 por ciento.

En desarrollado en conjunto con el Banco Mundial y el Fondo Monetario Internacional, el programa de recuperación económica redujo significativamente el rol del gobierno en la economía, incrementando las inversiones extranjeras, permitió al gobierno cancelar el interés de la deuda debida a gobiernos extranjeros y a bancos multinacionales, y causó la venta de 15 de los 41 negocios apropiados por el gobierno. La empresa de telecomunicaciones compañía telefónica y el capital en madera, arroz, e industrias pesqueras también fueron privatizadas. Corporaciones internacionales fueron contratadas para administrar la enorme compañía de azúcar, GUYSUCO, y la compañía minera estatal más grande de bauxita. Una compañía americana fue permitida a abrir una mina de bauxita, y dos compañías canadienses fueron permitidas a desarrollar la mina de oro a tajo abierto más grande en Sudamérica. No obstante, los esfuerzos por privatizar las dos compañías mineras de bauxitas del estado, Berbico Mining Company y Linden Mining Company no han tenido éxito.



</doc>
<doc id="42078" url="https://es.wikipedia.org/wiki?curid=42078" title="Edsger Dijkstra">
Edsger Dijkstra

Edsger Wybe Dijkstra (AFI: ) (Róterdam, Países Bajos, 11 de mayo de 1930 - Nuenen, Países Bajos, 6 de agosto de 2002) fue un científico de la computación de los Países Bajos.

Poco después de su muerte en el 2002, recibió la distinción ACM "PODC Influential Paper Award" en computación distribuida por su trabajo en la auto-estabilización en programas computacionales. Este premio fue renombrado a "Premio Dijkstra" el siguiente año en su honor.

Edsger W. Dijkstra nació en Róterdam. Su padre, que fue Presidente de la Sociedad Holandesa de Química, había aprendido química durante la secundaria y más tarde de su superintendente. Su madre era matemática, pero nunca tuvo un trabajo formal.

Dijkstra siempre había considerado emprender una carrera en Derecho y representar a los Países Bajos en las Naciones Unidas. Sin embargo, tras graduarse en la escuela en 1948, bajo la dirección de sus padres estudió matemáticas y física, y finalmente pasó a estudiar Física teórica en la Universidad de Leiden. Más tarde trabajó como investigador para "Burroughs Corporation" a principios de los años 1970. En la Universidad de Texas en Austin, Estados Unidos, ocupó el "Schlumberger Centennial Chair in Computer Sciences". En 1965 dio lugar al primer paper en el campo de la computación concurrente y la programación concurrente. Entre sus contribuciones a las ciencias de la computación está la solución del problema del camino más corto, también conocido como el algoritmo de Dijkstra, la notación polaca inversa y el relacionado algoritmo shunting yard, "THE multiprogramming system", el algoritmo del banquero y la construcción del semáforo para coordinar múltiples procesadores y programas. Otro concepto debido a Dijkstra, en el campo de la computación distribuida, es el de la auto-estabilización, una vía alternativa para garantizar la confiabilidad del sistema. El algoritmo de Dijkstra es usado en "la ruta más corta primero" (SPF) que es usado en el protocolo de enrutamiento "Open Shortest Path First" (OSPF). También se le debe la autoría de la expresión «Crisis del software», aparecida en su libro The Humble Programmer y usada ampliamente en la famosa reunión de la OTAN de 1968 sobre desarrollo del software. Recibió el Premio Turing en 1972.

Era conocido porque alertó sobre los peligros de la sentencia GOTO en la programación, que culminó en 1968 con la carta al editor que se publicó con el título "Go To Statement Considered Harmful" ("La sentencia Goto considerada perjudicial"), visto como un paso importante hacia el rechazo de la expresión GOTO y de su eficaz reemplazo por estructuras de control tales como el bucle while. El famoso título del artículo no era obra de Dijkstra, sino de Niklaus Wirth, entonces redactor de Comunicaciones del ACM. Dijkstra era un aficionado bien conocido de ALGOL, y trabajó en el equipo que desarrolló el primer compilador para este lenguaje. En ese mismo año creó el primer sistema operativo con estructura jerárquica, de niveles o capas. Fue denominado THE (Technische Hogeschool, Eindhoven) que se utilizó con fines didácticos. 

Desde los años 1970, el principal interés de Dijkstra fue la verificación formal. La opinión que prevalecía entonces era que uno debe primero escribir un programa y seguidamente proporcionar una prueba matemática de su corrección. Dijkstra objetó que las pruebas que resultan son largas e incómodas, y que la prueba no da ninguna comprensión de cómo se desarrolló el programa. Un método alternativo es la "derivación de programas", «desarrollar prueba y programa conjuntamente». Uno comienza con una especificación matemática del programa que se supone va a hacer y aplica transformaciones matemáticas a la especificación hasta que se transforma en un programa que pueda ser ejecutado. El programa que resulta entonces es sabido correcto por la construcción. Muchos de los últimos trabajos de Dijkstra tratan sobre las maneras de hacer fluida la argumentación matemática.

Respecto a su carácter árido y ácido, conocidas son su oposición a la instrucción GOTO y al lenguaje BASIC («mutila la mente más allá de toda recuperación»). Alan Kay expuso que en informática, la arrogancia se mide en "nanodijkstras".

Dijkstra murió el 6 de agosto de 2002 después de una larga lucha contra el cáncer.

Dijkstra es conocido como un "personaje" en el mundo de las ciencias de la computación. En el prólogo de su libro "A Discipline of Programming", escrito en 1976, declaró la siguiente frase: "Debido a la ausencia de una bibliografía, no ofrezco ni explicación ni apología". De hecho, gran parte de sus artículos y libros no tienen ninguna referencia. Esta ausencia de referencias fue criticada por muchos investigadores. Sin embargo, Dijkstra eligió esta forma de trabajar para remarcar su autosuficiencia.

Aunque parezca irónico, Dijkstra, uno de los mayores desarrolladores del software de su época, evitó el uso de computadores en su trabajo durante décadas. Cuando, finalmente, sucumbió a la tecnología, únicamente utilizó los ordenadores para enviar correos electrónicos y hacer búsquedas en la red. Dijkstra nunca utilizó un computador para realizar ninguno de sus trabajos, todos ellos fueron realizados a mano.

Desde una edad muy temprana destacó por su ingenio y elocuencia. Cuando era pequeño le aseguró a su madre que no resolvería ningún problema o cuestión que le ocupará más de cinco líneas de un folio.

Dijkstra también destacó como escritor de ensayos. En uno de ellos, en tono humorístico describió una empresa ficticia en la que había trabajado como presidente llamada Mathematics Inc. Esta empresa se había dedicado a comercializar teoremas matemáticos (un paralelismo a lo que estaba ocurriendo con las empresas tecnológicas, las cuales estaban haciendo una abusiva comercialización de los programas que desarrollaban). Al concluir este discurso Dijkstra aseguró que era la empresa más emocionante, y a la vez miserable, jamás concebida.

Desde 1952 hasta 1962, Dijkstra trabajó en el "Mathematisch Centrum" en Ámsterdam, donde colaboró con Bram Jan Loopstra y Carel S. Scholten, los cuales habían sido contratados para construir un computador. Su modo de trabajo fue muy disciplinado: en primer lugar, debían escribir un manual de programación. Posteriormente los diseñadores de Hardware debían tener fe en que Dijkstra, el programador, escribiera las líneas de códigos para una máquina todavía inexistente. De su experiencia aprendieron la gran importancia que tiene una documentación clara y que una tediosa depuración de un programa puede ser evitada si se ha hecho un diseño cuidadoso. En este centro, Dijkstra y Jaap Zonneveld desarrollaron un compilador para el lenguaje de programación ALGOL, que tuvo una gran influencia en su posterior actividad científica.

Dijkstra fue uno de los pioneros en el establecimiento de la "programación distribuida". Gracias a este tipo de programación, Dijkstra fue el primero en presentar una solución al problema de exclusión mutua.

Desde la década de 1970 el principal interés de Dijkstra fue la verificación formal. La verificación formal es un método de validación estática, en el que, partiendo de un conjunto de axiomas, reglas de inferencia y algún lenguaje lógico, se puede encontrar una demostración de un programa. En 1976 Dijkstra publicó su libro "A Discipline of Programming" el cual presentó su método de desarrollo sistemático de programas, junto con sus pruebas de corrección. 

En su exposición, utilizó su Lenguaje de Comandos Guardados. Este lenguaje, con su dependencia en el no determinismo, la semántica de la precondición más débil y el método de desarrollo propuesto, produjeron un impacto considerable en el campo de las ciencias de ese momento.

En 1984, para añadir mayor apoyo a su enfoque de la programación, publicó junto con Wim Feijen un libro de texto para estudiantes de primer año de informática, llamado "Een methode van programmeren". La versión inglesa se publicó en 1988, llamada "A Method of Programming".

Dijkstra fue uno de los mayores oponentes de la visión de las ciencias de la computación desde el punto de vista de la ingeniería. Mediante el término "ciencias de la computación", que sustituyó a "ciencias del computador", Dijkstra quería hacer énfasis en los mecanismos abstractos que esta ciencia tiene.

Dijkstra consideraba que el trabajo de un programador no era la realización de programas, sino diseñar las distintas clases de computación para el posterior desarrollo de estos.
Este pensamiento queda reflejado en su obra "The Humble Programmer" (1972).

También, se opuso a que la ingeniería del software estuviera bajo la tutela de la academia de la computación. Sobre esto, Dijkstra argumentó que, "Al igual que a la economía es considerada como "La Ciencia Miserable", a la ingeniería del software debería ser considerada como "La disciplina Condenada", debido a que no se acerca, ni siquiera, a su objetivo, ya que este es contradictorio en sí mismo". 




</doc>
<doc id="42107" url="https://es.wikipedia.org/wiki?curid=42107" title="Región de Kantō">
Región de Kantō

La es un área geográfica de Honshū, la isla más grande de Japón. Los límites de esta región coinciden, aproximadamente, con la llanura de Kantō. La región tiene una población de 42 000 000 habitantes, siendo el área metropolitana más poblada del mundo.

La región está compuesta por las prefecturas de Gunma, Tochigi, Ibaraki, Saitama, Chiba, Kanagawa y la Metrópolis de Tokio.

Además de Tokio, en la región de Kantō se encuentran las ciudades de Yokohama, Kawasaki, Saitama y Chiba.

Kantō es una región muy densa, llana y con mucha vegetación.




</doc>
<doc id="42110" url="https://es.wikipedia.org/wiki?curid=42110" title="Región de Kansai">
Región de Kansai

La o se encuentra en el medio de la isla principal de Japón, Honshu.

El "Ki" (畿) del término Kinki en japonés, "miyako," significa ciudad o metrópolis. Se remonta al período Edo en el que la capital de Japón estaba localizada en esta región.

Población: 22 757 897 habitantes.

La región de Kansai comprende las prefecturas de Japón de:




</doc>
<doc id="42125" url="https://es.wikipedia.org/wiki?curid=42125" title="Hanja">
Hanja

Hanja , a veces traducido como caracteres sinocoreanos, es el nombre que reciben los sinogramas en coreano pero, de forma más específica, se refiere a los caracteres chinos que los coreanos tomaron prestados e incorporaron a su idioma, cambiando su pronunciación. Al contrario que los caracteres kanji japoneses, algunos de los cuales han sido simplificados, casi todos los hanja son idénticos a los hanzi del chino tradicional, aunque algunos difieren un poco de la forma tradicional en el orden de los trazos (por ejemplo, los caracteres chinos y se escriben y , respectivamente, en hanja). "Hanja-mal" o "hanja-eo" son las palabras que se pueden escribir con hanja, mientras que "hanmun" se refiere a la escritura del chino clásico, aunque "hanja" a veces se usa libremente como sinónimo para estos otros conceptos.

Hoy en día, el hanja no se usa para escribir palabras de origen nativo, ni de origen chino.

Un impulso principal para la introducción de caracteres chinos en Corea fue la extensión de budismo coreano. El principal texto chino que introdujo el hanja en Corea, sin embargo, no fue un texto religioso, sino el texto chino, "Cheonjamun". 

Hubo otros sistemas, concebidos antes, con el fin de utilizar los caracteres chinos simplificados para transcribir el coreano fonéticamente :

El hanja era el único medio de escribir coreano hasta que el rey Sejong de Joseon inventó el alfabeto hangul en el siglo XV. Sin embargo, aún después de la invención del hangul, la mayoría de los eruditos coreanos continuaron escribiendo mediante el hanmun. 

No fue sino hasta el siglo XX cuando el hangul suplantó mayoritariamente el uso del hanja. Oficialmente, los hanja no se han utilizado en Corea del Norte desde junio de 1949 (y, adicionalmente, todos los textos se escriben horizontalmente en vez de verticalmente), porque Kim Il-sung lo consideró una consecuencia de la ocupación japonesa y un estorbo para la capacidad de leer y escribir. Además, muchas préstamos del chino se han reemplazado con palabras de origen nativo.

Cada hanja está formado por uno de los 214 radicales y, a veces, de uno o más elementos suplementarios. La gran mayoría del ellos utiliza los elementos suplementarios para indicar la pronunciación del carácter, pero algún hanja que otro es puramente pictográfico y se pronuncia de modo diferente.

En coreano moderno, cuando un hanja aparece en una palabra o como palabra de pleno derecho, se pronuncia siempre de la misma manera. Sin embargo, para ayudar a incluir los caracteres, los diccionarios de caracteres y los libros escolares se refieren a cada carácter no solo por su aspecto, sino también por su significado. Dicha lectura, la cual da el significado y el sonido de los caracteres, se llama "eumhun" (음훈;音訓; según 音"sonido" + 訓"significado", "aprendizaje").

En los diccionarios coreanos modernos, se imprimen todas las entradas de palabras de origen sino-coreano en hangul y clasificados en el orden del hangul; la forma hanja siguiente inmediatamente entre paréntesis (una práctica similar se encuentra en los diccionarios japoneses). Eso permite prevenir las ambigüedades y sirve también de etimología, puesto que el significado hanja y el hecho de que la palabra esté formada por hanja ayudan a menudo a incluir el origen de la palabra.

Ejemplos de cómo el hanja puede ayudar a aclarar las ambigüedades de numerosos homónimos que se escriben ("sudo") en hangul:




</doc>
<doc id="42127" url="https://es.wikipedia.org/wiki?curid=42127" title="Hannover">
Hannover

Hannover es una ciudad alemana, capital del estado federado de Baja Sajonia y de la Región de Hannover. Cuenta con una población de 1 002 529 habitantes en su área metropolitana. Su gentilicio es hanoveriano, -na.

Hannover fue fundada en época medieval en la orilla oriental del río Leine. Su nombre original "Honovere" puede significar "alta orilla (del río)", aunque esto es objeto de debate (cf. "das Hohe Ufer"). Hannover era un pequeño pueblo de capitanes de transbordador y pescadores que se convirtió en una ciudad relativamente grande en el debido a su posición en un cruce de caminos natural. Como el viaje por tierra era relativamente difícil, su posición en las regiones navegables del río le ayudaron a crecer incrementando el comercio. Se relacionó con la ciudad hanseática de Bremen por el Leine, y estaba situada cerca del borde meridional de la amplia llanura del norte de Alemania y noroeste de los montes del Harz, de manera que el tráfico este-oeste como trenes de mulas pasaban por él. Hannover fue así una puerta de entrada a los valles de los ríos Rin, Ruhr y Sarre, sus zonas inductriales donde crecieron hasta el sudoeste y las regiones de llanuras al este y el norte, pues el tráfico interior bordeando el Harz entre los Países Bajos y Sajonia o Turingia.

En el se construyeron las principales iglesias de Hannover, así como una muralla defensiva con tres puertas. El comienzo de la industrialización de Alemania llevó a comerciar en hierro y plata de los montes Harz septentrionales, lo que incrementó la importancia de la ciudad.

En 1636 Jorge de Brunswick-Luneburgo, gobernante de Brunswick-Luneburgo principado de Calenberg, trasladó su residencia a Hannover. Los duques de Brunswick-Luneburgo fueron elevados por el Sacro Imperio Romano Germánico al rango de príncipe elector en 1692, y esta elevación fue confirmada por la dieta imperial en 1708. Así, el principado fue elevado a Electorado de Brunswick-Luneburgo, coloquialmente conocido como el Electorado de Hannover por la capital de Calenberg (véase también: Casa de Hannover). Sus electores más tarde se convertirían en monarcas de Gran Bretaña (y desde 1801, del Reino Unido de Gran Bretaña e Irlanda). El primero de ellos fue Jorge I Luis, quien accedió al trono británico en 1714. El último monarca británico que gobernó en Hannover fue Guillermo IV. La Ley semisálica, que requería sucesión por la línea masculina si era posible, prohibía el ascenso de la reina Victoria en Hannover. Como descendiente por vía masculina de Jorge I, la reina Victoria era ella misma un miembro de la Casa de Hannover. Sus descendientes, sin embargo, llevaban el nombre titular de Sajonia-Coburgo-Gotha. Tres reyes de Gran Bretaña, o el Reino Unido, fueron al mismo tiempo también Príncipes electores de Hannover.

En la época de la unión personal de las coronas del Reino Unido y Hannover (1714-1837), los monarcas raramente visitaron la ciudad. De hecho, durante los reinados de los tres últimos gobernantes conjuntos (1760-1837), hubo solo una breve visita, por Jorge IV en 1821. Desde 1816 a 1837 el virrey Adolfo representó al monarca en Hannover.

En el , Hannover toma parte en la guerra de los Siete Años del lado de la Prusia de Federico II el Grande. La batalla de Hastenbeck se combatió cerca de la ciudad el . El ejército francés derrotó al Ejército de observación hannoveriano, lo que llevó a la ocupación de la ciudad como parte de la Invasión de Hannover. Fue tomado de nuevo por fuerzas anglo-alemanas lideradas por Fernando de Brunswick al año siguiente.

Después de que Napoleón impusiera la Convención de Artlenburg (Convención del Elba) el 5 de julio de 1803, alrededor de soldados franceses ocuparon Hannover. La Convención también exigía que se deshiciera el ejército de Hannover. Sin embargo, Jorge III no reconoció la Convención del Elba. Esto dio como resultado que un gran número de soldados de Hannover eventualmente emigraron a Gran Bretaña, donde se formó la King's German Legion. Era solo tropas de Hannover y Brunswick que consistentemente se opusieron a Francia a través de todas las guerras napoleónicas. La legión más tarde tuvo un papel importante en la batalla de Waterloo en 1815. El Congreso de Viena en 1815 elevó el electorado al Reino de Hannover. La ciudad capital de Hannover se amplió a la orilla occidental del Leine y desde entonces ha crecido considerablemente.

En 1837, la unión personal del Reino Unido y Hannover acabó porque el heredero de Guillermo IV en el Reino Unido era femenino (la reina Victoria). Hannover solo podía heredarse por vía masculina. Así, Hannover pasó al hermano de Guillermo IV, Ernesto Augusto, y siguió siendo un reino hasta 1866, cuando fue anexionado por Prusia durante la guerra austro-prusiana. A pesar de que se esperaba que Hannover derrotara a Prusia en la batalla de Langensalza, Prusia empleó el orden de batalla Kesselschlacht de Moltke el Viejo en lugar de eso, para destruir el ejército hannoverian. La ciudad de Hannover se convirtió en la capital de la provincia de Hannover prusiana. Después de la anexión, la gente de Hannover generalmente se opuso al gobierno prusiano.

Para la industria de Hannover, sin embargo, la nueva conexión con Prusia significó una mejora en el negocio. La introducción del comercio libre promocionó el crecimiento económico, y lideró la recuperación del Gründerzeit (la era de los fundadores). Entre 1879 y 1902 la población de Hannover creció desde 87.600 hasta 313.940. 

En 1842 se inauguró el primer tranvía de tracción animal, y desde 1893 se instaló un tranvía eléctrico. En 1887, Emile Berliner de Hannover inventó la grabación y el gramófono.

En 1920 se incorporan a Hannover la ciudad de Linden con los barrios de Linden Nuevo y Viejo, Limmer, Davenstedt, Badenstedt, Bornum y Ricklingen, creciendo la población de 80.000 a 400.000 habitantes. En 1928 también se unieron el castillo y los Herrenhauser Garten, Leinhausen y Marienweder. En 1937 hicieron lo mismo partes de Bemerode y Laatzen.

Desde 1918 el burgomaestre de la ciudad es el "Oberbürgermeister" ('alcalde') y no el "Stadtdirektor" ('administrador de la ciudad'). El primer alcalde fue el socialdemócrata Robert Leinert, sustituido en 1925 por el conservador Arthur Menge, que se mantuvo en el puesto hasta 1937. Gracias a sus medidas de creación de empleo, se pudo construir el Maschsee y el Hermann-Löns-Park, parque de 86 ha al sureste de la ciudad. En el aspecto cultural, Hannover fue una referencia en los años 20 con la fundación del grupo "Vorort der Moderne" por parte de Kurt Schwitters. Dirigió la revista dadá "Merz" y el grupo "die abstrakten Hannover".

En 1921 se construye en la fábrica de HAWA el "HAWA Vampyr", el primer planeador del mundo para todos los tipos de aire. En 1924 Hanomag fabrica el "Kommissbrot", primer coche producido en serie de Europa. "El Schienenzeppelin", vehículo ferroviario de alta velocidad impulsado por una hélice, se construye en 1930.

A partir de 1937 el alcalde y los comisionados del estado de Hannover eran miembros del NSDAP (Partido nazi). Entonces había una gran población judía en Hannover. 484 judíos de Hannover de origen polaco fueron expulsados a Polonia, incluyendo a la familia Grynszpan a finales de octubre de 1938. Sin embargo, Polonia rechazó aceptarlos, dejándolos abandonados en la frontera con miles de otros deportados judío-polacos, alimentados solo intermitentemente por la Cruz Roja polaca y organizaciones de beneficencia judía. El segundo hijo de esta familia, Herschel Grynszpan, se encontraba en París cuando se enteró de la expulsión de su familia. Fue a la embajada de Alemania y disparó al diplomático alemán Ernst Eduard vom Rath, que murió poco después.

Los nazis tomaron esta acción como pretexto para un progromo por todo el país, conocido como la «Noche de los cristales rotos». Alcanzó Hannover el 9 de noviembre de 1938, cuando la sinagoga de Calenberger Neustadt, diseñada en 1870 por Edwin Oppler en estilo neorromántico, fue incendiada por los nazis. 

En septiembre de 1941, a través del plan de "Action Lauterbacher", se empezaron a crear guetos para el resto de las familias judías de Hannover. Incluso antes de la Conferencia de Wannsee, el 15 de diciembre de 1941 los primeros judíos eran deportados a Riga. Un total de 2400 personas fueron deportadas, y muy pocas sobrevivieron. Durante la guerra se construyeron siete campos de concentración en Hannover, en los que se confinó a muchos judíos. De los aproximadamente 4800 judíos que vivían en Hannover en 1938, no quedaban más de 100 a la llegada de las tropas estadounidenses, el 10 de abril de 1945, para ocupar Hannover a finales de la guerra. Hoy, un monumento en la plaza de la Ópera de Hannover recuerda la persecución de los judíos en Hannover.

Después de la guerra un gran grupo de judíos ortodoxos supervivientes del cercano campo de concentración de Bergen-Belsen se asentaron en Hannover.
Además de un campo para gitanos, alrededor de Hannover existían varios campos de concentración con miles de reclusos en condiciones inhumanas. Cuatro días antes de la liberación de Hannover, 150 reclusos fueron fusilados. Durante la guerra alrededor de 60.000 desplazados hicieron trabajos forzosos en 500 campos de concentración, principalmente en la industria de defensa.

El arquitecto de la ciudad Karl Elkart organizó las deportaciones de judíos y la arianización del arte y la cultura. En el campo de concentración de Ahlem se levantó en 1987 un monumento en el recinto de la antigua Escuela Judía de Horticultura.

Durante la Segunda Guerra Mundial Hannover fue un importante centro de transporte y de fabricación de armamento, por lo que a partir de 1940 fue blanco de los bombardeos aliados, incluyendo la Campaña del petróleo. Entre los objetivos estuvieron la AFA (Stöcken), la refinería de Deurag-Nerag (Misburg), las plantas Continental (Vahrenwald y Limmer), la fábrica de metalistería ligera (VLW) en Ricklingen y Laatzen (hoy feria de Hannover), la planta de goma Hannover/Limmer, la empresa Hanomag (Linden) y la fábrica de tanques "M.N.H. Maschinenfabrik Niedersachsen" (Badenstedt). Trabajadores forzados fueron a veces usados para el del campo de concentración de Neuengamme. Áreas residenciales fueron también objetivos, y más de 6000 civiles fueron muertos por los bombardeos aliados. Más del 90% del centro de la ciudad fue destruido en un total de 88 ataques. Después de la guerra, la no fue reconstruida y sus ruinas se dejaron como memorial de guerra.

El avance aliado sobre el terreno hacia el interior de Alemania llegó a Hannover en abril de 1945. La 84.ª división de infantería tomó la ciudad el 10 de abril de 1945.

Hannover estaba en la zona de ocupación británica, y fue parte del nuevo estado (Land) de Baja Sajonia en 1946. Tras ello, el pueblo elige un nuevo Consejo, que designa a un alcalde. Entre 1972 y 2006 ocupó el puesto la misma persona, Herbert Schmalstieg.

La reconstrucción de la ciudad se llevó a cabo bajo la dirección de Rudolf Hillebrecht, arquitecto municipal. La nueva ciudad se basó en el modelo "Autogerechte Stadt", orientado por completo al coche. La ciudad está circunvalada por calles de varios carriles (Lavesallee, Leibnizufer, Hamburger Allee y Berliner Allee) unidas por rotondas. Gran parte del tráfico que atravesaba la ciudad ha sido desviado hacia vías rápidas. La vía de Messe atravesó por el medio el parque de Eilenriede. El entramado histórico urbano de la ciudad se mantiene a grandes rasgos. La malla de calles solo traza las líneas principales de las calles históricas.

Una de las características de Hannover es la aparición de zonas urbanas alejadas de la estructura histórica, lo que le valió reconocimiento a nivel nacional. Más tarde se revisaron los valores urbanos de la reconstrucción, tomando como modelo los barrios del y no el desarrollo urbano moderno, orientado al coche como en las ciudades de Estados Unidos. Las pérdidas causadas por la guerra lleva a muchos habitantes de Hannover a pedir que se reconstruyan los edificios históricos tal y como estaban antes de la guerra. Por ello, se decide la reconstrucción de la antigua residencia de verano de los Welfen en Herrenhauser Garten. 

En 1947 Rudolf Augstein funda la revista "Der Spiegel" y un año más tarde Henri Nannen hace lo mismo con la revista "Stern". Ambos periódicos importantes se trasladaron poco después a Hamburgo. Durante 1951 se celebra el primer "Bundesgartenschau" (Feria Nacional de Jardinería).

El 23 de junio de 1965 el Consejo de la ciudad decide construir una red de metro. En el centro de la ciudad se realiza una red de túneles que conectarán con la red de tranvías. Las obras comenzaron el 16 de noviembre de 1965 en Waterlooplatz. La red se siguió construyendo a lo largo de los años, hasta 1993. Al finalizar las obras se peatonalizaron grandes zonas, como el centro de la ciudad y la Lister Meile.

En el 2000 se celebró en la ciudad la Expo 2000, la primera Exposición Internacional que se celebraba en Alemania. El tema fue «Hombre, naturaleza y tecnología — Origen de un nuevo mundo». Se esperaban 40 millones de visitantes, aunque sólo se llegó a 18 millones, por lo que el balance general fue negativo.

En 2001 la administración de la ciudad de Hannover ha sido unificado con el antiguo distrito de Hannover. Juntos, forman parte de la Región de Hannover.

Hoy Hannover es Ciudad vicepresidente de Alcaldes por la Paz, una organización internacional de alcaldes que moviliza ciudades y ciudadanos por todo el mundo para abolir y eliminar armas nucleares para el año 2020.

Además, Hannover se ha convertido en un importante centro industrial y de servicios. Las empresas de servicios incluyen una serie de bancos, proveedores de servicios financieros y compañías de seguros como Norddeutsche Landesbank, Sparkasse, Hannover Rück, Talanx y VHV. Las principales empresas industriales incluyen Continental AG, Volkswagen Commercial Vehicles, Komatsu Limited y Wabco.

La ciudad de Hannover está dividida administrativamente en 13 distritos y estos, a su vez, en 51 barrios. Los 13 distritos de Hanóver son:


La ciudad de Hannover, conocida por las grandes ferias como la CeBIT, se encuentra a la orilla del río Leine. El centro de la ciudad ("Stadtmitte") cuenta con la Estación Central Ferroviaria ("Hauptbahnhof") que además de dar servicio de trenes para las principales ciudades y alrededores, cuenta con restaurantes y tiendas que abren todos los días de la semana. Una gran zona comercial peatonal se prolonga desde la estación de trenes hacia el sur, siendo la estación de metro "Kröpcke" su epicentro. A pocas manzanas al sur-oeste se encuentra el casco antiguo de la ciudad ("Altstadt"), donde se pueden ver edificios antiguos en la Kramergasse, el imponente Antiguo Ayuntamiento ("Altes Rathaus") construido en el y la iglesia del mercado "Marktkirche", construida entre 1349 y 1359, en ladrillo y estilo gótico. Siguiendo hacia el sur, se llega al Nuevo Ayuntamiento (vista panorámica desde la torre) y poco después, el Maschsee, un lago artificial que es popular destino de excursión y lugar de fiesta en verano. Un recorrido autoguiado, conocido como la «Línea Roja», permite visitar los lugares más destacados del centro; más información en el centro de información turística situado enfrente de la estación de trenes.

Saliendo de la estación de trenes en dirección norte, se llega rápidamente a la "Lister Meile", una atractiva zona comercial de algo más de kilómetro y medio de longitud que pasa por uno de los barrios más bellos de la ciudad: List.

Hannover también es una de las ciudades más verdes de Alemania: el bosque urbano "Eilenriede" es de los mayores de Europa y al noroeste del centro se encuentran los Jardines de la Casa Señorial ("Königlichen Gärten Herrenhausen") creados en 1666 por Sofía, princesa del Palatinado. Es uno de los jardines barrocos más bellos y más grandes de Alemania. Junto a "Herrenhausen" se halla el jardín botánico de estilo inglés, "Berggarten", que muestra orquídeas, cactus y el ecosistema tropical en un invernadero. Uno de los puntos estrella es el concurso de fuegos artificiales en verano.

A un par de kilómetros al este del centro está el Zoo de Hannover, uno de los más antiguos y espectaculares de Alemania. Alberga unos 2000 animales en seis mundos zoológicos, que recrean magníficamente su hábitat natural sin barreras visibles. Hay hasta ocho espectáculos al día, recorrido en barco por África, camino de aventura, camino de la evolución, safaris guiados, etc.

En los alrededores de Hannover hay también lugares interesantes que visitar, como Wedemark al norte, Burgdorf al este, Springe o Hamelín (ciudad del cazador de ratas) al sur o Wunstorf al oeste, cerca del lago Steinhude ("Steinhuder Meer").

En el centro de Hannover nos encontramos un lago artificial. El lago Maschsee, que mide de circunferencia 6 km, su construcción fue ordenada por Adolf Hitler en el año 1930 y finalizó en el 1936.


Hannover fue ciudad-sede de la Copa Mundial de Fútbol de 1974, la Eurocopa 1988, Copa Confederaciones 2005 y de la Copa Mundial de Fútbol de 2006

Hannover posee en la actualidad el recinto ferial más grande de Alemania, el "Deutsche Messe Hannover", que cuenta con 1.000.000 de m² y 27 recintos cubiertos. Una de las tantas ferias que se celebran aquí es la Feria de la Informática de Hannover, conocida como CeBIT, el acontecimiento anual más relevante para la industria de la informática en Europa, que recibe cada marzo a unos 500.000 visitantes. En el mismo recinto se celebró la Exposición Universal en el 2000.

Hannover ofrece una extensa red de transporte público, incluyendo metro (U-Bahn), trenes de cercanías (S-Bahn), tranvías y autobuses. El desarrollo de esta red de transporte público se comenzó a gestar en los años 60 y se consolidó en los 90 con la celebración de la EXPO 2000.

La estación central de trenes (Hauptbahnhof – Hbf) se encuentra en pleno centro de la ciudad. La estación de Kröpcke es una de las más importantes de la ciudad, ya que en ella cruzan todas las líneas de tranvía.


Hannover está hermanada con las siguientes ciudades:




</doc>
<doc id="42128" url="https://es.wikipedia.org/wiki?curid=42128" title="Hannover (desambiguación)">
Hannover (desambiguación)

El término Hannover puede referirse a:


Personas

</doc>
<doc id="42130" url="https://es.wikipedia.org/wiki?curid=42130" title="Santaella">
Santaella

Santaella es un municipio español de la provincia de Córdoba, Andalucía. En el año 2019 contaba con 4629 habitantes. Su extensión superficial es de 225,8 km² y tiene una densidad de 20,5 hab/km². Sus coordenadas geográficas son 38º34' N, 4º50' O. Se encuentra situado en la comarca de la Campiña Sur, a una altitud de 238 metros y a 43 kilómetros de la capital de provincia, Córdoba.

En época de dominio árabe se la conoció como "Shant'Yala", conquistada por Fernando III en 1240. Unas indagaciones identifican a Santaella con la Arcilasis de Ptolomeo, y también se ha llegado a afirmar que el nombre deriva de Santa Olalla o Eulalia, mártir emeritense.

Santaella se encuentra en la depresión del Guadalquivir, situada al suroeste de la provincia de Córdoba, cercana a otros pueblos como son La Carlota, Montalbán de Córdoba, La Rambla, Montemayor, Puente Genil y Écija, ya provincia de Sevilla.

Su extenso término ocupa un espacio considerado como de Campiña Alta, pero todos sus rasgos geográficos básicos se identifican con la subcomarca de la Campiña Baja, al norte en dirección al Guadalquivir.

En cuanto al relieve predomina una sedimentación margoarcillosa del Mioceno terminal (Era Terciaria), lo que explica la presencia de un paisaje suavemente ondulado, siendo su altitud media de 100 a 150 metros sobre el nivel del mar y cuyas pendientes rara vez sobrepasan el 5 %.

A esta imagen se suma algunos cerros de relativa altura siendo las cotas más elevadas el cerro de la Esparraguera con 328 m, La Puerca con 327 m y La Membrilla con 314 m, apenas superando todas ellas los 300 metros.

Su suave relieve unido a una tierra fértil y de valle hace de la agricultura la principal actividad económica del pueblo, donde los cultivos más destacables son de cereales y el olivo.

En cuanto a la hidrografía, el principal eje destacable es el río Genil a pesar de que apenas pasa por el término municipal y sirviendo de límite suroriental, por lo que hay que destacar también otros ríos y arroyos como son el río Cabra y el arroyo Salado, los cuales desembocan en el río Genil.

En referencia al clima decir que se caracteriza, como el resto de la comarca, por un clima de inviernos templados-fríos y de lluvias irregulares, y con unos veranos muy calurosos y secos.

Pedanías: La Montiela, Bocas del Salado, El Ingeniero y El Fontanar.

Número de habitantes en los últimos diez años.

Su única actividad económica es la agricultura, de secano y regadío, de la que se derivan algunas industrias auxiliares.
Situada en el valle medio del Guadalquivir, en la llamada Campiña de Córdoba, sus miles de hectáreas de tierra inmejorable para la agricultura, han hecho de esta localidad un factor importante en el desarrollo agrícola de la provincia.
Destaca la producción de cereal que, junto con el olivo, han sido los cultivos básicos de su agricultura. El cereal, tradicionalmente, se ha alternado con cultivos de verano tales como garbanzos, remolacha, girasol, melones, ajos...

En la actualidad la producción agrícola se va diversificando al introducirse el regadío.

Las tierras de Santaella se verán surcadas en un futuro próximo por una red arterial de canales pertenecientes al Plan de Riegos Genil-Cabra, que abre nuevas perspectivas para su campo.
El plan del Genil-Cabra, supone la puesta en riego de la mayor parte de nuestras tierras. Hoy una amplia zona del Término Municipal ya se beneficia de él.

Junto a esta capital importancia de la agricultura, y a su amparo, se desarrollan diversas industrias de transformación y un creciente sector terciario.

Las tierras de Santaella han atraído a los hombres desde sus tiempos más remotos. Documentada la aparición de éstos en el Paleolítico Inferior, en el más remoto periodo de la Edad de Piedra, continuando su presencia hasta nuestros días.

En el amplio término de Santaella se han encontrado abundantes testimonios del pasado que han ido reconstruyendo parte importante del pasado de esta tierra.

Los asentamientos de la época del bronce, ibéricos, romanos, visigodos y árabes han dejado cada uno de ellos huella de su paso en las tierras de esta población.

Con la llegada de los romanos y los sucesivos años bélicos, Roma acabó totalmente asentada y sometiendo a las poblaciones quedando estas romanizadas y por consecuente también Santaella. Sobre la época romana no se tiene constancia de un núcleo de población como tal.

La época ibérica nos deja, quizás, la pieza más importante que haya en el Museo Municipal, la Leona de Santaella. Hallada en el Cerro de la Mitra y se trata de una escultura perteneciente a una tumba.

Bajo el dominio árabe se la conoció como Santa-Ialla, conquistada por Fernando III en 1240. Años más tarde fue donada a Córdoba y quedó constituida en municipio en el año 1569.

Felipe II le concede su independencia jurisdiccional, para pasar, más tarde, a erigirse en marquesado, recobrando su independencia en 1735.
Desde esta fecha los avatares de Santaella reflejan el devenir histórico de la región y país en los que se insertan.

Es conocida como la catedral de la campiña y declarada Bien de Interés Cultural, es el monumento más representativo de Santaella. 

De origen musulmán, fue una antigua mezquita de época califal del siglo X. 

Destaca en el exterior su torre, del gótico tardío, terminada en 1527 por Hernán Ruiz I. Dentro de esta torre se formó una pequeña capilla gótica, al lado de ella se abre una bella puerta plateresca que da al patio de las campanas.

La iglesia cuenta con bellas muestras de orfebrería religiosa, ricas vestiduras telares, pinturas y un púlpito en mármol rosa.

Es del siglo XVI. La portada que da acceso al patio está fechada en 1699. Las obras realizadas en la primitiva ermita a mediados del siglo XVIII la sustituyeron por el magnífico templo actual. Las obras del edificio se realizaron entre 1747 y 1752, gracias a la generosidad del sacerdote Miguel Vicente Alcaide y Lorite.

La imagen más antigua de Santaella es sin duda la de Nuestra Señora del Valle considerada obra de transición del románico al gótico. 

Tiene planta de cruz latina, cabecera trilobulada bajo cúpula y elegante decoración geométrica en las tribunas del coro. 
La muralla y torre son de origen islámico, de época almohade, de finales del siglo XII.

En parte de la muralla cercana a la torre se encuentra una típica puerta con arco de herradura apuntando, que era la antigua puerta de la villa, hoy en día homenaje a los caídos en la guerra civil española.

Entre la puerta de la muralla y la torre se encuentra una construcción barroca de mampostería con portada y balcones, antiguamente sede del antiguo Ayuntamiento.

Muestra de un intenso pasado histórico en Santaella. 

Especial es la visita al Museo Municipal. Su sección más amplia es la de Arqueología, en ella se recoge una muestra interesante de los vestigios del pasado del hombre por nuestras tierras, expuesta con un marcado carácter didáctico. 

Dividida en tres salas: 

La primera y más amplia, dedicada a la Prehistoria.

La segunda sala recoge en sus vitrinas vestigios de los pueblos prerromanos. 

La tercera sala está dedicada a las tres grandes culturas.

Además hay sección de Etnología recoge toda una serie de restos de nuestro pasado reciente.

En Santaella encontramos un pueblo sensible a la cultura y al arte, así lo ponen de manifiesto la proliferación de asociaciones culturales con diversos fines: Protección del Patrimonio, la ecologista "Sant-Yala"... 


Parte del Patrimonio Histórico que encontramos en Santaella, se encuentra inscrito en el Patrimonio Histórico Andaluz (Patrimonio Histórico Andaluz en la Campiña Sur )

En la vida de todo pueblo son importantes las fiestas tradicionales, con las que se altera el cotidiano vivir. Santaella también cuenta con las suyas:




</doc>
<doc id="42137" url="https://es.wikipedia.org/wiki?curid=42137" title="Cléveris">
Cléveris

Cléveris ( o "Cleve"; ) es una ciudad alemana del estado federado de Renania del Norte-Westfalia en la región de Düsseldorf.

Es un importante centro turístico con bellos monumentos civiles y religiosos.

En 1614 la ciudad fue anexada a Prusia.

La Línea Sigfrido fue un sistema de defensa a lo largo de 630 km, que empezaba a la altura de Cléveris en la frontera sur con los Países Bajos, y terminaba en la frontera con Suiza. A diferencia de la línea Maginot, fue pensada con propósitos propagandísticos y fue construida entre 1938 y 1940.

La eurorregión Rin-Waal (; ) está enmarcada dentro de los programas de cooperación transfronteriza adelantados de la Unión Europea. Comprende Cléveris, la ciudad de Duisburgo y partes de las provincias de Güeldres, Brabante Septentrional y Limburgo en los Países Bajos.



</doc>
<doc id="42141" url="https://es.wikipedia.org/wiki?curid=42141" title="Hamelín">
Hamelín

Hamelín (en alemán: "Hameln") es una ciudad de Baja Sajonia, Alemania, a orillas del río Weser. Con una población de casi 58 000 habitantes, es la capital del distrito de Hamelin-Pyrmont.

Es principalmente conocida por el cuento "El flautista de Hamelín". También es el principal punto de acceso a las cercanas montañas Weserbergland, que pueden ser visitadas a pie o en bicicleta. Es la ciudad donde fueron ejecutados los asesinos condenados en el Juicio de Bergen-Belsen por crímenes contra la humanidad tras la Segunda Guerra Mundial.



</doc>
<doc id="42142" url="https://es.wikipedia.org/wiki?curid=42142" title="Hamelin">
Hamelin

Hamelin es una población y comuna francesa, situada en la región de Baja Normandía, departamento de Mancha, en el distrito de Avranches y cantón de Saint-James.


</doc>
<doc id="42144" url="https://es.wikipedia.org/wiki?curid=42144" title="Ricardo S. Sánchez">
Ricardo S. Sánchez

Ricardo S. Sánchez (1953) es un militar estadounidense de origen mexicano. Comandante del Ejército de los Estados Unidos durante la invasión y ocupación de Irak a partir del 14 de junio de 2003. 

Sánchez nació el año de 1953 en la ciudad fronteriza de Río Grande, Texas, en el seno de una familia pobre de ascendencia mexicana y cursó las licenciaturas en matemáticas e historia en la Universidad Agrícola y Mecánica de Texas ("Texas A&M"). Después de graduarse comenzó su carrera militar en la 82.ª División Aerotransportada del Ejército y en el año de 1977 fue transferido al cuerpo acorazado. Tras asumir diversas responsabilidades en las bases militares estadounidenses en Corea, Panamá y Alemania fue nombrado comandante de batallón durante la Operación Tormenta del Desierto, tomando el control de la ciudad iraquí de Basora en 1991 sin perder a uno sólo de sus hombres.

Tras asumir la dirección de las fuerzas terrestres aliadas durante la Operación Libertad Iraquí a principios del año 2003, Sánchez se hizo responsable del ataque que costó la vida a Uday y a Qusay Husein y de la captura de su padre, Sadam Husein.




</doc>
<doc id="42146" url="https://es.wikipedia.org/wiki?curid=42146" title="David Adjaye">
David Adjaye

David Adjaye (Dar es Salaam, septiembre de 1966) es un arquitecto ghanés.

Establecido en Londres, se inició como creador en 1994 remodelando bares y residencias. En el año 2000 creó su propia firma, "Adjaye Associates".

David Adjaye obtuvo su licenciatura en la London South Bank University, y terminó su maestría en 1993 en la Royal College of Art. El mismo año, ganó la medalla de bronce del RIBA, un premio normalmente ganado por los alumnos que solo han obtenido un título de licenciatura.

Después de un tiempo trabajando en diversos estudios de arquitectura, en 1994 Adjaye y William Russell establecieron por su cuenta un estudio al que llamaron "Adjaye & Russell", con sede en el norte de Londres. Esta oficina se disolvió en 2000 y Adjaye estableció su propio estudio el mismo año.

En 2006 fue nominado para el Premio Stirling por su Idea Store Whitechapel, en Londres. 
También colaboró con el artista Olafur Eliasson para crear una instalación de luz, "Your black horizon", en la Bienal de Venecia de 2005. Ha trabajado con Chris Ofili para crear un ambiente propicio para el Upper Room, hoy propiedad de la Tate Britain.

Sus trabajos recientes incluyen el Museo de Arte Contemporáneo de Denver, el Centro Nobel de la Paz en Oslo y la Escuela de Administración de Moscú Skolkovo, completada en el 2010.
El , fue seleccionado en un concurso para diseñar el Museo Nacional de Historia y Cultura Afroamericanas, que forma parte de la Smithsonian en Washington, DC, prevé abrir en 2015. La característica de su diseño es una corona de la escultura yoruba.





</doc>
<doc id="42149" url="https://es.wikipedia.org/wiki?curid=42149" title="Americio">
Americio

El americio es un elemento químico artificial de número atómico 95 situado dentro del grupo de los actínidos en la tabla periódica de los elementos. Su símbolo es Am. Todos sus isótopos son radiactivos y no existen en la naturaleza. Su nombre proviene de América, de forma análoga al europio.

El americio fue aislado por primera vez por Glenn T. Seaborg, Leon O. Morgan, Ralph A. James, y Albert Ghiorso en 1944 en el Laboratorio de Metalurgia de la Universidad de Chicago. El equipo creó el isótopo Am a partir de Pu, bombardeándolo con neutrones en un reactor nuclear. Esto se transformó en Pu y después en Pu, cambiando así a Am por desintegración beta. Seaborg obtuvo la patente US 3156523 para "Element 95 and Method of Producing Said Element" ("Elemento 95 y el método para producir dicho elemento").

El americio puro tiene un lustre plateado y blanco. Es más plateado que el plutonio y el neptunio, y aparentemente más maleable que este o el uranio. La desintegración alfa de Am es aproximadamente tres veces la del radio. Unos cuantos gramos de Am emiten una alta cantidad de rayos gamma, lo cual crearía serios problemas de salud a cualquiera que se expusiese al elemento. También presenta la característica de que es fisible.

Han sido descritos 19 radioisótopos del americio, siendo los más estables el Am con una vida media de 7370 años y el Am con vida media de 472,7 años. El resto de los isótopos radiactivos tienen vidas medias menores que 51 horas, casi en su mayoría mayores a 100 minutos. El elemento también tiene ocho isómeros nucleares, siendo el de mayor estabilidad Am (vida media de 141 años). Los pesos atómicos de los isótopos de americio oscilan entre 231,046 u.m.a (del Am) hasta 249,078 u.m.a. (correspondientes al Am).

Este elemento puede ser producido en cantidades de varios kilogramos y tiene algunos usos (en especial el Am, en virtud de que es relativamente más sencillo producir muestras de este radioisótopo). Este mismo radioisótopo fue utilizado como una fuente portátil de rayos gamma para su uso en radiografías. El isótopo Am es un emisor de neutrones y además es citado para uso en un avanzado cohete de propulsión nuclear; sin embargo, es demasiado caro como para producirse en cantidades suficientemente grandes.

El americio tiene cierta utilidad en el hogar y en la industria: algunos detectores de humo contienen una pequeña muestra, normalmente unos 0,9 microcurios (cerca de 0,2 miligramos) de Am, como fuente de radiación ionizante. El funcionamiento de estos detectores se basa en la disminución de la conductividad del aire. Una cámara del detector permite el contacto entre el americio y el ambiente. Dicho aire es ionizado por la presencia de partículas alfa provenientes de la desintegración de los núcleos de Am y se vuelve, por tanto, conductor, cerrando así un circuito. La presencia de otras partículas no ionizadas reduce la conductividad dentro de la cámara, interrumpe el circuito, y permite que suene la alarma. Cabe destacar que la cantidad de americio presente en estos detectores no pone en peligro la salud de los inquilinos. A pesar de que se prohíba su comercialización el hecho de tener uno instalado no significa incurrir en un delito. Estas alarmas fueron retiradas del mercado debido a que su gestión como residuos era especial y más cara de lo normal.
El número de oxidación más común del americio es +3. Es mucho más complicado oxidar Am(III) a Am(IV) que hacerlo de Pu(III) a Pu(IV) en solución acuosa.

Los científicos trabajan para reducir la radiotoxicidad o bien encontrar el modo de hacerla útil para ser usada como combustible nuclear.

El americio, a diferencia del uranio, no forma fácilmente dióxido de americio (AmO). Esto se debe a su dificultad para oxidarse por arriba de +3 cuando se encuentra en solución acuosa. En el medio ambiente puede hacerse un compuesto complejo agregándose el carbono y oxígeno.






</doc>
<doc id="42156" url="https://es.wikipedia.org/wiki?curid=42156" title="Organización territorial de Dinamarca">
Organización territorial de Dinamarca

La organización territorial Dinamarca está dividida administrativamente en cinco regiones y estas en 98 municipios. Esta está vigente desde el 1 de enero de 2007 tras ser abolida la histórica división del territorio en 13 distritos.

Desde 1970 hasta el 31 de diciembre de 2006, Dinamarca estuvo dividida en 13 distritos ("amter") y 271 ("kommuner").

En el caso del área metropolitana de Copenhague, este estaba administrado por el distrito homónimo a excepción de dos municipios autónomos, uno del mismo nombre y el de Frederiksberg. En tanto, la isla de Bornholm se encontraba dividida en cinco municipios que conformaban un condado hasta que fueron unidas en un solo municipio regional el 1 de enero de 2003. Este municipio regional tenía las mismas características que los municipios autónomos de la capital.

En 2004, el gobierno propuso reformar el sistema administrativo al actual: cinco grandes regiones con el fin de administrar el sistema de salud. La propuesta además incluía la reducción de municipios a cerca de 100 con un mínimo de 20.000 habitantes por cada uno (aunque se establecieron algunas excepciones). El parlamento de Dinamarca finalmente aprobó la propuesta el 24 de febrero de 2005.



</doc>
<doc id="42158" url="https://es.wikipedia.org/wiki?curid=42158" title="Fráncfort del Óder">
Fráncfort del Óder

Fráncfort del Óder (en alemán: "Frankfurt an der Oder") es una ciudad de Brandeburgo (Alemania), a orillas del río Óder y en la frontera polaco-alemana. La coletilla "del Óder" se le añade para diferenciarla de Fráncfort del Meno ("Frankfurt am Main"). La ciudad es sede de la Universidad Europea Viadrina. Al otro lado del Óder se encuentra la localidad polaca de Słubice, que formó parte de Fráncfort hasta 1945.

Durante los primeros años de la Segunda Guerra Mundial la ciudad sufrió daños relativamente moderados. Sin embargo, en febrero de 1944 la Royal Air Force realizó un ataque planificado. El resultado fueron 58 víctimas mortales con la destrucción de una fábrica y varias casas.

En abril de 1945 el Ejército Rojo llega a la ciudad en el marco de la batalla de Berlín. Al final de la guerra, el centro de la ciudad estaba destruido en más de un 90%.

Fráncfort del Óder está ubicada a 80 kilómetros de la capital alemana, Berlín.

Las fuentes de datos se pueden encontrar en detalle en los Wikimedia Commons.



</doc>
<doc id="42172" url="https://es.wikipedia.org/wiki?curid=42172" title="(2050) Francis">
(2050) Francis

(2050) Francis es un asteroide perteneciente al cinturón de asteroides descubierto por Eleanor Francis Helin desde el observatorio del Monte Palomar, Estados Unidos, el 28 de mayo de 1974.

Francis fue designado inicialmente como .
Más tarde se nombró en honor de Fred Francis y Kay Francis, padres de la descubridora.

Francis orbita a una distancia media del Sol de 2,324 ua, pudiendo acercarse hasta 1,77 ua y alejarse hasta 2,878 ua. Su inclinación orbital es 26,61° y la excentricidad 0,2383. Emplea en completar una órbita alrededor del Sol 1294 días.



</doc>
<doc id="42173" url="https://es.wikipedia.org/wiki?curid=42173" title="(2074) Shoemaker">
(2074) Shoemaker

(2074) Shoemaker es un asteroide perteneciente al grupo de los asteroides que cruzan la órbita de Marte descubierto por Eleanor Francis Helin desde el observatorio del Monte Palomar, Estados Unidos, el 17 de octubre de 1974.

Shoemaker se designó inicialmente como .
Posteriormente fue nombrado en honor del astrónomo estadounidense Eugene Shoemaker (1928-1997).

Shoemaker está situado a una distancia media de 1,8 ua del Sol, pudiendo alejarse hasta 1,947 ua y acercarse hasta 1,652 ua. Tiene una excentricidad de 0,0819 y una inclinación orbital de 30,08°. Emplea en completar una órbita alrededor del Sol 881,9 días.



</doc>
<doc id="42174" url="https://es.wikipedia.org/wiki?curid=42174" title="(2391) Tomita">
(2391) Tomita

(2391) Tomita es un asteroide perteneciente al cinturón de asteroides descubierto por Karl Wilhelm Reinmuth desde el Observatorio de Heidelberg-Königstuhl, Alemania, el 9 de enero de 1957.

Tomita recibió al principio la designación de .
Posteriormente, en 1987, se nombró en honor del astrónomo japonés Koichiro Tomita (1925-2006).

Tomita está situado a una distancia media de 2,44 ua del Sol, pudiendo alejarse hasta 2,768 ua y acercarse hasta 2,112 ua. Tiene una excentricidad de 0,1344 y una inclinación orbital de 3,011 grados. Emplea en completar una órbita alrededor del Sol 1392 días.

La magnitud absoluta de Tomita es 12,5 y el periodo de rotación de 7,953 horas.



</doc>
<doc id="42176" url="https://es.wikipedia.org/wiki?curid=42176" title="(2393) Suzuki">
(2393) Suzuki

(2393) Suzuki es un asteroide que forma parte del cinturón exterior de asteroides y fue descubierto por Margueritte Laugier desde el Observatorio de Niza, Francia, el 17 de noviembre de 1955.

Suzuki se designó inicialmente como .
Más tarde fue nombrado en honor del astrónomo japonés Keishin Suzuki.

Suzuki orbita a una distancia media de 3,236 ua del Sol, pudiendo acercarse hasta 2,623 ua y alejarse hasta 3,849 ua. Tiene una inclinación orbital de 10,21° y una excentricidad de 0,1895. Emplea 2126 días en completar una órbita alrededor del Sol.



</doc>
<doc id="42177" url="https://es.wikipedia.org/wiki?curid=42177" title="(2399) Terradas">
(2399) Terradas

(2399) Terradas es un asteroide que forma parte del cinturón de asteroides y fue descubierto por Carlos Ulrrico Cesco desde el observatorio El Leoncito, Argentina, el 17 de junio de 1971.

Terradas se designó inicialmente como .
Posteriormente fue nombrado en honor del matemático español Esteban Terradas e Illa (1883-1950).

Terradas está situado a una distancia media de 2,239 ua del Sol, pudiendo acercarse hasta 1,859 ua y alejarse hasta 2,62 ua. Tiene una inclinación orbital de 5,13° y una excentricidad de 0,1699. Emplea 1224 días en completar una órbita alrededor del Sol.



</doc>
<doc id="42178" url="https://es.wikipedia.org/wiki?curid=42178" title="(2653) Principia">
(2653) Principia

(2653) Principia es un asteroide perteneciente al cinturón de asteroides descubierto por el equipo del Indiana Asteroid Program desde el Observatorio Goethe Link de Brooklyn, Estados Unidos, el 4 de noviembre de 1964.

Principia se designó inicialmente como .
Más adelante, en 1987, fue nombrado por la obra científica "Principia", del físico inglés Isaac Newton (1643-1727), con motivo del tricentenario de su publicación.

Principia está situado a una distancia media del Sol de 2,444 ua, pudiendo alejarse hasta 2,64 ua y acercarse hasta 2,247 ua. Su excentricidad es 0,08035 y la inclinación orbital 4,746 grados. Emplea en completar una órbita alrededor del Sol 1395 días.

La magnitud absoluta de Principia es 12,1 y el periodo de rotación de 5,523 horas. Está asignado al tipo espectral V de la clasificación SMASSII.



</doc>
<doc id="42179" url="https://es.wikipedia.org/wiki?curid=42179" title="(3907) Kilmartin">
(3907) Kilmartin

(3907) Kilmartin es un asteroide que forma parte del cinturón de asteroides y fue descubierto por Maximilian Franz Wolf el 14 de agosto de 1904 desde el Observatorio de Heidelberg-Königstuhl, Alemania.

Kilmartin fue designado al principio como .
Más adelante, en 1989, a propuesta de Brian Marsden, fue nombrado en honor de la astrónoma neozelandesa Pamela Kilmartin.

Kilmartin está situado a una distancia media del Sol de 2,793 ua, pudiendo acercarse hasta 2,452 ua y alejarse hasta 3,133 ua. Tiene una excentricidad de 0,1218 y una inclinación orbital de 11,01 grados. Emplea en completar una órbita alrededor del Sol 1705 días.

La magnitud absoluta de Kilmartin es 11,8 y el periodo de rotación de 3,841 horas.



</doc>
<doc id="42180" url="https://es.wikipedia.org/wiki?curid=42180" title="(4446) Carolyn">
(4446) Carolyn

(4446) Carolyn es un asteroide que forma parte del cinturón exterior de asteroides y fue descubierto por Edward L. G. Bowell desde la Estación Anderson Mesa, en Flagstaff, Estados Unidos, el 15 de octubre de 1985.

Carolyn se designó al principio como .
Posteriormente, en 1991, fue nombrado en honor de la astrónoma estadounidense Carolyn Shoemaker.

Carolyn orbita a una distancia media del Sol de 3,986 ua, pudiendo acercarse hasta 2,87 ua y alejarse hasta 5,102 ua. Su inclinación orbital es 7,239 grados y la excentricidad 0,2799. Emplea en completar una órbita alrededor del Sol 2907 días.

Carolyn pertenece al grupo asteroidal de Hilda.

La magnitud absoluta de Carolyn es 11,2.



</doc>
<doc id="42182" url="https://es.wikipedia.org/wiki?curid=42182" title="(4457) van Gogh">
(4457) van Gogh

(4457) van Gogh es un asteroide que forma parte del cinturón de asteroides y fue descubierto por Eric Walter Elst el 3 de septiembre de 1989 desde el Observatorio de la Alta Provenza, Francia.

van Gogh recibió al principio la designación de .
Más tarde, en 1990, se nombró en honor del pintor neerlandés Vincent van Gogh (1853-1890) con motivo del centenario de su muerte.

van Gogh está situado a una distancia media de 2,664 ua del Sol, pudiendo alejarse hasta 3,001 ua y acercarse hasta 2,327 ua. Su excentricidad es 0,1265 y la inclinación orbital 13,82 grados. Emplea 1588 días en completar una órbita alrededor del Sol.

La magnitud absoluta de van Gogh es 12 y el periodo de rotación de 7,606 horas.



</doc>
<doc id="42183" url="https://es.wikipedia.org/wiki?curid=42183" title="(6000) United Nations">
(6000) United Nations

(6000) United Nations es un asteroide perteneciente al cinturón de asteroides, región del sistema solar que se encuentra entre las órbitas de Marte y Júpiter, más concretamente a la familia de Eunomia, descubierto el 27 de octubre de 1987 por Poul Jensen desde el Observatorio Brorfelde, Holbæk, Dinamarca.

Designado provisionalmente como 1987 UN. Fue nombrado United Nationspor votación de la Comisión 20 de la IAU en su reunión de 1994 en La Haya por recomendación del Comité de Nombres de Planetas Menores.

United Nations está situado a una distancia media del Sol de 2,600 ua, pudiendo alejarse hasta 3,084 ua y acercarse hasta 2,116 ua. Su excentricidad es 0,186 y la inclinación orbital 14,41 grados. Emplea 1531,84 días en completar una órbita alrededor del Sol.

La magnitud absoluta de United Nations es 11,9. Tiene 11 km de diámetro y su albedo se estima en 0,211. 




</doc>
<doc id="42186" url="https://es.wikipedia.org/wiki?curid=42186" title="Categoría de conjuntos">
Categoría de conjuntos

En matemática, la categoría de conjuntos es categoría cuyos objetos son todos los conjuntos y los morfismos son las funciones. Es la categoría más básica y la más comúnmente usada en matemática. La denotamos generalmente por Set. 

Los epimorfismos en Set son las funciones sobreyectivas, los monomorfismos son las funciones inyectivas, y los isomorfismos son las funciones biyectivas. 

El conjunto vacío actúa como el objeto inicial en Set, mientras que cada singletón es un objeto terminal. No hay así ningún objeto cero en Set. 

La categoría Set es completa y co-completa. El producto en esta categoría está dado por el producto cartesiano de conjuntos. El coproducto está dado por la unión disjunta: los conjuntos dados "A" donde "i" se extiende sobre un cierto I, construimos el coproducto como la unión de "A" × {"i"} (el producto cartesiano sirve para asegurar que todos los componentes son disjuntos). 

Set es el prototipo de una categoría concreta; otras categorías son concretas si "se asemejan" a Set de una cierta manera bien definida. 

Cada conjunto de dos elementos sirve como un clasificador de subobjetos en Set. El objeto de partes de un conjunto está dado por su conjunto de partes, y el objeto exponencial de los conjuntos "A" y "B" está dado por el conjunto de todas las funciones de "A" a "B". Set es así un topos (y en particular cartesiano cerrada).

Set no es abeliana, aditiva o preaditiva; no tiene siquiera morfismos cero. 

Cada objeto no inicial en Set es inyectivo y (asumiendo axioma de elección) también proyectivo.



</doc>
<doc id="42188" url="https://es.wikipedia.org/wiki?curid=42188" title="Rótula">
Rótula

La rótula ("patella") es un hueso sesamoideo situado en el plano anterior de la articulación de la rodilla, engastada en el tendón del cuádriceps. Es aplanada, de forma triangular con vértice inferior, y su eje mayor mide unos 5 cm. El borde superior (base) y la cara anterior reciben las fibras del tendón del cuádriceps, y de su vértice parte el ligamento rotuliano que continúa al tendón del cuádriceps. La cara posterior (cara articular) posee la superficie articular para el fémur y, por debajo, una zona rugosa relacionada con formaciones adiposas de la articulación de la rodilla. La superficie articular consta de dos vertientes laterales separadas por una cresta roma central que se adaptan a la superficie rotuliana del fémur. Se considera el hueso sesamoideo más grande del cuerpo humano.

Se encuentra en la parte anterior de la rodilla. Su vértice se articula con el fémur.
La rótula es un hueso plano y redondeado que se encuentra incluido en el tendón terminal del músculo cuadriceps femoral y está situado por delante de la extremidad inferior del fémur.

Pueden considerarse en él una cara anterior, una cara posterior, la base, el vértice o apex y dos bordes laterales.

Las cuatro cabezas del cuádriceps (M. vasto intermedio, M. vasto lateral, M. vasto medial, M. recto femoral) se condensan en láminas tendinosas que confluyen en la proximidad de la rótula formando el tendón del cuádriceps, en cuyo espesor se localiza la rótula. El mayor componente de fibras emerge por el vértice inferior de la rótula y forma una potente cinta tendinosa denominada ligamento rotuliano que se inserta en la tuberosidad de la tibia.

Del sector inferior de los bordes laterales de la rótula emergen láminas fibrosas, las cuales contribuyen a reforzar la articulación de la rodilla. Un aspecto de interés es que los componentes tendinosos fibrilares de cada vientre del cuádriceps ocupan planos diferentes y pueden ser identificados en la región rotuliana. Las fibras del recto femoral, son las más superficiales y algunas de ellas saltan hasta el ligamento rotuliano sin insertarse en la rótula. Las fibras de los vasto medial y vasto lateral y ocupan un plano más profundo y, como se ha descrito antes, parte de sus componentes emergen por los bordes laterales de la rótula para reforzar la articulación de la rodilla. Las fibras más profundas son las del vasto intermedio, que se agotan en el borde superior de la rótula. Por encima de la rótula puede aparecer una bolsa sinovial interpuesta entre los planos tendinosos superficial y profundo del tendón del cuádriceps (bolsa subtendinosa prerrotuliana).

Es convexa de arriba abajo y también en sentido transversal. Está cubierta de manojos fibrosos procedentes del tendón del cuádriceps, único músculo que se inserta en la misma. La separa de la piel una bolsa serosa llamada bolsa prerrotuliana y compleja.
Su articulación es con la tibia y peroné.

La rótula ha evolucionado de manera convergente en los mamíferos placentarios y aves; la mayoría de los marsupiales solo tienen rudimentaria rotuliana, no osificada, aunque algunas especies poseen una rótula ósea. La rótula también está presente en los monotremas ( el ornitorrinco y el equidna). En los tetrápodos más primitivos, incluyendo anfibios y la mayoría de los reptiles (excepto algunos Lepidosaurios), los tendones de los músculos de la pierna superior se unen directamente a la tibia y una rótula no está presente.

Actualmente la anatomía comparada lo relaciona como un remanente de un olecranon femoral primitivo como los presentes en los primates menores.


</doc>
<doc id="42189" url="https://es.wikipedia.org/wiki?curid=42189" title="Fémur">
Fémur

El fémur es el hueso del muslo, el segundo segmento del miembro inferior. Es el hueso más largo, fuerte y voluminoso del cuerpo humano, y de la mayor parte de los mamíferos.
El fémur se encuentra en la parte inferior de nuestro cuerpo; los músculos que se encuentran en el fémur son: bíceps femoral, las cuatro cabezas del cuádriceps (recto femoral, vasto lateral, vasto medial y vasto intermedio o crural), semitendinoso y semimembranoso.

Su longitud en promedio es de 26.74% de la altura de una persona, esta proporción varía en los hombres, en mujeres y la mayoría de los grupos étnicos y este dato es útil en la antropología, ya que ofrece una base para una estimación razonable de la altura de un sujeto de tener un esqueleto incompleto.

En latín fémur significa muslo, en latín médico su forma genitiva es siempre femoris, pero en latín clásico el genitivo es a menudo Feminis, y no debe confundirse con las formas derivadas de la palabra en latín "femina", que significa mujer.

El fémur se desarrolla a partir de las yemas de las extremidades, como resultado de las interacciones entre el ectodermo y el mesodermo subyacente, la formación se produce más o menos alrededor de la cuarta semana del desarrollo.

En la sexta semana de desarrollo, el primer modelo de cartílago hialino del fémur está formado por los condrocitos. Osificación endocondral, comienza por el final del período embrionario y centros de osificación primarios están presentes en todos los huesos largos de las extremidades, incluyendo el fémur, por la 12ª semana de desarrollo. El desarrollo de las extremidades posteriores va a la zaga del desarrollo extremidad anterior por 1-2 días.
El fémur se clasifica como un hueso largo y consta de un diáfisis, el eje (o cuerpo) y dos epífisis o las extremidades que se articulan con los huesos adyacentes en la cadera y la rodilla. 
. Durante la época de crecimiento ósea también encontramos metáfisis, que está situada entre la diáfisis y la epífisis.

De la clase de los Presenta una ligera curvatura de concavidad posterior, y en el esqueleto se dispone inclinado hacia abajo y adentro, oblicuidad que resulta más notable en el caso de la mujer por la mayor separación entre las cavidades cotiloideas de los coxales, donde se articula el fémur por arriba (articulación coxofemoral) –la pelvis femenina es más ancha que la masculina–.
Además, en el fémur se observa una ligera torsión: el eje del cuello femoral no está en el mismo plano que el eje transversal de los cóndilos, sino que configuran un ángulo agudo de declinación, abierto hacia dentro y adelante. Según la apertura de este ángulo tendremos una coxa u otra: 

a.)   Coxa normal (126º)

b.)   Coxa vara (115º): el que tiene más riesgo de sufrir una fractura ya que cuanto más cerrado es el ángulo más fuerza ejercemos sobre esa zona. A menos angulación más estrés, tendencia a que tengamos más fuerzas compresoras en la zona medial y distractoras en la lateral.

c.)   Coxa valga (140º): en defecto es mejor que quede un ángulo más grande

Anatómicamente, y como en todos los huesos largos, se distinguen en el fémur tres partes fundamentales:

Son cinco los puntos de osificación del fémur: uno "primitivo", y cuatro "complementarios".



El punto de osificación de la epífisis distal tiene importancia forense ya que sirve para poder establecer la madurez del feto, la osificación comienza en el noveno mes de la vida fetal y en el momento del nacimiento suele tener unos 5 mm de diámetro, aunque el grado de su desarrollo no permite conclusiones definitivas, sino solo estimativas.

La osificación del fémur se completa en torno a los 19 años de edad en la cabeza femoral.

La diáfisis femoral es aproximadamente prismática triangular. En ella hay que describir tres caras y tres bordes.

Su "cara anterior", ligeramente convexa en sentido transversal, y lisa, presta inserción en su mayor parte, y por arriba, al músculo crural, uno de los componentes del cuádriceps crural. Más abajo, se inserta el subcrural.

Separadas de la cara anterior por los "bordes interno" y "externo", se muestran las otras dos caras del fémur, la interna y externa, o mejor, la posterointerna y posteroexterna, que prestan inserción al crural. El vasto interno y vasto externo las cubren, sin que se inserten en la superficie ósea. Se ve cuán íntimas son las relaciones del fémur con tres de los componentes del cuádriceps crural.

De los bordes, el interno y externo están poco marcados, de forma que las caras anterior y posterolaterales carecen de límites claros. El "borde posterior", sin embargo, es notable: la "línea áspera".

La "línea áspera", conformada por un labio lateral -externo- y otro medial -interno-, entre los que queda un "intersticio", recorre la diáfisis longitudinalmente.

La línea áspera termina de modo distinto por abajo y por arriba:

En resumen, el cuerpo del fémur está especialmente relacionado con el músculo cuádriceps crural pues tres de sus cuatro cuerpos musculares -crural, vasto interno y vasto externo- se insertan en él, posibilitando el movimiento de extensión de la pierna. Además, los aductores del muslo, bíceps crural y glúteo mayor, entre otros, tienen también sus inserciones en este hueso, como corresponde a la riqueza de movimientos del miembro inferior.



Voluminoso, el extremo o epífisis inferior se organiza en los cóndilos, dos masas laterales respecto al plano sagital de la diáfisis: "cóndilo interno" y "cóndilo externo". En ellos se desarrolla la "tróclea", superficie lisa para la articulación del fémur con la tibia en la rodilla -articulación femorotibial-.

Por debajo y detrás los cóndilos están completamente separados por la profunda "escotadura o fosa intercondílea".

Por encima de la tróclea destaca:

El fémur es el único hueso del muslo, sirve como un punto de fijación para todos los músculos que ejercen su fuerza sobre las articulaciones de la cadera y de la rodilla. Algunos músculos biarticulares - que cruzan las dos articulaciones, como los músculos gemelos y Plantares. En total, 22 músculos individuales o bien se originan en o insertan en el fémur.

En sección transversal, el muslo está dividido en tres compartimentos. Estos compartimentos utilizan el fémur como un eje, y están separados por membranas duras del tejido conectivo (o septos). Cada uno de estos compartimentos tiene su propio suministro sanguíneo y nervioso, y contiene un grupo diferente de los músculos. Estos compartimentos se conocen como compartimento anterior, compartimentos medial y posterior.
Una fractura femoral que implica la cabeza femoral, el cuello femoral o el cuerpo del fémur inmediatamente por debajo del trocánter menor se puede clasificar como una fractura de cadera, especialmente cuando se asocia con osteoporosis. Las fracturas de fémur se pueden manejar en un entorno pre-hospitalario con el uso de una férula de tracción.

En los tetrápodos primitivos, los principales puntos de inserción muscular a lo largo del fémur son el trocánter menor y tercer trocánter, y una cresta a lo largo de la superficie ventral de la diáfisis femoral se refiere como la cresta aductor. El cuello del fémur es generalmente mínima o ausente en las formas más primitivas, lo que refleja una fijación sencilla al acetábulo. El trocánter mayor se presentó en los arcosaurios extintos, así como en las aves y los mamíferos modernos, están asociados con la pérdida de la marcha en expansión primitiva. El trocánter menor es un desarrollo único de los mamíferos, que carecen tanto de los trocánteres internos y cuarto. La cresta del aductor también es a menudo ausente en los mamíferos o, alternativamente reducido a una serie de pliegues a lo largo de la superficie del hueso.

Algunas especies de ballenas, serpientes y otros vertebrados , que no caminan, tienen fémures vestigiales.

Uno de los vertebrados más antiguos conocidos por tener un fémur es el "Eusthenopteron", un pez de aletas lobuladas prehistóricos del periodo Devónico tardío.

Estructuras análogas a la tercera trocánter están presentes en los mamíferos, incluyendo algunos primates.



</doc>
<doc id="42190" url="https://es.wikipedia.org/wiki?curid=42190" title="Hueso coxal">
Hueso coxal

El hueso coxal ("Os coxae"; "ilium", "ischium", "pubis"), del latín "cadera", es un hueso de la pelvis ósea, par, plano, esponjoso, en forma cuadrilátera helicoidal, compuesto por tres huesos embrionarios: ilion, pubis e isquion. Tiene dos caras: externa e interna; cuatro bordes: superior, inferior, anterior y posterior, y cuatro ángulos.

Abarca desde la cintura hasta la pelvis. Se articula con el homónimo opuesto a nivel de la sínfisis púbica y con el sacro para formar la pelvis, y con el fémur para formar la articulación de la cadera o coxofemoral. A pesar de estar articulada en sí misma, existe cierta movilidad en los huesos coxales, de especial importancia durante los trabajos de parto, en las mujeres.

La zona articular más importante del hueso coxal es el "acetábulo" o "cotilo" que es la cavidad articular para la cabeza del fémur. Es en este punto donde los tres huesos conformantes del hueso coxal se encuentran. Este acetábulo es rebordeado por el "rodete cotiloideo" o labrum acetabular, que es un cartílago que amplía la cavidad cotiloidea, permite mayor articulación con el fémur, y contribuye a la estabilización de la articulación coxofemoral por la creación de presión negativa durante la marcha.

Ilion: el ilion es uno de los tres huesos que forman el coxal en la cintura pelviana. Es un hueso ancho y acampanado que constituye las secciones superior y lateral de la pelvis. El ilion se caracteriza por sus alas que se extienden a cada lado de la espina dorsal.

Isquion: el isquion es uno de los tres huesos que fusionados forman la pelvis en un adulto. El isquion soporta el peso del cuerpo cuando estamos sentados y está unido al pubis en la parte delantera y a las alas del ilion en los lados y en la parte posterior.

Pubis: el pubis es uno de los tres huesos que se fusionan para formar la pelvis. Este presenta dos segmentos o ramas a cada lado de la sínfisis púbica: El superior se articula con las alas o con el ilion. El inferior se articula con el isquion de la pelvis.

Cresta ilíaca: la cresta ilíaca marca el surco superior de las alas del ilion y presenta un labio interno y otro externo con una línea en medio de ambos.

Sínfisis púbica: la sínfisis púbica es la conexión entre las dos partes del pubis. Presenta una línea de cartílago calcificado y resistente. En la mujer, la sínfisis púbica está cubierta con un tejido adiposo denominado monte de Venus.

Agujero Obturador: el obturador es una gran apertura en cada pubis que permite el paso de vasos sanguíneos y nervios desde la cavidad abdominal hasta el interior de la parte superior de las piernas.



</doc>
<doc id="42193" url="https://es.wikipedia.org/wiki?curid=42193" title="Amílcar Barca">
Amílcar Barca

Amílcar Barca o Barcas (c. 275 a 228 a. C.) fue un general y estadista cartaginés, líder de la familia Bárcida, y padre de Aníbal, Asdrúbal y Magón. Fue también suegro de Asdrúbal el Bello. El nombre de Amílcar (púnico-fenicio 𐤇𐤌𐤋𐤒𐤓𐤕 "ḥmlqrt", «hermano de Melkart») era un nombre común para los hombres de Cartago. El nombre 𐤁𐤓𐤒 ("Brq" o "Baraq") significa "rayo" en el idioma púnico y por lo tanto equivalente al epíteto o sobrenombre Cerauno, común entre muchos comandantes griegos contemporáneos. La palabra permanece en árabe y hebreo con el mismo significado.

Amílcar mandó las fuerzas de tierra cartaginesas en Sicilia durante 247-241 a. C., durante las últimas etapas de la primera guerra púnica. Mantuvo su ejército intacto y encabezó una exitosa guerra de guerrillas contra los romanos en Sicilia. Después de la derrota de Cartago en 241 a. C. Amílcar se retiró a África después de un tratado de paz. Cuando la Guerra de los mercenarios estalló en 239 a. C., Amílcar fue llamado a mandar las fuerzas cartaginesas y fue fundamental en la conclusión del conflicto con éxito. Amílcar dirigió la expedición cartaginesa en Iberia en 237 a C , y después de ocho años amplió el territorio cartaginés en Iberia antes de morir en la batalla de Illici en 228 a C .

Nacido en Cartago, posiblemente originario de una familia aristocrática cartaginesa de Cirene (actual Libia) emigrada a Cartago. La tradición habla de que la familia descendía directamente de Dido ("Elisa"), fundadora de la ciudad púnica según la mitología cartaginesa. En el 247 a.C, a la edad de 28 años, asume el mando de las tropas cartaginesas en Sicilia durante la primera guerra púnica contra Roma.

Amílcar (o 𐤇𐤌𐤋𐤒𐤓𐤕, "Hmlqrt", en púnico «hermano de Melqart», dios de los fenicios que los cartagineses denominarían Baal), es el fundador de la estirpe de los Bárcidas (de 𐤁𐤓𐤒, "Barqa" o "Baraq", «rayo, fulgor»), una serie de generales y hombres de estado al servicio de Cartago. Héroe de la primera guerra púnica, de la Guerra de los Mercenarios y padre del célebre Aníbal -el Bárcida que alcanzaría el cénit de la dinastía durante la segunda guerra púnica-. También es conocido como gobernante de la Iberia cartaginesa y como posible fundador de varias ciudades españolas como la capital de la Iberia Púnica Qart Hadsht (Cartagena), Alicante (Akra Leuké) o Barcelona.

En la Primera guerra púnica, Amílcar, tras haber desembarcado por sorpresa en el noroeste de Sicilia al mando de un heterogéneo y reducido contingente militar formado en su mayor parte por mercenarios de diversas nacionalidades, confirma no obstante el control cartaginés sobre la isla, tradicional feudo romano. Utiliza para ello tácticas y elementos mixtos e innovadores, al estilo de Pirro y Alejandro, dotando a sus hombres de una versatilidad y disciplina extraordinarias (con las dificultades ya comentadas, al tratarse de fuerzas muy diversas en tipología y origen) mediante las cuales consigue hacerse fuerte en el monte "Heirktê" o "Ercte" (actual Monte Pellegrino, cerca de Palermo) y desde donde hace frente a los continuos ataques romanos en constante inferioridad numérica, llegando incluso más allá de la defensa, armando un contraataque que le llevaría exitosa y prácticamente hasta la costa sur de Italia. Si bien Amílcar no llegó a recuperar ninguna de las ciudades perdidas ante Roma ni a ganar batallas relevantes, su actuación fue siempre digna y exitosa, causando numerosas bajas y provocando un elevado y continuo coste en recursos a los romanos. Tras la derrota cartaginesa en la primera guerra púnica, Amílcar acabó invicto, retirándose con sus 20.000 hombres ordenadamente sin rendir las armas (algo inaudito entre los enemigos derrotados por Roma) y con un bien ganado prestigio entre sus hombres y sus enemigos.

La situación en Cartago tras la derrota era de profundo malestar, y las condiciones de la rendición ante Roma suponían una humillante sumisión al vencedor, aparte de un notable déficit económico tanto por las pérdidas sufridas como por los tributos a pagar al bando victorioso. La desazón se hace especialmente ardua entre las tropas mercenarias que deseaban cobrar su paga –algunos no la cobraban desde mucho antes de acabar el conflicto-, aunque también entre los campesinos libios, así como los comerciantes que veían ahora cortadas las rutas comerciales y con ellas sus ingresos. Esta crisis desemboca en lo que se llamó la Rebelión de los Mercenarios los cuales, unidos a esclavos fugitivos y a campesinos empobrecidos, y dirigidos por el líder libio Matón, el mercenario galo Autarito y el esclavo campano Spendios, alzan un ejército de cerca de 90 000 hombres, creando un alzamiento popular contra Cartago, apoderándose y levantando la mayoría de las ciudades aliadas y llegando a poner cerco a la misma capital. Con la metrópoli en jaque por las derrotas de las exiguas tropas cartaginesas al mando de Hannón, en una situación mucho más peligrosa y cercana al saqueo y a la destrucción que durante toda la primera guerra púnica, Amílcar resulta ser elegido como caudillo para sofocar tan peligrosa revuelta, en base al respeto y el temor que su imagen causaba entre los mercenarios, aparte del prestigio militar y la demostrada capacidad en el manejo de tropas labrados contra Roma. Así pues, con la ciudad cercada, consigue sacar de noche a sus tropas (muy inferiores en número a las rebeldes) por sorpresa y, tras una larga, dura y magistral campaña de hostigamiento, tras tres sangrientos años y cuatro meses de arduas luchas acaba con la cruenta rebelión, crucificando a los rebeldes supervivientes.

Tras tan notable y duro triunfo, Amílcar consigue una enorme popularidad, y a pesar de los recelos de sus adversarios en el Senado Cartaginés, consigue el puesto de comandante en jefe del ejército, convirtiéndose prácticamente en el auténtico dueño y señor de Cartago. Ante la pérdida de Sicilia, Cerdeña y Córcega ante Roma, Amílcar pone sus ojos en Iberia, inhóspita tierra de extraordinaria riqueza, como base para expansión y también para compensar las pérdidas económicas y navales, comenzando así la reconstrucción de la potencia cartaginesa. Recluta y entrena un nuevo ejército, y tras pacificar Numidia y sellar el control púnico sobre el norte de África, decide lanzarse sobre Iberia (236 a. C.). Durante ocho años, consolida los cimientos de lo que sería la nueva potencia cartaginesa a partir de la riqueza de los nuevos territorios conquistados en Iberia, estableciendo alianzas diplomáticas con los pueblos nativos y sacando provecho de los ricos yacimientos mineros ibéricos y demás materias primas. Enriquece las tropas cartaginesas con los fieros soldados íberos y baleares, y consigue sofocar, en compañía de su yerno Asdrúbal el Bello, las numerosas y continuas rebeliones de los nativos no sumisos ante la expansión cartaginesa. 

En invierno de 229-228 a. C., en una escaramuza contra rebeldes oretanos capitaneados por el caudillo Orisón, acontece su prematura muerte en las cercanías de "Helike". La localización de Helike es conflictiva. Tradicionalmente, se ha venido especulando con Elche de la Sierra (Albacete), Elche (Alicante), e incluso Belchite (Zaragoza). Otras interpretaciones modernas, se limitan a ubicarla en alguna ciudad oretana, sin concretar más, dadas las contradicciones en las fuentes históricas, que tantas polémicas han generado a lo largo de los años.

Amilcar sería sucedido en el mando por su yerno, Asdrúbal el Bello.

Amílcar es, sin lugar a dudas, un personaje relevante, clave en la historia de su nación y también en la de sus enemigos, espejo en el cual se miraron sus “cachorros de león” –como a él le gustaba llamar a sus hijos-, especialmente su hijo mayor, el más célebre de los púnicos y para muchos, el más grande general de todos los tiempos: Aníbal.





</doc>
<doc id="42196" url="https://es.wikipedia.org/wiki?curid=42196" title="Lodz">
Lodz

Lodz (; ) es la capital del voivodato homónimo y la tercera ciudad más poblada de Polonia, con 687 702 habitantes (2018). Está situada en el centro del país, 121 km al suroeste de Varsovia. El escudo de la ciudad es un ejemplo de armas parlantes, ya que representa un barco ("łódź"), que alude al nombre de la ciudad.

Lodz fue una vez un pequeño asentamiento que apareció por primera vez en registros escritos alrededor de 1332. A principios del siglo XV se le concedieron los derechos de ciudad, pero seguía siendo una ciudad modesta. Fue propiedad de obispos y clérigos kuyavianos hasta finales del siglo XVIII, cuando Prusia anexó Lodz como resultado de la segunda partición de Polonia. Tras el colapso del ducado independiente de Varsovia, la ciudad se convirtió en parte del Congreso de Polonia, un estado cliente del Imperio ruso. Fue entonces cuando Lodz experimentó un rápido crecimiento en la industria textil y en la población debido a la afluencia de migrantes, sobre todo alemanes y judíos. Desde la industrialización del área, la ciudad ha luchado con muchas dificultades, como el multinacionalismo y la desigualdad social, que se documentaron vívidamente en la novela "La tierra prometida" escrita por el autor polaco ganador del Premio Nobel Władysław Reymont. Los contrastes se reflejaron en gran medida en la arquitectura de la ciudad, donde coexistían lujosas mansiones con fábricas de ladrillos y antiguas casas de vecindad.

Después de que Polonia recuperó su independencia en 1918, Lodz se convirtió en una de las ciudades más grandes de Polonia y en uno de los centros más multiculturales e industriales de Europa. El período de entreguerras vio un rápido desarrollo en la educación y la salud. Después de la invasión de Polonia en 1939, el ejército alemán capturó la ciudad y le cambió el nombre a Litzmannstadt en honor al general alemán Karl Litzmann, quien salió victorioso cerca del área durante la Primera Guerra Mundial. La gran población judía de la ciudad se vio obligada a ingresar a una zona amurallada conocida como el Gueto de Lodz, desde el cual fueron enviados a los campos de concentración y exterminio alemanes. Tras la ocupación de la ciudad por parte del ejército soviético, Lodz, que sufrió daños insignificantes durante la guerra, se convirtió en parte de la recientemente establecida República Popular de Polonia.

Después de años de prosperidad durante la era socialista, Lodz experimentó un declive después de la caída del comunismo en Europa central y oriental; sin embargo, actualmente está experimentando la revitalización de su área del centro de la ciudad. La ciudad también es conocida internacionalmente por su Escuela Nacional de Cine, cuna de los actores y directores polacos más renombrados, incluidos Andrzej Wajda y Roman Polanski, y en 2017 se incorporó a la Red de Ciudades Creativas de la UNESCO y fue nombrada Ciudad de la Película de la UNESCO.

La ciudad de Lodz aparece por primera vez en registros escritos en un documento en el cual se hace entrega de la villa de "Łodzia" a los obispos de Włocławek en 1332. En 1423 el rey Ladislao II Jaguellón (en polaco: "Władysław II Jagiełło") otorgó el título de ciudad a Lodz. Desde entonces hasta el siglo XVIII Lodz fue un pequeño asentamiento situado en una ruta comercial entre Mazovia y Silesia. En el siglo XVI la ciudad tenía menos de 800 habitantes, la mayoría agricultores que trabajaban en granjas cercanas.

En 1793, debido a la segunda división de Polonia, Lodz pasó a formar parte de Prusia tomando el nombre pruso de "Lodsch". En 1806 se unió al Gran Ducado de Varsovia creado por Napoleón I, y en 1815 pasó a formar parte de Rusia.

En 1820 Stanisław Staszic promovió un movimiento para convertir lo que había sido hasta entonces un pequeño poblado en un moderno centro industrial. La llegada constante de trabajadores, hombres de negocios y artesanos desde todas partes de Europa hizo que Lodz se convirtiera en el principal centro de producción textil de todo el Imperio ruso. El primer molino para hilar algodón se construyó en 1825, y 14 años más tarde comenzó a operar la primera fábrica de toda Polonia y Rusia en funcionar con máquinas de vapor.

Los inmigrantes venían a la "Tierra prometida" (como se conocía a la ciudad o "Ziemia obiecana", en polaco) desde todas partes de Europa, principalmente de Sajonia y Bohemia, aunque también de países más alejados como Portugal, Inglaterra, Francia e Irlanda. Sin embargo, los tres pueblos predominantes que más contribuyeron al desarrollo de la ciudad fueron: polacos, germanos y judíos.

En 1850 Rusia abolió los aranceles en la aduana entre Rusia y Polonia (por entonces un régimen títere impuesto por Rusia), lo que dio un gran impulso al desarrollo industrial en Lodz y ayudó a la ciudad a convertirse en la segunda más grande de Polonia. En 1865 se inauguró el primer tramo de ferrocarril en Lodz (hasta Koluszki), perteneciente a la vía de ferrocarril que más tarde llegaría a unir Varsovia y Viena. Pronto la ciudad tuvo comunicación férrea con Varsovia y con Białystok. En el período 1823-1873 la población de la ciudad se doblaba cada diez años, lo que dio lugar a que en el periodo 1870-1890 se produjera el desarrollo industrial más intenso de la historia de la ciudad.

Lodz se convirtió pronto en un centro del movimiento socialista. En 1892 una gran huelga paralizó la mayoría de las fábricas de la ciudad. Durante la revolución rusa de 1905 murieron más de 300 a manos de la policía zarista. A pesar del ambiente de crisis precedente a la Primera Guerra Mundial, la ciudad creció constantemente hasta 1914. En ese año Lodz ya se había convertido en una de las ciudades industriales más densamente pobladas del mundo (13.280 habitantes por kilómetro cuadrado).

Durante parte de la Primera Guerra Mundial la ciudad estuvo bajo ocupación alemana. Con la batalla de Lodz, se inician las hostilidades el 11 de noviembre de 1914. Las tropas rusas toman la ciudad de Łódź pero la pierden el 6 de diciembre de 1914. 

En noviembre de 1918, al finalizar la guerra, se restableció la independencia de Polonia, la población local desarmó a las tropas alemanas y liberó la ciudad. Como consecuencia de la Primera Guerra Mundial, Lodz perdió aproximadamente el 40% de su población debido al reclutamiento de tropas, las epidemias y la emigración de la mayor parte de la población alemana.

En 1922 Lodz se convirtió en la capital del voivodato de Lodz. Sin embargo había cesado ya el rápido crecimiento de población acontecido en el siglo anterior. La gran depresión de los años 30 y la guerra de aduanas con Alemania acabó con el comercio de textil con los mercados del oeste; mientras que por otra parte la Revolución rusa de 1917 y la Guerra Civil Rusa (1918-1922) acabaron con el provechoso comercio con los territorios del este.
La ciudad se convirtió en escena de múltiples disturbios y protestas de trabajadores.
Por otro lado el 13 de septiembre de 1925 empezó a operar el aeropuerto de la ciudad, el aeropuerto de Lublinek. 


Durante la invasión alemana de Polonia de 1939 las fuerzas polacas del ejército de Lodz comandadas por el general Juliusz Rómmel defendieron la ciudad contra los primeros ataques alemanes. Sin embargo, la Wehrmacht capturó la ciudad el 8 de septiembre. La ciudad pasó a formar parte del Reich en noviembre de 1939 y se renombró como "Litzmannstadt" en honor al general Karl Litzmann, quien capturó la ciudad en la Primera Guerra Mundial. No obstante muchos habitantes de Lodz de ascendencia germana se negaron a ser ciudadanos alemanes y fueron deportados al Gobierno General. Pronto las autoridades nazis montaron el gueto de Lodz en la ciudad, con más de 200.000 judíos de todos los territorios cercanos. Sólo 900 personas habían sobrevivido cuando se cerró el gueto en agosto de 1944. En las cercanías de la ciudad surgieron diversos campos de concentración y campos de exterminio para los habitantes no judíos de la zona; entre ellos la infame prisión Radogoszcz y varios campos menores para gitanos y para niños polacos.

A principios de 1945, Lodz tenía menos de 300.000 habitantes. Sin embargo, tras la guerra, el número de habitantes comenzó a crecer debido a la inmigración desde Varsovia y desde los territorios anexionados por la Unión Soviética. Hasta 1948 fue la capital "de facto" de Polonia, ya que los hechos acontecidos durante y después de la sublevación de Varsovia habían destruido por completo la capital, por lo que el gobierno y la administración del país se trasladaron temporalmente a Lodz. Se planteó la posibilidad de trasladar la capital permanentemente, pero esta idea no ganó muchos apoyos, y en 1948 empezó la reconstrucción de Varsovia.

Después de la Segunda Guerra Mundial, bajo el régimen comunista polaco, muchos industriales perdieron sus fortunas cuando las autoridades nacionalizaron todas las compañías privadas. Otra vez, Lodz se convirtió en un importante centro industrial.

Después del periodo de transición económica sufrida por Polonia durante la década de los 90, la mayoría de las empresas volvieron a privatizarse. En aquella época la tasa de desempleo permanecía muy elevada (24%) debido al declive de la industria que conllevaba muchos problemas económicos y sociales. Al mismo tiempo quedaban pendientes las cuestiones residenciales. La mayoría de las viviendas provenían del siglo XIX y se encontraban en pésimo estado ya que el proyecto de su renovación había sido abandonado después de la Segunda Guerra Mundial. 
En la actualidad, en el marco del programa de gentrificación más amplio de Europa, la alcaldía de Lodz pretende reavivar las antiguas zonas industriales, creando el así llamado Nuevo Centro de la Ciudad. Desde el año 2010 cuando arrancó la iniciativa, se realizaron varios proyectos de renovación urbana. Entre ellos cabe mencionar la estación de trenes Łódź Fabryczna y el museo de ciencias EC1 que se encuentra en una antigua central termoeléctrica. 

Desde 1990 Łódź ha sufrido una reducción de población sin precedentes, pasando de 850.000 habitantes en 1990 a 776.300 en 2004. De seguir esta tendencia, en cinco años Lodz dejará de ser la segunda ciudad de Polonia en favor de Cracovia. Pese a ello, la ciudad tiene una tasa de desempleo relativamente baja y una economía en crecimiento. La caída de la población se atribuye a la proximidad a Varsovia, que experimenta un crecimiento más rápido.

El turismo de Lodz gravita hacia la calle Piotrkowska, que va de norte a sur durante algo más de cuatro kilómetros, lo que la convierte en la segunda calle comercial más larga del mundo, después de la calle Alcalá. Recientemente renovada, tiene muchos bellos edificios que se remontan al siglo XIX, en el estilo arquitectónico de la Secesión vienesa. Resulta agradable visitar los bares de la calle Piotrkowska de fines de la primavera a principios del otoño.

Łódź no tiene colinas ni grandes extensiones de agua (a pesar de que Lodz significa barca en polaco), pero aún es posible mantener el contacto con la naturaleza en uno de sus parques, por notablemente Łagiewniki (el parque urbano más grande de Europa), Zdrowie y Poniatowski. El Zoo y el Jardín Botánico de Lodz también ofrecen agradables oportunidades de disfrutar del 
ocio.

Antes de 1990, la economía de Lodz se basaba en la industria textil, desarrollada en el siglo XIX gracias a la favorable composición química del agua local. Como resultado, Lodz creció de una población de 13.000 habitantes en 1840 a más de 500.000 en 1913. En vísperas de la Primera Guerra Mundial, Lodz era ya una de las ciudades industriales más densamente pobladas del mundo, con 13.280 personas por km². La industria textil declinó drásticamente en 1990 y 1991, y actualmente Lodz no cuenta con ninguna empresa importante en ese sector. Pese a ello, hay aún muchas pequeñas empresas textiles, la mayoría de las cuales exportan su producción a Rusia y otros países de la antigua Unión Soviética.

La ciudad se beneficia de su ubicación en el centro de Polonia. Varias firmas tienen centros logísticos en sus inmediaciones. Dos autopistas en proyecto, A1 del norte al sur del país, y A2, de este a oeste, se cruzarán al noreste de la ciudad. Cuando se completen, en torno a 2010, potenciarán el emplazamiento de la ciudad. También se ha empezado a modernizar la conexión ferroviaria con Varsovia, que actualmente es completamente inadecuada, requiriendo casi 2 horas para cubrir los 137 km que las separan. En los próximos años gran parte de la vía se modificará para aceptar trenes a velocidades de 160 km/h, lo que reducirá la duración del viaje a unos 75 minutos. Más adelante, una auténtica línea de alta velocidad unirá ambas ciudades. Cuando esto ocurra, Lodz y Varsovia tendrán posibilidades de convertirse en una área metropolitana.

Lodz alberga actualmente tres grandes universidades públicas y varios centros de enseñanza superior más pequeños. Los centros superiores con mayor número de estudiantes de Lodz incluyen:

Lodz tiene 5 distritos, cada uno con su propia alcaldía de distrito: 


Las ciudades vecinas más importantes son Pabianice y Zgierz.

El deporte más popular en Lodz es el fútbol, representado por el Widzew Łódź y el ŁKS Łódź. Otros equipos de la ciudad son el Budowlani Łódź (rugby), "Klub Żużlowy Orzeł Łódź" (equipo de speedway) y el KS Społem Łódź (ciclismo en ruta). El "Łódzkie Sportowe Towarzystwo Waterpolowe", actual campeón de la Liga de Polonia de waterpolo masculino y con más de diez títulos cosechados, también tiene su sede en Lodz.




</doc>
<doc id="42197" url="https://es.wikipedia.org/wiki?curid=42197" title="Idioma polaco">
Idioma polaco

El idioma polaco ("polski") es una lengua eslava del grupo occidental hablado principalmente en Polonia. Se escribe con el alfabeto latino, con gran uso de dígrafos y signos diacríticos extras.

El polaco se habla principalmente en Polonia, pero los emigrantes han llevado el idioma consigo, por lo que hay un número significativo de polacoparlantes en Alemania, Argentina, Australia, Austria, Bélgica, Brasil, Canadá, la República Checa, Chile, Colombia, Costa Rica, Ecuador, Eslovaquia, España, Estados Unidos, Francia, Grecia, Hungría, Irlanda, Israel, Kazajistán, Letonia, México, Países Bajos, Paraguay, Reino Unido, Rumanía, Rusia, República de Sudáfrica, Suecia, Uruguay y Venezuela.

Además, todavía existen minorías polacoparlantes en las tierras anexionadas por la Unión Soviética después de la Segunda Guerra Mundial: Bielorrusia, Lituania y Ucrania.

El polaco es idioma oficial de Polonia, así como del condado de Vilna (Lituania).

El polaco tiene varios dialectos que corresponden básicamente a las antiguas divisiones tribales: los más significativos (en número de hablantes) son el de la Gran Polonia (en el noroeste), el de la Pequeña Polonia (sureste), el mazoviano (Mazovia y Mazuria ) y el silesio (Śląskie, Silesia). El mazoviano comparte algunas características con el kashubo, cuyos hablantes (entre 100 000 y más de 200 000) viven al oeste de Gdansk cerca del mar Báltico.

El polaco cuenta con seis vocales orales y dos nasales. Las vocales orales son: /i/ (escrito "i"), /ɨ/ (escrito "y"), /ɛ/ (escrito "e"), /a/ (escrito "a"), /ɔ/ (escrito "o") y /u/ (escrito "u" o "ó"). Las vocales nasales son: /ɛ̃/ (escrito "ę") y /ɔ̃/ (escrito "ą").

El sistema polaco de consonantes es complejo: entre sus características más relevantes se incluyen las series de consonantes africadas y palatales resultantes de cuatro palatalizaciones protoeslávicas y dos palatización posteriores que tuvieron lugar en el polaco y el bielorruso. Dicho conjunto de consonantes, junto con su escritura más común, puede presentarse como a continuación:
Respecto a las africadas, estas se distinguen de secuencias de oclusiva y fricativa, por ejemplo, "czy" de "trzy". Se presenta también la neutralización de los pares de consonantes sordas y sonoras en algunos ambientes, como en final de palabra por ensordecimiento y en determinadas secuencias consonánticas por asimilación. Las letras ź, dz, dź se pronuncian como ś, ts, ć al final de la palabra, respectivamente. Además el dígrafo rz y la letra ż se pronunciarán sz después de la t, la p y al final de palabra.

Por norma general, la gran mayoría de las palabras en polaco llevan el acento en la penúltima sílaba. Tan solo en palabras de origen extranjero, en ciertos tiempos verbales como las conjugaciones plurales del pasado y en el condicional, además de verbos en primera persona plural de tiempo pasado, deja de cumplirse esta regla.

Por ejemplo, en las palabras "uniwersytet", muzyka", poszliśmy, zrobiliśmy", el acento recae sobre la antepenúltima sílaba en el lenguaje literario, mientras que en el lenguaje hablado, el acento recae en la penúltima sílaba.

El alfabeto polaco se derivó del alfabeto latino mediante la modificación de caracteres por diacríticos. Este alfabeto fue uno de las tres formas principales de ortografía latina desarrollada para una lengua eslava, siendo las otras dos la checa y la croata. El casubio usa un sistema basado en la escritura polaca. La escritura polaca es mayormente fonémica, se da una correspondencia regular entre los grupos de caracteres y fonemas, con pocas excepciones.

Los diacríticos usados en el alfabeto polaco son la "kreska" (similar gráficamente al acento agudo) en las letras "ć, ń, ó, ś, ź" y atravesando la letra en "ł"; el punto o "kropka" en la letra ż, y el "ogonek" ("colita") en las letras "ą", "ę". Las letras "q", "v", "x" se usan en nombres y palabras extranjeras. En los últimos tiempos está de moda utilizar esos caracteres en la jerga juvenil, como por ejemplo en el restaurante varsoviano "Qchnia", es decir, "kuchnia" , que significa cocina.

En suma, el alfabeto polaco tiene 35 caracteres; 9 son vocálicos y 26 son consonánticos.

En polaco existen nueve vocales, de las cuales siete son simples y dos nasales. De las simples, cinco son las mismas que en español [a, e, i, o, u]; además la <"ó"> tiene una pronunciación diferente y ocupa su propio capítulo en el diccionario, aunque su pronunciación moderna es la misma que la de <u>, y la <"y"> que es considerada como vocal. Las vocales nasales son dos <"ą, ę">.

Las vocales nasales se marcan mediante un acento diacrítico conocido como "ogonek" (cuyo significado literal es "colita").

La "ę" final tiende a perder la nasalización; de este modo, "idę" (yo voy), teniendo que ser pronunciado "idèun" será comúnmente pronunciado "idèn" o incluso "idè". Además, si una [i] precede a dicha vocal nasal, ambas serán pronunciadas casi como un sonido, suavizando la consonante anterior, esto es, "imię" (nombre) será pronunciado "imièun", siendo la [m] suave, cercana a la [ñ].

Al contrario que en español, cuando dos vocales seguidas se encuentran en una palabra, son pronunciadas separadamente, en diferentes sílabas, p. ej. "Haiti" "Ha-i-ti".

Si dos vocales idénticas se encuentran, también serán pronunciadas por separado, p. ej. la palabra "zoo" se pronuncia "zo-o".

Por otro lado, cuando [i] se encuentra delante de otra vocal, marca la palatización o "ablandamiento" de la consonante anterior, p. ej. "pies" (perro).


La [ń] también se puede incluir en este apartado, puesto que es equivalente a la [ñ] del español.


Hay algunos grupos de consonantes que representan un solo sonido. Estos se explican a continuación, a excepción de [ni], que se explica cuando se tratan la [ń] y [ci, rz, si, zi], que son explicados cuando [ć,ż,ś,ź], respectivamente.

Además existen otros grupos de consonantes que se pronuncian simultáneamente, pero que corresponden a la unión de diversos sonidos simples o dobles. Estos son: "ck", "szcz" y "ść".

Coloquialmente, el fonema [ł] se pierde entre consonantes y a final de palabra después de una consonante, por ejemplo, el vocablo "jabłko" que significa "manzana" se pronuncia ['japkɔ].

El fonema [dż] es un dígrafo usado muy raramente, en especial en palabras tomadas de otros idiomas, así "dżez" significa jazz.

Abreviaturas

(*) También existen las formas plurales "jedni" (masculino personal) y "jedne" (masculino no personal, femenino y neutro) para sustantivos "plurale tantum" como «puerta» ("drzwi") o «pantalones» ("spodnie").

(**) Se utiliza "raz" («vez») para contar: «un, dos, tres» es "raz, dwa, trzy".


El polaco tiene un sistema de cinco géneros, neutro, femenino y tres géneros masculinos (personal, animado e inanimado), y dos números: singular y plural (aunque quedan algunos restos de un número dual). Existen siete casos, como en los demás idiomas eslavos (excepto macedonio y búlgaro) que son nominativo, genitivo, dativo, acusativo, instrumental, locativo y vocativo.

Los sustantivos, adjetivos y verbos son flexivos, y tanto la declinación de los sustantivos como la conjugación son difíciles de aprender debido a que tienen muchas reglas y excepciones. Todo verbo puede ser perfectivo o imperfectivo.

Los verbos tienen 4 conjugaciones diferentes. Para la primera conjugación sus terminaciones son en -ąć, -ść, -źć, -ować, -ywać/iwać si termina en "ch" como en el verbo enamorarse zakochiwać się, -awać, -nąć, -uć, -c, -ać(se puede confundir con la tercera conjugación, ya que sus terminaciones son iguales), por ejemplo el verbo dar dać, " "dam", "dasz", "da, damy, dacie","dadzą"" con el verbo; por ejemplo: el verbo enviar posłać (primera conjugación) ""poślę", "poślesz", pośle, poślemy, poślecie, "poślą"" y además también con otros verbos terminados en -ać de la primera conjugación. Por ejemplo, dziać się ""dzieję się, dziejesz się, dzieje się, dziejemy się, dziejecie się, dzieją się"", -eć (se puede confundir con la cuarta conjugación, ya que sus terminaciones son iguales) por ejemplo, el verbo desmayarse mdleć ""mdleję, mdlejesz, mdleje, mdlejemy, mdlejecie, mdleją"" (primera conjugación) con el verbo entender rozumieć,"rozumiem, rozumiesz, rozumie, rozumiemy, rozumiecie, rozumieją"" (cuarta conjugación) y las terminaciones -ić e -yć también pueden ser confundidas con las terminaciones de la segunda conjugación. Por ejemplo, en bić (golpear) de la primera conjugación ""biję", "bijesz, bije, bijemy, bijecie, biją"" con el verbo lubić (gustar) de la segunda conjugación ""lubię", "lubisz", "lubi, lubimy, lubicie, lubią"".

Para la segunda conjugación, sus terminaciones son en -ić y en -yć.

Para la tercera conjugación, es en -ać excepto por mieć (tener o tener que).

Para la cuarta y última conjugación es en -eć. 

Los verbos suelen venir en parejas, en las que uno es imperfectivo y el otro perfectivo (que suele ser el imperfectivo con un prefijo), pero también hay una gran cantidad de verbos perfectivos con diferentes prefijos para un solo verbo imperfectivo.

Estos son los tiempos verbales:

El sufijo se le coloca al verbo en la parte de la frase que lleva el énfasis. A veces la pregunta se puede enfatizar con la partícula "-że". Así que '¿qué habéis hecho?' se puede escribir así:
Todas estas formas se emplean sin un sujeto - "wy" 'vosotros'. Claro que se puede emplear el sujeto, pero solo suena bien en la primera oración, ya que en las otras dos lo que se enfatiza es el verbo, así que el sujeto no es tan importante:

El tiempo pasado del verbo depende del número y del género, así que la tercera persona singular del pretérito perfecto simple es:

Los casos de la declinación son: nominativo, acusativo, dativo, instrumental, vocativo, genitivo y locativo.

Tomado del (en inglés).

En el idioma polaco, el orden básico de las palabras en la oración es del tipo SVO (sujeto-verbo-objeto), si bien, dado que es una lengua flexiva, tal orden no es fundamental. La conjugación del verbo permite la omisión del sujeto y, de igual modo, el complemento también puede desaparecer si es evidente por el contexto. Las siguientes frases significan lo mismo ("Michell tiene un gato"):

Sin embargo, solo la primera oración suena natural en polaco. Las demás, si se usan, deben utilizarse solo para enfatizar algún elemento de la oración.

Siempre que se pueda averiguar por el contexto, el sujeto, el complemento o incluso el verbo pueden omitirse:

En polaco, existe la tendencia a omitir el sujeto y no el complemento. Es raro que se omita el complemento y no el sujeto. Si la pregunta fuera "Kto ma kota?" (¿quién tiene un gato?), la respuesta debe ser "Michell" tal cual, sin verbo.

En particular, "ja" (yo) y "ty" (tú), así como sus plurales "my" (nosotros/as) y "wy" (vosotros/as), se omiten casi siempre. Esto es algo que ocurre con una frecuencia similar en español debido a que ambas lenguas contienen esa información en sus respectivas conjugaciones verbales.





</doc>
