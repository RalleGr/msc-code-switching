<doc id="27893" url="https://es.wikipedia.org/wiki?curid=27893" title="Historia de Cataluña">
Historia de Cataluña

Cataluña es un territorio situado en el noreste de la península ibérica formado inicialmente a partir de los condados que formaban la Marca Hispánica del Imperio carolingio y cuya extensión y unidad fue completándose a lo largo de la Edad Media. Tras la unión dinástica del condado de Barcelona y el Reino de Aragón en el siglo XII, los territorios catalanes se constituyeron en parte integrante de la Corona de Aragón, alcanzando una notable preponderancia marítima y comercial a finales del período medieval. Actualmente, la palabra Cataluña se emplea habitualmente para referirse a la comunidad autónoma del mismo nombre situada en España, mientras que tanto instituciones culturales, tales como el Instituto de Estudios Catalanes y la Universidad de Perpiñán, como medios de comunicación catalanes, hablan de Cataluña Norte para hacer referencia al Rosellón, la región integrada en el Departamento de los Pirineos Orientales de Francia.

Los primeros pobladores del territorio que actualmente ocupa Cataluña se remontan a los inicios del Paleolítico Medio. Los restos más antiguos descubiertos corresponden a la mandíbula de un individuo del género Homo (especie incierta) encontrada en Bañolas, de unos 66.000 ± 7.000 años de antigüedad.

Entre los yacimientos más importantes de este periodo destacan el de las cuevas de Mollet (Serinyà, Pla de l'Estany), el Cau del Duc, en el macizo del Montgrí, el yacimiento de Forn d’en Sugranyes (Reus) y los abrigos Romaní i Agut (Capellades), mientras que para el Paleolítico Superior destacan los de Reclau Viver, la cueva de la Arbereda y la Bora Gran d’en Carreres, en Serinyà, o el Cau de les Goges, en Sant Julià de Ramis.

De la siguiente etapa prehistórica, el Epipaleolítico o Mesolítico, se han conservado importantes yacimientos, la mayor parte datados entre el 8000 y el 5000 a. C., como el de Sant Gregori (Falset) y el Filador (Margalef de Montsant) y, en lo que respecta a las manifestaciones artístico-creenciales, Arte levantino, el Cogul, Cabra Feixet (el Perelló) y Ulldecona.

El período Neolítico se inicia en tierras catalanas hacia el 4500 a. C., aunque en un grado de sedentarización de los pobladores mucho menor que en otros lugares, gracias a la abundancia de bosques, lo que propició que la caza y la recolección siguieran siendo actividades fundamentales y que el establecimiento de asentamientos se demorase en muchos lugares. Los yacimientos neolíticos más importantes de Cataluña son la cueva de Fontmajor (l'Espluga de Francolí), la cueva de Toll (Moià), las cuevas Gran i Freda de Montserrat y los abrigos con arte esquemático del Cogul, Os de Balaguer, Albi, Tivissa y Alfara de Carles.

El período Calcolítico o Eneolítico se desarrolla en Cataluña entre el 2500 y el 1800 a. C., momento en el cual se construyen los primeros objetos de cobre.

La Edad del Bronce se sitúa cronológicamente en el período 1800-700 a. C., de la cual se conservan escasos restos, pero destacan unos poblados formados en la zona del Bajo Segre.
La Edad del Bronce coincide con la llegada de los pueblos indoeuropeos, a través de sucesivos flujos migratorios que se desarrollan desde el año 1200 a. C., responsables de la creación de los primeros poblados de estructura protourbana.

A partir de mediados del siglo VII a. C. el territorio catalán alcanza el período conocido como Edad del Hierro.

Este periodo se caracteriza, en una primera etapa, por la confluencia de diferentes culturas colonizadoras en el actual territorio catalán, en particular la griega y la cartaginesa, que darán lugar a la formación, como en el resto de la península, de la cultura ibérica.

De esta etapa es la formación de Emporion, en la costa gerundense, enclave comercial impulsado por la ciudad griega de Focea desde Massalia (actual Marsella), en el siglo VI a. C.

En lo que se refiere a la civilización ibérica, se ha constatado la existencia de diferentes tribus dispersas por tierras catalanas, entre ellos los indigetes (en el Ampurdán), los ceretanos (en la Cerdaña) o los airenosinos (en el Valle de Arán).

Se distinguen cuatro grandes periodos en el actual territorio de Cataluña.
El inicial, que abarca del siglo VIII al VII a. C., que corresponde a una etapa de formación, en que los pueblos indígenas entran en contacto con pueblos colonizadores, y en el que aparecen los primeros objetos de hierro.
El segundo es el periodo antiguo, del siglo VII a. C. a mediados del V a. C., en el que se consolida el proceso de iberización.
Le sigue un período de plenitud, que va de mediados del siglo V hasta el siglo III a. C.
Y, finalmente, la fase de decadencia, que se inicia en el 218 a. C. con la presencia de Roma, en que la cultura ibérica es absorbida por el potente impulso de la romanización.

La segunda etapa de la historia antigua de Cataluña corresponde al período de romanización, iniciado en el siglo III a. C. La llegada de los romanos a la península ibérica tuvo lugar en el 218 a. C., con el desembarco de Cneo Cornelio Escipión en Emporion, la actual Ampurias, con el objetivo de cortar las fuentes de aprovisionamiento de los ejércitos del general cartaginés Aníbal durante la segunda guerra púnica. La principal base de operaciones de los romanos durante la guerra, y primer núcleo de romanización en la península fue la ciudad de Tarraco, actual Tarragona.

Tras la derrota de los cartagineses y de diferentes tribus ibéricas sublevadas ante la presencia romana, en el 195 a. C., se completó prácticamente la conquista romana en territorio catalán y se inició el proceso de romanización, a través de la cual los distintos pueblos peninsulares fueron asimilados por la cultura romana y abandonaron sus propios rasgos.

El actual territorio catalán quedó englobado primero en la provincia llamada Hispania Citerior, para formar parte desde el 27 a. C. de la Tarraconense, cuya capital fue Tarraco. Una provincia que abarcaba unas dos terceras partes de la península ibérica, y comprendía las regiones al norte y al sur del Ebro, desde los Pirineos al norte hasta Sagunto al sur, el valle de Duero, excepto la zona de su orilla meridional entre el Tormes y su desembocadura en Cale (Oporto, Portugal), los valles del Tajo y del Guadiana hasta los límites con la Lusitania, y el extremo oriental de Andalucía, al este de la frontera de la Baetica que discurría desde Cástulo (Linares), pasando por Acci (Guadix) hasta La Bahía de Almería, quedando estas zonas (que durante varios años pertenecieron a la Baetica) en territorio tarraconense; al este limitaba con el mare Nostrum –mar Mediterráneo–, y al oeste con el océano Atlántico y al norte con el Cantábrico y la cordillera de los Pirineos, que la separaba del sur de la Galia, es decir, de las provincias romanas de Aquitania y Galia Narbonense.

Producto del periodo romano será la adopción de toda la estructura administrativa y las instituciones propiamente romanas, el desarrollo de una gran red urbana y viaria, la generalización de un sistema agrícola basado en la trilogía mediterránea (cereales, viña y olivo), la introducción de los regadíos, el desarrollo del derecho romano y la adopción del latín.

La crisis del siglo III que afectó al Imperio romano y que originaría su decadencia afectó gravemente al actual territorio catalán, donde se han detectado importantes niveles de destrucción y procesos de abandono de villas romanas. También de este siglo son las primeras noticias documentales de la presencia del cristianismo en Cataluña. Aunque los datos arqueológicos indican la recuperación de algunos núcleos, como Barcino (Barcelona), Tarraco (Tarragona) o Gerunda (Gerona), la situación no volvió a ser la de antes, las ciudades se amurallaron y los núcleos se redujeron.
En el siglo V, se produce la invasión generalizada del Imperio romano por parte de los pueblos germánicos. El pueblo germano de los visigodos que había obtenido permiso para entrar en el Imperio y colaborar en la defensa de los limes en la actual Bulgaria como aliados romanos; fueron liderados por Ataúlfo tras la situación de marginación dentro de la sociedad romana y de extrema pobreza de este grupo étnico. Ataúlfo fue un visigodo y general romano que llegó al máximo escalafón militar dentro del ejército romano, y que lideró la rebelión visigoda, llegando a Italia y a Roma, venciendo o esquivando a las legiones romanas, y llegando a conquistar a la hasta entonces invicta ciudad de Roma (2º saqueo). Como acuerdo entre los romanos y los visigodos y para que estos volvieran a aceptar el orden romano, sus leyes, dejaran de saquear Italia, y volvieran a ser fieles aliados, se les entrega Hispania, y parte de Francia. Los visigodos llegan a la península ibérica por la principal vía romana, instalándose en la ciudad Tarraconense en (410). Y cuando en el 475 el rey visigodo Eurico formó el reino de Tolosa, incorporó el actual territorio catalán, con gobierno primero desde Tolosa y luego desde Toledo.

Los visigodos dominaron el territorio hasta inicios del siglo VIII, cuando en mitad de una guerra civil por la sucesión del reino (que entonces ya abarcaba toda la península ibérica), una de las partes llama a la potencia emergente, el Imperio Omeya, en busca de ayuda y para que decidiera la guerra a su favor. Los musulmanes ya ocupaban todo el norte de África y su imperio se extendía hasta la India. Después de derrotar a las tropas fieles al rey visigodo, Roderic (don Rodrigo), en la batalla de Guadalete y con apoyo de los visigodos rebeldes que aspiraban al poder conquistan rápidamente la península, encontrando sólo una resistencia marginal en las zonas montañosas del norte. La conquista relámpago musulmana se basó en un ejército de 30.000 hombres (los romanos habían tenido un ejército de 50.000 para la defensa del Imperio de Occidente y otros 50.000 para la defensa del Imperio de Oriente); en unos soldados altamente motivados; en las tácticas de caballería ligera que tan bien funcionaron en terrenos abiertos; en la debilidad de un reino dividido en mitad de una guerra civil sucesoria; en el desinterés de una población hispanorromana dominada por una minoría aristocrática visigoda que no había conseguido integrarles en el reino (la integración entre visigodos y población local no se produjo hasta épocas posteriores); en el mandato religioso del cristianismo en contra de la guerra (que no cambió hasta finales del siglo XI con el encumbramiento de la clase caballeresca, aprox. 1075, y las cruzadas desde 1100); en el miedo a las represalias acompañado de la tolerancia de los musulmanes con los que se sometían sin resistencia; en las facilidades concedidas a las clases dominantes para mantener el poder si cambiaban de bando; en la tolerancia religiosa mediante el simple pago de un impuesto por parte de los no musulmanes; y, sólo en algunos casos, la entrega de tierras a los nuevos conquistadores (las mejores para los árabes y yemeníes, las peores para los bereberes).
En el 718, la conquista musulmana de la península ibérica llegó al noreste de la península y pasó a la Septimania visigoda, un proceso que tuvo lugar sin graves conflictos bélicos, excepto algunos focos de resistencia aislados como el de Tarragona. El poder musulmán se extendía por la Galia ya desde 719, Narbona, Carcasona, hasta Tolosa, e incluso Burdeos, en una continuada expansión hasta centro-Europa. La posterior reacción carolingia liderada por Carlos Martel, duque de Eudes, con su poderoso ejército de caballería pesada (con cotas de malla), puso freno a la expansión musulmana por Europa en la batalla de Toulouse en 721, y los hizo retroceder a raíz de la batalla de Poitiers en el 732, llegando a liberar Narbona en 759 por Pipino el Breve.

La reacción continuó con el proceso de crear una marca defensiva que sirviese de frontera meridional para el Imperio carolingio. Esto supuso la ocupación por los francos durante el último cuarto del siglo VIII de las actuales comarcas pirenaicas, de Gerona y, en el 801, de Barcelona, tras la cual se formó una región fronteriza que seguía aproximadamente el curso de los ríos Llobregat, Cardener y el curso medio del Segre. Los dominios del Imperio carolingio delimitados por esta área fronteriza con Al-Ándalus y los Pirineos serían conocidos con el nombre de Marca Hispánica, aunque a diferencia de otras marcas carolingias nunca se constituyó formalmente como tal. Este territorio se organizó políticamente en diferentes condados dependientes del rey franco.

A finales del siglo IX, el monarca carolingio Carlos el Calvo designó a Wifredo el Velloso, un noble descendiente de una familia del Conflent, conde de Cerdaña y Urgel (870), y conde de Barcelona y Gerona (878), lo cual suponía la reunión bajo su mando de buena parte del territorio de la Marca Hispánica. Wifredo fue el primer conde en transmitir el gobierno de sus territorios directamente a sus descendientes, debido a la crisis en que estaba sumido el Imperio y al consiguiente aumento de poder de los gobernantes locales en los territorios fronterizos. Aunque a su muerte Wifredo repartió sus condados entre sus hijos, se mantuvo la unidad entre Barcelona, Gerona y Osona, excepto durante un breve periodo. Se atribuye a la política de Wifredo la repoblación de Osona, así como la fundación de los monasterios de Ripoll y San Juan de las Abadesas, y la restauración de la sede episcopal de Vich.

Durante el siglo X, los condados se convirtieron en verdaderos condados independientes del poder carolingio, según el poder central del Imperio se debilitaba, y las guerras civiles, de sucesión, hacían su trabajo de desgaste, un hecho que el conde Borrell II oficializó en el 987 al no prestar juramento al primer monarca de la dinastía de los Capeto. En estos años de formación de los condados, se desarrollaron los primeros pasos de repoblación del territorio tras la invasión musulmana, trayendo grandes contingentes de población de los territorios dentro del Imperio carolingio que eran dominios poseídos por los Condes de Barcelona como súbditos del Imperio, la repoblación se hizo principalmente con población del sur de Francia (las diferencias con la población actual del sur de Francia vienen a raíz de la aniquilación de esta población en las guerras contra la herejía de los cátaros, y la repoblación con habitantes del norte de Francia). Así, durante los siglos IX y X se creó una sociedad donde predominaban pequeños propietarios libres, llamados "aloers", enmarcados en una sociedad agraria donde cada núcleo familiar producía lo que consumía, generando muy pocos excedentes, y típica de la Edad Media.

El siglo XI se caracteriza en Cataluña por el desarrollo de la sociedad feudal, como consecuencia de las presiones señoriales para desarrollar lazos de vasallaje con los campesinos libres (alodiales, en catalán "aloers"). Los años centrales del siglo se caracterizaron por una guerra social virulenta, donde la violencia señorial arrolló a los campesinos, gracias a las ventajas que obtenían de las nuevas tácticas militares, la caballería pesada, y basadas en la contratación de mercenarios bien armados y a caballo.

Así, a finales del siglo, la mayoría de los campesinos propietarios se habían convertido en siervos sometidos al señor. Este proceso coincidió con un debilitamiento del poder de los condes y la división del territorio en numerosos señoríos, que con el paso del tiempo, daría lugar a la articulación de un Estado feudal basado en complejas fidelidades y dependencias, en lo alto del cual se encontraría el conde de Barcelona, tras el triunfo sobre el resto de señores de Ramón Berenguer I. Con el tiempo, los condes de Barcelona vincularían a todos los demás condados catalanes con el condado que posteriormente pasaría a formar parte de la Corona de Aragón.

Es también en este periodo, durante el siglo XI, cuando se consolidan la Taifa de Tortosa y la Taifa de Larida.

Hasta mediados del siglo XII, los sucesivos intentaron ampliar sus territorios en múltiples direcciones y por diversos medios. Ramón Berenguer III (1082-1131) incorporó mediante alianza matrimonial el condado de Besalú (1111), recibió por herencia el de Cerdaña (1117 o 1118), y conquistó por la fuerza parte del condado de Ampurias (entre 1123 y 1131). Más allá de los Pirineos, también controló el de Provenza (desde 1112), que al morir legó a su segundo hijo Berenguer Ramón. Por su parte, en 1118 la Iglesia catalana se independizó de la sede de Narbona y fue restaurada la sede de Tarragona.

Bajo el gobierno del conde Ramón Berenguer IV (1131-1162), se produjeron diferentes hechos fundamentales para la historia de Cataluña. El primero, su boda con Petronila de Aragón, lo que supuso la unión dinástica, del condado de Barcelona y del Reino de Aragón, por lo que con el tiempo el territorio común sería denominado Corona de Aragón. Como consecuencia de tal tipo de unión, los reinos, Estados, dominios o títulos así unidos no fueron integrados o fusionados, sino que las mismas personas poseían cada uno de ellos en forma independiente; y, por lo general los dominios del título mantenían sus propias instituciones y legislación (particularismo). Según lo acordado en las Capitulaciones matrimoniales de Barbastro en agosto de 1137, Ramón Berenguer pasó a ser el "princeps" o dominador de Aragón, ya que el rey aragonés Ramiro le hizo donación de su hija y de su reino para que la tuviera a ella y al reino en dominio «salva la fidelidad a mí y a mi hija» "(«dono tibi, Raimundo, barchinonensium comes et marchio, filiam meam in uxorem, cum tocius regni aragonensis integritate [...] salva fidelitate mihi et filie mee.»)", y se retiró a la vida monástica. Según estas capitulaciones, Ramiro no cedía su dignidad real, esto es, que en adelante sería rey, señor y padre de Ramón Berenguer tanto en Aragón como en todos sus condados. Sin embargo, en noviembre del mismo año, 1137, Ramiro renunciaba a todo lo que se había reservado en las Capitulaciones de Barbastro, 

La unión en la Corona de Aragón, del condado de Barcelona y el reino de Aragón no fue, pues, el fruto de una fusión ni de una conquista, sino el resultado de una unión dinástica pactada. De hecho, los territorios que compusieron la Corona mantuvieron por separado sus propias leyes, costumbres e instituciones, y los monarcas reinantes tuvieron que respetar estas bases.

A nivel dinástico, existen diversas explicaciones en la historiografía actual sobre la continuidad de las casas gobernantes en la Corona unida. Así, algunos historiadores, como Ubieto o Montaner, creen que se produjo un prohijamiento por el cual Ramón Berenguer pasaba a ser un miembro más de la Casa de Aragón. En cambio, José Luis Villacañas o Vicente Salas Merino, entre otros autores, consideran que la dinastía reinante entre 1162 y 1412 fue la Casa de Barcelona.

En lo sucesivo, Ramón Berenguer IV materializó las nuevas conquistas políticamente diferenciadas asignadas a título personal como marquesados. Conquistó Tortosa y Amposta en 1148, y Lérida en 1149 gracias a una ofensiva conjunta con el conde Ermengol VI de Urgel. Estos territorios fueron repoblados a lo largo del siglo XII y suelen recibir el nombre genérico de Cataluña Nueva, para distinguirlos de los antiguos condados carolingios que conformaban el área oriental de la Marca Hispánica, denominados Cataluña Vieja. La línea de separación entre ambas áreas geográficas suele establecerse en la línea delimitada por los ríos Llobregat, su afluente el Cardener, y el Segre.

A finales del siglo XII, diferentes pactos con el Reino de Castilla delimitaron las futuras zonas donde desarrollar nuevas conquistas de territorio musulmán, pero en 1213, la derrota de Pedro II el Católico en la batalla de Muret acabó con el proyecto de consolidación del poder de la Corona sobre Occitania. Tras un periodo de agitación, en 1227, Jaime I el Conquistador asumió plenamente el poder como heredero al trono de la Corona de Aragón y se inició la expansión territorial sobre nuevos territorios.
En su reunión de 1188, la asamblea de Paz y Tregua, germen de las Cortes catalanas, había establecido los límites de lo que a partir de mediados del siglo XIV se conocerá como Principado de Cataluña, y que se definirá como el territorio sometido a la jurisdicción de dichas Cortes. En dicha asamblea se estableció su ámbito jurisdiccional «desde Salses a Tortosa y Lérida y sus ríos» (Constitución XVIII). No obstante, tanto la frontera occidental como la meridional tuvieron una definición incierta durante décadas. Así, delegados de las tierras de Lérida y Fraga acudieron a las Cortes de Aragón convocadas por Jaime I en Daroca en 1228. En 1244, en cambio, Jaime I fijó la frontera en el río Cinca, situando en el ámbito catalán territorios anteriormente adscritos a Aragón como la Ribagorza, La Litera y el valle de Arán. En cuanto al límite meridional, fue quedando establecido en el curso inferior del río Ebro, entre la desembocadura del Segre y el mar.
A lo largo del segundo cuarto del siglo XIII se incorporan a la corona las Islas Baleares y Valencia. Este último territorio, el Reino de Valencia, pasó a convertirse en uno de los reinos de la Corona de Aragón, con Cortes propias y unos nuevos fueros: los "Furs de València". En cambio, el territorio mallorquín, junto a los condados de Rosellón y Cerdaña, la ciudad de Montpellier y los señoríos de Omeladés y Carladés, sería entregado en herencia su segundo hijo, Jaime, y formarían el Reino de Mallorca, iniciándose así un periodo de tensión interna que concluiría con su anexión a la Corona de Aragón en 1343, por parte de Pedro IV el Ceremonioso. En 1258, 29 años después de la conquista del Reino de Mallorca y 20 después de la del Reino de Valencia se firma el Tratado de Corbeil en el que el Rey Luis IX de Francia renuncia a sus derechos sobre los condados catalanes pasando a formar parte de la Corona de Aragón y Jaime I a la mayor parte de los condados del norte de los Pirineos.

Entre las décadas finales del siglo XIII y las primeras del XIV, los condados catalanes vivieron épocas de gran plenitud, en las que experimentó un fuerte crecimiento demográfico y una expansión marítima por el Mediterráneo. Esta época coincide con los reinados de Pedro III el Grande, que invadió Sicilia (1282) y tuvo que defenderse de una cruzada francesa contra Cataluña; de Alfonso III el Liberal, que se apoderó de Menorca, y de Jaime II, que invadió Cerdeña y con quien el poderío de la Corona alcanzó su máxima expansión económica en la Edad Media. Sin embargo, desde el segundo cuarto del siglo XIV se inició un cambio de signo para Cataluña, marcado por la sucesión de catástrofes naturales y crisis demográficas, el estancamiento y recesión de la economía catalana y el surgimiento de tensiones sociales.

Por su carácter limítrofe, la Ribagorza siguió siendo objeto de disputa entre catalanes y aragoneses durante el siglo XIII. En las Cortes reunidas en Zaragoza en 1300, el rey Jaime II aprobó que tanto Ribagorza como La Litera quedasen bajo jurisdicción aragonesa.

El reinado de Pedro IV el Ceremonioso (1336-1387) se caracterizó por graves tensiones bélicas, entre las que se cuentan la anexión del reino de Mallorca, el sofocamiento de una rebelión sarda, de la rebelión de los unionistas aragoneses y valencianos y, sobre todo, la guerra con Castilla. Estos episodios generaron una delicada situación financiera, en un marco de crisis demográfica y económica, pero también un poderoso desarrollo institucional y legislativo, en el que destaca la creación de la Diputación General de Cataluña o Generalidad de Cataluña (1365).

En 1375, una protesta de los representantes de Fraga ante las Cortes reunidas en Tamarite vuelve a desplazar el límite occidental de Cataluña, ya que esta ciudad vuelve a quedar bajo el fuero de Aragón.

La muerte sin descendencia y sin el nombramiento de sucesor del rey Martín I el Humano en 1410 abrió, además, una grave crisis sucesoria. Ello abrió un periodo de interregno en el que aparecieron diversos candidatos al trono. Los intereses comerciales, así como la animadversión que despertaba Jaime de Urgel, acabarían favoreciendo al candidato de la dinastía castellana de los Trastámara, Fernando de Antequera, quien, tras el llamado Compromiso de Caspe de 1412, fue nombrado monarca de la Corona de Aragón. Con la llegada de la Casa de Trastámara se comienza a introducir el idioma castellano en Cataluña.

El sucesor de Fernando I de Aragón, Alfonso V el Magnánimo, promovió una nueva etapa expansionista, esta vez sobre el Reino de Nápoles, el cual dominó finalmente en 1443. Paralelamente, se agravó la crisis social en Cataluña, tanto por los conflictos rurales como urbanos. El desenlace de estos conflictos fue, en 1462, la rebelión de los remensas, protagonizada por los campesinos frente a las presiones señoriales y la guerra civil catalana, que se extendería por un periodo de diez años, tras los cuales la región quedó exhausta, los conflictos remensas no quedaron resueltos y Francia retuvo hasta 1493 los condados de Rosellón y Cerdaña, que fueron ocupados durante el conflicto.

El matrimonio de Fernando II de Aragón con Isabel la Católica, reina de Castilla, celebrado en Valladolid en 1469, condujo a la Corona de Aragón a una unión dinástica con Castilla, efectiva a su muerte, en 1516, pero ambos reinos conservaron sus instituciones políticas y mantuvieron las cortes, las leyes, las administraciones públicas y la moneda propias. Sería Fernando II de Aragón, el Católico, quien, con la sentencia arbitral de Guadalupe resolvió el conflicto remensa en 1486, reformó en profundidad las instituciones catalanas, recuperó pacíficamente los condados catalanes del norte y amplió la actuación de la corona sobre Italia.

Ya desde los tiempos de los Reyes Católicos los catalanes participan directamente en las expediciones y campañas militares españolas. El almirante Cardona conquista Mers-el-Kebir (conocida tradicionalmente en las crónicas españolas como Mazalquivir) en 1505. Pere Bertran i de Margarit, ampurdanés, acompaña a Colón en su segundo viaje.

En el siglo XVI, la población catalana inició una recuperación demográfica y una cierta recuperación económica. El reinado de Carlos I fue para Cataluña una etapa de armonía en la nueva estructura que formaban ahora los reinos hispánicos. En 1521 nombró Virrey de Cataluña al Arzobispo de Tarragona, Don Pedro Folch de Cardona, uniendo Besalú, Vallespir, Peralada, Ausona (Osona), Ampurias, Urgel y Cerdanya al resto de condados, siendo gobernados juntos por primera vez como región histórica unificada.

Cuando llega Carlos I de España, un rey que permaneció poco tiempo en la península, toma como base de operaciones a Castilla, con una población de 6 millones (entre los reinos más poblados de Europa en la época), una pujante economía (Flandes, Portugal y el Norte de Italia eran las otras economías más desarrolladas del continente), y el descubrimiento de América por el reino de Castilla, y su nuevo ejército que gracias al Gran Capitán era el más poderoso de Europa, lo convertía en la fuente perfecta para sus ambiciones expansionistas e imperiales, siendo la base principal de impuestos y de reclutamiento de tropas. Mientras que Cataluña con sus 300 000 habitantes, se libraban de llevar esta pesada carga, en Castilla se producía la «revuelta de los comuneros» por los nuevos impuestos para pagar los ejércitos y los sobornos para los príncipes electores alemanes para ser nombrado Emperador del Sacro Imperio Romano Germánico, las mayores cantidades de oro pagadas hasta la época, así como porque la pequeña nobleza y la burguesía tenían las vistas puestas en la expansión ultramarina, y no en la expansión europea del nuevo rey, que había nacido y crecido en Flandes (actuales Holanda, Bélgica y parte de Francia). Esta revuelta fue aplastada por los tercios que volvieron de Italia, con el apoyo de la población de Navarra y Vascongadas (que recibieron los fueros del rey en agradecimiento por su apoyo), y con el apoyo de la gran nobleza, en contra de la pequeña nobleza y la burguesía de las ciudades. A largo plazo, las necesidades militares y los elevados impuestos, como la alcabala que debía ser pagado cada vez que se producía una operación comercial o de transporte (se suma en cada operación 10%+10+10+..., no como el IVA actual, que solo se paga en la venta final), llevaron al reino de Castilla a la quiebra. La ventaja de la Corona de Aragón al evitar el pago de estos elevados impuesto en favor del rey y para la defensa del reino (no se enviaban grandes números ni en tropas ni dinero), no evitaba tener elevados impuestos en la Corona de Aragón, aunque esta vez a favor de los nobles, y que temían perderlos en favor del rey.

El hecho de que el descubrimiento de América y que por tanto los derechos sobre ella estuvieran en el reino de Castilla, alejó a la Corona de Aragón de sus ventajas hasta la unificación con el reino de Castilla con la llegada de los Borbones en la guerra de Sucesión. Aunque el Reino de Aragón se había opuesto a una unificación con el reino de Castilla, puesto que la nobleza que integraba las cortes de Aragón suponían que esta sería una dilución de sus poderes, y tener que soportar la mayor carga impositiva que tenía el reino de Castilla.

Durante el reinado de Felipe II la Corona de Aragón continúa sin soportar el mantenimiento militar de los reinos. Ello se explica por la negativa de la Corona de Aragón a proveer de más tropas y fondos al rey y la defensa y expansión de sus dominios, así como por el paso del peso político y económico internacional del Mediterráneo al Atlántico, la debilidad del principado de Cataluña, siendo la preeminencia del Reino de Valencia en el espacio de la vieja confederación una cuestión de menor importancia.

El reinado de Felipe II marcaría, en cambio, el inicio de un proceso de deterioro, la crisis económica que comienza en Castilla en 1580 y los elevados impuestos que se atenazan sobre el reino vecino, llevando a este a una gran pérdida de población, llegando la meseta y salvo Madrid, a tener menos población en la actualidad que antes de 1580; la economía de Cataluña se resiente, pero se mantiene la unidad del reino. Entre los elementos más negativos de este periodo destacan la piratería berberisca sobre las zonas costeras y el bandolerismo en las zonas interiores. La nueva dinámica y las nuevas fidelidades que generaba originaron también un retroceso en la lengua y en la cultura catalanas, que iniciaron una etapa de decadencia, tras la pujanza de los siglos anteriores.

Durante el reinado de Felipe II, hubo catalanes, como Luis de Requesens que participaron activamente en la política exterior «las Españas» (o de los reinos españoles), tanto diplomáticamente como por el uso de las armas, como súbditos de la corona y del rey.

En 1600, y ya desde 1580 la crisis económica había minado a los reinos peninsulares unificados bajo un solo rey; el ejército, los tercios, seguían siendo una fuerza de élite, pero ya no disponían de la abrumadora superioridad tecnológica del siglo XVI, el norte de Flandes se había independizado y en América los reinos españoles mantenían la superioridad, pero sufrían el acoso de piratas y la expansión inglesa, francesa y holandesa. Mientras que en Asia se perdían factorías de puestos portugueses, con peor defensa posible que los americanos (con más población fiel a la corona y con fácil apoyo entre sus partes). En esta tesitura comienza en 1618 la guerra de los Treinta Años, y que llevaría a la Francia de Richelieu, y al francés como potencias Europeas de primer nivel, rompiendo la supremacía de las dos superpotencias hasta la época (el Imperio otomano y el Imperio español). Europa pasa al equilibrio entre potencias; y esto gracias a la habilidad en la política internacional de Richelieu, al dinero del Reino de Francia, a la división religiosa y al poderío militar del reino de Suecia, que imprimió la primera derrota en batalla campal a los tercios. En 1648, al final de la guerra de los Treinta Años, tras la paz de Westfalia, se abre un nuevo mundo de equilibrios de poder.

La crisis económica, los nuevos impuestos y las nuevas necesidades militares llevan a que se produzca un levantamiento popular en Cataluña. Las razones de fondo son de dos tipos, en primer lugar por las llamadas «causas antiguas» (reducción de los privilegios medievales de la nobleza desde la unión de Aragón y Castilla, no convocatoria y presidencia de las Cortes Catalanas, introducción de algunos de los impuestos que se pagaban en Castilla, y la introducción en Barcelona de la Inquisición nueva en sustitución de la vieja Inquisición que ya operaba desde la Edad Media, y que fue el modelo por el cual se implantó la Inquisición en Castilla en la época de los Reyes Católicos); y «causas nuevas» (la presencia en territorio catalán de tropas extranjeras a sueldo del rey, considerando como tales a castellanas y aragonesas necesarias para defender las fronteras contra Francia en la guerra, pero nunca deseables en tu territorio, y el desempeño de cargos públicos por personas no catalanas. Y en segundo lugar por la política centralizadora del Conde-duque de Olivares, que pretendía unificar los reinos de Aragón y Castilla, reorganizar y subir el pago de impuestos para mantener la guerra de los treinta años. Se pueden resumir los principales problemas en crisis económica, el malestar de la guerra, la presencia de tropas para proteger la frontera contra Francia, dadas a los abusos de los ejércitos de la época; y la petición de nuevos impuestos y levas para mantener el esfuerzo militar durante la guerra.

Durante la guerra existente entre Francia y España desde 1635, los franceses invadieron el Rosellón al mando de Condé y se apoderaron de la villa y la plaza de Salses. Los catalanes levantaron sus somatenes y formaron, con ayuda de soldados reales, un ejército de 25.000 a 30.000 soldados al mando del virrey Santa Coloma, que recuperó la plaza el 6 de enero de 1640, tras lo que Olivares pretendió llevar la guerra al interior de Francia y forzar la paz. Con esta intención se ordenó una leva forzosa de unos 5000 soldados catalanes, enervando aún más los ánimos, con lo que a mediados de marzo los conselleres (Pau Claris) y la Diputación empredieron negociaciones secretas con el Cardenal Richelieu, primer ministro de Francia, que fueron ratificadas a finales de mayo.

En 1640 comienza la revuelta de Independencia en Portugal con apoyo de Francia e Inglaterra. Un gran éxito para la diplomacia internacional francesa que abre un nuevo frente para las tropas del rey de España, que ya había visto como comenzaba una revuelta en Nápoles y Sicilia.

El 22 de mayo (1640) llegaron a Barcelona 3.000 campesinos del Vallés armados y encabezados por los obispos de Vich y Barcelona. De regreso al Ampurdán, asesinaron a los oficiales del rey refugiados en los conventos obligándoles a retroceder hacia el Rosellón cometiendo estos, actos de venganza en Calonge, Palafrugell, Rosas y otros pueblos.

El 6 de junio, que era la festividad de Corpus (día que posteriormente ha sido recordado con el nombre de Corpus de Sangre), los segadores entraron en la ciudad de Barcelona en busca de trabajo en la siega, siendo acompañados por rebeldes armados, cometiendo distintos saqueos y asesinatos, con una respuesta de los soldados del rey que apresan a un segador prófugo de la justicia por asesinato. La resistencia de los segadores contra la detención de su compañero, los disturbios y combates posteriores y los incidentes sangrientos dan origen a la guerra civil entre los catalanes realistas y los catalanes independentistas y que simpatizaban con el espíritu del levantamiento, aunque el levantamiento comenzó en un primer momento como una revuelta contra las tropas del rey, contra la nobleza y la burguesía, que sufrieron numerosos asaltos, saqueos y asesinatos a manos de los levantados en los primeros momentos.

El embajador francés, Du Plessis Besancon, se reunió en Barcelona con el presidente de la Generalidad, Pau Claris, con la intención de convertir a Cataluña en república independiente bajo la protección de Francia. Se alcanzó un acuerdo mediante la firma del tratado el 16 de diciembre de 1641 y Cataluña se sometió a la soberanía del rey Luis XIII de Francia.

A finales de 1642 murió Richelieu y, pocos meses después, el rey Luis XIII. Por su parte, Felipe IV prescindió del Conde-duque de Olivares. Todo ello marcó un cambio de tendencia en la guerra y, aunque las tropas francesas entraron en Cataluña como aliados de los catalanes, pronto fue evidente para éstos que los soldados franceses se comportaban de igual modo a como lo habían hecho los de Felipe IV.

Un año después fueron recuperadas Lérida y las comarcas leridanas, que no volvieron a caer en manos francesas.

En 1648 termina la guerra de los Treinta Años con la Paz de Westfalia, lo que deja libres a las tropas del rey para intervenir en la revuelta en Cataluña.

En 1649 los realistas avanzaron hasta casi Barcelona, donde el comportamiento de los franceses hizo inclinarse la balanza nuevamente a favor de Felipe IV produciéndose incluso varias conspiraciones en este sentido, siendo de destacar la protagonizada por doña Hipólita de Aragón, baronesa de Albi.

En 1651 don Juan José de Austria puso sitio a Barcelona recuperando en menos de un año Mataró, Canet, Calella, Blanes, San Feliu de Guíxols y Palamós. La Diputación general reconoció a Felipe IV, provocando la huida de Margarit (presidente de la Diputación tras la muerte de Clarís) y sus partidarios a Francia. La ciudad, en estado de peste después de un año de asedio, se rindió a don Juan de Austria el 11 de octubre de 1652, poco después, el 3 de enero de 1653, Felipe IV confirmó los fueros catalanes, con algunas reservas.

El fin de la guerra se saldó con la anexión del Rosellón, el Conflent, el Vallespir y parte de la Cerdaña a la corona francesa, anexión confirmada en el Tratado de los Pirineos (1659), aunque en la Cataluña transpirenaica francesa los fueros catalanes fueron derogados en 1660 y el uso del catalán poco después, incumpliendo el rey Luis XIV de Francia este tratado.

El Tratado de los Pirineos o Paz de los Pirineos fue firmado el 7 de noviembre de 1659 por parte de los representantes de Felipe IV de Castilla, Luis de Haro y Pedro Coloma, y los de Luis XIV de Francia, el Cardenal Mazarino y Hugues de Lionne, en la isla de los Faisanes (río Bidasoa), poniendo fin al litigio de la Guerra de los Treinta Años. Una de las consecuencias de este tratado fue la cesión a Francia del condado del Rosellón y parte del de la Cerdaña.

Felipe IV negoció este tratado sin consultar las Cortes Catalanas ni los afectados. De hecho, se lo escondió oficialmente hasta las Cortes de Barcelona de 1702, aunque fue público y notorio desde 1660, tal como consta en el Dietario de la Generalidad, donde la Diputación del General tuvo que hacer una embajada al Virrey de Cataluña para «darle la enhorabuena de la feliz nueva del ajuste de las paces entre España y Francia». Los territorios afectados conspiraron durante años para volver a unirse con el Principado, y las autoridades catalanas también se resistieron a aceptar la partición, que no pudo hacer efectiva hasta el año 1720.

El territorio catalán se dividía así en contra de la voluntad de las instituciones catalanas, contra el Juramento por las Islas, por el que las tierras del antiguo Reino de Mallorca no podían separarse de las de la Corona de Aragón, por la voluntad de la monarquía hispánica de ceder los territorios del norte de Cataluña a cambio de mantener las posesiones en Flandes. A diferencia de Gibraltar o Menorca, cedidas a Inglaterra en 1713 por el Tratado de Utrecht, ningún gobierno español ha pedido la restitución de los territorios norcatalanes cedidos en el Tratado de los Pirineos. A menudo se considera al Tratado de los Pirineos como parte de los Tratados de Westfalia, lo que se considera una consecuencia

Periodo borbónico (1700-1705)

Con la muerte del rey Carlos II y su sucesión por parte de Felipe V (1700), nieto de Luis XIV (proclamado conde de Barcelona por la sublevación de 1640) se instaló en el trono hispánico una nueva dinastía, la Casa de Borbón, reinante en Francia, que sustituía a la de los Habsburgo. Esta circunstancia llevó a la formación de la Gran Alianza de la Haya por parte de Inglaterra, las Provincias Unidas y el Sacro Imperio Romano Germánico a favor de los derechos del archiduque Carlos de Austria, iniciándose así la Guerra de Sucesión Española.

Aunque en Cataluña se aceptó inicialmente a Felipe V, y éste había jurado y prometido guardar sus fueros, las clases dirigentes catalanas fueron desconfiando por lo que percibían como formas absolutistas y centralistas del nuevo monarca, así como por la política económica pro-francesa. 

Periodo austriacista (1705-1714)

La oposición al monarca que culminó con el ingreso del Principado (pacto de Génova) y de toda la Corona de Aragón (salvo el Valle de Arán y algunas ciudades), en la Alianza de la Haya. Así, mientras en los reinos de Castilla y de Navarra Felipe V era comúnmente aceptado, en la Corona de Aragón, Carlos, instalado en Barcelona tras haberla invadido con el Sitio de Barcelona (1705), era reconocido como rey con el nombre de Carlos III. Aunque el apoyo al archiduque en la Corona de Aragón no fue unánime (ciudades como Cervera permanecieron fieles a Felipe V), sí fue abrumadoramente mayoritario.

La guerra se desarrolló en Europa y en la península con diversas alternancias para ambos bandos. Sin embargo, Gran Bretaña se conformaba con la obtención de nuevas bases navales (Gibraltar y Menorca) y con que los borbones no acumulasen los numerosos territorios de las dos coronas. La causa de Carlos perdió apoyos y el propio pretendiente perdió interés al heredar la corona de Austria. Los tratados de Utrecht (1713) y de Rastatt (1714) dejaron a la Corona de Aragón internacionalmente desamparada frente al poderoso ejército franco-castellano de Felipe V, quien ya había manifestado su intención de suprimir las instituciones tradicionales. A pesar de la resistencia a ultranza, como ocurrió con Aragón y Valencia (1707), todo el territorio catalán fue invadido y Barcelona finalmente capituló el 11 de septiembre de 1714.

Con los Decretos de Nueva Planta (Aragón y Valencia en 1707, Cataluña en 1716), se produjo la abolición de las instituciones y libertades civiles catalanas, se extendieron a los diversos territorios de la Corona de Aragón buena parte de las instituciones castellanas. Sin embargo, el derecho civil catalán (al igual que el aragonés) fue respetado por el monarca.

Todos los territorios de la Corona de Aragón pasaban a tener una nueva estructura territorial y administrativa a imagen de la de Castilla (excepto en el Valle de Arán); se instauraba el catastro y otros impuestos por los que la monarquía conseguía por fin sus objetivos de control económico y se centralizaban todas las universidades catalanas en Cervera, como premio a su fidelidad y para controlar mejor a las élites cultivadas, situación que se prolongó hasta 1842.

A pesar de la difícil situación interna, Cataluña lograría a lo largo del siglo XVIII una notable recuperación económica, centrada en un crecimiento demográfico importante, un aumento considerable de la producción agrícola y una reactivación comercial (especialmente gracias al comercio con América, abierto solo a partir de 1778), transformaciones éstas que marcarían la crisis del Antiguo Régimen y posibilitarían después la industrialización, un primer proceso de la cual se daría en el siglo XVIII, especialmente centrado alrededor del algodón y otras ramas textiles.

A finales de siglo, sin embargo, las clases populares empezaron a notar los efectos del proceso de proletarización que ya se manifestaba, lo cual dio lugar a diferentes situaciones críticas hacia finales de ese siglo. En la década de los noventa se iniciaron además nuevos conflictos en la frontera con Francia, derivados de las consecuencias de la Revolución francesa.

En 1808, Cataluña fue ocupada por las tropas de Duhesme, general de Napoleón, tras el comienzo de la Guerra de Independencia Española en Móstoles. El 26 de enero de 1812, Cataluña fue incorporada al Imperio Francés y dividida en 4 departamentos: Bouches-de-l'Èbre, Montserrat, Sègre y
Ter. Al igual que en el resto de España, la mayoría de la población catalana se rebela contra la ocupación. Entre los hechos de armas destacan la batalla del Bruch en 1808 y los tres asedios a que es sometida Gerona, defendida en el tercer sitio por sus habitantes bajo la dirección del general Álvarez de Castro, ayudado externamente por el capitán Juan Clarós y sus 2500 hombres. Durante el mismo, los franceses perdieron gran cantidad de hombres y medios antes de conseguir rendirla por el hambre, las epidemias y el frío el 10 de diciembre de 1809. El dominio francés se extendió hasta 1814, cuando el Duque de Wellington firmó el armisticio por el cual los franceses debían abandonar Barcelona y otras plazas fuertes que habían ocupado hasta el último momento. El 28 de mayo de 1814 las tropas se retiraron al mando del general Pierre Joseph Habert.

Durante el reinado de Fernando VII (1808-1833) se sucedieron diversas sublevaciones en territorio catalán y tras su muerte, el conflicto por la sucesión entre el infante Carlos María Isidro y los partidarios de Isabel II dio lugar a la primera guerra carlista, que se prolongaría hasta 1840 y que sería especialmente virulenta en territorio catalán. La victoria de los liberales sobre los carlistas dio pie al desarrollo de la revolución burguesa bajo el reinado de Isabel II. Los vencedores se dividieron pronto en moderados y progresistas, mientras que en Cataluña se empezaba a desarrollar el republicanismo. Durante esta época, la industrialización avanza en Cataluña a mayor velocidad que en el conjunto de España, dando lugar al surgimiento de una nueva clase social, el proletariado, que soportaría condiciones de vida y trabajo muy duras.

El desarrollo del reinado de Isabel II, se tradujo en un progresivo aumento de la agitación social y en el desarrollo de la ideología republicana y federal. 

El descontento estalló la Revolución de 1868, también conocida como "La Gloriosa", que causó la caída de Isabel II y dio lugar al comienzo del Sexenio Revolucionario.

La temporal coalición de liberales moderados, progresistas y republicanos que había derribado a Isabel tuvo enormes dificultades para decidir la forma de gobierno. Finalmente, siendo jefe de Gobierno el general Prim, catalán de Reus y eterno conspirador, se decidió mantener la monarquía en la persona de Amadeo de Saboya. Sin embargo, el asesinato de Prim privó al nuevo monarca de su principal apoyo antes de llegar a España. El estallido de la Tercera Guerra Carlista agravó la situación. La oposición cruzada de los monárquicos alfonsinos y carlistas, por un lado, y los republicanos y movimientos obreros, por otro, obligaron a Amadeo a abdicar al cabo de sólo dos años y cuatro meses de subir al trono. El enfrentamiento entre las diversas opciones monárquicas favoreció la proclamación de la Primera República Española. Ésta tuvo que afrontar la insurrección armada de los carlistas, las conspiraciones de los alfonsinos y la agitación de los movimientos obreristas vinculados a la Primera Internacional, así como la división de los mismos republicanos en unitarios y federalistas. Además, tanto bajo la monarquía de Amadeo como durante la misma República, en Cataluña se suceden diversos intentos separatistas que fueron neutralizados por los distintos gobiernos. Los gobiernos se suceden vertiginosamente y la República se encaminaba hacia el federalismo.

La Revolución Industrial de Cataluña, o la era del vapor, se produjo entre 1840 y 1891, lo que convirtió Cataluña en uno de los territorios de mayor dinamismo industrial y se incorporó al grupo reducido de las regiones europeas que alcanzaron antes de 1860 unos niveles de industrialización elevados. La Revolución Industrial fue posible por el renacimiento económico que experimentó la sociedad y la economía catalana durante el siglo XVIII.

El aumento de la demanda y la transformación del sistema productivo, con una movilización importante de la iniciativa, trabajo y capital fueron elementos centrales.

Durante la primera etapa del proceso de industrialización, desde la finalización de la Revolución Liberal hasta la virada nacionalista del capitalismo español (1891), las relaciones económicas con el resto de España se intensificaron mucho decididamente. La integración económica progresó al mismo tiempo que se avanzó en la unificación del ámbito administrativo, fiscal y financiero. El desarrollo de las infraestructuras modernas, especialmente gracias a la construcción de la red ferroviaria, incentivó esta dinámica.

El crecimiento económico catalán fue resultado, en gran parte, de la rápida integración en la economía española. Las ventas de los productos de la nueva industria conformaron la corriente más activa de estas relaciones. También aumentaron las conexiones con el mercado colonial de Cuba y Puerto Rico y, aunque de forma limitada, el tráfico con el resto del mundo.

Paralelamente al rebrote del catalanismo, en todo el Estado surge una nueva manera de entender el Estado español: el federalismo.
Francesc Pi i Margall, un catalán instalado en Madrid y uno de los presidentes de la Primera República Española fue el gran ideólogo del federalismo en España, que definía que sólo el pacto federal libremente establecido entre las diversas regiones españolas podía garantizar el respeto total a la realidad plural del Estado.

En Cataluña, por el contrario, el federalismo fue una de las caras que adoptó el catalanismo político. Una ideología populista e interclasista, que estaba estrechamente relacionada con los inicios del movimiento obrero. El federalismo catalán vivió una época gloriosa: el Sexenio Revolucionario. Durante este período se produjo una división entre federalistas, los moderados y los radicales. Ambos eran partidarios de la federación, pero los radicales exigían como paso previo a la igualdad la independencia, para poder decidir libremente la federación posterior. Los moderados preferían un federalismo impulsado desde el gobierno central.

En 1873, a raíz de la proclamación de la Primera República Española, un grupo de federalistas intransigentes intentaron, desde la Diputación de Barcelona, proclamar el Estado Catalán.

En 1874, el pronunciamiento del general Martínez Campos en Sagunto dio paso a la Segunda Restauración Borbónica en el trono español, en la persona de Alfonso XII. Se abre así un periodo dominado por la figura política de Antonio Cánovas del Castillo, consiguiéndose una mayor estabilidad política. La conquista de la plaza carlista de Seo de Urgel supuso el fin de la guerra en Cataluña. Por otro lado, el nuevo régimen reprimió las protestas obreras. La tranquilidad obtenida con el sistema del turno de partidos se extendería hasta inicios del siglo XX, momento en que afloraría nuevamente la oposición política, especialmente de republicanos y catalanistas, y las tensiones sociales.

La industrialización estaría marcada por una grave escasez de recursos energéticos propios y la debilidad del mercado interior español, además de por las presiones para adoptar políticas proteccionistas que evitaran la competencia de productos extranjeros. A partir del segundo tercio del siglo se desarrolló también la "Renaixença" ('renacimiento'), un movimiento cultural de recuperación del catalán como lengua de cultura, que empezaba a superar así su larga etapa de decadencia.
En esta etapa inicial del catalanismo político, la personalidad más notoria es Valentí Almirall, quien participó activamente en la vida política al lado de los federales intransigentes o radicales oponiéndose al centralismo, la oligarquía y la especulación. Almirall pretendía regenerar Cataluña de modo que repercutiera en el resto del Estado, que imaginaba como una asociación de pueblos a modo de la Corona de Aragón, además es uno de los defensores de la raza catalana.

Almirall intentó unir las derechas y las izquierdas catalanistas, pero no lo consiguió porque existían demasiados divergencias entre las dos corrientes. Impulsó el Primer Congreso Catalanista, que se celebró en 1880, en el que se conjunta los diferentes grupos catalanistas: el federalismo republicano y la corriente apolítica, el literario, el propulsor de los Juegos Florales y de la revista "La Renaixença" [sic], pero las tendencias izquierdistas de Almirall hizo que el grupo de "La Renaixença" abandonara el Congreso y rompiera el entendimiento. Sin embargo, el Congreso tomó tres acuerdos fundamentales: crear una entidad aglutinadora del catalanismo —el Centro Catalán—, el comienzo de gestiones para constituir la Academia de la Lengua Catalana —que tendrá una corta vida—, y la redacción de un documento en defensa del catalán, que a partir de este momento se llamará catalán a la lengua llemosina, a pesar de la existencia de otras lenguas habladas en Cataluña.

Posteriormente, Valentí Almirall impulsó el Segundo Congreso Catalanista, que se declaró partidario de la cooficialidad del catalán en Cataluña, proclamó la existencia de Cataluña como realidad por encima de divisiones administrativas y condenó la militancia de catalanistas a partidos de ámbito estatal. Este último hecho impulsó la creación de partidos de ámbito únicamente catalán, inexistentes hasta el momento. La época gloriosa del Centro Catalán y de Almirall culminó con el Memorial de Agravios y la publicación «Lo catalanisme».

El siglo XIX ve también la primera vertebración del catalanismo como un movimiento político. En este proceso destacaron tres sectores principales:


En 1880 tiene lugar el Primer Congreso Catalanista. Reclaman una escuela en lengua catalana para transmitir la cultura y la lengua. Esta demanda tiene una primera respuesta en 1882 con la creación del Centro Catalán, constituido por Valentí Almirall. En 1883 se reúnen en el Segundo Congreso Catalanista, dando paso al primer acto oficial en catalán: el Memorial de agravios. Se trata de un escrito pidiendo al rey, Alfonso XII, ciertos privilegios políticos. Los componentes del Centro Catalán querían conseguir el apoyo de la burguesía, pero eso fue inviable. La burguesía no hacía suyo el catalán medievalizante que hablaban e incluso surgió un movimiento llamado "La Renaixença popular", burlándose de aquellos sectores más cultos.

Viendo que no conseguían el apoyo de la burguesía, los integrantes del grupo de "La Renaixensa" se separaron del Centro Catalán y crearon la Lliga de Catalunya, consiguiendo así el apoyo que buscaban. En 1888, aprovechando la visita de la Reina regente en Barcelona para la Exposición Universal, redactan el "Mensaje a la Reina Regente", pidiendo autonomía política para Cataluña.

En 1887, tras ser derrotado en las elecciones a la Junta Directiva del Centro Catalán, el sector más conservador se escindió y, junto con un grupo de universitarios llamado Centro Escolar Catalanista crearon la Liga de Cataluña, los dirigentes de la que, más tarde se integraron en otro partido político catalán, la Lliga Regionalista. Partiendo de su iniciativa se creó la Unió Catalanista, que englobaba diversas entidades unidas por el catalanismo, divididos en dos tendencias: la gente de 'La Renaixensa', más culturalista y apolítica, y la Lliga de Catalunya, más partidaria de participar en la vida política. Los catalanistas de izquierdas, Almirall y los federalistas, no formaban parte. La Unió Catalanista convocó una asamblea en Manresa en 1892, donde se congregó buena parte de la burguesía catalana conservadora. En esta asamblea se aprobaron las Bases para la Constitución Regional Catalana, más conocidas como «Bases de Manresa». Estas bases marcaban las pautas a seguir para una futura 'Constitución regional catalana', es decir, un Estatuto. Estas bases expresan los planteamientos del regionalismo conservador y tradicionalista opuesto al sistema parlamentario basado en el sufragio universal. La posterior actuación de la Lliga Regionalista se fundamenta en estas bases.

En 1891 se fundó la Unió Catalanista, pero no se presentaron a las elecciones, ya que lo ven absurdo por las manipulaciones caciquistas y el pucherazo. Este partido redactó las Bases de Manresa, un programa de autonomía política para Cataluña. Àngel Guimerà pronunció un discurso pidiendo el catalán como lengua oficial y acto seguido, la burguesía retiró su apoyo a este partido por identificar la demanda de la lengua oficial con el republicanismo.

La Sublevación carlista de octubre de 1900, en Badalona, fue sofocada.

El verano de 1909 se produce una revuelta popular conocida como la Semana Trágica, en que una huelga general degenera en actos de vandalismo que son reprimidos duramente.

La creciente conflictividad social degenerará a lo largo del reinado de Alfonso XIII, dando lugar desde 1917 a una intensificación de las tensiones y al desarrollo del pistolerismo, alentado desde la patronal contra los obreros y enfrentado al terrorismo anarquista. Ello desencadena una espiral de violencia que sólo se frenará con la llegada de la dictadura del general Primo de Rivera (1923-1930), apoyada en su inicio por la burguesía catalana.

Tras la caída de Primo de Rivera, la izquierda republicana y catalanista invirtió grandes esfuerzos para generar un frente unitario, bajo la figura de Francesc Macià. Así nació Esquerra Republicana de Catalunya, un partido que logró romper el abstencionismo obrero y consiguió un triunfo espectacular en las elecciones municipales del 12 de abril de 1931, que precederían a la proclamación de la Segunda República Española.

En las décadas siguientes fue tomando cuerpo el catalanismo político, como culminación de un proceso de afirmación de la conciencia nacional catalana, las primeras formulaciones del cual fueron debidas al político republicano Valentí Almirall. En 1901 se formó la Liga Regionalista de Enric Prat de la Riba y Francesc Cambó, que impulsó la Solidaridad Catalana. En cuanto al movimiento obrero, el final del siglo XIX se caracteriza en Cataluña por tres tendencias: el sindicalismo, el socialismo y el anarquismo, a los cuales se suma, a inicios del siglo XX, el lerrouxismo. Ello conduce a que en las primeras décadas del siglo XX se distingan dos grandes líneas de fuerza, el catalanismo y el obrerismo.

El primero, bajo el liderazgo de Prat de la Riba, consiguió una primera plataforma de autogobierno desde 1716: la Mancomunidad de Cataluña (1913-1923), presidida primero por éste, y más tarde por Josep Puig i Cadafalch. El obrerismo encontró en el anarcosindicalismo la síntesis aglutinadora de anarquistas y sindicalistas, los dos sectores mayoritarios del movimiento obrero, y en la Confederación Nacional del Trabajo (CNT), la organización de combate para luchar por sus derechos.

Se conoce como Semana Trágica a los acontecimientos sucedidos en Barcelona y otras localidades catalanas, entre el 25 de julio y el 2 de agosto de 1909. El detonante de estos hechos fue la movilización de reservistas para su envío a la zona de Melilla, donde el día 9 del mismo mes había comenzado la Guerra de Melilla, para muchos motivada exclusivamente por el descubrimiento del año anterior de unas minas propiedad de una sociedad controlada por el Conde de Romanones, el Marqués de Comillas y el Conde de Güell. Esta movilización fue muy mal acogida por las clases populares, ya que, debido a la legislación de reclutamiento, se podía quedar exento de la incorporación a filas mediante el pago de seis mil reales, cantidad que no estaba al alcance de los más pobres (el sueldo de un obrero de la época no era de más de 5 pesetas o 10 reales al día). Por otra parte, los reservistas mayoritariamente ya estaban casados y con familia a su cargo.

El gobierno de Maura y el nuevo gobernador civil, Evaristo Crespo Azorín, lleva a cabo una represión durísima y, peor, arbitraria. En total, entre julio de 1909 y abril de 1910 fueron detenidas 1.967 personas y 200 más fueron expulsadas a 300 kilómetros de Barcelona. Organizó un proceso militar contra 1.925 individuos, de ellos 214 en contumacia, de los cuales 469 fueron sobreseídos y 584 absueltos. Se dictaron 17 penas de muerte, pero solo 5 fueron aplicadas. Siguiendo la acusación formulada en una carta que le dirigen los prelados de Barcelona, es detenido Francisco Ferrer Guardia, creador de la Escuela Moderna, quien acusan de ser el instigador de la revuelta. A pesar de las protestas internacionales, el 13 de octubre del mismo año Ferrer es fusilado junto con Eugenio del Hoyo Manjón, Antoni Malet Pujol, Ramón Clemente García y Josep Miquel Baró en el castillo de Montjuïc. Ninguno de ellos había sido dirigente destacado durante la revuelta. Estos fusilamientos ocasionan una amplia repulsa hacia Maura en España y en toda Europa, con una gran campaña en la prensa extranjera, así como manifestaciones y asaltos a diversas embajadas. El rey Alfonso XIII, alarmado por estas reacciones tanto en el exterior como en el interior destituye Maura y lo sustituye por el liberal Segismundo Moret. Tras los hechos de la Semana Trágica, la Barcelona anarquista recibió el apodo de la Rosa de fuego.

La Mancomunidad de Cataluña fue una institución que agrupó las cuatro diputaciones catalanas: Barcelona, Gerona, Tarragona y Lérida. Se formó el 6 de abril de 1914, si bien el proceso para su creación comenzó en 1911. El Congreso de Diputados la aprobó, pero con competencias muy recortadas respecto al proyecto enviado por el Gobierno. En cambio, el Senado no lo hizo cerrando la vía legislativa. Finalmente el gobierno, necesitado del apoyo parlamentario de los catalanistas, se decidió por la vía del decreto que el 18 de diciembre de 1913 el rey firmó: el derecho de mancomunidades provinciales. La Mancomunidad respondía a una larga demanda histórica de los catalanes, en significar la federación de las cuatro diputaciones catalanas y en cierto sentido un retorno de la capacidad de la gestión administrativa de las antiguas Cortes Catalanas. Aunque debía tener funciones puramente administrativas, y sus competencias no iban más allá de las de las diputaciones provinciales, adquirió una gran importancia política: representaba el primer reconocimiento por parte del estado español de la personalidad y de la unidad territorial de Cataluña desde 1714. La institución estaba integrada por una asamblea que reunía los noventa y seis diputados provinciales - 36 por Barcelona y 20 para las tres restantes - y que se renovaba pues junto a estas - por mitades, cada dos años, por sufragio universal masculino, en razón de 4 diputados por partido judicial - y por el Consejo, formado por ocho consejeros y el Presidente. Su acción política estuvo regida por el consenso entre las distintas orientaciones presentes, fueran o no catalanistas. Fue presidida por Enric Prat de la Riba (1914-1917) y luego por Josep Puig i Cadafalch (1917-1923), militantes ambos de la Liga Regionalista. A continuación lo hizo Alfons Sala (1923-1925), impuesto por Primo de Rivera en 1923). La Mancomunidad llevó a cabo una labor de creación de infraestructuras de caminos y puertos, obras hidráulicas, ferrocarriles, teléfonos, beneficencia o sanidad. También emprendió iniciativas para aumentar los rendimientos agrícolas y forestales introduciendo mejoras tecnológicas, de servicios y educativas, y potenció las enseñanzas tecnológicas necesarias para la industria catalana.

A principios del siglo XX el lemosín (ya llamado desde 1880 como catalán, a pesar que en el Valle de Arán se habla aranés) era la lengua mayoritaria de la región, pero no existía todavía un estándar ni unas normas. Además Enric Prat de la Riba era consciente que «de la cultura catalana el estado no se preocupa y las diputaciones tenemos que suplir esta deficiencia fomentando el cultivo y perfeccionamiento de la lengua». Cuando se creó el IEC se hicieron dos encargos a la Sección Filológica liderada por Pompeu Fabra: sistematizar unas reglas de escritura y promocionar el catalán como lengua de uso científico, objetivos que se explicitaron durante la constitución del IEC: «el restablecimiento y la organización de todo lo que se refiere a la cultura genuinamente catalana» y «la investigación científica de todos los elementos de la cultura catalana». El IEC publicó las Normas ortográficas en 1913, dotando el catalán de una ortografía formal. Inmediatamente se generaron grandes y duros debates sobre algunas de las decisiones ortográficas tomadas (lo más encarnizado fue lo de escribir los plurales -"es" y no -"as"), pero poco a poco se fueron aceptando: La Mancomunidad adoptó enseguida el catalán de Fabra y lo promocionó: todas sus instituciones lo adoptaron como lengua vehicular, desde las diversas escuelas de educación profesional hasta las escuelas de primaria. En 1916 la Mancomunidad de Cataluña envió una petición oficial para reconocer la lengua catalana como cooficial, adjuntando un detallado programa de normalización lingüística. La propuesta provocó quejas y presiones de la Real Academia Española, hasta que el entonces presidente, el conde de Romanones, dijo que nunca daría este reconocimiento al catalán, porque se usaba como "emblema político".

En Cataluña fue inicialmente aplaudido por los sectores de la alta burguesía conservadora que dieron la bienvenida a Primo como salvaguarda ante las fuerzas radicales del anarquismo. En un primer momento se permitió que la Mancomunidad continuara existiendo, pero la dictadura trabajó a fondo contra el nacionalismo catalán republicano, cada vez más radicalizado y en alza, prohibiendo partidos, asociaciones e instituciones autóctonas. Finalmente, la Mancomunidad de Cataluña fue definitivamente suprimida en 1924 y prohibido el uso de la lengua y la bandera catalanas en la administración y en la vida pública.

Cataluña se convirtió pronto en uno de los focos más activos y unánimes de oposición a la dictadura, ambiente que favoreció el crecimiento de la fuerza y popularidad del nacionalismo republicano que tuvo en Estat Català (Estado Catalán) en 1922 y en su líder Francesc Macià, el luchador más comprometido. Por el contrario, el catalanismo moderado y socialmente conservador de la Lliga Regionalista quedó muy desprestigiado.
El 14 de abril de 1931, el mismo día en que se proclamaba la República en Madrid, Francesc Macià proclamaba desde el balcón de la antigua Generalidad de Cataluña la República Catalana dentro de una federación de pueblos ibéricos. El hecho motivó preocupación fuera de los círculos nacionalistas, siendo solucionado con la restauración de la Generalidad de Cataluña. La posterior aprobación de la Constitución republicana que, tras enconados debates reconoció la posibilidad de autonomía regional, permitió la aprobación del Estatuto de Autonomía de Cataluña de 1932. Los diputados catalanes elaboraron un Estatuto aprobado en referéndum el 2 de agosto de 1931 y modificado y aprobado en las Cortes Españolas el 12 de septiembre de 1932. Con el estatuto aprobado, el 20 de noviembre de 1932 se hicieron las únicas elecciones al Parlamento de Cataluña del periodo republicano para constituir las instituciones y pasar de un gobierno provisional a un gobierno estatutario con Francesc Macià ratificado como Presidente y Lluís Companys como presidente del Parlamento. En su virtud fueron instaurados un gobierno y un parlamento autónomos en Cataluña. Macià fue investido primer presidente de la Generalidad, cargo que desempeñó hasta su muerte en diciembre de 1933. Fue sustituido en el cargo por Lluís Companys. Las elecciones parlamentarias de 1933, primeras en las que las mujeres tuvieron derecho al voto, convirtieron a la conservadora CEDA en la principal fuerza política. Tras una etapa de gobierno minoritario del Partido Republicano Radical dirigido por el antaño revolucionario y ahora centrista Alejandro Lerroux, la CEDA exigió participar en el ejecutivo. Su entrada en el gobierno con tres ministros motivó que los socialistas convocaran la conocida como Revolución de 1934, que en Cataluña no fue secundada por el sindicato mayoritario, la anarcosindicalista CNT. Sin embargo, el 6 de octubre Companys proclamó «el Estado Catalán de la República Federal española». Carente del apoyo del movimiento obrero y contando con las únicas fuerzas de los Mozos de Escuadra y milicianos de su propio partido, el levantamiento fue sofocado por el Capitán General Domingo Batet. El gobierno español suspendió las instituciones autónomas catalanas, nombrando un ejecutivo provisional con participación de la Liga Catalana y los radicales. La autonomía fue restablecida tras las elecciones parlamentarias de 1936, que llevaron al poder a los partidos de izquierda agrupados en el Frente Popular, y que supusieron la amnistía para los participantes en la tentativa revolucionaria y la vuelta de Companys al gobierno catalán. En el período republicano el gobierno catalán en gran parte continuó y amplió la política educativa de la Mancomunidad de Cataluña. Tuvo muchas dificultades financieras y la cesión de competencias no se acabó nunca de hacer en su totalidad. En general este período constituyó un ensayo y una lección histórica para la realización posterior de la Generalidad de 1977.

En cuanto al movimiento obrero, destaca la crisis de la CNT con la escisión del sector moderado, los denominados treintistas. Los partidos de inspiración socialista iniciaron un proceso de convergencia que culminaría en la formación de dos partidos rivales: el Partido Obrero de Unificación Marxista (POUM) y el Partido Socialista Unificado de Cataluña (PSUC).

Tras la victoria electoral de las izquierdas en febrero de 1936 (en Cataluña bajo la bandera del Front d'Esquerres de Catalunya) y la sustitución del presidente conservador Niceto Alcalá-Zamora por el izquierdista Manuel Azaña la tensión política continuó incrementándose. Los actos violentos de ambos bandos culminaron con el asesinato del líder de la derecha radical, José Calvo Sotelo. Pocos días después tuvo lugar el fallido golpe de estado contra la II República, que desembocó en la Guerra Civil. En Barcelona, el golpe fue liderado por el general Manuel Goded, pero la oposición armada de los militantes de sindicatos y partidos de izquierda y la decisiva intervención de la Guardia Civil propició el fracaso de la rebelión. A partir de ese momento, Cataluña quedaría dentro del sector no controlado por los sublevados y bajo la teórica autoridad del gobierno republicano.

El desarrollo de la guerra en Cataluña se caracterizó en una primera fase por una situación de doble poder: el de las instituciones oficiales (la Generalidad y el Gobierno republicano) por un lado, y el de las milicias populares armadas coordinadas por un Comité Central de Milicias Antifascistas de Cataluña por otro. Se desató una oleada de represión contra los sectores a los que se consideraba afines a los sublevados, principalmente religiosos católicos y simpatizantes de la Liga Catalana. La poco coordinada acción militar se encaminó en dos direcciones: una ofensiva contra el Aragón controlado por los sublevados, que sólo permitió estabilizar el frente durante un tiempo; y un fracasado intento de conquistar Mallorca.
Con el avance de la guerra se produjeron también graves enfrentamientos entre las organizaciones que querían dar prioridad a la revolución social, principalmente la CNT y el POUM, y quienes consideraban prioritario dirigir los esfuerzos al frente bélico y mantener el apoyo de los sectores moderados. Este segundo sector integraba al gobierno republicano, el PSUC, la Esquerra Republicana de Catalunya y otros partidos. El enfrentamiento culminó en las jornadas de mayo de 1937, durante las cuales ambos bandos se enfrentaron con las armas. La victoria del bando gubernamental supuso una mayor integración de los anarcosindicalistas en la disciplina del Ejército Popular de la República y la eliminación (incluso física) del POUM, incómodo rival comunista para el PCE y el PSUC (ya dominado por los prosoviéticos). Tampoco fue buena la colaboración entre la Generalidad dirigida por Companys y el gobierno republicano debido al deseo de éste de centralizar el mando bélico y a la tendencia de aquella a exceder sus competencias estatutarias.

Finalmente el ejército rebelde rompió en dos el frente republicano al ocupar Vinaroz, lo que aisló a Cataluña del resto del territorio republicano (constituido ya solo por Valencia y la zona central). La derrota de los ejércitos republicanos en la batalla del Ebro permitió la ocupación de Cataluña por las tropas encabezadas por el general Franco entre 1938 y 1939. La victoria total del proclamado Generalísimo supuso el fin de la autonomía catalana y el inicio de una larga dictadura.

El franquismo (1939-1975) supuso en Cataluña, como en el resto de España, la anulación de las libertades democráticas, la prohibición y persecución de los partidos políticos (salvo Falange Española Tradicionalista y de las JONS), la clausura de la prensa no adscrita a la dictadura militar y la eliminación de las entidades de izquierdas.

Además, se suprimieron el Estatuto de Autonomía y las instituciones de él derivadas, y se persiguió con sistematicidad la lengua y la cultura catalanas, sobre todo en la administración, en los medios de comunicación, en la escuela, en la universidad, en la señalización pública y en general en toda manifestación pública. El catalán fue excluido de la esfera pública y administrativa y quedó reducido al uso familiar y vecinal. El castellano pasó a ser la única lengua de la enseñanza, de la administración y de los medios de comunicación. La situación se agravó por las grandes oleadas inmigratorias de castellanoparlantes del siglo XX, sobre todo las de los años 60 y 70, procedentes del resto de España, sobre todo de Andalucía y Extremadura, y que en gran parte se concentraron en el área metropolitana de Barcelona. Todo esto provocó un gran retroceso del uso social del catalán y de su conocimiento, hasta el punto que en Cataluña el castellano superó al catalán como lengua materna por primera vez en su historia. En Cataluña el factor más importante del bilingüismo social es la inmigración desde el resto de España en el siglo XX. Se ha calculado que, sin migraciones, la población de Cataluña habría pasado de unos 2 millones de personas en 1900 a 2,4 en 1980, en vez de los más de 6,1 millones censados en esa fecha (y superando los 7,4 millones en 2009); es decir, la población sin migración habría sido solamente el 39 % en 1980. 

Los vencidos fueron desvertebrados. A los numerosos muertos durante la guerra hay que sumar los que fueron fusilados tras la victoria franquista, como el propio presidente Lluís Companys; muchos otros, obligados al exilio, no volverían a su país; gran número de los que no huyeron fueron encarcelados; y muchos más fueron «depurados» e inhabilitados para ocupar cargos públicos o ejercer determinadas profesiones, lo que les dejó en pésima situación económica en una época ya dura de por sí. Un pequeño sector de anarquistas y comunistas intentó librar una guerra de guerrillas en unidades conocidas como maquis. Su acción más destacada fue la invasión del Valle de Arán.

Tras la primera etapa de economía autárquica, en la década de los años 1960 la economía entró en una etapa de modernización agrícola, de incremento de la industria y recibió el impacto del turismo de masas. Cataluña fue también una de las metas del movimiento migratorio, que dio a Barcelona y a las localidades de su entorno un crecimiento acelerado. También se desarrolló fuertemente la oposición antifranquista, cuyas manifestaciones más visibles en el movimiento obrero fueron Comisiones Obreras, desde el sindicalismo, y el PSUC.

En la década de los años 1970, el conjunto de fuerzas democráticas se unificaron alrededor de la Asamblea de Cataluña. El 20 de noviembre de 1975 falleció el dictador Francisco Franco, hecho que abriría un nuevo período en la historia de Cataluña.

Globalmente, la casi total exclusión del catalán del sistema educativo y las severas limitaciones a su uso en los medios de comunicación de masas durante todos estos años, tuvo consecuencias de larga duración y que estarían presentes años después del final de la dictadura, como se observa en las altas tasas de analfabetismo en catalán que se da entre las generaciones escolarizadas en esos años: en 1996 solo un tercio del tramo de edad comprendido entre los 40 y los 44 años era capaz de escribir en catalán, hablado por el 67 % de los censados, cifras que descendían al 22 % de los mayores de 80 años capaces de escribirlo con un 65 % de hablantes.

Con la muerte del general Franco, se inició el periodo conocido como transición democrática, a lo largo del cual se irían alcanzando las libertades básicas, consagradas por la Constitución española de 1978. En ella se reconoce la existencia de comunidades autónomas dentro de España, lo que da lugar a la formulación del Estado de las Autonomías.

Tras las primeras elecciones generales, en 1977, se restauró provisionalmente la Generalitat, gracias al impulso de la sociedad civil catalana (representada por la masiva manifestación que tuvo lugar en Barcelona el 11 de septiembre de ese año) y la iniciativa del Gobierno de Adolfo Suárez, apoyada por el rey y las altas instancias del Estado. 

Josep Tarradellas, que había preservado la legalidad del autogobierno catalán como presidente en el exilio, tras declarar su adhesión al rey y al proceso de reforma política. Tarradellas constituyó un gobierno autónomo provisional compuesto por representantes de las fuerzas más relevantes en aquel momento.

En el Referéndum para la ratificación de la Constitución española, del 6 de diciembre de 1978, se dieron los siguientes resultados: 72,3% de participación en la provincia de Gerona, con el voto favorable del 89,8% de los votantes (218.316 Sí, 10.681 No); 67,7% de participación en la provincia de Barcelona, con el voto favorable del 90,4% de los votantes (2.095.467 Sí, 109.530 No); 67% de participación en la provincia de Tarragona, con el voto favorable del 91% de los votantes (225.330 Sí, 10.849 No), y 66,5% de participación en la provincia de Lérida, con el voto favorable del 91,3% de los votantes (162.757 Sí, 6.785 No). Por tanto, en el conjunto de las cuatro Juntas Provinciales de Cataluña se alcanzó un 67,9% de participación con el voto favorable del 90,5% de los votantes (en el conjunto de España la participación fue del 67,1% del censo, obteniendo el voto favorable del 87,9% de los votantes) .

En 1979, se aprobó finalmente un nuevo Estatuto de Autonomía de Cataluña, netamente superior al de 1932 en algunos aspectos como enseñanza y cultura, pero inferior en otros como justicia, finanzas y orden público. En él, Cataluña se define como «nacionalidad», se reconoce el catalán como «lengua propia de Cataluña» y alcanza la oficialidad junto al castellano. Tras su promulgación, tuvieron lugar las primeras elecciones catalanas, que dieron la presidencia de la Generalidad a Jordi Pujol, de Convergència i Unió (gracias a una votación a favor de ERC), cargo que ostentaría, tras seis triunfos electorales consecutivos, hasta el año 2003.

Elecciones al Parlamento de Cataluña de 1980: CiU 43, PSC 33, PSUC 25, UCD 18, ERC 14, Partido Andalucista 2.

A lo largo de las décadas de 1980 y 1990 se desarrollaron diferentes aspectos de la construcción autonómica, entre ellos el despliegue de la policía autonómica, los Mozos de Escuadra, la creación de la administración comarcal y el Tribunal Superior de Justicia de Cataluña. También se desarrolló la Ley de Normalización Lingüística y la inmersión lingüística en las escuelas, a fin de fomentar el conocimiento y el uso del catalán; y se crearon la Corporación Catalana de Medios Audiovisuales, los medios de comunicación de radio y televisión de titularidad pública catalana (Catalunya Ràdio y TV3).

El 5 de noviembre de 1992, España ratificó en Estrasburgo, la Carta europea de las lenguas regionales o minoritarias, por la que adquiere entre otros, el compromiso de reconocerlas, respetarlas y promoverlas.

En 1992 Barcelona celebró los Juegos Olímpicos, que sirvieron para dar a Cataluña y a España visibilidad internacional. A lo largo de la década de los años 1990, la ausencia de mayorías absolutas en el gobierno español apenas contribuyó a ampliar las competencias autonómicas, a pesar del apoyo de CiU al último gobierno de Felipe González (1993-1996) y al primero de José María Aznar (1996-2000).


Uno de los fenómenos más notorios en la primera década del siglo XXI fue el incremento de población de origen foráneo en Cataluña. El número de personas nacidas en el extranjero se incrementó de menos del 3% en 2000 a cerca del 15% en 2010.

Por otra parte políticamente, el desgaste de CiU tras tantos años en el gobierno y su apoyo a los últimos gobiernos de Aznar condujeron a que, en noviembre de 2003, los resultados de las elecciones autonómicas posibilitaran un cambio de partidos en el gobierno de la Generalidad.

Pasqual Maragall fue nombrado presidente en diciembre de 2003, y encabezó un gobierno de coalición formado por el PSC-PSOE-CpC, ERC y ICV-EUA, el Tripartito catalán. 

El 16 de septiembre del 2005, la ICANN aprobó oficialmente el .cat, el primer dominio para una comunidad lingüística.

Los problemas asociados al proyecto de reforma del Estatuto de Autonomía de Cataluña, se tradujo en un adelanto de la convocatoria de elecciones a noviembre de 2006

José Montilla sucedió a Maragall el 28 de noviembre de 2006. Fue el primer presidente de la Generalidad no nacido en Cataluña después de la Segunda República, natural de la localidad cordobesa de Iznájar.

Las elecciones autonómicas del 28 de noviembre de 2010 dieron de nuevo la victoria a Convergència i Unió, por lo que su candidato y cabeza de lista por Barcelona, Artur Mas, fue investido como presidente de la Generalidad el 23 de diciembre de ese mismo año. Pero esta legislatura acabó en fracaso después del rechazo del gobierno de Rajoy al pacto fiscal, la promesa electoral de Artur Mas y que buscaba terminar el déficit fiscal de Cataluña con un sistema parecido al concierto vasco.

Influido por la presión callejera ante el malestar social y el creciente independentismo plasmado en la mayor manifestación de la historia de Cataluña en el 11 de septiembre de 2012 y que pedía la independencia de Cataluña, el presidente Artur Mas convocó unas nuevas elecciones, confiando en una posible mayoría absoluta para convocar un referéndum por la autodeterminación de Cataluña. Mas ganó las elecciones, pero perdió 12 escaños. Aun así, consiguió llegar a un acuerdo de gobernabilidad con ERC, el gran ganador de las elecciones ya que se había convertido en el segundo partido en escaños (siendo tercero en votos tras el PSC), por primera vez en la historia postfranquista. Este acuerdo dio lugar a la convocatoria de un referéndum por la autodeterminación de Cataluña en 2014, el cual fue condenado por el Tribunal Superior de Justicia de Cataluña (TSJC).

El 9 de noviembre de 2014 se realizó la consulta sobre el futuro político de Cataluña de 2014.
El 27 de septiembre de 2015 se celebraron unas nuevas elecciones autonómicas que las fuerzas independentistas denominaron «plebiscitarias». Las consecuencias políticas del proceso independentista produjeron la ruptura de CiU y la integración de CDC y ERC en una coalición llamada Junts pel Sí, ganadora de las elecciones pero sin mayoría absoluta. Las dos nuevas fuerzas emergentes de Cataluña fueron Ciudadanos (primera fuerza de la oposición por delante del PP y PSC) y CUP (llave de la gobernabilidad en el nuevo Parlament).
Ese año surgió el movimiento a favor de Tabarnia.

Carles Puigdemont se convirtió en presidente de la Generalidad el 12 de enero de 2016.

El presidente del Gobierno Mariano Rajoy aplicó en Cataluña el artículo 155 de la Constitución española en octubre de 2017.

En las elecciones al Parlamento de Cataluña de diciembre de 2017 convocadas por Mariano Rajoy, Ciudadanos ganó las elecciones en escaños y votos, pero al no obtener la mayoría no pudo formar gobierno. Fue investido presidente de la Generalidad Quim Torra, un conservador esencialista e independentista de línea dura que había sido electo diputado regional por la lista de Junts per Catalunya.





</doc>
<doc id="27894" url="https://es.wikipedia.org/wiki?curid=27894" title="Ley scout">
Ley scout

La Ley guía y scout es el conjunto de valores en los que el escultismo. Fue originalmente diseñada por Robert Baden-Powell. Como herramienta educativa es el núcleo del Método Scout y, alrededor de ella pivotan los demás elementos del Escultismo.

Al escribir Escultismo para Muchachos, Robert Baden-Powell se inspiró en la obra de Ernest Thompson Seton, quien fundó los indios Woodcraft en 1902 en Estados Unidos y más tarde difundió el Movimiento Scout en ese país de América del Norte.
Baden-Powell también se inspiró para la Ley Scout en el código de Bushido de los samurais japoneses, las leyes de honor de los indios americanos, el código de la caballería de los caballeros europeos, y los guerreros Zulú.
Al igual que Seton, Baden-Powell decidió utilizar un conjunto de leyes positivas, en contraste con las prohibiciones del Antiguo Testamento.
La Ley Scout original publicada por Robert Baden-Powell en 1908 tenía nueve artículos.
B-P fue luego perfeccionándola y en 1911 le agregó el décimo artículo.
La última versión de su pluma, ya con diez artículos, es publicada en la reedición de su libro Escultismo para muchachos en 1938.

Las diez leyes de dicha redacción considerada original de la Ley Scout son:

Extraído de "Cartas a un Guía de Patrulla, La ley Scout" del Capitán Roland E. Philipps(1920)

Luego de más de cien años de vida el Movimiento Scout fue adaptando dicha redacción original al idioma y las características propias de cada país.

El texto de la promesa ha variado de un país a otro y a través del tiempo, sin embargo debe cumplir ciertos requerimientos establecidos por la Organización Mundial del Movimiento Scout (OMMS) para ser aceptado como Organización Scout Nacional Miembro.
La Constitución de la OMMS establece en su Artículo II, párrafo 2 "Adhesión a la Promesa y Ley":

Todos los miembros del Movimiento Scout deben adherir a la Ley y la Promesa, en lenguaje apropiado a la cultura y costumbres de cada Organización Scout Nacional y aprobado por la Organización Mundial.
La aprobación de la Organización Mundial del Movimiento Scout en cada reformulación debe ser aprobada por su Comité de Constituciones.



(Baden Powell Scouts Argentina es una asociación de carácter mixto a nivel Grupos Scouts, con secciones masculinas o femeninas dentro de cada Grupo, en atención a los diferentes ritmos naturales de maduración psicosocial de niños y niñas, con el fin de formar mejores ciudadanos que contrubuyan a lograr un mundo mejor).

El / La Scout:



versión OFICIAL de la Ley de las guías y lo scouts de la Asociación de Guías y Scouts de Chile

www.guiasyscoutsdechile.cl - Actualizado a diciembre de 2016.



Guías y Scouts de Costa Rica

La Guía y el Scout son:

01# -El Scout cifra su honor al ser digno de confianza.

02# -El Scout es leal para con su patria, padres, jefes y subordinados.

03# -El scout ayuda sin pensar en la recompensa.

04# -El scout es amigo de todos sin distinción de credo, raza, nacionalidad y clase social.

05# -El scout es cortes y caballeroso.

06# -El Scout ve la naturaleza como la obra de Dios, Y cuida flora y fauna.

07# -El scout obedece sin replicar y hace todo en orden y completo.

08# -El Scout ríe y canta en sus dificultades.

09# -El scout es económico, ahorrador y cuidadoso con el bien ajeno

10# -El scout es puro de pensamientos, palabras y acciones.


""Proyecto Hércules XXI Andalucía""



Del Ceremonial de Guías y Scouts de Europa:















</doc>
<doc id="27895" url="https://es.wikipedia.org/wiki?curid=27895" title="Generalidad">
Generalidad

Generalidad puede referirse a:

</doc>
<doc id="27902" url="https://es.wikipedia.org/wiki?curid=27902" title="A Few Good Men">
A Few Good Men

A Few Good Men (Cuestión de Honor, título en Hispanoamérica; Algunos hombres buenos, en España) es una película estadounidense de dirigida por Rob Reiner e interpreada por Tom Cruise, Jack Nicholson, Demi Moore, Kiefer Sutherland, Kevin Bacon y Kevin Pollak en los papeles principales. Está basada en la obra teatral homónima de Aaron Sorkin, el cual también escribió el guion de la película. 

Ha sido galardonada con seis premios cinematográficos estadounidenses y fue candidata a cuatro Premios Óscar: a la mejor película, al mejor actor de reparto (Jack Nicholson), al mejor sonido y al mejor montaje. Forma parte del AFI's 10 Top 10 en la categoría de "Películas judiciales".

Dos abogados militares, Daniel Kaffee (Tom Cruise) y Sam Weinberg (Kevin Pollak), deben defender en un juicio a dos marines. Según la acusación, ellos han matado a un compañero. Ellos mantienen, sin embargo, que cumplieron órdenes del coronel Nathan R. Jessep (Jack Nicholson) para castigar a su compañero, el soldado William T. Santiago, por haber infringido el código de honor del Cuerpo de Marines. La defensa se encuentra con grandes dificultades para averiguar la verdad por los obstáculos que pone el coronel.

La película relata la muerte del soldado Santiago como consecuencia de la aplicación de una sanción disciplinaria, llamada "Código Rojo", en forma accidental por un soldado y un cabo. El caso, sucedido en la base de Marines de Guantánamo, Cuba, conmueve a la plana mayor del ejército y un joven abogado, brillante como litigante, Daniel Kaffe, debe tomar la defensa del caso. Por información de Asuntos Internos, él se notifica que pudo haber sido aplicado un Código Rojo, cosa que no figura en ningún manual, pero obviamente se aplica.

El caso desorienta a Kaffe y a sus colaboradores Sam Weimberg y Joan Gallaway (Demi Moore), y se postula un caso de Obediencia Debida (el oficial de menor rango tiene que obedecer al de mayor rango, aunque no tenga lógica), cosa que el fiscal, el capitán Jack Ross (Kevin Bacon), amigo de Kaffe, tratará de demostrar que no existe.

Uno de los coroneles, Matthew Markinson (J.T. Walsh), decide traicionar esa norma implícita en el medio del juicio, y es por ello que se inicia un proceso que toma al teniente John Kendrik (Kiefer Sutherland) y hasta al coronel Jessep.

En una entretejida madeja se deben descubrir, entre muchos interrogantes planteados, si Santiago fue envenenado, por qué se lo hizo y si realmente corría peligro su vida permaneciendo en un lugar en el que no soportaría el riguroso entrenamiento de la base cubana.

La historia relatada muestra hasta qué punto se tiene honor en la milicia y hasta donde podemos llevarlo, contra qué lo sostenemos, si estamos en condiciones de actuar éticamente ante presiones externas y cuánto conocemos sobre los que gobiernan nuestras fuerzas armadas.

Curiosidades:


La película fue un gran éxito de taquilla. También recibió críticas generalmente muy positivas.




</doc>
<doc id="27903" url="https://es.wikipedia.org/wiki?curid=27903" title="True Romance">
True Romance

True Romance (en Argentina: "Escape salvaje", en España: "Amor a quemarropa", en México: "La Fuga") es una película estadounidense, dirigida por Tony Scott y estrenada en 1993.

El solitario Clarence (Christian Slater) está celebrando su cumpleaños como de costumbre, viendo una sesión triple de películas de artes marciales en un destartalado cine. Entonces entra la rubia y explosiva Alabama (Patricia Arquette) y derrama sus palomitas sobre Clarence. La joven le cuenta más tarde que es una prostituta contratada por el jefe de Clarence para que pasase una noche divertida, pero Clarence y Alabama acaban por enamorarse e incluso por casarse. Entonces a Clarence le asaltan serias dudas sobre el pasado de Alabama y su "protector" el temible y violento "Drexl" (Gary Oldman). De modo que va al club a recoger las cosas de Alabama. Cuando abre la maleta ya en su apartamento, descubren que está llena de droga; la cual por un lado, ellos pretenden vender y por otro lado, los socios de Drexl pretenden recuperar.

Desde finales de los años 1980, Quentin Tarantino y su agente personal, Cathryn James, llevaban tiempo ofreciendo el guion de "True Romance", obteniendo solo respuestas negativas. Luego de un año, el guion captó el interés de Stanley Margolias, un productor que llevaba dos películas en su haber. Les prometió conseguir un contrato a cambio de una retribución; sin embargo, obtuvo respuestas igual de tibias que el dúo. Luego de un decepcionante año, mediados de 1990, Margolias logró que Tony Scott se interesase en dirigir la película. 




</doc>
<doc id="27905" url="https://es.wikipedia.org/wiki?curid=27905" title="Mancomunidad de Cataluña">
Mancomunidad de Cataluña

La Mancomunidad de Cataluña (en catalán, "Mancomunitat de Catalunya") fue una institución que agrupó, entre 1914 y 1925, las cuatro diputaciones catalanas en un único ente regional.

Promovida por el dirigente de la catalanista Liga Regionalista Enric Prat de la Riba, la Mancomunidad de Cataluña fue creada por un Real Decreto del gobierno español de marzo de 1914. «Era la primera grieta, fuera del ámbito vasco-navarro, en el rígido esquema territorial que, salvo el breve paréntesis de 1873-1874, había caracterizado al Estado desde la Constitución de 1812»: por esta razón provocó un rechazo no solo entre la derecha española, sino también entre los socialistas que la consideraron un instrumento al servicio de la «burguesía catalana».

Fue disuelta en 1925 por la dictadura de Primo de Rivera.

En 1911 Enric Prat de la Riba, presidente de la Diputación Provincial de Barcelona desde 1907 y uno de los dos líderes de la Lliga Regionalista junto con Francesc Cambó, decidió impulsar una vieja reivindicación catalanista, que aparecía también en el programa de la coalición "Solidaritat Catalana" que ganó las elecciones generales de 1907 en Cataluña: aglutinar las cuatro diputaciones catalanas en un único ente regional. El 16 de octubre los cuatro organismos provinciales aprobaron conjuntamente las "Bases de Mancomunidad Catalana" que preveía la formación de una asamblea formada por todos los diputados provinciales y de un consejo permanente de ocho miembros, dos por provincia. Mes y medio después el proyecto de Bases fue entregado al presidente del gobierno José Canalejas y lo presentó el 1 de mayo de 1912 a las Cortes como proyecto de Ley de Mancomunidades. Sin embargo, un sector de su propio partido, encabezado por Segismundo Moret y apoyado por el diputado Niceto Alcalá Zamora, se opuso al proyecto. 

Para conseguir el respaldo de la mayoría de los diputados liberales, Canalejas tuvo que pronunciar uno de sus mejores discursos parlamentarios, a pesar de lo cual diecinueve de sus diputados, incluido Moret, votaron en contra. El proyecto fue aprobado el 5 de junio de 1912 por la Cámara baja. No obstante, cuando Canalejas fue asesinado, todavía no había sido ratificado por el Senado. Finalmente, la ley entró en vigor en diciembre de 1913, y la Mancomunidad de Cataluña se constituyó a principios de 1914.

Para apoyar la petición presentada por los diputados provinciales y los parlamentarios catalanes de que se constituyera la Mancomunidad, las cuatro diputaciones catalanas organizaron en 1913 un plebiscito de todos los ayuntamientos catalanes a favor del proyecto, que estuvo acompañado de una gran manifestación celebrada en Barcelona el 23 de octubre del mismo año. 

Fue el político conservador Eduardo Dato quien promulgó el Real Decreto por el cual se autorizaba la unión de las diputaciones con fines puramente administrativos. El 18 de diciembre de 1913 el rey firmó el . A pesar de que la ley era aplicable a todas las provincias españolas, solo las cuatro catalanas llegaron a ver aprobada la Mancomunidad de Cataluña. Hubo otras propuestas, como el proyecto de Mancomunidad Valenciana, que no pasó de esta fase. Y también hubo numerosas reacciones por parte de entidades públicas españolas contra esta singularidad catalana como, por ejemplo, el texto elaborado por la Asamblea de las Diputaciones castellano-leonesas de 24 de enero de 1919.

La Mancomunidad se constituyó el 6 de abril de 1914 bajo la presidencia de Enric Prat de la Riba, presidente de la Diputación de Barcelona y de la Lliga Regionalista. Según su propio estatuto, la Mancomunidad de Cataluña constaba de una Asamblea General, formada por 96 diputados de las cuatro diputaciones; la Presidencia, ocupada por el presidente de la Diputación Provincial de Barcelona; y el Consejo permanente, que incluía las siguientes consejerías: Caminos y Puertos, Cultura e Instrucción, Agricultura y Servicios Forestales, Beneficencia y Sanidad, Obras hidráulicas y Ferrocarriles, Teléfonos, Política Social, y Hacienda. 

Las cuatro diputaciones catalanas cedieron sus competencias a la Mancomunidad pero, en contra de lo esperado por la Lliga Regionalista, el Estado no cedió ninguna de las suyas. A pesar de todo, la Mancomunidad «puso en evidencia cómo una gestión honesta y atenta a las necesidades del territorio podía ser eficaz pese a disponer de escasos recursos. Realizó una importante tarea educativa y cultural fundando escuelas técnicas (de agricultura, industrial, del trabajo, de bibliotecarias, de administración) o creando instituciones de alta cultura (Institut d'Estudis Catalans, Biblioteca de Catalunya), al tiempo que fomentaba obras de infraestructuras impulsando las redes de carreteras, de teléfonos y los servicios de asistencia social». De esta forma «se incrementó el sentimiento autonomista en amplias capas de la sociedad». Además, con el apoyo de los ayuntamientos, mejoró el suministro de agua potable, impulsó la formación profesional, promovió la creación de una red de bibliotecas, reconoció la normativa ortográfica impulsada por Pompeu Fabra y estimuló la renovación pedagógica.

La relevancia de la Mancomunitat también residía en «su carácter simbólico al representar en una única institución a la totalidad de las provincias catalanas, la primera experiencia de autogobierno desde el Decreto de Nueva Planta, cuyo aniversario Prat de la Riba no olvidó mencionar en su discurso inaugural del 6 de abril de 1914. Se trataba de una baza que la Lliga no dejaría escapar. El naciente e importante órgano administrativo ayudaría a desarrollar una conciencia catalanista y constituía una primera base con vistas a una futura autonomía de más largo abasto». Y por otro lado «la Mancomunidad de Cataluña también evidenciaba el giro de la Lliga hacia un pragmático pactismo, ofreciendo apoyo parlamentario al Gobierno de turno a cambio de concesiones concretas, una estrategia del catalanismo conservador que reencontraremos nuevamente tras la Transición. Prat de la Riba permanecía en Barcelona transformado en hombre de gobierno, mientras Francesc Cambó se convertía en el líder parlamentario en Madrid. La Lliga se hallaba en su momento más dulce».

Según Jordi Canal el proyecto de Prat de la Riba al frente de la "Mancomunitat" fue «construir la nación catalana» para lo que se propuso dotarla de «estructuras de estado», centrándose especialmente en el campo de las infraestructuras y el de la cultura. Para Prat de la Riba ningún pueblo de Cataluña debía estar sin una carretera, sin teléfono y sin escuela con biblioteca.

A fin de conseguir una capacidad legislativa de la que carecían, Francesc Cambó, líder de la Lliga tras la muerte de Prat de la Riba en 1917, lideró la redacción de un Proyecto de estatuto para Cataluña. Este estatuto, redactado por la Mancomunidad y por los parlamentarios catalanes, fue aprobado el 26 de enero de 1919 pero rechazado posteriormente por las Cortes españolas.

La Mancomunidad de Cataluña fue presidida por Prat de la Riba desde 1914 hasta su fallecimiento el 1 de agosto de 1917. Tras la presidencia interina de Román Sol, le sucedió Josep Puig i Cadafalch que ganó la votación, por 48 votos contra 39, al político dinástico leridano Joan Rovira.

El 24 de diciembre de 1923 dimitió Josep Puig i Cadafalch en señal de protesta por la política anticatalanista de la Dictadura de Primo de Rivera, instaurada tres meses antes, y se exilió en Francia. El 12 de enero de 1924 Primo de Rivera disolvió todas las diputaciones provinciales, salvo las forales ya que según él el regionalismo podía contribuir a "deshacer la gran obra de unidad nacional". Inmediatamente después fueron designados por los gobernadores civiles los nuevos diputados provinciales, todos ellos "españolistas" y el líder de la Unión Monárquica Nacional, Alfonso Sala Argemí, conde de Egara, pasó a presidir la "Mancomunitat". En el discurso de toma de posesión Alfons Sala dijo:
La Asamblea de la Mancomunidad estaba presidida por el marqués de Marianao y en el Consejo permanente destacaba Darío Romeu, barón de Viver, "conseller" de cultura de la Mancomunidad y que sería nombrado alcalde de Barcelona por Primo de Rivera.

Sin embargo a los pocos meses comenzaron las tensiones entre Sala y Primo de Rivera ya que el dictador empezó a cuestionar la existencia misma de la Mancomunidad, porque temía que en otras manos, "tendenciosas", fuera el embrión de "un pequeño Estado", "capaz de dañar a España". Así se lo expuso Primo de Rivera a Sala en una carta que le envió en agosto de 1924:
Las críticas del dictador arreciaron en los primeros meses de 1925. En marzo habló claramente del "fracaso de la Mancomunidad como órgano político permanente, deliberante y ejecutivo". y ese mismo mes aprobó el Estatuto Provincial de 1925 que supuso la supresión de facto de la "Mancomunitat", cuyas competencias el Estatuto Municipal de 1924 ya había recortado considerablemente. En una larga "nota oficiosa" que acompañó al decreto de creación del Estatuto Provincial reconoció que había cambiado de opinión sobre el "regionalismo", pues antes pensaba que éste podía ser positivo para la regeneración de España, pero ahora se había dado cuenta de que «reconstruir desde el poder la región, reforzar su personalidad, exaltar el orgullo diferenciativo entre unas y otras es contribuir a deshacer la gran obra de la unidad nacional, es iniciar la disgregación, para la que siempre hay estímulo en la soberbia o el egoísmo de los hombres».Refiriéndose concretamente a la Mancomuniad en la "nota oficiosa" se decía:
Alfons Sala intentó mantener aún ciertas funciones de la Mancomunidad al frente de la comisión coordinación de las cuatro diputaciones provinciales, pero cuando comprendió que "no podría convertirse en una nueva versión de la "Mancomunitat"" dimitió el 22 de abril de 1925. El nuevo presidente de la Diputación de Barcelona, José María Milá Camps, conde de Montseny, presidió la "Comisión gestora interina de los servicios coordinados" que fue la encargada de liquidar los últimos asuntos de la Mancomunidad. Primo de Rivera justificó más tarde la disolución de la "Mancomunitat" diciendo que se había convertido en el catalizador de un «verdadero nacionalismo que cada día amenazaba más las raíces y los fundamentos de la verdadera nacionalidad española».

La Diputación de Barcelona se convirtió entonces en el principal instrumento de la política de la Dictadura en Cataluña, contando con José María Milá Camps, conde de Montseny, en la presidencia y con Olano y Olázaga, conde de Fígols en la vicepresidencia. La Diputación desplegó una campaña españolista que incluía conferencias patrióticas, ceremonias de exaltación de España y "cursos de ciudadanía".

En conclusión, como ha destacado el historiador Shlomo Ben Ami, "el espíritu unitario de Primo de Rivera había prevalecido, finalmente, al eliminarse la "pesadilla" de la Mancomunidad y sentarse los fundamentos de un nuevo e inflexible Estado unitario".






</doc>
<doc id="27911" url="https://es.wikipedia.org/wiki?curid=27911" title="Asamblea de Cataluña">
Asamblea de Cataluña

La Asamblea de Cataluña (en catalán "Assemblea de Catalunya") fue un organismo unitario de la oposición antifranquista de Cataluña creado en noviembre de 1971. Sus reivindicaciones fundamentales fueron la exigencia de libertades democráticas, la amnistía general para los presos políticos y la consecución del estatuto de autonomía, que quedaron sintetizadas en el célebre lema de "Llibertat, Amnistia, Estatut d'Autonomia". Además de los partidos políticos —todos ellos clandestinos—, formaron parte de ella fuerzas de diversa índole, como organizaciones sindicales, grupos profesionales, representantes del movimiento universitario, del movimiento vecinal, grupos confesionales cristianos, asambleas comarcales, etc., de ahí el enorme eco social que tuvo. Los objetivos de la Asamblea se alcanzaron durante la transición democrática especialmente cuando las Cortes aprobaron el Estatuto de Autonomía de Cataluña de 1979. 

Habiendo conseguido sobrevivir a la dura represión de las dos primeras décadas de la dictadura, la oposición antifranquista resurgió a partir de 1960. El acto "fundacional", en cuanto al catalanismo político, se suele situar en los sucesos del Palau de la Música de Barcelona de mayo de 1960, durante los cuales el público asistente a un acto celebrado en el Palacio de la Música Catalana presidido por varios ministros franquistas cantó el "Cant de la senyera", que funcionaba como himno alternativo al prohibido "Els Segadors". Como presunto responsable de la protesta fue detenido, juzgado y condenado por un tribunal militar a siete años de cárcel Jordi Pujol, a quien también se acusó de ser el autor del panfleto "Us presentem al general Franco".

En esos años el partido de oposición con mayor implantación fue el PSUC y el primer acontecimiento político importante fue "La Capuchinada" de 1966, así llamada por el convento de los capuchinos de Sarrià que la policía rodeó para proceder a detener a los promotores del ilegal y clandestino Sindicato Democrático de Estudiantes de la Universidad de Barcelona que estaban allí reunidos junto con un grupo de intelectuales, quienes entre otras cosas reivindicaban el deber de las universidades de «acoger a las lenguas y culturas nacionales y responsabilizarse de su desarrollo y consolidación».

Como consecuencia de las acciones emprendidas para conseguir la libertad de los detenidos en la "Capuchinada", se fundó la "Taula Rodona", un organismo que agrupaba a toda la oposición antifranquista y del que también formó parte el PSUC, por primera vez desde el final de la Guerra Civil, precedente de la Coordinadora de Forces Polítiques de Catalunya, fundada en 1969 e integrada por el Front Nacional de Catalunya, el Moviment Socialista de Catalunya, Unió Democrática de Catalunya y el PSUC. En su manifiesto fundacional la Coordinadora reclamó la amnistía y las libertades políticas y sindicales, así como el restablecimiento del Estatuto de Autonomía de 1932 y la convocatoria de Cortes constituyentes, como paso previo al reconocimiento del derecho de autodeterminación que se extendía a todos los pueblos del Estado español. Con la fundación de este organismo unitario de toda la oposición y la presentación de un programa conjunto «el antifranquismo catalán [se situó] a la cabeza de la oposición española».

Como medio de protesta por el proceso de Burgos la Coordinadora organizó en diciembre de 1970 una "Assemblea d'Intel•lectuals" celebrada en el Monasterio de Montserrat, cuyo éxito condujo a la formación en noviembre del año siguiente de la Asamblea de Cataluña, «la creación más original y culminante del antifranquismo catalán». Además de los partidos de la Coordinadora se integraron en ella el PSAN —una escisión del Front Nacional de Catalunya—, el PSOE, los sindicatos CC OO y UGT, así como diversos colectivos profesionales y sociales, además de entidades legales y personas independientes. 

El programa de la Asamblea se sintetizó en el lema "Llibertat, Amnistía, estatut d'autonomia" que alcanzó una gran popularidad —su primera campaña "Per què l'Estatut de 1932?" iniciada en mayo de 1972 obtuvo un notable éxito—, extendiendo su influencia por todo el territorio catalán con más de 40 delegaciones, a pesar de que su comisión permanente fue detenida por la policía en 1973 (113 personas) y en 1974 (67 personas). «Su mayor éxito fue sacar la reivindicación democrática y nacionalista del gueto de los partidos a la calle constatando su implantación social. La Assemblea invirtió la situación: hasta entonces los grupos clandestinos tenían que eludir la represión, con ella el problema era del Gobierno que tenía que combatir en la calle una plataforma ilegal y provocadora, que atraía un número creciente de ciudadanos». Y por otro lado «condenó al fracaso inmediato, faltas de todo tipo de apoyo social, las tentativas de constituir grupos de lucha armada a imagen de ETA como el Front d'Alliberament de Catalunya (FAC), fundado en 1969, que realizó diversos atentados terroristas hasta 1971, la Organització de Lluita Armada (OLLA) surgida en 1972 o el Exèrcit Popular Català (EPOCA), bautizado con este nombre por las notas policiales».

Un momento crítico en la historia de la Asamblea fue la "Caiguda dels 113"' ('Caída de los 113'). El 28 de octubre de 1973 la policía franquista detuvo en la Parroquia de Santa María Mitjancera de la ciudad de Barcelona a 113 personas, representantes de partidos políticos y sindicatos clandestinos pero también de colegios profesionales y asociaciones de vecinos. Inmediatamente se inició en Cataluña una gran movilización ciudadana de apoyo a los detenidos y se inició una campaña de solidaridad que tuvo resonancia internacional.

Tras la muerte del general Franco en noviembre de 1975, la Asamblea de Cataluña incrementó su campaña a favor de la "Llibertat, Amnistia i Estatut d'Autonomía" que se tradujo en las dos manifestaciones celebradas en Barcelona los días 1 y 8 de febrero de 1976 y que fueron duramente reprimidas por la policía. Aprovechando el mayor margen de libertad otorgado por el nuevo gobierno de Adolfo Suárez formado en julio, se organizó a lo largo del verano de ese año la "Marxa de la Llibertat" impulsada por el sacerdote Lluís Maria Xirinacs —que resultaría elegido senador en las primeras elecciones democráticas de junio de 1977— que recorrió no sólo Cataluña sino también Valencia y Baleares con el lema "Poble català, posa't a caminar" y que en ocasiones fue reprimida por la policía. Sin embargo el protagonismo de la lucha por las libertades pasó a los partidos políticos que en diciembre de 1975 habían constituido el Consell de Forces Polítiques de Catalunya, sucesor de la Coordinadora. Fue este organismo el que negoció con el gobierno de Suárez la conmemoración del primer 11 de septiembre en libertad desde el final de la guerra civil. El permiso fue concedido en el último momento y aun así más de 100.000 personas se reunieron en San Baudilio de Llobregat, lugar de nacimiento del "conseller en cap" de 1714 Rafael Casanova, mientras que las manifestaciones convocadas en otras localidades eran brutalmente reprimidas por la policía.

Los cuatro puntos programáticos de la Asamblea de Cataluña fueron los siguientes:

La Asamblea de Cataluña se disolvió tras la celebración de las elecciones generales de junio de 1977 que en Cataluña arrojaron un resultado diferente al resto de España, ya que ganó la izquierda: el Partit Socialista de Catalunya-Congrés, coaligado con el PSOE, fue la fuerza más votada, y obtuvo 15 diputados; el PSUC, 8; y la coalición Esquerra de Catalunya, encabezada por Esquerra Republicana de Cataluña, que no pudo presentarse con sus propias siglas a las elecciones, 1. El partido del gobierno Unión de Centro Democrático (UCD), que ganó en toda España, quedó en tercer lugar con nueve escaños, siendo superado no solo por el PSC-C (PSOE) sino también por el Pacte Democràtic per Catalunya encabezado por Convergència Democràtica de Catalunya, un partido fundado por Jordi Pujol en 1974 que aglutinaba al catalanismo progresista de raíz católica. El resultado en el Senado fue aún más contundente pues la coalición de la izquierda Entesa dels Catalans consiguió los doce escaños a los que optaba, y al grupo se sumaron otros tres senadores independientes, sumando un total de 15 sobre los 16 que le correspondían a Cataluña.
Diez días después de celebrarse las elecciones se constituía la "Assemblea de Parlamentaris", que reunía a todos los diputados y senadores catalanes, que reclamó la restauración del Estatuto de Autonomía de 1932.



</doc>
<doc id="27912" url="https://es.wikipedia.org/wiki?curid=27912" title="Santa Ana">
Santa Ana

Santa Ana hace referencia a varios artículos:

























</doc>
<doc id="27920" url="https://es.wikipedia.org/wiki?curid=27920" title="Lluís Companys">
Lluís Companys

Lluís Companys i Jover (Tarrós, 21 de junio de 1882-Barcelona, 15 de octubre de 1940) fue un político y abogado español, de ideología catalanista y republicana, líder de Esquerra Republicana de Catalunya, ministro de Marina de España en 1933 y presidente de la Generalidad de Cataluña desde 1934 hasta 1939. Exiliado tras la Guerra Civil, fue capturado en Francia por la Gestapo, a petición de la policía franquista, y trasladado a España, donde fue torturado, sometido a un consejo de guerra y finalmente fusilado en el castillo de Montjuic.

Lluís era hijo de una familia de propietarios rurales de buena posición de la comarca de Urgel en la provincia de Lérida. Su padre, Josep Companys i Fontanet, era un hombre ilustrado y de ideas liberales. Su madre, María Luisa de Jover, era de origen noble y ascendencia aragonesa. Lluís fue el segundo de diez hermanos, de los que sobrevivieron ocho, cinco varones y tres mujeres. Con ocho años, sus padres le enviaron a estudiar, interno, a Barcelona en el prestigioso Liceo Polyglota. Allí cursó el bachillerato y conoció a Francesc Layret, dos años mayor que él.

En 1898 ingresó en la Universidad de Barcelona para estudiar Derecho. Se involucró en actividades políticas de carácter republicano, posiblemente por influencia de Layret, que también estudiaba Derecho en la universidad barcelonesa. En 1900 participó en la fundación de la Asociación Escolar Republicana en la universidad junto a Layret. También publicaron un semanario, "La defensa escolar", en el que Companys escribió sus primeros artículos. Por entonces tomó la palabra en su primer mitin político, un acto de carácter anticlerical celebrado en la plaza de toros de Barcelona.

Licenciado en 1903, ingresó en la Unión Republicana de Nicolás Salmerón. En 1906, con motivo del incendio por militares de las redacciones de las revistas catalanistas "Cu-Cut!" y "La Veu de Catalunya" y la aprobación, como consecuencia de ello, de la ley de Jurisdicciones, se formó la coalición electoral Solidaridad Catalana. Unión Republicana se dividió entre los partidarios de unirse a la coalición catalanista, encabezados por Salmerón, y los contrarios a ello que, encabezados por Alejandro Lerroux, abandonaron el partido (creando dos años después el Partido Republicano Radical). Companys, al igual que Layret y la mayor parte de la militancia de las comarcas del interior permanecieron en Unión Republicana y se unieron a Solidaridad Catalana. A pesar de su éxito en las elecciones de 1907, la coalición evidenció pronto su debilidad, desapareciendo después de la Semana Trágica (1909), debido a la heterogeneidad y diversidad de intereses de sus integrantes. En la represión posterior a la Semana Trágica, Companys fue detenido por primera vez siendo liberado al no serle imputado ningún cargo.

En 1909 la debilitada Unión Republicana, circunscrita básicamente ya a Cataluña, se coaligó con el Centre Nacionalista Republicà y los federales en una alianza electoral que se presentó a las elecciones de 1910. En abril de 1910, a iniciativa de Joaquim Lluhí, se convirtió en un único partido, la Unión Federal Nacionalista Republicana. Companys fue nombrado presidente de su sección juvenil. Como consecuencia de su intensa actividad juvenil fue detenido quince veces siendo calificado de «individuo peligroso» en los informes policiales.

El 17 de octubre de 1910 Companys contrajo matrimonio con su primera mujer, Mercé Micó, con la que tuvo dos hijos, Lluís Companys i Micó (Lluïset), nacido en 1911, y Maria de l'Alba (igual que una de sus tías paternas), nacida en 1915. Su hijo mayor manifestó durante su juventud síntomas de esquizofrenia que se agravaron y complicaron en la edad adulta con una tuberculosis ósea. La enfermedad de su hijo mayor fue siempre fuente de preocupación para Companys.

La Unión Federal Nacionalista Republicana tuvo su mayor éxito en las elecciones de 1910 en las que obtuvo once diputados. Sin embargo la muerte de su líder, José María Vallés, en 1911, produjo la desbandada del partido en 1912. Este hecho coincidió con la creación del Partido Reformista de Melquíades Álvarez, en el que ingresó el ala menos nacionalista de la UFNR, entre cuyos integrantes se encontraba Companys. También entró en la órbita del reformismo en el periódico republicano "La Publicidad", para el cual trabajó Companys desde 1904 en la sección de política municipal barcelonesa. Allí coincidió con José Zulueta, Laureano Miró y Eusebio Corominas. Durante esa época, el periodismo constituía la mayor fuente de ingresos de Companys. También fue el fundador de los semanarios "La Aurora" y "La Barricada", del que fue redactor jefe en 1912.

En 1913 fue candidato en Barcelona del Partido Reformista en las elecciones municipales en el distrito Sants-Les Corts, sin resultar elegido. Al año siguiente abandonó el reformismo aunque mantuvo su vinculación con "La Publicidad". En esta publicación coincidió en 1915 con Marcelino Domingo (director del periódico, del que Companys era redactor jefe), con el que mantendría una relación muy estrecha y compartiría trayectoria política hasta el advenimiento de la República. En mayo de ese año, Domingo, Companys y Layret crearon el Bloc Republicà Autonomista (BRA), el cual se presentó a las elecciones del año siguiente. Domingo se presentó candidato por el distrito de Tortosa, en Tarragona, del que era natural, en tanto que Companys, encabezando una «candidatura republicana obrera», lo hacía por Roquetas, distrito próximo al tortosino. Domingo resultó elegido, en tanto que Companys fue derrotado por un amplio margen por el candidato dinástico liberal. Esta candidatura de Companys fue la primera candidatura republicana en aquel distrito.

Hasta entonces había trabajado como periodista. En junio de 1916 hizo los ejercicios de grado y recibió el título de licenciado en Derecho, inscribiéndose en el Colegio de Abogados de Barcelona. Después de trabajar como pasante en dos bufetes, comenzó a ejercer como abogado laboralista de militantes obreros y otros clientes sin recursos. Paralelamente, Companys continuó su labor periodística. En septiembre de 1916, Companys, Layret y Domingo fundaron un nuevo periódico, "La Lucha", como órgano de expresión del BRA. Companys era el redactor jefe y responsable de la información política, Domingo el director y Layret era el financiador de la empresa.

En abril de 1917, el BRA se fusionó con más de 150 formaciones para formar el Partit Republicà Català (Partido Republicano Catalán, PRC). "La Lucha" se convirtió en su órgano de expresión. Muy ideologizado y combativo, en ella publicaron líderes obreros y socialistas como Pablo Iglesias o Miguel de Unamuno. "La Lucha" se opuso rotundamente a la guerra de Marruecos, abogaba por la autonomía catalana (el PRC fue uno de los principales defensores del proyecto de estatuto de autonomía catalán de 1919) y la causa aliada en la Primera Guerra Mundial. Todo ello llevó a la publicación a tener frecuentes problemas con la censura.

Durante 1917, el PRC había participado en la Asamblea de Parlamentarios, una reunión de la mayoría de los parlamentarios catalanes (salvo los de los partidos dinásticos) que, con las Cortes cerradas, propugnaba la convocatoria de elecciones a Cortes Constituyentes, de cara a una nueva organización del Estado que reconociera la autonomía de las regiones. Sin embargo, la disolución de la Asamblea por parte del gobierno y la huelga revolucionaria de 1917 hizo que la conservadora Lliga Regionalista se apartase de sus aliados republicanos. Ante ello, estos se presentaron unidos en la convocatoria de elecciones municipales de noviembre de 1917. Companys resultó elegido concejal por el distrito barcelonés del Raval dentro de una candidatura radical. Sus posturas políticas estaban entonces lejos del catalanismo. Tal como narra el historiador Hilari Raguer, al ser también elegido Manuel Carrasco Formiguera como concejal en Barcelona, Companys se negó a dejarle pasar alegando que era un separatista y que debía gritar primero "¡Viva España!".

Los años que trascurrieron entre 1917 y 1922 fueron de una extrema violencia social en Barcelona. Fue la época del pistolerismo en los que se enfrentaron, de una parte, los sectores más violentos del anarcosindicalismo, partidarios de la "acción directa" y de otra escuadrones de pistoleros pagados por los empresarios, con la intervención de la represión estatal en apoyo de los patronos. Todo ello se saldó con centenares de muertos, en su mayoría obreros. Ejerció entonces, junto a su amigo Layret, como abogado defensor de numerosos sindicalistas aproximándose al anarcosindicalismo. También retomó una antigua amistad de la infancia con Salvador Seguí (el «El Noi del Sucre»), el cual había nacido en Tornabous, pueblo vecino de Tarrós. El padre de Seguí trabajaba para la familia de Companys, y ambos habían compartido juegos infantiles. En 1918, en un ambiente de huelgas generalizado, el gobierno decretó el estado de excepción y, entre otros muchos, Companys permaneció detenido durante varios días. En febrero de 1919 comenzó la huelga de La Canadiense, que duró casi dos meses y desembocó en una huelga general. Companys intervino en las negociaciones entre huelguistas y patronos, convencido de la necesidad de establecer alianzas entre el obrerismo anarquista y la izquierda republicana autonomista. Companys trató de involucrar al gobierno en la negociación y, ante su negativa, intentó que fuese el ayuntamiento de Barcelona, del que era concejal, el que mediara. La negativa del alcalde hizo que Companys tildara al consistorio de "esquirol", razón por la que fue encarcelado durante un mes. La radicalización y el acercamiento a los postulados obreristas por parte de Companys y Layret se acentuó durante ese año. En septiembre, ambos solicitaron la adhesión del PRC a la III Internacional. Aunque la solicitud nunca se materializó, el movimiento significó que abandonaron el partido los sectores más centristas y nacionalistas.

En diciembre de 1919 y enero de 1920 se produjo un cierre patronal en Barcelona, hecho que marcó el triunfo de la patronal en el conflicto social. En noviembre ese año, el gobernador civil Martínez Anido había ordenado la detención de los dirigentes obreros. Companys, junto a Salvador Seguí, Martí Barrera, Josep Viadiu, entre otros sindicalistas, fue encarcelado. El 30 de noviembre, tres días después de su detención, y con otros treinta y cinco presos, fue deportado al castillo de la Mola en Mahón (Islas Baleares). Layret fue asesinado cuando se disponía a asumir su defensa. A pesar de su deportación, en las elecciones legislativas de diciembre de 1920 Companys fue elegido diputado por Sabadell en la candidatura del PRC en el lugar que debía ocupar el fallecido Layret, que ostentaba el escaño, logrando la inmunidad parlamentaria, lo que le libró de la cárcel. Paralelamente, Companys siguió con sus labores periodística. Aunque "La Lucha" había tenido que cerrar en junio de 1919, tras salir de la cárcel se hizo con la dirección del diario republicano "L'Avenir" de Sabadell, fundado por Layret y en el que ya colaboraba. Durante 1922, fue uno de los impulsores de la Unió de Rabassaires, un sindicato de viticultores no propietarios que también expandió su ámbito de acción a aparceros y arrendatarios, así como fundador de su órgano de expresión, el bisemanario "La Terra", del que también sería director. El apoyo de la Unió fue trascendental para revalidar su escaño por Sabadell en las elecciones de abril de 1923.

En septiembre de 1923, el general Miguel Primo de Rivera, capitán general de Cataluña, dio un golpe de Estado con el apoyo del ejército y la aprobación del rey Alfonso XIII. La dictadura duró más de seis años. Durante la misma, Companys centró sus esfuerzos en potenciar la Unió de Rabassaires, de la que fue abogado asesor desde 1925. El sindicato prestó su apoyo a la Alianza Republicana, el órgano de coordinación de partidos y fuerzas de oposición a la dictadura y a la monarquía de Alfonso XIII, al que pertenecía el PRC, con Marcelino Domingo como representante. Creada en 1926 tenía al líder radical Alejandro Lerroux como figura destacada. Companys fue uno de los dirigentes republicanos que participaron en el homenaje que recibió Lerroux en Barcelona en junio de 1926. Sus actividades opositoras no se limitaron a la acción política y sindical: en enero de 1929 Companys participó desde Barcelona en la fallida intentona insurreccional promovida por Sánchez Guerra (precisamente quien, como presidente del Consejo de Ministros, había destituido a Martínez Anido en 1922), por lo que fue detenido y pasó tres meses en prisión. En diciembre fue uno de los firmantes del manifiesto que publicó el PRC en pro del entendimiento entre las fuerzas republicanas catalanas y su coordinación con los republicanos del resto de España. Fruto de este llamamiento, y de la acción del grupo de intelectuales catalanistas agrupados en torno al semanario "L'Opinió", fue la firma, en mayo de 1930, del Manifiesto de Inteligencia Republicana por parte de representantes de los grupos republicanos y de izquierdas catalanes de todas las tendencias, incluyendo a representantes de la CNT. Entre los firmantes del manifiesto se encontraba Companys. Pocos días después, el Partido Republicano Radical Socialista (PRRS), fundado el año anterior, entre otros, por Marcelino Domingo, correligionario de Companys en el PRC, publicó su primer manifiesto al que Companys se adhirió.

La firma del Manifiesto de Inteligencia Republicana no fructificó en un frente o coalición electoral debido a las divergencias entre las organizaciones firmantes. Por ello en octubre de 1930 Companys y otros miembros de su partido, así como republicanos independientes, hicieron un llamamiento en "L'Opinió" para la convocatoria de una Conferencia de Izquierdas Catalanas. La conferencia se celebró en Barcelona entre el 17 y el 19 de marzo de 1931. En ella participaron Estat Català (después de superar las reticencias iniciales y tras el retorno del exilio de su líder, Francesc Macià, el Partit Republicà Català, el grupo formado en torno a "L'Opinió", así como diversos grupos republicanos de las comarcas catalanas, antiguos núcleos federales, algunos radicales y otros grupos nacionalistas de reciente creación. Aunque Companys fue el presidente de la comisión organizadora de la conferencia, no pudo asistir al haber una orden de detención en contra suya, lo que le obligó a enviar su discurso de apertura para ser leído en la conferencia. En ella se debatieron varias ponencias. La relativa al problema agrario había sido coescrita por Companys.

De la conferencia nació un nuevo partido, en el que se integraron las personas y organizaciones existentes: Esquerra Republicana de Catalunya (ERC). Companys fue elegido miembro de la ejecutiva del partido. ERC era un partido interclasista, que incluía en su seno desde "rabassaires" del mundo rural a sectores del proletariado industrial pasando por la pequeña burguesía. La posición política de Companys, fundador de la Unió de Rabassaires y abogado de numerosos dirigentes anarcosindicalistas, podría ser uno de los factores de este amplio espectro social. Políticamente, ERC incluía tendencias independentistas, provenientes del Estat Catala de Macià, el republicanismo federal de Companys o el izquierdismo del grupo de "L'Opinió".

Después de la formación de Esquerra Republicana, se le planteó al nuevo partido el dilema de concurrir o no a las inminentes elecciones municipales del 12 de abril de 1931. Las distintas tendencias dentro del partido tenían posturas diferentes y Companys logró convencer a los abstencionistas, encabezados por Macià y el sector procedente de Estat Català de la necesidad de participar. La propuesta de Esquerra era encabezar candidaturas conjuntas republicanas catalanistas, pero la negativa de Acció Catalana Republicana a unirse a Esquerra en una coalición en Barcelona, hizo que finalmente solo Unió Socialista de Catalunya participara en la candidatura de Esquerra Catalana. Diseñadas las candidaturas, Companys formó parte de la lista al ayuntamiento de Barcelona por el distrito VIII. Como en el resto de España, los resultados constituyeron un rotundo éxito de las candidaturas republicanas. Entre estas, la candidatura de Esquerra fue la inesperada triunfadora, obteniendo 25 concejales, entre los que se encontraba Companys, en tanto que los radicales (en una candidatura de Conjunción Republicano-Socialista con el PSOE, la UGT y los federales) obtenían 12 concejales. También resultó elegido un republicano independiente. Entre las fuerzas no republicanas solo la Lliga Regionalista con 12 concejales obtuvo representación.

Conocidos los resultados, la cúpula de ERC trató de acordar un plan de acción. La noche del lunes 13, los dirigentes del partido, con Macià al frente, se reunieron, sin llegar a decidir una estrategia, si bien aquel se mostró decidido a actuar al día siguiente. Por la mañana, Companys se reunió con varios de los concejales electos de su partido, recibiendo el grupo la orden de Macià de dirigirse al ayuntamiento, al que él también se dirigiría. Al mediodía accedió, junto con Nicolau Battestini, Josep Bertran de Quintana y Amadeu Aragay y otros, al ayuntamiento. Allí, depusieron al alcalde accidental Antonio Martínez Domingo y, tras ser aclamado como alcalde por sus compañeros y hacerse con una bandera tricolor, Companys salió al balcón que da a la plaza de San Jaime y proclamó la República a la una de la tarde. A continuación, Companys remitió un telegrama al presidente del comité revolucionario, Niceto Alcalá-Zamora: «Esta mañana, a las doce, acompañado de los concejales electos, he requerido al alcalde accidental, señor Martínez Domingo, la entrega de la vara de alcalde y del cargo, lo que ha hecho haciendo constar su protesta. Le saludo: Companys». Una hora más tarde, Macià se dirigió al ayuntamiento también y, desde el mismo balcón, a las dos y cuarto de la tarde, proclamó el «Estado catalán, que con toda cordialidad procuraremos integrar en la Federación de Repúblicas Ibéricas». Inmediatamente, Macià cruzó la plaza, entró en la Diputación Provincial (el actual Palacio de la Generalidad) y anunció que se hacía cargo de un Gobierno provisional para Cataluña, destituyendo a continuación a los máximos poderes judicial y militar del territorio. Por la tarde, se proclamaba la República en Madrid y el comité revolucionario se constituía en Gobierno provisional, bajo la presidencia de Niceto Alcalá Zamora.

Companys y los correligionarios que habían proclamado la República provenían fundamentalmente del PRC y del grupo de "L'Opinió" y formaban el ala republicana del partido, que afrontaba el hecho catalán integrando a Cataluña dentro de una solución federal. Macià, por su parte, representaba a la facción procedente de Estat Català, partidaria de la independencia de Cataluña, aun permitiendo alguna solución de tipo confederal. No obstante, la iniciativa tomada por Companys al acudir al ayuntamiento perseguía hacerse con la alcaldía, algo que no consiguió, puesto que Macià prefirió que se encargase de una función de menos exposición pública, la de gobernador civil de Barcelona. El mismo día 14 de abril, Macià envió a Companys a tomar el gobierno civil, que en la situación de confusión había sido ocupado por el radical Emiliano Iglesias. El nombramiento de Companys como nuevo gobernador civil fue aprobado por el ministro de Gobernación del Gobierno provisional de la República, Miguel Maura y refrendado oficialmente el 24 de abril. Companys siguió con la responsabilidad de gobernador civil hasta el mes de junio, cuando dimitió, siendo sustituido por Carlos Esplá. Companys declaró que abandonaba la responsabilidad de gobernador para reanudar su labor política y preparar la campaña electoral para las inminentes elecciones a Cortes Constituyentes.

La proclamación de la República Catalana por parte de Macià abrió un conflicto con el recién constituido Gobierno provisional de la República. Para resolverlo, tres días después, tres ministros del Gobierno provisional (los catalanes Marcelino Domingo y Lluis Nicolau d'Olwer, más Fernando de los Ríos) llegaban a Barcelona para negociar con Macià (un proceso en el que no participó Companys), alcanzando un acuerdo por el que Macià renunciaba a la República Catalana a cambio del compromiso del Gobierno provisional de que presentaría en las futuras Cortes Constituyentes un estatuto de autonomía para Cataluña, previamente «aprobado por la Asamblea de Ayuntamientos catalanes», y del reconocimiento del gobierno catalán, que dejaría de llamarse Consejo de Gobierno de la República Catalana para tomar el nombre de Gobierno de la Generalidad de Cataluña. La nueva Generalidad de Cataluña asumiría las funciones de las cuatro diputaciones provinciales catalanas y sería la encargada de organizar una asamblea con representantes de los Ayuntamientos hasta que no fuera elegida por sufragio universal. Esta asamblea, denominada Diputación provisional de la Generalidad se constituyó mediante elecciones indirectas realizadas el 24 de mayo entre todos los concejales catalanes y tenía dos objetivos principales: presentar la ponencia del estatuto de autonomía y organizar el plebiscito para su aprobación. Companys fue elegido miembro de la Diputación en representación del partido judicial de Sabadell. La primera reunión de la Diputación Provisional tuvo lugar el 9 de junio. En ella se eligió a los once diputados que formarían parte de la ponencia estatutaria. Companys estaba entre ellos, si bien no participó directamente en la redacción del anteproyecto, ya que se eligió una comisión redactora reducida compuesta por cinco miembros. También se eligió a la mesa de la nueva asamblea, siendo elegido Jaume Carner, independiente próximo a Esquerra, como presidente y Lluís Companys y Josep Irla, ambos pertenecientes a Esquerra, como vicepresidentes. Companys sustituiría provisionalmente a Carner en enero de 1932, cuando aquel fue nombrado ministro de Hacienda.

En las elecciones generales del 28 de junio de 1931, Companys fue elegido diputado por la provincia de Barcelona, en la lista de Esquerra Catalana, que incluía candidatos de ERC, USC e independientes, y que obtuvo una amplísima victoria sobre la Lliga. Companys fue el segundo candidato más votado en su circunscripción, tras Josep Suñol i Garriga. Marginado por Macià de posiciones de responsabilidad en Cataluña, la ejecutiva del partido decidió enviar a Companys a Madrid para liderar la representación parlamentaria catalana. En las Constituyentes, Companys ejerció la jefatura del grupo parlamentario de Esquerra desde su constitución, en julio de 1931, hasta septiembre de 1932. Fue también el presidente de la minoría catalana, grupo constituido por los diputados catalanes que apoyaban el Estatuto de autonomía de Cataluña. Aunque no quiso formar parte de la Mesa de las Cortes, formó parte de la Diputación Permanente, así como de la comisión de Reforma Agraria, prueba del interés de su partido de participar no solo en lo relacionado con la autonomía catalana. En palabras de Companys tras la constitución de las Cortes: «Los Diputados catalanes hemos venido aquí a defender nuestro Estatuto a la fraternal comprensión de los señores Diputados y a su sentido democrático; pero hemos venido también para intervenir en otras cuestiones que afectan a la grandeza de España: la Constitución, la Reforma agraria, las leyes sociales».

En las Cortes Constituyentes, Companys tuvo una participación muy relevante, llevando el protagonismo de la minoría, junto con Lluhí. En su condición de presidente de la minoría, estableció un contacto directo y personal con Macià, que era quien fijaba las posiciones que debía adoptar la minoría en las Cortes. Inicialmente Companys se mostró muy crítico con los gobiernos provisionales encabezados por Alcalá-Zamora, a los que veía muy poco audaces en su política de reformas: «en el país existe un afán nervioso y difuso de que se le gobierne revolucionariamente; hay una apetencia de reformas inmediatas y subversivas que serían constructivas, porque hoy gobernar revolucionariamente es cumplir el sentido gubernamental de la política». También protagonizó varios enfrentamientos con el ministro de Trabajo, el socialista Francisco Largo Caballero, acusándole de favorecer a la UGT, en detrimento de la CNT, con la que Esquerra mantenía un acuerdo tácito, lo que había permitido mantener la paz social en Cataluña en los primeros meses de la República. También intervino intensamente en los debates constitucionales, especialmente en los temas relacionados con la autonomía catalana. Tras el nombramiento de Manuel Azaña como presidente del Consejo de Ministros en octubre de 1931, Esquerra se convirtió en uno de los apoyos clave del gobierno, especialmente tras el abandono del Partido Radical de la coalición gubernamental, si bien no quiso entrar en el ejecutivo. Paralelamente, Companys siguió con su actividad periodística, fundando y ejerciendo la dirección de "La Humanitat", que más tarde se convertiría en el órgano oficial de Esquerra Republicana de Catalunya. Su primer número salió a la calle el 9 de noviembre de 1931. Su papel como director de "La Humanitat" le permitió conservar su influencia dentro de la dirección del partido.

En noviembre de 1931, Companys se vio salpicado por el escándalo Bloch, un polémico asunto relacionado con los contactos que el financiero francés M. Bloch (condenado por estafa) había tenido con varios parlamentarios de ERC durante una breve visita a Madrid. El asunto tuvo mucha repercusión en los medios políticos y periodísticos de toda España pidiéndose dimisiones y responsabilidades políticas. Ante ello, Companys presentó a Macià su dimisión como líder tanto del grupo de ERC como de la minoría catalana. La dimisión no fue aceptada ni por la ejecutiva del partido ni por Macià, por lo que los diputados de ERC votaron en contra de aceptar su dimisión y Companys, que se encontraba inmerso en los debates constitucionales, siguió en su puesto. Companys, al frente de su grupo, votó favorablemente la Constitución. También intervino en las deliberaciones en torno a la cuestión religiosa, apoyando la limitación de la presencia de la Iglesia católica en el ámbito público, o en las relativas al sufragio femenino, mostrándose partidario de la extensión del voto a las mujeres. También votó a favor de la reforma agraria. Desde el 6 de mayo de 1932, fecha en la que comenzó la discusión sobre el Estatuto de Cataluña en las Cortes, aprobado en referéndum por los ciudadanos catalanes pero incompatible en algunos aspectos con la nueva Constitución, hasta su aprobación el 9 de septiembre, Companys intervino activamente en los debates. A pesar de que el trámite parlamentario supuso un severo recorte del texto enviado desde Cataluña, tanto Companys como sus compañeros de la minoría catalana votaron a favor de la aprobación del estatuto.

Una vez aprobado el estatuto, el centro de la actividad política de los partidos catalanes se trasladó de las Cortes madrileñas al nuevo Parlamento que se había de constituir en Barcelona, puesto que por primera vez se había creado un espacio político autónomo en Cataluña y era preciso que cada partido consolidase su posición en este nuevo escenario. Fruto de ello es que la actividad de los diputados de Esquerra se redujo de forma drástica en el periodo posterior a la aprobación del estatuto. Al ser elegidos diputados autonómicos, muchos diputados catalanes, aunque no abandonaron su acta en las Cortes, centraron en el Parlamento de Cataluña su acción política.

En noviembre de 1932, se produjeron las elecciones al Parlamento de Cataluña, en las que Companys fue candidato de ERC por Lérida. Las elecciones dieron un triunfo arrollador a Esquerra Catalana, coalición de ERC con Unió Socialista de Catalunya, los federales, Unió Catalanista y el Partido Radical Autonomista, que obtuvo 67 de los 85 escaños en juego. Companys obtuvo escaño y el día 13 de diciembre fue elegido presidente del Parlamento de Cataluña, por una amplia mayoría (setenta votos a favor y uno en blanco, el suyo seguramente). De esta forma, Companys se convertía en la segunda autoridad de la autonomía catalana, solo después del presidente de la Generalidad de Cataluña, Francesc Macià. Además, en caso de que éste muriera o fuese destituido, Companys se convertiría automáticamente en el nuevo presidente. Companys expresó su emoción por haber sido elegido presidente del parlamento de la siguiente forma:

Tras su elección, aunque no abandonó su escaño en las Cortes, presentó su dimisión como presidente del grupo parlamentario de Esquerra Republicana, haciéndose cargo del grupo Miquel Santaló.

Su labor al frente de la cámara catalana no fue reseñable, sin desempeñar tampoco un papel institucional. Al contrario, su actuación fue marcádamente partidista, como demostraron diversas declaraciones públicas y mítines políticos en los que intervino durante la primera mitad de 1933.

Companys permaneció al frente de la cámara catalana hasta mediados de 1933, cuando la abandonó para integrarse en el gobierno de la República, el último presidido por Manuel Azaña durante la primera legislatura republicana. La crisis ministerial tuvo su origen en la grave enfermedad, un cáncer de garganta, que sufría Jaume Carner, ministro de Hacienda, elegido diputado como independiente en las candidaturas de Esquerra. Desde febrero, Azaña había supervisado la labor ministerial y, llegado junio, con el grueso de la legislación reformista ya aprobada, pidió permiso al presidente de la República, Alcalá Zamora, para sustituirle. Sin embargo, el presidente decidió abrir una crisis ministerial, en un intento de escorar hacia la derecha la coalición gubernamental. La negativa socialista a participar en un gobierno con los radicales, dejó a Azaña como único candidato a presidente del Consejo, con un gobierno en el que entraron los federales y, por vez primera, ERC. Los propósitos fundamentales de Esquerra para sostener el gobierno eran, por una parte, prolongar la legislatura temiendo un posible triunfo de las derechas en las elecciones. Por otro, presionar para conseguir el traspaso de las competencias contempladas en el nuevo estatuto. En este contexto se produjo la entrada de Companys en el gobierno, sustituyendo como ministro catalán a Carner, pero sin hacerse cargo de su cartera, sino de una de muy bajo perfil, la de Marina, para disgusto del propio Companys y de su partido, que aspiraban a conseguir la de Industria y Comercio. El grado de sintonía personal entre Azaña y Companys no era muy alto.

Companys fue Ministro de la Marina entre junio y septiembre de 1933. Ocupó la cartera con «desgana y sin interés», desarrollando una labor poco reseñable, con escasos proyectos de ley remitidos al parlamento. La salida de Companys del gobierno fue fruto de la retirada de confianza de Alcalá Zamora a Azaña, tras producirse las elecciones a vocales del Tribunal de Garantías Constitucionales. Los sucesivos gobiernos de Lerroux y Martínez Barrio, en los que participó Esquerra pero no Companys, gestionaron el país hasta la convocatoria de elecciones en noviembre de 1933. Retornado a Barcelona, Companys se volcó de nuevo en la política catalana. En octubre había presidido la clausura del II Congreso Extraordinario de ERC, apareciendo como el sucesor natural de Macià, y en noviembre fue candidato en las elecciones generales, siendo el candidato más votado por la circunscripción de Barcelona-ciudad, si bien lo fue gracias a una argucia de Francesc Cambó, que ordenó el voto de sus fieles a Companys con el objetivo de que sobrepasase el umbral del 40% y no hubiese que repetir las elecciones, según disponía la legislación electoral. De esta forma, aunque Companys fue el candidato más votado, la Lliga obtuvo los 14 de los 15 escaños correspondientes a las mayorías en Barcelona-ciudad. Los resultados en toda España supusieron una rotunda derrota para los partidos republicanos de izquierda (salvo la Esquerra catalana) que prácticamente desaparecían del hemiciclo (13 escaños) y una reducida representación para el PSOE (59 escaños), quedando la CEDA como partido con más diputados (202 escaños), con los radicales (115 escaños) en segundo lugar.

La vida de Companys experimentó también cambios durante 1933. Se separó de su esposa Mercé Micó y se unió sentimentalmente a Carme Ballester, una militante del partido que había formado parte de Estat Catalá.

El 25 de diciembre de 1933, apenas constituido el primer gobierno del bienio radical-cedista, encabezado por Alejandro Lerroux, se produjo la muerte de Francesc Macià, que no pudo recuperarse de una operación de apendicitis. Companys aparecía como el sucesor natural del presidente catalán, especialmente tras la expulsión del partido del grupo de "L'Opinió", que había tenido lugar en septiembre y cuyos miembros podían haber sido sus rivales a la hora de liderar el partido y el gobierno catalán. La responsabilidad de elegir al nuevo presidente de la Generalidad estaba en manos del Parlamento, el cual, reunido en sesión extraordinaria el 31 de diciembre, eligió a Companys presidente con 56 votos favorables y 6 abstenciones, entre ellas la suya y la de los diputados de la Lliga Catalana. Previamente, el grupo parlamentario de Esquerra se había reunido para elegir al candidato de su partido. Además de Companys, otros dos candidatos se barajaron como alternativa: Carles Pi i Sunyer y Humbert Torres. La identificación de Companys como la opción republicana, obrerista y "rabassaire" fue la que hizo que fuese el elegido. Sin embargo, su elección distó de suscitar el apoyo unánime que sí concitaba la figura de Macià. Los sectores más nacionalistas de su propio partido cuestionaban su trayectoria catalanista, por lo que su apoyo interno no era general. Su vinculación con el anarcosindicalismo suscitaba recelos en tanto que desde los sectores más conservadores de Cataluña se ponía en duda su capacidad. Más aún, en contraste con la figura de Macià, al que se consideraba representante de toda Cataluña, Companys era visto como un hombre de partido.

Tras su toma de posesión, y a diferencia del gobierno saliente, creó un gobierno de concentración republicana, en el que participaban consejeros no solo de su partido, de la Unió Socialista de Catalunya o de Acció Catalana Republicana, sino también del Partit Nacionalista Republicà d'Esquerra, el partido creado por los disidentes de "L'Opinió". De los siete consejeros de que constaba su gobierno solo tres ocupaban el mismo puesto en el gobierno presidido por Macià. Durante todo su mandato como presidente, Companys presidiría gobiernos de amplia base política.

Una de las primeras medidas impulsadas por el nuevo gobierno fue la Ley de Contratos de Cultivo, que pretendía sustituir los contratos de "rabassa morta" por otros más favorables para los arrendatarios de viñedos, de forma que los "rabassaires" pudiesen acceder a la propiedad de la tierra que cultivaban según unas condiciones menos restrictivas que las existentes entonces (los arrendatarios podrían comprar la tierra que trabajaban tras un periodo de cultivo ininterrumpido de quince años; también se estipulaba que los contratos de arrendamiento tuvieran una duración de seis años). Se trataba de la primera ley importante de carácter socioeconómico promovida por la Generalidad de Cataluña y fue aprobada por el Parlamento de Cataluña, por unanimidad (la Lliga se había retirado del Parlamento tras las elecciones municipales catalanas celebradas en enero), el 21 de marzo de 1934. Entró en vigor el 11 de abril. Sin embargo, la nueva legislación contó con la oposición frontal de los propietarios, agrupados en el Instituto Agrícola Catalán de San Isidro, y de la Lliga Catalana, la cual pidió y apoyó el recurso de inconstitucionalidad presentado por el Gobierno de la República, presidido por el radical Ricardo Samper ante el Tribunal de Garantías Constitucionales el 4 de mayo. La argumentación del ejecutivo central era que la competencia sobre obligaciones contractuales la reservaba el artículo 15 de la Constitución de 1931 al Estado, en tanto que la Generalidat aducía que en virtud del artículo 12 del Estatuto, le correspondía la legislación en materia de política social agraria. El 10 de junio de 1934, el tribunal declaró, por 13 votos a 10, que el Parlamento de Cataluña no tenía competencias sobre el tema y anuló por tanto la ley, lo que se tradujo inmediatamente en protestas callejeras en Barcelona y diversos puntos de Cataluña. Ante este hecho, interpretado por Esquerra como una agresión al autogobierno catalán, sus diputados, juntos con los de la Unió Socialista de Catalunya, se retiraron de las Cortes españolas. Por su parte, dos días después de la sentencia, el gobierno catalán hizo aprobar en el Parlamento un texto idéntico al declarado anticonstitucional, especificando además su carácter retroactivo respecto a la fecha inicial de entrada en vigor. Por su parte, las fuerzas de la izquierda republicana española, apoyaban las reivindicaciones catalanas. Así, durante el debate sobre la Ley de Contratos de Cultivo en las Cortes españolas, el 21 de junio, Azaña afirmaba que «el poder autónomo de Cataluña es el último poder republicano que queda en pie en España».

Poco después de producía una reorganización del gobierno catalán. El 28 de junio, Josep Dencàs se hacía cargo de la cartera de Gobernación, sustituyendo a Joan Selves i Carner, que había muerto inesperadamente. Militante de ERC, Dencàs era el fundador y líder de las Joventuts d'Esquerra Republicana-Estat Català (JEREC), las cuales formaban el ala independentista de Esquerra. Las JEREC se oponían frontalmente al anarcosindicalismo, porque consideraban que los conflictos sindicales desviaban la atención de los obreros de la lucha verdaderamente importante, la "nacional". Para ello, contaban con una fuerza de choque, los "escamots". Tras su nombramiento, Dencàs nombró a Miquel Badia, amigo y colaborador en las JEREC, como responsable de Orden Público. El tándem Dencàs-Badia adoptó métodos expeditivos contra las organizaciones sindicales, lo que sería muy criticado. Un aspecto no esclarecido sobre los sucesos de octubre de 1934 en Barcelona fue la razón por la cual el presidente Companys encargó la cartera de Gobernación a alguien tan alejado ideológicamente, al cual incluso desde dentro del gobierno catalán se había calificado de fascista, y en unos momentos de máxima tensión social. El historiador Jordi Rabassa apunta dos posibles razones. Una sería que Companys necesitaba aplicar una política más contundente en el ámbito del orden público y no quería aparecer como el responsable de ello, para lo que necesitaría a Dencàs como chivo expiatorio. Otra sería que, en caso de fracasar, Companys podría deshacerse los independentistas de Estat Català, el grupo más fuerte opuesto a su política dentro de su partido. El propio Dencàs afirmaría que Companys le había nombrado consejero de Gobernación para preparar una revuelta independentista. Durante los meses siguientes, Dencàs amenazaría varias veces con dimitir, al no haber recibido el visto bueno del gobierno catalán para desencadenar la intentona independentista, el cual tampoco había autorizado la compra de armas en Europa para preparar la rebelión.

El conflicto entre los gobiernos central y autónomo siguió durante el verano. El 26 de junio, el gobierno de Samper anunciaba que declaraba la nueva ley catalana nula y sin efecto, al tratarse de la misma ley que había sido declarada anticonstitucional y que estaba considerando legislar por decreto en relación con los conflictos de competencias entre los gobiernos estatal y autónomo. Ante la oposición parlamentaria, el gobierno Samper renunció a sus pretensiones de legislar por decreto, sometiéndose a un voto de confianza el 4 de julio con el objeto de resolver el conflicto de acuerdo a la Constitución y al Estatuto. El 10 de julio, la Generalidad aprobaba varios decretos para aplicar la ley objeto de la polémica pero, al mismo tiempo, ambos gobiernos buscaban un acuerdo que pusiera fin al conflicto. No ayudaba a la resolución el hecho de que, a diferencia de Macià, Companys no tenía las mismas relaciones personales con Alcalá Zamora. Durante el mes de julio, el consejero de Justicia de la Generalidad de Cataluña, Joan Lluhí, se reunía con Samper, en tanto que el ejecutivo catalán declaraba oficialmente que era su intención hacer que la legislación sobre contratos de cultivo se ajustase a las «leyes básicas» de la República. Mientras tanto, seguía el proceso de traspaso de competencias a la Generalidad de Cataluña. El 13 de septiembre, la Generalidad publicó unos nuevos decretos que modificaban los iniciales siguiendo lo requerido por el gobierno estatal. A pesar de otros desencuentros entre ambas administraciones (que produjeron incluso una nueva denuncia del ejecutivo Samper contra el catalán por injurias y desacato a cuenta de unas declaraciones de Companys contra una ley que regulaba la jurisdicción de la Generalidad sobre el personal de la administración de justicia se llegó a un acuerdo el 21 de septiembre, pero este acuerdo no fue aceptado por la Confederación Española de Derechas Autónomas (CEDA), de forma que cuando Samper presentó el acuerdo, declarando que las modificaciones introducidas eliminaban la anticonstitucionalidad de la ley original, Gil-Robles, líder de la CEDA, anunció que retiraban su apoyo al gobierno, por lo que este dimitió. Tres días después se anunció la creación de un nuevo gobierno, bajo la presidencia de Alejandro Lerroux y la presencia de tres ministros de la CEDA. Los partidos republicanos (salvo el radical) expresaron inmediatamente su rechazo a dicha fórmula.

Tras la entrada en el gobierno de la República de tres ministros de la CEDA y al desatarse la huelga revolucionaria convocada por los socialistas en octubre en diversos puntos del país, el 6 de octubre de 1934 Companys, tras acusar al nuevo gobierno español de «monarquizante» y «fascista», proclamó el «Estado Catalán» dentro de la República Federal Española, invitando a los republicanos de izquierda de toda España a establecer un gobierno provisional de la República en Barcelona. Según declararía Companys durante su posterior juicio, el 5 de julio Joan Lluhí le habría pedido en nombre del ejecutivo catalán a Azaña, que se encontraba en Barcelona tras asistir al entierro de su antiguo colaborador Jaume Carner Romeu, que encabezase un gobierno provisional de la República en la capital catalana, pero este no habría aceptado.

Companys contaba con el apoyo de las fuerzas catalanistas de izquierda y con los partidos y organizaciones obreras, agrupados en la Alianza Obrera. Con la importante salvedad de la CNT que se había negado a secundar la huelga.

Este hecho es uno de los más controvertidos de la Segunda República y especialmente de los protagonizados por Companys. Existen innumerables interpretaciones del hecho. Stanley G. Payne, en "La primera democracia española" (1995), afirma que «Companys era un hombre básicamente sensato que llevaba meses sometido a presiones extremas de los catalanistas radicales». Pere Anguera, en "La España de los nacionalismos y las autonomías" (2003) señala a la radicalización social del independentismo y a la catalanista de los partidos marxistas, en un clima de crisis política entre los gobiernos de distinto signo en Madrid y Barcelona. En este contexto, Companys habría tratado de frenar una revolución social, desencadenando un movimiento político a cuyo frente se situaba, con el propósito de desactivar la revuelta social. También habría pretendido no perder el control de la Unió de Rabassaires y habría influido los posicionamientos crecientemente radicales y catalanistas de independentistas y partidos obreros. Josep Sánchez Cervelló, en el capítulo dedicado a Companys en "En el combate por la Historia" (2012), interpreta que con el desencadenante formal de la entrada de la CEDA en el ejecutivo, fueron las tensiones dentro de su gobierno entre los partidarios de mantener una alianza estrecha con las fuerzas de la izquierda republicana del resto de España (postura defendida por Joan Lluhí, consejero de Justicia), los independentistas (con Josep Dencàs, consejero de Gobernación, a la cabeza), y los que fundamentalmente promovían una revolución socialista (Joan Comorera, líder de la USC y consejero de Economía y Agricultura), los que llevaron a Companys a la radicalización y a la proclamación del 6 de octubre, con la que pretendía asumir un perfil catalanista del que según sus críticos habría carecido hasta entonces.

Tras la intervención militar dirigida por el comandante en jefe de la IV División Orgánica, el general Batet, Companys fue detenido junto con el gobierno catalán en pleno y encarcelado en el buque "Uruguay", fondeado en el puerto de Barcelona, que fue requisado para ser utilizado como prisión. Companys y sus consejeros permanecieron recluidos en el "Uruguay" hasta el 7 de enero de 1935, cuando fueron trasladados a la cárcel Modelo de Madrid para ser juzgados por el Tribunal de Garantías Constitucionales.

Las consecuencias para la autonomía catalana fueron desastrosas. El 7 de octubre, con el país aún bajo el estado de guerra, el general Batet designó al coronel de Intendencia Francisco Jiménez Arenas presidente accidental de la Generalidad. El 2 de enero, las Cortes aprobaban una ley por la que se suspendía el estatuto de autonomía, nombrándose a un gobernador general de Cataluña que asumía las funciones del presidente de la Generalidad y de su consejo ejecutivo. En noviembre, Amadeu Hurtado, presidente de la Real Academia de Jurisprudencia y Legislación de Cataluña había tratado de buscar una solución que salvase el autogobierno catalán del procesamiento de sus dirigentes, proponiendo que la presidencia de la Generalidad, en ausencia de su presidente, y del presidente del parlamento, fuese ocupada por el vicepresidente, Antonio Martínez Domingo, de la Lliga. Sin embargo, Companys desautorizó cualquier posible arreglo, impidiendo cualquier colaboración por parte de Esquerra Republicana.

Companys y sus consejeros fueron juzgados por rebelión por el Tribunal de Garantías Constitucionales. El 6 de junio de 1935 por diez votos a favor y ocho en contra, Companys y los miembros de su gobierno fueron condenados a treinta años de reclusión mayor e inhabilitación absoluta. Posteriormente Companys y los consejeros Comorera y Lluhí fueron trasladado al penal de El Puerto de Santa María (Cádiz), en tanto que el resto de consejeros eran internados en la cárcel de Cartagena.

A pesar de ello, fue candidato del Front d'Esquerres en las elecciones de febrero de 1936 por la circunscripción de Barcelona-ciudad, resultando elegido diputado.
Tras el triunfo del Frente Popular en las elecciones celebradas el 16 de febrero de 1936, no tardó en llegar la amnistía. Tras la dimisión de Portela, Azaña formó gobierno el 19 de febrero. Ante los continuos tumultos y manifestaciones exigiendo que los presos de octubre fuesen liberados, el presidente del Consejo propuso a la Diputación Permanente de las Cortes un decreto de amnistía. El 21 resultaba aprobado el decreto-ley y se dieron las instrucciones para que se produjese urgentemente la liberación de presos. Esa noche, Companys y sus compañeros del penal del Puerto de Santa María, Comorera y Lluhí, fueron liberados y trasladados hacia Madrid, pasando por Córdoba, donde pernoctaron. Al día siguiente, se reunieron en Ocaña con los otros cuatro consejeros, que venían de Cartagena y con todo el grupo de amigos y familiares que se había desplazado desde Barcelona para recibirlos. Esa noche llegaron a Madrid.

Liberado en 1936 tras la victoria del Frente Popular, en previsión de un posible golpe militar nombró al capitán Frederic Escofet como Comisario General de Orden Público de Cataluña.

Tras el fracaso del golpe de Estado del 18 de julio al que hicieron frente fundamentalmente milicias anarquistas, el presidente Companys firmó el 21 de julio un decreto de creación del Comité Central de Milicias Antifascistas de Cataluña. El 11 de septiembre de ese año, "La Vanguardia" recogía unas declaraciones suyas con los titulares «el Presidente condena los actos de terrorismo» y «hay que terminar con los actos que se cometen al margen de la Justicia». Pero no solo se trató de declaraciones públicas, enmarcadas en la pugna del gobierno de la Generalidad con el Comité Central de Milicias Antifascistas: Companys fue una pieza fundamental, dado el cargo que ocupaba, en una tarea que involucró a muchas más personas, y cuyos rostros más visibles fueron los consejeros Ventura Gassol y Josep Maria Espanya, el presidente del Parlamento de Cataluña, Joan Casanovas, y el rector de la Universidad de Barcelona, Pedro Bosch Gimpera. En conjunto, salieron de los puertos catalanes 9206 personas (incluyendo entre ellos al cardenal y arzobispo de Tarragona Vidal y Barraquer, capturado por milicianos de la FAI y salvado "in extremis" de ser asesinado) hacia Marsella y Génova, la mitad de ellos durante 1936, utilizando pasaportes, visados y salvoconductos, muchas veces falsos, expedidos por la Generalidad de Cataluña. En su calidad de presidente, Companys firmó con el delegado del Comité Internacional de la Cruz Roja un convenio que preveía que cualquier persona pudiese abandonar la zona de España en la que se encontrase, el cual no fructificó al negarse las autoridades franquistas a firmarlo también.

Durante toda la guerra encabezó el Gobierno de Cataluña tratando de mantener la unidad entre los partidos y sindicatos que le apoyaban. Ello fue muy difícil por las tensiones entre comunistas y socialistas agrupados en el Partido Socialista Unificado de Cataluña con los anarquistas de la Confederación Nacional del Trabajo, apoyados estos últimos por el POUM. A partir de octubre de 1937 se sucedieron sus enfrentamientos con el Gobierno republicano de Juan Negrín, instalado en Barcelona, y en abril de 1938, tras la ocupación de Lérida, escribió una carta al presidente del Gobierno español, quejándose de las arbitrariedades que estaba cometiendo y de la marginación que sufría el Gobierno catalán. Casi al mismo tiempo, la nueva administración franquista acordaba, mediante una ley promulgada en Burgos el 5 de abril, con las firmas del ministro del Interior Ramón Serrano Súñer y del general Franco, la derogación formal del estatuto de Cataluña

Después del triunfo franquista en la batalla del Ebro, la ofensiva sobre Cataluña comenzó el 23 de diciembre de 1938. El 3 de enero, las tropas franquistas pasaron el Ebro en un movimiento crucial para la suerte de la ofensiva. Desde entonces, las tropas republicanas se batieron en retirada, sin lograr establecer ninguna línea de resistencia efectiva. El 15 de enero cayó Tarragona y a partir de entonces, la aviación franquista bombardeaba día y noche Barcelona. El 18 de enero se celebró un consejo de ministros en Barcelona al que también asistieron el presidente de las Cortes, Martínez Barrio y Companys, en el que se decretó, más de dos años después del inicio de la guerra, el estado de guerra. Ante la petición del presidente del Consejo, Negrín, y a pesar de saber ya que la guerra estaba perdida, el 20 de enero Companys dirigió un mensaje radiofónico al pueblo catalán pidiendo una postrera resistencia ante las tropas franquistas que avanzaban sobre Barcelona. El día siguiente, Negrín convocó a Companys a una reunión urgente. En ella, le comunicaba que Barcelona era indefendible y que en pocas jornadas sería ocupada irremisiblemente por el ejército franquista. Por ello, le comunicaba que la Generalidad debía evacuar Barcelona. El día 22, Negrín ordenaba que los organismos estatales abandonaran Barcelona y se dirigieran a Gerona y Figueras. Al día siguiente, Companys se preparó para partir. Aunque había considerado permanecer en Barcelona y esperar en su despacho a las nuevas autoridades, Companys salió de Barcelona a las tres de la madrugada del día 24. La noche anterior cenó con su amigo Josep Andreu i Abelló, presidente del Tribunal de Casación de Cataluña. Ambos recorrieron en coche las calles desiertas de Barcelona. Andreu narró ese último paseo nocturno de Companys en la capital de Cataluña:

El día 26, la vanguardia franquista tomó Barcelona. Decenas de miles de refugiados se dirigían, junto las tropas republicanas en retirada, a la frontera. Tras pasar por San Hilario Sacalm y Darnius, acompañado por los consejeros Tarradellas, Sbert y Pi i Sunyer, así como por Andreu i Abelló, Companys llegó el 30 de enero al mas Perxés en Agullana, apenas a cinco kilómetros de la frontera por una carretera de montaña (evitando la aglomeración de refugiados en La Junquera). Allí se reunió con él, el 4 de febrero, el lehendakari Aguirre, amigo de Companys, que se había desplazado desde París a Cataluña para organizar la evacuación de las oficinas del Gobierno de Euzkadi en Barcelona y de los refugiados vascos y que le había hecho a Companys la promesa de acompañarle en su salida al exilio. El 5 de febrero abandonaron el país Azaña y Martínez Barrio, acompañados por Negrín. Inicialmente se había acordado que los cinco presidentes partieran al mismo tiempo, pero finalmente Azaña y Negrín se adelantaron. Horas después les siguió una comitiva formada por Companys, Aguirre y altos cargos de la Generalidad y del Gobierno Vasco. En el km 8 de Agullana hacia La Bajol se desviaron escoltados por el comandante Escofet y sus hombres por un camino de cabras ascendiendo el collado de Lli y luego descendieron hacia Les Illes. En el descenso se cruzaron con Negrín que regresaba a España después de acompañar a Azaña a Francia. José Antonio Aguirre, rememoró después en sus escritos: «Pocas personas han conocido como yo momentos de intimidad de Companys, que es cuando se descubren los hombres tal como son...aquel hombre estaba sumido en un profundo abatimiento...yo le animaba diciendo que los pueblos no mueren como los hombres y que llegaría la hora de nuestro triunfo... “no es eso..., me contestó, mi preocupación en estos momentos está concentrada en todos esos compatriotas mios que huyen sin amparo y en mi hijo enfermo”... me confió que todos sus ahorros no llegaban al equivalente a dos mil dólares y añadió...“ ese dinero no es para mí, lo tenía fuera para atender la curación de mi pobre hijo que está en un sanatorio de Bélgica... yo me moriré de hambre si es preciso, pero mi hijo no, no”.». Aguirre escribió que llevó el asunto a la primera reunión del gobierno vasco en París acordándose ayudar económicamente a Companys en los primeros momentos en Francia.

Tanto la Generalidad como el exilio catalán atravesaron graves dificultades económicas pues el gobierno catalán, presionado por orden ministerial de Negrín, entregó sus fondos de tesorería al gobierno central de la II República. Ello lo realizó el consejero de Hacienda Josep Tarradellas el 2 de febrero antes de cruzar la frontera. Al no tener recursos propios, el exilio catalán estuvo supeditado a la ayuda económica del SERE presidido por Negrín o de la JARE de Prieto.
Tras pasar por Perpiñán se trasladó a París, donde ya se encontraba su esposa, Carme Ballester, instalándose en el Boulevard de la Seine cerca de la modesta representación que la Generalidad había establecido en la Rue Pepinière. Su situación allí distaba de ser cómoda. Companys se había convertido en el blanco de las críticas por parte de todos los sectores del catalanismo (tanto de los que se exiliaron tras el estallido de la guerra como de aquellos que llegaron a Francia tras la caída de Cataluña). Le acusaban de ser el culpable de todos los males que había sufrido Cataluña. A Companys le responsabilizaban de no hacer frente a los revolucionarios que tomaron virtualmente el poder en Cataluña tras el fracaso de la sublevación, de haberles dejado hacer y, por tanto, de forma indirecta, de ser corresponsable de las víctimas de la violencia revolucionaria y de la mala imagen que tales desmanes habían proyectado en el exterior. También se le achacaba no haber podido mantener su papel como presidente y el de su partido como fuerza dominante en Cataluña y haberse convertido en un títere primero de los anarquistas y luego de los comunistas, con lo que habría paralizado el proceso de recuperación política y cultural catalanes iniciado con la "Renaixença". Companys confesó a Rafael Tasis que le preocupaba la actitud de muchos exiliados catalanes hacia él atribuyéndole la culpa de muchas cosas, considerándolo poco catalanista y más asociado al republicanismo español, así como culpándolo de haberse dejado engañar por falsas promesas.

Una de sus primeras decisiones en el exilio fue formar la Fundación Ramon Llull para proteger la lengua y la cultura catalana en marzo de 1939. Fue dirigida por prestigiosos exiliados como el catalán Pompeu Fabra, y el andaluz Pablo Picasso como presidente de honor de la sección de artes plásticas.

Al declarase la Segunda Guerra Mundial, el único órgano político representativo de Cataluña y su único símbolo era la Presidencia de la Generalidad pues el gobierno catalán se había disuelto y el parlamento no se podía reunir al estar dispersos sus diputados. Con el catalanismo dividido y las autoridades francesas imponiendo restricciones a las actividades políticas, Companys decidió constituir el Consejo Nacional de Cataluña. Debía ser un organismo nacional representativo en el exilio. Consultados las personalidades más relevantes, estos propusieron que no participase ningún político que hubiese tenido un cargo oficial en Cataluña y que Companys renunciara a la Presidencia de la Generalidad. Companys optó por una vía intermedia constituyendo un Consell con cinco personalidades culturales. Pero este organismo no tuvo transcendencia pues tres meses después Companys fue detenido y fusilado otros dos meses más tarde.

La presencia de Companys en París había suscitado reticencias por parte de las autoridades francesas, que lo querían fuera de la capital por su radicalismo y por agitar a las masas de refugiados. Debido a ello Companys abandonó París en junio de 1939. Gracias a las gestiones de Joan Casanelles, antiguo diputado y amigo de Companys, el presidente y su esposa se establecieron en la localidad bretona de La Baule-les-Pins (Loire-Atlantique). Desde allí se desplazaba frecuentemente a París, tanto para estar al corriente de los asuntos gestionados en la oficina parisina de la Generalidad, como para visitar a su hijo 
Lluís, que estaba internado en un sanatorio debido a su grave enfermedad mental. En mayo su hija Maria, junto con su marido, Hèctor Gally, habían partido hacia México. A pesar de los ruegos de su hija, Companys decidió quedarse en Francia para no perder el contacto con su hijo. Con la derrota francesa ante la Alemania nazi y la firma de la capitulación, el matrimonio Companys quedó en la zona ocupada. Tras la caída de París en manos de los alemanes (14 de junio), el embajador español en Francia, José Félix de Lequerica, solicitó a las nuevas autoridades que todas las organizaciones de exiliados españoles e instituciones políticas fueran disueltas. Con la colaboración de las autoridades alemanas, el personal de la embajada pudo incautarse de todo el patrimonio de dichas organizaciones. Tras la firma del armisticio, Ramón Serrano Suñer, ministro de la Gobernación, envió a Francia al secretario general de la Dirección General de Seguridad, con el objetivo de localizar a los dirigentes republicanos que aún estaban en Francia, conseguir su captura y entrega a España. Gracias a la documentación incautada, el 8 de agosto las autoridades de la zona de ocupación alemana recibieron una lista con 800 nombres para su detención y entrega a las autoridades franquistas. El 13 de agosto de 1940 agentes de la policía militar alemana detuvieron a Companys en una casa de La Baule-les-Pins, junto a Nantes, y lo entregaron a las autoridades franquistas el 29 de agosto de 1940.
La entrega al gobierno del general Franco la realizó el policía español Pedro Urraca Rendueles a través de la frontera de Irún. Fue trasladado a la Dirección General de Seguridad en Madrid, donde permaneció hasta el 3 de octubre de 1940, siendo torturado. Desde ahí fue enviado al castillo de Montjuic, que servía de prisión. Allí fue juzgado en consejo de guerra el 14 de octubre. Su defensor de oficio fue el capitán de Artillería Ramón de Colubí. Como había sido juzgado en rebeldía y en aplicación retroactiva de la Ley de Responsabilidades Políticas por un tribunal especial de Barcelona, solo fue juzgado y sentenciado por «Adhesión a la rebelión militar», en una única jornada por un tribunal militar sumarísimo sin garantías. Tras un juicio que duró unas pocas horas, fue sentenciado a morir fusilado. El dictador Franco dio el «enterado», por lo que el fusilamiento tuvo lugar al alba del día siguiente, 15 de octubre de 1940, en el foso de santa Eulalia del castillo de Montjuic. No quiso que se le pusiera una venda en los ojos y murió diciendo: «Per Catalunya!» («¡Por Cataluña!»).

En la década de los noventa, el alemán Helmut Kohl y el francés François Mitterrand pidieron perdón en nombre de sus respectivos países por haber colaborado en la detención y deportación de Lluís Companys. En junio de 2013, Esquerra Republicana de Catalunya se querelló en Argentina contra el Estado español, con motivo de los crímenes del bando franquista contra cargos republicanos.

El 21 de diciembre de 2018 el Gobierno de España presidido por Pedro Sánchez acordó en un Consejo de Ministros celebrado en Barcelona condenar el juicio sumarísimo a que fue sometido Companys y restaurar su honorabilidad. Ello no supuso de momento la anulación de la sentencia, que deberá promulgarse por ley. Un mes después, la ministra de Justicia Dolores Delgado entregaba en México a la nieta de Companys la documentación que reconoce la «restitución de la plena dignidad» del "president".

En 1943, Ángel Ossorio y Gallardo, el político y abogado que le había defendido tras los hechos de octubre de 1934 escribió "Vida y sacrificio de Companys".

En 1979, el ayuntamiento de Barcelona, el primero elegido democráticamente desde la República, acordó proceder al cambio de nombre del Salón de Víctor Pradera, un paseo que se encontraba entre el Arco de Triunfo y el parque de la Ciudadela. Desde entonces, la avenida lleva el nombre de paseo de Lluís Companys. En 1997 se erigió allí una escultura en homenaje a su figura.

En julio de 2001, el Estadio Olímpico de Montjuic en Barcelona, en el que se habían celebrado las pruebas de atletismo de los Juegos Olímpicos de verano de Barcelona en 1992, recibió el nombre de Lluís Companys, según resolución del ayuntamiento de Barcelona a propuesta de Comisiones Obreras de Cataluña.

En 2005 se erigió un monolito en el foso de Santa Eulalia del castillo de Montjuic, frente al lugar donde Companys fue ejecutado. La inauguración tuvo un carácter institucional bajo la presidencia del presidente de la Generalidad Pasqual Maragall.






</doc>
<doc id="27922" url="https://es.wikipedia.org/wiki?curid=27922" title="Tambor">
Tambor

Un tambor es un instrumento de percusión de sonido indeterminado, perteneciente a la familia de los membranófonos según el sistema de clasificación de Hornbostel-Sachs. Consta de una caja de resonancia, que suele ser de forma cilíndrica, y una membrana llamada parche, que cubre la abertura de la caja. Algunos tipos de tambores tienen parches en ambos lados. El sonido se obtiene al golpear el instrumento en el parche con la mano o con baquetas. También se suele percutir la caja.

Los tambores generalmente se tocan golpeando con la mano, o con una o dos palos o baquetas. Se utiliza una amplia variedad de palos, incluidos palos de madera y palos con batidores suaves de fieltro en el extremo. En el jazz, algunos bateristas usan escobillas para un sonido más suave y silencioso. En muchas culturas tradicionales, los tambores tienen una función simbólica y se utilizan en ceremonias religiosas.

Los tambores se usan con frecuencia en la musicoterapia, especialmente los tambores de mano, debido a su naturaleza táctil y su fácil uso por parte de una amplia variedad de personas.

Los tambores adquirieron incluso un estatus divino en lugares como Burundi, donde las "karyenda" eran un símbolo del poder del rey.

Los instrumentos de tipo tambor son los instrumentos de percusión más comunes. Algunos son:


</doc>
<doc id="27923" url="https://es.wikipedia.org/wiki?curid=27923" title="Números sociables">
Números sociables

El concepto de número sociable es la generalización de los conceptos de números amigos y números perfectos. Un conjunto de números sociables es una sucesión alícuota, o una sucesión de números en que cada término es igual a la suma de los factores propios del término anterior. En el caso de los números sociables, la sucesión es cíclica, es decir, los términos se repiten.

El periodo de esta sucesión, o el orden del conjunto de números sociables, es el número de términos de la sucesión que hay en el ciclo. Si el periodo de la sucesión es 1, el número es un número sociable de orden 1, o un número perfecto. Por ejemplo, 6 tiene por factores propios los números 1, 2 y 3, que a su vez suman 6. Un par de números amigos es un conjunto de números sociables de orden 2. No se conocen, por el momento, números sociables de orden 3.

Es una pregunta abierta si todos los enteros son, o bien sociables, o bien su sucesión alícuota acaba en un primo (y, como consecuencia, en 1); o si, por el contrario, existe algún número cuya sucesión alícuota nunca acaba.

He aquí un ejemplo con período 4:

Los más sencillos (con los enteros más pequeños) son:
12 496 → 14 288 → 15 472 → 14 536 → 14 264 → ... de cinco términos,
hay otro de veintiocho términos, y este de cuatro:
1 264 460 → 1 547 860 →1 727 636 → 1 305 184 → ...

El primero de ellos fue hallado por Poulet en 1918, y los últimos, incluido el mostrado, por Henri Cohen en 1969.



</doc>
<doc id="27924" url="https://es.wikipedia.org/wiki?curid=27924" title="Francesc Macià">
Francesc Macià

Francesc Macià i Llussà, también conocido en castellano como Francisco Maciá (Villanueva y Geltrú, 21 de septiembre de 1859-Barcelona, 25 de diciembre de 1933), fue un político y militar español de ideología republicana e independentista catalana, teniente coronel del Ejército de Tierra, presidente de la Generalidad de Cataluña y uno de los fundadores de los partidos Estat Català y Esquerra Republicana de Catalunya; fue sucedido al frente de este último por Lluís Companys tras su muerte a los 74 años.

Nacido en Villanueva y Geltrú el 21 de septiembre de 1859, a los quince años ingresó en la Academia de Ingenieros de Guadalajara. Termina su formación tras cinco años y pasa destinado como teniente a Madrid en la sección de telegrafía. Fue destinado a Sevilla con el grado de capitán (1882) y después a Lérida, donde llegaría a teniente coronel.

Se casó con Eugenia Lamarca en 1888, hija de terratenientes leridanos.

Sin embargo tuvo que salir de la institución militar después de condenar el ataque de algunos oficiales del ejército al semanario La Veu de Catalunya en 1905. (Asaltaron la imprenta en la que se elaboraba el semanario que había publicado una caricatura que consideraron vejatoria para los oficiales destinados en Cataluña, la revista satírica el Cu-cut y justo después el emplazamiento de la Liga Regionalista. En vez de tomarse medidas contra los militares se les dio la razón y a los autores de la caricatura se les juzgó por un tribunal militar, es decir, la Ley de Jurisdicciones). Este hecho llevó a que se crease la Solidaridad Catalana, y Macià comenzó su actividad política.

Se presenta a diputado en las elecciones del 21 de abril de 1907 en las listas de la Solidaridad Catalana representando a Barcelona, obteniendo escaño con un gran éxito para su coalición política (44 de 47 diputados de Cataluña). En 1908 participó en una concentración carlista en Butsenit, en la que ofrecería su espada de militar a la causa carlista. Volverá a ser elegido diputado en 1914, 1916, 1918, 1919, 1920 y 1923. En el Congreso se dedica inicialmente a promover la regeneración de España aunque irá deslizándose hacia el republicanismo.

A finales del año 1918 fundó la Federació Democràtica Nacionalista, una pequeña formación nacionalista fundamentalmente situada dentro la izquierda política, aunque no exenta de afinidad con las huestes carlistas. En julio de 1922 protagonizó la fundación de una organización paramilitar, Estat Català («Estado Catalán», EC).
En 1923, tras el golpe de estado de septiembre de 1923 por parte de Miguel Primo de Rivera, se exilió en Francia. Asentado inicialmente en Perpiñán, se trasladaría a finales de año en París, previo paso por Châteauroux. Es en esta época cuando desde Estat Català desarrolla su carácter insurreccional manteniendo contacto con anarquistas y comunistas, consigue la ayuda económica de las comunidades de catalanes residentes en Sudamérica y presta apoyo a casi todos los intentos insurreccionales en España. 

En 1925 efectuó un fallido viaje a Moscú para tratar de recabar ayuda de las autoridades comunistas, manteniendo encuentros con Grigori Zinóviev y Nikolái Bujarin.

En 1926 durante la dictadura de Miguel Primo de Rivera organizó una incursión armada de voluntarios —el denominado «complot de Prats de Molló»— para invadir Cataluña desde Francia, provocar una insurrección general y proclamar una república catalana; la expedición, deficientemente preparada, no llegó a cruzar la frontera franco-española al ser detenida por la Gendarmería francesa en Prats de Molló. Esto le hará ganar mucha popularidad en Cataluña. Abortado el complot, Macià fue detenido y desterrado a Bélgica. Tras residir unos cuantos meses en Bruselas, entró clandestinamente en Argentina, donde residió más de medio año. Tras efectuar visitas a las comunidades de catalanes en Uruguay, Argentina y Chile, llegó a Cuba en agosto de 1928. Fundó en La Habana el Partido Separatista Revolucionario de Cataluña, del cual fue presidente y en el que estudió por primera vez la posibilidad de constituir una República Catalana (septiembre-octubre de 1928). Caída la dictadura del general Primo de Rivera (enero de 1930), Macià regresa a España el 22 de febrero de 1931. Fue elegido diputado a Cortes en 1931 y en 1933.

En 1931 Estat Català se unió con el Partit Republicà Català de Lluís Companys y el grupo "L'Opinió" para fundar el nuevo partido Esquerra Republicana de Catalunya, manteniendo autonomía interna.
El 14 de abril de 1931, después de unas elecciones municipales que dieron la mayoría a su nuevo partido, "Esquerra Republicana de Catalunya", Macià proclamó la República Catalana desde el Palacio de la Generalidad de Cataluña. Los dirigentes del carlismo catalán acudieron entonces a ofrecerle su «colaboración patriótica». La proclamación de la República Catalana por parte de Macià abrió un conflicto con el recién constituido Gobierno provisional de la República. Para resolverlo, tres días después, tres ministros del Gobierno provisional (los ministros Marcelino Domingo, Nicolau d'Olwer y Fernando de los Ríos,) llegaban a Barcelona para negociar, alcanzando un acuerdo por el que Macià renunciaba a la República Catalana a cambio del compromiso del Gobierno provisional de que presentaría en las futuras Cortes Constituyentes un estatuto de autonomía para Cataluña, y que el Gobierno de Cataluña utilizaría en adelante la denominación de Generalitat. Con la creación del Parlamento Catalán fue elegido diputado por dos circunscripciones diferentes, Lleida y Barcelona ciudad, teniendo que renunciar a una de las actas. Fue elegido presidente de la Generalidad con 63 votos a favor en el Parlamento Catalán el 14 de diciembre de 1932. Se mantuvo en el cargo hasta su muerte en 1933. Falleció de una apendicitis el 25 de diciembre de 1933 a los 74 años. Fue sustituido al frente de la Generalidad de Cataluña por Lluís Companys.

Durante su mandato, se produjeron algunos conflictos sociales como la huelga General de Barcelona de septiembre de 1931. Con la creación de Estat Catalá trató de ensamblar un ultranacionalismo compatible con un populismo de izquierdas. Representante de un nacionalismo radical periférico, su figura llegó a ser tomada coyunturalmente como modelo por Ernesto Giménez Caballero a la hora de elucubrar acerca de la conformación de un nacionalismo español combativo y fascistizante. Por contra, durante el periodo de la Segunda República, desde la perspectiva del liberalismo europeo, imbuido de un aura heroica, tendió a ser visto como el abanderado de un movimiento democrático.

Su se encuentra depositado en el CRAI Biblioteca Pavelló de la República de la Universitat de Barcelona. Consta de correspondencia recibida y/o escrita por Joan Agell, escritos de Joan Agell, documentos de Centre Català de Nueva York, documentos diversos, escritos diversos y recortes de prensa.

Cuando Macià fallece se lleva a cabo un rito masónico para su enterramiento consistente en introducir su corazón y sus vísceras en urnas. Durante la Guerra Civil Española, ante el inminente triunfo del Bando Nacional, Josep Tarradellas manda a un funcionario a recoger el corazón de Macià y llevárselo al exilio y comunica a la familia que, para evitar profanaciones, el cuerpo de Macià había sido trasladado secretamente de su tumba oficial al Panteón Collaso Gil. En 1954 Tarradellas es nombrado presidente de la Generalitat en el exilio. Durante la Transición Española, Tarradellas regresa a España y la familia le reclama el corazón de Macià, ya que el Ayuntamiento de Barcelona desea realizar un acto solemne de la devolución del corazón al sepulcro. Se procede a la exhumación del cadáver del Panteón Collaso Gil pero se descubre que Macià no ha sido enterrado allí, lo que provoca la profunda indignación de la familia de Macià y del Ayuntamiento. Tras esto se comprueba que, efectivamente, el cuerpo de Maciá se encontraba en su tumba original. Se descubre, además, que en la tumba de Macià el corazón sigue allí, con lo cual el supuesto corazón de Macià que conservaba Tarradellas era de un individuo desconocido.

"Era un hombre de acción, más que de palabras. Era un hombre de ideas simples, de ideologías políticas sin especulaciones filosóficas, sin abstracciones. En una palabra, sin ninguna preparación filosófica o ideológica especial". 




</doc>
<doc id="27927" url="https://es.wikipedia.org/wiki?curid=27927" title="Josep Tarradellas">
Josep Tarradellas

Josep Tarradellas Joan (Cervelló, Cataluña 19 de enero de 1899-Barcelona, Cataluña 10 de junio de 1988) fue un político español, presidente de la Generalidad de Cataluña en el exilio desde 1954 hasta 1977, y de la Generalidad provisional desde esta fecha hasta 1980.

En 1986 se le concedió el título nobiliario de marqués de Tarradellas.

Nacido el 19 de enero de 1899 en la localidad de Cervelló, en la provincia de Barcelona. Sus padres, Salvador y Casilda, se habían casado en el mes de noviembre del año anterior y era el mayor de dos hermanos. En 1914 se trasladó a la ciudad de Barcelona con sus padres y su hermana y empezó a trabajar en varios trabajos como aprendiz sin cobrar por ello, también estuvo como dependiente de un comercio. Al año siguiente, se inscribió como socio en el Centro Autonomista de Dependientes del Comercio y de la Industria (CADCI), donde estudió catalán, español, francés, inglés, aritmética, contabilidad y cultura general. Su militancia catalanista hizo que empezase en la vida política siendo muy joven, llegando a secretario de propaganda del CADCI.

En 1919 fundó los semanarios "Abrandament" y "El Intransigente", y se unió a la Federación Democrática Nacionalista de Francesc Macià (a quien había conocido en 1916). En 1920 militó en la Joventut Nacionalista La Falç. Contrajo matrimonio con Antònia Macià, en 1927. Empezó a destacar con la fundación de Esquerra Republicana de Catalunya, formación con la cual sería elegido diputado a las Cortes y al Parlamento de Cataluña.

Fue diputado y consejero de Gobernación y de Sanidad de la Generalidad de Cataluña entre 1931 y 1932, y del primer gobierno posterior a las elecciones al Parlamento de Cataluña de 1932. Por divergencias ideológicas con Francesc Macià y sus críticas a Estat Català, en 1933 fue expulsado de Esquerra Republicana de Catalunya y salió del Gobierno, creando con otros miembros de "L'Opinió" el Partit Nacionalista Republicà d'Esquerra. Sin embargo, a pesar de no estar implicado en la Revolución de 1934 contra el gobierno de la República, fue igualmente encarcelado. Pudo regresar nuevamente a ERC en 1936 y tras el triunfo electoral del Frente Popular ese mismo año, se le dio el cargo de consejero de Servicios Públicos, Economía y Finanzas. Al comenzar la Guerra Civil Española, fue miembro del Consejo, y como "conseller en cap" impulsó varias leyes. También fue presidente de la Comisión de Indústrias de Guerra donde se hizo una gran labor para poder luchar en contra del ejército que se sublevó y dio el Golpe de Estado en plena democracia. 

En 1938 fue nombrado secretario general de Esquerra Republicana de Catalunya.

Ya casi terminada la guerra, en febrero de 1939 se marchó a Francia. El gobierno franquista pidió su extradición, que fue denegada a raíz de la protesta indignada que llevó a cabo la delegación de México ante el mariscal Pétain en ocasión de la entrega a Franco del presidente Companys. Pudo así ir a Suiza, donde obtuvo el derecho de asilo.

Volvió a París en 1944 y rechazó el cargo de ministro en el gobierno de la República Española en el exilio. En 1954, cuando el presidente de la Generalitat en el exilio, Josep Irla, dimitió por motivos de salud, se convocó en la ciudad de México —donde residía el grupo más numeroso de diputados— la elección de la Mesa del Parlamento de Cataluña, de la Diputación Permanente y del presidente de la Generalidad. El día 7 de agosto fue elegido presidente de la Generalitat en la embajada de la República Española en México, por los diputados del Parlamento de Cataluña, aunque su presencia fue sólo testimonial (9 diputados); otros fueron representados o enviaron su voto. Renunció a formar gobierno en el exilio, y después de viajar por diferentes países de América, fijó su residencia en Francia, en Saint-Martin-le-Beau (Tours). En 1954 renunció al cargo de secretario general de Esquerra Republicana de Catalunya. Hasta la muerte del general Franco mantuvo una actitud testimonial en defensa de la legitimidad de la presidencia de la Generalitat como único poder catalán.

Su padre Salvador, pudo esconder bajo tierra - en los terrenos de la finca donde vivían-, la gran cantidad de archivos personales del President y de la misma institución de la Generalitat. Estos archivos están hoy en día en un ala del monasterio de Poblet en Cataluña, llamado "Arxiu Montserrat Tarradellas i Macià".

Tras la muerte del dictador Francisco Franco, regresó nuevamente a España. El 29 de septiembre de 1977 el Gobierno presidido por Adolfo Suárez restableció la Generalidad de Cataluña de forma provisional. Tras realizar varias negociaciones con Salvador Sánchez-Terán y el presidente del Gobierno, se le reconoció la legitimidad del cargo que ostentaba, nombrándole presidente de la Generalidad preautonómica el 17 de octubre del mismo año. Seis días después, el 23 de octubre, desde el balcón del Palacio de la Generalidad gritó a la multitud concentrada en la plaza de Sant Jaume la famosa frase «"Ciutadans de Catalunya, ja sóc aquí!"». Hoy en día, a estas palabras se les atribuye un gran simbolismo histórico, especialmente para los catalanes, pues de alguna forma ponen punto final a la dictadura franquista, y todo lo que ella implicaba, para dar paso a la democracia en España. Muchas personas le dan gran importancia a esta frase, sosteniendo que las palabras que usó Tarradellas no fueron casuales: dijo «Ciutadans de Catalunya» (Ciudadanos de Cataluña), en vez de «catalans» (catalanes), pues según estos su intención era aludir a todos los habitantes de Cataluña, no solamente a los nacidos en dicho territorio. Tras la aprobación del nuevo Estatuto de autonomía de Cataluña de 1979 y la celebración de las primeras elecciones autonómicas, se retiró de la vida política.

Durante este tiempo mantuvo unas relaciones tensas con el nacionalista catalán Jordi Pujol, relaciones que no se verían exentas de conflictos y reproches mutuos. En 1980, durante una entrevista con el periodista Julio Merino, en referencia a Pujol llegó a contestarle: «Señor Merino, yo de enanos y corruptos no hablo». Tarradellas también comentó respecto a Banca Catalana:

Con posterioridad, tras su salida del gobierno regional, Tarradellas llegaría a calificar al pujolismo como una «dictadura blanca», y también criticó «la peligrosa deriva rupturista, sectaria y victimista que había tomado [Pujol]».

En 1980 fue investido doctor "honoris causa" por la Universidad de Toulouse. En ese mismo año cedió su archivo a la comunidad monástica de Poblet (Tarragona). En 1985, fue titulado marqués de Tarradellas por el rey Juan Carlos I. Murió en Barcelona el 10 de junio de 1988.

Su pensamiento político era republicano y catalanista. Siempre defendió la cultura catalana desde un prisma no separatista que no vulnerara los derechos lingüísticos y culturales de los castellanohablantes. 

Afirmaba que Cataluña debía ser autocrítica, entender al pueblo español e integrarse en España. En su tarea política siempre pretendió establecer la conciliación y la concordia entre Cataluña y el resto de España. Abogó por los gobiernos de unidad en Cataluña con el propósito de que ésta fuese más fuerte, así como del diálogo positivo y constructivo con Madrid. 

Su actitud contraria a la independencia y al concepto de unos «Países Catalanes» hizo que fuese criticado por parte de diversos sectores nacionalistas e independentistas, que lo tacharon de traidor a Cataluña, de mal político y de vendido a la monarquía española. Uno de los personajes más críticos fue el historiador Josep Benet. Sin embargo, por parte del catalanismo moderado y de sectores no nacionalistas, Tarradellas es considerado un gran político, avanzado a su tiempo e incluso un visionario de hacia dónde se dirigiría la política catalana.

Fue muy crítico con Jordi Pujol, llegando a afirmar en 1985 que «La gente se olvida de que en Cataluña gobierna la derecha; que hay una dictadura blanca muy peligrosa, que no fusila, que no mata, pero que dejará un lastre muy fuerte».

El 21 de diciembre de 2018 el Consejo de Ministros del gobierno español aprobó, en homenaje a él, el cambio de nombre del aeropuerto de Barcelona, renombrándolo como Aeropuerto Josep Tarradellas Barcelona-El Prat, cambio de denominación se hizo efectivo el 1 de marzo de 2019, fecha en la cual se publicó en el Boletín Oficial del Estado (BOE).

El Archivo Montserrat Tarradellas i Macià se encuentra en el Palacio del Abad, junto al monasterio de Poblet, en Cataluña, y conserva el fondo personal de Josep Tarradellas y otros fondos personales, como son los de Carlos Sentís, Paul Preston, Joan Antoni Samaranch, Josep Maria Bricall o Ramon Barnils.





</doc>
<doc id="27928" url="https://es.wikipedia.org/wiki?curid=27928" title="Bon Odori">
Bon Odori

El es un festival de danza tradicional japonés. El Bon Odori se celebra en Japón cada verano (entre julio y agosto) y es organizado localmente por cada ciudad.

"Bon" es una temporada festiva durante la cual se da la bienvenida a las almas de los ancestros. El Bon es una tradición budista, originaria de China.

Durante el Bon Odori la gente se reúne en lugares abiertos alrededor de una torre con tambores taiko (tambor japonés) y baila al compás de la música tradicional. La música debe ser alegre para dar la bienvenida a las almas de los ancestros y la gente debe mantener un humor alegre. El Bon Odori debe ser celebrado durante la noche debido a que se cree que las almas de los ancestros regresan durante la noche.

En Argentina la comunidad japonesa lo festeja durante el verano austral.

Desde 1999, en Colonia Urquiza, partido de La Plata, se celebra el "Bon Odori La Plata" en el predio de la Escuela Japonesa de dicha ciudad (calle 186 y 482). Todos los años, en el segundo sábado del mes de enero, miles de personas se suman al festejo. Durante toda la tarde y noche se realizan show de taiko y daiko, presentaciones de danza tradicional, feria de artesanías e indumentaria, juegos, patio de comidas, espectáculos de fuegos artificiales y el tradicional baile colectivo alrededor de la torre principal (yagura)

 


</doc>
<doc id="27935" url="https://es.wikipedia.org/wiki?curid=27935" title="Seijin no Hi">
Seijin no Hi

El es el día en que los japoneses celebran su mayoría de edad.
Traducido literalmente como "Día del Adulto".

Los jóvenes que cumplen los 20 años entre el 2 de abril del año anterior y el 1 de abril del año presente son convocados a una ceremonia en que el alcalde les informa de las responsabilidades que deberán afrontar a lo largo de su vida como adultos. Después rezan en los templos cercanos a su ciudad. Para la ocasión, visten sus mejores kimonos y trajes tradicionales.

El "seijin no hi" es oficial desde 1948. Desde entonces hasta 1999 se celebraba el 15 de enero. Desde el año 2000, al haberse dictado la ley denominada "Happy Monday", tiene lugar el segundo lunes de enero: dependiendo del año caerá entre el 8 y el 14 de enero.


</doc>
<doc id="27938" url="https://es.wikipedia.org/wiki?curid=27938" title="Movimiento Scout Católico">
Movimiento Scout Católico

El Movimiento Scout Católico (Scouts MSC) se define como un movimiento de educación integral que se propone formar hombres y mujeres libres, críticos, comprometidos con su fe y en el momento histórico que les ha tocado vivir, abiertos a los demás, capaces de amar y de vivir en grupo.

Su metodología pedagógica scout se basa en la vida en pequeños grupos, la autogestión, el contacto con la naturaleza, el juego, la adhesión libre a la ley scout y una promesa como camino de experimentación del compromiso.

El Movimiento Scout Católico es un movimiento de apostolado seglar de la Iglesia católica, erigido canónicamente como asociación pública de fieles por la Conferencia Episcopal Española el 6 de julio de 1973. Es por tanto el movimiento responsable del escultismo católico en España, estructurado organizativamente como una federación de asociaciones scouts confesionales católicas. En la actualidad agrupa a más de 28.000 niños, niñas, jóvenes y educadores scouts de toda España repartidos en cerca de 500 Grupos Scouts. Está presente en todas las comunidades autónomas y en la mayoría de las diócesis españolas. 

En el ámbito internacional Scouts MSC es miembro de la Organización Mundial del Movimiento Scout (OMMS) que agrupa a más de 30 millones de scouts de la mayoría de países del mundo, organizados por regiones (Scouts MSC pertenece a la Región Europea de Escultismo). Asimismo, pertenece a la Conferencia Internacional Católica de Escultismo (CICE) que agrupa a Asociaciones Scouts Nacionales católicas y a Comités Pastorales scouts católicos de asociaciones pluriconfesionales, que son parte de la OMMS, ante quien goza de estatus consultivo y cuyos estatutos están aprobados por el Pontificio Consejo para los Laicos de la Santa Sede. 

El Movimiento Scout Católico ha aportado a lo largo de su historia a diversas personas para los órganos internacionales del Escultismo Mundial. Así, el Dr. Mario Díaz ha sido miembro (2005-2011) y Vicepresidente (2008-2011) del Comité Scout Mundial (equipo directivo de 12 personas que dirige la OMMS), el hermano lasaliano José Antonio Warletta ha sido Presidente del Comité Scout Europeo, D. Enrique López Viguria ha sido Secretario Mundial de la CICE y D. Jaume Bosch i Puges ha sido Secretario Regional de la CICE Europa-Mediterráneo.

A nivel de España, Scouts MSC forma parte de la Federación de Escultismo en España (FEE) creada en 1978 y que actualmente está formada por la Federación de Asociaciones de Scouts de España (ASDE) y el Movimiento Scout Católico y cuenta cómo entidad asociada con la Federació Catalana d'Escoltisme i Guiatge (FCEG). 

Scouts MSC es miembro de pleno derecho y fundador del Consejo de la Juventud de España, entidad que ha presidido en el mandato constituyente (Enrique López Viguria) y en la de su 25 aniversario (Daniel Lostao, 2008-2010). Además prácticamente todas sus asociaciones forman parte de los Consejos de Juventud Autonómicos. Scouts MSC forma parte también de la Plataforma de Organizaciones de Infancia, de la Plataforma de Voluntariado de España, del Foro de Laicos y, como movimiento confesional y de iglesia, mantiene contacto en el ámbito formal con la Conferencia Episcopal Española a través de la ´Comisión Episcopal de Apostolado Seglar, participando en las reuniones convocadas por el Departamento de Juventud. 

Además, tiene relaciones y proyectos conjuntos de solidaridad, hermanamiento y convivencia cultural e interreligiosa con Asociaciones Scouts de Alemania, Argelia, Bélgica, Bolivia, El Salvador, Francia, Italia, Libia, Marruecos, Portugal, Uruguay...

El 22 de enero de 2013 de declarada de Utilidad Pública por el Ministerio del Interior.

Los principios fundamentales del Movimiento Scout Católico se definen en la Carta de Scouts MSC, documento aprobado en la 51ª Asamblea General Ordinaria del Movimiento Scout Católico (Madrid, 24 y 25 de octubre 2009).

Scouts MSC se define como un movimiento Educativo dirigido a niños, niñas y jóvenes con un Proyecto Educativo que integra como agentes educativos a responsables, familias y comunidades cristianas que conforman el entorno educativo del Escultismo.

Scouts MSC se define como parte del Movimiento Scout, de acuerdo con los valores recogidos por la Ley y Promesa, mediante la aplicación del método Scout, con el objetivo de contribuir a la transformación positiva del mundo.

Scouts MSC se define como parte de la Iglesia católica y corresponsables de su misión a través de su proyecto educativo. Scouts MSC está abierto a cualquier persona dispuesta a profundizar su experiencia trascendental con independencia de su tradición religiosa. Scouts MSC está comprometido a fomentar la pluralidad, el Ecumenismo y el diálogo interreligioso.

Scouts MSC se define como un movimiento comprometido con su entorno social, abierto a la cooperación con todos. Scouts MSC se compromete con la preservación y sostenibilidad del medio natural. Scouts MSC promueve un modelo social intercultural donde todos tienen cabida a través del método Scout.


La dirección de Scouts MSC se lleva a cabo por medio de un Consejo, un Comité Federal y una Asamblea. Para vertebrar el funcionamiento de la federación se constituyen otros órganos de trabajo: Permanentes, Comités y equipos de trabajo.

El Consejo es el órgano director de Scouts MSC y está formado por:

El Comité Federal es el máximo órgano de gobierno de Scouts MSC entre asambleas y está formado por el Consejo (con voz y sin voto) y los presidentes de las asociaciones miembro. Se reúne con periodicidad trimestral.

La Asamblea es el máximo órgano de gobierno. Está compuesta por el Consejo y una delegación de cada asociación miembro encabezada por su Presidente y su Consiliario. Se reúne dos veces al año con carácter ordinario.

Una Mesa temática es un órgano que coordina, propone y anima las líneas de actuación de Scouts MSC en un área concreta. Formadas por los representantes de las federaciones para las distintas áreas de trabajo. En la actualidad (2018) existen las siguientes:

Son grupos operativos de apoyo, seguimiento y coordinación de distintos programas o servicios de Scouts MSC. En la actualidad (2018) son:

Los comités son grupos asesores de personas expertas, de intercambio de información y delimitación de estrategias en un campo
determinado.

Las comisiones son grupos operativos de apoyo, seguimiento y coordinación, encargados de la realización de una tarea concreta con
duración determinada.

El movimiento scout católico es uno de los movimientos en los que el uniforme es muy importante a la hora de cualquier celebración, dependiendo de los grupos este será rutinario o se utilizará de forma excepcional, para eucaristías o actos scouts. Está formado por la camisa que es universal para todo el movimiento scout católico que va cambiando de coloren función de la rama a la que se pertenezca quedando enmarcado de la siguiente manera:

Además la camisa lleva dos insignias que son también a nivel nacional, además de las propias de cada comunidad autónoma y de cada grupo, a esto le acompaña la pañoleta del grupo para encontrar el sentimiento de permanencia al mismo con el nudo de la amistad siempre y cuando no se tenga promesa, en algunos grupos también forma parte el del uniforma las botas de montaña y el pantalón.




</doc>
<doc id="27943" url="https://es.wikipedia.org/wiki?curid=27943" title="MSC">
MSC

MSC puede referirse a:


</doc>
<doc id="27945" url="https://es.wikipedia.org/wiki?curid=27945" title="Apretón de manos">
Apretón de manos

Un apretón de manos (o estrechón de manos) es un tipo de ritual corto (saludo), donde dos manos derecha con derecha o izquierda con izquierda son aferradas una con la otra, generalmente realizado cuando dos personas se encuentran o despiden, o cuando se termina un acuerdo. Su propósito es demostrar buenas intenciones y posiblemente haya sido originado como un gesto para mostrar que las manos no portan armas.

Generalmente es considerado inapropiado el rechazar un apretón de manos y en la mayoría de los círculos sociales se espera que aquella persona con el mayor estatus social sea quien lo inicie,
particularmente de una reina.

Antiguamente era considerado un insulto el entregar la mano izquierda en vez de la derecha, mas hoy en día, los "Scouts", miembros de las organizaciones que promueven el escultismo, han cultivado la tradición de un saludo con la mano izquierda basados en una experiencia de guerra de Robert Baden-Powell.

En muchos lugares del mundo un saludo de manos con un apretón mediocre o no existente no es bien aceptado. Tampoco suele ser apreciado un saludo de manos donde alguno de los participantes tengan la mano sudada o sucia, especialmente si padece alguna enfermedad, pues los apretones de manos son una vía común de transmisión del virus del resfriado común.

El del apretón de manos es antiguo. Hay ciertos indicios, ya en época prerromana, que así lo atestiguan. Se trata de las denominadas «teseras de hospitalidad», documento portátil en bronce o plata del que cada parte comprometida conserva una mitad. Estas teseras tienen forma figurada (animal: jabalí, delfín, etc., «manos entrelazadas» o formas geométricas). El texto está escrito en varios casos en lengua celtibérica (Osma, Monreal de Ariza, Sasamón, Cabeza del Griego, etc.) y otros en lengua latina, y su límite cronológico se sitúa entre los siglos II a. C.-I d. C.

Los «pactos de hospitalidad» eran una costumbre muy asentada entre los pueblos indoeuropeos occidentales y en la península ibérica un elemento indígena que pervivió a la organización romana. Eran acuerdos de amistad, una vinculación especial por la cual los implicados (individuos o ciudades) se recibían en mutua protección, reconociéndose leyes, derechos y deberes que se plasman sobre teseras (manos entrelazadas) o cartas tábulas (tablas de bronce). Hasta entonces los pactos de hospitalidad siempre habían sido verbales, un rito con presencia de testigos y de los dioses que actuaban como garantes. Las teseras y kortikas (cortes o cartas) de nuestro legado arqueológico fueron escritas en lengua celtíbera y alfabeto ibérico (similar al griego) y latino.

El apretón de manos se utilizó en la Edad Media. Los caballeros para saludarse «daban» la mano contraria al lugar donde llevaba la espada, que solía ir colgada a la izquierda. Al ofrecer esa mano el contrincante se aseguraba de que este no iba a sacar la espada de repente para atacarlo.

Desde el siglo XX el apretón de manos occidental es utilizado en todo el mundo, aunque algunas culturas poseen formas alternativas de saludar, las cuales son preferidas sobre el apretón. Se dice que las sociedades secretas y algunos grupos privados incorporan saludos de manos únicos.



</doc>
<doc id="27956" url="https://es.wikipedia.org/wiki?curid=27956" title="Bingo">
Bingo

El bingo (del inglés "bingo") es un juego de azar que consiste en un bombo con un número determinado de bolas numeradas en su interior. Los jugadores juegan con cartones con números aleatorios escritos en ellos, dentro del rango correspondiente. Un locutor va sacando bolas del bombo, anunciando los números en voz alta. Si un jugador tiene dicho número en su cartón lo tacha, y el juego continúa así hasta que alguien consigue marcar todos los números de su cartón.

Existen varias teorías sobre cuando empezó esta actividad, pero la mayoría de ellas la datan del siglo XVI. Se trata de un juego muy popular en todo el mundo del que existen dos variedades típicas, que son la de 90 bolas y la de 75 bolas.

Algunas teorías remontan el origen de este popular juego de azar al tiempo de la cultura romana. Otras lo relacionan a la antigua Italia en el siglo XVI, pero lo realmente cierto es que constituye una de las primeras formas de juego popular.

La historia conocida de este juego (no aceptada por todos los historiadores) se remonta a la época de los bárbaros y los potentados que cobraban los famosos impuestos a diferentes aldeas, villas, entre otros estamentos de la sociedad en épocas remotas.

El juego en general consistía en integrar en un recipiente varias bolas con números que representaban a diferentes aldeas de las diferentes potencias y sobre la base de los aciertos los caballeros y soldados hacían los cobros en oro, plata, minerales, joyas y otros objetos de valor como compensación y retribución de su suerte en ser elegidos, en varias ocasiones los valores adquiridos eran para el uso de construcciones y en otras ocasiones los utilizaban para la alimentación de grandes masas de ejércitos y entre otros para combatir conflictos y conquistas.

Con el transcurso de los años y debido a nuevas normas asociadas a la sociedad y leyes que promulgaron grandes potentados como es el caso de los romanos, estos juegos que anteriormente se utilizaban para el recaudo de dinero y riquezas, empezaron a ser utilizadas para brindar diversión a los diferentes visitantes y exploradores del mundo en busca de negocios y sobre la base de esto las ideas que se crearon fueron basadas en brindar diversión con juegos, bailes, mujeres y estamentos de prestigio con otras disciplinas como fueron los dados, las barajas, y otros juegos que ahora divierten a millones de jugadores y apasionados apostadores en el mundo.

En cambio, numerosos historiadores y especialistas afirman que el origen de esta costumbre es la lotería italiana, cuando se unieron los reinos de Italia en 1530. La hipótesis de gran aceptación afirma que el antecesor del popular juego es “Il Giocco del Lotto d`Italia”, una lotería nacional que era jugada semanalmente y se ha extendido en el tiempo hasta la fecha actual. Hoy en día, es un componente esencial del presupuesto del país, que genera más de 75 millones de dólares en ingresos actuales. “Lo Giuoco del Lotto d’Italia” se juega cada sábado en este país.

La cercanía operativa de ambos juegos se manifiesta en los elementos que intervienen para el desarrollo de los mismos. En los dos casos, el organizador debe contar con bolas numeradas, un bolillero o tómbola y cartones numerados. El social juego de bingo parece ser una evolución de este juego que se ha extendido por siglos en la región de Italia.

En 1770, este juego llamó la atención a los franceses, quienes lo denominaron Le Lotto, y se estableció con las reglas que se siguen aún en la actualidad. Fueron los primeros en jugar con las tarjetas de bingo, fichas y en cantar en voz alta los números.
En esta época, sólo fue jugado por la gente de la alta aristocracia. Los premios no eran organizados de la manera actual sino que se extendían en numerosas posibilidades de reconocimiento por ganar. Distintos elementos típicos de los años mencionados constituían los premios.

En los años 1800 el bingo se propagó rápidamente por toda Europa. Los juegos de bingo educativos se hicieron populares.
En 1850 fue diseñado un juego de bingo en Alemania para enseñarle a los niños las tablas de multiplicar, además de otros juegos de bingo educativo como “bingo para deletrear”, “bingo animal”, “bingo histórico”.
Estos bingos fueron diseñados para proporcionarles a los niños de 3 a 6 años de edad un poco de diversión y al mismo tiempo, enseñarles a cantar y a reconocer los números.

Después de extenderse por toda Europa el juego comenzó a presentarse en Norteamérica. En un principio el juego se hizo popular en las ferias de los pueblos y festivales. Consistía en un organizador que sacaba discos enumerados de una caja de cigarros mientras los jugadores marcaban los números en sus tarjetas colocando alubias (frijoles) sobre ellas y se gritaba “beano” si ganaban.

Durante una visita al carnaval de Atlanta en 1929, Edwin Lowe, un vendedor de juguetes de Nueva York, descubrió el Beano. Lowe notó la gran emoción que sentían los jugadores. Intentó participar en un juego de Beano esa misma noche, pero no consiguió un sitio. Los jugadores estaban muy enganchados, y cuando el hombre que llevaba el juego de Beano intentó cerrar el chiringuito, los jugadores simplemente rechazaron dejar de jugar. Finalmente, a las 3 de la mañana, según cuenta la historia, el organizador dejó paso a Lowe.
Al regresar a Nueva York, Lowe compró algunas alubias, y todo el resto de cosas necesarias para poder realizar el juego. Invitó a algunos amigos a su apartamento para poner a prueba su nuevo juego. Antes de lo que se imaginaba, sus amigos estaban jugando al Beano con la misma emoción y fervor que los que había visto en el carnaval. Durante un juego, Lowe estudió el comportamiento de un jugador que estaba a punto de ganar. Sólo necesitaba un número más para completar su tarjeta, pero se ponía más y más nervioso cuando veía que su número no salía. Finalmente, cuando consiguió tapar todos sus números, de la emoción gritó:” B-B-B-BINGO!” en vez de Beano. Esto es lo que explica su nombre de hoy en día.

Una vez dado a conocer en Norteamérica, rápidamente se extendió en el resto del mundo.

Un cura de Wilkes-Barre, Pensilvania, es el hombre responsable de introducir por primera vez el bingo como forma de recaudar fondos para la iglesia. Un miembro de la congregación sugirió utilizar el juego para poder obtener dinero para mantenimiento. Fue entonces, cuando el juego del bingo, original, que solo ofrecía 24 variantes únicas de tarjetas, se fue expandiendo. Dado que cada vez eran más los miembros de la iglesia que tomaban parte en el juego del bingo, se repartían más cartones. Los curas pronto se dieron cuenta de que muchos jugadores ganaban el mismo juego, por lo tanto buscaron nuevas formas para hacer que las combinaciones de números fueran únicas.

Para ello, pidieron ayuda a Lowe, quien contrató a un profesor de matemáticas de la universidad de Columbia, llamado Carl Leffler, para que lo ayudase a incrementar la cantidad de combinaciones en las tarjetas de bingo. Para 1930, Leffler ya había creado más de 6000 tarjetas de bingo con combinaciones únicas (se dice que después de esto Leffler se volvió loco).

Esta nueva forma de bingo hizo que este juego se consolidara como forma para recaudar fondos. Para 1934, ya había más de 10000 bingos semanales operativos en toda América del Norte. Desde las iglesias hasta las reservas de indios americanos, todos ellos eran jugadores de bingo que gastaban semanalmente 90 millones de dólares en bingo solamente en el norte de América.

En 1977 se autorizó el bingo en España. Se inventó un nuevo sistema de bingo diferente al que imperaba por entonces: el bingo de 90 números. En la década de los ochenta se vivió una auténtica fiebre del “bingo moderno” cuando las máquinas y los salones de juego entraron en escena.

En 1992 había 604 salas de bingo en España, según los primeros datos oficiales conocidos. Hoy en día existen diversidad juegos de internet.

El juego estaba vetado en España desde el año 1922, por lo que cualquier tipo de juego solo se hacía en el ámbito privado o de una forma ilegal.

Tras el final de la dictadura y el paso a la democracia empieza a plantearse la idea de regular y legalizar el juego, para ellos se lleva a cabo un Real-Decreto, por el que se regulan los aspectos penales, administrativos y fiscales de los juegos de suerte, envite o azar y apuestas. Es el llamado REAL DECRETO-LEY 16/1977 de 25 de febrero. Tras la aprobación de esta ley comienzan en España a surgir las primeras salas de bingo.

Aparte, existen otras leyes a nivel nacional que afectan de una forma u otra a las salas de bingo en competencias como: Propiedad Intelectual, Haciendas Locales, Defensa de la Competencia, Legislación Mercantil, Ley de Sociedades, Impuesto de Actividades Económicas, Competencia Desleal, Protección de la Seguridad Ciudadana, transferencias de competencias a las Comunidades Autónomas, Riesgos Laborales, Norma Básica de Edificación, Ficheros de Prohibidos, etc.

A partir de la normativa nacional, cada comunidad autónoma redacta su propia normativa que regula el mundo del juego en todos sus ámbitos:

El juego del bingo se compone de un bombo con bolas numeradas, cartones con números aleatorios impresos y rotuladores o fichas para tachar o tapar estos.
Una partida consiste en extraer las bolas del bombo al azar y cantar su respectiva numeración. Los jugadores, provistos de cartones, tacharán el número cuando éste sea cantado por el cajero (persona que se encarga de la extracción de las bolas).
Al completar una línea horizontal en un cartón, el jugador deberá cantar "línea" y se llevará un pequeño porcentaje del total recaudado con la venta de los cartones. Cuando un jugador consigue tachar todos los números de su cartón, tendrá que gritar "bingo" y se convertirá en el ganador de la partida llevándose, así, el porcentaje mayor de la recaudación en concepto de premio...

En el juego del bingo se necesitan unos elementos indispensables, como son un bolillero o bombo,
las bolillas o bolas de números, cartones y un espacio de mesas.

La facilidad con que puede organizarse un juego de bingo es uno de los factores que ha motivado la
extensión de este entretenimiento de azar.

El bombo, o bolillero, está formado por dos cúpulas semiesféricas transparentes muy resistentes a los
golpes, ya que han de soportar el impacto de las bolas.

Las cúpulas tienen 50x50 cm.
El modo de girar del bolillero puede variar, puede ser movido por una manija, de forma manual, o
mediante un motor eléctrico que lo hace girar.

Una vez que una de las bolillas fue separada, se dice su número y se continúa mezclando. En el caso
del bolillero manual, mientras se retira la bolilla separada se detiene el mezclado. Con el bolillero
eléctrico el mezclado no se detiene nunca porque la bolilla se desliza por un canal.

En ambos casos, luego de que el número es anunciado, los jugadores deberán marcar las
coincidencias en todos los cartones de bingo que posean. Este trabajo puede ser abrumador si se tienen más tarjetas de las que se pueden abarcar, por lo que recomendamos no jugar con más de tres o cuatro tarjetas. El tiempo entre bolillas es muy breve.

Las bolillas para el bingo tienen las siguientes características especiales:

Material: nitrato de celulosa

Impresas en 10 (diez) posiciones

Colores: negro, azul, verde, rojo y naranja, fondo blanco

Diámetro: 38,5 mm (+/ 0,5 mm)

Peso: 2,5 g (+/ 0,5 g)

Los cartones son una de las piezas fundamentales para poder jugar al Bingo. Dichos cartones son fabricados en material adecuado para facilitar que puedan ser marcados por los jugadores, y son válidos exclusivamente para una sola partida. Los cartones pertenecen a series que contienen un número no inferior a 96.000 cartones distintos.

En el anverso de cada cartón figura la serie a la que pertenece, rango de número de cartones dentro de cada serie asignado al establecimiento, número de orden y número de cartones que integran la serie. En el dorso se consignan los impuestos a satisfacer, así como un extracto de las principales reglas del
juego. Igualmente se consigna en el dorso de los cartones la advertencia de que la división de los
dos cartones de la unidad de venta, así como las marcas o tachaduras que impidan la lectura de los
elementos identificativos del cartón, inutiliza éste a efectos de premio.

Los cartones de bingo son fabricados por la “Real Casa de la Moneda. Fábrica Nacional de Moneda y Timbre”. Los Cartones de Bingo se imprimen a 4 colores y que incorporan numeración. La impresión (series) se lleva a cabo en bobinas, por un procedimiento offset, realizándose a la vez la numeración de los cartones. En cada serie salen 1944 cartones de bingo, esto se debe al proceso de fabricación (54 planchas de 36 cartones cada una), aparte de este criterio de 1944 cartones, también existe el de 3888 (múltiplo
de 1944). Estos dos criterios se utilizan en todas las salas de bingo.

Las series se entregan en tiras de 6 cartones dispuestas verticalmente y cada tira consta de los 90
números que intervienen en el juego del bingo. Se producen guías y distintivos de máquinas recreativas a solicitud de las diversas Comunidades Autónomas, incorporando diferentes elementos de seguridad tanto en el soporte como en la impresión. La preocupación es la seguridad de que los cartones no puedan ser falsificados o manipulados. Por esto, la FNMT-RCM ofrece plena seguridad mediante el uso de papeles con marca de agua, tintas invisibles y otros elementos de seguridad, que permiten diferenciar en el acto cualquier falsificación.

El cartón se protege de manera que cualquier intento de manipulación lo deteriora
irreparablemente. Los cartones varían en formato según el tipo de bingo en el que se vayan a utilizar, así tenemos
características diferentes según sea bingo simultáneo, bingo online, binjuegos o el bingo clásico en
sala.

Jefe/a de Sala: ejercerá la dirección y control general del funcionamiento de la sala, adoptando las decisiones relativas a la marcha de las distintas operaciones de acuerdo con las normas técnicas del bingo y adecuando el ritmo de aquellas en consideración a la afluencia de público, cartones, cuidará del correcto funcionamiento de todos los aparatos, instalaciones y servicios; ejercerá la jerarquía sobre todo el personal al servicio de la sala; será el responsable de la correcta marcha de la contabilidad específica del juego, así como la tenencia y custodia de la propia sala, de las autorizaciones precisas para su funcionamiento y de la documentación relativa al personal.
Jefe/a de Mesa: será el responsable de la comprobación de las bolas y cartones; llevará la contabilidad de los cartones vendidos para cada sorteo; efectuará la determinación de los premios de línea o bingo respectivamente, comprobará los cartones premiados, informando de todo ello a los jugadores, será responsable del libro de actas de registro y llevará el control del “stock” de cartones por partida. Contestará individualmente cuantas peticiones de información o reclamaciones formulen los jugadores y consignará todo ello, así como las incidencias que se produzcan, en el acta

Locutor/a-Vendedor/a: realizará la venta directa de los cartones y la recaudación de su importe, que entregará junto con los cartones sobrantes al Cajero/a; retirará de la mesa, antes de efectuar la venta de los nuevos cartones, los utilizados por los jugadores en la jugada anterior y repasará las series dentro de su jornada laboral. En su turno de Locutor/a pondrá en funcionamiento la máquina cuando se inicie la jugada, leerá en voz alta el número de la bola según el orden de salida; apagará la máquina al finalizar el juego y abonará a los jugadores los importes de línea y bingo, contando su importe en el momento del abono, para facilitar el abono de los premios durante la venta de cartones de la siguiente partida y siempre que la organización del trabajo lo permita, este cometido lo podrá realizar cualquier otra categoría profesional definida en este artículo. Cuando realice la labor de locución no realizará la función de venta de cartones, aunque podrá colaborar en otras funciones dentro de la sala.

Admisión y Control: será el encargado/a de controlar la entrada de jugadores en la sala de juego, comprobando que el carnet corresponde a la persona que lo presenta, y negando la entrada a las personas que lo tuvieran prohibido, dando cuenta al Jefe/a de Sala de los incidentes. Tendrá asimismo como misión la llevanza del fichero de visitantes y su actualización.

Servicios Auxiliares: estas categorías: administración, aparcacoches, porteros/as, vigilantes y personal de limpieza, etc., no están comprendidas entre las técnicas del Bingo y realizarán las funciones propias de sus especialidades, sin que les sea exigida credencial de juego o permiso gubernativo alguno.

Hay dos Grupos Profesionales que engloban las Categorías específicas del juego del Bingo:

Grupo de Técnicos de Juego: que integra las Categorías Profesionales de Jefe/a de Sala, Jefe/a de Mesa y Cajero/a.
Grupo de Técnicos de Sala: integrado por las Categorías Profesionales de locutor/a-Vendedor/a y Admisión-Control.

El juego de bingo posee elementos que le son propicios para su composición, una de ellos
es el cartón. Existen diferentes tipos y clases de cartones para desarrollar un juego de bingo.
Los cartones de bingos contienen casilleros con números desde los más bajos hasta los más
altos y viceversa.

Bingo simultáneo

En el bingo simultáneo se juega sobre 90 números, del 1 al 90, ambos incluidos, y de forma simultánea
por jugadores presentes en diferentes salas de juego colectivas de dinero y azar, integrados en una
Red de distribución.

Así, los cartones están formados por quince números diferentes entre ellos, compuestos de 3 filas y 9
columnas.

Los cartones tienen que cumplir el modelo aprobado por el órgano administrativo correspondiente y
que tenga atribuida la competencia en materia de juego. Estos cartones tendrán el soporte material
adecuado para facilitar que puedan ser marcados por los jugadores, siendo válidos exclusivamente
para una partida.

Bingo online

El cartón en este caso es visual y no existe coste de impresión del papel.
Los jugadores de todas las salas juegan la misma partida de manera simultánea.

Se convierte en un juego rápido y de bajo coste por partida. El sistema empleado es con tarjeta chip.
Dentro del bingo online tenemos la modalidad del bingo online clásico, el online 75 y el flash.

Bingo electrónico online

El formado del cartón corresponde con el clásico español, 15 números sobre 90; la única diferencia
es el uso de un terminal electrónico. El jugador compra sobre el ordenador los cartones que quiere
jugar y aparecen en la pantalla. Todos los terminales conectados a la red juegan la misma partida.

Bingo 75

Es el Bingo americano, muy jugado en red. Tiene formato de cartón y juego de 24 números
sobre 75 (la casilla central no tiene número). Basado en la realización de figuras dentro del cartón se pueden
obtener diferentes posibilidades de premios de bingo (líneas, diagonales,
cruces, etc...). Estas figuras se llaman “patrones”, y cada juego tiene uno o más patrones que dan premio.
La composición del cartón es la siguiente: en la columna “B” se ubican los
números entre el 1 y el 15, en la columna “I” los números del 16 al 30, en la
“N” los números del 31 al 45, en la “G” del 46 al 60 y finalmente en la
columna “O” los números del 61 al 75. Los patrones para premios de
Bingo como se ha dicho antes, pueden ser de cualquier forma: en diagonal, línea, cruces, cuadrados, letras... En cada juego se especifica qué patrón da premio.
Bingo flash

Bingo electrónico en red con formato “flash”, 3 números sobre 15. El sorteo consistirá en extraer 9
bolas. Los cartones utilizados tienen 3 númerso que van desde el número 1 al 15 y cada número tiene
un color de 6 posibles, en caso de completar el cartón en la extracción número 3, el premio de bingo
equivale a pagar la apuesta realizada (0,25 euros por cartón) por 30, en caso de completar el cartón
en la extracción número 4, el premio equivale a pagar la apuesta realizada por 15 y así
sucesivamente

Cash bingo

Bingo electrónico en red con formato de cartón de 16 números sobre 80. El Cash Bingo se juega
sobre cartones (virtuales) en los cuales los 16 números se representan en cuatro columnas de cuatro
números cada una. En la primera columna se sitúan los números del 1 al 20, y es de color rojo. En la
segunda columna se sitúan los números del 21 al 40 y es de color amarillo. En la tercera columna se
sitúan los números del 41 al 60, y es de color azul. Finalmente, en la cuarta columna se sitúan los
números del 61 al 80 y es de color blanco.

Binjuegos

Es el equivalente a la modalidad del bingo interconectado acumulado con múltiples
estructuraciones de premios, que se juega en una sala virtual formada por los terminales distribuidos
en las diversas salas, jugando los diversos jugadores de forma totalmente asíncrona pues su objetivo
de premio se construye en una fracción porcentual sobre un acumulado general, y que por los límites
que tienen las estructuras (de más de 5 categorías), los premios son fijos.

El cartón es virtual. No existe coste de impresión de papel.
Las modalidades de juegos dentro de Binjuegos son: Bingo 33 y Bingo Keno.

Bingo 33

Juego de bingo electrónico con formato de cartón clásico, 15 números sobre 90, jugado sobre
terminales electrónicos. El jugador compra un determinado número de cartones, y a continuación
inicia la extracción de un sorteo de 33 bolas. Una vez finalizadas las extracciones, se comprueba el
número de líneas, dobles líneas y bingo obtenidos por el jugador. Existen premios adicionales
dependiendo del número de extracción con que se completa el cartón.

"'Bingo Keno"

Juego de bingo electrónico que consiste en seleccionar 10 números de 80 posibles. Esta selección
puede ser automática o manual. Seguidamente, el jugador inicia la secuencia de extracción de un
sorteo de 20 bolas, y finalizadas las extracciones se comprueba el número de aciertos obtenidos.
Existe un plan de ganancias dependiendo del número de aciertos.

Bingos no oficiales

Son fabricados para reuniones familiares, animación, fiestas, hoteles, discotecas, asociaciones…
Las series son de 960 cartones, y se venden en paquetes de 10 series. Estos cartones no necesitan de
bolígrafo porque disponen de lengüetas. Este modelo de cartón está registrado en la Oficina Española de Patentes y Marcas.

Tienen un formato de 12 × 7 cm, y cada paquete pesa 7 kg.
La diferencia entre los dos modelos está en el papel y en las perforaciones de las lengüetas, el
primero es cartulina y tiene perforaciones en círculo, mientras que el segundo es de cartón y las
perforaciones conforman un rectángulo.

Son unos paneles informativos que muestran información relativa a los premios.

En el caso del bingo clásico Español, son paneles de 90 números, que indican los números extraídos a
medida que los va cantando el locutor.

Es el ordenador de control de juego de la sala. Desde él se gestionan todos los elementos del bingo,
e incluye una extensa cartelería de mensajes, informes sobre estadísticas, premios… que sirven de
ayuda en la gestión del negocio.

Es el gestor de caja de sala, herramienta imprescindible para una rápida y segura venta y liquidación
de cartones.

El sistema de admisión controla el acceso del público a la sala de juego, respetando las exigencias
de la normativa de Protección de Datos.

Está disponible en diferentes versiones adaptadas a los requerimientos de todas las Comunidades
Autónomas.

Permite un juego más eficaz de acercar a los clientes la información sobre el juego. Hay posibilidad de poner 1,2 y 3 monitores en mesas.

En el telebingo se puede ver el número de cartones vendidos, el precio del cartón, los premios (línea,
bingo, prima y acumulado), las bolas que se extraen, las bolas que ya se han extraído, las 3 últimas
cantadas y el orden de extracción. Cuando la partida acaba se puede poner un programa televisivo
en el descanso.

Hay distintas posibilidades de locución automática: desde el modo de seguridad (que evita los
errores de pulsación de números en el teclado) y el modo absolutamente automático (que sustituye
al locutor). Este último tiene la posibilidad de grabación de un amplio número de voces.

Existen varias versiones, son de 15”, pantalla táctil y pueden ser inalámbricos y con cable. El monitor
se suspende sobre la mesa.

Hay otro tipo de modelo en donde el terminal es inalámbrico, portátil, con una batería de 12 horas y
una pantalla táctil de 8,5”.

Existen dos tipos principales de bingo, el bingo de 75 bolas y el de 90 bolas. La forma de jugar es la misma en ambos tipos, pero el número de bolas existentes en el bombo y los cartones varia de uno a otro.

Como su nombre indica, en el bingo de 75 bolas existen 75 bolas numeradas del 1 al 75 en el bombo. Este tipo de juego es más común en Norteamérica. Los cartones tienen un total de 24 números, divididos en 5 columnas. Las columnas están definidas por cada una de las letras del bingo, B, I, N, G, O, y en cada una de ellas están los números dentro de un rango específico. En la columna B se encuentran los números que van desde el 1 hasta el 15, en la I van del 16 al 30, en la N del 31 al 45 sin número en la tercera fila, en la G del 46 al 60 y por último en la O van desde el 61 hasta el 75. En este tipo de bingo se puede ganar un premio rellenando todos los números de nuestro cartón. Esto se conoce como bingo o full house. La otra manera de ganar un premio jugando al bingo de 75 bolas, es consiguiendo marcar en nuestro cartón una determinada figura preestablecida antes de empezar el juego, como alguna letra, o algún símbolo, sin necesidad de marcar todos los números del cartón.

El bingo de 90 bolas es el que se juega en más partes del mundo. En esta versión el bombo tiene 90 bolas numeradas del 1 al 90. Los cartones tienen 15 números que debes marcar. Estos números se encuentran distribuidos en 3 filas diferentes, con 9 columnas cada una, habiendo un total de 5 números por fila. Los números están mezclados con espacios en blanco. Aquí se pueden ganar premios de 3 formas diferentes, la primera de ellas es cuando consigues marcar todos los números que existen en cualquiera de las 3 líneas de un cartón. Este premio es llamado "línea". En algunos sitios se premia también al jugador que consiga marcar dos líneas de su cartón, pero no se hace en todos los lugares. Por último el premio más importante es cuando se canta bingo, que consiste en haber tachado todos los números de un cartón.

El bingo en red o bingo en línea se trata de un subapartado dentro de los juegos de casinos electrónicos, y es uno de los servicios más solicitados entre los clientes, ya que cuenta con bonos de juegos, promociones, ofertas para obtener ingresos económicos, además de todos aquellos premios que ya se encuentran en el bingo tradicional.
Dada la relevancia del bingo en el mercado, en los últimos años, debido a la extensión de Internet a todos los ámbitos de nuestra vida, se ha propagado la aparición de sitios web donde se puede jugar al bingo en línea. Se trata de una variación del bingo tradicional, pero con una mayor privacidad y sencillez de juego. La versión de este juego en sistemas virtuales se ha convertido en un gran atractivo dentro del mercado online.

El bingo en línea se regula interiormente a través de sistemas seguros de software, que proporcionan diversos organismos proveedores de software. Estas empresas tienen una amplia experiencia en el sector de las apuestas y en la construcción de bingos en línea, por lo cual se pueden obtener amplios resultados.
Otro aspecto interno importante para la construcción de bingos en línea son los distintos programas de afiliados que configuran estas páginas. Estos programas redirigen a los visitantes de sus páginas mediante banners a bingos en línea, por lo que un porcentaje de los beneficios del jugador, son para los afiliados. De este modo, el mercado se amplía potencialmente, y el sector de juegos y apuestas es un campo en auge para nuevos inversores en la red.

Los proveedores de software son las empresas destinadas a crear sistemas virtuales de desarrollo e innovación tecnológica. Se encargan del funcionamiento en línea de muchas estructuras específicas. Estas empresas de especializan en distintos sectores, abordando un mercado con mayor o menor competencia. La competencia, en la mayoría de los casos se condiciona por la rentabilidad económica y atractivo del sector.
En especial, el sector de las apuestas es un sector sumamente rentable, aunque muy explotado, por lo que la competencia e intención de liderazgo es muy alta. La capacidad de reinvención, de innovación tecnológica y de nuevas modalidades de juego es un proceso continuo, por lo que es un mercado altamente competente y en continua renovación.
Este sector está estrechamente vinculado con los programas de afiliados, por lo que amplían potencialmente su oferta y alcance.
Aquí se citan los principales proveedores de software, diseñadores de sistemas virtuales de bingo en la red:
- MAdEX Games Engine
- NextGen Gaming
- WagerWorks
- GreenTube
- Entraction
- Cyberarts
- Net Entertainment
- Parlay Entertainment
- Chartwell Technology
- Playtech
- Microgaming
- Cryptologic- Real Time Gaming
- Boss Media
- Ongame
- 888.com
- Zitro
- Virtuefusion
- Party Gaming
- ZedPlan
- Gtech G2
- Degestec Games

Un programa de afiliados es un acuerdo entre una página web y una empresa que vende bienes o servicios por Internet, por el cual paga una comisión a la entidad de la página web por cada venta que le hacen a un cliente referido desde su página.
Es un sistema beneficioso para poder ejercer la venta sin tener producto que vender. Únicamente se ejerce de intermediario, siempre aprovechando un nivel de visitas alto en la página. Si la página es nueva o no recibe las visitas apropiadas, al menos 3000 visitas diarias, el sistema no resulta beneficioso para el gestor.
Se obtienen beneficios por tres métodos:
- Por comisión de venta. Aproximadamente entre el 1% y 60% dependiendo del producto y el programa.
- Por clic sobre el banner. La comisión recibida es mucho menor, oscila entre 0.01 euros y 0.5 euros.
- Por referido. El beneficio se produce cuando el visitante referido se registra en la página enlazada. Puedo oscilar entre 1 euro y 5 euros por cliente.
En la actualidad, existen una gran variedad de programas de afiliados que abarcan un gran mercado en la red.

Los juegos lucrativos en línea en España, como es el caso del bingo en línea, son legales desde el 28 de mayo de 2011 mediante la publicación en el B.O.E. de la ley de Juegos de Azar 13/201. Las primeras licencias fueron otorgadas el 1 de junio de 2012. Ahora cualquier persona puede participar en línea en juegos de azar, ruletas, bingo, póquer, apuestas, etc con la máxima garantía de que el juego está regulado, supervisado y controlado por la Dirección General de Ordenación del Juego.

Se necesitan algunas condiciones para poder jugar al bingo en línea en España. Entre ellas destaca la condición imprescindible de haber cumplido los 18 años. Además a la hora de realizar un registro, este ha de ser personal, puesto que no está permitido jugar accediendo con las credenciales de otra persona. Por su parte, los operadores efectúan verificaciones periódicas de la correcta utilización de las cuentas. 
Con el objetivo de promover el juego responsable los operadores de bingo en línea con licencia, ofrecen a sus usuarios herramientas para fijar sus propios límites de gasto así como la posibilidad de desactivar su cuenta de manera temporal o permanente.

Estadísticas hechas a partir de las memorias de juego anuales del Ministerio del Interior de España.





</doc>
<doc id="27963" url="https://es.wikipedia.org/wiki?curid=27963" title="Capoeira">
Capoeira

Capoeira es una expresión cultural afro-brasileña que tiene diversas facetas como danza, arte marcial, música, acrobacias, y expresión corporal. Fue creado en la República de Angola y desarrollado en Brasil por los descendientes africanos con influencias indígenas probablemente desde los principios del siglo XVI, entre las clases populares. Es conocido por sus rápidos y complejos movimientos, que utilizan los brazos y las piernas para ejecutar maniobras de gran agilidad en forma de patadas, fintas y derribos, entre otros. La capoeira como arte marcial incorpora movimientos bajos, derribos, barridos, golpes de mano abierta, de puño, con los codos y las rodillas, con la cabeza e incluso el manejo de armas tradicionales; mientras que en el ámbito artístico ydeportivo se hace más énfasis en las acrobacias y las demostraciones ritualizadas de habilidad. Su práctica se desarrolla con música tradicional de tambores, el berimbau, y canto. Su practica es similar a la de la danza marcial del taekkyon en Corea.

La Roda de capoeira (círculo de personas haciendo Capoeira) fue declarada Patrimonio Cultural Inmaterial de la Humanidad por la Unesco el 26 de noviembre de 2014.

Existen varias teorías en relación al origen de la palabra capoeira. Una de ellas viene establecida por la lengua tupí-guaraní donde, "kapuêra" (ka´ávy = campo, matorral; puêra = que ya fue) resulta en la secuencia de las palabras capuíra, capoêra y capoeira. Según algunos estudios, la palabra capoeira designaría un tipo especial de jaulas, usadas en el transporte de aves (capón), que eran conducidas por esclavos a los mercados. El término se extendería de las jaulas a los esclavos, traídos de Angola, en África. Según los defensores de esa hipótesis, mientras aguardaban la llegada de los comerciantes, los esclavos se divertían en la práctica de su arte-lucha, pasando también a denominarse igualmente bajo ese término (capoeira). Llegó a extenderse también al claro de un bosque donde se practicaba este deporte y luego a una población cercana.

Es una arte interdisciplinaria que incluye varios aspectos culturales, marciales, deportivos y artísticos.
Es un movimiento de conciencia atlética que podría verse, en parte como una danza, un diálogo rítmico con una pareja al compás de la música de los instrumentos tradicionales, y en parte como una pelea, una estrategia contenida de movimientos de ataque y defensa

La capoeira es una combinación de acrobacia, baile y otras expresiones corporales. Fue desarrollado por descendientes de africanos que tomaron influencias de las culturas aborígenes locales.
En 2014, la capoeira fue incluida en el Patrimonio Cultural Inmaterial de la Humanidad de la UNESCO. La disciplina puede desarrollarse de manera deportiva y acrobática o a modo de estilo de lucha. A nivel general se caracteriza por los movimientos de piernas y brazos y los saltos.
Tradicionalmente la capoeira se practicó al ritmo del birimbao, un instrumento de cuerda. En la actualidad es habitual que se utilicen instrumentos de percusión como acompañamiento.
La práctica de la capoeira se lleva a cabo en “rodas”: los músicos y los capoeiristas forman un círculo mientras dos practicantes se enfrentan en el “jogo” (el juego). Mientras estas dos personas entablan una lucha (sin contacto físico), los demás aplauden y cantan.

Desde los siglos XV al XVI, Portugal transportaba esclavos a Sudamérica provenientes de África occidental.
En el año 1544 se funda la compañía de Lagos, cuya finalidad era intensificar el tráfico de esclavos. A finales de siglo, Portugal recibía una media de 12.000 esclavos por año provenientes de Guinea, Angola, Mozambique y demás regiones africanas.

Brasil era uno de los destinos americanos para los cautivos africanos, alcanzando un 42% de todos los esclavos que cruzaban el Atlántico. Los más vendidos habitualmente en Brasil eran Akan, Igbo, Yoruba, Dahomean, Muslim Guineanos, Hausa, y Bantú (entre ellos Kongos, Kimbundas, y Kasanjes) provenientes de Angola, Congo y Mozambique. Bajo condición de esclavos eran vendidos y llevados a trabajar a las plantaciones de caña de azúcar y algodón de los señores hacendados. Dada esta situación se produce la mezcla de los grupos africanos en las Senzalas (galpones muy reducidos donde dormían hacinados).

Estos africanos trajeron sus tradiciones culturales y religiosas consigo al Nuevo Mundo. Otra teoría sugiere que la capoeira se originó a partir de una danza de cortejo en Angola realizada por los pretendientes a jóvenes, o por lo menos fue uno de los componentes que la formaron, pero esta es sólo una de tantas teorías. Hay controversia acerca de si el juego llegó con los esclavos africanos o si los africanos refinaron un juego brasileño preexistente. Indistintamente, el catalizador para la capoeira, fue la homogeneización de los africanos bajo la opresión esclavista. La "Capoeira" surgió como una forma de resistencia a la opresión, un arte practicada en secreto, una transmisión de cultura y un estímulo espiritual.

Muchos eruditos brasileños sostienen que la capoeira nació como una forma de disimular el hecho de que los esclavos se estaban entrenando para pelear (contra sus dueños), ocultándola bajo la forma de una alegre coreografía de danza. Esto explica por qué actualmente la capoeira se muestra como una mezcla de técnicas de lucha y danza fluida.

Hubo grupos de esclavos que se escaparon de los asentamientos y se agruparon en diferentes lugares. Estas agrupaciones eran definidas por Portugal como 'Quilombos'. El quilombo más importante en 1580 era Palmares, y su gobernante fue Zumbi dos Palmares, situado en la "Sierra da Barriga", llegando a albergar 30.000 habitantes. Se le denominaba así por sus habitantes de Angola-Janga (pequeña Angola - en homenaje a la patria de sus orígenes). Llegó a mantenerse autosuficiente por más de un siglo.

Este quilombo era conformado por varias pequeñas aldeas agrupadas sobre la margen izquierda del río Gurungumba (Lambi, Arotirene, Tabocas, Dombabanga, Macacos, Subupuira, Osenga, Amaro, etc) y dos asentamientos mayores en las montañas Barriga (Gran Palmares). A ambos lados de una calle que recorría el largo del pantano se podían encontrar palmeras y tierras cultivadas. Basado en un sistema político de raíces africanas, un rey gobernaba a la población sin distinción de origen étnico, sosteniendo frente a las fuerzas portuguesas y holandesas la imagen del Brasil africano en el interior del país ante el Brasil europeo de las costas. Las áreas alejadas eran gobernadas por jefes y potentados. Dentro del mismo quilombo existía una fábrica de armas y un campo de entrenamiento donde se preparaban para los ataques europeos. Los entrenamientos se realizaban en el mocambo de Subupira y estaban a cargo de Gana-Zona, el hermano del rey.

El crecimiento de la población estable se garantizaba por medio del robo constante de esclavos, quienes permanecían en el quilombo privados de su libertad hasta redimirse por la incorporación de otro esclavo. Paralelamente al aumento poblacional, aumentaba también el precio de los esclavos, causando perjuicios económicos a los hacendados. La producción agrícola estaba muy organizada. Cultivaban porotos, maíz, mandioca y tabaco, y criaban gallinas y cerdos. La producción alcanzaba para la alimentación, el almacenamiento para épocas de guerra, y los sobrantes se vendían clandestinamente a las poblaciones vecinas que sólo tenían caña de azúcar. Además de la actividad agrícola, los quilombolas desarrollaron la caza, pesca, metalurgia y la creación de artesanías. El comercio de alimentos y artesanías a cambio de armas, municiones y sal con ciertos portugueses era tan importante que dichos colonos llegaron a oponerse a la guerra contra los palmarinos.

El fuego cerrado contra el Quilombo comenzó en 1680 cuando Palmares rechazó el tratado de paz con los blancos. Los portugueses resolvieron acabar de una vez con el Quilombo y, para eso, contrataron al bandeirante Domingos Jorge Velho. Macaco, la capital del Quilombo se había transformado en una ciudadela fortificada, el cerco duró 42 días y en la madrugada del 5 de febrero, los invasores finalmente rompieron la resistencia del Quilombo.

De la capital del Quilombo, que fue "Macaco", deriva la palabra que significa mono en portugués, además de ser el nombre de un movimiento de fuga en la capoeira.

Después de que la esclavitud se aboliera en 1888, los libertos se trasladaron a las ciudades de Brasil. Con la escasez de empleo, muchos se unieron o formaron bandas criminales. Continuaron practicando capoeira, que con el tiempo se asoció con actividades criminales, debido al racismo de la época. Como resultado, la capoeira fue prohibida en Brasil en 1890; el castigo por practicarla era extremo (a los infractores se les cortaban los tendones en la espalda y en los tobillos) y la policía era despiadada en su intento de erradicar su práctica. Sin embargo, la capoeira se continuó practicando en la clandestinidad.

Las "rodas" se reunían en áreas con varias vías de escape y mientras estaban escondidos, un individuo quedaba observando el paso de la policía: cada vez que se acercaban, este individuo tocaba un ritmo con el berimbau, parecido al sonido que hacían los caballos de la guardia, al que llamaban cavalaria (caballería en español). Los capoeiristas adoptaban 'apelidos', 'motes' o apodos para impedir que la policía descubriera sus verdaderas identidades. Hasta ahora, cuando una persona es bautizada en capoeira durante la "cerimônia do batizado", se le da un 'apelido' o 'mote'.

La capoeira experimentó un resurgimiento en los años 20 como consecuencia de su estudio por parte de educadores y expertos en artes marciales. Entre estos se hallaban Mario Aleixo y Anibal "Zuma" Burlamaqui, el autor del primer manual de capoeira y de las primeras reglas de competición para este arte (las cuales se inspiraban en el boxeo en cuanto a KOs y rondas). Particularmente importantes fueron los esfuerzos de Mestre Sinhozinho, un maestro de la "capoeira carioca" de Río de Janeiro que refinó al límite sus aplicaciones marciales, aunque a costa de abandonar la música y los aspectos artísticos de la capoeira.

Sin embargo, Mestre Bimba hizo una gran contribución para la preservación de este arte al abrir la primera academia para la enseñanza de capoeira. Esto representó un gran avance hacia la legalización de esta práctica en Brasil y permitía a la capoeira ganar popularidad en una época en la que este arte estuvo a punto de extinguirse en su forma pura. Un notable ejemplo de la influencia del sistema de enseñanza de Mestre Bimba tuvo lugar en 1937, cuando fue invitado a actuar con sus alumnos en un evento en el que Getúlio Vargas (el presidente de Brasil en aquella época) estaba presente. Vargas quedó tan impresionado con la disciplina y devoción de los alumnos de Mestre Bimba, que declaró la capoeira el deporte nacional de Brasil.

Mestre Bimba tuvo un mayor impacto en la práctica y el método de enseñanza de esta disciplinas e introdujo cambios que perduran hasta nuestros días. Debido a estos cambios, Mestre Bimba se convirtió en una figura controvertida. Antes de su legalización, la capoeira se asociaba con las clases más pobres y desfavorecidas, actividad criminal y estereotipos negativos de la población afrobrasileña. Para cambiar la percepción que tenía la gente de esta práctica, Mestre Bimba eliminó rituales y tradiciones del arte de la capoeira que impartía en su academia. Denominó su variante como "Luta Regional de Bahia" ("Lucha regional de Bahia")

La Capoeira de Mestre Bimba se llama actualmente "Capoeira Regional" y en consecuencia muchas de las formas modernas de Capoeira, que no derivan directamente de las enseñanzas de Bimba, también se engloban dentro de esta categoría. La Capoeira de Mestre Bimba continuó ganando popularidad, pero se intentó evitar que este arte perdiera sus tradiciones y rituales.

En 1942, Mestre Pastinha abrió la primera academia para la enseñanza del arte más tradicional, conocida como: "Capoeira Angola". Los esfuerzos de Mestre Pastinha evitaron que la "Capoeira Angola" se perdiera en pos de las formas modernizadas del arte que estaban ganando popularidad, conservando la distancia corta, los golpes de mano abierta, y el manejo de las armas tradicionales como la vara larga, los garrotes, el alambre del berimbau, las navajas en los pies, y hasta el uso de botellas.
Esta época fue un hito del cambio drástico en el modo de instruir en el arte de la capoeira. Anteriormente se transmitía en secreto, normalmente a través de un pariente, como un padre o un tío, o en pequeños grupos donde la gente joven de una comunidad particular recibían consejos de los miembros más antiguos. En esta época, la academia adquirió predominancia en la práctica de este arte.

En la actualidad existen un sin fin de academias alrededor del mundo, las cuales llevan esta arte marcial, no solo como un arte, sino también como una forma de vida, una inspiración. La capoeira se ha convertido en una forma de integración social, ya que no importa de donde viene la persona que lo practica, no discrimina credo, ni estrato social, no se pretende demostrar la superioridad de alguien con respecto a los demás.

Maestros de diferentes escuelas y estilos participan en seminarios donde discuten la necesidad de hacer esta práctica accesible a las clases más desfavorecidas que no pueden permitirse el coste de una academia.

Desde siempre, la capoeira se practica en rodas, que son por así decirlo "luchas amistosas sin contacto", aunque no siempre ha de ser así. Los practicantes forman un círculo cerrado formado por capoeiristas y músicos, que llevan el ritmo e intensidad del "juego" ("jogo") donde se muestra la maña ("mandinga"). En la roda hay 2 capoeiristas en un momento determinado: dos capoeiristas jugando y el resto en espera de sustituir a uno de estos dos anteriores. Durante la roda, los capoeiristas que observan el juego se limitan a cantar y tocar las palmas para dar mayor energía a la misma. Cabe señalar que en la mayoría de escuelas al entrar al jogo uno debe estar colocado a los pies del berimbao, aunque hay escuelas y estilos que permiten la compra de jogo libre.

El tamaño mínimo de la roda es un círculo de unos 3 metros de diámetro. Aunque normalmente son mayores, llegando a alcanzar los 10 metros. El ritmo tocado con el berimbau señala la velocidad del jogo en la roda. Los toques del berimbau determinan el tipo de juego que se va a ejecutar. En función de la escuela o grupo, se tocarán unos ritmos u otros (Banguela, Sao Bento Grande, Iuna, Angola, Sao Bento Pequeno...).
Normalmente no se dan golpes pero se fingen o muestran, aunque depende directamente del ritmo que lleven los berimbaus. En algunos ritmos los golpes se marcan pero no se completan mientras que en otros (ej., São Bento Grande da Regional) está permitido el contacto y los jugadores pueden tocarse, golpearse y derribarse, llegando en ocasiones a juegos bastante violentos. Los 'jogos' lentos son más suaves, menos impresionantes para los espectadores ocasionales. La música rápida permite cobrar impulso circular, lo que es la clave para ganar "aire" en la roda.

Nótese, sin embargo, que es el toque específico interpretado por el berimbau en las rodas de capoeira regional, sin importar su velocidad, el que dicta el tipo de 'jogo'.

La educación en valores juega un papel importante en "Capoeira" y los mejores profesores se esfuerzan por inculcar "Respeito" (Respeto), "Responsabilidade" (Responsabilidad), "Segurança" (Seguridad), "Malicia" (Inteligencia/malicia), y "Liberdade" (Libertad).

La capoeira moderna es a menudo criticada por la vertiente más tradicional debido a la pérdida de su 'alegría' y diálogo, en el sentido de que muchos capoeiristas tienden a centrarse más en impresionantes acrobacias o en elementos marciales en vez de interactuar activamente con el otro jugador en la roda. Dominar en la roda es algo psicológico y artístico más que una cuestión de ver quién hace más volteretas.

Existen historiadores que afirman que en la Capoeira, se encuentran movimientos que reflejan a algunos animales de la jungla. Como el jaguar, por su manera cautelosa y a la vez explosiva de atacar; la araña, por su manera de entrelazar su presa, por todos lados; el macaco, con sus saltos y cabriolas y la zorra, por sus astutas técnicas de engañar al enemigo. En todo caso, el esclavo que escapaba a la jungla, estaba encadenado y tenía que defenderse de los «Capitães do mato» (cazadores de esclavos) como pudiera. Aplicaba golpes con la cabeza, los codos, las rodillas, girando, saltando o rodando por el suelo.

La capoeira como disciplina marcial destaca sobre todo por la suavidad y amplitud de sus movimientos, que en su mayoría describen trayectorias circulares, golpes repentinos, atrapes con los pies, el uso de amagues y fintas, las distancias largas y medias, los golpes con mano abierta, la esquiva corporal conjunta, y el uso de armas tradicionales.

La Capoeira como arte no se centra en herir al oponente. Más bien, enfatiza la destreza. Los capoeiristas a menudo prefieren mostrar el movimiento sin completarlo, imponiendo su superioridad en la roda. Si el oponente no puede esquivar un movimiento lento, no hay razón para usar uno más rápido. Cada ataque que entra, da a los participantes la oportunidad de practicar una técnica de evasión.

La ginga (literalmente: "mecerse, balancearse") es el movimiento fundamental en capoeira. Es la posición básica desde la que se practican la totalidad de los demás movimientos y tiene diferentes variantes. La ginga consiste en el balanceo entre dos posiciones, la posición básica y la posición paralela. Cuando estamos en la primera de las posiciones, una de las piernas permanece adelantada con la rodilla flexionada apoyando toda la planta del pie y la de atrás permanece también flexionada, apoyada solamente de la punta del pie, usando el tobillo-pie como muelle. Con esto conseguimos periódicamente un impulso para facilitarnos un hipotético movimiento. Si tenemos la pierna derecha delante, tendremos el brazo derecho levemente flexionado buscando el equilibrio corporal, y el brazo izquierdo adelantado, flexionado a la altura de la cara a modo de guardia. La segunda de las posiciones, paralela, consiste, como su nombre indica, en tener las dos piernas paralelas; en este momento la guardia estaría cambiando de posición. Desde la paralela, volvemos a la posición inicial pero cambiando de pierna, y así sucesivamente. De esta manera formamos un triángulo isósceles con la base en la posición "paralelo" y la punta en el pie atrasado de la posición básica. Este movimiento se hace para preparar el cuerpo para otros movimientos.

Los ataques principales en Capoeira son las patadas, barridos, y golpes con la cabeza. Algunas escuelas también enseñan puñetazos, golpes de mano abierta, derribos, barridos, golpes con codos y rodillas, pero esto no es muy común. Se ha especulado que estos movimientos tienen su origen en la lucha de esclavos esposados contra sus guardias pero es bastante improbable ya que los esclavos estaban a menudo sujetos por los pies y/o el cuello. Otra explicación más plausible para el uso primario de los pies es la creencia común en el Oeste Africano de que "las manos se usan para crear y los pies para destruir".

Los golpes con el codo se usan habitualmente en lugar de los puñetazos. "Cabeçada" o los cabezazos son comunes al igual que ocurre en muchas artes de lucha de la Diaspora Africana. Los rodillazos se ven algunas veces. Asimismo la "Capoeira" usa movimientos acrobáticos y atléticos para maniobrar alrededor del oponente. Las volteretas laterales llamadas aú (un movimiento acrobático muy común), hacer el pino ("bananeira"), trompos ("pião de cabeça"), hand-spins ("pião de mão"), volteretas ("gato"), movimientos sentados, giros, saltos, piruetas ("mortal"), y largos regates son comunes en capoeira aunque pueden variar dependiendo de la forma y el ritmo.
Las fintas son elementos especialmente importantes en los jogos de "Capoeira" y las trampas/ amagues y los movimientos multiangulares e ilusorios son habituales.

Algunos golpes de capoeira son: martelo, queixada, armada, bençao, meia lua de frente, meia lua de compasso, ponteira, pissao, pissao giratorio, etc...

Las defensas en la capoeira consisten en movimientos evasivos y balanceos. Una sucesión de flexiones del tronco son denominados "esquivas", que literalmente significa 'escapar', son también básicos en el vocabulario defensivo de los capoeiristas. Hay diferentes esquivas para cada paso de la Ginga, dependiendo de la dirección de la patada y la intención del defensor. Una defensa básica es el "rolê", un movimiento giratorio que combina un quiebro y un lento movimiento.

Permite al jugador que se defiende evadir el ataque rápidamente y posicionarse alrededor del agresor a fin de repeler un ataque. Es esta combinación de ataques y defensas lo que le confiere a la "Capoeira" esa percepción de fluidez y coreografía.

Otros movimientos evasivos como "rasteira", "vingativa", "tesoura de mão" o "queda" permite al capoeirista alejarse o acercarse peligrosamente en un intento de hacer tropezar a su agresor en un momento de vulnerabilidad.

También cabe mencionar una defensa básica que es enseñada a todo principiante llama "cocorinha" que consiste agacharse pronto ante un ataque frontal quedando sentado en nuestros talones con una mano en el suelo y la otra cubriendo el rostro, dicha defensa es tan desconcertante que el objetivo pasa de estar enfrente a estar en el suelo en el cual puede hacer derribes sin ningún problema.

También hay estilos de movimientos que combinan ambos elementos de ataque y defensa. Un ejemplo es el "Aú Batido". El movimiento comienza como una voltereta lateral evasiva, que se transforma en un bloqueo/patada, se utiliza como reacción a un movimiento de bloqueo del adversario o cuando se presenta una oportunidad de hacerlo, ejemplo: el oponente baja la guardia. Dos patadas llamadas "meia lua de compasso" y "armada" se combinan para crear una doble patada hilada. También hay más combinaciones, como queixada com martelo y armada com martelo

La "Chamada" (literalmente "llamada") es un ritual que tiene lugar dentro de las formas más tradicionales de Capoeira, pudiendo o no, ser estrictamente Capoeira Angola. Consiste en una invitación realizada por uno de los dos participantes por medio de gestos y acciones corporales típicos que "chaman" o invitan al otro Capoeirista a acercarse (generalmente la persona que inicia la "Chamada" deja de moverse al ritmo de la música y se coloca de frente o cerca a los instrumentos, extendiendo sus manos de tal modo que sea clara la invitación al ritual). En respuesta, el otro participante se acerca a él con cautela y coloca su cuerpo de tal modo que permanezca alguna parte en contacto con el capoeirista que inició la "Chamada", esto puede ser juntando las palmas de las manos con las del otro, colocando la parte superior de cabeza en el vientre del compañero o cualquier otra postura, según sea indicado o "permitido" por quien "llamó" en un principio. Ambos participantes caminan unos pasos hacia adelante y hacia atrás; siendo quien inició el que decide cuando finalizar el ritual, para ello realiza la invitación a retomar el juego normal, a través de gestos como señalar el suelo con sus manos. Los puntos críticos de la "Chamada" ocurren durante el acercamiento, se le considera una 'lección para la vida', comunicando el hecho de que la aproximación es una situación peligrosa.

Acercarse a gente, animales, o ciertas situaciones son siempre momentos críticos donde uno debe ser consciente del peligro de la situación. El propósito de la "Chamada" es divulgar esta lección y la de realzar la concienciación de la gente a participar en el ritual.

Durante el ritual se considera también crítico el momento de caminar con el otro participante, porque ambos Capoeiristas son vulnerables debido a la proximidad o a un inminente ataque sorpresa.

Participantes experimentados y profesores de este arte ponen a prueba la conciencia de sus estudiantes sugiriendo golpes, golpes de cabeza o zancadillas durante la "chamada" para demostrar cuando un aprendiz les deja posibilidad de ataque. El final de la "chamada" lo realiza el mismo jugador que inició el ritual y consta de gestos invitando al oponente a retomar el juego normal. Otro momento crítico ya que ambos jugadores son vulnerables a un ataque sorpresa.

La "chamada" puede dar como consecuencia un alto desarrollo del sentido de mentalización y ayuda a los practicantes a ingeniárselas para anticiparse a las intenciones de otras personas. La "chamada" puede ser muy simple, componiéndose únicamente de los elementos básicos, o tornarse extremadamente elaborado incluyendo diálogos competitivos, artimañas o incluso adornos teatrales.

La "Volta ao mundo" (vuelta alrededor del mundo) tiene lugar después de un intercambio de movimientos que han alcanzado una conclusión, o después de haber una interrupción en la armonía del 'jogo'. En cualquiera de esas situaciones, un jugador caminará alrededor del perímetro del círculo al contrario de las manecillas del reloj y el otro jugador se unirá a la vuelta alrededor de mundo antes de retomar el 'jogo' normal. Esto se hace por lo regular cuando un jugador ya está muy cansado.

Literalmente: Pillería o pillaje. Cuando los estudiantes dominan los movimientos básicos, comienzan a adquirir más habilidad al perfeccionar el arte del engaño, o malandragem. Se basa en la improvisación y el empleo de una ráfaga de fintas y quiebros para engañar al oponente incitándolo a error.

Estos intentos pueden ser evidentes o sutiles dependiendo de los jugadores. La efectividad del malandragem se basan en la observación aguda, la destreza y en una habilidad innata para anticiparse a los movimientos del adversario y preparar una respuesta apropiada. Algunos capoeiristas aprovechan este aspecto para llevarlo a la altura del engaño teatral y el drama.

Cada vez con más frecuencia se muestran jogos con un despliegue de elaboradas exhibiciones e incluso representando coreografías donde se reconstruyen aspectos históricos y culturales de la Capoeira.

La capoeira tiene dos estilos principales, diferentes que se clasifican en: Capoeira Angola y Capoeira Regional.
La "Capoeira Angola" se refiere a la forma tradicional del 'jogo'. Es la forma más antigua, aproximadamente unos 500 años, con raíces en las tradiciones Africanas y es la vertiente de la que se cree que parten y derivan las demás formas de capoeira.

"Capoeira Angola" se considera la madre de la capoeira y se caracteriza por mantenerse ligada a las tradiciones marciales, por los movimientos furtivos y por los participantes jugando al 'jogo' más cerca el uno del otro que en la "regional" o "contemporánea". La música comienza lenta, y va aumentando el ritmo poco a poco según avanza la roda, y el 'jogo' bajo, en el suelo, con mucha malicia y picardía, con pocas acrobacias.

El Mestre Pastinha está considerado el padre de las academias modernas de "Capoeira Angola". Vivió en Salvador, Bahia y fue quien ayudó a importar y conservar la filosofía y los movimientos tradicionales de la capoeira al marco de las escuelas de capoeira angola. Hoy en día cada grupo se centra en preservar, difundir y enseñar el arte desde todas sus facetas (música, filosofía, movimentación, expresión corporal, jogo, etc.), siguiendo la línea de entrenamiento y aprendizaje de cada mestre.

La Capoeira Angola se preocupa de mantener las tradiciones, y por tanto del origen o descendencia de cada grupo. En su árbol genealógico se muestra cómo todo Mestre es a su vez descendiente de otro Mestre, desde el origen con M. Pastinha hasta la actualidad.

Los practicantes de capoeira angola utilizan un uniforme, generalmente amarillo y negro, y en ocasiones blanco (ceremonial). La capoeira angola no usa corda, ya que no se pretende demostrar la superioridad de alguien con respecto a los demás, cada capoerista angolero muestra su habilidad escondiendo de forma maliciosa lo que sabe y usándolo solo cuando es necesario.

"Regional" es una forma nueva de capoeira. La inventó el Mestre Bimba, mezclando capoeira angola con otra lucha conocida como Batuque. La hizo más accesible al público y la desligó de los elementos criminales de Brasil.

Es más espectacular que la capoeira angola y tiene más aceptación por parte de los nuevos capoeiristas en todo el mundo. Combina la malicia de capoeira angola y un juego acrobático más rápido y atlético, marcado por el son del berimbau. En esta vertiente dominan los golpes rápidos; dominan los desequilibrantes y algunos golpes secos. Sin embargo, también podemos encontrar ritmos lentos y cadenciados en la capoeira regional, que marcan juegos más lentos y más próximos al suelo.

El uniforme de la capoeira regional es blanco con una "corda" (cordón en español) de distinto color de acuerdo al grado de preparación del capoeirista (tomando el modelo de grados de las artes marciales japonesas o gendai budo) y de acuerdo al grupo de capoeira a que el mismo pertenezca. Antiguamente se utilizaban pañuelos de colores que los capoeiristas llevaban al cuello para cumplir la misma función, pero con la modernización de la capoeira, pasaron a utilizarse las ya mencionadas cordas. La corda se lleva a la altura de la cintura, se hace un nudo en el lado izquierdo del pantalón y el resto cuelga del mismo lado.

La batería o "charanga" de la capoeira regional está compuesta exclusivamente por un berimbau, y dos panderos, al contrario que la capoeira angola y la contemporánea, que incluyen más instrumentos.

"Contemporánea" es un término empleado para grupos que practican múltiples estilos de capoeira simultáneamente. Los practicantes de "Capoeira Contemporânea" mezclan elementos de la "Regional" y "Angola" así como nuevos movimientos que no pueden clasificarse dentro de ninguno de estos estilos.

Es una práctia controvertida debido a que muchos jugadores defienden que "Angola" debe practicarse sola al igual que la "Regional", para que el estudiante llegue a entender el 'jogo' en su totalidad. Otros jugadores defienden que un capoeirista debería tener un conocimiento de la capoeira moderna y tradicional y animarse a practicar ambas formas simultáneamente. Es una cuestión muy discutida entre los capoeiristas.

Se aplica a muchos grupos que no encuentran rastros de su linaje en el Mestre Bimba o Mestre Pastinha y no se identifican con ninguna tradición.

Cada 'jogo', "Regional" y "Angola" hacen hincapié en habilidades y puntos fuertes distintos. "Regional" resalta la rapidez y reflejos rápidos, mientras que la "Angola" subraya la importancia de cada movimiento, casi como en una partida de ajedrez. Las academias que imparten una mezcla de ambas lo ofrecen como una forma de aprovechar las fortalezas de los dos "jogos" para influir en el jugador.

La capoeira regional contemporánea, además de mezclar las fortalezas de la capoeira angola y la regional, incluye acrobacias que sirven para incitar al otro jugador. Asimismo la capoeira regional contemporánea adopta movimientos más estilizados que el juego original de Angola y el regional de Bimba.

Los instrumentos típicos usados para interpretar la música que acompaña a la capoeira son:



Asociadas a la capoeira existen dos danzas: la samba y el maculelé:



Las promociones de capoeira son conocidas como Comités, ya que, como empresas, estos contratan a luchadores a participar en peleas de la misma empresa. Generalmente, las mismas tienen campeonatos. Aquí la lista de todos las empresas de capoeira que existen hoy en día.

 Federação Capoeira Fighters

 Mayor League Capoeira

 Federação Universal da Capoeira

 Capoeira Liga Deutschland

 Australian Capoeira Championship

Algunas empresas aparecieron y se ganaron el cariño de la gente, pero por una u otra razón desaparecieron:





En español

En inglés

En español



</doc>
<doc id="27964" url="https://es.wikipedia.org/wiki?curid=27964" title="Cloro">
Cloro

El cloro es un elemento químico de número atómico 17 situado en el grupo de los halógenos (grupo VIIA) de la tabla periódica de los elementos. Su símbolo es Cl. En condiciones normales y en estado puro forma dicloro: un gas tóxico amarillo-verdoso formado por moléculas diatómicas (Cl) unas 2,5 veces más pesado que el aire, de olor desagradable y tóxico. Es un elemento abundante en la naturaleza y se trata de un elemento químico esencial para muchas formas de vida.

En la naturaleza no se encuentra en estado puro ya que reacciona con rapidez con muchos elementos y compuestos químicos, por esta razón se encuentra formando parte de cloruros (especialmente en forma de cloruro de sodio), cloritos y cloratos , en las minas de sal y disuelto en el agua de mar.

El cloro (del griego χλωρος, que significa «verde pálido») fue descubierto en su forma diatómica en 1774 por el sueco Carl Wilhelm Scheele, aunque creía que se trataba de un compuesto que contenía oxígeno. Lo obtuvo a partir de la siguiente reacción:

Además de su carácter asfixiante, descubrió que decoloraba muchos pigmentos vegetales. Poco después, Claude Louis Berthollet llevó este descubrimiento a la práctica, para el blanqueo de tejidos, utilizando una disolución de cloro en agua. Leonard Alban y Mathieu Vallet introdujeron una mejora muy importante, al disolver el cloro en una solución de potasa en agua, lo que reducía el desprendimiento de vapores tóxicos. Por su parte, Charles Tennant obtuvo el hipoclorito de calcio, haciendo reaccionar el cloro gas con cal sólida. Este material era más eficaz como decolorante, y más fácil de manejar.

En 1810 el químico inglés Humphry Davy demostró que se trataba de un elemento químico, al que dio el nombre de cloro debido a su color. El gas cloro se empleó en la Primera Guerra Mundial, siendo el primer caso de uso de armas químicas como el fosgeno y el gas mostaza.

El cloro se encuentra en la naturaleza combinado con otros elementos formando principalmente sales iónicas; como es el caso del cloruro sódico y cálcico; también con la mayoría de metales; desde el cloruro de hafnio hasta el cloruro de plata. Podría decirse que el cloro combina de forma natural bastante bien con la mayoría de elementos, excepto con los de su grupo, halógenos y gases nobles, aunque en las últimas décadas de manera sintética forma parte de los mismos en compuestos conocidos como son los fluorocloruros y cloruros de xenón.

Finalmente cabe destacar que la gran mayoría de estos compuestos suelen encontrarse con impurezas formando parte de minerales como la carnalita, KMgCl·6HO.

El cloro comercial se obtiene por electrólisis en el proceso de preparación de los álcalis y se expande en forma líquida, no es puro; y por lo tanto, ha de purificarse.

Si se trata el dióxido de manganeso hidratado con ácido clorhídrico concentrado se produce un gas exento en gran parte de impurezas tales como el oxígeno gas (O(g)) y óxidos de cloro.

4HCl + MnOxHO = MnCl + (x+2)HO + Cl


En la naturaleza se encuentran dos isótopos estables de cloro. Uno de masa 35 uma, y el otro de 37 uma, con unas proporciones relativas de 3:1 respectivamente, lo que da un peso atómico para el cloro de 35,5 uma.

El cloro tiene 9 isótopos con masas desde 32 uma hasta 40 uma. Solo tres de estos se encuentran en la naturaleza: el Cl, estable y con una abundancia del 75,77 %, el Cl, también estable y con una abundancia del 24,23 %, y el isótopo radiactivo Cl. La relación de Cl con el Cl estable en el ambiente es de aproximadamente 700 × 10:1.

El Cl se produce en la atmósfera a partir del Ar por interacciones con protones de rayos cósmicos. En el subsuelo se genera Cl principalmente mediante procesos de captura de neutrones del Cl, o por captura de muones del Ca. El Cl decae a S y a Ar, con un periodo de semidesintegración combinado de 200090 años.

El período de Desintegración de este isótopo hidrofílico y no reactivo lo hace útil para la datación geológica en el rango de 60 000 a un millón de años. Además, se produjeron grandes cantidades de Cl por la irradiación de agua de mar durante las detonaciones atmosféricas de armas nucleares entre 1952 y 1958. El tiempo de residencia del Cl en la atmósfera es de aproximadamente una semana. Así pues, es un marcador para las aguas superficiales y subterráneas de los años 1950, y también es útil para la datación de aguas que tengan menos de 50 años. El Cl se ha empleado en otras áreas de las ciencias geológicas, incluyendo la datación de hielo y sedimentos.

Las principales aplicaciones de cloro son en la producción de un amplio rango de productos industriales y para consumo. Por ejemplo, es utilizado en la elaboración de plásticos, solventes para lavado en seco y desgrasado de metales, producción de agroquímicos y fármacos, insecticidas, colorantes y tintes, etc.

El cloro es un químico importante para la purificación del agua (como en plantas de tratamiento de agua), en desinfectantes, y en la lejía. El cloro en agua es más de tres veces más efectivo como agente desinfectante contra "Escherichia coli" que una concentración equivalente de bromo, y más de seis veces más efectiva que una concentración equivalente de yodo.

El cloro como antiséptico fue introducido en 1835 por Holmes (en Boston) y en 1847 por Semmelweis (en Viena). El cloro se emplea como desinfectante en mobiliarios, equipos, instrumental y áreas hospitalarias. El cloro suele ser usado en la forma de ácido hipocloroso para eliminar bacterias, hongos, parásitos y virus en los suministros de agua potable y piscinas públicas. En la mayoría de piscinas privadas, el cloro en sí no se usa, sino hipoclorito de sodio, formado a partir de cloro e hidróxido de sodio, o tabletas sólidas de isocianuratos clorados. Incluso los pequeños suministros de agua son clorados rutinariamente ahora. ("Véase también" cloración)

Suele ser impráctico almacenar y usar el venenoso gas cloro para el tratamiento de agua, así que se usan métodos alternativos para agregar cloro. Estos incluyen soluciones de hipoclorito, que liberan gradualmente cloro al agua, y compuestos como la dicloro-S-triazinatriona de sodio (dihidrato o anhidro), algunas veces referido como "diclor", y la tricloro-S-triazinatriona, algunas veces referida como "triclor". Estos compuestos son estables en estado sólido, y pueden ser usados en forma de polvo, granular, o tableta. Cuando se agrega en pequeñas cantidades a agua de piscina o sistemas de agua industrial, los átomos de cloro son hidrolizados del resto de la molécula, formando ácido hipocloroso (HClO), que actúa como un biocida general, matando gérmenes, microorganismos, algas, entre otros de ahí su importancia en el empleo en endodoncia como agente irrigante de los conductos radiculares abordándose como solución en forma de hipoclorito de sodio en distintas concentraciones sea 0,5 % o 0,2 % las más frecuentes empleadas. El cloro también es usado como detergente para bacterias como el Bacillus repridentius o como el Martelianus marticus.

El cloro elemental es un oxidante. Interviene en reacciones de sustitución, donde desplaza a los halógenos menores de sus sales. Por ejemplo, el gas de cloro burbujeado a través de una solución de aniones bromuro o yoduro los oxida a bromo y yodo, respectivamente.

Como los otros halógenos, el cloro participa en la reacción de sustitución radicalaria con compuestos orgánicos que contienen hidrógeno. Esta reacción es frecuentemente —pero no invariablemente— no regioselectiva, y puede resultar en una mezcla de productos isoméricos. Frecuentemente, también es difícil el control del grado de sustitución, así que las sustituciones múltiples son comunes. Si los diferentes productos de la reacción se pueden separar fácilmente, por ejemplo, por destilación, la cloración radicalaria sustitutiva (en algunos casos acompañada de una declorinación térmica concurrente) puede ser una ruta sintética útil. Algunos ejemplos industriales de esto son la producción de cloruro de metilo, cloruro de metileno, cloroformo y tetracloruro de carbono a partir de metano, cloruro de alilo a partir de propileno, y tricloroetileno y tetracloroetileno a partir de 1,2-dicloroetano.

Como con los otros haluros, el cloro participa de reacciones de adición electrofílicas, más notablemente, la cloración de alquenos y compuestos aromáticos, con un catalizador ácido de Lewis. Los compuestos orgánicos de cloro tienden a ser menos reactivos en la reacción de sustitución nucleofílica que los correspondientes derivados de bromo o yodo, pero tienden a ser más baratos. Pueden ser activados por sustitución con un grupo tosilato, o por el uso de una cantidad catalítica de yoduro de sodio.

El cloro es usado extensivamente en química orgánica y química inorgánica como un agente oxidante, y en reacciones de sustitución, porque frecuentemente el cloro imparte propiedades deseadas a un compuesto orgánico, debido a su electronegatividad.

Los compuestos de cloro son usados como intermediarios en la producción de un gran número de productos industriales importantes que no contienen cloro. Algunos ejemplos son: policarbonatos, poliuretanos, siliconas, politetrafluoroetileno, carboximetilcelulosa y óxido de propileno.

El ácido clorhídrico reacciona con los carbonatos, esto permite que sea una sustancia de altísima utilidad en la identificación de minerales con presencia de carbonatos, como lo es la Calcita. Algunas rocas comunes que contienen carbonatos son las calizas, las margas y el mármol.

El gas cloro, también conocido como Bertholita, fue usado como un arma en la Primera Guerra Mundial por Alemania el 22 de abril de 1915, en la segunda batalla de Ypres. Como lo describieron los soldados, tenía un olor distintivo de una mezcla entre pimienta y piña. También tenía gusto metálico y pungía el fondo de la garganta y el pecho. El cloro puede reaccionar con el agua en la mucosa de los pulmones para formar ácido clorhídrico, un irritante que puede ser letal. El daño hecho por el gas de cloro puede ser evitado por una máscara antigás, u otros métodos de filtración, que hacen que la posibilidad total de morir por gas cloro sea mucho menor que por otras armas químicas. Fue diseñado por Fritz Haber, un científico alemán de la Sociedad Kaiser Wilhelm en Berlín, posteriormente laureado con un Premio Nobel, en colaboración con el conglomerado químico alemán IG Farben, quienes desarrollaron métodos para descargar el gas cloro contra una trinchera enemiga. Se alega que el rol de Haber en el uso del cloro como un arma mortal condujo a su esposa, Clara Immerwahr, al suicidio. Después de su primer uso, el cloro fue utilizado por ambos bandos como un arma química, pero pronto fue reemplazado por los gases más mortales fosgeno y gas mostaza.

El gas de cloro también ha sido usado por insurgentes contra la población local y las fuerzas de coalición en la guerra de Irak, en la forma de bombas de cloro. El 17 de marzo de 2007, por ejemplo, tres tanques cargados con cloro fueron detonados en la provincia de Anbar, matando a dos personas, y enfermando a más de 350. Otros ataques con bombas de cloro resultaron en mayores recuentos de muertos, con más de 30 muertes en dos ocasiones separadas. La mayoría de las muertes fueron causadas por la fuerza de las explosiones, en vez de por los efectos del cloro, dado que el gas tóxico es dispersado rápidamente en la atmósfera por la explosión. Las autoridades iraquíes han incrementado la seguridad para el manejo del cloro, que es esencial para proveer agua potable segura para la población.

El cloro es usado en la manufactura de numerosos compuestos orgánicos clorados, siendo los más significativos en términos de volumen de producción el 1,2-dicloroetano y el cloruro de vinilo, intermediarios en la producción del PVC. Otros organoclorados particularmente importantes son el cloruro de metilo, cloruro de metileno, cloroformo, cloruro de vinilideno, tricloroetileno, tetracloroetileno, cloruro de alilo, epiclorhidrina, clorobenceno, diclorobencenos y triclorobencenos.

El cloro también es usado en la producción de cloratos y en la extracción de bromo.

La inhalación de cloro produce una importante toxicidad química directa de las vías respiratorias:



Las formas de cloro involucradas en la toxicidad respiratoria no se limitan al cloro gaseoso sino también a los compuestos que se forman por su combinación con otras sustancias, tales como el ácido hipocloroso, el dióxido de cloro y la cloramina. De hecho, debido a que el cloro gaseoso es moderadamente soluble en agua, cuando entra en contacto con las mucosas de las vías respiratorias puede formar ácido hipocloroso, ácido clorhídrico y diversos oxidantes altamente reactivos, a medida que se va disolviendo en el líquido de la superficie de las vías respiratorias. Esto provoca lesiones que no se limitan a las vías respiratorias inferiores, sino que también puede afectar a los ojos, la piel y las vías respiratorias superiores. La vía aérea se ve especialmente afectada desde la nariz hasta el nivel de los bronquios. El daño oxidativo de las vías respiratorias puede no aparecer de manera inmediata, sino que puede desarrollarse de manera retardada, durante cualquier etapa de la enfermedad (días e incluso semanas después de la exposición al cloro).

El funcionamiento normal de las vías respiratorias puede no volver a restablecerse con normalidad después sufrir lesiones por la inhalación de cloro, dejando secuelas permanentes tales como asma, hiperreactividad inespecífica de las vías respiratorias, síndrome de disfunción reactiva de las vías aéreas, fibrosis pulmonar e hiperplasia mucosa. Una única exposición a niveles elevados es suficiente para provocar secuelas permanentes.

Además de las actividades profesionales relacionadas con la industria y la manipulación del cloro, una actividad destacada en la que se produce exposición a esta sustancia es la natación. Tanto los nadadores como las personas que trabajan en las piscinas (entrenadores, monitores, salvamentos...) están expuestos a una importante toxicidad química directa de las vías respiratorias por la inhalación del cloro ambiental. Esta toxicidad (y sus efectos sobre la salud) se produce por las dos vías descritas en la anterior sección: exposición a bajos niveles de cloro de manera continuada y picos de niveles elevados ocasionales involuntarios (exposiciones agudas). Las exposiciones a los niveles más altos se deben a fallos puntuales en los sistemas de cloración automática y negligencia de los operarios de mantenimiento, por falta de conocimiento o ausencia de cultura de seguridad. Otras causas que motivan desprendimiento de cloro al aire con acumulación de niveles excesivos, aunque el nivel de cloro en el agua esté dentro de la normativa, incluyen insuficiente ventilación, actividades con gran agitación del agua (como entrenamientos intensos, niños jugando) y presencia de un elevado número de usuarios.

Los accidentes por inhalación de productos químicos en piscinas no son hechos inusuales. Algunos ejemplos se detallan a continuación.

En España en 1992, una niña de diez años murió asfixiada por inhalación de cloro en una piscina climatizada cubierta. Otros once niños resultaron intoxicados en el mismo incidente y sufrieron lesiones pulmonares, dos de ellos muy graves. Los hechos se produjeron como consecuencia de una negligencia en la manipulación de los sistemas de depuración del agua.

Entre los años 2008 a 2012 se documentaron 41 accidentes en piscinas por sustancias químicas, con un total de 428 víctimas, una de ellas mortal (un operario) y al menos 1750 personas evacuadas. El número de víctimas en un único incidente osciló desde una sola persona afectada hasta más de 80 intoxicados (Asturias, 2010). La mayoría de los accidentes se produjo en piscinas municipales.



</doc>
<doc id="27968" url="https://es.wikipedia.org/wiki?curid=27968" title="Escudo de Madrid (desambiguación)">
Escudo de Madrid (desambiguación)

Escudo de Madrid puede referirse a:


</doc>
<doc id="27969" url="https://es.wikipedia.org/wiki?curid=27969" title="Euglenophyceae">
Euglenophyceae

Euglenophyceae es un grupo de protistas flagelados, comúnmente presentes en agua dulce, en especial cuando ésta es rica en materia orgánica. Son organismos comunes, de distribución cosmopolita, que también se encuentran en el suelo, en barros salobres y algunos en aguas marinas. Son unicelulares, aunque en ocasiones forman colonias unidas por una matriz gelatinosa, sésiles o libres. La mayoría de sus miembros presentan cloroplastos y son autótrofos, aunque algunas especies han perdido secundariamente los cloroplastos y son por tanto heterótrofos. Las euglenofíceas son protistas que han conseguido las características algales mediante endosimbiosis con un alga verde. El género típico es "Euglena", una conocida alga unicelular.

Las euglenofíceas son organismos fotosintéticos, aunque algunas especies han perdido secundariamente los cloroplastos. Abundan especialmente en ambientes de agua dulce eutróficos y son indicadores de contaminación orgánica. Varias especies habitan en aguas salobres y estuarios y unos pocos linajes forman parte del plancton marino. Viven en los sedimentos o nadando en la columna de agua.

Presentan formas variables incluso dentro de la misma especie: usualmente son flagelados, pero pueden pasar a un estado inmóvil cambiando de forma, o haciéndose esféricos y enquistándose. La célula presenta un bolsillo o invaginación apical o subapical que consiste de un canal angosto y un reservorio. En este bolsillo están insertados los flagelos. Puede haber dos flagelos iguales o desiguales, el segundo flagelo también puede ser más corto y estar unido a la base del flagelo largo; algunas especies tienen más de dos flagelos. Normalmente el flagelo emergente presenta una fila de mastigonemas. Puede aparecer un estigma o mancha ocular, con un fotorreceptor sensible a luz. 

Carecen de pared celular, pero presentan una película que recubre la célula o periplasto proteináceo dentro de la membrana plasmática. El periplasto, que puede estar ornamentado, está formado por un conjunto de bandas encajadas unas dentro de otras de manera que permitan deslizarse por movimientos de contracción y expansión. Debajo hay microtúbulos y vesículas mucilaginíferas involucradas en la formación del periplasto. En ocasiones se produce, externamente, mucílago formando una lorica.

La reproducción asexual es por bipartición, incluso cuando están en fase flagelada. Primero hay una duplicación de todos los orgánulos y luego la citoquinesis siguiendo las líneas helicoidales de las bandas del periplasto. Cuando las condiciones no son favorables se enquistan y germinan cuando vuelven a serlo. No se ha observado reproducción sexual. 

La clasificación se basa en la disposición de los flagelos, excepto un género, que es sésil, "Colacium", que conserva sus flagelos en el reservorio. Algunas cepas de "Euglena gracilis" son utilizadas como indicadoras de vitamina B en el medio.

Las especies fotosintéticas presentan cloroplastos supuestamente adquiridos por endosimbiosis secundaria de un alga verde prasinofita del grupo de las Pyramimonadales, pues están rodeados de tres membranas y contienen clorofilas "a" y "b" Los cloroplastos se presentan en grupos de tres a doce, mientras que los tilacoides forman grupos de dos a seis, generalmente en grupos de tres. Los cloroplastos pueden ser lenticulares, acintados, reticulados o estrellados. Como pigmentos accesorios presentan β-caroteno y xantofilas. Entre estas últimas están la astaxantina, que les da un color rojizo, hematocromo, por ejemplo en "Euglena sanguinea", que da un color rojo al agua donde vive, y euglenorodona.

Como material de reserva acumulan paramilo (un beta-1-3-glucano, agregación lineal de glucosa), que aparece en grandes corpúsculos, unos pocos por célula. Además acumulan crisolaminarina, que también es un beta-1-3-glucano, pero ramificado. Puede aparecer un pirenoide, donde se forma el material de reserva. El paramilo que puede estar dentro o fuera de las células, según el género.

Si las euglenas son colocadas en oscuridad, pierden su plastos quedando en forma de proplastidios, que volverán a pigmentarse con la luz.

Dentro de las euglenofíceas se distinguen dos órdenes:







</doc>
<doc id="27970" url="https://es.wikipedia.org/wiki?curid=27970" title="Fiebre">
Fiebre

La fiebre, pirexia o "síndrome febril" es un síndrome (conjunto de signos y síntomas) que se manifiesta generalmente, aunque no siempre, cuando un animal de sangre caliente tiene una temperatura corporal superior a la considerada normal para su especie y cuyo principal signo clínico es la hipertermia. Por lo general es la respuesta del organismo a agentes de naturaleza infecciosa (que es lo más frecuente) o a causas no infecciosas (toxinas de resorción, lesiones en ciertos territorios nerviosos, etc.). La hipertermia es el signo médico más común en enfermedades infecciosas. Cabe aclarar que, semiológicamente hablando, fiebre o síndrome febril no son sinónimos de hipertermia ya que este último término hace referencia a un signo clínico, mientras que la fiebre es un síndrome que generalmente se presenta con el signo hipertermia.

Los signos de la fiebre son:





Existe también un aumento del catabolismo proteico durante la fiebre con una mayor excreción de urea, que se acentúa en el momento del descenso de la temperatura. También el catabolismo graso aumenta durante la fiebre. Y cuando la dieta no aporta bastantes hidratos de carbono se produce una tendencia a la acidosis. En el análisis de orina verificamos una albumina llamada "febril".




La temperatura normal del cuerpo humano oscila entre 35 y 37 °C.
Las fiebres por encima de los 40,5 °C pueden amenazar proteínas de vital importancia, provocando estrés celular, infarto cardíaco, necrosis de tejidos, ataques paroxísticos y delirios.

Debido al sistema inmunitario poco desarrollado con el que cuentan los niños, son más propensos a sufrir fiebres elevadas.

Son sustancias externas al cuerpo humano. Puede tratarse de microorganismos, productos de los microorganismos como endotoxinas liberadas por bacterias gram (–), o el ácido lipoteicoico o el peptidoglicano de las bacterias gram (+); agentes químicos (anfotericina, fenotiazidas).




Los pirógenos endógenos convergen a una región cerebral que regula la fiebre, el área preóptica del hipotálamo anterior (POA: "preoptic area"). Mecanismo controvertido, ya que los pirógenos endógenos tienen que atravesar la barrera hematoencefálica la cual es impermeable a ellos. Al menos dos rutas se evidencian: transporte activo a través de la barrera hematoencefálica por transportadores específicos para citoquinas; transferencia de mensaje donde la barrera hematoencefálica tiene fenestraciones, es decir en los órganos circumventriculares sensoriales particularmente en el organum vasculosum laminae terminalis (OVLT).

Pero hay otras rutas alternativas: la circulación de citoquinas inducen la generación de prostaglandina E2 (PGE-2) y tal vez prostaglandinas F2a (PGF-2a) permeable a la BHE, el mediador putativo más proximal a la fiebre, por las células endoteliales de la microvasculatura cerebral o perivascular como la microglía y macrófagos meningeales.

Directamente trasmisión al POA de los mensajes de los pirógenos vía aferentes periféricas (mayormente vagales) activado por citoquinas.



En el ser humano, las temperaturas superiores a 41 °C son mortales usualmente.
Siempre que dudemos de la temperatura axilar de un paciente, podremos tomar la temperatura rectal. La temperatura real del paciente será la que el termómetro nos indique restando 1°C a la temperatura mostrada. Por ejemplo, si un paciente muestra una temperatura axilar y dudamos de si es la temperatura correcta (vamos a poner el caso de un paciente que presenta signos y síntomas de fiebre pero el termómetro nos muestra una temperatura de 37°C), entonces tomaremos la temperatura rectal. Si el termómetro nos indica 39.5°C, restaremos 1°C y esa será la temperatura indicativa (38.5°C).

La fiebre está relacionada habitualmente con la estimulación del sistema inmunitario del organismo. En este sentido, puede ser útil para que el sistema inmunitario tome ventaja sobre los agentes infecciosos, haciendo al cuerpo humano menos receptivo para la replicación de virus y bacterias, sensibles a la temperatura.

Además de las infecciones, son causa de fiebre el abuso de anfetaminas y la abstinencia de una sustancia psicotrópica en un adicto a ella, así como la recepción de calor emitida por maquinaria industrial o por insolación.






</doc>
<doc id="27972" url="https://es.wikipedia.org/wiki?curid=27972" title="Fisiología renal">
Fisiología renal

La fisiología renal es el estudio de la fisiología de los riñones. La función principal del riñón es la regulación del medio interno mediante la excreción, de agua y metabolitos, así como la retención de anabolitos que el organismo necesita; además, tiene una función endocrina secretando renina, calicreina, eritropoyetina y prostaglandinas.


El riñón es responsable del mantenimiento del equilibrio de varias sustancias:


"Artículo Principal": Equilibrio ácido-base

El cuerpo es muy sensible al valor de pH. Fuera del rango de pH que es compatible con la vida, las proteínas son desnaturalizadas y digeridas, las enzimas pierden su habilidad para funcionar, y el cuerpo es incapaz de sostenerse. Los riñones mantienen el equilibrio ácido-base con la regulación del pH del plasma sanguíneo. Las ganancias y pérdidas de ácido y base deben ser equilibradas. Los ácidos se dividen en "ácidos volátiles" y "ácidos fijos"

El principal punto de control para el mantenimiento del equilibrio estable es la excreción renal. El riñón es dirigido hacia la excreción o retención de sodio mediante la acción de la aldosterona, la hormona antidiurética(ADH o arginina-vasopresina), el péptido natriurético atrial(ANP), y otras hormonas. Los rangos anormales de la excreción fraccional de sodio pueden implicar la necrosis tubular aguda o la disfunción glomerular.

La habilidad del riñón para realizar muchas de sus funciones depende de tres funciones fundamentales de filtración, reabsorción, y secreción.

La sangre es filtrada por las nefronas, las unidades funcionales del riñón. Cada proteínas plasmáticas insignificantes para entrar al espacio de Bowman. La filtración es conducida por las Fuerzas de Starling.

El ultrafiltrado sigue a su vez, por el túbulo proximal, el Asa de Henle, el túbulo contorneado distal , y una serie de ductos colectores para formar la orina.

La reabsorción tubular es el proceso por el cual los solutos y el agua son removidos desde el fluido tubular y transportados en la sangre. Es llamado reabsorción (y NO "absorción") porque estas sustancias han sido absorbidas ya una vez (particularmente en los intestinos).

La reabsorción es un proceso de dos etapas que comienza con la extracción activa o pasiva de sustancias desde el fluido tubular hacia el intersticio renal (el tejido conectivo que rodea las nefronas), y luego el transporte de estas sustancias desde el intersticio hacia el torrente sanguíneo. Estos procesos de transporte son conducidos por las Fuerzas de Starling, por difusión, y por Transporte Activo.

El umbral plasmático renal es la mínima concentración en el plasma sanguíneo de una sustancia que resulta en la excreción de dicha sustancia en orina.

Por ejemplo, el umbral plasmático renal para la glucosa es 180 mg por cada 100 mL. La glucosuria (azúcar en orina) resulta cuando la concentración plasmática alcanza y excede el umbral plasmático renal de la glucosa. Cuando la concentración plasmática de glucosa es muy alta, la glucosa filtrada puede saturar sus portadores y alcanzar el transporte máximo de esa molécula. Cualquier cantidad que pase el transporte máximo continuará a través de los túbulos renales y será excretado en orina. Cabe destacar la diferencia entre umbral plasmático renal y transporte máximo, en el caso de la glucosa, este último es de 320mg, en donde si la concentración es superior se comienza a eliminar la glucosa de manera proporcionalmente directa a su concentración en el plasma ( situación en que todos los transportadores están saturados). Esto difiere del comportamiento del umbral renal, en el que pasado los 180mg, comienza una curva de excreción no lineal.

En algunos casos, la reabsorción es indirecta en el agua del riñón. Por ejemplo, el bicarbonato (HCO) no tiene un transportador, por tanto su reabsorción involucra una serie de reacciones en el lúmen del túbulo y el epitelio tubular. Comienza con la secreción activa de hidrogenión (H) dentro del fluido tubular mediante un intercambiador Na/H:


Algunas hormonas regulatorias claves para la reabsorción:

Ambas hormonas ejercen sus efectos principalmente en túbulo contorneado distal y túbulo colector.



</doc>
<doc id="27973" url="https://es.wikipedia.org/wiki?curid=27973" title="Galera">
Galera

La galera (del griego medieval ["galéa"]) fue un tipo de barco ampliamente usado por múltiples grupos humanos desde la antigüedad hasta el final de la edad de la vela. El origen del término es oscuro, tal vez relacionado con "galeos", «galeus». Es un barco impulsado por la fuerza de los remos, y en ocasiones por el viento; por eso poseía una o más velas grandes.

Era indudablemente en cuanto a su forma el eslabón entre la "Navis longo" romana, la galera de los siglos XV y XVI y los dromones bizantinos. Muy semejantes sus condiciones respectivas en lo tocante a su ligereza, fue también muy semejante su destino en las armadas de tan distintas épocas, sirviendo en todas ellas de naves auxiliares y exploratorias.

Las dimensiones de los mayores barcos de esta especie en las fechas últimamente citadas eran: eslora, 140 pies: manga, 20: puntal, 9. Hasta el siglo XVI, en que se perfeccionó el uso de la artillería a bordo de las embarcaciones, iban armadas las galeras de un espolón a proa (el "rostrum" de la nave romana) hecho de bronce o de madera reforzado con zunchos de hierro y colocado muy bajo, casi en la línea de flotación con el objeto de desfondar el barco enemigo a quien embistiesen. Sobre la cubierta de la galera iban dispuestos a una y otra banda los bancos de los remeros, existiendo una división, llamada crujía, que permitía ir de la popa a la proa: en este paso se colocaba el cómitre o nostromo ("hortator" entre los romanos) para vigilar y animar a los remeros.

Había galeras que llevaban uno, dos y tres palos variando según el tamaño El elemento propulsor principal eran los remos y el auxiliar la acción del viento sobre las velas. Los remeros, hasta siete por bancada, tomaban asiento en bancos que iban empotrados de una parte en el mamparo del corredor o crujía y del otro en el costado. El número de bancos, y por tanto, desde la más pequeña que tenía 20 por banda, normalmente solía ser de 25 o 26, aun cuando hubiera buques de la familia de las galeras, las medias galeras y los leños, que tenían algunos menos, y otras en cambio muchos más, como las cuatro galeras portuguesas que fueron con la Armada Invencible, cada una de las cuales contaba 306 remeros. La longitud de los remos era de unos 50 pies próximamente que se manejaban apoyando el primer tercio en las postizas o piezas rectangulares de madera adosadas por fuera de la embarcación, una por cada costado y que corrían a lo largo desde los yugos de popa hasta los del brazal o de proa. Las más antiguas galeras tenían las velas cuadrangulares, siendo la más grande la del trinquete, aunque después eran latinas y la vela del trinquete fue más pequeña que la del palo mayor. Unas veces, a imitación de las naves romanas, tenían parapetos en los costados, gruesas planchas o una serie de paveses o escudos que servían de abrigo en el combate a remeros y soldados; y otras, altos castillos a popa y a proa desde donde arrojaban las flechas, dardos y aún el fuego griego.

Las velas eran cuadras, es decir, de forma trapezoidal, y frecuentemente latinas o triangulares. Solo el palo mayor descansaba en la sobrequilla, el trinquete lo hacía sobre la cubierta. la longitud del palo mayor, según Crescentino, era de unos 20 metros. Las entenas estaban compuestas de dos partes unidas por ligadas: la de la vela mayor era tan larga como la galera menos 15 pies. Las dos partes se llamaban car y pena. En las partes altas de los palos solían llevar unas pequeñas plataformas o cofas, llamadas gavias. El interior de las galeras solía estar dividido por mamparos transversales en seis compartimento, destinados los de popa al capitán y los restantes a pañoles de víveres, velas y demás efectos.

Modernamente se llama galera a todo barco de remo y vela antiguo, propio para la guerra, caracterizado por su gran eslora respecto a su manga y su relativa ligereza tanto en la marcha como en las evoluciones. En realidad el nombre de galera empezó a usarse en España en el siglo XIV, aunque desde los inicios de la Edad Media, ya se empleaba en el Mediterráneo los de "galea" y "galia".

La galera existe desde la antigüedad. Originalmente, usaba una fila de remeros por cada lado de la embarcación (monorreme). Tiempo después, los fenicios inventaron una galera con dos filas de remeros en dos órdenes, una superior y una más abajo, que era más veloz sin perder maniobrabilidad; esta evolución de la galera se llamó birreme. En la Antigua Grecia crearon y usaron el trirreme, galera de tres filas de remeros. Los antiguos romanos, y antes de ellos los cartagineses, llegaron a utilizar el quinquerreme, que constaba de cinco remeros distribuidos en tres órdenes, con dos hombres en el orden superior, dos en el medio y uno en el inferior. Lo común era usar birremes. La liburna y la "navis longa" de los romanos también caen dentro de la denominación.

Los remeros normalmente eran esclavos o prisioneros. Durante muchos siglos se mantendrá la condena a galeras como uno de los más crueles castigos posibles, tanto que incluso Miguel de Cervantes la menciona en el "Quijote".

Durante la Edad Media no se hicieron progresos notables en el arte de construir embarcaciones. La innovación de montar una fila de remeros extra fue abandonada. Sin embargo, las galeras permitieron a diversas culturas expandirse a enormes distancias. Tal fue el caso, por ejemplo, del "drakkar" o barco-dragón de los vikingos.

En el siglo XV aparece una nueva clase de embarcación, llamada carabela, que usaba un velamen variado para navegar sin remeros, y por lo tanto requería mucha menos tripulación que la galera. Sin embargo, la carabela no sustituyó rápidamente a la galera. Para dar una idea: en la época del descubrimiento de América, 1492, la expedición de Cristóbal Colón navegó en dos carabelas y una nao, pero la flota reunida por las potencias cristianas contra el Imperio otomano durante la batalla de Lepanto en 1571 era de galeras. Este sería el último gran combate naval en el que se utilizaría únicamente este tipo de embarcación.

En el siglo XVI, en que la artillería llegó a tener un valor práctico en el combate, se instaló en las galeras. Los gálibos de ellas, sin embargo no sufrieron modificación. Los cañones se instalaban en las extremidades, en repisas o castillos. En algunas galeras se montaban debajo de una doble plataforma transversal que servía para facilitar la maniobra de la vela trinquete. En la crujía se montaba un gran cañón de caza o bombarda, y a sus lados otros más pequeños, falconetes y pedreros.

Durante el Renacimiento aparece un tipo intermedio: una galera con velas, llamada galeaza, precedente del galeón.

En España, el Cuerpo General de Galeras fue disuelto por orden de 28 de noviembre de 1748, firmada por el Secretarío del Despacho de Guerra y Marina e Indias, el marqués de la Ensenada:

Pero en 1784, con la llegada de Carlos III y su empeño en terminar de una vez por todas con la piratería berberisca, se construyen nuevas galeras en España y se integran dentro del Cuerpo General de Marina existente. Pervivieron sin especial relevancia hasta los primeros años del siglo XIX.





</doc>
<doc id="27974" url="https://es.wikipedia.org/wiki?curid=27974" title="Glándula sebácea">
Glándula sebácea

Las glándulas sebáceas están situadas en la dermis media y formadas por células llenas de lípidos que se desarrollan embriológicamente en el cuarto mes de gestación, como una gemación epitelial del folículo piloso. 

Esta glándula se caracteriza por sintetizar el sebo, sustancia lipídica cuya función es la de "lubricar" y proteger la superficie de la piel.
Esta secreción glandular es de carácter continuo, con cierta predominancia durante el anagen del ciclo del folículo piloso. La secreción de cada lóbulo es de carácter holocrino, es decir, con ruptura de las células individuales, drenando desde los acinos al conducto sebáceo principal que va a desembocar en el canal piloso.
Estas glándulas se encuentran en toda la piel, variando en tamaño y número según su localización: en la cara y cuero cabelludo son grandes y numerosas (400 a 900 por cm²), en el tronco son pequeñas y menos abundantes, incrementándose en la parte anterior del tórax y línea media de la espalda.Al microscopio electrónico se observa que las células periféricas glandulares contienen tonofilamentos, reflejando su origen epidérmico, y escasos lípidos. A medida que los lípidos se forman, el glucógeno se va consumiendo, los tonofilamentos se van desplazando y el citoplasma se rellena de vacuolas. En la célula las vacuolas se fusionan entre sí provocando un aumento de tamaño hasta cien veces el normal, adquiriendo un aspecto de célula de cuerpo extraño. En un estadio posterior se desorganiza la membrana y la célula se rompe eliminando su contenido al canal sebáceo.

Varias condiciones médicas involucran sebo, incluyendo acné, quistes sebáceos, hiperplasia, y adenoma sebáceo. Estas son normalmente atribuidas a glándulas sebáceas hiperactivas que producen sebo en exceso.

Las glándulas sebáceas se encuentran a través de todas las áreas de la piel excepto por las palmas de las manos y las suelas del pie. Hay dos tipos de glándula sebácea, las que están conectadas a los folículos capilares, en unidades pilosebáceas y aquellas que existen independientemente..

Una o más glándulas pueden rodear cada folículo capilar, y las glándulas están rodeadas por músculos erectores de pili. Las glándulas tienen una estructura acinar, en la cual varias glándulas salen a partir de un conducto central. Las glándulas depositan sebo en los capilares y lo llevan a la superficie de la piel junto con el tallo de pelo. La estrucutura consistente de pelo, folículo capilar, músculos erectores de pili y glándula sebácea es una invaginación epidérmica conocida como la unidad pilosebácea.

Las glándulas sebáceas también se encuentran en áreas sin pelo de los párpados, nariz, pene, labia minora, la membrana mucosa interna de la mejilla, y pezones. Algunas glándulas sebáceas tienen nombres únicos.

Las glándulas sebáceas son visibles por primera vez entre las semanas 13 y 16 del desarrollo fetal. Las glándulas sebáceas se desarrollan del mismo tejido que da lugar a la epidermis de la piel. Sobreexpresión de los factores de señalización Wnt, Myc y SHH aumentan la probabilidad de la presencia de glándulas sebáceas.

Las glándulas sebáceas de un feto humano secretan una sustancia llamada vernix caseosa, una sustancia cerosa, blanca traslúcida que recubre la piel de los recién nacidos. Después del nacimiento la actividad de las glándulas sebáceas disminuye hasta el punto de una presencia casi nula durante las edades de 2 a 6 años, después aumenta hasta su cima de actividad durante la pubertad debido a los altos niveles de andrógenos.

Las glándulas sebáceas secretan la sustancia aceitosa, cerosa llamada "sebo" que está hecho de triglicéridos, ésteres de cera, escualeno y metabolitos de células productoras de grasas. El sebo es hidrofóbico y lubrica la piel y el pelo de los mamíferos. Las secreciones sebáceas en conjunto con las glándulas apocrinas juegan un papel importante en la termorregulación. En condiciones cálidas, las secreciones emulsionan el sudor producido por las glándulas ecrinas y esto produce una capa de sudor que no se pierde fácilmente por las gotas de sudor. Esto es de gran importancia para retrasar la deshidratación. En condiciones más frías, la composición del sebo se vuelve más lipídica recubriendo pelo y piel, la lluvia es repelida eficientemente..

El sebo se produce en un proceso holocrino, en el cual las células dentro de las glándulas sebáceas se desintegran mientras liberan sebo y el resto de la célula es secretada junto con el sebo. Las células son reemplazadas constantemente por mitosis en la base del ducto.

El sebo, secretado por la glándula sebácea en humanos, está compuesto principalmente de triglicéridos (~41%), ésteres de cera (~26%), escualeno (~12%), y ácidos grasos libres (~16%). La composición del sebo varía entre las especies. Los ésteres de cera y el escualeno son únicos del sebo y no se producen en ninguna otra parte del cuerpo..El ácido sapiénico es un ácido graso del sebo que es único para los humanos y está implicado en el desarrollo del acné.. El sebo no tiene olor, pero su rompimiento por bacterias puede producir olores fuertes..

Los esteroides sexuales son conocidos por afectar la velocidad de la secreción del sebo: andrógenos como testosterona han demostrado estimular la secreción y los estrógenos han demostrado inhibir la secreción.La dihidrotestosterona actúa como el andrógeno principal en la próstata y en folículos capilares.

Las glándulas sebáceas son parte del sistema integumentario del cuerpo y sirve para proteger el cuerpo contra gérmenes. Las glándulas sebáceas secretan ácidos que forman el manto ácido. Este es una capa muy fina de ácido en la superficie de la piel y actúa como barrera contra bacteria, virus y otros contaminantes potenciales que pueden penetrar la piel. El pH de la piel está entre 4.5 y 6.2, y esta acidez ayuda a neutralizar la naturaleza alcalina de los contaminantes.

Los lípidos sebáceos realizan una contribución importante en mantener la integridad de la barrera de la piel y expresan propiedades tanto pro-inflamatorias como antiinflamatorias.. El sebo puede actuar como un sistema de entrega para antioxidantes, lípidos antimicrobianos, feromonas e hidratación del estrato córneo. Los ácidos grasos contenidos dentro del sebo tienen una amplia actividad microbiana. Además, la secreción de glándulas sebáceas proporciona vitamina E a las capas superiores de la piel facial.

Durante los últimos tres meses del desarrollo fetal, las glándulas sebáceas del feto producen vernix caseosa, una sustancia blanca y cerosa que crea una capa para proteger la piel del líquido amniótico..

Las glándulas areolares están en la areola que rodea el pezón del seno de la mujer. Estas glándulas secretan un fluido aceitoso que lubrica el pezón y también secreta compuestos volátiles que se cree que sirven como una estímulo olfatorio para el recién nacido. Durante el embarazo y la lactancia estas glándulas, también llamadas glándulas de Montgomery, se hacen más grandes.

Las glándulas de Meibomio, en los párpados secretan una forma de sebo llamada meibum en el ojo, que ralentiza la evaporación de las lágrimas. También sirve para crear un sello hermético cuando los ojos están cerrados y su calidad lipídica también previene que los párpados se queden pegados. Las glándulas de Meibomio también son conocidas como glándulas tarsales, glándulas Zeis y glándulas palpebrales. Se pegan directamente a los folículos de los párpados que están arreglados verticalmente entre las placas tartales y los párpados.

Los granos de Fordyce o gránulos de Fordyce, son glándulas sebáceas ectópicas que se encuentran en los genitales y en la mucosa oral. Se muestran como milia blanca amarillenta..

La cera de oído está compuesta en parte por sebo producido por las glándulas en el canal auditivo. Estas secreciones son viscosas y tienen un alto contenido lipídico que proporciona buena lubricación.

Las glándulas sebáceas están relacionadas con problemas de la piel, como acné y keratosis pilaris. En los poros de la piel, el sebo y la queratina pueden crear un tapón hiperqueratósico llamado comedón.

El acné es un problema muy común, particularmente durante la pubertad en adolescentes, y se cree que se relaciona con un incremento de la producción de sebo debido a factores hormonales. El aumento de la producción de sebo puede conducir a un bloqueo del ducto de la glándula sebácea. Esto puede causar un comedón (puntos negros), que pueden causar una infección, particularmente por la bacteria "Propionibacterium acnes". Esta puede inflamar los comedones, que entonces cambian a las lesiones características del acné. Los comedones generalmente aparecen en las áreas con más glándulas sebáceas, principalmente la cara, hombros, parte superior del pecho y espalda. Los comedones pueden ser blancos o negros dependiendo de la unidad completa de pilosebáceos o si el ducto sebáceo está bloqueado. 

Hay muchos tratamientos disponibles para el acné, desde reducir azúcares en la dieta hasta medicamentos que incluyen antibióticos, peróxido de benzoilo, retinoides y tratamientos hormonales. Los retinoides reducen la cantidad de sebo producido por las glándulas sebáceas. Si los tratamientos convencionales fallan, se puede buscar la presencia de Demodex que podría ser una causa probable..

Otras condiciones que involucran las glándulas sebáceas son:

La palabra "sebácea" significa "que consiste de sebo", fue usada por primera vez en 1728 y viene del Latín adipem que significa sebo.Las glándulas sebáceas han sido documentadas desde por lo menos 1746 por Jean Astruc, quién las definió como "...las glándulas que separan la grasa."Las describe en las cavidades orales, la cabeza, los párpados y los oídos, como "universalmente" conocidas.Astruc las describe al ser bloqueadas por "pequeños animales" que son "implantados" en los ductos secretores,y le atribuye su presencia en las cavidades orales a úlceras aftosas, señalando "estas glándulas naturalmente [secretan] un humor viscoso, que pone varios colores y consistencias... en su estado natural es muy suave, balsámico, y destinado a mojar y lubricar la boca".En "The Principles of Physiology" 1834, Andrew Combe observó que las glándulas no estaban presentes en las palmas de las manos ni las plantas de los pies.

Las glándulas prepuciales de ratones y ratas son grandes glándulas sebáceas modificadas que producen feromonas usadas para marcar territorio. Estas y las glándulas sensoriales en los flancos de los hámsters tienen una composición similar a las glándulas sebáceas humanas, son sensibles a andrógenos y han sido usadas como una base para estudio.

La adenitis sebácea es un enfermedad inflamatoria autoinmune que afecta a las glándulas sebáceas. Se sabe que se presenta principalmente en perros, particularmente en poodles y akitas, donde se cree generalmente que es de herencia autosómica recesiva. También se ha descrito en gatos y un reporte describe la condición en un conejo. En estos animales causa la pérdida de pelo, aunque la naturaleza y distribución de la pérdida de pelo difiere bastante.


</doc>
<doc id="27975" url="https://es.wikipedia.org/wiki?curid=27975" title="Gripe">
Gripe

La gripe (también, gripa o influenza) es una enfermedad infecciosa causada por el influenzavirus A o el influenzavirus B, géneros ambos de virus de ARN de la familia Orthomyxoviridae.

Aunque en algunos países se utilizan los términos "gripe" o "gripa" para referirse al resfriado común, estos términos no deben confundirse o usarse por igual. Las palabras "gripe" y "gripa" proceden de la palabra francesa "grippe" (procedente del suizo-alemán "grupi", "acurrucarse"), mientras que "influenza" procede del italiano. La gripe puede ser similar a un resfriado; sin embargo, suele iniciarse súbitamente con fiebre alta, dolor de garganta, debilidad, malestar general, dolores musculares (mialgias), dolor estomacal, dolores articulares (artralgias), dolor de cabeza (cefalea) y tos, que generalmente es seca y sin mucosidad. También puede provocar, esto más a menudo en niños, náuseas, vómitos y diarrea.

En los seres humanos puede afectar las vías respiratorias, esto es, la nariz, la garganta, los bronquios y, con poca frecuencia, los pulmones; sin embargo, también puede afectar al corazón, el cerebro o los músculos. La gripe suele curarse espontáneamente en algunos días, pero en algunos casos puede agravarse debido a complicaciones que pueden resultar fatales, especialmente en niños pequeños, en mujeres embarazadas, en adultos mayores o en personas con el estado inmunitario alterado.

La gripe se distribuye mundialmente en patrones estacionales ya sea como epidemias o pandemias que provocan una considerable morbilidad y mortalidad. Anualmente se presenta en otoño e invierno en zonas templadas. Se transmite desde individuos infectados a través de gotas en aerosol cargadas de virus procedentes de secreción nasal, bronquial o saliva que contenga alguna de ellas, emitidas con la tos o los estornudos o solo al hablar. Generalmente se requiere una distancia cercana (menor a un metro) con la persona enferma para contraer la infección.

El tratamiento es solo sintomático, y en los casos graves y hospitalarios es solo de mantenimiento de constantes, pues los fármacos antivirales tienen una eficacia muy limitada (los más eficaces son los inhibidores de la neuraminidasa) y no carecen de toxicidad. Los antibióticos solo son útiles si hay infección bacteriana asociada. El pronóstico es bueno con recuperación parcial a la semana y total a los quince días, siendo, en las epidemias habituales, los "exitus letalis" consecuencia de la patología o del deficiente estado inmunitario, previos a la infección gripal.

En los países desarrollados, se han establecido campañas de vacunación anuales frente a la gripe para las personas con mayor riesgo de contraer la enfermedad o que son más vulnerables a sus complicaciones, así como controles estrictos a las aves de corral. La vacuna humana habitual es la trivalente, que contiene proteínas purificadas e inactivadas de las tres cepas que se considera que serán más comunes en la siguiente epidemia: dos subtipos del virus A de la gripe y uno del virus B. Una vacuna elaborada para la gripe de un determinado año puede no ser eficaz para campañas posteriores, debido a las frecuentes y rápidas mutaciones (cambios en sus antígenos) que sufre el virus, y a la dominancia variable de las diferentes cepas.

Los síntomas de la gripe en humanos fueron descritos por Hipócrates el 412 a.C.

Desde entonces se han descrito numerosos episodios similares. Desde 1173, Hirsch tabuló una serie de brotes periódicos de gripe. En América, la primera descripción de una epidemia de gripe se documento en Texcoco, en 1552, y se le denominó «pestilencia catarral». De 1580 se cuenta con el primer registro detallado de una gran pandemia de gripe y desde entonces se han descrito 31 pandemias.

La pandemia gripal de 1580 comenzó en Asia y se extendió a Europa, África y finalmente a América, aunque quizá fuera de tosferina. Los italianos la denominaron «influencia planetaria», por una serie de fenómenos astrales que se observaron previo al brote; de esta denominación surgió el nombre influenza. Las pandemias se sucedieron durante los siglos XVII y XVIII, siendo la de 1830–1833 especialmente virulenta y de gran morbilidad, ya que infectó una cuarta parte de la población expuesta.

La pandemia más letal conocida fue la gran pandemia de gripe española de 1918 (virus A, subtipo H1N1), que se presentó en dos oleadas entre la primavera de 1918 y el otoño de 1919, así denominada porque en España la ocurrencia de la enfermedad fue ampliamente publicitada, lo cual no ocurría con el resto de las naciones, dada la censura imperante durante el período de la primera guerra mundial en la cual estaban inmersos. Las estimaciones más antiguas indicaban poco más de veinte millones de muertos, mientras que actualmente se sitúa la cifra entre 50 y 100 millones de personas fallecidas por aquella pandemia en todo el mundo.

Esta pandemia ha sido descrita como el mayor holocausto médico de la historia y causó al menos tantos muertos como la peste negra. Esta gran mortalidad fue debida a la alta tasa de infectividad (hasta el 50 % de la población expuesta) y a la gravedad de los síntomas causados por la producción masiva de citocinas (tormenta de citocinas). A esto hay que sumar que los primeros síntomas, en 1918, fueron atribuidos a otras enfermedades como dengue, cólera, o la fiebre tifoidea. Un observador escribía que "una de las peores complicaciones es la hemorragia de las mucosas, especialmente la nasal, la del estómago o la intestinal. También son frecuentes el sangrado de oídos y las petequias". La mayor parte de las muertes ocurrieron por neumonía bacteriana, una infección secundaria provocada por la gripe, pero el virus también mató, directamente, a consecuencia de las hemorragias masivas y el edema pulmonar.

La pandemia de 1918 tuvo un origen geográfico aún dudoso y se extendió por todo el planeta, incluso al Ártico y a remotas islas del Océano Pacífico. La gravedad inesperada de la enfermedad produjo la muerte de entre el 2 y el 20 % de todos los infectados (frente a la tasa habitual de mortalidad de la gripe común, que está en torno al 0,1 %). Otra característica diferencial de esta pandemia fue que la mortalidad afectó sobre todo a jóvenes, con un 99 % de las muertes en personas por debajo de los 65 años, y más de la mitad en adultos entre los 20 y los 40 años. La gripe común tiene sus mayores tasas de mortalidad, por el contrario, en los estratos de población más joven (menores de dos años) y sobre todo entre los mayores de 70. La mortalidad total real de la pandemia de gripe de 1918–1919 no se conoce con certeza, pero se estima que en torno al 2,5 % al 5 % de la población mundial murió por su causa (unos 25 millones de personas solo en las primeras 25 semanas). Valga como comparación que el virus del sida ha causado esa misma cantidad de muertes en sus primeros 25 años de existencia.

Con la reciente disponibilidad de muestras de fallecidos por el virus de la gran pandemia de gripe de 1918, cultivos de virus de la gripe y las novedosas técnicas de biología molecular se ha conseguido clonar el genoma completo del agente causal de la pandemia de 1918. Para ello, se ha utilizado metodología basada en la genética reversa para generar un virus de influenza que contiene los ocho segmentos genéticos de este virus. Este logro permite estudiar las propiedades asociadas a su extraordinaria virulencia. En marcado contraste con la influenza humana contemporánea (el virus H1N1), en los ensayos realizados "in vitro" el virus de la pandemia de 1918 tuvo la capacidad de replicarse en ausencia de tripsina, lo que le permitió causar la muerte en ratones y embriones de pollo, mostrando un fenotipo de alta replicación en las células epiteliales bronquiales. Por otra parte, la expresión coordinada de los genes del virus de 1918 sin duda otorga un fenotipo único de alta virulencia observada con este virus pandémico y que no se ha observado en ningún otro virus de la influenza analizado hasta este momento.

Las pandemias posteriores de gripe (la gripe asiática (tipo A, subtipo H2N2) y la de 1968 o gripe de Hong Kong (tipo A, subtipo H3N2) no han sido tan devastadoras, pero también provocaron millones de defunciones. En las últimas pandemias, la disponibilidad de antibióticos ha servido para controlar las infecciones oportunistas y esto ayudó a reducir la tasa de mortalidad con respecto a la de la gran pandemia de 1918.

La familia de virus Orthomyxoviridae es la causante (etiología) de la gripe y fue descrita por primera vez en cerdos por Richard Schope en 1931. Este descubrimiento fue seguido en breve por el aislamiento del virus en humanos por un grupo de investigación dirigido por Patrick Laidlaw y el Medical Research Council del Reino Unido en 1933. Sin embargo, hubo que esperar hasta 1935 para que Wendell Meredith Stanley, Premio Nobel de Química 1946, estableciera la verdadera naturaleza no celular de los virus.

El primer paso significativo hacia la prevención de la gripe fue el desarrollo de una vacuna de virus muertos por Thomas Francis Jr en 1944. Posteriormente Frank Macfarlane Burnet demostró que los virus pierden virulencia al ser cultivados en proteína de huevo, posibilitándose así las vacunas de virus inactivados, mucho más eficaces.

La aplicación de esta observación permitió a un grupo de investigadores de la Universidad de Míchigan desarrollar la primera vacuna empleada en población, con la colaboración del ejército de los Estados Unidos. La decisión del ejército de participar en el desarrollo de esta vacuna se debió a su experiencia con la gripe durante la Primera Guerra Mundial, cuando miles de soldados murieron por el virus en cuestión de pocos meses.

Aunque se desataron algunos temores con la gripe del cerdo de Nueva Jersey en 1976, en 1977 con un rebrote de la gripe rusa y en Hong Kong y otros países asiáticos en 1997 (con la variante H5N1 de la gripe aviar), no ha habido ninguna pandemia de importancia desde la gripe de Hong Kong de 1968. En mayo de 2009 México tuvo una alerta de A(H1N1) (gripe A) que mantuvo a la población de la Ciudad de México en cuarentena. La inmunidad adquirida con las pandemias previas y las campañas de vacunación parecen haber limitado la extensión del virus y pueden ayudar a prevenir futuras pandemias.

Durante el siglo XX se produjeron cinco pandemias de gripe debido a la aparición por mutación de diferentes cepas del virus. A menudo estas nuevas cepas han surgido a partir del trasvase de cepas típicas de animales al ser humano, en lo que se denomina salto de especie o heterocontagio. Una variante mortal del virus de la gripe aviar denominada H5N1 pasó por ser la principal candidata para la siguiente pandemia de gripe en humanos desde que traspasó la barrera de especie en los años 1990 y provocó decenas de defunciones en Asia, hasta la aparición de la neogripe A (H1N1) en 2009. Afortunadamente aquella variante aviar no mutó y no puede transmitirse de persona a persona, pues solo afectó a humanos desde aves contagiadas y ese contagio no es fácil pues requiere unas condiciones muy especiales.

Los virus de la gripe resisten más en ambiente seco y frío. Pueden conservar su capacidad infectiva durante una semana a la temperatura del cuerpo humano, durante 30 días a 0 °C y durante mucho más tiempo a menores temperaturas. Puede ser fácilmente inactivado mediante detergentes o desinfectantes.

La incidencia global se calcula en 10-20 %, pero la selectiva, en determinados grupos poblacionales, puede llegar al 40-50 %.

La gripe alcanza sus picos de mayor prevalencia durante el invierno y, debido a que el hemisferio norte y el hemisferio sur atraviesan esta estación en diferentes momentos, existen, de hecho, dos temporadas de gripe cada año: de octubre a abril en el hemisferio norte y de mayo a septiembre en el hemisferio sur. Este es el motivo por el que la OMS (asesorada por los Centros Nacionales para la Gripe) hace recomendaciones para dos formulaciones vacunales cada año, una para cada hemisferio. Además del clima y la humedad, el estilo de vida de las poblaciones y otros factores están asociados a la aparición de la gripe.

No está completamente claro por qué las epidemias de gripe ocurren de esta forma estacional y no de manera más uniforme a lo largo de todo el año. Una posible explicación es que el contacto interpersonal es más estrecho en invierno debido a un mayor tiempo de vida en el interior de domicilios y edificios y esto facilitaría una transmisión del virus de persona a persona. Otra explicación es que las temperaturas más altas de los meses de verano y la mayor sequedad del aire limitaría la expulsión del moco por deshidratación del mismo, dificultando la transmisión a través del mecanismo de aerosol que se da durante la tos o el estornudo. El virus también puede sobrevivir mucho más tiempo en los fomites (objetos y superficies transmisores como pomos de puertas, encimeras...) cuando el ambiente es más frío. Los desplazamientos poblacionales durante las vacaciones de Navidad en el hemisferio norte también podrían jugar algún papel. Un factor que puede contribuir al fenómeno estacional es que la transmisión a través del aerosol mucoso es mayor en ambientes fríos (por debajo de 5 °C) y escasa humedad relativa. Sin embargo, los cambios estacionales en las tasas de infección se dan también en regiones tropicales y estos picos de infección pueden verse principalmente durante la temporada de lluvias. Los cambios estacionales en las tasas de contacto durante los períodos escolares parecen jugar un rol más importante que en otras enfermedades escolares como el sarampión y la tos ferina. Una combinación de estos pequeños factores estacionales puede verse amplificada por fenómenos de resonancia dinámica con los ciclos endógenos de enfermedades regionales.

No se conoce el mecanismo por el cual el virus subsiste entre los brotes epidémicos y se han sugerido dos hipótesis:



En las pandemias, y así se definen, la epidemia progresa hasta afectar a todo el planeta. Fue particularmente famosa y mortífera la de 1580, que algunos creen fue en realidad de tosferina. Las cinco últimas, del siglo XX, han sido causadas por virus de la cepa A, con la aparición de los subtipos:

Las tres últimas pandemias se originaron en Asia, avanzaron hacia occidente y pasaron a América.

Las pandemias tienen características comunes:

La letalidad acumulada de las epidemias supera, en mucho, a la de las pandemias.

Un estudio realizado acerca de la eficiencia de la entrada del virus H3N2 ha demostrado que la presencia de diferentes neuraminidasas afecta a la eficiencia de entrada del virus de la gripe. Esto es sorprendente ya que la misma molécula que permite la liberación del virus de la superficie celular ayuda a mejorar la entrada. La neuraminidasa produce la rotura enzimática del ácido siálico del receptor celular para separar la unión virus-membrana y permitir que el virus sea liberado e infecte otras células. 

El estudió generó diferentes pseudovirus que infectaban a la bacteria de la cepa X-31 y que presentaban: solamente hemaglutinina sin neruraminidasa (H3X-31), hemaglutinina y neruraminidasa propias de la cepa X-31 (H3X-31/N2X-31), partículas que presentan la hemaglutinina de la bacteria X-31 y la neuraminidasa de la cepa Japan (H3X-31/N2Japan) y la última con la hemaglutinina de la bacteria X-31 y la neuraminidasa de una cepa que causa gripe aviar (H3X-31/N2MS96). Se demostró mediante diversos ensayos que las bacterias que presentaban hemaglutinina y neuraminidasa coincidentes, es decir, que provenían ambas de la misma cepa (la H3X-31/N2X-31), presentaban mayor eficacia de entrada, seguidas por la H3X-31/N2Japan (ya que la neuraminidasa de la cepa Japan es más parecida filogenéticamente a la neuraminidasa de la X-31), luego la H3X-31/N2MS96 y por último la que no presenta neuraminidasa. Por lo tanto, presentar la neuraminidasa correspondiente es esencial en la entrada viral y los desajustes en la combinación de hemaglutinina y neuraminidasa, pueden causar un descenso importante en la capacidad infectiva. 

El virus de la gripe es un virus ARN de la familia Orthomyxoviridae, que comprende cinco géneros:

Solo los tres primeros ("influenzavirus") son causantes de gripe. La nomenclatura general de los virus de la gripe como tipos A, B o C se basa en características antigénicas de la nucleoproteína (NP) y los antígenos proteínicos de la matriz (M) para cada género. Cada género a su vez, se subtipifica y las cepas o subtipos se designan siguiendo este criterio:

Este género posee una especie: el virus de la influenza A. Las aves acuáticas salvajes son los huéspedes naturales de sus muchos subtipos. En ocasiones, los virus pueden transmitirse a otras especies lo que puede provocar graves epidemias en la población de aves para consumo humano, o saltar directamente al hombre con la consiguiente pandemia. Los virus tipo A son los patógenos más agresivos de los tres géneros que pueden provocar la enfermedad. En función del anticuerpo dominante, pueden dividirse en varios serotipos diferentes. Los serotipos que se han confirmado en los seres humanos son los siguientes:


Este género comprende a la especie "Influenza B virus". Infecta casi en exclusiva a humanos y es menos frecuente y menos agresivo que el tipo A. Además del hombre, el único animal susceptible de ser infectado por este tipo de virus es la foca. Este virus tiene una tasa de mutación de 2 a 3 veces más baja que el tipo A por lo que es genéticamente menos diverso, conociéndose solamente un serotipo del grupo B. A consecuencia de esta carencia de variabilidad antigénica un cierto grado de inmunidad frente a este tipo se adquiere normalmente desde la infancia. Sin embargo, presenta el suficiente grado de mutación como para impedir la inmunidad completa y definitiva. Esta reducida tasa de cambios antigénicos, en combinación con su limitado rango de huéspedes posibles, determina la inexistencia de pandemias de virus tipo B.

Este género posee una especie: el "Influenza C virus", que infecta a humanos y a cerdos, y que puede causar cuadros graves y epidemias locales en animales. El tipo C es menos frecuente que los otros dos tipos, y parece ser responsable con cierta frecuencia de cuadros banales en niños.

Los Influenzavirus A, B y C poseen una estructura muy parecida. Las partículas víricas alcanzan un diámetro de entre 80 y 120 nanómetros con una forma más o menos esférica, aunque en ocasiones pueden verse algunos ejemplares de tipo filamentoso. Aunque inusual para un virus su genoma no es un fragmento único de ácido nucleico sino que contiene siete u ocho fragmentos de ARN inverso. El genoma del tipo A codifica 11 proteínas: Hemaglutinina (HA), Neuraminidasa (NA), Nucleoproteína (NP), M1, M2, NS1, NS2(NEP), PA, PB1, PB1-F2 y PB2.

HA y NA son grandes cadenas glicoproteicas que se proyectan del exterior de la partícula vírica. HA es una lectina mediadora de la fijación del virus a la célula diana y de la entrada del material genético en ella, mientras que NA está involucrada en la liberación de la progenie viral desde las células infectadas al exterior, mediante la ruptura de azúcares que ligan a las partículas virales maduras. Estas proteínas son objetivos para los fármacos antivirales. Además cumplen una función de antígeno al que los anticuerpos pueden fijarse. Los influenzavirus A están clasificados en subtipos basándose en la respuesta antigénica a HA y NA, dando lugar a la nomenclatura "H" y "N" como se mencionó más arriba.

Los virus de la gripe se fijan mediante hemaglutininas a los azúcares de ácido siálico de la membrana celular de las células epiteliales mucosas de las fosas nasales, garganta y pulmones (más en nasofaringe y tráquea pues la afectación bronquiolar y alveolar se da solo en los casos graves), en los mamíferos, y del intestino, en las aves. (Paso 1 de la imagen).. 

Por tanto, la entrada del virus de la gripe requiere la presencia de hemaglutinina (HA), mientras que la salida requiere neuraminidasa. La entrada es mediada por endocitosisis por clatrina y se produce mediante estos pasos: 

En primer lugar la hemaglutinina del virus de la gripe reconoce los receptores que presentan ácido siálico en la superficie celular. El complejo virus-receptor es introducido en la célula por endocitosis. A causa de la actividad de una bomba de protones vacuolar los protones (H+) son bombeados dentro de la vesícula, por lo que el pH de la vesícula endosomal desciende. La proteína viral M2 transporta los H+ al núcleo del virión. El descenso en el pH libera la proteína viral M1 del RNA viral (ya que M1 está localizada entre la envoltura viral y el genoma). El descenso en el pH endosomal también desencadena cambios conformacionales en la hemaglutinina. Esto causa la exposición del péptido de fusión, una secuencia hidrofóbica que se inserta en la membrana endosomal y causa que se fusione con la envoltura viral. El RNA viral y las proteínas, como M1, son liberados en el citoplasma y el genoma viral es transportado al núcleo celular para la replicación del RNA viral. 

La célula importa el virus mediante endocitosis. Los ciclos de replicación duran entre 4 y 6 horas. En el endosoma así formado, parte de las proteínas de hemaglutinina fusionan la cubierta viral con la membrana vacuolar, liberando las moléculas de ARN vírico, proteínas accesorias y de ARN polimerasa al citoplasma (Paso 2). Estas proteínas y el ARN forman un complejo que es transportado al núcleo celular, donde la ARN polimerasa comienza a transcribir copias complementarias positivas del ARN inverso (antisentido). (Pasos 3a y b). El ARN vírico puede ser devuelto al citoplasma y traducido (Paso 4), o permanecer en el núcleo. Las proteínas víricas recién creadas son también secretadas mediante el aparato de Golgi hacia la superficie celular (en el caso de la neuraminidasa y la hemaglutinina, Paso 5b) o transportadas de vuelta al núcleo para fijarse al ARNv y formar nuevas partículas víricas (Paso 5a). Otras proteínas víricas tienen múltiples acciones en la célula huésped, incluyendo la propia degradación del ARN celular con el fin de emplear los nucleótidos resultantes para la síntesis de más ARNv e inhibiendo la transcripción del ARN celular. El genoma vírico está compuesto por ocho segmentos de ARN de una sola cadena (monocatenario).

El ARN inverso formado dará lugar al genoma de futuros virus, ARN polimerasa y otras proteínas virales que se ensamblarán en un nuevo virión con capacidad infectante. Las moléculas de hemaglutinina y neuraminidasa se agrupan formando protuberancias en la membrana celular. El ARN vírico y las proteínas de la nucleocápside salen del núcleo y entran en estas protuberancias de la membrana (Paso 6). Los virus maduros se abren al exterior de la célula en una esfera de fosfolípidos de membrana, adquiriendo hemaglutinina y neuraminidasa junto con esta cubierta membranosa. (Paso 7). De nuevo, las partículas víricas así formadas se adherirán a nuevas células huésped mediante las hemaglutininas transportadas; los virus maduros se liberan entonces una vez que las neuraminidasas rompen los residuos de ácido siálico de la célula huésped. Tras la liberación de la nueva generación de partículas víricas, la célula huésped muere.

Aproximadamente una vez cada diez mil nucleótidos (la longitud del ARN del virus), la ARN polimerasa comete un error en la inserción de un nucleótido (debido a la ausencia de enzimas de prueba de lectura de ARN) lo que ocasiona que casi cada nuevo virus creado porta al menos una mutación. Esas mutaciones provocan la variación antigénica de los virus y las dificultades del sistema inmunitario para identificarlos como tales y eliminarlos.

La separación del genoma en ocho fragmentos diferentes permite recombinar los cambios si más de una estirpe viral infecta a la misma célula. El recambio rápido resultante en el material genético produce cambios antigénicos y permite al virus infectar nuevas especies huésped y superar rápidamente los mecanismos de defensa inmunitaria. Esto tiene trascendencia en la fase de emergencia de las pandemias como se discutirá en la sección de epidemiología.

La viremia es excepcional y el virus habitualmente solo es localizable en las vías respiratorias, pero en casos graves en la autopsia se han encontrado virus en hígado, bazo, corazón, riñones y ganglios linfáticos. Los síntomas, distales al aparato respiratorio y habituales de la gripe (como la fiebre, la cefalea o la astenia) tienen su origen en las enormes cantidades de citoquinas y quemoquinas (como el interferón o el factor de necrosis tumoral) producidas y liberadas por las células infectadas por el virus. Pero en contraste con el rhinovirus, causante del catarro común, la gripe causa un cierto grado de daño tisular, por lo que los síntomas no son exclusivamente debidos a la respuesta inflamatoria.

En la defensa inmunitaria contra el virus se implican 5 mecanismos:


La eliminación del virus (hacia el 8.º día) seguramente es debida a los 3 primeros mecanismos pues los 2 últimos, con producción de anticuerpos, son tardíos.

Las células de la mucosa que forma el epitelio respiratorio presentan cambios inflamatorios (tumefacción) del núcleo y en el espacio intracelular (citoplasma) se forman vacuolas ("burbujas") fruto de dichos cambios. Finalmente la célula se necrosa (muere) y se desprende dejando la capa basal del epitelio expuesta: esta capa es mucho más sensible, es incapaz de retener el moco y su exposición es la causa de la mayor parte de los síntomas respiratorios del cuadro.

Cinco días después se inicia la regeneración que inicialmente tiene aspecto metaplásico (células atípicas), pero que a las dos semanas adquiere un aspecto totalmente normal.

Si se produce una neumonía vírica se puede producir la pérdida de epitelio ciliado en la tráquea, bronquios y bronquiolos. Los alveolos pulmonares se ven con las paredes engrosadas por edema (líquido en su interior) e infiltración y con un revestimiento membranoso hialino (de tejido conectivo en respuesta a la inflamación). Con ello el intercambio de oxígeno entre el pulmón y la sangre se ve comprometido y el déficit de oxígeno en sangre puede ocasionar una disminución global de oxígeno disponible para los tejidos (hipoxia tisular), con el consiguiente deterioro funcional.

La infección con virus de influenza puede ser asintomática y subclínica sin interferir en la capacidad laboral, pero con plena infectividad. Son casos en los que el portador, y también transmisor, no es consciente de la enfermedad. Esto es muy frecuente en la gripe por virus C y mucho más raro en los tipos A y B.

En los humanos los síntomas de la gripe tienen una aparición más brusca, y son más graves y más duraderos que los síntomas del resfriado común. La recuperación completa se logra en una o dos semanas. En ocasiones puede ser mortal, especialmente en pacientes debilitados (por ser ancianos o enfermos crónicos) o con déficit inmunitario. La gripe puede agravar patologías crónicas previas: pacientes con enfisema, bronquitis crónica o asma pueden presentar episodios de disnea durante la fase aguda de la gripe y también puede agravarse una patología coronaria previa o descompensarse un cuadro de insuficiencia cardíaca. El tabaco es otro factor de riesgo que se asocia con cuadros más graves y un incremento de la mortalidad, pero no por su acción directa en la patogenia sino por las lesiones enfisematosas y bronquíticas, previas y subyacentes por él motivadas.

Los síntomas de la gripe comienzan de manera brusca (por ello se suele recordar incluso la hora exacta de aparición): entre 18 o 72 horas (visto que poseen periodos de incubación extremadamente cortos, que es cuando son proclives los contagios) tras el contacto con el virus y la infección. Los primeros síntomas suelen ser estornudos con sensación de resfriado, fiebre alta de hasta 39 °C, cansancio intenso (astenia), con dolores musculares y articulares. El malestar general suele provocar el encamamiento del paciente durante dos o tres días, con dolores musculares generalizados (de mayor intensidad en espalda y piernas) y con persistente dolor articular, más intenso en ambas rodillas.

Los síntomas (lo que refiere el paciente en la anamnesis) más habituales son:

Los signos (que se evidencian con los 5 pilares de la exploración física: inspección, palpación, percusión, olfatación y auscultación) más frecuentes son:

Investigaciones sobre los síntomas y signos de la gripe han demostrado que los mejores indicadores para el diagnóstico de gripe son:
Notas de la tabla:

Dado que los fármacos antivirales son más eficaces en los primeros estadios de la enfermedad (primeras 48 horas) es importante el diagnóstico precoz de la gripe. La evaluación combinada de los diferentes síntomas listados más arriba puede mejorar la eficacia del primer diagnóstico. No obstante incluso evaluando la aparición combinada de síntomas se producen errores en el diagnóstico, por lo que en ocasiones se recurre al teorema de Bayes como herramienta estadística para afinar el diagnóstico, aunque hay que tener en cuenta que su aplicabilidad varía con la prevalencia de la gripe en el momento de su aplicación: es decir, durante una epidemia de gripe o en pleno invierno es más probable que determinada combinación de síntomas apunten a una gripe que, por ejemplo, en pleno verano y sin casos de gripe en la comunidad. Usando los datos de los CDC (Centros para el Control de Enfermedades —Centers for Disease Control—), la siguiente tabla muestra como la probabilidad de gripe varía con su prevalencia:

Dos estudios de análisis de decisiones han sugerido que durante epidemias locales de gripe, la prevalencia estaría en torno al 70 %, y por lo tanto, los pacientes con alguna de las combinaciones de síntomas mencionadas más arriba deberían, (si estuviesen inmunodeprimidos, que es muy improbable), ser tratados con inhibidores de la neuraminidasa sin necesidad de la aplicación del test. Incluso en ausencia de una epidemia local, el tratamiento estaría justificado (según algunos pocos pues el tratamiento sintomático y de sostén suele preferirse dada la escasa eficacia y la toxicidad de los antivirales actuales, salvo en la neogripe A de 2009), en la población anciana durante la temporada "alta" de gripe ya que la prevalencia estaría por encima del 15 %.


La mayor dificultad diagnóstica, si la epidemia aún no está establecida, puede darse con:

La VSG está poco acelerada en contraste con la intensidad de los síntomas.

Los leucocitos pueden aumentar al inicio, pero lo característico es la leucopenia con linfocitosis a partir del segundo día. Una leucocitosis superior a 15 000 sugiere complicación bacteriana.

La disponibilidad de tests de laboratorio para el diagnóstico de la gripe continúa mejorando. Los CDC de los Estados Unidos publican actualizaciones de los test de laboratorio disponibles. De acuerdo con los CDC, el diagnóstico rápido mediante los test de laboratorio disponibles tienen una sensibilidad del 70–75 % y una especificidad del 90–95 % en comparación con los cultivos del virus. Estos test pueden ser especialmente útiles durante las temporadas de gripe (prevalencia=25 %), pero no en ausencia de epidemias locales o en temporada baja (prevalencia=10 %).

Los métodos serológicos (los antígenos virales se detectan con inmunofluorescencia o con ELISA) son poco útiles en clínica (pero sí son muy útiles en epidemiología) pues se requiere una valoración y cuantificación evolutivas y obtener suero de la fase de convalecencia (cuando ya cesó el peligro y se retiró el tratamiento), de manera que es positiva si hay cuadruplicación de las tasas de anticuerpos entre una cuantificación y la siguiente. Se prefiere la prueba de anticuerpos fijadores del complemento a la de la inhibición de la hemaglutinación porque esta última depende de las variaciones de cepa o subtipo.

El test de la PCR en tiempo real (RT-PCR) positivo en la neogripe A determina el paso desde diagnóstico de sospecha a diagnóstico de probabilidad.

El diagnóstico de certeza solo es posible con la identificación del virus mediante la inoculación de las secreciones faríngeas en cultivos celulares de riñón de mono, o más habitualmente en la cavidad amnial de embriones de pollo.

Los consejos generales para una persona afectada de gripe son reposo, ingesta abundante de líquidos (aunque existe poca evidencia de la utilidad), y el uso de algún fármaco que alivie los síntomas.

La aspirina no está indicada en niños y adolescentes (y el tratamiento previo parece aumentar la susceptibilidad de padecerla) con síntomas de gripe (y tampoco en cualquier otra situación febril) para evitar la aparición del síndrome de Reye, una complicación infrecuente, pero grave del hígado y del cerebro que puede afectarles cuando toman este antiinflamatorio en el contexto de algunas enfermedades víricas (especialmente la infección por Influenzavirus B).

La neumonía vírica en su fase grave suele requerir ingreso en cuidados intensivos y requerir medidas de mantenimiento como oxigenoterapia, fluidoterapia, fisioterapia y neumoterapia.

Diversos experimentos científicos han investigado si el tomar una cantidad mayor de lo normal de algún nutriente es útil contra las enfermedades infecciosas (incluyendo a la propia gripe y a otras que afectan al tracto respiratorio: resfriados, etc.). Estas investigaciones se han centrado principalmente en estudiar la vitamina C, pero en algún caso se han extendido a la vitamina D y el zinc. Como resultado, las investigaciones solo han encontrado que el tomar una cantidad adicional de estos nutrientes ayuda a reducir la duración y la severidad de las enfermedades infecciosas, sin haber sido demostrado que eso valga para prevenirlas. En cualquier caso, sus efectos pueden variar dependiendo del paciente. Una cuestión distinta son los casos de desnutrición, en los que estos nutrientes deben ser ingeridos de alguna manera hasta niveles suficientes para asegurar que el sistema inmunitario del cuerpo humano funcione de manera normal. Esto consigue una gran mejoría en países en vías de desarrollo para prevenir y curar enfermedades como la neumonía, la diarrea y la malaria.

Acerca de la vitamina D, hay que tener en cuenta que el cuerpo humano no tiene por qué ingerirla, pues estar expuesto al sol de manera moderada hace que la propia piel la produzca. Si es ingerida en suplementos hay que llevar más cuidado, pues al ser liposoluble y no hidrosoluble puede acumularse y provocar intoxicación en dosis altas.

Dado que la gripe es una infección vírica los antibióticos (fármacos antibacterianos, pero inactivos frente a virus) no mejoran el cuadro, salvo que se prescriban por la aparición de una infección bacteriana secundaria, situación en la que suele ser útil la tinción de Gram y un antibiograma para elegir el antibiótico adecuado.

No se deben administrar con fines profilácticos (preventivos), pues además de su inutilidad, así se seleccionan cepas microbianas multiresistentes.

En general los fármacos antivirales se reservan para personas con alto riesgo de padecer complicaciones (como obesos mórbidos, hospitalizados, ancianos, menores de 5 años, comorbilidades crónicas) o clínica severa. Es ideal empezar el tratamiento antes de 2 días de iniciados los síntomas.

Los dos tipos principales de antivirales son los inhibidores de la neuraminidasa y los inhibidores M2 (derivados del adamantano).

Son de primera elección en la infección por el virus de la gripe, aunque el CDC estadounidense recomendó el uso de inhibidores M2 durante la temporada de gripe 2005–2006.

Lamentablemente un estudio demostró que la administración del tratamiento antiviral en pacientes con gripe provoca la aparición de resistencia durante la terapia, alterando el pronóstico de la enfermedad. Ello tiene importancia en el impacto que lleva el tratar masivamente a una comunidad (~20 % de la población) durante una pandemia, lo cual puede provocar la desastrosa aparición de cepas resistentes durante el período de administración del tratamiento.

El oseltamivir (de nombre comercial Tamiflu) y el zanamivir (Relenza) son inhibidores de la neuraminidasa que han sido diseñados para detener la propagación del virus en el organismo humano. Tienen un rango alto de efectividad tanto frente a Influenzavirus A como B. El grupo colaborativo Cochrane para la gripe ha realizado estudios sobre estos fármacos concluyendo que ayudan a reducir los síntomas y las complicaciones derivadas de la infección. Las diferentes cepas de virus de la gripe presentan resistencias variables a su acción por lo que es imposible predecir qué grado de resistencia se encontrará en una futura pandemia.

Se sabe que el oseltamivir es mucho más vulnerable al desarrollo de resistencias que lo es el zanamivir, debido a la diferencia en su modo de acción. Sin embargo, el zanamivir es un medicamento inhalado, de modo que puede no ser adecuado para el tratamiento de una infección sistémica puesto que las concentraciones del zanamivir, aunque muy buenas en el tracto respiratorio, no alcanzan un efecto sistémico adecuado.

Los antivirales amantadina y rimantadina han sido diseñados para bloquear un canal iónico (proteína M2) y prevenir así la entrada del virus a las células huésped. Estos fármacos son en ocasiones eficaces frente a Influenzavirus A si se administran precozmente, pero son siempre ineficaces frente al grupo B. La resistencia medida a amantadina y rimantadina en cepas americanas aisladas de H3N2 se ha incrementado hasta un 91% en el 2005. La actividad de los admantanos parece ser poco eficaz contra las cepas H5N1.

Las complicaciones de la gripe ocurren más a menudo en pacientes mayores de 64 años de edad, así como en aquellos con ciertos trastornos crónicos, como enfermedades cardíacas y pulmonares, diabetes mellitus, hemoglobinopatías, disfunción renal e inmunodepresión. La pulmonía es la complicación más grave de la gripe y puede presentarse como neumonía gripal "primaria", neumonía bacteriana secundaria o neumonía mixta, vírica y bacteriana.

Es la menos frecuente, pero la más grave de todas las complicaciones neumónicas. Actualmente solo aparece en pacientes con bronquitis crónica, enfisema, cardiópatas —generalmente con estenosis mitral—, en deficiencias inmunológicas —como en la diabetes mellitus, sida, etc.— y ya más raramente en el embarazo, frecuente en la pandemia de 1918.

Aparece como cuadro gripal que no se resuelve y en el que hay aumento de la fiebre, expectoración escasa, pero sanguinolenta, taquipnea con dificultad respiratoria intensa y, finalmente, cianosis central.

El paciente tiende a sentarse en la cama por la aparición de ortopnea, pues respira mejor sentado que estando incorporado.

Como en todas las neumonías atípicas virales no hay consolidación pulmonar completa, los alveolos siguen ventilando y por ello la exploración auscultatoria puede ser anodina, con murmullo vesicular normal.

Contrastando con lo anterior las radiografías de tórax muestran infiltrados muy difusos que son generalmente bilaterales y centrales (perihiliares). Es conveniente pedir la radiografía anteroposterior y también la lateral izquierda para así evaluar mejor la extensión neumónica. La gasometría arterial muestra intensa hipoxia.

El curso suele ser muy grave y el "exitus letalis", a pesar de todas las terapias, suele sobrevenir a los 7 días.

Las bacterias patógenas más frecuentes son "Streptococcus pneumoniae", "Staphylococcus aureus" y "Haemophilus influenzae", que probablemente están previamente en la faringe y causan la infección por disminuir las defensas broncopulmonares durante el cuadro gripal.

La neumonía bacteriana suele comenzar cuando ya hay franca mejoría del cuadro gripal, unos 2-3 días tras el inicio de la enfermedad.

El esputo se hace purulento, la auscultación es de evidente consolidación pulmonar y las radiografías de tórax muestran los signos habituales de la neumonía.

Las bacterias pueden identificar por hemocultivo y menos frecuentemente por cultivo de esputo, pero el virus gripal ya no se puede identificar por haber transcurrido más de una semana desde el inicio de la enfermedad.

El pronóstico es mucho mejor que el de la neumonía vírica dada la habitual eficacia de los antibióticos si se aplican rápidamente, salvo que el germen responsable sea resistente a ellos.

Es un cuadro clínico mezcla de los dos anteriores pues hay empeoramiento en la fase aguda y posteriormente los síntomas son los típicos de la neumonía bacteriana y, quizás, la más frecuente de las complicaciones neumónicas.

La extensión suele ser menor que la habitual en la neumonía vírica y responde bien a los antibióticos, lo que induce a pensar que las bacterias son el agente patógeno predominante.

En este síndrome hay encefalopatía y degeneración grasa del hígado. Aparece ocasionalmente en la infección por el virus B de la gripe y menos en la infección por el A. También aparece a veces con el virus varicela-zóster (VVZ).

Al parecer está relacionado con la administración de aspirina en niños y adolescentes prepuberales (hasta 16-18 años) para el tratamiento de algunas viriasis.

Hay náuseas y vómitos durante uno o dos días, seguidos de trastornos mentales, desde letargia a coma, con hepatomegalia (aumento del tamaño del hígado) y elevación de los niveles en el suero sanguíneo de las enzimas aspartato aminotransferasa (GOT), alanina aminotransferasa (GPT) y LDH en sangre, pero permaneciendo la bilirrubina normal y sin presentar ictericia.

La mortalidad, que antes era del 40%, actualmente ha descendido al 10%. En las autopsias de pacientes fallecidos del síndrome de Reye no se suele encontrar el virus ni en cerebro ni en hígado.

Otras complicaciones menos frecuentes descritas en asociación con la gripe incluyen:


Ya más raramente, pero que sí fueron frecuentes en la pandemia de 1918, pueden presentarse:


Otras complicaciones neurológicas, de presentación muy ocasional, son parálisis de pares craneales, mielitis, sordera, afasia, hemiplejía, síndrome de Guillain-Barré y psicosis, pero la relación con el proceso gripal no está totalmente demostrada.

La mayoría de las personas que contraen la gripe se recuperan en una o dos semanas (una de enfermedad y otra de convalecencia), pero algunas desarrollan complicaciones graves como neumonía. Según la OMS: "Cada invierno, diez millones de personas contraen la gripe. La mayoría sólo enferman y se ausentan del trabajo durante una semana, pero la población anciana presenta un mayor riesgo de complicaciones mortales. Sabemos que la cantidad de fallecimientos anuales es de unos cientos de miles de individuos, pero incluso en los países desarrollados las cifras son inciertas porque las autoridades médicas no suelen verificar quién muere realmente a consecuencia de la gripe y no de otros cuadros parecidos". Incluso la población sana puede verse afectada y a cualquier edad pueden producirse complicaciones graves. El grupo de población de personas por encima de los 50 años, los niños pequeños y la población de cualquier edad con patología crónica tienen mayor riesgo de padecer esas complicaciones, como neumonía, bronquitis, sinusitis u otitis.

Existen vacunas y antivirales para la profilaxis y el tratamiento de las infecciones por el virus de la gripe. Las vacunas están formuladas a partir de virus inactivados o viriones atenuados de la gripe humana H1N1 y H3N2, así como los de los virus de la influenza B. Debido a que la antigenicidad de los virus salvajes evolucionan, las vacunas se reformulan anualmente. Sin embargo, cuando la antigenicidad de las cepas que forman parte de las vacunas y la de los virus salvajes que circulan entre la población no coinciden, las vacunas dejan de ser efectivas. En otras ocasiones, incluso cuando ambas antigenicidades coinciden, se puede dar el caso de que aparezcan mutantes que escapan a la vacuna. Los fármacos más frecuentes incluyen la amantadina, que inhibe la pérdida de la envoltura de los viriones al interferir con M2, y oseltamivir, que inhibe la liberación de los viriones de las células infectadas al interferir con NA. Sin embargo, los mutantes que son capaces de escapar a la vacuna se han generado, principalmente, en ex usuarios de drogas y con menor frecuencia para el último fármaco.

Se han realizado varios estudios con el objetivo de demostrar la inmunogenicidad de la vacuna inactivada contra la gripe. En 1976 se encontró que dicha inmunidad persistía al cabo de tres años posterior a la vacunación del tipo monovalente A. Un año después se reportó que los individuos vacunados durante una epidemia de influenza tipo A presentaban inmunidad a partir del octavo o noveno día después de la vacunación y persistía al cabo de un año. En 1982 se comprobó la eficacia de la vacuna trivalente en 75 reclutas del ejército italiano y cientos de otros voluntarios de otros países.

La vacunación antigripal está ampliamente recomendada para grupos de alto riesgo, que son aquellos en los que las complicaciones de la gripe pueden ser graves:


Además de los grupos de riesgo es habitual la vacunación anual del personal de servicios sociales básicos como médicos, docentes, bomberos o militares.

En general la vacuna se administra a todo aquel con mayor indefensión ante las complicaciones por déficit inmunitario y también a todo aquel que lo solicite dadas sus escasas contraindicaciones (hipersensibilidad o alergia a las proteínas de huevo o a los antibióticos usados en el cultivo de los virus), a fin de dificultar la transmisión todo lo posible.

Las vacunas frente al virus de la gripe pueden fabricarse siguiendo diferentes procesos: el más habitual es el cultivo de virus en proteínas de huevo de gallina. Tras su purificación el virus es inactivado (mediante el uso de agentes químicos (detergentes) o físicos para producir una vacuna que pueden ser de virus íntegros o fraccionados, estas últimas son de elección en niños por ocasionar menor número de reacciones febriles. También pueden realizarse cultivos de virus en proteínas de huevo hasta que pierden su virulencia generando así vacunas.

Las de virus vivos atenuados para administración nasal son menos aconsejables en inmunodeprimidos.

La eficacia de estas vacunas es variable y no se encuentran grandes diferencias entre las vacunas de virus fraccionado (subvirones) y las vacunas de subunidades, en términos de inocuidad, reactogenicidad e inmunidad en adultos y ancianos.

Debido a la alta tasa de mutación del virus una formulación vacunal concreta confiere inmunidad durante no más de unos pocos años. Cada año la OMS realiza una predicción sobre qué cepa del virus es más probable que sea la causante de la siguiente oleada, permitiendo así a la industria farmacéutica el desarrollo de las vacunas más apropiadas contra esas cepas. Las vacunas también se pueden desarrollar para proteger a las aves de corral de consumo humano de la gripe aviar. Estas vacunas pueden ser eficaces contra múltiples cepas y son usadas junto con el sacrificio selectivo de los animales con mayor riesgo de transmisión de cepas mutadas, como parte de una estrategia de prevención con objeto de evitar o reducir las posibles epidemias y pandemias en humanos.

Es posible estar vacunado y aun así contraer la gripe (uno de cada 5 casos) pues la vacuna tiene una eficacia de alrededor del 80 %. La vacuna se elabora antes de cada temporada de gripe para unas cepas específicas, pero puede suceder que se produzca la propagación de alguna cepa no prevista o mutada. Se tarda en torno a seis meses en formular y fabricar masivamente una nueva vacuna; en ocasiones una nueva o imprevista cepa se propaga durante ese período y consigue infectar a mucha gente antes de disponer de los millones de dosis vacunales necesarias (como sucedió en la epidemia de gripe Fujian (H3N2) en la temporada de gripe 2003-2004). También es posible infectarse justo antes de la vacunación y enfermar con la cepa supuestamente cubierta por la vacuna, ya que la vacuna tarda unas dos semanas en lograr su máxima efectividad.

La temporada 2006–2007 fue la primera en la que el CDC recomendó la vacunación anual de los niños menores de 5 años.

Las vacunas contra la gripe son seguras y rara vez se reportan efectos adversos. Los efectos secundarios más frecuentes son dolor, enrojecimiento y leve edema en el sitio de la inyección (20 %), dolor de cabeza, malestar y debilidad generalizada. Con menos frecuencia se han observado mareos e hipotensión. En 1-2 % de los casos hay fiebre y síntomas constitucionales. Puede causar también reacciones inmunitarias que se asemejan a una infección real por el virus, o a síntomas generales de infección (muchos síntomas catarrales o gripales son, en realidad, síntomas generales inespecíficos de infección), aunque de una manera leve y transitoria.

Los casos más graves incluyen reacciones alérgicas y broncoespasmo, por reacción frente a alguno de los componentes de la vacuna (residuos de las proteínas del huevo o de los antibióticos empleados para su elaboración); no obstante este tipo de reacciones son extremadamente infrecuentes.

Unos adecuados hábitos personales de higiene son eficaces también para la prevención de la infección. Las personas que han contraído la gripe son más infectivas durante el segundo y tercer día tras haberla contraído y su capacidad infectiva se prolonga durante unos diez días. Los niños son especialmente infectivos (más que los adultos) y pueden propagar partículas víricas desde antes incluso de la aparición de sus síntomas, y hasta dos semanas después.

Dado que la gripe se contagia a través de las gotas emitidas en aerosol con la tos, el estornudo e incluso con el habla, y a través del contacto con superficies contaminadas, es de especial importancia recomendar a la población que se cubra la cara cuando tosan o estornuden, así como el lavado frecuente de manos.

La desinfección de superficies está recomendada en las zonas en las que pueda depositarse el virus. El alcohol es un eficaz desinfectante del virus de la gripe y si se usa junto con sales cuaternarias de amonio se incrementa notablemente su eficacia. En los hospitales las sales cuaternarias de amonio y diversos compuestos halogenados, como el hipoclorito de sodio son habitualmente empleados para la desinfección de zonas sanitarias y equipamiento médico que han sido ocupados o usados por pacientes con síntomas de gripe.

En anteriores pandemias el cierre de colegios, iglesias y teatros ralentizó la propagación del virus, pero no parece haber tenido una influencia significativa en la disminución de la tasa de mortalidad.

Las investigaciones sobre el virus de la gripe se están centrando en estudios de virología molecular, acerca de cómo el virus desencadena los mecanismos patogenéticos de la enfermedad, en la respuesta inmunológica del huésped, en la genómica viral y en la manera en que el virus se propaga provocando oleadas epidémicas. Estos trabajos están ayudando a desarrollar medidas de lucha más eficaces contra el virus; por ejemplo, un mejor conocimiento de la respuesta inmunitaria del organismo ayuda al desarrollo de mejores vacunas, y un conocimiento detallado de cómo el virus penetra en las células diana mejora el diseño de los nuevos fármacos antivirales. Un importante programa básico de investigación es el Influenza Genome Sequencing Project (Proyecto de Secuenciación del Genoma del virus de la Gripe), que está creando una base de datos de secuencias genéticas del virus; esta base de datos ayudará a clarificar qué factores influyen en la mayor mortalidad o virulencia de una cepa determinada frente a otra, qué genes están involucrados en la mayor o menor inmunogenicidad y cómo el virus evoluciona en el tiempo.

La investigación de nuevas vacunas es especialmente importante, ya que las actuales son lentas y caras de producir y deben ser reformuladas cada año. La secuenciación del genoma del virus de la gripe y el uso de la tecnología de recombinación genética pueden acelerar la aparición de la siguiente generación de cepas vacunales, permitiendo a los científicos colocar nuevos antígenos en cepas de vacunas previamente desarrolladas. Nuevas tecnologías están siendo también desarrolladas para permitir el crecimiento de virus directamente en cultivos celulares, mejorando las vacunas y disminuyendo los costes. La búsqueda de una vacuna universal para el tipo A, dirigida contra la superficie externa de la proteína transmembrana M2 (M2e), está siendo llevada a cabo en la Universidad de Gante por Walter Fiers, Xavier Saelens y su equipo y ha concluido con éxito la Fase I para ensayos clínicos.

El virus de la gripe puede infectar a numerosas especies animales y producirse una transferencia de cepas virales entre ellas. Las aves son el principal reservorio animal del virus. Se han identificado hasta dieciséis variedades de hemaglutinina y nueve de neuraminidasa. Todos los subtipos conocidos (HxNy) pueden aislarse en pájaros, pero muchos subtipos son endémicos de otras especies como humanos, perros, caballos y cerdos; en poblaciones de camellos, hurones, gatos, focas, visones y ballenas también se ha demostrado la existencia de infección o exposición al virus. Algunas variedades del virus se nombran en función de la especie a la que la cepa está adaptada o de la que es endémica. Las principales cepas nombradas usando esta convención son la gripe aviar, la gripe humana, la gripe del cerdo, la gripe del caballo y la gripe del perro. Con el nombre de gripe del gato se hace referencia normalmente a un tipo de rinotraqueitis vírica propia de los felinos o a la infección por calicivirus, pero exactamente a la infección por alguna de las variantes del influenzavirus. En los cerdos, los caballos y los perros los síntomas suelen ser similares a los humanos, con tos, fiebre y pérdida del apetito. La existencia de pandemias en animales no está tan bien estudiada como en humanos, pero está registrada una epidemia de gripe en una población de focas de la costa de New England, causando aproximadamente unas 500 muertes en 1979–1980. Por otra parte, las epidemias en cerdos son habituales y no suelen provocar gran mortandad.

Los síntomas de la gripe en las aves son variables y pueden ser inespecíficos. Los síntomas de una infección poco patógena pueden ser tan leves como algunas plumas encrespadas, una pequeña reducción en el número de los huevos de cada puesta o una discreta pérdida de peso con algunos leves síntomas respiratorios. Estos síntomas leves e inespecíficos dificultan el diagnóstico de campo, siendo necesaria la realización de test de laboratorio para el diagnóstico de aves infectadas. Algunas cepas como la asiática H9N2 son extremadamente virulentas con las aves de corral y pueden causar síntomas más graves y mayor mortalidad. En sus variantes más patógenas, la gripe en los pollos y los pavos provoca la aparición repentina de un cuadro grave con una mortalidad cercana al 100 % en cuarenta y ocho horas. Dado que el virus se propaga con mucha rapidez en condiciones de hacinamiento propias de las granjas intensivas de estas aves, estas epidemias pueden causar grandes pérdidas económicas.

Una cepa muy patógena de H5N1 adaptada a las aves (llamada HPAI A(H5N1), de las siglas en inglés "Highly Pathogenic Avian influenza virus tipo A, subtipo H5N1": Virus de la gripe aviar tipo A altamente patogénico) provoca la gripe aviar, endémica de muchas poblaciones de pájaros, especialmente en el sudeste asiático. Esta cepa asiática de HPAI A(H5N1) se está extendiendo por todo el mundo. Es epizoótica (epidémica en animales) y panzoótica (puede causar epidemias en múltiples especies animales y en amplias áreas geográficas), matando decenas de millones de aves y provocando el sacrificio de cientos de millones más para controlar la extensión de la enfermedad. La mayoría de las referencias en los medios de comunicación sobre la gripe aviar y la variante H5N1 son sobre esta cepa específica.

Por el momento HPAI A(H5N1) provoca una enfermedad en las aves, y no existen evidencias de transmisión de humano a humano. En casi todos los casos de infección en humanos se había producido un estrecho contacto físico con aves infectadas. Se desconoce si en el futuro esta cepa podrá mutar hacia una estirpe capaz de transmitirse entre humanos. Debido a su gran virulencia y letalidad, a su presencia endémica y su extensa distribución en el reservorio biológico aviar, el virus H5N1 disparó las alarmas de pandemia en la temporada de gripe 2006–07, y se está invirtiendo una gran cantidad de recursos económicos en prepararse para una potencial pandemia de gripe a nivel mundial.

La influenza es una enfermedad que produce altos costos para el individuo y las naciones debido a la pérdida de productividad y al tratamiento médico asociado a la enfermedad, así como costos indirectos de las medidas preventivas.

El impacto económico de las pandemias del pasado no se han estudiado con intensidad, a tal punto que algunos autores han sugerido que la influenza española más bien tuvo un efecto positivo a largo plazo en el crecimiento económico "per cápita", a pesar de la gran reducción en la población trabajadora y los efectos represivos a corto plazo.

Otros estudios han intentado predecir los costos asociados a pandemias tan graves como la de 1918, las repercusiones sobre los países donde el 30 % de los trabajadores se enfermen y 2,5 % de ellos mueran. Se estima que una tasa de morbilidad del 30 % para una enfermedad que dure 3 semanas debe disminuir el Producto Nacional Bruto en un 5 %. Los costos adicionales provenientes del tratamiento médico de 18-45 millones de personas sumarían unos 700 mil millones de dólares.

Los costos de la prevención de la enfermedad son igualmente elevados. Diferentes gobiernos alrededor del mundo han gastado millones en la preparación y planificación de una potencial pandemia de gripe aviar, con costos asociados a la compra de vacunas, así como en el desarrollo de planificación de desastres y estrategias para la mejora del control de fronteras. Por ejemplo, el 18 de enero de 2006, durante una conferencia internacional en China, varias naciones internacionales prometieron recaudar 2 mil millones de dólares para combatir la gripe aviar.

Para 2006, se habían gastado más de diez mil millones de dólares y se habían sacrificado más de 200 millones de aves con el fin de tratar de contener el virus aviar H5N1. Sin embargo, todos estos esfuerzos han sido ineficaces en el control de la dispersión del virus, de modo que se han intentado distintos abordajes. Por ejemplo, en Vietnam, el gobierno adoptó en 2005 una campaña masiva combinando vacunación, desinfección, desecho de aves y campañas informativas en las ciudades con producción comercial de aves. Como resultado de estas medidas, el costo de criar aves ha aumentado en ese país, mientras que el precio para el consumidor ha disminuido porque la demanda ha caído por debajo de lo surtido. Ello ha causado pérdidas a los criaderos de aves, quienes no pueden costear las medidas demandadas por el gobierno. La crianza multinacional de aves se ha vuelto un mercado improductivo a medida que la gripe aviar se vuelve endémica en las aves salvajes alrededor del mundo. La ruina financiera de los criadores de aves más pobres es tan severa que les amenaza con inanición, a tal punto que algunos han cometido suicidio y otros han dejado de cooperar con las medidas gubernamentales en el control del virus, aumentando aún más el riesgo humano de contagio y la probabilidad de una mutación pandémica.

La Cámara de Comercio de México D.F aseguró que las pérdidas fueron de aproximadamente $57 millones diarios durante la primera semana.

La gripe A (H1N1), fue una pandemia causada por una variante del "Influenzavirus A" (subtipo H1N1), que surgió en el año 2009 descubierta por los doctores Torres y Puccio Ponte en la Universidad de Miami. Las denominaciones "gripe A" y gripe "A (H1N1)", usadas por numerosos medios de comunicación, pueden dar lugar a confusiones, ya que ha habido otras pandemias de gripe A (H1N1) en épocas pasadas. Por esta razón, este virus fue conocido oficialmente por la Organización Mundial de la Salud como Virus H1N1/09 Pandémico, haciendo referencia al año de su aparición. Esta nueva cepa viral es conocida como "gripe porcina" (nombre dado inicialmente), "gripe norteamericana" (propuesto por la Organización Mundial de la Salud Animal) y "nueva gripe" (propuesto por la Unión Europea), nombres que han sido objeto de diversas controversias. El 30 de abril de 2009 la Organización Mundial de la Salud (OMS) decidió denominarla gripe A (H1N1). Esta es una descripción del virus: la letra "A" designa la familia de los virus de la gripe humana y de la de algunos animales como cerdos y aves, y las letras "H" y "N" (Hemaglutininas y Neuraminidases) corresponden a las proteínas de la superficie del virus que lo caracterizan.

El origen de la infección es una variante de la cepa H1N1, con material genético proveniente de una cepa aviaria, dos cepas porcinas y una humana que sufrió una mutación y dio un salto entre especies (o heterocontagio) de los cerdos a los humanos, para después permitir el contagio de persona a persona.

El 11 de junio de 2009 la Organización Mundial de la Salud (OMS) la clasificó como de nivel de alerta seis; es decir, "pandemia en curso". Para poder clasificar una enfermedad a dicho nivel, debe verse involucrada la aparición de brotes comunitarios (ocasionados localmente sin la presencia de una persona infectada proveniente de la región del brote inicial). Sin embargo, ese nivel de alerta no define la gravedad de la enfermedad producida por el virus, sino su extensión geográfica.

El 10 de agosto de 2010 la OMS anunció el fin de la pandemia, 14 meses después y luego de haberle dado la vuelta al mundo. La pandemia tuvo una mortalidad baja, en contraste con su amplia distribución, dejando tras de sí unas 19.000 víctimas.


General

Historia

Microbiología

Patogénesis

Epidemiología

Prevención y tratamiento

Investigación



</doc>
<doc id="27977" url="https://es.wikipedia.org/wiki?curid=27977" title="Hiram I de Tiro">
Hiram I de Tiro

Hiram I, también transcrito como Jirán I, fue rey de la ciudad fenicia de Tiro entre los años 969 y 939 a.  C.
Sucedió a su padre Abibaal como rey de Tiro, y durante su reinado su ciudad creció hasta dejar de ser una población satélite de la vecina ciudad de Sidón, y convertirse en una de las principales ciudades fenicias. Bajo el gobierno de Hiram se sometió una revuelta en la primera colonia tiria, la ciudad de Útica del Norte de África, situada cerca del emplazamiento de la futura Cartago.

También conforme a lo que dice la biblia (libro segundo de Samuel, capítulo cinco) el rey Hiram también ayudo al rey David enviando gente que sabía construir con madera y piedra. Mediante ellos envió madera para que le hicieran a David un palacio en Jerusalén.

Según la Biblia ("Libro Primero de los Reyes", capítulo 5), Hiram envió mensajeros a Salomón para ofrecerle sus respetos después de que éste fuera coronado como sucesor de David, y tras convertirse en el más poderoso gobernante de la región, al ocupar el vacío dejado por Egipto y Asiria. A través de su alianza con Salomón, Hiram pudo acceder a los mercados egipcios, árabes y mesopotámicos. Los dos reyes aunaron esfuerzos por crear una nueva ruta comercial que comunicara los lejanos países de Saba y Ofir (Yemen y Somalia probablemente), a través del puerto de "Esyon-Gueber", donde hoy día se yergue la ciudad de Eilat.

Para construir el Templo de Jerusalén que proyectaba consagrar a Yaveh, Salomón necesitaba maderas finas, por lo que comerció con Hiram, intercambiando veinte mil cargas de trigo y veinte mil medidas de aceite por la apreciada madera de cedro del Líbano. Los obreros de Salomón y de Hiram trabajaron conjuntamente, extrayendo madera y cortando piedra en las canteras, para terminar el templo.

Hiram amplió los puertos tirios, a la vez que unió las dos islas donde se asentaba la ciudad, y erigiendo un palacio real y un templo dedicado a Melqart. La arqueología moderna no ha encontrado evidencias de estos trabajos.

Fue sucedido como rey de Tiro por Baal-Eser I (935-919 a. C.).


</doc>
<doc id="27978" url="https://es.wikipedia.org/wiki?curid=27978" title="Inflamación">
Inflamación

La inflamación (del latín "inflammatio": encender, hacer fuego) es la forma de manifestarse de muchas enfermedades. Se trata de una respuesta inespecífica frente a las agresiones del medio, y está generada por los agentes inflamatorios. La respuesta inflamatoria ocurre solo en tejidos conectivos vascularizados y surge con el fin defensivo de aislar y destruir al agente dañino, así como reparar el tejido u órgano dañado. Se considera por tanto un mecanismo de inmunidad innata, estereotipado, en contraste con la reacción inmune adaptativa, específica para cada tipo de agente infeccioso.

El sistema inmunológico innato está formado por defensas contra las infecciones que pueden activarse inmediatamente una vez que el agente patógeno ataca. El sistema inmunitario innato se compone esencialmente de barreras que tienen como objetivo eliminar los virus, bacterias, parásitos y otras partículas extrañas del cuerpo o limitar su capacidad de diseminarse y moverse por todo el cuerpo. La inflamación es un ejemplo de una respuesta inmunitaria innata.

El sistema inmunitario adaptativo, también llamado inmunidad adquirida, utiliza antígenos específicos para montar estratégicamente una respuesta inmunitaria. A diferencia del sistema inmunológico innato, que ataca solo sobre la base de la identificación de las amenazas generales, la inmunidad adaptativa se activa por la exposición a los patógenos, y utiliza una memoria inmunológica para aprender acerca de la amenaza y mejorar la respuesta inmunológica en consecuencia. La respuesta inmune adaptativa es mucho más lenta para responder a las amenazas e infecciones que la respuesta inmune innata, que está preparada y lista para luchar en todo momento.

La inflamación se identifica en medicina con el sufijo "-itis". El mayor problema que surge de la inflamación es que la defensa se dirija tanto hacia agentes dañinos como a no dañinos, de manera que provoque lesión en tejidos u órganos sanos.


En las primeras civilizaciones existen testimonios de su conocimiento y su curación, los primeros escritos aparecieron en papiros egipcios que datan del 3000 a.de C.

En Grecia y Roma se conserva un libro, de los numerosos escritos por Aulo Cornelio Celso, enciclopedista, "De Medicinae" y en donde se identifican 4 signos cardinales de la inflamación. Posteriormente Virchow añadió el quinto signo.

Actualmente se pueden reconocer sus 5 signos cardinales, que son:

En 1793, el cirujano escocés Hunter destacó algo que en la actualidad es considerado obvio: "La inflamación no es una enfermedad, sino una respuesta inespecífica que produce un efecto saludable en el organismo en que tiene lugar".

El patólogo Julius Cohnheim fue el primer investigador que utilizó el microscopio para observar vasos sanguíneos inflamados en membranas finas y translúcidas, como el mesenterio y la lengua de la rana. Tras la observación de las alteraciones iniciales del flujo sanguíneo, el edema posterior al incremento de la permeabilidad vascular, la migración leucocitaria. En 1867 demostró que la emigración de los glóbulos blancos es el origen de la pus. La contribución de Cohnheim fue fundamental para entender todo el proceso inflamatorio.

El biólogo ruso Elias Metchnikoff descubrió el proceso de la fagocitosis al observar la ingestión de espinas de rosal por los amebocitos de las larvas de estrellas de mar, y de bacterias por leucocitos de mamífero (1882); la conclusión de este investigador fue que el objeto de la inflamación era el de hacer llegar las células con capacidad fagocitaria a la zona de lesión para que fagocitaran a los agentes infecciosos. No obstante, al poco tiempo quedó claro que tanto los factores celulares (fagocitos) como los factores séricos (anticuerpos) eran imprescindibles para la defensa frente a microorganismos, y como reconocimiento por ello Metchnikoff y Paul Ehrlich (quién desarrolló la teoría humoral) compartieron el premio Nobel de Medicína en 1908.

A estos nombres se debe añadir el de Sir Thomas Lewis quien, mediante experimentos sencillos sobre la respuesta inflamatoria de la piel, estableció el concepto de que diversas substancias químicas inducidas localmente por el estímulo de una lesión, como la histamina, son factores mediadores de las alteraciones vasculares de la inflamación. Este concepto fundamental constituye la base de los importantes descubrimientos de los mediadores químicos de la inflamación y de la posibilidad de utilizar fármacos antiinflamatorios.

Lewis llamó a los mediadores químicos de la inflamación "H1", y definió la triple respuesta ante la agresión que consistía en:

Dependiendo de las características temporales de la inflamación definimos dos tipos de respuesta, inflamación aguda e inflamación crónica.

La fase aguda de la inflamación es sinónimo de reacción inmune innata. En la inflamación aguda distinguimos tres puntos clave: cambios hemodinámicos, alteración de la permeabilidad vascular y modificaciones leucocitarias.

Después de un periodo inconstante y transitorio de vasoconstricción arteriolar, se produce vasodilatación e hiperemia activa (aumento de flujo sanguíneo en la zona de la lesión), que causa enrojecimiento y aumento de la temperatura. Después se produce un periodo de hiperemia pasiva en la que disminuye el flujo por un aumento de la permeabilidad microvascular con extravasación de líquido y aumento de la viscosidad sanguínea en los vasos de menor calibre, que es lo que se denomina estasis (parálisis total del flujo). A medida que evoluciona la estasis se produce la orientación periférica (marginación) de los leucocitos, que se adhieren al endotelio, atraviesan la pared vascular y se dirigen al intersticio.

Paso por paso (solo de manera didáctica, ya que estos eventos ocurren superponiéndose) se observa lo siguiente:


Asimismo, durante la fase de reparación que sigue a la inflamación aguda y durante la inflamación crónica se produce un fenómeno de proliferación de vasos sanguíneos denominado angiogénesis.

En condiciones normales el endotelio no permite la salida de proteínas y el intercambio se produce por pinocitosis. Durante la inflamación, se alteran las bases morfológicas del endotelio por acción de los mediadores químicos, produciéndose una alteración de las uniones celulares y las cargas negativas de la membrana basal: Majno y Palade vieron aperturas entre las células que no se encontraban rotas.
Generalmente, este efecto se produce en las vénulas, pero si es muy intenso se alcanza a los capilares y se produce extravasación por rotura.

La salida de líquidos, proteínas y células a partir de la sangre se denomina exudación. Es importante distinguir los siguientes conceptos:

El aumento de la permeabilidad vascular se genera por varios mecanismos, que pueden producirse simultáneamente:

Es el mecanismo más común, desencadenado por diferentes mediadores, como la histamina, la bradiquinina, los leucotrienos y la sustancia P, entre otros. Estas sustancias provocan la contracción brusca, por fosforilacion oxidativa, de los filamentos de actina y miosina de las células endoteliales que se retraen, de forma que los espacios interendoteliales aumentan. Después el citoesqueleto se reorganiza para mantener la contracción durante más tiempo. Las sustancias inflamatorias deben disolver la membrana basal de estas aperturas.

La necrosis de las células endoteliales provoca su separación de la pared del vaso, creando de esta forma una apertura en el mismo. Puede producirse en heridas severas, como quemaduras, o por la acción tóxica de microbios que afectan directamente el endotelio. Los PMN que se adhieren a las células endoteliales también pueden dañarlas. En este caso, la pérdida de líquido continúa hasta que se forma un trombo o se repara el daño.

El transporte de fluidos y proteínas a través de las propias células endoteliales (y no entre ellas) puede realizarse mediante canales que se forman a partir de vacuolas y vesículas no recubiertas interconectadas (denominado orgánulo vesiculovacuolar). Parece que VEGF estimula el número y el tamaño de estos canales.

En condiciones normales, el sistema linfático filtra y controla las pequeñas cantidades de líquido extravascular que se ha perdido en los capilares. Durante la inflamación, la cantidad de líquido extracelular aumenta, y el sistema linfático participa en la eliminación del edema. Asimismo, en este caso una mayor cantidad de leucocitos, restos celulares y microbios pasa a la linfa. Como ocurre con los vasos sanguíneos, los linfáticos también proliferan en los procesos inflamatorios, para atender al incremento de la demanda. Puede ocurrir que los vasos linfáticos se inflamen de forma secundaria (linfangitis), o que se inflamen los ganglios (linfadenitis), a causa de la hiperplasia de los folículos linfoides y al mayor número de linfocitos y macrófagos.

Los leucocitos fagocitan a los patógenos, destruyen a las bacterias y a los microorganismos, y degradan el tejido necrótico, pero también pueden prolongar la lesión tisular al liberar enzimas, mediadores químicos y especies reactivas del oxígeno (ERO, o también ROS, por sus siglas en inglés; también denominados radicales libres de oxígeno, RLO). Los dos grupos de leucocitos más importantes en un proceso de inflamación son los leucocitos polimorfonucleares neutrófilos (PMN) y los macrófagos.

El tejido conjuntivo contiene macrófagos y mastocitos, que son células centinelas capaces de reconocer la presencia de microbios, células muertas o cuerpos extraños. Los macrófagos son los elementos principales en el inicio del proceso de inflamación, ya que poseen receptores específicos capaces de reconocer microbios y células muertas. Cuando reconocen estos elementos, los macrófagos producen las citoquinas IL-1 y TNF-α, que desecadenan la inflamación propiamente dicha actuando sobre las células endoteliales de los vasos sanguíneos cercanos (sobre todo las vénulas post-capilares), para permitir la migración transendotelial de los leucocitos.

Los mastocitos reaccionan al estrés físico que se detecta en los tejidos (calor, frío, presión) y producen los mediadores serotonina e histamina, que son potentes agentes vasoactivos que actúan sobre la contracción y la permeabilidad de los vasos, tanto arteriales como venosos.

Como consecuencia de la activación de macrófagos y mastocitos, se produce la liberación de los mediadores químicos de la inflamación. Estos mediadores inducen vasodilatación en la zona afectada, lo que provoca la salida de líquido de la sangre hacia los tejidos, generando un edema. Por esta razón, la viscosidad de la sangre aumenta, debido al aumento de concentración de los glóbulos rojos, lo que provoca un descenso en el flujo sanguíneo (estasis). En estas condiciones hemodinámicas, los leucocitos se redistribuyen en posición periférica, un fenómeno denominado "marginación". A continuación, los leucocitos "ruedan" sobre la superficie del endotelio, estableciendo contactos transitorios con las células endoteliales, soltándose y volviéndose a unir. Finalmente, los leucocitos se "adhieren" firmemente al endotelio, antes de iniciar la "migración" a través de los capilares (ver el apartado "Diapédesis" de los neutrófilos para un detalle molecular completo).

Los leucocitos que han atravesado los capilares se dirigen hacia la zona afectada por un proceso de quimiotaxis. Una vez allí, fagocitan los microbios y los destruyen, generando la producción de pus. El pus será eliminado hacia el exterior si la lesión está en contacto con el exterior, o generará un absceso si la zona donde se ha formado el pus está en el interior de un órgano.

Una vez eliminado el pus (bien de manera natural o por intervención quirúrgica en caso de absceso), los macrófagos y los linfocitos proceden a la reparación del tejido dañado por la inflamación aguda. El daño tisular está producido generalmente por los PMN, que son muy numerosos y liberan enzimas hidrolíticas y radicales libres que dañan los tejidos. La reparación se produce gracias a los macrófagos, que estimulan a los fibroblastos a sintetizar colágeno y a las células endoteliales a generar nuevos vasos, mediante la secreción de factores de crecimiento. Sin embargo, la reparación es siempre incompleta, ya que no se recupera la estructura original: las glándulas y los pelos de la zona no se regeneran.

La naturaleza de los leucocitos infiltrados varia según el momento de la respuesta inflamatoria y el tipo de estímulo. En la mayor parte de los casos de inflamación aguda, los neutrófilos (PMN) predominan durante las primeras 6-24h, y luego son reemplazados por monocitos en 24-48h. La rápida aparición de los PMN se debe a que son más abundantes en la sangre, responden más rápido a las quimioquinas y se adhieren más fuertemente a las moléculas de adhesión que aparecen en las células endoteliales activadas, como las selectinas E y P. Sin embargo, después de entrar en los tejidos, los PMN tienen una vida media corta: sufren apoptosis y desaparecen después de 24-48h. Los monocitos responden más despacio, pero no solo sobreviven en los tejidos, sino que además proliferan y dan lugar a los macrófagos, de manera que se convierten en la población dominante en las reacciones inflamatorias crónicas. Sin embargo, en algunos casos las poblaciones de leucocitos pueden variar: en infecciones por "Pseudomonas", los neutrófilos se reclutan de forma continua durante varios días, y en infecciones virales, los linfocitos son los primeros en llegar, por ejemplo.

Estos mediadores son pequeñas moléculas que consisten en lípidos (prostaglandinas, leucotrienos y tromboxano), aminoácidos modificados (histamina, serotonina) y pequeñas proteínas (citoquinas, factores de crecimiento, interleuquinas...) que representan información específica destinada a las células capaces de utilizar esta información gracias a la presencia de receptores específicos en su membrana plasmática. Los mediadores de la inflamación son de origen plasmático (sintetizados por el hígado) o celular.

El ácido araquidónico (AA) es un derivado del ácido graso esencial ácido linoleico, con muchos enlaces dobles, que se encuentra normalmente esterificado en forma de fosfolípido en las membranas celulares. El AA se libera por acción de las fosfolipasas celulares, a partir de cualquier célula activada (plaquetas), estresada o a punto de morir por necrosis. Una vez liberado, el AA puede metabolizarse por dos vías:
Los derivados del ácido araquidónico (también denominados eicosanoides) sirven como señales intra o extracelulares en una gran variedad de procesos biológicos, entre ellos la inflamación y la hemostasis. Sus efectos principales son:

Histamina y serotonina son las dos principales aminas vasoactivas, llamadas así por su importante acción sobre los vasos. Se almacenan ya preformados en gránulos, dentro de las células que los producen, por lo que son mediadores precoces de la inflamación. El principal productor de histamina son los mastocitos, aunque también se produce por los basófilos y las plaquetas. En el caso de los mastocitos, la histamina se libera cuando estas células producen desgranulación, en respuesta a diferentes tipos de estímulos:
La histamina dilata las arteriolas y aumenta la permeabilidad de las vénulas. Es el principal mediador del aumento transitorio inmediato de la permeabilidad vascular, produciendo espacios interendoteliales en las vénulas que favorecen la salida del exudado plasmático. Este efecto se realiza a través de receptores H1 presentes en las células endoteliales.

La serotonina es otro mediador preformado que produce efectos similares. Está presente en las plaquetas y en ciertas células neuroendocrinas, por ejemplo en el tracto gastrointestinal. La liberación de serotonina (e histamina) se activa cuando las plaquetas se agregan en contacto con el colágeno, la trombina, ADP y complejos antígeno-anticuerpo (ver Hemostasis para un mayor detalle sobre este proceso).

Las citoquinas son pequeñas proteínas (entre 5 y 20 kD) que permiten el intercambio de información entre las diferentes células durante el proceso de inflamación, la hematopoyesis y las respuestas inmunes. Los factores de crecimiento que utilizan las células epiteliales para estimular su renovación son asimismo citoquinas.

En general, las citoquinas se pueden considerar como hormonas con un radio de acción limitado, a excepción de IL-1 y TNF-α, que funcionan como verdaderas hormonas, transmitiendo información a través de todo el organismo.

Las citoquinas liberadas por los macrófagos durante la inflamación van a afectar a las células endoteliales, los PMN (durante la fase aguda) y después los fibroblastos y de nuevo las células endoteliales durante la fase de reparación. La información emitida por una citoquina solo será recibida por aquellas células que presenten receptores específicos para esa citoquina. Los mensajes de las citoquinas son múltiples; los principales son:
Algunos mensajes muy importantes, como la estimulación de los linfocitos T, son emitidos por muchas citoquinas. Esta redundancia asegura la transmisión de la información.

El factor activador de plaquetas (PAF) es otro mediador derivado de fosfolípidos. Se encuentra en plaquetas, mastocitos, basófilos, PMN, monocitos, macrófagos y células endoteliales. Sus acciones principales son:

El óxido nítrico (NO) es un gas producido en algunas neuronas del cerebro, macrófagos y células endoteliales. Actúa de forma paracrina (acción y local) sobre las células diana, a través de la inducción de GMPc, que inicia una serie de sucesos intracelulares que provocan la relajación del músculo liso (vasodilatación). La vida media in vivo del NO es muy corta, por lo que solo actúa sobre las células muy próximas al lugar de producción.

El NO se sintetiza a partir de L-arginina por la enzima NO-sintasa (NOS). Hay tres tipos de NOS: endotelial (eNOS), neuronal (nNOS) e inducible (iNOS). Las dos primeras son constitutivas, se expresan a niveles bajos y pueden activarse rápidamente aumentando los niveles de calcio intracelular. Sin embargo, la iNOS se activa solamente cuando los macrófagos y otras células son activados por citoquinas (como IFN-γ) o productos microbianos.

Los radicales libres de oxígeno son un tipo de especies reactivas del oxígeno (ERO, o también ROS, por sus siglas en inglés). Estos radicales pueden liberarse al medio extracelular por los leucocitos después de que hayan sido activados por la presencia de microbios, quimioquinas, complejos inmunes, o después de la fagocitosis. Su producción depende de la activación del sistema NADPH oxidasa. Las principales especies producidas intracelularmente son el anión superóxido (O2~), el peróxido de hidrógeno HO y el radical hidroxilo (*OH). El anión superóxido puede combinarse con el óxido nítrico para formar especies reactivas del nitrógeno. Estas sustancias atacan todos los materiales biológicos (ADN, proteínas, lípidos...), bien arrancando electrones, arrancando átomos de hidrógeno o adicionándose sobre los enlaces dobles: reaccionan como potentes oxidantes. La consecuencia es, por tanto, la alteración y la posterior pérdida de función de las moléculas afectadas.

La liberación extracelular de estas potentes sustancias a bajas concentraciones activan quimiocinas, citoquinas y moléculas de adhesión leucocitaria endotelial, amplificando la respuesta inflamatoria. Están implicados en las siguientes respuestas inflamatorias:
El plasma, los fluidos tisulares y las células poseen mecanismos antioxidantes para protegerse de los radicales libres de oxígeno. Entre estos se encuentran:
Además existen compuestos de origen alimentario con capacidad antioxidante que también intervienen en la neutralización de ERO:
Por ello, el efecto negativo de los ERO se observa si se produce un desequilibrio debido a una producción exagerada de estas sustancias o por una disminución de los sistemas de defensa, enzimáticos y no enzimáticos.

Los neutrófilos y los monocitos contienen gránulos lisosomiales necesarios para la digestión de los materiales fagocitados. Si estos compuestos se vierten al exterior, pueden amplificar la respuesta inflamatoria, ya que tienen un efecto destructor sobre los tejidos (elastasas, colagenasas, proteasas...). Para contrarrestar su efecto, existen antiproteasas en el suero, fundamentalmente la α1-antitripsina, que es el principal inhibidor de la elastasa. Otra antiproteasa importante es la α2-macroglobulina.

Los neuropéptidos son sustancias segregadas por los nervios sensoriales y varios tipos de leucocitos, y juegan un papel en la propagación de la respuesta inflamatoria. Entre ellos se encuentran la sustancia P y la neurocinina A, pertenecientes a la familia de los taquininos y producidos en el SNC y periférico. Los pulmones y el tracto gastrointestinal son ricos en fibras que contienen sustancia P. Esta tiene muchas funciones: transmisión de las señales dolorosas, regulación de la presión sanguínea, estimulación de la secreción de las células endocrinas y aumento de la permeabilidad vascular.

Una gran variedad de fenómenos en la respuesta inflamatoria están mediados por proteínas plasmáticas que pertenecen a tres sistemas interrelacionados:

De estos tres sistemas, probablemente los mediadores de la inflamación más importantes in vivo son bradiquinina, C3a, C5a y trombina.

Las citoquinas IL-1 y TNF-α producidas por los macrófagos funcionan como "hormonas" de la inflamación, y actúan sobre el conjunto del organismo para movilizar todos los recursos disponibles para luchar contra el agente infeccioso. En particular, su acción sobre el centro de la fiebre permite elevar la temperatura, lo que compromete la supervivencia bacteriana. Su acción sobre el hígado permite aumentar la síntesis de las proteínas de fase aguda, que son también antibacterianas (sistema del complemento, proteína C reactiva).

Puesto que este potente proceso de defensa puede producir daños importantes en los tejidos del huésped, es importante mantenerlo bajo un estricto control. En parte, la inflamación desaparece simplemente porque los mediadores se producen en estallidos rápidos, solo mientras persiste el estímulo, tienen vidas medias cortas, y son degradados tras su liberación. Los neutrófilos también tienen una vida media corta y mueren por apoptosis unas pocas horas después de dejar la sangre. Además, durante el desarrollo del proceso inflamatorio se disparan unas serie de señales de STOP que sirven para terminar la reacción de forma activa:

Cuando la inflamación se mantiene durante un tiempo prolongado (semanas o meses), se habla de inflamación crónica, en la que coexisten el daño tisular y los intentos de reparación, en diversas combinaciones. Puede producirse por mantenimiento de la inflamación aguda (si no se resuelve la causa), o bien empezar de manera progresiva y poco evidente, sin las manifestaciones de la inflamación aguda. Este segundo caso es el responsable del daño tisular de algunas de las enfermedades humanas más invalidantes, como la artritis reumatoide, la aterosclerosis, la tuberculosis o la fibrosis pulmonar. Además, es importante en el desarrollo del cáncer y en enfermedades que anteriormente se consideraban exclusivamente degenerativas, como el Alzheimer.

En caso de no resolución se drenan también las bacterias y se extiende la infección por vía linfática: linfangitis (inflamación de los vasos linfáticos) y linfadenitis (inflamación de los ganglios linfáticos).

Entre las causas de la inflamación crónica se pueden distinguir:

En el caso de microbios difíciles de erradicar, como micobacterias, ciertos hongos, virus y parásitos. Pueden dar lugar a la formación de granulomas.

En algunas enfermedades en las que la respuesta inmunitaria se produce de manera exagerada o inapropiada en relación al agente desencadenante, la inflamación crónica juega un papel importante en el aspecto patológico de las mismas. En estos casos, como la respuesta inmune está sobredimensionada, no produce beneficio, sino daño. Por ejemplo:
En este tipo de enfermedades, se suelen producir brotes repetidos de inflamación, por lo que se pueden observar características mixtas de la inflamación aguda y crónica.

Dichos agentes pueden ser:

La alteración de la permeabilidad intestinal está implicada en el desarrollo de un creciente número de enfermedades, entre ellas ciertas enfermedades inflamatorias, en las que el aumento de la permeabilidad intestinal permite el paso de antígenos desde el intestino a la sangre, produciendo una respuesta inmune que puede dirigirse contra cualquier órgano o tejido.

El epitelio intestinal es la superficie mucosa más grande del organismo e interactúa con el entorno. Cuando la mucosa intestinal está sana, con la permeabilidad intacta, constituye la principal barrera para evitar el paso de macromoléculas (nutrientes incompletamente digeridos, toxinas y ciertas bacterias intestinales). Cuando la permeabilidad intestinal está dañada (aumentada), la barrera intestinal pierde su función protectora y pasan al torrente sanguíneo moléculas que no deberían pasar, provocando la aparición de reacciones inmunitarias. En la mayoría de los casos, el aumento de la permeabilidad intestinal aparece antes que la enfermedad y provoca una anormalidad en la exposición al antígeno que desencadena el proceso inflamatorio. Esto implica que la respuesta inflamatoria puede ser en teoría detenida y posiblemente invertida, si se elimina el desencadenante o desencadenantes ambientales.

Los dos factores más potentes que provocan aumento de la permeabilidad intestinal son ciertas bacterias intestinales y la gliadina (principal fracción tóxica del gluten), independientemente de la predisposición genética, es decir, tanto en celíacos como en no celíacos. Otras posibles causas son la prematuridad, la exposición a la radiación y la quimioterapia.

Mientras que la inflamación aguda se caracteriza por la aparición de cambios vasculares, edema e infiltración de neutrófilos, la inflamación crónica presenta las siguientes características distintivas:

Además de los infiltrados celulares, en la inflamación crónica es muy importante el crecimiento de vasos sanguíneos (angiogénesis) y linfáticos, estimulado por factores de crecimiento como VEGF, producidos por macrófagos y células endoteliales.

Los macrófagos son el tipo celular dominante en la inflamación crónica. Son uno de los componentes del sistema fagocítico mononuclear, también denominado sistema retículo-endotelial, que está formado por células originadas en la médula ósea. Los macrófagos son células residentes en los tejidos, que se originan a partir de los monocitos del plasma. Sin embargo, mientras que los monocitos tienen una vida media corta (1 día), los macrófagos tisulares sobreviven durante meses o años. Según el tejido en el que se encuentran, los macrófagos tisulares reciben nombres diferentes: por ejemplo, los histiocitos del tejido conjuntivo, las células de Kupffer del hígado, las células de Langerhans de la epidermis, los osteoclastos del tejido óseo, la microglía del SNC o los macrófagos alveolares del pulmón. Los macrófagos tisulares son células centinela, conjuntamente con los mastocitos, ya que presentan receptores específicos capaces de detectar agentes infecciosos, como los receptores de tipo Toll. La unión de estos receptores a sus ligandos produce la activación de los macrófagos, proceso que puede inducirse además por la presencia de citoquinas como el interferón-γ (IFN-γ), una molécula segregada por los linfocitos T activados y por las células NK.

Los productos de los macrófagos activados eliminan microbios e inician el proceso de reparación tisular, y son los responsables de la mayor parte de los daños tisulares en la inflamación crónica. Entre estos productos, podemos destacar las especies reactivas del oxígeno (ERO) y del nitrógeno, así como las enzimas lisosomales, citoquinas, factores de crecimiento y otros mediadores de la inflamación. Algunos de estos productos, como los radicales libres, son tóxicos y destruyen tanto los microbios como los tejidos; otros atraen otros tipos celulares o inducen la producción de colágeno por parte de los fibroblastos o la angiogénesis. De hecho, podrían existir dos poblaciones diferentes de macrófagos activados, en función del tipo de activación que hayan sufrido:

La artillería destructiva a disposición de los macrófagos les convierte en unos eficaces combatientes en la lucha contra la invasión por agentes patógenos, pero se convierte en un arma temible de doble filo cuando se dirige hacia los propios tejidos. Por ello, la destrucción de tejidos es un elemento característico de la inflamación crónica, ya que a diferencia de la inflamación aguda, en la que los macrófagos desaparecen cuando se elimina la causa (mueren o entran en las vías linfáticas), en la inflamación crónica los macrófagos se acumulan, aumentando los daños colaterales.

Los linfocitos son células que se movilizan en la respuesta específica del sistema inmune, activándose con el objetivo de producir anticuerpos y células capaces de identificar y destruir el microbio patógeno. Los macrófagos segregan citoquinas (sobre todo TNF e IL-1) y quimioquinas capaces de reclutar leucocitos a partir de la sangre y movilizarlos hacia la zona afectada. Las interacciones entre linfocitos y macrófagos son bidireccionales, ya que los macrófagos reclutan y activan linfocitos, y estos a su vez segregan citoquinas (sobre todo IFN-γ) con una potente capacidad de activar macrófagos. De manera que una vez que los linfocitos entran en acción, la inflamación tiende a agravarse, convirtiéndose en crónica y severa.

Las células plasmáticas se diferencian a partir de los linfocitos B activados. Su función consiste en la producción de grandes cantidades de anticuerpos dirigidos contra el microbio patógeno, o en ocasiones contra antígenos endógenos (en las enfermedades autoinmunes). En algunos pacientes con inflamación crónica (como la artritis reumatoide), las células plasmáticas, linfocitos y células presentadoras de antígenos se acumulan en nódulos similares a los ganglios linfáticos, que contienen incluso centros germinales bien definidos. Estos nódulos se denominan "órganos linfoides terciarios".

Los eosinófilos son abundantes en reacciones inflamatorias mediadas por IgE y en infecciones por parásitos. Estos leucocitos tienen gránulos que contienen la proteína básica principal, una proteína catiónica muy básica que es tóxica tanto para los parásitos como para los tejidos. Tienen por ello un papel importante en la destrucción de tejidos en reacciones inmunes, como las alergias.

Los mastocitos, como los macrófagos, son células centinelas ampliamente distribuidas por los tejidos, que reaccionan al estrés físico (calor, frío, presión), y participan tanto en la inflamación aguda como en la crónica. En sus membranas tienen receptores para IgE, que en reacciones de hipersensibilidad inmediata, estimulan la degranulación, liberando mediadores como y prostaglandinas. Este tipo de reacción ocurre en las reacciones alérgicas, pudiendo llegar a producir un choque anafiláctico. En la inflamación crónica, como presentan una gran variedad de mediadores, pueden promover o limitar la inflamación, en función de las circunstancias.

Aunque los neutrófilos (PMN) son característicos de la inflamación aguda, en muchos casos de inflamación crónica puede detectarse la presencia de PMN durante meses, bien debido a la persistencia de la infección o de mediadores producidos por los linfocitos. Esto ocurre por ejemplo en la osteomielitis (infección bacteriana crónica del hueso) o en el daño crónico de los pulmones inducido por el humo del tabaco y otros irritantes.

Es un patrón característico de inflamación crónica que solo se encuentra en algunos casos bien definidos de inflamación crónica. Un granuloma es un intento celular de aislar un cuerpo extraño que no puede ser fagocitado. Normalmente se produce una fuerte activación de linfocitos T, que induce a su vez la activación intensa de los macrófagos. Como resultado de esta activación, se producen los granulomas, que son focos de inflamación crónica, en los que el agente patógeno está en el centro, rodeado por macrófagos transformados en células pseudo-epiteliales, rodeados por leucocitos mononucleares, sobre todo linfocitos y en ocasiones células plasmáticas. El prototipo de enfermedad granulomatosa es la tuberculosis, pero los granulomas pueden identificarse en otras enfermedades, como la sífilis, vasculitis, sarcoidosis, lepra o la enfermedad de Crohn. Se pueden detectar dos tipos fundamentales de granulomas:

El granuloma puede ir asociado a:

Cuando existe mucha fibrosis se diferencia perfectamente el granuloma y se denomina sarcoidosis: enfermedad que afecta principalmente al pulmón, ganglios linfáticos, piel, conjuntiva, riñón, ... Otras veces se puede formar un espacio con gas; también pueden aparecer cristales de ácido úrico, que se depositan formando el granuloma (gota). Y en la tuberculosis el granuloma se caracteriza por necrosis caseosa central sin inclusiones y sin fibrosis, lo que lo diferencia de la sarcoidosis. Sin embargo, hay tantas presentaciones atípicas de granulomas que siempre es necesario identificar el agente patógeno por otros métodos: tinciones específicas, cultivos celulares, técnicas moleculares (como la técnica de Reacción en cadena de la polimerasa o PCR) o estudios serológicos.



</doc>
<doc id="27979" url="https://es.wikipedia.org/wiki?curid=27979" title="Marqués">
Marqués

marqués es un título nobiliario mediante el cual monarcas europeos han concedido un honor o dignidad a ciertas personas y linajes a lo largo de la historia. Su posición en la jerarquía nobiliaria europea es superior a la de conde e inmediatamente inferior a la de duque. Su forma femenina es marquesa y su señorío se denomina marquesado.

Sus orígenes se remontan a los señores de frontera del reino, llamados inicialmente marqueses, ya que tenían a su cargo la defensa de una frontera y administración de una marca dentro del Imperio carolingio. Estas marcas eran territorios fronterizos, como la Marca Hispánica, (frontera con los territorios musulmanes).

Los títulos nobiliarios de España son reconocidos por el rey y regulados por el Estado; su uso indebido es perseguido por la ley y en ningún caso son susceptibles de ser comprados ni vendidos y es el título que con más frecuencia se ha otorgado. La corona española ha otorgado el título a personas que no han gozado de nobleza, como premio a sus grandes méritos o por alguna venta cuando escaseaban las arcas del monarca, lo que se dio con mayor notoriedad en los siglos XVII y XVIII. 

En España, el título de marqués no se consolidaría hasta el siglo XV, siendo los marquesados más antiguos los de Villena, Santillana, Aguilar de Campoo y Astorga. Actualmente existen en España 1.372 títulos de marqués, de lo s cuales 142 ostentan además la dignidad de Grande de España.

Los marquesados, como el resto de los títulos nobiliarios, son hereditarios en la persona del hijo o hija primogénitos del último titular. El uso de tales títulos se hace extensivo a los consortes legítimos de quien ostenta la dignidad y a los cónyuges viudos mientras no contraigan nuevas nupcias. El tratamiento que corresponde a los marqueses Grandes de España es el de Excelencia y para los marqueses que no son Grandes de España, el de Ilustrísimo.

En Alemania, Bohemia y Hungría el equivalente a los marqueses son los margraves, y los territorios que ellos controlaron fueron los margraviatos. Por eso los marqueses alemanes suelen denominarse indistintamente como marqueses o margraves y gozaron de reconocimiento como príncipes del Imperio.

Con el paso del tiempo, el territorio sobre el que los marqueses ejercían su jurisdicción empezó a ser llamado marquesado, como es el caso del Marquesado de Brandeburgo (en el cual comenzó la Dinastía Hohenzollern que un día llegaría a convertirse en real de Prusia e imperial alemana) o el también importante Marquesado de Baden.





</doc>
<doc id="27980" url="https://es.wikipedia.org/wiki?curid=27980" title="Péplum">
Péplum

Péplum es un género fílmico que comúnmente puede conceptualizarse como cine histórico de aventuras. Las películas están ambientadas en la Antigüedad, fundamentalmente greco-romana. Popularmente se conoce como cintas de "espadas y sandalias".

El término fue acuñado por el crítico francés Jacques Siclier en el número de mayo de 1962 de la revista "Cahiers du Cinéma", en un artículo titulado "L'âge du péplum", usando metonímicamente el nombre de una prenda de vestuario muy frecuente en tales películas, el llamado "péplum" (del griego "πεπλον" -peplo-), especie de túnica sin mangas abrochada al hombro.

Las temáticas antiguas no eran novedad en el cine, como por ejemplo "Cabiria" o "Intolerancia". Sin embargo, el género "péplum" propiamente dicho aparece hacia 1958 con la película "Hércules". En esta, el papel de Hércules recayó en Steve Reeves, un ex Míster Universo que se transformó en uno de los iconos del género.

El éxito del filme "Hércules" y de su segunda parte llamada "Hércules encadenado o Hércules y la reina de Lidia" (1959) llevó a la cinematografía italiana a montar una verdadera industria de péplum, que reciclará una y otra vez los mismos escenarios y vestuarios para filmar una seguidilla de películas de entretenimiento masivo.
Del mismo modo, marcó una serie de pautas que el resto de producciones seguiría de una manera más o menos literal, llegando en ocasiones a ser una sucesión de tópicos que homogeneizan fuertemente el género, independientemente del héroe que las protagonizara o la historia que estuviera contando.

El éxito en el extranjero de estos filmes se ve potenciado por la tendencia contemporánea hollywoodense a rodar grandes películas épicas para competir con la televisión por vía de incrementar la espectacularidad de los filmes; es la misma época de "Doctor Zhivago", "Lawrence de Arabia", "El Cid", "Genghis Khan", e incluso productos bastante cercanos al péplum, como es el caso de "Ben-Hur", "La túnica sagrada", "Quo Vadis?", "Los diez mandamientos", "Cleopatra", "Espartaco" y "La caída del Imperio Romano". Sin embargo, estas aproximaciones colosalistas al cine "de romanos" se distancian bastante del espíritu más simple de los filmes auténticamente péplum. La crítica estadounidense acuñará para estos últimos el irónico mote de "muscleman epic".

La excesiva reiteración de argumentos y la evidente pobreza de medios de los filmes péplums terminaron por extenderle la partida de defunción. Así, en 1964 se rueda la que se considera la última película de la hornada péplum, "Combate de gigantes", de Giorgio Capitani, que reúne a los grandes héroes del género, Hércules, Sansón, Maciste y Ursus en una misma película. Sin embargo, las películas "de romanos" de bajo presupuesto seguirían rodándose incluso hasta comienzos de la década de 1980.

Aun así, la influencia del péplum en el cine popular ha sido bastante importante. Aunque el péplum fue sepultado por la aparición del spaghetti western, este nuevo género cinematográfico tomó varios elementos del péplum, incluyendo el protagonista errante que viaja de lugar en lugar, librando en cada pueblo una batalla contra la opresión. También es de destacar el éxito en plenos noventas, de alguna película como La Odisea, o las series de televisión "" y "", series que en el fondo eran reediciones de las antiguas películas péplums, con efectos especiales modernos y tramas algo más remozadas.

Ordenadas de acuerdo al año de su producción y del lugar de ambientación.








(Monarquía etrusca, República romana e Imperio romano. Los reinados de Calígula y Nerón están representados en el apartado Paleocristiano).




Ursus:

Maciste:

Goliat:

En el año 2000, el director Ridley Scott volvió a la gloria, después de años de oscuridad, con su película "Gladiator". En esencia, el argumento está calcado de "La caída del Imperio romano", y en espíritu, es en realidad un péplum de alto presupuesto. El éxito de este filme, y de "El Señor de los Anillos", que pese a no ser un péplum sino fantasía heroica, está realizado con similares efectos especiales por computadoras que requeriría un filme péplum real, reavivó el interés de los grandes estudios por el género. De este modo se rodaron nuevas películas y series de género dramático-histórico que han hecho resurgir el "péplum moderno". Estas realizaciones son en muchos aspectos una revisión del cine péplum, pero no comparten su esencia de ser producciones de bajo presupuesto, casi artesanales en muchos casos, y con historias sin un gran desarrollo. Entre los actores que destacan en esta especie de péplum moderno se puede citar al británico Gerard Butler.








</doc>
<doc id="27982" url="https://es.wikipedia.org/wiki?curid=27982" title="Radiómetro de Crookes">
Radiómetro de Crookes

El radiómetro de Crookes o molinillo de luz ("light-mill") es un dispositivo inventado en 1873 por el químico inglés William Crookes. Consiste en cuatro brazos que sostienen cada uno un álabe o placa en sus extremos, pintados de blanco de un lado y de negro del otro. Los cuatro brazos que soportan las placas están suspendidos en una aguja y sostenidos por un eje de vidrio para disminuir en lo posible la fricción. Este molinito se encuentra dentro de una esfera de vidrio sellada y en la que se ha realizado un vacío parcial.

Los álabes rotan al ser expuestos a luz, siendo más rápido el giro cuanto más intensa es la luz incidente. Eso proporciona una medida cuantitativa de la intensidad de la radiación electromagnética. La explicación de la rotación de este dispositivo ha sido históricamente el motivo de mucha controversia científica.

Crookes tuvo la idea a raíz de algunas investigaciones químicas que realizaba. En el curso experimentos químicos que exigían medidas cuantitativas muy precisas, se hallaba pesando muestras en una cámara a vacío parcial, con el objeto de reducir el efecto de las corrientes de aire. De pronto, notó que el valor de las pesadas era perturbado cuando sobre la balanza incidía luz solar. Investigando ese efecto, creó el dispositivo que lleva su nombre. Todavía se fabrican y venden radiómetros de Crookes con propósitos recreativos o didácticos.

El momento de fuerza que genera el sistema de las placas es muy pequeño, ya que tanto la longitud del brazo como la masa de la placa son muy pequeñas, por lo que el eje debe estar muy bien equilibrado y debe tener rozamiento prácticamente nulo para que pueda rotar.

Crookes quería saber si la luz al chocar en una superficie ejercía alguna fuerza, así que pensó que la luz rebotaría en los lados plateados de las placas, mientras que sería absorbida por el lado ennegrecido. Si todo lo que hubiera fuera una pura transferencia de momento entre los fotones incidentes y las placas, tendríamos que las placas girarían de manera que el lado negro fuese delante, puesto que al absorberse ahí los fotones, se tomaría menos cantidad de movimiento o momento que en los lados plateados, donde los fotones son reflejados (rebotan). Pero Crookes se llevó una sorpresa al observar que su radiómetro giraba de manera contraria a lo previsto (el lado negro de las placas se alejaba de la luz).

Originalmente se pensó que el giro era producido por el calentamiento de los lados negros de las placas, pero en posteriores experimentos se comprobó que el radiómetro giraba en sentido opuesto de nuevo (lado negro yendo hacia la luz) si se enfriaba bruscamente. Esto contradecía esa hipótesis original y muchas otras teorías) ya que el lado claro no podía calentarse y producir con ello el giro.

La explicación fue hallada por dos grandes científicos, James Clerk Maxwell y Osborne Reynolds: el efecto real ocurre en los bordes de las paletas.

Básicamente, en el lado caliente, las moléculas del gas se están moviendo con una velocidad media más alta que los gases en el lado frío. Cuando las moléculas calientes golpean el borde de la paleta, en promedio producirán una fuerza en la paleta que está hacia el lado fresco. Puesto que la velocidad media de las moléculas calientes es mayor que la velocidad media de las moléculas frías, habrá una fuerza en la paleta hacia el lado fresco. A este efecto se le llamó 'arrastre térmico'.

En posteriores experimentos más avanzados y con un vacío casi perfecto se logró determinar que la luz sí ejerce una fuerza.




</doc>
<doc id="27983" url="https://es.wikipedia.org/wiki?curid=27983" title="Radiómetro">
Radiómetro

El radiómetro, es un instrumento para detectar y medir la intensidad de energía térmica radiante, en especial de rayos infrarrojos.

Un radiómetro es un tubo de vidrio o cuarzo en el que se ha hecho un vacío parcial; dentro del tubo se encuentra un eje con cuatro paletas muy ligeras. Una cara de las paletas está ennegrecida, mientras que la otra es de metal pulimentado. Al recibir radiación externa el lado negro de una paleta absorbe más radiación que el lado pulimentado de la paleta opuesta, lo que hace que la primera paleta se aleje de la fuente de radiación. Dicho efecto produce una rotación constante de las paletas, con una velocidad que depende de la intensidad de la energía radiante. 

Estos radiómetros mecánicos, que antes se empleaban en instrumentos meteorológicos para efectuar medidas en las capas altas de la atmósfera, han sido sustituidos casi por completo por dispositivos electrónicos de estado sólido que miden la energía radiante de forma más directa y precisa.

El radiómetro es un dispositivo diseñado por el químico inglés Sir. William Crookes en 1873, el cual fue construido cuando trataba de medir la masa molecular del talio (elemento descubierto por el mismo). Al momento de pesarlo en una balanza analítica, Crookes notó que la flotabilidad del aire reducía ligeramente el peso, por lo que se dio a la tarea de eliminar la fuente del error, construyendo una cámara de vacío para pesar sus muestras. Pero en lugar de estabilizar sus mediciones como esperaba, su arreglo en la cámara de vacío dio lugar a lecturas extrañas que fueron influenciadas por la temperatura del material que pesaba. Objetos calientes parecían ser repelidos por objetos fríos, ya que en algunos experimentos observó que un objeto ubicado en una balanza cambiaba su peso cuando se le colocaba un cuerpo caliente cerca de él.

Consta de un molinete, cuyas aletas son blancas o metálicas por una cara y negras por la otra, dispuesto, para que pueda girar con un roce mínimo, en el interior de una ampolla de cristal en la cual se ha practicado un vacío parcial. Los rayos luminosos son reflejados por la superficie clara y absorbidos por la negra, la cual consiguientemente, se calienta. Así, el aire residual de la ampolleta se expande al contacto con las superficies negras y empuja las aspas, provocando una rotación del molinete, tanto mayor cuanto más intensa es la luz. Estos instrumentos han sido sustituidos casi por completo por dispositivos electrónicos de estado sólido, que miden la energía radiante de forma más directa y precisa.

Las fuentes de uso general en Radiometría son de vital importancia como sistemas auxiliares para la calibración de los detectores que constituyen los medidores de potencia óptica para fibras ópticas. Las fuentes láser de semiconductor son los elementos que general e inyectan luz como señal de portadora para las comunicaciones por fibra óptica, señal que debe ser medida con medidores de potencia en fibras como el que se pretende desarrollar.

Las características deseables en una fuente óptica, van a depender de la aplicación en concreto a la que se va a aplicar, pero en general, son las siguientes:

• Estabilidad temporal: El flujo que se radia debe permanecer constante. Lo ideal es que fuera siempre el mismo, esto es, que el flujo de energía radiado, no variase en el tiempo, incluso con los apagados y encendidos de la fuente.

• La distribución espectral debe de permanecer constante siempre, y que además no cambie su forma relativa, idealmente nunca.

• Flujo radiante suficiente: Es importante que la relación señal/ruido sea la mayor posible para obtener los niveles de incertidumbre más bajos. 

• Fiabilidad y facilidad de uso.

• Inmunidad frente a cambios medio – ambientales exteriores.

• Reducido tamaño. 

• Poco peso. 

• Poco consumo.

• Elevado rendimiento: Conseguir todas estas características en un dispositivo único, es prácticamente imposible, y por esta razón, en función de la aplicación en la que vaya a estar presente nuestra fuente óptica, buscaremos unas características u otras.



</doc>
<doc id="27984" url="https://es.wikipedia.org/wiki?curid=27984" title="Horus Escorpión II">
Horus Escorpión II

Horus Escorpión II ("hor Serq") fue un gobernante del Antiguo Egipto, perteneciente a la denominada Dinastía 0. El nombre de su cónyuge era Shesh I, madre de Narmer y bisabuela de otra reina, Shesh II.

Aunque los datos sobre Horus Escorpión son imprecisos, incluso se duda de su existencia, habría vivido hacia el año 3075 a. C., ya que la Paleta de Narmer, que refleja la invasión del Bajo Egipto por parte de su hijo Narmer, está fechada en 3050 a. C.

La existencia de Horus Escorpión II parece confirmada por una «cabeza de maza ceremonial» de piedra caliza, descubierta en un templo de Hieracómpolis durante el periodo de excavaciones de 1897/98 por los arqueólogos James Edward Quibell y Frederick William Green, en la que figura un faraón, de gran tamaño, con la corona Blanca del Alto Egipto y la imagen de un escorpión grabado junto a su cabeza.

Esta maza, custodiada en el Museo Ashmolean, es una de las representaciones más antiguas de un rey egipcio. Pertenece a una época en la que la escritura era incipiente, grabándose junto al rey un escorpión, a modo de jeroglífico, que representaría el nombre del faraón. El nivel de estratigrafía de esta maza se perdió debido a los métodos de excavación empleados, pero su estilo indica una fecha de finales del período predinástico. Aunque gravemente dañada, las partes visibles son extraordinarios registros de esta primera historia de Egipto, indicando que Horus Escorpión habría vivido antes o durante el imperio de Narmer en Tinis.

También se encontró un fragmento de una segunda maza más pequeña, conocida como la pequeña cabeza de maza ceremonial de escorpión. Aunque el fragmento no es muy grande, en él se ve claramente al faraón portando la corona Roja del Bajo Egipto. 

En uno de los vasos dedicados por él en Hieracómpolis, está acompañado del halcón Horus, símbolo de la realeza egipcia.

Se ha querido interpretar esto como evidencia de la existencia de un gobernante llamado Horus Escorpión II, que habría realizado la unificación del Antiguo Egipto o su inicio, pues según la tradición fue llevada a cabo con posterioridad, hacia el año 3050 a. C., cuando los gobernantes del Alto Egipto dominaron al Bajo Egipto. 

Horus Escorpión lleva una azada en la mano, que se relaciona con los ritos religiosos sobre la apertura de los diques tras la inundación del Nilo, o el primer surco en el campo. Los estandartes, con aves –concretamente avefrías o el "ave rejit"–, simbolizarían los nomos o poblaciones implicadas de Egipto; varias plantas de papiro indican que el acontecimiento transcurría en el Bajo Egipto; también hay una flor de siete pétalos en la parte superior, de difícil interpretación. Los nueve arcos (que representan a los tradicionales enemigos de los egipcios) se interpretan como prueba de que los ataques que culminaron con la unificación de Narmer comenzaron en el Bajo Egipto.

Su tumba podría ser la localizada en Umm el-Qaab, Abidos, la denominada B-50.

Para los egiptólogos Werner Kaiser y Günter Dreyer, este rey es el sucesor de Horus Ka y el predecesor de Narmer.




</doc>
<doc id="27985" url="https://es.wikipedia.org/wiki?curid=27985" title="Saltillo">
Saltillo

Saltillo es la ciudad capital del estado de Coahuila de Zaragoza, México. Cuenta con una población de 1,000,229 habitantes, lo que la convierte en la y en su zona metropolitana con las ciudades vecinas de Ramos Arizpe y Arteaga cuenta con 1,222,107 habitantes, siendo en su conjunto la vigésima metrópoli más grande del país. Cuenta con una superficie de 3837km² y se localiza en la región Noreste de México y en la región sureste de Coahuila, está rodeado por altas montañas de la sierra madre oriental y se encuentra a 400km al sur de la frontera con Texas, Estados Unidos y a 842km de la Ciudad de México.

Saltillo ha tenido un papel muy importante en la historia de México, en 1811, en pleno fervor de la Independencia, los insurgentes ocuparon Saltillo para dirigirse hacia Parras y Monclova, en ese mismo año, Allende e Hidalgo llegaron a la Villa en retirada hacia Estados Unidos, Hidalgo nombró jefes del movimiento a Ignacio López Rayón y José María Liceaga, además de que en 1847 se enfrentaron los ejércitos de México y los Estados Unidos cerca de la capital, en la Batalla de La Angostura. Otro momento importante de la historia es que en 1864 estableció Benito Juárez su gobierno en esa ciudad.

También tuvo una gran importancia dentro de la vida postrevolucionaria de México, en donde se vivieron momentos de vital importancia para la naciente democracia del país, pues se decretó la Constitución y la ciudad fue ocupada por una facción revolucionaria. El municipio se levantó en armas contra el gobierno de Porfirio Díaz y fue un municipio donde hubo una gran cantidad de revolucionarios importantes además de que fue sede de encuentros entre ejércitos como el huertista y el carrancista.

Se puede determinar que el nombre de la ciudad se debe a una formación de agua, la cual todavía existe y se encuentra en la escalinata de la Iglesia del ojo de agua, se puede visitar y gracias a su pureza es potable.
El nombre que Alberto del Canto dio a la ciudad fue: Villa de Santiago de Saltillo. No se ha determinado con plena certeza el origen del nombre de Saltillo, ya que existen varias versiones. Una de ellas sugiere que se trata de una palabra chichimeca, corrompida y castellanizada, que significaba “tierra alta de muchas aguas”. Otra versión, quizá más acertada, lo relaciona con un pequeño salto de agua que caía desde una elevación del terreno en cuya cima está el principal ojo de agua del lugar y al pie del cual se fundó la villa. Desde este manantial se construyó una acequia que, por gravedad, surtía de agua a la población. Probablemente fue entonces cuando desapareció la pequeña cascada.

Varios exploradores seguramente recorrieron el hoy valle de Saltillo en busca de minas, aunque es sabido que la principal fuente de riqueza se basaba en la captura de indios chichimecas para esclavizarlos o venderlos en las ciudades mineras. El primer grupo de exploradores que se tiene registro llegó a Coahuila a fines de 1568, comandados por Francisco Cano, Teniente de Alcalde de Mazapil, quien exploró el sur de los hoy municipios de Saltillo y General Cepeda, tomando posesión a nombre de la Nueva Galicia. Al año siguiente, Martín López de Ibarra, Teniente de Gobernador de la Nueva Vizcaya, exploró la misma zona y repartió mercedes y tierras a nombre de su provincia. Probablemente hayan entrado también el Capitán Francisco de Puga y Luis de Carvajal hacia 1573. Posteriormente, el portugués Alberto del Canto, quien había sido vecino del Real de Mazapil, llevó a cabo la fundación de la villa de Santiago del Saltillo, a nombre de la Gobernación de Nueva Vizcaya, poco antes de 1577.

Ya instalada la villa, esta se encontró ante el constante asedio de los originarios comarcanos, estando ante el peligro constante de despoblar la villa. Ante esta situación, fueron traídas familias tlaxcaltecas con la intención de que los indígenas de la región imitaran el trabajo de estos, de ahí se haría famoso el tradicional «Sarape de Saltillo». La villa se dividía en dos por medio de un canal o arroyo de agua que nacía del «Ojo de Agua» y bajaba por la calle Allende. La parte norponiente y norte (San Esteban de la Nueva Tlaxcala) correspondía a los indígenas, quienes la convirtieron en un vergel debido al incansable trabajo y a sus amplios conocimientos en horticultura, mientras que la parte suroriente y oriente (Villa de Santiago del Saltillo) correspondía a los españoles. Los indígenas hacían diversas actividades, como la elaboración de dulces de frutas y de leche, elaboración del sarape, cultivo de árboles frutales, pastoreo de ganado, pan de pulque, entre muchas otras actividades.

La ciudad de Saltillo ha tenido algunos episodios importantes de la historia de México. Uno de los más destacados fue el ocurrido el 22 de febrero de 1847 durante la guerra México-Estados Unidos: la batalla de La Angostura, en la que participaron tropas mexicanas e invasores norteamericanos, las primeras comandadas por López de Santa Anna y los generales Mora, Villamil, Micheltorena, Blanco, Corona, Pacheco, Lombardini, Urrea, Sánchez y otros; y las segundas, comandadas por el general Zachary Taylor. Se dieron cruentos enfrentamientos entre los catorce mil mexicanos y los siete mil invasores que contaban con superior artillería. Triunfaron los mexicanos en varios frentes sin obtener la victoria ya que, inexplicablemente, se retiraron del campo de batalla.

La modernidad llegó a Coahuila, y prácticamente a todo México, con la llegada del ferrocarril en 1880, durante el porfiriato. Hacia 1890 se crearon redes de telégrafo, teléfono y de alumbrado público, además de la construcción de edificios culturales como teatros y plazas; otras obras de carácter social como el hospicio y el hospital civil, y otras de higienización como el sistema de agua potable y de drenaje, el rastro, el mercado y el panteón de Santiago, fueron también creados en esta época. 

Durante la revolución mexicana, figuraron varios personajes coahuilenses que habían estudiado en colegios saltillenses tales como el Ateneo Fuente y el Colegio de San Juan, entre otros.

Durante la Revolución mexicana, Saltillo se mantuvo sin grandes sobresaltos. La ciudad fue tomada por las fuerzas de Victoriano Huerta, posteriormente por las de Francisco Villa y luego las de Venustiano Carranza. Centenares de campesinos fueron forzados a unirse a las diversas agrupaciones, por lo que muchos huyeron a Texas, al igual que unas familias aristócratas.

Hacia 1923 se fundó la actual Universidad Agraria Antonio Narro. En los años cincuenta se creó el Instituto Tecnológico de Saltillo y la Universidad de Coahuila. Y dos décadas más tarde, la Universidad Autónoma del Noreste y el Campus Saltillo del Tecnológico de Monterrey.
La vida agrícola de Saltillo en la segunda mitad del siglo XX se fue transformando rápidamente hacia la actividad industrial; las enormes huertas desaparecieron y las industrias dominan el paisaje de hoy.

En el segundo cuarto del siglo XX, Saltillo cambió el giro de las actividades agrícolas y textiles hacia las industriales con la creación de empresas como CIFUNSA, CINSA, Éxito, Molinos el Fénix, entre otras. A mediados del siglo, con la política proteccionista de México, se siguieron creando empresas tales como Moto Islo en 1961, además de Zincamex e Inyec Diesel en esa misma década.

La verdadera explosión industrial ocurrió en las décadas de los 70's y 80's con la llegada de la industria armadora de automóviles a la región, con empresas como General Motors y Chrysler, junto con sus respectivas empresas satélites o proveedoras. Desde entonces, a Saltillo y su Zona Metropolitana (Ramos Arizpe y Arteaga) se le conoce como la "Detroit de México".

Sin embargo, actualmente se está dando un impulso para la diversificación de la industria, con la llegada de empresas farmacéuticas, de artículos electrodomésticos, de químicos, de cerámica e incluso de partes para la industria aeroespacial, y lograr así evitar la concentración de la misma en una sola área, con todos los riesgos que ello implica.

Saltillo se encuentra en una zona penisísmica, donde se han registrado varios sismos o movimientos telúricos. El último se registró en mayo de 2018 con magnitud 4.0 en la escala de Richter.

En Saltillo se realizó la primera unión entre dos personas del mismo sexo en toda Latinoamérica. Esto sucedió en enero de 2007 cuando dos mujeres oriundas de Matamoros, Tamaulipas, se unieron mediante el Pacto Civil de Solidaridad,

El clima de Saltillo es templado semiseco, con una temperatura promedio de 17°C. Los inviernos son extremosos, predominando temperaturas máximas superiores a 18 grados Celsius y algunos días con temperaturas mínimos inferiores a cero grados. Para la ocurrencia de nevadas se requiere humedad y la época húmeda en Saltillo ocurre de mayo a octubre; por lo que es muy raro que se presenten más de 5 días de nieve al año, incluso, hay años en que no se presentan nevadas. Las nevadas más significativas ocurrieron el 12 enero de 1962, 11 de enero de 1967, enero de 1983, 13 de diciembre de 1997, 24 de diciembre de 2004, 12 de enero de 2010, 3 y 4 febrero de 2011. La últimas nevadas ocurrieron el 8 de diciembre, con una capa de 20 cm de espesor;15 de diciembre de 2017; el 17 y 18 de enero de 2018. El invierno 2017-2018 fue uno de los inviernos más fríos pues se registraron 3 nevadas en la ciudad. De acuerdo a los registros meteorológicos, Saltillo es una de las ciudades más frías en invierno en México (-18 el 13 de diciembre de 1997, según fuentes no oficiales, ya que no hay registro que valide esta información; -14.5 en enero 1962, según la fuente oficial del Servicio Meterológico Nacional); solo por debajo de la Ciudad de Chihuahua (-18 el 3 y 4 de febrero 2011), Ciudad Juárez (-23ºC el 11 de enero de 1962). Los veranos son cálidos, con temperaturas que suelen superar los 38°C. En mayo de 2012 se registraron 42°C. 

Compuesto por formaciones geológicas del periodo Jurásico, el cañón de San Lorenzo, ubicado al sureste de Saltillo, en la Sierra de Zapalinamé, es un atractivo turístico que atrae decenas de aventureros cada semana por la diversidad de deportes extremos que se pueden practicar aquí como la escalada en roca, rapel, ciclismo de montaña, senderismo, montañismo y campismo. Entre sus parajes destaca Balcones, La Ventana, Cascada de los Elefantes, La Y, Roca Escuela y la casa de Lorenza.

Accidentes fluviales de poniente a oriente.

Entra desde el surponiente a la ciudad por la colonia Tanquesito al extremo sur de la calle Pedro Ampudia, baja cerca y a lo largo de la vía férrea, pasa al lado del Hospital Universitario y más al norponiente por la colonia Pueblo Insurgente y continua paralelamente pero relativamente cercano al bulevar Vito Alessio Robles hacia el complejo automotriz de GM y converge a la altura de carretera “Los Pinos” con el arroyo de Cevallos. Cuenta con una presa Tlaxcalteca (patrimonio histórico en peligro).

Inicia al sur del Bulevar Francisco Coss, pasa detrás del Tecnológico de Saltillo, cruza el Bulevard Venustiano Carranza a la altura del Hotel “El Paso” hacia el noreste, pasa entre los edificios de Liverpool y Home Depot, y se canaliza por el Bulevar Nazario Ortiz hacia la calle Benito Juárez.

Inicia su cauce en la Colonia Magisterio, hacia el templo del Santo Cristo del Ojo de Agua, atraviesa el centro de la ciudad entre las calles Arteaga y Matamoros cerca de la escuela Coahuila, después a la altura de la Plaza “1o de mayo” en calle Emilio Castelar converge con el cauce que baja cerca de la calle Antonio Cárdenas (o Abasolo sur) al parecer desde el Parque “el Chapulín”, se canaliza subterráneamente pasando por la colonia Topo chico, baja a través de la calle Nava en la colonia República y luego por Luis Echeverría y baja de nuevo por Abasolo norte y conecta en Nazario Ortiz con el Charquillo.

Inicia desde el extremo oriente de la calle Ateneo, baja detrás del deportivo San Isidro pasando a un lado de Campo Redondo, atraviesa el lago de la Ciudad Deportiva hacia el Tecnológico de Monterrey y continua hasta converger con el arroyo de Cevallos a la altura del Bulevar Moctezuma o Pedro Figueroa.

Inicia en la sierra Zapaliname, desde la colonia Lomas de Lourdes pasa a lo largo del Bulevar Luis Echeverría oriente, pasa atrás del Mercado de Abastos, atraviesa por un lado de Plaza Sendero, luego baja a lo largo de la calle Tezcatlipoca, pasa cerca del Club Campestre y converge con el arroyo de la Navarreña en carretera hacia Monterrey y camino a los Valdés.

Inicia en la sierra a la altura de la colonia Vista Hermosa, de forma cruzada atraviesa colonias como Fundadores y Morelos, baja por un lado del Motel Corona en bulevar Fundadores, pasa al lado del panteón Dolores en el Bulevard Jesús Valdés Sánchez y continua hacia el sur rodea el Club Campestre por su lado oriente y el fraccionamiento Country Club y continua a hacia la ciudad de Ramos.

Ubicado en el Cañón de San Lorenzo al sureste de la ciudad de Saltillo. Compuesto por formaciones geológicas originadas entre el Jurásico Superior y Cuaternario que facilitan la infiltración intensa de agua al subsuelo, permitiendo así la recarga constante de los acuíferos que abastecen de agua potable a la ciudad de Saltillo.
El 3 de julio del 2008, el Gobierno del Estado de Coahuila decide comprar la propiedad, la cual fue otorgada a Protección de la Fauna Mexicana en comodato el 23 de julio de 2012 para su manejo y conservación.

Es la montaña más alta del municipio, alcanza los 3,462 metros sobre el nivel del mar.

Montaña que alcanza los 3,104 metros sobre el nivel del mar.

La ciudad de Saltillo de acuerdo con el último conteo y delimitación oficial realizada en 2010 en conjunto por el INEGI, el CONAPO y la SEDESOL, es la ciudad número 17 más poblada de México.</small>

La ciudad de Saltillo es una zona urbana y comercial, es la ciudad más rica del Coahuila de Zaragoza, una gran parte de la población labora en la industria que se concentra en el municipio de Ramos Arizpe, considerado una de las zonas más industrializadas del país que conforma uno de los mayores clústers automotrices en México, desde 1970 se han instalado en la región plantas como Grupo Industrial Saltillo, General Motors, Magna, Fiat Group, Chrysler, Daimler, Freightliner, Delphi, Nemak, Plastic Omnium, etc.

Al sur de Saltillo, Coahuila, con dirección a Zacatecas, se encuentran algunos parques industriales, entre ellos La Angostura y Derramadero los cuales sirven como canales para aumentar el comercio y que en poco tiempo han crecido a pasos agigantados. Las empresas tanto nacionales como extranjeras están jugando un papel muy importante en cuanto a la inversión en esta zona, debido a que estas empresas han acercado a sus proveedores para facilitar los procesos logísticos, con ellos se generan fuentes de empleo y se crea una mejor imagen de la región haciéndola atractiva para inversiones futuras.

La infraestructura vial en la ciudad de Saltillo es una de las más modernas del país, con más de 30 pasos a desnivel y dos distribuidores viales que componen 28km de vía libre que permiten atravesar la ciudad sin semáforos de norte a sur, estas obras convirtieron a la capital del estado en una «ciudad moderna y en pleno desarrollo». Empero, en los últimos años, algunas arterias se han visto saturadas, debido al crecimiento acelerado de la población y el aumento en el parque vehicular, aunado a la falta de un transporte público eficiente. Según datos del Instituto Nacional de Estadística y Geografía (INEGI), el número de vehículos en circulación en la capital ha crecido en más de un 15%, y varias avenidas de la ciudad se han vuelto insuficientes para el desplazamiento de los mismos, en especial en horarios de alto tráfico.

Actualmente la ciudad cuenta con un gran número de universidades de nivel superior, las cuales se en listan a continuación:

En 1989, año en que fue creado el Centro Histórico de Saltillo y la Junta de Protección y Conservación del Patrimonio Cultural.
Se transformó el centro urbano embelleciendo la imagen urbana y la restauración de edificios de valor histórico.




En Saltillo existen alrededor de 22 museos, entre ellos: Museo de los Presidentes' Coahuilenses, Recinto del Patrimonio Cultural Universitario, 'Pinacoteca Ateneo Fuente' de la Universidad Autónoma de Coahuila, Museo –Archivo Parroquial, Sala de Historia Natural «Prof. Rafael B. Narro» (Ateneo Fuente. Universidad Autónoma de Coahuila), Museo de Paleontología de la Benemérita Escuela Normal de Coahuila, Museo de Arqueología «Prof. Carlos Cárdenas Villarreal» de la Benemérita Escuela Normal de Coahuila.




Durante el siglo XX recibió el sobrenombre de La Atenas de México por el gran número de personajes intelectuales destacados.

El sarape (o jorongo) es una prenda rectangular, de uso masculino, con o sin apertura para la cabeza y rayas multicolores esfumadas como un arco iris. Es uno de los objetos más representativos de México. El sarape es una prenda de la indumentaria tradicional masculina de México generalmente de colores vivos y con patrones o diseños generalmente un tanto predecibles. Se le puede portar con elegancia y es relativamente el equivalente masculino del rebozo de las mujeres.

El sarape es una parte de la vestimenta característica de «lo mexicano», es decir, del estereotipo de lo nacional, junto con el sombrero, que une tradiciones mesoamericanas y europeas de tejido, además de temas prehispánicos y coloniales.

Generalmente se fabrica de lana, fibra que mantiene el calor más eficientemente, pero también se teje de algodón. El grosor del hilo escogido para el tejido, así como su material, la elaboración misma de cada nudo necesario y el tamaño final del sarape, son variables que influyen en el peso final del sarape, y también en la sensación que da como un material fácil de manejar.

Es tradicional de varias partes de México, como en Saltillo. De hecho, fueron colonizadores de origen tlaxcalteca quienes llevaron el sarape a Coahuila de Zaragoza, Zacatecas y probablemente a Nuevo México.

Suele comparársele con un poncho mexicano sin gorro y se le conoce con distintos nombres en todo el país, tales como: tilma, chamarro, cotón, cobija o frazada. También se le conoce como gabán, pero puede decirse que esta última denominación es errónea, pues el sarape no tiene una apertura central para meter la cabeza.

Sirve de abrigo, cobija, cubrecama, mantel o capote. También adorna muros y pisos, a modo de tapiz o alfombra. Otro uso es el de ponérselo al caballo antes de subir la silla de montar. Y en el pasado, durante riñas, servía también como práctico escudo, especialmente como estorbo contra objetos punzocortantes.

En el Centro Histórico se puede visitar la Fábrica de Sarapes, donde se puede observar como se crea una de estas prendas y si así se desea, comprar uno. En el año del 2009 se inauguró en Saltillo el Museo del Sarape y Trajes Mexicanos (Allende 160 sur), contando con ejemplares del siglo XVIII y XIX, y donde se explican lor procesos de obtención de la lana, su teñido, el tejido en telar y su uso, a través de la historia.

El pan de pulque es la gran tradición de la región, actualmente la ciudad de Saltillo es relacionada o sinónimo de este producto, buscado por habitantes y consumidores del país entero así como del extranjero; otros panes conocidos son también las empanadas de nuez, las chorreadas, los molletes, pan de trenzas, obispos, etc. Además un platillo típico de esta ciudad es la carne asada, cabrito, etc. No hay ocasión especial para la carne asada, se puede hacer en un cumpleaños, un aniversario, un viernes por la tarde o un domingo por el mediodía, en fin no hay semana sin carne asada

La ciudad de Saltillo es famosa por su rondalla, al ser la máxima representante del movimiento rondallesco en México desde hace más de cuatro décadas. La Rondalla de Saltillo fue más allá de trasponer los límites establecidos y crear un estilo propio. Cuenta con múltiples grabaciones y ha recorrido diversos países, se caracteriza por utilizar guitarras, requintos, un contrabajo, voces y un poeta, vestimenta elegante, traje sastre o esmoquin. El poeta Marco Antonio Aguirre llegó a La Rondalla de Saltillo en 1966 y escribió su historia con giras, 30 discos grabados y fama internacional.

Representado por Saraperos de Saltillo - Liga Mexicana de Béisbol, Bicampeones de la LMB 2009-2010

Los Saraperos de Saltillo arribaron a la Liga Mexicana de Béisbol en 1970. Tuvieron su origen en una cena que celebraron los integrantes del Comité Pro-Obras de la Catedral de Saltillo, cuyo presidente era don Jorge Torres Casso.




El 25 de noviembre de 1923, en la antigua plaza de toros “Guadalupe”, se efectuó la que se considera la primera pelea de boxeo profesional en Saltillo, entre Ignacio Cerecero (pantaloncillo blanco) y Humberto Cid González, “El Relámpago”, que resultó vencedor al final de la pelea.
Fungió como árbitro el ferrocarrilero Samuel Ortega Hernández. El nombre de Humberto Cid González “El Relámpago” le fue impuesto en 1977 a una de las calles de una nueva colonia de la ciudad.


Algunos personajes destacados:






La ciudad de Saltillo tiene las siguientes ciudades hermanas alrededor del mundo:



</doc>
<doc id="27990" url="https://es.wikipedia.org/wiki?curid=27990" title="Tabarna">
Tabarna

Tabarna término utilizado en el antiguo Imperio Hitita, se refería a la máxima autoridad imperial; es, el equivalente del Emperador entre los romanos.

Parece ser que la palabra deriva del nombre de Labarna, uno de los primeros grandes reyes hititas, y probable fundador del Imperio Antiguo Hitita. De esta manera, el título de Tabarna se habría transformado en genérico a partir de un nombre propio, al igual que el título de César entre los romanos.

El tabarna no era un monarca absoluto, en el sentido que entendemos un Emperador. Antes bien, aparecía asesorado por un consejo consultivo, el panku, que presenta a rasgos generales las características propias de los consejos de ancianos de otras culturas y civilizaciones, y convierte al Imperio Hitita por lo tanto en una aristocracia militar.

Aunque entre el Antiguo y el Nuevo Imperio Hitita hubo un eclipe político derivado fundamentalmente del ascenso de Mitanni, hubo una continuidad política en los reyes de Hattusa. Distinta fue la situación al caer Hattusa en manos de los invasores kaskas hacia el año 1190 a. C., lo que significó también la destrucción de la unidad hitita.


</doc>
<doc id="27991" url="https://es.wikipedia.org/wiki?curid=27991" title="Tratado de Verdún">
Tratado de Verdún

El Tratado de Verdún fue un pacto alcanzado el 10 de agosto de 843 entre Lotario I, Luis el Germánico y Carlos el Calvo —hijos de Ludovico Pío y nietos de Carlomagno—, en la localidad francesa homónima. Este tratado tuvo como origen la "ordinatio imperii", que decretaba el modo de proceder si fallecía uno de los monarcas subsidiarios sin descendencia. No obstante, esto dio como resultado una serie de conflictos en el imperio que, lejos de solventar las divisiones, las acentuó. El documento estableció las regiones que le correspondían a cada heredero y previo a la rúbrica de este tratado, se acordó entre ellos un compromiso de ayuda mutua. Así, se puso fin a la «guerra civil carolingia» y al proyecto de Carlomagno de hacer resurgir el Imperio romano, mediante la firma de los Juramentos de Estrasburgo el 14 de febrero de 842. Tras ser llevado a cabo el reparto, surgieron tres territorios que pasaron a denominarse Francia Occidental, Francia Media y Francia Oriental.

Lotario I se estableció en Italia y fue el depositario del título de emperador. Luis el Germánico fijó su residencia en Baviera y se le concedieron los territorios germánicos y anexos que iban desde los Alpes hasta el Rin. Carlos el Calvo recibió la parte occidental de lo que restaba del Imperio carolingio. Gracias a este reparto surgieron tres realidades socio-políticas desarrolladas como reinos independientes de las que Francia Oriental y Francia Occidental (germen del futuro Reino de Francia) subsistieron hasta el siglo X, a diferencia del territorio central que fue absorbido por los territorios occidental y oriental tras la defunción de los herederos de Lotario I.

Tras la muerte de Luis el Piadoso, el Imperio carolingio se dividió entre sus tres hijos: Carlos el Calvo, Lotario I y Luis el Germánico, siguiendo lo firmado en el Tratado de Verdún. De este modo, a cada uno de los herederos le fue otorgado un reino: a Lotario I se le otorga Italia, Luis el Germánico se establece en Baviera y Carlos el Calvo en Aquitania. En dicho acuerdo Lotario I se reservó el título de emperador y el reparto del Imperio de Luis el Piadoso se realizó de la siguiente manera entre sus herederos:


Tras la muerte de Luis el Piadoso y el reparto a raíz del Tratado de Verdún, el título imperial quedó reducido a un carácter simbólico. Después del reparto, Carlos II el Calvo recibió el territorio de la Francia Occidentalis, precursor de la actual Francia. Tras llegar a Verdún, cada hermano recibió su territorio: Lotario I recibe la Francia Media, a Luis el Germánico se le entregó la Francia Orientalis y el territorio restante hasta España se le hizo entrega a Carlos, hecho reflejado en los Anales de Flodoard.

El acuerdo tuvo resultados políticos considerables. Asimismo, se evidenció el fracaso de la restauración imperial carolingia, gestando el germen de lo que posteriormente serían las naciones de Francia — al oeste— sobre la base del territorio de Carlos; y en el poniente Alemania —sobre la base de las regiones de Luis al este—. La demarcación de Lotario (que suele denominarse Lotaringia, aunque es más correcto denominar con ese apelativo a la zona septentrional que se le concedió a su vástago Lotario II), comprendía el área que la historiografía designa con el nombre de Flandes —los actuales Países Bajos, Bélgica y Luxemburgo—; el sector ubicado al oeste del Rin — las actuales comarcas francesas de Alsacia y Lorena y parajes de las actuales áreas alemanas denominadas Renania — y los actuales territorios de Borgoña, Provenza y el norte de la actual Italia.

Su estabilidad fue muy insegura por sus divisiones y reparto. Primero entre los vástagos de Lotario —Tratado de Prüm, 855— y después entre las monarquías vecinas —Tratado de Mersen, firmado el 8 de agosto de 870, y Tratado de Ribemont, en el 880— y gracias al Tratado el Imperio quedó de la siguiente forma: el Imperio franco fue dividido en tres partes diferenciadas formando tres reinos: el reino central, oriental y occidental. El título de emperador recayó sobre Lotario I, que a su vez recibió el reino central, cuya extensión iba desde el mar del Norte hasta el golfo de Gaeta; incluyéndose las ciudades de Aquisgrán y Roma. Por su parte, Luis el Germánico se hizo con el reino oriental. Por último, Carlos el Calvo recibió el reino occidental y, a pesar de esta división del Imperio carolingio, formalmente sí se reconocería la unidad imperial, siendo coronado como rey en el año 848 en Orleans.

Tras el reparto de Verdún, Carlos el Calvo recibió el territorio denominado Francia Occidental, cuyo marco cronológico se extendía desde el año 843 hasta el año 987, surgiendo a raíz de la fragmentación del Imperio carolingio tras el Tratado de Verdún. También se le denominó Reino de los francos occidentales y es el germen del Reino de Francia. Este reino surgió tras producirse la división del Imperio carolingio a raíz del Tratado de Verdún y geográficamente abarcaba el sur de la actual Francia, culminando en la denominada Marca Hispánica. No obstante, Carlos sostuvo un enfrentamiento con su sobrino Pipino II de Aquitania, dado que al fallecer su padre fue reconocido como soberano solo por la nobleza sin tener en cuenta el beneplácito del emperador, quien en la asamblea de Worms del año 939, eligió a Carlos como monarca. Por su parte, Carlos el Calvo entró en guerra con Pipino en el año 840. Así, tras varias derrotas, en el año 845 se rubricó el tratado de Benoît-sur-Loire, reconociendo los derechos de su sobrino. A partir del año 840, proliferaron batidas vikingas, siendo París saqueada entre los años 856 y 862. Por ello, Carlos el Calvo tomó medidas que fueron ineficaces, siendo necesario llegar a un vasallaje con los vikingos, cediéndoles el territorio que se denominaría Normandía. Además a esto se unieron las incursiones de los magiares a partir del año 920.

Por su parte, el primogénito de Ludovico Pío sobre el que recae el título de emperador, Lotario I, obtuvo como reino la Francia Media, que estaba situada en medio del mar del Norte y el mar Mediterráneo. Comprendía lo que actualmente son los Países Bajos, Luxemburgo, Bélgica, el oeste del Rin, Francia, Suiza y el norte de Italia. A su vez, el Reino de los Francos Orientales, llamado también Francia Oriental, sería el germen de la futura monarquía en Alemania. A Luis el Germánico le correspondió la parte oriental mayoritariamente germano parlante, hecho que es referido en los Annales fuldenses, que hacían mención a la división del Imperio y a la parte oriental que se le otorgó a Luis el Germánico. Este territorio estaba compuesto de conquistas procedentes del siglo , que incluía los ducados de Alemania, Baviera, Sajonia y Turingia junto con las marcas danesa y eslava.

El 10 de agosto del año 843, fallecido Luis el Piadoso y tras una añada, sus vástagos y herederos rubricaron el Tratado de Verdún mediante el que Luis el Germánico obtuvo la parte oriental denominada Francia Oriental, que estaba formada por incorporaciones regionales del siglo al Imperio carolingio, entre las que se incluían: Alemania, Baviera, Sajonia, Turingia y las marcas danesa y eslava cuya población era germano y eslavo parlantes mayoritariamente, formando una población que se dividía por raza, costumbres y lengua.





</doc>
<doc id="27992" url="https://es.wikipedia.org/wiki?curid=27992" title="Viaje al centro de la Tierra">
Viaje al centro de la Tierra

Viaje al centro de la Tierra (Voyage au centre de la Terre) es una novela de Julio Verne, publicada el 25 de noviembre de 1864, que trata de la expedición de un profesor de mineralogía el profesor Lidenbrock, su sobrino Axel y un guía llamado Hans, al interior del globo o al interior de la Tierra y se encuentran en su aventura con una gran sorpresa al llegar.

Esta es una de las pocas novelas de Julio Verne que fue serializada.

El personaje principal de la historia, el joven Axel, reside en una vieja casa situada en la Königstrasse, en Hamburgo, junto a su tío Otto Lidenbrock, un prestigioso profesor de mineralogía en el "Gelehrtenschule des Johanneums" (designado en libro como "Johanneum"), a quien describe como un hombre temido por su fuerte carácter pero muy original, su pareja Gräuben y su sirvienta, Marta. Un día el profesor le llama a su despacho, donde le enseña un manuscrito de gran valor del Heimskringla, de Snorri Sturluson. Pero ese libro esconde una gran sorpresa: un pergamino de origen rúnico que oculta un mensaje secreto. Tras muchos esfuerzos y gracias a un descubrimiento casual de Axel, lograrán descifrarlo. En él, un alquimista islandés llamado Arne Saknussemm revela cómo llegar al centro de la tierra. El profesor, eufórico, decide ir al lugar indicado en el pergamino junto con su sobrino Axel. 

Axel está muy asustado y no quiere ir, pero no tiene otra opción, y salen hacia el punto indicado en el pergamino: Islandia. Tras un largo viaje, llegarán a Reikiavik, ciudad cercana al Snæfellsjökull, volcán por el que tendrán que introducirse para alcanzar el corazón terrestre, siguiendo las indicaciones de Saknussemm. Allí contratan a Hans, un cazador de éiders profesional, que les acompañará a lo largo de su odisea. Equipados con víveres, herramientas, armas, instrumentos, linternas eléctricas y un botiquín, emprenden el viaje hacia el volcán. 

Emprenden el asalto del Sneffels por caminos difíciles. La marcha es penosa, pero al fin alcanzan la cumbre del volcán. Allí encontrarán una grata sorpresa: Saknussemm ha señalado su presencia inscribiendo su nombre en una roca, mostrando así que su viaje era real. Llegados al fondo del cráter, se abren tres chimeneas. Siguiendo una vez más las instrucciones dejadas por el alquimista en el pergamino, averiguan cuál de las tres chimeneas es la que conduce al centro de la Tierra: aquella que la sombra del pico Scartaris acaricie antes de las calendas de julio. Por medio de una cuerda, se van deslizando y bajan así 2 800 pies en once horas. Allí improvisan una cama para dormir y recuperar fuerzas.

A la mañana siguiente, siguen hundiéndose en las entrañas del Globo dejándose caer por pendientes inclinadas, formadas por lava seca que tapiza el interior del cráter. Tras un largo descenso, llegan al fondo de la chimenea, donde se encuentran con dos caminos. El profesor Lidenbrock decide tomar el del Este, y tal camino resulta ser el erróneo, pues al tercer día se quedan sin agua y han de retroceder para ir hacia el Oeste. Cuando los personajes están muriéndose de sed tras varios días sin hallar nada de agua, Hans, el guía que los acompaña, halla un torrente bajo las rocas. Perforan la piedra con las herramientas que llevan y consiguen agua, pero a 100º de temperatura; la dejan enfriar y de ese modo sacian su sed y llenan las cantimploras.

A la mañana siguiente, siguen su camino descendiendo y acercándose cada vez más al centro de la tierra. Axel se despista de su tío y de Hans, y se pierde en un túnel. No obstante, la peculiar acústica del lugar le permite conversar con su tío a pesar de encontrarse muy lejos de él. Siguiendo las indicaciones de este, se pone en camino. Cae accidentalmente por un pozo, pero providencialmente la inclinación de este le llevará hasta donde están Hans y su tío. Cuando vuelve en sí, ve que se encuentran junto a un mar: están en una caverna capaz de contener la cantidad de agua de un océano. Cerca de allí, hay un bosque de hongos donde hallan esqueletos de animales y de humanos.

Hans construye una balsa, y de ese modo embarcan e inician una travesía con el fin de alcanzar nuevas salidas en las orillas opuestas. El viaje por mar se hace más largo de lo que pensaban. Durante la travesía pescarán peces extintos del género pterichthyodes y se encuentran con monstruos marinos enormes, un ictiosaurio y un plesiosaurio pero por suerte los animales están luchando entre ellos y no se percatan de la presencia de la balsa.

Axel y sus dos acompañantes continúan el viaje con su monótona uniformidad. Pasan al lado de un islote, llamado por ellos "Islote de Axel", en el que hay un géiser de agua hirviendo a una temperatura de 163ºC.
Siguen su camino y les amenaza una tempestad, el viento sopla a una velocidad incalculable, los relámpagos no cesan, el calor aumenta. De repente ven un disco de fuego pasearse por el espacio a la velocidad de un huracán (posiblemente un rayo globular), que les arranca la vela con el mástil, y los tres amigos son arrastrados con gran rapidez hasta que la almadía choca con los arrecifes de la costa.

Axel y su tío se libran de la muerte gracias al guía, Hans, que los arranca del abismo tumbándolos en la arena de la playa. Consiguen rescatar la pólvora, la brújula, el manómetro y alimentos para cuatro meses, si bien han perdido las armas.

Con la ayuda de la brújula, comprueban su situación y ven que durante la tempestad han retrocedido en lugar de avanzar. Furioso y desafiando todos los peligros, el profesor Lidenbrock dice que han de volver a la balsa para seguir el viaje, pero antes quiere inspeccionar el lugar donde habían llegado a la deriva. Este lugar les reserva más sorpresas: un cementerio de cuerpos fosilizados en el cual hallan primero un cráneo humano y luego un cadáver entero semimomificado de la era cuaternaria. 

Siguen explorando el terreno y se alejan de la orilla del mar. Llegan a un bosque de vegetación de la era terciaria con palmeras, pinos, cipreses y helechos. Debajo de esos árboles ven agitarse unos mastodontes gigantes y lo que creen un ser humano de más de cuatro metros de altura con una cabeza del tamaño de un búfalo que los pastorea como si fueran ovejas. Les parece imposible y piensan que podría ser una visión, pero huyen a gran velocidad hacia el mar, donde han dejado la balsa. En su huida encuentran un puñal que perteneció a Arne Saknussemm, el alquimista que 300 años atrás hizo ese mismo viaje al centro de la Tierra, y más adelante en una roca encuentran grabadas sus iniciales, señalándoles el camino una vez más.

Según Lidenbrock, para llegar al centro del Globo aún tienen que bajar 1 500 leguas. Para seguir el viaje deben tomar una galería, pero una roca enorme obstruye la entrada y no les permite penetrar por ningún sitio. Optan por romper la roca con la pólvora que tienen. Preparan todo, encienden la mecha y se refugian en la almadía que tienen en la playa. No obstante, la extremada inestabilidad del terreno hace que la explosión provoque un terremoto y que el mar, convertido en una ola gigante, se los lleve violentamente a lo largo de diversas galerías. Pronto acabarán en una galería vertical, pero el agua entonces, al recobrar su nivel natural, empieza a subirles a gran velocidad, a modo de un ascensor superrápido. Los tres exploradores se consideran perdidos, viendo que a causa de la velocidad de su ascensión apenas pueden respirar y que el calor se hace insoportable.

Las paredes se mueven, los vapores se condensan... Son los síntomas de una erupción, y están dentro de la chimenea de un volcán en actividad. De repente, un movimiento giratorio se apodera de la balsa, que se balancea sobre las olas de lava en medio de una lluvia de cenizas, y salen disparados por el abrasador orificio del cráter.

Cuando Axel abre los ojos, comprueba que se hallan al aire libre, en la superficie de la tierra. Pero no están en Islandia sino en la isla de Estrómboli, Italia, en pleno Mediterráneo. Habían entrado por un volcán, el Snæfellsjökull, y han salido por el Estrómboli situado a más de 1 200 leguas del primero. Un cono de prodigiosa altura, coronado de humos, se divisa hacia el poniente: es el Etna. 

Axel y su tío regresan a casa. La noticia de su viaje al centro de la Tierra se había propagado por todas partes, pero nadie se había creído semejante aventura. No obstante, la presencia de Hans y varios informes llegados de Islandia cambian la opinión pública. El profesor Lidenbrock y Axel pasan a ser hombres famosos, y Hans regresa a su tierra natal de Islandia.

Al final del libro descubrirán que la indicación de la brújula por la cual habían creído retroceder era errónea: la bola luminosa con la que se encontraron en la tempestad había alterado los polos, haciendo que señalara el norte donde en realidad estaba el sur.

Principales
Secundarios




</doc>
<doc id="27993" url="https://es.wikipedia.org/wiki?curid=27993" title="Zenobia">
Zenobia

Septimia Bathzabbai Zainib (; ; ), más conocida como Zenobia (240-274), fue la segunda mujer del príncipe Septimio Odenato (castellanización del nombre Odenat) de Palmira, dependiente del Imperio romano, y reina del Imperio de Palmira entre 267 y 272, tras el asesinato de su marido en 267, cuando tomó el poder en nombre de su joven hijo heredero.

Aprovechando las disputas en el interior del imperio romano por el liderazgo del mismo, el reino de Palmira se sublevó e intentó crear su propio imperio con la intención de dominar a los dos que le flanqueaban, el romano y el sasánida. También tenían el incentivo de aprovechar el vacío de poder que el Imperio sasánida aún no había alcanzado a llenar. Las campañas militares de Zenobia le permitieron crear un imperio que abarcaba toda el Asia Menor e incluso logró tomar Egipto con sus tropas en el año 269, ya que allí se había levantado un posible candidato al trono romano. Zenobia logró deponer al pretendiente y reclamó la corona del imperio para su hijo. 

Gobernó Egipto hasta el año 272, cuando fue derrotada y enviada como rehén a Roma por el emperador Aureliano. A partir de este momento, el destino de Zenobia parece confuso. Existen múltiples teorías desde que una enfermedad acabó con la vida de Zenobia, hasta que fue una huelga de hambre o una ejecución por decapitación la causa de su muerte. La versión más optimista y aceptada cuenta que Aureliano quedó tan impresionado por Zenobia que la liberó, otorgándole una villa en Tibur (actual Tívoli, Italia) donde se convirtió en una filósofa destacada de la alta sociedad, viviendo como una matrona romana más.

La sociedad de Palmira era una amalgama de tribus semíticas (en su mayoría arameos y árabes) y Zenobia no puede ser identificada en ningún grupo; como ella era de Palmira, puede que tuviese sangre árabe y aramea. La información sobre sus ancestros y sus conexiones familiares inmediatos es escasa y contradictoria. No se sabe nada acerca de su madre y se discute la identidad de su padre, quien podría haber sido Zabaii ben Selim o Julio Aurelio Zenobio. Fuentes maniqueas mencionan a una "Nafsha", hermana de la "reina de Palmira", pero esas fuentes son confusas y "Nafsha" puede referirse a Zenobia misma; es dudoso que Zenobia tuviera una hermana.

La "Historia Augusta" contiene detalles acerca de su corta vida, aunque su grado de certeza es dudoso, en su niñez su pasatiempo era la caza y aparentemente no era una plebeya sino que habría recibido una educación apropiada para una noble muchacha de Palmira. Además de su lengua materna el arameo de Palmira, Zenobia era capaz de hablar en latín y fluidamente el arameo egipcio y el griego.

Alrededor de 255, con unos 14 años, Zenobia se convirtió en la segunda esposa de Septimio Odenato el "raz" (señor) de Palmira a partir de 258.Al casarse, adoptó el praenomen "Septimia", aunque firmaba con su nombre arameo "Bat-Zabbai". Con este matrimonio recibió un hijastro llamado Hairan, hijo del primer matrimonio de Odenato. 

Alrededor de 266 Odenato y Zenobia tuvieron un hijo, "Lucius Iulius Aurelio Septimio Vaballathus Atenodoro", más conocido como Vabalato.
En 267 su marido y su hijastro fueron asesinados por su sobrino y primo Meonio, y ella lo sentenció a muerte. Su hijo Vabalato tenía entonces solo un año de edad, por lo que Zenobia sucedió a su esposo y gobernó Palmira como regente del menor. A ambos les fueron otorgados los títulos honoríficos de Augusta y Augusto.

Tras la muerte de Galieno en 268 y viendo que su sucesor, Claudio el Gótico, tenía que dedicar todos sus esfuerzos a contrarrestar una invasión goda, Zenobia sublevó a Palmira e intentó crear su propio imperio. Su objetivo declarado era proteger el Imperio romano de Oriente del Imperio sasánida, por la paz de Roma, sin embargo, sus esfuerzos aumentaron significativamente el poder de su trono. Roma, envuelta en un nuevo periodo de caos debido a las distintas sucesiones, dejó a la reina de Palmira, que estaba bien asentada en su reino, intentar aspirar a crear un tercer imperio, con la intención de dominar a los dos imperios que le flanqueaban. 

Zenobia fortificó y embelleció la ciudad de Palmira, que contaba entonces con una población que superaba los 150.000 habitantes. Las murallas que rodeaban la ciudad, según se decía, tenían 21 kilómetros de circunferencia. Contaba con una avenida custodiada por grandes columnas corintias de más de 15 metros de altura. Estaba llena de hermosos templos, monumentos, jardines y edificios públicos, entre ellos destacaba el Templo del Sol. 

Zenobia mandó erigir en el año 271 un par de estatuas de ella y de su difunto esposo. También estatuas de héroes y de benefactores se encontraban por toda la ciudad, pidiendo a todos los nobles de la ciudad que mandaran esculpir sus estatuas y con ellas levantaran una columna en la que exhibirlas. Todos los notables de la ciudad, posaron ante los artistas para satisfacción de los ediles. En Palmira podían encontrarse cerca de doscientas estatuas en sus columnas y en las paredes del ágora.

Zenobia fue conquistando nuevos territorios, aumentando el territorio del Imperio de Palmira en memoria de su esposo y como legado a su hijo. 

En 269, Zenobia, su ejército, y el general Zabdas conquistaron violentamente Egipto con la ayuda de su aliado egipcio, Timágenes, y su ejército. El prefecto romano de Egipto, Probo Tenagino y sus fuerzas, trataron de expulsarles de Egipto, pero el ejército de Zenobia capturó y decapitó a Probo. Zenobia se proclamó reina de Egipto y acuñó monedas con su nombre. En ese momento su reino se extendía desde el Nilo hasta el Éufrates.

Después de estas incursiones iniciales, Zenobia llegó a ser conocida como la "reina guerrera del Este" al dirigir personalmente a su ejército, demostrando ser buena jinete, capaz de caminar tres o cuatro millas con sus soldados a pie.

Zenobia hizo expediciones con su gran ejército y conquistó Anatolia hasta Ancira y Calcedonia, y más tarde Siria, Palestina y el Líbano. En su imperio de corta duración, Zenobia tomó rutas de comercio vitales para los romanos.

El emperador Aureliano, subido al trono en el año 270, tras estabilizar la frontera del Danubio, decidió finalmente emprender una campaña militar contra ella. Mandó algunas de sus fuerzas hacia Egipto y el grueso de su ejército hacia el este a través de Asia Menor. Zenobia contaba con un gran ejército, formado por sus arqueros y catafractos comandado por dos generales, Zabdas y Zabbai. Pero Aureliano conquistó Egipto y lanzó sus fuerzas hacia Siria.

Zenobia fue derrotada en Emesa (actual Homs), y se retiró a Palmira, donde fue sitiada por Aureliano en 272. Palmira había hecho acopio de víveres y confiaba en la fuerza de sus excelentes arqueros, esperando resistir durante meses, pero gracias a los jefes árabes del desierto, que Zenobia había desdeñado, Aureliano venció la resistencia de la ciudad. Zenobia y su hijo se escaparon de allí en camello con la ayuda de los sasánidas, pero fueron capturados en el río Éufrates por los jinetes de Aureliano, y se ordenó que fueran llevados a Roma. El corto reinado de Zenobia sobre Egipto y el Imperio de Palmira había terminado. Los palmiranos restantes que se negaron a rendirse fueron capturados y ejecutados por orden de Aureliano.









</doc>
<doc id="27995" url="https://es.wikipedia.org/wiki?curid=27995" title="Molecularidad">
Molecularidad

La molecularidad es el número de moléculas que forman parte como reactivos en un proceso elemental, es decir, la suma de las moléculas de cada reactivo antes de formar el complejo activado para convertirse en los productos.

Es un concepto teórico que indica el nº de partículas individuales que participan en un paso elemental del mecanismo de reacción.

En los procesos (pasos) elementales del mecanismo de reacción pueden coincidir orden de reacción y molecularidad. No puede haber reacciones elementales con molecularidad superior a 3 (Termoleculares).

formula_1


formula_2


formula_3


formula_4


</doc>
<doc id="27996" url="https://es.wikipedia.org/wiki?curid=27996" title="Sofia Kovalévskaya">
Sofia Kovalévskaya

Sofía o Sonia Vasílievna Kovalévskaya o, como la traduce Sofía Casanova, Zofja Kowalewska (Moscú, 15 de enero de 1850-Estocolmo, 10 de febrero de 1891) () fue una matemática y escritora rusa que hizo contribuciones significativas en los campos del análisis, las ecuaciones diferenciales parciales y la mecánica. Fue la primera mujer que consiguió una plaza como profesora universitaria en Europa (Suecia, 1881). Su nombre en ocasiones se translitera como "Sophie, Sonya, Sonja o Sonia". Su apellido "Kovalévskaya" significa «la mujer de Kovalevski».

Nacida y criada en el seno de una familia gitana rusa de buena formación académica, Sofía era también descendiente de Matías Corvino, . Su abuelo, por casarse con una mujer gitana y estar emparentado con dicha etnia, perdió el título hereditario de príncipe. Por el lado paterno era de ascendencia polaca y entre sus ascendientes contaba con el cartógrafo Friedrich Schubert y el astrónomo Theodor von Schubert; por el lado materno era bielorrusa.

Desde los ocho años vivió en Palibino (Bielorrusia), en una casa donde se respiraba un denso ambiente cultural y científico. Amaba desde niña la lectura y la poesía, y llegó a cultivar con éxito la autobiografía, la novela y el teatro. Pronto adquirió un pensamiento muy independiente, influido por su hermana mayor, la socialista Anna Jaclard; además, dos de sus tíos le inculcaron el amor al saber: uno era un auténtico apasionado de la lectura y era un matemático aficionado; el otro le enseñó ciencias y biología. 

Bajo la guía del preceptor de sus hermanos Y. I. Malevich, Sofia comenzó sus primeros estudios reales de matemáticas. A los trece años empezó a mostrar muy buenas cualidades para el álgebra. Por esa época, escribió: «Comencé a sentir una atracción tan intensa por las matemáticas, que empecé a descuidar mis otros estudios». Pero su padre, un teniente general de artillería al que le horrorizaban las mujeres sabias, decidió interrumpir las clases de matemáticas de su hija. Aun así, Sofia siguió estudiando por su cuenta libros de álgebra y pidió prestado un ejemplar del "Álgebra" de Bourdeu que leía por la noche cuando el resto de la familia dormía. Así, aquello que nunca había estudiado lo fue deduciendo poco a poco. Un año más tarde, un vecino, el profesor Tyrtov, presentó a la familia de Sofia un libro del que él era autor, y Sofia trató de leerlo. No entendió las fórmulas trigonométricas e intentó explicárselas a sí misma.

A partir de los conocimientos que ya tenía, Sofia explicó y analizó por sí misma lo que era el concepto trigonométrico de seno, tal y como se desarrolló originalmente. Un profesor descubrió las facultades de Sofia, y habló con su padre para recomendarle que facilitara los estudios a su hija. Al cabo de varios años, su padre accedió, y Sofia comenzó a tomar clases particulares.

Los años de su adolescencia fueron años de rebelión, la época de las grandes revoluciones y manifestaciones del en las que el socialismo feminista iba perdiendo terreno. Su apellido de soltera era Korbin-Kukóvskaya, y era descendiente de un rey de Hungría. A los once años, se enamoró del escritor Fiódor Dostoyevski, quien llegó a cortejar a su hermana. Más tarde, al casarse a los 18 años, adoptó el apellido de su novio. 

Para poder seguir unos estudios científicos en el extranjero, puesto que Rusia no daba pasaportes a mujeres solteras, ni permitía que una mujer viviera separada de su familia, Kovalévskaya fue forzada a casarse a los 18 años con el paleontólogo evolucionista que era nihilista como ella, Vladimir Kovalevski; juntos viajaron a Viena. Y ella se inscribió en la Universidad de Heidelberg en 1869 y siguió allí los cursos de Hermann Ludwig von Helmholtz y Leo Königsberger. Estos profesores le aconsejaron marchar a Berlín a recibir clases de Karl Weierstraß o Weierstrass, pero de forma privada, las mismas que éste impartía en la universidad, ya que esta no permitía la formación de mujeres. Karl Weierstraß lo hacía con gusto, pues era una de sus mejores discípulas. Al mismo tiempo que estudiaba, comenzaba su trabajo de doctorado. Pero cuando estalló la Comuna de París (1871) Sofia marchó allí con su marido y su hermana Anna, apoyándola a ella y a su marido en la revolución desde abril hasta mayo de 1871, aunque no de forma activa: trabajaba en un hospital. Vuelta a Berlín, empezó a investigar sobre tres tesis en noviembre de 1872: dos memorias sobre matemáticas y una sobre astronomía. La primera era sobre ecuaciones con derivadas parciales, en la que consiguió corregir y mejorar un resultado de Cauchy (enunciando y demostrando lo que hoy se llama el Teorema de Cauchy-Kowalevski). La segunda era un estudio sobre las integrales abelianas, y la tercera explicaba la forma de los anillos de Saturno. Por estas tres memorias obtuvo el título de doctora "summa cum laude" en la Universidad de Gotinga en 1874, siendo la primera mujer en obtener este título no solo en Alemania, sino en el mundo (aunque ya Maria Gaetana Agnesi había obtenido uno en Bolonia en el siglo XVIII). Weierstrass le había buscado una universidad que aceptase doctorar a una mujer, por más que, como él decía, cada uno de estos tres trabajos hubiera bastado por sí solo para hacer una tesis doctoral; lo consiguió a condición de que no pasara el examen oral, esto es, Sofía se doctoró "in absentia". Con su marido, traductor de Charles Darwin al ruso, Sofia marchó a Inglaterra, donde ella conoció a la novelista George Eliot y al filósofo de la evolución Herbert Spencer.

Volvieron entonces a Rusia, pero ella no encontró modo de ejercer su oficio de matemática ni convalidar su título; además, una especulación inmobiliaria prácticamente arruinó a la pareja, que atravesó entonces por grandes estrecheces económicas, agravadas al nacerles una hija, Sofía, el 17 de octubre de 1878. Tras unos años de interrupción, volvió en 1880 a las matemáticas, aunque su marido subestimaba sus cualidades científicas; tradujo su disertación al ruso y la presentó a un congreso en ese mismo año. Para escapar de los acreedores se mudaron a Moscú, donde ella asistió regularmente a los eventos de la Sociedad Matemática de Moscú. Estaba nuevamente tan fascinada por las matemáticas que decidió viajar a Berlín durante dos meses para actualizarse y conectar con las investigaciones recientes. Como ya no podía ayudarlo, dejó en marzo de 1881 a su esposo, que ahora se había enredado en otro ruinoso negocio petrolero, y a finales de año se mudó a París con su pequeña hija. En 1882 ya había conocido a los matemáticos franceses más importantes y en julio fue aceptada en la Sociedad Matemática de París. Su marido se suicidó en condiciones horribles (ingiriendo formol) en abril de 1883. Y a fines de ese año viajó a Estocolmo.

Gracias a Gösta Mittag-Leffler, Sofía pudo trabajar a prueba durante un año en la Universidad de Estocolmo en 1884 como Privatdozent. La decisión no gustó nada a los machistas: en agosto de 1884 el dramaturgo August Strindberg escribió en un periódico lo siguiente:

Aunque empezó dando clases en alemán, a los seis meses ya había aprendido el sueco. Durante este tiempo, Sofía escribió el más importante de sus trabajos, que aportaba una nueva solución a uno de los problemas que más habían atribulado a matemáticos famosos: la rotación de cuerpo sólido en torno a un punto fijo, problema tan difícil que la Academia de ciencias de Berlín había propuesto un premio hacia 1850 sin obtener ningún resultado. Se conocían las soluciones de Euler y Lagrange, pero Kowalevska encontró el tercer y último caso que quedaba en el cual se podían resolver las ecuaciones, y las resolvió. Y por su trabajo innovador y original sobre este tema obtuvo el premio Bordin de la Academia de ciencias de París (1888), y el de la Academia de ciencias de Estocolmo al año siguiente. Además le dieron un puesto permanente de profesora en la Universidad de Estocolmo, convirtiéndose así en una de las primeras mujeres profesoras de universidad de Europa. Además, participó activamente en la redacción de la revista "Acta Mathematica", fundada por Mittag-Leffler.

Se suele pasar por alto que también fue escritora. Se le deben unos "Recuerdos de mi infancia", impresos con gran éxito en 1889; algunas piezas teatrales (en colaboración con Anne Charlotte Leffler) y una novela parcialmente autobiográfica, "Una nihilista" (1899), que fue traducida al español por la eslavista Sofía Casanova en 1909. 

Kovalévskaya guardó en secreto su lesbianismo, aunque hasta su muerte en 1891 matuvo una relación romántica con la escritoria Anne Charlotte Leffler, hermana del matemático Gösta Mittag-Leffler, y a la que conoció mientras eran estudiantes en Berlín. Falleció de neumonía a la temprana edad de cuarenta y un años, el diez de febrero de 1891.

Entre sus trabajos, figuran "Sobre la teoría de las ecuaciones diferenciales", que apareció en el "Journal de Crelle", y "Sobre la rotación de un cuerpo sólido alrededor de un punto fijo". El cuento homónimo del libro "Demasiada felicidad", de la Premio Nobel de Literatura Alice Munro, está inspirado en la vida de Kovalévskaya.





</doc>
<doc id="27997" url="https://es.wikipedia.org/wiki?curid=27997" title="Ascensor espacial">
Ascensor espacial

Un ascensor espacial es un ascensor hipotético que conecta la superficie de un planeta con el espacio.

Básicamente es una estación espacial en una órbita geosíncrona, y de la que parte un cable de 35.786 km de largo que llega hasta el suelo, y que puede tener forma de riel. Para mantener el equilibrio de la estructura, además de situar el anclaje en algún punto lo más cerca posible del ecuador, para minimizar los efectos de tensión por la diferencia entre la rotación de la Tierra y la órbita geosincrónica del satélite, los ponentes de esta tecnología futurista proponen utilizar un tramo de cable idéntico extendido hacia el espacio o bien un contrapeso, de tal suerte que el cable estaría en equilibrio con su centro de masas en órbita geosíncrona. Una vez el cable en su lugar, pueden subir y bajar por él naves y cargas a un coste unas cien veces menor que el que supone lanzarlas por medio de un cohete (prácticamente, el coste de la electricidad necesaria para impulsar el ascensor, que puede ser electricidad renovable procedente de placas solares situadas en el contrapeso).

El concepto fue formulado, tal y como se conoce hoy día, por el ingeniero ruso Yuri Artsutanov en 1960, dentro de un artículo del diario Pravda «В Космос — на электровозе» (traducido al inglés como ""To the cosmos by electric train""), aunque reconocía que la resistencia a la tracción necesaria para construir el cable no podía obtenerse con ningún material conocido en ese momento. Sin embargo, la idea de un ascensor espacial se remonta al 1895, concebida por el físico ruso Konstantin Tsiolkovsky.

Los ascensores espaciales eran hasta hace muy poco un tema exclusivo del género de la ciencia ficción, pues ningún material conocido podía soportar la enorme tensión producida por su propio peso. Actualmente ciertos materiales comienzan a parecer viables como materia prima: los expertos en nuevos materiales consideran que teóricamente los nanotubos de carbono pueden soportar la tensión presente en un ascensor espacial. Debido a este avance en la resistencia de los nuevos materiales, varias agencias están estudiando la viabilidad de un futuro ascensor espacial:

En Estados Unidos, un antiguo ingeniero de la NASA llamado Bradley C. Edwards ha elaborado un proyecto preliminar que también están estudiando científicos de la NASA. Edwards afirma que ya existe la tecnología necesaria, que se necesitarían 20 años para construirlo y que su costo sería 10 veces menor que el de la Estación Espacial Internacional. El ascensor espacial de Edwards no se parece a los presentes en las obras de ficción, al ser mucho más modesto y a la vez innovador en lo que concierne a su eventual método de construcción.

Edwards propone que el ascensor espacial se construya de manera análoga a como se construían los puentes en tiempos pasados: tendiendo una cuerda entre ambos extremos del obstáculo natural, y reforzar progresivamente la cuerda inicial con tramos cada vez más gruesos y resistentes. El elevador de Edwards sería una cinta extremadamente fina (unos cuantos nanómetros) de nanotubos de carbono, que sería lanzada al espacio de manera convencional. Una vez en órbita geosíncrona, la cinta sería descendida a la Tierra con la ayuda de un peso. La cinta sería tan ligera que la nave en la que fue lanzada serviría de contrapeso.

El cable sería recuperado al llegar a la superficie terrestre y anclado en una plataforma flotante en algún punto del ecuador. Con eso se terminaría la construcción del primer elevador espacial. Pese a su finura, la cinta de nanotubos de carbono sería lo suficientemente resistente para soportar el ascenso de un vehículo eléctrico de un centenar de kilogramos.

Edwards también propone utilizar tal capacidad de carga inicial no para carga, sino para reforzar el cable añadiendo más cintas a la primera, utilizando un vehículo eléctrico que montaría el cable sujetándose de él, tal proceso se repetiría hasta lograr construir un cable compuesto capaz de llevar a órbita geosíncrona la capacidad de carga deseada.

También las agencias europea y japonesa están trabajando en sus propios diseños. Asimismo, la Spaceward Foundation ha establecido diversos concursos y premios para quienes aporten mejoras para la construcción de dicho ascensor.

En noviembre de 2009 un proyecto desarrollado en Seattle en los Estados Unidos ganó un concurso apoyado por la NASA que tenía como objetivo diseñar un ascensor espacial basado en las ideas presentadas en la literatura científica y de ficción. La máquina ganadora, llamada "LaserMotive LLC" logró ascender 899 metros a lo largo de un cable que colgaba desde un helicóptero e impulsada por un motor eléctrico el cual recibía su carga a partir de un conjunto de celdas voltaicas que convertían en energía eléctrica la luz emitida por un láser en tierra que apuntaba directamente a la máquina.

Esta máquina consiguió mediante este método ascender los 899 metros de cable en tres minutos y 48 segundos por lo cual se le entregó un premio de 900.000 dólares por parte del Proyecto Retos Centenarios de la NASA.

Hay una cierta disputa entre Arthur C. Clarke y Charles Sheffield como introductores del concepto en una obra de ficción. El primero introdujo el concepto a una audiencia más amplia en su novela "Las fuentes del paraíso" (en inglés "The Fountains of Paradise") de 1978; en dicha obra, los ingenieros construyen un ascensor espacial en la cima de la isla ecuatorial de Taprobane (que tiene cierta semejanza con Sri Lanka). Charles Sheffield menciona un ascensor espacial en su novela "La telaraña entre los mundos", que fue terminada unos meses antes, aunque no logró publicarla hasta después de aparecer la novela de Clarke. 

Los ascensores espaciales se han convertido en una figura recurrente de la ciencia ficción dura, al ser uno de los pocos métodos eficientes para colocar grandes cargas en órbita. Los ascensores espaciales son argumentos narrativos en obras tales como:





</doc>
<doc id="27998" url="https://es.wikipedia.org/wiki?curid=27998" title="Delta">
Delta

Delta puede referirse a:

La diferencia entre dos valores próximos de una magnitud y varias funciones y operadores:


Un delta fluvial es un accidente geográfico producido por el depósito de sedimentos en la desembocadura de un río.
















</doc>
<doc id="27999" url="https://es.wikipedia.org/wiki?curid=27999" title="K-Pax">
K-Pax

K-PAX es una película coproducida entre Estados Unidos y Alemania. Basada en la novela K-PAX de Gene Brewer. Ha habido mucha controversia en torno a su argumento, ya que se la acusa de plagiar la película argentina "Hombre mirando al sudeste", de Eliseo Subiela, con un punto de partida prácticamente idéntico. La denuncia fue retirada posteriormente.

En un hospital psiquiátrico uno de los pacientes que se hace llamar Prot (Kevin Spacey) declara ser de otro planeta. Su médico (Jeff Bridges) intenta ayudarle y hacerle volver a la realidad. A lo largo de su estancia en el hospital psiquiátrico Prot hace dudar al mismísimo doctor, así como al resto del personal del centro y los pacientes sobre su verdadera identidad, demostrando conocimientos sobre el campo de la astronomía que ningún ser humano conoce, así como ayudando a los pacientes del centro a curarse de sus enfermedades mentales. El médico de Prot siente que éste "lo ha elegido" con lo cual sigue atendiéndolo a pesar de que se intenta trasladar a Prot a otro nivel del hospital psiquiátrico. Mediante hipnosis a la que es sometido Prot, Powell obtiene información que lo guía a una pequeña ciudad y a la aparente identidad de Prot, junto a su historia: siendo casi un genio, decide casarse con su novia (embarazada) de secundaria y trabajar al lado de su padre en un matadero, para mantener a su familia. Un día, regresando del trabajo, descubre con horror que un exconvicto ha violado y asesinado a su mujer y a su hija, por lo que lo mata y luego se mete en un río cercano con intención de suicidarse. Oficialmente, nunca fue procesado pues desapareció y el sherif del lugar tampoco tiene interés en ubicarlo, pues comprende el actuar de Prot. Esto explica parte de su comportamiento, pero lo inexplicable se produce al llegar el plazo de término de la "visita" de Prot al planeta, fecha en que el doctor temía que se suicidara, cosa que no ocurre, sino que queda en estado catatónico (dejando abierta la posibilidad de que la entidad extraterrestre haya abandonado el cuerpo dejándolo como un recipiente vacío o que, en caso de ser sólo un enfermo mental, que dicha enfermedad terminase por cortar sus vínculos con la realidad), al tiempo que una de las pacientes del hospital desaparece, entendiendo los demás que fue ella la elegida para acompañar a Prot a K-pax, el supuesto planeta de donde provenía. Al final de la película se puede ver el reencuentro de Powell y su hijo con quien estaba distanciado, pero que gracias a Prot logra amistarse.



</doc>
<doc id="28001" url="https://es.wikipedia.org/wiki?curid=28001" title="La noche de la iguana">
La noche de la iguana

La noche de la iguana es una película estadounidense de 1964 dirigida por John Huston, basada en la obra de teatro homónima de Tennessee Williams. Protagonizada por Richard Burton, Deborah Kerr y Ava Gardner en los papeles principales, ganó un premio Óscar al mejor diseño de vestuario (Dorothy Jeakins), y fue nominada a la mejor actriz de reparto (Grayson Hall), a la mejor dirección artística (Stephen Grimes) y a la mejor fotografía (Gabriel Figueroa). El rodaje atrajo mucha atención de la prensa, que perseguía a las estrellas por los platós para conseguir información y fotos de la reciente pareja Elizabeth Taylor y Richard Burton.

Fue filmada en 1963 en las primeras escenas en la iglesia de San Francisco Javier en Tepotzotlán Méx y Puerto Vallarta, Jalisco, México, y sus alrededores (playa Mismaloya).

Un sacerdote anglicano retirado y alcohólico (Richard Burton) sufre una severa crisis emocional mientras preside una ceremonia eclesiástica. Como resultado decide retirarse a México, viéndose obligado a tomar la ocupación de guía turístico de maestras estadounidenses, en su mayoría solteras. Durante su último tour, es víctima de los audaces avances románticos de una jovencita (Sue Lyon) que hace todo lo posible por seducirlo, y se gana el odio del resto de las damas de la expedición. La jefa del grupo despide al guía por su comportamiento. Al borde de otra crisis nerviosa, arriba a Puerto Vallarta y se refugia en el colorido hotel de una vieja amiga, Maxine (Ava Gardner), con la que mantiene una buena relación. Allí conocerá a Hannah (Deborah Kerr), mujer rígida y anticuada que se dedica a la pintura itinerante, y que viaja siempre en compañía de su abuelo, un inspirado poeta de casi cien años. Las relaciones del guía con todas estas mujeres le marcarán para el futuro.



</doc>
<doc id="28002" url="https://es.wikipedia.org/wiki?curid=28002" title="Alguien a quien amar">
Alguien a quien amar

Alguien a quien amar (1994) es una extraña película independiente, triste y optimista a la vez. Dirigida por Alexandre Rockwell y protagonizada por Rosie Pérez. 

Mercedes (Rosie Pérez) es una bailarina de discoteca que aspira a ser actriz. Mantiene una relación con Harry (Harvey Keitel), que está casado y se considera a sí mismo un actor apreciado por el público. Otro hombre está enamorado de Mercedes, pero no tiene dinero ni sabe cómo conseguir que ella se interese por él.


</doc>
<doc id="28003" url="https://es.wikipedia.org/wiki?curid=28003" title="American Buffalo">
American Buffalo

American Buffalo es una película estadounidense, dirigida por Michael Corrente y estrenada en el año 

Donny (Dennis Franz) es propietario de una misera tienda en el centro de la ciudad, donde se reúne cada día con sus dos amigos y hace planes para el futuro. Teach (Dustin Hoffman) es demasiado corto u obcecado para reconocer lo que la vida le ha dado, y no hace más que quejarse. Bobby (Sean Nelson) es un adolescente que no aprovecha las experiencias que le cuentan los otros dos y que podrían serle útiles ya que es el único de ellos que aún tiene ocasión de orientar su vida de forma positiva. De todo ello sale un plan que cada uno ve de manera diferente.

Está basada en la obra de teatro homónima de David Mamet.


</doc>
<doc id="28004" url="https://es.wikipedia.org/wiki?curid=28004" title="Procedimiento ilegal">
Procedimiento ilegal

Procedimiento ilegal es una película estadounidense de 1987, del género comedia policíaca, con ingredientes románticos y de suspense, dirigida por John Badham. Protagonizada por Richard Dreyfuss, Emilio Estévez, Madeleine Stowe, Aidan Quinn y Forest Whitaker en los papeles principales. El film fue rodado en Vancouver, British Columbia.

La película fue un éxito de crítica y público. Ganadora del premio BMI Film Music Award 1988 (Arthur B. Rubinstein), y del premio Edgar Allan Poe Awards 1988 a la Mejor película (Jim Kouf).

Tuvo una secuela en 1993; "Another Stakeout".

A los policías Chris Lecce (Richard Dreyfuss) y Bill Reimers (Emilio Estévez) se les encomienda vigilar a una mujer joven (Madeleine Stowe), cuyo exnovio (Aidan Quinn), un delincuente que se ha fugado de prisión, podría ponerse en contacto con ella. El aburrimiento durante la vigilancia se hace cada vez más insoportable, hasta que Lecce entra ilegalmente en la casa de la mujer y posteriormente la conoce. Entretanto, el preso fugado se dirige a la casa de su exnovia.


La película recibió generalmente críticas positivas, manteniendo un 87% en Rotten Tomatoes y un 6,6/10 en IMDb. La película fue número uno su primera semana. Acabó recaudando 65,6 millones de dólares y fue el octavo film más visto de ese año en Estados Unidos.



</doc>
<doc id="28007" url="https://es.wikipedia.org/wiki?curid=28007" title="Ascensor">
Ascensor

Un ascensor o elevador es un sistema de transporte vertical, diseñado para mover personas u objetos entre los diferentes niveles de un edificio o estructura. Está formado por partes mecánicas, eléctricas y electrónicas que funcionan en conjunto para ponerlo en marcha. 

De acuerdo a su método de funcionamiento existen dos tipos: el ascensor electromecánico y el ascensor hidráulico u oleodinámico.

La primera referencia a un ascensor aparece en las obras del arquitecto romano Vitruvio, quien sostiene que Arquímedes (ca. 287 a. C. – ca. 212 a. C.) había construido el primer elevador probablemente en el año 236 a.C. Fuentes literarias de épocas posteriores mencionan ascensores compuestos de cabinas sostenidas con cuerda de cáñamo y accionadas a mano o por animales. Se estima que ascensores de ese tipo estaban instalados en un monasterio de Sinaí, Egipto.

Hacia el año 1000, en el "Libro de los Secretos" escrito por Ibn Khalaf al-Muradi, de la España islámica se describe el uso de un ascensor como dispositivo de elevación, a fin de subir un gran peso para golpear y destruir una fortaleza. 

En el siglo XVII, había prototipos de ascensores en algunos edificios palaciegos ingleses y franceses.

Los ascensores antiguos y medievales utilizaban sistemas de tracción basados en el mecanismo de la grúa. La invención de otro sistema basado en la transmisión a tornillo, fue tal vez el paso más importante en la tecnología del ascensor desde la antigüedad, que finalmente condujo a la creación de los ascensores de pasajeros modernos. El primer modelo fue construido por Ivan Kulibin e instalado en el Palacio de Invierno en 1793, mientras que varios años más tarde, otro ascensor Kulibin fue instalado en Arkhangelsk, cerca de Moscú. En 1823, se inaugura una "cabina de ascensor" en Londres.

En 1851, Waterman inventó el primer prototipo de montacargas. Se trataba de una simple plataforma unida a un cable, para subir y bajar mercancías y personas.

A medida que se fueron construyendo edificios más altos, la gente se sintió menos inclinada a subir escaleras largas. Los grandes almacenes comenzaron a prosperar, y surgió la necesidad de un aparato que trasladara a los clientes de un piso a otro con mínimo esfuerzo. 

El montacargas inspiró al estadounidense de Vermont, Elisha G. Otis, para inventar un elevador con un sistema dentado, que permitía amortiguar la caída del mismo en caso de que se cortara el cable de sustento. Fue la primera demostración de un sistema de seguridad para elevadores de pasajeros. 

Por extraño que parezca, el talento de Elisha Otis como diseñador se descubrió mientras trabajaba como maestro mecánico en una fábrica de armazones de camas de Albany (estado de Nueva York). Inventó varios dispositivos que ahorraban trabajo, y por eso fue enviado a Yonkers (Nueva York), donde podría utilizarse mejor su aptitud. Allí diseñó y construyó este primer ascensor con mecanismo automático de seguridad en caso de que hubiera alguna avería en el cable. En 1853 ya había establecido su propio negocio para fabricar ascensores, la compañía Otis Elevator Company, que aún existe en la actualidad y es la mayor compañía de ascensores del mundo ya que ha instalado 2,5 millones de elevadores y escaleras mecánicas por todo el planeta. Al año siguiente Otis demostró este invento en una exposición que se llevó a cabo en Nueva York.

El 30 de agosto de 1957 se aplicó un sistema de puertas automáticas en los ascensores de pasajeros, lo que permitió prescindir de puertas actuadas manualmente.

Otro tipo de ascensor es el conocido como "paternoster"; consiste en una serie de cabinas abiertas, de capacidad limitada, que se mueven lentamente por dos huecos contiguos. Por uno suben las cabinas y, al llegar a la parte superior, se cambian al otro hueco por el que bajan en un ciclo continuo, sin detenerse. Los pasajeros suben y bajan en marcha. Era muy práctico en lugares de mucha circulación de personas entre pisos, aunque tenía problemas de seguridad, por lo que fue sustituido por las escaleras mecánicas, mucho más seguras.
Los comercios pronto se dieron cuenta del potencial del invento, y en 1857 se instaló el primer ascensor de pasajeros en un gran almacén ubicado en la avenida Broadway, esquina calle Broome, en la ciudad de Nueva York, Estados Unidos. Movido a vapor, este elevador subía cinco pisos en menos de un minuto. En aquel entonces, eso era rápido. En contraste con eso, hoy los ascensores de uno de los edificios más altos del mundo, la Torre Willis, en Chicago, suben 412 metros en menos de un minuto. En la actualidad, el edificio más alto del mundo, la Torre Burj Khalifa en Dubái, con 828 m de altura, tiene ascensores de la compañía Otis Elevator Company que suben la distancia más larga del mundo: 504 metros; también tiene el acceso de ascensor situado a mayor altura del mundo: a 638 metros; y el ascensor con doble cabina más rápido del mundo: 10 metros por segundo.

La cabina es el elemento básico del sistema de ascensores. Está formada por dos partes: el bastidor o chasis y la caja o cabina, o por una cabina autoportante.

La mayoría de los ascensores tienen un contrapeso, que tiene una masa igual a la de la cabina, más la mitad de la carga máxima autorizada, para que el motor no tenga que mover toda la masa de la cabina, sino solo una fracción. Debido a ello, un ascensor vacío, pesa menos que el contrapeso. El contrapeso también está conducido por unas guías. Su función es equilibrar la carga para facilitar el trabajo del motor y no forzarlo en su funcionamiento.

Los grupos tractores para ascensores están formados normalmente por un motor acoplado a un reductor de velocidad, en cuyo eje de salida va montada la polea acanalada que arrastra los cables por adherencia.

En los extremos inferior o superior del bastidor de la cabina, se encuentra el sistema de paracaídas, ya sea instantáneo o progresivo. Este libera unas cuñas contra las guías para frenar la cabina en caso de que baje a una velocidad mayor que la permitida por el limitador, impidiendo así que la cabina caiga libremente incluso en el caso de que se cortaran todos los cables que la sujetan. En los ascensores modernos y según normativa de cada país o región también frena en subida.

En ocasiones, se instala también un sistema de frenado en el contrapeso. Por ejemplo, cuando debajo del suelo del foso hay zona de paso de personas como un estacionamiento de automóviles. Si el contrapeso que puede pesar 700 kg cayera en caída libre podría romper el suelo del foso y dañar a personas que estuvieran en la zona de debajo del ascensor.

El control de los sistemas de ascensores se realiza mediante sistemas electrónicos, encargados de hacer funcionar la dirección de movimiento de la cabina y de seleccionar los pisos en los que esta deba detenerse.

En 1862 la compañía de ascensores Otis inventó el primer sistema de control con "memoria" para grupos de ascensores, lo que permitió su automatización y prescindir de los ascensoristas.

Actualmente, los controles de ascensores funcionan con microprocesadores electrónicos que mediante algoritmos de inteligencia artificial determinan la forma de administrar la respuesta a los pedidos de llamadas coordinando la operación de los distintos equipos.

Los cuadros de maniobra actuales tienen un sistema de información de errores, que en caso de avería muestran en una pantalla el código de error de tal forma que el mecánico del ascensor sepa cuál ha sido el motivo de que el ascensor se detuvo. 

Un ascensor cuenta con múltiples dispositivos de seguridad para evitar cualquier riesgo de accidentes y en cuanto cualquier dispositivo falla el ascensor queda automáticamente detenido. Cualquier elevador por antiguo que sea tiene contactos en: las puertas exteriores, puertas de cabina, contacto de rotura de cables (actualmente ya no se montan), de disparo de polea del limitador superior, de aflojamiento de cable en polea de limitador inferior, de acuñamiento en cabina, etc. En cuanto cualquiera de estos contactos falle, el ascensor se parará indicando el contacto o dispositivo que ha fallado.

La seguridad del sistema es un elemento clave en los ascensores. Para maximizar la seguridad se emplean varios dispositivos específicos:

En el acceso a los pisos, que hace imposible la apertura de todas las puertas de acceso excepto la del piso en que se halla detenida la cabina.

Todas las cerraduras, una en cada rellano, tienen un fleje o un brazo con una ruedita, que al ser oprimido permite el destrabe de la puerta, y solo cuando está mecánicamente trabada mediante el gancho de doble uña, se cierra el contacto eléctrico del enclavamiento que permite que llegue alimentación a las bobinas de los contactores, y se permite el movimiento del ascensor. Hay dos tipos de mecanismos que permiten abrir las puertas exteriores cuando la cabina llega a planta. En los ascensores antiguos hay un elemento llamado electroleva, que es el encargado de oprimir el fleje de la puerta del piso de destino. Esta electroleva es retráctil, es decir, viaja con la cabina retraído para no oprimir los flejes de cada piso por el que va pasando (lo que permitiría la apertura de cada una de las puertas y la detención del ascensor), por lo que solo cuando el control de maniobras le indica mediante una señal eléctrica que la cabina se encuentra en la parada pertinente, la electroleva se expande y acciona el fleje de la puerta correspondiente. El proceso inverso se da cuando el ascensor es requerido desde otro sitio: la electroleva se retrae antes de la partida y solo se expande al llegar a él. En los ascensores modernos hay otro tipo de mecanismos. Si las puertas exteriores son automáticas, es decir se abren por sí mismas, una de las hojas de cabina lleva instalado un patín retráctil que abre la puerta exterior al mismo tiempo que abre la interior de la cabina. Si las puertas exteriores son manuales o semi-automáticas (las abre la persona que va a entrar en el ascensor y se cierran solas), las puertas de cabina incorporan un patín que empuja la polea de la cerradura o palanca del enclavamiento para permitir abrir la puerta exterior.

Existen instantáneos y también progresivos, para ascensores de alta y media velocidad. Consiste en un sistema de palancas cuyo movimiento acciona unas cuñas o rodillos que se encuentran en una caja junto a las guías (caja de cuñas). Cuando se da la caída de la cabina o sobrepasa la velocidad nominal , las guías son mordidas por las cuñas o rodillos y se produce la detención de la cabina.

Lo componen dos poleas: una instalada en el cuarto de máquinas y otra alineada verticalmente con la primera en el fondo del hueco. A través de ambas pasa un cable de acero cuyos extremos se vinculan, uno a un punto fijo del bastidor de la cabina, y otro a un sistema de palancas cuyo extremo se encuentra en la parte superior del bastidor. El cable acompaña a la cabina en todo momento y es absolutamente independiente de los cables de tracción, es decir, no interviene en la sujeción de la cabina y el contrapeso. En la polea superior del limitador se produce la detención brusca del cable cuando la velocidad de dicha polea (y por tanto la de la cabina) supera el 25% de la velocidad nominal. El cable limitador activa el sistema de palancas, llamado paracaídas. Asimismo incorpora un contacto eléctrico tanto en el mecanismo de acuñamiento de la cabina como en la polea superior que corta la serie principal para evitar que el motor siga funcionando una vez que la cabina ha quedado "clavada" a las guías mediante el mecanismo de acuñamiento. Este mecanismo fue patentado por Rubén Lorenzo Curiel en 1853.

Interrumpen la alimentación cuando la cabina rebasa los extremos en ascenso o en descenso.

La cabina de un ascensor eléctrico no puede aplastarse nunca contra el techo del hueco dado que poco después de sobrepasar el final de carrera de subida, el contrapeso ya se apoya en el muelle del foso y la polea tractora que mueve los cables, pierde la tracción.
En un ascensor hidráulico pasa lo mismo, pero por la medida del pistón. Pocos centímetros después que la cabina pase el final de carrera superior, en vástago del pistón no se puede extender más puesto que hace tope dentro del pistón y en los topes de las guías. 
Interrumpe la maniobra, corta la alimentación del grupo tractor y actúa el freno. Permite la detención del ascensor dejando sin efecto los mandos de cabina y pisos. Normalmente deja bajar la cabina a la parada más baja. Si nos referimos al STOP o PARADA normalmente debe dejar parar la cabina en la parada siguiente tanto hacia arriba como abajo. Este sistema de emergencia también se puede denominar "Rescata-matic". En ascensores antiguos, la pulsación del botón de PARADA o STOP, producía una detención instantánea de la cabina, pudiendo el viajero quedar atrapado entre dos pisos sin posibilidad de salida. En los modelos actuales, este botón ha dejado de existir en los tableros de cabina, quedando únicamente el botón de alarma como dispositivo de emergencia en manos del usuario.

Para que lo utilicen los pasajeros en caso de emergencia. En ocasiones está conectado a una línea de teléfono desde la que se puede solicitar asistencia en caso de quedar atrapado.

Ilumina la cabina en caso de que el alumbrado normal sea interrumpido. 

Debe existir una fuente de socorro, de recarga automática que sea capaz de alimentar al menos una lámpara de un vatio durante una hora, en el caso de interrupción de la corriente de alimentación del alumbrado normal. El alumbrado de emergencia debe conectarse automáticamente desde que falle el suministro del alumbrado normal.

En los ascensores modernos suele instalarse un dispositivo llamado pesacargas. La función de este elemento es evitar que el ascensor mueva más peso del máximo permitido, evitando así el desgaste excesivo del grupo tractor y los frenos. Hay varios tipos de sistema de pesacargas y en la actualidad todos ellos son digitales, por lo que tienen una exactitud bastante elevada. 

En ascensores antiguos a los que quiera adaptarse un sistema de pesacargas, se suele emplear un mecanismo que consta de unos sensores que se adaptan en los cables de tracción y una centralita que recoge la información dada por los sensores. Esta centralita está conectada a su vez a la caja de revisión del ascensor, por lo que el cuadro de maniobra sabe en cada momento si el ascensor tiene más peso del permitido.

En los ascensores nuevos, el sistema es parecido, pero los sensores se colocan entre el suelo de la cabina y el chasis, permitiendo una exactitud todavía mayor.

Los cuadros de maniobra tienen 3 estados diferentes en lo que al pesacargas se refiere:


La construcción y característica de los grupos tractores y de los motores con que estos van equipados, varían según sea la velocidad nominal del ascensor y del servicio que deben prestar.

Se le llama así al sistema en suspensión compuesto por un lado por una cabina, y por el otro por un contrapeso, a los cuales se les da un movimiento vertical mediante un motor eléctrico. Todo ello funciona con un sistema de guías verticales y consta de elementos de seguridad como el amortiguador situado en el foso (parte inferior del hueco del ascensor) y un limitador de velocidad mecánico, que detecta el exceso de velocidad de la cabina para activar el sistema de paracaídas, que automáticamente detiene el ascensor en el caso de que esto ocurra. 

El ascensor eléctrico es el más común para transporte de personas a baja y alta velocidad (superior a 0,8 m/s), elevadores con alta exigencia de confort (hospitales, hoteles) o elevadores que sirven más de 6 pisos.

Los grupos tractores con motores de una velocidad solo se utilizan para ascensores de velocidades no mayores de 0,7 m/s. Por lo general, se instalan en ascensores de viviendas de 300 kg o 4 personas de carga máxima.

Su nivel de parada es muy impreciso y varía mucho con la carga, incluso es distinto en subida como en bajada. En muchos países está prohibida su instalación para nuevos ascensores por su falta de precisión en la parada.

Los grupos tractores de dos velocidades poseen motores trifásicos de polos conmutables, que funcionan a velocidad rápida y otra lenta según la conexión de los polos. De esta manera se obtiene con una velocidad de nivelación baja un frenado con el mínimo de error (aproximadamente 10 mm de error) y un viaje más confortable.

Estos grupos tractores en la actualidad están siendo retirados, ya que consumen demasiada energía y son algo ruidosos.

La aceleración en la arrancada y la desaceleración antes de que actúe el freno se llevan a cabo mediante un variador de frecuencia acoplado al cuadro de maniobra. El freno actúa cuando el ascensor está prácticamente parado y se consigue así una nivelación y un confort que superan incluso los del sistema de dos velocidades.

En los ascensores hidráulicos el accionamiento se logra mediante una bomba, acoplada a un motor eléctrico, que inyecta aceite a presión, por unas válvulas de maniobra y seguridad, desde un depósito a un cilindro, cuyo pistón sostiene y empuja la cabina, para ascender. En el descenso se deja vaciar el pistón del aceite mediante una válvula con gran pérdida de carga para que se haga suavemente. De este modo el ascensor oleodinámico solamente consume energía en el ascenso. Por el contrario, la energía consumida en el ascenso es cuatro veces superior a la que consume el ascensor electro-mecánico, por lo que el resultado es que, por término medio, consumen más o menos el doble que estos. Este tipo de ascensor, no tiene contrapeso.

El grupo impulsor realiza las funciones del grupo tractor de los ascensores eléctricos, y el cilindro con su pistón la conversión de la energía del motor en movimiento.

El fluido utilizado como transmisor del movimiento funciona en circuito abierto, por lo que la instalación necesita un depósito de aceite. La maquinaria y depósito de este tipo de ascensor pueden alojarse en cualquier lugar, situado a una distancia de hasta 12 metros del hueco del mismo, con lo cual permite más posibilidades para instalar este ascensor en emplazamientos con limitación de espacio.

Son los más seguros, más lentos y los que más energía consumen, aunque son los más indicados para instalar en edificios sin ascensor.

Actualmente se está generalizando el ascensor eléctrico sin cuarto de máquinas o MRL ("Machine Room Less"). Las ventajas desde el punto de vista arquitectónico son claras: el volumen ocupado por la sala de máquinas de una ejecución tradicional desaparece, ahorrando los costes de la tradicional sala de máquinas, pudiendo ser aprovechada para otros fines o haciendo posible que se pueda llegar con el ascensor hasta la terraza o planta más alta donde anteriormente se situaba la sala de máquinas. En este tipo de ascensores se suelen utilizar motores "gearless" de imanes permanentes, accionados mediante una maniobra con control por variador de frecuencia, situados en la parte superior del hueco sobre una bancada directamente fijada a las guías, que están ancladas a cada forjado. Con ello, las cargas son transferidas al foso en lugar de transmitirse a las paredes del hueco, evitando así vibraciones y molestias a las viviendas adyacentes.

La empresa alemana ThyssenKrupp Elevator es el primer fabricante de ascensores en inventar e implantar un sistema de dos cabinas viajando independientemente en un mismo hueco de ascensor. Gracias a un extraordinario trabajo de ingeniería y un avanzado sistema de control, con un concepto de alta seguridad, es posible que operen las dos cabinas de forma independiente, creándose inmensos beneficios potenciales para su uso en nuevas instalaciones y en modernizaciones de edificios.

El corazón del sistema es un control de selección de destino, capaz de asignar de manera inteligente a cada ascensor las llamadas de los distintos pisos. Cuando un usuario llama a un ascensor desde el pasillo, antes de que el pasajero entre allí, recoge la información de la planta en la que está y a la que se dirige, y le asigna el elevador más adecuado para su trayecto.

La principal ventaja de este sistema, es que incrementa la capacidad de transporte de los ascensores del edificio, utilizando un menor volumen de construcción y de espacio.

Para lograr un funcionamiento más eficaz, los sistemas de ascensores más modernos poseen una memoria que almacena los pedidos de llamada y los atienden priorizando las peticiones que están en dirección al coche, según distintos algoritmos de funcionamiento:

Las botoneras colocadas en los pasillos de los pisos terminales poseen un solo botón.

En subida:
El ascensor va deteniéndose en todos los pisos marcados desde la cabina, pero no atiende ninguna llamada de piso, salvo la del piso más alto por encima del último registrado por los pasajeros. Una vez llegada la cabina al último piso cuya llamada haya sido registrada, y pasado un tiempo sin nuevos pedidos, el ascensor cambia de dirección.

En bajada:
El ascensor va deteniéndose en todos los pisos registrados en la cabina y también atiende los pedidos de llamada de los pisos, que supone son de bajada, hasta llegar al piso inferior que tenga un pedido de atención. En caso de que el ascensor disponga de dispositivo pesacargas el elevador no parará en las plantas intermedias si la cabina tiene la carga completa.

Las botoneras colocadas en los pasillos de los pisos intermedios poseen dos botones: uno para pedidos de subida y otro para bajada.

En subida:
El ascensor va deteniéndose en todos los pisos marcados desde la cabina y también en los pedidos de piso marcados como subida, pero no los de bajada. Al llegar al piso más alto por encima del último registrado por los pasajeros o desde los rellanos, y pasado un tiempo sin nuevos pedidos, el ascensor cambia de dirección.

En bajada:
El ascensor va deteniéndose en todos los pisos registrados en la cabina y también atiende los pedidos de llamada de los pisos en bajada pero no los de subida, hasta llegar al piso inferior que tenga un pedido de atención.

Los modernos ascensores disponen de avanzados sistemas de inteligencia artificial con algoritmos lógicos que maximizan el rendimiento de los equipos coordinando las operaciones de cada uno, para lograr acelerar la atención de llamadas y aumentar la capacidad de transporte.

Este modo de funcionamiento, llamado "en batería", logra una máxima eficiencia mediante índices que calculan varias veces por segundo las circunstancias de funcionamiento en que se halla cada equipo, decidiendo cuál de todos posee una situación más ventajosa frente al conjunto para atender el pedido de llamada.

Los equipos de última generación emplean un microprocesador especialmente para realizar la tarea de coordinación, debido a la gran cantidad de variables y datos en tiempo real que tienen en cuenta los complejos algoritmos.

En teoría un cuerpo que cayera de 443 m de altura se precipitaría a una velocidad de 320 km/h. Pero esos ascensores están dotados de mecanismos de seguridad.

El perfeccionamiento de los ascensores modernos tuvo sus orígenes en 1854, cuando el ingeniero estadounidense Elisha Graves Otis instaló el primer mecanismo de seguridad en un elevador de carga, en la exposición del Palacio de Cristal en New York. Antes, los elevadores de ese tipo eran muy inseguros: sus cables se rompían con frecuencia y, en ocasiones se producían accidentes mortales.

Con cierto espíritu teatral, Otis hizo una demostración de su elevador: se subió en él, junto con cajas, barriles y demás cargas; luego ordenó que cortaran el cable. En los montacargas anteriores, esto hubiera sido mortal. Pero el mecanismo de seguridad funcionó y el elevador se detuvo inmediatamente.

¿El secreto de Otis? Un recio muelle fijado en la parte superior de la plataforma del elevador. Al subir la plataforma, el muelle se arqueaba y sus extremos no tenían contactos con los rieles guía que había en cada lado. Pero al cortar el cable, el muelle recuperaba su forma y sus extremos se trababan en los rieles evitando así el desplome.
En 1857, Otis instaló el primer elevador de pasajeros, en un edificio de cinco pisos de Broadway, New York. La invención del elevador de seguridad fue un factor decisivo en la aparición de los rascacielos. Antes los edificios eran de un máximo de seis pisos, ya que la gente se oponía a subir demasiadas escaleras, por lo agotador.
El elevador de pasajeros y las técnicas de construcción con estructuras de hierro, proporcionaron los medios para las edificaciones de gran altura.

Los ascensores modernos no difieren en esencia del modelo Otis. Consisten en una cabina que se iza, mediante cables de acero, por dos rieles guía, y cuentan además con un mecanismo de seguridad que impide el desplome.
Los cables salen de la cabina y van hasta una polea situada en la parte superior del cubo del elevador, y que es accionada por un motor. Los cables bajan por la fuerza de un contrapeso que corre por rieles guía. 

Un componente clave de la protección es el limitador de velocidad, que está unido por medio de un cable al dispositivo de seguridad montado debajo de la cabina del elevador.

El limitador se sirve de la velocidad, cuando alcanza una velocidad superior a la velocidad nominal del elevador este dispositivo se enclava a su vez y por medio de la fricción jala al cable y este activa al sistema de paracaídas montado en la parte inferior de la cabina, momentos antes de que se enclave el limitador de velocidad se activa un contacto eléctrico lo cual manda una señal al control para detener el equipo eléctricamente, en caso de que no funcione este contacto se activa el limitador de velocidad, entonces tenemos dos formas de detener el elevador una es mecánica por medio del paracaídas y otro es eléctrico por medio de los contactos eléctricos. El primero en accionarse es el contacto eléctrico si no funciona se detiene mecánicamente.

El ascensor cuenta con un eje de tran, o bien vías reforzadas de tran las cuales evitan que la caja se salga de su eje, brindando mayor seguridad y menos esfuerzo de reparación a los operarios de algunos ascensores. El tran es un elemento de metal o hierro reforzado en titanio o los mismos elementos excentes de metal o hierro.
Si la cabina continúa acelerándose, el regulador tira con fuerza de su cable, y este activa el mecanismo de seguridad.
En algunos mecanismos especiales se utilizan rodillos o levas de bordes dentados, que se calzan en los rieles guía y detienen la cabina. Otros usan cuñas similares a las zapatas del freno de los automóviles.
Como tal el elevador es un medio de transporte seguro que evita la fatiga y las molestias que implica el hecho de subir y bajar escaleras actualmente, este también es un medio muy favorable para el uso de personas con discapacidades físicas.

En España, los ascensores están regulados por el Real Decreto 2291/1985, de 8 de noviembre, por el que se aprueba el Reglamento de Aparatos de Elevación y Manutención de los mismos. En él se han separado las normas de carácter general de aquellas otras propiamente técnicas más afectadas por el progreso previsible, las cuales están recogidas en las Instrucciones Técnicas Complementarias (ITC).

A partir del 1 de septiembre de 2017, entran en vigor las normas EN 81-20 y En 81-50 mucho más actualizadas y completas, anulando así la normativa anterior.

El mantenimiento de ascensores según a normativa incluye diferentes coberturas: Estándar, Semi Riesgo y Todo Riesgo. Durante el mantenimiento estándar, que es lo que se considera el mantenimiento básico de carácter obligatorio de un ascensor se abordan 5 puntos fundamentales:


Por otro lado, cada 3 o 4 meses se debe de manera obligatoria limpiar el foso, revisar el freno, controlar el nivel de aceite de los motores y maquinarias, revisar posibles fugas y servicios de limpieza en cabina y cuarto de máquinas.

También es necesaria una revisión anual más a fondo.Puntos esenciales que se revisan en un ascensor anualmente:





</doc>
<doc id="28010" url="https://es.wikipedia.org/wiki?curid=28010" title="Restauración Meiji">
Restauración Meiji

La describe una cadena de eventos que condujeron a un cambio en la estructura política y social de Japón en el período comprendido de 1866 a 1870 que abarca parte del período Edo denominado Shogunato Tokugawa tardío y el comienzo de la Era Meiji.

La restauración Meiji "Bakumatsu no Dōran" (fin del régimen del "shōgun") fue la sucesión política que llevó al Shogunato Tokugawa a su final para renovar el poder de gobierno de Japón al tennō, cedido a la figura del "shōgun" durante el shogunato Kamakura. Este régimen era muy parecido al feudalismo europeo: el emperador (que se creía que descendía de los dioses) no tenía el poder real sino que dependía del "daimyō" (señor feudal o hacendado de familias importantes) más importante. Este se titulaba "shōgun", que es el mayor rango que un daimyō podía obtener. Por eso el régimen político se llamaba shogunato. Japón hasta 1853 había permanecido aislado del resto del mundo económica y políticamente (excepto para China y los Países Bajos). En esta fecha llega una escuadra de la Armada estadounidense (al mando del Comodoro Perry) que tenía como propósito exigir un tratado de comercio. Este hecho se conoce también como "Kuro-fune raikō" (llegada de los barcos negros). Al no tener Japón una armada para hacerle frente tuvo que aceptar el tratado, evidenciando lo débil que era el país.

Esta revolución tuvo una particularidad única en la historia; la misma clase dominante fue la que vio la necesidad de cambio y de renunciar a sus derechos especiales. Por eso estaban divididos en dos bandos: los "Ishin shishi" y los partidarios del shogunato. Los "daimyō" que estaban en contra del shogunato lideraron a los "Ishin shishi". Entre ellos destacan tres dirigentes, el llamado "Ishin sanketsu" (el triunvirato "Ishin"), cuyos integrantes eran Toshimichi Okubo, Saigō Takamori y Kogoro Katsura.

Los partidarios del shogunato contaban con diferentes fuerzas para enfrentarse a estos revolucionarios: entre ellos, el Shinsengumi (una fuerza paramilitar-policial situada en Kioto). Para 1867 el movimiento revolucionario había logrado un avance decisivo y el emperador Meiji (que no tenía poder real) dicta la orden de disolver el "bakufu" (shogunato). Pero el shōgun Tokugawa Yoshinobu se resiste a dejar el poder en manos del "Ishin shishi" y en 1868 se desarrollan cinco batallas más, llamadas las Guerras Boshin, en orden cronológico son estas: Toba-Fushimi, Monte Ueno, Nagoaka, Aizu y Hakodate. 

Posteriormente los samuráis tras los radicales cambios realizados por el emperador, se rebelan contra él, formando un ejército cuyo enemigo será el emperador al abolir los privilegios de la clase samurái, los contrincantes fueron el recién fundado cuerpo de policía, formada en gran parte por samuráis que se pusieron al servicio del emperador y samuráis de los clanes vencedores en las Guerras Boshin: Satsuma y Chōshū. 

Los resultados de las cinco guerras fueron determinantes y finalmente el "shōgun" convocó a consejo al "shishi" Saigō Takamori, en el que estuvo presente Katsu Kaishū, comisionado de la armada seleccionado como negociador entre ambas facciones. El resultado de este consejo fue la rendición del shogunato.

La formación en 1866 de la alianza Satsuma-Chōshū entre Saigō Takamori, el líder del territorio Satsuma, y Kido Takayoshi, el líder del territorio Chōshū, construyen los cimientos de la restauración Meiji. Estos dos líderes apoyaron al Emperador Kōmei (padre del emperador Meiji) y se aliaron junto a Sakamoto Ryoma con el propósito de cambiar el gobierno del Shogunato Tokugawa ("bakufu") y devolver el poder al emperador. A finales de 1867, el Emperador Meiji asciende al trono después de la muerte del emperador Kōmei. 
Este periodo también supuso un cambio a Japón desde el comienzo de una sociedad feudal a tomar una economía capitalista con una persistente influencia occidental.

En 1868 comienza la era Meiji. En esta, quedan abolidos los privilegios especiales de los samuráis, se le da a la población la posibilidad de portar apellido (privilegio hasta entonces de la aristocracia, mientras que la gente llevaba el nombre de su profesión, por ejemplo, el capitán de un barco se llamaba "Anjin" (capitán)). Estos cambios provocaron la inestabilidad del país en el comienzo de la era Meiji. Hubo muchos levantamientos, pero se puede destacar el de Saigō Takamori, integrante del triunvirato ishin, amigo y compañero de Ōkubo Toshimichi. Saigō es derrotado por Ōkubo y hecho ejecutar. La era Meiji logró la "estabilidad total" después de cuatro décadas.




</doc>
<doc id="28011" url="https://es.wikipedia.org/wiki?curid=28011" title="Min">
Min

Min era el dios lunar, de la fertilidad y la vegetación, dios de la lluvia, protector de los comerciantes y los mineros, representaba la fuerza generadora de la naturaleza en la mitología egipcia. 


Fue representado como hombre de piel negra o verde (colores que simbolizaban respectivamente la regeneración y la fertilidad) manteniendo el falo erecto, sobre un pedestal, y portando corona de dos largas plumas y flagelo. En algunas ocasiones se representa como un toro negro o un león.

Min era de las deidades egipcias más antiguas, su culto se remonta a la época predinástica; procedía de Coptos, cerca de la ruta caravanera del Uadi Hammamat donde era el protector de los viajeros mercaderes y de los mineros. Min era un dios lunar relacionado con el calendario. Estaba vinculado a la realeza pues aseguraba la abundancia. 

Se le consideraba hijo de Ra, o de Shu, y Jentit-Iabet era su madre-esposa; formaba pareja con Repit en Atribis, y con Aperetisis en la época griega, siendo su hijo Kolanthes. También formaba tríada con Kadesh y Reshep. En una estela del museo del Louvre se le cita como hijo de Osiris e Isis.

Fue denominado "Jefe del Cielo" y "Abridor de las nubes", en la época predinástica, como dios de la lluvia, y fuerza generadora; también era el "Guardián de los caminos", pues era el protector de los comerciantes y caravanas que viajaban por el desierto. Min, como dios lunar, era el "Protector de la Luna". Era llamado "toro de su madre", como fecundador de la diosa-cielo; también era el "Señor del desierto oriental". 

Durante el Imperio Medio fue asociado a Horus el Viejo como Min-Horus, y en el Imperio Nuevo con Amón-Ra, siendo muy popular. Muchos de los atributos de Min fueron recogidos por Amón, a quien también se le representó a veces con el falo erecto, para destacar su potencia fecundadora. Se le asoció a la serpiente Kamutef en Luxor. Como dios de la fertilidad y la vegetación, los griegos lo asociaron con el dios Pan. 

El culto a Min fue uno de los más duraderos y extendidos, siendo popular en la totalidad de Egipto en todos los periodos, desde el predinástico hasta la época romana. Los griegos llamaron a la ciudad de "Ipu" o "Jent-Min", donde era adorado, Panópolis, la acual Ajmin. También fue venerado en "Jemnis" y Coptos, donde se le adoró en la forma de toro blanco llamado "Tep Hesepet" durante el Imperio Nuevo.

Era el dios del mes de Tybi, al comienzo de la estación de Peret o de la siembra. Además, el último día del mes lunar estaba consagrado a Min y era llamado el día de "La salida de Min". Durante el Imperio Nuevo era muy popular, celebrándose en su honor fiestas orgiásticas el día 28 del mes de Mesore. 

Se le ofrecía la primera cosecha de trigo en la "Fiesta de la Escalera". La lechuga, debido a sus presuntas propiedades afrodisíacas, era la planta sagrada de Min, y al principio de la estación de la cosecha, se sacaba su imagen del templo a los campos. Ello formaba la parte central del "festival de la salida de Min", durante el cual se bendecían los cultivos y se celebraban juegos gimnásticos en su honor.




</doc>
<doc id="28012" url="https://es.wikipedia.org/wiki?curid=28012" title="Historia de Europa">
Historia de Europa

La historia de Europa se refiere al conjunto de sucesos relativos al continente europeo, desde que fue poblado por los primeros seres humanos hasta la actualidad.

El Homo sapiens habría aparecido hace unos 130.000 años en África, según la opinión científica mayoritaria. La llegada del Homo sapiens a Europa podría haberse dado desde el Cercano Oriente a Europa, donde se asentaron entre 40.000 y 25.000 a. C. (Paleolítico Superior).

La Antigüedad clásica está dominada por el influjo de la civilización greco-latina sobre el resto de Europa. . La fragmentación política de Europa y los sucesivos intentos forzados de unificación sumieron al continente en numerosos conflictos y guerras durante la Edad Media, como la Guerra de los Cien Años (que duró más de un siglo).

La Edad Moderna marca para Europa el inicio de procesos que mucho después darán lugar a la globalización, y es el tiempo en el que los conflictos bélicos se hicieron cada vez más desastrosos, como la llamada guerra de los Treinta Años. Los procesos económicos y el desarrollo científico y tecnológico se aceleraron en desmedro de otros continentes de manera mucho más notoria durante la Edad Contemporánea, produciendo tensiones por competencias que desencadenaron más guerras (como las guerras napoleónicas y las guerras mundiales). Hoy los procesos tendentes a la unificación se procuran pacíficamente, tal es el caso de la formación de la Unión Europea, si bien no exenta de avances y retrocesos.

Las evidencias arqueológicas y lingüísticas sugieren que durante el III milenio a. C., contingentes importantes de pueblos que hablaban lenguas indoeuropeas entraron en Europa, encontrándose con poblaciones preindoeuropeas cuyo origen no es fácil de precisar. Los diversos pueblos indoeuropeos del II milineo a. C. ya hablaban lenguas diferentes, en particular en durante el milenio I a. C. ya es posible distinguir los grupos lingüísticos presentes en la actualidad: pueblos celtas, pueblos germanos, pueblos baltos y eslavos, pueblos itálicos, pueblos paleobalcánicos y pueblos helénicos (algunas ramas indoeuropeas como los daco-albaneses no se testimoniarían hasta más tarde).

No se conoce mucho sobre la lengua o la identidad étnica de los pueblos asentados en Europa antes de las migraciones indoeuropeas, se conoce que los aquitanos, los iberos, los taresios y etruccos y retios hablaban lenguas no indoeuropeas que se conocen muy imperfectamente, al igual que la lengua de los minoicos (eteocretense) o el eteochipriota.

Hacia el año 3000 a. C., por influencia de la cultura del Medio Oriente, en la isla de Creta surgió una civilización que construyó un imperio marítimo que abarcó a todo el mar Egeo, y que comerció con Egipto y el Levante.

Los griegos se estructuraron políticamente en torno a comunidades autónomas llamadas polis ("ciudad-estado"). A diferencia de otras culturas, los griegos nunca formaron un solo gran imperio; cuando fueron unificados, sucedió por obra de invasores externos (macedonios y romanos), y no por sí mismos.

Por su parte, los griegos emprendieron dos oleadas colonizadoras, a Jonia primero, y luego por toda la cuenca del mar Mediterráneo y el mar Negro posteriormente, fundando las ciudades que después serían Marsella, Nápoles, Tarento, Síbaris, Bizancio, etc. Aunque centrándose en África, los fenicios y cartagineses también llevaron a cabo labores de fundación de ciudades en Europa, incluyendo a Tartessos y Cartagena. En el norte de Italia, de manera paralela, surgió la cultura de los etruscos.

Durante la segunda mitad del Primer Milenio, el Mediterráneo se convirtió en campo de batalla para distintas potencias políticas. Atenas intentó hacerse con la hegemonía del Mediterráneo a través de la Liga de Delos, a la vez que vivió un período de esplendor durante el llamado Siglo de Pericles, pero colapsó después de su derrota en las Guerras del Peloponeso (431 a. C.-404 a. C.). Siguió un siglo de inestabilidad en Grecia, hasta que Filipo II la unificó bajo su hegemonía. Posteriormente, Alejandro Magno emprendió la conquista del mundo oriental, y aunque después de su muerte (323 a. C.) las potencias orientales volvieron a ser independientes, Macedonia permaneció como gran potencia.

En el Occidente, por su parte, empezó a surgir el poderío de la República Romana. Esta se enfrentó a los etruscos en una larga serie de guerras, que culminaron con la anexión de las principales ciudades etruscas hacia 250 a. C.. A la vez se enfrentaron al poderío cartaginés y lo doblegaron en las guerras púnicas (264 a. C.-146 a. C.). Durante el siglo siguiente, los romanos se extendieron por Grecia y por Oriente. En Europa, los romanos siguieron extendiendo sus fronteras tierra adentro, hasta que en la época de Octavio Augusto (31 a. C.-14 d. C.), el Imperio romano cubría todas las tierras europeas al sur de los ríos Rin y Danubio.

En este proceso de expansión, los romanos destruyeron la cultura de los celtas en Hispania y en la Galia. Después, al saltar a Gran Bretaña en el año 43, los romanos destruyeron los núcleos celtas en Inglaterra y Gales. Con todo, la cultura druidídica se conservó en Irlanda y Escocia.

Al otro lado del río Rin, por su parte, vivían las tribus de los germanos. No formaron un reino unificado, sino que eran colecciones de tribus comandadas por un rey y una aristocracia tribal. Algunas tribus de germanos intentaron cruzar la frontera y atacar a los romanos, aunque sin éxito (los cimbrios y teutones, por ejemplo). Durante los cuatro siglos que van desde la época de Julio César hasta la de Teodosio el Grande, la frontera de los ríos Rin y Danubio fue efectivamente el límite entre la cultura de los romanos y la de los germanos.

En el año 235, el Imperio romano entró en un período de caos y confusión, del cual salió medio siglo después, pero fuertemente debilitado, y con una economía y políticas de corte marcadamente más totalitarias; este nuevo régimen se denomina el Dominado. Durante esta crisis, los bárbaros germanos empezaron a presionar con mayor fuerza al Imperio romano, e incluso colonizaron (o fueron llamados como colonos) a varias tierras romanas fronterizas.

En esta época, dentro del Imperio romano, prosperó la religión del cristianismo. En 313, Constantino decretó la tolerancia religiosa hacia los cristianos en el llamado ""Edicto de Milán"", mientras que en 395, Teodosio el Grande proclamó al cristianismo como religión oficial del Imperio. En este período, y en particular desde el Concilio de Nicea en adelante, el cristianismo desarrolló fuertes estructuras jerárquicas, además de desarrollar fuertemente la doctrina y los dogmas de fe. En ese sentido, el cristianismo empezó a desarrollar la fisonomía que presentaría la Iglesia católica durante la Edad Media.

En el año 378, en la batalla de Adrianópolis, los germanos infligieron una dura derrota a los romanos. A partir de entonces la presión de los germanos aumentó aún más. En 406 cruzaron el Rin, y ante la impotencia de los romanos, se instalaron en varias tierras del Imperio. En 410, los visigodos saquearon Roma (por primera vez en siete siglos la ciudad imperial es hollada), y los vándalos repiten esto en 455. Aunque todavía nominalmente en pie, el Imperio romano se disgrega. En 476, Odoacro (jefe de la tribu de los hérulos) toma el poder, pero en vez de proclamarse Emperador, envía las enseñas imperiales a Bizancio, terminando así "de iure" el Imperio romano de Occidente.

Los caudillos germánicos se lanzaron entonces, durante los siglos V y VI, a varias guerras que los debilitaron políticamente. Hacia el año 600 sobrevivían solo los reinos de los visigodos, los lombardos, los francos y los anglosajones. Estas monarquías eran verdaderas aristocracias militares, en las que el rey era más un ""primus inter pares"" que un verdadero monarca absoluto.

Después de la desintegración del mundo antiguo como consecuencia de las irrupciones de los pueblos germánicos: Bélgica (259), Galia (268-78), Italia (260-70), Tracia, Grecia y Asia Menor (258-69), cuando los persas derrotaron y capturaron al emperador Valeriano (260). viene la época de la Alta Edad Media o de las "Edades Oscuras", que abarca el periodo comprendido desde la caída del Imperio romano hasta el feudalismo. En el año 409 los jutos, anglos y sajones desalojan a los romanos de la Gran Bretaña; En el 490 visigodos y vándalos llegan a España, mientras que los hunos alcanzan Orleáns y Milán. Estas invasiones suponen la disolución y desplazamiento del centro del poder imperial de Roma hacia el norte de Europa en lo que sería el Imperio carolingio.

Los germanos se lanzaron también a la tarea de unificar la sociedad germánica con la romana. En muchos casos esto se reflejó en un proceso legislativo que tendió a unificar las leyes aplicables a los germanos y a los romanos. Este proceso legislativo vino a quedar completo en el siglo VII, época en la que ya no era posible distinguir entre ambas poblaciones.

Mientras el Imperio romano de Occidente era destrozado por los bárbaros, el Imperio romano de Oriente consiguió sobrevivir. Algunos consideran a Constantino I (reinó 306-337) como el primer "emperador bizantino". Fue él quien trasladó la capital imperial en 324 de Nicomedia a Bizancio, refundándola como Constantinopla, o Nova Roma ( "Nueva Roma"). La ciudad de Roma en sí no había servido como capital desde el reinado de Diocleciano. Otros fechan los inicios del Imperio en el reinado de Teodosio I (379-395) y consideran que el cristianismo se instauró como religión oficial suplantando a la religión pagana romana, tras su muerte en 395, cuando la división política entre el Este y el Oeste se convirtió en permanente. Sin embargo, otros fechan todavía más tarde el inicio del imperio, en 476, cuando Rómulo Augústulo, tradicionalmente considerado el último emperador occidental, fue depuesto, con lo que el único que conservó la autoridad imperial, fue el emperador griego en el Oriente. Otros apuntan a la reorganización del imperio en la época de Heraclio (620), cuando los títulos latinos fueron sustituidos oficialmente con versiones en griego. En cualquier caso, el cambio fue gradual y para la década de 330, cuando Constantino inauguró su nueva capital, el proceso de helenización y el aumento de la cristianización ya estaban en marcha. Se considera generalmente que el imperio terminó después de la caída de Constantinopla bajo los turcos otomanos en 1453.

Bajo la égida de Justiniano I (527-565), los generales bizantinos iniciaron una ambiciosa serie de campañas militares para anexarse los antiguos territorios romanos de Occidente, conquistando el norte de África a los vándalos, Italia a los ostrogodos (aunque por breve tiempo, porque en 568 se apoderaron de ella los lombardos) y partes de Hispania, que consiguieron mantener en su poder hasta 622. Sin embargo, el desgaste de estas guerras, más las emprendidas por Justiniano y sus sucesores contra la potencia persa de los sasánidas, debilitaron mortalmente al Imperio. Además, la "Peste de Justiniano" afectó al Imperio bizantino, incluida su capital Constantinopla, en los años 541-542. Se estima que la plaga provocó hasta un máximo de 100 millones de muertes en todo el mundo, causado la caída de alrededor del 50% de número de habitantes de Europa entre 541 y 700. El éxito de las conquistas árabes, también puede haber contribuido a la catástrofe demográfica. En el siglo VII la irrupción de los árabes le asestó al Imperio bizantino un duro golpe, privándolo de sus territorios africanos (incluyendo Egipto), de Palestina y de Siria. A partir de entonces el Imperio bizantino sería una potencia que basaría su poderío en el dominio de la Anatolia y los Balcanes.

Las conquistas árabes llegaron hasta Europa. En el año 711, al mando de Tarik y enviados por el gobernador africano Muza, los árabes conquistaron y destruyeron el Reino Visigótico, y se anexaron Hispania. Aun así, un núcleo de montañeses asturianos resistió, y se transformaría en la semilla del contragolpe cristiano contra los musulmanes. En 732, una incursión musulmana contra la Galia fue frenada en la Batalla de Poitiers por Carlos Martel, marcando el máximo de expansión musulmana en Europa. Algo después, en 756, el Emir Abderramán I se independizó del Califato Abasida, y creó en España el Emirato de Córdoba, que se transformó en un importante núcleo del saber y la cultura en la Europa de la Edad Media.

Después de la caída del Imperio romano en Occidente en el siglo V, Europa occidental emerge como una nueva civilización. Tras las invasiones bárbaras y la separación del Imperio bizantino (Imperio romano de Oriente), éste sobrevivió otro milenio.

El Feudalismo reemplazó al Imperio romano en Europa. La única institución que sobrevivió fue la Iglesia católica, que preservó parte de la cultura romana, y se convirtió en la principal fuente de aprendizaje hasta el siglo XIII. Hasta el año 1000 crece el feudalismo, que debilita al Sacro Imperio Romano y define a la Iglesia Católica como el mayor poder cristiano, ya que el papado no solo tenía su propio estado, sino que atesoraba todo el saber grecorromano y era el guía espiritual de todos los poderosos estados europeos, consiguiendo controlar en muchas ocasiones sus políticas exteriores y de conquistas.

La Casa de los Pipínidas, a la que pertenecía como mayordomo de palacio de los francos el mencionado Carlos Martel, pidió el reconocimiento al papado como reyes, y fueron entronizados. La Dinastía Merovingia fue reemplazada así por la Dinastía Carolingia. Como parte del acuerdo entre Pipino el Breve (hijo de Carlos Martel) y el papado, varios territorios italianos fueron entregados a éste, transformándose en la semilla de los futuros Estados Pontificios.

El hijo de Pipino el Breve fue Carlomagno, quien gobernó el Imperio carolingio desde 771 hasta su muerte en 814. Carlomagno, aliado con el papa, hacia el año 800, conquista Francia, el oeste de Alemania, gran parte de Italia y partes de otros países. Surge el Sacro Imperio Romano Germánico cuyo emperador intenta dominar al papado que había constituido un estado independiente en el centro de Italia.

Carlomagno protegió al papado, lidiando varias guerras contra sus enemigos tradicionales los lombardos y fortaleciendo el rol social de la Iglesia. Creó también la Escuela Palatina, a cargo de Alcuino de York, y propulsó el llamado "Renacimiento carolingio". En política exterior intentó atacar a los musulmanes de España, operación que se vio frustrada por la dura derrota sufrida en la Batalla de Roncesvalles (778), aunque en 804 creó la Marca Hispánica. Libró también una guerra de aproximadamente 30 años contra los sajones, e inició la cristianización de Alemania. Entabló relaciones diplomáticas tanto con el Imperio bizantino como con el Califato Abasida. En el ámbito interno llevó a cabo una serie de reformas administrativas, dividiendo su imperio en marcas y condados, algunos de los cuales sobrevivieron a su Imperio como entes independientes.

Sin embargo, al morir Carlomagno en 814, su heredero Ludovico Pío resultó ser un monarca débil y no pudo proseguir la obra de su antecesor. En 843, los hijos de Ludovico Pío (nietos de Carlomagno) se repartieron el Imperio en el Tratado de Verdún, surgiendo así las coronas de Francia y de Alemania (otro territorio surgido de dicho tratado, la Lotaringia, se desintegró rápidamente).

Después del Gran Cisma de Oriente y Occidente, el cristianismo occidental fue aprobado por los recién creados reinos de Europa Central: Polonia, Hungría y Bohemia. La Iglesia católica se desarrolló como una gran potencia, dando lugar a conflictos entre el papa y el Emperador. En 1129 la Iglesia Católica estableció la Inquisición para hacer a los europeos occidentales sus miembros por la fuerza. La Inquisición castigaba a aquellos que practican la herejía para que se arrepintiesen. Si no lo hacían, sufrían la pena de muerte. Durante este tiempo muchos nobles gobernaron la iglesia. Los monjes de Cluny consiguieron establecer una iglesia donde no existían los nobles. El papa Gregorio VII, continuó la labor de los monjes con 2 objetivos principales: librar la iglesia del control de los reyes y nobles y aumentar el poder del papa. La influencia de la Iglesia católica había crecido enormemente debido a las conversiones de reyes paganos (Escandinavia, Polonia, Hungría, Lituania ), Reconquista cristiana de Al-Ándalus, y las cruzadas. Como resultado, la mayor parte de Europa era católica en el siglo XV.

Los primeros signos del renacimiento de la civilización en Europa occidental comenzaron a aparecer en el siglo XI, cuando el comercio comenzó de nuevo en Italia, dando lugar a la situación económica y el crecimiento cultural de ciudades-estado independientes, tales como Venecia y Florencia y, al mismo tiempo, los estados-nación empezaron a tomar forma en lugares como Francia, Inglaterra, España y Portugal, aunque el proceso de su formación (por lo general marcado por la rivalidad entre la monarquía, la aristocracia señores feudales y la iglesia) en realidad duró varios siglos. Estos nuevos estados-nación comenzaron a escribir en sus propias lenguas en lugar del tradicional latín. Por otra parte, el Sacro Imperio Romano, basado esencialmente en Alemania e Italia, se vio fragmentado en un sinnúmero de principados feudales o pequeñas ciudades-estado, cuya subordinación al emperador fue solo formal.

Los siglos XIII y XIV, cuando el Imperio mongol llegó al poder, se denomina a menudo la edad de los mongoles. Ejércitos mongoles se extendieron hacia el oeste bajo el mando de Batu Kan. Sus conquistas incluyeron la parte occidental de Rusia (salvo Novgorod, que se convirtió en vasallo), las tierras de los cumanos, Hungría y Polonia (que había permanecido como Estado soberano). Registros mongoles indican que Batu Kan estaba planeando una completa conquista de las restantes potencias europeas, comenzando con un ataque de invierno en Austria, Italia y Alemania, cuando debió regresar a Mongolia tras la muerte del Gran Kan Ogodei. En Rusia, los mongoles de la Horda de Oro gobernaron durante casi 250 años. En Europa, el Centro y el Oriente estaba dominado por el Reino de Polonia, Chequia y Hungría. Hasta la batalla de Grunwald fue también fuerte la Orden Teutónica.

La peste negra fue una devastadora pandemia que asoló Europa en el siglo XIV y que causó la muerte de un 30 a un 60% de la población del continente europeo, reduciendo la población mundial estimada desde 450 millones hasta 350 o 375 millones en el año 1400. La mayor parte de los científicos cree que la peste negra fue un brote de peste bubónica, una terrible enfermedad que se ha extendido en forma de epidemia varias veces a lo largo de la historia. La peste es causada por la bacteria Yersinia pestis que se contagia por las pulgas con la ayuda de la rata negra (Rattus rattus), que hoy conocemos como rata de campo.

Durante el siglo XV en Francia, Inglaterra y España, nuevos monarcas formaron poderosas naciones.
En el Centro y Oriente de Europa dominaba la República de las Dos Naciones. Después del año 1655 Polonia- Lituania fue el estado más fuerte en la parte oriental del continente. Más tarde comenzó la era de la dominación de Rusia y Austria.

La Iglesia Católica estaba perdiendo poder por la corrupción, los conflictos internos, y el surgimiento de la cultura en lo artístico, filosófico, científico y tecnológico, del movimiento renacentista.

Las nuevas naciones se encontraban envueltas en guerras y problemas políticos.

Martín Lutero empezó la reforma en 1517, la reforma y la contrarreforma fue acompañada de guerras y persecuciones religiosas, con enormes implicaciones para Europa. En Inglaterra, Enrique VIII también rompió con la iglesia católica, autoproclamándose cabeza de la Iglesia en su reino, y el imperio Alemán encabezado por los Habsburgo fue atacado por los príncipes protestantes de Alemania.

En Europa Central, polacos, lituanos, y húngaros, adoptaron la tolerancia religiosa entre los católicos, protestantes, ortodoxos y judíos. También los reyes católicos Isabel de Castilla y Fernando de Aragón estaban muy preocupados por la unidad religiosa de sus reinos, por lo que tomaron medidas cautelarias, como por ejemplo la creación de la Inquisición española (1478) y la expulsión de los judíos que no quisieran convertirse al cristianismo(1492). Su nieto Carlos I, heredará el título imperial, y hará de España el motor de un gran imperio que liderará Europa durante todo el siglo XVI y parte del XVII. Según el historiador Kamen, sería esta dominación española la primera globalización económica de la historia europea, y también el primer estado cosmopolita, puesto que estaba integrado por alemanes, austriacos, portugueses, italianos, flamencos y españoles de los varios reinos peninsulares, Aragón, Castilla y Navarra.

En innumerables ocasiones a través de todo el siglo XVII en el antiguo continente han estallado muchos conflictos políticos y religiosos. El objetivo de dichas guerras fueron la lucha por la supremacía en el continente. Durante este período, se concentraron en Europa del Este numerosas guerras entre Polonia, Rusia y Turquía, después también Suecia entró en guerras. Durante el período comprendido entre 1612-1613 el ejército polaco ocupó Moscú, y hasta mediados del siglo XVII, Polonia continuó dominando dicha parte de Europa. La época dorada del imperio polaco finalizó después de dos hechos acaecidos, el primer hecho, la Rebelión de Jmelnytsky y el segundo, el Diluvio. Mientras, en Europa central, sucedería una terrible guerra, la denominada Guerra de los Treinta Años. Hacia finales de este siglo, Imperio otomano comenzó a ser una amenaza por sus ánsias expansionistas, llegando a ser una amenaza para Austria. Durante la Batalla de Kahlenberg Turquía fue vencida por la alianza austríaco-polaca, frenando así la amenaza invasiva turca.

República de las Dos Naciones con sistema político de la mancomunidad, llamado "Democracia de los Nobles", se caracterizaba por la limitación del poder del monarca por las leyes y la cámara legislativa (Sejm) controlada por la Nobleza de Polonia (Szlachta). Este sistema fue el precursor de los conceptos modernos de democracia,Monarquía constitucional, y federación.

Desde principios del siglo XV extendiéndose hasta comienzos del siglo XVII los navíos de Europa surcaron los mares del mundo en busca de nuevos socios y rutas comerciales con los que se pudo contribuir al floreciente capitalismo europeo. Durante estas exploraciones, los europeos invadieron naciones y cartografiaron territorios que anteriormente no conocían. 

La Ilustración ("Lumières", en francés; "Enlightenment", en inglés; "Illuminismo", en italiano; "Aufklärung", en alemán), en frase de uno de sus más importantes representantes, D'Alembert, «lo discutió, analizó y agitó todo, desde las ciencias profanas a los fundamentos de la revelación, desde la metafísica a las materias del gusto, desde la música hasta la moral, desde las disputas escolásticas de los teólogos hasta los objetos del comercio, desde los derechos de los príncipes a los de los pueblos, desde la ley natural hasta las leyes arbitrarias de las naciones, en una palabra, desde las cuestiones que más nos atañen a las que nos interesan más débilmente». Esto mismo nos indica que, más que el contenido mismo de sus doctrinas, lo original del movimiento fue la forma de pensamiento y valoración.

El siglo XVIII constituye, en general, una época de progreso de los conocimientos racionales y de perfeccionamiento de las técnicas de la ciencia. Fue un período de enriquecimiento que potenció a la nueva burguesía, si bien se mantuvieron los derechos tradicionales de los órdenes privilegiados dentro del sistema monárquico absolutista. Sin embargo, la historia del siglo XVIII consta de dos etapas diferenciadas: la primera supone una continuidad del Antiguo Régimen (hasta la década de 1770), y la segunda, de cambios profundos, culmina con la Revolución estadounidense, la Revolución francesa y Revolución industrial en Inglaterra.

Desde Gran Bretaña, donde algunos de los rasgos esenciales del movimiento se dieron antes que en otro lugar, la Ilustración se asentó en Francia, donde la anglofilia fue difundida por Voltaire, y produjo aquí su cuerpo ideológico, el enciclopedismo, y sus más representativas personalidades (Montesquieu, Diderot, Rousseau, Buffon, etc); también dio sus frutos, en ocasiones más o menos autónomamente, pero en la mayoría de casos dependientes de Gran Bretaña y, sobre todo, de Francia, en otras zonas europeas (Países Bajos, la península italiana y la ibérica, el conglomerado germánico, Polonia, Rusia, Suecia, etc.) o en sus colonias americanas; frutos condicionados por el grado de desarrollo ideológico y sociopolítico adquirido en el momento de lanzamiento de la nueva ideología y por el proceso interno seguido a lo largo de su desenvolvimiento.

En la segunda mitad del siglo XVIII se inicia en Inglaterra una transformación de las estructuras económicas y sociales que sirvió de base para el posterior desarrollo, la revolución industrial en el siglo XIX. La expansión colonial conllevó un aumento en la demanda de productos que no podía cubrirse con la protoindustria tradicional. La creación de fábricas, con el consiguiente aumento significativo de la producción y las consecuencias sociales que éstas trajeron; el cambio en el comercio textil, pasando de la lana al algodón, con el desarrollo de nuevas tecnologías aplicadas a todo el proceso de producción textil; así como la invención de la máquina de vapor y su aplicación práctica en el ferrocarril; todo ello supuso una revolución económica que conllevó una auténtica ruptura con el modelo económico medieval.

Cuando se creó la máquina de vapor gran parte de las empresas la adquirieron y su producción se volvió más rápida y sofisticada.

Al final del siglo XVIII, la negativa del rey francés Luis XVI (apoyada por la nobleza y el clero) de compartir el poder político con el llamado Tercer Estado originó la Revolución francesa en 1789, como un intento de crear una nueva forma de gobierno basada en los principios de "Liberté, Égalité, Fraternité" (Libertad, Igualdad y Fraternidad). El rey fue ejecutado, Francia fue proclamada una república y una especie de gobierno democrático fue establecido. En el subsiguiente conflicto (relacionado con la coalición de la mayoría de las monarquías europeas que le declararon la guerra a la Francia republicana) el general Napoleón Bonaparte tomó el poder.

En los años de la era Napoleónica, Francia venció repetidamente a Austria (cuyo monarca fue forzado a abdicar al título de Emperador del Sacro Imperio romano Germánico), Rusia, Prusia y a otras potencias aliadas principalmente a Inglaterra. También organizó la Confederación del Rin. Después de ser proclamado emperador francés en 1804, Napoleón fue derrotado finalmente en la Batalla de Waterloo en 1815.

Luego de la derrota de la Francia revolucionaria, las otras potencias mayores trataron de restaurar la situación que existía antes de 1789. De cualquier forma, sus esfuerzos no fueron suficientes como para detener la proliferación de los movimientos revolucionarios: las clases medias estaban fuertemente influidas por los ideales de democracia emanados de la Revolución francesa, la Revolución industrial trajo otros cambios sociales y económicos, las clases bajas empezaron a ser influenciadas por ideas socialistas, comunistas y anarquistas (especialmente las resumidas por Karl Marx en el Manifiesto del Partido Comunista, y la preferencia de los nuevos capitalistas por el Liberalismo).

Mayor inestabilidad vino de la formación de varios movimientos nacionalistas (en Alemania, Italia, Polonia, etc), que buscaban la unificación nacional o su liberación del gobierno extranjero. Como resultado, el periodo entre 1815 y 1871 vio un gran número de intentos revolucionarios y guerras de independencia. Aunque los revolucionarios eran comúnmente derrotados, la mayoría de los estados europeos se habían convertido en monarquías constitucionales (dejando de ser absolutistas). Hacia el año 1871, Alemania (victoriosa en la Guerra Franco-prusiana) se había desarrollado como un estado nacional unificado, llevándose a cabo la unidad alemana, bajo la figura del Imperio alemán, cuyo arquitecto fue Otto von Bismarck. Italia, cuyos estados también habían estado divididos, logró la unificación bajo el liderazgo de Camillo di Cavour y Giuseppe Garibaldi.

La dinámica política de Europa cambió en dos ocasiones durante el siglo XIX. La primera, tras el Congreso de Viena, y la segunda, después de la Guerra de Crimea. En 1815, durante el Congreso de Viena, las principales potencias de Europa se las arreglaron para producir un balance pacífico del poder entre los imperios después de las guerras Napoleónicas (a pesar de que ocurrieran movimientos revolucionarios internos). Pero la paz solo duraría hasta que el Imperio otomano hubiera declinado lo suficiente como para convertirse en blanco de los demás. Esto provocó la Guerra de Crimea en 1854 y se inició así un tenso periodo de choques menores dentro de los imperios de Europa que prepararon el estallido de la Primera Guerra Mundial.

Desde 1870, la hegemonía que Bismarck ejerció a lo largo de Europa puso a Francia en una situación crítica, obligando al país galo a reconstruir sus relaciones internacionales, buscando alianzas con Rusia e Inglaterra para controlar el creciente poderío de Alemania. De esta manera, Europa se dividió en dos.

Luego de la relativa paz durante el siglo XIX, la rivalidad entre las potencias europeas estalló en 1914, cuando se inició la Primera Guerra Mundial. En un lado se encontraban Alemania, el Imperio austrohúngaro y el Imperio otomano (las Potencias Centrales), mientras que del otro lado se encontraban Serbia y la "Triple Entente" - la vaga coalición de Francia, Inglaterra y Rusia, a la que se le uniría Italia en 1915 y los Estados Unidos en 1917. A pesar de la derrota de Rusia en 1917 (la guerra fue una de las principales causas de la Revolución rusa, que culminó en la formación de la Unión Soviética), la "Entente" finalmente consiguió el triunfo en el otoño de 1918.

En el Tratado de Versalles de 1919 los vencedores le impusieron duras condiciones a Alemania y reconocieron a los nuevos estados (como: Polonia, Checoslovaquia y Yugoslavia creados en Europa Central con territorios que pertenecieron a Alemania, Austria-Hungría, y al Imperio ruso, tomando como base la supuesta autodeterminación de los pueblos. En las siguientes décadas, el temor al comunismo y a la Depresión económica de 1929-33 provocaron el auge de gobiernos extremistas - Fascista o Nazi - en Italia (1922), Alemania (1933), España (luego de una guerra civil que finalizó en 1939) y en otros países como Hungría.

Desde 1936 los futuros beligerantes de Europa en la Segunda Guerra Mundial comienzan a enfrentarse directa o indirectamente en el marco de la Guerra Civil Española. El 25 de octubre el Ministro de Asuntos Exteriores italiano, sostuvo una visita en la Alemania nazi que dio lugar al "Pacto del Eje Roma-Berlín". El acuerdo consolidó las posiciones de Alemania e Italia contra Gran Bretaña y Francia. El 25 de noviembre siguiente, Japón y Alemania firmaron el "Pacto Anti-Komintern". En 1939 Alemania y la URSS firman el Pacto Molotov-Ribbentrop. El protocolo secreto definía la repartición de la Europa del este y central bajo influencia alemana y rusa, y establecía la cuarta partición de Polonia. El 1 de septiembre Hitler ordenó la invasión de Polonia sin previa declaración de guerra, lo que motivó que Francia y el Reino Unido declararan la guerra a Alemania el 3 de septiembre, aún existiendo un tratado que comprometía a estos países. La URSS ocupó la parte oriental de Polonia, hecho acordado en el pacto germano-soviético, matando a miles de oficiales polacos en lo que se conoce como la Masacre de Katyn; posteriormente atacó a Finlandia el 30 de noviembre, en lo que se conoce como la Guerra de Invierno, pero enfrentada a una resistencia inesperada, ambos países firmaron la paz en Moscú el 12 de marzo de 1940, tras ceder Finlandia posesiones territoriales a cambio de conservar su independencia.

Tras la conquista de Polonia, Alemania invadió Dinamarca y Noruega, esperando la intervención de Francia y Reino Unido, pero como estos dos países no tomaron la iniciativa de atacar, no se produjo ninguna acción bélica en varios meses (conocido con el término francés "Drôle de guerre", "guerra graciosa"), hasta la invasión de los Países Bajos, Francia y Bélgica por parte de Alemania en mayo y junio de 1940 ("Blitzkrieg" o guerra relámpago).

Desde la guerra contra Finlandia, Stalin había estado realizando esfuerzos apurados para modernizar el Ejército Rojo, ya que tanto él como Adolf Hitler sabían que el tratado de paz firmado no duraría mucho tiempo. Sin embargo, Hitler se adelantó a los planes de Stalin y en junio de 1941 Alemania lanzó la Operación Barbarroja contra la Unión Soviética, cuyo objetivo final era la derrota del país eslavo en solo tres meses, de esta manera Alemania despojaría a los ingleses de un posible aliado.

Después de derrocar a Mussolini, Italia, invadida por el sur, cambió al bando aliado en 1943, y Rumanía hizo lo mismo en 1944, al ser invadida por los rusos. Alemania capituló el 7 de mayo de 1945, tras haber caído Berlín el día 2 de mayo ante las fuerzas soviéticas. El día 8 de mayo se firmó el armisticio que puso fin a la guerra en Europa. Las Guerras Mundiales terminaron con la posición preeminente de Europa Occidental.

El mapa de Europa fue redibujado en la Conferencia de Yalta y fue dividido como la principal zona de contención en la Guerra Fría entre las dos nuevas potencias emergentes, la capitalista Estados Unidos y la comunista Unión Soviética. Los Estados Unidos pusieron a Europa Occidental (Inglaterra, Francia, Italia, Alemania Occidental, España, etc.) dentro de su esfera de influencia, estableciendo la OTAN como una medida precautoria en contra de una posible invasión soviética; la Unión Soviética hizo lo mismo con Europa Central (Polonia, Checoslovaquia, Hungría, Rumanía, Bulgaria, Alemania Oriental) formando el Pacto de Varsovia. Europa fue dividida, conociéndose a esta situación con la metáfora de "Telón de acero". Esta situación duró hasta 1989, cuando el debilitamiento de la Unión Soviética originó la Glásnost y el fin de la división de Europa - los gobiernos satélites soviéticos se vieron libres para disolver los regímenes comunistas (y las dos Alemanias pudieron reunificarse). En 1991 la misma Unión Soviética se colapsó, dividiéndose en varios estados (el principal quedó como la Federación Rusa) y se disolvieron la mayoría de los gobiernos comunistas.

Después del fin de la Segunda Guerra Mundial, Europa Occidental inició lentamente un proceso de integración política y económica, con el deseo de unir a Europa y así prevenir otra guerra. Este proceso dio como resultado el desarrollo eventual de organizaciones como la Eurozona y la Unión Europea. Al final de la Guerra Fría, los países de Europa Central comenzaron a ser incluidos en estas organizaciones.

El 9 de mayo de 1950, Robert Schuman pronuncia el célebre discurso en el que tal como lo reconoce oficialmente la Unión Europea (UE) se dio el primer paso para la formación de esta organización. La UE se iniciaba como una vaga alianza económica entre naciones europeas, pero se requería un mayor esfuerzo para integrar estrechamente a los estados miembros y convertir a la UE en una organización supranacional. El proceso de integración de Europa fue lento debido a la negativa de la mayoría de los estados miembros a ceder su soberanía.

De cualquier forma, el proceso empezó a acelerarse a principios de los años 1990. Las naciones dentro de la Unión Europea crearon una "zona de libre comercio" y eliminaron la mayoría de las barreras aduaneras a lo largo de sus fronteras. La nueva moneda para Europa, el Euro, fue establecida electrónicamente en 1999, uniendo oficialmente a las monedas de cada nación participante. El Euro fue puesto en circulación en 2002 y las viejas monedas se volvieron obsoletas.

Pese al fortalecimiento de la unidad continental, Europa no supo evitar conflictos como las Guerras yugoslavas y en 2003 algunos países europeos, encabezados por Alemania, Francia y Rusia, se opusieron al nuevo concepto de "guerra preventiva" y rechazaron participar en la Invasión de Iraq. Otros países europeos, encabezados por Italia, España y Polonia, respaldaron la Guerra de Iraq y enviaron efectivos militares.

Desde 2013 la UE está conformada por 28 países europeos y algunos territorios de ultramar. Ese mismo año los jefes de gobierno de los países que forman la UE aprobaron el Tratado de Lisboa, que deberá ser ratificado por cada uno de los estados miembros antes de finales del 2008( dicho tratado entró en vigor el 1 de diciembre de 2009) introduciendo por primera vez la posibilidad de la salida de un Estado miembro de la UE en su artículo 50 que se utilizó tras el referendum del Brexit( convocado por David Cameron al conseguir la mayoría absoluta en 2015 sin embargo tras defender la permanencia del Reino Unido en la UE dimitió como primer ministro. 
El 23 de junio de 2016 (tras haber ganado los partidarios de la salida del Reino Unido de la UE por un 51% fue invocado formalmente por Theresa May(Primera Ministra del Reino Unido el artículo 50 del tratado de Lisboa) el 29 de marzo de 2017 esto produjo el inicio de las negociaciones para la salida del Reino Unido de la UE sin embargo a pesar de haber alcanzado un acuerdo con la UE en noviembre de 2018 no consiguió que lo aprobase el Parlamento Británico esto produjo la dimisión de Theresa May tras ella vino Boris Johnson actual Primer Ministro Británico tras ser elegido por la militancia del Partido Conservador Británico en julio de 2019, Boris Johnson consiguió hacer modificaciones en el acuerdo de salida que fueron aceptadas por la UE y en octubre del 2019 se llegó aún acuerdo que permitió la salida del Reino Unido como estado miembro de la UEel 31 de enero de 2020(además las elecciones al parlamento británico celebradas el 12 de diciembre de 2019 facilitaron la salida dando la mayoría absoluta a Boris Johnson) aunque siguen sometidos a las regulaciones de la UE hasta alcanzar un acuerdo comercial y se tiene de plazo hasta el 31 de diciembre de 2020 pero que se puede ampliar debido a la falta de tiempo para alcanzar un acuerdo comercial o producirse una salida sin acuerdo por parte del Reino Unido.
Esto ha producido en la UE que desde el 31 de enero de 2020 la UE tiene 27 estados miembros. 
ref></ref> Actualmente la UE se basa en cuatro tratados (Tratados de Roma, Maastricht y Ámsterdam) que fijan sus normas de actuación.

Por otra parte la UE es la primera potencia comercial, representando el 20% de las importaciones y exportaciones mundiales.

Un aspecto interesante de la demografía europea durante la segunda mitad del siglo XX y principios del siglo XXI, es que durante la segunda mitad del siglo XX, la baja natalidad y las condiciones económicas imperantes en Europa y las regiones adyacentes, favoreció enormemente los procesos migratorios, y numerosos países de Europa recibieron grandes cantidades de migrantes de Asia, África y menor medida América Latina, llegando a tener muchos países porcentajes de población inmigrantes procedente de esas regiones de entre el 5 y 15%.


[35]https://www.elmundo.es/internacional/2019/10/17/5da5f9e9fdddff7e8f8b457a.html
[36]https://es.m.wikipedia.org/wiki/Salida_del_Reino_Unido_de_la_Uni%C3%B3n_Europea.


</doc>
<doc id="28027" url="https://es.wikipedia.org/wiki?curid=28027" title="Birthday (canción de The Sugarcubes)">
Birthday (canción de The Sugarcubes)

«Birthday» fue el segundo sencillo de los Sugarcubes correspondiente a su primer álbum: "Life's Too Good". Este sencillo fue lanzado en octubre de 1987 a través de One Little Indian.
Con la canción “Birthday” los Sugarcubes se dieron a conocer en todo el mundo teniendo especial repercusión la voz de Björk por la que la crítica ubicaron a la banda en lo alto de las listas británicas como en "Melody Maker".




</doc>
<doc id="28028" url="https://es.wikipedia.org/wiki?curid=28028" title="Regina (canción)">
Regina (canción)

«Regina» es el primer sencillo de un total de 6 correspondiente al álbum "Here Today, Tomorrow, Next Week!" de la banda islandesa The Sugarcubes en la que se encontraba la cantante y compositora Björk. El mismo fue lanzado en julio de 1989 a través de One Little Indian.




</doc>
<doc id="28029" url="https://es.wikipedia.org/wiki?curid=28029" title="Tidal Wave (single)">
Tidal Wave (single)

«Tidal Wave» es el segundo sencillo de un total de 6 correspondiente al álbum "Here Today, Tomorrow, Next Week!" de la banda islandesa The Sugarcubes en la que se encontraba la cantante y compositora Björk. El mismo fue lanzado en 1989.




</doc>
<doc id="28030" url="https://es.wikipedia.org/wiki?curid=28030" title="Sódóma Reykjavík (álbum)">
Sódóma Reykjavík (álbum)

Sódóma Reykjavík es un álbum lanzado en agosto de 1992 y corresponde a la banda sonora de la película "Sódóma Reykjavík", también conocida como "Remote Control".
Este compilado está integrado por 13 canciones interpretadas por bandas islandesas, dentro de sus participantes más importantes se encuentra la cantante Björk, quien interpretó la canción "Ó Borg Mín Borg" acompañada de KK Band y la canción "Takk", junto a Þórhallur.





</doc>
<doc id="28032" url="https://es.wikipedia.org/wiki?curid=28032" title="12.11 (canción)">
12.11 (canción)

«12.11» es el tercer sencillo de un total de 6 correspondiente al álbum "Here Today, Tomorrow, Next Week!" de la banda islandesa The Sugarcubes en la que se encontraba la cantante y compositora Björk. El mismo fue lanzado en 1989.

Este lanzamiento consistía de una caja formada por 11 discos de 12 pulgadas.

</div>



</doc>
<doc id="28033" url="https://es.wikipedia.org/wiki?curid=28033" title="7.8">
7.8

«7.8» es el cuarto sencillo de un total de seis correspondiente al álbum "Here Today, Tomorrow, Next Week!" de la banda islandesa The Sugarcubes,de la que formaba parte la cantante y compositora Björk. El mismo fue lanzado en noviembre de 1989.

"7.8" estaba compuesto de 8 discos de 7 pulgadas.



</doc>
<doc id="28034" url="https://es.wikipedia.org/wiki?curid=28034" title="Altruismo">
Altruismo

El altruismo (del noruega antiguo "altrui", «de los otros») se puede entender como:

De acuerdo a la Real Academia Española, el altruismo proviene del francés "altruisme" y designa la «diligencia en procurar el bien ajeno aún a costa del propio». 

El término altruismo se refiere a la conducta humana y es definido como la preocupación o atención desinteresada por el otro o los otros, al contrario del egoísmo. Suelen existir diferentes puntos de vista sobre el significado y alcance del altruismo o cuidar de los demás desinteresadamente, sin beneficio alguno.

En línea con los estudios de Daniel Batson, Elena Gaviria afirma que "existe una cantidad considerable de evidencia empírica que sugiere que, por lo menos, tenemos la capacidad de comportarnos movidos por sentimientos no puramente egoístas. El que manifestemos o no esa capacidad depende probablemente de muchos factores, pero la tenemos, y eso ya es algo". El altruismo en sí mismo no es observable, ya que requiere inferencias sobre intenciones y motivos, así que los estudios de la psicología social se han consagrado empíricamente a la observación de la conducta de ayuda. Así pues, los elementos involucrados son el donante de ayuda o benefactor y los factores situacionales envueltos en el ofrecimiento o negación de la misma, y solo después se analizan los determinantes motivacionales de la conducta. Según la "Enciclopedia Blackwell de Psicología social" (1995) se incluye dentro de las conductas prosociales consideradas beneficiosas para otras personas y para el sistema social: la ayuda (cualquier acción que tiene por consecuencia un beneficio a otra persona), el altruismo (conducta que supone más beneficios al receptor que a aquel que la realiza) y la cooperación (conducta que supone un beneficio común y en la cual son todos las que la cursan benefactores y receptores). Las dos primeras son más bien de carácter interpersonal, la última de carácter más bien grupal.

En cuanto a la ayuda, los experimentos han determinado que, contrariamente a lo que pueda suponerse, la conducta de ayuda suele inhibirse cuantos más espectadores se hallen presentes ("bystander effect"), ignorancia pluralista. En el modelo de John Darley y B. Latané, la prestación de ayuda se somente a cinco pasos consecutivos que si se resuelven afirmativamente desembocan en la conducta de ayuda:


La ayuda puede ser directa o indirecta y los costes pueden ser altos tanto por ayudar como por no ayudar. Entre los motivos de esta conducta se encuentran el refuerzo positivo del aprendizaje de la misma en el pasado, también los factores emocionales y neurológicos implicados en la empatía y la retribución y las normas sociales y personales. Por otra parte, el altruismo puede resultar contraproducente según el juicio del receptor: hay que distinguir entre la ayuda que alguien pide y la que se ofrece sin haber sido solicitada; en este último caso es frecuente que hacer un favor no pedido para sentirse bien el ayudante se rechace si el ayudado es persona con autoestima y autonomía altas. Desde el punto de vista del receptor, la petición de ayuda es el resultado de un proceso con tres fases que solo si se contestan afirmativamente conducen a la petición de ayuda, y en el cual hay un proceso de cálculo entre beneficios y costes:


Según A. Nadler, el que una persona decida pedir ayuda o no depende de tres factores:


Referente a lo primero, desde el punto de vista de la autoestima es más costoso pedir ayuda para los hombres que para las mujeres y para las personas de más alta autoestima que para los de más baja. Respecto a lo segundo, cuando el problema está directamente relacionado con la imagen personal y social es menos probable que se solicite ayuda (es menos frecuente recurrir a un psicólogo o psiquiatra por la salud mental que a un médico por la salud física). Además, es disuasor no poder devolver el favor al otro cuando creemos que se espera de nosotros que lo hagamos. En cuanto a lo tercero, la gente suele preferir como donante a alguien que no sea demasiado amenazante para su autoestima antes que a una persona más competente: debe parecerse al potencial benefactor. La gente suele recurrir a parientes, a amigos o a personas semejantes a ellos para pedir ayuda (Alcohólicos anónimos, por ejemplo), porque las relaciones interpersonales entre desconocidos exigen reciprocidad, mientras que entre conocidos se trata de relaciones comunales.

Auguste Comte acuñó la palabra "altruisme" en 1851 y ésta fue adoptada luego por el español. Muchos consideran su sistema ético algo extremo, pues según este los únicos actos moralmente correctos son aquellos que intentan promover la felicidad de otros.

Es la conducta que beneficia a otros, que es voluntaria y cuyo autor no pide beneficios externos. Aunque la finalidad propia del altruismo puede presentar varias dificultades, el motivo de esto se debe a que los agentes morales presentan toda una serie de prejuicios cognitivos que hacen las labores altruistas y activistas más dificultosas. Algunos de estos prejuicios se reflejan en una parcialidad que lleva a dar prioridad a algunos individuos sobre otros. Esto provoca que se asigne menos importancia a ciertas causas que en realidad son más significativas que otras consideradas como menos relevantes, es decir, presentan un cierto grado de subjetividad. Algunos de estos prejuicios pueden ser las actitudes sexistas, racistas, xenofobia, chovinistas entre otras. Además, las tendencias egoístas llevan a que nos desentendamos de causas que podrían conseguir un impacto mayor en el mundo. 

Por otra parte, otros prejuicios provocan que adoptemos patrones irracionales en nuestra toma de decisiones. Esto se debe a que muchas de nuestras inclinaciones e intenciones a la hora de actuar han sido seleccionadas a lo largo de la historia natural por razones de carácter evolutivo. Esto se debe a que éstas presentaron ventajas en la transmisión de nuestro material genético. Pero, en realidad, éstas no ofrecen ninguna ventaja a la hora de deliberar sobre la forma en la que debemos actuar. Más bien, todo lo contrario. Pero es necesario recalcar que estas intenciones no determinan necesariamente lo que buscamos y cómo lo debemos buscar. Pero es cierto que sí pueden modifican nuestras inclinaciones y condicionan nuestra forma de actuar en muchos casos. A lo largo de la historia evolutiva, las capacidades y disposiciones que se acabaron estableciendo no son las que estimulan la realización de ciertas funciones de la mejor manera, sino las que hicieron que el material genético se transmitiera de forma eficiente. Esto provoca que cuando intentemos formar parte de una causa de forma activa, no utilicemos nuestros recursos de la mejor forma por culpa de los distintos prejuicios o sesgos cognitivos que tenemos por causas evolutivas. Algunos ejemplos de estos sesgos cognitivos:

-Una incompetencia a la hora de comparar correctamente distintas magnitudes cuando estas son muy grandes.

-Confundimos aquello que deseamos que suceda con aquello que es previsible que suceda.
-Creemos que nuestras propias experiencias representan adecuadamente el conjunto de lo que ocurre. -Nos cuesta cambiar nuestra forma de ver las cosas incluso cuando se nos presentan evidencias nuevas que deberían cambiar nuestras posiciones o inclinaciones. 

-Tendemos a no incluir en nuestras consideraciones aquellas opciones en las que hay incertidumbre.

El altruismo biológico en etología y, por consiguiente, en la biología evolutiva, es el patrón de comportamiento animal en el cual un individuo pone en riesgo su vida para proteger y beneficiar a otros miembros del grupo. Casi todas estas teorías explican cómo un individuo puede sacrificar incluso su propia supervivencia por proteger la de los demás, aunque siempre añaden el hecho de que entre los miembros de ese grupo ha de hallarse algún miembro que comparta parte de sus mismos genes. Esta sería una manera de asegurar la continuidad de su información genética. Pese a ello, esta teoría resulta insuficiente para explicar las conductas altruistas que se desarrollan hacia individuos no emparentados, es decir, con los que no se comparte información genética.

Para explicar el altruismo no emparentado, se ha postulado que, en estos casos, la conducta altruista se lleva a cabo cuando el individuo espera de alguna forma ser recompensado por el otro o por algún otro miembro del grupo; o que por último algunas de las conductas altruistas pueden ser el resultado de la necesidad del individuo de sentirse aceptado por el grupo o una persona, por sentirse partícipe dentro de él, con lo cual indirectamente también obtiene un beneficio. Esta acepción fue propuesta por científicos que exploraban las razones por las que podría haber evolucionado el comportamiento no egoísta. Se aplica no solo a las personas (altruismo psicológico), sino también a animales e incluso a plantas.

Existe, sin embargo, una interpretación de la noción de altruismo contraria a la anteriormente expuesta. En su obra "El gen egoísta" (1976), Richard Dawkins acusa a estas tesis de desviarse del darwinismo ortodoxo y propone, a cambio, una concepción que entiende la evolución considerando el bien del individuo (gen), y no el de la especie, como factor capital. Dawkins sostiene que lo que habitualmente se entiende por altruismo, esto es: la conducta de un organismo cuando "se comporta de tal manera que contribuya a aumentar el bienestar de otro ser semejante a expensas de su propio bienestar" se trataría de un "altruismo individual aparente" y, por lo mismo, la conducta contraria sería un egoísmo individual aparente. Así, su tesis fuerte consiste en que existe una ley fundamental denominada "egoísmo de los genes" que explica tanto el altruismo como el egoísmo individual desde el punto de vista genético. En definitiva, Dawkins sostiene que la interpretación ortodoxa de la "selección natural" darwiniana es aquella que la concibe como selección de genes (egoísmo del gen), y no como selección de grupos (altruismo entre individuos).

En el siglo XIX, algunos filósofos como John Stuart Mill defendían que el ser humano no es naturalmente altruista, sino que necesita ser educado para llegar a serlo. Pitirim A. Sorokin reconocía limitaciones en el mismo. Recientemente se han hecho investigaciones que muestran que el altruismo aparece en el ser humano al cumplir los 18 meses, al igual que en el chimpancé; lo que sugiere que los seres humanos tienen una tendencia natural a ayudar a los demás.

Hay una serie de situaciones que nos incitan a los humanos a ayudarnos los unos a los otros y son las siguientes: cuando nos recompensan, cuando estamos de buen humor, cuando alguien más ayuda al hacer una atribución de altruismo y cuando las normas dictan ayuda.




</doc>
<doc id="28035" url="https://es.wikipedia.org/wiki?curid=28035" title="Human Behaviour">
Human Behaviour

Human Behaviour fue el primer sencillo de la cantante y compositora islandesa Björk. También es el primer sencillo de "Debut", su primer álbum solista. Contiene una muestra de «Go down dying» de Tom Jobim. La canción refleja la naturaleza y las emociones humanas desde un punto de vista animal. Forma parte de una trilogía de canciones que incluye Isobel y Bachelorette.
También hay editada una versión acústica de Human Behaviour que Bjork grabó para el programa de TVE Planeta Rock el 13 de octubre de 1993. Es parte de una de las versiones single Violent Happy.

En Francia se publica una versión en digipack cuando se alcanzan las 100000 copias vendidas del álbum en el que se incluye un CD que contiene un agradecimiento grabado por la propia Björk a los fans del país galo.

El videoclip de Human Behaviour fue dirigido por el director francés Michel Gondry. El vídeo es algo surrealista: Björk es cazada por un oso en el bosque. Además, vuela a la Luna y planta una bandera de la URSS. Acaba siendo comida por el oso y atrapada en su estómago.

El vídeo recibió 6 nominaciones a los Premios MTV: Mejor Vídeo Femenino, Mejor Vídeo de Artista Revelación, Vídeo Revelación, Mejores Efectos Especiales, Mejor Dirección Artística y Mejor Director, ganando ninguno de ellos. Además fue nominado a los Premios Grammy, perdiendo contra "Steam" de Peter Gabriel.

UK CD 1


UK CD 2


UK Vinilo 12"

"Cara A"
"Cara B"

UK Vinilo 12" Promo (1)

"Cara A"
"Cara B"

UK Vinilo 12" Promo (2)

"Cara A"
"Cara B"

UK Vinilo 10" Promo Edición Limitada

"Cara A"
"Cara B"

EUR CD


FRA CD Promo


FRA Vinilo 12" Promo (1)

"Cara A"
"Cara B"

FRA Vinilo 12" Promo (2)

"Cara A"
"Cara B"

EEUU CD Promo


EEUU Vinilo 12"

"Cara A"
"Cara B"

EEUU Vinilo 12" Promo

"Cara A"
"Cara B"

JPN CD





</doc>
<doc id="28037" url="https://es.wikipedia.org/wiki?curid=28037" title="All is full of love">
All is full of love

«All is Full of Love» es un sencillo lanzado en junio de 1999 por la cantante y compositora islandesa Björk. Pertenece a "Homogenic", su tercer álbum como solista, o cuarto si se toma en cuenta "Björk".

El videoclip de la canción seguía emitiéndose en el 2011 en la MTV en su bloque de viedobox clásicos, junto a vídeos como "Ava Adore" de The Smashing Pumpkins, "Friday I'm in Love" de The Cure.

En EE. UU. la canción fue un éxito dance de rock alternativo, de hecho alcanzó el puesto nº. 8 en las listas dance de EE. UU.. El sencillo fue el primero en la discografía de Björk en publicarse en el nuevo formato de "DVD single" para mejorar la calidad del vídeo. 

La canción tiene sonidos inspirados por máquinas y está acompañado por instrumentos orquestales y clavicordio tocado por Guy Sigsworth. Fue originalmente lanzada como sencillo dance por Funkstorung con sus remixes a finales del 1998, pero después recibió un sencillo propio con un vídeo hecho para la canción en el verano de 1999.

El videoclip fue dirigido por Chris Cunningham y en él los protagonistas son dos robots que se aman.

"All is Full of Love" recibió una candidatura a los premios Grammy y ganó varios, como "Mejor Video" y "Mejores Efectos Especiales" en los "MTV Video Awards" del año 2000. El video es en sí mismo una muestra de la contradicción existente en "Homogenic", el blanco y el negro y el amor y la máquina (metáforas de la cuerda y la electrónica existentes en el propio disco).

El vídeo fue censurado por algunas cadenas porque se decía que daba una imagen homosexual, al ser los robots más bien femeninos.










Se lanzaron tres versiones de «All is Full of Love».

Nombre: "All is Full of Love"
Fecha de lanzamiento: junio de 1999
Formato: CD

Nombre: "All is Full of Love"
Fecha de lanzamiento: junio de 1999
Formato: DVD




</doc>
<doc id="28038" url="https://es.wikipedia.org/wiki?curid=28038" title="Hunter (canción de Björk)">
Hunter (canción de Björk)

«Hunter» es un sencillo lanzado en octubre de 1998 por la cantante y compositora islandesa Björk. El mismo corresponde a "Homogenic", su tercer álbum solista.
La canción también apareció en la de la película .

El videoclip fue dirigido por Paul White de Me Company y fue realizado con animación de imágenes en tres dimensiones (3D) a cargo de la compañía de efectos especiales Digital Domain. En vemos a una Björk calva revolviéndose y en algunos momentos transformándose en oso polar. La metamorfosis representa la fusión entre orgánico y tecnológico presente en la canción, y el "cazador" del cual habla la letra.

Se lanzaron tres versiones de "Hunter".

Nombre: "Hunter".
Fecha de lanzamiento: octubre de 1998.
Formato: CD.

Nombre: "Hunter".
Fecha de lanzamiento: octubre de 1998.
Formato: CD.




</doc>
<doc id="28039" url="https://es.wikipedia.org/wiki?curid=28039" title="Pagan Poetry">
Pagan Poetry

«Pagan Poetry» (en español: «Poesía pagana») es una canción de la cantante islandesa Björk, tomado de su álbum "Vespertine". La canción alcanzó el número 38 en los gráficos musicales de Reino Unido y número 12 en Canadá. Fue escrita y producida por Björk con una producción adicional por Marius De Vries y mezclado por Mark "Spike" Stent. El video musical de la canción fue uno de los más controvertidos en toda la carrera de la cantante.

La canción «Pagan Poetry» fue escrita y producida por Björk.

Hemos discutido cómo hacer algo con la imagen en movimiento que era un espejo de lo que estaba pasando musicalmente. . . . Tenía que tener una mirada diferente de las imágenes de vídeo y de las imágenes de vídeo alteradas digitalmente. Sabía que tenía que mirar como exquisitos como sea posible. Es quitando el artificio y los efectos digitales, en la imagen cruda de Björk.

El video musical fue dirigido por Nick Knight quien ya había fotografiado a Björk para la portada del álbum "Homogenic" de (1997). Knight explica que el video narra sobre «una mujer preparándose para el matrimonio y para su amante». Fue considerado uno de los vídeos más controvertidos de Björk. El video contiene tres escenas: una toma de video de perforaciones, un vídeo privado real grabado por Björk y una escena con el vestido blanco diseñado por Alexander McQueen.

La escenas de los pírsines y la escena del vestido se hicieron en un día, en junio de 2001, en el estudio de fotografía de Nick Knight al noroeste de Londres. Las primeras escenas pertenecen a efectos visuales de posproducción por Peter Marin. Marin editó principalmente las escenas privadas y de perforaciones con un efecto abstracto, lineal y casi acuarelístico. Para las perforaciones se utilizaron dobles, un equipo de pírsines y una enfermera. Björk solo perforó su oreja con los hilos de perlas. La escena con el vestido fueron grabadas directamente, sin ninguna edición y cortes.

El video comienza con una imagen desenfocada de un hilo, por donde caen algunas perlas. Seguido a éste, un líquido blanco salta a la toma, haciendo alusión a un orgasmo. A continuación, se muestra escenas explícitas de sexo no simulado (como felación y penetración vaginal) veladas por un efecto rotoscópico y animaciones en 3D. A lo largo de estas escenas, aparecen perforaciones reales de alto riesgo. Estas escenas, junto a las escenas sexuales se entrecortan y son mostradas con los efectos mencionados. Luego, Björk aparece con el vestido blanco diseñado por Alexander McQueen, que cubre de cintura a abajo del cuerpo. En toda la parte superior, principalmente en el pecho, varias perlas se encajan a través de su piel. Ella se agita emocionalmente al ritmo de la música, jalándose algunos hilos con perlas. Finalmente, aparece la "espalda" de Björk perforada por un corsé de pírsines.

El video musical fue considerado en la lista de MTV como uno de los videos más controvertidos, al poseer imágenes de sexo explícito, sexo oral y perforaciones de alto riesgo. Fue censurado en Estados Unidos y Latinoamérica. Fue finalmente pasado a MTV2 para ser mostrado sin ninguna edición.

El sencillo fue lanzado en CD dobles y un DVD. Los cedés incluyen un remix por Mathew Herbert, una nueva versión de la canción «Aurora» del álbum Vespertine, y unos canciones de lado B «Batabid» y «Domestica». En un comienzo, "Domestika" era el título de trabajo para "Vespertine", y la canción era incluida como «Lost Keys», pero más tarde se cambió.

«Pagan Poetry» ha sido muy elogiado por la crítica, citando como un punto culminante del álbum. Allmusic, dijo de "Pagan Poetry", que "comparte una serenidad amplia con más los más silenciosos momentos del álbum" e incluyó esta canción como una selección de pista, la revista Rolling Stone dijo: "Pagan Poetry", despliega los cielos de Zeena Parkins con el arpa y un buque de cajas de música con un toque de casa de té asiático. Blender dijo: "Pagan Poetry" suena como el preludio de un interludio sexual particularmente exótico". En marzo de 2006, en el número 77 de la edición española de Rolling Stone, "Pagan Poetry" fue clasificado con el número 38 por los profesionales de la música española y los expertos en una lista de las mejores canciones del siglo 21. Slant Magazine dijo del álbum "Vespertine delicadamente deja rastros del ciclo de dicha relación" y llamó a la canción "la pérdida de la identidad personal y la completa trampa posesiva" Pitchfork Media colocó la canción en el número 227 en su lista de "El Top 500 canciones de la década de 2000".







</doc>
<doc id="28040" url="https://es.wikipedia.org/wiki?curid=28040" title="The Plainsman">
The Plainsman

The Plainsman, conocida como El llanero en Argentina y como Buffalo Bill en España, es una película protagonizada por Gary Cooper.

"Buffalo Bill" es un relato sobre tres personajes reales del Oeste americano, Wild Bill Hickok (Gary Cooper), Calamity Jane (Jean Arthur) y Buffalo Bill (James Ellison).

La película se tituló originalmente "The Plainsman" y estuvo dirigida por Cecil B. DeMille, a pesar de que la participación del personaje de Buffalo Bill es destacada es secundaria pues la trama principal está llevada por la historia de amor entre Wild Bill Hickok y Calamity Jane.


</doc>
<doc id="28043" url="https://es.wikipedia.org/wiki?curid=28043" title="Bat 21">
Bat 21

Bat 21 es una película estadounidense de 1988, basada en la novela homónima de William C. Anderson y dirigida por Peter Markle, con Gene Hackman y Danny Glover en los principales papeles.

Durante la Guerra de Vietnam, un avión EB-66 de observación es derribado. El único superviviente es el piloto teniente coronel Hambleton (Gene Hackman), que además es un experto en misiles. Como Hambleton es un militar de gran interés para el ejército estadounidense, se pone en marcha una misión de rescate, a pesar de ser ésta muy peligrosa. Hambleton se comunica con el equipo de rescate mediante una radio portátil. El problema es que el Vietcong le está escuchando, y Hambleton lo sabe. El seguimiento de la operación de rescate es asignado a un controlador aéreo avanzado (Danny Glover). Puesto que el rescate en la zona del derribo es imposible, el propio teniente coronel Hambleton idea un plan para llegar a otra zona de rescate más segura: un sistema basado en la forma de diferentes hoyos de campos de golf que conoce, con el cual transmite sus movimientos al equipo de rescate sin que los enemigos, que escuchan sus transmisiones, puedan descifrarlo (en teoría, al ser el golf un deporte desconocido para ellos). 

La película está basada en hechos reales: el piloto y experto en contramedidas electrónicas (con el nombre en clave de Bat 21, que es el que da nombre a la película, por cuestiones de inteligencia y para evitar el rastreo enemigo o el uso del derribado con otros fines) es tratado de rescatar, pero la misión resulta muy difícil debido a que el Vietcong está lanzando la mayor ofensiva terrestre de la guerra, durante las celebraciones del Tet (podría hacerse una analogía con la Navidad cristiana), momento en el que los norteamericanos no iban a atacar como respeto a la fe local y para conservar la simpatía de Vietnam del Sur, que mantenía esas creencias.


</doc>
<doc id="28054" url="https://es.wikipedia.org/wiki?curid=28054" title="Pat Garrett y Billy the Kid">
Pat Garrett y Billy the Kid

Pat Garrett y Billy The Kid es un western de 1973 procedente de EE. UU., dirigido por Sam Peckinpah y protagonizado por los conocidos actores James Coburn y Kris Kristofferson.

La película también cuenta con Bob Dylan para la música (aparte de actuar), lo cual dio lugar a la banda sonora del mismo nombre.

Pat Garrett (James Coburn), que había sido compañero del bandido Billy the Kid (Kris Kristofferson), se ha pasado al otro lado de la ley y es ahora sheriff del condado de Lincoln. Defiende los intereses del Gobernador Lew Wallace (Jason Robards) y de los ganaderos del territorio en el que actúa su antiguo compañero. 

Pocos días después de ser nombrado sheriff, Garrett consigue frustrar un intento de robo de Billy y lo lleva a prisión. Sin embargo, este consigue escapar matando a cuatro hombres. Garrett lo persigue sin descanso durante semanas. Sin embargo, los ganaderos son tan poderosos que algunas cosas escapan de su poder.

El trabajo fuera de la ley (pero a su vez dentro de ella) del sheriff Pat Garrett, consiste básicamenete en perseguir y conseguir información de viejos amigos y conocidos, y deshacerse así del que alguna vez fue compañero suyo de fechorías tiempo atrás y terminó muerto gracias a un sherif del condado.




</doc>
<doc id="28058" url="https://es.wikipedia.org/wiki?curid=28058" title="Meiji">
Meiji

Meiji es un término que puede referirse a:

</doc>
<doc id="28079" url="https://es.wikipedia.org/wiki?curid=28079" title="Sabrina (película de 1954)">
Sabrina (película de 1954)

Sabrina ("Sabrina") es una película estadounidense de 1954. Es adaptación de la obra de teatro de 1953 "Sabrina Fair" (subtitulada "A Woman of the World"), escrita por Samuel A. Taylor (1912 - 2000).

La película fue dirigida por Billy Wilder, y contó con Audrey Hepburn, Humphrey Bogart y William Holden como actores principales. Fue candidata a seis Oscar, entre ellos al mejor director, a la mejor actriz principal (Hepburn) y al mejor guion adaptado, pero finalmente solo ganaría el de mejor vestuario.

Sabrina Fairchild (Audrey Hepburn) es la hija de Thomas, el chófer de la familia Larrabee, y desde niña está locamente enamorada de David Larrabee (William Holden). David es un vividor y mujeriego, divorciado ya tres veces, que sin embargo nunca ha reparado en ella, lo que provoca que, desconsolada, decida suicidarse envenenándose con monóxido de carbono, encerrándose en el garaje y poniendo en marcha a la vez los ocho coches de la familia. Lo impide Linus (Humphrey Bogart), el hermano mayor de David, un hombre dedicado a la familia y a sus empresas.

Avergonzada por la situación, Sabrina se marcha a París para estudiar en una escuela de cocina. Cuando dos años después vuelve a la residencia de los Larrabee, se ha convertido en una mujer sofisticada y atractiva que llama la atención de David cuando casualmente la encuentra en la estación, pese a no reconocerla al principio como la hija del chófer. Esa misma tarde, la invita a una recepción en la mansión. Linus, conociendo el carácter de su hermano, teme que el compromiso de David con Elizabeth Tyson (Martha Hyer) acordado por el patriarca de los Larrabee peligre, y con él la fusión entre Larrabee Industries y la empresa del padre de Elizabeth. Linus discute con David sobre su responsabilidad ante la familia, pero éste no quiere saber nada más allá de su propio interés, así que Linus se decide por una maniobra alternativa: intentará seducir a Sabrina, de manera que se enamore de él y olvide a su hermano, y luego la mandará de nuevo a París para asegurar el matrimonio de David y el acuerdo empresarial.

Ayudado por un accidente que sufre David, Linus y Sabrina comienzan a pasar más tiempo juntos, y ella se da cuenta de que él no sólo es un hombre de negocios sin tiempo para los sentimientos. Sin embargo, Linus acaba también enamorado de Sabrina, y llevado por los remordimientos le cuenta su plan dirigido ante todo por los intereses de las empresas familiares. Sabrina, profundamente decepcionada, se muestra de acuerdo en dejar la mansión Larrabee a la mañana siguiente. Linus habla con David para ponerle al corriente de la situación; David comprende que Linus está enamorado de Sabrina pero siempre va a anteponer las necesidades de la familia a su propia felicidad.

Al día siguiente está convocada la reunión del consejo de administración de la empresa para formalizar la firma de la fusión. Cuando David no se presenta a la hora indicada, Linus asume que ha escapado a París con Sabrina, pero en el último momento el hermano menor aparece, disculpándose por el retraso, y confirma su decisión de casarse con Elizabeth Tyson y llevar adelante la fusión de las empresas. Liberado de su compromiso con el negocio, Linus acepta sus sentimientos hacia Sabrina y corre para reunirse con ella en el barco para zarpar juntos hacia su nueva vida en París.


Sabrina supone el retorno de Wilder a la comedia romántica sofisticada, al estilo de Ernst Lubitsch y de la primera época de Wilder en la Paramount. Wilder quiso subrayar un aspecto poco desarrollado en la obra de Samuel Taylor: la idea de que Bogart se utiliza a sí mismo para que la chica desista de su hermano y éste pueda casarse con la hija de un magnate azucarero y garantizar así una lucrativa fusión para la familia.

Wilder se centra en el personaje de Bogart y lo convierte en una Ninotchka masculina que da la espalda a la vida y cuya sombría actitud es el fruto de su dedicación al trabajo. Muchos de los memorables toques visuales ponen de relieve su planteamiento de una vida dedicada a los negocios (por ejemplo, llama a una docena de secretarias de mediana edad para saltar sobre una lámina de plástico y comprobar su resistencia ante un avergonzado William Holden). Los planos desconexos de Bogart paseando por su cavernoso despacho subrayan una vida de éxitos pero solitaria. Cuando dimite para seguir a Hepburn en su viaje por Europa, Wilder le sitúa corriendo por una larga perspectiva de puertas que se abren, el final de su vacua vida de ejecutivo.

Bogart se presta a engañar a Hepburn sustituyendo a Holden por motivos puramente egoístas, pensando en sus negocios, pero una vez la conoce, se siente tan culpable como Charles Boyer en "Si no amaneciera", a la vez que admite necesitar amor, como Greta Garbo en "Ninotchka". Wilder y Lehman revisten de gran refinamiento dichas revelaciones.

Durante la película las relaciones entre Bogart y el resto del reparto fueron bastante tensas. Bogart aceptó ese papel porque su agente le convenció de que debía participar en una comedia, para mitigar la imagen de duro que tenía.En cambio, la relación entre Hepburn y Holden fue excelente durante todo el rodaje. 

La película tuvo un "remake" en 1995, dirigido por Sydney Pollack, con Julia Ormond como Sabrina, Greg Kinnear como David y Harrison Ford como Linus.

Escenas de "Sabrina"



</doc>
<doc id="28089" url="https://es.wikipedia.org/wiki?curid=28089" title="Meiji Tennō">
Meiji Tennō

Mutsuhito conocido por su nombre póstumo como (Kioto, 3 de noviembre de 1852-Tokio, 30 de julio de 1912) fue hijo de Kōmei Tennō y la consorte Nakayama Yoshiko, fue el emperador de Japón número 122º, de acuerdo con el orden tradicional de sucesión imperial Japonés, reinando desde el 3 de febrero de 1867, hasta su muerte en 1912.

Cuando Mutsuhito nació, Japón era un país aislado, preindustrial y feudal, dominado por el shogunato Tokugawa y los "daimyō", que controlaban los más de 250 dominios descentralizados del país. 
Como todos sus predecesores, desde su muerte ha sido llamado por su nombre póstumo. Desde su muerte, la tradición de dar al emperador el nombre de la era conjuntamente con su reinado fue establecida. Habiendo gobernado este en el periodo Meiji, ahora es conocido como Emperador Meiji. Su nombre personal era Mutsuhito. Fuera de Japón, algunas veces se refieren a él, como Emperador Mutsuhito, sin embargo, en Japón, los emperadores sólo son llamados por su nombre póstumo. Llamar a un emperador por su nombre personal podría ser considerado un exceso de confianza e incluso un acto despectivo.

El shogunato Tokugawa se había establecido a principios del siglo 17. Bajo su regla, el shōgun gobernó Japón. Unos 180 señores, conocidos como daimyōs, gobernaban reinos autónomos bajo el shōgun, y ocasionalmente el shōgun pedía regalos a los daimyōs pero no los imponía impuestos. El shōgun también controlaba a los daimyōs de otras maneras; solo el shōgun podía aprobar los matrimonios de daimyō, y el shōgun podía deshacerse de un daimyō de sus tierras. 

Tokugawa Ieyasu, que se había retirado oficialmente de su cargo en 1605, fue el primer shōgun Tokugawa. Al retirarse, Tokugawa Ieyasu y su hijo Tokugawa Hidetada, el shōgun titular, emitieron un código de conducta para la nobleza en 1605. Bajo Según el código, el Emperador debía dedicar su tiempo a la erudición y las artes. Los emperadores bajo el shogunato parecen haberse adherido estrechamente a este código al estudiar los clásicos confucianos y dedicar tiempo a la poesía y la caligrafía. A los emperadores solo se les enseñaron los rudimentos de la historia y geografía japonesa y china. El shōgun no buscó el consentimiento o el consejo del Emperador para sus acciones. 

Poco después de tomar el control a principios del siglo XVII, los funcionarios del shogunato (conocidos genéricamente como bakufu) terminaron gran parte del comercio occidental con Japón y prohibieron a los misioneros de las islas. Además del importante comercio chino, solo los holandeses continuaron el comercio con Japón, manteniendo un puesto en la isla de Dejima por Nagasaki. Sin embargo, a principios del siglo XIX, los buques europeos y estadounidenses aparecieron en las aguas alrededor de Japón con una frecuencia cada vez mayor.

Los matrimonios consanguíneos eran comunes en la historia temprana de la clase alta japonesa como una forma de proteger el linaje ideal o real; Sin embargo, esto vino con consecuencias inesperadas. Meiji tenía enfermedades hereditarias que eran el resultado de la endogamia. Estos defectos genéticos incluyeron, entre otros, el prognatismo mandibular y la deformación espinal, que también se pueden encontrar en sus hijos. Además de las enfermedades congénitas, Meiji también sufría de beriberi y apenas podía caminar. Tuvo quince hijos con sus concubinas. Diez de ellos murieron prematuramente. El príncipe Yoshihito (más tarde emperador Taishō) fue el único heredero masculino que alcanzó la edad adulta, pero su cuerpo y mente eran débiles, con meningitis, diabetes, trombosis cerebral y enfermedades mentales.

El Príncipe Mutsuhito nació el 3 de noviembre de 1852 en una pequeña casa en la propiedad de su abuelo materno en el extremo norte del Palacio. La madre del príncipe Mutsuhito, Nakayama Yoshiko, era una concubina para con su padre, el emperador Kōmei, y ella era la hija del consejero principal en funciones, Nakayama Tadayasu. El joven príncipe recibió el nombre de Sachinomiya, o Príncipe Sachi. 

Gran parte de la infancia del Emperador se conoce solo a través de relatos posteriores, que su biógrafo Donald Keene señala que a menudo son contradictorios. Un contemporáneo describió a Mutsuhito como saludable y fuerte, algo intimidante y excepcionalmente talentoso en el sumo. Otro afirma que el príncipe era delicado y a menudo enfermo. Algunos biógrafos afirman que se desmayó cuando escuchó disparos por primera vez, mientras que otros lo niegan. El 16 de agosto de 1860, Sachinomiya fue proclamado príncipe de la sangre y heredero al trono y fue formalmente adoptado por la consorte de su padre. Más tarde ese año, el 11 de noviembre, fue proclamado príncipe heredero y se le dio un nombre adulto, Mutsuhito. El príncipe comenzó su educación a la edad de siete años. Probó ser un estudiante indiferente, y más tarde en la vida escribió poemas lamentando no haberse aplicado más en la práctica de la escritura. 

El emperador Kōmei cayó gravemente enfermo a la edad de 36 años y murió el 30 de enero de 1867. 

En una breve ceremonia en Kioto, el príncipe heredero ascendió formalmente al trono el 3 de febrero de 1867. El nuevo emperador continuó su educación clásica, que no incluía asuntos de política. Mientras tanto, el shōgun Yoshinobu luchó por mantener el poder. En repetidas ocasiones solicitó la confirmación del emperador de sus acciones, que finalmente recibió, pero no hay indicios de que el joven emperador estuviera involucrado en las decisiones. Los shishi y otros rebeldes continuaron dando forma a su visión del nuevo Japón, y aunque veneraban al Emperador, no habían pensado en que él participara activamente en el proceso político. 

La lucha política alcanzó su punto culminante a fines de 1867. Se llegó a un acuerdo mediante el cual Yoshinobu mantendría su título y parte de su poder, pero el poder legislativo se conferiría a una legislatura bicameral basada en el modelo británico. El acuerdo se vino abajo y el 9 de noviembre de 1867, Yoshinobu presentó oficialmente su renuncia al Emperador y renunció formalmente diez días después. Al mes siguiente, los rebeldes marcharon hacia Kyoto, tomando el control del Palacio Imperial. El 4 de enero de 1868, el Emperador leyó ceremoniosamente un documento ante el tribunal que proclamaba la "restauración" del dominio imperial, y al mes siguiente, se enviaron documentos a potencias extranjeras: 

   ""El Emperador de Japón anuncia a los soberanos de todos los países extranjeros y a sus súbditos que se ha otorgado permiso al shōgun Tokugawa Yoshinobu para devolver el poder de gobierno de acuerdo con su propia solicitud. En adelante, ejerceremos la autoridad suprema en todos los asuntos internos y externos del país. En consecuencia, el título de Emperador debe ser sustituido por el de Tycoon, en el que se han hecho los tratados. Los oficiales están siendo nombrados por nosotros para la conducción de los asuntos exteriores. Es deseable que los representantes de los poderes del tratado reconozcan este anuncio"."

Yoshinobu se resistió solo brevemente, pero no fue hasta finales de 1869 que los últimos grupos de bakufu fueron finalmente derrotados en la Guerra de Boshin. En el noveno mes del año siguiente, la era se cambió a Meiji, o "gobierno ilustrado", que luego se usó para el nombre póstumo del Emperador. Esto marcó el comienzo de la costumbre de nombrar póstumamente al Emperador después de la era durante la cual gobernó.
Meiji Tennō fue el líder simbólico de la restauración Meiji en donde el shogunato Tokugawa fue abolido por fuerzas imperiales en una breve convulsión interna conocida como la guerra Boshin. Tras esto el Emperador Meiji proclamó la conversión del Japón a un gobierno democrático de corte occidental. Sin embargo, el Parlamento Japonés carecía de poderes reales y tampoco los tenía el Emperador Meiji, ya que el poder pasó entonces de mano de los Tokugawa a una nueva nobleza "genrō" formada por los daimyō y samuráis que habían ayudado a la restauración. Esta nueva oligarquía ubicó a sus hombres en las esferas políticas y militares del nuevo gobierno.La restauración y modernización consecuente convirtieron a Japón en una potencia industrial, ubicándola por encima de otras naciones en el Pacífico. Si bien la función del Emperador en la restauración es discutida, su influencia pudo haber sido realmente importante en las guerras en que Japón se vio involucrada a comienzos del Siglo XX. Entre las medidas que tomó se destacan, además de las ya mencionadas, el traslado de la capital de Kioto a Tokio, la implantación de un nuevo sistema de estudios (1872), la institución del Senado, "Genroin" (1875), la inauguración de la Asamblea Nacional (1890) y la anexión de Corea (1910). El Emperador Meiji demostró una gran longevidad en el trono manteniéndose en el poder por más de 40 años, tras la cual, se consolida el desarrollo económico y político de Japón, alzándose como potencia dominante en Asia.

El 19 de septiembre de 1868, el Emperador anunció que el nombre de la ciudad de Edo debía cambiarse a Tokio, que significa "capital oriental". Fue coronado formalmente en Kyoto el 15 de octubre (una ceremonia que se había pospuesto desde el año anterior debido a los disturbios civiles). Poco antes de la coronación, anunció que la nueva era, o nengō, se llamaría Meiji o "gobierno ilustrado". Hasta ahora, el nengō a menudo había sido cambiado varias veces en el reinado de un Emperador; a partir de ahora, se anunció que solo habría un nengō por reinado.

Poco después de su coronación, el Emperador viajó a Tokio por carretera, visitándolo por primera vez. Llegó a fines de noviembre y comenzó una estadía prolongada distribuyendo sake entre la población. La población de Tokio estaba ansiosa por una visita imperial. Tokio había sido el sitio de la corte de shōgun y la población de la ciudad temía que con la abolición del shogunato, la ciudad pudiera caer en decadencia. No sería hasta 1889 que se tomó la decisión final de trasladar la capital a Tokio. Mientras estaba en Tokio, el Emperador abordó un barco naval japonés por primera vez, y al día siguiente dio instrucciones para estudiar cómo se podría fortalecer la armada japonesa. Poco después de su regreso a Kioto, se emitió un rescripto a nombre del Emperador (pero probablemente escrito por funcionarios de la corte). Indicaba su intención de involucrarse en los asuntos del gobierno. Y, de hecho, asistió a reuniones de gabinete e innumerables funciones gubernamentales, aunque rara vez hablaba, casi hasta el día de su muerte. 

Los revolucionarios exitosos se organizaron en un Consejo de Estado y, posteriormente, en un sistema en el que tres ministros principales lideraron el gobierno. Esta estructura duraría hasta el establecimiento de un primer ministro, que lideraría un gabinete de manera occidental, en 1885. Inicialmente, ni siquiera la retención del Emperador era segura; El líder revolucionario Gotō Shōjirō declaró más tarde que algunos funcionarios "temían que los extremistas pudieran ir más allá y abolir el Mikado".Los nuevos líderes de Japón buscaron reformar el sistema de mosaico de dominios gobernados por los daimyōs. En 1869, varios de los daimyōs que habían apoyado la revolución dieron sus propiedades de tierra al Emperador y fueron nombrados de nuevo como gobernadores, con salarios considerables. Para el año siguiente, todos los demás daimyō habían seguido su ejemplo.

En 1871, cuando Japón se organizó en 72 prefecturas, el Emperador anunció que los dominios serían completamente abolidos. Los daimyō serían compensados con salarios anuales equivalentes al diez por ciento de sus ingresos anteriores (de los cuales ahora no tenían que deducir el costo de gobernar), pero se les exigió mudarse a la nueva capital, Tokio. La mayoría de los daimyō se retiraron de la política.

La nueva administración abolió gradualmente la mayoría de los privilegios del samurai, incluido su derecho a un estipendio del gobierno. Sin embargo, a diferencia de los daimyōs, muchos samurai sufrieron financieramente por este cambio. La mayoría de las otras distinciones de clase fueron abolidas. La discriminación legalizada contra la burakumin terminó. Sin embargo, estas clases continúan sufriendo discriminación en Japón hasta la actualidad. 

Aunque se formó un nuevo parlamento, no tenía poder real. El poder había pasado del Tokugawa a las manos de esos daimyōs y otros samuráis que habían dirigido la Restauración. Japón estaba así controlado por el Genrō, una oligarquía que comprendía a los hombres más poderosos de las esferas militar, política y económica. El emperador mostró una mayor longevidad política que sus predecesores recientes, ya que fue el primer monarca japonés en permanecer en el trono después de los 50 años desde la abdicación del emperador Ōgimachi en 1586.

Los japoneses se enorgullecen de la Restauración Meiji, ya que junto con la industrialización que lo acompaña permitieron a Japón convertirse en el poder preeminente en el Pacífico y en un jugador importante en el mundo en una generación. Sin embargo, el papel del Emperador Meiji en la Restauración, así como la cantidad de autoridad personal e influencia que ejerció durante su reinado, sigue siendo discutible. No guardaba ningún diario, casi no escribía cartas (a diferencia de su padre) y dejaba "no más de tres o cuatro" fotografías. Las cuentas de personas que lo conocieron o estaban cerca de él generalmente contienen poca información sustancial o están mutuamente contradictorio.

Cerca del final de su vida, varios anarquistas, incluido Shūsui Kōtoku, fueron ejecutados (1911) acusados ​​de haber conspirado para asesinar al soberano. Esta conspiración se conocía como el Incidente de alta traición (1910).

El emperador Meiji, que sufría de diabetes, nefritis y gastroenteritis, murió de uremia. Aunque el anuncio oficial decía que murió a las 00:42 el 30 de julio de 1912, la muerte real fue a las 22:40 el 29 de julio.

Para 1912, Japón había pasado por una revolución política, económica y social y surgió como una de las grandes potencias del mundo. El New York Times resumió esta transformación en el funeral del Emperador en 1912 como: "el contraste entre lo que precedió al coche fúnebre y lo que le siguió fue realmente sorprendente. Antes de que se convirtiera en el antiguo Japón; después del nuevo Japón". 

Después de la muerte del Emperador en 1912, la Dieta japonesa aprobó una resolución para conmemorar su papel en la Restauración Meiji. Se eligió un jardín de iris en un área de Tokio donde se conocía que visitaban el Emperador Meiji y la Emperatriz como la ubicación del edificio para el santuario sintoísta Meiji Jingū. El santuario no contiene la tumba del Emperador, que se encuentra en Fushimi Momoyama, al sur de Kioto. 

En la película "El último samurái" al emperador se le representa como un hombre débil y fácil de manejar, sin hacer alusión al riesgo de golpe de Estado, teniendo la presión de los shogunatos rebeldes que veían intereses económicos con Estados Unidos. La determinación del Emperador solo se muestra al final cuando hace respetar sus ideas rompiendo el tratado con los estadounidenses, después de consolidar su poder tras la batalla.

El emperador Meiji es interpretado por Toshirō Mifune en la película dramática de guerra japonesa de 1980 The Battle of Port Arthur (a veces denominada 203 Kochi). Dirigida por Toshio Masuda, la película representa el asedio de Port Arthur durante la guerra ruso-japonesa, y también protagonizada por Tatsuya Nakadai (como el general Nogi Maresuke) y Tetsuro Tamba (como el general Kodama Gentarō).





</doc>
<doc id="28094" url="https://es.wikipedia.org/wiki?curid=28094" title="Verdún (desambiguación)">
Verdún (desambiguación)

Verdún puede referirse a:

</doc>
<doc id="28104" url="https://es.wikipedia.org/wiki?curid=28104" title="Tratado de Versalles (desambiguación)">
Tratado de Versalles (desambiguación)

Tratado de Versalles puede referirse a alguno de los siguientes tratados firmados en el Palacio de Versalles de Francia:

</doc>
<doc id="28105" url="https://es.wikipedia.org/wiki?curid=28105" title="Presidente de los Estados Unidos">
Presidente de los Estados Unidos

El presidente de los Estados Unidos (; acrónimo: POTUS) es el jefe de Estado y de Gobierno de los Estados Unidos. Es el más alto cargo político del país por influencia y reconocimiento. El presidente lidera el poder ejecutivo del Gobierno federal.

Entre otros poderes y responsabilidades, el Artículo II de la Constitución de los Estados Unidos encarga al presidente la «fiel ejecución» de la ley federal, hace del presidente el comandante en jefe de las Fuerzas Armadas, lo autoriza a nombrar oficiales ejecutivos y judiciales con el consejo y consentimiento del Senado, lo sitúa al frente de la política exterior de los Estados Unidos, y permite al presidente conceder indultos o moratorias.

El presidente es elegido mediante sufragio indirecto por un colegio electoral (o por la Cámara de Representantes si el colegio electoral no concede la mayoría de votos a ningún candidato) para un mandato de cuatro años. Desde la ratificación de la Vigesimosegunda Enmienda en 1951, ninguna persona puede ser elegida para el cargo de presidente más de dos veces. En caso de muerte, destitución, dimisión o renuncia de un presidente, el vicepresidente asume la presidencia.

Hasta la fecha, ha habido un total de personas que han asumido el cargo y cuarenta y cinco presidencias. Esto ocurre porque el presidente Grover Cleveland sirvió en dos mandatos no consecutivos y se le cuenta por orden cronológico tanto como el vigesimosegundo como el vigesimocuarto presidente. De las personas elegidas para el cargo, cuatro murieron durante su mandato por causas naturales, uno dimitió y cuatro fueron asesinados. El primer presidente fue George Washington, que fue investido en 1789 después de un voto unánime del colegio electoral. William Henry Harrison fue el que menos tiempo permaneció en el cargo, con tan solo 32 días, y Franklin D. Roosevelt, con sus 12 años en el puesto, fue el que permaneció por más tiempo y el único presidente que sirvió por más de dos mandatos (ganó cuatro veces las elecciones presidenciales).

El actual presidente es el republicano Donald Trump, que tomó posesión el 20 de enero de 2017.

Desde principios del siglo XX, el papel hegemónico de los Estados Unidos en el escenario político y económico internacional ha llevado al presidente de este país a ser una figura conocida a nivel global y, debido a la condición del país como única superpotencia, en 2009 la revista "Forbes" calificaba a su titular como «la persona más poderosa del mundo».

El Tratado de París (1783) puso fin a la Guerra de Independencia y reconoció la constitución de las Trece Colonias como los Estados Unidos de América, pero con una estructura gubernamental inestable. El Segundo Congreso Continental había redactado los Artículos de la Confederación en 1777, describiendo una Confederación permanente, pero concediendo al Congreso de la Confederación (la única institución federal) poco poder para financiarse o para asegurar el cumplimiento de sus resoluciones. En parte, esto reflejaba la visión antimonárquica del período revolucionario y el nuevo sistema estadounidense fue explícitamente diseñado para prevenir el ascenso de un tirano estadounidense en sustitución del monarca británico.

Sin embargo, durante la depresión económica debida al colapso del dólar continental tras la Revolución estadounidense, la viabilidad del gobierno estadounidense se vio amenazada por el malestar político en varios estados, el empeño de los deudores en utilizar el gobierno popular para eliminar sus deudas y la aparente incapacidad del Congreso Continental de hacer frente a las obligaciones públicas asumidas durante la guerra. El Congreso también parecía incapaz de convertirse en un foro para la cooperación productiva entre los estados, que animaban el comercio y el desarrollo económico. En respuesta a esta problemática se convocó una Convención constitucional, inicialmente para reformar los Artículos de la Confederación, pero que posteriormente comenzó el diseño de un nuevo sistema de gobierno que incluiría un mayor poder ejecutivo aunque reteniendo un esencial control y equilibrio con la idea de restringir cualquier tendencia imperial en la presidencia.

Las personas que presidieron el Congreso Continental durante el período Revolucionario, y conforme a los Artículos de la Confederación, ostentaban el título de «presidente de los Estados Unidos en el Congreso Reunido» y a menudo se abreviaba como «presidente de los Estados Unidos». El cargo tenía poco poder ejecutivo claramente definido. Con la ratificación de la Constitución en 1787, se creó un poder ejecutivo separado, encabezado por el presidente de los Estados Unidos.

La autoridad ejecutiva del presidente conforme a la Constitución, moderada por el control de los poderes legislativo y judicial del gobierno federal, fue diseñada para solucionar los problemas políticos afrontados por la recién creada nación y para intentar superar futuros desafíos, siempre previniendo la subida al poder de un autócrata en una nación cautelosa frente a las autoridades monárquicas.

La Constitución de los Estados Unidos y sus posteriores Enmiendas fija los poderes y deberes del presidente:

El primer poder conferido al presidente por la Constitución estadounidense es el poder legislativo del veto presidencial. La llamada «Cláusula de Presentación» ("Presentment Clause") requiere que cualquier proyecto de ley aprobado por el Congreso sea presentado al presidente antes de que pueda convertirse en ley. Una vez que norma legal ha sido presentada, el presidente tiene tres opciones:


En 1996, el Congreso intentó cambiar el poder de veto presidencial con la "Line Item Veto Act". La legislación autorizó al presidente a firmar cualquier propuesta de ley de gastos en ley al mismo tiempo que eliminaba ciertos artículos de gastos dentro de la propuesta, en particular cualquier nuevo gasto, cualquier cantidad de gastos discrecionales, o cualquier nuevo beneficio fiscal limitado. Si el presidente eliminaba un artículo, el Congreso podría aprobar ese artículo en particular otra vez. Si el presidente vetara entonces la nueva legislación, el Congreso podría anular el veto con el procedimiento ordinario, o sea, con el voto de las dos terceras partes en ambas Cámaras. En el caso "Clinton contra la Ciudad de Nueva York" (1998), la Corte Suprema estadounidense resolvió que esta modificación del poder de veto presidencial era inconstitucional.

Quizás el más importante de todos los poderes presidenciales es su posición al frente de las Fuerzas Armadas de los Estados Unidos como su comandante en jefe. Mientras que el poder de declarar la guerra corresponde constitucionalmente al Congreso, el presidente comanda y dirige a sus ejércitos y es responsable de planear la estrategia militar. Los padres de la Constitución fueron cautos limitando los poderes presidenciales en cuanto a los militares; Alexander Hamilton lo explica en su "Ensayo Federalista n.º 69":

El Congreso, de acuerdo con la Resolución de Poderes de Guerra ("War Powers Resolution") de 1973, debe autorizar cualquier despliegue de tropas de más de 60 días de duración a menos que el propio Congreso haya declarado la guerra. Además, el Congreso ejerce cierta limitación al poder militar presidencial por su control y regulación de los gastos militares.

Junto con las fuerzas armadas, el presidente también está al frente de la política exterior. A través del Departamento de Estado y el Departamento de Defensa, el presidente es responsable de la protección de los estadounidenses en el extranjero y de los ciudadanos extranjeros en los Estados Unidos. El presidente decide si hay que reconocer nuevas naciones y nuevos gobiernos y negocia tratados con otras naciones, que se hacen vigentes en los Estados Unidos cuando son aprobados por las dos terceras partes del Senado. El presidente también puede negociar «acuerdos ejecutivos» con poderes extranjeros que no están sujetos a la confirmación de Senado.

El presidente es el director ejecutivo de los Estados Unidos, y está a la cabeza del poder ejecutivo del gobierno, cuya responsabilidad es «cuidar que las leyes sean fielmente ejecutadas». Para llevar a cabo este deber, se le otorga el control de los cuatro millones de empleados del poder ejecutivo federal.

Al presidente le corresponde el nombramiento de varios miembros del poder ejecutivo. Embajadores, miembros del Gabinete y otros oficiales federales, son todos designados por el presidente con el «consejo y consentimiento» de una mayoría del Senado. Los nombramientos realizados mientras el Senado no está en periodo de sesiones son temporales y expiran al final de la siguiente sesión del Senado. El presidente puede proponer unos 6000 nombramientos mientras ejerce su mandato.

El poder del presidente para cesar a funcionarios ejecutivos ha sido durante mucho tiempo objeto de debate. Generalmente, el presidente puede cesar a los funcionarios ejecutivos a su discreción. Sin embargo, el Congreso puede reducir por decreto la autoridad presidencial para cesar a comisionados de agencias reguladoras independientes y a ciertos oficiales ejecutivos inferiores.

El presidente también tiene la facultad de proponer jueces federales, incluidos miembros de la Corte Suprema de los Estados Unidos y de las Cortes de Apelaciones. Sin embargo, estos nombramientos requieren la confirmación del Senado y esto puede suponer un escollo importante ante la posibilidad de que un presidente quisiera formar una judicatura federal con una postura ideológica particular. El presidente puede designar jueces para los tribunales de distrito de los Estados Unidos, pero a menudo deferirá a la cortesía senatorial estos nombramientos. También puede conceder perdones e indultos, como se hace a menudo justo antes del final de un mandato presidencial.

El llamado «privilegio ejecutivo» otorga al presidente la capacidad de retener información al público, al Congreso y a los tribunales cuando el asunto atañe a la seguridad nacional. George Washington fue el primero en reclamar el privilegio cuando la Cámara de Representantes solicitó ciertos documentos sobre la negociación del Tratado Jay con el Reino de Gran Bretaña. Aunque el privilegio no figura en la Constitución ni en ninguna otra ley, la acción de Washington creó el precedente para el privilegio. Cuando Richard Nixon trató de usarlo como razón para no aportar unas pruebas ante una citación del Congreso durante el escándalo Watergate, la Corte Suprema sentenció en el caso "Estados Unidos contra Nixon", , que el privilegio ejecutivo no era de aplicación en casos donde un presidente intentaba evitar un procesamiento criminal. Cuando el presidente Bill Clinton intentó usar el privilegio ejecutivo en cuanto al escándalo Lewinsky, la Corte Suprema sentenció en el caso "Clinton contra Jones", , que el privilegio tampoco podía invocarse en los casos de pleitos civiles. Estos casos establecieron el precedente legal de que el privilegio ejecutivo es válido, pero el grado exacto del privilegio todavía está pendiente de una definición clara.

Aunque el presidente de los Estados Unidos no tiene capacidad para introducir legislación directamente, puede desempeñar un papel importante en su conformación, sobre todo si el partido político del presidente tiene mayoría en una o ambas Cámaras del Congreso. Los miembros del poder ejecutivo no pueden ocupar simultáneamente su puesto y un escaño en el Congreso, pero es habitual que redacten la legislación y que un Senador o Representante la presente por ellos. El presidente puede influir de una forma importante en el poder legislativo a través del informe anual, escrito u oral, que constitucionalmente debe presentar al Congreso, y que en la actualidad se denomina Discurso del Estado de la Unión. Este discurso a menudo perfila la oferta legislativa para el año próximo.

De acuerdo con el , el presidente puede convocar a una o a ambas Cámaras del Congreso para una sesión extraordinaria. Si ambas Cámaras no llegan a un acuerdo sobre la fecha de celebración de la convocatoria, el presidente puede designar una fecha para la reunión del Congreso. Esta facultad del presidente de convocar de forma extraordinaria el Congreso sólo se ejerció en 27 ocasiones en toda la historia de los Estados Unidos. La última fue ejercida en 1948 por Harry Truman.

El de la Constitución marca los requisitos necesarios para tener la consideración de elegible como presidente. Un candidato presidencial debe:


Con respecto al tema de la ciudadanía estadounidense, cumple aclarar que el Artículo II de la Constitución dice textualmente que es requisito ser «"a natural born Citizen, or a Citizen of the United States, at the time of the Adoption of this Constitution"», o sea, un ciudadano de nacimiento de los Estados Unidos. La Decimocuarta Enmienda, adoptada en 1868, define en su Sección 1, Cláusula 1 que «"All persons born or naturalized in the United States, and subject to the jurisdiction thereof, are Citizens of the United States and of the State wherein they reside."», esto es, que cualquier persona nacida o naturalizada en los Estados Unidos es legalmente ciudadano estadounidense, sin embargo, sin el requisito de nacimiento en suelo estadounidense, no serían elegibles. Este es un tema ampliamente debatido en el país, y para algunos columnistas como John W. Dean, antiguo consejero presidencial, es una cláusula constitucional obsoleta que contradice el espíritu del llamado «sueño americano» y entra en conflicto con el propio «Estatuto de Libertad» estadounidense, que da la bienvenida a los extranjeros, pero que les impide acceder al máximo puesto de responsabilidad del país.

Conforme a la Vigesimosegunda Enmienda, nadie puede ser elegido presidente más de dos veces. La Vigesimosegunda Enmienda también especifica que alguien que sirve más de dos años como presidente o presidente interino, de un mandato para el cual otro fue elegido como presidente, sólo puede optar a la presidencia una vez. Los estudiosos de la Constitución discrepan sobre si una persona que ya no es elegible para la presidencia podría ser elegida como vicepresidente, de acuerdo con los requisitos establecidos en la Duodécima Enmienda.

La Constitución contempla la descalificación de algunas personas para la presidencia. Bajo el , el Senado tiene la opción, a su criterio, de descalificar a altos cargos condenados tras un "impeachment" para ocupar otros cargos federales, incluida la presidencia. También, la Sección 3 de la Decimocuarta Enmienda prohíbe a cualquier persona que, habiendo prestado juramento para apoyar la Constitución, y que posteriormente se rebelara contra los Estados Unidos, pueda ser elegida para servir como presidente, a menos que cada Cámara del Congreso haya retirado la descalificación por un voto favorable de dos terceras partes de sus miembros.

La campaña presidencial contemporánea comienza antes de las elecciones primarias, cuando los dos principales partidos políticos estadounidenses hacen una selección de candidatos antes de sus convenciones nacionales de nominación, donde el elegido se convierte en el candidato del partido para la presidencia. Por lo general, el candidato presidencial del partido elige a un candidato a la vicepresidencia y esta opción es confirmada por la convención.

Los candidatos participan en debates televisados a escala nacional, que generalmente están restringidos a las candidaturas Demócrata y Republicana aunque en algunas ocasiones se invitan a terceros partidos, como el caso de Ross Perot en los debates de 1992. Los nominados de cada partido hacen campaña a lo largo de todo el país para explicar sus programas electorales, convencer a los votantes y solicitar contribuciones a la campaña. La mayor parte del proceso electoral moderno se centra en hacer campaña en los llamados «estados oscilantes» (aquellos en los que un partido no tiene históricamente una mayoría clara), a través de visitas frecuentes y anuncios en los medios de comunicación.

En los Estados Unidos el presidente es elegido mediante sufragio indirecto. Un determinado número de Electores representantes, conocidos colectivamente como Colegio electoral, eligen oficialmente al presidente. Durante el «"Election Day"» (el martes siguiente al primer lunes de noviembre), el electorado de cada uno de los estados y el Distrito de Columbia selecciona a estos electores por votación. Cada estado tiene asignado un determinado número de electores, que se corresponden con la suma de delegados de ese estado en cada una de las Cámaras del Congreso. En la mayoría de los estados la candidatura que obtiene la mayoría de los votos gana la totalidad de los electores del estado para votar en el Colegio electoral.

Los electores ganadores se reúnen el primer lunes después del segundo miércoles de diciembre, aproximadamente seis semanas después de la elección, para elegir el presidente y el vicepresidente de los Estados Unidos. Ninguna disposición constitucional o ley federal exige que los Electores voten de acuerdo con el voto popular en su respectivo estado, sin embargo en la actualidad es raro que los electores hagan caso omiso del voto popular y emitan su voto electoral a favor de alguien que no sea el candidato de su partido. Tras la votación, los Electores envían un registro de la misma al Congreso. La apertura del voto de los Electores corresponde al vicepresidente, que actúa en su calidad de presidente del Senado y es leído en voz alta en una sesión conjunta de ambas Cámaras del Congreso entrante, que fue elegido al mismo tiempo que el presidente.

La determinación de quien será el presidente depende de los votos del colegio electoral, no de quien obtuvo el mayor número de votos populares en el país. Sin embargo, sólo en cinco ocasiones (en las elecciones de 1824, 1876, 1888, 2000 y 2016) el candidato que obtuvo el mayor número de votos populares no consiguió la mayoría de votos electorales ni, por tanto, su elección como presidente. Si ningún candidato obtuviera la mayoría de los votos electorales, la Duodécima Enmienda establece que la elección del presidente corresponde a la Cámara de Representantes. La Cámara ha tenido que seleccionar al presidente en dos ocasiones, en 1800 y 1824.

De acuerdo con la Vigésima Enmienda, el mandato presidencial comienza en el mediodía del 20 de enero del año siguiente a la elección. Esta fecha, conocida en los Estados Unidos como «"Inauguration Day"» (día inaugural), marca el principio del mandato de cuatro años tanto del presidente como del vicepresidente. Antes de poder ejercer, debe realizar un acto de toma de posesión del cargo y, de acuerdo con la Constitución, se requiere que preste el juramento presidencial:

Aunque no es una exigencia, los presidentes han utilizado tradicionalmente una Biblia para prestar el juramento, y añadiendo al final del mismo «"So help me God!"» (¡con la ayuda de Dios!). Del mismo modo, aunque ninguna disposición legal requiere que el juramento del cargo sea administrado por una persona concreta, tradicionalmente el presidente presta su juramento ante el juez presidente de la Corte Suprema de los Estados Unidos.

La duración del mandato del presidente y del vicepresidente de los Estados Unidos es de cuatro años. Inicialmente la Constitución no fijaba un límite en el número de mandatos, pero pocos presidentes se presentaron a una tercera reelección. Sin embargo, en 1940, Franklin D. Roosevelt presentó su candidatura y fue elegido para su tercer mandato (posteriormente fue elegido para el cuarto, pero murió unos meses después de su toma de posesión), convirtiéndose en el único presidente en ejercer la presidencia en más de dos ocasiones. Con anterioridad a Roosevelt, Ulysses S. Grant quiso presentarse a un tercer mandato en 1880 tras permanecer en el cargo de 1869 hasta 1877, pero no consiguió la nominación de su partido. Theodore Roosevelt accedió a la presidencia tras el asesinato de William McKinley y fue posteriormente elegido en 1904 para un mandato completo, y así sirvió en el cargo de 1901 hasta 1909. Presentó posteriormente su candidatura (para un mandato no consecutivo) en 1912, pero perdió ante Woodrow Wilson.

Con la ratificación de la Vigesimosegunda Enmienda en 1951, se prohíbe a cualquier persona elegida para la Presidencia, y que ha servido como presidente, ser reelegida más de una vez y si ha actuado como presidente interino durante más de dos años del mandato no vencido de su precursor, ser elegida más de una vez. Harry S. Truman, que ocupaba la presidencia en el momento de la ratificación de la enmienda (que eximía expresamente de esta limitación al presidente en el cargo en el momento de su entrada en vigor) también buscó un tercer mandato antes de retirarse de las elecciones de 1952.

Desde la ratificación de la enmienda, cinco presidentes han servido en dos mandatos completos: Dwight D. Eisenhower, Ronald Reagan, Bill Clinton, George W. Bush y Barack Obama, mientras que Jimmy Carter y George H. W. Bush se presentaron a la reelección para un segundo mandato, pero fueron derrotados. Richard Nixon fue elegido para un segundo mandato, pero dimitió antes de completarlo. Lyndon B. Johnson fue el único presidente que conforme a la enmienda podía ser elegible para servir más de dos mandatos, pues sólo permaneció en el cargo durante catorce meses tras el asesinato de John F. Kennedy. Sin embargo decidió no participar en las elecciones de 1968. Gerald Ford buscó un mandato completo después de servir los últimos dos años y cinco meses del segundo mandato de Nixon, pero no fue elegido.

El cargo de presidente puede quedar vacante por varias circunstancias: muerte, dimisión y destitución.

En cuanto a la destitución, la Sección 4 del contempla que la Cámara de Representantes puede someter a un proceso de destitución a altos funcionarios federales, incluido el presidente, en casos de «traición, cohecho u otros delitos mayores o infracciones penales». Tras este proceso, la Cláusula 6 de la Sección 3 del otorga al Senado el poder de destituir de su puesto a los funcionarios acusados, si dos terceras partes de sus miembros votan su culpabilidad. Tres presidentes han sido procesados por la Cámara de Representantes, Andrew Johnson en 1868, Bill Clinton en 1998 y Donald Trump en 2019, aunque ninguno fue condenado posteriormente por el Senado.
De acuerdo con la Sección 3 de la Vigesimoquinta Enmienda, el presidente puede transferir los poderes y deberes presidenciales al vicepresidente, que pasaría a actuar como presidente interino, presentando una declaración al presidente de la Cámara de Representantes y al presidente "pro tempore" del Senado manifestando las razones de la transferencia. El presidente recobra los poderes y deberes presidenciales cuando les presenta a ambos representantes del Congreso una declaración escrita declarando dicha reanudación. Esta transferencia de poderes puede darse por cualquier motivo que el presidente considere apropiado. En 2002 y 2007 el presidente George W. Bush transfirió durante un corto período la autoridad presidencial al vicepresidente Dick Cheney. En ambas ocasiones fue debido a un proceso médico que requirió que Bush fuera sedado; Bush recuperó el poder presidencial el mismo día.

La Sección 4 de la Vigesimoquinta Enmienda contempla la posibilidad de transferencia de los poderes presidenciales al vicepresidente si este último y la mayoría del Gabinete transmiten al presidente de la Cámara de Representantes y al presidente "pro tempore" del Senado una declaración de incapacidad presidencial para desempeñar el cargo. En este caso el vicepresidente asumiría los poderes presidenciales en calidad de presidente interino; sin embargo, el presidente puede rechazar su inhabilitación y continuar en el puesto. Si el vicepresidente y el Gabinete impugnan esta decisión, es entonces el Congreso, que debe reunirse en el plazo de dos días si no se encuentra ya en sesión, quien debe decidir al respecto de la incapacidad o no del presidente para desempeñar el cargo.

La Constitución de los Estados Unidos menciona la dimisión del presidente, pero no regula la forma de ejecutar tal dimisión o las condiciones para su validez. Por acuerdo del Congreso, la única prueba válida de la decisión presidencial es un documento escrito declarando su dimisión firmado por el propio presidente y entregado en la oficina del Secretario de Estado. El 9 de agosto de 1974, afrontando su probable destitución en pleno escándalo Watergate, Richard Nixon se convirtió en el único presidente en dimitir del puesto.

Al igual que en el caso de dimisión, para la no aceptación del puesto también basta con la presentación de un escrito en ese sentido ante el Secretario de Estado.

La Constitución especifica que el vicepresidente debe ser el sucesor presidencial en caso de producirse una vacante en el puesto por muerte, dimisión, renuncia, inhabilitación, destitución o cualquier otra causa. Si tanto el puesto de presidente como el de vicepresidente están vacantes o están ocupados por personas incapacitadas para el puesto, el presidente de la Cámara de Representantes ocuparía el puesto como presidente interino. La línea sucesoria presidencial continúa con el presidente "pro tempore" del Senado, seguido a su vez por cada miembro del Gabinete en un orden establecido, siempre y cuando reúnan los requisitos determinados constitucionalmente para ser presidente.

En 1789, aunque inicialmente no se mostró de acuerdo con recibir un salario por sus servicios, el primer Congreso de los Estados Unidos acordó pagar a George Washington un salario de 25 000 dólares al año (aproximadamente unos 566 000 dólares del año 2009), un sueldo realmente elevado para la época, aunque el gobierno por entonces no proporcionaba una mansión oficial y Washington debía asumir los elevados gastos de una residencia presidencial con ese salario, por lo que manifestó que el salario era apenas suficiente para costear estos gastos.

El salario presidencial ha ido experimentando sucesivos aumentos a lo largo de los años y en 1999, siendo presidente Bill Clinton, el Congreso aprobó el actual salario presidencial de 400 000 dólares anuales, que entró en vigor en 2001. Le corresponde además (año 2005) una cuenta de gastos de 50 000 dólares, 100 000 dólares libres de impuestos para viajes y una cuenta de gastos personales de 19 000 dólares.

Anteriormente a 1958, al cesar sus mandatos los presidentes no recibían ninguna pensión, sin embargo a partir de ese año, con la "Former Presidents Act" (3 U.S.C. § 102) el Congreso aprobó que los presidentes salientes empezaran a recibir una pensión vitalicia de 25 000 dólares anuales, además de una oficina y personal. Esta pensión ha ido aumentando desde entonces con la aprobación del Congreso. Los ex presidentes reciben una pensión basada en el sueldo de los secretarios del gabinete de la administración vigente, cuyo sueldo es de 193 400 dólares en el caso del año 2009. La viuda de un presidente tiene derecho a una pensión de 20 000 dólares anuales, si no cuenta con otra pensión.

Desde 1800, ocupando la presidencia John Adams, la Casa Blanca, en Washington D. C., sirve como residencia oficial del presidente estadounidense. Mientras permanezca en el cargo tiene derecho al uso de sus instalaciones y personal, incluida asistencia médica, recreo, servicios domésticos y servicio de seguridad. La Instalación de Apoyo Naval Thurmont, popularmente conocida como Camp David, es una instalación militar en el "Catoctin Mountain Park", un área recreativa situada en el condado de Frederick (Maryland), a las afueras de Washington D. C., que se utiliza en la actualidad como residencia oficial de descanso del presidente y sus invitados.

El Servicio Secreto de los Estados Unidos es el encargado de la protección del presidente y su familia. Como parte de su protección, a los presidentes, las primeras damas, sus hijos y otros miembros de la familia inmediata, así como otras personas y lugares relevantes, se les asigna un nombre en clave por parte del Servicio Secreto. La utilización de estos nombres en clave era por motivos de seguridad en un tiempo en que las comunicaciones electrónicas no se cifraban de forma habitual, como hoy en día; actualmente estos nombres en clave simplemente se utilizan por tradición, así como por su brevedad y claridad.

Cuando realiza viajes de larga distancia, el presidente utiliza alguno de los dos aviones identificados por la Fuerza Aérea estadounidense como VC-25 (una versión militar muy modificada del modelo civil Boeing 747-200B) denominados con el indicativo «"Air Force One"» cuando el presidente los está utilizando, que están profusamente equipados y en los que puede llevar a cabo todas sus funciones. El presidente también utiliza un helicóptero del Cuerpo de Marines, identificado como «"Marine One"» cuando el presidente se encuentra a bordo. Para desplazamientos por tierra, utiliza una limusina blindada basada en un chasis Cadillac ampliamente modificado, denominada en ocasiones «"Cadillac One"» en referencia al avión presidencial.

Algunos presidentes han tenido carreras significativas después de dejar el cargo. Tal es el caso de William Howard Taft que fue presidente del Tribunal Supremo, o el de Herbert Hoover con su trabajo en la reorganización del gobierno después de la Segunda Guerra Mundial. Grover Cleveland, cuya candidatura para la reelección fracasó en 1888, fue posteriormente elegido nuevamente presidente cuatro años más tarde, en 1892. Dos antiguos presidentes sirvieron en el Congreso después de abandonar la Casa Blanca; John Quincy Adams fue elegido para la Cámara de Representantes, donde permaneció diecisiete años, y Andrew Johnson volvió al Senado en 1875. John Tyler sirvió en el Congreso provisional de los Estados Confederados durante la Guerra de Secesión y fue elegido para la Cámara de Representantes Confederada, aunque murió antes de que ésta se reuniera. Más recientemente, Richard Nixon realizó numerosos viajes al extranjero, incluyendo la República Popular China y Rusia. Jimmy Carter actuó como mediador internacional, defensor de los derechos humanos en todo el mundo y fue galardonado con el en 2002. Bill Clinton también ha realizado gestiones de mediación y negociación a nivel internacional, como en el caso de sus gestiones para la liberación de dos periodistas estadounidenses, Laura Ling y Euna Lee, en Corea del Norte. Bill Clinton también ha participado activamente en política, como en el caso de las primarias presidenciales del partido Demócrata de 2008 en apoyo de su esposa, Hillary Clinton.

Hasta 1997, todos los expresidentes y sus familias, contaban con la protección del Servicio Secreto hasta la muerte del presidente. El último presidente que recibió protección vitalicia del Servicio Secreto tras este cambio legislativo fue Bill Clinton; George W. Bush y todos los presidentes posteriores serían protegidos por el Servicio Secreto durante un máximo de diez años tras la finalización de su mandato. Sin embargo, el 10 de enero de 2013, el presidente Obama firmó una ley que restableció la protección del Servicio Secreto de por vida para él, George W. Bush y todos los presidentes subsiguientes. Si el cónyuge vuelve a casarse, pierde el derecho de protección por parte del servicio secreto.

Todos los presidentes desde Herbert Hoover han creado un lugar donde preservar y poner a disposición del público documentos, archivos, colecciones y otros objetos históricos relacionados con sus mandatos, que, aunque no es exclusivamente una biblioteca, es conocido como Biblioteca Presidencial. Las Bibliotecas son constituidas y mantenidas por la Administración Nacional de Archivos y Documentos ("NARA" por sus iniciales en inglés). Hay actualmente trece bibliotecas presidenciales en el sistema NARA. También hay varias bibliotecas presidenciales mantenidas por gobiernos estatales y fundaciones privadas, como la Biblioteca y Museo Presidencial de Abraham Lincoln, que está al cargo del estado de Illinois.






</doc>
<doc id="28107" url="https://es.wikipedia.org/wiki?curid=28107" title="Colonia">
Colonia

El término colonia puede referirse:

















</doc>
<doc id="28111" url="https://es.wikipedia.org/wiki?curid=28111" title="Emperador de Japón">
Emperador de Japón

El es el jefe de Estado y es el símbolo constitucionalmente reconocido de la nación japonesa y de la unidad de su pueblo. Es la cabeza de la familia imperial japonesa, la familia real del Japón.

El papel del emperador de Japón oscilaba hasta mediados del siglo XX entre un clérigo de alto rango con grandes poderes simbólicos y un auténtico gobernante imperial. Ha existido un culto imperial (Arahitogami) que considera al "tennō" como sumo sacerdote mediador entre los hombres y la divinidad, debido a sus cercanos lazos con los dioses japoneses (lazos de herencia). La violencia y las operaciones militares han sido considerados incompatibles con el papel del "tennō" al menos durante 14 siglos: por ello los monarcas japoneses no han actuado como comandantes militares, al contrario de lo habitual en Occidente. La principal función del emperador durante la mayor parte de los últimos mil años habitualmente ha sido la de simplemente autorizar u otorgar legitimidad a aquellos situados en el poder.

Bajo la , el emperador se ha convertido en una figura ceremonial y simbólica con funciones similares a las de un jefe de Estado en una monarquía constitucional (ver Política de Japón). Sin embargo, ni la constitución japonesa ni ninguna otra norma atribuyen expresamente al emperador la titularidad de la jefatura del Estado.

El actual emperador, Su Majestad Imperial, es Naruhito, desde 2019, vitalicio.

Desde mediados del siglo XIX, la residencia oficial del emperador es el palacio de "Kōkyo", localizado en el centro de Tokio. Anteriormente, los emperadores residían en Kioto.

Ciertos datos y fechas referentes a la institución imperial son objeto de discusión entre los historiadores japoneses. Muchos emperadores citados en la murieron a una edad muy temprana y difícilmente se puede considerar que hubieran "gobernado" de verdad. Otros fueron eclipsados por sus predecesores, los cuales se habían retirado aparentemente a un monasterio pero continuaron ejerciendo su influencia, en un proceso llamado "reinado enclaustrado". De todos modos, es importante mantener la lista oficial entera, porque incluso hoy día la forma habitual de datación en la historia japonesa es por los reinados de los emperadores.

Aunque el emperador haya sido un símbolo de continuidad con el pasado, el grado de poder ejercido por el emperador de Japón ha variado considerablemente a lo largo de la historia japonesa.

Se considera que los más antiguos emperadores registrados en Kojiki y Nihonshoki, como el emperador Jimmu,
no tienen credibilidad histórica. El primer monarca ahora en lista como emperador que es generalmente reconocido por los historiadores como existente históricamente fue el emperador Ojin, pero el tiempo de su reinado es impreciso (presumiblemente fue el siglo IV d. C. tardío y/o en el comienzo del siglo V d. C.). Estos dos libros declaran que la casa imperial mantuvo un linaje continuo, aunque hoy algunos historiadores creen que muchos emperadores antiguos que se decía eran descendientes del emperador Ōjin no tenían una conexión genealógica con su predecesor. Sin embargo, la genealogía que inicia en el siglo V tardío puede ser considerada como fiable, lo que quiere decir que la dinastía ha continuado por lo menos unos 1500 años.

Los emperadores enclaustrados han entrado en conflicto con sus correspondientes emperadores oficiales de vez en cuando. Un ejemplo notable es la rebelión Hogen de 1156, en la que el exemperador Sutoku trató de arrebatar el poder al emperador Go-Shirakawa (en ejercicio). Otros ejemplos, como la rebelión del emperador Go-Toba en 1221 contra el Shogunato Kamakura, o la Restauración Kenmu en 1336 bajo el emperador Go-Daigo, muestran claramente la lucha de poder que ha tenido lugar entre la Casa Imperial y los gobiernos militares en Japón.

No es sino hasta los siglos recientes que Japón incorpora diversas zonas remotas de su territorio actual. El nombre Nippon no se empieza a utilizar sino varios siglos después del inicio del actual línea imperial. Realmente, el Gobierno centralizado comenzó a aparecer poco antes de la época del príncipe Shotoku. El emperador era más bien una venerada encarnación de la armonía divina más que la cabeza de una administración estatal. En Japón siempre ha sido fácil para los señores ambiciosos mantener su poder, dado que dicha posición no era en absoluto contradictoria con la del emperador. El parlamentarismo de hoy recoge esa coexistencia que tenía el emperador con diferentes "shogunes", señores de la guerra, regentes, guardianes, etc. Podemos decir que técnicamente es un error traducir como "emperador" el término japonés "tennō", que no logra definir de manera exacta su labor, si lo comparamos con el término imperial en el sentido occidental.

Históricamente, los títulos del "tennō" en japonés nunca incluyeron designaciones territoriales como sí sucedía con los monarcas europeos. La posición del emperador es un fenómeno territorialmente independiente - el emperador es el emperador, incluso aunque tenga seguidores en una sola provincia (como a veces sucedió con las cortes del norte y del sur).

Desde fines de 1100 a 1867, el poder real estuvo en manos del "shōgun", cuya autoridad provenía, en teoría, directamente del emperador. Cuando los exploradores portugueses llegaron por primera vez a Japón (ver “período Nanban”), consideraron la relación entre el emperador y los shogunes como la del papa (de raigambre divina, pero con poco poder político) y el rey (terrenal, pero con un amplio poder político), aunque esto es en cierto punto inexacto, ya que, como el emperador, los papas han manejado distintos grados de poder a lo largo de la historia.

La Restauración Meiji fue, de hecho, una especie de revolución, con los dominios de Satsuma y Choshu uniéndose para derribar al Shogunado Tokugawa. El padre del emperador Meiji, el emperador Komei, comenzó a hacer valer su poder político luego que las naves del comodoro Matthew Perry visitan Edo. Para principios de 1860, la relación entre la Corte Imperial y el shogunado había cambiado drásticamente. Irónicamente, Komei levantó la voz contra el shogunado dado que él y otros nobles estaban molestos ante la ineficacia del Shogunado en expulsar a los intrusos bárbaros. Dominios insatisfechos y rōnin comenzaron a reunirse bajo el lema “sonno, joi,” o “respeta al emperador, expulsa a los bárbaros.” Satsuma y Choshu usaron este alboroto para moverse contra el enemigo histórico, y obtuvieron una importante victoria militar en las afueras de Kioto contra las fuerzas Tokugawa. En 1868 se declara la “restauración” imperial, y el shogunado fue despojado de sus poderes. En los próximos años se verá un significativo desorden y descontento, además de esporádicas rebeliones.

Sin embargo, los modernistas de la élite japonesa se dieron cuenta que los llamados al "joi" eran surrealistas. Si los extranjeros no podían ser expulsados, concluyeron que Japón debía volverse una nación fuerte y moderna para evitar el destino y las humillaciones que sufrían las otras naciones orientales. Otros tenían el propósito de expandir el territorio japonés más allá de las fronteras para la gloria del emperador, y muchos fueron atraídos por los ideales de la Iluminación occidentales. Mediante la constitución de 1889, el emperador de Japón transfirió gran parte de sus antiguos poderes como monarca absoluto a los representantes del pueblo, pero permaneció como cabeza del imperio. Aunque inspirada en las constituciones de Europa, la nueva Constitución Meiji no fue tan democrática como muchos esperaban. Al emperador se le dieron amplios y vagos “poderes reservados” que a su turno eran explotados por el primer ministro y por varios camarillas alrededor del emperador. Para 1930 el gabinete japonés estaba mayoritariamente compuesto por líderes militares seudo-fascistas que usaron al emperador y su supuesta divinidad como un punto de partida ultranacionalista para la expansión del imperio. Cuando estalló la II Guerra Mundial, el emperador era el símbolo por el cual los soldados peleaban y morían. El mismo emperador estaba fuera de la vista, sin embargo, y su rol durante este período es discutido. La concepción tradicional posterior a la Segunda Guerra Mundial sostiene que estaba dominado por el ejército, aunque la documentación publicada desde 1989 apunta a una participación más activa del emperador en la política bélica. Aún hay controversia sobre el rol que jugó Hirohito en el comando de las fuerzas japonesas durante la segunda guerra sino-japonesa y la guerra del Pacífico.

El papel del emperador es definido en el capítulo I de la Constitución de Japón de 1947:

A diferencia de otros monarcas constitucionales, el emperador del Japón no tiene poderes reservados.

Aunque el emperador actualmente lleva a cabo muchos de los roles de un soberano ceremonial como jefe de Estado, ha habido una persistente controversia sobre si el emperador es de hecho un verdadero monarca en un sentido político o meramente un pretendiente, ostentando dicho cargo en una república constitucional parlamentaria. En una monarquía tradicional, el poder político deviene de la soberanía monárquica, cuya prerrogativa real es luego ejercida al capricho de los legisladores electos, de la forma establecida en la convención constitucional. Sin embargo, si no hay prerrogativa real, entonces la soberanía debe descansar en el pueblo, tal como lo establece el artículo 1º de la Constitución de Japón. Por lo tanto, el emperador es simplemente un actor político dentro de un gobierno que realmente no adhiere al sistema de Westminster donde la posición de “jefe de Estado” requiere de una persona con soberanía o con mandato popular para asumir tal oficio. Los esfuerzos en los años 1950 de los políticos conservadores en enmendar la constitución para nombrar explícitamente al emperador como jefe de estado fueron rechazados. A pesar de todo, el emperador lleva a cabo todas las funciones diplomáticas asociadas normalmente al jefe de estado y así es reconocido por los poderes extranjeros.

El tratamiento de los emperadores de Japón es a menudo problemático, debido a las diferencias lingüísticas y culturales entre Japón y el mundo occidental. Mientras los japoneses llaman “{nombre} "tennō"” (para los anteriores) o "Kinjou Heika" (今上陛下) para el actual, los académicos hispano y angloparlantes han usado distintas variantes, como “emperador {nombre}” y, menos comúnmente, “{nombre} "tennō"”. Lo que a menudo no es comprendido, sin embargo, es que los emperadores son llamados póstumamente “{nombre} "tennō"”, y así la palabra "tennō", o “emperador”, forma parte de su propio nombre. Esto es particularmente malentendido desde el Emperador Meiji en adelante, dado que el nombre póstumo que se da a los emperadores ahora es el mismo que el de la época que ellos presidieron, mientras que antes el reinado de un emperador podía contener una sucesión de eras. Términos tales como “Emperador Meiji” deben ser entendidos en inglés como “el emperador del período Meiji”, que no es siempre lo que se entiende en japonés.

En español, el término mikado (御門 o 帝 o みかど), que significa “la Puerta”, se usaba antiguamente para referirse al emperador del Japón; este uso ahora es obsoleto. En japonés, los emperadores de Japón, no así los de los otros países, son conocidos como "tennō" (天皇). Literalmente, la palabra "tennō" combina los caracteres de “gobernante” y “cielo”, pero este no es un signo de divinidad; el uso de ten (天, “cielo”) en la palabra japonesa fue una adopción del concepto chino de Enviado del Cielo, que implica que un emperador ha sido designado por los cielos para equilibrar los asuntos políticos y religiosos en sus dominios.

Hay dos palabras en japonés equivalente a la palabra hispana “emperador”: "tennō" (天皇) es usada específicamente para describir al emperador del Japón, "kōtei" (皇帝, el título usado por el emperador chino) es usado para describir a los emperadores extranjeros. Sumeramikoto (literalmente “gobernante celestial sobre las nubes”) fue también usado en el japonés antiguo.

Tradicionalmente, los japoneses consideran de mala educación el llamar a un noble por su nombre propio. Esta costumbre está en retirada, pero aún es observada ante la familia imperial. "Tennō" se agrega de forma póstuma (como prefijo), pero no al emperador reinante. Al contrario, los emperadores pasados son llamado por sus nombres póstumos, tales como el Emperador Jimmu, Emperador Kammu, Emperador Meiji. Desde la Era Meiji, los nombres de era son también usados como nombres póstumos. El emperador reinante es casi siempre referido como "Tennō Heika" (天皇陛下, que literalmente significa “Su Majestad el Emperador”) o de forma más solemne como "Kinjō Heika" (今上陛下). Por otra parte, en lenguaje coloquial siempre se le refiere como "Heika", "Okami" o "To-gin san" ("To-gin" es sinónimo de "Kinjō"). El emperador actual no es llamado por el nombre de la era, el que se el egregará luego como nombre póstumo.

Hoy en día esta costumbre es menos considerada. En español, los recientes emperadores han sido llamados por sus nombres personales, de acuerdo con los usos occidentales. Como bien se explicó, en japonés esto suena ofensivo y, en cierto modo, blasfemo.

Por ejemplo, el emperador que reinó hasta 1989 era usualmente llamado Hirohito en español, pero luego de su muerte fue rebautizado como "Shōwa Tennō" y es llamado de esa forma en japonés. Sin embargo, durante su reinado, nunca se le llamó Hirohito o "Shōwa Tennō" en japonés. Más bien, se hacía referencia a él simplemente como "Tennō Heika" (que significa “Su Majestad el Emperador”).

En el caso de las abdicaciones imperiales, el exemperador toma el título de "Daijō Tennō o Jōkō" (emperador emérito, según la definición oficial de la Agencia para la Casa Imperial), quien mantiene el tratamiento de Majestad Imperial junto a su consorte. En el caso de los nombres de eras, se termina la era del emperador abdicante y se inicia el del emperador en ejercicio, en el caso de Akihito, la era Heisei terminó a la medianoche del 1 de mayo de 2019 y dio paso a la actual era, Reiwa, bajo la cual gobierna su hijo, el actual emperador Naruhito.

El gobernante de Japón era conocido como ヤマト大王/大君 (yamato ōkimi, Gran Rey de Yamato), 倭王/倭国王 (waō/wakokuō, Rey de Wa, usado externamente), o 治天下大王 (amenoshita shiroshimesu ōkimi o sumera no mikoto, Gran Rey que gobierna todo bajo el cielo, de uso interno) en las fuentes chinas y japonesas anterior al Siglo VII. El uso más antiguo documentado de la palabra "tennō" es en una tablilla de madera, o "mokkan", que fue desenterrada en Asuka-mura en la prefectura de Nara en 1998 y fechada en la era del Emperador Tenji y la Emperatriz Jitō. La introducción del término se dio en medio del proceso de Sinización de Japón, y es considerado por muchos como un intento de los gobernantes japoneses de igualarse con los Emperadores Chinos. Notablemente, "Tianhuang" (天皇), el equivalente chino de "tennō", estaba entre los títulos adoptados por Emperador Gaozong de la China Tang del mismo período, a pesar de que no se sabe si los dos surgieron independientemente o si uno fue influenciado por el otro.

A lo largo de la historia, contrariamente a cualquier suerte de práctica de harén, en que no se reconoce una esposa jefa y solo manteniendo un surtido de mujeres mueble, los emperadores japoneses y los nobles solían nombrar una esposa jefa.

La dinastía imperial practicó de forma consistente la poliginia oficial, una práctica que solo terminó en el período Taisho (1912-1926). Además de la emperatriz, el emperador podía tomar, y casi siempre tomaba, varias consortes secundarias (“concubinas”) de distintos grados jerárquicos. Los otros dinastas (shinno) también podían tener concubinas. Luego de un decreto del Emperador Ichijō, algunos emperadores tuvieron incluso dos emperatrices simultáneamente (kogo y chugu son los dos títulos separados en esta situación). Con el auxilio de esta poligamia, el clan imperial fue capaz de producir una mayor descendencia. (Los hijos de consortes secundarias eran usualmente reconocidos como príncipes imperiales, y podían ser reconocidos como herederos al trono si la emperatriz no daba a luz un heredero.)

De las ocho mujeres "tennō" (emperatriz reinante) de Japón, ninguna se casó ni dio a luz luego de ascender al trono. Algunas de ellas, siendo viudas, habían tenido hijos antes de su reinado.
En la sucesión, los hijos de la emperatriz eran preferidos a los de las consortes secundarias. Así, era significativo qué familias tenían oportunidades preferenciales de proveer esposas jefe a los príncipes imperiales, esto es, dar futuras emperatrices.

Aparentemente la más antigua tradición de matrimonios oficiales en la dinastía imperial eran aquellos entre miembros de la dinastía, incluso entre medios hermanos o entre tío y sobrina. Dichos matrimonios eran arreglados para preservar mejor la sangre imperial o estaban destinados a producir hijos como modo de reconciliación entre dos ramas de una dinastía. Las hijas de las consortes permanecían como concubinas, hasta que el emperador Shōmu —en lo que se reportó como la primera elevación de este tipo— ascendió a su consorte Fujiwara a esposa jefa.

Los monarcas japoneses han sido, así como muchos otros en otras partes, dependientes de las alianzas con jefes poderosos y con otros monarcas. Muchas de dichas alianzas eran selladas con matrimonios. La específica característica en Japón era el hecho que esos matrimonios pronto se incorporaron como elementos de tradición que controlaban los matrimonios de las generaciones venideras, aunque la alianza original haya perdido su significado real. Un patrón repetido ha sido un yerno imperial bajo la influencia de su poderoso suegro no imperial.

Desde los siglos VII y VIII, los emperadores solían tomar a las mujeres del Clan Fujiwara como sus más altas esposas – las más probables madres de los futuros monarcas. Esto era encubierto como una tradición matrimonial entre los herederos de dos kamis, dioses Shinto: los descendientes de Amaterasu con los descendientes de la familia kami de los Fujiwara. (Originalmente, los Fujiwara eran descendientes de una nobleza relativamente menor, así su kami es difícilmente reconocible en la mitología japonesa.) El producir niños imperiales, herederos de una nación, descendiente por ambas ramas de dos kamis, era considerado deseable – o al menos así parecía a los Señores Fujiwara, que así recibían preferencia en el mercado de los matrimonios imperiales. La realidad tras esos matrimonios era la alianza entre un príncipe imperial y un Señor Fujiwara, su suegro o abuelo, este último con sus recursos apoyando el ascenso del príncipe al trono y más a menudo controlando el gobierno. Estos arreglos crearon la tradición de los regentes (Sessho y Kampaku), cuyo puesto podía ser utilizado solo por un señor sekke Fujiwara.

Anteriormente los emperadores se casaban con mujeres de familias del clan gobernante Soga, y con mujeres de la misma familia imperial, ya sea con primas en variados grados y a menudo con sus hermanas (medias hermanas). Muchos miembros de la familia imperial de los siglos VI y VII eran hijos de parejas de medios hermanos. Estos matrimonios usualmente eran aparatos de alianza o sucesión: los señores Soga se aseguraban de mantener dominado a un príncipe, para ser puesto como títere en el trono; o un príncipe se aseguraba la combinación de dos descendientes imperiales, para fortalecer su propia pretensión al trono y la de sus hijos. Estos matrimonios también eran una manera de sellar una reconciliación entre dos ramas de la familia imperial.

Luego de un par de siglos, los emperadores ya no pudieron desposar a ninguna mujer fuera de esas familias como primera esposa, sin importar el poder o la riqueza que ese matrimonio pudiese traer. Rara vez un príncipe sin una madre proveniente de estas familias era autorizado para ascender al trono. La primitiva necesidad y conveniencia dieron paso a una estricta tradición que no hacía sino dar a determinadas mujeres el carácter de posibles novias, porque estas familias habían producido posibles esposas por siglos. La tradición se hizo más fuerte que la misma ley.

Las mujeres Fujiwara eran a menudo emperatrices, y las concubinas provenían de familias nobles menos importantes. En el último milenio, los hijos de un varón de la familia imperial con una mujer Fujiwara eran preferidos en la sucesión.

Las cinco familias Fujiwara, Ichijo, Kuji, Nijo, Konoe y Takatsukasa, fueron la fuente principal de novias imperiales desde los siglos VIII a XIX, incluso más comúnmente que las mismas hijas del clan imperial. Así, las mujeres Fujiwara, por lo común eran las emperatrices y madres de los emperadores.

La fuente aceptable de esposas imperiales, novias para el emperador y el príncipe heredero, fueron incluso reglamentadas en las leyes de la casa imperiales durante la era Meiji (1889), que establecían que las hijas de Sekke (las cinco ramas principales de la familia Fujiwara) y las hijas del mismo clan imperial eran primariamente novias aceptables.

Luego de que esa ley fue abolida a consecuencia de la Segunda Guerra Mundial y el cambio en la constitución de Japón en 1947, el anterior emperador Akihito fue el primer príncipe heredero en más de mil años en tener una emperatriz no elegida del círculo aceptable, actuación seguida por el actual emperador Naruhito.

La dinastía imperial japonesa basa su posición en el hecho de que ha reinado “desde tiempos inmemoriales”. Es cierto que sus orígenes están escondidos tras las nieblas del tiempo: no hay pruebas que muestren la existencia de cualquier emperador que no haya sido descendiente de su predecesor, hasta los más tempranos emperadores. Un antiguo ancestro de la dinastía, el Emperador Keitai (aparecido en los años 500 d. C.), a pesar de que se sospecha no era descendiente de su predecesor, la tradición lo coloca como un pariente lejano de sus antecesores. De acuerdo a los registros, la familia que él inició en el trono, desciendo al menos de una, o probablemente de varias princesas imperiales de la dinastía inmediatamente anterior. La tradición erigida por estas leyendas ha elegido reconocer solo al ancestro masculino putativo para legitimar su sucesión, sin dar importancia al peso de los lazos por parte de las princesas. Hace milenios, la familia imperial japonesa creó su propio y particular sistema de sucesión hereditaria. Este es no basado en la primogenitura, más o menos patrilineal, basado mayoritariamente en rotación. Hoy, Japón usa un estricto sistema de primogenitura patrilineal – en otras palabras, Ley Sálica pura. Esta fue adoptada según el modelo prusiano, por el que Japón fue fuertemente influenciado en la década de 1870.

La primogenitura patrilineal estricta es, no obstante, directamente contradictoria con muchas antiguas tradiciones japonesas sobre la sucesión imperial.

Los principios controladores y su interacción eran aparentemente bastante complejos y sofisticados, llevando incluso a resultados idiosincrásicos. Algunos principios básicos de la sucesión parecen ser:

- Las mujeres podían suceder (pero existían niños que no les eran propios y cuyo padre tampoco era patrilineal de la casa imperial, así no hay precedente de que un hijo de una mujer imperial con un hombre no imperial fuera autorizado para suceder, así como tampoco lo hay prohibiéndolo a los hijos de las emperatrices). Sin embargo, la accesión femenina era claramente mucho más rara que la de los hombres.

- La adopción era posible y una forma muy utilizada para incrementar el número de herederos capaces de suceder (sin embargo, el niño adoptado debe ser hijo de otro miembro patrilineal de la casa imperial.

- La abdicación era común, y de hecho se dio mucho más que la muerte en el trono. En aquellos días, el principal papel del emperador era ser una especie de sacerdote (o dios), que contenía muchísimos y repetitivos rituales, que se juzgaba que, tras un servicio de alrededor de diez años, el susodicho merecía un retiro digno como un honorable exemperador.

- La primogenitura no era usada – al contrario, en la época temprana, la casa imperial practicó un sistema parecido a la rotación. Muy a menudo un hermano (o hermana) sucedía al más viejo incluso en caso que su predecesor dejara descendencia. El “turno” de la siguiente generación venía luego de varios individuos de la generación anterior. La rotación era común entre dos o más ramas de la casa imperial, así primos más o menos distantes se sucedían entre ellos. El Emperador Go-Saga incluso decretó la alternación entre los herederos de sus dos hijos, cuyo sistema continuó por un par de siglos (llevando a una lucha inducida por los shogunes entre dos ramas, los emperadores “del norte” y “del sur”). Hacia el fin de esto, los alternantes eran primos muy lejanos contados en grados de descendencia masculina (pero siempre hubo matrimonios entre miembros de la casa imperial, así que la relación sería más cercana si se contasen los grados femeninos). Durante los últimos 500 años, sin embargo, debido probablemente a la influencia del confucianismo, la sucesión por parte de los hijos –no siempre, aunque más comúnmente, el hijo de más edad que sobrevivía al emperador- ha sido la norma.

Históricamente, la sucesión al Trono del Crisantemo japonés ha pasado siempre por línea masculina el linaje imperial. Generalmente han sido hombres, aunque de los más de cien monarcas masculinos ha habido seis mujeres como emperatrices en ocho ocasiones.

Hace unos mil años, comenzó la tradición de que el emperador debe ascender al poder relativamente joven. Un dinasta que ha pasado la infancia se considera apta y lo suficientemente crecido. El alcanzar la edad de mayoría legal no era un requisito. Así, una multitud de emperadores han ascendido desde pequeños, jovencitos de 6 a 8 años de edad. Las labores ceremoniales eran juzgadas posibles de ser realizadas por un niño. Un reino de alrededor de diez años era reputado un servicio suficiente. Ser un niño aparentemente era un buen atributo, para soportar deberes tediosos y para tolerar la subyugación de los poderes políticos, así como a veces para esconder a los verdaderos miembros poderosos de la dinastía imperial. Casi todas las emperatrices japonesas y docenas de emperadores abdicaron, y vivieron el resto de sus vidas en el retiro, y/o ejerciendo influencia tras los velos. Muchos emperadores abdicaron y pasaron a su retiro cuando aún eran adolescentes. Estas tradiciones se aprecian en el folclore, teatro y literatura japoneses, así como en otras formas de arte, donde el emperador es usualmente descrito o representado como un adolescente.

Antes de la Restauración Meiji, Japón tuvo ocho "tennō", o emperatrices reinantes, todas hijas por línea de padre de la Casa Imperial. Ninguna de ellas ascendió como esposa o viuda de un emperador. Las hijas y nietas imperiales, sin embargo, usualmente ascendían al trono como una suerte de “medida de intervalo” – si un hombre apto no estaba disponible o algunas ramas imperiales estaban en conflicto, por lo que se necesitaba un compromiso. Casi todas las emperatrices japonesas y docenas de emperadores abdicaron – muchas emperatrices una vez que un menor apto alcanzaba la edad de ascender. Tres emperatrices, la emperatriz Suiko, la emperatriz Kōgyoku (también llamada emperatriz Saimei) y la emperatriz Jitō, eran viudas de emperadores fallecidos y princesas de sangre imperial por derecho propio. Una, la emperatriz Genmei, era la viuda de un príncipe de la corona y princesa de sangre imperial. Las otras cuatro, la emperatriz Genshō, la emperatriz Kōken (también llamada emperatriz Shōtoku), la emperatriz Meishō y la emperatriz Go-Sakuramachi, eran hijas solteras de emperadores anteriores. Ninguna de estas emperatrices se casaron o tuvieron hijos luego de ascender al trono.

El artículo 2º de la Constitución Meiji de 1889 (la Constitución del Imperio del Japón) estatuía, “El Trono Imperial debe ser sucedido por los descendientes imperiales varones, de acuerdo con las providencias de la ley de la Casa Imperial.” La Ley de la Casa Imperial de 1889 fijó la sucesión en los descendientes varones de la línea imperial, y excluyó específicamente a las mujeres descendientes de la sucesión. En el evento que no hubiese varones en la línea principal, el trono pasaría a la línea colateral más cercana, nuevamente en línea masculina. Si la emperatriz no fuese capaz de dar a luz a un heredero, el emperador podía tomar una concubina, y le hijo que llas tuviera sería reconocido como heredero al trono. Esta ley, promulgada el mismo día que la Constitución Meiji, gozaba de igual estatus con aquella.

El artículo 2º de la Constitución de Japón, promulgada en 1947 bajo la influencia de la ocupación estadounidense y aún con fuerza, provee que “El Trono Imperial será dinástico y sucedido de acuerdo con la Ley de Casa Imperial aprobada por la Dieta.” La Ley de la Casa Imperial de 16 de enero de 1947, promulgada por la 92º sesión de la Dieta Imperial, retuvo la exclusión de las dinastas mujeres contenida en la ley de 1889. El gobierno del primer ministro Yoshida Shigeru remendó rápidamente la legislación para dar a la Ley de la Casa Imperial concordancia con la Constitución de Japón escrita por los estadounidenses, que entró en efecto en mayo de 1947. En un esfuerzo por controlar el tamaño de la familia imperial, la ley establece que solo los legítimos descendientes varones en la línea de sucesión masculina pueden ser dinastas; que los príncipes y princesas imperiales pierden su estatus de miembros de la Familia Imperial si se casan fuera de ésta; y que el Emperador y otros miembros de la Familia Imperial no pueden adoptar hijos. También evitó que otras ramas que no descendiesen de Taisho accedieran a ser príncipes imperiales.

La Sucesión se regula por las leyes promulgadas por la Dieta de Japón. La ley actual excluye a las mujeres de la sucesión, si bien muy ocasionalmente las mujeres ocuparon el trono en siglos precedentes. Un cambio a esta ley ha sido considerado desde 2005 dado que el actual Emperador Naruhito es padre solo de una niña. Esto crea un desafío tanto logístico como político: cualquier cambio en la ley puede significar una revisión para establecer la sucesión en el primogénito más que en el primer varón; no obstante, el actual emperador no es el primogénito, sino que tiene hermanas mayores.

Hay una potencial crisis sucesoria dado que no han nacido niños varones en la familia imperial desde el Príncipe Akishino en 1965. Luego del nacimiento de la Princesa Aiko, ha habido cierto debate público sobre la enmienda a la Ley de la Casa Imperial para permitir a las mujeres suceder en el trono. En enero de 2005, el primer ministro Jun'ichirō Koizumi designó a un panel especial compuesto de magistrados, catedráticos e intelectuales en orden a estudiar cambios en la Ley de la Casa Imperial y para hacer recomendaciones al gobierno.

El panel referido recomendó el 25 de octubre de 2005 enmendar la ley para permitir a las mujeres de la descendencia masculina ascender al trono japonés. El 20 de enero de 2006, el primer ministro Jun'ichirō Koizumi dedicó parte de su cuenta anual a la controversia, plegándose a la idea de convocar a un plebiscito para permitir a las mujeres ascender al trono para asegurar que la sucesión continúe de manera estable. Sin embargo, poco después del anuncio de que la princesa Kiko estaba embarazada por tercera vez, Koizumi suspendió estos planes. El 6 de septiembre de 2006, la esposa del Príncipe Fumihito dio a luz a un varón, el Príncipe Hisahito, y que es el segundo en la línea de sucesión, luego de su padre, a partir del 1 de mayo de 2019

El emperador es símbolo del Estado japonés y de unidad colectiva, el trono imperial es dinástico, y la sucesión de acuerdo con la Ley de la Casa Imperial debe ser aprobada por la Dieta; tiene funciones de consejo y aprobación en cuestiones de Estado y el gabinete es responsable ante él, delega el cumplimiento de sus actos en cuestiones de Estado tal como sea previsto por ley, lleva adelante solamente los actos en cuestiones de Estado y no tiene poderes relativos al Gobierno, asimismo, la Casa Imperial no debe recibir nada sin permiso previo de la Dieta, toda propiedad de la misma corresponde al Estado y los gastos son determinados por la Dieta.




</doc>
<doc id="28124" url="https://es.wikipedia.org/wiki?curid=28124" title="Conferencia de Paz de París (1919)">
Conferencia de Paz de París (1919)

La Conferencia de Paz de París fue la reunión en 1919 de los Aliados después del armisticio para acordar las condiciones de paz con los países de las Potencias Centrales: Alemania, el Imperio otomano, Bulgaria, Austria y Hungría, estos dos últimos como representantes del desaparecido Imperio austrohúngaro. Los aliados empezaron sus labores de negociación entre sí el 18 de enero de 1919 bajo la dirección del "Comité de los Cuatro": Wilson, Clemenceau, Lloyd George y Orlando, aunque los que realmente dirigieron las negociaciones fueron los tres primeros. A los países vencidos no se les dejó asistir a estas reuniones, así que los que decidieron el futuro de los vencidos, fueron los países vencedores, que tenían distintas posturas.





A partir de junio de 1919 se presentan los tratados para su firma a los países derrotados. 

De las muchas disposiciones del tratado, una de las más importantes y controvertidas rezaba que Alemania y sus aliados aceptasen toda la responsabilidad de haber causado la guerra y, bajo los términos de los artículos 231-248, desarmarse, realizar importantes concesiones territoriales y pagar indemnizaciones a los estados vencedores. El Tratado fue socavado tempranamente por acontecimientos posteriores a partir de 1922 y fue ampliamente violado en los años treinta con la llegada al poder del nazismo.


El Tratado de Saint-Germain-en-Laye fue firmado el 10 de septiembre de 1919 entre las potencias aliadas y Austria. En este tratado se establecía el desmembramiento de la antigua monarquía de los Habsburgo, el Imperio Austrohúngaro, y Austria quedó limitada a algunas zonas en las que se hablaba solamente el alemán.

Mediante este tratado se reconocía la independencia de Hungría y la creación de los nuevos estados de Checoslovaquia (con Bohemia, Moravia, Silesia y Eslovaquia) y Yugoslavia (con Eslovenia, Bosnia y Herzegovina, parte de Dalmacia, Croacia y Voivodina). Hungría cedería Transilvania, parte del Bánato y Bucovina a Rumania, algo que se concretó en el Tratado de Trianón, y el Burgenland a Austria. 

Polonia se anexó Galitzia e Italia obtuvo el Trentino, Tirol del Sur, Trieste e Istria, sin embargo, los ingleses se negaron a cumplir completamente lo acordado en el Tratado de Londres oponiéndose a que Italia recuperara Dalmacia, antiguo territorio veneciano. Esto último fue visto por los italianos como una traición por parte de Inglaterra y fue uno de los principales motivos que llevaron al posterior ascenso del Fascismo.

Una cláusula importante era la prohibición de revisar o revocar la independencia de Austria, con el fin de impedir una unión política y/o económica con Alemania (Anschluss), sin la autorización de la Sociedad de Naciones, ya que tras la pérdida de su Imperio los austriacos se plantearon la posibilidad de la unificación fracasada en 1866 tras la Guerra Austro-Prusiana.

El Tratado de Trianon, firmado posteriormente entre los aliados y Hungría, completa el proceso de desmembramiento del Imperio Austrohúngaro.

Con este tratado, la mitad de los doce millones de habitantes del Imperio que eran de lengua alemana quedaron fuera de la nueva República de Austria, como fueron los Sudetes en Checoslovaquia, la región del Tirol del Sur, con capital en Bolzano, en Italia, y algunas comunidades en Hungría y Transilvania. Esto llevó a problemas que precedieron la Segunda Guerra Mundial.

La desintegración del Imperio Austrohúngaro causó tensiones y dificultades entre las nuevas naciones. Austria quedó reducida a un territorio de 80.000 km² con una población de unos 6 millones de habitantes, un tercio de los cuales vivían en Viena que se convirtió en una capital muy grande para un país tan pequeño. Se le prohibió unirse a Alemania y fue obligada a pagar compensaciones de guerra y a reducir su ejército a 30.000 soldados.

El Tratado de Neuilly-sur-Seine fue firmado el 27 de noviembre de 1919 en Neuilly-sur-Seine (Francia) entre Bulgaria y las potencias vencedoras en la Primera Guerra Mundial.

De acuerdo con lo estipulado en el tratado, Bulgaria reconocía el nuevo Reino de Yugoslavia, pagaba 400 millones de dólares en concepto de indemnización y reducía su ejército a 20.000 efectivos. Además, perdía una franja de terreno occidental en favor de Yugoslavia y cedía Tracia occidental a Grecia, por lo que quedaba sin acceso al Mar Egeo.

El tratado es conocido en Bulgaria como la "Segunda Catástrofe Nacional", siendo la primera su derrota en la Guerra Balcánica de 1913.

Hungría proclamó su independencia frente a Austria en el 16 de noviembre de 1918. Las fronteras temporales «de facto» de Hungría fueron las mismas que las trazadas por las líneas de la tregua de noviembre-diciembre de 1918. En comparación con el antiguo Reino de Hungría, esas fronteras no incluían:





La Triple Entente pidió reconocer a Hungría los nuevos territorios pertenecientes a Rumanía, a través de una línea trazada a lo largo del río Tisza. Sin la posibilidad de rechazar esos términos, pero tampoco queriendo aceptarlos, los líderes de la Primera República Húngara dimitieron y los comunistas llegaron al poder. Se formó la República Soviética Húngara y se organizó rápidamente un Ejército Rojo Húngaro. Ese Ejército tuvo, en un principio, éxito en contra de las legiones checoslovacas y llegó cerca de la antigua frontera de Galitzia (polaca), separando de esa manera a las tropas checoslovacas de las tropas rumanas. En el 1 de julio de 1919 se firmó la cesación de hostilidades entre el Ejército Rojo y las tropas checoslovacas, mientras que las tropas rumanas cruzaron el río Tisza, derrotaron al Ejército Rojo y ocuparon Budapest en el 4 de agosto de 1919.

El Estado húngaro fue restablecido por la Triple Entente, quien ayudó al almirante Horthy a llegar al poder, en el mes de noviembre de 1919. En diciembre de 1919 una delegación húngara fue invitada a la Conferencia de Paz de Versalles. Las fronteras definitivas de Hungría fueron establecidas por el Tratado de Trianon, firmado en el 4 de junio de 1920. Además de los territorios mencionados anteriormente, Hungría perdió otros territorios ocupados como parte del Imperio austrohúngaro:


Conforme al Tratado de Trianon, las ciudades Pécs, Mohács, Baja y Szigetvár, temporalmente bajo administración yugoslava, pasaron a Hungría. Un comité asignó pequeñas partes del norte de los antiguos distritos Árva y Szepes a Polonia, puesto que ahí vivía una mayoría de población polaca.

Los dirigentes de Francia, Gran Bretaña y los Estados Unidos declararon sus diferentes objetivos en relación con el Imperio otomano durante la Conferencia de Paz de París, 1919. 

El Tratado dejaba al Imperio otomano sin la mayor parte de sus antiguas posesiones, limitándolo a Estambul y parte de Asia Menor. En Anatolia Oriental se creaba un estado autónomo para los kurdos (Kurdistán), y varios distritos pasaban a Armenia (la República de Armenia se independizó de Rusia en 1918) para formar la Gran Armenia. Grecia recibía Tracia Oriental, Imbros, Ténedos y la región de Esmirna. Se reconocía la separación de Egipto, Hedjaz y Yemen; mientras que Mosul, Palestina y Transjordania pasaban a administración británica y Siria, Líbano y Alejandreta a administración francesa, que también recibía una zona de influencia en Cilicia. Chipre quedó para los británicos que ya lo administraban y Castellorizo para los italianos con una zona de influencia en la región de Antalya. La navegación en los estrechos sería libre y controlada por una comisión internacional.

El Tratado logró la expulsión del Imperio otomano de Europa. Esto había sido el sueño del cristianismo durante casi quinientos años contados a partir de la Liga Santa, se le puso la condición al Imperio otomano, tal que nunca podía ser reactivado de nuevo en su antigua forma.

Se configuró un nuevo mapa político de Europa creándose nuevas naciones: Polonia, Checoslovaquia, Hungría, Yugoslavia, Finlandia, Estonia, Letonia y Lituania. Se ratificaron las fronteras de los países vencidos. También se creó el conocido como "Cordón sanitario" para aislar el mundo capitalista del comunista.

La delegación de Japón, encabezada por Makino Nobuaki, planteó el reconocimiento de la igualdad racial en los estatutos de la Sociedad de Naciones, pero su petición no fue atendida. Desde el principio la delegación japonesa no fue tratada igual que los "cuatro grandes" y no sólo se les asignó un puesto en el extremo de la mesa de las negociaciones, sino que sus miembros tuvieron que soportar comentarios denigratorios y chistes racistas —el presidente francés Georges Clemenceau, por ejemplo, se quejó de tener que estar junto a los «feos» japoneses en una ciudad llena de atractivas mujeres rubias; el presidente australiano Billy Hughes, defensor a ultranza de una "Australia Blanca", hizo chistes sobre el canibalismo en referencia a los pueblos del Pacífico—. En el curso del debate sobre la igualdad racial, cuando al británico Lord Balfour se le argumentó que en la Constitución de Estados Unidos se reconocía que «todos los hombres son creados iguales», él respondió que no creía que «un hombre de África central fuera creado igual que un europeo». Entonces Makino pidió que se votara la propuesta y consiguió que fuera aprobada por la mayoría de los países representados en la conferencia, pero la oposición de Gran Bretaña y sus Dominios, especialmente Australia, fue tan radical que finalmente el presidente norteamericano Woodrow Wilson dictaminó que el voto quedaba anulado debido a la disconformidad expresada por varios países. Como ha señalado el ensayista indio Pankaj Mishra, la resolución en la que se rechazaba la igualdad racial «iba a ser recordada durante décadas por los nacionalistas japoneses».

Según este mismo autor indio, Wilson no respaldó la propuesta japonesa —que en el fondo respondía a los principios expresados en los Catorce Puntos— porque, además de que podía poner en cuestión la legislación antiasiática de Estados Unidos, «temía perder el apoyo de los británicos y de sus aliados australianos. En gran medida, la anglofilia cegaba a Wilson y a sus asesores (en su mayoría miembros de la élite blanca anglosajona y protestante de la costa Este), lo que le impedía ver la pasión anticolonial que existía en Asia y África».

Los vencidos, sobre todo Alemania, se quedaron con la sensación de haber sido tratados injustamente (revanchismo y nacionalismo), que, entre otras cosas, causaría el estallido de la Segunda Guerra Mundial. Además no se resolvió el problema de las nacionalidades quedando en evidencia el principio teórico de las negociaciones.


</doc>
<doc id="28133" url="https://es.wikipedia.org/wiki?curid=28133" title="Kartum">
Kartum

Kartum es el título de una película británica del género de cine histórico de tipo bélico, dirigida en 1966 por el director cinematográfico Basil Dearden, con la participación de actores de renombre, como Charlton Heston, Laurence Olivier, Ralph Richardson, Richard Johnson, Alexander Knox y Johnny Sekka. La película fue nominada a un Oscar de la Academia.

En 1883, el Primer Ministro británico Gladstone (Richardson) envía al General Charles Gordon (Charlton Heston) a Jartum, Sudán, donde miles de civiles viven bajo la amenaza del fanático musulmán autodenominado como el Mahdi (Lawrence Olivier), y sus ejércitos de seguidores llamados los derviches. El Mahdi ha reforzado su autoridad al masacrar un ejército de soldados sudaneses probritánicos y amenazan con extender su influencia por toda la región.

El Muhammad Ahmad-El Mahdi es un místico líder musulmán que se siente llamado por el profeta "Mahomed-El Bendecido" para hacer huir a sus enemigos infieles (el Imperio otomano y el británico) de sus tierras ancestrales y sus intenciones son nada menos que llegar hasta Constantinopla.

Gordon es un militar británico que camina entre la marcialidad inglesa cumpliendo las órdenes del Imperio británico y un espíritu renegado y con un profundo amor nacionalista a los sudaneses. El Imperio británico, representado por Gladstone, se resiste a enviar refuerzos al Sudán debido a que la presencia de tropas puede desestabilizar la región y pretende abandonar Sudán. Gordon se opone a las intenciones británicas y es en esta postura renegada la que acarrea la respuesta de los derviches y se desata una cruenta yihad por parte de El Mandhi.

Gordon consigue ganarse el respeto de El Mahdi al presentarse sin armas y solo acompañado por un ayudante al campamento enemigo pidiendo una tregua; pero el Mahdi no puede impedir que sus seguidores sitien la ciudad. En este momento en que el destino de la historia se encuentra pendiente de un hilo, Gordon se enfrenta a la mayor batalla de su vida en defensa de la ancestral ciudad de Jartum.

Charton Heston como el General Gordon y Laurance Olivier como el Mahdi, ambos ganadores de premios Oscar de la Academia, se enfrentan actoralmente en este épico y conmovedor drama personificando con gran calidad artística a dos hombres aguerridos, místicos y sólidos en sus convicciones; pero que se respetan entre sí y dos imperios que se oponen por una región convulsionada por el fanatismo religioso de los derviches y los intereses colonialistas británicos. 
La batalla final por la sitiada ciudad de Jartum termina de manera ignominiosa para los intereses británicos.

Filmada en Cinerama, con asombrosas batallas en el desierto orquestadas por el creador de la carrera de cuadrigas de "Ben-Hur", "Kartum" ofrece un magnífico espectáculo de acción con excelentes interpretaciones y asombrosa cinematografía, si bien se pierde por un exceso de diálogos haciéndola poco dinámica, aspecto que es acentuado al no aprovechar al máximo la espectacularidad de la historia, hechos y escenarios.

Por lo que se refiere a los aspectos técnicos, la película fue rodada en Ultra Panavision 70 mm y presentada en "Cinerama", lo que dota de gran vistosidad a varias escenas, en especial las relativas a combates en el desierto. Destaca la actuación de Lawrence Olivier como el Mahdi.

Añadir que, inicialmente el papel del General Gordon iba a recaer en el actor Burt Lancaster, propuesta que tuvo que rechazar al coincidir con otro rodaje: "El Gatopardo".


La película fue nominada a un Oscar al mejor guion original.



</doc>
<doc id="28134" url="https://es.wikipedia.org/wiki?curid=28134" title="Who's Afraid of Virginia Woolf?">
Who's Afraid of Virginia Woolf?

Who's Afraid of Virginia Woolf? es una película estadounidense de 1966 de comedia negra y drama dirigida por Mike Nichols. El guion de Ernest Lehman es una adaptación de la obra de teatro homónima de Edward Albee. Tuvo como protagonistas a Elizabeth Taylor como Martha y Richard Burton como George, con George Segal como Nick y Sandy Dennis como Honey.

La película fue nominada a trece Premios Oscar, incluyendo Mejor Película y Mejor Director por Mike Nichols, y es una de las dos únicas películas en ser nominada en todas las categorías elegibles (la otra es "Cimarron"). Los cuatro actores principales de la película fueron nominados en sus respectivas categorías de actuación. De gran éxito de público en el momento de su estreno, lanzó a la fama a un joven realizador que en 1967 reeditaría el éxito de crítica y público con otro clásico, "El graduado".

La película ganó cinco premios, incluyendo un segundo premio de la Academia a la Mejor actriz por Elizabeth Taylor y el de Mejor actriz de reparto por Sandy Dennis. Sin embargo, la película pierde frente a "A Man for All Seasons" en las categorías Mejor película, Mejor director, Mejor actor y Mejor guion adaptado. En 2013, la película fue seleccionada para su preservación en el Registro Nacional de Cine de la Biblioteca del Congreso de los Estados Unidos como "cultural, histórica o estéticamente significativa". Además, se la reconoce como uno de los filmes más importantes de la carrera de Elizabeth Taylor, por su actuación y por el gran elenco que compone la producción.

El título hace una referencia a la famosa escritora Virginia Woolf y a su apellido, utilizándolo como una parodia de la frase y canción clásica de Frank Churchill y Ann Ronell, "Who's Afraid of the Big Bad Wolf?" ("¿Quién le teme al lobo feroz?").

La película se centra en un vecindario inglés de la universidad de Nueva Inglaterra, se basa en la relación volátil de un profesor de Historia en la universidad llamado George y su esposa alcohólica Martha, quien además era la hija del presidente de la universidad. George y Martha se involucran en juegos emocionales entre sí, pero ignorando que es peligroso. Ambos van a una fiesta y al salir de aquel lugar, eran las dos de la madrugada, razón en la que Martha llega a su casa con su esposo y producen una pequeña discusión en cuanto a las películas de Bette Davis.

Después de la discusión, Martha revela que había invitado a un joven matrimonio, a quien conoció en la fiesta para tomar una copa. George no acepta al ver que era tarde, pero al final, termina aceptando las ideas y decisiones de su esposa. Luego, llegan los huéspedes, Nick, un profesor de biología (Martha piensa que enseña matemáticas en la pequeña discusión anterior) y su esposa, Honey. Mientras los cuatro comienzan a beber, Martha y George son capaces de practicar un abuso verbal frente a los invitados, ellos sienten vergüenza y revelan que era mejor no haber ido, pero más tarde se quedan al enredarse con el matrimonio de George y Martha. 

Honey y Martha se separan un tiempo de los esposos, Martha decide mostrarle la casa a su amiga. Cuando regresan, Honey revela que Martha le ha mencionado asuntos relacionados de su hijo y el de George y añade que al día siguiente (domingo) marcará su decimosexto cumpleaños. George se enoja ya que anteriormente le pidió a Martha no comentar sobre este tema y Martha ha divulgado esta información. 

Más tarde, Martha se burla de George agresivamente y este se aleja de los huéspedes y de su esposa para ir a otra habitación de la casa. Martha cuenta una historia muy vergonzosa de cómo ella humilló a George delante de su padre. Las burlas de Martha continúan y George reacciona violentamente tomando una escopeta y trata de dispararle a Martha. Al disparar, Honey se asusta y grita, pero se trataba de un paraguas que se abrió al disparar. Después de esta pesada broma, Martha continúa burlándose de George y este rompe una botella como producto de su enojo. Nick y Honey son cada vez más inestables, y Honey pronto corre al baño a vomitar, debido al exceso de alcohol.

Cuando sus invitados proponen irse, George insiste en llevarlos a casa, a pesar de su estado de embriaguez. Se acercan a una caseta y Honey sugiere que se detengan a bailar. Mientras Honey y George miran, Nick baila sugestivamente con Martha, quien continúa burlándose y criticando a George. George desconecta la máquina de discos y anuncia que el juego ha terminado. En respuesta, Martha alude al hecho de que pudo haber asesinado a sus padres como el protagonista en su novela inédita y de no ficción , lo que llevó a George a atacar a Martha hasta que Nick lo aleja de ella. George le cuenta al grupo sobre una segunda novela que supuestamente escribió sobre una joven pareja del Medio Oeste, una maestra guapa y su tímida esposa, que se casan debido a su embarazo histérico.y dinero, luego establecerse en una pequeña ciudad universitaria. Honey, avergonzada, se da cuenta de que Nick le contó indiscretamente a George sobre su pasado y sale corriendo de la habitación. Nick promete vengarse de George, y luego corre tras Honey.

En el estacionamiento, George le dice a su esposa que no puede soportar la forma en que ella lo humilla constantemente, y ella lo acusa burlonamente de que se haya casado con ella por esa misma razón. Su ira estalla en una declaración de "guerra total". Martha se marcha, recuperando a Nick y Honey, dejando a George para regresar a casa a pie. Cuando llega a casa, descubre que el auto se estrelló en el camino y Honey medio consciente en el asiento trasero y ve a Martha y Nick juntos a través de la ventana de la habitación. A través del balbuceo borracho de Honey, George comienza a sospechar que su embarazo fue real y que tuvo un aborto en secreto . Luego diseña un plan para volver a Martha.

Cuando Martha acusa a Nick de ser sexualmente inadecuado, culpa de su falta de rendimiento a todo el licor que ha consumido. George luego aparece sosteniendo dragones dragones, que arroja a Martha y Nick en otro juego. Menciona a él y al hijo de Martha, lo que la incita a recordar su nacimiento y su infancia y cómo fue casi destruido por su padre. George acusa a Martha de participar en un comportamiento destructivo y abusivo con el niño, quien con frecuencia se escapó para escapar de su atención. George luego anuncia que recibió un telegrama con malas noticias: su hijo murió en un accidente automovilístico.

Cuando Martha le ruega a George que no "mate" a su hijo, Nick de repente se da cuenta de la verdad: Martha y George nunca habían podido tener hijos, y llenaron el vacío con un hijo imaginario. Al declarar a su hijo muerto, en consecuencia, George lo "mató". George explica que su única regla mutuamente acordada era nunca mencionar la "existencia" de su hijo a nadie más, y que él "lo mató" porque Martha rompió esa regla al mencionarlo a Honey.

La joven pareja se marcha en silencio, y George y Martha se quedan solos cuando el día comienza a salir. George comienza a cantar la canción "¿Quién teme a Virginia Woolf?", Y Martha responde: "Yo soy, George, yo soy".

La película fue la única nominada para los Premios Óscar en cada categoría en la que podía ser elegible (película, actor, actriz, actor de reparto, actriz de reparto, director, guion, dirección artística/decoración del set (blanco y negro), cinematografía (blanco y negro), sonido, diseño de vestuarios (blanco y negro), música y montaje). 

Cada uno de los cuatro actores fue nominado para un Oscar, pero solo Elizabeth Taylor (Oscar a la mejor actriz) y Sandy Dennis (Oscar a la mejor actriz de reparto), lo ganaron. La película también ganó el premio de Oscar a la mejor fotografía en blanco y negro por el gran trabajo de cámara de Haskell Wexler (fue la última película en ganar en dicha categoría antes de que fuera eliminada). También recibió:

Recibió además:


Un gran duelo interpretativo entre Richard Burton y Elizabeth Taylor, por aquel entonces casados, bien secundado por la otra pareja protagonista del filme, George Segal y Sandy Dennis. Célebre por contener una de las mejores interpretaciones, si no la mejor, de Taylor y por una puesta en escena brillante que, sin deshacerse de su origen teatral, logra tener entidad propia como largometraje.

En el agregador de revisión de reseñas Rotten Tomatoes , la película tiene una calificación de aprobación del 95% basada en 42 reseñas, con una calificación promedio de 8.53 / 10. El consenso crítico del sitio web dice: "Dirigido por una actuación volcánica de Elizabeth Taylor, ¿Quién teme a Virginia Woolf? Es una adaptación mordaz de la obra de Edward Albee que sirve como una brillante tarjeta de presentación para el director debut Mike Nichols". En Metacritic , que asigna una calificación media ponderada a las críticas, la película tiene una puntuación de 75 basada en 11 críticas, lo que indica "críticas generalmente favorables".

En una crítica positiva, Variety escribió que "La adaptación entusiasta y la producción atractiva de Ernest Lehman, la dirección sobresaliente de Mike Nichols en su debut cinematográfico y cuatro actuaciones destacadas logran un blanco artístico". y, alabando la actuación de Taylor, que su "caracterización es a la vez sensual, rencorosa, cínica, lamentable, repugnante, lujuriosa y tierna". 



</doc>
<doc id="28135" url="https://es.wikipedia.org/wiki?curid=28135" title="Benimámet">
Benimámet

Benimámet (en valenciano y oficialmente Benimàmet) es una pedanía de Valencia, situada en el noroeste de su término municipal, en el distrito de Poblados del Oeste limitando con las poblaciones de Burjasot y Paterna. Su población censada en 2012 era de 14.174 habitantes (INE). Fue un municipio independiente hasta 1882, año en que pasó a ser una pedanía de Valencia. Conforma, junto con Beniferri, el distrito de Poblados del Oeste (en valenciano "Poblats de l'Oest"). En sus alrededores se encuentra ubicada la Feria Muestrario Internacional de Valencia y el Velódromo Municipal Lluís Puig.

El término Benimámet proviene de la forma árabe "Benimahaber", "Benimahabar" o "Benimabar", probablemente escrita ("Banī Maḥbar"). Sin embargo, también se lo ha hecho derivar de ("Banī Muḥammad"). Carmen Barceló, por su parte, defiende la forma ("Banī Maḥbit"), antropónimo árabe conocido. En todo caso, el topónimo deriva de un antropónimo formado por "banī" («hijos de») y el nombre en cuestión. La actual forma Benimámet aparece mencionada por primera vez en 1310.

En Benimámet pudo haber un asentamiento romano, dado que ha habido en su término algunos hallazgos, sobre todo monetarios. Sin embargo, sólo hay certeza de que fue una alquería andalusí, y apenas se tiene documentación anterior a su conquista por Jaime I de Aragón. Su primera mención aparece en el Llibre del Repartiment con la forma "Benimahaber". En él consta que el 21 de agosto de 1238 se entregan a Sanchís de Stada los bienes pertenecientes hasta entonces a Hibraim Alfachar.

La incorporación a Valencia como municipio anexionado, respondía a la ley que permitía a las ciudades anexionarse municipios limítrofes de una población inferior a 2.000 habitantes. Por ello, a finales de la década del siglo XX, surge un movimiento de segregación representado por el colectivo "Benimàmet Poble" amparado en la escasa atención prestada por el Ayuntamiento de Valencia a la población de Benimámet y en la comparación de las infraestructuras propias de la pedanía con las de las poblaciones colindantes, iniciándose así, el largo proceso jurídico-administrativo que pretende segregar a la población de la ciudad de Valencia.

Benimámet se encuentra al noroeste de la ciudad de Valencia, está considerado como parte de Valencia. La superficie geográfica es llana en gran parte. Aunque, en la zona noreste, en la zona de la Feria de Valencia, se eleva entre diez y veinte metros más que en el centro de Benimámet, que se encuentra a cuarenta y tres msnm. En cuanto a la distancia, se encuentra a cinco kilómetros con setecientos metros de Valencia.

Benimámet limita, al oeste con Paterna, al norte con Burjasot, al sur con la Huerta Valenciana y al este con Valencia.

Benimámet tiene características de población dormitorio de Valencia. A principios del siglo XX fue lugar de segunda residencia para algunos miembros de la pequeña burguesía de la capital que en verano habitaban los chalets del barrio de Las Carolinas, así como en la parte norte de la Calle Felipe Valls y Plaza de Luis Cano. De aquella época han quedado todavía algunos chalets y viviendas de recreo, aunque un número importante han sido pasto de la construcción de pisos. En la década de 1950 y, de manera continuada desde entonces, Benimámet ha aumentado de población gracias a la inmigración que ha recibido de las provincias de Teruel, Cuenca y del interior de Valencia.

A lo largo de los años 1970 llegaron inmigrantes procedentes de Andalucía, particularmente de la provincia de Jaén, y en la actualidad la población continúa acogiendo inmigración de origen pakistaní, de países africanos, de América Latina, del Magreb y de Europa del Este, convirtiendo a la población en una amalgama cultural y pluriétnica.

Benimámet depende del Ayuntamiento de Valencia en consideración de barrio del distrito de Poblados del Oeste (en valenciano "Poblats de l'Oest"). Sin embargo, dada su condición de poblamiento rural, cuenta, de acuerdo con las leyes estatales y autonómicas pertinentes, con un alcalde de barrio, compartido con Beniferri, que se encarga de velar por el buen funcionamiento del barrio y de las relaciones cívicas, firmar informes administrativos y elevar al ayuntamiento de la ciudad las propuestas, sugerencias, denuncias y reclamaciones de los vecinos.

Al tratarse de una ciudad dormitorio, la mayor parte de sus habitantes trabajan fuera de la población, razón por la cual, en la actualidad, tanto la industria como la agricultura tienen una importancia marginal en la economía de la población.

Históricamente, la actividad principal de Benimámet fue la agricultura (cítricos fundamentalmente) y alguna pequeña industria manufacturera, aunque entre los años sesenta y ochenta del siglo XX tuvo cierta importancia la fabricación de muebles, particularmente Sanfélix Villarrubí, donde a principios de los setenta del siglo pasado llegó a tener más de cien trabajadores. En la actualidad, a consecuencia del urbanismo desaforado que sufre la población, las zonas dedicadas a la agricultura son mínimas.

Una importante fuente de ingresos la constituye el turismo de convenciones dada la proximidad de la Feria Muestrario Internacional de Valencia, o más conocida como la Feria de muestras.

Se fundó en 1917. En la actualidad se organizan alrededor de 40 eventos anuales, más de la mitad son eventos internacionales y se han contabilizado más de un millón trescientos mil visitantes. Con un presupuesto anual de 75 millones de euros, se estima un impacto económico de 750 millones de euros anuales en promedios. Existe un calendario de ferias.











Benimámet tiene muchos lugares ajardinados, lo que constituye en la posibilidad de encontrar muchos lugares de esparcimiento y recreo: la Plaza Luis Cano que dispone de área infantil, el Parque Camales con áreas infantiles, deportiva y para mayores, el Parque del Chalet Panach en la calle Campamento y a las afueras del Velódromo Lluis Puig es posible la práctica deportiva y el esparcimiento. Benimámet cuenta además con una zona singular, el Parque Lineal.

El Parque de Panach tiene una superficie de 6.066 m². El agua toma un especial protagonismo con la construcción de un puente y de una cascada que salvan el desnivel del jardín, debajo de los cuales se localiza un estanque con surtidores de agua y vegetación a su alrededor. En el jardín abundan las especies de árboles y arbustos autóctonos, así como algunos cítricos que recuerdan el antiguo huerto de naranjos que inicialmente ocupaba el terreno, mientras que el paseo principal está flanqueado por palmeras datileras. El jardín recupera un antiguo huerto existente junto a un chalet construido en el siglo XIX, rehabilitado como biblioteca pública.
El interior del edificio principal está decorado con azulejos de Nolla y con lámparas que imitaban a las del Hotel Alfonso XIII de Sevilla. Junto a la calle Joaquín Marín, se encuentran los restos recuperados de una antigua construcción fabril, donde las antiguas mesas de trabajo se han reutilizado para juegos de mesa, y en cuyo entorno existe una zona de descanso con una pérgola entre rosales. Este jardín dispone de dos zonas equipadas con juegos infantiles.

El Parque Lineal de Benimàmet es una zona singular que ha resultado del soterramiento de las vías del metro a su paso por el núcleo urbano de esta población. Esta zona verde se extiende desde la estación de metro de Les Carolines a más allá de la estación de Benimàmet e incluye 850 m de carril bici, 3 zonas de juegos infantiles, varias pistas de petanca, un parque biosaludable, una zona de pícnic con 10 mesas, escenario con gradas para la realización de eventos y un área de socialización canina.

En el Parque Lineal dentro de los más de 30.000 m² de superficie ajardinada, hay plantados más de 500 árboles y alrededor de 7.300 arbustos y plantas de flor que se pueden disfrutar en un paseo de 1.200 metros lineales. El ajardinamiento se completa con 12.000 m² de pradera mediterránea.
Dentro de la superficie del parque encontramos dos eucaliptos, uno de ellos es de grandes dimensiones y está considerado como el árbol más alto de la ciudad.
En las proximidades de la estación de metro de Las Carolinas se encuentra un singular espacio, protegido con carpas y acondicionado con asientos, destinado a la realización de eventos sociales que se pone a disposición de las diferentes asociaciones del barrio y que está llamado a ser una importante zona de reunión ciudadana.
Las salidas de emergencia del metro están decoradas con murales hechos por artistas de Benimàmet.

Si visitas Benimámet no puedes marcharte sin dar un paseo por sus calles, y en especial, por la calle Felipe Valls donde verás preciosas villas : Villa Carmen, Villa Isabel , Villa Garnelo, entre otras.

Se celebran en marzo, como en muchos pueblos de Valencia, las Fallas dedicadas a San José. Benimámet agrupa 5 fallas, siendo la más antigua, creada en el año 1944, la Falla de Benimámet-Plaza Luis Cano. También está la Falla del Secanet, barrio de tradición inmigrante, la Falla de la Plaza de la Tienda, la Falla Evaristo Bas-Cullera y la Falla Campamento-La Yesa. 

En verano las fiestas consideradas patronales: San Francisco de Paula, por los agricultores, y San Vicente Mártir, patrono del pueblo, y fiesta que de alguna manera ha sido utilizada por ciertos sectores más creyentes. En el barrio de Las Carolinas, la Fiesta de San José, que actualmente cuenta con mucha popularidad.

Las fiestas más antiguas son a la Virgen del Rosario que hoy no se celebra, la Minerva que es por tradición familiar, la custodia del Altísimo y San Vicente Mártir que en la actualidad es la fiesta con más clavarios. Desde 1885 se celebra a San Francisco de Paula por el milagro de la salvación del cólera y que hoy cuenta con numerosos devotos ("véase": Pandemias de cólera en España).
También en Benimámet se celebra la cabalgata de Reyes, la Bendición de los Animales de San Antonio Abad, la cruz de Mayo en la plaza de Camporrobles, el canto de "los mayos" por diferentes entidades festeras y falleras, la noche de San Juan, se celebraba la Virgen de Agosto y San Agustín con grandes festejos y también se celebra la patrona de la música, Santa Cecilia, que clavariesas y la Banda de Música de la Sociedad Instructiva del Obrero Agrícola y Musical llenan las calles de festejos musicales.

Benimámet cuenta actualmente con 2 centros de Educación Infantil, 3 colegios Educación Primaria y 2 institutos, así como diversos centros de enseñanza extraescolar.

Destaca asimismo la Sala Cervantes como centro de iniciativas culturales.

También en Benimámet se sitúa una sede de la Universidad Popular de Valencia, en la que se realizan actividades de culturización, expresión plástica y corporal y formación ocupacional, entre otras. 

Benimámet cuenta además con la biblioteca Teodoro Llorente, ubicada en el Chalet de Panach. Esta fomenta la investigación y la lectura con su amplio catálogo de libros, CD y DVD, además de libre disposición de Internet por WIFI.





</doc>
<doc id="28136" url="https://es.wikipedia.org/wiki?curid=28136" title="Risky Business">
Risky Business

Risky Business (titulada Negocios arriesgados en México, Negocios riesgosos y Negocio de riesgo en Hispanoamérica y Risky Business en España) es una película estadounidense de género comedia. Estrenada en 1983 está escrita y dirigida por Paul Brickman en lo que fue su debut como realizador. La película está interpretada en sus papeles principales por Tom Cruise, Rebecca De Mornay, Richard Masur, Bronson Pinchot y Joe Pantoliano. También se considera la cinta que impulsó la carrera cinematográfica de Cruise quien fuera nominado por este papel en los premios Globos de Oro. 

Joel (Cruise) es un modélico estudiante de secundaria de 17 años que vive con sus adinerados padres en Chicago. Ellos desean que su hijo asista a la Universidad de Princeton por lo que Joel participa en Future Enterprisers una actividad extraescolar en la que los estudiantes trabajan en equipos para crear pequeñas empresas. 

Cuando sus padres se van de viaje Miles (Armstrong), amigo de Joel, lo convence de que aproveche su nueva libertad para divertirse y hacer extravagancias que no puede hacer delante de sus padres como ​​bailar en la sala de estar en ropa interior. Al día siguiente Joel llama a una prostituta, Lana (De Mornay), que le pide 300 dólares por sus servicios durante toda la noche. Joel va al banco a buscar dinero pero al regresar descubre que Lana se ha ido llevándose consigo un costoso huevo de cristal Steuben de su madre. Joel encuentra a Lana en un hotel y le pide que le devuelva el huevo robado pero son interrumpidos por Guido (Pantoliano), el proxeneta de Lana, quien lo amenaza con una pistola. Joel y Lana huyen en el Porsche 928 de su padre y, aunque son perseguidos por Guido, finalmente logran escapar.

Lana le dice a Joel que el huevo de cristal está, con el resto de sus cosas, en casa de Guido y que tratará de recuperarlas. Joel le permite a Lana quedarse en su casa mientras él va a la escuela y Lana invita a otra prostituta, Vicki, a quedarse pero Joel rechaza la idea. Esa noche Joel, Lana, Vicki y Barry (Pinchot), amigo de Joel, salen y mientras Vicki y Barry se alejan, Joel y Lana hablan. Pese a las advertencias de Joel, Lana quita la marcha de la palanca de cambios del coche lo que hace que el Porsche ruede cuesta abajo hacia un muelle. A pesar del inútil intento de Joel de detenerlo el muelle cede tirando el Porsche en el lago Míchigan.

Cuando Joel lleva el automóvil a un taller de reparación se horroriza al saber cuánto costará limpiarlo y repararlo. Para solucionarlo el y Lana deciden convertir la casa de sus padres en un burdel por una noche y con la participación de Joel en las ganancias pagarán la reparación. La fiesta es un gran éxito ya que la casa se llena de amigos y compañeros de clase de Joel y compañeros de trabajo de Lana. Sin embargo el reclutador de Princeton, Rutherford (Masur), elige justo esa misma noche para entrevistar a Joel de cara a su admisión a Princeton. La entrevista, plagada de interrupciones, no logra impresionar a Rutherford aunque después decide quedarse en la fiesta y se familiariza con los amigos de Lana. Después de la fiesta Joel y Lana tienen relaciones sexuales.

A la mañana siguiente Joel descubre que su casa ha sido saqueada. Cuando trata de llamar a Lana es Guido quien responde al teléfono y este le comunica que si quiere recuperar los muebles deberá pagar por ellos a lo que el joven accede. Finalmente Joel y sus amigos logran que todo vuelva a su ser justo un momento antes de que sus padres vuelvan a casa aunque su madre percibe que el huevo de cristal tiene una fisura. Posteriormente el padre de Joel lo felicita ya que el entrevistador quedó muy impresionado y ha indicado que Joel será aceptado en Princeton. 

Finalmente Joel se encuentra con Lana en un restaurante, y especulan sobre su futuro, ella le dice que quiere seguir viéndolo, pero él bromea que le costará.


Las canciones incluidas en la banda sonora están interpretadas por algunos artistas populares en la música de los años 1980 como Jeff Beck, Prince, Journey o Phil Collins. Sin embargo el grueso de las canciones, instrumentales y de estilo electrónico, fueron compuestas por el grupo de música electrónica alemán Tangerine Dream integrado entonces por Edgar Froese, Christopher Franke y Johannes Schmoelling. También en la película se incluyeron canciones de The Police, Bruce Springsteen y Talking Heads que no aparecen en las ediciones discográficas de la banda sonora.


</doc>
<doc id="28137" url="https://es.wikipedia.org/wiki?curid=28137" title="Teorema de Sarkovskii">
Teorema de Sarkovskii

Sea una aplicación continua "f" : formula_1formula_2. Si esta función tiene un punto periódico de período "k", entonces tiene puntos periódicos de todos los períodos inferiores a "k" según el orden "«" siguiente:

Este teorema es "óptimo", es decir, si m « k según el orden precedente, existen aplicaciones continuas con puntos periódicos de periodo m pero sin punto periódico de período k.
En particular, una función que presenta un punto x periódico de orden tres, es decir tal que:

donde formula_3 es la composición de las funciones, entonces presentará puntos periódicos de cualquier orden:

Se dice que el periodo tres implica el caos, y esta propiedad es fundamental en la teoría del caos.<br>
Este corolario recibe el nombre de Teorema de Li y Yorke, matemáticos que redescubrieron en Estados Unidos parte del teorema ruso, que había pasado totalmente inadvertido en Occidente.

El ejemplo fundamental es "f(x)= a·x·(1 - x)", con "x" en el intervalo [ 0; 1], y "a" en [0; 4]. Cuando "a" crece de 0 a 4, va apareciendo puntos periódicos de orden 2, luego 4, luego 8, 16, ... y finalmente 3.

En las abcisas está el parámetro a. El período 3 aparece para "a" algo mayor que 3,8, justo al salir de la zona caótica (en gris).

El teorema utiliza el que R es totalmente ordenado y unidimensional, no se aplica a los números complejos:<br>
La función "f" :C →C definida por f(z) = e·z es tal que todos los puntos del plano son periódicos de orden 3, pero de ningún otro orden (excepto 0 que es de orden 1) - f es una rotación de ángulo 120 grados o 2·π/3 radianes y no existe equivalentes de las rotaciones en una dimensión.


</doc>
<doc id="28139" url="https://es.wikipedia.org/wiki?curid=28139" title="Teorema de Li y Yorke">
Teorema de Li y Yorke

El teorema de Li y Yorke es un teorema matemático que afirma que, siendo "f": R → R una aplicación continua, si "f" tiene un punto periódico de periodo 3 entonces tiene puntos de cualquier periodo.



</doc>
<doc id="28140" url="https://es.wikipedia.org/wiki?curid=28140" title="Pan (mitología)">
Pan (mitología)

Pan (en griego, Πάν) era el semidiós de los pastores y rebaños en la mitología griega. Era especialmente venerado en Arcadia, a pesar de no contar con grandes santuarios en su honor en dicha región. En la mitología romana se identifica a este dios como un Fauno.

Pan era también el dios de la fertilidad y de la sexualidad masculina. Dotado de una gran potencia y apetito sexual, se dedicaba a perseguir por los bosques, en busca de sus favores, a ninfas y muchachas. En muchos aspectos, el dios Pan tiene cierta similitud con Dioniso.

Era el dios de las brisas del amanecer y del atardecer. Vivía en compañía de las ninfas en una gruta del Parnaso llamada Coricia. Se le atribuían dones proféticos y formaba parte del cortejo de Dioniso, puesto que se suponía que seguía a este en sus costumbres. Era cazador, curandero y músico. Habitaba en los bosques y en las selvas, correteando tras las ovejas y espantando a los hombres que penetraban en sus terrenos. 

Portaba en la mano el cayado o bastón de pastor y tocaba la siringa, a la que también se conoce como Flauta de Pan. Le agradaban las fuentes y la sombra de los bosques, entre cuya maleza solía esconderse para espiar a las ninfas. 

Se dice que Pan era especialmente irascible si se le molestaba durante sus siestas. Los habitantes de Arcadia tenían la creencia de que, cuando una persona dormía la siesta, no se la debía despertar bajo ningún motivo ya que, de esa forma, se interrumpía el sueño del dios Pan. En este caso, Pan se aproxima a la noción de Demonium Meridianum (Demonio del Mediodía).

Por último, como deidad, Pan representaba a toda la naturaleza salvaje. De esta forma, se le atribuía la generación del miedo enloquecedor. De ahí la palabra pánico que, en principio, significaba "el temor masivo que sufrían manadas y rebaños ante el tronar y la caída de rayos".

Pan tiene diecinueve genealogías diferentes; en la mayoría de ellas su padre fue Hermes, en tanto que el nombre de la madre varía (usualmente ésta pertenecería a la raza de las ninfas; una hija de Dríope, Timbris, Sose, Calisto u Orneo). 

Según una de las tradiciones, cuando Hermes pastoreaba los rebaños de Dríope, tuvo una relación amorosa con una de las hijas de este, de la que nació el dios Pan. Según esta versión, cuando nació, presentaba sus miembros inferiores en forma de macho cabrío y el resto del cuerpo con apariencia de hombre. En la cabeza tenía dos cuernos y su cara era arrugada, con una barbilla prominente, con todo el cuerpo cubierto por una espesa capa de pelo. Se dice que, apenas nacido, escapó a las montañas, donde Hermes tuvo que buscarlo para llevarlo al Olimpo envuelto en una piel de liebre. Una vez allí, lo llamaron Pan, puesto que era la diversión de "todos".

Otra de las tradiciones cuenta que Penélope, durante la ausencia de su esposo Odiseo, tuvo varios amantes, quedando encinta de uno de ellos. De esta manera, nació Pan, nombre que significa "hijo de todos". 

Otra de ellas decía que, tras el regreso de sus viajes, Odiseo repudió a Penélope por sus infidelidades y que, una vez abandonada, concibió al dios Pan, fruto de su unión con Hermes.

Otras tradiciones apuntan a que fue hijo de Zeus y de la ninfa Hibris, de Zeus y Calisto o de Hermes y una ninfa.

En cuanto a su descendencia, varía según el autor. En las "Dionisíacas" de Nono se dice que Pan engendró a los doce Panes, una raza de sátiros menores que colaboraron con Dioniso. En otras fuentes aparece como padre de Croto (con Eufeme), Acis (con Simetis), Eurimedonte (sin especificar la mujer), Creneo (con la ninfa Isménide o Ismenis), Iinge (con la ninfa Eco) y finalmente el también célebre Sileno (habido con la Oceánide Melia).

En cuanto a sus relaciones, se dice que tuvo amores correspondidos con la ninfa Pitis, que también era pretendida por Bóreas. Este último, arrastrado por los celos, arrojó a Pitis desde lo alto de una roca. Sintiendo pena, la diosa Gea la transformó en pino, siendo Pan, desde entonces, coronado con las hojas del pino. También existe la creencia de que el pino gime cuando sopla Bóreas.

Asimismo, Pan estaba intensamente enamorado de la ninfa Siringa, quien no le correspondía. Se dice que una vez, mientras huía de Pan, se lanzó al río Ladón. Quedó acorralada y pidió ayuda a sus hermanas las ninfas quienes, conmovidas, la convirtieron en un cañaveral. Se cuenta que, cuando Pan llegó, sólo pudo abrazar las cañas que se mecían por el viento y el rumor que producían le causó tal agrado que decidió construir un nuevo instrumento musical con ellas. Así, creó la flauta siringa, en recuerdo de la ninfa de igual nombre.

Del mismo modo, sedujo a Selene regalándole un vellón de gran blancura. Desde entonces, ambos fueron venerados en una caverna del monte Liceo.

Según cuenta Heródoto, unos días antes de la batalla de Maratón, un mensajero ateniense que volvía de pedir ayuda a Esparta encontró al dios y este le prometió que vencerían a los persas. Por ello, tras ganar efectivamente la batalla a causa de un súbito pánico en las filas enemigas, fue incluido entre los grandes dioses reconocidos por el estado. En la propia ciudad de Atenas se le consagró una de las grutas de la vertiente norte de la Acrópolis y se decretó en su honor una fiesta anual donde se realizaban carreras de antorchas.

También estaban consagrados a Pan los montes Ménalo, Lampea y Nomia, todos ellos en Arcadia. Por otra parte, en Licosura existía un santuario oracular de Pan. 

Los ritos de fertilidad originales fueron asumidos a partir del siglo V por las Bacantes, que duraron hasta bien entrada la Edad Media. Desde entonces, y hasta nuestros días, la imagen tradicional de Pan se asocia con la imagen del diablo (en forma de macho cabrío) y los aquelarres.















</doc>
<doc id="28141" url="https://es.wikipedia.org/wiki?curid=28141" title="Pan (satélite)">
Pan (satélite)

En astronomía, Pan es una de las lunas del planeta Saturno, llamada también Saturno XVIII. Es el más interno de los satélites conocidos de este planeta (apenas a 133 583 km del centro de Saturno), y se encuentra en la división Encke del anillo A de Saturno, de la que actúa como luna pastora, siendo responsable de mantenerla abierta. Fue descubierto por Mark R. Showalter en 1990 que provoca la separación de los anillos de Saturno mientras examinaba las viejas fotografías obtenidas nueve años antes por el Voyager en su encuentro con Saturno. Pan es conocida como la "luna tortellini", por su forma peculiar a una pequeña empanadilla de pasta tortellini.

También Pan, en la mitología griega, era el dios sátiro de los bosques, los campos y la fertilidad, hijo de Hermes, mensajero de los dioses olímpicos, y de una ninfa también de los bosques.

La existencia de un satélite en la división Encke fue predicha por Jeffrey N. Cuzzi y Jeffrey D. Scargle en 1985, basado en los bordes ondulados de la división que indicaba una distorsión gravitacional. En 1986 Showalter y su equipo infirió su órbita y masa modelando su estela gravitacional. Llegaron a una muy precisa predicción de 133.603 ± 10 km para el semieje mayor y una masa de 5–10 masas de Saturno, e infirieron que había un solo satélite dentro de la división. El actual semieje mayor difiere solo en 19 km y la masa actual es de 8,6 masas de Saturno.

El satélite fue encontrado después en la primera posición predicha. La búsqueda fue realizada considerando todas las imágenes del "Voyager 2" y usando cálculos computacionales para predecir si el satélite sería visible en condiciones favorables en cada una de ellas. Cada imagen cualificada del Voyager 2 con resolución mejor a ~50 km/Pixel muestra a Pan claramente. Entre todas, aparece en once imágenes del "Voyager 2".

La excentricidad orbital de Pan produce que la distancia entre él y Saturno varíe en cerca de 4 kilómetros. Su inclinación orbital, que debería causar que se mueva de arriba a abajo, no es distinguible del cero con los datos actuales. La división Encke, en la cual Pan orbita, es de cerca de 325 kilómetros de ancho.

Los científicos de "Cassini" han descrito a Pan como con forma de nuez debido a la cresta ecuatorial, similar a la del satélite Atlas, que es visible en las imágenes. La cresta se debe al material del anillo de Saturno que ha sido barrido desde la división Encke.

La división Encke contiene un anillo que es coincidente con la órbita de Pan, indicando que Pan mantiene las partículas en órbita de herradura.

El satélite fue nombrado el 16 de septiembre de 1991 basado en la figura mitológica Pan, quién fue (entre otras cosas) el dios de los pastores. Esta es una referencia al rol de Pan como el satélite pastor. También es designado como .

Fue descubierto por Mark R. Showalter en 1990 analizando las antiguas fotos de la sonda "Voyager 2" y recibió su designación provisional debido a que las imágenes del descubrimiento estaban fechadas en 1981.

También hay un asteroide llamado (4450) Pan.

Ha sido seleccionada como APOD ( Astronomy Picture of the Day ) el 13 de marzo de 2017



</doc>
<doc id="28145" url="https://es.wikipedia.org/wiki?curid=28145" title="Río Grande (película de 1950)">
Río Grande (película de 1950)

Río Grande ("Rio Grande") es una película estadounidense de 1950 dirigida por John Ford, que tiene como protagonistas a John Wayne y a Maureen O'Hara.

Junto con "Fort Apache" (1948) y "She Wore a Yellow Ribbon" ("La legión invencible", 1949), "Río Grande" integra la conocida como "trilogía de la caballería" de John Ford.

El coronel Kirby Yorke (John Wayne) combate a los apaches desde un fuerte cercano a la frontera con México. Su hijo, que ha fracasado en West Point, se alista, siendo enviado al regimiento del coronel Yorke, su padre. Dispuesta a sacarlo de allí, también llega al fuerte la esposa de Yorke (Maureen O'Hara), distanciada de él por el gran apego del coronel hacia el ejército y sus normas. Es el reencuentro del matrimonio tras muchos años de separación. En medio de un agrio conflicto familiar, la lucha con los indios se recrudece.



</doc>
<doc id="28146" url="https://es.wikipedia.org/wiki?curid=28146" title="Río Lobo">
Río Lobo

Río Lobo es un western dirigido y producido por Howard Hawks en (la última película dirigida por él), y con actuación John Wayne, Jorge Rivero y Jennifer O'Neill.

Esta película supuso la quinta colaboración a lo largo de veintidós años de John Wayne y del legendario director Howard Hawks, y cierra la trilogía de los ríos cinematográficos de la filmografía de Howard Hawks comenzada con "Río Bravo" (1959) y "El Dorado" (1966).

Este western clásico repleto de acción trata del espectacular robo de un tren de la Unión por las guerrillas confederadas. El coronel del tren (John Wayne) encarcela a los jefes enemigos Cordona (Jorge Rivero) y Tuscarora (Christopher Mitchum), pero los tres hombres acaban haciéndose amigos al terminar la guerra.

Tras esto, comienzan a buscar a los traidores de la Unión responsables de una serie de robos a trenes por parte de los confederados, y que los conducirá a la ciudad de Río Lobo, donde se les unirá la joven Shasta Delaney (Jennifer O'Neill), la cual destapa la trama de corrupción de la ciudad.


La película se estrenó en los Estados Unidos el 16 de diciembre de 1970 y en España el 11 de abril de 1971. Fue un éxito de taquilla. Según El País esta película, siguiendo los esquemas y la brillantez de los otros Ríos de Hawks, este western recrea con humor y sentido del espectáculo una trama de venganzas y ambiciones de oro, por lo que es un clásico. Fue, según "Alohacriticón", un buen western de Howard Hawks que supuso la despedida cinematográfica del estupendo director estadounidense.



</doc>
<doc id="28149" url="https://es.wikipedia.org/wiki?curid=28149" title="Sabrina (película de 1995)">
Sabrina (película de 1995)

Sabrina es una película estadounidense de 1995 dirigida por Sydney Pollack. Con guion de Barbara Benedek y David Rayfiel fue protagonizada por Julia Ormond y Harrison Ford. Sería nominada a dos Premios Óscar de la Academia en 1996.

Sabrina Fairchild (Julia Ormond) es la joven hija del chófer de la familia Larrabee, Thomas, y ha estado enamorada de David Larrabee (Greg Kinnear) toda su vida. Pero el nunca se ha fijado sinceramente en ella, Sabrina viaja a París para una pasantía de moda en Vogue y regresa como una mujer atractiva, sofisticada y hermosa. David, después de no haberla reconocido inicialmente, se siente rápidamente atraído por ella a pesar de estar recién comprometido con la doctora Elizabeth Tyson.

El hermano mayor de David, Linus (Harrison Ford) es un adicto al trabajo y busca sacar ventaja de la prometida de su hermano menor Elizabeth. Linus teme que la inminente boda de David con la muy adecuada Elizabeth pueda estar en peligro. Si la boda se cancelara, también podría afectarse una lucrativa fusión con la empresa familiar de la novia: Tyson Electronics, dirigida por su padre Patrick. Esto podría costarle a la Corporación Larrabee dirigida por Linus y su madre Maude muchos millones de dólares si la relación entre las dos familias se complica.

Linus intenta redirigir el afecto de Sabrina hacia sí mismo y funciona, se muestra como un hombre sentimental y que busca una compañera, mientras su hermano sufre un accidente que lo deja en la obligación de mantenerse aislado y en descanso, pero en el proceso, Linus también se enamora de Sabrina. Reacio a admitir sus sentimientos, Linus le confiesa su plan a Sabrina en el último momento y la envía triste de regreso a París. Antes de que ella tome el avión a París, su padre le informa que durante los años de trabajo como chófer del Sr. Larrabee, él escuchó cuando el Sr. Larrabee vendía acciones en la bolsa de valores, él también negociaba con sus ahorros, vendía y cuando el Sr. Larrabee compraba, él también compraba acciones. Sabrina dice en tono de broma "¿Papá me estás diciendo que tienes un millón de dólares?" Su padre dice que no, que tiene un poco más de dos millones ahorrados como resultado de las inversiones en la bolsa de valores y su madre querría que ella los tuviera.

Mientras tanto, Linus se da cuenta de sus verdaderos sentimientos por Sabrina, y es inducido por David y su madre a seguirla a París, ellos notaron el amor de Linus por ella y promueven ellos mismos la fusión con Tyson Electronics, con el fin de liberar a Linus de tal empresa. Linus viaja y le revela su amor a Sabrina, finalmente besándola.

Aunque con pequeños cambios, la película es una adaptación del filme también titulado Sabrina de 1954, dicho filme fue dirigido por Billy Wilder, con Humphrey Bogart, Audrey Hepburn y William Holden.




</doc>
<doc id="28151" url="https://es.wikipedia.org/wiki?curid=28151" title="Escila">
Escila

En la mitología griega, Escila (en griego Σκύλλα) fue una hermosa ninfa, que algunas fuentes la refieren como hija de Forbantes y Hécate o de Forcis y Hécate, y otras como hija de Forcis y Ceto. De su nombre proviene la isla epónima, Sicilia.

Escila posteriormente fue transformada en un monstruo marino, con torso de mujer y cola de pez, así como con seis perros partiendo de su cintura con dos patas cada uno, haciendo un total de doce; según otras versiones, sería un ser con seis largos y serpentinos cuellos con cabezas grotescas, mientras que sus doce patas serían de otra naturaleza; finalmente, según otras fuentes, compartiría algo de ambas descripciones. Sin embargo, se dice siempre que poseía en cada cabeza tres apretadas hileras de afilados dientes, así como que emitía un aullido estridente similar al de un perro.

Este ser habitaba en un estrecho paso marítimo, en el lado opuesto a su contraparte Caribdis que también era una monstruo. Los lados del canal estaban dentro del alcance de una flecha, de modo que los barcos que intentasen evitar a Caribdis deberían acercarse a Escila, y viceversa. Con el tiempo fue transformada por los dioses en una roca, aún existente, que suponía graves peligros para los navegantes.

Esta figura mitológica aparece en las aventuras de Odiseo.

En el canto XII de la "Odisea", Circe aconseja a Odiseo que navegue más cerca de Escila que de Caribdis, ya Escila devoraría a seis de sus hombres, pero su contrapartida succionaría el barco entero: 

Según la obra "Las metamorfosis", de Ovidio, Escila fue una vez una hermosa ninfa. El dios marino Glauco, anteriormente un pescador, se enamoró de ella, pero ella huyó de él hacia la tierra, donde no podía alcanzarla. Desesperado, Glauco fue a la isla de la diosa hechicera Circe, para que le preparase una poción de amor y así derretir el corazón de la joven. Circe, que estaba secretamente enamorada de Glauco, le recomendó dedicar su amor a alguien más digno de él, intentando cortejarlo con dulces palabras y miradas, pero el dios no quiso saber nada de ella. Circe se enfureció tanto, mas con Escila, no con Glauco, por ello, fingió ayudar al dios entregándole un frasco, recomendándole que lo vertiese en la charca donde Escila solía bañarse. Glauco siguió sus instrucciones y vertió la poción; en cambio, tan pronto como la ninfa entró en el agua se transformó en un horrible monstruo de seis cabezas perrunas. Glauco, que vigilaba esa triste escena desde la lejanía, perdió su interés por ella y se marchó llorando amargamente.

En mitos griegos posteriores, se dice que Heracles encontró a Escila durante un viaje a Sicilia y le dio muerte. Luego Forcis, el padre de Escila, le aplicó antorchas ardientes al cuerpo y le devolvió la vida.

Según el comentario de Servio sobre la "Eneida", Escila fue una hermosa náyade de la que se enamoró Poseidón, pero fue convertida en un monstruo por la celosa Anfitrite.

De la narración sobre Escila y Caribdis surge una expresión: «Estar entre Escila y Caribdis», vale decir, «estar entre la espada y la pared», o sea, en un problema de difícil (si no imposible) solución.











</doc>
<doc id="28153" url="https://es.wikipedia.org/wiki?curid=28153" title="Programador">
Programador

Un programador es aquella persona que elabora programas de computadora, es decir escribe, depura y mantiene el código fuente de un programa informático, que ejecuta el hardware de una computadora, para realizar una tarea determinada.

Los programadores también son denominados desarrolladores de software, aunque estrictamente forman parte de un equipo de personas de distintas especialidades (mayormente informáticas), y siendo que el equipo es propiamente el desarrollador.

La programación es una de las principales disciplinas dentro de la informática.

En muchos países, un programador es también una categoría profesional reconocida.

Ada Lovelace, hija del prestigioso poeta Lord Byron, es considerada la primera programadora de la historia. Su contribución más notable consistió en elaborar un método para calcular los números de Bernoulli en la máquina analítica de Charles Babbage. En homenaje a Ada Lovelace, fue puesto el nombre al lenguaje de programación Ada.

El programador se encarga de la implementación de prototipos mediante un lenguaje de programación, que compilados pueda entender la computadora.

Inicialmente, la profesión se formalizó desde el enfoque tayloriano de la especialización de funciones en la empresa. Así, el proceso de producción de software se concibe como un conjunto de tareas altamente especializadas donde está claramente definido el papel de cada categoría profesional:


Hoy día se reconoce que este enfoque no es válido para organizar tareas de tipo intelectual, como es el desarrollo de software. De manera que la profesión de programador ha ido evolucionando. Las dificultades de comunicación entre analistas y programadores (un mero documento no basta para describir lo que se quiere hacer) dio origen a una categoría de profesional intermedia, denominada analista-programador. La concepción original del programador ha desaparecido siendo sustituida por la de un profesional mucho más formado y con unas funciones menos «mecánicas».

La profesión de analista también ha evolucionado, surgiendo el concepto diseñador (de software). Esto se debe a los avances de la ingeniería del software donde se reconoce que el análisis es una actividad compleja y distinta del diseño. Escuetamente, el análisis describe el problema (es decir, «qué» hacer) mientras que el diseño describe la solución («cómo» hacerlo).

En la mayoría de países industrializados esto ha dado lugar a la categoría diseñador o arquitecto del software.

Estrictamente hablando, la profesión de programador si conoce especialidades. No obstante, existen diversas ramas por las que se decantan los propios profesionales y que se ven reflejadas en la oferta de empleo. Así, es posible mencionar algunas:



</doc>
<doc id="28154" url="https://es.wikipedia.org/wiki?curid=28154" title="¡Hatari!">
¡Hatari!

¡Hatari! es una película estadounidense de 1962, dirigida por Howard Hawks y protagonizada por John Wayne. El título significa "peligro" en swahili. La película presenta un grupo de cazadores que captura animales salvajes para posteriormente ser vendidos a zoológicos, mostrando un retrato interesante pero anticuado de África, dominado todavía por los no africanos.

"¡Hatari!" fue filmado en los que hoy es el norte de Tanzania. Muchas escenas fueron filmadas cerca de la ciudad de Arusha, en un rancho de caza de Ngorongoro, que en aquella época fue propiedad del actor Hardy Krüger. 

Un grupo de cazadores dirigido por Sean Mercer (John Wayne) está cumpliendo en Tanzania el encargo de capturar animales de muy variadas especies, cuando se incorpora al grupo Ana María D'Allesandro (Elsa Martinelli), que será llamada Dallas y que tiene la tarea de fotografiar su trabajo, y el tirador francés Charles Maurey (Gerard Blain) al que llamarán Chips. 

Todos ellos van a tener muchas diversiones y aventuras... y algunos de ellos también una historia de amor. 

La película reúne varios personajes de diferentes partes del mundo.
En 1963 fue nominada a los Oscar, y obtuvo el segundo lugar en los premios "Laurel de oro" en la categoría "Top action drama".




</doc>
<doc id="28155" url="https://es.wikipedia.org/wiki?curid=28155" title="Yakuza (película)">
Yakuza (película)

Yakuza es una coproducción estadounidense-japonesa de 1975, dirigida por Sydney Pollack, protagonizada por Robert Mitchum en el papel principal y basada en una historia de gánsteres escrita por Leonard Schrader.

Harry Kilmer ("Robert Mitchum") regresa al Japón después de una larga ausencia para ayudar a su amigo George Tanner ("Brian Keith") a rescatar a su hija que ha sido secuestrada. Allí se reencuentra con la que fue su mujer, Eiko ("Keiko Kishiuna"), una japonesa a la que tuvo que abandonar a petición de Ken ("Ken Takakura"), el hermano de ella. Ken odia a Kilmer por ser estadounidense y por haber convivido con su hermana, pero a la vez tiene una deuda con él por haberla salvado durante la posguerra. Kilmer le pedirá que salde dicha deuda ayudándole a rescatar a la hija de su amigo.


"Yakuza" retrata el choque de los valores tradicionales japoneses durante la transición entre la ocupación de los Estados Unidos y el éxito económico a principios de 1970. Los temas que trata la historia son los conceptos de endeudamiento y obligación moral, la lealtad a la familia y a los amigos, y el sacrificio; los valores culturales orientales y occidentales son contrastados, y la tradición clásica japonesa frente a la moderna y occidentalizada, tradición contemporánea de Japón.

Tras una decepcionante lanzamiento inicial, la película ganó seguidores de culto.


</doc>
<doc id="28158" url="https://es.wikipedia.org/wiki?curid=28158" title="Wyatt Earp (película)">
Wyatt Earp (película)

Wyatt Earp es una película estadounidense de wéstern de 1994 basada en la vida de Wyatt Earp y su trabajo como marshal en el pueblo de Tombstone, Arizona. La cinta, dirigida por Lawrence Kasdan y protagonizada por Kevin Costner, Dennis Quaid y Michael Madsen, entre otros, fue nominada al .

La película presenta una mirada más a la vida de Wyatt Earp, su labor para restablecer la ley en Tombstone, y el famoso tiroteo en el O.K. Corral,
entre la familia Earp y los Clanton.
La trama comienza con la juventud de Earp en California y sus vivencias en un mundo de brutalidad propia del Oeste.
Earp desarrolla la capacidad de reaccionar efectivamente ante agresiones de matones e ilegales y esto le vale ser nombrado alguacil en un pueblo donde impera sólo la ley del más fuerte.

Earp con su gestión gana fama de ser un sheriff duro, enérgico e intransigente con quienes no respetan la ley colocando el pueblo de Dodge City en orden, y su fama trasciende las fronteras estatales. Además, se gana muchos enemigos. Sólo tiene además de sus hermanos un solo amigo, Doc Holliday, un exmédico aquejado de una tuberculosis en progreso y quien lo secunda y apoya en sus acciones.

Earp además está casado con Urilla Sutherland, pero al fallecer ésta de fiebre tifoidea decide huir del dolor. Sus hermanos obtienen empleos de policía en el pequeño poblado de Tombstone, Arizona, donde el desorden, las bandas de desalmados como los Clanton y otras, provocan a gusto desórdenes callejeros.

Wyatt Earp es reclutado por sus hermanos como policía y pronto ocupa el oficio de marshal. En esto compite con el otro comisario deshonesto que apoya a estas bandas con tal de mantener su empleo, y además exhibe la foto de su novia desnuda como trofeo de guerra. Es entonces cuando Wyatt Earp conquista a la novia de este comisario.

Los Clanton desafían a los Earp en un corral y en el tiroteo fallece un asociado y los Clanton quedan heridos. Estos se vengan dejando casi lisiado al hermano mayor y matan al hermano menor de Wyatt Earp. Luego, Wyatt Earp los elimina en tiroteos en diferentes lugares desconocidos, sin piedad.

Una vez terminada su misión, lleva a Doc Holliday a un hospital, donde se queda hasta su inevitable muerte, y luego continúa con su vida, que se convierte gradualmente en leyenda.



</doc>
<doc id="28161" url="https://es.wikipedia.org/wiki?curid=28161" title="Mutiny on the Bounty (película de 1935)">
Mutiny on the Bounty (película de 1935)

Mutiny on the Bounty —título original en inglés traducible como «El motín de la Bounty»—, conocida en Hispanoamérica como Motín a bordo y en España como La tragedia de la Bounty y Rebelión a bordo, es una película estadounidense basada en la novela homónima de Charles Nordhoff y James Norman Hall. Fue dirigida por Frank Lloyd y contó con Clark Gable, Charles Laughton, Herbert Mundin, Franchot Tone, Donald Crisp y Dudley Digges en los papeles principales. 

"Mutiny on the Bounty" ganó el Oscar a la mejor película del año, y tuvo candidaturas a otros siete: las de Laughton, Gable y Tone al mejor actor, así como las de mejor director, mejor montaje, mejor banda sonora y mejor guion.

Basada en la trilogía de novelas por Charles Nordhoff y James Norman Hall sobre el motín a bordo de la ""Bounty"", la película relata el viaje del barco a Tahití para recoger retoños del árbol del pan con la finalidad de ser plantados en las colonias británicas de las Indias Occidentales y proveer de alimento barato a los esclavos. Pero durante el viaje la actitud tiránica del capitán Bligh (Charles Laughton) convierte el viaje en algo insoportable para la tripulación. El primer oficial Fletcher Christian (Clark Gable) no está de acuerdo con la estricta aplicación de la disciplina que hace el capitán, ya que considera que resulta nefasta para la moral de los marineros, cuya vida es de por sí bastante dura. El contraste entre la vida paradisíaca en Tahití y el regreso a la rutina de a bordo desemboca en un motín dirigido por Christian, que regresa a Tahití con la "Bounty" abandonando a Bligh y unos cuantos de sus fieles en una chalupa en alta mar. Bligh, al que hasta ahora conocíamos como pésimo gestor de recursos humanos, se revela como un magnífico navegante y un tipo corajudo capaz de llevar el pequeño bote hasta el lejano puerto de Timor. Bligh regresa a Tahití a bordo del "Pandora" para ajustar las cuentas con los amotinados, pero Christian avista el barco y prepara la "Bounty" para zarpar de Tahití... conseguirán escapar?

Este hecho resulta fílmicamente muy dramático pero es históricamente inexacto: en la realidad histórica, Bligh navegaba en esos momentos a bordo del "Providence" en una segunda misión -esta vez coronada por el éxito- en pos del árbol del pan, siendo el "Pandora" capitaneado por el capitán Edward Edwards.


Las críticas contemporáneas fueron entusiastas. Andre Sennwald, de The New York Times , escribió: "Siniestro, brutal, absolutamente romántico, hecho de horror y coraje desesperado, es una fotoplay tan salvajemente emocionante y tremendamente dramática como la que ha salido de Hollywood en los últimos años. La trilogía Nordhoff-Hall nació, por supuesto, para ser filmado, y Metro-Goldwyn-Mayer le ha dado el tipo de producción que merece una gran historia ". The Hollywood Reporter dijo que era "una de las mejores películas de todos los tiempos", con "el barrido épico del mar" . Variety lo llamó "Hollywood en su máxima expresión. La historia ciertamente no podría haber sido presentada tan poderosamente a través de ningún otro medio".

Según los registros de MGM, la película ganó $ 2,250,000 en los Estados Unidos y Canadá y $ 2,210,000 en otros lugares, lo que resultó en una ganancia de $ 909,000. 

Fue la tercera película más popular en la taquilla británica en 1935–36.

En su reposición en las pantallas españolas tras la guerra civil, "Mutiny on the Bounty" se tituló "La tragedia de la Bounty", por considerar las autoridades de la dictadura franquista que la palabra «rebelión» no era aceptable. El título se ha mantenido tras el estreno de la versión de 1962, que en subsiguientes reposiciones, pases televisivos y ediciones en vídeo usurparía el título original en castellano con el que se estrenó la de 1935.



</doc>
<doc id="28162" url="https://es.wikipedia.org/wiki?curid=28162" title="Mutiny on the Bounty (película de 1962)">
Mutiny on the Bounty (película de 1962)

Mutiny on the Bounty (Motín a bordo o Rebelión a bordo) es una película estadounidense de 1962 dirigida por Lewis Milestone, con Marlon Brando y Trevor Howard como actores principales. Está basada en la novela homónima de Charles Nordhoff (1887 - 1947) y James Norman Hall (1887 - 1951).

En la película, el narrador es el horticultor de la expedición, interpretado por Richard Haydn.

"Mutiny on the Bounty" tuvo siete candidaturas a los Oscar, aunque no ganó ninguno, pues ese año la gran triunfadora resultó ser " Lawrence de Arabia". Con ligeros cambios y omisiones respecto a la novela (como el desembarco en Tenerife), la película logra relatar cómo era la vida en el mar y las normas que regían el destino de la tripulación, además de mostrar el estilo de vida isleño en el sur del Pacífico.

Durante el rodaje, Marlon Brando conoció a Tarita, que sería su tercera esposa y con la que tendría dos hijos. Brando sostuvo una agria competencia con Trevor Howard, quien lo consideraba irreverente, durante todo el rodaje de la película.

En 1787, la fragata británica "Bounty" comienza un viaje a Tahití para trasladar un cargamento de árbol del pan a Jamaica. El orgullo y la ambición del capitán Bligh (Trevor Howard) llevan a la tripulación a luchar contra su trato despótico, al tiempo que lo hace también contra el hambre y contra las inclemencias del mar. 

Los marinos llegan a la paradisíaca isla, donde son recibidos por los isleños. El carácter libre y desinhibido de las mujeres subyuga a la tripulación, y se inician muchos romances, como el del segundo oficial Fletcher Christian (Marlon Brando) con Maimiti (Tarita), hija del jefe de la isla.

Pero los marinos han de abandonar Tahití para cumplir con su misión. En el viaje de vuelta, un enfrentamiento con el segundo oficial por el racionamiento exagerado del agua en beneficio del cargamento desencadena un motín encabezado por el tripulante John Mills (Richard Harris). Los amotinados logran hacerse con el barco y eligen a Fletcher Christian como nuevo capitán. El capitán Bligh y los tripulantes que lo apoyan - entre ellos, Fryer, el contramaestre (Eddie Byrne) - son desalojados del barco y puestos a bordo de un bote en las cercanías de Tofoa, una de las Islas Tonga. 

En lugar de dirigirse a Tofoa, el capitán Bligh se embarca en una peligrosa aventura de 4.000 millas hasta Timor, para regresar cuanto antes al Reino Unido y dar a conocer los hechos al almirantazgo británico, el cual lanza una expedición para encontrar y enjuiciar a los amotinadores. Aun así inculpan a Bligh por lo ocurrido, aunque el no haya infringido la ley. 

Por su parte, los amotinados regresan a Tahití, y, después de aprovisionarse y embarcar a algunas isleños con ellos (mujeres incluidas), buscan un lugar donde vivir escondidos. Encuentran la isla de Pitcairn, que, por estar apartada de las rutas marítimas y por venir mal señalada en los mapas del almirantazgo británico, tras quemar la nave, se convierte en su nuevo hogar.




</doc>
<doc id="28164" url="https://es.wikipedia.org/wiki?curid=28164" title="Still of the Night (película)">
Still of the Night (película)

Still of the Night (Bajo sospecha en España y En la quietud de la noche en Hispanoamérica) es una película estadounidense de de Robert Benton con Roy Scheider y Meryl Streep como protagonistas.

George Bynum, un paciente del psiquiatra de Manhattan Dr. Sam Rice (Roy Scheider), es brutalmente asesinado. Poco después, el doctor Rice recibe la visita de un compañero de trabajo de Bynum y su amante Brooke Reynolds (Meryl Streep), además del detective Vitucci, a cargo de la investigación. Rice revisa las notas de sus sesiones con Bynum y comienza su propia investigación. Al mismo tiempo, se enamora de la enigmática Brooke, a pesar de que su comportamiento es cada vez más sospechoso. Cuanto más se acerca Rice a la verdad, más pone su vida en peligro.


</doc>
<doc id="28169" url="https://es.wikipedia.org/wiki?curid=28169" title="Bajo sospecha (película de 1943)">
Bajo sospecha (película de 1943)

Bajo sospecha (en inglés "Above Suspicion") es una película estadounidense basada en la novela "Above Suspicion" de Helen MacInnes.

En 1939 Richard Myles (Fred MacMurray), un profesor estadounidense que enseña en la Universidad de Oxford, y su nueva esposa Frances (Joan Crawford) se encuentran en viaje de novios por Europa. Antes de salir Myles fue contactado por el servicio secreto británico, que le solicitó su colaboración mientras se encontrase en Alemania, ya que el comienzo de la guerra es inminente. Myles accedió porque lo consideró interesante. Cuando inician sus gestiones en Alemania, Myles y su esposa incluso se divierten, pero pronto cambia su opinión sobre este asunto.


</doc>
<doc id="28174" url="https://es.wikipedia.org/wiki?curid=28174" title="Tuvalu">
Tuvalu

Tuvalu (en tuvaluano: "Tuvalu", en inglés: "Tuvalu" y hasta 1974 llamadas Islas Ellice) es uno de los cuatro países que forman la Polinesia, o uno de los catorce que conforman Oceanía. Su capital es Funafuti.

Es un país insular localizado en el océano Pacífico, aproximadamente a mitad de camino entre Hawái y Australia. Los países más cercanos a Tuvalu son Kiribati, Samoa y Fiyi. Consta de 4 arrecifes de coral y 5 atolones, con un área total de 26 km². Después de la Ciudad del Vaticano (932 hab.) y antes de la República de Nauru (13 048 hab.) es la nación independiente con menor número de habitantes. También es el miembro de las Naciones Unidas con menor número de habitantes, ya que dispone solamente de 11 810.

Tiene una altitud máxima de 5 metros sobre el nivel del mar, siendo, después de Maldivas (2 metros sobre el nivel del mar), el país con la menor altitud máxima. Tiene clima tropical marítimo, moderado por los vientos alisios del este de marzo a noviembre, los meses restantes con abundantes lluvias y la vegetación típica está compuesta de palmeras (cocoteros).

Debido al cambio climático y a la progresiva subida del nivel del mar, su terreno va decreciendo, las playas de estas islas tienden a su desaparición y debido a los continuos tifones, las aguas marinas salinizan progresivamente los cultivos y parece irremediable que el aumento del nivel del mar anegue el archipiélago.
Todos estos cambios climáticos han sido confirmados por el Grupo Intergubernamental de Expertos sobre el Cambio Climático (IPCC), quienes asumen que lo peor todavía no ha llegado.
Tuvalu como miembro de las Naciones Unidas solicita ayuda para que el país pueda sobrevivir a la catástrofe que parece irreparable. Se esta intentando reubicar su población, aunque trasladar a todos sus habitantes es realmente complicado.

El término Tuvalu proviene del idioma indígena local en el que significa "ocho islas", y hasta 1949 en el que los indígenas poblaron la isla de Niulakita eran las islas que disponían de población permanente y estable.

Tuvalu está habitado desde comienzos del primer milenio a.C., cuando se trasladaron habitantes desde los países de Tonga y Samoa. Los primeros europeos en llegar fueron españoles en 1568, dirigidos por Álvaro de Mendaña y Neyra, que nombraron al archipiélago como Islas Nombre de Jesús. Algunos comerciantes de esclavos y balleneros procedentes de Perú visitaron frecuentemente las islas. En 1865 la Sociedad Misionera de Londres, de religión protestante, comenzó su proceso de evangelización de Tuvalu mediante la cual convirtió a la población al anglicanismo por completo en la década de 1920. También a finales del siglo XIX, los comerciantes europeos comenzaron a asentarse en las islas con la esperanza de beneficiarse de los recursos locales.
En 1892, las islas pasaron a formar parte del protectorado británico de las Gilbert y Ellice (Micro-Polinesia británica), este protectorado se convirtió en colonia en 1915.

Durante la Segunda Guerra Mundial, Marines de los Estados Unidos desembarcaron en Funafuti (Villaolivos) el 2 de octubre de 1942. Por esas fechas los japoneses ya habían ocupado Tarawa y otras islas de lo que hoy en día es Kiribati. Un batallón de construcción naval ("abejas del mar" o "Seabees" en inglés) construyeron una pista de aterrizaje principal en Funafuti y aeródromos satélites en Nanumea y Nukufetau. La pista construida en Funafuti continúa siendo utilizada hoy día en el Aeropuerto Internacional de Funafuti. Las bajas civiles durante la Segunda Guerra Mundial fueron escasas. En una ocasión en abril de 1943, durante un bombardeo japonés, 680 personas se refugiaron en una iglesia. Afortunadamente para ellos, un soldado norteamericano (el cabo Ladd) les convenció de salir y refugiarse en trincheras. Poco después una bomba destruyó la iglesia. Tuvalu sirvió como base de apoyo para las ofensivas contra los atolones de Makin y Tarawa.

En 1974, diferencias étnicas dentro de la colonia provocaron que los polinesios de las Islas Ellice decidieran separarse de los micronesios de las Islas Gilbert (después Kiribati). Al año siguiente, las Islas Ellice se convirtieron en la colonia británica de Tuvalu. La independencia se concedió en 1978.

Tuvalu firmó en 1979 un tratado de amistad con los Estados Unidos que reconoce la legítima posesión tuvaluana de cuatro pequeñas islas reclamadas anteriormente por los Estados Unidos.

Entre 1995 y 1997, Tuvalu adoptó una nueva bandera pero, finalmente, se restituyó la antigua Bandera de Tuvalu, que es la que posee en la actualidad.

Según el primer ministro de Tuvalu, su país se encuentra amenazado por el cambio climático y piden responsabilidad a los países contaminantes y a la ONU por lo cual sus habitantes tendrán que decidir urgentemente sobre dos cuestiones: acerca de mantener la monarquía constitucional o convertir Tuvalu en una república, y sobre la conveniencia de trasladar a Nueva Zelanda a sus 11 810 habitantes, ya que las islas viven en continua alerta debido a los ciclones y otros fenómenos meteorológicos y corren el riesgo de inundarse debido al aumento del nivel del mar. Mientras que algunas personas han sugerido para la reubicación de la población de Tuvalu a Australia, Nueva Zelanda, o Kioa (Fiyi), el ex primer ministro Maatia Toafa dijo que su gobierno no considera el aumento del nivel del mar como una amenaza por la que toda la población tendría que ser evacuada.

Tuvalu es el país propietario del famoso dominio de internet .tv. La ICANN ya se ha enfrentado a la desaparición de países por causas políticas, aunque esta vez podría ser por causas geográficas.

Tuvalu es una monarquía constitucional perteneciente a la Commonwealth, en la que la reina Isabel II es reconocida oficialmente como reina de Tuvalu. Está representada en Tuvalu por un Gobernador General, nombrado a propuesta del primer ministro. El parlamento local, o Fale I Fono tiene 15 miembros y es elegido cada cuatro años. Sus miembros eligen a un primer ministro que es el jefe de gobierno. El Gabinete es nombrado por el gobernador general, con el asesoramiento del primer ministro. Cada isla tiene su propio jefe o "Ulu-Aliki", y varios sub-jefes ("Alikis") además de los ancianos. Los ancianos forman juntos un consejo de ancianos o "fenua te sina" (literalmente: 'gris-pelos'). En el pasado, otra casta, a saber, la de los sacerdotes ("tofuga") también fue una de las encargadas de tomar decisiones. Los "sinas" o "fenuas", "Aliki" y "Ulu-Aliki" forman la autoridad a nivel local. El Ulu-Aliki es seleccionado sobre la base de su ascendencia familiar, y sus competencias están compartidas con la "pule" o "kaupule" que es un grupo formado por los elegidos presidentes, uno en cada atolón. No hay partidos políticos oficiales y las campañas electorales son en gran medida sobre la base personal y los lazos familiares además de la reputación.

El Gobierno de Tuvalu está representado en el Reino Unido por un cónsul honorario, con sede en la Casa de Tuvalu, en Londres.

Hay ocho tribunales (uno en cada isla), con jurisdicción limitada. El más alto tribunal de Tuvalu es el Tribunal Superior. Las sentencias del Tribunal Superior pueden ser recurridas ante el Tribunal de Apelación de Tuvalu. Solo se puede recurrir una sentencia del Tribunal de Apelación ante "la Reina (o el Rey) en Consejo", es decir, en el Consejo Privado en Londres.

Tuvalu no tiene fuerzas militares regulares, y no gasta dinero en tenerlas. Su fuerza de policía incluye una Unidad de Vigilancia Marítima para misiones de búsqueda y salvamento y para realizar las operaciones de vigilancia. La policía tiene una sola patrullera, de la clase "Pacific" (HMTSS "Te Mataili"), suministrada por Australia en virtud del programa para la vigilancia marítima y la pesca en el océano Pacífico.

Tuvalu mantiene estrechas relaciones con Fiyi, Nueva Zelanda, Australia y el Reino Unido. Tiene relaciones diplomáticas con la República de China (Taiwán), Taiwán mantiene la única embajada residente en Tuvalu y tiene un gran programa de asistencia en las islas. También posee buenas relaciones con los Estados Unidos tras la firma de un contrato con ellos en el que Estados Unidos reconoce como de Tuvalu un grupo de islas que se disputaban los dos países.

Tuvalu se convirtió en miembro de la ONU en el año 2000 y mantiene una misión de la ONU en Nueva York. Una importante prioridad internacional para Tuvalu en las Naciones Unidas, en la Cumbre Mundial sobre el Desarrollo Sostenible en Johannesburgo y en otros foros internacionales es la promoción de preocupación sobre el calentamiento global y la posible elevación del nivel del mar. En Tuvalu son defensores de la ratificación y aplicación del Protocolo de Kyoto. Tuvalu también es miembro del Banco Asiático para el Desarrollo.

Tuvalu es un miembro pleno del Foro de las Islas del Pacífico y la Comisión del Pacífico Sur. Tuvalu tiene una casa en Londres, Inglaterra que cumple una función principalmente de consulado. Tuvalu declaró su zona sur una zona libre de armas nucleares en el Tratado del Pacífico Sur en el año 1985.

La poca población de Tuvalu está distribuida en 9 islas, 6 de las cuales son atolones. La isla más pequeña, Niulakita, estaba deshabitada hasta 1949, cuando se desplazó gente desde Niutao.

Es uno de los países más pequeños en el mundo, de hecho, el cuarto más pequeño, solo le superan la Ciudad del Vaticano (0.44 km²); Mónaco (1.95 km²) y Nauru (21 km²). Tuvalu también tiene tierras muy pobres. No hay agua potable, y la tierra es escasamente utilizable para la agricultura.

Aunque Tuvalu técnicamente no tiene ninguna subdivisión administrativa —su población es demasiado pequeña (estimada en 11 000 en 2004)— el país puede ser dividido en 9 islas, o más bien atolones, a mitad del camino entre Hawái y Australia. Originalmente, sólo ocho de estas islas estaban habitadas, de ahí el nombre Tuvalu que quiere decir "ocho islas" en idioma tuvaluano. Las nueve islas son: Fongafale, Nanumea, Nanumanga, Niutao, Nui, Niulakita, Nukufetau, Nukulaelae y Vaitupu.

En el 2001 el gobierno de Tuvalu anunció que las islas, de las cuales el punto más elevado es de 5 msnm, tendrían que ser evacuadas en caso de aumento del nivel del océano. En efecto, la elevación que se viene produciendo del nivel del océano a causa del calentamiento global, aunque aún es poco perceptible en otros países, resulta evidente en Tuvalu debido a su escasísima altitud y a lo exiguo del territorio, de modo que durante las mareas altas acompañadas de tormentas gran parte del país queda sumergido.

Nueva Zelanda ha aceptado recibir un contingente anual de 75 evacuados, mientras que Australia rechazó las peticiones.

El producto interno bruto de Tuvalu es de 36 millones de USD (según estimaciones de 2012), lo cual lo coloca como el segundo país más pobre del mundo (únicamente superando a Somalia). Suponía unos ingresos medios de 3048 dólares per cápita.

El dólar de Tuvalu tiene el mismo valor que el dólar australiano, que también circula en las islas (en 2010, 1,1208 dólares australianos equivalían a un dólar estadounidense). La economía de Tuvalu es la menos dinámica de cualquier Estado independiente del mundo, está basada en una agricultura de subsistencia; la ganadería de cerdos y aves de corral; la pesca tiene una importancia creciente, aunque la única exportación es la copra (médula de coco utilizada para la extracción de aceite). Gran parte de los ingresos estatales se obtiene de la venta de sellos y monedas; la inversión exterior y los ingresos que remiten los emigrantes que trabajan en el extranjero apuntalan la economía del país.

Ésta recibió una inyección muy importante en 2000, tras la cesión de su dominio (.tv, que le había sido concedida un año antes por la Unión Internacional de Telecomunicaciones), a una empresa estadounidense a cambio de 50 millones de dólares en 12 años. El Gobierno de Tuvalu recibe un millón de dólares cada 3 meses y posee el 20 % de la empresa que gestiona el dominio .tv.

La emisión de sellos postales, principalmente destinado al coleccionismo filatélico, es también una importante fuente de ingreso para su economía.

Debido a la lejanía del país con respecto a otros países, el turismo no aporta mucho los ingresos, se estima que un centenar de turistas visita anualmente Tuvalu. Casi todos los visitantes son los funcionarios de gobierno, los trabajadores, las organizaciones no gubernamentales o consultores.

Tuvalu presuntamente participó en Japón en la compra de votos en el régimen de Comisión Ballenera Internacional en 2006. Greenpeace sostiene que la compra de votos se llevó a cabo y Tuvalu es uno de los países que para recibir asistencia económica de Japón en 2006 sostiene que no.

La moneda de Tuvalu es el dólar tuvaluano, actualmente 1 dólar de Tuvalu equivale a 1,07 dólares de Nueva Zelanda (2020). Solo hay un banco en Tuvalu, que se encuentra en la capital del país Funafuti. En Tuvalu solo se puede pagar en efectivo, no aceptan tarjetas de crédito y las divisas se deben cambiar en el Banco de Tuvalu.

El 1 de enero de 1976 Tuvalu inició la impresión de sus propios sellos. En Funafuti existe una Oficina de Correos para que apoye sus propios sellos, que representa a la isla o momentos importantes en la historia nacional, bailes o trajes tradicionales. Existe una Sociedad Filatélica conjunta con Kiribati (anteriormente formaban las Islas Ellice).

La denominación .tv es la utilizada como propia por Tuvalu después de haber comprado los derechos. Antes estaba permitido que lo utilizasen todas las empresas de cualquier país siempre y cuando le entregasen un aporte al gobierno de Tuvalu.

El problema es que esta denominación es muy popular puesto que en muchos idiomas "tv" es la abreviatura de la televisión, el tener esta denominación no solo es interesante para las televisiones, sino también para sitios pornográficos.

En el año 2000 la gestión de esta denominación ha sido vendida por el gobierno de Tuvalu a la empresa dotTV, una filial de VeriSign, durante 12 años a cambio de 50 millones de dólares estadounidenses. Esta venta ha aportado grandes ingresos al micro-estado, que era, antes de la venta de la propiedad, uno de los países más pobres del mundo. Actualmente el Gobierno de Tuvalu posee una participación del 20 % en la empresa DotTv.

Los inesperados ingresos generados por la venta es un tema de controversia en el país. Parte de la población local protestó contra esta práctica, debido a que muchos sitios con esa denominación son sitios de pornografía. Para la mayoría de la población cristiana, este dinero se considera impuro.

A pesar de la controversia, el dinero ha ayudado a mejorar la infraestructura vial y dotar así al país de carreteras.

Los servicios de transporte en Tuvalu son limitados. Un ferry comunica los principales atolones. Además hay unos 8 kilómetros de carreteras, pero no dispone de ferrocarriles.

Funafuti es el puerto de mayor importancia aunque también hay un puesto de atraque de aguas profundas en el puerto en Nukufetau. Desde el año 1999, la flota de la marina mercante se compone de cuatro buques de 1.000 toneladas de registro bruto o más, que pueden transportar un total de 33.199 toneladas métricas de peso entre todos. Esto incluye dos buques de carga y un buque de transporte de pasajeros. El único aeropuerto del país es el Aeropuerto Internacional de Funafuti. El código IATA de este aeropuerto es FUN. Las calles de Funafuti se encuentran pavimentadas desde el 2002. Otras calles menos importantes están sin pavimentar. Tuvalu es uno de los pocos países del mundo que no cuentan con vías férreas.

La principal emisora de radio en el país es Radio Tuvalu, operada por Tuvalu Media Corporation, la empresa estatal de comunicaciones, y que posee una estación en AM y otra en FM.

"Tuvalu Echoes" es el único periódico editado en el país. Publica dos ediciones quincenales, una en inglés y la otra en tuvaluano (denominada "Sikuleo o Tuvalu"), y pertenece al Estado.

La población de la isla se ha más que duplicado desde 1980 y se estima que llegaba a 11.810 en julio de 2006. La población de Tuvalu es sobre todo de la etnia polinesia; aproximadamente el 4 % de la población es de Micronesia. Cerca del 97 % de la población de Tuvalu son miembros de la Iglesia de Tuvalu, una iglesia protestante. La religión se ha mezclado con algunos elementos de las religiones indígenas. Otras religiones que se practican en la isla son los Adventistas del Séptimo Día (1.4 %) y Bahaí (1 %) ambas relacionadas con culturas indígenas.

El tuvaluano es el idioma hablado por casi todo el país, mientras que un dialecto del idioma gilbertés se habla en Nui. El inglés es también un idioma oficial, pero no se habla por la gente en la calle sino que es hablado en el parlamento y en las funciones oficiales que se llevan a cabo en Tuvalu.

La educación en Tuvalu es gratuita y obligatoria entre las edades de 6 y 15 años. Cada isla tiene una escuela primaria. Para la educación secundaria existe la Motufoua Secondary School que se encuentra localizada en Vaitupu. Los estudiantes viajan a la escuela durante el curso escolar y regresan a sus islas de origen en sus vacaciones escolares. Fetuvalu High School, una escuela operada por la Iglesia de Tuvalu, está ubicada en Funafuti.

La tasa de alfabetización de adultos es del 99,0 % (2002). En 2010, había 1.918 alumnos que pasaron por 109 profesores (98 certificados y 11 no certificados). La relación maestro-estudiante en las escuelas primarias en Tuvalu es de alrededor de 1:18 para todas las escuelas, con la excepción de "Nauti School", que tiene una relación maestro-alumno de 1:27. "Nauti School" en Funafuti es la escuela primaria más grande de Tuvalu, con más de 900 estudiantes (45 % del total de matriculaciones en educación primaria). La relación alumno-maestro en Tuvalu es baja en comparación con la región del Pacífico (donde es de 1:29).

Se han establecido centros de formación comunitarios (CTC, por sus siglas en inglés) en las escuelas primarias de cada atolón. Los CTC proporcionan formación profesional a los estudiantes que no superan el octavo grado por no haber cumplido con los requisitos de acceso a la educación secundaria. Los CTC ofrecen formación en carpintería básica, jardinería y agricultura, costura, y cocina. Al finalizar su formación, los graduados pueden continuar sus estudios en la escuela secundaria Motufoua o en el Instituto de Formación Marítima de Tuvalu (TMTI). Los adultos también pueden asistir a cursos en los CTC.

La Ordenanza sobre el empleo tuvaluano de 1966 establece la edad mínima para el empleo remunerado a los 14 años y prohíbe que los niños menores de 15 realicen trabajos peligrosos.

El sistema tradicional de la comunidad todavía sobrevive en gran medida en Tuvalu. Cada familia tiene su propia tarea, o salanga que llevar a cabo para la comunidad, como la pesca, la construcción de viviendas o de la defensa. Las habilidades de una familia se transmiten de padre a hijo.

La mayoría de las islas tienen su propia Futi, o tiendas de propiedad del gobierno. Estas tiendas son similares a una tienda de conveniencia en las que se puede comprar alimentos enlatados o empaquetados y en los que las mercancías son más asequibles debido a las subvenciones gubernamentales.

Otro componente importante es el falekaupule o ayuntamiento, donde se debaten los temas importantes y que se utiliza para ciertos eventos.

Las comidas tradicionales que son consumidos en Tuvalu son: pulaka, mariscos entre los que se incluyen normalmente cangrejos, tortugas, y algunos peces, los plátanos con pan, coco, y la carne de cerdo. El "Pulaka" (una raíz que también recibe a veces el nombre de taro) es la principal fuente de hidratos de carbono, se cultiva en grandes fosas por debajo de la capa freática en compost natural del suelo. El pescado es la principal fuente de proteínas. El pan y los plátanos son platos suplementarios. Por último, el coco es utilizado por sus jugos en bebidas y alimentos para hacerlas más sabrosas. Se suele comer carne de cerdo con fateles (o partes de la danza para celebrar ciertos acontecimientos).

La música tradicional antes del contacto europeo incluye poemas realizados en una especie de recitación monotonal, aunque esta tradición se ha extinguido, así como canciones de trabajo que realizan las mujeres para alentar a los hombres mientras trabajaban.

El más famoso estilo de música de baile de Tuvalu, fatele, está influenciado por las melodías y la armonía. Se celebra una competición dividiendo a cada isla en dos partes o equipos (llamados "feitu's"). Los "Feitus" existen sólo al bailar la fatele (que se lleva a cabo como una competición), pero no para otras actividades.

Los dos principales bailes tradicionales de Tuvalu son los fakanu y fakaseasea. De éstas, la fakanu ha desaparecido, aunque sobrevive la fakaseasea, realizada únicamente por personas mayores.

La actual bandera de Tuvalu se creó cuando la nación se separó de Kiribati en 1978. Al igual que muchas antiguas y actuales dependencias británicas, la bandera de Tuvalu se basa en el "Union Jack" que aparece en la parte superior izquierda del cantón. Cuando se unió con las Islas Gilbert en una sola colonia, la bandera fue la "Union Jack" con las armas, ahora adoptada por Kiribati.

Las estrellas representan las 9 islas que forman Tuvalu incluidas aquellas en las que no hay vida humana ni animal. En 1995 la bandera fue sustituida después de un cambio de gobierno, esta bandera no se basó en la bandera británica, y también mostró las islas como estrellas. Este pabellón, sin embargo, no fue muy apreciado por los habitantes, y el antiguo pabellón fue restaurado en 1997, con algunas modificaciones menores.

Un deporte tradicional que se desempeña en Tuvalu es "kilikiti", que es similar al cricket. Otro deporte popular y específico de Tuvalu es el "ano", que se juega con 2 bolas redondas de 12 cm de diámetro.

Es más común la práctica de deportes como el fútbol y el ciclismo. Tuvalu tiene una selección nacional de fútbol, organizada por la Asociación Nacional de Fútbol de Tuvalu, miembro de la OFC pero no de la FIFA. Existen tres divisiones futbolísticas, la División-A, B y C, mientras que se organiza la Copa Navidad, la NBT, la Independencia y los Juegos de Tuvalu durante el receso de las ligas. El club más ganador es el Nauti FC que posee 7 títulos en la División-A, 2 en Copa NBT y 4 en la Independencia.

Tuvalu participó por primera vez en los Juegos Olímpicos en 2008, en Pekín, China, con el envío de tres competidores en dos deportes.




</doc>
<doc id="28175" url="https://es.wikipedia.org/wiki?curid=28175" title="Primera Edad del Sol">
Primera Edad del Sol

La Primera Edad del Sol, también conocida como los Días Antiguos, es una etapa de la cronología de la historia de la Tierra Media, el mundo ficticio en que transcurre la mayor parte de las obras del escritor británico J. R. R. Tolkien. Las historias que tratan los sucesos de esta época son las primeras que Tolkien empezó a escribir en su juventud, y a las que aún seguía dando forma, retocando detalles aquí y allá, cuando le alcanzó la muerte. Abarca un período de aproximadamente 590 años solares.

La parte más importante (en extensión) del Silmarillion, y que le da el nombre, es el "Quenta Silmarillion", que en Quenya, la lengua de los elfos Noldor, significa ""La historia de los Silmarils""; y las narraciones a ella pertenecientes se inscriben casi en su totalidad en la Primera Edad.

Las Edades de los Árboles tocan a su fin con la destrucción de los Dos Árboles de Valinor (Telperion y Laurelin) a manos de Melkor y Ungoliant. Transcurriría todavía un lapso de tiempo antes de que se alzasen en los cielos la Luna (Isil) y el Sol (Anar), creados gracias a las artes de Yavanna "Kementári" a partir de la última hoja de Telperion (para hacer de ella la Luna) y el último fruto de Laurelin (para hacer de él el Sol), cuando los dos árboles estaban agonizantes pero todavía no del todo muertos.

La frontera entre las Edades de los Árboles y la Primera Edad es difusa, puesto que se puede interpretar que se sitúa en cualquier instante entre estos dos acontecimientos, aunque es de común acuerdo que comienza con la primera salida, ya sea de la Luna, que salió primero, o del Sol, que salió cuando ya la Luna había descrito siete viajes a través del cielo.

La Primera Edad comienza con el levantamiento de la Luna y del Sol. En ese momento los hombres despiertan en el Este y algunos, luego de sucesos que se pierden en el misterio, emprenden el viaje hacia el Oeste. Los Noldor llegan a la Tierra Media y los Sindar los reciben gustosos. Al inicio los Noldor salen victoriosos y organizan el largo asedio de casi 400 años contra la fortaleza de Melkor, Angband. En este período los hombres llegan a Beleriand y se convierten en aliados de los Elfos contra Melkor y de hecho entre estos hombres (conocidos como los Edain) y los Elfos se lleva a cabo una unión tan especial de la que son producto algunos hijos llamados los Peredhil o medio elfos. Sin embargo los eventos comienzan a ser desafortunados para ellos y batalla tras batalla, Beleriand se ve perdida en manos de Melkor. El hado de los Noldor muestra sus efectos en cada rincón de sus reinos, y los desastres ocurren siempre. Al final solo un reducido número de Noldor, Sindar y Hombres resisten, y los Peredhil toman el protagonismo, intercediendo por los elfos y los hombres, con lo que los Valar deciden ayudar y Melkor es vencido finalmente.

Mientras los Noldor caminan por el Helcaraxë guiados por Fingolfin, y mientras Fëanor organiza a los que le siguen para comenzar a batallar contra Morgoth, los Valar debaten sobre lo que debe hacerse a continuación. Es entonces cuando se decide rescatar lo poco que queda de los árboles y alumbrar con ellos a toda la Tierra Media, un poco por compasión a los Noldor, pero sobre todo en consideración a los elfos que ya vivían antes en la Tierra Media y que ahora recibirían la furia de Morgoth, y sobre todo pensando en los segundos hijos de Eru, los Hombres, que aún estaban por llegar.

Así, Yavanna levanta con el poder de Varda la última hoja de Telperion, formando así la Luna, que guiaría Tilion, un maia de Oromë. Cuando la Luna se levantó por primera vez, los Noldor de Fingolfin terminaron su travesía por el Helcaraxë y llegaron a las puertas de Angband donde se refugiaba Morgoth, y lo desafiaron, aunque por precaución después se retiraron, llegando a las orillas del lago Mithrim, donde los Noldor de Fëanor estaban acampados.

A las siete ocasiones en que la Luna viajó por el cielo, Yavanna tomo el último fruto de Laurelin, formando así el Sol, que sería guiado por Arien, una maia de fuego al servicio de Aulë. Cuando el Sol se levantó por primera vez lo hizo en el Oeste, y en ese instante se dice que sucedió el despertar de los Hombres en un lugar desconocido en el oriente de la Tierra Media. El Sol hizo su primera travesía pero fue capturado por las criaturas marinas de Ulmo, a las que les gustó su luz, y por eso desde entonces el Sol sale en el Este.

Puesto que los Noldor están exiliados, los Valar levantan numerosas islas encantadas en el mar, de forma tal que ningún marinero por hábil que sea pueda encontrar el camino de regreso a Aman a través del mar.

Morgoth guerrea con los elfos, en numerosas batallas. En la primera de ellas, casi vence a los sindar que aún no conocían del regreso de los noldor. En la segunda de ellas (Dagor-nuin-Giliath, la Batalla bajo las Estrellas), los noldor de Fëanor atacan pero Fëanor muere en manos de los Balrogs, con lo que su primogénito Maedhros debería convertirse en el Rey Supremo de los Noldor en el exilio, pero este cede el trono a su tío Fingolfin, gracias a la amistad que lo une con su primo, el primogénito de Fingolfin, Fingon el Valiente y a su deseo de restaurar a los noldor como pueblo unido.

Elwë, que para entonces ya es conocido como Thingol, recibe a los noldor en sus tierras y les concede establecer reinos al norte, de forma tal que protegieran Beleriand de Morgoth, pues su regreso resultó muy oportuno para los sindar. Sin embargo siempre hubo recelo entre Thingol y los noldor, excepto con los hijos de Finarfin, que eran sus parientes cercanos. La tercera batalla (Dagor Aglareb, la Batalla Gloriosa) supuso un fracaso total para Morgoth, que no esperaba que los noldor estuvieran tan unidos desde que los dejó en Aman con sus peleas internas.

Comienza entonces el largo asedio de Angband, de casi 400 años del Sol. Durante esta época, los sindar se separan de los noldor, al descubrir por los hijos de Finarfin de la matanza de Alqualondë, y el Quenya (idioma oficial de los noldor, que aprendieron en Aman) queda prohibido en Beleriand, quedando el sindarin como idioma oficial. Igualmente en esta época, Turgon hijo de Fingolfin, funda la ciudad oculta de Gondolin, inspirado en sueños por el Vala Ulmo. Finrod hijo de Finarfin funda a su vez la ciudad secreta de Nargothrond, también inspirado en sueños por Ulmo.

En esta época también llegan a Beleriand los primeros hombres, que fueron conocidos como los Edain. Finrod los conoce y conserva con la casa de Bëor (los primeros en llegar) una larga y verdadera amistad. Estos hombres se establecen en Dorthonion (territorio de Finrod y sus hermanos), bajo el permiso de Thingol. Después llegan los hombres "Haladin" (la casa de Haleth), que se establecen junto con los drúedain que los acompañan en el bosque de Brethil, en el extremo oeste del bosque de Doriath, bajo permiso de Thingol y con la condición de que cuiden el paso norte hacia Beleriand. Por último llegan los hombres de Marach (la casa de Hador), que bajo permiso de Thingol se establecen en el territorio de Fingolfin, en Dor-lómin.

Con la cuarta batalla, la Dagor Bragollach (la Batalla de la Llama Súbita), se rompe el asedio. Muchos noldor mueren, en especial de la casa de Finarfin, entre ellos sus hijos Angrod y Aegnor. Los hijos de Fëanor quedan dispersos. Barahir rescata a Finrod y este le da su anillo en prenda de ayudarlo a él o cualquier pariente suyo siempre que lo necesiten. Fingolfin muere al ir desesperadamente a retar en combate singular a Morgoth. Su hijo Fingon queda entonces como Rey Supremo de los noldor en el exilio. Eöl se desposa a la fuerza con Aredhel hija de Fingolfin y esta concibe a Maeglin, con quien luego huye a Gondolin con su hermano Turgon. Morgoth comienza a ganar terreno. Sauron conquista Dorthonion y Tol Sirion. De esta manera el reino que perteneció a los hijos de Finarfin cae en manos de Morgoth, solo Nargothrond sobrevive por ser un reino secreto, que además se encuentra dentro de Beleriand, al que Morgoth todavía no accede (aunque controlando Tol Sirion ya tiene paso a él). Igualmente algunos de los reinos de los hijos de Fëanor caen en manos de Morgoth, con lo que Curufin y Celegorm se van a refugiar a Nargothrond y el resto se queda agrupado alrededor de Maedhros.

Nacen Húrin y su hermano Huor, de hombres de la tercera y la segunda casas. Húrin y Huor son rescatados cuando muy jóvenes por las águilas, que los llevan a la ciudad escondida de Gondolin, donde según las reglas del lugar jamás podrían salir; sin embargo mantienen una fuerte amistad con el rey Turgon y este los deja salir con la condición de que no revelen nunca el lugar en que se encuentra Gondolin. Húrin y Huor se desposan después con mujeres de la primera casa, y tienen respectivamente a sus hijos Túrin y Tuor.

En esta época, Beren hijo de Barahir huye de Dorthonion, y conoce en Doriath a la hija de Thingol, Lúthien, y ambos se enamoran. Thingol no permite la unión de un hombre con su hija, y le encomienda a Beren la misión de capturar un Silmaril de la corona de Morgoth como prenda por su hija. Beren desesperado acude a Finrod en Nargothrond, quien, por el juramento hecho a su padre Barahir, le brinda ayuda con pocos elfos, ya que la ciudad entera fue convencida por Curufin y Celegorm, hijos de Fëanor, de no ayudar en tal empresa que equivaldría a traicionar a Fëanor, por el Juramento que sus hijos hicieron. Son capturados por Sauron y Finrod muere defendiendo a Beren. Beren es rescatado por Lúthien y Huan, el perro cazador de Celegorm. Beren y luego Lúthien con él, van a Angband, y disfrazados logran robar un Silmaril de la corona de Morgoth. Beren pierde la mano donde tenía el Silmaril y casi muere pero son rescatados por las águilas. Thingol entonces permite la unión pero antes deben matar a Carcharoth, el lobo de Morgoth que le arrancó la mano a Beren, y que huyó hasta Doriath consumido por el Silmaril en sus entrañas. El lobo es muerto por Huan, pero también mata a Beren y a Huan. Lúthien muere de pena.

En Aman, los Valar conocen a Lúthien y ella canta con dolor por su amor por Beren y por los hijos de Ilúvatar abandonados en la Tierra Media. Los Valar entonces, bajo el permiso de Eru, permiten que Beren regrese de la muerte junto con Lúthien, quien para que esto se lleve a cabo elige un destino mortal distinto al de los elfos, e idéntico al de los Hombres. Se lleva a cabo entonces la Primera Unión de Elfos con Hombres. Beren y Lúthien se van a vivir a Ossiriand. Nace de ellos Dior, que luego se casa con Nimloth de Doriath y de ellos nace Elwing y otros dos hijos, los primeros medio elfos.

Esta es la quinta gran batalla de Beleriand. En ella los noldor se vuelven a aliar para combatir contra Melkor. El Señor de Doriath, el sinda Thingol, no acude con ellos pero tampoco evita que quien lo desee vaya a luchar, lo mismo sucede con Nargothrond, ahora al mando de Orodreth, hermano de Finrod, que sufrió durante la época de Beren y Lúthien por la codicia de los hijos de Fëanor. Los enanos también se alían con los noldor, y junto con los hombres de las Tres casas y los hombres cetrinos que llegaron después a Beleriand (y que estaban aliados con los hijos de Fëanor), organizan una gran batalla contra Melkor, que se llegaría a llamar Nírnaeth Arnoediad, «la batalla de las lágrimas innumerables».

Morgoth por su parte contraataca con todas sus fuerzas (orcos, Glaurung el Dragón, Balrogs, y los hombres cetrinos que traicionan a los hijos de Fëanor). Al final la batalla queda perdida para los noldor, y aunque hasta Turgon salió de Gondolin para combatir, son vencidos y este tiene que retirarse. Fingon muere a manos de los Balrogs y su hermano Turgon queda como Rey Supremo de los noldor en el exilio, escondido en Gondolin. Huor muere y Hurin defiende hasta el final la huida de Turgon, quedando al final preso por Melkor, quien lo maldice a él y a los suyos. Los enanos se retiran de la batalla luego de que su rey muere a manos de Glaurung. Los hijos de Fëanor se retiran por la traición de los hombres cetrinos. Muchos elfos, noldor y sindar, son capturados y llevados a Angband. De esta forma, el resto de los reinos de los hijos de Fëanor quedan conquistados y estos tienen que vivir por los bosques sin poder establecerse.

Todo el reino que antiguamente pertenecía a Fingolfin y su hijo Fingon, así como a los hombres de la casa de Hador, es capturado y cedido por Melkor a los hombres cetrinos como recompensa. Así mismo, las Falas son conquistadas, cayendo sus ciudades Brithombar y Eglarest, por las fuerzas de Melkor, al no haber ya protección en esa región de Beleriand.

Túrin, hijo de Húrin, comienza sus desgracias, primero en Doriath a donde huyó dejando atrás a su madre Morwen y hermana Nienor en Dor-lómin. Luego huye a las zonas invadidas de Beleriand donde se convierte en un bandido en la guarida de Mîm el enano. Su amigo Beleg el arquero de Doriath se le une pero son traicionados por Mîm y huyendo al norte, en una lamentable equivocación, Túrin mata a Beleg con su propia espada. Túrin llega a Nargothrond donde se pone el apodo de Mormegil, la "Espada negra" (por Gurthang (antes llamada Anglachel), la espada negra que porta). Ahí gana fama como capitán, y a pesar de las advertencias de unos elfos del mar, por parte de Ulmo, consigue hacer de Nargothrond ya no una ciudad secreta sino una fortaleza para enfrentar a Morgoth. Este lanza un ataque con Glaurung y vence, destruyendo Nargothrond, matando a Orodreth, capturando a los elfos y dejando a Túrin desesperado. Este quiere rescatar a la hija de Orodreth, Finduilas, pero no lo consigue. Túrin huye al bosque de los Haladin, donde se pone el (cruelmente irónico) sobrenombre de Turambar, el "Amo del destino". Ahí conoce a su hermana menor, a la que no reconoce porque nació después de su partida, y que tiene amnesia debida a una maldición de Glaurung, y sin saberlo se casan y conciben un hijo. Glaurung ataca a los Haladin y Túrin los defiende, matando a Glaurung, no sin antes revelarles a Túrin y Nienor el espantoso error que cometieron. Enloquecida, Nienor se suicida lanzándose al río con el hijo que lleva en el vientre. Túrin se suicida sobre su propia espada.

Húrin es liberado de Angband, quien va a Nargothrond, ya abandonado por las fuerzas de Morgoth y tomada por Mîm, a quien mata por traicionar a su hijo, y roba de Nargothrond el Nauglamír de Finrod, hecho por los Enanos. Se lo da a Thingol y después, sin deseos de vivir por las desgracias de los suyos, se avienta al mar. Thingol le pide a los enanos engarzar el Silmaril de Beren en el Nauglamir y estos lo quieren robar, Thingol muere a sus manos y Melian se retira de la Tierra Media para siempre. Beren y Lúthien recuperan el Nauglamir de los enanos, a los que matan con ayuda de los Ents. Dior se convierte en rey de Doriath y ahí él se entera de la muerte natural de Beren y Lúthien años después, de quienes hereda el Nauglamir con el Silmaril. Los hijos de Fëanor exigen se les entregue el Silmaril pero Dior se niega. En una Segunda Matanza de elfos contra elfos, los hijos de Fëanor destruyen Doriath, pero varios de ellos mueren, Dior también. Elwing alcanza a huir con el Nauglamir al Sur, a la bahía de Balar, donde los últimos reductos libres de elfos y hombres existen en el mar, con Círdan el carpintero de barcos al mando.

Durante esta época, Tuor, el hijo de Huor, es criado en Dor-lómin por los elfos de Mithrim, quienes lo educan en las costumbres élficas, y luego huye hacia el mar, donde Ulmo lo contacta para que vaya a avisar a Turgon que el tiempo de Gondolin ha terminado. Tuor llega por fin a Gondolin pero Turgon no quiere hacer caso, y Tuor termina desposándose con la hija de Turgon, Idril, dando lugar a la Segunda Unión de Elfos con Hombres. Nace de esa unión Eärendil. Maeglin, celoso de Tuor, traiciona Gondolin, revelándosela a Morgoth, quien la conquista rápidamente. Tuor, Idril, Eärendil y otros sobrevivientes huyen de Gondolin hacia el Sur, a la bahía de Balar; mientras huyen, un Balrog les cierra el paso en las montañas de Gondolin y Glorfindel los salva a todos sacrificando su propia vida. Turgon muere defendiendo Gondolin, y Ereinion Gil-Galad, hijo de Fingon, que en ese entonces ya vivía en Balar, queda como Rey Supremo de los Noldor en el exilio.

Eärendil y Elwing se conocen y se casan. Nacen de ellos los gemelos Elros y Elrond, los medio elfos. Eärendil emprende el viaje en busca de su padre, que se había embarcado al oeste en busca de Valinor, y de quien se dice (aunque no se sabe con certeza), que se le concedió ser contado entre los elfos, para vivir en Aman junto a su esposa Idril. Los hijos de Fëanor exigen el Silmaril a Elwing y realizan la Tercera Matanza de elfos contra elfos, en la que también mueren otros más de los hijos de Fëanor. Elwing huye tirándose al mar con el Silmaril, pero deja a sus hijos en manos de Maedhros y Maglor, los únicos hijos de Fëanor que quedan, los cuales, a pesar de todo, los cuidan.

Elwing es levantada por Ulmo del mar con forma de ave, se dirige al barco de Eärendil y juntos van al oeste y llegan a Aman con la ayuda del Silmaril. Eärendil habla con los Valar en nombre de todos los hombres y elfos de la Tierra Media y pide perdón por los noldor. Los Valar conceden y organizan la Guerra de la Cólera, en que por fin Morgoth es vencido.

Los noldor de Finarfin, junto con los Valar, los Maiar y los Vanyar, y con Eärendil en su barco (que se le destinó a volar para siempre por los cielos), van a la Tierra Media en barcos de los Teleri de Olwë, todos al mando de Eönwë, el heraldo de Manwë. Eärendil, portando el Silmaril de Beren y Lúthien, se levanta por primera vez en el cielo occidental como señal de esperanza.

Morgoth no puede soportar el ataque. Caen muchos Balrogs (aunque algunos alcanzan a esconderse bajo tierra), cae también Sauron, los dragones alados salen a la batalla por primera vez y son vencidos por Eärendil. Beleriand comienza a hundirse bajo el mar por la furia de la batalla y solo quedan algunos promontorios e islas pequeñas sobre el mar.

Morgoth es expulsado y exiliado al Vacío Intemporal, donde debe permanecer para siempre, sin embargo se dice que al final del tiempo logrará salir y guerreará contra las criaturas libres de Arda por última ocasión (ver Dagor Dagorath, la Última Batalla). Sauron en cambio mostró arrepentimiento, orillado por el miedo, y fue convocado por los Valar para responder por sus actos en Aman. Sin embargo, por el mismo miedo, decidió no presentarse y se escondió en la Tierra Media por mucho tiempo.

Los últimos dos Silmarils son recuperados, pero los dos últimos hijos de Fëanor sobrevivientes (Maedhros y Maglor) los roban del ejército de los Valar. Sin embargo, por la maldición de los noldor, las joyas ya no les pertenecen y les queman y enloquecen. Maedhros se tira en una fosa volcánica, junto con el Silmaril que lleva, que se queda en la tierra. Maglor arroja su Silmaril al mar, y él desde entonces vaga por las orillas del mar lleno de arrepentimiento. El tercer Silmaril pertenece al aire y Eärendil lo porta sin repercusión para él.

Los noldor son perdonados y aquellos que lo deseen pueden regresar a Aman, a habitar la isla de Tol Eressëa, donde antaño vivieron los Teleri antes de fundar Alqualondë. Sin embargo no todos los noldor regresan, y algunos permanecen en la Tierra Media con sus líderes; Gil-Galad como Rey Supremo y Galadriel hermana de Finrod, desposada con Celeborn de Doriath. Los noldor establecen sus reinos en Lindon y Eriador. A los Edain se les concede como regalo por su lealtad la isla de Númenor, donde establecen un largo reinado.

Se les concede a los medio elfos el poder de elegir su destino, si mortal o élfico. Elros elige el destino de los hombres y se convierte en el primer rey de Númenor. Elrond elige el destino de los elfos y se convierte en el segundo al mando de Gil-Galad, el cual vive en Mithlond, los Puertos Grises, con Círdan. Galadriel y Celeborn se van a Eregion, región fundada entonces por los noldor, al lado de la ciudad de Khazad-dûm de los enanos.

Con el fin de la Guerra de la Ira y el hundimiento de Beleriand comienza la Segunda Edad del Sol.


</doc>
<doc id="28176" url="https://es.wikipedia.org/wiki?curid=28176" title="Ivanhoe (película de 1952)">
Ivanhoe (película de 1952)

Ivanhoe es una película de coproducción angloestadounidense de 1952 basada en la novela del mismo título escrita en 1819 por Sir Walter Scott. 

La película, que contó con la dirección de Richard Thorpe y con la actuación de Robert Taylor, Elizabeth Taylor, Joan Fontaine, George Sanders y Finlay Currie, tuvo tres candidaturas a los Premios Óscar.

A su regreso de las Cruzadas, el rey Ricardo Corazón de León (Norman Wooland) es apresado en Austria. Para su rescate es necesaria una elevada suma de dinero que su hermano Juan sin Tierra (Guy Rolfe) se niega a pagar, ya que así puede seguir usurpando el trono de Inglaterra. Entre los partidarios de Ricardo se encuentra el caballero sajón Wilfred de Ivanhoe (Robert Taylor), quien lucha por conseguir el rescate. Ivanhoe era hijo de Cedric el sajón (Finlay Currie), dirigente de la resistencia sajona frente a la dominación normanda. Pero éste había renegado de su hijo porque había marchado a las Cruzadas sin su autorización, abandonando temporalmente a Lady Rowena (Joan Fontaine), última descendiente de la realeza sajona. 

Por ese motivo, Ivanhoe tendrá que reconciliarse primero con su padre, para conseguir con él y los demás sajones que apoyan al rey Ricardo, luchar contra Juan Sin Tierra a fin de lograr restaurar en el trono a su legítimo rey. 
Para conseguir el perdón paterno, Ivanhoe acude a un torneo organizado por el príncipe Juan y sus barones traidores, pero antes de participar en él, Ivanhoe salva a un judío, Isaac de York (Felix Aylmer), de ser asesinado. Como recompensa por su acción, su hermosa hija, Rebeca, (Elizabeth Taylor) le obsequia sus joyas a Ivanhoe con el fin de que pueda adquirir armadura, armas y caballo para participar en el torneo. Rebeca ha comenzado a enamorarse de Ivanhoe.

Cuando Ivanhoe llega de incógnito al torneo, con el nombre de "El Desheredado", los campeones normandos han vencido a todos los sajones que han osado enfrentarse a ellos. Ivanhoe los enfrentará uno a uno hasta derrotarlos a todos; a saber, sir Ralph de Vipont, Phillip de Malvoisin, Front de Boeuf (Francis De Wolff), sir Hugh de Bracy (Robert Douglas) y el templario sir Brian de Bois-Gilbert (George Sanders), quien ya se había enfrentado con Ivanhoe en Tierra Santa. 

Es precisamente Bois-Gilbert quien hiere gravemente a Ivanhoe en el último combate, aunque igualmente cae derrotado pues De Bracy lo había herido levemente en el anterior choque.

Finalmente, Ivanhoe es declarado vencedor y se le concede el derecho de elegir a la reina del torneo, Ivanhoe elige a Lady Rowena, ante la decepción de Rebeca que ha acudido con su padre a ver el encuentro.

Ivanhoe se desploma a causa de sus heridas y todos descubren su identidad, que hasta entonces había permanecido oculta; incluso su padre lo ensalza por su hazaña. Pero, es Rebeca, quien previa conversación y acuerdo con Lady Rowena, también muy preocupada por la suerte del guerrero Ivanhoe, se ocupa de trasladarlo a su casa a fin de cuidarlo y curar sus heridas hasta alcanzar su completa recuperación. 
A partir de ese momento la acción se torna agitada. En el traslado de Ivanhoe, es hecho prisionero junto con sus protectores judíos, al igual que su padre y su séquito, en el cual está Lady Rowena. Todos ellos son llevados al castillo de Frente de Buey, donde Bois-Gilbert cortejará a Rebeca, y De Bracy a Lady Rowena. 

Pero los traidores normandos son sorprendidos por Robin de Locksley (Robin Hood) (Harold Warrender) y sus hombres, que asaltan el castillo. Frente de Buey muere en la defensa, de Bracy se rinde, y Bois-Gilbert huye con Rebeca al santuario de los Templarios.

Ivanhoe logra reunir el rescate para Ricardo, recibiendo entre otras la aportación de Isaac de York y parte del pueblo judío que contribuyen con dinero emolumentos de su pueblo para lograr la liberación del rey Ricardo.

Mientras, Rebeca es juzgada como hechicera o bruja, por usar sus conocimientos de herbolaria para curar enfermos, y acusada de haber hechizado al caballero Bois-Gilbert, quien en el fondo está perdidamente enamorado de ella. A punto de ser condenada, Ivanhoe lanza su guante, como símbolo de reto y solicita un "Juicio de Dios", en el cual la inocencia o culpabilidad de Rebeca se decidirá en un torneo a muerte entre el retador de la acusada, Ivanhoe, y el campeón elegido por la acusación, que definitivamente es Bois-Gilbert.

Rebeca asiste al duelo entre los dos valerosos guerreros: uno, al que ella ama, empeñado en demostrar su inocencia; el otro que la ama a ella, condenado a demostrar su culpabilidad, tras una demostración de los dos caballeros en su habilidad en manejo de las armas, Ivanhoe dará muerte a Gilbert y salvará a Rebeca. En ese instante, el rey Ricardo Corazón de León irrumpe en el torneo junto a sus caballeros, su hermano Juan Sin Tierra, el usurpador, baja la cabeza en señal de sumisión y es sometido, mientras el verdadero rey, Ricardo Corazón de León, exhorta a todo el pueblo a fortalecer la unión.




</doc>
<doc id="28177" url="https://es.wikipedia.org/wiki?curid=28177" title="Klute">
Klute

Klute (en Argentina y en España), o también conocida como Mi pasado me condena (en México y en Venezuela) es una película estadounidense de 1971 dirigida por Alan J. Pakula y con Jane Fonda y Donald Sutherland en los papeles principales.

La película fue galardonada con varios premios cinematográficos estadounidenses y uno internacional.

Trata de la historia de una prostituta que colabora con un detective en la solución de un caso.


En papeles menores aparecen Sylvester Stallone, Harry Reems, Richard Jordan, Veronica Hamel y Kevin Dobson.




</doc>
<doc id="28181" url="https://es.wikipedia.org/wiki?curid=28181" title="The Usual Suspects">
The Usual Suspects

The Usual Suspects (llamada Los sospechosos de siempre o Sospechosos comunes, en Hispanoamérica, y Sospechosos habituales, en España) es una película estadounidense de 1995, escrita por Christopher McQuarrie (quien ganó un por este trabajo) y dirigida por Bryan Singer. Fue protagonizada por Kevin Spacey (Oscar al Mejor Actor de Reparto), Gabriel Byrne, Stephen Baldwin, Benicio del Toro y Kevin Pollak.

La película, con un presupuesto de 4 millones de dólares, no fue muy bien recibida en las salas de cine durante su lanzamiento, formando parte de la lista de «Las películas más odiadas por Roger Ebert», pero fue atractiva para muchos seguidores del género de crimen/drama y es considerada una película de culto. Diez años después de su estreno permanece en el Top 25 de Internet Movie Database «Top 250 Movie List». Forma parte del AFI's 10 Top 10 en la categoría de "Películas de misterio".

Roger «Verbal» Kint (Kevin Spacey) es un pequeño estafador lisiado que se encuentra en un interrogatorio de la policía de Los Ángeles y le cuenta a su interrogador, el Agente Kujan (Chazz Palminteri), una historia sobre los acontecimientos que desencadenaron un tiroteo y una masacre dentro de un barco apostado en el puerto de Los Ángeles. Usando la narración en retrospectiva, la historia de Verbal llega a ser cada vez más compleja, mientras él intenta "aclarar" los hechos, para la satisfacción del Agente Kujan, que está interesado en saber por qué él y sus compañeros de crimen estaban en ese barco.

En un barco en la bahía de San Pedro, una figura sin rostro identificada como "Keyser" habla brevemente con un hombre herido llamado Keaton (Byrne), entonces Keyser parece dispararle a Keaton, antes de poner el barco en llamas. Al día siguiente, el agente del FBI Jack Baer (Giancarlo Esposito) y los del Servicio de Aduanas del agente especial David Kujan (Palminteri) llegan a San Pedro por separado para investigar lo sucedido en el barco en eso llega el agente federal Josh Hillman junto con el comisario Peter Turner de los U.S Marshals debido a que Uno de ellos es un fugitivo. Parece que hay sólo dos supervivientes: Roger "Verbal" Kint (Spacey), un estafador con una leve parálisis y un criminal llamado Arkosh Kovash (Morgan Hunter). Baer interroga a Kovash quien está atendiendo sus graves quemaduras en el hospital. Este afirma que Keyser Söze, un genio criminal turco con una reputación casi mítica, se encontraba en el puerto para "matar a muchos hombres". Kovash comienza a describir a Söze a través de un intérprete, mientras que un dibujante de la policía hace una representación de la cara de Söze. Mientras tanto, Verbal ha testificado en detalle sobre el incidente a cambio de casi total inmunidad. A la espera de pagar la fianza por el cargo menor de armas, Verbal se coloca en la abarrotada oficina del sargento de policía de San Pedro, Jeffrey Rabin (Dan Hedaya) donde Kujan exige escuchar su historia desde el principio. Verbal comienza seis semanas antes en Nueva York:

Cinco delincuentes se unen en una línea de policía: Dean Keaton (Gabriel Byrne), un oficial de policía corrupto que aparentemente ha renunciado a su vida de crimen; Michael McManus (Stephen Baldwin), un ladrón profesional de mal genio; Fred Fenster (Benicio del Toro), Verbal Kint y Todd Hockney (Kevin Pollak).

Mientras están los cinco detenidos, McManus convence a los demás de unir fuerzas para cometer un robo dirigido a "El mejor servicio de taxis en New York", un grupo de corruptos agentes de policía que escoltan a contrabandistas a sus destinos en la ciudad. Tras el robo con éxito, el quinteto viaja a Los Ángeles para vender su botín a un conocido de McManus, "Redfoot" (Peter Greene), quien les propone otro trabajo: robar a un comerciante de joyas. En lugar de llevar joyas o dinero como se les dijo, llevaba heroína . Un enfrentamiento furioso entre los ladrones y Redfoot revela que el trabajo vino de un abogado llamado Kobayashi (Pete Postlethwaite). Los ladrones más tarde se reúnen con Kobayashi, quien afirma que trabaja para Keyser Soze y los chantajea para atacar un barco en el puerto de San Pedro. Kobayashi describe la misión de un barco de contrabando de 91 millones de dólares en cocaína, va a ser vendida por rivales de Söze. Los ladrones deben a destruir la droga y, si deciden esperar hasta que los compradores lleguen, pueden dividir el dinero como quieran.

En la actualidad, Verbal le cuenta a Kujan la historia de Keyser Söze: después de que sus rivales húngaros invadieron su casa, son sorprendidos de que mata a su propia esposa e hijos, y luego masacra a la multitud entera, menos a uno. Después de ese incidente Söze pasó a la clandestinidad, nunca trata directamente con alguien en persona, y dice que se convirtió en "un cuento de miedo que cuentan los criminales a sus hijos por la noche". Kujan no está familiarizado con Söze, Verbal dice que ha oído rumores durante años sobre criminales que trabajan para Söze pero en realidad no saben para quién trabajan. Verbal también dice que Fenster intentó huir, dando lugar a una sentencia de muerte por Kobayashi. Los restantes cuatro ladrones secuestran a Kobayashi, con la intención de matarlo si él no los deja en paz. Amenazado, Kobayashi revela que Edie Finneran (Suzy Amis), abogada y novia de Keaton, está en su oficina (creyendo que fue contratada para los servicios jurídicos), y amenaza con matarla, así como a las familias de los cuatro ladrones, en caso de negarse a hacer el trabajo.

En la noche de la venta de cocaína, los vendedores (un grupo de argentinos mafiosos) y los compradores (un grupo de mafiosos húngaros) se encuentran en el muelle. Keaton le dice a Verbal que no vaya y que tome el dinero si el plan sale mal para que junto con Edie (su novia) puedan perseguir a Kobayashi en "su camino". Verbal acepta a regañadientes, y mira el barco desde la distancia. Keaton, McManus, Hockney atacan a los hombres en el muelle, matando a la mayoría de ellos. Keaton y McManus están a bordo de la nave para encontrar la droga mientras Hockney va detrás de la furgoneta que transportaba el dinero pero es fatalmente disparado por alguien invisible cuando la encuentra. Keaton y McManus descubren que no hay cocaína en el barco. Mientras, un pasajero argentino muy bien resguardado, es asesinado por el asaltante invisible mientras este es buscado. McManus es asesinado con un cuchillo en la parte posterior de su cuello y Keaton, dándose la vuelta para irse, es herido por una bala por un hombre vestido con un traje negro y sombrero. La misteriosa figura parece hablar brevemente con Keaton antes de dispararle de nuevo.

Cuando Verbal termina la historia, Kujan revela lo que sabe: el cuerpo del hombre argentino fue encontrado por la mañana en la costa, y se revela al hombre, Arturo Márquez (Castulo Guerra), quien con el fin de escapar de la cárcel, le había revelado a las autoridades que él podría identificar a Keyser Söze. El asume que el grupo de húngaros son el mismo grupo que Söze casi aniquila en Turquía y se ofrecen a comprar a Márquez del grupo argentino por 91 millones de dólares. Con la fabricación de un acuerdo, Kujan especula, Söze contrató a Verbal y su equipo para que fueran a robar a los muelles, cuando en realidad se trataba de una tapadera para que Söze entrara personalmente en el barco y matara a Márquez sin ser detectado. Kujan a través de su análisis concluye que Keaton era realmente Keyser Söze. Está convencido de que Keaton ha fingido su muerte (como lo había hecho unos años antes de escapar de otra investigación), y deliberadamente dejó a Verbal como testigo. Bajo un interrogatorio agresivo de Kujan, Verbal entre lágrimas admite que todo el asunto era idea de Keaton desde el principio, pero se niega a declarar.

Verbal sale por libertad bajo fianza después de haber sido arrestado, Verbal recupera sus cosas personales del funcionario de la propiedad. Momentos más tarde, Kujan, relajado en la oficina de Rabin, se da cuenta con sorpresa de que los detalles y los nombres de la historia de Verbal son extraídos de varios objetos alrededor de la habitación, incluyendo el tablón de anuncios lleno de gente de Rabin y el logo de la "Compañía de porcelana Kobayashi" en la parte inferior de la taza de café. Kujan se da cuenta de que la mayor parte de la historia de Verbal fue improvisada para su beneficio y va tras él, corriendo junto a una máquina de fax, que recibe la impresión del dibujo de la policía de la cara de Keyser Söze, que se asemeja a nada menos que a Verbal Kint.

Mientras tanto, Verbal se aleja de la comisaría de policía, dejando de fingir su parálisis cerebral. Se sube a un coche esperando conducido por "Kobayashi", alejándose mientras Kujan sale fuera, buscando en vano. Verbal cita a Charles Baudelaire: "El mayor truco del diablo fue convencer al mundo de que no existía". Esto es seguido por la descripción anterior de Keyser Söze: "Y así, él se ha ido".


</doc>
<doc id="28183" url="https://es.wikipedia.org/wiki?curid=28183" title="Gelsa">
Gelsa

Gelsa es una localidad y municipio español de la Ribera Baja del Ebro, provincia de Zaragoza, Aragón.
Tiene una población de 1122 habitantes (INE 2014).

Gelsa está situada en la Depresión del Ebro sobre depósitos cuaternarios, en la margen izquierda del río a 147 msnm, siendo uno de los municipios de Aragón situado a menor altitud.
Se encuentra a tan sólo 5 km de la capital comarcal, Quinto, y a 45 km de Zaragoza.

Tiene una temperatura media anual de 13,9 °C y una precipitación anual de 340 mm.

El topónimo Celsa proviene de la colonia romana Lépida Celsa, primera colonia romana fundada en el valle del Ebro, y que originariamente era un poblado íbero de los ilergetes denominado Kelse.
Aunque el núcleo de dicha población se encuentra en la vecina Velilla de Ebro, es muy probable que se extendiera también hasta la actual Gelsa, como parecen atestiguar los hallazgos de enterramientos y de una lápida dedicada a la diosa Obana.
Julio César concedió a Celsa título y honores de colonia romana antes del año 43 a.C., y la distinguió con singulares privilegios como la acuñación de moneda.
Con Augusto empezó una lenta decadencia de esta colonia a favor de Caesaraugusta, actual Zaragoza.
Se piensa que el fin de Celsa pudo producirse durante la invasión de Hispania por los bárbaros.

La localidad de Gelsa fue probablemente fundada por los árabes tras su conquista de la península ibérica; algunas construcciones son de dicha época, como las calles de los Cubiertos y Ocho Esquinas, el Pilón de las Levatas y el Pilón de la Atalaya, hoy desaparecido.
La huella árabe está también presente en los sistemas de riego tales como el azud, las norias y las acequias.

Posiblemente Gelsa fue reconquistada para los reinos cristianos por Pedro I poco después de la conquista de Barbastro, aunque la población musulmana continuó ocupando estas tierras tras la ocupación.
En 1210, Pedro II cedió Gelsa en señorío, junto con otros lugares de la baronía de Quinto, a los Torrellas Ortiz, que las vendieron al conde Lope de Luna en 1358.
En 1431, el señorío pasó a Juan de Funes; el octavo señor de esta casa, Antonio de Funes, fue quien mandó construir el palacio de la plaza Mayor.

El fogaje de 1495 realizado en el Reino de Aragón deja constancia de que en aquella época la práctica totalidad de los habitantes de Gelsa —unos 400 aproximadamente— eran moriscos.
En 1610, era el pueblo de Zaragoza donde más moriscos vivían (en torno a 1 700) y el tercero de todo Aragón.
En consecuencia, la expulsión de los moriscos de España a partir de 1609 hizo necesario repoblar la villa, por lo que Juan de Funes y Villalpando expidió una carta puebla para Gelsa (1628).
Por otra parte, María Francisco Climente, primera esposa de Juan, fue quien aportó a la localidad la reliquia de la «Santa Espina» —véase más abajo—, quedando custodiada en el Monasterio de la Purísima Concepción y la Santa Espina.

La Iglesia Parroquial, dedicada a San Pedro, fue erigida en el último tercio del siglo XVII y en 1728 se construyó una fábrica de tejidos de lana dirigida por el ingeniero gelsano José Genzor y López de Perea. Los graneros del conde —actualmente el Centro Cultural— fueron construidos antes de 1779.

Pascual Madoz, en su Diccionario geográfico-estadístico-histórico de España de 1845, refiere que «Jelsa» —escrito de esta manera— «"cuenta con 380 casas, inclusa la del ayuntamiento y cárcel, el palacio del Sr. conde de Montijo, barón de Quinto... la iglesia parroquial (San Pedro Apóstol)... una pequeña capilla llamada de Pedro, que se dice fue la primera parroquia y cuyo edificio se halla bastante quebrantado [y] una ermita dedicada a la virgen del Buen Suceso"».
Menciona también la existencia de «"telares donde se elaboran estameñas, fajas y mantas, un molino harinero con 4 muelas, 2 de aceite y un batán"».

A principios del siglo XV, la población de Gelsa era de unos 1700 habitantes, cifra que, tras la expulsión de los moriscos, se vio disminuida a menos 400 habitantes.
Ya en el siglo XIX, el censo de España de 1857 registra 2818 habitantes para Gelsa, que era en ese momento el segundo municipio más poblado del partido judicial de Pina —al que entonces pertenecía—, después de Pina de Ebro.
Sin embargo, su evolución demográfica en los dos últimos tercios del siglo XX ha sido regresiva: 2120 habitantes en 1930, 1595 habitantes en 1970 y 1239 habitantes en 2001. En 2014 el municipio contaba con 1122 habitantes.
La economía de la localidad se basa en la agricultura, la ganadería y la industria del yeso, ya que existen dos fábricas dedicadas a la producción de yesos y escayolas.

En el terreno agrícola, es muy importante el cultivo de secano —trigo—, mientras que la agricultura de regadío o de huerta es de gran calidad. Destaca el contraste del paisaje de la ribera del Ebro con la aridez del resto del paisaje monegrino.
Por su parte, la ganadería es actividad menos importante y se dedica al ganado ovino y bovino.

Actualmente se intenta desarrollar el polígono industrial "La Atalaya".

Es de interés artístico el casco antiguo, también llamado «barrio morisco», lugar donde se agruparon tras la reconquista las viviendas de los musulmanes. Esta parte está caracterizada por sus calles estrechas y «cubiertos» (edificaciones situadas sobre la calle que comunican las casas de uno y otro lado).

La iglesia parroquial de la localidad, dedicada a San Pedro Mártir de Verona, fue construida en el último tercio del siglo XVII y posteriormente reformada en 1863.
Presenta fábrica de ladrillo, tapial y zócalo de sillar. Tiene tres naves, crucero, cabecera plana, cubierta de bóveda de lunetos y cúpula sobre el crucero.
Su torre fue levantada en 1826 y el reloj con campanas fue instalado en 1899.
La parroquia alberga en su interior un relicario de cristal guarnecido en oro con forma de columna; contiene la llamada «Santa Espina», que según la leyenda procede de la corona de espinas que llevó Jesús de Nazaret.

El Convento de las Monjas Clarisas, emplazado frente a la iglesia, fue construido por mandato de Juan de Funes Villalpando y Ariño, Marqués de Osera, en 1621. Lo ocuparon durante diez años los Padres Franciscanos venidos de Pina de Ebro, que después volvieron a Pina.

La Ermita de Nuestra Señora del Buen Suceso, patrona de la villa, tiene fábrica de ladrillo y tapial.
Posee ábside semicircular y cubierta de bóveda de lunetos, sobre el porche de entrada, con tres arcos de medio punto. Edificada en el siglo XVIII, fue quemada en 1936 y posteriormente reconstruida con donativos de los vecinos.

En cuanto a la arquitectura civil, cabe destacar el edificio del Ayuntamiento, casino durante los siglos XIX y XX, así como la casa palacio de la familia Funes, situada en la plaza Mayor, que data del siglo XV.




</doc>
<doc id="28187" url="https://es.wikipedia.org/wiki?curid=28187" title="Sesgo estadístico">
Sesgo estadístico

En estadística se llama sesgo de un estimador a la diferencia entre su esperanza matemática y el valor numérico del parámetro que estima. Un estimador cuyo sesgo es nulo se llama "insesgado" o "centrado".

En notación matemática, dada una muestra formula_1 y un estimador formula_2 del parámetro poblacional formula_3, el sesgo es:

El no tener sesgo es una propiedad deseable de los estimadores. Una propiedad relacionada con esta es la de la consistencia: un estimador puede tener un sesgo pero el tamaño de este converge a cero conforme crece el tamaño muestral.

Dada la importancia de la falta de sesgo, en ocasiones, en lugar de estimadores "naturales" se utilizan otros corregidos para eliminar el sesgo. Así ocurre, por ejemplo, con la varianza muestral.

En el diseño y elaboración de un estudio de investigación en clínica, puede haber distintos tipos de sesgos:




</doc>
<doc id="28191" url="https://es.wikipedia.org/wiki?curid=28191" title="Metaanálisis">
Metaanálisis

El metaanálisis es un conjunto de herramientas estadísticas, que son útiles para sintetizar los datos de una colección de estudios. El meta-análisis se inicia recopilando estimaciones de un cierto efecto (expresado en un índice de tamaño del efecto, como la diferencia de medias tipificada, la razón de riesgo, o la correlación) de cada estudio.El metaanálisis permite valorar estos efectos en contexto: si el tamaño del efecto es consistente, el efecto del tratamiento puede ser considerado como fuerte y el tamaño del efecto se estima con mayor precisión que con un solo estudio. Si el tamaño del efecto varía, esa variación puede ser descrita y, potencialmente explicada.

El término metaanálisis, como tal, fue inicialmente aplicado en las ciencias sociales y en psicología. A partir de la década de los 80, se comenzó a aplicar de forma creciente en medicina y a partir de los 90 son muy frecuentes los artículos que describen resultados de metaanálisis en publicaciones médicas.

El término "meta- análisis" fue acuñado por "Gene V. Glass" en 1976, siendo el primer estadístico moderno en señalar que su mayor interés era "a qué hemos llamado el "meta-análisis" de la investigación científica". Aun cuando esto le permitiera ser ampliamente reconocido como el fundador del método moderno, no fue sino hasta la década de los 1990's cuando la práctica de los meta-análisis comenzó a figurar, pero no siempre, como los componentes importantes de un proceso de revisión sistemática. La teoría estadística en torno al metaanálisis mejoró notablemente gracias al trabajo desempeñado por Nambury S. Raju, Larry V. Hedges, Harris Cooper, Ingram Olkin, John E. Hunter, Jacob Cohen, Thomas C. Chalmers, Robert Rosenthal, y Frank L. Schmidt.

Conceptualmente hablando, se utiliza un enfoque estadístico para combinar los resultados de múltiples estudios. Por tanto, sus ventajas son las siguientes:


El metaanálisis que arrojan varios estudios de corto alcance, no predice los resultados de un solo estudio amplio. Algunos han argumentado que una debilidad del método es que los focos de sesgo no están controlados por el método: un buen metaanálisis de estudios mal diseñados todavía dará lugar a malas estadísticas. Esto significaría que sólo los estudios metodológicamente sólidos deben ser incluidos en un metaanálisis, una práctica llamada «síntesis de la mejor prueba». Otros analistas incluirían estudios más débiles, y añadirían una variable de predicción a nivel de estudio que refleje la calidad metodológica de los estudios para examinar el efecto de la calidad del estudio sobre el tamaño del efecto. Sin embargo, otros han argumentado que el mejor enfoque es el de preservar la información sobre la variación en la muestra del estudio, echando una red tan amplia como sea posible, y que los criterios de selección metodológica introduzcan subjetividad no deseada, anulando el propósito de este enfoque.

Otro escollo potencial es la confianza en lo disponible de estudios publicados, lo que puede generar resultados exagerados debido a dicho sesgo, pues los estudios que muestran resultados negativos o insignificantes tienen menos probabilidades de ser publicados. Para cualquier área de investigación determinado, no se puede saber cuántos estudios han sido ocultados o descartados.

Este problema resulta en la distribución de tamaños del efecto que están sesgados, asimétricos o totalmente aislados; creando un "error común de razonamiento lógico", en el que se sobreestima la importancia de los estudios publicados, mientras otros estudios ni se publican. Esto debiera ser considerado en serio al interpretar los resultados de un metaanálisis.

Esto se puede visualizar con un gráfico de embudo, el cual, es un diagrama de dispersión del tamaño de muestra y de efecto. Para un cierto nivel de efecto, cuanto menor sea el estudio, mayor es la probabilidad de encontrarlo por casualidad; al mismo tiempo, cuanto mayor sea el nivel de efecto, menor será la probabilidad de que un estudio más grande pueda resultar así de positivo. En caso de que muchos estudios negativos no fuesen publicados, los positivos restantes darían lugar a tal gráfico de embudo en el cual el tamaño de efecto es inversamente proporcional al tamaño de muestra, es decir, una parte importante del efecto que se muestra se debe a la posibilidad de que no se equilibra en el diagrama por ausencia de datos negativos no publicados. En cambio, al publicarse la mayoría de estudios, el efecto mostró no tener razón para sesgarse por el tamaño de estudio; por lo cual resulta, un gráfico de embudo simétrico. Así que, si no hay sesgo de publicación, no habría relación alguna entre el tamaño de muestra y el tamaño de efecto. Una relación negativa entre el tamaño de muestra y el de efecto implicaría que los estudios que encontraron efectos significativos fueran más propensos de publicarse y/o enviarse para tal fin. Hay varios procedimientos disponibles que intentan corregir el problema de cajón al identificarse, tales como adivinar en la mecha de distribución de los efectos de estudio.

Los métodos para detectar el sesgo de publicación han sido polémicos ya que suelen tener bajo impacto para detectarlo, incluso pueden generar falsos supuestos bajo ciertas circunstancias. Un método conjunto para analizar el sesgo de publicación ha sido propuesto para abatir falsos supuestos y sugerir que el 25% de los metaanálisis en psicología podrían tener sesgo de publicación. Sin embargo, los posibles problemas de bajo impacto siguen siendo controvertidos y las estimaciones de sesgo podrían ser inferiores a la cantidad real.

El error más grave en el metaanálisis (H. Sabhan) ocurre a menudo cuando la(s) persona(s) realizando un metaánálisis tiene(n) una agenda económica, social, o política, como la aprobación o la reprobación legislativa. La gente con estos tipos de agendas podrían ser más propensos de utilizar indebidamente los metaanálisis debido a sus prejuicios.


Para conocer las directrices de informes, consulte los artículos de Reporte Preferidos para Revisiones Sistemáticas y los Meta-análisis ("Preferred Reporting Items for Systematic Reviews and Meta-Analyses" - PRISMA, por sus siglas en inglés).

En general, existen dos tipos de prueba que se pueden distinguir al realizar un metaanálisis: los datos iniciales aportados por cada participante (DIP) y los datos de agregado (AD). Considerando que los datos iniciales representan la información en bruto procedente de los centros de estudio, los agregados de hecho son más comunes y disponibles (por ej: desde la literatura) y típicamente representan estimaciones globales, tales como razones de ventaja (odds ratio) o riesgos relativos. Esta distinción ha incrementado las necesidades de diferentes métodos cuando la prueba es deseada, conduciendo al desarrollo de métodos de una o dos etapas; en los de una etapa, los datos iniciales son simultáneamente modelados mientras representan la agrupación de participantes dentro de los estudios; por el contrario, los métodos de dos etapas, sintetizan los datos agregados de cada estudio y consideran aquí las cargas de estudio. Reduciendo los datos iniciales a datos agregados, los métodos de dos etapas pueden incluso aplicarse cuando se cuenta con los datos iniciales; lo que presenta una alternativa de acción al realizar el metaanálisis.

Aunque se cree que los métodos de una o dos etapas arrojan resultados parecidos, estudios recientes han demostrado que dichos métodos pueden a veces llevar a diferentes conclusiones.

El modelo de efectos fijos ofrece una ponderación de estimaciones seriadas: se suele emplear el inverso de la varianza de cada estimación como peso del estudio, de tal manera que los estudios con muestras mayores tienden a contribuir más a la media ponderada que los estudios con muestras menores. En consecuencia, cuando los estudios en un metaanálisis son dominados por uno grande, los hallazgos en estudios más pequeños resultan prácticamente ignorados. Lo más importante, este modelo supone que todos los estudios incluidos son idénticos: estudian a la misma población, usan la misma variable y definiciones de resultados, etc. Este supuesto es típicamente irreal porque toda investigación es propensa a ser influida por varias fuentes de heterogeneidad; así, los efectos del tratamiento pueden diferir según la configuración regional, los niveles de dosificación, las condiciones de estudio.

Un modelo común para sintetizar estudios heterogéneos, es el "modelo de efectos aleatorios"; este es tan solo la media ponderada de los tamaños del efecto de un grupo de estudios. El peso que se aplica en este proceso de ponderación con un metaanálisis de efectos aleatorios se realiza en dos pasos:


En un caso extremo en el que la varianza específica sea muy grande puede ocurrir que el peso esté muy condicionado por esa varianza, resultando despreciable en términos prácticos los tamaños muestrales de los estudios. De esta forma, la media ponderada será muy cercana a la media aritmética simple, no ponderada. En el extremo opuesto está el caso en que la estimación de la varianza específica proporciona el valor cero. En este caso los pesos serán iguales a los inversos de las varianzas de muestreo y el resultado será idéntico al que se obtiene bajo el modelo de efecto fijo. El modelo de efecto fijo es un caso particular del modelo de efectos aleatorios, que se produce cuando la varianza específica es igual a cero.

La medida de esta inversión depende únicamente de dos factores: la heterogeneidad de precisión, y la heterogeneidad del tamaño del efecto:

Por otra parte el método más utilizado para estimar la varianza específica y tener en cuenta la heterogeneidad es el método de DerSimonian-Laird (DL), o método de los momentos, propuesto en 1986. Posteriormente se han propuesto otros métodos, como el de máxima verosimilitud restringida (REML), un método iterativo y computacionalmente más intensivo. Sin embargo, una comparación entre estos dos modelos (y otros) demostró que hay pocas diferencias prácticas y DL es bastante adecuado en la mayoría de los escenarios.

La metarregresión es una herramienta utilizada en el metaanálisis para examinar el impacto de las variables moderadoras en el estudio del tamaño del efecto utilizando técnicas basadas en regresión. La metarregresión es más eficaz en esta tarea, de lo que son las técnicas de regresión estándar.

En Medicina, un metaanálisis es el estudio basado en la integración estructurada y sistemática de la información obtenida en diferentes ensayos clínicos, sobre un problema de salud determinado. Consiste en identificar y revisar los estudios controlados sobre un determinado problema, con el fin de dar una estimación cuantitativa sintética de todos los estudios disponibles. Dado que incluye un número mayor de observaciones, un metaanálisis tiene un poder estadístico superior al de los ensayos clínicos que incluye. Los dos principales problemas metodológicos de los metaanálisis de ensayos clínicos son:
Un metaanalisis clínico se basa principalmente en una integración o reciclaje entre la información ya obtenida y poder obtener un análisis mayor.

El primer "metaanálisis clínico" fue realizado por Karl Pearson en 1904, en un intento de superar el problema del reducido poder estadístico de los estudios con pequeños tamaños muestrales; si se analizan los resultados de un grupo de estudios similares, se puede alcanzar una valoración más exacta de los efectos.

En Estadística, un metaanálisis se refiere al conjunto de métodos enfocados a contrastar y combinar los resultados de diferentes estudios; con la esperanza de identificar patrones entre los resultados de estudio, las fuentes de desacuerdo entre dichos resultados, u otras relaciones interesantes que pueden salir a la luz en el contexto de múltiples estudios.

En su más simple forma, se lleva a cabo al identificar una medida común del tamaño de efecto; del cual un promedio ponderado podría ser el dato de salida en un metaanálisis. La ponderación podría estar relacionada con tamaños de muestra dentro de los estudios individuales.

Más a menudo, hay otras diferencias entre los que necesitan ser permitidos; pero el objetivo general de un metaanálisis radica en estimar con mayor fuerza el tamaño real de efecto, en contraste a uno menos preciso derivado en un solo estudio bajo un sencillo conjunto determinado de supuestos y condiciones.






</doc>
<doc id="28194" url="https://es.wikipedia.org/wiki?curid=28194" title="Yakuza">
Yakuza

La yakuza (ヤクザ) es el equivalente del crimen organizado; es una mafia japonesa que data del siglo XVII. El origen de la palabra no se conoce con exactitud, pero se dice que proviene de un juego de cartas llamado hanafuda, muy famoso entre los "bakuto", en el que la peor mano consiste en un 8 ("ya"), un 9 ("ku") y un 3 ("za"). La yakuza moderna ha extendido sus actividades a la corrupción bancaria y política. En 2009, el último año del que se tiene registro, tenía un estimado de 87 900 miembros en Japón. 

Se ignora el origen de la palabra "yakuza", pero está extendida la creencia de que proviene del estilo de vida de los "bakuto" (博徒 ‘apostadores’), una de las dos clases sociales que dieron origen a los yakuza (los otros son los "tekiya" o «vendedores ambulantes»). Los "bakuto" estaban muy abajo en la sociedad japonesa del período Edo, por estar prohibidas las apuestas. De ahí derivó su imagen indeseable y el nombre "ya" (ocho), "ku" (nueve) y "za" (tres), ya que 8, 9 y 3 son 20 puntos, que es la peor mano en el "oicho-kabu", una variante del juego de cartas hanafuda.

Es la mafia más temida de Japón. Durante el período Edo, la figura del samurái era privilegiada dentro de la sociedad debido a su eficiencia militar y los servicios de seguridad que prestaban a la comunidad, a través de los "daimyō", señores feudales o Shōgun. Al final del período de guerras, Japón inicia su era moderna y continúa unificándose en un solo gobierno, así que muchos samuráis eran despedidos porque resultaban inútiles a los nuevos destinos de la nación y se convertían en mercenarios ambulantes conocidos como "rōnin". Estos siguieron haciendo trabajos de manera independiente para sus jefes y la alta sociedad. Al cabo del tiempo se empezaron a organizar en bandas paramilitares que protegían regiones a cambio de comida y comodidades que proporcionaba la comunidad. Poco tiempo después terminan dominando los negocios ilegales de Japón.

A finales del siglo XIX y al iniciarse el XX tenían el control de las apuestas, el contrabando, lavado de dinero, los espectáculos, la especulación de bienes inmobiliarios, la extorsión, el tráfico de drogas y armas. Además, después de la Segunda Guerra Mundial, ciertas bandas de ideología ultraderechista comenzaron a operar y extorsionar dentro de grupos políticos.

Su organización se derivó de los códigos de los samuráis pero mucho más estructurados y fortalecidos; todo el clan se considera una familia donde se profesa la fidelidad absoluta a la banda, el ultranacionalismo, la obediencia al mayor rango y su estricto y brutal código de honor. Los novatos se adoctrinan a través del sistema senpai-kōhai, en el cual se especifican los procedimientos de castigo a la deslealtad, como por ejemplo la amputación de un dedo meñique para aquel miembro que cometa algún fallo grave o incurra en traición. Dicha amputación sirve aún en la actualidad para reconocer a los miembros retirados o disidentes. La amputación se realizaba principalmente en el dedo meñique de la mano izquierda, ya que es el dedo que aplica más fuerza a la hora de realizar un corte con la katana, al perder ese dedo no podrías ser mortífero en combate con katanas, te volvías inservible y acababas degradado o expulsado de la organización.

Los tatuajes dentro de la organización son muy importantes; revelan muchas veces el rango dentro de la organización, el clan al que se pertenece, el lema del clan, algunos incluyen dragones y referencias a su genealogía samurái. La mayoría empieza como un tatuaje pequeño al que se le hacen adiciones y terminan cubriendo grandes partes del cuerpo; el tatuaje es uno de los rasgos físicos más característicos de la yakuza. Tales tatuajes son aplicados con la técnica "tebori", la cual es muy dolorosa, y el tiempo que lleva terminar el tatuaje puede ser de meses o hasta años; no se tatúa con una sola aguja sino con varias. Los yakuzas llevan estos tatuajes para demostrar que pueden soportar el dolor.

En la actualidad, la yakuza está dividida en 3000 clanes con un total de 100 000 miembros. El más importante es el denominado Yamaguchi-gumi, el cual se estima en un tamaño de 40 000 miembros activos; se considera el mayor grupo del mundo dedicado a la mafia, no solo por el número de miembros, sino también por su poder económico. Son también importantes los clanes Sumiyoshi Rengo-Kai e Inagawa-kai, que en conjunto con el clan Yamaguchi-gumi, mueven alrededor de 15 000 millones de dólares anuales.

A causa del Terremoto de Japón de 2011, los distintos grupos yakuza se movilizaron anónimamente en tareas de ayuda a las poblaciones afectadas.

A continuación se listan los clanes yakuza más importantes, ordenados según el número de miembros que los integran:




</doc>
<doc id="28196" url="https://es.wikipedia.org/wiki?curid=28196" title="Jardines Colgantes de Babilonia">
Jardines Colgantes de Babilonia

Los Jardines Colgantes de Babilonia son una de las siete maravillas del mundo antiguo, fueron construidos en el siglo VI a. C durante el reinado de Nabucodonosor II en la antigua ciudad de Babilonia (Babel de los textos bíblicos), a orillas del río Éufrates (Mesopotamia). Las aguas para regar las plantas eran traídas desde las orillas del río Éufrates, que se encontraba en las faldas de la montaña. En los jardines se plantaban palmeras y árboles frutales, como el dátil y los cocos.

Se cree que sus diseños y construcciones se iniciaron en 600 a. C., por orden del rey Nabucodonosor II de la dinastía caldea del Imperio neobabilónico, como muestra de amor hacia su esposa Amitis, hija del rey Ciáxares del Imperio medo (Media o "Umman Manda"), para recordarle las montañas de su tierra. Es considerada una de las siete maravillas del mundo antiguo junto con la Gran Pirámide de Guiza, el templo de Artemisa en Éfeso, la estatua de Zeus en Olimpia, el Mausoleo de Halicarnaso, el Coloso de Rodas y el Faro de Alejandría.

Hacia el año 600 a. C., Nabucodonosor II, rey de los caldeos, quiso hacer a su esposa Amitis, hija del rey de los medos, un regalo que demostrara su amor por ella y le recordara las hermosas montañas de su florida tierra, tan diferentes de las grandes llanuras de Babilonia..

Según otra leyenda, en cambio, los jardines habrían sido creados en el siglo IX a. C. Cerca de 810 a. C., reinaba Sammuramat en Asiria y Babilonia, llamada Semíramis por los griegos, viuda de Shamshiadad V, y regente de su hijo Adad-nirari III. Fue una reina valiente. Se dice que conquistó India y Egipto, pero no resistió que su hijo conspirara para derrotarla, y se suicidó.

Los jardines pertenecían a la Mesopotamia antigua y se cuentan entre la siete maravillas del mundo antiguo.

Los jardines estaban junto al palacio del Rey, contiguo al río, para que los viajeros los pudieran contemplar, ya que el acceso al pueblo estaba prohibido.
En la más alta de las terrazas se situaba un depósito de agua desde el cual corrían varios arroyos.

Los Jardines Colgantes de Babilonia no "colgaban" realmente en el sentido de estar suspendidos por cables o cuerdas. El nombre proviene de una traducción incorrecta de la palabra griega "kremastos" o del término en latín "pensilis", que no significa exactamente "colgar" pero si "sobresalir", como en el caso de una terraza o de un balcón.

El geógrafo griego Estrabón, quién describió los jardines en el siglo I a. C., escribió:
Las excavaciones arqueológicas más recientes en la antigua ciudad de Babilonia, en el actual territorio de Irak, destaparon el asentamiento del palacio. Otros hallazgos incluyen la construcción abovedada con paredes gruesas y una irrigación cerca del palacio meridional.

Un grupo de arqueólogos examinó el área meridional del palacio y recreó la construcción abovedada como los Jardines Colgantes. Sin embargo, el historiador griego Estrabón había indicado que los jardines estaban situados en el río Éufrates, mientras que la construcción abovedada está alejada varios cientos de metros. Reconstruyeron el lugar del palacio y localizaron los jardines en el área que se extendía del río al palacio.

En la orilla del río, las paredes recientemente descubiertas de 25 metros de espesor pudieron estar escalonadas en forma de terrazas, tal y como las describen las referencias griegas. Sin embargo, hay pocas pruebas para cualquiera de estas teorías, pues no se menciona nada en los numerosos documentos babilónicos de la época.

Con la posible decadencia de Babilonia y el fin del Imperio neobabilónico, los jardines fueron abandonados progresivamente. Cuando Alejandro Magno llegó a la ciudad en el siglo IV a.C., los jardines ya estaban parcialmente en ruinas y totalmente abandonados. Finalmente los jardines fueron destruidos por el rey Evemero en el año 126 a. C.



</doc>
<doc id="28197" url="https://es.wikipedia.org/wiki?curid=28197" title="Consentimiento informado">
Consentimiento informado

El consentimiento informado es el procedimiento mediante el cual se garantiza que el sujeto ha expresado voluntariamente su intención de participar en una investigación, después de haber comprendido la información que se le ha dado acerca de los objetivos de la misma, los beneficios, las molestias, los posibles riesgos y las alternativas, sus derechos y responsabilidades.

En algunos casos, tales como el examen físico de un médico, el consentimiento es tácito y sobreentendido. Para procedimientos más invasivos o aquellos asociados a riesgos significativos o que tienen implicados alternativas, el consentimiento informado debe ser presentado por escrito y firmado por el paciente.

Bajo ciertas circunstancias, se presentan excepciones al consentimiento informado. Los casos más frecuentes son las emergencias médicas donde se requiere atención médica inmediata para prevenir daños serios o irreversibles, así como en casos donde por razón de incapacidad de hecho o biológica, el sujeto no es capaz de dar o negar permiso para un examen o tratamiento.

Consentimiento médico informado es el documento mediante el cual se garantiza que el candidato y/o trabajador, es informado y acepta voluntariamente la realización de las evaluaciones médicas ocupacionales después de haber comprendido la información que se le ha dado, acerca de los objetivos del examen, los beneficios, y las directrices a seguir.

El consentimiento informado tiene sus raíces legales en 1947 con el Código de Núremberg, a través del cual se juzgó a un grupo de médicos acusados de realizar experimentos caracterizados como crímenes en contra de la humanidad, cometidos contra prisioneros de guerra en campos de concentración nazis durante la Segunda Guerra Mundial, los cuales se realizaban sin información o consentimiento sobre los riesgos a los que se enfrentaban las víctimas.

En 1964 se promulgó en la Asamblea Médica Mundial la Declaración de Helsinki, que ha sido modificada en varias ocasiones, agrupando un conjunto de reglamentos que orientan a los médicos en experimentos con seres humanos, y resalta la importancia del consentimiento voluntario dentro de los protocolos de estudio.
La primera sentencia del consentimiento informado tuvo lugar en las islas británicas en 1767 en el caso Slater vs. Baker & Stapleton (Cfr. Galán Cortés Julio César, Responsabilidad civil médica), pero el documento se perdió.

El consentimiento informado debe reunir al menos cuatro requisitos que son:

Estudios a nivel internacional demuestran que hay una fuerte tendencia a considerar el consentimiento informado como una herramienta que protege a los proveedores de salud de problemas legales y reclamos, en vez de un proceso en el que se toman las decisiones en forma conjunta y responsable por parte del paciente y el profesional. Dado el aumento en los últimos años de las demandas contra profesionales sanitarios, éstos se protegen con la práctica de la llamada "medicina defensiva".

Todo paciente tiene el derecho a no ser informado si así lo expresa previamente, es decir, el paciente puede revocar libremente por escrito su consentimiento en cualquier momento. En caso de que el paciente posea un riesgo para la salud pública, se admite la ausencia del consentimiento informado para el internamiento, cuarentena u hospitalización del paciente. En caso de riesgo inmediato grave para la integridad física o psíquica del paciente, el consentimiento puede obviarse. En caso de pacientes menores de edad o de incapacidad del paciente legalmente reconocida, física o mental, se admite que el consentimiento informado sea pedido a su representante legal, que será generalmente el familiar más próximo. En caso de riesgo grave para la salud pública o la vida del paciente el consentimiento del representante legal solo se tendrá en cuenta.

El consentimiento informado está basado en el principio de autonomía, es decir, el derecho del paciente a ser reconocido como persona libre y dueña de tomar sus decisiones. El paciente debe estar en condiciones de comunicar su decisión y éste ha sido informado adecuadamente de sus opciones, es decir, no pueden ser decisiones hechas como resultado de delirio o alucinaciones. La decisión del paciente es consistente con sus valores y metas y se mantiene estable en el tiempo si no ha habido modificaciones hechas por el mismo sujeto. Los familiares de un paciente no están en el derecho de requerir al médico del paciente que no se le comunique ciertos detalles o información al mismo.

Los componentes de la capacidad de tomar decisiones incluye la habilidad de comprender las opciones, de entender las consecuencias de escoger una u otra opción y poder evaluar el costo y beneficio personal de cada consecuencia y relacionarla a sus valores y prioridades.

En algunos casos cuando el paciente no es capaz de comprender los componentes y opciones que le son presentadas, sus familiares o representantes designadas por una corte pueden servir para tomar decisiones por el individuo.

La capacidad de tomar decisiones se conoce legalmente como «competencia». El término se usa a menudo de manera amplia en la medicina para indicar si una persona tiene capacidad de decisión. Técnicamente, una persona solo puede ser declarada "incompetente" por un tribunal de justicia.

El informe Belmont estadounidense identificó los principios éticos básicos a tener en cuenta durante una investigación biomédica y los catalogó «de beneficio» (beneficencia y no maleficencia), «de respeto por las personas» (autonomía) y «de equidad» (justicia). El principio de beneficencia se refiere a la obligación ética de medir la relación riesgo/beneficio, es decir, lograr los máximos beneficios y de reducir al mínimo el daño y la equivocación. De manera que el diseño de la investigación sea acertado y que los investigadores sean competentes, tanto para realizar la investigación como para salvaguardar el bienestar de las personas que participan en ella.

El proceso de consentimiento informado se consideran uno de los principios de autonomía, que obliga a la selección equitativa de los sujetos de investigación.

Para muchos procedimientos, como exámenes de sangre de rutina, radiografías, y férulas o yesos, el consentimiento suele estar implícito. Para otras pruebas invasivas o para tratamientos con riesgo significativo, se le debe dar un formulario de consentimiento escrito al paciente y una explicación verbal, de preferencia en su idioma nativo. Por lo general, se incluye en el formulario de consentimiento informado una explicación de la condición médica que justifique la prueba, procedimiento o tratamiento, así como una explicación de la finalidad y los beneficios de la prueba propuesta de procedimiento o tratamiento. El profesional de la salud suele verse obligado a dar una explicación o descripción de la prueba procedimiento o tratamiento propuesto, incluyendo las posibles complicaciones o efectos adversos y una descripción de las opciones alternativas, si las hubiere, y sus beneficios y riesgos relativos, así como un análisis de las consecuencias de no aceptar la prueba, procedimiento o tratamiento en cuestión.

El formulario de consentimiento debe estar firmado y fechado tanto por el profesional de la salud como por el paciente o su representante legal. Una copia del formulario de consentimiento firmado siempre está disponible para el paciente y su médico.

Salvo para tratamientos autorizados legalmente de manera involuntaria, los pacientes legalmente competentes para tomar decisiones médicas o que sean calificados por los proveedores salud de tener la capacidad de decisión, tienen el derecho legal y moral de rechazar cualquier tratamiento. Esto aplica incluso si el paciente opta por hacer una "mala decisión" que pueda resultar en una discapacidad grave o incluso la muerte.

Con el fin de documentar que se le ha dado al paciente la opción de obtener un tratamiento recomendado, y ha optado por rechazarlo, se le suele pedir que firme un formulario «contra opinión médica», que es la forma de proteger al médico de responsabilidad legal de no proporcionar el procedimiento en cuestión. El rechazar una prueba, tratamiento o procedimiento no significa necesariamente que se niegan todos los cuidados. Se espera que se le ofrezca al paciente las mejores opciones disponibles después de rechazar la ofrecida en inicio.

Si a causa de la intoxicación, lesión, enfermedad, estrés emocional, u otra razón, un proveedor de cuidado de salud decide que un paciente no tiene capacidad de decisión, el paciente puede no ser capaz de rechazar el tratamiento. por lo general, la ley presume que una persona razonable diera consentimiento para tratamientos en la mayoría de las situaciones de emergencia para prevenir la discapacidad permanente o muerte.

En una declaración jurada o documento de voluntades anticipadas se puede dejar en escrito la voluntad de un sujeto antes de que ocurra una emergencia. Estos documentos legales encaminan a los médicos y otros proveedores de atención de salud en cuanto a qué tratamientos específicos el individuo desea o rechaza, en caso de enfermedad o lesión que le impida tener la capacidad de decisión.





</doc>
<doc id="28198" url="https://es.wikipedia.org/wiki?curid=28198" title="Computación paralela">
Computación paralela

La computación paralela es una forma de cómputo en la que muchas instrucciones se ejecutan simultáneamente, operando sobre el principio de que problemas grandes, a menudo se pueden dividir en unos más pequeños, que luego son resueltos simultáneamente (en paralelo). Hay varias formas diferentes de computación paralela: paralelismo a nivel de bit, paralelismo a nivel de instrucción, paralelismo de datos y paralelismo de tareas. El paralelismo se ha empleado durante muchos años, sobre todo en la computación de altas prestaciones, pero el interés en ella ha crecido últimamente debido a las limitaciones físicas que impiden el aumento de la frecuencia.Como el consumo de energía —y por consiguiente la generación de calor— de las computadoras constituye una preocupación en los últimos años, la computación en paralelo se ha convertido en el paradigma dominante en la arquitectura de computadores, principalmente en forma de procesadores multinúcleo.

Las computadoras paralelas pueden clasificarse según el nivel de paralelismo que admite su hardware: equipos con procesadores multinúcleo y multi-procesador que tienen múltiples elementos de procesamiento dentro de una sola máquina y los clústeres, MPPS y "grids" que utilizan varios equipos para trabajar en la misma tarea. Muchas veces, para acelerar tareas específicas, se utilizan arquitecturas especializadas de computación en paralelo junto a procesadores tradicionales.

Los programas informáticos paralelos son más difíciles de escribir que los secuenciales, porque la concurrencia introduce nuevos tipos de errores de software, siendo las condiciones de carrera los más comunes. La comunicación y sincronización entre diferentes subtareas son algunos de los mayores obstáculos para obtener un buen rendimiento del programa paralelo.

La máxima aceleración posible de un programa como resultado de la paralelización se conoce como la ley de Amdahl.

Tradicionalmente, los programas informáticos se han escrito para el cómputo en serie. Para resolver un problema, se construye un algoritmo y se implementa como un flujo en serie de instrucciones. Estas instrucciones se ejecutan en una unidad central de procesamiento en un ordenador. Sólo puede ejecutarse una instrucción a la vez y un tiempo después de que la instrucción ha terminado, se ejecuta la siguiente.

La computación en paralelo, por el contrario, utiliza simultáneamente múltiples elementos de procesamiento para resolver un problema. Esto se logra mediante la división del problema en partes independientes de modo que cada elemento de procesamiento pueda ejecutar su parte del algoritmo de manera simultánea con los otros. Los elementos de procesamiento son diversos e incluyen recursos tales como una computadora con múltiples procesadores, varios ordenadores en red, hardware especializado, o cualquier combinación de los anteriores.

El aumento de la frecuencia fue la razón dominante de las mejoras en el rendimiento de las computadoras desde mediados de 1980 hasta el año 2004. El tiempo de ejecución de un programa es igual al número de instrucciones multiplicado por el tiempo promedio por instrucción. Manteniendo todo lo demás constante, el aumento de la frecuencia de reloj reduce el tiempo medio que tarda en ejecutarse una instrucción, por tanto un aumento en la frecuencia reduce el tiempo de ejecución de los programas de cómputo.

Sin embargo, el consumo de energía de un chip está dada por la ecuación P = C × V × F, donde P es la potencia, C es el cambio de capacitancia por ciclo de reloj —proporcional al número de transistores cuyas entradas cambian—, V es la tensión, y F es la frecuencia del procesador (ciclos por segundo).Un aumento en la frecuencia aumenta la cantidad de energía utilizada en un procesador. El aumento del consumo de energía del procesador llevó a Intel en mayo del 2004 a la cancelación de sus procesadores Tejas y Jayhawk, este hecho generalmente se cita como el fin del escalado de frecuencia como el paradigma dominante de arquitectura de computadores.

La ley de Moore es la observación empírica de que la densidad de transistores en un microprocesador se duplica cada 18 a 24 meses. A pesar de los problemas de consumo de energía, y las repetidas predicciones de su fin, la ley de Moore sigue vigente. Con el fin del aumento de la frecuencia, estos transistores adicionales —que ya no se utilizan para el aumento de la frecuencia— se pueden utilizar para añadir hardware adicional que permita la computación paralela.

Idealmente, la aceleración a partir de la paralelización es lineal, doblar el número de elementos de procesamiento debe reducir a la mitad el tiempo de ejecución y doblarlo por segunda vez debe nuevamente reducir el tiempo a la mitad. Sin embargo, muy pocos algoritmos paralelos logran una aceleración óptima. La mayoría tienen una aceleración casi lineal para un pequeño número de elementos de procesamiento, y pasa a ser constante para un gran número de elementos de procesamiento.

La aceleración potencial de un algoritmo en una plataforma de cómputo en paralelo está dada por la ley de Amdahl, formulada originalmente por Gene Amdahl en la década de 1960. Esta señala que una pequeña porción del programa que no pueda paralelizarse va a limitar la aceleración que se logra con la paralelización. Los programas que resuelven problemas matemáticos o ingenieriles típicamente consisten en varias partes paralelizables y varias no paralelizables (secuenciales). Si formula_1 es la fracción de tiempo que un programa gasta en partes no paralelizables, luego

es la máxima aceleración que se puede alcanzar con la paralelización del programa. Si la parte secuencial del programa abarca el 10% del tiempo de ejecución, se puede obtener no más de 10× de aceleración, independientemente de cuántos procesadores se añadan. Esto pone un límite superior a la utilidad de añadir más unidades de ejecución paralelas. «Cuando una tarea no puede divididirse debido a las limitaciones secuenciales, la aplicación de un mayor esfuerzo no tiene efecto sobre la programación. La gestación de un niño toma nueve meses, no importa cuántas mujeres se le asigne».

La ley de Gustafson es otra ley en computación que está en estrecha relación con la ley de Amdahl. Señala que el aumento de velocidad con formula_3 procesadores es

Ambas leyes asumen que el tiempo de funcionamiento de la parte secuencial del programa es independiente del número de procesadores. La ley de Amdahl supone que todo el problema es de tamaño fijo, por lo que la cantidad total de trabajo que se hará en paralelo también es independiente del número de procesadores, mientras que la ley de Gustafson supone que la cantidad total de trabajo que se hará en paralelo varía linealmente con el número de procesadores.

Entender la dependencia de datos es fundamental en la implementación de algoritmos paralelos. Ningún programa puede ejecutar más rápidamente que la cadena más larga de cálculos dependientes (conocida como la ruta crítica), ya que los cálculos que dependen de cálculos previos en la cadena deben ejecutarse en orden. Sin embargo, la mayoría de los algoritmos no consisten sólo de una larga cadena de cálculos dependientes; generalmente hay oportunidades para ejecutar cálculos independientes en paralelo.

Sea P y P dos segmentos del programa. Las condiciones de Bernstein describen cuando los dos segmentos son independientes y pueden ejecutarse en paralelo. Para "P", sean "I" todas las variables de entrada y "O" las variables de salida, y del mismo modo para "P". "P" y "P" son independientes si satisfacen


Una violación de la primera condición introduce una dependencia de flujo, correspondiente al primer segmento que produce un resultado utilizado por el segundo segmento. La segunda condición representa una anti-dependencia, cuando el segundo segmento ("P") produce una variable que necesita el primer segmento ("P"). La tercera y última condición representa una dependencia de salida: Cuando dos segmentos escriben en el mismo lugar, el resultado viene del último segmento ejecutado.

Considere las siguientes funciones, que demuestran varios tipos de dependencias:

La operación 3 en Dep(a, b) no puede ejecutarse antes de —o incluso en paralelo con— la operación 2, ya que en la operación 3 se utiliza un resultado de la operación 2. Esto viola la condición 1, y por tanto introduce una dependencia de flujo.

En este ejemplo, no existen dependencias entre las instrucciones, por lo que todos ellos se pueden ejecutar en paralelo.

Las condiciones de Bernstein no permiten que la memoria se comparta entre los diferentes procesos. Por esto son necesarios algunos medios que impongan un ordenamiento entre los accesos tales como semáforos, barreras o algún otro método de sincronización.

Las subtareas en un programa paralelo a menudo son llamadas hilos. Algunas arquitecturas de computación paralela utilizan versiones más pequeñas y ligeras de hilos conocidas como hebras, mientras que otros utilizan versiones más grandes conocidos como procesos. Sin embargo, «hilos» es generalmente aceptado como un término genérico para las subtareas. Los hilos a menudo tendrán que actualizar algunas variables que se comparten entre ellos. Las instrucciones entre los dos programas pueden entrelazarse en cualquier orden. Por ejemplo, considere el siguiente programa:

Si la instrucción 1B se ejecuta entre 1A y 3A, o si la instrucción 1A se ejecuta entre 1B y 3B, el programa va a producir datos incorrectos. Esto se conoce como una condición de carrera. El programador debe utilizar un bloqueo ("lock") para proporcionar exclusión mutua. Un bloqueo es una construcción del lenguaje de programación que permite a un hilo de tomar el control de una variable y evitar que otros hilos la lean o escriban, hasta que la variable esté desbloqueado. El hilo que mantiene el bloqueo es libre de ejecutar su sección crítica —la sección de un programa que requiere acceso exclusivo a alguna variable—, y desbloquear los datos cuando termine. Por lo tanto, para garantizar la correcta ejecución del programa, el programa anterior se puede reescribir usando bloqueos:

Un hilo bloqueará con éxito la variable V, mientras que el otro hilo no podrá continuar hasta que V se desbloquee. Esto garantiza la correcta ejecución del programa. Si bien los bloqueos son necesarios para asegurar la ejecución correcta del programa, pueden ralentizar en gran medida un programa.

Bloquear múltiples variables utilizando cerraduras no atómicas introduce la posibilidad de que el programa alcance un bloqueo mutuo ("deadlock"). Un bloqueo atómico bloquea múltiples variables a la vez, si no puede bloquearlas todas, no se bloquea ninguna de ellas. Si hay dos hilos y cada uno necesita bloquear las mismas dos variables utilizando cerraduras no atómicas, es posible que un hilo bloquee uno de ellas y el otro bloquee la segunda variable. En tal caso se produce un bloqueo mutuo donde ningún hilo puede completar la ejecución.

Muchos programas paralelos requieren que sus subtareas actúen en sincronía. Esto requiere el uso de una barrera. Las barreras se implementan normalmente mediante un bloqueo. Una clase de algoritmos, conocida como algoritmos libres de bloqueo y libres de espera, evitan el uso de bloqueos y barreras. Sin embargo, este enfoque es generalmente difícil de implementar y requiere estructuras de datos correctamente diseñadas.

No todas las paralelizaciones conllevan una aceleración. Por lo general, mientras una tarea se divida en cada vez más hilos, estos hilos pasan una porción cada vez mayor de su tiempo comunicándose entre sí. Eventualmente, la sobrecarga de comunicación domina el tiempo empleado para resolver el problema, y la paralelización adicional —dividir la carga de trabajo entre incluso más hilos— aumenta la cantidad de tiempo requerido para terminar. Esto se conoce como desaceleración paralela.

Las aplicaciones a menudo se clasifican según la frecuencia con que sus subtareas se sincronizan o comunican entre sí. Una aplicación muestra un paralelismo de grano fino si sus subtareas deben comunicase muchas veces por segundo, se considera paralelismo de grano grueso si no se comunican muchas veces por segundo, y es vergonzosamente paralelo si nunca o casi nunca se tienen que comunicar. Aplicaciones vergonzosamente paralelas son consideradas las más fáciles de paralelizar.

Los lenguajes de programación en paralelo y computadoras paralelas deben tener un modelo de consistencia de datos —también conocido como un modelo de memoria—. El modelo de consistencia define reglas para las operaciones en la memoria del ordenador y cómo se producen los resultados.

Uno de los primeros modelos de consistencia fue el modelo de consistencia secuencial de Leslie Lamport. La consistencia secuencial es la propiedad de un programa en la que su ejecución en paralelo produce los mismos resultados que un programa secuencial. Específicamente, es un programa secuencial consistente si «... los resultados de una ejecución son los mismos que se obtienen si las operaciones de todos los procesadores son ejecutadas en un orden secuencial, y las operaciones de cada procesador individual aparecen en esta secuencia en el orden especificado por el programa».

La memoria transaccional es un tipo de modelo de consistencia. La memoria transaccional toma prestado de la teoría de base de datos el concepto de transacciones atómicas y las aplica a los accesos a memoria.

Matemáticamente, estos modelos se pueden representar de varias maneras. Las Redes de Petri, que se introdujeron en 1962 como tesis doctoral de Carl Adam Petri, fueron un primer intento de codificar las reglas de los modelos de consistencia. Más tarde fueron creadas las arquitecturas de flujo de datos para implementar físicamente las ideas de la teoría del flujo de datos. A principios de la década de 1970, los cálculos de procesos tales como la Comunicación de Sistemas y Comunicación de Procesos Secuenciales se desarrollaron para permitir un razonamiento algebraico sobre sistemas compuestos por elementos que interactúan entre sí. Adiciones más recientes a la familia de cálculo de proceso, como el cálculo-π, han añadido la capacidad para razonar acerca de las topologías dinámicas. Lógicas tales como la TLA+ de Lamport, y modelos matemáticos se han desarrollado para describir el comportamiento de sistemas concurrentes.

Michael J. Flynn creó uno de los primeros sistemas de clasificación de computadoras, programas paralelos y secuenciales, ahora conocida como la taxonomía de Flynn. Flynn clasifica los programas y computadoras atendiendo a si están operando con uno o varios conjuntos de instrucciones y si esas instrucciones se utilizan en una o varias series de datos.

La clasificación instrucción-única-dato-único (SISD) es equivalente a un programa totalmente secuencial. La clasificación instrucción-única-datos-múltiples (SIMD) es análoga a hacer la misma operación varias veces sobre un conjunto de datos grande. Esto se hace comúnmente en aplicaciones de procesamiento de señales. Instrucciones-múltiples-dato-único (MISD) es una clasificación que rara vez se utiliza. A pesar de que se diseñaron arquitecturas de computadoras en esta categoría —como arreglos sistólicos—, muy pocas aplicaciones se materializaron. Los programas instrucciones-múltiples-datos-múltiples (MIMD) constituyen el tipo más común de programas paralelos.

Según David A. Patterson y John L. Hennessy, «Algunas máquinas son híbridos de estas categorías, por supuesto, este modelo clásico ha sobrevivido porque es simple, fácil de entender, y da una buena primera aproximación. Además, es, tal vez por su comprensibilidad, el esquema más utilizado.»

Desde el advenimiento de la integración a gran escala (VLSI) como tecnología de fabricación de chips de computadora en la década de 1970 hasta alrededor de 1986, la aceleración en la arquitectura de computadores se lograba en gran medida duplicando el tamaño de la palabra en la computadora, la cantidad de información que el procesador puede manejar por ciclo. El aumento del tamaño de la palabra reduce el número de instrucciones que el procesador debe ejecutar para realizar una operación en variables cuyos tamaños son mayores que la longitud de la palabra. Por ejemplo, cuando un procesador de 8 bits debe sumar dos enteros de 16 bits, el procesador primero debe adicionar los 8 bits de orden inferior de cada número entero con la instrucción de adición, a continuación, añadir los 8 bits de orden superior utilizando la instrucción de adición con acarreo que tiene en cuenta el bit de acarreo de la adición de orden inferior, en este caso un procesador de 8 bits requiere dos instrucciones para completar una sola operación, en donde un procesador de 16 bits necesita una sola instrucción para poder completarla.

Históricamente, los microprocesadores de 4 bits fueron sustituidos por unos de 8 bits, luego de 16 bits y 32 bits, esta tendencia general llegó a su fin con la introducción de procesadores de 64 bits, lo que ha sido un estándar en la computación de propósito general durante la última década.

Un programa de ordenador es, en esencia, una secuencia de instrucciones ejecutadas por un procesador. Estas instrucciones pueden reordenarse y combinarse en grupos que luego son ejecutadas en paralelo sin cambiar el resultado del programa. Esto se conoce como paralelismo a nivel de instrucción. Los avances en el paralelismo a nivel de instrucción dominaron la arquitectura de computadores desde mediados de 1980 hasta mediados de la década de 1990.

Los procesadores modernos tienen "pipeline" de instrucciones de varias etapas. Cada etapa en el "pipeline" corresponde a una acción diferente que el procesador realiza en la instrucción correspondiente a la etapa; un procesador con un "pipeline" de N etapas puede tener hasta n instrucciones diferentes en diferentes etapas de finalización. El ejemplo canónico de un procesador segmentado es un procesador RISC, con cinco etapas: pedir instrucción, decodificar, ejecutar, acceso a la memoria y escritura. El procesador Pentium 4 tenía un "pipeline" de 35 etapas.

Además del paralelismo a nivel de instrucción del "pipelining", algunos procesadores pueden ejecutar más de una instrucción a la vez. Estos son conocidos como procesadores superescalares. Las instrucciones pueden agruparse juntas sólo si no hay dependencia de datos entre ellas. El "scoreboarding" y el algoritmo de Tomasulo —que es similar a "scoreboarding" pero hace uso del renombre de registros— son dos de las técnicas más comunes para implementar la ejecución fuera de orden y la paralelización a nivel de instrucción.

El paralelismo de datos es el paralelismo inherente en programas con ciclos, que se centra en la distribución de los datos entre los diferentes nodos computacionales que deben tratarse en paralelo. «La paralelización de ciclos conduce a menudo a secuencias similares de operaciones —no necesariamente idénticas— o funciones que se realizan en los elementos de una gran estructura de datos». Muchas de las aplicaciones científicas y de ingeniería muestran paralelismo de datos.

Una dependencia de terminación de ciclo es la dependencia de una iteración de un ciclo en la salida de una o más iteraciones anteriores. Las dependencias de terminación de ciclo evitan la paralelización de ciclos. Por ejemplo, considere el siguiente pseudocódigo que calcula los primeros números de Fibonacci:

Este bucle no se puede paralelizar porque CUR depende de sí mismo (PREV2) y de PREV1, que se calculan en cada iteración del bucle. Dado que cada iteración depende del resultado de la anterior, no se pueden realizar en paralelo. A medida que el tamaño de un problema se hace más grande, la paralelización de datos disponible generalmente también lo hace.

El paralelismo de tareas es la característica de un programa paralelo en la que «cálculos completamente diferentes se pueden realizar en cualquier conjunto igual o diferente de datos». Esto contrasta con el paralelismo de datos, donde se realiza el mismo cálculo en distintos o mismos grupos de datos. El paralelismo de tareas por lo general no escala con el tamaño de un problema.

La memoria principal en un ordenador en paralelo puede ser compartida —compartida entre todos los elementos de procesamiento en un único espacio de direcciones—, o distribuida —cada elemento de procesamiento tiene su propio espacio local de direcciones—.El término memoria distribuida se refiere al hecho de que la memoria se distribuye lógicamente, pero a menudo implica que también se distribuyen físicamente. La memoria distribuida-compartida y la virtualización de memoria combinan los dos enfoques, donde el procesador tiene su propia memoria local y permite acceso a la memoria de los procesadores que no son locales. Los accesos a la memoria local suelen ser más rápidos que los accesos a memoria no local.

Las arquitecturas de ordenador en las que cada elemento de la memoria principal se puede acceder con igual latencia y ancho de banda son conocidas como arquitecturas de acceso uniforme a memoria (UMA). Típicamente, sólo se puede lograr con un sistema de memoria compartida, donde la memoria no está distribuida físicamente. Un sistema que no tiene esta propiedad se conoce como arquitectura de acceso a memoria no uniforme (NUMA). Los sistemas de memoria distribuidos tienen acceso no uniforme a la memoria.

Los sistemas informáticos suelen hacer uso de cachés, pequeños recuerdos rápidos ubicados cerca del procesador que almacenan las copias temporales de los valores de la memoria —cercano, tanto en el sentido físico y lógico—. Los sistemas computacionales paralelos tienen dificultades con las cachés y la posibilidad de una ejecución incorrecta del programa debido a que se puede almacenar el mismo valor en más de un lugar. Estos equipos requieren coherencia en la caché del sistema, generalmente realizan un seguimiento de los valores almacenados en caché y estratégicamente los eliminan, garantizando la correcta ejecución del programa. "Bus sniffing" es uno de los métodos más comunes para hacer el seguimiento de los valores a los que se está accediendo. El diseño de grandes sistemas de coherencia caché y de alto rendimiento es un problema muy difícil en arquitectura de computadores. Como resultado, las arquitecturas de memoria compartida no son tan escalables como los sistemas de memoria distribuida.

La comunicación procesador-procesador y procesador-memoria se puede implementar en hardware de varias maneras: a través de memoria compartida —ya sea multipuerto o multiplexado—, un conmutador de barras cruzadas ("crossbar switch"), un bus compartido o una red interconectada de una gran variedad de topologías como estrella, anillo, árbol, hipercubo, hipercubo grueso —un hipercubo con más de un procesador en un nodo—, o de malla n-dimensional.

Las computadoras paralelas basadas en redes interconectadas deben tener algún tipo de enrutamiento para permitir el paso de mensajes entre nodos que no están conectados directamente. Es probable que el medio utilizado para la comunicación entre los procesadores de grandes máquinas multiprocesador sea jerárquico.

Las computadoras paralelas se pueden clasificar de acuerdo con el nivel en el que el hardware soporta paralelismo. Esta clasificación es análoga a la distancia entre los nodos básicos de cómputo. Estos no son excluyentes entre sí, por ejemplo, los grupos de multiprocesadores simétricos son relativamente comunes.

Un procesador multinúcleo es un procesador que incluye múltiples unidades de ejecución (núcleos) en el mismo chip. Los procesadores superescalares pueden ejecutar múltiples instrucciones por ciclo de un flujo de instrucciones (hilo), a diferencia de este, un procesador multinúcleo puede ejecutar múltiples instrucciones por ciclo de secuencias de instrucciones múltiples. Cada núcleo en un procesador multinúcleo potencialmente puede ser superescalar, es decir, en cada ciclo, cada núcleo puede ejecutar múltiples instrucciones de un flujo de instrucciones.

El "Multithreading" simultáneo —de la cual Intel HyperThreading es el más conocido— era una forma de pseudo-multinúcleo. Un procesador con capacidad de "multithreading" simultáneo tiene una sola unidad de ejecución (núcleo), pero cuando esa unidad de ejecución está desocupada —por ejemplo, durante un error de caché—, se utiliza para procesar un segundo hilo. El microprocesador Cell de IBM, diseñado para su uso en la consola Sony PlayStation 3, es otro prominente procesador multinúcleo.

Un multiprocesador simétrico (SMP) es un sistema computacional con múltiples procesadores idénticos que comparten memoria y se conectan a través de un bus. La contención del bus previene el escalado de esta arquitectura. Como resultado, los SMPs generalmente no comprenden más de 32 procesadores. «Debido al pequeño tamaño de los procesadores y de la significativa reducción en los requisitos de ancho de banda de bus, tales multiprocesadores simétricos son extremadamente rentables, siempre que exista una cantidad suficiente de ancho de banda».

Un clúster es un grupo de ordenadores débilmente acoplados que trabajan en estrecha colaboración, de modo que en algunos aspectos pueden considerarse como un solo equipo. Los clústeres se componen de varias máquinas independientes conectadas por una red. Mientras que las máquinas de un clúster tienen que ser simétricas, de no serlo, el balance de carga es más difícil de lograr. El tipo más común de clúster es el cluster Beowulf, que es un clúster implementado con múltiples ordenadores comerciales idénticos conectados a una red de área local TCP/IP Ethernet. La tecnología Beowulf fue desarrollada originalmente por Thomas Sterling y Donald Becker. La gran mayoría de los superordenadores "TOP500" son clústeres.

Un procesador paralelo masivo (MPP) es un solo equipo con varios procesadores conectados en red. Tienen muchas de las características de los clúster, pero cuentan con redes especializadas de interconexión —en tanto que las clústeres utilizan hardware estándar para la creación de redes—. Los MPPs también tienden a ser más grandes que los clústeres, con «mucho más» de 100 procesadores. En un MPP, «cada CPU tiene su propia memoria y una copia del sistema operativo y la aplicación. Cada subsistema se comunica con los demás a través de un interconexión de alta velocidad».

La computación distribuida es la forma más distribuida de la computación paralela. Se hace uso de ordenadores que se comunican a través de la Internet para trabajar en un problema dado. Debido al bajo ancho de banda y la latencia extremadamente alta de Internet, la computación distribuida normalmente sólo se refiere a problemas vergonzosamente paralelos. Se han creado muchas aplicaciones de computación distribuida, SETI@home y Folding@home son los ejemplos más conocidos.

La mayoría de las aplicaciones de computación distribuida utilizan "middleware", software que se encuentra entre el sistema operativo y la aplicación para administrar los recursos de red y estandarizar la interfaz de software. El más común es la Infraestructura Abierta de Berkeley para Computación en Red (BOINC). A menudo, los programas de computación distribuida hacen uso de «ciclos de repuesto», realizando cálculos cuando el procesador de un equipo está desocupado.

Dentro de la computación paralela, existen dispositivos paralelos especializados que generan interés. Aunque no son específicos para un dominio, tienden a ser aplicables sólo a unas pocas clases de problemas paralelos.

El cómputo reconfigurable es el uso de un arreglo de compuertas programables (FPGA) como coprocesador de un ordenador de propósito general. Un FPGA es, en esencia, un chip de computadora que puede reconfigurarse para una tarea determinada.

Los FPGAs se pueden programar con lenguajes de descripción de hardware como VHDL o Verilog. Sin embargo, los lenguajes de programación pueden ser tediosos. Varios vendedores han creado lenguajes «C a HDL» que tratan de emular la sintaxis y/o semántica del lenguaje de programación C, con el que la mayoría de los programadores están familiarizados. Los lenguajes «C a HDL» más conocidos son Mitrion-C, C Impulse, DIME C y C-Handel. También se pueden utilizar para este propósito subconjuntos específicos de SystemC basados en C++.

La decisión de AMD de abrir HyperTransport a otros fabricantes la ha convertido en la tecnología que permite la computación reconfigurable de alto rendimiento. De acuerdo con Michael D'Amour R., Director de Operaciones de la DRC Computer Corporation, «cuando entramos en AMD, nos llamaban ladrones de zócalos. Ahora nos llaman socios».

El cómputo de propósito general en las unidades de procesamiento de gráficos (GPGPU) es una tendencia relativamente reciente en la investigación de ingeniería informática. Los GPUs son co-procesadores que han sido fuertemente optimizados para procesamiento de gráficos por computadora. El procesamiento de gráficos por computadora es un campo dominado por operaciones sobre datos en paralelo, en particular de álgebra lineal y operaciones con matrices.

Al principio, los programas de GPGPU normalmente utilizaban el API de gráficos para ejecutar programas. Sin embargo, varios nuevos lenguajes de programación y plataformas se han construido para realizar cómputo de propósito general sobre GPUs, tanto Nvidia como AMD han liberado de entornos de programación con CUDA y Stream SDK, respectivamente. Otros lenguajes de programación de GPU incluyen: BrookGPU, PeakStream y RapidMind. Nvidia también ha lanzado productos específicos para la computación en su serie Tesla. El consorcio de tecnología Khronos Group ha lanzado OpenCL, que es un marco para la escritura de programas que se ejecutan en distintas plataformas conformadas por CPUs y GPUs. AMD, Apple, Intel, Nvidia y otros están apoyando OpenCL.

Se han diseñado varios circuitos integrados de aplicación específica (ASIC) para hacer frente a las aplicaciones paralelas.

Debido a que un ASIC (por definición) es específico para una aplicación dada, puede ser completamente optimizado para esa aplicación. Como resultado, para una aplicación dada, un ASIC tiende a superar a un ordenador de propósito general. Sin embargo, los ASICs son creados con litografía de rayos X. Este proceso requiere una máscara, que puede ser extremadamente cara. Una máscara puede costar más de un millón de dólares. Mientras más pequeño sean los transistores necesarios para el chip, más cara será la máscara. Mientras tanto, el incremento del rendimiento en computadoras de propósito general —como se describe en la Ley de Moore— tiende a eliminar esta diferencia en sólo una o dos generaciones de chips. El alto costo inicial, y la tendencia a ser superados por la ley de Moore, ha hecho inviable el uso de ASICs para la mayoría de las aplicaciones paralelas. Sin embargo, algunos han sido construidos, un ejemplo es el peta-flop RIKEN MDGRAPE-3 de la máquina que utiliza ASICs para la simulación de dinámica molecular.

Un procesador vectorial es un CPU o un sistema computacional que puede ejecutar la misma instrucción en grandes conjuntos de datos. «Los procesadores vectoriales tienen operaciones de alto nivel que trabajan sobre arreglos lineales de números o vectores. Un ejemplo de operación con vectores es: "A" = "B" × "C", donde "A", "B", y "C" son vectores de 64 elementos, donde cada uno es un número de punto flotante de 64 bits». Están estrechamente relacionadas con la clasificación SIMD de Flynn.

Las computadoras Cray se volvieron famosas por su procesamiento de vectores en los años 1970 y 1980. Sin embargo, los procesadores vectoriales, tanto CPUs como sistemas computacionales, han desaparecido. Los conjuntos de instrucciones de los procesadores modernos incluyen algunas instrucciones de procesamiento de vectores, por ejemplo: AltiVec y Streaming SIMD Extensions (SSE).

Los lenguajes de programación concurrentes, bibliotecas, APIs y modelos de programación paralela han sido creados para la programación de computadores paralelos. Estos generalmente se pueden dividir en clases basadas en las suposiciones que se hacen sobre la arquitectura de memoria subyacente: compartida, distribuida, o compartida-distribuida. Los lenguajes de programación de memoria compartida se comunican mediante la manipulación de variables en la memoria compartida. En la arquitectura con memoria distribuida se utiliza el paso de mensajes. POSIX Threads y OpenMP son dos de las API más utilizadas con la memoria compartida, mientras que Message Passing Interface (MPI) «Interfaz de Paso de Mensajes» es el API más utilizado en los sistemas de paso de mensajes. El concepto «valor futuro» es muy utilizado en la programación de programas paralelos, donde una parte de un programa promete proporcionar un dato requerido a otra parte del programa en un tiempo futuro.

Las empresas CAPS entreprise y Pathscale están intentando convertir las directivas de HMPP (Hybrid Multicore Parallel Programming) en un estándar abierto denominado OpenHMPP. El modelo de programación OpenHMPP basado en directivas ofrece una sintaxis para descargar de manera eficiente los cálculos sobre aceleradores de hardware y optimizar el movimiento de datos hacia y desde la memoria del hardware. Las directivas OpenHMPP describen llamadas a procedimientos remotos (RPC) en un dispositivo acelerador —por ejemplo el GPU— o de forma más general un conjunto de núcleos. Las directivas permiten anotar código C o Fortran para describir dos grupos de funcionalidades: la descarga de los procedimientos en un dispositivo remoto y la optimización de las transferencias de datos entre la memoria principal de la CPU y la memoria del acelerador.

La paralelización automática de un programa secuencial por un compilador es el santo grial de la computación paralela. A pesar de décadas de trabajo por parte de los investigadores, la paralelización automática ha tenido un éxito limitado.

Los principales lenguajes de programación en paralelo permanecen explícitamente paralelos o en el mejor de los casos parcialmente implícitos, en los que un programador le da al compilador directivas de paralelización. Existen pocos lenguajes de programación paralelos totalmente implícitos: SISAL, Parallel Haskell, y (para FPGAs) Mitrion C.

Mientras un sistema computacional crece en complejidad, el tiempo medio entre fallos por lo general disminuye. Un punto de control de aplicación es una técnica mediante la cual el sistema informático toma una «instantánea» de la aplicación, un registro de todas las asignaciones actuales de recursos y estados variables, semejante a un volcado de memoria, esta información se puede utilizar para restaurar el programa si el equipo falla. Disponer de un punto de control significa que el programa puede reiniciar desde este y no desde el principio. Mientras que los puntos de control proporcionan beneficios en una variedad de situaciones, son especialmente útiles en los sistemas altamente paralelos con un gran número de procesadores que son utilizados en la computación de altas prestaciones.

Mientras que las computadoras paralelas se hacen más grandes y más rápidas, se hace factible resolver problemas que antes tardaban demasiado tiempo en ejecutarse. La computación en paralelo se utiliza en una amplia gama de campos, desde la bioinformática (plegamiento de proteínas y análisis de secuencia) hasta la economía (matemática financiera). Los tipos de problemas encontrados comúnmente en las aplicaciones de computación en paralelo son:

Los orígenes del verdadero paralelismo (MIMD) se remontan a Federico Luigi, Menabrea Conte y su «Bosquejo de la máquina analítica inventada por Charles Babbage». IBM introdujo el IBM 704 en 1954, a través de un proyecto en el que Gene Amdahl fue uno de los principales arquitectos. Se convirtió en el primer equipo disponible en el mercado que utilizaba comandos aritméticos de punto flotante totalmente automáticos.

En abril de 1958, S. Gill (Ferranti) analizó la programación en paralelo y la necesidad de la ramificación y la espera. También en 1958, los investigadores de IBM John Cocke y Daniel Slotnick discutieron por primera vez el uso del paralelismo en cálculos numéricos. Burroughs Corporation presentó la D825 en 1962, un equipo de cuatro procesadores que accede a un máximo de 16 módulos de memoria a través de un conmutador de barras cruzadas. En 1967, Amdahl y Slotnick publicaron un debate sobre la viabilidad de procesamiento en paralelo en la Conferencia de la Federación Americana de Sociedades de Procesamiento de la Información. Fue durante este debate que la Ley de Amdahl fue acuñada para definir los límites de aceleración que se pueden alcanzar debido al paralelismo.

En 1969, la compañía estadounidense Honeywell introdujo su primer sistema Multics, un sistema con multiprocesador simétrico capaz de ejecutar hasta ocho procesadores en paralelo.En 1970, C.mmp, un proyecto en la Universidad Carnegie Mellon con varios procesadores, fue «uno de los primeros multiprocesadores con más de unos pocos procesadores». «El primer bus con conexión multi-procesador y caché espía fue el Synapse N+1 en el año 1984».

Las computadoras paralelas SIMD se remontan a la década de 1970. La motivación detrás de las primeras computadoras SIMD era amortizar el retardo de la compuerta de la unidad de control del procesador en múltiples instrucciones. En 1964, Slotnick había propuesto la construcción de un ordenador masivamente paralelo para el Laboratorio Nacional Lawrence Livermore. Su diseño fue financiado por la Fuerza Aérea de los Estados Unidos, que fue el primer esfuerzo por lograr la computación en paralelo SIMD. La clave de su diseño fue un paralelismo bastante alto, con hasta 256 procesadores, lo que permitió que la máquina trabajara en grandes conjuntos de datos en lo que más tarde sería conocido como el procesamiento de vectores. Sin embargo, ILLIAC IV fue llamado «el más infame de los superordenadores», pues solo se había completado una cuarta parte del proyecto. Tardó 11 años, costando casi cuatro veces la estimación original. Cuando estaba listo para ejecutar una aplicación real por primera vez en 1976, fue superado por supercomputadoras comerciales, como el Cray-1.



</doc>
<doc id="28203" url="https://es.wikipedia.org/wiki?curid=28203" title="Dances with Wolves">
Dances with Wolves

Dances with Wolves (conocida como Bailando con Lobos en España y Danza con Lobos en Hispanoamérica) es una película estadounidense dirigida y protagonizada por Kevin Costner. Estrenada en 1990, la película está basada en la novela homónima de Michael Blake y recibió siete premios Óscar.

Durante la Guerra de Secesión estadounidense, el condecorado teniente John J. Dunbar (Kevin Costner) es enviado por el mayor Fambrough (Maury Chaykin) a un puesto avanzado en la frontera del territorio indio sin ningún tipo de compañía más que su fiel caballo "Cisco". Al llegar debía relevar al oficial al mando, pero se encuentra que el puesto está abandonado. El transportista de pertrechos que acompañaba a Dunbar es asesinado por fieros indios Pawnee apenas abandona a Dunbar.
El sentido del deber impulsa a Dunbar a mantener su puesto, y Dunbar lo convierte en un puesto militar limpio y ordenado, pero en completa soledad.

A medida que avanzan los días, traba amistad con un desconfiado lobo de pradera al que llama "Calcetines" y que lo acompaña en sus patrullas.

En una de sus patrullas, Dunbar rescata del suicidio a una mujer blanca que se ha naturalizado con los Sioux, llamada "Erguida con puño en alto", y la devuelve a su aldea de origen; además establece con dificultad una relación amistosa con un líder sioux llamado "Ave que patea" (Graham Greene) que ve la nobleza de alma de Dunbar y convence a su tribu para que lo admita. 
Así, Dunbar va conociendo más la cultura de su rival, descubre la esencia de vida de los Sioux y que la enemistad no debería existir entre ambos bandos.
Sin darse cuenta, Dunbar adopta el estilo de vida indio y éstos lo bautizan como "Danza con lobos" por su amistad con un lobo de pradera. Dunbar se enamora y se casa con "Erguida con puño en alto", pasando a ser un miembro más de la tribu. 
Pronto, Dunbar se dará cuenta del abismo de humanidad que existe entre el hombre blanco y los naturales y deberá decidir qué camino tomar.


La música de la película fue compuesta y dirigida por el renombrado compositor John Barry, que le reportó su cuarto Óscar de la academia, pasando a convertirse en una de sus obras más valoradas por el público. La edición de la partitura salió en 1990, pero posteriormente salió una reedición en 1995 y en 2004 que contenía toda la partitura en su totalidad.

Es una obra compuesta para orquesta sinfónica y presenta una factura y desarrollo clásicos, fieles a la tradición musical del género de las bandas sonoras. Se estructura a partir de varios temas: el de John Dunbar, Two Socks, Stands with The Fist Remember, los indios lakota y las praderas americanas. Barry se esforzó por dotar a la composición de una emotividad lo más compatible posible con los objetivos de Kevin Costner. Una de sus características es, paradójicamente, el no presentar música en ciertos pasajes de la película, reservándola para otros más pertinentes: presentación de personajes, transiciones entre secuencias, escenas de acción.

Su orquestación es típicamente "barryniana". Alterna de manera sencilla el metal (especialmente trombones y trompas) con tuttis de cuerda y adornos a base de percusiones y trompetas. En general, su ritmo es pausado y sentimental, pero contundente, como queriendo resaltar la sencillez de las emociones que pretende representar la película: libertad, amor, amistad, etc. Su sonido es americano, pero alejado del sonido western típico, acaso porque la película no es un western al uso, sino un drama épico ambientado en la frontera americana.

Este es el listado de canciones de la edición de 1995:


La canción "Journey To Fort Sedgewick" fue utilizada por Repsol en sus anuncios publicitarios durante los años 1990.




</doc>
<doc id="28204" url="https://es.wikipedia.org/wiki?curid=28204" title="Conflicto de interés">
Conflicto de interés

Un conflicto de interés es aquella situación en la que el juicio del individuo -concerniente a su interés primario- y la integridad de una acción tienden a estar indebidamente influidos por un interés secundario, de tipo generalmente económico o personal.

Existe conflicto de interés cuando en el ejercicio de las labores dentro de una institución, sobreviene una contraposición entre el interés propio e institucional. A continuación presentamos algunas situaciones que conllevan conflicto de interés:




</doc>
<doc id="28207" url="https://es.wikipedia.org/wiki?curid=28207" title="George Segal (actor)">
George Segal (actor)

George Segal, Jr. (Great Neck Plaza, Nueva York; 13 de febrero de 1934) es un actor estadounidense ganador del Globo de Oro. Nació en Great Neck, Long Island, en el estado de Nueva York. Es un gran intérprete del banjo. Mientras estudiaba en el colegio organizó un conjunto de música que cosechó muchos éxitos. Después estudió artes dramáticas en la Universidad de Columbia, en Nueva York, donde organizó nuevamente un grupo musical. Una vez terminados sus estudios se ganó la vida limpiando lavabos en un teatro de Nueva York, esperando que llegase su oportunidad.

Por fin, en 1955, Segal debutó en el teatro con la obra "Don Juan", de Molière. Al año siguiente actuó en otra obra, esta vez de Eugene O'Neill. A continuación tuvo que cumplir el servicio militar. A su regreso, consiguió participar en el festival Shakespeare de Nueva York, hasta que en 1960 tuvo su primer éxito importante en "The Premise", una obra con características de revista, que estuvo en cartel durante un plazo prolongado.

En 1961, Segal actuó en su primera película. En los años siguientes hizo varias películas más, aunque en todos los casos en papeles pequeños. En la película de Stanley Kramer de 1965 "Ship of Fools" ya comenzó a ser conocido. Sin embargo, fue con la película de ese mismo año "King Rat", una historia sobre la Segunda Guerra Mundial, con el que saltó a la fama como actor de cine. Mientras rodaba esas películas, Segal continuó actuando en el teatro, donde trabajó también con el director Mike Nichols, con quien coincidió en 1966 en el rodaje de "Quién teme a Virginia Woolf", película que cosechó varios Oscar.

En los años siguientes Segal intervino en multitud de películas, generalmente en papeles principales o secundarios importantes. Sus dotes de interpretación son extensas, y es capaz de actuar en papeles cómicos con la misma facilidad que en papeles dramáticos. Su aspecto risueño le ha hecho ganar la simpatía de las audiencias.

Segal fue introduciéndose también en la televisión, aunque hasta la década de los años 90 no comenzó a trabajar en serio en este medio. Desde entonces ha intervenido regularmente en una o dos producciones de películas o mini-series para la televisión cada año, hasta el extremo de que últimamente parece sentirse más a gusto en este medio que en el cine. Con sus intervenciones en televisión ha cosechado también un notable éxito.

Segal se casó en tres ocasiones. Con su primera esposa tuvo dos hijas. Su segundo matrimonio duró hasta 1996, año en que falleció su esposa. En ese mismo año se volvió a casar por tercera vez.

En el año 1974, se publica el LP "A Touch of Ragtime", figurando como "George Segal and the Imperial Jazzband". En la portada del disco se lo ve sonriente con un banjo. Entre otros, participa en este disco Harry Nilsson.



</doc>
<doc id="28209" url="https://es.wikipedia.org/wiki?curid=28209" title="Multiplexación">
Multiplexación

En telecomunicación, la multiplexación es la técnica de combinar dos o más señales, y transmitirlas por un solo medio de transmisión. La principal ventaja es que permite varias comunicaciones de forma simultánea, usando un dispositivo llamado multiplexor. El proceso inverso se conoce como demultiplexación. Un concepto muy similar es el de control de acceso al medio.

Existen muchas estrategias de multiplexación según el protocolo de comunicación empleado, que puede combinarlas para alcanzar el uso más eficiente; los más utilizados son:


Cuando existe un esquema o protocolo de multiplexación pensado para que múltiples usuarios compartan un medio común, como por ejemplo en telefonía móvil o WiFi, suele denominarse control de acceso al medio o método de acceso múltiple. Como métodos de acceso múltiple destacan:


En informática y electrónica, la multiplexación se refiere al mismo concepto si se trata de buses de datos que haya que compartir entre varios dispositivos (discos, memoria, etc.). Otro tipo de multiplexación en informática es el de la CPU, en la que a un proceso le es asignado un quantum de tiempo durante el cual puede ejecutar sus instrucciones, antes de ceder el sitio a otro proceso que esté esperando en la cola de procesos listo a ser despachado por el planificador de procesos. También en informática, se denomina multiplexar a combinar en un mismo archivo contenedor, varias pistas de dos archivos, por ejemplo de audio y vídeo, para su correcta reproducción, también en informática multiplexar un archivo, es una forma que se mantengan varias copias idénticas de este archivo, esto para respaldar información en caso de que ocurra un fallo en el archivo principal.

En las telecomunicaciones se usa la multiplexación para dividir las señales en el medio por el que vayan a viajar dentro del espectro radioeléctrico. El término es equivalente al control de acceso al medio.

De esta manera, para transmitir los canales de televisión por aire, vamos a tener un ancho de frecuencia x, el cual habrá que multiplexar para que entren la mayor cantidad posible de canales de TV. Entonces se dividen los canales en un ancho de banda de 6 MHz (en gran parte de Europa y América, mientras que en otros países el ancho de banda es de 8 MHz). En este caso se utiliza una multiplexación por división de frecuencia FDM.

Multiplexar un paquete de datos, significa tomar los datos de la capa de aplicación, etiquetarlos con un número de puerto (TCP o UDP) que identifica a la aplicación emisora, y enviar dicho paquete a la capa de red.



</doc>
<doc id="28210" url="https://es.wikipedia.org/wiki?curid=28210" title="Pedro y el lobo">
Pedro y el lobo

Pedro y el lobo (en ruso: Петя и волк) es una composición sinfónica de Serguéi Prokófiev (Op. 67) escrita en 1936. La obra de Prokófiev es una historia para niños, con música y texto adaptado por él, con un narrador acompañado por la orquesta. 

En 1935, Natalya Sats y el teatro central infantil de Moscú encargaron a Sergei Prokofiev una nueva sinfonía musical para niños. Se intentaba cultivar el gusto musical en los niños desde los primeros años de escuela. Intrigado por la invitación, Prokofiev completó "Pedro y el lobo" en cuatro días. El estreno se produjo el 2 de mayo de 1936, y su acogida fue desfavorable. En palabras del propio autor, «...[la asistencia] fue pobre y no consiguió atraer mucha atención».

"Pedro y el lobo" está escrita para una flauta, un oboe, un clarinete en la, un fagot, tres trompas en mi, un timbal y cuerdas para la alegoría de los personajes principales, y un acompañamiento de trompeta en si bemol, trombón, triángulo, pandereta, platillos, castañuelas, tambor de caja, y bombo en la orquestación.

Cada personaje de la historia tiene asignado un instrumento y un tema musical: 


Pedro, un joven pionero soviético, vive con su abuelo, que es leñador, en una casa en un claro del bosque. Un día Pedro sale de casa, dejando abierta la puerta del jardín, y se hace amigo de un pájaro. Un pato ve la puerta abierta y decide salir a nadar al estanque cercano. El pájaro y el pato empiezan a discutir: «¿qué clase de ave eres tú que no puedes volar?», a lo que el pato replica: «¿Qué clase de ave eres tú que no puedes nadar?». Entonces el gato de Pedro sale sigiloso intentando atrapar a las aves y Pedro les aconseja que se pongan a salvo, el pájaro vuela a un árbol y el pato nada al centro del estanque.

Entonces llega el abuelo y regaña a Pedro por estar en el prado, y le dice que afuera le puede atrapar el lobo del bosque. Pedro responde diciendo que no tiene miedo, que es muy valiente y puede atrapar al lobo. El abuelo lo mete en la casa de la oreja y cierra la puerta. Poco después en efecto aparece un enorme lobo, el gato se pone a salvo en un árbol, pero el lobo atrapa al pato y se lo come. Pedro presencia la escena mirando a través de una ranura de la puerta. 

Pedro se engancha a una cuerda y salta el muro del jardín, y se encarama a la rama de un árbol. Le pide al pájaro que vuele alrededor del lobo para distraerlo, mientras él desde la rama prepara un nudo corredizo, baja la cuerda y consigue enlazar al lobo por la cola. El lobo trata de liberarse pero Pedro tira con todas sus fuerzas y logra atar la cuerda al árbol. En esto llegan tres cazadores que venían rastreando al lobo y se preparan para dispararle. Pero Pedro les convence para que le ayuden a llevarlo vivo al zoológico. Y todos emprenden un desfile triunfal hacia el zoo, celebrando felices el fin del terror. Al final se puede incluso oír al pato en el interior de la barriga del lobo pues se lo había tragado sin morderlo.

Walt Disney produjo una versión animada de esta obra en 1946, con Sterling Holloway como narrador. Se estrenó como un fragmento de "Música maestro", que se reeditaría al año siguiente acompañando a "Fantasía" (un corto anterior a la película), y que posteriormente en los años 1990 se editó en vídeo por separado.
Esta versión realiza varios cambios respecto al original:


El estudio de animación ruso Soyuzmultfilm produjo una versión de la obra en 1958 en cortometraje, llamado también "Pedro y el lobo". Está realizado con marionetas en animación por fotograma. Fue dirigido por Anatoly Karanovich y narrado por I. Medvedyeva. Esta versión hace los siguientes cambios en la historia:
Esta versión no se estrenó fuera del bloque soviético.

En 2006 Suzie Templeton dirigió con como productor Hugh Welchman, otra adaptación en animación stop-motion, "Peter and the Wolf". Destaca por carecer totalmente de diálogos y narración. La banda sonora fue interpretada por la Philharmonia Orchestra, y la orquesta acompañó en directo su estreno en el Royal Albert Hall. Esta película ganó el premio "Cristal de Annecy" y el premio de la audiencia en el Festival Internacional de Cine de Animación de Annecy de 2007, y también ganó el . Esta versión hace más cambios respecto a la historia original de Prokofiev que las anteriores:




</doc>
<doc id="28212" url="https://es.wikipedia.org/wiki?curid=28212" title="Complejo activado (química)">
Complejo activado (química)

En química, un complejo activado de una reacción química elemental es la disposición particular de los átomos en la cima de la barrera energética. Si representamos su energía frente a todas las coordenadas del sistema, generalmente veremos cómo es un mínimo energético en todas ellas, menos en la coordenada de reacción -que lleva de reactivos de la reacción a los productos de ésta-, en la que es un máximo. 

La estabilización del complejo activado, por ejemplo, a través de enzimas (o catalizadores en general) conlleva generalmente una aceleración sustancial de la reacción.


</doc>
<doc id="28214" url="https://es.wikipedia.org/wiki?curid=28214" title="Carga eléctrica">
Carga eléctrica

La carga eléctrica es una propiedad física intrínseca de algunas partículas subatómicas que se manifiesta mediante fuerzas de atracción y repulsión entre ellas a través de campos electromagnéticos. La materia cargada eléctricamente es influida por los campos electromagnéticos, siendo, a su vez, generadora de ellos. La denominada interacción electromagnética entre carga y campo eléctrico es una de las cuatro interacciones fundamentales de la física. Desde el punto de vista del modelo estándar la carga eléctrica es una medida de la capacidad que posee una partícula para intercambiar fotones.

Una de las principales características de la carga eléctrica es que, en cualquier proceso físico, la carga total de un sistema aislado siempre se conserva. Es decir, la suma algebraica de las cargas positivas y negativas no varía en el tiempo.

La carga eléctrica es de naturaleza discreta, fenómeno demostrado experimentalmente por Robert Millikan. Por razones históricas, a los electrones se les asignó carga negativa: –1, también expresada "–e". Los protones tienen carga positiva: +1 o "+e". A los quarks se les asigna carga fraccionaria: ±1/3 o ±2/3, aunque no se los ha podido observar libres en la naturaleza.

En el Sistema Internacional de Unidades la unidad de carga eléctrica se denomina culombio o coulomb (símbolo C). Se define como la cantidad de carga que pasa por la sección transversal de un conductor eléctrico en un segundo, cuando la corriente eléctrica es de un amperio, y se corresponde con:


En el Sistema Cegesimal de Unidades (CGS) la carga eléctrica del electrón, es: <br>

Desde la Antigua Grecia se conoce que al frotar ámbar con una piel, ésta adquiere la propiedad de atraer cuerpos ligeros tales como trozos de paja y plumas pequeñas. Su descubrimiento se le atribuye al filósofo griego Tales de Mileto (ca. 639-547 a. C.), quién vivió hace unos 2500 años.

En 1600 el médico inglés William Gilbert observó que algunos materiales se comportan como el ámbar al frotarlos y que la atracción que ejercen se manifiesta sobre cualquier cuerpo, aun cuando no fuera ligero. Como el nombre griego correspondiente al ámbar es "ἤλεκτρον" (ēlektron), Gilbert comenzó a utilizar el término "eléctrico" para referirse a todo material que se comportaba como aquel, lo que originó los términos "electricidad" y "carga eléctrica". Además, en los estudios de Gilbert se puede encontrar la diferenciación de los fenómenos eléctricos y magnéticos. 

El descubrimiento de la atracción y repulsión de elementos al conectarlos con materiales eléctricos se atribuye a Stephen Gray. El primero en proponer la existencia de dos tipos de carga es Charles du Fay, aunque fue Benjamin Franklin quien al estudiar estos fenómenos descubrió cómo la electricidad de los cuerpos, después de ser frotados, se distribuía en ciertos lugares donde había más atracción; por eso los denominó (+) y (-).

Sin embargo, fue solo hacia mediados del siglo XIX cuando estas observaciones fueron planteadas formalmente, gracias a los experimentos sobre la electrólisis que realizó Michael Faraday, hacia 1833, y que le permitieron descubrir la relación entre la electricidad y la materia; acompañado de la completa descripción de los fenómenos electromagnéticos por James Clerk Maxwell.

Posteriormente, los trabajos de Joseph John Thomson al descubrir el electrón y de Robert Millikan al medir su carga, fueron de gran ayuda para conocer la naturaleza discreta de la carga.

La carga eléctrica es una propiedad intrínseca de la materia que se presenta en dos tipos. Estas llevan ahora el nombre con las que Benjamin Franklin las denominó: cargas positivas y negativas. Cuando cargas del mismo tipo se encuentran se repelen y cuando son diferentes se atraen. Con el advenimiento de la teoría cuántica relativista, se pudo demostrar formalmente que las partículas, además de presentar carga eléctrica (sea nula o no), presentan un momento magnético intrínseco, denominado "espín", que surge como consecuencia de aplicar la teoría de la relatividad especial a la mecánica cuántica.

Las investigaciones actuales de la física apuntan a que la carga eléctrica es una propiedad cuantizada. La unidad más elemental de carga se encontró que es la carga que tiene el electrón, es decir alrededor de 1,602 176 487(40) × 10 culombios (C) y es conocida como carga elemental. El valor de la carga eléctrica de un cuerpo, representada como "q" o "Q", se mide según el número de electrones que posea en exceso o en defecto.

Esta propiedad se conoce como "cuantización de la carga" y el valor fundamental corresponde al valor de carga eléctrica que posee el electrón y al cual se lo representa como "e". Cualquier carga "q" que exista físicamente, puede escribirse como formula_1 siendo "N" un número entero, positivo o negativo. 

Por convención se representa a la carga del electrón como "-e", para el protón "+e" y para el neutrón, "0". La física de partículas postula que la carga de los quarks, partículas que componen a protones y neutrones toman valores fraccionarios de esta carga elemental. Sin embargo, nunca se han observado quarks libres, y el valor de su carga en conjunto, en el caso del protón suma +e y en el neutrón suma 0.

Aunque no tenemos una explicación suficientemente completa de por qué la carga es una magnitud cuantizada, que sólo puede aparecer en múltiplos de la carga elemental, se han propuestos diversas ideas:


En el Sistema Internacional de Unidades la unidad de carga eléctrica se denomina culombio (símbolo C) y se define como "la cantidad de carga que a la distancia de 1 metro ejerce sobre otra cantidad de carga igual una fuerza de 9×10 N".

Un culombio corresponde a la carga de 6,241 509 × 10 electrones. El valor de la carga del electrón fue determinado entre 1910 y 1917 por Robert Andrews Millikan y en la actualidad su valor en el Sistema Internacional de acuerdo con la última lista de constantes del CODATA publicada es:

Como el culombio puede no ser manejable en algunas aplicaciones, por ser demasiado grande, se utilizan también sus submúltiplos:

Frecuentemente se usa también el sistema CGS cuya unidad de carga eléctrica es el Franklin (Fr). El valor de la carga elemental es entonces de aproximadamente 4,803×10 Fr.

En concordancia con los resultados experimentales, el "principio de conservación de la carga" establece que no hay destrucción ni creación neta de carga eléctrica, y afirma que en todo proceso electromagnético la carga total de un sistema aislado se conserva.

En un proceso de electrización, el número total de protones y electrones no se altera, sólo existe una separación de las cargas eléctricas. Por tanto, no hay destrucción ni creación de carga eléctrica, es decir, la carga total se conserva. Pueden aparecer cargas eléctricas donde antes no había, pero siempre lo harán de modo que la carga total del sistema permanezca constante. Además esta conservación es local, ocurre en cualquier región del espacio por pequeña que sea.

Al igual que las otras leyes de conservación, la conservación de la carga eléctrica está asociada a una simetría del lagrangiano, llamada en física cuántica invariancia gauge. Así por el teorema de Noether a cada simetría del lagrangiano asociada a un grupo uniparamétrico de transformaciones que dejan el lagrangiano invariante le corresponde una magnitud conservada. La conservación de la carga implica, al igual que la conservación de la masa, que en cada punto del espacio se satisface una ecuación de continuidad que relaciona la derivada de la densidad de carga eléctrica con la divergencia del vector "densidad de corriente eléctrica", dicha ecuación expresa que el cambio neto en la densidad de carga formula_6 dentro de un volumen prefijado formula_7 es igual a la integral de la densidad de corriente eléctrica formula_8 sobre la superficie formula_9 que encierra el volumen, que a su vez es igual a la intensidad de corriente eléctrica formula_10:
Otra propiedad de la carga eléctrica es que es un invariante relativista. Eso quiere decir que todos los observadores, sin importar su estado de movimiento y su velocidad, podrán siempre medir la misma cantidad de carga. Así, a diferencia del espacio, el tiempo, la energía o el momento lineal, cuando un cuerpo o partícula se mueve a velocidades comparables con la velocidad de la luz, el valor de su carga no variará.

Se llama densidad de carga eléctrica a la cantidad de carga eléctrica por unidad de longitud, área o volumen que se encuentra sobre una línea, una superficie o una región del espacio, respectivamente. Por lo tanto se distingue en estos tres tipos de densidad de carga. Se representaría con las letras griegas lambda (λ), para densidad de carga lineal, sigma (σ), para densidad de carga superficial y ro (ρ), para densidad de carga volumétrica.

Puede haber densidades de carga tanto positivas como negativas. No se debe confundir con la densidad de portadores de carga.

A pesar de que las cargas eléctricas son cuantizadas con q y, por ende, múltiplos de una carga elemental, en ocasiones las cargas eléctricas en un cuerpo están tan cercanas entre sí, que se puede suponer que están distribuidas de manera uniforme por el cuerpo del cual forman parte. La característica principal de estos cuerpos es que se los puede estudiar como si fueran continuos, lo que hace más fácil, sin perder generalidad, su tratamiento. Se distinguen tres tipos de densidad de carga eléctrica: lineal, superficial y volumétrica.

Se usa en cuerpos lineales como, por ejemplo hilos.

Donde formula_11 es la carga encerrada en el cuerpo y formula_12 es la longitud. En el Sistema Internacional de Unidades (SI) se mide en C/m (culombios por metro).

Se emplea para superficies, por ejemplo una plancha metálica delgada como el "papel de aluminio".

donde formula_11 es la carga encerrada en el cuerpo y formula_9 es la superficie. En el SI se mide en C/m (culombios por metro cuadrado).

Se emplea para cuerpos que tienen volumen.

donde formula_11 es la carga encerrada en el cuerpo y formula_7 el volumen. En el SI se mide en C/m (culombios por metro cúbico).

Se denomina electrización al efecto de ganar o perder cargas eléctricas, normalmente electrones, producido por un cuerpo eléctricamente neutro. Los tipos de electrificación son los siguientes:




</doc>
<doc id="28217" url="https://es.wikipedia.org/wiki?curid=28217" title="Serguéi Prokófiev">
Serguéi Prokófiev

Serguéi Serguéievich Prokófiev (en ruso ; Sóntsovka, 23 de abril de 1891–Moscú, 5 de marzo de 1953) conocido como Serguéi Prokófiev, fue un compositor, pianista y director de orquesta soviético. Como creador de obras maestras reconocidas en numerosos géneros musicales, es considerado uno de los principales compositores del siglo XX. Sus obras incluyen piezas tan escuchadas como la marcha de "El amor de las tres naranjas", la suite "El teniente Kijé", el ballet "Romeo y Julieta", de donde se toma la "Danza de los caballeros", y "Pedro y el lobo". De las formas y géneros establecidos en los que trabajó, creó siete óperas completas, siete sinfonías, ocho ballets, cinco conciertos para piano, dos conciertos para violín, un concierto para violonchelo, un concierto sinfónico para violonchelo y orquesta, y nueve sonatas de piano completadas.

Graduado del Conservatorio de San Petersburgo, Prokofiev inicialmente se hizo un nombre como compositor-pianista iconoclasta, logrando notoriedad con una serie de obras ferozmente disonantes y virtuosas para su instrumento, incluidos sus dos primeros conciertos para piano. En 1915, Prokofiev hizo una ruptura decisiva de la categoría estándar de compositor-pianista con su orquestal "Suite escita", compilada a partir de música originalmente compuesta para un ballet encargado por Sergei Diaghilev de los Ballets Russes. Diaghilev encargó otros tres ballets a Prokofiev: "Chout", "Le pas d'acier" y "El hijo pródigo", que en el momento de su producción original causaron sensación entre críticos y colegas. Sin embargo, el mayor interés de Prokofiev fue la ópera, y compuso varias obras en ese género, incluyendo "El jugador" y "El ángel de fuego". El único éxito operístico de Prokofiev durante su vida fue "El amor de las tres naranjas", compuesto para la Ópera de Chicago y posteriormente se presentó durante la siguiente década en Europa y Rusia.

Después de la Revolución de 1917, Prokofiev dejó Rusia con la bendición oficial del ministro soviético Anatoly Lunacharsky, y residió en los Estados Unidos, luego en Alemania, luego en París, y se ganó la vida como compositor, pianista y director de orquesta. Durante ese tiempo, se casó con una cantante española, Carolina (Lina) Codina, con quien tuvo dos hijos. A principios de la década de 1930, la Gran Depresión disminuyó las oportunidades para que los ballets y óperas de Prokofiev se presentaran en Estados Unidos y Europa occidental. Prokofiev, que se consideraba a sí mismo como el compositor más importante, resentía el tiempo que le tomaba hacer una gira como pianista, y recurría cada vez más a la Unión Soviética para solicitar comisiones de nueva música; en 1936, finalmente regresó a su tierra natal con su familia. Disfrutó de cierto éxito allí, especialmente con "El teniente Kijé", "Pedro y el Lobo", "Romeo y Julieta", y quizás sobre todo con "Alexander Nevsky".

La invasión nazi de la Unión Soviética lo impulsó a componer su trabajo más ambicioso, una versión operística de "Guerra y paz" de Leo Tolstoi. En 1948, Prokofiev fue atacado por producir "formalismo antidemocrático". Sin embargo, disfrutó del apoyo personal y artístico de una nueva generación de intérpretes rusos, especialmente Sviatoslav Richter y Mstislav Rostropovich: escribió su novena sonata para piano para el primero y su Sinfonía concertante para el segundo. 

Prokófiev nació en 1891 en Sóntsovka (ahora Sóntsivka, Raión Pokrovsk, Óblast de Donetsk, Ucrania oriental), una finca rural remota en la gobernación de Yekaterinoslav del Imperio ruso. Su padre, Serguéi Alekséievich Prokófiev, era ingeniero agrónomo. La madre de Prokófiev, María (de soltera Zhitkova), provenía de una familia de antiguos siervos que habían sido propiedad de la familia Sheremétev, bajo cuyo patrocinio se enseñó a los siervos desde una edad temprana. Fue descrita por Reinhold Glière (el primer profesor de composición de Prokófiev) como "una mujer alta con hermosos ojos inteligentes ... que supo crear una atmósfera de calidez y sencillez sobre ella". Después de su boda en el verano de 1877, los Prokófiev se mudaron a una pequeña propiedad en la gobernación de Smolensk. Eventualmente, Serguéi Alekséievich encontró empleo como ingeniero de caminos, empleado por uno de sus antiguos compañeros de estudios, Dmitri Sontsov, a cuya propiedad en las estepas ucranianas se mudaron los Prokófiev.

En el momento del nacimiento de Prokófiev, María, que había perdido dos hijas anteriormente, había dedicado su vida a la música; durante la primera infancia de su hijo, pasó dos meses al año en Moscú o San Petersburgo tomando clases de piano. Serguéi Prokófiev se inspiró en escuchar a su madre practicando el piano por la noche, en su mayoría obras de Chopin y Beethoven, y escribió su primera composición para piano a la edad de cinco años, un ""Galope indio"", que fue escrito por su madre en una escala mayor con un cuarto grado de escala elevado, ya que el joven Prokófiev sentía "renuencia a abordar las notas negras". A los siete años también había aprendido a jugar al ajedrez. El ajedrez seguiría siendo una pasión suya, y se familiarizó con los campeones mundiales de ajedrez como José Raúl Capablanca, a quien venció en un partido de exhibición simultánea en 1914, y Mijaíl Botvínnik, con quien jugó varios partidos en la década de 1930. A la edad de nueve años, estaba componiendo su primera ópera, "The Giant", así como una obertura y otras piezas.

En 1902, la madre de Prokófiev se encontró con Serguéi Tanéyev, director del Conservatorio de Moscú, quien inicialmente sugirió que Prokófiev debería comenzar las clases de piano y composición con Alexander Goldenweiser. Incapaz de arreglar eso, Tanéyev en cambio arregló las cosas para que el compositor y pianista Reinhold Glière pasara el verano de 1902 en Sóntsovka enseñando a Prokófiev. La primera serie de lecciones culminó, ante la insistencia de Prokófiev, de 11 años, con el incipiente compositor haciendo su primer intento de escribir una sinfonía. El verano siguiente, Glière volvió a visitar Sóntsovka para dar más clases. Cuando, décadas después, Prokófiev escribió sobre sus lecciones con Glière, dio crédito al método simpático de su maestro, pero se quejó de que Glière le había presentado la estructura de frase "cuadrada" y las modulaciones convencionales, que posteriormente tuvo que desaprender. Sin embargo, equipado con las herramientas teóricas necesarias, Prokófiev comenzó a experimentar con armonías disonantes y marcas de tiempo inusuales en una serie de piezas cortas de piano que llamó ""ditties"" (a partir de la llamada "forma de canción", más precisamente de forma ternaria, en la que se basaron), sentando las bases para su propio estilo musical.

A pesar de su creciente talento, los padres de Prokófiev dudaron sobre iniciar a su hijo en una carrera musical a tan temprana edad, y consideraron la posibilidad de que asistiera a una buena escuela secundaria en Moscú. En 1904, su madre se había decidido en cambio por San Petersburgo, y ella y Prokófiev visitaron la entonces capital para explorar la posibilidad de mudarse allí para su educación. Fueron presentados al compositor Aleksandr Glazunov, profesor en el Conservatorio de San Petersburgo, quien pidió ver a Prokofiev y su música. Prokófiev había compuesto dos óperas más, "Desert Islands" y "The Feast during The Plague", y estaba trabajando en su cuarta, "Undina". Glazunov quedó tan impresionado que instó a la madre de Prokófiev a que su hijo solicitara la admisión al Conservatorio. Pasó las pruebas introductorias y se inscribió ese año.

Varios años más joven que la mayoría de su clase, Prokófiev era visto como excéntrico y arrogante, y molestaba a varios de sus compañeros manteniendo estadísticas sobre sus errores. Durante ese período, estudió bajo, entre otros, Alexander Winkler para el piano, Anatoli Liádov para armonía y contrapunto, Nikolái Cherepnín para dirección, y Nikolái Rimski-Kórsakov para orquestación (aunque cuando Rimski-Kórsakov murió en 1908, Prokófiev señaló que era solo uno de muchos estudiantes en una clase muy concurrida y lamentó que de otro modo "nunca tuvo la oportunidad de estudiar con él"). También compartió clases con los compositores Borís Asáfyev y Nikolái Miaskovski, y este último se convirtió en un amigo relativamente cercano y de por vida.

Como miembro de la escena musical de San Petersburgo, Prokófiev desarrolló una reputación como un rebelde musical, mientras recibía elogios por sus composiciones originales, que interpretó él mismo en el piano. En 1909, se graduó de su clase en composición con notas poco impresionantes. Continuó en el Conservatorio, estudiando piano con Anna Yésipova y continuando sus clases de dirección bajo Cherepnín.

En 1910, el padre de Prokófiev murió y el apoyo financiero a Serguéi cesó. Afortunadamente, comenzó a hacerse un nombre como compositor y pianista fuera del Conservatorio, haciendo apariciones en las noches de música contemporánea de San Petersburgo. Allí interpretó varias de sus obras para piano más aventureras, como sus altamente cromáticos y disonantes, "Etudes" op. 2 (1909). Su actuación impresionó a los organizadores de las Noches lo suficiente como para invitar a Prokófiev a dar el estreno ruso de "Drei Klavierstücke" op. 11, de Arnold Schoenberg. La experimentación armónica de Prokófiev continuó con "Sarcasmos para piano", op. 17 (1912), que hace un uso extenso de politonalidad. Compuso sus primeros dos conciertos para piano alrededor de ese momento, el último de los cuales causó un escándalo en su estreno (23 de agosto de 1913, Pávlovsk). Según una versión, el público salió de la sala con exclamaciones de "¡Al diablo con esta música futurista! ¡Los gatos en el tejado hacen mejor música!", Pero los modernos estaban en éxtasis.

En 1911, llegó la ayuda del renombrado musicólogo y crítico ruso Alexander Ossovsky, quien escribió una carta de apoyo al editor de música Boris P. Jurgenson (hijo del fundador de la editorial Peter Jurgenson [1836-1904]); y así se le ofreció un contrato al compositor. Prokófiev hizo su primer viaje al extranjero en 1913, viajando a París y Londres, donde se encontró por primera vez con los Ballets Rusos de Serguéi Diáguilev.

En 1914, Prokófiev terminó su carrera en el Conservatorio al participar en la "batalla de los pianos", una competencia abierta a los cinco mejores estudiantes de piano, cuyo premio fue un piano de cola Schreder: Prokófiev ganó al interpretar su propio "Concierto para piano n.º 1". Sus primeras obras, como el "Concierto para piano n.º 1" (1911) y la "Suite escita" para orquesta (1914), le valieron mala fama como músico, pues no correspondía con la línea nacionalista rusa.

Poco después, viajó a Londres, donde se puso en contacto con el empresario Sergei Diaghilev. Diaghilev encargó el primer ballet de Prokófiev, "Ala y Lolli"; pero cuando Prokófiev le trajo el trabajo en curso a Italia en 1915, lo rechazó como "no ruso". Instando a Prokófiev a escribir "música que fuera de carácter nacional", Diáguilev luego le encargó el ballet "Chout" ("The Fool", el título original en ruso fue "Сказка про шута, семерых шутов перешутившего" ("Skazka pro shutá, semeryj shutov pereshutívshevo"), que significa ""El cuento del bufón que superó a otros siete bufones""). Bajo la guía de Diáguilev, Prokófiev eligió su tema de una colección de cuentos populares recopilados por el etnógrafo Aleksandr Afanásiev. La historia, relacionada con un bufón y una serie de trucos de confianza, había sido previamente sugerida a Diáguilev por Ígor Stravinski como posible tema para un ballet, y Diáguilev y su coreógrafo Léonide Massine ayudaron a Prokófiev a darle forma de guion de ballet. La inexperiencia de Prokófiev con el ballet lo llevó a revisar el trabajo extensamente en la década de 1920, siguiendo la detallada crítica de Diáguilev, antes de su primera producción. El estreno del ballet en París el 17 de mayo de 1921 fue un gran éxito y fue recibido con gran admiración por un público que incluía a Jean Cocteau, Ígor Stravinski y Maurice Ravel. Stravinski llamó al ballet "la única pieza de música moderna que podía escuchar con placer", mientras que Ravel lo llamó "una obra de genio".
En paralelo durante la Primera Guerra Mundial, Prokófiev regresó al Conservatorio. Estudió órgano para evitar ser reclutado. Compuso "El jugador", ópera basada en la novela homónima de Fiódor Dostoievski, pero los ensayos estuvieron plagados de problemas y el estreno, previsto para el año 1917, tuvo que ser cancelado debido a la Revolución de febrero. En el verano de aquel año, Prokófiev compuso su primera sinfonía, la "Clásica". Este es el nombre que él mismo le dio, dado que fue compuesta en un estilo que, según Prokófiev, Joseph Haydn habría usado si estuviera vivo en esa época. Es de estilo más o menos clásico, pero incorpora elementos musicales más modernos (ver Neoclasicismo). La sinfonía también fue una obra contemporánea exacta del "Concierto para violín n.º 1, en re mayor, op. 19", que estaba programado para estrenarse en noviembre de 1917. Compuso la melodía de apertura del concierto en 1915, durante su historia de amor con Nina Mescherskaya. Los movimientos restantes se inspiraron en parte en la representación en San Petersburgo de 1916 de la obra "Mitos" de Karol Szymanowski por el violinista polaco Paul Kochanski.

Las primeras interpretaciones de ambas obras debieron esperar hasta el 21 de abril de 1918 y el 18 de octubre de 1923, respectivamente. 

A pesar de los acontecimientos que llevaron a la abdicación del zar Nicolás II de Rusia y, finalmente, la Revolución de Octubre, 1917 se convirtió en el año más productivo de Prokófiev en términos de composición. Junto con el "Primer concierto para violín" y la "Sinfonía "clásica"", compuso la "tercera y cuarta sonatas para piano" y las "Visiones fugitivas para piano". También comenzó la cantata "Siete, eran siete", basada en textos caldeos, y trabajó en el "Tercer concierto para piano".

Se quedó brevemente con su madre en Kislovodsk en el Cáucaso. Después de completar la composición de la cantata "Siete, ellos eran siete", una "invocación caldea" para coro y orquesta, Prokófiev dice "quedé sin nada que hacer y el tiempo colgó pesadamente de mis manos". Creyendo que Rusia "no tenía ningún uso para la música en ese momento", Prokófiev decidió probar fortuna en América hasta que la confusión en su tierra natal hubiera pasado. Partió hacia Moscú y Petersburgo en marzo de 1918 para resolver cuestiones financieras y organizar su pasaporte. En mayo se dirigió a los Estados Unidos, obteniendo el permiso oficial de Anatoly Lunacharsky, el Comisario del Pueblo para la Educación, quien le dijo: "Eres un revolucionario en la música, somos revolucionarios en la vida. Debemos trabajar juntos. Si quieres ir a América, no me interpondré en tu camino".

Al llegar a San Francisco después de haber sido liberado de los interrogatorios por funcionarios de inmigración en la Isla de los Ángeles el 11 de agosto de 1918, Prokofiev pronto fue comparado con otros exiliados rusos famosos (como Serguéi Rajmáninov). Su concierto de debut como solista en Nueva York dio lugar a varios compromisos más. También firmó un contrato con el director musical de la Chicago Opera Association, Cleofonte Campanini, para la producción de su nueva ópera "El amor de las tres naranjas"; sin embargo, debido a la enfermedad y la muerte de Campanini, el estreno fue pospuesto. La demora fue otro ejemplo de la mala suerte de Prokófiev en asuntos operísticos. El fracaso también le costó su carrera como solista estadounidense ya que la ópera le tomó demasiado tiempo y esfuerzo. Pronto se encontró en dificultades financieras, y en abril de 1920, se fue a París, no queriendo regresar a Rusia y reconocer un fracaso.

En París, Prokófiev reafirmó sus contactos con los Ballets Rusos de Diáguilev. También completó algunas de sus obras más antiguas, inacabadas, como el "Tercer Concierto para piano". "El amor de tres naranjas" finalmente se estrenó en Chicago, bajo la batuta del compositor, el 30 de diciembre de 1921. Diáguilev se interesó lo suficiente en la ópera como para pedirle a Prokófiev que diera una audición de la partitura vocal en junio de 1922, mientras ambos estaban en París para una reactivación de "Chout", por lo que podría considerarlo para una posible producción. Stravinsky, que estuvo presente en la audición, se negó a escuchar más que el primer acto. Entonces acusó a Prokófiev de "perder el tiempo componiendo óperas", Prokófiev replicó que Stravinsky "no estaba en posición de establecer una dirección artística general, ya que él mismo no es inmune al error". Según Prokófiev, Stravinsky "se volvió incandescente por la ira" y "casi llegamos a las manos y nos separamos solo con dificultad". Como resultado, "nuestras relaciones se tensaron y durante varios años la actitud de Stravinsky hacia mí fue crítica".

En marzo de 1922, Prokófiev se mudó con su madre a la ciudad de Ettal, en los Alpes bávaros, donde durante más de un año se concentró en un proyecto de ópera, "El Ángel de Fuego", basado en la novela de Valeri Briúsov. Su música posterior había adquirido seguidores en Rusia, y recibió invitaciones para regresar allí, pero decidió quedarse en Europa. En 1923, Prokófiev se casó con la cantante española de madre rusa, Carolina Codina (1897-1989, de nombre artístico Lina Llubera) antes de regresar a París.

En París, varias de sus obras, incluida la "Segunda Sinfonía", se representaron, pero su recepción fue tibia y Prokófiev sintió que "evidentemente ya no era una sensación". Aun así, la "Segunda Sinfonía" pareció incitar a Diaghilev a encargar "Le pas d'acier (El paso de acero)", una partitura de ballet "modernista" destinada a retratar la industrialización de la Unión Soviética. La obra fue recibida con entusiasmo por audiencias y críticos parisinos.

Alrededor de 1924, Prokófiev fue introducido a la Ciencia Cristiana. Comenzó a practicar sus enseñanzas, que creía que eran beneficiosas para su salud y su temperamento ardiente y a las que permaneció fiel por el resto de su vida, según el biógrafo Simon Morrison.

Prokófiev y Stravinsky restauraron su amistad, aunque a Prokófiev le disgustó particularmente la "estilización al modo de Bach" de Stravinsky en obras tan recientes como el "Octeto" y el "Concierto para piano y instrumentos de viento". Por su parte, Stravinsky describió a Prokófiev como el Compositor ruso de su tiempo, después de él.

En 1927, Prokófiev hizo su primera gira de conciertos en la Unión Soviética. En el transcurso de más de dos meses, pasó un tiempo en Moscú y Leningrado (el nuevo nombre a San Petersburgo), donde disfrutó de una exitosa puesta en escena de "El amor de las tres naranjas" en el Teatro Mariinsky. En 1928, Prokófiev completó su "Tercera Sinfonía", que se basaba ampliamente en su ópera no estrenada "El Ángel de Fuego". El director Serguéi Kusevitski caracterizó a la Tercera como "la mayor sinfonía desde la Sexta de Chaikovski".

Mientras tanto, sin embargo, Prokófiev, bajo la influencia de las enseñanzas de la Ciencia Cristiana, se había vuelto contra el estilo expresionista y el tema de "El Ángel de Fuego". Ahora prefería lo que llamó una "nueva simplicidad", que creía más sincera que las "artimañas y complejidades" de tanta música moderna de la década de 1920. Durante 1928-29, Prokofiev compuso lo que iba a ser su último ballet para Diáguilev, "El hijo pródigo". Cuando se representó por primera vez en París el 21 de mayo de 1929, con coreografía de George Balanchine, Serge Lifar en el papel principal y decorados de Georges Rouault, la audiencia y los críticos quedaron especialmente impresionados por la escena final en la que el hijo pródigo se arrastra sobre el escenario arrodillado para ser bienvenido. su padre. Diaghilev había reconocido que en la música de la escena, Prokofiev "nunca había sido más claro, más simple, más melodioso y más tierno". Solo unos meses después, Diaghilev murió.

Ese verano, Prokofiev completó el "Divertimento, op. 43" (que había comenzado en 1925) y revisó su "Sinfonietta, op. 5/48", un trabajo que comenzó en sus días en el Conservatorio. En octubre de ese año, tuvo un accidente automovilístico mientras conducía a su familia de regreso a París después de sus vacaciones: cuando el auto volcó, Prokófiev perdió algunos músculos en su mano izquierda. Prokófiev, por lo tanto, no pudo actuar en Moscú durante su gira poco después del accidente, pero pudo disfrutar viendo las interpretaciones de su música en público. Prokófiev también asistió a la "audición" del Teatro Bolshói de su ballet "El paso de acero", y fue interrogado por miembros de la Asociación Rusa de Músicos Proletarios (RAPM) sobre el trabajo: se le preguntó si la fábrica retrataba "una fábrica capitalista, donde el trabajador es un esclavo, o una fábrica soviética, donde el trabajador es el maestro. Si se trata de una fábrica soviética, cuándo y dónde lo examinó Prokófiev, que desde 1918 hasta el presente había estado viviendo en el extranjero y vino aquí por primera vez en 1927 durante dos semanas?" Prokófiev respondió: "Eso se refiere a la política, no a la música, y por lo tanto no responderé". La RAPM condenó el ballet de manera dogmática como una "anécdota antisoviética llana y vulgar, una composición contrarrevolucionaria que linda con el fascismo". El Bolshói no tuvo más opción que rechazar el ballet.Con la mano izquierda sanada, Prokófiev recorrió los Estados Unidos con éxito a principios de 1930, apoyado por su reciente éxito europeo. Ese año Prokófiev comenzó su primer ballet no Diáguilev con "En el Dniéper, op. 51", una obra encargada por Serge Lifar, que había sido nombrado maitre de ballet en la Ópera de París. En 1931 y 1932, completó su "cuarto y quinto conciertos para piano". El año siguiente vio la finalización de la "Canción Sinfónica, Op. 57", de la que el amigo de Prokófiev, Myaskovski, pensando en su posible audiencia en la Unión Soviética, le dijo "no es para nosotros ... carece de lo que entendemos por monumentalismo - una simplicidad familiar y amplios contornos, de los cuales eres extremadamente capaz, pero que temporalmente estás evitando cuidadosamente".
A principios de la década de 1930, tanto Europa como América sufrían la Gran Depresión, que inhibió tanto las nuevas producciones de ópera como las de ballet, aunque las audiencias para las apariciones de Prokófiev como pianista no habían disminuido, al menos en Europa. Sin embargo, Prokófiev, que se veía a sí mismo como un compositor en primer lugar, estaba cada vez más resentido por la cantidad de tiempo que perdía para la composición a través de sus apariciones como pianista. Después de haber estado nostálgico por algún tiempo, Prokófiev comenzó a construir puentes sustanciales con la Unión Soviética. Tras la disolución de la RAPM en 1932, actuó cada vez más como embajador musical entre su país de origen en Europa occidental, y sus estrenos y comisiones fueron cada vez más bajo los auspicios de la Unión Soviética. Uno de ellos fue "El teniente Kijé", que fue comisionado como la banda sonora de una película soviética. Otra comisión, del Teatro Kírov (como se denominaba entonces al Mariinsky) en Leningrado, fue el ballet "Romeo y Julieta", compuesto para un guion creado por Adrian Piotrovsky y Serguéi Rádlov siguiendo los preceptos de "drambalet" (ballet dramatizado, oficialmente promovido en el Kirov para reemplazar las obras basadas principalmente en la visualización coreográfica y la innovación). Tras la amarga renuncia de Rádlov al Kírov en junio de 1934, se firmó un nuevo acuerdo con el Teatro Bolshói de Moscú, en el entendido de que Piotrovsky seguiría participando. Sin embargo, el final feliz original del ballet (contrario a Shakespeare) provocó controversia entre los funcionarios culturales soviéticos; la producción del ballet fue pospuesta indefinidamente cuando el personal del Bolshói fue revisado a instancias del presidente de la Comisión de Asuntos de Arte, Platón Kérzhentsev. Nikolái Myaskovski, uno de sus amigos más cercanos, mencionó en varias cartas cómo le gustaría que Prokófiev permaneciera en Rusia. 
El "Concierto para violín n.º 2 en sol menor" opus 63, escrito en 1935 fue estrenado el 1 de diciembre de 1935 en Madrid por el violinista francés Robert Soëtans y la Orquesta Sinfónica de Madrid dirigida por Enrique Fernández Arbós.

En 1936, Prokófiev y su familia se establecieron permanentemente en Moscú, después de desplazarse entre Moscú y París durante los últimos cuatro años. Ese año compuso una de sus obras más famosas, "Pedro y el lobo", para el Teatro Central para Niños de Natalya Sats. Se trata de un trabajo programático para narrador, instrumentos individuales y orquesta. Sats también persuadió a Prokófiev para que escribiera dos canciones para niños, "Sweet Song" y "Chatterbox"; finalmente se unieron a "The Little Pigs" y se publicaron como "Tres canciones para niños, op. 68". Prokófiev también compuso la gigantesca "Cantata para el vigésimo aniversario de la Revolución de Octubre", originalmente destinada a la presentación durante el año del aniversario, pero efectivamente bloqueada por Kerzhentsev, quien exigió en la audición del trabajo ante la Comisión de Asuntos de las Artes: "¿Qué crees tú?" ¿Ha vuelto, Sergey Sergeyevich, tomando textos que pertenecen a la gente y poniéndoles una música tan incomprensible? La Cantata tuvo que esperar hasta el 5 de abril de 1966 para un estreno parcial, algo más de 13 años después de la muerte del compositor.

Obligado a adaptarse a las nuevas circunstancias (cualesquiera que fueran los recelos privados que tuviera sobre ellas), Prokófiev escribió una serie de ""Canciones de masas"" (Opp. 66, 79, 89), utilizando las letras de los poetas soviéticos oficialmente aprobados. En 1938, Prokófiev colaboró ​​con Serguéi Eisenstein en la épica película histórica "Aleksándr Nevski", parte de su música más creativa y dramática. Aunque la película tenía una grabación de sonido muy pobre, Prokófiev adaptó gran parte de su partitura a una cantata de gran escala para mezzosoprano, orquesta y coro, que fue interpretada y grabada extensamente. Tras el éxito de "Alejandro Nevski", Prokófiev compuso su primera ópera soviética, "Semyon Kotko", que debía ser producida por el director Vsevolod Meyerhold. Sin embargo, el estreno de la ópera se pospuso porque Meyerhold fue arrestado el 20 de junio de 1939 por la NKVD (policía secreta de Iósif Stalin) y fusilado el 2 de febrero de 1940. Solo meses después del arresto de Meyerhold, Prokófiev fue 'invitado' a componer "Zdravitsa" (literalmente traducido '¡Salud!', pero con más frecuencia conocida por el título inglés "Hail to Stalin") (Op. 85) para celebrar el 60º cumpleaños de Iósif Stalin.

Más tarde, en 1939, Prokófiev compuso sus "Sonatas para piano Nos. 6, 7 y 8, Opp. 82-84", ampliamente conocidas hoy como las ""Sonatas de Guerra"". Estrenadas respectivamente por Prokófiev (n.º 6: 8 de abril de 1940), Sviatoslav Richter (n.º 7: Moscú, 18 de enero de 1943) y Emil Guilels (n.º 8: Moscú, 30 de diciembre de 1944), que fueron posteriormente muy interpretadas en particular por Richter. El biógrafo Daniel Jaffé argumentó que Prokófiev, "habiéndose forzado a componer una alegre evocación del nirvana que Stalin quería que todos creyeran haber creado" (es decir, en "Zdravitsa"), posteriormente, en las tres sonatas, "expresó sus verdaderos sentimientos". Como evidencia, Jaffé ha señalado que el movimiento central de Sonata No. 7 se abre con un tema basado en Robert Schumann 'Wehmut' ('Tristeza', que aparece en el "Liederkreis" de Schumann, Op. 39): sus palabras se traducen, "A veces puedo cantar como si estuviera contento, pero secretamente las lágrimas son buenas y así liberas mi corazón. Los ruiseñores... cantan su canción de anhelo desde la profundidad de su mazmorra ... todo el mundo se deleita, pero nadie siente el dolor, la profunda tristeza en la canción". Irónicamente (parece que nadie notó su alusión), la Sonata No. 7 recibió un Premio Stalin (Segunda Clase), y la No. 8 un Premio Stalin (Primera Clase). 

Mientras tanto, "Romeo y Julieta" finalmente fue montado por el Kirov Ballet, coreografiado por Leonid Lavrovsky, el 11 de enero de 1940. Para sorpresa de todos sus participantes, los bailarines que lucharon para arreglárselas con los ritmos sincopados de la música y casi boicotearon la producción, el ballet fue un éxito instantáneo, y fue reconocido como el mayor logro del ballet dramático soviético.

Ante la Operación Barbarroja, con la invasión alemana de la Unión Soviética en junio de 1941, se ordenaron diversas evacuaciones hacia territorios más alejados los presuntos teatros de operaciones militares. Prokófiev era uno de los que estaba dentro de esos planes y marchó hacia el Cáucaso. El año ya había empezado mal para el compositor, había sufrido un ataque al corazón en primavera. Lina se quedaba en Moscú con sus dos hijos. Prokófiev se separa de Lina en 1941, aunque nunca se divorciaron formalmente. Desde entonces estaba ligado sentimentalmente con la escritora y libretista de 25 años Mira Mendelson (1915-1968), que era evacuada de Moscú junto con Prokófiev.

Durante los años de la guerra, las restricciones sobre el estilo y la petición de que los compositores escribieran en un estilo de "realismo socialista" se aflojaron, y Prokofiev generalmente pudo componer a su manera.

Siguió escribiendo la ópera "Guerra y paz", basada en la novela monumental de Tolstoi. El tratamiento que le dio Prokófiev también fue igualmente monumental. La partitura para piano fue completada en el verano de 1942 (cambiando dos escenas de la versión original), y fue sometida al Comité soviético para las Artes. El Comité exigió que las escenas de la segunda parte (la Guerra) fueran más patrióticas y tuvieran mayor énfasis heroico. Prokófiev, que quería ver su obra maestra representada cuanto antes, añadió marchas, coros, y otros materiales a la segunda parte para satisfacer al comité. Además, compuso el Prólogo coral, que enfatiza el desafío del pueblo ruso frente al enemigo.
Estaba previsto estrenarla en 1943 en el Teatro Bolshói de Moscú con dirección de Serguéi Eisenstein y dirección de Samuil Samosud. Pero solo se pudo hacer una representación privada de ocho escenas con acompañamiento para piano en el Centro de Actores de Moscú el 16 de octubre de 1944, y una representación pública en versión de concierto, con nueve escenas, dirigida por Samosud, que tuvo lugar en el Gran Hall del Conservatorio de Moscú el 7 de junio de 1945. La primera representación escenificada fue de una versión ampliada en siete 
escenas, que tuvo lugar el 12 de junio de 1946 en el Teatro Maly de Leningrado, con dirección de Samosud. La segunda parte, también con una escena adicional (escena 10), se iba a representar en julio de 1947, pero después del ensayo no se ofrecieron representaciones públicas, «"por razones ajenas al control del teatro y del compositor"». Después del Decreto Zhdánov de febrero de 1948, Prokófiev comenzó a trabajar en una versión más reducida de la ópera, para un solo día, al tiempo que hizo varias revisiones del esquema original, aunque mantuvo la estructura de 13 escenas. Esta versión se interpretó por primera vez el 26 de mayo de 1953 en el Teatro Comunale, Florencia, dirigida por Artur Rodziński, dos meses después de la muerte del compositor.

También empezaba en 1942 un borrador para otra ópera, "Khan Buzay", que abandonaría. Asimismo, también escribía música para cuatro películas, el ballet "La cenicienta", varias suites sinfónicas, el "Cuarteto de cuerda núm. 2", una "Sonata para flauta y piano", una transcripción de la misma para violín y piano (hecho a instancias del violinista David Oistrakh), dos marchas militares y unas cuantas canciones folclóricas.

En 1943 Prokofiev se unió a Eisenstein en Alma-Ata, la ciudad más grande de Kazajistán, para componer más música de cine ("Iván el Terrible") y el ballet de Cenicienta (Op. 87), una de sus composiciones más melódicas y célebres. En 1944, Prokofiev compuso su "Quinta Sinfonía (Op. 100)" en la colonia de compositores fuera de Moscú. Dirigió su estreno el 13 de enero de 1945, justo quince días después del triunfante estreno el 30 de diciembre de 1944 de su "Octava Sonata de Piano" y, el mismo día, la primera parte de "Ivan el Terrible" de Eisenstein. La obra rápidamente emergió como su sinfonía más popular y se le otorgó su segundo premio Stalin. Con el estreno de su "Quinta Sinfonía", que fue programada junto a "Pedro y el Lobo" y la "Sinfonía Clásica" (dirigida por Nikolai Anosov), Prokófiev pareció alcanzar el cenit de su fama como compositor líder de la Unión Soviética. 

"La Cenicienta", el segundo ballet más popular de Prokófiev después de Romeo y Julieta, fue originalmente encargada por el Teatro Kírov, justo antes de la invasión alemana. Pero no fue estrenado hasta el 1945 en el escenario del Bolshoi con un éxito considerable y con la famosa bailarina Galina Ulanova. El estreno en el Kírov de Leningrado se produjo cinco meses más tarde y se repitió el éxito. Antes del estreno hizo varias transcripciones para piano de la misma (Op. 95, 97 y 102).

Esta etapa brillante en su vida como compositor culmina desgraciadamente en enero de 1945, cuando Prokófiev sufrió una conmoción cerebral en una caída. Su vida corrió peligro los siguientes días y a partir de entonces sufriría a menudo dolores de cabeza y periodos de presión arterial peligrosamente alta. No se recuperaría nunca más de forma completa de este accidente, aunque la grandeza de sus trabajos no den esta impresión.

Prokofiev tuvo tiempo de escribir su "Sexta Sinfonía" de posguerra y su "Novena Sonata para Piano" (para Sviatoslav Richter) antes del llamado "Decreto Zhdanov". A principios de 1948, después de una reunión de compositores soviéticos convocada por Andrei Zhdanov, el Politburó emitió una resolución denunciando a Prokofiev, Dmitri Shostakovich, Myaskovsky y Khachaturian por el crimen del "formalismo", descrito como una "renuncia a los principios básicos de la música clásica" ... "a favor de sonidos confusos, nerviosos que convierten la música en cacofonía". Ocho de las obras de Prokofiev fueron prohibidas: "El año 1941", la "Oda al final de la guerra", el "Poema festivo", la "Cantata por el trigésimo aniversario de la revolución de octubre", la "Balada de un niño desconocido", "Los pensamientos" ciclo para piano de 1934 y la "sonata para piano núms. 8". Tal era la amenaza percibida detrás de la prohibición de las obras que incluso las obras que habían evitado la censura ya no fueron programadas: en agosto de 1948, Prokófiev estaba en graves aprietos financieros, su deuda personal ascendía a 180.000 rublos.

Mientras tanto, el 20 de febrero de 1948, la esposa de Prokófiev, Lina, fue arrestada por "espionaje", ya que había intentado enviar dinero a su madre en España. Después de nueve meses de interrogatorio, fue sentenciada por un Colegio Militar de tres miembros del Tribunal Supremo de la URSS a 20 años de trabajos forzados. Finalmente fue liberada después de la muerte de Stalin en 1953 y en 1974 abandonó la Unión Soviética.

Los últimos proyectos de ópera de Prokófiev, entre ellos su desesperado intento de apaciguar a las autoridades culturales, "La historia de un hombre real", fueron cancelados rápidamente por el Teatro Kirov. El libreto de esta ópera era del compositor y Mira Mendelson, y se basa en la novela homónima de Boris Polevoy, que a su vez se basó en la historia del piloto Alexey Maresyev. El desaire, en combinación con su salud en declive, hizo que Prokófiev se retirara progresivamente de la vida pública y de diversas actividades, incluso su apreciado ajedrez, y se dedicó cada vez más a su propio trabajo. Después de una grave recaída en 1949, sus médicos le ordenaron limitar su composición a una hora por día.

En la primavera de 1949, escribió su "Sonata para violonchelo en C, op. 119", para Mstislav Rostropovich, de 22 años, quien dio la primera presentación en 1950, con Sviatoslav Richter. Para Rostropovich, Prokofiev también recompuso extensivamente su "Concierto para violonchelo", transformándolo en un Concierto sinfónico, su última gran obra maestra y un hito en el repertorio de violonchelo y orquesta de la actualidad. La última presentación pública a la que asistió fue el estreno de la "Séptima Sinfonía" en 1952, por la cual recibió el premio Stalin. La música fue escrita para la División de Radio para Niños.

Prokofiev murió a la edad de 61 años el 5 de marzo de 1953, el mismo día que Iósif Stalin, cuando acababan de comenzar los ensayos para su ballet "La flor de piedra" (1950), que fue puesto en escena el año siguiente. Había vivido cerca de la Plaza Roja, y durante tres días las multitudes se reunieron para llorar a Stalin, por lo que era imposible transportar el cuerpo de Prokófiev para el funeral en la sede de la Unión de Compositores Soviéticos. Está enterrado en el cementerio de Novodevichy en Moscú. Era ateo.

El principal periódico musical soviético reportó la muerte de Prokófiev con un breve artículo en la página 116. Las primeras 115 páginas se dedicaron a la muerte de Stalin. Por lo general, la muerte de Prokófiev se atribuye a una hemorragia cerebral. Había estado enfermo crónicamente durante los ocho años anteriores; la naturaleza precisa de la enfermedad terminal de Prokofiev sigue siendo incierta.

Lina Prokofiev sobrevivió a su marido distanciado por muchos años, muriendo en Londres a principios de 1989. Las regalías de la música de su difunto esposo le proporcionaron unos ingresos modestos, y actuó como narradora de una grabación de "Pedro y el lobo" de su marido (actualmente lanzada en CD por Chandos Records) con Neeme Järvi dirigiendo la Orquesta Nacional Escocesa. Sus hijos Sviatoslav (1924-2010), arquitecto, y Oleg (1928-1998), artista, pintor, escultor y poeta, dedicaron una gran parte de sus vidas a la promoción de la vida y el trabajo de sus padres.







</doc>
<doc id="28221" url="https://es.wikipedia.org/wiki?curid=28221" title="Enlace químico">
Enlace químico

Un enlace químico es el proceso químico responsable de las interacciones atractivas entre átomos y moléculas,y que confiere estabilidad a los compuestos químicos diatómicos y poliatómicos. La explicación de tales fuerzas atractivas es un área compleja que está descrita por las leyes de la "química cuántica".

Una definición más sencilla es que un enlace químico es la fuerza existente entre los átomos una vez que se ha formado un sistema estable.

Las moléculas, cristales, metales y gases diatómicos (que forman la mayor parte del ambiente físico que nos rodea) están unidos por enlaces químicos, que determinan las propiedades físicas y químicas de la materia.

Las cargas opuestas se atraen porque al estar unidas adquieren una situación más estable que cuando estaban separadas. Esta situación de mayor estabilidad suele darse cuando el número de electrones que poseen los átomos en su último nivel es igual a ocho, estructura que coincide con la de los gases nobles ya que los electrones que orbitan el núcleo están cargados negativamente, y que los protones en el núcleo lo están positivamente, la configuración más estable del núcleo y los electrones es una en la que los electrones pasan la mayor parte del tiempo "entre" los núcleos, que en otro lugar del espacio. Estos electrones hacen que los núcleos se atraigan mutuamente.

En la visión simplificada del denominado enlace covalente, uno o más electrones (frecuentemente un par de electrones) son llevados al espacio entre los dos núcleos atómicos. Ahí, los electrones negativamente cargados son atraídos a las cargas positivas de "ambos" núcleos, en vez de sólo su propio núcleo. Esto vence a la repulsión entre los dos núcleos positivamente cargados de los dos átomos, y esta atracción tan grande mantiene a los dos núcleos en una configuración de equilibrio relativamente fija, aunque aún vibrarán en la posición de equilibrio. En resumen, el enlace covalente involucra la compartición de electrones en los que los núcleos positivamente cargados de dos o más átomos atraen simultáneamente a los electrones negativamente cargados que están siendo compartidos. En un enlace covalente polar, uno o más electrones son compartidos inequitativamente entre dos núcleos.

En una visión simplificada de un enlace iónico, el electrón de enlace no es compartido, sino que es transferido. En este tipo de enlace, el orbital atómico más externo de un átomo tiene un lugar libre que permite la adición de uno o más electrones. Estos electrones recientemente agregados ocupan potencialmente un estado de menor energía (más cerca al núcleo debido a la alta carga nuclear efectiva) de lo que experimentan en un tipo diferente de átomo. En consecuencia, un núcleo ofrece una posición de más fuerte unión a un electrón de lo que lo hace el otro núcleo. Esta transferencia ocasiona que un átomo asuma una carga neta positiva, y que el otro asuma una carga neta negativa. Entonces, el "enlace" resulta de la atracción electrostática entre los átomos, y los átomos se constituyen en ((iones)) de carga positiva o negativa.

Todos los enlaces pueden ser explicados por la teoría cuántica, pero, en la práctica, algunas reglas de simplificación les permiten a los químicos predecir la fuerza de enlace, direccionalidad y polaridad de los enlaces. La regla del octeto y la (TREPEV) teoría de repulsión de pares de electrones de la capa de valencia son dos ejemplos.

Existen teorías más sofisticadas, como la teoría del enlace de valencia, que incluye la hibridación de orbitales y la resonancia, y el método de combinación lineal de orbitales atómicos dentro de la teoría de los orbitales moleculares, que incluye a la teoría del campo de los ligantes. La electrostática es usada para describir polaridades de enlace y los efectos que ejerce en las sustancias químicas.

Las primeras especulaciones respecto a la naturaleza del "enlace químico" son tan tempranas como en el siglo XII. Se suponía que ciertos tipos de especies químicas estaban unidas entre sí por un tipo de afinidad química. 

En 1704, Isaac Newton esbozó su teoría de enlace atómico, en "Query 31" de su "Opticks", donde los átomos se unen unos a otros por alguna "fuerza". Específicamente, después de investigar varias teorías populares, en boga en aquel tiempo, de cómo los átomos se podía unir unos a otros, por ejemplo, "átomos enganchados", "átomos pegados unos a otros por reposo", o "unidos por movimientos conspirantes", Newton señaló lo que inferiría posteriormente a partir de su cohesión que:

En 1819, a raíz de la invención de la pila voltaica, Jöns Jakob Berzelius desarrolló una teoría de combinación química, introduciendo indirectamente el carácter electropositivo y electronegativo de los átomos combinantes. A mediados del siglo XIX, Edward Frankland, F. A. Kekule, A. S. Couper, A. M. Butlerov y Hermann Kolbe, ampliando la teoría de radicales, desarrollaron la teoría de valencia, originalmente llamado "poder combinante" en que los compuestos se mantenía unidos debido a la atracción entre polos positivo y negativo. En 1916, el químico Gilbert N. Lewis desarrolló el concepto de enlace de par de electrones, en el que dos átomos pueden compartir uno y seis electrones, formando el enlace de un solo electrón, enlace simple, enlace doble, o enlace triple:

En las propias palabras de Lewis:

El mismo año, Walther Kossel lanzó una teoría similar a la de Lewis, con la diferencia de que su modelo asumía una transferencia completa de electrones entre los átomos, con lo que era un modelo de enlace iónico. Tanto Lewis y Kossel estructuraron sus modelos de enlace a partir de la regla de Abegg (1904).

En 1927, el físico danés Oyvind Burrau derivó la primera descripción cuántica matemáticamente completa de un enlace químico simple, el producido por un electrón en el ion de hidrógeno molecular (dihidrogenilio), H. Este trabajo mostró que la aproximación cuántica a los enlaces químicos podrían ser correctas fundamental y cualitativamente, pero los métodos matemáticos usados no podrían extenderse a moléculas que contuvieran más de un electrón. Una aproximación más práctica, aunque menos cuantitativa, fue publicada en el mismo año por Walter Heitler y Fritz London. El método de Heitler-London forma la base de lo que ahora se denomina teoría del enlace de valencia. En 1929, "sir" John Lennard-Jones introdujo el método de combinación lineal de orbitales atómicos (CLOA o dentro de la teoría de orbitales moleculares, sugiriendo también métodos para derivar las estructuras electrónicas de moléculas de F (flúor) y las moléculas de O (oxígeno), a partir de principios cuánticos básicos. Esta teoría de orbital molecular representó un enlace covalente como un orbital formado por combinación de los orbitales atómicos de la mecánica cuántica de Schrödinger que habían sido hipotetizados por los electrones en átomos solitarios. Las ecuaciones para los electrones de enlace en átomos multielectrónicos no podrían ser resueltos con perfección matemática (esto es, "analíticamente"), pero las aproximaciones para ellos aún producen muchas predicciones y resultados cualitativos buenos. Muchos cálculos cuantitativos en química cuántica moderna usan tanto las teorías de orbitales moleculares o de enlace de valencia como punto de partida, aunque una tercera aproximación, la teoría del funcional de la densidad, se ha estado haciendo más popular en años recientes.

En 1935, H. H. James y A. S. Coolidge llevaron a cabo un cálculo sobre la molécula de dihidrógeno que, a diferencia de todos los cálculos previos que usaban funciones solo de la distancia de los electrones a partir del núcleo atómico, usó funciones que sólo adicionaban explícitamente la distancia entre los dos electrones. Con 13 parámetros ajustables, ellos obtienen el resultado muy cercano al resultado experimental para la energía de disociación de enlace. Posteriores extensiones usaron hasta 54 parámetros y producen gran concordancia con los experimentos. Este cálculo convenció a la comunidad científica que la teoría cuántica podría concordar con los experimentos. Sin embargo, esta aproximación no tiene relación física con la teoría de enlace de valencia y orbitales moleculares y es difícil de extender a moléculas más grandes.

En el año 1927, la teoría de enlace de valencia fue formulada, argumentando esencialmente que el enlace químico se forma cuando dos electrones de valencia, en sus respectivos orbitales atómicos, trabajan o funcionan para mantener los dos núcleos juntos, en virtud a los efectos de disminución de energía del sistema. En 1939, a partir de esta teoría, el químico Linus Pauling publicó lo que algunos consideran uno de las más importantes publicaciones en la historia de la química: "Sobre la naturaleza del enlace químico". En este documento, tomando en cuenta los trabajos de Lewis, la teoría del enlace de valencia (TEV) de Heitler y London, así como su propio trabajo preliminar, presentó seis reglas para el enlace de electrones compartidos, aunque las tres primeras ya eran conocidas genéricamente: 

Sus tres últimas reglas eran nuevas:

A partir de este artículo, Pauling publicaría en 1939 un libro de texto, "Sobre la Naturaleza del Enlace Químico', que vendría a ser llamado por algunos como la "biblia" de la química moderna. Este libro ayudó a los químicos experimentales a entender el impacto de la teoría cuántica sobre la química. Sin embargo, la edición posterior de 1939 falló en explicar adecuadamente los problemas que parecían ser mejor entendibles por la teoría de orbitales moleculares. El impacto de la teoría del enlace de valencia declinó durante la década de 1960 y 1970 a la par con el crecimiento en popularidad de la teoría de orbitales moleculares, que estaba siendo implementada en muchos programas de grandes ordenadores. A partir de la década de 1960, los problemas más difíciles de la implementación de la teoría del enlace de valencia en programas de computadoras habían sido mayormente resueltos y la teoría del enlace de valencia vio un resurgimiento.

La teoría de los orbitales moleculares (TOM) usa una combinación lineal de orbitales atómicos para formar orbitales moleculares, que abarcan la molécula entera. Estos orbitales son divididos frecuentemente en orbitales enlazantes, orbitales antienlazantes, y orbitales de no enlace. Un orbital molecular es simplemente un orbital de Schrödinger que incluye varios, pero frecuentemente solo dos, núcleos. Si este orbital es del tipo en que los electrones tienen una mayor probabilidad de estar "entre" los núcleos que en cualquier otro lugar, el orbital será un orbital enlazante, y tenderá a mantener los núcleos cerca. Si los electrones tienden a estar presentes en un orbital molecular en que pasan la mayor parte del tiempo en cualquier lugar excepto entre los núcleos, el orbital funcionará como un orbital antienlazante, y realmente debilitará el enlace. Los electrones en orbitales no enlazantes tienden a estar en orbitales profundos (cerca a los orbitales atómicos) asociados casi enteramente o con un núcleo o con otro y entonces pasarán igual tiempo entre los núcleos y no en ese espacio. Estos electrones no contribuyen ni detractan la fuerza del enlace.

A pesar de que todos los electrones de un átomo giran alrededor de su núcleo, solo los electrones de valencia giran más lejos de él, mientras más alejados del núcleo se encuentren, más posibilidades tendrá ese átomo de interactuar con electrones de otro.

Los electrones de valencia interaccionan de distintas formas, ya que dependen de las características del otro átomo con el que pueda conjuntarse. Algunos átomos ceden sus electrones a otro para lograr su equilibrio, otros los ganan y a veces también los comparten. Por ejemplo, en el fluoruro de litio (LiF), uno de los átomos (el litio) dona su electrón de valencia, mientras que el flúor lo recibe. De esta forma se forman iones, átomos con carga neta, positivos (Li+) y negativos (F-).

La representación de Lewis se caracteriza por ilustrar los símbolos de los elementos y los electrones de valencia que hay alrededor de ellos como puntos o taches. Para interpretar la simbología del agua en la representación de Lewis, hay que saber que cada uno de los dos átomos de hidrógeno sólo cuenta con un electrón de valencia que pueden ser representados con un punto; mientras que el átomo de oxígeno tiene ocho electrones de los cuales seis son de valencia y se pueden representar con taches para diferenciarlos de los electrones de valencia del hidrógeno.

La mayoría de los átomos se unen compartiendo electrones mediante uno, dos o hasta tres pares. Para no colocar tantos puntos, cada par compartido se representa como una línea (H-O-H). Del mismo modo, casi todos los átomos muestran una tendencia a perder, ganar o compartir un número de electrones necesarios para completar ocho electrones de valencia (regla del octeto), tal como lo hace el oxígeno en la molécula del agua. Por otro lado, únicamente el hidrógeno completa dos, por lo que se dice que ha formado la regla del dúo al solo tener como máximo dos electrones. 

En algunos aspectos, la teoría del enlace de valencia es superior a la teoría de orbitales moleculares. Cuando se aplica a la molécula más simple de dos electrones, H, la teoría del enlace de valencia, incluso al nivel más simple de la aproximación de Heitler-London, produce una aproximación más cercana a la energía de enlace, y provee una representación más exacta del comportamiento de los electrones al formarse y romperse los enlaces químicos. En contraste, la teoría de orbitales moleculares simple predice que la molécula de hidrógeno se disocia en una superposición lineal de átomos de hidrógeno, e iones positivos y negativos de hidrógeno, un resultado completamente contrario a la evidencia física. Esto explica en parte por qué la curva de energía total versus la distancia interatómica del método de orbitales de valencia yace por encima de la curva del método de orbitales moleculares a todas las distancias y, más particularmente, para distancias mucho más grandes. Esta situación surge para todas las moléculas diatómicas homonucleares y es particularmente un problema para el F, para el que la energía mínima de la curva con la teoría de orbitales moleculares es aún mayor en energía que la energía de los dos átomos de flúor no enlazados.

Los conceptos de hibridación son versátiles, y la variabilidad en el enlace en muchos compuestos orgánicos es tan modesta que la teoría del enlace permanece como una parte integral del vocabulario del químico orgánico. Sin embargo, el trabajo de Friedrich Hund, Robert Mulliken, y Gerhard Herzberg mostró que la teoría de orbitales moleculares provee una descripción más apropiada de las propiedades espectroscópicas, magnéticas y de ionización de las moléculas. Las deficiencias de la teoría del enlace se hicieron aparentes cuando las moléculas hipervalentes (por ejemplo, el PF) fueron explicadas sin el uso de los orbitales "d" que eran cruciales en el esquema de enlace basado en hibridación, propuesto para tales moléculas por Pauling. Los complejos metálicos y compuestos deficientes en electrones (como el diborano) también resultaron ser mejor descritos por la teoría de orbitales moleculares, aunque también se han hecho descripciones usando la teoría del enlace de valencia.

En la década de 1930, los dos métodos competían fuertemente hasta que se observó que ambas eran aproximaciones a una teoría mejor. Si se toma la estructura de enlace de valencia simple y se mezcla en todas las estructuras covalentes e iónicas posibles que surgen de un juego particular de orbitales atómicos, se llega a lo que se llama la función de onda de interacción de configuración completa. Si se toma la descripción de orbital molecular simple del estado fundamental y se combina dicha función con las funciones que describen todos los estados excitados posibles usando los orbitales no ocupados que surgen del mismo juego de orbitales atómicos, también se llega a la función de onda de interacción de configuración completa. Puede verse que la aproximación de orbital molecular simple da demasiado peso a las estructuras iónicas, mientras que la aproximación de enlace de valencia simple le da demasiado poco. Esto puede ser descrito diciendo que la aproximación de orbitales moleculares simple es demasiado "deslocalizada", mientras que la aproximación de enlaces de valencia es demasiado "localizado".

Estas dos aproximaciones son ahora observadas como complementarias, cada una proveyendo sus propias perspectivas en el problema del enlace químico. Los cálculos modernos en química cuántica generalmente empiezan a partir de (pero finalmente van más allá) un orbital molecular en vez de una aproximación de enlace de valencia, no por algún tipo de superioridad intrínseca de la segunda, sino porque la aproximación de orbitales moleculares es mucho más rápidamente adaptable a computación numérica. Sin embargo, ahora hay mejores programas de enlace de valencia disponibles.

La tridimensionalidad de los átomos y moléculas hace difícil el uso de una sola técnica para indicar los orbitales y enlaces. En la fórmula química, los enlaces químicos (orbitales enlazantes) entre átomos están indicados por varios métodos diferentes de acuerdo al tipo de discusión. Algunas veces, se desprecian completamente. Por ejemplo, en química orgánica, la fórmula molecular del etanol (un compuesto en bebidas alcohólicas) puede ser escrito en papel como isómeros conformacionales, tridimensional, completamente bidimensional (indicando cada enlace con direcciones no tridimensionales), bidimensional comprimida (CH–CH–OH), separando el grupo funcional del resto de la molécula (CHOH), o sus constituyentes atómicos (CHO), de acuerdo a lo que se esté discutiendo. Algunas veces, incluso se marcan los electrones no enlazantes de la capa de valencia (con las direcciones aproximadas bidimensionalmente, estructura de Lewis). Algunos químicos pueden también representar los orbitales respectivos.

Estos enlaces químicos son fuerzas "intramoleculares", que mantienen a los átomos unidos en las moléculas. En la visión simplista del enlace localizado, el número de electrones que participan en un enlace (o están localizados en un orbital enlazante), es típicamente un número par de dos, cuatro, o seis, respectivamente. Los números pares son comunes porque las moléculas suelen tener estados energéticos más bajos si los electrones están apareados. Teorías de enlace sustancialmente más avanzadas han mostrado que la fuerza de enlace no es siempre un número entero, dependiendo de la distribución de los electrones a cada átomo involucrado en un enlace. Por ejemplo, los átomos de carbono en el benceno están conectados a los vecinos inmediatos con una fuerza aproximada de 1.5, y los dos átomos en el óxido nítrico no están conectados con aproximadamente 2.5. El enlace cuádruple también son bien conocidos. El tipo de enlace fuerte depende de la diferencia en electronegatividad y la distribución de los orbitales electrónicos disponibles a los átomos que se enlazan. A mayor diferencia en electronegatividad, con mayor fuerza será un electrón atraído a un átomo particular involucrado en el enlace, y más propiedades "iónicas" tendrá el enlace ("iónico" significa que los electrones del enlace están compartidos inequitativamente), estos enlaces son frecuentes entre átomos que se ubican a la izquierda de la tabla periódica (baja electronegatividad) y átomos que se encuentran a la derecha de la tabla periódica (más electronegativos), porque permite la transferencia de electrones de valencia produciendo iones. A menor diferencia de electronegatividad, mayores propiedades covalentes (compartición completa) del enlace, generalmente entre átomos vecinos de la tabla periódica.

Los átomos enlazados de esta forma tienen carga eléctrica neutra, por lo que el enlace se puede llamar no polar.

Ejemplo:


Los enlaces covalentes pueden ser simples (H - H) cuando se comparte un solo par de electrones, dobles (O = O) al compartir dos pares de electrones, triples cuando comparten tres tipos de electrones, o cuádruples cuando comparten cuatro tipos de electrones.

Los enlaces covalentes no polares se forman entre átomos iguales, no hay variación en el número de oxidación.
Los enlaces covalentes polares se forman con átomos distintos con gran diferencia de electronegatividades. La molécula es eléctricamente neutra, pero no existe simetría entre las cargas eléctricas originando la polaridad, un extremo se caracteriza por ser electropositivo y el otro electronegativo.

El enlace covalente polar es intermediado en su carácter entre un enlace covalente y un enlace iónico. Los enlaces covalentes polares se forman con átomos distintos con gran diferencia de electronegatividades. La molécula es eléctricamente neutra, pero no existe simetría entre las cargas eléctricas originando la polaridad, un extremo se caracteriza por ser electropositivo y el otro electronegativo.

Los enlaces covalentes pueden ser simples cuando se comparte un solo par de electrones, dobles al compartir dos pares de electrones, triples cuando comparten tres pares de electrones, o cuádruples cuando comparten cuatro pares de electrones.

La diferencia entre enlace simple doble y triple reside en que en un enlace simple los átomos están más alejados, lo que hace al enlace más débil (menor energía) por el contrario en uno triple los átomos están más cerca que en el simple, esto hace al enlace más energético y más fuerte por lo tanto más energético.

.Los enlaces covalentes no polares (0 o menor que 0,4) se forman entre átomos iguales, no hay variación en el número de oxidación. Los átomos enlazados de esta forma tienen carga eléctrica neutra.

En otras palabras, el enlace covalente es la unión entre átomos en donde se da un compartimiento de electrones, los átomos que forman este tipo de enlace son de carácter no metálico. Las moléculas que se forman con átomos iguales (mononucleares) presentan un enlace covalente pero en donde la diferencia de electronegatividades es nula.

Se presenta entre los elementos con poca diferencia de electronegatividad (< 1.7), es decir cercanos en la tabla periódica de los elementos químicos o bien, entre el mismo elemento para formar moléculas diatómicas.

Un enlace covalente es la unión química entre un elemento no metálico con otro no metálico. Dentro de estos se puede encontrar una clasificación según el tipo de enlace; existiendo el enlace sencillo (en el cual comparte un solo par de electrones); ejemplo del mismo se encuentra la molécula de ácido clorhídrico; el segundo es el enlace doble (en el cual se comparten dos pares de electrones); siendo ejemplo de ello la molécula de dióxido de carbono; el último caso representa lo que se define como triple enlace (en el cual se comparten tres pares de electrones); siendo ejemplo de ello la molécula diatómica de nitrógeno. Dentro de sus propiedades se encuentran: variedad en sus puntos de ebullición y fusión; geometrías moleculares definidas. polaridad del enlace debido a electronegatividades que difieren la carga eléctrica parcial del átomo enlazado. Se pueden encontrar como enlace covalente puro u homopolar (unión de dos o más átomos del mismo elemento) siendo ejemplo O₂; como enlace covalente polar o heteropolar (unión entre dos no metales diferentes) ejemplo de ello H₂O; por último el covalente coordinado (en la que un átomo se coordina para completar su octeto) siendo ejemplo el H₂SO4.

El enlace iónico es un tipo de interacción electrostática entre átomos que tienen una gran diferencia de electronegatividad. No hay un valor preciso que distinga la ionicidad a partir de la diferencia de electronegatividad, pero una diferencia sobre 2.0 suele ser iónica, y una diferencia menor a 1.7 suele ser covalente. En pocas palabras, un enlace iónico es aquel en el que los elementos involucrados aceptan o pierden electrones (se da entre un catión y un anión) o dicho de otra manera, es aquel en el que un elemento que tiene más electronegatividad se atrae con los electrones con menos electronegatividad. El enlace iónico implica la separación en iones positivos y negativos. Las cargas iónicas suelen estar entre –3e a +3e, este tipo de enlace es frecuente entre átomos de los grupos IA, IIA, IIIA que pierden electrones (Cationes) y átomos de los grupos VA, VIA, VIIA que ganan electrones (aniones).

Ejemplo:

La unión entre el sodio y el cloro, es un enlace iónico donde el sodio pierde 1 electron del último nivel de energía (3s) y el cloro gana ese electrón, completando 8 electrones en el último nivel de energía.

Na = formula_4 pierde un electrón formula_5 (catión)

Cl = formula_6 gana un electrón formula_7 (anión)

El enlace covalente coordinado, algunas veces referido como enlace dativo, es un tipo de enlace covalente, en el que los electrones de enlace se originan solo en uno de los átomos, el donante de pares de electrones, o base de Lewis, pero son compartidos aproximadamente por igual en la formación del enlace covalente. Este concepto está cayendo en desuso a medida que los químicos se pliegan a la teoría de orbitales moleculares. Algunos ejemplos de enlace covalente coordinado existen en nitronas y el borazano. El arreglo resultante es diferente de un enlace iónico en que la diferencia de electronegatividad es pequeña, resultando en una covalencia. Se suelen representar por flechas, para diferenciarlos de otros enlaces. La flecha muestra su cabeza dirigida al aceptor de electrones o ácido de Lewis, y la cola a la base de Lewis. Este tipo de enlace se ve en el ion amonio y en los complejos químicos, donde un átomo central (por lo general un catión metálico) está unido a otras moléculas denominadas ligandos.

Los enlaces con uno o tres electrones pueden encontrarse en especies radicales, que tienen un número impar de electrones. El ejemplo más simple de un enlace de un electrón se encuentra en el catión hidrógeno molecular, H. Los enlaces de un electrón suelen tener la mitad de energía de enlace, de un enlace de 2 electrones, y en consecuencia se les llama "medios enlaces". Sin embargo, hay excepciones: en el caso del dilitio, el enlace es realmente más fuerte para el Li de un electrón, que para el Li de dos electrones. Esta excepción puede ser explicada en términos de hibridación y efectos de capas internas.

El ejemplo más simple de enlace de tres electrones puede encontrarse en el catión de helio dimérico, He, y puede ser considerado también medio enlace porque, en términos de orbitales moleculares, el tercer electrón está en un orbital antienlazante que cancela la mitad del enlace formado por los otros dos electrones. Otro ejemplo de una molécula conteniendo un enlace de tres electrones, además de enlaces de dos electrones, es el óxido nítrico, NO. La molécula de oxígeno, O, también puede ser vista como si tuviera dos enlaces de 3-electrones y un enlace de 2-electrones, lo que justifica su paramagnetismo y su orden formal de enlace de 2.

Las moléculas con número impar de electrones suelen ser altamente reactivas. Este tipo de enlace solo es estable entre átomos con electronegatividades similares.

Los enlaces flexionados, también conocidos como enlaces banana, son enlaces en moléculas tensionadas o impedidas estéricamente cuyos orbitales de enlaces están forzados en una forma como de banana. Los enlaces flexionados son más susceptibles a las reacciones que los enlaces ordinarios.
El enlace flexionado es un tipo de enlace covalente cuya disposición geométrica tiene cierta semejanza con la forma de una banana. doble enlace entre carbonos se forma gracias al traslape de dos orbitales híbridos sp3. Como estos orbitales no se encuentran exactamente uno frente a otro, al hibridarse adquieren la forma de banana.

En el enlace de tres centros y dos electrones ("3c-2e"), tres átomos comparten dos electrones en un enlace. Este tipo de enlace se presenta en compuestos deficientes en electrones, como el diborano. Cada enlace de ellos (2 por molécula en el diborano) contiene un par de electrones que conecta a los átomos de boro entre sí, con un átomo de hidrógeno en el medio del enlace, compartiendo los electrones con los átomos de boro.

El enlace de tres centros y cuatro electrones ("3c-4e") explica el enlace en moléculas hipervalentes. En ciertos compuestos aglomerados, se ha postulado la existencia de enlaces de cuatro centros y dos electrones.

En ciertos sistemas conjugados π (pi), como el benceno y otros compuestos aromáticos, y en redes conjugadas sólidas como el grafito, los electrones en el sistema conjugado de enlaces π están dispersos sobre tantos centros nucleares como existan en la molécula o la red.

En muchos casos, la ubicación de los electrones no puede ser simplificada a simples líneas (lugar para dos electrones) o puntos (un solo electrón). En compuestos aromáticos, los enlaces que están en anillos planos de átomos, la regla de Hückel determina si el anillo de la molécula mostrará estabilidad adicional.

En el benceno, el compuesto aromático prototípico, 18 electrones de enlace mantiene unidos a 6 átomos de carbono para formar una estructura de anillo plano. El orden de enlace entre los diferentes átomos de carbono resulta ser idéntico en todos los casos desde el punto de vista químico, con una valor equivalente de aproximadamente 1.5.

En el caso de los aromáticos heterocíclicos y bencenos sustituidos, las diferencias de electronegatividad entre las diferentes partes del anillo pueden dominar sobre el comportamiento químico de los enlaces aromáticos del anillo, que de otra formar sería equivalente.

En un enlace metálico, los electrones de enlace se encuentran situados en una estructura de átomos. En contraste, en los compuestos iónicos, la ubicación de los electrones enlazantes y sus cargas son estáticas. Debido a la deslocalización o el libre movimiento de los electrones, se tienen las propiedades metálicas de conductividad, ductilidad y dureza.
El enlace metálico es similar al iónico; sin embargo, el primero es más compacto que el segundo, ya que el número de átomos que rodean a cada uno de ellos es mayor.

Con base en la estructura del enlace metálico es posible identificar las propiedades más características de los metales, tales como su conductividad eléctrica y calorífica (conductividad), la capacidad para extenderse en hilos muy finos (ductilidad) , la capacidad para obtener láminas finas (maleabilidad), densidades elevadas, puntos de fusión altos... etc.

El modelo más sencillo de enlace metálico se basa en una de las propiedades características de los metales: su baja electronegatividad (ceden electrones con facilidad). Así pues, el enlace metálico podemos describirlo como una distribución muy ordenada y compacta de iones positivos del metal (red metálica) entre los cuales se distribuyen los electrones perdidos por cada átomo a modo de “nube electrónica”. Es importante observar que los electrones pueden circular libremente entre los cationes, no están ligados (sujetos) a los núcleos y son compartidos por todos ellos. Esta nube electrónica hace de “colchón” entre las cargas positivas impidiendo que se repelan, a la vez que mantienen unidos los átomos del metal.

Características principales de los metales:


Los metales son propensos a perder sus electrones debido a su baja energía de ionización, es posible tomar en consideración a un átomo metálico como un catión unido al electrón de valencia que podría perder. En un metal tenemos muchísimos átomos unidos entre sí. Entonces, podemos considerar a un metal como un conjunto de cationes metálicos inmersos en un mar de electrones de valencia deslocalizados. La atracción electrostática entre carga positiva (del catión) y negativa (del electrón) mantiene fuertemente unidos a todos los átomos del metal.

El modelo del mar de electrones desarrolla de manera sencilla las propiedades de los metales. Por ejemplo: La ductilidad y maleabilidad ocurre debido a que la deslocalización de electrones ocurre en todas las direcciones a manera de capas. 

Hay cuatro tipos básicos de enlaces que se pueden formar entre dos o más moléculas, iones o átomos que de otro modo no estarían asociados. Las fuerzas intermoleculares originan que las moléculas se atraigan o repelan unas a otras. Frecuentemente, esto define algunas de sus características físicas (como el punto de fusión) de una sustancia.

Una gran diferencia de electronegatividad entre dos átomos enlazados fuertemente en una molécula ocasiona la formación de un dipolo (un par positivo-negativo de cargas eléctricas parciales permanentes). Los dipolos se atraen o repelen unos a otros.

En alguna forma este es un ejemplo de un dipolo permanente especialmente fuerte. Sin embargo, en el enlace de hidrógeno, el átomo de hidrógeno está más cerca a ser compartido entre los átomos donante y el receptor, en un enlace 3-c 2-e. Los enlaces de hidrógeno explican el punto de ebullición relativamente alto de los líquidos como el agua, amoníaco, y fluoruro de hidrógeno, comparado con sus contrapartes más pesadas en el mismo grupo de la tabla periódica.

Los dipolos instantáneos a dipolo inducido, o fuerzas de London, son las interacciones más débiles, pero también las más ubicuas, entre todas las sustancias químicas. Imagine el átomo de helio: en cualquier instante, la nube electrónica alrededor del átomo (que, de otro modo sería neutral) puede estar ligeramente desbalanceada, con momentáneamente más carga negativa en un lado que en el otro. Esto es a lo que se refiere como un dipolo instantáneo. Este dipolo, con su carga ligeramente desbalanceada, puede atraer o repeler a los electrones en los átomos de helio vecinos, estableciendo otro dipolo (dipolo inducido). Los dos átomos se estarán atrayendo por un instante, antes que la carga se rebalancee y los átomos se muevan.

La interacción catión-pi se presenta entre la carga negativa localizada de los electrones de un orbital pi, ubicados sobre y debajo del plano de un anillo aromático, y una carga positiva.

En el límite (irrealístico) del enlace iónico puro, los electrones están perfectamente localizados en uno de los dos átomos en el enlace. Tales enlaces pueden ser interpretados por la física clásica. Las fuerzas entre los átomos están caracterizadas por potenciales electrostáticos continuos isótropos. Su magnitud es una proporción simple a la diferencia de cargas.

Los enlaces covalentes se entiende mejor por la teoría del enlace de valencia o la teoría del orbital molecular. Las propiedades de los átomos involucrados pueden ser interpretadas usando conceptos tales como número de oxidación. La densidad electrónica en el enlace no está asignada a átomos individuales, en vez de ello está deslocalizada entre los átomos. En la teoría del enlace de valencia, los dos electrones en los dos átomos se emparejan con una fuerza de enlace que depende del traslape entre los orbitales. En la teoría del orbital molecular, la combinación lineal de orbitales atómicos (CLOA) ayuda a describir las estructuras de orbitales moleculares deslocalizados y las energías basadas en los orbitales atómicos de los átomos de los que proviene. A diferencia de los enlaces iónicos puros, los enlaces covalentes pueden tener propiedades de direccionalidad (anisotropía). Estas pueden tener sus propios nombres, como sigma y pi.

En el caso general, los átomos forman enlaces que son intermedios entre iónico y covalente, dependiendo de la electronegatividad relativa de los átomos involucrados. Este tipo de enlace es llamado algunas veces enlace covalente polar.

En 1985, los químicos de la Universidad de Rice en Texas, Robert F. Curl y Richard E. Smalley, y uno de la Universidad de Sussex, Harold Kroto utilizaron un láser de alta potencia para vaporizar grafito en un esfuerzo por crear moléculas poco comunes, que se creía existían en el espacio interestelar. La espectrometría de las masas reveló que uno de los productos resultó ser una especie desconocida con la fórmula (C). Debido a su tamaño y al hecho de que es carbono puro, esta molécula tiene una forma extraña en la que trabajaron varios investigadores utilizando papel, tijeras y cinta adhesiva. Posteriormente, mediciones espectroscópicas y de rayos X confirmaron que el (C) tenían la forma similar a una esfera hueca con un átomo de carbono localizado en cada uno de sus 60 vértices. Geométricamente, el buckybalón (abreviatura de "buckminsterfulerene") es la molécula más simétrica que se conoce. Sin embargo, a pesar de sus características peculiares, su esquema de enlace es simple. Cada carbono tiene una hibridación sp2, y tiene orbitales moleculares deslocalizados que se extienden sobre la estructura completa. El buckybalón, así como otros miembros de mayor peso representan un concepto completamente nuevo en la arquitectura molecular con implicaciones de largo alcance. Por ejemplo, se ha preparado con un átomo de helio dentro de su estructura. Por el descubrimiento del buckybalón los tres científicos fueron premiados con el premio Nobel de química 1996. 

Un descubrimiento fascinante, realizado en 1991 por científicos japoneses, fue la identificación de estructuras relacionadas con el buckybalón. Estas moléculas tienen una longitud de cientos de nanómetros y presentan una forma tubular con una cavidad interna aproximada de 15 nanómetros de diámetro.




</doc>
