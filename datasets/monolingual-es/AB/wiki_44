<doc id="40944" url="https://es.wikipedia.org/wiki?curid=40944" title="Ley seca">
Ley seca

La ley seca, también conocida como «prohibición» (en inglés, "prohibition"), es una controvertida medida que han aplicado ciertos Estados durante la historia, consistente en la ilegalización de la fabricación, transporte, importación, exportación y la venta de alcohol.

La ley seca, al prohibir el alcohol y no dar respuesta a la demanda existente, puede favorecer la generación de mercados negros y dinero negro, que consiguen el licor en otros lugares donde se produce, lo introducen ilegalmente y lo venden para satisfacer tal necesidad a un precio más alto, debido a que la demanda sigue siendo más alta que la oferta para el consumo de alcohol.

La prohibición más importante y mediática fue la enmienda XVIII de la Constitución de los Estados Unidos (conocida como Ley Voltead) apoyada por numerosos activistas anti-alcohol como Carrie Nation. La prohibición provocó un auge considerable del crimen organizado. Un buen ejemplo de esto fueron Al Capone (inspiración de infinidad de películas, como "Los intocables") y otros gánsteres estadounidenses. Un año después de la ratificación de esta enmienda quedó prohibida la manufactura, venta, transporte, importación y exportación de licores intoxicantes para ser usados como bebida en los Estados Unidos y en todo el territorio sometido a su jurisdicción. Fue ratificada en 1919 acogiéndose a la XVIII Enmienda, entró en vigor el 16 de enero de 1920 y derogada en 1933 con la XXI Enmienda de la Constitución norteamericana (dentro y fuera de los hogares). El 5 de diciembre de 1933 terminó oficialmente la ley seca.

La ley debió considerar excepciones, como en el caso de los médicos, que se lo recetaban a sus pacientes como un tratamiento terapéutico en situaciones muy específicas. Otras excepciones que hacía la ley seca, era uso religioso de vino para el rito cristiano y los rituales judíos del Sabbat. Estas situaciones eran demasiado excepcionales, como para servir excusa a la mayoría de los consumidores de alcohol.

La persistente demanda de bebidas alcohólicas, estimuló la fabricación y comercialización de licores, que se convirtió en una gran industria clandestina. la ilegalidad de esta práctica, causó que el alcohol tuviera precios elevadísimos en el mercado negro, atrayendo importantes bandas delincuentes. Una de los casos más importantes de esa época fue el de Al Capone y otros jefes de la mafia estadounidense, que ganaron millones de dólares a través del tráfico y comercialización clandestina, expandiendo sus actividades a casi todo el país y resultando involucrados en numerosos casos de corrupción junto con funcionarios y policías encargados de cumplir con la ley seca.

Se prohíbe el alcohol en muchos países musulmanes por una prescripción vetatoria que aparece en el Corán. Sin embargo, hay mucha diversidad en la aplicación según el país y la época.

Arabia Saudita prohíbe la producción, importación y consumo de alcohol e impone castigos severos a los que violan la prohibición: semanas o meses de cárcel y posiblemente latigazos y potro árabe. Kuwait también tiene leyes que vedan el consumo de alcohol, pero no se pena con latigazos, sino cárcel. Catar prohíbe la importación y castiga a los que se embriagan con sanciones de cárcel o deportación. Sin embargo, se puede conseguir alcohol en los restaurantes y bares de ciertos hoteles, y los ciudadanos extranjeros pueden obtener alcohol mediante un sistema de permisos.

Otros países de población musulmana mayoritaria, como Egipto, Siria, Líbano y Jordania, no tienen impedimentos sobre el alcohol y su producción y consumo son legales siempre que las personas alcancen la edad indicada por las leyes para comprar o consumir bebidas etílicas. En Turquía, el régimen islamista-conservador de Erdoğan implantó en 2013 una controvertida ley seca que prohíbe la venta de alcohol a partir de las 22:00 P.M. , así como en un radio de 100 m en torno a mezquitas y escuelas; además, la venta de bebidas espirituosas está negada en el lapso de 24 horas, mientras se realicen las elecciones generales, municipales o presidenciales.

No se tiene registro ni precedentes sino hasta comienzos del siglo XX, en la pequeña Isla del Príncipe Eduardo se decreta ley seca.


Existen varios tipos de leyes secas parciales, pero comúnmente se denominan así algunas regulaciones del comercio y consumo de alcohol, que se aplican en países donde el alcohol es aceptado como droga lícita. La principal regulación prohíbe la venta y el consumo público de bebidas alcohólicas en determinados horarios, y también en algunos países se prohíbe la venta y consumo de bebidas alcohólicas determinados días.

En Argentina, Bolivia, Brasil, Chile, Colombia, Costa Rica, Ecuador, El Salvador, Guatemala, México, Paraguay, Perú, Uruguay, Panamá y Venezuela esta norma entra en vigencia siempre cerca de cualquier tipo de elección a nivel nacional, como por ejemplo votaciones para Presidente y Congresistas de la República, Alcaldes o Presidentes Regionales. Dependiendo del país, la norma se aplica desde una determinada cantidad de horas antes del inicio de la elección hasta cierta cantidad de horas después de la misma. Se consigue así evitar que la intoxicación etílica de numerosas personas resultara en desmanes y desórdenes. En algunos de estos países, durante este período, no se puede beber ni expender ningún tipo de alcohol en lugares públicos. 

En Argentina, mediante la Ley Nacional de Lucha contra el alcoholismo (Nº 24.788), la mayoría de los municipios, en uso de sus facultades de poder de policía, prohíben, en los locales de expendio minorista (almacenes, quioscos, supermercados) la venta de bebidas con contenido alcohólico, desde las 21:00 y hasta las 09:00 del día siguiente. Esta disposición no rige para los locales de entretenimiento nocturno (bares, boliches, pubs, discotecas hasta las 5:00 a.m.).

A su vez, a través de un decreto firmado por el Gobierno Nacional en 2009 (decreto 149), se reglamentó que tanto en las publicidades como en los envases y en todos los puntos de venta de bebidas alcohólicas se deben exhibir ante el público consumidor, por cualquier medio —afiches, carteles, stickers, etc.—, y con letras con suficiente relieve, tamaño y visibilidad, las leyendas: "PROHIBIDA SU VENTA A MENORES DE 18 AÑOS" y "BEBER CON MODERACION"

Existe una ley seca especial para el período de elecciones, quedando prohibido la venta y/o consumo de bebidas alcohólicas desde doce horas antes de la apertura de los comicios y hasta tres horas luego del cierre.

En Chile, la razón de ser del primer tipo (restricción por horario) es regular parte del consumo y no el total. Uno de los argumentos para implantarla es que reduce los accidentes de tránsito e impide el consumo por parte de menores de edad entre otros. Consiste en limitar su venta hasta ciertas horas de la noche. Las botillerías (locales de venta de alcohol) deben cerrar a una hora determinada, que varía según lo establecido por el decreto municipal de cada comuna, pero por lo general es a las 3.00. 

Este tipo de prohibición sufre críticas y quejas de los consumidores y de los comerciantes. Los primeros argumentan que se les restringe sus libertades personales, y los segundos dicen que se generan pérdidas económicas. Otros están a favor, sobre todo quienes viven en los alrededores de pubs, restaurantes, discotecas y botillerías, argumentando que se disminuye la cantidad de ebrios en las calles, la suciedad, delincuencia y contaminación acústica, todo lo cual les da más tranquilidad para dormir y conservar el orden público.

También existe una ley seca especial para el período de elecciones, en la cual se prohíbe la venta y/o expendio de bebidas alcohólicas durante el día de la elección, excepto en los bares de hoteles. Además, también se prohíbe en las cercanías de estadios, aplicándose la ley seca especialmente cuando se juegan partidos de alta convocatoria, como el Superclásico del Fútbol Chileno entre Colo Colo y Universidad de Chile, o para los encuentros de la Selección Chilena de Fútbol, tanto en el Estadio Nacional como en el Estadio Monumental.

En Colombia se conoce como Ley Seca a la restricción que limita o prohíbe el expendio y consumo de bebidas alcohólicas en días especiales; generalmente días en los cuales existen eventos programados importantes como elecciones públicas, o ante la amenaza de disturbios políticos o deportivos que despierten rivalidades profundas (fue decretada en Bogotá en la final de fútbol del torneo apertura 2013). Su principal razón de ser es evitar que se presenten disturbios o estos se agraven cuando parte de la población participante se encuentra bajo influencia del alcohol. Este tipo de ley seca es habitual en los días de elecciones, y la fuerza de la tradición ha hecho que esta medida no sea controvertida. Según el Artículo 206 del Código Electoral Colombiano, la Ley Seca empieza a las 18 horas del día anterior a las elecciones y termina a las 6 horas del día siguiente. En la ciudad de Bogotá no es permitido el expendio de bebidas alcohólicas antes de las 10 horas todos los días del año en todos los establecimientos.

En Colombia se conoce como "Ley Zanahoria" a las restricciones de horario que aplican a bares y venta de alcohol a determinadas horas. Las restricciones suelen ser las de prohibir la venta de alcohol y el funcionamiento de bares y discotecas después de las 4 horas. Estas restricciones, las cuales han causado controversia similar a la chilena, son decretadas por las administraciones municipales o distritales.

La primera Ley Zanahoria, y que dio nombre a las demás restricciones, fue promulgada en 1995 en Bogotá, durante la primera administración de Antanas Mockus. Zanahoria es un término de argot colombiano para las conductas o personas sanas, generalmente usado en forma despectiva. Por lo general estas restricciones cobijan únicamente sitios públicos de ventas de alcohol, tales como licoreras, estancos, bares y discotecas; así como al consumo de alcohol en la calle, y no tienen jurisdicción sobre clubes privados ni sobre el consumo en los hogares. La ley ha provocado que muchos bares y discotecas hayan cambiado así su razón social, haciéndose llamar "club" y al amparo de vacíos legales se han popularizado los "after party", los cuales son establecimientos informales que funcionan en casas privadas, generalmente desocupadas, sin ningún tipo de publicidad.

En algunos cantones de Costa Rica, la norma entra en vigencia jueves y viernes de la Semana Santa.

Para el Jueves Santo y el Viernes Santo cada cantón determina si es prohibido vender bebidas alcohólicas, por lo que personeros de las distintas municipalidades acompañados por policías se encargan de cerrar estos establecimientos, y de sellar los lugares en los que se encuentra el alcohol.

Normalmente, los costarricenses compran el alcohol en los días previos a la vigencia de la ley seca, por lo que es común que se incremente la venta de bebidas alcohólicas y se consuma de igual manera en casas y recintos clandestinos durante la vigencia de la ley. Además, generalmente existe un mercado negro organizado en cada localidad para garantizar el suministro del licor.

En Ecuador está prohibida la venta, distribución y el consumo de bebidas alcohólicas 36 horas antes de las elecciones hasta a 12 horas después. Está prohibido el consumo y venta de bebidas alcohólicas en lugares públicos, los días domingos de todo el año. Desde junio 2016 es posible comprar bebidas alcohólicas los dias domingos en los supermercados, tiendas, abacerías, abarrotes, micromercados y gasolineras para el consumo exclusivamente en domicilios.

En España existen diversas regulaciones de ámbito autonómico que restringen los horarios de venta y los espacios de consumo de alcohol, conocidas genéricamente como "ley antibotellón", y cuyo objetivo es reducir el daño causado por el alcohol entre los jóvenes. El alcohol es considerado lícito en todo el territorio español, por lo que estas leyes, dependiendo de la Comunidad Autónoma, actúan de tres maneras:


En México se aplicó desde 1915 en todo el país la restricción de venta de bebidas alcohólicas 24 horas antes de los procesos electorales y durante toda la jornada de los comicios, actualmente ésta disposición se encuentra regulada en el artículo 300 de la Ley General de Instituciones y Procedimientos Electorales (LGIPE), dejando a partir de ese momento a criterio de cada estado y municipio su aplicación.
El consumo de bebidas alcohólicas en la vía pública está prohibido en prácticamente todo el territorio nacional.

En Perú, según la Ley Orgánica de Elecciones (artículo 351), se aplica una restricción de la venta de bebidas alcohólicas 24 horas antes de las 00 horas del día de la votación, hasta las 12.00 horas del día siguiente a las elecciones.

En Panamá, la ley seca es la prohibición de la venta y consumo de bebidas alcohólicas durante ciertas ocasiones del año o en situaciones especiales como las elecciones generales (en Panamá las elecciones de todos los cargos políticos: presidente, gobernadores, diputados, alcaldes... se realizan el mismo día). La prohibición es aplicada a nivel de las gobernaciones provinciales y también se halla conferida en el Código Electoral. Usualmente los días de duelo nacional se prohíbe el expendio y consumo, además del uso de música festiva por parte de las estaciones de radio y el cierre de los centros nocturnos tales como bares, discotecas, jardines, cantinas y clubes para caballeros. En los feriados del 9 de enero, Viernes Santo y el Día de los Difuntos es habitual que se establezca ley seca desde las 0:00 del día feriado hasta las 00:00 del día siguiente. En el caso especial del Día de los difuntos y el Viernes Santo se ha creado una conmoción en cuanto a la espera del fin de la ley seca; por tanto, es común que los centros de diversión nocturna estén rodeados de personas esperando la apertura de los mismos a las 0:01. Durante las elecciones, la prohibición ocurre desde las 12:00 p.m. del día antes de la elección y culmina a las 12:00 p.m del día siguiente a la elección. Las personas que se presenten en estado de ebriedad a los centros electorales son arrestadas y conducidos a la estación de la Policía Nacional más cercana para esperar que pasen los efectos de la bebida sobre los mismos y se les aplica la sanción establecida en el Código Electoral.

En Panamá también se conoce como Ley Zanahoria, al Decreto que impone la restricción de horario a la venta y consumo de licor, aplicado a bares y discotecas desde las 02:00 hasta las 09:00 horas. Estas restricciones han causado controversia entre los propietarios de estos negocios, ya que no incluyen a los hoteles y casinos, por lo que se espera un pronunciamiento de las autoridades judiciales, en cuanto a la legalidad del mismo.
En modificaciones posteriores al decreto ejecutivo Ley Zanahoria, se incluyó en la norma a los hoteles y casinos, por considerarlo un fuero especial y competencia desleal, el hecho de que los hoteles y casinos si pudieran vender licor, pero con la salvedad de que solo podrían hacerlo a personas que estuvieran hospedadas en dicho hotel.
El horario también se cambió al siguiente:
La prohibición tampoco incluye a lugares de expendio como supermercados, tiendas y abarroterías.

Durante la Pandemia de enfermedad por coronavirus de 2020 en Panamá se ha impuesto por las autoridades gubernamentales una ley seca desde el 24 de marzo hasta el fin de la emergencia nacional, es decir, de manera indefinida.

En República Dominicana también existe "la ley seca". El Presidente Leonel Fernández Reina dispuso por decreto el control del consumo y el expendio de bebidas alcohólicas. De domingo a jueves solo se puede vender hasta la medianoche, en los establecimientos comerciales tales como colmados, restaurantes, bares, etc. Los viernes y sábados el horario se extiende hasta las dos de la madrugada. Esta ley está afectando muy duramente a los restaurantes y bares, ya que el negocio que no cierre o no suspenda la venta de las bebidas alcohólicas pasado un minuto de la hora determinada por ley son clausurados y penados con multas, si no disponen de un permiso que los habilite a trabajar sin restricciones. En algunos restaurantes, bares y discotecas que se encuentren localizados en hoteles o resorts no tienen restricción de horarios.

En Venezuela el gobierno prohíbe la venta y distribución de bebidas alcohólicas en el territorio nacional 24 horas antes de cada elección, incluyendo restricciones a todos los vendedores, licorerías, supermercados, restaurantes, bares, clubs y cualquier local que venda bebidas alcohólicas.

existe una restricción parcial a la venta de bebidas alcohólicas, el horario para los expendios autorizados como licorerías y supermercados es de 11 a 20 de lunes a sábado, los bares y restaurantes pueden expender bebidas alcohólicas hasta más tarde, siendo los límites de los horarios controlados por los municipios, teniendo en cuenta las características de los locales, zona donde se ubican, etc. En días de elecciones (que son día domingo) se aplica la ley seca a licorerías, bares y restaurantes desde las 2 de la tarde del viernes hasta las 6 de la tarde del lunes.

Desde 2007 se aplica una Ley Semiseca durante Semana Santa y Carnavales, esto con el fin de disminuir la ingesta de alcohol por parte de los conductores que viajan en esta temporada, buscando así una reducción de los accidentes de tránsito. Sin embargo este espacio ha permitido los expendios ilegales de licor.



</doc>
<doc id="40946" url="https://es.wikipedia.org/wiki?curid=40946" title="Europa (desambiguación)">
Europa (desambiguación)

El término Europa puede referirse a:
















</doc>
<doc id="40953" url="https://es.wikipedia.org/wiki?curid=40953" title="Exudado">
Exudado

En medicina, un exudado es el conjunto de elementos extravasados en el proceso inflamatorio que se depositan en el intersticio de los tejidos o cavidades del organismo. Provoca edema, diferenciándose del trasudado por la mayor riqueza de proteínas y células.

Según el elemento predominante se habla de:


</doc>
<doc id="40959" url="https://es.wikipedia.org/wiki?curid=40959" title="Paria">
Paria

El término paria hace referencia a varios artículos:



</doc>
<doc id="40976" url="https://es.wikipedia.org/wiki?curid=40976" title="Idioma irlandés">
Idioma irlandés

El idioma irlandés o gaélico irlandés moderno (en irlandés: "Gaeilge") es un idioma goidélico de la familia de lenguas indoeuropeas originario de Irlanda y hablado históricamente por los irlandeses. Se estima que el número de personas en la isla que lo hablan como lengua nativa ronda entre 20 000 y 80 000, predominantemente en las regiones rurales occidentales. El irlandés era la lengua principal de la isla antes de que se produjese la conquista inglesa de Irlanda durante la Edad Media. Desde 1922 con la independencia de la República de Irlanda (llamado originalmente el Estado Libre Irlandés), ha sido el idioma oficial junto al inglés. En 1998 con el Acuerdo de Viernes Santo, fue reconocido oficialmente como lengua de minoría en Irlanda del Norte, un país constituyente del Reino Unido. El 13 de junio de 2005 se aprobó e incluyó como idioma de trabajo en la Unión Europea entrando en vigor el 1 de enero de 2007. El 22 de enero del mismo año, el ministro Noel Treacy, lo usó por primera vez en una reunión del Consejo de Ministros de la Unión Europea.

En la actualidad es idioma oficial en todos los territorios pertenecientes a Irlanda e Irlanda del Norte.

El "Departamento de la Gaeltacht de Asuntos Rurales y Comunitarios de Irlanda" estimó en 2003 que alrededor de 1 500 000 personas aseguraban tener conocimiento del idioma. En 2007, de los 4,3 millones de habitantes que poseía la república, el 40,8 % de la población era capaz de hablarlo.

Las comunidades y regiones donde se habla el irlandés se llaman "Gaeltachtaí" ("Gaeltacht" en singular) y la mayor de ellas es Connemara, en el Condado de Galway, incluyendo las islas Aran.

Al ser el irlandés un requerimiento de estudio en las escuelas públicas del país, muchos lo hablan con fluidez como segundo idioma nativo. Aunque el idioma principal de la isla es el inglés, existen varios periódicos, revistas y emisoras de radio en irlandés, especialmente en los "Gaeltachtaí". Desde 1996 existe un canal de televisión llamado Teilifís na Gaeilge ("Televisión del Irlandés") o TG4.

Los tres dialectos irlandeses principales son el del Ulster en el norte, el de Munster en el sur y el de Connacht en la región central y occidental de la isla. El irlandés pertenece a la división gaélica o goidélica de los idiomas célticos.

El irlandés forma parte del grupo céltico insular de las lenguas celtas. El celta insular se divide a su vez en dos subramas: el britónico y el goidélico, que comprende el irlandés.

En "An Caighdeán Oifigiúil" (el estándar de escritura oficial del irlandés) el nombre de la lengua es "Gaeilge" (pronunciado [ˈɡeːlʲɟə] en irlandés).

Antes de la simplificación de 1948, esta forma se deletreaba "Gaedhilge"; originalmente este era el genitivo de "Gaedhealg", la forma usada en irlandés moderno clásico. Ortografías anteriores del mismo incluyen "Gaoidhealg" ([ge:ʝəlg]) en irlandés medio y "Goídelc" ([goiðelg]) en irlandés antiguo. La ortografía moderna resulta de la eliminación de las letras 'dh' mudas en "Gaedhilge".

Otras formas del nombre encontradas en varios dialectos modernos del irlandés, además de "Gaeilge" que pertenece al sur de Connacht, incluyen "Gaedhilic/Gaeilic/Gaeilig" ([ˈɡeːlʲɪc]) o "Gaedhlag" ([ˈɡeːl̪əɡ]) en irlandés de Ulster e irlandés del norte de Connacht y "Gaedhealaing/Gaoluinn/Gaelainn" ([ˈɡˠeːl̪ˠɪŋ/ˈɡˠeːl̪ˠɪn]) en irlandés de Munster.

En inglés se le suele llamar generalmente "Irish" ("irlandés"). El término "Irish Gaelic" ("gaélico irlandés") suele usarse a menudo cuando los anglohablantes discuten la relación entre las tres lenguas goidélicas (irlandés, gaélico escocés y manés) o cuando la discusión puede generar confusión con el hiberno-inglés, el tipo de inglés que se habla en Irlanda. En inglés el gaélico escocés es generalmente conocido simplemente como "Gaelic" ("gaélico"). Fuera de Irlanda y también entre hablantes nativos de manera usual, el término "Gaelic" todavía se usa para referirse al idioma. El término arcaico "Erse" (de "Erische"), originalmente una forma en escocés de la palabra "Irish" aplicada en Escocia (por los habitantes de las tierras bajas escocesas) para todas las lenguas goidélicas, ya no es usado para ninguna de ellas, y en la mayoría de los contextos actuales es considerado peyorativo.

Las primeras pruebas del irlandés escrito son las inscripciones Ogam del siglo IV DC; esta etapa del idioma es conocida como paleoirlandés. Estas escrituras han sido encontradas a través de Irlanda y en la costa oeste de Gran Bretaña. El paleoirlandés cambió hacia el irlandés antiguo a lo largo del siglo V. El irlandés antiguo, a partir del siglo VI, usó el alfabeto latino y se encuentra principalmente en marginalia de manuscritos latinos. Para el siglo X el irlandés antiguo evolucionó en el irlandés medio, que era hablado a través de Irlanda, Escocia y la isla de Man. Es el lenguaje de un gran cuerpo de literatura, incluyendo el famoso Ciclo de Ulster. A partir del siglo XII el irlandés medio comenzó a evolucionar hacia el irlandés moderno en Irlanda, en gaélico escocés en Escocia y en el idioma manés en la Isla de Man. El irlandés moderno emergió desde el idioma literario conocido como irlandés moderno temprano en Irlanda y como gaélico clásico en Escocia; este fue usado a través del siglo XVIII. El irlandés moderno temprano, que databa del siglo XIII, fue el idioma literario tanto en Irlanda como en la parte gaeloparlante de Escocia, y autores como Geoffrey Keating dan fe del mismo.

A partir del siglo XVIII el idioma fue en declive, perdiendo terreno rápidamente contra el inglés, en parte las inteligentes restricciones dictadas por el gobierno británico - un evidente ejemplo del proceso conocido por los lingüistas como sustitución lingüística. En el siglo XIX perdió a una gran cantidad de sus hablantes debido a la muerte y a la emigración resultantes de la pobreza, particularmente durante la gran hambruna (1845-1849).

Al final del siglo XIX, miembros del movimiento por el Renacimiento gaélico hicieron esfuerzos para promover el aprendizaje y uso del irlandés en Irlanda.

El irlandés es reconocido por la Constitución de Irlanda como la primera lengua oficial y la lengua nacional de la República de Irlanda (siendo el inglés la segunda lengua oficial). Desde la fundación del Estado Libre Irlandés en 1922, el Gobierno irlandés requería un grado de competencia en gaélico para todos aquellos que eran nombrados en el posiciones dentro del servicio civil (incluyendo trabajadores postales, oficiales del fisco, inspectores agrícolas, etc.). Tener destreza en uno solo de los idiomas oficiales para entrar al servicio público se implementó en 1974, en parte a las acciones de organizaciones de protesta como el Movimiento por la Libertad de Idioma.

Mientras que el requisito del Primer Idioma Oficial también era eliminado para muchos trabajos en el servicio público, el irlandés permanecía como una asignatura obligatoria en todas las escuelas dentro de la república que recibieran fondos públicos. Aquellos que deseen enseñar en escuelas primarias del Estado deben aprobar exámenes obligatorios llamados ""Scrúdú Cáilíochta sa Ghaeilge"". La necesidad de aprobar irlandés o inglés en el "Certificado de Salida" para entrar a la Gardaí (policía irlandesa) se adoptó en septiembre de 2005, sin embargo, los candidatos tienen clases en el idioma durante los dos años de entrenamiento. Todos los documentos oficiales del Gobierno irlandés deben ser publicados en irlandés y en inglés o sólo en irlandés (de acuerdo a la Ley de Idiomas Oficiales de 2003, que es aplicada por ""an comisinéir teanga"", el ombudsman del idioma).

La Universidad Nacional de Irlanda requiere que todos los estudiantes que deseen embarcarse en una licenciatura en el sistema federal de la UNI que aprueben la asignatura de irlandés en el "Certificado de Salida" o los Exámenes GCE/GCSE. Se hacen excepciones a este requisito para estudiantes nacidos fuera de la República de Irlanda, aquellos nacidos en la República de Irlanda pero que completaron la educación primaria fuera de ella y para estudiantes diagnosticados con dislexia.

En 1938, el fundador de la "Conradh na Gaeilge", Douglas Hyde, fue investido como el primer Presidente de la República de Irlanda. La grabación de su discurso de inauguración, "Declaration of Office" en irlandés de Roscommon es casi la única prueba que sobrevive de alguien hablando en ese dialecto.

La Universidad Nacional de Irlanda, Galway requiere nombrar a personas competentes en el idioma irlandés, mientras que cumplan todos los demás requisitos de la vacante a la que serán nombradas. Este requerimiento está asentado en la Ley de la University College Galway, 1929 (Sección 3). Se espera que este requisito sea revocado en su debido momento.

Aunque la legislación parlamentaria moderna debe ser promulgada tanto en irlandés como en inglés, en la práctica frecuentemente solo está disponible en inglés. Esto es a pesar del artículo 25.4 de la Constitución de Irlanda que requiere que una "traducción oficial" de cualquier ley en un idioma oficial debe ser provista en el otro idioma oficial-a menos que haya sido aprobada en ambos idiomas.

Antes del establecimiento del Estado de Irlanda del Norte en 1921, el irlandés estaba reconocido como una asignatura escolar y como "celta" en algunas instituciones de tercer nivel. Entre 1921 y 1972, Irlanda del Norte tuvo un cierto grado de autonomía en su gobierno. Durante esos años, el partido político que mantenía el poder en el Parlamento de Stormont, el Partido Unionista del Ulster (UPP), era hostil al idioma. En las retransmisiones de los medios de comunicación, no se daba cobertura a los asuntos de la minoría cultural irlandesa y el idioma irlandés estuvo excluido de la radio y la televisión prácticamente durante los primeros cincuenta años del Estado de Irlanda del Norte. El idioma recibió un cierto grado de reconocimiento formal en Irlanda del Norte del Reino Unido bajo el Acuerdo de Viernes Santo de 1998, y después, en 2001, a través de la ratificación del gobierno con relación al idioma de la Carta Europea de las Lenguas Minoritarias o Regionales. El gobierno británico prometió legislar a favor del idioma como parte del Acuerdo de St. Andrews de 2006.

El irlandés es un idioma oficial de la UE desde el 1 de enero de 2007, implicando que los eurodiputados con fluidez en irlandés pueden hablarlo en el Parlamento Europeo y en sus comités, aunque en el caso de los últimos tienen que notificar con anticipación a un intérprete simultáneo para asegurar que lo que dirán sea interpretado en los otros idiomas. Aunque es una lengua oficial de la Unión Europea, y por el momento solo la reglamentación de decisiones conjuntas debe estar traducida al irlandés, debido a una derogación renovable de cinco años de lo que debe ser traducido, pedida por el Gobierno irlandés cuando negoció el nuevo estatus oficial del idioma. Cualquier expansión en el número de documentos que deban ser traducidos dependerá de los resultados de la primera revisión de los primeros cinco años o si las autoridades irlandesas buscan una extensión. El gobierno irlandés se ha comprometido a capacitar al número necesario de traductores e intérpretes y en asumir los costos necesarios.

Antes de que el irlandés se volviera un idioma oficial tenía el estatus de idioma de tratado, y sólo los documentos del más alto orden de la UE estaban disponibles en irlandés.

Hay partes de Irlanda donde el irlandés aún es hablado como una lengua materna tradicional de manera diaria. Estas regiones son conocidas colectivamente como "Gaeltacht", o en el plural irlandés "Gaeltachtaí". Aunque los hablantes con fluidez del irlandés, cuyos números han sido estimados por Donncha Ó hÉallaithe en veinte o treinta mil, son una minoría de los hablantes totales del idioma, representan una concentración más alta de hablantes que otras áreas del país y solamente en algunas áreas Gaeltacht (en especial las que tienen mayor fuerza en el idioma) este continúa siendo la lengua vernácula de la población general.

Hay regiones Gaeltacht en:

Existen algunas más pequeñas en:
Para resumir el alcance de su supervivencia: el irlandés permanece como una lengua vernácula en las siguientes áreas: sur de Connemara, desde un punto occidental de Spiddal, cubriendo Inverin, Carraroe, Rosmuck y las islas; las islas Aran; noreste de Donegal en el área alrededor de Gweedore, incluyendo Rannafast, Gortahork, los pueblos circundantes y la isla Tory; en el pueblo de Rathcarne, Condado de Meath.

Gweedore ("Gaoth Dobhair"), Condado de Donegal, es el distrito Gaeltacht más grande de Irlanda.

Las áreas Gaeltacht más fuertes numérica y socialmente son aquellas de Connemara Sur, el oeste de la península de Dingle y el noreste de Donegal, en donde la mayoría de los residentes usan el irlandés como lenguaje primario. Estas áreas son usualmente conocidas como la "Fíor-Ghaeltacht" ("verdadera Gaeltacht") y colectivamente tienen una población de poco menos de 20 000.
Decenas de cientos de adolescentes irlandeses acuden anualmente a las escuelas de verano de irlandés. Los estudiantes viven con familias en un Gaeltacht, asisten a clases, participan en deportes, van a "céilithe" y están obligados a hablar irlandés. En esas actividades se promueven toda clase de aspectos de la cultura y tradición irlandesas.

De acuerdo a la información obtenida por el Departamento Irlandés de Asuntos Comunitarios, Rurales y de Gaeltacht, solo un cuarto de los hogares en áreas oficialmente Gaeltacht hablan con fluidez el irlandés. El autor de un análisis detallado de la encuesta, "Donncha Ó hÉallaithe" del Instituto Galway-Mayo de Tecnología, describió la política seguida por el Gobierno irlandés para el gaélico como "un completo y absoluto desastre".

Hay una serie de dialectos distintos del irlandés. En términos generales, los tres principales dialectos coinciden con las provincias de Munster ("Cúige Mumhan"), Connacht ("Cúige Chonnacht") y Ulster ("Cúige Uladh"). Registros de algunos dialectos de Leinster fueron hechos por la Comisión de Folklore Irlandés entre otros cuerpos antes de su extinción. Terranova, en el este de Canadá, también tiene un dialecto menor del irlandés, muy parecido al irlandés de Munster hablado durante los siglos XVI y XVII (ver Irlandés de Terranova).

El irlandés de Munster es principalmente hablado en los Gaeltachtaí de Kerry ("Contae Chiarraí"), Ring ("An Rinn") cerca de Dungarvan ("Dún Garbháin") en el Condado de Waterford ("Contae Phort Láirge") y Muskerry, ("Múscraí") y la isla Cape Clear ("Oileán Chléire") en la parte occidental del Condado de Cork ("Contae Chorcaí"). La subdivisión más importante en Munster es entre el irlandés Decies ("Na Déise") (hablado en Waterford) y el resto del irlandés de Munster.

Algunas características típicas del irlandés de Munster son:

El dialecto más fuerte del irlandés de Connacht se encuentra en Connemara y las islas Aran. Más cercano al Gaeltacht de Connacht es el dialecto hablado en la pequeña región en la frontera entre Galway ("Gaillimh") y Mayo ("Maigh Eo"). El dialecto del norte de Mayo de Erris ("Iorras") y la isla Achill ("Acaill") es, en gramática y morfología esencialmente un dialecto de Connacht, pero muestra algunas similitudes con el irlandés de Ulster debido a una inmigración a gran escala de la gente desposeída después de la Colonización del Ulster.

Hay algunas características en el irlandés de Connemara fuera del estándar oficial - notablemente la preferencia de sustantivos verbales terminados en "-achan", p.e. "lagachan" en lugar de "lagú", "debilitante". La pronunciación fuera del estándar del área Cois Fharraige con vocales alargadas y terminaciones fuertemente reducidas le da un sonido distinto. Las características distintivas del dialecto de Connacht y Ulster incluyen la pronunciación de las "bg" y "mh" cerradas como [w], en lugar de [vˠ] en Munster. Por ejemplo "sliabh" ("montaña") es pronunciada [ʃlʲiəw] en Connacht y Ulster en comparación a [ʃlʲiəβ] en el sur. Además, los hablantes de Connacht y Ulster tienden a incluir el pronombre "nosotros" en vez de usar la forma compuesta estándar usada en Munster, p.e. "bhí muid" es usado para "nosotros fuimos" en lugar de "bhíomar".

Como en el irlandés de Munster, antes de -nn, -m, -rr, -rd, -ll, en palabras monosilábas y en la sílaba tónica de palabras polisílabas donde la sílaba es seguida por una consonante, algunas vocales breves son alargadas mientras que otras son diptongadas, por lo que "ceann" [kʲaun] "cabeza", "cam" [kɑum] "torcido", "gearr" [gʲa:r] "corto", "ord" [o:rd] "mazo", "gall" [gɑul] "extranjero, no-Gael", "iontas" [u:ntəs] "una maravilla", etc.

El irlandés de Meath de hoy en día (en Leinster) es un caso especial. Pertenece principalmente al dialecto de Connemara. La comunidad gaeloparlante en Meath es por la mayor parte un grupo de hablantes de Connemara que se mudaron ahí durante la década de 1930, después de la campaña por reforma de la tierra liderada por Máirtín Ó Cadhain - quien subsecuentemente se convirtió en uno de los principales escritores modernistas del lenguaje.

El primer presidente irlandés Douglas Hyde fue uno de los últimos hablantes del dialecto irlandés de Roscommon.

Lingüísticamente el dialecto más importante del Ulster hoy es el de Rosses ("na Rossa"), que ha sido usado exhaustivamente en la literatura por autores como los hermanos Séamus Ó Grianna y Seosamh Mac Grianna, localmente conocidos como Jimí Fheilimí y Joe Fheilimí. Este dialecto es esencialmente el mismo que el de Gweedore ("Gaoth Dobhair" = Ensenada/Entrada de Agua Corriente), y es usado por cantantes nativos como Enya ("Eithne") y Moya Brennan ("Máire Brennan") y sus hermanos en Clannad ("Clann as Dobhar" = Familia del Dobhar - una sección de Gweedore), Na Casaidigh y Mairéad Ní Mhaonaigh de otra banda local, Altan.

El irlandés del Ulster suena muy diferente, comparte muchas características con el gaélico escocés y tiene muchas palabras con características y matices en los significados. Sin embargo, desde la desaparición de los dialectos irlandeses en lo que era Irlanda del Norte, es probablemente una exageración ver el Irlandés del Ulster como una forma intermediaria entre el gaélico escocés y los dialector del sur y el oeste del irlandés. Por ejemplo, el gaélico escocés del norte tiene muchas características en común con el irlandés de Munster y no con el del Ulster.

Un rasgo notable del irlandés del Ulster y el gaélico escocés es el uso de una partícula negativa "cha(n)" en lugar del Munster y Connacht "ní". El irlandés del sur del Ulster retiene "ní" de manera más pronunciada, mientras que "cha(n)" ha desplazado a "ní" en la mayoría de los dialectos del norte (p.e. Rosguill y la isla Tory), aunque aún en estas áreas "níl" ("no es") es más común que "chan fhuil" o "cha bhfuil".

"An Caighdeán Oifigiúil" ("El Estándar Oficial"), a veces acortado a "An Caighdeán", es la lengua estándar que es enseñada en la mayoría de las escuelas en Irlanda, aunque con fuertes influencias de dialectos locales.

Su desarrollo tuvo dos propósitos. Uno fue simplificar la ortografía irlandesa que había retenido su ortografía clásica, removiendo muchas letras mudas, y darle a la forma escrita un estándar que fuera un "dialecto libre". Aunque muchos aspectos del Caighdeán son esencialmente las del irlandés de Connacht, esto era simplemente porque es el dialecto central que forma un "puente" entre el norte y el sur. En realidad, los hablantes pronuncian las palabras como en su propio dialecto, pues la ortografía simplemente refleja la pronunciación del irlandés clásico. Por ejemplo, "ceann" ("cabeza") en el irlandés moderno temprano era pronunciado (cenˠː). La ortografía fue retenida, pero la palabra se pronuncia de maneras diversas [caun] en el sur, [cɑːn] en Connacht y [cænː] en el norte. "Beag" ("pequeño") era [bʲɛɡ] en irlandés moderno temprano, y es ahora [bʲɛɡ] en irlandés de Waterford, [bʲɔɡ] en irlandés de Cork-Kerry, varía entre [bʲɔɡ] y [bʲæɡ] en el oeste, y es [bʲœɡ] en el norte.

La simplificación, sin embargo, en algunos casos probablemente fue demasiado lejos al simplificar el estándar tomando en cuenta solo al oeste. Por ejemplo, el irlandés moderno temprano "leabaidh", [lʲebʷɨʝ], ("cama") se pronuncia [lʲabʷə] así como [lʲabʷɨɟ] en irlandés de Waterford, [lʲabʷɨɟ] en irlandés de Cork-Kerry, [lʲæbʷə] en irlandés de Connacht, [lʲæːbʷə] en irlandés de Cois Fharraige y [lʲæbʷi] en el norte. Los hablantes nativos desde el norte hasta el sur consideran que "leabaidh" debe ser la representación en el Caighdeán y no el actual "leaba".

Por otro lado, el Caighdeán no llegó lo suficientemente lejos en muchos casos. Por ejemplo, ha mantenido la ortografía del irlandés clásico de "ar" ("en, para, etc.") y "ag" ("a, por, de, etc."). La primera es pronunciada [ɛɾʲ] a través del mundo de habla goidélica (y es escrita "er" en manés, y "air" en gaélico escocés), y debe ser escrita ya sea "eir", "oir" o "air" en irlandés. La segunda se pronuncia [ɪɟ] en el sur y [ɛɟ] en el norte y oeste. De nuevo, el manés y el gaélico escocés reflejan esta pronunciación mucho más claramente que el irlandés lo hace, en manés "ec" y en escocés "aig".

En muchos casos, sin embargo, el Caighdeán solo puede referirse a la lengua clásica, en que cada dialecto es diferente, como sucede en las formas personales de "ag" ("a, por, de, etc.").


Otro propósito fue el crear un estándar gramáticamente "simplificado" que lo hicieran un lenguaje más fácil de aprender para la mayoría de la población escolar angloparlante. En parte esto es porque el Caighdeán no es universalmente respetado por los hablantes nativos, en que hace el idioma simplificado un ideal, en vez del ideal que los hablantes nativos tradicionalmente tenían de sus dialectos (o del dialecto clásico que conocían). Por supuesto, este no era el objetivo original de sus desarrolladores, quienes preferían ver la "versión escolar" del Caighdeán como un medio de facilitarle a los aprendices de una segunda lengua la tarea de aprender el irlandés de manera completa. El sistema de verbos del Caighdeán es el principal ejemplo, con la reducción de formas verbales irregulares y formas personales del verbo - excepto en las primeras personas. Sin embargo, una vez que la palabra "estándar" se comenzói a usar, las formas representadas como "estándar" tomaron poder por sí mismas, y por lo tanto el fin último ha sido olvidado en muchos círculos.

El Caighdeán es, en general, hablado por hablantes no nativos, y como muchos de los hablantes más influyentes son de la capital (y son muy a menudo políticos), es a veces llamado "irlandés de Dublín". Como es enseñado en las escuelas gaeloparlantes (donde el irlandés es el principal o a veces el único, medio de instrucción), es a veces también llamado "Irlandés de Gaelscoil". Es también la base del llamado "irlandés de Belfast", que es el Caighdeán fuertemente influenciado por el irlandés del Ulster.

Las diferencias entre dialectos es considerable y ha llevado a dificultades recurrentes para definir un irlandés estándar. Un buen ejemplo es el saludo "¿Cómo estás?". Así como este saludo varía de región en región, y entre clases sociales, entre hablantes del inglés, este saludo varía entre hablantes irlandeses:


En décadas recientes contacto entre hablantes de diferentes dialectos se ha vuelto más frecuente y las diferencias entre los dialectos son menos notables.

Las características más desconocidas para los angloparlantes del idioma son la ortografía, las mutaciones de consonante inicial, el orden verbo sujeto objeto y el uso de dos formas diferentes del verbo "to be" (ser/estar). Sin embargo, ninguna de ellas es exclusiva del irlandés, pues todas ocurren en otras lenguas celtas, así como en lenguas no-celtas: la mutación de consonantes iniciales provocadas morfosintácticamente se encuentra en el idioma fula, el orden VSO también se encuentra en malgache, árabe clásico y hebreo bíblico, y el euskera, el catalán, el portugués,el asturleonés, el español y el italiano distinguen entre "ser" y "estar".
El orden de las palabras en irlandés es VSO (verbo-sujeto-objeto) por lo que, por ejemplo, "Él me golpeó" es "Bhuail" (golpear en pasado), "sé" (él), "mé" (me).

Un aspecto de la sintaxis irlandesa desconocida para los hablantes de otras lenguas es el uso de la copula (conocida en irlandés como "an chopail"). Se usa para describir la identidad o característica permanente de una persona o cosa (p.e. "quién" o "qué"), en contraste a los aspectos temporales tales como "cómo", "dónde" y "porqué". Esto se parece a la diferencia entre los verbos "ser" y "estar" en español y portugués (ver Cópula Romance), aunque no es exactamente lo mismo.

Algunos ejemplos son:

Otra característica de la gramática irlandesa que es compartida con otras lenguas celtas es el uso de pronombres preposicionales "forainmneacha réamhfhoclacha", que son esencialmente preposiciones conjugadas. Por ejemplo, la palabra para "a" es "ag", que en primera persona se vuelve "agam" ("a mí"). Cuando se usa con el verbo "bí" ("ser"), "ag" indica posesión; es el equivalente del verbo "tener".


El alfabeto que usa el irlandés moderno es similar al del inglés sin las letras j, k, q, v, w, x, y, z; sin embargo algunas palabras anglicanizadas sin un significado único irlandés como "Jeep" se escriben como 'Jíp'. Algunas palabras toman una letra o algunas letras que no se usan tradicionalmente y la reemplazan con el sonido fonético más cercano, p.e. 'phone'>'Fón'. El lenguaje escrito parece desalentador para aquellos que no están familiarizados con él, sin embargo una vez que es entendido es bastante sencillo. El acento agudo o "sínead fada" (´), sirve para alargar el sonido de la vocal y en algunos casos también cambia su cualidad. Por ejemplo, en irlandés de Munster (Kerry), "a" es /a/ o /ɑ/ y "á" es /ɑː/ como en ""law"", pero en irlandés del Ulster (Donegal), "á" tiende a ser /æː/.

En los años de la Segunda Guerra Mundial, Séamus Daltún, a cargo del "Rannóg an Aistriúcháin" (el departamento oficial de traducciones del gobierno de la República de Irlanda), publicó sus propias guías sobre cómo estandarizar la ortografía y gramática de la lengua irlandesa. Este estándar de facto fue posteriormente aprobado por el Estado y fue llamado Estándar Oficial o "Caighdeán Oifigiúil". Simplificó y estandarizó la ortografía. Muchas palabras tenían letras mudas que fueron eliminadas y combinaciones de vocales fueron llevadas más cerca del lenguaje hablado. Cuando existían varias versiones en diferentes dialectos para una misma palabra, se escogió una o varias de ellas.

Ejemplos:

La ortografía estándar no siempre refleja la pronunciación de cada dialecto. Por ejemplo, en irlandés estándar, "bia" tiene el genitivo "bia", pero en irlandés de Munster el genitivo se pronuncia /bʲiːɟ/. Por esta razón, la ortografía "biadh" aún es usada por los hablantes de algunos dialectos, en particular aquellos que muestran una diferencia auditiva significativa y percibible entre "biadh" (caso nominativo - "de comida") y "bídh" (caso genitivo - "de la comida"). En Munster, la última ortografía produce la pronunciación /bʲiːɟ/ porque las terminaciones "-idh" e "-igh" se vuelve "-ig". Otro ejemplo puede ser la palabra "crua" ("duro") que es pronunciada /kruəɟ/ en Munster, de acuerdo a la ortografía pre-Caighdeán, "cruaidh". En Munster, "ao" se pronuncia /eː/ y "aoi", /iː/, sin embargo la nueva ortografía del genitivo de "saoghal" ("vida" o "mundo"): "saoghail", se volvieron "saoil" y "saol", produciendo irregularidades en la concordancia entre la ortografía y la pronunciación ya que la palabras son pronunciadas /sˠeːlʲ/ y /sˠeːl̪ˠ/ respectivamente.

El irlandés moderno solo tiene un signo diacrítico, el acento agudo ("á é í ó ú"), conocido en irlandés como la "síneadh fada" ("marca larga", plural "sinte fada"). En inglés, es conocida frecuentemente como la "fada" cuando el adjetivo es usado como sustantivo. El punto diacrítico superior, llamado un "ponc séimhithe" o "sí buailte" (usualmente acortado a "buailte", deriva del "punctum delens" usado en manuscritos medievales que indicaban supresión, similar a tachar palabras indeseadas en la escritura de hoy en día. Desde ese entonces ha sido usado para indicar la lenición de "s" (/s/ a /h/) y "f" (de /f/ a cero) en Idioma irlandés antiguo.

La lenición de "c", "p" y "t" era indicada poniendo una letra "h" después de la consonante afectada; la lenición de otros sonidos no se marcaba. Posteriormente ambos métodos fueron extendidos a ser indicadores de lenición de todo sonido excepto "l" y "n" y dos sistemas rivales eran usados: lenición podía ser marcada por un "buailte" o por una "h" pospuesta. Eventualmente el uso del "buailte" predominaba en textos que usaban las letras gaélicas, mientras que la "h" predominaba en textos usando las letras romanas.

Hoy la caligrafía celta y el "buailte" son usadas raramente excepto cuando el estilo "tradicional" es requerido, p.e. el lema del escudo de la University College Dublin o el símbolo de las Fuerzas de Defensa Irlandesas, la insignia en el sombrero de las Fuerzas de Defensa Irlandesas, "Óglaiġ na h-Éireann". Letras con el "buailte" están disponibles en Unicode y en el juego de caracteres Latin-8.

En irlandés hay dos clases de mutación consonántica:


En la actualidad, la lengua irlandesa es asignatura obligatoria en la República de Irlanda y lo ha sido desde la independencia. Aunque muchos estudiantes aprenden bien el irlandés a través del programa educativo de la República, y desarrollan también un saludable respeto por él, muchos otros lo encuentran difícil o se les enseña mal por parte de profesores desmotivados. La actitud de estos estudiantes hacia el irlandés oscila entre la apatía y la hostilidad.

La sintaxis, la morfología y el vocabulario del idioma difieren más del inglés que muchas otras lenguas europeas, lo cual provoca que el aprendizaje suponga un reto para muchos. El gobierno irlandés se ha esforzado en corregir la situación volviendo a diseñar el currículo de Educación Primaria para enfocarlo en el irlandés hablado. Sin embargo, en Secundaria el irlandés se enseña todavía de la manera académica propia de principios de siglo: los estudiantes deben escribir largos ensayos, artículos de debates e historias en irlandés para el examen del título de secundaria.

Recientemente se ha discutido la abolición de la obligatoriedad del irlandés. Mientras que están en contra , la mayoría de los irlandeses no está de acuerdo. En 2005 Enda Kenny, líder del Fine Gael (entonces principal partido de la oposición en Irlanda) y actual Taoiseach, solicitó que fuera asignatura optativa en los dos últimos años de secundaria, lo que atrajo críticas desde muchos sectores, aunque hay quien lo apoyó. Kenny, a pesar de ser un hablante fluido de irlandés, dijo que creía que hacer obligatorio el idioma le había hecho más mal que bien.

Un desarrollo relativamente reciente es la proliferación de los "gaelscoileanna", es decir, escuelas donde el irlandés es la lengua vehicular de la educación. En septiembre de 2005 había 158 "gaelscoileanna" en educación primaria y 36 en secundaria en la República de Irlanda y en Irlanda del Norte en conjunto (excluyendo los "gaeltacht", cuyas escuelas no son considaradas "gaelscoileanna"), lo que significaba unos 31.000 estudiantes. Esto ha representado un incremento desde un total de menos de 20 a principios de los años setenta, y hay planeadas 15 más en el presente. Con la apertura del "Gaelscoil Liatroma" en el condado de Leitrim en 2005, hay ahora al menos una "gaelscoil" en cada uno de los 32 condados históricos de Irlanda.

Tanto en Irlanda del Norte como en la República de Irlanda existen los siguientes medios de comunicación cuyos contenidos están íntegramente creados en lengua irlandesa.

Las características más extrañas de la lengua son la ortografía, la mutación de consonantes iniciales y el orden verbo-sujeto-objeto (VSO). Sin embargo, al igual que en el castellano, existen los verbos ser y estar, que en inglés sería solo el verbo "to be." Estas características no son exclusivas del idioma irlandés ya que se encuentran en otras lenguas celtas así como en lenguas no célticas: morfosintácticamente la mutación de consonantes iniciales se encuentra en el idioma fula (lengua hablada en África occidental), y el orden de palabras VSO se encuentra en el árabe clásico y el hebreo bíblico.

El orden de las palabras sigue el patrón VSO, por ejemplo: "Él me golpeó" sería "Bhuail" (golpear) "sé" (él) "mé" (me, a mí). Un aspecto del irlandés que no es familiar a hablantes de otros idiomas es el uso de la cópula (en irlandés: "chopail"). La cópula es usada para describir qué o quién es alguien, en oposición a cómo o dónde. Es usada para decir que un nombre es otro nombre más que un adjetivo, algo parecido a los verbos ser y estar del español.




San Juan V 1 -8

En la Gaeltacht y en los condados de Kerry (SO), Galway (O) y Donegal (NO), muchos refranes y proverbios populares se dicen y escuchan en lengua irlandesa.





</doc>
<doc id="40978" url="https://es.wikipedia.org/wiki?curid=40978" title="ISO 3166-2:JP">
ISO 3166-2:JP

Los códigos ISO 3166-2 para Japón abarcan 47 prefecturas. La primera parte es el código JP de la ISO 3166-1 para Japón, la segunda parte es numérica, de dos dígitos. El propósito de esta familia de estándares es establecer una serie mundial de abreviaturas cortas para los lugares, para el uso en etiquetas de paquetes, envases y objetos similares. Un código alfanumérico corto puede servir para indicar claramente una localización en una forma más conveniente y menos ambigua que el topónimo completo. 

Los nombres de las subdivisiones se enumeran en la norma ISO 3166-2 publicada por la Agencia de Mantenimiento ISO 3166 (ISO 3166/MA).



</doc>
<doc id="40983" url="https://es.wikipedia.org/wiki?curid=40983" title="Tel Aviv">
Tel Aviv

Tel Aviv-Yafo (en , en árabe "Tall ʾAbīb-Yāfā"), usualmente llamada Tel Aviv, es la segunda ciudad más grande de con una población estimada de 411 800 habitantes. Tiene una superficie de 51,4 km² y está situada en la costa mediterránea de Israel. Se trata de la mayor y más poblada ciudad en el área metropolitana del Gush Dan, donde residen 3 850 000 personas. El actual alcalde de la ciudad es Ron Huldai.

Tel Aviv, establecida en julio de 1906, fue fundada oficialmente el segundo día de Pésaj de 1909, en las afueras de la antigua ciudad portuaria de Jaffa (en , "Yafo"). El crecimiento de Tel Aviv hizo que pronto superara a Jaffa en población; finalmente, ambas ciudades se fusionaron en un solo municipio en 1950, dos años después de la creación del Estado de Israel.

Desde 2003, su «Ciudad Blanca» de arquitectura Bauhaus fue declarada Patrimonio de la Humanidad por la Unesco, ya que comprende la más grande concentración de edificios del Movimiento Moderno del mundo.

Es el centro de la economía global israelí, el hogar de la Tel Aviv Stock Exchange y muchas oficinas corporativas y centros de investigación y desarrollo, referencia de la zona conocida popularmente como "Silicon Wadi".

También está considerada la capital cultural israelí debido a su carácter cosmopolita y moderno y un importante centro de artes escénicas. Sus playas, cafés, tiendas de lujo y estilo de vida secular la han convertido en un popular destino turístico. En 2008, una encuesta de la consultora "Mercer" sobre el costo de vida clasificó a Tel Aviv como la ciudad más cara en el Oriente Medio y la 14.ª más cara del mundo.

Su nombre significa en hebreo, literalmente, «la colina ("Tel") de la primavera ("Aviv")», en alegoría al libro del fundador del sionismo político, Theodor Herzl, "Altneuland", «Vieja Tierra Nueva». «Tel Aviv» es también el nombre de un suburbio judío de Babilonia () del tiempo de este profeta.

Tel Aviv se encuentra a unos en la llanura costera de Israel, en el centro de Israel, el histórico puente terrestre entre Europa, Asia y África. Inmediatamente al norte del antiguo puerto de Yaffo, Tel Aviv se encuentra en terrenos que solían ser dunas de arena y, como tal, tiene tierras poco fértiles. La tierra ha sido aplanada y tiene importantes pendientes, sus accidentes geográficos más notables son acantilados sobre la costa del Mediterráneo y la desembocadura del río Yarkon. Debido a la expansión de Tel Aviv y la región de Gush Dan, las fronteras entre Tel Aviv y Yaffo y entre los barrios de la ciudad ya no existen.

La ciudad se encuentra localizada a 60 kilómetros al noroeste de Jerusalén y a 90 kilómetros al sur de la ciudad de Haifa. Entre las ciudades y pueblos colindantes se incluyen Herzliya al norte, Ramat HaSharon al noreste, Petah Tikva, Bnei Brak, Ramat Gan y Giv'atayim al este, Holon al sureste, y Bat Yam al sur. La ciudad es económicamente estratificada entre el norte y el sur del país. El sur de Tel Aviv es generalmente más pobre que el norte de dicha ciudad, con la excepción de Neve Tzedek y algo de desarrollo reciente en las playas de Yaffo. El centro de Tel Aviv es el hogar de Azrieli Center y de un importante distrito comercial y financiero a lo largo de la autopista Ayalon. El sector norte de Tel Aviv alberga la Universidad de Tel Aviv, el parque Yarkon y barrios residenciales de lujo como Ramat Aviv y Afeka.

Tel Aviv tiene clima mediterráneo con veranos cálidos, otoños y primaveras agradables e inviernos frescos y húmedos (Clasificación climática de Köppen). La humedad tiende a ser alta durante todo el año debido a la proximidad de la ciudad al mar. En invierno, las temperaturas rara vez caen por debajo de 5 °C (40 °F) y se sitúan, por lo general, entre 10 °C (50 °F) y 15 °C (60 °F). En verano la temperatura media es de 26 °C (80 °F) y, a menudo, durante el día las temperaturas superan los 32 °C (90 °F). La ciudad tiene, en promedio, más de 300 días soleados al año. El récord de temperatura de la ciudad fue de 46,5 °C (115 °F), mientras que el registro más bajo de la ciudad baja fue -1,9 °C (30 °F).

A pesar de la alta humedad, las precipitaciones durante el verano son raras. La precipitación media anual es de 673 milímetros, normalmente concentrada en el período de octubre a abril. El invierno es la estación más húmeda, a menudo acompañada por fuertes lluvias y tormentas eléctricas. La nieve es extremadamente rara, ya que el último registro de nevadas dentro de los límites de la ciudad tuvo lugar en febrero de 1950. El mes más lluvioso se registró en enero de 2000 con 424,9 mm; en tanto que el día más pluvioso fue el 8 de noviembre de 1955 con 133 mm.

La ciudad fue establecida en la Convención de Judíos de Yafo, que tuvo lugar en julio de 1906, en la cual, motivados por la baja calidad de vida de los judíos de dicha ciudad, a la cual se sumaba el decreto conocido como "Muhram" según el cual los habitantes judíos de Yafo debían cambiar de domicilio anualmente.

Hacia 1909 se adquirieron los terrenos para comenzar la construcción de la nueva ciudad, la cual debería seguir las líneas arquitectónicas del movimiento Garden City inglés, con la intención de crear una ciudad de características modernas, espaciosa y con abundantes espacios verdes, que podría ofrecer una alternativa a la atestada Yafo. Los primeros terrenos adquiridos consistían en 60 parcelas, las cuales fueron sorteadas entre las familias interesadas el segundo día de Pésaj de 1909, fecha adoptada como el aniversario oficial de la ciudad.

El barrio fue construido por la cooperativa Ajuzat Bait - אחוזת בית y ese fue el primer nombre que recibió. La prohibición de establecer en el barrio cualquier tipo de industria hizo que la expansión del núcleo tuviese una doble vertiente: hacia el norte, residencial y hacia el oeste, industrial. La población local creció mucho durante sus inicios: pasó de 2.000 habitantes en 1920 a 34.000 habitantes en 1925, año en el que el escocés Patrick Geddes diseñó un plan urbanístico para la ciudad. 

A finales del año 1930 comenzó a desarrollarse el área de la desembocadura del río Yarkon, conocida como la península del Yarkón. En primer lugar se estableció la central termoeléctrica junto al Aeropuerto Sde Dov al norte de la boca del río Yarkon y después de lo que el desarrollo de la zona sur de la boca Yarkon que se parece a una Península. la "Tel Aviv International Trade Fair" que se llama: "el Orient Fair" fue construido para los países pabellones polivalentes en los estilos arquitectónicos que caracterizan la ciudad, especialmente los Estilo Internacional. en la parte norte-oriental del recinto ferial internacional, se construyó la primera "Maccabiah Stadium" en 1932.

En 1937 el "Wauchope Bridge" fue construido sobre la boca Yarkon el nombre de Arthur Grenfell Wauchope que fue la Altos Comisionados para Palestina y Transjordania. él fue diseñado para conectar la alimentación de lectura con la Feria Internacional.

El 14 de mayo de 1948, en Tel Aviv, Ben Gurión proclamó el nacimiento del Estado de Israel. Tel Aviv fue la capital provisional hasta 1950, en que se trasladó la capitalidad a Jerusalén. La ciudad se convirtió en el paradigma de la modernidad en Israel, y es el núcleo de la Zona Centro del país, donde se concentra la mayor cantidad de población. Posteriormente, la ciudad se unificó con Jaffa, formando hoy un solo municipio.

Tel Aviv ha sufrido varios bombardeos en su historia; durante la Segunda Guerra Mundial fue bombardeada por la aviación italiana el 9 de septiembre de 1940; durante la guerra de independencia de Israel fue bombardeada por Egipto; en 1991, durante la Guerra del Golfo, recibió el impacto de misiles Scud lanzados por Irak; en noviembre de 2012, durante el conflicto que tuvo Israel con Gaza, la ciudad recibió varios ataques aéreos que dejaron 6 muertos y decenas de heridos y en agosto de 2014 su área metropolitana fue a menudo bombardeada desde Gaza. Además, en junio de 2016 sufrió un ataque terrorista en el conocido Mercado Sarona, que dejó 4 muertos y 6 heridos, siendo así el mayor tiroteo y atentado de la ciudad.

La ciudad tiene una población de 388.700
. Según la Oficina Central de Estadísticas (CBS), a partir de junio de 2006, la población de Tel Aviv está creciendo a una tasa anual del 0,9%. Se compone de 91,8% judíos, 4,2% árabes y 4,0% "otros". De acuerdo con algunas estimaciones, cerca de 50.000 trabajadores extranjeros no registrados viven en Tel Aviv.

De acuerdo a las estadísticas de diciembre de 2001, el estatus socioeconómico de Tel Aviv está calificado como alto (8 de cada 10) y el 63,1% de los estudiantes de último grado de secundaria recibieron certificados de graduación en el año 2000. En 2000, el salario medio mensual era de 6773 NIS, que es aproximadamente igual a la media nacional. En la ciudad la población está distribuida en 22,2% menores de 20, 18,5% de edades comprendidas entre 20-29, 24% de edades comprendidas entre 30-44, y el 16,2% de edades comprendidas entre los 45 y 59. 19,1% está por encima de los 60. Tel Aviv posee la mayor y más poblada área metropolitana de Israel, incluso por delante de Jerusalén, aunque esta última es la ciudad más poblada del país.


La administración política de la ciudad promociona los derechos de las personas LGTB. Poseen Ayuntamiento de gestión democrática cuyos 31 miembros se eligen cada cinco años por sufragio universal. El censo electoral está compuesto por todos los residentes empadronados en Tel Aviv mayores de 18 años, nacionales de Israel y con al menos un año de residencia en la ciudad.
El municipio es responsable de los servicios sociales, los programas comunitarios, la infraestructura pública, urbanismo, turismo y otros asuntos locales.

El Ayuntamiento de Tel Aviv se encuentra en el Parque Rabin, y su alcalde es Ron Huldai desde 1998. Huldai fue reelegido en las elecciones municipales de 2008, derrotando a Dov Henin. El alcalde que más tiempo gobernó fue Shlomo Lahat, quien estuvo en el poder durante 19 años; en tanto que el que menos estuvo en el sillón principal fue David Bloch, quien estuvo en el cargo durante dos años (1925-27). Fuera de los kibutz, Meretz recibe más votos en Tel Aviv que en cualquier otra ciudad de Israel.

Tel Aviv es la ciudad con más arquitectura Bauhaus. Hay más edificios construidos al estilo Bauhaus que en cualquier otro lugar del mundo, incluyendo cualquier ciudad de Alemania. El estilo fue llevado en los 30 por arquitectos judíos europeos que huían del régimen nazi. Desde 2003, "La Ciudad Blanca" es considerada patrimonio de la humanidad, y son más de 1500 los edificios "International Style" contabilizados y sujetos a distintos planes de restauración y preservación.

A pesar de un brote de nuevos estilos arquitectónicos –incluyendo modernos rascacielos– el modelo dominante de Tel Aviv desde el aire sigue siendo la profusión de "pequeños edificios con forma de caja y techo blanco plano" que reflejan la tradición Bauhaus de la ciudad, muchas de cuyas doctrinas han sido integradas en la arquitectura contemporánea en todo el mundo.

En Tel Aviv se encuentra el parque Yarkon, que es el parque más famoso de Israel. Es incluso más grande que el Central Park de Nueva York (350 hectáreas). Tel Aviv tiene la estación de autobuses más grande del mundo.


Tel Aviv está hermanada con 31 ciudades y tiene una alianza con Los Ángeles, California, EE. UU.:



</doc>
<doc id="40992" url="https://es.wikipedia.org/wiki?curid=40992" title="Supernova">
Supernova

Una supernova (del latín "nova", «nueva») es una explosión estelar que puede manifestarse de forma muy notable, incluso a simple vista, en lugares de la esfera celeste donde antes no se había detectado nada en particular. Por esta razón, a eventos de esta naturaleza se los llamó inicialmente "stellae novae" («estrellas nuevas») o simplemente "novae". Con el tiempo se hizo la distinción entre fenómenos aparentemente similares pero de luminosidad intrínseca muy diferente; los menos luminosos continuaron llamándose "novae" (novas), en tanto que el término supernova fue acuñado por Walter Baade y Fritz Zwicky en 1931 para denominar a los más luminosos agregándoles el prefijo «"super-"».

El término más arcaico fue utilizado desde la antigüedad para indicar la explosión de una estrella súper gigante roja en sus capas externas, las cuales producen una luminosidad que puede aumentar 100 000 veces su brillo original. Esta luminosidad dura unos pocos días y, en ocasiones, puede ser observada a simple vista desde la Tierra. Al ver un nuevo resplandor en el cielo, los seres humanos creían que había aparecido una nueva estrella. Al año siguiente de la muerte de Fritz Zwicky, en agosto de 1975, apareció una nova que pudo ser observada a simple vista desde la Tierra, durante algunos días. Esta nova surgió de la explosión de una gigante roja.

Las supernovas producen destellos de luz intensísimos que pueden durar desde varias semanas a varios meses. Se caracterizan por un rápido aumento de la intensidad luminosa hasta alcanzar una magnitud absoluta mayor que el resto de la galaxia. Posteriormente su brillo decrece de forma más o menos suave hasta desaparecer completamente.

Se han propuesto varios escenarios para su origen. Pueden ser estrellas masivas que ya no pueden desarrollar reacciones termonucleares en su núcleo, y que son incapaces de sostenerse por la presión de degeneración de los electrones, lo que las lleva a contraerse repentinamente (colapsar) y generar, en el proceso, una fuerte emisión de energía. Otro proceso más violento aún, capaz de generar destellos incluso mucho más intensos, puede suceder cuando una enana blanca miembro de un sistema binario cerrado, recibe suficiente masa de su compañera como para superar el límite de Chandrasekhar y proceder a la fusión instantánea de todo su núcleo: esto dispara una explosión termonuclear que expulsa casi todo, si no todo, el material que la formaba.

La explosión de supernova provoca la expulsión de las capas externas de la estrella por medio de poderosas ondas de choque, enriqueciendo el espacio que la rodea con elementos pesados. Los restos eventualmente componen nubes de polvo y gas. Cuando el frente de onda de la explosión alcanza otras nubes de gas y polvo cercanas, las comprime y puede desencadenar la formación de nuevas nebulosas solares que originan, después de cierto tiempo, nuevos sistemas estelares (quizá con planetas, al estar las nebulosas enriquecidas con los elementos procedentes de la explosión).

Estos residuos estelares en expansión se denominan remanentes y pueden tener o no un objeto compacto en su interior. Dicho remanente terminará por diluirse en el medio interestelar al cabo de millones de años. Un ejemplo es RCW 86.

Las supernovas pueden liberar varias veces 10 J de energía. Esto ha resultado en la adopción del foe (10 J) como unidad estándar de energía en el estudio de supernovas.

El 20 de septiembre de 2016, un astrónomo aficionado llamado Víctor Buso, se convirtió en la primera persona en la historia en fotografiar el nacimiento de una supernova a 86 millones de años luz, en la galaxia espiral NGC 613, al explotar la estrella bautizada SN 2016gkg. o

La clasificación de las supernovas tiene razones históricas, y nació de los primeros intentos,
por parte de los astrónomos, de comprenderlas; es así como se empezó agrupándolas de acuerdo a las líneas de absorción de diferentes elementos químicos que aparecen en sus espectros.

La primera clave para la división es la presencia o ausencia de hidrógeno. Si el espectro de una supernova no contiene una línea de hidrógeno es clasificada como "tipo I"; de lo contrario, se la clasifica como "tipo II".

Dentro de estos dos grupos principales hay también subdivisiones de acuerdo a la presencia de otras líneas.

Las supernovas de tipo Ia carecen de helio y presentan, en cambio, una línea de silicio en el espectro. La teoría más aceptada con respecto a este tipo de supernovas sugiere que son el resultado de la relativamente rápida acreción de masa por parte de una enana blanca de carbono-oxígeno desde una estrella compañera, generalmente una gigante roja. Esto puede suceder en sistemas estelares binarios muy cercanos. Ambas estrellas tienen la misma edad y los modelos indican que casi siempre tendrán una masa semejante. Pero normalmente siempre hay una más masiva que la otra y unas ligeras diferencias en este aspecto hacen que la más masiva evolucione (abandone la secuencia principal) antes que la estrella de menor masa. Una estrella con menos de 8-9 masas solares evoluciona, al final de su vida, en una enana blanca. Por esto es corriente que, en sus etapas finales, un sistema binario esté constituido por una enana blanca y una gigante roja con sus capas exteriores muy expandidas (ver:Evolución estelar:gigantes rojas).

Esta envoltura, básicamente de hidrógeno y helio, está poco cohesionada gravitatoriamente, por lo que es capturada fácilmente por la enana blanca. Alrededor de cada estrella hay un perímetro de influencia, delimitado por una superficie equipotencial llamada lóbulo de Roche, en el que predomina su fuerza de gravedad. Si parte de la envoltura de la gigante roja, que siempre está tendiendo a aumentar de volumen, invade el lóbulo de la enana blanca, será atraída por esta.

El material tiene que depositarse con la suficiente rapidez para que no se encienda la capa superficial de hidrógeno (si esto ocurre, el fenómeno se conoce como nova). Si el ritmo de acreción es el adecuado, la masa de la enana blanca pronto alcanza el límite de Chandrasekhar, momento en el cual los electrones degenerados ya no son capaces de sostener el objeto. El aumento de presión resulta en el colapso de la estrella, cuyas temperaturas se disparan hasta llegar a iniciar la fusión del carbono en su núcleo. Esta ignición alcanza toda la estrella, empezando en su centro y extendiéndose rápidamente hasta las capas más externas. Dado que tienen muy poco hidrógeno en su superficie, este se ioniza rápidamente, volviéndose transparente e indetectable cuando se leen los espectros de estos destellos luminosos. La manera en que propaga la energía de la explosión en el interior de la enana es aún objeto de debate entre los científicos. Si bien se supone que la fuente principal de energía está en el centro, se desconoce si existen otros puntos simultáneos de ignición que generen ondas de choque convergentes que potencien el rendimiento de la explosión. Las turbulencias generadas por la inestabilidad de Rayleigh-Taylor parecen ser causa de una rápida propagación del frente de ignición en todo el volumen de la estrella. Se desconoce cómo dicha ignición hace su transición de deflagración subsónica a detonación supersónica.

Durante la detonación se quema, en cuestión de segundos, una cantidad de carbono que a una estrella normal le llevaría siglos. Esta enorme energía libera una poderosa onda de choque que destruye la estrella, expulsando toda su masa a velocidades de alrededor de los 10.000 km/s. La energía liberada en la explosión también causa un aumento extremo en la luminosidad, por lo que estas supernovas llegan a ser las más luminosas de todas, emitiendo alrededor de 10 J (1 foe). Normalmente no quedan rastros de la estrella que originó el cataclismo, sino solo restos de gas y polvo sobrecalentados en rápida expansión. La desaparición, por consiguiente, del campo gravitatorio de la enana blanca, produce un cambio en la trayectoria de la estrella vecina, si esta pudo sobrevivir a la detonación. Al no verse sometida a la fuerza de atracción de la estrella destruida, la otra saldrá disparada en la dirección que seguía en el momento del estallido, como si de una «onda» se tratase. Estas estrellas fugitivas se pueden en principio detectar ya que deberían tener velocidades mucho mayores que las de su entorno.

Vale la pena recalcar nuevamente que el mecanismo que produce las supernovas de tipo Ia es, en cierto modo, similar al de las novas, pero en estas la enana blanca acreta materia más lentamente, encendiéndose su superficie antes de que la masa total alcance el límite de Chandrasekhar. Este fenómeno en general no causa el colapso de la enana blanca, por lo que puede reiterarse, lo que no es el caso de las supernovas.

La supernovas de tipo Ia son fenómenos muy raros ya que requieren unos requisitos muy estrictos para su formación. En primer lugar, solo se producirían en sistemas binarios compuestos por estrellas de masa intermedia y baja. Estos sistemas en principio son bastante corrientes, pero aún hay más restricciones. La suma de las masas de ambas estrellas ha de ser mayor que la masa de Chandrasekhar (1,44 M). Han de estar lo suficientemente cerca como para que sus lóbulos de Roche puedan ser invadidos por la envoltura de la gigante roja en expansión. De ser posible, la envoltura de la gigante debería engullir a la enana blanca, lo cual garantizaría una absorción rápida del material y su frenado debido a la fricción con el gas estelar. Esto cerraría aún más la binaria, lo cual aumentaría el ritmo de la acreción. Si la absorción fuese demasiado lenta y pausada, ocurriría el mencionado fenómeno de nova periódica.

También puede existir una supernova tipo Ia generada por la fusión de dos enanas blancas del mismo sistema binario. Puede ocurrir que ninguna de las dos logre por sí sola acretar la suficiente masa como para generar una supernova, pero juntas, en cambio, pueden superar la masa de Chandrasekhar. Dos enanas blancas en rotación emiten ondas gravitatorias y, con el tiempo, sus órbitas se acercan y aceleran, lo cual a su vez acelera la emisión de ondas y retroalimenta el proceso. Puede llegar un momento en el que una de las dos enanas (la menos masiva), se disgregue y forme un toro (forma de «dónut») alrededor de la otra estrella. Después, el material del disco empieza a caer sobre la superficie. El ritmo no debe ser ni muy lento ni muy rápido tampoco, ya que en cualquiera de los casos se produciría la quema prematura del carbono en la superficie.
Las supernovas de tipo Ia poseen una curva de luz característica. Cerca del momento de luminosidad máxima, el espectro contiene líneas de elementos de masa intermedia que van desde el oxígeno hasta el calcio (presentes en las capas externas de la estrella). Meses después de la explosión, estos elementos se han hecho totalmente transparentes y la luz que domina es la que proviene de los elementos más pesados procedentes del núcleo. En el máximo de emisión se concentra la luz emitida por el níquel-56. Este va decayendo por radiactividad a cobalto-56, también radiactivo. En un momento dado, la emisión de luz es dominada por el cobalto, cuyos fotones de alta energía suavizan la curva de decrecimiento del brillo. La luminosidad termina con la conversión de todo el cobalto a hierro-56, el cual emitirá las líneas más tardías producto de su estado ionizado.

A diferencia de otros tipos de supernovas, las supernovas de tipo Ia se encuentran en todo tipo de galaxias, incluyendo las elípticas. Asimismo, tampoco muestran ninguna preferencia por regiones de formación estelar. Esto es así porque los sucesos que desembocan en una supernova Ia pueden durar mucho tiempo en términos estelares, sobre todo la aproximación de los dos cuerpos. Además no se originan a partir de estrellas muy masivas, por lo que no tienen por qué ubicarse en zonas de formación estelar reciente (donde se encuentran las gigantes azules), de modo que pueden acontecer en las regiones más viejas de las galaxias. Esta particularidad permite encontrarlas mirando cualquier parte del cielo, con una distribución homogénea con probabilidad constante allí donde haya galaxias.

Dada la similitud en las formas y en la magnitud de las curvas de luz de todas las supernovas de tipo Ia observadas hasta la fecha, es que son utilizadas como medida estándar de luminosidad en astronomía extragaláctica, lo que en términos astrofísicos se llama una candela estándar; en este caso, se pueden calibrar con una décima de magnitud. Las ventajas con respecto a las demás candelas estándar, como las cefeidas clásicas, es que su alta luminosidad permite detectarlas en galaxias muy lejanas, ayudando a inferir distancias de objetos que, de otra manera, sería imposible calcular. La razón de la similitud de las curvas de luminosidad es aún cuestión de debate, pero parece estar relacionada, en parte, con el hecho de que las condiciones iniciales en que se generan estos fenómenos sean casi idénticas. Estas propiedades tan favorables han revolucionado la cosmología, permitiendo desvelar la expansión acelerada del universo gracias a su utilización estadística.

En la Vía Láctea, el candidato más conocido para este tipo de supernova es IK Pegasi (HR 8210), localizado a una distancia de tan solo 150 años luz. Este sistema binario está formado por una estrella de secuencia principal y una enana blanca, separadas únicamente por 31 millones de km. La enana tiene una masa estimada en 1,15 veces la masa solar. Se piensa que pasaran varios miles de millones de años antes de que la enana blanca llegue a la masa crítica necesaria para convertirse en una supernova de tipo Ia.

Los espectros de las supernovas de tipos Ib y Ic no muestran la línea del silicio presente en los espectros de las Ia; se cree que se trata de estrellas al final de su vida (como las tipo II), pero que perdieron todo su hidrógeno en etapas anteriores, por lo que las líneas de este elemento no aparecen en sus espectros. En particular, se piensa que las supernovas de tipo Ib resultan del colapso de una estrella de Wolf-Rayet que ha expulsado toda su envoltura de hidrógeno por medio de los intensos vientos propios de estas estrellas. Se conocen también varias de estas supernovas en sistemas binarios: en este caso, la estrella compañera puede ayudar a desligar gravitatoriamente el gas de la envoltura de la otra estrella, la que no necesita ser tan masiva como una Wolf-Rayet aislada. En casos extremos, cuando no solo escapa el hidrógeno sino también el helio, puede quedar expuesto el núcleo de carbono, y este sería el escenario de una supernova Ic. El proceso de la explosión de estas supernovas es esencialmente el mismo que el de las supernovas de colapso gravitatorio típicas, las tipo II.

Las supernovas de tipo II son el resultado de la imposibilidad de producir energía una vez que la estrella ha alcanzado el equilibrio estadístico nuclear con un núcleo denso de hierro y níquel. Estos elementos ya no pueden fusionarse para dar más energía, sino que "requieren" energía para fusionarse en elementos más pesados. La barrera de potencial de sus núcleos es demasiado fuerte para que la fusión sea rentable por lo que ese núcleo estelar inerte deja de sostenerse a sí mismo y a las capas que están por encima de él. La desestabilización definitiva de la estrella ocurre cuando la masa del núcleo de hierro alcanza el límite de Chandrasekhar, lo que normalmente toma apenas unos días. Es en ese momento cuando su peso vence a la presión que aportan los electrones degenerados del núcleo y este colapsa. El núcleo llega a calentarse hasta los 3.000 millones de grados, momento en el que la estrella emite fotones de tan alta energía que hasta son capaces de desintegrar los átomos de hierro en partículas alfa y neutrones en un proceso llamado fotodesintegración; estas partículas son, a su vez, destruidas por otros fotones, generándose así una avalancha de neutrones en el centro de la estrella.
formula_1
formula_2

Estas reacciones son endotérmicas, por lo que no ayudan a sostener el núcleo compacto y este sigue colapsando, emitiendo más y más neutrones cada vez. De hecho provocan un enfriamiento del núcleo, lo que se traduce en una menor presión y, por tanto, en una aceleración del proceso. Los propios átomos de hierro captan parte del inmenso flujo de neutrones, transformándose en elementos más pesados por medio del fenómeno llamado captura de neutrones, o "proceso-r".

El núcleo se contrae tan rápido que deja un espacio de baja densidad casi vacío entre él y el resto de la estrella. La envoltura, por su parte, empieza a caer sobre el núcleo frenándose por un aluvión de fotones de frecuencia extrema, que fotodesintegran las capas más interiores de dicha envoltura. Esta destrucción de núcleos no solo transmite momento sino que también produce un flujo de neutrones y protones que serán capturados por las capas siguientes para formar elementos más pesados. Simultáneamente, las densidades enormes que se alcanzan en la «sopa» de núcleos pesados y electrones en que se ha convertido el núcleo supercompactado, posibilitan una nueva reacción. Los electrones del núcleo estelar empiezan a caer sobre los núcleos atómicos reaccionando con los protones para formar neutrones en un proceso llamado captura de electrones por lo que, poco a poco, el núcleo se va convirtiendo en una masa de neutrones hiperdensa llamada neutronium. Los procesos de fotodesintegración y de captura de electrones aceleran aún más el hundimiento de la estrella, ya que, además, ahora también la presión de degeneración pierde fuerza rápidamente.
formula_3

Pero la captura de electrones no solo resulta en la producción de neutrones sino también en la de neutrinos. La captura se produce a tal ritmo que se genera un flujo explosivo de neutrinos que es arrastrado por el colapso, hasta que su abundancia creciente los hace degenerar y, bloquear así, la captura de nuevos electrones. Por breves instantes los electrones ni siquiera pueden seguir combinándose con los protones ya que no hay lugar en el espacio de fases donde colocar a los neutrinos que resultarían, dado que estos están ya degenerados. Pero esto no tarda en resolverse ya que, a consecuencia de este taponamiento, se produce un escape de los neutrinos del núcleo llevándose gran cantidad de energía, lo que reactiva las capturas y realimenta a los frentes de onda de neutrinos que se expanden con gran rapidez. La emisión de neutrinos durará unos 10 segundos.

Las capas externas de material que caen hacia el núcleo se encuentran de camino con el frente de choque de la avalancha de neutrinos, también llamado neutrinosfera. A través de un proceso que no ha sido develado por completo aún, parte de la energía liberada en la explosión de neutrinos es transferida a las capas externas de la estrella. Se cree que, como se puede ver en la fórmula siguiente, los neutrinos son capaces de generar fotones mediante un proceso inverso al de generación de fotoneutrinos (ver:Neutrinos térmicos).

Cuando la onda de choque alcanza la superficie de la estrella varias horas más tarde, ocurre un incremento enorme de su luminosidad. Si la masa del núcleo colapsante es lo suficientemente pequeña, entre 1,5 y 2,5 masas solares, los propios neutrones podrán frenar el colapso; si no, seguirá contrayéndose hasta concentrarse toda la materia en una singularidad, formando así un agujero negro. Esta frontera entre estrella de neutrones y agujero negro no está bien definida debido a la falta de entendimiento de los procesos del colapso de una supernova.

formula_4

En el caso de las supernovas que generan estrellas de neutrones, las capas externas apenas si llegan a chocar con la superficie del núcleo compacto. Es posible que ni la alcancen y antes hayan sido barridas por el flujo de neutrinos. En las que acaban en agujeros negros, inicialmente sí se forma una estrella de neutrones pero la cubierta posee tanta masa y empuje que gran parte de esta cae sobre la estrella de neutrones haciendo que supere la masa máxima de unas 2,5 masas solares, aunque este límite tampoco se conoce con exactitud.

La energía desarrollada por una supernova de tipo II típica es de unos 10 J (unos 100 foes) emitidos en los 10 segundos de flujo explosivo de neutrinos. De toda esta energía, tan solo un foe es absorbido por el material, reemitiéndose en forma de energía cinética del material en expansión. Entre 0,01 y 1 foes se emiten en forma de energía luminosa. Esta última es la energía detectable ópticamente. Las supernovas con mejor rendimiento son las que dejan estrellas de neutrones como remanentes ya que, en este caso, el porcentaje de masa expulsado es máximo. En el caso de las que dejan un agujero negro, la expansión será menos eficiente porque gran parte de la energía de la explosión quedará atrapada en él. En cualquier caso, las supernovas de colapso difícilmente se acercarán al foe completo que liberan las supernovas tipo Ia.

La cuestión de cómo las supernovas logran emitir toda esa energía aún no se entiende bien. De hecho, los modelos realizados por ordenador no dan explosión alguna o, si la dan, esta es muy marginal. Se ha especulado sobre toda una serie de factores que podrían influir en la potencia de la explosión, o que incluso podrían ser cruciales para que esta se produjera. En primer lugar puede estar la fuerza centrífuga, que es máxima en el plano ecuatorial y que, sin duda, tiene una contribución positiva ayudando a que el material escape. Con la compresión de la estrella dicha fuerza debería acentuarse al conservarse el momento angular de la estrella. Por otra parte están los campos magnéticos que también deberían contribuir con su presión magnética. Estos dos aspectos se omiten en los modelos porque ni tienen simetría esférica ni se pueden fijar debidamente al desconocerse sus magnitudes, que por otra parte deben ser diferentes para cada estrella.

Las supernovas de tipo II pueden dividirse en los subtipos II-P y II-L. Los tipos II-P alcanzan una meseta en su curva de luz mientras que los tipos II-L poseen un decrecimiento lineal en su curva. La causa de esto se cree que es por diferencias en la envoltura de las estrellas. Las supernovas de tipo II-P poseen una gran envoltura de hidrógeno que atrapa la energía liberada en forma de rayos gamma y la liberan en frecuencias más bajas, mientras que las de tipo II-L, se cree, poseen envolturas mucho menores, convirtiendo menor cantidad de energía de rayos gamma en luz visible.

Las masas de las estrellas que dan lugar a supernovas están entre alrededor de las 10 masas solares hasta las 40 o 50. Más allá de este límite superior (que tampoco se conoce con exactitud), los momentos finales de la estrella son implosiones completas en las que nada escapa al agujero negro que se forma, rápida y directamente, engulliéndolo todo antes de que un solo rayo de luz pueda salir. Estas estrellas literalmente se desvanecen al morir.

Se ha especulado que algunas estrellas excepcionalmente masivas podrían producir hipernovas al extinguirse. El escenario propuesto para semejante fenómeno dice que, tras la transformación repentina del núcleo en agujero negro, de sus polos brotarán dos jets de plasma relativista. Estas intensas emisiones se producirían en la banda de frecuencias de los rayos gamma y podrían ser una explicación plausible para las enigmáticas explosiones de rayos gamma.
"La primera fase de la supernova es un colapso rápido del núcleo incapaz de sostenerse. Esto conlleva una fuerte emisión de fotones y neutrones que son absorbidos por las capas interiores frenando así su colapso. Simultáneamente un frente de choque de neutrinos se genera durante la neutronización del núcleo compacto. Finalmente, la neutrinosfera choca contra la cubierta y transmite su momento expulsando las capas y produciendo la explosión de supernova".

Los restos o el remanente de supernova es una estructura nebulosa formada a partir de la explosión. Este remanente está rodeado por una onda de choque expansiva que barre todo a su alrededor y choca durante su paso. La estrella ya sin energía alguna en su núcleo implosiona según su gravedad ocasionando alguna de las dos rutas posibles para una supernova: Una estrella de neutrones o un agujero negro. Pero no todo se destruye en una explosión de supernova, sino que el núcleo de la estrella permanece. Este núcleo, rico en hierro, proseguirá su hundimiento. El hundimiento se detendrá o, por el contrario, continuará indefinidamente dependiendo de la masa del núcleo tras la explosión.

Los descubrimientos de supernovas son notificados a la UAI ("Unión Astronómica Internacional"), la cual distribuye una circular con el nombre recientemente asignado. El nombre se forma por el año del descubrimiento y la designación de una o dos letras. Las primeras 26 supernovas del año llevan letras de la A a la Z (vg. Supernova 1987A); las siguientes llevan aa, ab, etc.

También llamados Púlsares, se forman cuando el hundimiento del núcleo se detiene a consecuencia de los neutrones, que se desplazan sin rumbo debido a las altas temperaturas ocasionando que la materia se encuentre disgregada en protones, neutrones y electrones. Las estrellas de neutrones o púlsares tienen un campo magnético muy grande, con lo que se induce a la emisión progresiva de radiación electromagnética en forma de pulsos, los cuales se mueven a intervalos periódicos de acuerdo con el período de rotación. 

Por otro lado, cuando el núcleo que se mantiene durante la explosión de supernova tiene una masa que sobrepasa el límite de la misma, es decir, la masa de unos tres soles, su hundimiento es inevitable. Esto conlleva a que la densidad de la estrella sea increíblemente alta, provocando que colapse, a partir de esto se forman los agujeros negros. Cuanto más densidad de luz exista, más grande será el agujero negro, tan grande que cualquier cosa que esté cerca de ellos será atrapada debido a su intensa fuerza gravitatoria.

Un quebradero de cabezas de larga data acerca de las supernovas de Tipo II es por qué el objeto compacto que queda después de la explosión adquiere una gran velocidad lejos del epicentro; se observa que los púlsar, y por lo tanto las estrellas de neutrones, tienen altas velocidades. Presumiblemente lo mismo sucede con los agujeros negros, a pesar de que son mucho más difíciles de observar aisladamente. El impulso inicial puede ser sustancial, imprimiéndole a un objeto de más de una masa solar la velocidad de 500  km/s o aún mayor. Esto indica una asimetría en la explosión, pero el mecanismo por el que el impulso se transfiere al objeto compacto sigue siendo desconocido.

Una posible explicación de la asimetría en la explosión es una convección a gran escala por encima del núcleo. La convección puede crear variaciones en las abundancias de elementos locales, dando lugar a una combustión nuclear irregular durante el colapso, rebote y la consiguiente explosión.
Otra posible explicación es que la acumulación de gas en la estrella de neutrones central puede crear un disco que expulsa chorros altamente direccionales propulsando materia a muy alta velocidad fuera de la estrella y provocando choques transversales que desbaratan por completo la estrella. Estos chorros podrían desempeñar un papel crucial en la explosión de la supernova resultante.

A través de la observación, también se han confirmado estas asimetrías iniciales en las explosiones de las supernovas Tipo Ia. Este resultado puede significar que la luminosidad inicial de este tipo de supernova depende del ángulo de observación. Sin embargo, la explosión se hace más simétrica con el paso del tiempo. Los primeros indicios de asimetrías son detectables mediante la medición de la polarización de la luz emitida.

A continuación se muestra una lista de las más importantes supernovas vistas desde la Tierra en tiempos históricos. Las fechas que se dan señalan el momento en que fueron observadas. En realidad, las explosiones ocurrieron mucho antes, pues su luz ha tardado cientos o miles de años en llegar hasta la Tierra.

Galileo usó la supernova 1604 como una prueba contra el dogma aristotélico imperante en esa época, de que el cielo era inmutable.

Las supernovas dejan un remanente estelar tras de sí; el estudio de estos objetos ayuda mucho a ampliar los conocimientos sobre los mecanismos que las producen.

Las supernovas contribuyen a enriquecer el medio interestelar con metales (para los astrónomos, «metal» es todo elemento más pesado que el helio). Así, tras cada generación de estrellas (y, consecuentemente, de supernovas), la proporción de elementos pesados del medio interestelar aumenta. Mayores abundancias en metales tienen importantes efectos sobre la evolución estelar. Además, solo los sistemas estelares con metalicidad lo suficientemente alta pueden llegar a desarrollar planetas. Una mayor metalicidad conlleva pues una mayor probabilidad de formación de planetas, pero también contribuye a formar estrellas de menor masa. Esto es debido a que el gas acretado por la protoestrella es más sensible a los efectos del viento estelar cuanto más elementos pesados posea, pues estos absorben mejor los fotones.

Alex Filippenko y sus colaboradores postulan que las mayores supernovas (como la SN 2005ap y la SN 2006gy) habrían sido producidas por estrellas muy masivas (de 100 o más masas solares, en los casos citados 150 masas solares), y que estrellas de esas características habrían constituido la primera generación de estrellas en el universo; al estallar como gigantescas supernovas habrían difundido en el universo los elementos químicos a partir de los cuales se generaron las nuevas estrellas (y astros en general). Tales elementos químicos serían en definitiva los que constituyen a cada ente material conocido, y por supuesto, incluidos todos los seres vivos.





</doc>
<doc id="40993" url="https://es.wikipedia.org/wiki?curid=40993" title="Bandera de Irlanda">
Bandera de Irlanda

La bandera nacional de Irlanda (en irlandés: "An Bhratach Náisiúnta") es la bandera nacional de la República de Irlanda. Es una bandera tricolor compuesta por tres franjas verticales de iguales dimensiones: verde, blanca y naranja. La franja anaranjada simboliza a los protestantes de Irlanda y la verde representa a los católicos del país. La franja blanca representa la paz que finalmente llegará entre ellos.

Es muy parecida a la bandera de Costa de Marfil, de la que difiere solamente por la disposición invertida de los colores y por las proporciones, y de la bandera de la India y Níger donde los colores están dispuestos de forma horizontal.

El color verde simboliza el republicanismo irlandés y representa a los católicos. El naranja representa a Guillermo III de Orange y a los protestantes, y finalmente el blanco simboliza la paz entre ambos.

Fue usada por primera vez por los nacionalistas irlandeses en 1848 durante la revuelta de la «Joven Irlanda». Fue diseñada para representar la población católica (verde) y la protestante (naranja, relativa a Guillermo III de Orange) de la isla de Irlanda, que viven juntas en paz, representada por el color blanco. Contrariamente a lo que se piensa, esta no fue la bandera del Alzamiento de Pascua, que fue en realidad una bandera verde con un arpa y las palabras «Irish Republic» (República Irlandesa), escritas en naranja. Esta bandera está expuesta en la sección de Kildare Street del Museo Nacional de Dublín. La tricolor fue utilizada en la revuelta, como bandera de la Compañía E, y fue colocada en la Oficina General de Correos (GPO, General Post Office) de Dublín, que fue el cuartel general de los jefes de la revuelta. Al contrario de la bandera oficial, la tricolor de la Compañía E hizo mella en la población y se convirtió de facto en la bandera de la República Irlandesa (1919-22).
La bandera fue adoptada como bandera nacional del Estado Libre irlandés en 1922. Cuando el Estado Libre fue renombrado a Éire en 1937, la constitución ("Bunreacht na hÉireann") le dio valor constitucional. Desde entonces ha sido la bandera de Irlanda.

La bandera nacional se iza en:


Además aparece envolviendo los ataúdes de:


En los funerales de Estado de patriotas irlandeses, como por ejemplo Sir Roger Casement (1965) o Kevin Barry (2000), sus ataúdes fueron envueltos en la bandera nacional en señal de respeto y honor.

Irónicamente, el simbolismo principal de la bandera, unidad y respeto entre católicos (verde) y protestantes -llamados orangistas - (debido al color naranja, orange), no se ha convertido en realidad. En el Acta del Gobierno de Irlanda de 1920, Irlanda quedó dividida, de modo que el noreste, con mayoría unionista, se convirtió en Irlanda del Norte. Este territorio, a través de un mecanismo originado en las secciones 11 y 15 del tratado anglo-irlandés, eligió no unirse al Estado Libre Irlandés, sino seguir formando parte del Reino Unido. El Estado norirlandés utiliza la bandera de la Unión Británica y la bandera llamada "Mano roja del Úlster" (con una corona superpuesta a una estrella de seis puntas) como símbolo del Estado.



</doc>
<doc id="40994" url="https://es.wikipedia.org/wiki?curid=40994" title="Irlanda del Norte">
Irlanda del Norte

Irlanda del Norte (, ; , ; en escocés del Ulster, "Norlin Airlann") es uno de los cuatro países constitutivos del Reino Unido, situado en el noreste de la isla de Irlanda. Limita al sur y oeste con la República de Irlanda, al norte con el canal del Norte y al este con el mar de Irlanda, que le separa de la isla de Gran Bretaña. El territorio norirlandés abarca 14130km², y su población estimada en 2017 es de 1870451 habitantes, lo que equivale a un tercio del total de la isla y al 3% del pueblo británico. La capital y ciudad más poblada es Belfast.

Fue fundada en 1921 por el Parlamento del Reino Unido, en aplicación del Acta de Gobierno de 1920 que supuso la partición de Irlanda en dos entidades: Irlanda del Norte e Irlanda del Sur. El norte está formado por seis condados (Antrim, Armagh, Down, Fermanagh, Derry y Tyrone) que conforman dos terceras partes de la provincia histórica del Úlster.

Cuando los irlandeses del sur proclamaron la creación del Estado Libre Irlandés, el parlamento norirlandés expresó su deseo de permanecer bajo soberanía británica. Dentro de la población norirlandesa se distinguen dos grupos religiosos: una mayoría de protestantes, muchos de los cuales son descendientes de la colonización del Úlster, y una minoría significativa de católicos. A su vez, los habitantes se dividen entre quienes apoyan la unión con el Reino Unido y quienes abogan por la integración en Irlanda.

La historia de la región en el siglo XX ha estado marcada por los enfrentamientos entre unionistas y republicanos. El estallido en 1968 del conflicto de Irlanda del Norte sumió al Úlster en una espiral de violencia que no quedó resuelta hasta tres décadas después: la firma del acuerdo de Viernes Santo en 1998 ha sentado las bases de un nuevo gobierno en el cual católicos y protestantes comparten el poder.

El nombre legal y oficial de la región es Irlanda del Norte (Northern Ireland). Este término es aceptado por los gobiernos de Reino Unido y de la República de Irlanda, así como por los organismos internacionales y la mayoría de sus habitantes. Además, forma parte de la nomenclatura oficial del estado: Reino Unido de Gran Bretaña e Irlanda del Norte.

El origen de la palabra «Irlanda» está basado en el irlandés antiguo "Ériu" (en irlandés moderno, "Éire"), referido a una diosa de la mitología gaélica. A su vez, "Ériu" proviene del protocéltico "*Īwerjū", cuya traducción sería «tierra de abundancia». El pueblo celta empezó a usar la palabra "Éire" para referirse a los habitantes de la zona. Por influencia del germánico se añadiría el término "land".

Aunque algunas veces se utiliza «Úlster» como sinónimo de Irlanda del Norte, ese término no es preciso porque la provincia del Úlster engloba todo el norte de Irlanda, incluyendo tres condados que sí forman parte de la República de Irlanda.

El uso de términos distintos puede revelar la identidad cultural, étnica y religiosa del interlocutor. Los unionistas suelen referirse a la nación constituyente como "Ulster" o "The Province" («la provincia»), y los nacionalistas irlandeses utilizan "The North" («el Norte») o "Six Counties" («seis condados»). El término informal "Norn Iron" está extendido en el lenguaje coloquial.

Irlanda del Norte no cuenta con símbolos oficiales propios desde la suspensión de autonomía en 1972. No obstante, tanto la bandera como el escudo norirlandeses previos siguen siendo utilizados en la Mancomunidad de Naciones, en acontecimientos deportivos y a nivel local. Suelen tener mayor aceptación entre las comunidades unionistas, mientras que los nacionalistas irlandeses no los sienten representativos y utilizan la bandera tricolor irlandesa.

La bandera oficial "de iure" es la bandera del Reino Unido. Desde 1953 hasta 1972 tuvo rango oficial el estandarte del Ulster: esta enseña muestra, sobre un fondo con la cruz de San Jorge, una estrella de seis puntas con una mano roja del Ulster y la Corona Imperial británica. El número de puntas representa los condados irlandeses que conforman la provincia.

De igual modo, el escudo de Irlanda del Norte estuvo en vigor desde 1924 hasta 1973. Además de la cruz de San Jorge y la estrella de seis puntas de plata con la mano roja del Ulster, surmontada por la corona británica, destacan dos soportes: un león rampante de oro y un alce heráldico de plata, ambos con estandartes de Irlanda y del Ulster respectivamente.

La variante con la cruz de San Patricio ("St. Patrick's Saltire"), un aspa roja sobre campo blanco, se utilizó a partir de 1783 en la insignia de la Orden de San Patricio. Después del acta de la unión de 1800, se añadió el aspa a la antigua bandera del Reino de Gran Bretaña para representar a Irlanda en el nuevo Reino Unido de Gran Bretaña e Irlanda. A veces se usa informalmente para representar a Irlanda del Norte, especialmente de parte del gobierno británico. En 1986, la política del gobierno durante las visitas de Estado a Londres era izar las cruces de San Jorge, San Andrés, San Patricio y el dragón galés. 

El himno oficial es el mismo que el británico, "God Save the Queen". La canción "Londonderry Air" ha sido utilizada por los norirlandeses en algunos eventos deportivos como los Juegos de la Mancomunidad. La selección de rugby de Irlanda, representativa de toda la isla de Irlanda, utiliza el himno común "Ireland's Call" desde 1995.

Irlanda del Norte está ubicada en el noreste de la isla de Irlanda, al noroeste del continente europeo. Su territorio abarca 14 130 km², aproximadamente el 16% del total de la isla. La única frontera en tierra firme es la que le une al oeste y sur con la República de Irlanda, con una medida de 499 km entre Lough Foyle y Carlingford Lough. Se encuentra además rodeada por el canal del Norte y al este con el mar de Irlanda. En los estrechos de Moyle el ancho se reduce a solo 20km, siendo la menor distancia entre la isla y Gran Bretaña, y a menos de 30km de Escocia desde la península de Kintyre.

Irlanda del Norte está conformada por seis condados tradicionales: Antrim, Armagh, Down, Fermanagh, Londonderry y Tyrone. La extensión actual fue establecida en la Comisión Irlandesa de Fronteras surgida tras la independencia irlandesa en 1921.

Todo el territorio estuvo cubierto por una gran capa de hielo en la última era glaciar y durante los periodos precedentes. Como consecuencia puede encontrarse relieve de origen glacial ("drumlin") en cuatro condados, la mayoría en el condado de Down. En el centro de la provincia está ubicado el lago Neagh, el más grande en las islas británicas y el tercero mayor en Europa Occidental, con una superficie de 391 km². Hay un segundo grupo importante de lagos en torno al lago Erne de Fermanagh. 

La isla norirlandesa más grande y la única habitada es Rathlin, al norte de la costa de Antrim. En todo el territorio hay una extensión de 200 km² de costa, la mayoría accidentadas por la presencia de fiordos e islotes; la principal entrada de mar es el fiordo oriental de Strangford Lough con una superficie de 150 km², aunque también son importantes los de Belfast, Foyle y Carlingford.

A lo largo del país hay sistemas montañosos de baja altura. Los montes Sperrin, uno de los más extensos de toda la isla de Irlanda, alcanzan una altura máxima de 679 metros sobre el nivel del mar, con ricos depósitos de oro. Los montes de Mourne se caracterizan por sus yacimientos de granito y por ser uno de los mayores atractivos turísticos nacionales, bajo gestión de la National Trust. Allí está situada la montaña norirlandesa más alta, Slieve Donard (849 metros).

La actividad volcánica sobre la meseta de Antrim generó los pilares naturales de la Calzada del Gigante, con un total de 40000 columnas de basalto en la costa nororiental de la isla. La mayor parte del territorio está integrado en la Provincia Ígnea del Atlántico Norte.

Irlanda del Norte está atravesada por numerosos ríos que tiempo atrás fueron vitales para el desarrollo agrícola de la zona. Los más importantes son el río Bann, con una extensión total de 129 km; el río Lagan, en cuyo valle se asienta Belfast, y el río Foyle, que fluye por toda la provincia del Úlster.

Irlanda del Norte tiene un clima oceánico suave y húmedo, marcado por las precipitaciones ligeras, la nubosidad y las temperaturas variables. Está atemperado por la corriente del Golfo proveniente del océano Atlántico, por lo que las diferencias entre estaciones son menos pronunciadas que en el interior de Europa. Comparado con otras naciones británicas, el clima norirlandés es más cálido que el de Escocia, con el que comparte similitudes. La temperatura media máxima en Belfast era de 6,5 °C en enero y 17,5 °C en julio. El máximo histórico registrado fue de 30,8 °C en Knockarevan, condado de Fermanagh, el 30 de julio de 1976, mientras que el más frío fue de –18,7 °C en Castlederg, condado de Tyrone, el 23 de diciembre de 2010.

La historia de los primeros habitantes de la provincia del Úlster ha quedado recogida en el Ciclo de la Rama Roja, un gran conjunto de escritos en prosa y verso centrados en los héroes tradicionales de los Ulaid, los pobladores del este. Se considera probable que los Ulaid y sus linajes llegaran a Irlanda desde Gran Bretaña como guerreros procedentes de la cultura celta de La Tène. Los terrenos sobre los que se asienta Belfast están habitados desde la Edad del Bronce, en el lugar arqueológico de "Giant's Ring" (Anillo del Gigante).

Antes de que se produjera la invasión cambro-normanda de Irlanda, la isla funcionaba con un sistema de pequeños reinos. El desembarco del rey Enrique II de Inglaterra en 1171 condujo finalmente a un señorío inglés con capital en Dublín. El este fue invadido por barones normandos, y el noble Hugh de Lacy fue nombrado conde de Úlster en 1205. Sin embargo, a partir del siglo XIV la provincia norteña volvió a estar controlada por clanes gaélicos.

Irlanda del Norte fue el epicentro de la guerra de los Nueve Años (1594-1603) contra los programas de colonización del Úlster a finales del siglo XVI. El rey Enrique VIII de Inglaterra se autoproclamó jefe de la Iglesia irlandesa en 1537, y cinco años más tarde había establecido el clientelar Reino de Irlanda. Sin embargo, la rebelión de los jefes gaélicos Red Hugh O'Donnell y Hugo O'Neill dificultó el control del norte de la isla. Después de ser derrotados en la batalla de Kinsale, los condes irlandeses fueron expulsados en 1607 y la corona británica se quedó con sus tierras. Desde entonces la región estuvo sujeta a un programa colonial con la llegada de ingleses protestantes (anglicanos) y escoceses (presbiterianos), frente a la población nativa católica.

En la rebelión irlandesa de 1641 se produjeron alzamientos comunales y una serie de ataques entre nativos e ingleses, con episodios como la masacre de Portadown. Sin embargo, las victorias del reino inglés en ese conflicto y en la posterior guerra Guillermita asentaron el dominio colonial en toda la isla. En lo que respecta a Irlanda del Norte, la operación más importante fue la batalla del Boyne en 1690. Tras ese triunfo, el rey Guillermo III de Inglaterra concedió privilegios civiles y religiosos a la población protestante, en detrimento de las comunidades católica y presbiteriana. Los enfrentamientos entre fraternidades como la Orden de Orange (protestante) y la Sociedad de Irlandeses Unidos (republicana) se volvieron constantes a lo largo del siglo XVIII, y su punto de inflexión fue la rebelión irlandesa de 1798.

La unión del Reino Unido de Gran Bretaña e Irlanda en 1801 supuso el cumplimiento de la emancipación católica en el Úlster, mediante el cual se abolirían medidas discriminatorias contra los católicos en varios ámbitos. Además se permitió que los campesinos, muchos de los cuales eran irlandeses nativos, pudiesen comprar terrenos agrícolas a los terratenientes. 

A finales del siglo XIX se había impulsado un movimiento político para dotar a Irlanda de autonomía ("Home Rule"), cuya aprobación en el Parlamento no tuvo lugar hasta 1912. Aunque los partidarios de la unión con el Reino Unido eran minoría en el conjunto de una Irlanda católica, sí eran superiores en Belfast y los seis condados del noreste de la isla: Antrim, Armagh, Down, Fermanagh, Derry y Tyrone. Los unionistas hicieron valer su mayoría en la Cámara de los Lores para vetar el proyecto durante décadas, pero la reforma parlamentaria de 1911 permitió que dicho veto fuese superable. 

En respuesta a la futura aprobación, casi medio millón de personas contrarias al parlamento irlandés firmaron el Pacto del Úlster, encabezados por el líder unionista Edward Carson. Un año más tarde, el propio Carson fundaría los Voluntarios del Úlster, una organización paramilitar contraria a la implementación del "Home Rule". La ley de autonomía de 1914 nunca llegó a aplicarse por el estallido de la Primera Guerra Mundial.

En 1921, Irlanda quedó dividida en dos entidades llamadas Irlanda del Norte e Irlanda del Sur, según los términos de la ley de autonomía del Gobierno de Irlanda de 1920 que fue aprobada en el transcurso de la Guerra de Independencia Irlandesa. El territorio norirlandés no sería considerado un país, si no más bien una provincia; estaría formado por los seis condados del noroeste, de mayoría unionista y protestante. Mientras los surirlandeses boicotearon la nueva institución, los norirlandeses sí desarrollaron un gobierno y parlamento propios bajo soberanía británica. El autogobierno no era de especial agrado entre los unionistas, pero libraba al ejecutivo británico de cualquier debate en Westminster por la «cuestión irlandesa». 

El conflicto terminó el 6 de diciembre de 1921 con la firma del tratado anglo-irlandés y la creación del Estado Libre Irlandés en toda la isla. Bajo sus términos, Irlanda del Norte tendría la opción de retirarse del nuevo estado y permanecer en Reino Unido durante el mes siguiente a la entrada en vigor. El Parlamento de Irlanda del Norte ejerció ese derecho un día después, el 7 de diciembre, a través de una carta al rey Jorge V:«Su Graciosa Majestad. Nosotros, los más fieles y leales súbditos de Su Majestad, los Senadores y Comunes reunidos en el Parlamento de Irlanda del Norte, teniendo constancia de la aprobación de la Ley de Constitución del Estado Libre Irlandés de 1922, y siendo necesaria la ley del Parlamento para la ratificación de los artículos del tratado entre Reino Unido e Irlanda, nosotros, desde esta humilde institución, rogamos a Su Majestad que los poderes del Parlamento y Gobierno del Estado Libre Irlandés no sean extendidos a Irlanda del Norte'».La Comisión Irlandesa de Fronteras sirvió para establecer los límites con el nuevo Estado Libre Irlandés. Debido al estallido de la guerra civil irlandesa, los trabajos se demoraron hasta el 3 de diciembre de 1925. Si bien algunos representantes de Dublín esperaban una reducción sustancial del territorio norirlandés, la comisión decidió que los seis condados permaneciesen en el Reino Unido sin cambios significativos. La situación británica de la nación quedó ratificada en la Ley de Irlanda de 1949, según la cual Irlanda del Norte no podía abandonar el Reino Unido sin el consentimiento de su Parlamento.

A pesar de la mayoría unionista y protestante, en la década de 1920 había una significativa minoría del 35% que era católica y nacionalista. Los republicanos irlandeses consideraban que la división de Irlanda iba en contra de la opinión mayoritaria del pueblo irlandés, y arguyeron que el nuevo estatus de Irlanda del Norte no era democrático ni legítimo, puesto que había sido concebido exclusivamente por y para los unionistas. Esta situación sería más tarde foco de conflicto entre ambas comunidades, y dio lugar a ataques entre el IRA (nacionalista) y la Fuerza Voluntaria del Ulster (unionista).

En 1968 se produjo el estallido del conflicto de Irlanda del Norte (en inglés: "The Troubles") sobre el estatus político de la región, que enfrentó por un lado a los unionistas, partidarios de preservar los lazos con el Reino Unido, y por otro lado a los republicanos irlandeses, demográficamente minoritarios. Se trató de una disputa esencialmente política y nacionalista relativa a la partición de Irlanda, en la que influyeron otros factores como el sectarismo y la religión. Ambos bandos recurrieron a las armas y la espiral de violencia desatada durante tres décadas deparó un saldo de 3254 muertos y más de 50000 heridos.

A mediados de la década de 1960, la minoría católica se había unido en la Asociación por los Derechos Civiles de Irlanda del Norte (NICRA) que, inspirada en el movimiento civil estadounidense, llevó a cabo una resistencia contra la discriminación en el acceso a la vivienda social pública y por la abolición del sufragio censitario ligado al pago de impuestos, el cual sobrerrepresentaba a la población protestante. Sin embargo, parte de la comunidad unionista acusaba al NICRA de ser una tapadera del IRA, y los miembros lealistas se enfrentaron a ellos en las manifestaciones. La tensión aumentó progresivamente hacia disturbios, comunidades segregadas y finalmente enfrentamientos armados entre el IRA Provisional (creado en 1969) y las unionistas UVF y Asociación en Defensa del Ulster. En algunos casos, como el «Domingo Sangriento» de 1972, la actuación del Ejército Británico al reprimir a los manifestantes conllevó un agravamiento de la situación. 

En vista de que la administración norirlandesa era incapaz de solucionarlo, Reino Unido suspendió la autonomía del Parlamento (controlado por los unionistas) el 30 de marzo de 1972 y pasó a administrarla directamente desde Londres. Además de la violencia sectaria, se produjo un bloqueo político entre los diferentes partidos sobre el estatus de la nación y la forma de gobierno. En 1973 hubo un referendum de permanencia en el Reino Unido en el que el «sí» ganó con un 98,9% de los sufragios y un 57,5% de participación; los católicos boicotearon la votación.

Desde finales de los años 1980 se buscó una solución negociada al conflicto norirlandés, si bien continuaron produciéndose episodios de violencia. La tregua de los paramilitares en 1994 propició conversaciones de los partidos políticos para una paz duradera. El resultado fue el acuerdo de Belfast del 10 de abril de 1998, también llamado «acuerdo de Viernes Santo». Supuso la devolución de la autonomía, con base en un reparto del poder entre católicos y protestantes a través de la nueva Asamblea Legislativa, y la creación del Servicio de Policía de Irlanda del Norte. En lo que respecta a su estatus político, Irlanda del Norte seguiría siendo británico hasta que una mayoría de votantes decidiera lo contrario en referéndum.

Este compromiso fue ratificado por los habitantes de Irlanda del Norte y de la República de Irlanda en un referéndum celebrado el 22 de mayo, y que implicaba una reforma de la Constitución de Irlanda para eliminar las reclamaciones territoriales por una Irlanda Unida. Las nuevas medidas entraron en vigor a partir del 2 de diciembre de 1999, con el nombramiento de un gobierno presidido por David Trimble.

A pesar de episodios como el atentado de Omagh (1998), y de la desconfianza entre ambas facciones que incluso derivó en una nueva suspensión de autonomía en 2002, el acuerdo del Viernes Santo ha sido importante para garantizar la estabilidad de Irlanda del Norte. Los firmantes John Hume y David Trimble fueron galardonados con el Premio Nobel de la Paz en 1998; el IRA anunció su desarme en 2005, mientras que el UVF renunció a la violencia en 2007.

Después de cuatro años de suspensión, en 2006 todos los partidos norirlandeses firmaron el Acuerdo de St. Andrews para el restablecimiento de la autonomía. Tras las elecciones norirlandesas se alcanzó un pacto de gobierno en 2007 entre los antagónicos DUP de Ian Paisley y el Sinn Féin de Martin McGuinness y Gerry Adams.

Desde 2016, Irlanda del Norte está pendiente de las consecuencias que pueda acarrear la salida del Reino Unido de la Unión Europea. Al contrario que el conjunto del estado, los norirlandeses votaron por la permanencia. Muchas voces favorables a la continuidad se han mostrado predispuestas a apoyar la reunificación de la isla para poder seguir en la Unión Europea, pero el gobierno norirlandés ha rechazado de momento convocar un referéndum al respecto.

Dado que Irlanda del Norte es uno de los países constituyentes del Reino Unido, el jefe de estado es el monarca británico. Constitucionalmente, el Reino Unido es un Estado unitario con un Parlamento y un Gobierno soberanos. Sin embargo, los norilandeses disponen de un autogobierno limitado desde la aprobación de la Ley de Gobierno de Irlanda de 1920, actualmente representado en la Asamblea de Irlanda del Norte y el Gobierno de Irlanda del Norte. La devolución de poder entró en vigor en 1999, en virtud de los acuerdos de Viernes Santo, y su última reforma data de 2006.

La Asamblea norirlandesa es unicameral y tiene 90 miembros, elegidos por sufragio universal en 18 distritos electorales usando el Sistema D'Hondt. Cada miembro tiene que describirse oficialmente como «unionista», «nacionalista» u «otros». Hay mecanismos legales para asegurar que las responsabilidades de gobierno sean compartidas entre los unionistas y los nacionalistas. El nombramiento del ministro principal de Irlanda del Norte, del viceministro principal y del presidente de la Asamblea deben contar con el apoyo de una mayoría de ambas comunidades.

Desde 1999 existe el Consejo Ministerial Norte-Sur, una institución conjunta con la República de Irlanda para coordinar medidas que afectan al conjunto de la isla. 

Además, la Oficina del Reino Unido representa al Gobierno británico en Irlanda del Norte sobre los asuntos reservados, así como los intereses de esta nación en el gobierno del Reino Unido. Su representante es el Secretario de Estado para Irlanda del Norte, miembro del Gabinete del Reino Unido.

El autogobierno norirlandés está limitado: aunque tienen competencias transferidas, el Parlamento Británico sigue conservando la capacidad de reformar, cambiar, ampliar o abolir el sistema de gobierno a voluntad. La autonomía ha sido suspendida en varias ocasiones por motivos relacionados con el conflicto norirlandés, incluyendo la disolución en 1972 de la institución propia original, el Parlamento de Irlanda del Norte.

Irlanda del Norte es una jurisdicción legal distinta, separada de Inglaterra, Gales y Escocia.

Irlanda del Norte está dividida en 11 distritos con competencias de gobierno locales y su propio concejo municipal. Sus representantes son elegidos en las elecciones municipales y también se aplica el sistema de gobierno compartido.

La división histórica de Irlanda del Norte son los seis condados que la conforman: Antrim, Armagh, Down, Fermanagh, Londonderry y Tyrone, más dos ciudades con estatuto de condado ("county boroughs"): Belfast y Derry. El nombre de «seis condados» se debe a la tradición de los condados de Irlanda establecida en el siglo XIX. Hoy en día solo tienen sentido simbólico: sí fueron división administrativa desde 1921 hasta 1973, pero en 1971 se diseñó un sistema regional de 26 distritos y representación proporcional que ha permanecido en vigor hasta su reforma en 2015.

A nivel político, Irlanda del Norte está dividida en 18 circunscripciones electorales ("constituencies"): cuatro en Belfast y 14 en el resto de condados. Cada circunscripción otorga un representante al Parlamento del Reino Unido y cinco a la Asamblea norirlandesa.

La población de Irlanda del Norte según el censo de 2011 es de habitantes, repartidos de la siguiente forma: un 88,8% son naturales de la provincia, el 4,5% proceden de Gran Bretaña, un 2,9% nacieron en la República de Irlanda y el 4,3% restante son naturales de otros países. El área es de 14130km² y la densidad de población es de 133hab/km². Se trata de la nación constitutiva más pequeña del Reino Unido en habitantes (2,9% del total) y superficie (5,7% del total). En lo que respecta a la isla de Irlanda, supondría el 28% de la población total.

La división política tradicional en Irlanda del Norte es entre unionistas y nacionalistas. Mientras los primeros quieren que la provincia siga siendo parte del Reino Unido, los segundos desean que se una a la República de Irlanda o bien sea independiente del dominio británico. A este factor debe sumarse también la división religiosa. Los unionistas o monarquistas son en su mayoría de religión protestante, descendientes de los colonos ingleses, escoceses y franceses hugonotes, o bien irlandeses nativos que se han convertido. Los nacionalistas, en cambio, son en su mayoría católicos y descendientes de la población anterior a la colonización del Úlster, con una minoría de montañeses escoceses y algunos conversos. El porcentaje de minorías étnicas es del 1,8%, más del doble respecto al censo de 2001.

La complejidad de la sociedad norirlandesa impide hacer una generalización sobre pertenencia y religión: no todos los católicos apoyan necesariamente el nacionalismo irlandés, y la misma regla es válida para los protestantes y anglicanos en relación al unionismo. Dentro de la identidad nacional británica, un 81% se definen como protestantes y un 13% son católicos. Del mismo modo, entre la identidad irlandesa hay un 57% de católicos, un 12% de no cristianos y un 4% de protestantes.

La Ley de Gobierno de Irlanda de 1920 estableció una estructura geográfica que dotaba a los unionistas de mayoría. Sin embargo, la población de origen irlandés ha crecido gracias a una mayor natalidad y a la inmigración desde la parte republicana. El número de matrimonios mixtos se ha incrementado a partir de la década de 1990.

La identidad nacional en Irlanda del Norte quedó reflejada en el censo de 2011 del siguiente modo: un 48% de sus habitantes se incluyeron en el grupo de británicos, un 29% en el de norirlandeses y un 25% en el de irlandeses. Si se tiene en cuenta la principal identidad, se reduce a un 40% de británicos, un 25% de irlandeses y un 21% de norirlandeses.

El sentimiento de pertenencia suele ir ligado a la religión: muchos protestantes se consideran a sí mismos británicos, mientras que una mayoría de católicos se consideran irlandeses. La raíz de esta división tiene origen en la colonización del Úlster en el siglo XVII, cuando la población de origen gaélico fue reemplazada por colonos de Gran Bretaña, y se agudizó a raíz del alzamiento de Pascua en la década de 1910. En ese sentido, la identificación exclusiva de «norirlandés» se ha introducido en el censo para reducir las divisiones sectarias.

En el acuerdo de Viernes Santo de 1998, los gobiernos de Reino Unido e Irlanda firmaron un compromiso sobre nacionalidad. Es norirlandés toda aquella persona que haya nacido en Irlanda del Norte y tenga, en el momento de nacer, al menos un padre o madre de nacionalidad británica, de nacionalidad irlandesa o con residencia permanente en Irlanda del Norte. El norirlandés es considerado automáticamente ciudadano británico, y la Constitución de Irlanda reconoce también el acceso a la nacionalidad irlandesa bajo las mismas condiciones que otros habitantes de la República. La gran mayoría de norirlandeses católicos se han acogido a esta normativa. Si un norirlandés desea renunciar a la nacionalidad británica, deberá abonar una tasa. En cuanto a las limitaciones, los hijos nacidos de ambos padres extranjeros no son considerados británicos ni irlandeses.

Entre los residentes hay un 59,1% con pasaporte británico, un 20,8% con pasaporte irlandés y un 18,9% sin pasaporte o con el de otro país.

Según el censo de 2011, el 40,8% se define como católico y el 41,6% se identifica con el protestantismo, repartido en distintas denominaciones como la Iglesia presbiteriana (19%), la Iglesia de Irlanda (14%) y el metodismo (3%). Hay confesiones con presencia testimonial como el judaísmo, el islamismo y el bahaísmo. El 17% de la población no profesa ninguna religión. En los últimos años se ha producido un incremento de la población católica debido a la inmigración procedente de la República de Irlanda y a un mayor índice de natalidad, lo que ha igualado el porcentaje de protestantes y católicos en Irlanda del Norte. 

Si se tiene en cuenta el peso de la religión entre las comunidades, el 48% tienen influencia protestante y el 45% tienen influencia católica. Las comunidades de Irlanda del Norte suelen describirse en función de sus conexiones con las dos religiones mayoritarias: mientras los unionistas tienden a ser protestantes o miembros de la anglicana Iglesia de Irlanda, los nacionalistas irlandeses son en su mayoría católicos.

Los idiomas oficiales son el idioma inglés y el idioma irlandés o gaélico irlandés moderno.

El idioma oficial "de facto" en Irlanda del Norte es el inglés, conocido y utilizado por la práctica totalidad de la población. El dialecto norirlandés del inglés tiene influencias del escocés del Úlster.

Algunas minorías usan el irlandés y el escocés, ambos con reconocimiento específico a través de la Carta Europea de las Lenguas Minoritarias o Regionales, ratificada por el gobierno británico en 2001, y del acuerdo del Viernes Santo. El gobierno norirlandés cuenta con dos organismos de protección: el "Foras na Gaeilge" para la lengua irlandesa y la "Ulster Scots Agency" para el escocés del Úlster. Ambos organismos funcionan por separado y bajo la supervisión del "North/South Language Body", parte del Consejo Ministerial Norte-Sur. Se estima que un 11% de los norirlandeses tiene «conocimientos básicos» de gaélico y un 3,7% sabe utilizarlo. El conocimiento del escocés es sensiblemente inferior; no llega al 2%.

En Irlanda del Norte sigue vigente la Ley de Administración de la Justicia de 1737, aprobada por el antiguo Parlamento de Irlanda, según la cual el inglés es la única lengua válida en los procesos judiciales.

Irlanda del Norte es una economía de mercado orientada al sector servicios, con una rica tradición industrial que se ha mantenido. El desempleo ha sido reducido considerablemente hasta situarse en el 6%, ligeramente por encima de la media nacional pero inferior al porcentaje irlandés. El país representa la economía más pequeña del Reino Unido, por lo que el gobierno británico otorga ayudas públicas a la inversión.

La industria pesada ha jugado un papel clave en el desarrollo de la región. La empresa Harland and Wolff fue durante mucho tiempo el mayor astillero del mundo, famoso por la construcción del RMS Titanic entre otros transatlánticos, así como numerosos portaviones para la Marina Real británica. No obstante, la recesión económica de los años 1970 motivó su transformación hacia la ingeniería civil. De igual modo, el norirlandés Harry Ferguson tiene el honor de haber desarrollado el primer tractor agrícola moderno. Hoy en día el mayor empleador industrial es Bombardier Aerospace, especializada en productos aeroespaciales, seguida por multinacionales como Caterpillar, DuPont, Fujitsu y Seagate.

El otro sector clave es la industria textil, y más concretamente la confección de tejidos de lino. La producción norirlandesa de linaza representaba el 10% de toda la Unión Europea.

Durante el conflicto norirlandés se produjo una desinversión nacional e internacional. La consiguiente reconversión industrial y desindustrialización provocó una drástica caída de la actividad laboral, así como tasas de desempleo superiores al 17% en los años 1980. Sin embargo, la firma de los acuerdos de paz en 1998 conllevó la recuperación económica del país, asociada a su vez al crecimiento de Irlanda.

Las empresas norirlandesas mantienen estrechos vínculos con las dos principales universidades del país: la Universidad de la Reina y la Universidad del Úlster.

Los principales socios comerciales de Irlanda del Norte son los estados miembro de la Unión Europea, y particularmente la República de Irlanda. El conjunto de Europa representa un 55% del total, pero si se desglosan los datos el comercio con los irlandeses lidera tanto las exportaciones (33%) como las importaciones (27%). Los principales bienes con los que comercia son los siguientes: maquinaria y equipamiento de transporte, alimentación, productos químicos y manufactura. 

Las competencias sobre energía están transferidas a la Autoridad Regulatoria de Irlanda del Norte. La generación de energía corre a cargo de AES UK, ESB y las empresas de energía renovable; la transmisión es operada por System Operator for Northern Ireland (SONI), y la distribución es responsabilidad de Northern Ireland Electricity (NIE), con una infraestructura que llega a más de 850 000 clientes. El mercado eléctrico está liberalizado. 

La principal infraestructura es la planta de gas natural de Ballylumford, al este de la provincia y con una potencia instalada de 1300MW. Además hay una planta de gas natural en Coolkeeragh para el área metropolitana de Derry (460MW) y otra de carbón en Kilroot, condado de Antrim (660 MW). Toda la red norirlandesa está conectada con la de República de Irlanda a través de tres interconectores, así como a la de Gran Bretaña mediante un cable submarino. El gas natural del área metropolitana de Belfast es conducido por una tubería de 135 km desde Twynholm (Dumfries and Galloway, Escocia) hasta la planta de Ballylumford.

El mercado inmobiliario de Irlanda del Norte estaba compuesto en 2011 por viviendas unifamiliares aisladas (36%), viviendas semi-pareadas (28%), casas adosadas (25%) y pisos o apartamentos (9%). En comparación al resto del Reino Unido, el número de hogares aislados es muy superior a la media nacional.

La red de carreteras y ferrocarriles norirlandeses es de propiedad estatal. El Departamento de Infraestructuras de Irlanda del Norte se encarga de su gestión y mantenimiento. Una corporación estatutaria creada en 1967, la Compañía de Transportes de Irlanda del Norte (cuyo nombre comercial es Translink), opera los servicios públicos de transporte a través de tres subsidiarias: NI Railways (ferrocarril), Ulsterbus (autobuses) y Metro (autobuses urbanos en Belfast).

Los ferrocarriles norirlandeses y la irlandesa Iarnród Éireann mantienen la línea conjunta Enterprise que va desde la Estación Central de Belfast hasta la de Dublín Connolly.

Hay tres aeropuertos en Irlanda del Norte: dos de titularidad privada —Aeropuerto Internacional de Belfast y Aeropuerto Ciudad de Belfast-George Best— y uno de titularidad pública, el Aeropuerto de la Ciudad de Derry. El Internacional de Belfast es el segundo mayor aeródromo de la isla de Irlanda, con más de cuatro millones de pasajeros al año.

Al formar parte del Reino Unido, Irlanda del Norte comparte la misma red de telecomunicaciones y servicios postales. Las llamadas telefónicas desde el territorio a la República de Irlanda y viceversa se cobran al mismo precio que una llamada doméstica, precedidas por el prefijo especial 048 o por el prefijo internacional 0044. Lo mismo sucede con los reglamentos de itinerancia móvil ("roaming") desde 2017. 

En telefonía fija y acceso a Internet, el principal operador es la multinacional BT Group y el mercado está abierto a la competencia en todos sus sectores desde la ruptura del monopolio. En 2006, Irlanda del Norte se convirtió la primera región europea con un 100% de cobertura de banda ancha. Además, ha podido mejorar su servicio rural y las conexiones internacionales gracias a las ayudas del Fondo Europeo de Desarrollo Regional. Se estima que el 90% de los norirlandeses tiene acceso a internet.

En telefonía móvil, existen cuatro operadores con red propia —Vodafone, O2, EE y Three— y un número considerable de operadores móviles virtuales. El 99% de la población reside en áreas con cobertura 4G, lo que supone la mayor proporción entre las naciones del Reino Unido. Siete de cada diez personas utilizaron su móvil en 2016 para acceder a internet, y nueve de cada diez están satisfechos con su cobertura.

Las competencias sobre medios de comunicación en Irlanda del Norte corresponden al gobierno del Reino Unido. La principal fuente de información es la televisión (62%), seguida de la radio (17%), los sitios web (9%) y la prensa escrita (4%). Los residentes deben pagar el canon televisivo británico.

La radiodifusora pública BBC cuenta con un centro de producción en Belfast (BBC Northern Ireland) que gestiona dos emisoras de radio y desconexiones de televisión regional. La oferta de televisión privada corre a cargo de UTV (filial norirlandesa de ITV), Channel 4, Channel 5, los canales gratuitos de "Freeview" y las plataformas de televisión por suscripción. Gracias a un acuerdo de reciprocidad, también pueden sintonizar los canales públicos de la República de Irlanda: RTÉ y TG4.

Hay una fuerte implantación de la prensa local, representada en las cabeceras "Belfast Telegraph", "The News Letter" (unionista) y "The Irish News" (nacionalista), así como disponibilidad de publicaciones británicas e irlandesas.

Irlanda del Norte comparte aspectos de la cultura de Irlanda y de la cultura del Reino Unido. La población de origen católico tiende a identificarse con la primera, mientras que los protestantes son más cercanos a la segunda. Desde la finalización del conflicto, se ha convertido en un destino turístico gracias a los festivales culturales, las visitas a atractivos naturales, y a la práctica de deportes como el golf y la pesca.

Belfast concentra la mayoría de las instituciones culturales norirlandesas como la biblioteca de Linen Hall, la más antigua de la nación y restringida a socios; el Museo del Úlster, el Metropolitan Arts Centre de arte contemporáneo y el Titanic Belfast.

Los desfiles son muy importantes en la sociedad norirlandesa, más que en el resto de Irlanda y Gran Bretaña. Cada comunidad cuenta con sus propias marchas.

Los más conocidos son los de las cofradías protestantes como la Orden de Orange, los Aprendices de Derry y las bandas de marcha lealistas. Cada verano, las cofradías celebran numerosos desfiles y las calles norirlandesas por donde pasa el recorrido se llenan de banderas británicas, pendones, verderones y bandas de música. El más importante es "The Twelfth", que cada 12 de julio conmemora en toda la provincia el triunfo de los orangistas sobre los jacobitas en la batalla del Boyne de 1690.

En las comunidades católicas son mucho menos habituales, pero se concentran en fechas como el Día de San Patricio, el alzamiento de Pascua o las huelgas de hambre de 1981.

Históricamente, los desfiles han sido objeto de controversia entre las comunidades protestante y católica, sobre todo cuando los protestantes atravesaban áreas de mayoría católica. Si bien los primeros aseguran que es una tradición iniciada en el siglo XIX, antes de que esas zonas estuviesen pobladas, los segundos lo consideran una provocación y un gesto triunfalista. Después de que se produjera una revuelta en Portadown, el gobierno norirlandés cuenta con un organismo regulador independiente, la Comisión de Desfiles ("Parades Commission"), que vigila el correcto desarrollo de las marchas desde 1998.

La mitología de Irlanda del Norte es común a la de toda la isla de Irlanda. Si bien muchas leyendas de la era precristiana se perdieron durante la cristianización de la isla, la mayoría de leyendas se han conservado hasta nuestros días. La historia mitológica irlandesa está dividida en cuatro «ciclos»: el ciclo del Úlster, el ciclo mitológico, el ciclo feniano y el ciclo de los reyes, los cuales cuentan la historia de Irlanda y del pueblo gaélico previa a las primeras invasiones, así como la genealogía de los reyes irlandeses.

El ciclo del Ulster —o ciclo de los Ulaid— se establece alrededor del comienzo de la era cristiana y casi todo tiene lugar en las provincias del Úlster y Connacht. Consiste en un grupo de historias heroicas que tratan de las vidas de Conchobar mac Nessa (el rey del Úlster), el gran héroe Cúchulainn (el hijo de Lug) y sus amigos, amantes y enemigos. El desarrollo de las historias se centra en torno a la corte real en Emain Macha (conocido como Fuerte Navan), cerca de la actual ciudad de Armagh. Los Ulaid mantenían estrechas relaciones con la colonia irlandesa en Escocia, y parte del entrenamiento de Cúchulainn tiene lugar en esta colonia.

La cultura popular de Irlanda del Norte está ligada a la música, por influencia tanto irlandesa como británica. Van Morrison, apodado «el León de Belfast» es considerado uno de los músicos más influyentes de su generación, primero con el grupo Them y después en su carrera de solista. Ganador de seis premios Grammy, es miembro del Salón de la Fama del Rock and Roll y del Salón de la Fama de los Compositores. El grupo The Undertones, pioneros del "pop-punk" en los años 1970, es originario de Derry. También han gozado de reconocimiento internacional las bandas alternativas Stiff Little Fingers, The Divine Comedy, y Two Door Cinema Club. El guitarrista Gary Moore (miembro de Thin Lizzy) era natural de Belfast.

Dentro de la música tradicional, el instrumento más conocido es el tambor Lambeg. Se trata de uno de los instrumentos acústicos más sonoros del mundo, pudiendo alcanzar niveles de 120 decibelios. Destacan a su vez danzas populares como la giga y el "reel".

La industria cinematográfica norirlandesa ha permanecido bajo la sombra de las producciones de Reino Unido e Irlanda, pero ha sido capaz de producir títulos con repercusión internacional. Buena parte de la filmografía ha tenido el conflicto norirlandés como tema central; el título más importante es «"Bloody Sunday"» (Paul Greengrass, 2002), basado en los sucesos del Domingo Sangriento, que ha sido galardonada con el del Festival de Cine de Berlín. El director norirlandés más afamado es Kenneth Branagh, especialista en adaptaciones de obras clásicas shakesperianas como "Enrique V" (1989), "Otelo" (1995) y "Hamlet" (1996).

Más conocidos son los numerosos actores que ha aportado a la industria audiovisual. Liam Neeson y Stephen Rea han sido candidatos a los premios Óscar, y Stephen Boyd llegó a ganar el Globo de Oro en 1959 por su papel en "Ben-Hur". Otros actores reconocidos son Ciarán Hinds, Bronagh Gallagher, Patrick Magee, Siobhán McKenna y Jamie Dornan. La Academia Irlandesa de Cine y Televisión (IFTA) tiene como objetivo el desarrollo profesional del sector audiovisual en el conjunto de la isla de Irlanda.

En el ámbito de la literatura, Irlanda del Norte cuenta con una tradición fuerte basada en clásicos como C. S. Lewis, Brian Friel y Flann O'Brien. El escritor irlandés Seamus Heaney, nacido en Derry, ha sido galardonado con el Premio Nobel de Literatura en 1995 «por las obras de una belleza lírica y una profundidad ética, que exaltan milagros diarios y vidas pasadas».

La gastronomía norirlandesa engloba estilos culinarios, recetas y tradiciones tanto de la cocina británica como de la cocina irlandesa. El ingrediente principal es la patata, presente en la mayoría de preparaciones como el puré "champ" y el guiso "colcannon". Hay pocos platos característicos de la región: los más conocidos son el pan de soda —hecho con bicarbonato sódico en vez de levadura—, el pan de papa, "bangers and mash", el queso de Coleraine y el "Ulster fry", una variante del desayuno completo.

Las disciplinas de equipo más practicadas en Irlanda del Norte son el fútbol, el rugby y el fútbol gaélico. En cuanto a las individuales, destacan el golf y el boxeo. Los deportistas norirlandeses pueden competir con Reino Unido o bien con la República de Irlanda en los Juegos Olímpicos. Sin embargo, Irlanda del Norte cuenta con su propio comité en los Juegos de la Mancomunidad.

En fútbol, Irlanda del Norte posee su propio campeonato de liga y su propia selección nacional, al igual que el resto de naciones constitutivas británicas. La Asociación Irlandesa de Fútbol (IFA) fue fundada el 18 de noviembre de 1880, y durante tres décadas fue el único representante de la isla de Irlanda. Después de que la República de Irlanda proclamase su independencia, la FIFA siguió reconociendo a la IFA como único representante irlandés hasta los años 1950, cuando ambas selecciones limitaron la elección de jugadores a sus respectivos territorios. Desde entonces, se han clasificado para tres Copas Mundiales (1958, 1982 y 1986) y una Eurocopa (2016). La IFA es también miembro de la International Football Association Board, encargada de definir las reglas del fútbol a nivel mundial. El equipo más laureado es el Linfield F.C. de Belfast, si bien los norirlandeses prefieren seguir las ligas inglesas. Existe la particularidad del Derry City, equipo norirlandés que disputa la FAI Premier Division, la liga de la zona republicana. En la capital se encuentra también el estadio Windsor Park, donde la selección disputa todos sus partidos internacionales. El único norirlandés que ha ganado el Balón de Oro ha sido George Best.

El rugby, en cambio, es representado en una selección irlandesa unificada con jugadores procedentes de las dos entidades de la isla. La Unión de Rugby Fútbol de Irlanda fue fundada en 1879; desde entonces es una potencia mundial de este deporte, ocupa las primeras posiciones del ranking de la World Rugby, y cada año disputa el Torneo de las Seis Naciones. El equipo Ulster Rugby forma parte de la Pro 14 y juega sus partidos en el estadio Ravenhill de Belfast.

Los deportes gaélicos están organizados en toda la isla de Irlanda por la Asociación Atlética Gaélica (GAA), la sociedad deportiva más grande de Irlanda con unos 500000 socios. Mantiene reglas estrictas acerca de la condición amateur de los jugadores y entrenadores. El fútbol gaélico es la variante donde los norirlandeses obtienen mejores resultados, especialmente la selección del condado de Tyrone. Aunque hay jugadores protestantes, el deporte es seguido principalmente por la comunidad católica. Casement Park es el principal estadio de los deportes gaélicos del país, y también es el recinto deportivo norirlandés de mayor capacidad. 

Irlanda cuenta desde 1891 con la federación de golf más antigua del mundo, la Golfing Union of Ireland, de la cual ellos también forman parte. El golf es el deporte en el que más norirlandeses han destacado, entre ellos Fred Daly, David Feherty, Ronan Raferty, Graeme McDowell, Darren Clarke y Rory McIlroy. En boxeo, Carl Frampton ha sido campeón del peso pluma por la Asociación Mundial.

Una de las figuras más populares en el deporte británico fue Alex Higgins, jugador de snooker y apodado «el billarista del pueblo». En 1984 se convirtió en el primer norirlandés en conquistar la Triple Corona.

John Watson y Eddie Irvine son los únicos norirlandeses que han logrado ganar al menos un gran premio de Fórmula 1, y Jonathan Rea ha ganado tres campeonatos del mundo de Superbikes, siendo el primer piloto de la historia en logarlos de forma consecutiva.




</doc>
<doc id="40998" url="https://es.wikipedia.org/wiki?curid=40998" title="ISO 3166-2">
ISO 3166-2

ISO 3166-2 es la segunda parte del estándar internacional de normalización ISO 3166, publicado por la Organización Internacional de Normalización (ISO), que define los códigos de identificación de las principales subdivisiones (por ejemplo, provincias o estados) de todos los países codificados en ISO 3166-1. El nombre oficial de la norma es "Códigos para la representación de nombres de países y sus subdivisiones - Parte 2: Código de subdivisión País", que fue publicada por primera vez en 1998.

El propósito de la norma ISO 3166-2 es establecer un estándar internacional de códigos alfanuméricos cortos y únicos, para representar las pertinentes divisiones administrativas y los territorios dependientes de todos los países, para su uso en etiquetas de paquetes, envases y otros objetos similares. Un código alfanumérico corto puede servir para indicar claramente una localización de una forma más conveniente y menos ambigua que el topónimo completo.

Cada código completo ISO 3166-2 consta de dos partes, separadas por un guion:

Cada código ISO 3166-2 completo, se puede utilizar para identificar de forma única una subdivisión del país en un contexto global.

Actualmente, más de 4000 códigos se definen en la norma ISO 3166-2. Para algunos países, los códigos se definen para más de un nivel de subdivisiones.

La siguiente tabla puede ser utilizada para acceder a los códigos ISO 3166-2 de cada país. La tabla contiene los siguientes datos:

Para los siguientes países, el número de sus subdivisiones en ISO 3166-2, la mayoría de ellos territorios dependientes, tienen también oficialmente asignados su código de país en ISO 3166-1:

El formato de los códigos ISO 3166-2 es diferente para cada país. Los códigos pueden ser alfabéticos, numéricos, o alfanuméricos, y pueden ser de longitud constante o variable. La siguiente es una tabla de los códigos ISO 3166-2 de cada país (para aquellos que los han definido), agrupados por su formato:

El ISO 3166/MA actualiza ISO 3166-2 cuando es necesario, mediante el anuncio de los cambios en sus boletines de noticias, y la liberación de nuevas ediciones que comprenden una consolidación de los cambios de los boletines. Los cambios en ISO 3166-2 consisten principalmente en correcciones ortográficas, adicción y supresión de subdivisiones, y modificación de la estructura administrativa.



</doc>
<doc id="41006" url="https://es.wikipedia.org/wiki?curid=41006" title="Lluvia de meteoros">
Lluvia de meteoros

Cuando un objeto astronómico (más comúnmente un cometa), se adentra en el interior del Sistema Solar, la interacción con el viento solar hace que su superficie se active. Los gases y materiales de la superficie del cometa salen despedidos al espacio, y pasan a orbitar al Sol en órbitas muy similares a las de su cometa de origen. Así se forma una corriente o anillo de partículas, denominado técnicamente enjambre de meteoros. La órbita terrestre cruza algunos enjambres de cometas de periodo corto, produciendo lluvias de meteoros anuales, como las Leónidas o las Perseidas. Cuando la actividad de una lluvia de meteoros sobrepasa los 1000 meteoros por hora, se la denomina tormenta de meteoros. 

Se cree que algunos asteroides pueden ser cometas exhaustos, es decir, cometas que han perdido todos sus elementos volátiles. Por eso, alguno de estos fenómenos tiene a asteroides como cuerpo progenitor. Es el caso de las Gemínidas, que se encuentran en la órbita del asteroide (3200) Phaeton.

Al entrar un meteoroide en la atmósfera terrestre a gran velocidad, se observa un trazo luminoso llamado estrella fugaz o meteoro. Este efecto luminoso está producido por la ionización de la atmósfera que genera la partícula, llegando a alcanza una temperatura comprendida entre los 5000 y los 7000 grados centígrados. La mayor parte de meteoros tienen el tamaño desde un granos de arena a un guisante y se desintegran en las capas altas de la atmósfera a unos 80 o 100 kilómetros de altura. Debido a su poca masa el rastro luminoso que deja tras de sí solo es visible unos escasos segundos. Algunos con masa mayor llegan a tener un brillo aparente superior al del planeta Venus, a los cuales se les denomina bólidos (en inglés, "fireballs"). Sólo cuando los meteoroides poseen una masa considerable pueden atravesar la atmósfera por completo hasta llegar a la superficie. Estos meteoroides pasan a recibir la denominación de meteoritos.

Estas son las lluvias anuales más notables:





</doc>
<doc id="41012" url="https://es.wikipedia.org/wiki?curid=41012" title="Rumano">
Rumano

El término Rumano se puede referir a:


</doc>
<doc id="41013" url="https://es.wikipedia.org/wiki?curid=41013" title="Sigerico">
Sigerico

Sigerico (¿? – 415) fue un rey visigodo que gobernó durante siete días en el año 415. Su nombre significa "Rey Victorioso" o "Rey de la Victoria" (gótico "sigis"-victoria y "reiks"-rey).

Tras el asesinato de Ataúlfo, por un asesino al servicio del general Sarus, quien había sido mandado asesinar anteriormente por Ataúlfo y era el hermano de Sigerico, se generó una lucha por el control del trono entre Sigerico y Walia, hermano de Ataúlfo, ganando en un principio Sigerico.

En sus pocos días de gobierno dio pruebas inequívocas de sus intenciones: mandó matar a seis hijos de Ataúlfo, para evitar futuros descendientes, y vejó a Gala Placidia, viuda de Ataúlfo y hermana del emperador Honorio, obligándola a caminar junto con otros prisioneros delante de su caballo hasta una distancia de doce millas desde la ciudad de Barcelona. Esta situación generó un gran malestar entre los partidarios de Walia, quienes le asesinaron al séptimo día de su reinado.



</doc>
<doc id="41016" url="https://es.wikipedia.org/wiki?curid=41016" title="Walia">
Walia

Walia o Wallia (¿?-418) fue rey de los visigodos entre 415 y 418, adquiriendo reputación de bravo guerrero y gobernante prudente. De la dinastía baltinga, hijo de Atanarico, y hermano de Ataúlfo (según Baronio, era hijo, pero se sabe que todos los hijos de Ataúlfo eran jóvenes y todos fueron asesinados por Sigerico), fue elegido al trono tras los asesinatos de este y de su sucesor Sigerico.

Tras el asesinato de Ataúlfo en 415 se generó una lucha por el trono entre Sigerico y Walia. En un principio accedió al poder Sigerico, quien en sus siete días de gobierno dio pruebas inequívocas de sus intenciones: mandó matar a los seis hijos de Ataúlfo, para evitar futuros descendientes, y atacó sin piedad a Gala Placidia, viuda de Ataúlfo. Esta situación causó un gran malestar entre los partidarios de Walia, quienes asesinaron a Sigerico el séptimo día de su reinado.

Intentó establecerse en el norte de África pero una tempestad dio al traste con sus expectativas, y falto de víveres firmó la paz con el emperador romano Honorio y un tratado ("foedus") con el que Walia se comprometía a entregar a Gala Placidia (hermana de Honorio raptada por Alarico I y que había sido esposa de Ataúlfo) y a expulsar de la península ibérica a los pueblos bárbaros que habían penetrado en el año 409.

Por su parte, el emperador Honorio entregaría 600 000 "modios" de trigo a los visigodos. En poco más de dos años los visigodos aniquilan a los vándalos asdingos que estaban asentados en la Bética y prácticamente a todos los alanos de la Lusitania. De los cuatro pueblos bárbaros (vándalos asdingos, vándalos silingos, suevos y alanos) que se asentaron en la Península solo quedaban dos, pero cuando parecía que también serían aplastados por Walia, Honorio decidió cambiar su plan y entregó a los visigodos la Aquitania para que se estableciesen allí. Fijó entonces la capital del reino visigodo en Tolosa (la actual ciudad de Toulouse, en Francia). 

Se casó con una hija de Ricomero, rey de los Francos, y de su mujer Ascyla. Su hija se casó con Requila, rey de los suevos, y junto a él fue madre de Ricimero.

Le sucedió Teodorico I, yerno de Alarico I.



</doc>
<doc id="41019" url="https://es.wikipedia.org/wiki?curid=41019" title="Mancicerta">
Mancicerta

Mancicerta (también Malâzgird; armenio: Մանազկերտ, Manazkert, inglés: Manzikert, kurdo: Milazgird) es un distrito y una ciudad en la provincia de Muş en el este de Turquía, con una población de 23.697 (año 2000).

Según investigaciones, la fundación moderna de Mancicerta fue en algún momento durante el reinado del rey Menua Urartian (810 a 785 aC). [1] El sufijo-ceñido, que se encuentra en topónimos muchos asentamientos del este de Anatolia, proviene del armenio "kert" que significa "construido por ". Una tradición popular folclórica armenia sostiene que Mancicerta fue fundada por Manaz, uno de los hijos de Hayk, el patriarca legendario y epónimo y progenitor de los armenios El nombre de la ciudad era originalmente Manavazkert (armenio: Մանավազկերտ), pero con el tiempo su nombre fue acortado a Manzikert simplemente.

Las tierras alrededor de Mancicerta pertenecieron a la Manavazian, una familia armenia de najararos que se decía descendiente de Manaz, hasta el 333 dC, cuando el rey Osroes III el pequeño de Armenia ordenó que todos los miembros de la familia sean pasados a cuchillo. Más tarde dio el tierras a otra familia, los Agbianosian. Mancicerta fue una ciudad fortificada, y fue un importante centro comercial ubicado en el cantón de Apahunik en la provincia Turuberán del antiguo Reino de Armenia. También sirvió como la capital del Emirato Caisí o Emirato de Mancicerta alrededor de 860 y hasta 964. En 968 El general bizantino Bardas Focas capturó Mancicerta, la cual fue incorporada al Catepán bizantino de Baspracania (Vaspurakan). En 1054, los selyúcidas hicieron un intento de tomar la ciudad pero fueron rechazados por la guarnición de la ciudad bajo el mando del general Basilio Apócape.

La batalla de Mancicerta fue luchada cerca de la ciudad en agosto de 1071. En una de las derrotas decisivas de la historia bizantina, el sultán selyúcida Alp Arslán derrotó y capturó al Emperador Romano Diógenes. La victoria turca condujo a la transformación étnica y religiosa de Armenia y Anatolia, el establecimiento del sultanato selyúcida de Rum, y más tarde el Imperio Otomano y la República de Turquía directamente. Los selyúcidas saquearon Mancicerta, y se masacró a gran parte de su población, además de reducir la ciudad a cenizas.

En 1915, en vísperas del genocidio armenio, Mancicerta tenía una población de 5.000 personas, la gran mayoría armenios. La economía de la ciudad giraba en torno al cultivo de cereales, el comercio y la producción de artesanías. Existían dos iglesias armenias, Yerek Khoran Surb Astvatsatsin (Tres Altares Santa Madre de Dios) y Surb Gevork (San Jorge) y una escuela armenia. Al igual que muchas otras ciudades y pueblos durante el genocidio su población armenia fue sometida a masacres y deportaciones. Con la primavera de 1915, llegaron a la ciudad las tropas del Imperio ruso, pero fueron repelidos por un contraataque turco poco después.


</doc>
<doc id="41026" url="https://es.wikipedia.org/wiki?curid=41026" title="Historia de Suiza">
Historia de Suiza

Las primeras noticias históricas sobre las tierras de la actual Suiza aparecen con Julio César en su «"La guerra de las Galias"». Después de las Grandes invasiones que bosquejaron las barreras lingüísticas del país, se formaron alianzas entre pequeños estados durante la Edad Media, entre 1291 y 1332, con la finalidad de formar la Confederación de los III Cantones, la cual fue la primera etapa para la formación de la Confederación Suiza. Luego de sucesivas alianzas de defensa hasta que en 1481 se constituyó la Confederación de los VIII Cantones. En los siglos siguientes, se construyó progresivamente la Confederación de los XIII Cantones hasta que alcanzó su independencia en 1648. Suiza obtuvo un estatus Federal en 1803 al ser dividida y reorganizada como República Helvética durante la ocupación de la Francia Revolucionaria gracias a Napoleón Bonaparte. Suiza se constituyó en veintidós cantones hasta su liberación en 1815 y, más tarde durante una guerra civil y religiosa, emerge el Estado federal en 1848. Debido a su política de neutralidad Suiza atravesó el siglo XX sin participar en guerra alguna.

Desde 1848, la Confederación Suiza ha sido un Estado federal formado por cantones relativamente independientes, algunos de los cuales han permanecido confederados desde hace más de siete siglos, por lo que se puede considerar a Suiza como una de las repúblicas más antiguas del mundo.

Hay restos arqueológicos que sugieren que pueblos dedicados a la caza-recolección se instalaron en los valles al norte de los Alpes al fin del Paleolítico. En la era Neolítica, esta región estaba relativamente muy poblada. Se han encontrado restos de construcciones paláfiticas o lacustres (sobre pilotes) en las zonas poco profundas de muchos lagos. Hacia el año 1500 a. C., arribaron a esta zona tribus de origen celta. Los retios o recios habitaron en la zona este, mientras que los helvecios se asentaron en el oeste.

Los primeros indicios de ocupación del territorio de Suiza se remontan al Musteriense ( a.C.) y a la aparición de varias piezas arqueológicas de culturas como Aziliense, Sauveterriense, Tardenoisiense, los principales vestigios datan de la era Neolítica junto con la aparición de la agricultura, milenio VI antes de Cristo. En el periodo Neolítico medio aparece la cultura del bronce, caracterizada por los poblados lacustres y poblados ribereños, en particular de la cultura campaniforme la cual se sitúa al borde del lago Neuchâtel y en la bahía de Zúrich en donde se descubrieron las ruedas más antiguas de Europa, que datan de años antes de Cristo. Estos pueblos contaban hasta con una centena de habitantes, que los abandonaron al final del siglo IX antes de Cristo con la cultura de Hallstatt.

Desde la edad del hierro, los Celtas ocupan el territorio trayendo con ellos las técnicas del hierro y desarrollando artes tales como la cerámica y la joyería. La segunda parte de la edad del hierro, se denominó “período de La Tène” nombre que se deriva de un lugar situado actualmente en el cantón de Neuchâtel descubierto en 1857. Algunos nombres de lugares actuales son de origen Celta como: Nyon o Yverdon.

A continuación llegó la inmigración de la tribu germánica de los Cimbrios o Cimbros, que dejan Jutlandia hacia 115 a.C. en dirección al sur a los cuales se unirán pocos años más tarde los Teutones; a partir, más o menos, del año 100 antes de Cristo, la mayor parte del altiplano suizo será ocupado por cinco tribus helvéticas, que mencionará por primera vez el historiador romano Tácito.

Originalmente nómadas, las tribus se sedentarizaron progresivamente, aunque dos de ellas se unieron a los Cimbrios, en 107 antes de Cristo, durante su expedición al suroeste de la actual Francia. Empujados por los Cimbrios, la tribu helvética de los Tigurins desciende el valle de Ródano encabezados por su joven jefe Divico. A orillas del Garona, en 107 a.C., se enfrentan y vencen a un ejército romano, cuyos soldados sobrevivientes tuvieron que pasar bajo un yugo en señal de derrota. Como represalia, Roma envía un nuevo ejército mandado por Cayo Mario quien se enfrenta a los germanos el 102 a.C. y los extermina casi totalmente en la batalla de AquaeSextiae (actualmente Aix en Provence); los tigurios fueron forzados a regresar y establecerse en la región de Avenches.

Poco antes de la guerra de las Galias, habitan el territorio que es actualmente Suiza diversas poblaciones celtas. Por un lado, el altiplano suizo está ocupado principalmente por los helvecios, una parte de Jura y la región de Basilea está en las manos de los ráuracos, los retios y los grisones ocupan una parte de la Suiza oriental. El Tesino poblado de leponcios mientras que el Valais actual está dividido entre los nantuates, los veragros, los sedunos y los uberios; Ginebra es un oppidum de los alóbroges. Julio César, aunque nunca estuvo allí, en sus Comentarios sobre la guerra de las Galias, describe el territorio de los helvecios, como limitado "de un lado por el Rin [...], del otro por el Jura [...] y de un tercero por el lago Léman y el Ródano". César describe cuatro tribus helvéticas y 12 poblaciones de las cuales una de ellas está situada en uno de las orillas del río Aar, la que es actualmente la ciudad de Berna.

A mediados del siglo I antes de Cristo, los helvecios emigran hacia el país de la tribu gala de los sántonos, en el oeste de la actual Francia. Aunque las razones de esta decisión no se conocen con certeza, entre los diversos motivos que habrían podido llevar a esta migración es la falta de tierras y la ambición del cabecilla Orgétorix. Fuera cual fuera la razón, estos últimos quemaron sus ciudades y pueblos y más de helvecios emprendieron el camino. Julio César, entonces procónsul de la Galia Narbonense, los combate en la batalla de Bibracte (58 antes de Cristo) y les obliga a regresar a su tierra donde deberán defender la frontera de Rin contra las invasiones germánicas. En el 52 antes de Cristo, según César, los helvecios envían refuerzos a Vercingétorix.

Los romanos van integrando progresivamente a los helvecios en el naciente Imperio mediante la fundación de una colonia de veteranos en Nyon, después bajo el reinado de Augusto, de Augusta Raurica cerca de Basilea, en el territorio helvético que pertenece desde entonces a la Galia Bélgica. Solo las tribus del Valais y los réticos permanecen independientes hasta que fueron conquistados por Tiberio y Claudio hacia el 7 antes de Cristo, que unificaron en la provincia de Recia cuya capital es Augsburgo.

En el siglo I, la orilla norte del Rin es una zona fronteriza estratégica del Imperio romano: está ocupada militarmente y defendida por campamentos militares permanentes, como en Augusta Raurica

La red viaria se consolida, se crean ciudades nuevas como "Forum Claudii Vallensium" (actualmente Martigny) mientras que las élites celtas se romanizan. El antiguo oppodium principal de los helvecios, "Aventicum" (actualmente Avenches), elevado al rango de colonia en 73, se convierte progresivamente en la principal ciudad de la región. Hacia el 47, el Valais se convierte en una provincia autónoma, los "Alpes Peninos", y el territorio de los helvecios se suma en el 89 a la provincia de Germania Superior cuya capital era la actual Maguncia.
Entre el siglo I y el II la paz romana reina en el imperio; las fronteras habían avanzado hacia el norte y Suiza ya no era entonces zona fronteriza. Mientras el latín se generaliza, el territorio conoce un periodo de prosperidad económica. El cristianismo llega desde Italia y se extiende progresivamente en todo el territorio, apareciendo las primeras iglesias en Ginebra y Martigny y sedes episcopales en Basilea, Martigny, Ginebra y Coira entre el 350 y el 400. Los misioneros cristianos fundaron muchas comunidades religiosas, particularmente en Saint-Ursanne, en Romainmôtier y también, el monje Galo se establece al sur del lago de Constanza, donde años más tarde se levantará la abadía que lleva su nombre.

Hacia el final del siglo III, entran en el actual territorio suizo invasiones bárbaras de alamanes de Germania Magna, especialmente en 260, cuando saquean numerosas ciudades, se dirigen progresivamente al Rin, a lo largo de lo cual los emperadores romanos del IV siglo construyen barreras defensivas (fortalezas y torres de vigilancia). Progresivamente desde 401, la población inquieta migra hacia el sur y abandona las ciudades de Nyon, luego de Augusta Raurica, al tiempo que las tropas romanas abandonan el Rin marchando al sur de los Alpes, y abandonando también definitivamente el territorio de Suiza a los pueblos germánicos llamados “Federales”, respectivamente el pueblo burgundio luego los alamanes.

Con la caída del Imperio romano entraron las tribus germánicas en la zona. Los burgundios se establecieron en el oeste, mientras que en el norte los alamanes forzaron lentamente a la población celto-romana a retirarse a las montañas. Los burgundios formaban parte del reino de los francos en 534. Dos años más tarde, el ducado de los alamanes siguió su camino. En la región bajo control alamán, solo permanecieron comunidades cristianas aisladas. La misión hiberno-escocesa reintrodujo la fe cristiana a principios del siglo VII.

Bajo el reinado de los reyes carolingios, el feudalismo proliferó, y los monasterios y obispados se constituyeron en bases importantes para mantener el poder. El Tratado de Verdún de 843 otorgó la alta Borgoña (la parte occidental de la Suiza actual) a Lotaringia y el reino alamán (la parte oriental) al reino oriental de Luis el Germánico, que formaría parte del Sacro Imperio Romano Germánico.

Hacia 443, los burgundios se establecieron al oeste del país en una región llamada Sapaudia («país de los abetos»), que corresponde a Saboya y hacen de Ginebra una de sus capitales. Los burgundios se asimilan a la población galo-romana conservando el latín como idioma y transformando progresivamente su territorio en un reino (poco después de que Odoacro haya depuesto al último emperador romano Rómulo Augústulo en 476) y extendiéndose de forma considerable en el valle del Ródano, el Cantón del Valais y los puertos alpinos.

A partir de 260, los alamanes se habían establecido progresivamente en el centro y el este del país buscando tierras cultivables e imponen allí sus dialectos germánicos. La frontera entre las dos tribus se fija entre los siglos VIII y IX. Los Alpes orientales se ven poco afectados por estas invasiones y mantienen incluso hasta hoy un dialecto del latín vulgar, el romanche también llamado retorrománico. La zona del Tesino, en el sur de la actual Suiza y parte de Galia Cisalpina, permanece bajo el control de la península itálica.

En 534, los francos vencen al rey burgundio Segismundo y se anexionan su reino, propiciando la instalación de los alamanes, a los que habían vencido previamente. Los francos conquistarán la Recia en 550, completando así su toma de control del conjunto del territorio helvético.
El territorio suizo forma parte del imperio de Carlomagno antes de convertirse en parte del Reino de Borgoña, al desmembrarse la Francia Media después de verse dividida entre los ducados de Borgoña al oeste y de Suabia al este. El feudalismo se impone al final del siglo IX cuando varias familias tratan de asentar su autoridad sobre diferentes partes del territorio: los condes de Saboya sobre el Vaud, Ginebra (cuyos condes son depuestos) y Valais, los condes de Gruyère sobre el interior del territorio de Friburgo, los Zähringen que fundan numerosas ciudades entre ellas Friburgo y Berna, los Kiburg se instalan en la Meseta suiza, los Hohenstaufen y los Habsburgo en la región de Zúrich hasta el paso de San Gotardo.

La habilitación del paso de San Gotardo, entre Uri y el Tesino, con la ayuda de los Walsers inmigrantes recientes y expertos en construcción de caminos, al inicio del siglo XII, tiene consecuencias importantes: el puerto del Gran San Bernardo en Valais pierde importancia en el tráfico internacional, lo que provoca una crisis económica de dos siglos en el Valle del alto Ródano. En recompensa por este trabajo, el Uri obtiene “por servicios prestados al emperador” la Inmediación Imperial que los independiza prácticamente de los Habsburgo, enriqueciéndose por los peajes y la venta de servicios (guías y posadas) lo que aviva evidentemente la codicia de los Habsburgo.

La omnipresencia y el poder de los Habsburgo unidos a su voluntad de extender sus dominios y arrebatar las riquezas de los pequeños ducados y condados suizos preocupan a la pequeña nobleza local, que no tiene sin embargo la importancia necesaria para oponerse a su poder, por lo que no le queda otra opción que servir a los “extranjeros” para sobrevivir. Por su parte, los campesinos pobres soportan cada vez peor los pesados impuestos que deben pagar para beneficio exclusivo de una aristocracia extranjera que les impone sus leyes sin tener en cuenta sus costumbres tradicionales. Los Waldstätten (literalmente «Comunidades del Bosque», agrupación de los cantones primitivos) de los valles del Lago de los Cuatro Cantones o Lago de Lucerna, trataron en 1240 de oponerse a esta amenaza con una revuelta, pero fracasan y son duramente reprimidos, al igual que las ciudades de Berna y sobre todo Zúrich que acaban casi en ruinas.

La historia suiza comienza oficialmente el 1 de agosto de 1291 cuando los pueblos de Uri, Schwyz y Unterwalden firmaron un Pacto federal (en alemán Bundesbrief) para combatir a los Habsburgo, soberanos de Austria. Los habitantes de estos territorios eran principalmente campesinos, siervos (esclavos) y, por supuesto, nobles (ciudadanos).

En abril de 1291, Rodolfo I de Habsburgo, primer miembro de la familia en llegar a emperador, recupera los derechos sobre Lucerna, en el extremo del Lago de los cuatro cantones, con el objetivo de restablecer la autoridad de su familia en la región. Después de su muerte, el , y previendo eventuales problemas de sucesión, los hombres libres de los valles del Uri, de Schwyz y de Nidwalden, renuevan un pacto de alianza jurídica y de defensa permanente, en una fecha indeterminada a inicios del mes de agosto.

Completamente olvidado, este pacto no se conoció hasta el siglo XVIII y fue publicado en su versión original en latín en 1760 por Johann Heinrich Gleser. No sería reconocido como primer Pacto federal hasta finales del siglo XIX por iniciativa del Consejo Federal y festejada su conmemoración por primera vez en su sexto centenario, en 1891. A partir de 1899, la fiesta nacional suiza se celebra anualmente el 1 de agosto; antes de esta fecha, la fundación de la Confederación tenía lugar el 8 de noviembre de 1307, fecha del legendario Juramento de Rütli según Egidio Tschudi. Los hechos míticos descritos en la leyenda de Guillermo Tell también tuvieron lugar en esa misma época, inicios del siglo XIV.
La situación se deterioró entre los Waldstätten (cantones primitivos) y los Habsburgo durante el reinado interino que siguió a la muerte de Enrique VII de Luxemburgo en 1313. En respuesta al ataque de Schwyz contra la abadía de Einsiedeln ocurrido el , se prohibió a los Waldstätten el acceso al mercado de Lucerna, lo que fue causa de que Luis de Baviera la emprendiese contra el Habsburgo, Federico el Hermoso, después de la doble elección de Wittelsbach ().

En 1315 el Duque de Austria Leopoldo I, hermano menor de Federico, lanza un doble ataque contra montañeses que vencieron por asalto una primera columna compuesta de a soldados en la batalla de Morgarten, el 15 de noviembre, en la que los austriacos sufrieron un verdadero desastre. La segunda columna, que se dirigía hacia Unterwalden, se retiró entonces sin llegar a combatir.

Tras esta victoria, los confederados renuevan su alianza con el pacto de Brunnen, el . En alemán este texto es el primero en el cual se utiliza el término Eidgenossen («Confederados», que, literalmente quiere decir «compañeros unidos por un juramento»). Detalla igualmente la prohibición hecha a los firmantes de aliarse con potencias extranjeras. Esta última cláusula no será derogada hasta la fundación de la República Helvética en 1789.

En 1332 los "Waldstätten" recibieron un nuevo aliado, Lucerna, que en ese momento era una población pequeña. Sin embargo fue muy importante, pues posibilitó la navegación sobre el Lago de los Cuatro Cantones, que desde entonces quedó completamente en territorio de los confederados.

Tres años más tarde, el pueblo de Zúrich se levantaría contra el poder de la nobleza. Pero Zúrich no firmó el Pacto de alianza con los cuatro confederados hasta 1351. Esta fue una de las adhesiones más importantes, pues en ese momento Zúrich ya contaba con 12.000 habitantes, lo que para la época era una ciudad importante de la región.

En 1352 los Habsburgo declararon la guerra a Zúrich, lo que obligó a los confederados a actuar; la guerra permitió a los aliados ocupar los territorios de Glaris y Zug, que estaban bajo dominio de los Habsburgo. Durante la ocupación, los habitantes de Zug pidieron auxilio a su emperador, pero este respondió diciéndoles que no importaba si la ciudad era conquistada, pues ya reconquistaría el territorio, porque en ese momento no tenía tiempo. Esto provocó que los zugueses firmaran igualmente una alianza con los confederados en 1352.

Los territorios de Glaris y Zug tuvieron que ser restituidos a los Habsburgo, pero ambos territorios volvieron a la federación, Zug en 1365, mientras que Glaris lo hacía en 1388.
Tiempo después la casa de los Habsburgo tuvo que firmar la paz con los "Waldstätten" tras perder la batalla de Sempach en 1386.

En el imaginario popular, la idea original de tres miembros fundadores se apaga progresivamente al recibir a nuevos miembros. En realidad, las tres entidades organizarán, sea en conjunto o individualmente, una verdadera red de alianzas de defensa durante cuarenta años comenzando con el Cantón de Lucerna en 1332 y el de Zúrich en 1351.

La ciudad de Zug y el valle de Glaris, firmaron una alianza en 1352, aunque este último no tuvo un estatuto de igualdad con los demás miembros. De todas maneras algunas semanas después de haber firmado estos acuerdos, los confederados deben devolver esos dos territorios a los Habsburgo. Hasta 1365 no recuperaron Zug y hasta 1388 Glaris. En 1353, se firma una alianza con el Cantón de Berna que tiene igualmente por objetivo impedir cualquier tipo de reclamación sobre Obwald en el territorio de Berna, en su entorno rural y dominio de la ciudad.

Cuando los ocho pequeños estados, unidos por esta red de alianzas, se agruparon bajo el nombre genérico de “Confederación de los VIII cantones”, en 1359, por primera vez aparecen dos bandas cruzadas sobre el fondo rojo como señal de renacimiento sobre los campos de batalla. Más tarde, en 1851 se definirá como escudo oficial del país la cruz blanca de brazos iguales sobre el fondo rojo. En 1370, el nuevo pacto, llamado "Pfaffenbrief" («Estatuto de sacerdotes» en alemán), se firma entre los Cantones que controlan el paso de San Gotardo, es decir, todos ellos, salvo Glaris y Berna. Este documento unifica el derecho que existe y hace a cada hombre, sea noble o plebeyo, laico o religioso, igual ante la justicia impartida por los jueces locales.

De todas formas los Habsburgo no renuncian a sus pretensiones. En dos ocasiones tratan vanamente de conquistar los cantones: la primera vez en 1386 en la batalla de Sempach, y más tarde, 1388, en la batalla de Näfels. En los dos casos, los montañeses, inferiores en número, pelean contra soldados experimentados, ganando así una reputación de guerreros intrépidos pero igualmente poco respetuosos con las costumbres guerreras. Esta doble victoria consolida la alianza de las ocho comunidades que firman en 1393, el primer estatuto común de ocho cantones, llamado el "Convenio de Sempach", que define reglas militares de comportamiento durante y después de los combates así como la manera de comprometerse con un conflicto, que no puede darse sino hasta después de una deliberación común.

Los cantones suizos aseguran parcialmente su independencia frente los dirigentes regionales, todos esperando saber la postura del Sacro Imperio Romano. El siglo XV vio una fase de expansión de la Confederación que conquista los territorios próximos y concluye alianzas con varios pueblos de los alrededores: Appenzell, el Valais y San Galo. En 1415, los confederados planean y ejecutan en común, a costa de los Habsburgo y con la bendición del emperador, la conquista del Cantón de Argovia del cual una parte es administrado bajo la forma de un tratado común.

Tras la muerte de Federico VII, conde de Toggenburgo (1436), sin dejar herederos, sus territorios quedaron sin gobierno y, entonces, los confederados, particularmente Schwyz y Zúrich se enfrentaron para repartirse la herencia del conde durante la llamada antigua guerra de Zúrich (1440–1446): Schwyz, en su afán por conseguir nuevas tierras, invadió la mayor parte del territorio del condado. El problema se dio cuando el ejército de Zúrich llegó a la zona para ocupar los mismos territorios. Zúrich se enfrentó con Schwyz tratando de conquistar los territorios ya ocupados por Schwyz; entonces interviene por primera vez la Dieta federal, dando la razón a Schwyz (entonces aliado con Glaris).

La Dieta federal decidió declarar la guerra a Zúrich, que se rindió a los confederados y al mismo tiempo fue obligada a firmar un tratado de paz. El burgomaestre de Zúrich (Stüssi), como represalia, decidió firmar un pacto con la casa de Austria, la enemiga de los confederados.

Zúrich, aliada con Austria, parte a la guerra contra los confederados. Desafortunadamente para Stüssi (burgomaestre de Zúrich), los confederados aparecían como el ejército más fuerte y grande de Europa, capaz de reunir más soldados que el mismo Imperio de los Austria, lo que significó que la batalla de Santiago del Sihl fue ganada por la confederación.

Finalmente, se conquista Turgovia en 1460 y se une igualmente como estado confederado tras la firma de un tratado común.

Al final de la guerra de Borgoña, dos nuevos cantones, Friburgo y Soleura, llaman a la puerta de la confederación. Sin embargo los cantones se dividen ante estas demandas de adhesión y la guerra civil amenaza entre los cantones rurales que temen perder su mayoría y los cantones urbanos. Finalmente el ermitaño Nicolas de Flue propone en 1481 un compromiso aceptable, el Convenio de Stans: Friburgo y Soleura son admitidos en la Confederación.
Después de la derrota de los Borgoñones, el emperador Maximiliano reorganiza el Sacro Imperio Romano instaurando un tribunal imperial y un nuevo impuesto, el céntimo real, en 1495. Los conféderados se niegan a someterse y vencen a las tropas imperiales y a las de una coalición de ciudades del sur de la actual Alemania en la llamada Guerra de Suabia que duró desde diciembre de 1498 a septiembre de 1499. El tratado de Basilea de marca la independencia de hecho de los cantones suizos frente al imperio que renuncia a sus derechos. De todas formas es necesario esperar a la Paz de Westfalia (1648) para que esta independencia sea reconocida jurídicamente. Las ciudades de Basilea y de Schaffhausen, ya unidas, serán cantones en 1501, seguidas por Appenzell en 1513. Nace la confederación de XIII cantones y durará hasta 1798.

Por entonces la confederación fue puesta a prueba en las tormentosas guerras de Italia. Actuando tanto como aliada, tanto como enemiga de Francia, logra dominar una parte del Tesino antes de sufrir una dura derrota en la batalla de Marignano en 1515. Entonces firmaron la Paz perpetua con Francia que obtuvo derecho de reclutar librementemente mercenarios suizos contra el Tesino y una parte de la Valtelina. Este tratado marca el fin de la política de expansión de los Confederados, que no volvieron a participar en las guerras de Europa, salvo como mercenarios.
En el siglo XVI llega a Zúrich la Reforma protestante como consecuencia de la predicación e influencia de Ulrico Zuinglio. Pronto se extenderá por una gran parte de la Confederación que quedará dividida durante las cuatro guerras religiosas: la primera (cuyo episodio de la sopa de leche se hará célebre) y la segunda guerras de Kappel que acaban, en 1531, con la derrota de los protestantes y la muerte de Zuinglio, son seguidas por las dos guerras de Villmergen en 1656 y 1712. La dieta federal se encuentra dividida entre siete cantones católicos, dos mixtos y cuatro reformados, menos numerosos pero más poblados. Esta división va aun a acentuarse con la Contrarreforma dirigida especialmente por los jesuitas uno de cuyos resultados fue la división en 1597 del cantón de Appenzell en dos semi-cantones: Appenzell Rodas Exteriores protestante y Appenzell Rodas Interiores. católico.

Contenida progresivamente por la Contrarreforma en la parte alemana del país, la Reforma se extiende entonces hacia el oeste, principalmente gracias al empeño del francés Guillermo Farel que predica y convierte la mayor parte del país de Vaud, de Neuchâtel y de Ginebra antes de llevarla a Lausana en un debate público contra los católicos (conocido por la historia bajo le nombre de «Disputa de Lausana») con la ayuda de Juan Calvino y Pierre Viret. En 1533, el obispo de Ginebra huye y la ciudad se convierte en una república libre y más tarde, en 1541, en una teocracia bajo la influencia radical de Calvino que trasforma la ciudad en la Roma Protestante.

Entre tanto, el Ducado de Saboya fracasa en 1536 al intentar recuperar sus viejos dominios: es expulsado del país de Vaud por los Berneses, los friburgueses y los Valesianos. De todas formas, en esta ocasión conquista algunos territorios, tales como el Chablais (actualmente francés) en la orilla sur del Lago Leman fijando así en consecuencia las fronteras del país.

Durante la Guerra de los Treinta Años, Suiza permanece neutral pero debe defenderse movilizando hombres en sus fronteras, creando así el concepto de «Neutralidad Armada», hasta que la independencia y la neutralidad de Suiza fueron reconocidas finalmente en la Paz de Westfalia que pone término al conflicto europeo en 1648.

El siglo XVII marca un periodo de prosperidad científica y económica con la evolución de la agricultura y la aportación de los hugonotes franceses. De este periodo data la concepción de nación suiza, desarrollado con la creación de cátedras de historia nacional en las Universidades del país que borra las diferencias confesionales, políticas, económicas y sociales para dar paso a una Suiza “Unida y pacífica”» mientras que la llegada de viajeros extranjeros señala los inicios del Turismo en Suiza. 

Sin embargo, durante este periodo se producen varias sublevaciones, como la Guerra campesina suiza de 1653 contra Berna y Lucerna, de países dominados, como la “Conjura Henzi” contra el patriciado de Berna en 1749, la “sublevación Livin” contra Uri en 1755 o la “Sublevación Chenaux” en 1781 contra Friburgo, o de “liberadores” como en la Leventina o, en el país de Vaud con el mayor Abraham Davel en 1755. Lo cierto es que estas sublevaciones puntuales no fueron otra cosa que estrategias para obtener o mantener derechos particulares, y no tenían, salvo la tentativa de Davel, carácter revolucionario.

La reacción en Suiza es profunda tras el anuncio de la masacre de guardias suizos en el asalto al palacio de las Tullerias el 10 de agosto de 1792. El mismo año, se envían tropas de Berna y de Zúrich a Ginebra, para impedir una invasión francesa de este territorio aliado. Sin embargo algunas semanas más tarde la ciudad del Leman cayó en manos de los revolucionarios. También en 1792 Francia invadió el obispado de Basilea que era independiente bajo el nombre de República rauraciense antes de ser sometida nuevamente por Francia bajo el nombre de departamento de Mont-terrible, que comprendía los actuales distritos del Jura de Porrentruy y Delemont, el 23 de marzo de 1793.

En 1795 Frédéric-Cesar de la Harpe, comienza un levantamiento del Vaud por razones lingüísticas, contra Berna, pero no consiguió muchos seguidores y debe huir y refugiarse en París. Desde su exilio exhortó al gobierno francés a enviar sus tropas a la Suiza Romance. Finalmente en 1798 tomando como pretexto la muerte de diez soldados destacados en Thierrens, las tropas francesas invadieron el país. Encontraron poca resistencia y los invasores fueron relativamente bien recibidos, excepto en Berna y en Suiza Central, donde Nidwalden libró en solitario un combate desesperado contra Francia. Las dos victorias francesas de Grauholz y de Fraubrunnen llevaron a la capitulación de Berna en el otoño de 1798. Después se produjo la efímera proclamación de unas cuarenta repúblicas en algunas semanas, finalmente París impone el nuevo régimen de la República Helvética.

El 24 de enero de 1798, se proclama la República Lemánica, separada y liberada de Berna. Pero la revolución no terminaría aquí, pues los territorios de Argovia, también en poder de Berna, se declararon independientes, al igual que el antiguo ducado de Toggenburgo, que ahora dejaba de ser parte de Schwyz para formar el cantón de Turgovia. Las secesiones también afectaron a los aliados de los confederados: el Bajo Valais se independizó del Alto Valais.

Napoleón, sabiendo que Suiza es el camino más corto entre el norte y el sur de Europa, así como entre Francia e Italia, decidió conquistar Suiza. Para justificar la invasión, Napoleón aprovechó la sublevación del pueblo del Lemán para entrar en Suiza, con la excusa de proteger a los habitantes de estos territorios; además dijo haber sido aconsejado por los mismos suizos (dos refugiados suizos en París convencieron a Napoleón de que liberase su patria, entre ellas el Lemán).

La invasión comenzó el 2 de marzo de 1798 con la caída de Friburgo y Soleura. Tres días más tarde, el gobierno bernés era sometido por primera vez. Los cantones se fueron sometiendo, algunos sin siquiera haber librado una batalla. Los confederados habían perdido sus grandes ejércitos.

El emperador francés obliga a los confederados a cambiar de régimen en 1799. Lo que se llamaba Confederación de los XIII, pasaba a ser la “República Helvética, una y sola”. Los cantones ya no eran cantones, ahora eran simples prefecturas, las Tres Ligas de los Grisones perdieron el territorio de la Valtelina, que fue anexada a la República Cisalpina. Los territorios del antiguo obispado de Basilea ahora se limitaban a la ciudad misma. Las ciudades de Mulhouse y Ginebra fueron anexionadas a Francia.

La «república helvética una e indivisible» según su nombre oficial, es un estado centralizado y unitario, gobernado por un directorio que nombra los gobernadores de los cantones convertidos en simples divisiones administrativos y cuyas fronteras fueron redibujadas de modo importante. Además del conflicto europeo, que se desarrollaba en parte sobre el suelo suizo, ilustrado por las batallas de Zúrich en 1799, los conflictos entre centralistas y federalistas eran incesantes hasta el verano de 1802, cuando las tropas francesas se retiraron del territorio y se desencadene la "Stecklikrieg" («Guerra de baston» en alemán), una revuelta federalista contra la República Helvética, cuyo gobierno se refugió en Lausanna.

El 30 de septiembre de 1802, Napoleón Bonaparte intervino y después de haber convocado en París a una delegación helvética formada por 63 representantes suizos y cuatro senadores franceses, impone el Acta de Mediación proclamada el 19 de febrero de 1803 que definió una nueva constitución para el país. Esta acta apaciguó las tensiones internas gracias, en particular, al restablecimiento de las fronteras tradicionales de la mayoría de los cantones, a excepción notable del cantón de Berna que se vio definitivamente amputado de los nuevos cantones de Vaud y de Argovia. Se crean también los cantones de San Galo, Turgovia, Tesino y de los Grisones, reuniendo bailías conocidas. A fin de garantizar el control de los puertos alpinos, Valais se separó de Suiza y llegó a ser independiente, pero será anexada por el primer Imperio francés en 1810, así como Ginebra que se convirtió en capital del departamento francés de Leman y Neuchatel se transformó en principado, ofrecido al mariscal Berthier, que nunca fue allí.

Los 19 cantones resultantes eran entidades independientes y disponía cada uno de su constitución y de su aduana. El poder central ejercido por la dieta federal era dirigido por el Landammann de Suiza, único caso histórico en el que el país fue dirigido por una sola persona. La Asamblea ejerce el control del ejército suizo así como del franco suizo que se convirtió en la única moneda del país. Sin embargo entre 1803 y 1813, Suiza es un protectorado francés, sin gran poder de decisión, que se encuentra realmente en París. Pero el país conocíó entonces un periodo de estabilidad y de paz aunque su industria resultó duramente afectada por los efectos del bloqueo continental y que el país debía proporcionar cuatro regímientos al "gran ejército" de Francia, con un total teórico de hombres.

El número de cantones y los nombres variaron. Ahora formaban parte de la confederación 18 cantones. Berna fue dividido en dos, Berna y Oberland (Thun). El Valais era anexionado a Francia como prefectura; Lemán (Vaud), Friburgo, Soleura, Lucerna, Basilea, Argovia, Baden (Argovia), Lugano (Tesino), Bellinzona (Tesino), Rhetia (Grisones), Zúrich, Schaffhausen, Linth (Glaris y San Galo), Säntis (San Galo y Appenzell), Waldstätten (Uri, Schwyz, Zug y Unterwalden) y Turgovia.

Por primera vez Suiza era declarada neutral.

En 1802 Bonaparte retira sus tropas de Suiza, lo que permite que un año más tarde, seis cantones cambien de nombre o se fusionen. El Lemán pasa a ser Vaud, Bellinzona y Lugano pasan a ser el Tesino, Rethia se denomina Grisones, Turgovia es reconocida como cantón, Linth se divide en Glaris y San Galo, Säntis se divide en Appenzell y otra parte se une a San Galo, Argovia y Baden se fusionan en Argovia, el Oberland desaparece reuniéndose con Berna, Waldsätten se divide en cuatro cantones: Uri, Schwyz, Unterwalden y Zug. El territorio del Valais desaparece, convirtiéndose en un departamento francés.

En 1813 los confederados se liberan por fin de Napoleón. En 1814 Ginebra vuelve a ser libre gracias a la ayuda de los austriacos.

A partir de 1813 ejércitos extranjeros atravesaron en repetidas ocasiones el país persiguiendo a los ejércitos franceses, abasteciéndose sobre el terreno, lo que produjo hambrunas a la población sin que el ejército ni la Dieta pudiera interponerse, excepto por una incursión de hombres durante algunos meses en el país de Gex, que fue la última salida de las tropas suizas al extranjero. Idos los franceses, varios cantones, en parte apoyados por las potencias europeas, se apresuraron a restaurar el antiguo régimen, mientras que la existencia de alguno de los nuevos cantones estuvo amenazada, en particular Argovia, que Berna quería recuperar.

En este contexto, el 7 de agosto de 1815, finalmente todos los cantones firmaron un nuevo pacto federal, estableciendo la Confederación suiza constituida por cantones independientes, unidos entre ellos por un solo tratado común y no por una red de alianzas heterogéneas. En el Congreso de Viena, las potencias europeas reconocieron la neutralidad perpetua de Suiza el 20 de mayo de 1815 y le atribuyeron tres cantones nuevos, el Valais, Ginebra, al cual Francia y el reino de Cerdeña cedieron algunas tierras a fin de asegurarle una continuidad territorial, y Neuchatel, que hasta entonces era un principado prusiano, formando así la Confederación de XXII cantones.

El tratado de París de 1815 atribuyó igualmente la parte de Jura perteneciente al obispado de Basilea y la región de Bienne al cantón de Berna, en compensación de la pérdida de Argovia y de los territorios del Vaud. Las ligas grisonas habían perdido definitivamente las bailias de Valtellina y Bormio en 1798, debido a la negativa de las Tres Ligas a acordar la igualdad a sus antiguos súbditos. La frontera de Suiza no sufrirá más cambios importantes.

Tras la Revolución de Julio de 1830 en Francia y por las ideas igualitarias propagadas por ella, la mitad de los cantones democratizaron gradualmente su constitución mediante la generalización del derecho al voto. En 1832, estalló un conflicto civil entre la ciudad de Basilea y su entorno rural forzando la intervención del ejército y provocando la separación del cantón en dos medios cantones el de Basilea-Ciudad y el de Basilea-Campiña. El mismo año, se rechaza una revisión del pacto federal que introduce más libertades individuales.

En los años siguientes, el Partido Radical-Demócrata crece en varias comunas urbanas y protestantes. Sus miembros, partidarios de un sistema más centralizado, llegaron gradualmente a ser mayoritarios en el parlamento, en el que aprobaron varios programas anti-católicos y anticonstitucionales y por ello se produjo el cierre de conventos de Argovia en 1841. En 1845 el cantón de Lucerna acoge a los jesuitas católicos en su territorio y les confía la educación superior, lo que escandalizó a los radicales que por unos pocos votos estuvieron a punto de provocar la expulsión de los jesuitas. Sintiéndose amenazados, los siete cantones católicos de Lucerna, Uri, Schwyz, Unterwalden, Valais, Vaud y Zug en 1845 concluyeron una alianza secreta, el "Sonderbund" (literalmente «alianza especial» en alemán) que sale a la luz cuando tratan de aliarse con Austria, actuando en contra de la Constitución. En 1847, el Parlamento ordenó la disolución de la Sonderbund y ante la negativa de los siete cantones, estalló la guerra civil.

El conflicto, en el que el general Guillaume-Henri Dufour mandaba las tropas de la Confederación, es breve y poco sangriento, y acabó con la derrota de los cantones católicos, seguida por el establecimiento y la adopción de una nueva constitución en 1848, que no volverá a ser revisada profundamente hasta 1874.

La nueva constitución federal, aprobada el 12 de septiembre de 1848 por una mayoría de quince cantones y medio contra seis y medio define un nuevo estado, federal y centralizado que, sin embargo, sigue llevando el nombre de «confederación» en el que los cantones ya no son independientes, aunque «soberanos» que ceden parte de sus prerrogativas al gobierno federal. La constitución también define las nuevas instituciones políticas: el Consejo Federal y la Asamblea Federal bicameral con sede en Berna, donde se asienta la nueva capital y se construye el Palacio Federal. Se establecieron la unión aduanera y monetaria, eliminando aduanas, fronteras y monedas cantonales y regionales.

La ley federal sobre la moneda del 7 de mayo 1850, establece el franco suizo, que circula desde 1852 y un sistema monetario similar al de Francia, que permite a Suiza ser parte de la Unión Monetaria Latina que fue creada en 1865 hasta su disolución en 1926. En 1854, se funda la Escuela politécnica federal de Zúrich, mientras que los ferrocarriles privados comienzan a recorrer la meseta suiza.

Sin embargo, las divisiones entre los cantones centrales y católicos y los protestantes de la meseta central son aun vivas. La deuda de guerra que debieron pagar los perdedores de la guerra de Sonderbund hasta 1852, el sistema mayoritario impuesto para las elecciones federales, eliminando prácticamente la oposición conservadora y la separación constitucional entre Iglesia y el Estado son algunos motivos de tensión que mejoran, sobre todo cuando los católicos conservadores consiguen un asiento en el Consejo Federal en 1891.

En cuanto a la política exterior, el período está marcado por el caso de Neuchatel entre 1856 y 1857 seguido por el caso de Saboya en 1860, cuando el Consejo Federal está considerando la ocupación de los territorios franceses de Chablais y Faucigny. En 1868, con la firma de la Convención de Mannheim, Suiza obtiene su única salida al mar: el cauce del Rin fue declarado como aguas internacionales entre el último puente y puerto de la ciudad de Basilea hasta su desembocadura.

Durante la guerra franco-prusiana de 1870, Suiza movilizó su ejército, mandado por el General Hans Herzog, pero limitándose, como neutral, a acoger refugiados, tales como los hombres del ejército francés del Este, mandados por el general Charles Denis Bourbaki que serán los primeros beneficiados de la ayuda del Movimiento internacional de la Cruz Roja recientemente creada por Henri Dunant.

En política interna, se concede gradualmente a los ciudadanos el derecho de referéndum facultativo y el de Iniciativa popular Federal. En 1868, el sistema mayoritario fue abandonado en favor del sistema proporcional, que se considera más representativo. En el mismo sentido, la revisión de la constitución de 1874 todavía otorga nuevos poderes al gobierno federal y se fija permanentemente el Tribunal Supremo Federal en Lausana. La escuela primaria se hace obligatoria, así como mantener un registro civil. Esta revision constitucional se lleva a cabo durante el" Kulturkampf" alemán cuyos efectos se hacen sentir también en Suiza en algunos artículos de la Constitución, llamada artículos de excepción, que restringen la libertad de religión y de expresión, especialmente en relación al catolicismo, y que llevan a la ruptura de relaciones diplomáticas entre Suiza y la Santa Sede en 1874.

La centralización del poder continúa, en 1891, el monopolio en la emisión de billetes de banco dado a la Confederación da como resultado, en 1907, la creación de Banco Nacional de Suiza, encargado de esta tarea y de la política monetaria. En 1898, el derecho penal y derecho civil en su totalidad llega a ser prerrogativa del estado federal, dando lugar a la creación de un Código Civil y un Código Penal seguido por el Código Federal de Obligaciones. También durante este período, el campo del progreso social, se implantó (1877) la limitación de la jornada laboral a once horas y seis días a la semana y luego en 1890, la Confederación debe crear un seguro en caso de accidente o enfermedad que puede hacer obligatorio para todos los habitantes, o para una o más categorías determinadas.

Cuando estalla la Primera Guerra Mundial, la población se divide. La Suiza alemana se inclina hacia las Potencias Centrales, mientras que la Suiza romance simpatiza con los Aliados. El Consejo Federal recibe plenos poderes y la Asamblea Federal designa como General del ejército Suizo a Ulrich Wille, decisión que está lejos de ser unánime, ya que se le considera demasiado cercano a Alemania. Las tropas suizas, relativamente bien preparadas y abastecidas, no sufren demasiado la guerra, pero la población suiza lo sufre hasta tal punto que en 1915, el Consejo Federal otorga al monopolio la distribución de cereales a la Confederación en un intento de luchar contra el mercado negro.

El Tratado de Versalles que marca el final de la guerra reconoció la neutralidad perpetua de Suiza, a cambio de renunciar al derecho, puramente teórico, a ocupar Saboya del norte en caso de conflicto, derecho que había obtenido en 1815. En Tirol se organizó un plebiscito acerca de su incorporación a la Confederación: el pueblo lo acepta, pero los aliados finalmente incorporan la región a la nueva República de Austria.

Las dificultades sociales provocadas por la guerra llevan a la Huelga General de 1918 convocada por el comité de Olten tras el armisticio y que dura tres días. La huelga, aunque abortada ante la amenaza de intervención militar, permite sin embargo al Partido Socialista de Suiza tener éxito en ciertas reivindicaciones tales como la elección por escrutinio proporcional del Consejo Nacional en 1919 o la limitación de la semana laboral a 48 horas en 1920.

El escrutinio proporcional es el final de la mayoría radical, que pierde en 1919 45 de los 105 escaños que tenía en el Parlamento. El Consejo Federal también queda remodelado con la adjudicación de un segundo escaño al Partido Demócrata Cristiano y en 1929, un escaño al Partido de los Campesinos, artesanos y burgueses (futura Unión Democrática del Centro). El Partido Socialista suizo aún se mantiene apartado del ejecutivo por la coalición en el poder.

La política exterior se basa en la neutralidad armada: Suiza se une en 1920 a la Sociedad de Naciones (SDN), con sede en Ginebra, después de votarlo el 16 de mayo de 1920, obteniendo una fuerte mayoría en los cantones francófonos (93,2% en el cantón de Vaud). La salida de la organización de Alemania y Italia en la segunda mitad de los años 30 complica la política suiza que decide en nombre de la neutralidad no aplicar las sanciones económicas decididas por la Sociedad de Naciones contra Italia.

La política interior de entreguerras se polariza en dos frentes opuestos, la izquierda y la derecha, y cada parte hace uso del arma del referéndum para bloquear las acciones que no le satisfacen, lo que obliga al gobierno federal a utilizar la Ley Federal Urgente que no puede ser refutada por referéndum. Económicamente, Suiza se ve sacudida por una primera crisis en 1921 y 1922 y posteriormente con varios años de retraso debido a la existencia de grandes proyectos, se ve inmersa en la crisis mundial del 29. El franco suizo llega a devaluarse un 30% en 1936.

Los inicios de 1930 se caracterizan por el surgimiento de "frentes" de los movimientos fascistas de los que, sin embargo, se alejan rápidamente los partidos burgueses. Los enfrentamientos entre la extrema izquierda y la extrema derecha culminaron en 1932 en el tiroteo de Ginebra del 9 de noviembre, durante el cual el ejército disparó contra la multitud matando a 13 personas y dejando a 65 heridos. En la segunda mitad de los años de 1930 se produce un cambio de clima político con la afiliación de varios partidos nacionales con la idea común de "defensa espiritual", que culmina con la Exposición nacional suiza en 1939 en Zúrich, la “landi”.

En 1937, patronos y trabajadores firman la paz del trabajo, que privilegia la consulta y la negociación en los conflictos sociales. Durante este período, el Gobierno también prepara el país ante un conflicto militar: Europa se está armando rápidamente y el Consejo Federal desea evitar los problemas de abastecimiento de la Primera Guerra Mundial. Por eso, el estallido de la Segunda Guerra Mundial en 1939, no toma a Suiza por sorpresa: el suministro está asegurado, el ejército dirigido por el general Guisan ocupa las fronteras y se garantiza el racionamiento del sustento de la población.

Después de la derrota de los franceses en mayo de 1940, el país está completamente rodeado por las fuerzas del Eje. Un discurso ambiguo de la Consejera Federal Marcel Pilet-Golaz que sugiere la necesidad de tratar con la dictadura provoca protestas. El , en el informe Rütli, presentan la estrategia de "Reducto Nacional", que consiste en desproteger las fronteras y fortalecer las montañas del interior a fin de permitir una guerra de desgaste contra un posible invasor.

Presionada por ambos grupos de beligerantes, Suiza mantiene una posición ambigua, por ejemplo, abre sus fronteras a los judíos que huyen del régimen nazi, pero mantiene el comercio con los aliados del Eje. En la política interna, un socialista, Ernst Nobs fue elegido para el Consejo Federal por primera vez en 1943 y seguido por un segundo en 1959, es el establecimiento de la "fórmula mágica", que se mantiene sin cambios hasta 2003.

Después de la guerra, Suiza continúa expandiendo el estado socialista por la introducción del Seguro de la Vejez y Sobrevivientes en 1946 y luego mediante la aplicación del «sistema de los tres pilares» en 1972. El sufragio femenino en Suiza, que existía en algunos cantones, se generaliza en toda la federación en 1971 y luego se impuso a nivel cantonal en los otros cantones, principalmente en 1971 y 1972. El cantón de Appenzell Rodas Interiores tiene la obligación de 1990 por sentencia de un tribunal de respetar el principio de la igualdad entre mujeres y hombres como garantiza la Constitución Federal. Los problemas confesionales del siglo XIX se olvidan y los artículos de excepción son esencialmente abolidos en 1973.

El final del año 1960 está caracterizado por la secesión de Jura pidiendo la separación de los distritos de habla francesa de Berna y la formación de un 23º Cantón. Finalmente se lleva a cabo una votación en 1974: Los distritos católicos de habla francesa aceptan la creación de la nueva entidad, mientras que los distritos protestantes votan a favor de su permanencia en el cantón de Berna. Después de un refrendo federal en 1978 se crea el cantón de Jura. En 1991, el derecho al voto y la elegibilidad se redujo de 20 a 18 años para varones y mujeres.

Externamente, Suiza permanece fuera de las Naciones Unidas y la Organización del Tratado del Atlántico Norte y aboga por una estricta neutralidad armada. Aunque no se interesó en la Comunidad Europea del Carbón y del Acero (CECA) y, cuando se formó, en la Comunidad Económica Europea (CEE), se unió al Consejo de Europa en 1963 y a la Unión Europea de Libre Comercio (EFTA) en 1960, ambos diseñados como un contrapeso a la CEE incipiente.

Durante este tiempo, Suiza es el país más próspero del mundo a pesar de la crisis del petróleo de 1973, que ve la instauración de algunas zonas sin automóviles. Se desarrollaron productos químicos y textiles, así como los bancos. La tasa de desempleo se mantiene por debajo del 3% y Suiza continúa con una política exterior de neutralidad estricta al tiempo que ofrece sus «buenos oficios» para resolver disputas. Por eso la primera reunión entre Mijaíl Gorbachov y Ronald Reagan, se celebró en Ginebra en 1985. La sede europea de la ONU en la misma ciudad también permite a la institución acoger a personas, como Yasser Arafat, que no puede ir a Estados Unidos.

Sin embargo, la crisis económica de los años 1990 afecta al país: el desempleo llega a ser de más del 6%, muchas empresas se reestructuran, otras se declararon en quiebra, y algunas pasan a manos extranjeras. A pesar de esta reestructuración, la economía Helvética mantiene una industria poderosa y los sectores financieros y bancarios están más desarrollados. Al mismo tiempo, las relaciones exteriores se caracterizan por el desarrollo de la Unión Democrática de Centro, que busca la independencia y la neutralidad del país frente a los grandes grupos supranacionales. El fracaso del referendum sobre la entrada en el Espacio Económico Europeo (EEE), el 6 de diciembre de 1992 marca una detención en el proceso de integración en la Unión Europea considerado por algunos como peligroso para la democracia directa y para ciertos aspectos de la economía suiza, como el secreto bancario.

A cambio se potencia la vía bilateral de Acuerdos entre Suiza y la Unión Europea como el establecimiento de la libre circulación de personas con 25 países europeos, una mayor integración económica y la integración en el cielo único europeo.

Muchos politólogos creen que a esta causa se debe la victoria del UDC o SVP en las elecciones de 2003, en las cuales este partido obtuvo el derecho de tener otro ministro en el Consejo Federal, acabando con más de 50 años de la llamada Fórmula mágica.

En 2002 el pueblo suizo aprueba la entrada de Suiza en la Organización de Naciones Unidas. En 2005 el pueblo suizo firma los acuerdos de Schengen.






</doc>
<doc id="41031" url="https://es.wikipedia.org/wiki?curid=41031" title="San Millán de la Cogolla">
San Millán de la Cogolla

San Millán de la Cogolla es un municipio de la comunidad autónoma de La Rioja en España. Está ubicado al pie de la Sierra de la Demanda (Sistema Ibérico) en la vertiente oriental que separa la Meseta del Valle del Ebro, a 728 m de altitud sobre el nivel del mar y a orillas del río Cárdenas. 

En una bula de 1199 por la que se concedían privilegios al monasterio de San Millán de la Cogolla aparece nombrado como "Coculla", que procede de "cuculla", cerrillo, cima de monte. Es típico de lugares altos y con carácter defensivo, debiendo corresponder a la época de la Reconquista.

El municipio tomó su nombre del santo Millán (evolución al Idioma español del nombre en latín "Æmilianus" o Emiliano), anacoreta que fue alumno de San Felices y vivió del 473 al 574, y creador de la comunidad mixta de eremitas de Suso, que luego daría lugar a uno de los focos culturales más importantes de la época medieval en el sur de Europa.

Por esas fechas existía en el lugar una iglesia llamada de San Jorge, que sería iglesia parroquial del pueblo hasta 1542, en la que se encontraba la sepultura de Santa Potamia, discípula de San Millán. Esta ermita, del siglo XII, se conserva en la actualidad a la entrada del pueblo, junto al Río Cárdenas, y está considerada una de las iglesias consagradas más antiguas de La Rioja.

La localidad está compuesta por cuatro barrios:

Entre los siglos XVI y XVII, se levantó el Monasterio de San Millán de Yuso (o de abajo), de grandes proporciones denominado desde los años 1960 el Escorial de La Rioja. Este monasterio fue uno de los más influyentes en la época medieval en la península ibérica y fue el centro religioso de muchas zonas de La Rioja, Burgos, Soria, Palencia y Álava.

En 1997 los monasterios de San Millán de la Cogolla, Suso y Yuso fueron catalogados por la UNESCO como Patrimonio de la Humanidad.

A 1 de enero de 2010 la población del municipio ascendía a 278 habitantes, 183 hombres y 95 mujeres.

Tradicionalmente la agricultura (cereal, patata, remolacha), ganadería (vacuno y ovino) y explotación maderera (haya, roble y pino) han sido los principales sectores productivos de la localidad, aunque ahora el impulso turístico generado por los monasterios ha contribuido a implantar el turismo como uno de los pilares económicos principales de la zona, y se ha creado un complejo hostelero importante, con hoteles, restaurantes y actividades lúdicas relacionadas.

Otra actividad importante, al estar ubicado en la Sierra de la Demanda, junto a la Reserva nacional, es la caza mayor (ciervo, jabalí y corzo), puestos de paloma torcaz y coto de caza menor con codorniz y perdiz como principales atractivos.

Dentro del recinto urbano está el Monasterio de San Millán, formado, a su vez, por el primitivo Monasterio de San Millán de Suso («de arriba») y el Monasterio de San Millán de Yuso («de abajo»). El Escritorio de San Millán es uno de los más antiguos de Europa, y fue un centro de cultura muy importante, muestra de ello es la magnífica colección de códices que se conservan. Entre los más importantes están el Códice 60, donde se encuentran las Glosas Emilianenses, algunas de las primeras palabras en euskera y en castellano por medio de anotaciones latinas y en lengua romance por lo que San Millán es conocida como la Cuna de la Lengua. Gonzalo de Berceo, primer poeta castellano de nombre conocido, sirvió al monasterio como notario. La biblioteca y el archivo están considerados como uno de los mejores conjuntos monásticos. Las razones históricas, literarias, artísticas, así como el conjunto monumental, hicieron posible su declaración como Patrimonio de la Humanidad en diciembre de 1997. En la actualidad el Monasterio de San Millán de Yuso está habitado por frailes de la Orden de Agustinos Recoletos.

Tanto el monasterio de Yuso como el de Suso fueron declarados Bien de Interés Cultural en la categoría de Monumento el 3 de junio de 1931.

Este monasterio ardió en llamas tras la expedición de Almanzor en la primavera de 1002 perteneciente a las campañas de Almanzor en la etapa final del Califato de Córdoba.





</doc>
<doc id="41032" url="https://es.wikipedia.org/wiki?curid=41032" title="Cuerpo negro">
Cuerpo negro

Un cuerpo negro es un objeto teórico que absorbe toda la luz y toda la energía radiante que incide sobre él, constituyendo un sistema físico idealizado para el estudio de la emisión de radiación electromagnética. Nada de la radiación incidente se refleja o pasa a través del cuerpo negro. Lo que diferencia un cuerpo negro de la materia oscura es que el cuerpo negro absorbe y emite luz, mientras que la materia oscura no interacciona con la radiación electromagnética. El nombre "cuerpo negro" fue introducido por Gustav Kirchhoff en 1862. La luz emitida por un cuerpo negro se denomina radiación de cuerpo negro.

Todo cuerpo emite energía en forma de ondas electromagnéticas, siendo esta radiación, que se emite incluso en el vacío, tanto más intensa es más elevada la temperatura del emisor. La energía radiante emitida por un cuerpo a temperatura ambiente es escasa y corresponde a longitudes de onda más largas que las de la luz visible, (es decir, de menor frecuencia, como las de la luz infrarroja, o de frecuencia aun menor). Al elevar la temperatura no solo aumenta la energía emitida sino que lo hace a longitudes de onda más cortas; a esto se debe el cambio de color de un cuerpo cuando se calienta. Los cuerpos no emiten con igual intensidad a todas las frecuencias o longitudes de onda, sino que siguen la ley de Planck.

A igualdad de temperatura, la energía emitida depende también de la naturaleza de la superficie; así, una superficie mate o negra tiene un poder emisor mayor que una superficie brillante. Así, la energía emitida por un filamento de carbón incandescente es mayor que la de un filamento de platino a la misma temperatura. La ley de Kirchhoff establece que un cuerpo que es buen emisor de energía es también buen absorbente de dicha energía. Así, los cuerpos de color negro son buenos absorbentes.

Los principios físicos de la mecánica clásica y la mecánica cuántica conducen a predicciones mutuamente excluyentes sobre los cuerpos negros o sistemas físicos que se les aproximan. Las evidencias de que el modelo clásico hacía predicciones de la emisión a pequeñas longitudes de onda en abierta contradicción con lo observado llevaron a Planck a desarrollar un modelo heurístico que fue el germen de la mecánica cuántica. La contradicción entre las predicciones clásicas y los resultados empíricos a bajas longitudes de onda, se conoce como catástrofe ultravioleta.

donde formula_1 es la cantidad de energía por unidad de área, unidad de tiempo y unidad de ángulo sólido; formula_2 es una constante que se conoce como constante de Planck; formula_3 es la velocidad de la luz; y formula_4 es la constante de Boltzmann. 

Se llama poder emisivo de un cuerpo formula_5 a la cantidad de energía radiante emitida por la unidad de superficie y tiempo:
La longitud de onda en la que se produce el máximo de emisión viene dada por la ley de Wien; por lo tanto, a medida que la temperatura aumenta, el brillo de un cuerpo va sumando longitudes de onda, cada vez más pequeñas, y pasa del rojo al blanco según va sumando las radiaciones desde el amarillo hasta el violeta. La potencia emitida por unidad de área viene dada por la ley de Stefan-Boltzmann.

Antes de Planck, la Ley de Rayleigh-Jeans modelizaba el comportamiento del cuerpo negro utilizando el modelo clásico. De esta forma, el modelo que define la radiación del cuerpo negro a una longitud de onda concreta:

donde "c" es la velocidad de la luz, "k" es la constante de Boltzmann y "T" es la temperatura absoluta. Esta ley predice una producción de energía infinita a longitudes de onda muy pequeñas. Esta situación que no se corrobora experimentalmente es conocida como la catástrofe ultravioleta.

El cuerpo negro es un objeto teórico o ideal, pero se puede aproximar de varias formas entre ellas una cavidad aislada y otros sistemas algo más complejos.

Es posible estudiar objetos en el laboratorio con comportamiento muy cercano al del cuerpo negro. Para ello se estudia la radiación proveniente de un agujero pequeño en una cámara aislada. La cámara "absorbe" muy poca energía del exterior, ya que esta solo puede incidir por el reducido agujero. Sin embargo, la cavidad irradia energía como un cuerpo negro. La luz emitida depende de la temperatura del interior de la cavidad, produciendo el espectro de emisión de un cuerpo negro. El sistema funciona de la siguiente manera: 

La luz que entra por el orificio incide sobre la pared más alejada, donde parte de ella es absorbida y otra reflejada en un ángulo aleatorio y vuelve a incidir sobre otra parte de la pared. En ella, parte de la luz vuelve a ser absorbida y otra parte reflejada, y en cada reflexión una parte de la luz es absorbida por las paredes de la cavidad. Después de muchas reflexiones, toda la energía incidente ha sido absorbida.

Según el "Libro Guinness de los Récords", la sustancia que menos refleja la luz (en otras palabras, la sustancia más negra) es una aleación de fósforo y níquel, con fórmula química NiP. Esta sustancia fue producida, en principio, por investigadores indios y estadounidenses en 1980, pero perfeccionada (fabricada más oscura) por Anritsu (Japón) en 1990. Esta sustancia refleja tan solo el 0,16 % de la luz visible; es decir, 25 veces menos que la pintura negra convencional.

En el año 2008 fue publicado en la revista científica Nanoletters un artículo con resultados experimentales acerca de un material creado con nanotubos de carbono que es el más absorbente creado por el hombre, con una reflectancia de 0,045 %, casi tres veces menos que la marca lograda por Anritsu.

Los objetos reales nunca se comportan como cuerpos negros ideales. En su lugar, la radiación emitida a una frecuencia dada es una fracción de la emisión ideal. La "emisividad" de un material especifica cuál es la fracción de radiación de cuerpo negro que es capaz de emitir el cuerpo real. La emisividad depende de la longitud de onda de la radiación, la temperatura de la superficie, acabado de la superficie (pulida, oxidada, limpia, sucia, nueva, intemperizada, etc.) y ángulo de emisión.

En algunos casos resulta conveniente suponer que existe un valor de emisividad constante para todas las longitudes de onda, siempre menor que 1 (que es la emisividad de un cuerpo negro). Esta aproximación se denomina "aproximación de cuerpo gris". La Ley de Kirchhoff indica que en equilibrio termodinámico, la emisividad es igual a la absortividad, de manera que este objeto, que no es capaz de absorber toda la radiación incidente, también emite menos energía que un cuerpo negro ideal.

En astronomía, la emisión de las estrellas se aproxima a la de un cuerpo negro. La temperatura asociada se conoce como Temperatura Efectiva, una propiedad fundamental para caracterizar la emisión estelar. 

La radiación cósmica de fondo de microondas proveniente del Big Bang se comporta casi como un cuerpo negro. Las pequeñas variaciones detectadas en esta emisión son llamadas anisotropias y son muy importantes para conocer las diferencias de masa que existía en el origen del universo.

La radiación de Hawking es la radiación de cuerpo negro emitida por agujeros negros.

La emisión de gas, polvo cósmico y discos protoplanetarios también se asocia con cuerpos negros, principalmente en la región infrarroja y milimétrica del espectro electromagnético. Son importantes herramientas para buscar sistemas planetarios.




</doc>
<doc id="41041" url="https://es.wikipedia.org/wiki?curid=41041" title="Geografía del Reino Unido">
Geografía del Reino Unido

El Reino Unido de Gran Bretaña e Irlanda del Norte (en inglés: "United Kingdom of Great Britain and Northern Ireland") es un Estado de Europa occidental que comprende las islas británicas y 1/6 de la isla de Irlanda. Limita al norte con el océano Atlántico y el mar del Norte y al sur con el canal de la Mancha, al otro lado del cual está Francia. Es el centro de la "Commonwealth". Se formó por la sucesiva unión al reino de Inglaterra de Gales (1536), Escocia (1603) e Irlanda del Norte (Ulster, 1922). Además de la isla de Gran Bretaña y la parte noreste de Irlanda, su territorio incluye otras islas del archipiélago británico: Wight, Man, Anglesey, Hébridas, Orcadas y Shetland) y las pequeñas islas Anglonormandas, frente a la península francesa de Cotentin.

El Reino Unido abarca Gran Bretaña (Inglaterra, Escocia y el país de Gales) e Irlanda del Norte. Otros territorios como las Islas del Canal, Man y las Colonias de la Corona también forman parte ""de facto"" del Estado británico.

Gran Bretaña se divide tradicionalmente en una zona montañosa al norte y al oeste, una zona de la tierra baja al sur y al este. Una frontera que funciona de la desembocadura del río Exe, en el suroeste, a la del Tees, en el noreste, es una expresión cruda de esta división. En general, el territorio está dominado por colinas rugosas y montañas bajas. En la parte septentrional se encuentran los montes de Ross, los Montes Grampianos, los Southern Uplands y los Montes Cheviot. En la parte occidental están los montes Peninos y los Montes Cámbricos o Cambrianos en Gales y Cornualles, que son una prolongación del plegamiento herciniano de Europa. Las Tierras Altas escocesas y las montañas del Ulster se parecen a los plegamientos caledonianos que pueden verse en la península escandinava, recubiertos por materiales más recientes de origen volcánico y glaciar. Todas estas cordilleras no son demasiado elevadas. Entre las distintas sierras aparecen a veces tierras estrechas más bajas, como las Lowlands (Escocia) o las Midlands de Inglaterra. 

La zona de llanuras o penillanura se concentra en el sureste de la isla de Gran Bretaña, siendo una continuación de la gran llanura del norte de Europa. Es una cuenca sedimentaria.

Los ríos son más bien cortos, pero su caudal es moderado y permite cierta navegación. Tienen cierta importancia económica. El más largo (354 km) y caudaloso del país es el río Severn, que nace en Gales y cruza Inglaterra para finalmente desembocar en el océano Atlántico a través de su estuario en el suroeste del país. Es también el río más caudaloso de Inglaterra. Su principal afluente es el Tern. 

El segundo en longitud es el Támesis, río que es el más largo de Inglaterra. Con 346 km, cruza Londres y desemboca en el mar del Norte. El Swale, inglés, afluente del río Ure, que se convierte a su vez en el río Ouse; donde el Ouse se junta con el Trent en Trent Falls (Faxfleet) y crea un gran estuario de mareas, el Humber. Desde aquí hasta el mar del Norte, forma parte de los límites entre el Yorkshire del Este en la orilla norte y North Lincolnshire y North East Lincolnshire en la orilla meridional. Aunque es un estuario desde el punto de vista de su formación, muchos mapas lo describen como río Humber. 

También destacan varios ríos escoceses que desembocan en el mar del Norte: el Tay (188 km), que es el más largo de Escocia (desemboca en el Fiordo de Tay); el Spey (desemboca en el Moray Firth); el Tweed y el Dee. El río más largo de Irlanda del Norte es el Bann (122 km) y el más largo de Gales es el Towy (en galés, "Tywi;" 103 km).

Como resultado de su historia industrial, el Reino Unido tiene un amplio sistema de canales, en su mayor parte construidos en los primeros años de la Revolución Industrial, antes del auge de la competición por los ferrocarriles. El Reino Unido también tiene numerosos embalses y pantanos para almacenar aguas para consumo doméstico y uso industrial. La generación de energía hidroeléctrica es bastante limitada, proporcionando menos del 2 % de la electricidad británica, principalmente de las Tierras Altas Escocesas.

Los lagos abundan en Escocia, donde se llaman "lochs", habiendo otra famosa región, el distrito de los Lagos, en el noreste de Inglaterra. Los lagos más grandes del Reino Unido, según sus países, son:

El lago más profundo del Reino Unido es el Loch Morar, con una profundidad máxima de 309 metros. El Loch Ness es el segundo, con 228 metros de profundidad. El más profundo de Inglaterra es el Wast Water, que desciende hasta los 79 metros.

El Reino Unido tiene un litoral que mide alrededor de 12 429 km. Las fuertes hendiduras de la costa ayudan a asegurar que ninguna localización esté a más de 125 km de aguas de marea. Las costas son especialmente recortadas en Escocia, donde abundan los brazos de mar largos y profundos, los "firths" y los "lochs", fiordos semejantes a los escandinavos: Sleat, Lorn, Clyde, Solway Firth, bahía de Morecambe, Cardigan, Canal de Bristol, Dornach, Moray Firth, Firth of Forth y The Wash. Otras ensenadas de la costa británica son: la Bahía de Carbis, la Bahía de Lyme, el estuario del Támesis, el estuario del Humber y Firth of Tay. La geología del Reino Unido comprende muchos cabos a lo largo de su costa, entre los que destacan:

El Reino Unido reclama la jurisdicción sobre la plataforma continental, tal como se define en órdenes de plataforma continental o de acuerdo con límites sobre los que hay acuerdos, una zona de pesca exclusiva de 200 millas náuticas y un mar territorial de 12 millas náuticas.

En conjunto, se calcula que el Reino Unido incluye cerca de 1098 pequeñas islas, algunas naturales y otras hechas por el hombre, los "crannógs", hechas en la Antigüedad con piedra y madera, a las que fueron añadiéndose detritos naturales con el tiempo. En Escocia, especialmente hay una gran cantidad de islas a lo largo de sus costas septentrional y occidental, formando los archipiélagos de las Hébridas, las Orcadas y las Shetland. 


Entre la isla de Gran Bretaña e Irlanda se encuentran el canal del Norte y el canal de San Jorge que dan acceso al mar de Irlanda. Más acantilada y recortada es la costa occidental que la oriental.

Pertenece al clima marítimo oceánico y templado. El clima británico es muy variable y puede pasar muy rápido de un día frío y lluvioso a un día soleado en solo unas horas. También varía bastante según la altura y las regiones. Los contrastes se deben sobre todo por los vientos oceánicos, que suavizan las temperaturas. Los vientos del sudoeste prevalecen sobre la corriente del Atlántico Norte, por lo que el rigor del clima se modera. Está influido por la corriente del Golfo ("The Gulf Stream"). 

El clima es en términos generales templado. Los inviernos son significativamente menos fríos que en otros lugares de una latitud similar, como Polonia, debido a esa influencia de la corriente del Golfo. A la inversa, el verano británico destaca por su carácter inestable y fresco, en comparación con Europa continental. En general el sur es más cálido que el norte. La temperatura más alta registrada en el Reino Unido fueron los 38,5 °C de Brogdale, cerca de Faversham, en el condado de Kent, el 10 de agosto de 2003. La más baja fueron -27,2 °C registrados en Braemar en los montes Grampianos, Escocia, el 11 de febrero de 1895 y 10 de enero de 1982 y Altnaharra, también en Escocia, el 30 de diciembre de 1995.

Más de la mitad de los días está nublado. La nubosidad es extrema y la pluviosidad abundante. La pluviosidad anual media varía de 3000 mm en las Tierras Altas escocesas hasta 553 mm en Cambridge. En general el sur es más seco que el norte. Escocia es el país más húmedo todos los meses del año, excepto en mayo, junio y diciembre, en los que llueve más en Gales. El mes más lluvioso es enero, con 170,5 mm de media. Escocia es también el país más nublado a lo largo de todo el año, aparte de en junio y julio, cuando hay más nubes en Irlanda del Norte. El condado de Essex es uno de los más secos del Reino Unido, con una lluvia anual media de alrededor de 600 mm, aunque es típico que llueva más de 100 días al año. En algunos años la lluvia en Essex puede estar por debajo de 450 mm, menos que la lluvia media anual en Jerusalén y Beirut. Son frecuentes las nieblas en las ciudades. Pueden producirse fuertes vientos e inundaciones, especialmente en el invierno.
La gran humedad de las islas favorece el crecimiento de vegetación atlántica. Hay bosques de robles y hayas hasta los 500 metros de altitud. Conforme a la normativa de la Unión Europea, el territorio de este país pertenece a la región biogeográfica atlántica. Destacan en su patrimonio natural un bien mixto, patrimonio de la Humanidad declarados por la Unesco: San Kilda, y cuatro bienes naturales: Calzada y Costa del Gigante, Isla de Henderson, Islas Gough e Inaccesible y el Litoral de Dorset y del este de Devon. Cuenta con una decena de reservas de la biosfera, entre ellas Beinn Eighe. 1,274.323 hectáreas están protegidas como humedales de importancia internacional al amparo del Convenio de Ramsar, en total, 168 sitios Ramsar.

El Reino Unido cuenta con 11.595 áreas protegidas que cubren 69.946 km² o el 28.52 % de su superficie. 

En cuanto a los temas medioambientales, ha de señalarse que las emisiones de dióxido de sulfuro de las centrales eléctricas contribuyen a la contaminación atmosférica. Algunos ríos están contaminados por residuos agrícolas. Las aguas costeras se encuentran contaminadas debido al vertido de un gran volumen de aguas residuales en el mar.

La población del Reino Unido se calcula en 61.113.205 habitantes (julio de 2009), lo que da una densidad de 250,86 habitantes por kilómetro cuadrado. La población se concentra en un 90 % en las ciudades, lo que le convierte en el país más urbanizado del mundo.

En cuanto a los grupos étnicos, son mayoritariamente blancos (de los que son ingleses el 83,6 %, escoceses 8,6 %, galeses 4,9 %, norirlandeses 2,9 %) 92.1 %, negros 2 %, hindúes 1,8 %, pakistaníes 1,3 %, mestizos 1,2 %, otros 1,6 % (censo de 2001). Los británicos derivan de una mezcla que se produjo a lo largo de la historia por invasiones de celtas (cimbrios, galos), germanos occidentales (anglos, sajones) y escandinavos. Durante varios siglos los ingleses emigraron a las colonias de su Imperio, y esta pérdida de población se ha ido compensando con la llegada a la metrópoli de personas provenientes de estos países, en particular del sudeste asiático, de ahí las minorías pakistaníes e hindúes en el país.

La lengua oficial es el inglés, aunque se habla galés por el 26 % de la población de Gales y el gaélico escocés lo hablan alrededor de 60.000 escoceses.

El 71,6 % de la población es cristiana, principalmente anglicana, aunque también hay católicos, presbiterianos y metodistas. Hay un 2,7 % de musulmanes, un 1 % que profesa el hinduismo y, siempre según el censo de 2001, un 1,6 % de otras creencias y 23,1 % de creencias sin especificar o ninguna.

La capital, Londres tiene un área metropolitana que tiene 12.875.000 habitantes, con una densidad de 1.130 habitantes por kilómetro cuadrado, la segunda área metropolitana de Europa después de Moscú. Pero hay toda una serie de ciudades importantes: Birmingham, Glasgow, Liverpool, Leeds, Sheffield, Edimburgo (capital de Escocia), Bristol, Mánchester, Leicester, Coventry, Kingston Upon Hull, Cardiff (capital de Gales, 292.150 hab.) y Belfast (capital de Irlanda del Norte, 276.459 hab.). 

Tradicionalmente, el Reino Unido se dividía en ciento dos condados, de los que 46 son de Inglaterra, 33 de Escocia, 13 del país de Gales y 8 de Irlanda del Norte. 

Anglesey (cap. Llangefni), Breconshire (Brecknock), Caernarvonshire (Caernarvon), Cardiganshire (Aberystwyth), Carmarthenshire (Carmarthen), Denbighshire (Ruthin), Flintshire (Mold), Glamorgan (Cardiff), Merionethshire (Dolgellau), Monmouthshire (Newport), Montgomeryshire (Welshpool), Pembrokeshire (Haverfordwest), Radnorshire (Llandrindod Wells).
Aberdeen (cap. Aberdeen), Angus (Forfar), Argyll (Lochgilphead), Ayr (Ayr), Banff (Banff), Berwick (Duns), Bute (Rothesay), Caithness (Wick), Clackmannan (Alloa), Dumfries (Dumfries), Dunbarton (Dumbarton), East Lothian (Haddington), Fife (Cupar), Inverness (Inverness), Kincardine (Stonehaven), Kinross (Kinross), Kirkcudbright (Kirkcudbright), Lanark (Glasgow), Midlothian (Edimburgo), Moray (Elgin), Nairn (Nairn), Orkney (Kirkwall), Peebles (Peebles), Perth (Perth), Renfrew (Paisley), Ross and Cromarty (Dingwall), Roxburgh (Newtown St. Boswells), Selkirk (Selkirk), Shetland (Lerwick), Stirling (Stirling), Sutherland (Golspie), West Lothian (Linlithgow), Wigtown (Stranraer).

Antrim (cap. Belfast), Armagh (Armagh), Belfast (County Borough), Down (Downpatrick), Fermanagh (Enniskillen), Londonderry (Londonderry), Londonderry (-), Tyrone (Omagh).
Las divisiones administrativas son actualmente más complejas. En Inglaterra hay 34 condados "two-tier" (como, p.e. Bedfordshire), 32 "boroughs" de Londres (p.e., Barking y Dagenham) y una "City", la "City of London" o "Greater London", 36 condados metropolitanos (como Barnsley) y 46 autoridades unitarias, por ejemplo Blackpool.

Tradicionalmente, Irlanda del Norte estuvo dividida en seis condados históricos: Antrim, Armagh, Down, Fermanagh, Londonderry y Tyrone. Ya no se usan para el gobierno local; en lugar de ello hay 26 distritos de Irlanda del Norte ("district council areas") que tienen diferentes extensiones geográficas, incluso en el caso de aquellos cuyo nombre coincide con el de los condados. En Escocia hay 32 autoridades unitarias, como City of Edinburgh o Glasgow City. Y en Gales también hay 22 autoridades unitarias, como Cardiff o Isle of Anglesey.

Los recursos naturales del país son: carbón (hay yacimientos en Yorkshire, Derbyshire, Nottinghamshire, Northumberland, Gales meridional y Escocia) (Yorkshire, Durham, Escocia, Staffordshire y Gales), petróleo (plataforma continental del mar del Norte), gas natural (Escocia), estaño, piedra caliza, hierro, sal, arcilla, plomo. Las cuencas hulleras de las Midlands entraron en clara regresión a mediados de los años ochenta, cerrándose numerosas minas de carbón. No obstante, sus reservas de gas y petróleo están declinando y el Reino Unido pasó a ser importador neto de energía en el año 2005. En cuanto al uso del suelo, hay que señalar que el 48,89 % del terreno se dedica a pastos permanentes, mientras que el 10 % está formado por bosques y arbolado (estimación de 1993). El regadío ocupa una extensión de 1.080 kilómetros cuadrados (estimación de 1993).

El Reino Unido fue agrícola y ganadero, pero también el primer país que se industrializó, siendo el lugar donde se originó la Revolución Industrial debido a la energía del carbón, que dio auge a la industria textil y siderúrgica. Tras la Segunda Guerra Mundial, y a pesar de la pérdida del Imperio, se convirtió en líder en el comercio europeo y centro financiero. A partir de los años ochenta, el gobierno privatizó las empresas públicas y contuvo el gasto social. Es uno de los miembros del quinteto de economías del trillón de dólares de Europa occidental. 

Los mayores ingresos del Producto Interior Bruto son los proporcionados por el sector servicios, en particular la banca, el sector de los seguros y los negocios, aportando el 75 % del PIB (estimación de 2009) y empleando al 80,4 % de la población activa (estimación de 2006). La necesidad de importar materias primas y de exportar sus manufacturas han hecho de siempre del Reino Unido uno de los líderes del comercio mundial. En exportaciones ocupa el 9.º puesto (estimación de 2009: 351.300.000.000 dólares estadounidenses), sólo superado, en la Unión Europea, por Alemania (2.º), Francia (5.º), Países Bajos (6.º) e Italia (7.º). En cuanto a las importaciones, ocupa el 6.º lugar (473.600.000.000 dólares, estimación de 2009), solo superado, dentro de la Unión Europea, por Alemania (2.º) y Francia (4.º).

La agricultura es intensiva, está altamente mecanizada y es muy eficiente según los estándares europeos, produciendo alrededor del 60 % de las necesidades alimentarias con menos del 2 % de la población activa (1,4 %) y produce el 1,2 % del PIB. Los mayores rendimientos se obtienen en la llanura sureste. Se producen cereales (cebada, trigo, avena), colza oleaginosa, patatas y hortalizas. Los pastos y prados permanentes (estimados en los ochenta en torno al 47 % del territorio) permiten el pastoreo de ganado vacuno y ovejas; también hay aves de corral. Por último, tiene un importante sector pesquero, siendo los puertos más destacados Hull y Aberdeen.

La industria, que fue la base de la economía durante más de dos siglos, tiene cada vez menos importancia. Actualmente sólo contribuye al PIB en un 23,8 % y ocupa al 18,2 % de la población activa. Las industrias producen maquinaria, equipamiento eléctrico y electrónico, ferroviario, construcción naval, aviones, vehículos de motor y sus partes, equipamiento electrónico y de comunicaciones, metales, productos químicos, carbón, petróleo, papel y productos papeleros, alimentos procesados, tejidos, ropa y otros bienes de consumo.




</doc>
<doc id="41044" url="https://es.wikipedia.org/wiki?curid=41044" title="Juan Miguel Aguilera">
Juan Miguel Aguilera

Juan Miguel Aguilera (nacido en Valencia en 1960) es un escritor de ciencia ficción. Se formó como diseñador industrial, aunque destaca por su importancia dentro de la ciencia ficción española.

Sus primeras obras están escritas en colaboración con Javier Redal. Son historias enmarcadas en la ciencia ficción dura ("hard") y ambientadas en La Saga de Akasa-Puspa. La recreación de mundos y ambientes es muy consistente y detallista. "Mundos en el abismo" y sus continuaciones "Hijos de la eternidad" y "Mundos y demonios" combinan una trama típica de "space opera" con elementos de ciencia ficción "hard".

"El refugio" muestra una gran influencia científica en biotecnología, bioquímica, comunicación entre especies o en evolución.

También ha colaborado con el escritor Rafael Marín Trechera.

En su obras en solitario deja en un plano secundario los detalles más estrictamente científicos y mezcla elementos de fantasía, en un género que él mismo califica de "historia especulativa". También ha participado como guionista de la película Náufragos y en el cómic Avatar.

Como ilustrador ha elaborado numerosas portadas para libros de ciencia ficción.

Ha recibido los premios Ignotus, Alberto Magno, Imaginales de la ciencia ficción francesa, Bob Morane , y Juli Verne.

Entre 2000 y 2002 fue presidente de la Asociación Española de Fantasía, Ciencia Ficción y Terror.









</doc>
<doc id="41045" url="https://es.wikipedia.org/wiki?curid=41045" title="UAI">
UAI

El acrónimo UAI puede referirse a:



</doc>
<doc id="41052" url="https://es.wikipedia.org/wiki?curid=41052" title="Real Monasterio de San Juan de la Peña">
Real Monasterio de San Juan de la Peña

El Real Monasterio de San Juan de la Peña situado en Botaya, al suroeste de Jaca, Huesca, Aragón (España), fue el monasterio más importante de Aragón en la alta Edad Media. En su Panteón Real fueron enterrados un buen número de reyes de Aragón. Forma parte del camino aragonés del Camino de Santiago. Su enclave es extremadamente singular.

Cuenta la leyenda, que un joven noble de nombre Voto (en algunas versiones, Oto), vino de caza por estos parajes cuando avistó un ciervo. El cazador corrió tras la presa, pero esta era huidiza y al llegar al monte Pano, se despeñó por el precipicio. Milagrosamente su caballo se posó en tierra suavemente. Sano y salvo en el fondo del barranco, vio una pequeña cueva en la que descubrió una ermita dedicada a San Juan Bautista y, en el interior, halló el cadáver de un ermitaño llamado Juan de Atarés. Impresionado por el descubrimiento, fue a Zaragoza, vendió todos sus bienes junto a su hermano Félix se retiró a la cueva, e iniciaron una vida eremítica.

Este sería el inicio del Monasterio del que escribía don Miguel de Unamuno: 

Se habitan estas montañas poco después de la conquista musulmana, al construir el castillo de Pano, destruido en el año 734. El origen legendario del Reino de Aragón también encuentra en el monasterio cueva de San Juan de la Peña su propia historia, cuando reunidos los guerreros cristianos junto a Voto y Félix deciden por aclamación nombrar a Garcí Ximénez su caudillo que les conducirá a la batalla por reconquistar tierras de Jaca y Aínsa, lugar este donde se produjo el milagro de la cruz de fuego sobre la carrasca del Sobrarbe.

Reinando en Pamplona García Íñiguez y Galindo Aznarez I, conde de Aragón, comienzan a favorecer al Monasterio. El rey García Sánchez I concedió a los monjes derecho de jurisdicción, y sus sucesores hasta Sancho el Mayor, continuaron esta política de protección. Allí pasó sus primeros años San Íñigo. En el reinado de Sancho Ramírez de Aragón adquiere su mayor protagonismo llegando a ser panteón de los reyes de Aragón.

Fueron devastadores los incendios de 1494 y 1675. A raíz del último de ellos, se construyó el Monasterio Nuevo. El Monasterio Antiguo fue declarado Monumento Nacional el 13 de julio de 1889 y el Monasterio Moderno el 9 de agosto de 1923. La restauración fue dirigida por el arquitecto modernista aragonés Ricardo Magdalena.

Probablemente existiera algún tipo de cenobio anterior al siglo XI, pero la construcción de mayor importancia empieza el año 1026 por iniciativa de Sancho el Mayor. En el año 1071 el rey Sancho Ramírez cede el conjunto existente a los monjes cluniacenses y favorece su reforma. En este momento se levanta el conjunto que hoy queda, en mayor o menor medida. La reforma benedictina de Cluny no podía obviar la construcción de un claustro que se finalizará ya entrado el siglo XII.

A finales del siglo XI son un conjunto de capiteles de influencia jaquesa del claustro con temas de animales fantásticos y algunos motivos geométricos y vegetales donde destacan los roleos. Un segundo grupo, formado por veinte capiteles, fue encargado en el último tercio del siglo XII al llamado "maestro de San Juan de la Peña", autor anónimo, también conocido como Maestro de Agüero, probablemente para sustituir otro anterior. El pequeño recinto ofrecía un cerramiento diáfano en forma de arcadas separadas por columnas. Los arcos se veían rematados con cenefas con el típico taqueado jaqués.

El Maestro desarrolla un programa sobre escenas bíblicas donde aparecen entre otras el Anuncio a los pastores, la Natividad, la Anunciación, la Epifanía, el Bautismo y la Circuncisión de Jesús, la Última Cena, episodios sobre Caín y Abel, la Creación de Adán y Eva, así como su Reprobación y posterior condena al trabajo. Seguramente el maestro de Agüero solo elaboró los capiteles para dos alas del claustro ya que a finales del siglo XII el monasterio entró en franca decadencia. El programa iconográfico que plantean los 26 capiteles que conservamos parece enfocar la Salvación a través de la Fe escogiendo los episodios más significativos para ello.

Se trabaja con bajorrelieves casi todos dominados por un "horror vacui" muy acentuado que provoca contorsiones en algunas figuras que superan el propio marco sacando un brazo como en la escena de Jesús y los Apóstoles. Los gestos son exagerados, casi teatrales, acentuando los ojos y la boca, y confiriendo narratividad a las escenas. En cuanto a las formas, estas se someten a esquemas geométricos que dominan desde la configuración del rostro o los pliegues de los paños, hasta los movimientos de caballos o de la misma agua que se vierte de un jarro a otro.

En el piso superior se encuentra el Panteón real. En él, durante cinco siglos se enterraron algunos de los monarcas de Aragón y de Navarra. Su aspecto actual data del siglo XVIII.

En San Juan de la Peña, los reyes de Aragón fueron sepultados en tumbas de piedra colocadas en tres órdenes superpuestos, desde la roca hacia afuera, presentando a la vista solo los pies del féretro. El panteón real ocupa las dependencias de la antigua sacristía de la iglesia alta, que data del siglo XI; fue reformado por Carlos III en 1770, siguiendo las indicaciones de don José Nicolás de Azara y del conde de Aranda, quien quiso ser enterrado en el atrio. La reforma solo afectó a la decoración, quedando los sepulcros en el mismo lugar; se levantó delante de ellos una pared en la que se colocaron láminas de bronce con las inscripciones correspondientes, se distribuyó por la sala profusión de estucos y mármoles, colocando en la pared frontera unos medallones con relieves que representan escenas de legendarias batallas.

Alberga los restos de algunos monarcas navarros que reinaron en Aragón, de los primeros condes aragoneses y de los tres reyes iniciales de la dinastía ramirense, Ramiro I, Sancho Ramírez, Pedro I, junto con sus esposas.

En 1889 se le otorga el título de Monumento Nacional que en 1920 es completado con la declaración por parte del rey Alfonso XIII como Sitio Nacional. Ya el 2 de febrero de 2004, el Gobierno de Aragón completa su declaración como Bien de interés cultural con la protección del conjunto monástico y su entorno.

La mayor parte del fondo documental del Monasterio se trasladó al Archivo Histórico Nacional de Madrid, donde se encuentra en la sección de Clero. Atendiendo a los trabajos publicados, la documentación se divide en tres grandes grupos:

Según la leyenda española sobre el Santo Grial, este permaneció en el monasterio, después de pasar por diversas ubicaciones como la cueva de Yebra de Basa, monasterio de San Pedro de Siresa, iglesia de San Adrián de Sásabe, San Pedro de la Sede Real de Bailo, la Catedral de Jaca, desde 1071 hasta 1399.

La necesidad de atraer a los peregrinos a Santiago que pasaban por el cercano camino de Jaca al monasterio aconsejó que en él se ubicara la reliquia. En 1399 el rey Martín I se llevó el vaso sagrado al palacio de la Aljafería de Zaragoza, donde estuvo más de veinte años, después de una breve estancia en Barcelona, acompañando al rey y posteriormente se trasladó a la Catedral de Valencia.

El primer lugar en España donde se celebra con el rito Romano es en el Reino de Aragón en el monasterio de San Juan de la Peña, el 22 de marzo de 1071, durante la estancia del Santo Cáliz en el monasterio y a continuación se oficializa en el resto del reino, sustituyendo al rito mozárabe.



</doc>
<doc id="41056" url="https://es.wikipedia.org/wiki?curid=41056" title="Instituto Federal Electoral">
Instituto Federal Electoral

El Instituto Federal Electoral (IFE) fue el organismo responsable de cumplir con la función de organizar las elecciones federales de México, es decir, las relacionadas con la elección del Presidente de México, Diputados Federales y Senadores que integran el Congreso de la Unión. Fue la máxima autoridad administrativa en la materia electoral en los Estados Unidos Mexicanos en el periodo 1990-2014.

Técnicamente era un órgano constitucional pues, al igual que los poderes ejecutivo, legislativo y judicial, nace directamente de la Constitución Política de México (fracción V del artículo 41). Inició sus operaciones el 11 de octubre de 1990 y las finalizó el 4 de abril de 2014.

En agosto del 2007 los diputados acordaron remover a los consejeros del IFE (consejeros electorales) y ampliar las facultades de fiscalización, así como nuevas atribuciones en materia de radio y televisión, respecto a la propaganda electoral.

Tras la reforma político electoral impulsada por el Presidente de México, Enrique Peña Nieto, se acordó la disolución del IFE para dar paso a la nueva institución que se encargará de los asuntos electorales a nivel federal, creando así al nuevo Instituto Nacional Electoral (INE) que entró en funciones a partir del 4 de abril de 2014.

El Instituto Federal Electoral sustituyó a la Comisión Federal Electoral. Nació como resultado de los conflictos postelectorales del año 1988, que provocaron una serie de reformas a la Constitución Política aprobadas el 4 de abril de 1990, publicadas el 6 de abril de 1990, y de la expedición de una nueva legislación reglamentaria en materia electoral federal: el Código Federal de Instituciones y Procedimientos Electorales (COFIPE), el 15 de agosto de 1990. Este instituto inició sus actividades el 11 de octubre de 1990, con la primera sesión de su máximo órgano de dirección: El Consejo General, y su primer presidente fue Fernando Gutiérrez Barrios, quien fungía como titular de la Secretaría de Gobernación.

Desde la fecha de creación del Instituto Federal Electoral la normatividad constitucional y legal en la materia ha experimentado cuatro importantes procesos de reforma en 1993, 1994, 1996 y 2007, que han impactado de manera significativa la integración y atributos del organismo depositario de la autoridad electoral. 

En su primera integración en 1990 se constituyó como un órgano de Estado con una concurrencia de los poderes: Ejecutivo, en la figura del Secretario de Gobernación, y Legislativo, en la de los Consejeros del Poder Legislativo, en tanto que, al buscar una representación del Poder Judicial, se creó la figura del consejero magistrado, en número de seis, cuyos requisitos resultaron ser los mismos que los que permiten elegir al Ministro de la Suprema Corte de Justicia de la Nación, razón por la cual se les asignó por disposición constitucional una remuneración equivalente al de dichos Ministros.

Los Magistrados fundadores fueron los juristas siguientes: el licenciado Luis Tirado Ledesma, el licenciado Manuel Barquín Álvarez, el licenciado Luis Espinosa Gorozpe, el licenciado Germán Pérez Fernández del Castillo, la doctora Olga Hernández Espíndola y la licenciada Sonia Alcántara Magos, quienes fungieron como tales desde el 11 de octubre de 1990 hasta el 18 de mayo de 1994 y colaboraron ampliamente en el proceso de democratización de México.

En el decreto de creación del Cofipe, publicado el 15 de agosto de 1990, en su ártículo tercero transitorio se estableció: "Los archivos, bienes y recursos de la Comisión Federal Electoral y de sus órganos técnicos, el Registro Nacional de Electores y la Comisión de Radiodifusión, pasarán al Instituto Federal Electoral. El Registro Nacional de Electores se integrará a la Dirección Ejecutiva del Registro Federal de Electores prevista en los artículos 85 y 92 de este Código. En tanto se instala el Instituto Federal Electoral, el Registro Nacional de Electores seguirá realizando las funciones que le atribuye el Código Federal Electoral y cumplirá los acuerdos tomados por la Comisión Federal Electoral". Cabe destacar que en la reforma constitucional del artículo 36 publicado el 6 de abril de 1990 se establece entre las obligaciones de los ciudadanos de la República la de inscribirse en el Registro Nacional de Ciudadanos. Sin embargo en el mismo Decreto se establece en el segundo de sus Tránsitorios, que en tanto no se establezca el Servicio del Registro Nacional Ciudadano, los ciudadanos deberán inscribirse en los Padrones Electorales. De hecho en las iniciativas de diferentes partidos políticos de Código Federal de Instituciones y Procedimientos Electorales se denomina a una de las Direcciones Ejecutivas del IFE como la Dirección Ejecutiva del Registro Nacional Ciudadano, sin embargo, el consenso final en el Poder Legislativo fue denominarla como Dirección Ejecutiva del Registro Federal de Electores; ello fue debido a que líderes de la oposición exigían un padrón electoral nuevo para elecciones de 1991 y ello no era posible con la Cédula de Identidad Ciudadana que requería un tiempo importante de transición para que los registros civiles del país se homogeneizaran. Esta situación ha quedado en el mismo estado de cosas desde aquella época, con algunos intentos del Poder Ejecutivo de ejercer esa función y hacer convivir dos documentos de identificación, lo cual ha sido fuente de polémicas.

Desde su creación, una de sus características fundamentales ha sido la profesionalización de la función ejecutiva y técnica electoral, de manera que desde el artículo 41 de la Constitución del 6 de abril de 1990 se estableció que los órganos ejecutivos y técnicos dispondrán del personal calificado necesario para prestar el servicio profesional electoral, que se trata del único servicio civil de carrera reconocido constitucionalmente en México. Este elemento fundamental de la composición del Instituto Federal Electoral le dio un sentido de permanencia y especialización a la función electoral, de manera que a diferencia de los modelos de organización electoral previas al Instituto Federal Electoral, en donde los órganos electorales se integraban cada que había elecciones con personal improvisado y sin la adecuada experiencia, lo que podía implicar parcialidad en la función electoral, fue transformado en un servicio profesional electoral que fortalece la actuación imparcial, más allá inclusive de los cambios que se puedan dar en el máximo órgano de dirección.
En 1994 se llevó a cabo un proceso de ciudadanización de los Consejeros, que forman parte del máximo órgano de dirección, de manera que ya no fuera requisito ser abogado para ser Consejero, lo que tuvo como consecuencia el cambio de nombre del cargo de Consejero Magistrado por el de Consejero Ciudadano.
En 1996 se discutió si los Consejeros representaban a la ciudadanía y a cuál ciudadanía, puesto que los partidos políticos son representantes de diversos sectores de la ciudadanía, por lo que se llegó a la conclusión de que se buscaba la profesionalización de la función directiva electoral, de manera que se reemplazó la denominación de

El Instituto Federal Electoral nació en 1990 con la función constitucional de organizar las elecciones; sin embargo, la opinión pública mexicana lo ha considerado un árbitro de las elecciones, función que pudo desempeñar, de manera tácita, mientras el secretario de Gobernación fue su presidente, es decir, de 1990 a 1996. Al alcanzar su independencia plena respecto al Poder Ejecutivo y ser el Consejero Presidente un ciudadano elegido por las dos terceras partes de la Cámara de Diputados, no contaba con los instrumentos para el arbitraje electoral, y se limitaba a procedimientos administrativos sancionadores dirigidos a los partidos políticos pero que resultaron ineficaces ante los múltiples actores del proceso electoral. Por ello, a partir del 2007 se le han otorgado instrumentos para sancionar no solo a los partidos políticos sino también a los ciudadanos, militantes y candidatos de los partidos políticos, así como a concesionarios y permisionarios de los medios electrónicos de comunicación (radio y televisión).

El Instituto Federal Electoral nace en el 41 Constitucional publicado el 6 de abril de 1990 con la facultad de atender lo relativo a los derechos y prerrogativas de los partidos políticos.

En 1993, la recaudación de fondos ("pase de charola") del Partido Revolucionario Institucional generó discusión en el seno del Consejo General, en las sesiones del 12 de marzo y 8 de junio, determinándose de que no había facultades para revisar el asunto y reconociendo las diferentes fuerzas políticas que no había disposiciones legales en la materia.

El 27 de enero de 1994, el Presidente del Consejo General, Dr. Jorge Carpizo dio lectura a un acuerdo suscrito por 8 partidos políticos para contribuir al proceso de paz, luego del alzamiento armado del Ejército Zapatista de Liberación Nacional, el 1 de enero de 1994. En dicho Acuerdo se establecen entre otros, el siguiente punto: "5. Realizar, una vez concluido el proceso electoral en curso, una revisión del sistema de financiamiento para los partidos políticos a fin de incorporar, en su caso, las precisiones que se estimen conducentes".

El 22 de noviembre de 1996 se publican en el Diario Oficial de la Federación reformas al Código Federal de Instituciones y Procedimientos Electorales, en las cuales se establece en el Artículo 80 de ese entonces, entre otras, la Comisión de Fiscalización de los Recursos de los Partidos y Agrupaciones Políticas, a la cual se le establecen atribuciones en el Artículo 49 del mismo ordenamiento vigente en ese entonces para la revisión de los informes de los partidos políticos y agrupaciones políticas sobre el origen y destino de sus recursos anuales y de campaña. 

Inmediatamente el 29 de noviembre de 1996 se integró la comisión con la Presidencia del Mtro Alonso Lujambio y la integración de los Consejeros Electorales José Barragan Barragan, Jaime Cárdenas Gracia, Mauiricio Merino y Jacqueline Peschard. En todo que el secretario Técnico de la comisión sería el Director Ejecutivo de Prerrogativas y Partidos Políticos.

El 13 de noviembre de 2007 se publica en el Diario Oficial de la Federación reformas al 41 Constitucional en donde se estableció que "la fiscalización de las finanzas de los partidos políticos estará a cargo de un órgano técnico del Consejo general del Instituto Federal Electoral, dotado de autonomía de gestión, cuyo titular será designado por el voto de las dos terceras partes del propio Consejo a propuesta del Consejero Presidente".

El 14 de enero de 2008 fue publicado un nuevo Código Federal de Instituciones y Procedimientos Electorales en donde se define en el artículo 79 la Unidad de Fiscalización de los Recursos de los Partidos Políticos, y se le definen sus atribuciones en el artículo 81.

Tanto en 2006 como en 2012, acentuada en esta última elección, el rebase de topes de gastos de campaña han sido motivo de atención del Tribunal Electoral del Poder Judicial de la Federación en la calificación de la elección de Presidente Electo, pero en ambos casos la máxima autoridad judicial electoral ha determinado que de conformidad con la legislación, la revisión de los informes de gastos de campaña es un paso posterior a la calificación de la elección.

Aunque el INE es la máxima autoridad administrativa electoral, sus actos y resoluciones pueden ser impugnadas ante el Tribunal Electoral del Poder Judicial de la Federación (TEPJF), que es el encargado de resolver diferencias en los asuntos electorales del país tanto en elecciones locales como en federales. De igual forma, los delitos penales en materia electoral son procesados por la Fiscalía Especializada para la Atención de los Delitos Electorales. Ambas instancias son entidades que no forman parte del Instituto Federal Electoral.

El Instituto Federal Electoral tiene competencia en toda la federación, por lo que cuenta con órganos centrales ubicados en la capital federal; órganos locales, uno en cada entidad federativa y órganos distritales, uno en cada distrito electoral federal uninominal. 

En cada nivel cuenta con órganos de dirección (Consejos), órganos ejecutivos (Juntas) y los órganos de vigilancia (Comisiones), además en el nivel central cuenta con órganos técnicos.

Adicionalmente, forma parte del Instituto la Contraloría General.
Su máximo órgano de dirección es un Consejo General, constituido por nueve Consejeros Electorales con voz y voto, designados en mayoría calificada por la Cámara de Diputados, de los cuales uno es nombrado Consejero Presidente. Su renovación es escalonada cada 3 años y duran en su ejercicio 9 años, salvo el Consejero Presidente que es nombrado por 6 años pudiendo ser reelecto. También lo integran solo con voz pero sin voto, un representante por cada fracción parlamentaria y uno por cada partido político nacional con registro. Por último, el Secretario Ejecutivo es parte integrante del Consejo General, como su Secretario General. 

La Junta General Ejecutiva del Instituto de conformidad con el artículo 121 del Código Federal de Instituciones y Procedimientos Electorales será presidida por el Presidente del Consejo y se integrará por un Secretario Ejecutivo y con los Directores Ejecutivos del Registro Federal de Electores, de Prerrogativas y Partidos Políticos, de Organización Electoral, del Servicio Profesional Electoral, de Capacitación Electoral y Educación Cívica, y de Administración.

La Comisión Nacional de Vigilancia es el órgano de vigilancia conformado por el Director Ejecutivo del registro Federal de Electores que la preside, los representantes de los partidos políticos nacionales, un Secretario designado por el presidente de la Comisión de entre los miembros del servicio profesional electoral con funciones en el área registral y un representante del Instituto Nacional de Estadística, Geografía e Informática.

Los órganos técnicos son los siguientes:


En cada entidad federativa el Instituto cuenta con un consejo local y una junta local ejecutiva. Existen en el país 32 Consejos Distritales y 32 Juntas Distritales Ejecutivas, es decir, una Junta y Consejo por cada entidad federativa, incluida la Ciudad de México.

Los Consejos Locales son órganos temporales que solo funcionan durante el Proceso Electoral Federal y son presididos por el Consejero Presidente, que es a la vez, el Vocal Ejecutivo de la Junta Local, el Secretario es el Vocal Secretario, 6 Consejeros Electorales y un representante de los partidos políticos. Solamente el Consejero Presidente y los Consejeros Electorales participan con voz y con voto; concurren con voz pero sin voto el resto de los Vocales de la Junta Local correspondiente.

De conformidad con lo preceptuado por el artículo 135 del Código Federal de Instituciones y Procedimientos Electorales (Cofipe), las Juntas Locales Ejecutivas, se encuentran integradas de la siguiente manera:


Las Comisiones Locales de Vigilancia se integran por un Presidente, que es el Vocal del registro Federal de Electores correspondiente, un representante de cada partido político nacional y un Secretario designado por su Presidente, de entre los miembros del Servicio Profesional Electoral

En cada distrito electoral uninominal tiene un Consejo Distrital y una Junta Distrital Ejecutiva. Hay 300 Distritos Electorales Federales.

Los Consejos Distritales son órganos temporales que solo funcionan durante el Proceso Electoral Federal y son presididos por el Consejero Presidente, que es a la vez, el Vocal Ejecutivo de la Junta Distrital, el Secretario es el Vocal Secretario, 6 Consejeros Electorales y un representante de los partidos políticos. Solamente el Consejero Presidente y los Consejeros Electorales participan con voz y con voto; concurren con voz pero sin voto el resto de los Vocales de la Junta Distrital correspondiente.

De conformidad con lo preceptuado por el artículo 145 del Código Federal de Instituciones y Procedimientos Electorales (Cofipe), las Juntas Distritales Ejecutivas se encuentran integradas de la siguiente manera:


Las Comisiones Distritales de Vigilancia se integran por un Presidente, que es el Vocal del Registro Federal de Electores correspondiente, un representante de cada partido político nacional y un Secretario designado por su Presidente, de entre los miembros del Servicio Profesional Electoral.

El Instituto Federal Electoral tiene como atribuciones, en forma integral y directa, las actividades relativas a la capacitación electoral y la educación cívica, la geografía electoral, los derechos y prerrogativas de las agrupaciones y partidos políticos, al padrón electoral y la lista de electores, la impresión de materiales electorales, la preparación de la jornada electoral, los cómputos en los términos que señala la ley, la declaración de validez y la entrega de constancias de las elecciones de diputados y senadores, el cómputo de la elección del Presidente de los Estados Unidos Mexicanos en cada uno de los distritos electorales uninominales, así como la regulación de la observación electoral y de las encuestas o sondeos de opinión con fines electorales. Cuenta además de manera exclusiva con atribuciones en materia de propaganda electoral en la radio y televisión tanto en elecciones federales como en elecciones locales, a través de la administración de los tiempos del Estado.

El PREP, más conocido por sus siglas. Es un sistema que provee pero no cuenta votos, los resultados preliminares de las elecciones federales y mediante la captura desde las Juntas Distritales y publicación vía internet de los datos plasmados por los funcionarios de casilla en las actas de Escrutinio y cómputo de casillas que se recibe en Centros de Acopio y Transmisión de Datos(CEDAT) y que desde 1994 ha estado trabajando con tecnología basada en Términales de Captura Remota. Su precedente es el Sistema de información de Resultados Electorales (SIRE) que operó en 1991 con base en recopilación de actas de escrutinio y cómputo de cada una de las casillas desde las Juntas Distritales y enviadas a través de Fax a Oficinas Centrales del IFE donde se capturó.

Permite dar a conocer resultados electorales, en tiempo real a través de internet antes del conteo rápido. Este programa no es parte de una división del IFE sino más bien es un mecanismo o instrumento de información electoral contemplados en el COFIPE. Sus resultados electorales, tiene un carácter informativo pero no son definitivos.

El programa de resultados electorales preliminares, es dotado por la secretaría ejecutiva mediante la UNICOM dictado en el Artículo 125 inciso l del COFIPE y de acuerdo al consejo general para la creación de la unidad el 30 de junio de 1998.

Los representantes del Poder Legislativo en el IFE son:


Los representantes de los partidos políticos en el Consejo General del IFE son los siguientes:


Los ingresos de los Consejeros se encuentran definidas en el artículo 112, párrafo 3 del Código Federal de Instituciones y Procedimientos Electorales vigente que establece: "La retribución que reciban el Consejero Presidente y los Consejeros Electorales será similar a la que perciban los Ministros de la Suprema Corte de Justicia de la Nación", redacción que viene de la reforma electoral publicada en el Diario Oficial de la Federación el 31 de octubre de 1996 cuando se estableció en el artículo 76, párrafo 3 del entonces Código Federal de Instituciones y Procedimientos Electorales una redacción igual. 

La Cámara de Diputados aprueba conforme al artículo 75 de la Constitución Política de los Estados Unidos Mexicanos la remuneración de los Consejeros Electorales en el Presupuesto de Egresos de la Federación, donde para 2012 se definió para el Consejero Presidente en una Percepción Bruta Anual de 4,127,880 pesos mexicanos y a los Consejeros Electorales de 3,524,834 pesos mexicanos; las cuales son inferiores a la Percepción Bruta Anual del Presidente de la República que es de 4,207,644 pesos mexicanos conforme a las Bases del artículo 127 de la Constitución; mientras que la Percepción Bruta Anual del Ministro Presidente y los Ministros de la Suprema Corte de Justicia de la Nación y de los ministros que se apegan al Tercero Tránsitorio del Decreto del 24 de agosto de 2009 por la base de no retroactividad de la ley del 14 Constitucional es de 5,892,778 pesos mexicanos; los Ministros entrantes de la Suprema Corte de Justicia tienen una Percepción Bruta Anual de 3,999,413.

El Artículo 207, párrafo 3 del Código Federal de Instituciones y Procedimientos Electorales establece que "Los miembros del Servicio Profesional Electoral, con motivo de la carga laboral que representa el año electoral, al ser todos los días y horas hábiles, tendrán derecho a recibir una compensación derivada de las labores extraordinarias que realicen, de acuerdo con el presupuesto autorizado"

En el acuerdo político denominado “Pacto por México” se ha propuesto: “Crear una autoridad electoral de carácter nacional y una legislación única, que se encargue tanto de las elecciones federales, como de las estatales y municipales” (Punto 5. 4) 
A partir de esta base diversos actores políticos han sugerido crear el Instituto Nacional Electoral (INE), la propuesta sería presentada formalmente en el 
segundo periodo ordinario de sesiones de 2013 y se aplicaría por primera vez en las elecciones estatales que se celebren a partir de 2014. Esta reforma crearía un 
organismo electoral dotado de autonomía constitucional y facultado para organizar los comicios federales y locales, así como las tareas que en materia de participación ciudadana le confiere al IFE la Constitución política de los Estados Unidos Mexicanos (verificación de firmas para la presentación de iniciativas ciudadanas y la celebración de consultas populares, así como la organización de dichas consultas). La transformación orgánica de la autoridad electoral estaría acompañada de la expedición de una Ley Federal de Partidos Políticos y –presumimos- de un Código Electoral General con aplicación en las elecciones federales, estatales y del Distrito Federal (ahora conocida como Ciudad de México). 

El 3 de abril de 2014, el pleno de la Cámara de Diputados aprobó el decreto por el cual se nombran a los nuevos 11 consejeros del Instituto Nacional de Elecciones, indicando con esto, la creación del mismo, por lo que obligaba a la toma de protesta de los consejeros al día siguiente de la aprobación del decreto y así iniciar las actividades formales del nuevo organismo electoral.

El 28 de febrero de 2014, el Instituto Federal Electoral, presentó un informe para presentar las bases para la transición del patrimonio al Instituto Nacional Electoral.

Son atribuciones del [INE] según el artículo 41, fracción V, apartado B, capacitación electoral, educación cívica, impresión de material electoral, cómputos de las elecciones y entrega de constancias de validez de las elecciones respectivas, entre otras.



</doc>
<doc id="41057" url="https://es.wikipedia.org/wiki?curid=41057" title="Griego">
Griego

El término griego hace referencia a varios artículos:





</doc>
<doc id="41058" url="https://es.wikipedia.org/wiki?curid=41058" title="(4144) Vladvasil'ev">
(4144) Vladvasil'ev

(4144) Vladvasil'ev es un asteroide que forma parte del cinturón de asteroides y fue descubierto por Liudmila Vasílievna Zhuravliova desde el Observatorio Astrofísico de Crimea, en Naúchni, el 28 de septiembre de 1981.

Vladvasil'ev fue designado inicialmente como .
Posteriormente, en 1994, se nombró en hoonor del bailarín ruso Vladímir Vasíliev.

Vladvasil'ev está situado a una distancia media de 3,157 ua del Sol, pudiendo alejarse hasta 3,271 ua y acercarse hasta 3,044 ua. Tiene una excentricidad de 0,03601 y una inclinación orbital de 9,272 grados. Emplea 2049 días en completar una órbita alrededor del Sol.

La magnitud absoluta de Vladvasil'ev es 11,8. Tiene un diámetro de 24,66 km y su albedo se estima en 0,0666.



</doc>
<doc id="41059" url="https://es.wikipedia.org/wiki?curid=41059" title="(8744) Cilla">
(8744) Cilla

(8744) Cilla es un asteroide que forma parte del cinturón de asteroides y fue descubierto el 20 de marzo de 1998 por el equipo del Lincoln Near-Earth Asteroid Research desde el Sitio de Pruebas Experimentales, en Socorro, Estados Unidos.

Cilla se designó inicialmente como .
Posteriormente, en 1999, fue nombrado en honor de Priscilla Annette (1994-1998), nieta de un miembro del equipo del Laboratorio Lincoln.

Cilla orbita a una distancia media de 3,124 ua del Sol, pudiendo acercarse hasta 2,578 ua y alejarse hasta 3,669 ua. Tiene una inclinación orbital de 2,608 grados y una excentricidad de 0,1746. Emplea 2017 días en completar una órbita alrededor del Sol. El movimiento de Cilla sobre el fondo estelar es de 0,1785 grados por día.

La magnitud absoluta de Cilla es 13,4.



</doc>
<doc id="41060" url="https://es.wikipedia.org/wiki?curid=41060" title="(8749) Beatles">
(8749) Beatles

(8749) Beatles es un asteroide que forma parte del cinturón de asteroides y fue descubierto por John Broughton el 3 de abril de 1998 desde el Observatorio de Reedy Creek, Australia.

Beatles se designó inicialmente como .
Más tarde, en 2001, fue nombrado por el grupo de música británico The Beatles.

Beatles orbita a una distancia media de 2,254 ua del Sol, pudiendo alejarse hasta 2,678 ua y acercarse hasta 1,831 ua. Tiene una excentricidad de 0,1878 y una inclinación orbital de 3,365 grados. Emplea en completar una órbita alrededor del Sol 1236 días. El movimiento de Beatles sobre el fondo estelar es de 0,2912 grados por día.

La magnitud absoluta de Beatles es 14,2.



</doc>
<doc id="41061" url="https://es.wikipedia.org/wiki?curid=41061" title="La creación (Haydn)">
La creación (Haydn)

La Creación (Die Schöpfung) es un oratorio compuesto por Joseph Haydn. El compositor concibió la idea de escribir un gran oratorio en su primer viaje a Inglaterra en 1791. Después de escuchar varias obras de Haendel, entre ellas "El Mesías", Haydn manifestó: «Quiero escribir una obra que proporcione fama universal y eterna a mi nombre». Fue compuesto entre 1796 y 98 (Hob. XXI:2) y se estrenó el 29 de abril de 1798 en Viena. La obra ilustra la creación del mundo, tal como se narra en el Génesis. Además de este libro del Antiguo Testamento, sus fuentes de inspiración son los salmos y "El paraíso perdido", de John Milton. El barón Gottfried Van Swieten fue el encargado de preparar el texto.

Su estreno tuvo lugar en Viena los días 19 y 30 de abril de 1798 bajo los auspicios de la Sociedad de los Asociados, una agrupación musical fundada por Van Swieten y a la que pertenecía la élite de la nobleza austro-húngara. Como no podía ser de otra manera, representó un éxito total mayor aún que los obtenidos en Inglaterra.

Un año después se estrenó en París, Londres, Berlín y Praga, siempre con igual éxito. Desde entonces, Haydn, mientras la edad y su estado de salud se lo permitieron, dirigió una representación anual de la obra en Viena, generalmente con fines benéficos. 

Según la forma clásica del oratorio, "La Creación" está dividida en tres partes y se compone de coros, recitativos y arias. En la primera y segunda parte los solistas son Gabriel, Uriel y Rafael (respectivamente soprano, tenor y bajo); en la tercera parte, son Uriel, Adán y Eva (tenor, bajo o barítono y soprano).

Los coros están claramente inspirados en los de Haendel y sus amplias formas polifónicas combinan extraordinariamente con las voces solistas.

3 flautas, 2 oboes, 2 clarinetes, 2 fagotes, 1 contrafagot; 2 cornos, 2 trompetas, 3 trombones; timbales; cuerdas: Vln. I y II (violines primeros y segundos), violas, violonchelos y contrabajos; clave.




</doc>
<doc id="41063" url="https://es.wikipedia.org/wiki?curid=41063" title="Inteligencia (desambiguación)">
Inteligencia (desambiguación)

Inteligencia generalmente se refiere a la capacidad de generar información nueva, combinando la que se recibe del exterior con aquella de la que se dispone en la memoria. Asimismo, en informática, puede referirse a:
También, en espionaje, puede hacer referencia a:
Además, en medicina, puede referirse a:
Asimismo, en psicología, puede hacer referencia a:
Además, en otros contextos, puede referirse a:



</doc>
<doc id="41066" url="https://es.wikipedia.org/wiki?curid=41066" title="Unlur">
Unlur

Unlur es un juego entre dos personas que van colocando por turnos fichas sobre un tablero hexagonal. Cada jugador tiene un objetivo diferente para conseguir la victoria. Se clasifica como juego de tablero abstracto, de conexión y de fuerzas desiguales.

Se juega sobre un tablero hexagonal formado por casillas hexagonales, normalmente de 6 casillas por lado, aunque son posibles otros tamaños.

Inicialmente el tablero está vacío y se van colocando por turnos fichas de un único color, típicamente fichas de color negro, hasta que un jugador pasa asignándose de esta forma las fichas negras y asignando al otro jugador las otras fichas, típicamente blancas. El jugador con las fichas blancas continúa jugando y se van colocando fichas sobre casillas desocupadas del tablero por turnos.

El jugador que lleva las fichas blancas gana si consigue formar una línea de fichas que conecte dos lados del tablero opuestos.

El jugador que lleva las fichas negras gana si consigue formar una línea de fichas que conecte tres lados del tablero alternos.

Para evitar los empates, si un jugador cumple con sus fichas el objetivo del adversario, pierde la partida. Si cumple los dos objetivos simultáneamente, gana la partida.

Este juego inventado por Jorge Gómez Arrausi fue el ganador de la segunda edición de la "Annual Game Design Competition" en 2002 cuyo tema ese año era el diseño de juegos de fuerzas desiguales. La competición fue organizada por la revista "Abstract Games", "About Board Games", y la "Strategy Gaming Society".


</doc>
<doc id="41068" url="https://es.wikipedia.org/wiki?curid=41068" title="Documento">
Documento

Un documento es un testimonio material de un hecho o acto realizado en funciones por instituciones o personas físicas, jurídicas, públicas o privadas, registrado en una unidad de información en cualquier tipo de soporte (papel, cintas, discos magnéticos, fotografías, etc.) en lengua natural o convencional. Es el testimonio de una actividad humana fijada en un soporte, dando lugar a una fuente archivística, arqueológica, audiovisual, entre otras.

Tradicionalmente, el medio de un documento era el papel y la información era ingresada a mano, utilizando tinta (esto es lo que se denomina hacer un manuscrito) o por un proceso mecánico (mediante una máquina de escribir, o utilizando una impresora láser).

Desde el punto de vista de la informática, es un archivo, pero con determinados atributos ya que contiene datos textuales o gráficos creados por el usuario con su computadora -o dispositivo móvil, por ejemplo- mediante un programa. El archivo recibe un nombre y un formato para guardarlo en un directorio, subdirectorio o carpeta previamente asignado en la unidad de almacenamiento. Es posible volver a abrirlo cuando se necesite acceder a su contenido, ya sea para imprimirlo, modificarlo o eliminarlo. Es mucho más frecuente decirle solamente archivo.

Todo objeto material que porte, registre o fije, en sí, información, es decir, el conjunto formado por el contenedor con su contenido; con el objetivo de conservar y transmitir dicha información en el dominio del espacio y del tiempo a fin de ser utilizada como instrumento jurídico o probativo, testimonio histórico, etc.

Toda fuente de información registrada sobre cualquier soporte, sea un disco compacto (CD), un disco versátil digital (DVD), papel, papiro o incluso una piedra o trozo de madera. Los documentos pueden clasificarse de acuerdo a:


En cuanto a la naturaleza de los documentos pueden ser textuales y no textuales.

Son características que tienen que ver con el carácter informativo. Las características intelectuales son el contenido, la finalidad, el tema, etc. Podemos hacer la siguiente clasificación: documentos primarios, secundarios, y terciarios.

Los documentos primarios son aquellos que contienen información original del autor/a y no han pasado por ninguna clase de tratamiento (libros, tesis doctorales, revistas, periódicos, boletines, actas de congresos). Los documentos secundarios son resultado de aplicar tratamiento a los documentos primarios (por ejemplo, bibliografías, índices, catálogos, revistas de resúmenes). Los documentos terciarios son resultado de aplicar tratamiento a los documentos secundarios, aunque algunos autores los definen como reproducciones mecánicas (fotocopias).




</doc>
<doc id="41070" url="https://es.wikipedia.org/wiki?curid=41070" title="Altair">
Altair

Altair (α Aquilae / α Aql / 53 Aql) es la estrella más brillante de la constelación de Aquila «El Águila». Los árabes, que también veían en esta constelación una gran águila volando, la llamaron "elnars-el-tair", de donde derivó el nombre de Altair.

Ocupa el en orden de brillo entre todas las estrellas del cielo. Su magnitud en banda B (filtro azul) es 0,99, su magnitud en banda V (filtro verde) es 0,77. Está a 16 años luz del sistema solar, acercándose a razón de 26,1 m/s.

Es un astro magnífico, unas cuatro veces más voluminoso que nuestro Sol, de tipo espectral A (color blanco, igual que Sirio) y muchísimo más joven, con solo 630 millones de años de edad. La temperatura superficial de este tipo espectral oscila entre 7500 y 11 000 K, y el espectro presenta líneas intensas del hidrógeno, el calcio ionizado y otros metales ionizados, además de líneas débiles del helio.

Esta estrella, junto con Vega (α Lyrae) y Deneb (α Cygni), configuran en el cielo del hemisferio norte lo que se conoce como el triángulo de verano, cuyo centro es la estrella Albireo (β Cygni).

Altair posee una de las velocidades de rotación más altas que se conocen, solo inferior a las de las estrellas de neutrones y las enanas blancas. El periodo de rotación es solo de 6 horas 30 minutos y sus estratos periféricos ecuatoriales se mueven a la velocidad de 250 km/s. La rápida rotación axial de Altair se supone que está relacionada con la joven edad de la misma y resalta inmediatamente al examinar el espectro, cuyas líneas aparecen considerablemente ensanchadas debido al claro desfase en longitud de onda, de la radiación emitida por las partes de la estrella que se aproximan, con relación a la que proviene de las que se alejan. Debido a las grandes fuerzas centrífugas que se desarrollan en el interior de su propia masa, la estrella ha tomado forma achatada y su diámetro ecuatorial es un 20 % mayor que el polar. Asimismo se verificó el fenómeno propio de estrellas de alta rotación conocido como «oscurecimiento gravitatorio».

Altair es una variable de tipo Delta Scuti y una doble óptica: tiene una compañera de magnitud +10 que, por el movimiento propio de Altair, se está alejando de ella; actualmente la separación ha alcanzado un valor de 165 segundos de arco.




</doc>
<doc id="41084" url="https://es.wikipedia.org/wiki?curid=41084" title="Belfast">
Belfast

Belfast (del irlandés Béal Feirste que significa "El vado arenoso en la desembocadura del río") es la capital y ciudad más grande de Irlanda del Norte y de toda la isla de Irlanda. En el censo de 2001 la población dentro de los límites de la ciudad (el área urbana de Belfast) era de 276 459 habitantes, mientras que 579 554 personas residían en la amplia Zona Metropolitana de Belfast. Esto la convertía en la decimoquinta ciudad más grande del Reino Unido, y la undécima mayor conurbación de ese país.

Belfast está situada en la costa este de Irlanda del Norte. La ciudad está flanqueada al noroeste por una serie de colinas, incluyendo la colina de Cavehill, que se cree que inspiró la novela de Jonathan Swift, "Los viajes de Gulliver". Él imaginaba que esta tenía la forma de un gigante dormido protegiendo a la ciudad. Belfast también está localizada al oeste del Belfast Lough (lago Belfast/ría de Belfast) y en la desembocadura de río Lagan lo que la convierte en una localización ideal para la industria de construcción naval que alguna vez la hiciera tan famosa. Cuando el "Titanic" fue construido en Belfast en 1912, Harland and Wolff tenía el mayor astillero del mundo. Siendo originalmente un pueblo en el Condado de Antrim, el municipio de Belfast fue creado cuando Belfast alcanzó el estatus de ciudad gracias a la reina Victoria en 1888.

Belfast sufrió lo peor del Conflicto de Irlanda del Norte. No obstante, desde el Acuerdo de Viernes Santo en 1998, ha habido una mayor modernización en la ciudad. Existen dos aeropuertos en la ciudad: el Aeropuerto George Best de la Ciudad de Belfast, adyacente al Belfast Lough y el Aeropuerto Internacional de Belfast que se encuentra cerca del lago Neagh. La Universidad Queen's es la más importante de la ciudad. La Universidad del Ulster también tiene un campus en la ciudad, donde se concentra los estudios de las bellas artes y diseño.

El lugar en el que se encuentra la actual Belfast ha estado siempre ocupado desde la Edad de Bronce. El lugar arqueológico conocido como "Giant's Ring" ("Anillo del Gigante"), localizado muy cerca de la ciudad tiene 5000 años de antigüedad y aún se pueden observar restos de fortificaciones que datan de la Edad de Hierro en las colinas que rodean la ciudad.

Se convirtió en un asentamiento importante en el siglo XVII cuando un gran número de colonos ingleses y escoceses se establecieron allí en proceso de colonización del Ulster, con el objetivo de erradicar a la población católica de Ulster. En 1641, los católicos se rebelaron, pero fueron duramente reprimidos. Belfast floreció como un importante centro comercial e industrial durante los siglos XVIII y XIX y se convirtió en la ciudad más industrializada de Irlanda superando incluso a Dublín gracias a sus astilleros, su industria textil y tabaquera entre otras. Los astilleros de Harland and Wolff se convirtieron en los más importantes del mundo, empleando hasta a 35.000 trabajadores. En estos astilleros se construyó el trágicamente famoso RMS Titanic.

Belfast se constituyó en la capital de Irlanda del Norte desde la creación de esta región administrativa en 1920 por la Ley de Gobierno de Irlanda de 1920. Desde entonces ha ido creciendo en número de habitantes y ha sido testigo de los enfrentamientos en sus ciudadanos católicos (en su mayoría "nacionalistas", favorables a la independencia del Reino Unido) y protestantes (o "leales", que se oponen a algún proceso que dé lugar a separarse del imperio británico).

Belfast fue bombardeada tres veces durante la Segunda Guerra Mundial por bombarderos de la Luftwaffe. El bombardeo que causó más daños ocurrió en la noche del 15 de abril de 1941, cuando 200 bombarderos, entre Heinkel He 111, Junkers y Dorniers, atacaron la ciudad sin encontrar resistencia importante. Se estima que unas mil personas murieron durante el bombardeo o de heridas ocasionadas durante el mismo. Además, unas 100 000 personas perdieron sus hogares. Aunque los astilleros y las fábricas de aviones fueron afectadas, rápidamente se recuperaron, ya que la demanda de barcos y aviones era elevada. Esto, por supuesto, significó la rápida recuperación de la economía de Belfast.

El 21 de julio de 1972, el IRA Provisional detonó 22 bombas dentro y alrededor de la ciudad, matando a nueve personas, incluyendo a dos policías, e hiriendo a otras 130. Además del Ejército Británico y la policía local, el IRA provisional se enfrentó a dos grupos paramilitares: la Asociación en Defensa del Ulster y la Fuerza Voluntaria del Ulster. Hasta 1994 se llevaron a cabo esporádicos enfrentamientos entre ambas fuerzas en Belfast. Aunque el cese al fuego entre ambos bandos ya no ha desatado la violencia en la ciudad, la ciudad mantiene un importante componente de segregación entre la población católica republicana y la población protestante unionista.

En 1997, los unionistas perdieron el control del Consejo de Belfast por primera vez en su historia. Esta derrota fue confirmada en las elecciones de 2001 y de 2005. Esto ha permitido que miembros de los nacionalistas SDLP y Sinn Féin ocupen el cargo de alcalde por primera vez. El alcalde actual, Jim Rodgers, pertenece al Partido Unionista del Ulster.

Belfast es la versión anglicanizada del nombre irlandés del área donde se encuentra, que significa ""Vado arenoso en la desembocadura del río"". Esto se refiere a la barra que se formó donde el río Farset se une al río Lagan en Donegall Quay y fluye hasta el Belfast Lough. Este fue el centro alrededor del cual se desarrolló la ciudad. El río Farset también recibe su nombre de la palabra para "foso de arena", "feirste" en irlandés. Sobrepasado por el río Lagan como el río más importante, el Farset ahora languidece en la oscuridad, bajo la Avenida Principal ("High Street"). El río abierto aún puede ser visto al borde del cementerio de Shankill. "Bank Street" (Calle del banco) en el centro de la ciudad se refiere no al sector bancario, sino al banco del río y "Bridge Street" (Calle del puente) fue el sitio donde se encontraba anteriormente un puente sobre el río Farset.
La ciudad de Belfast tiene el lema en latín ""Pro tanto quid retribuamus"". Esto se puede traducir como "Lo que debemos dar a cambio de mucho" (literalmente "Habiendo recibido tanto, lo que debemos devolver") y fue tomado del Salmo 116 versículo 12 de la Vulgata.

En el escudo de armas de la ciudad se muestra un escudo central, con la imagen de un barco y una campana, flanqueado por un lobo encadenado a la izquierda y un caballito de mar a la derecha. Un hipocampo más pequeño se sitúa en la parte superior. Este blasón data de 1613, cuando el rey Jacobo VI de Escocia y I de Inglaterra le otorgó el estatus de pueblo a Belfast. El sello fue usado por los comerciantes de la ciudad durante el siglo XVII en sus firmas y monedas. Una gran vidriera de colores en el Consejo de Belfast muestra el sello, donde una explicación sugiere que el hipocampo y el barco hacen referencia a la significante historia marítima de Belfast. El lobo puede simbolizar un tributo al fundador de la ciudad, sir Arthur Chichester, y referirse a su propio escudo de armas.

Belfast se sitúa en la costa oriental de Irlanda del Norte a . Una consecuencia de esta latitud norteña es que propicia días cortos en invierno y largos en verano. Durante el solsticio de invierno, el día más corto del año, la puesta de sol local, sucede antes de las 16.00, mientras que el amanecer es alrededor de las 8.45. Esto se compensa con el solsticio de verano en junio, cuando el sol se pone después de las 22.00 y sale antes de las 5.00.

Belfast también se localiza en el extremo este de Belfast Lough y en la desembocadura del río Lagan. En 1994, una presa fue construida a través del río por la Laganside Corporation para aumentar el nivel del agua para que cubriera las indecorosas zonas de fango que le dieron a Belfast su nombre (""El vado arenoso en la desembocadura del río""). El área del Distrito de Gobierno Local de Belfast es de 109,6 km² (42,3 millas cuadradas).

La ciudad está flanqueada al norte y noroeste por una serie de colinas, incluyendo la Montaña Divis, Montaña Negra ("Black Mountain") y Cavehill que se piensa fue la inspiración para la obra de Jonathan Swift, "Los viajes de Gulliver". Cuando Swift vivía en Lilliput Cottage cerca del fondo de la calle Limestone de Belfast, él imaginó que la colina Cavehill tenía la forma de un gigante dormido. La forma de la nariz del gigante, conocida localmente como la "Nariz de Napoleón", es llamada oficialmente "McArt's Fort" probablemente en honor a Art O'Neill, un cacique del siglo XVI que controló el área en esa época. Las colinas de Castlereagh se encuentran al sureste de la ciudad.

Belfast tiene un clima templado. La temperatura diaria promedio es de 18 °C (64 °F) en julio y 6 °C (43 °F) en enero. La temperatura más alta registrada en Belfast fue de 30,8 °C (87,4 °F) el 12 de julio de 1983. La ciudad tiene una precipitación significante (más de 0,25 mm) en 213 días en un año con una precipitación anual promedio de 846 milímetros, mayor a la de Dublín o a la de la costa sureste de Irlanda. Siendo un área urbana y costera, Belfast normalmente recibe nevadas durante menos de 10 días al año. El cambio climático también está afectando a Belfast, prueba de ello es que julio y septiembre de 2006 y abril de 2007 rompieron récords como los meses más calurosos que se han registrado en la ciudad.

Belfast experimentó un enorme crecimiento en su población alrededor de la primera mitad del siglo XX. Este incremento se redujo y alcanzó su punto máximo cerca del inicio del Conflicto de Irlanda del Norte con el censo de 1971 registrando cerca de 600 000 habitantes en el Área Urbana de Belfast. Desde entonces, los números del interior de la ciudad han disminuido dramáticamente, ya que la gente se ha ido mudando a las afueras, aumentando la población suburbana de Belfast. El censo de población de 2001 dentro de la misma Área Urbana registró 277 391 habitantes, con 579 554 personas residiendo en Área Metropolitana de Belfast. La densidad de población en el mismo año fue de 24,15 habitantes por hectárea (en comparación al 1,19 en todo el territorio de Irlanda del Norte).

El censo del año 2001 también mostró que:


Al igual que muchas ciudades, el centro de la ciudad de Belfast se caracteriza actualmente por estar poblado por gente mayor, estudiantes y gente joven soltera, mientras que las familias tienden a vivir en la periferia. Las áreas socio-económicas se encuentran en el Distrito Comercial Central, con una pronunciada afluencia extendiéndose en el "Malone Road" (Camino Malone) hacia el sur. Un área de gran aislamiento se extiende al oeste de la ciudad. De hecho, las zonas alrededor de las calles Falls y Shankill son las más privadas de recursos de toda Irlanda del Norte, además de las más afectadas por los "Problemas" de unionistas y republicanos.

A pesar de un periodo de relativa paz, la mayor parte de las áreas y distritos de Belfast aún reflejan la naturaleza dividida de Irlanda del Norte. Muchas áreas están todavía segregadas según las características étnicas, políticas o religiosas, especialmente en los barrios de la clase obrera. Estas zonas, "católica" o "protestante", "republicana" o "unionista" están invariablemente marcadas con banderas, grafiti y murales. La segregación ha estado presente a lo largo de la historia de Belfast, pero se ha mantenido o incrementado en cada nuevo estallido de violencia en la ciudad. Esta intensificación de la segregación ha mostrado pocas señales de reducción durante los tiempos de paz. Cuando la violencia surge, tiende a ser en áreas de interacción. Los mayores niveles de segregación en la ciudad se encuentran en Belfast del Oeste, con muchas zonas con más del 90 % de católicos. Niveles opuestos pero comparativamente altos se encuentran en la predominante área protestante de Belfast del Este.

Las comunidades de minorías étnicas han estado viviendo en Belfast desde la década de 1930. Los mayores grupos son el chino y los viajeros irlandeses. Desde la expansión de la Unión Europea, las cifras han aumentado debido a una gran afluencia de inmigrantes de Europa Oriental. Las cifras del censo de 2001 indican que Belfast tiene una población de minorías étnicas total de 4584 habitantes, es decir, el 1,3 % de la población. Más de la mitad de estos viven en Belfast del Sur con cerca del 2,63 % de la población de la zona. La mayoría de los 5000 musulmanes y 3000 hindúes estimados que viven y trabajan en Irlanda del Norte residen en el área de Belfast Mayor ("Greater Belfast").

Belfast tiene numerosos sitios que atraen la atención del visitante: El ayuntamiento de Belfast, de estilo eduardiano, con su cúpula de 53 metros de altura; el Ulster Bank,
construido en 1860 y en estilo victoriano se destacan la Queens University y la biblioteca Linenhall. El Waterfront Hall es un soberbio edificio de líneas modernas.

Pero muchos turistas se interesan más por el pasado reciente de Belfast y nunca falta un taxista dispuesto a mostrarle al visitante los lugares que fueron noticia por los estallidos de violencia. Aún pueden verse los vastos muros de ladrillo y hormigón levantados antaño para separar a los barrios católicos de los protestantes, a fin de evitar disturbios. En la zona oeste de Belfast, donde la mayoría de los habitantes son católicos, se ven pintadas y grafitis del tipo "¡Abajo la Reina!" (Isabel II), "¡Viva el IRA!" o "¡Viva Irlanda!" En cambio, en la zona este, donde la mayoría de la población es protestante, se leen frases como "¡No nos rendiremos!" o "¡Aquí no hay Papa ni papado!" La animadversión entre ambos grupos suele aumentar sobremanera el 12 de julio de cada año, cuando los protestantes celebran el aniversario de la batalla de Boyne, ocurrida en 1690, en la que un rey inglés derrotó a los rebeldes católicos irlandeses. Para esa fecha, los protestantes suelen organizar bulliciosas fiestas callejeras, que enfurecen a los católicos, por lo que la policía debe extremar las medidas de seguridad.

En general, Belfast no es una ciudad peligrosa y los habitantes de Belfast, sean católicos o protestantes, toleran a los turistas extranjeros, pero como medida de precaución, al forastero que visita Belfast se le suele aconsejar dos cosas: ten cuidado de hablar de política y de mencionar su religión. Aunque muchos de los habitantes no tienen problemas de hablar de la política del país y darán su opinión personal de muchas cosas, la política de la región es muy complicada y no es difícil ofender a algunas personas.

El 6 de marzo de 2008 se inauguró un nuevo centro comercial en el centro de Belfast, conocido como 'Victoria Square, Belfast'. Es la urbanización más grande que jamás se ha realizado en todo el país.
El 31 de marzo de 2012 se inauguró un museo dedicado al RMS Titanic, conocido como "Titanic Belfast".
Las seis plantas del museo exploran la historia del Titanic, de la gente y de la ciudad que lo construyó y también cuenta con una conexión en directo con los restos de la nave. La fachada de este moderno centro de interpretación de seis plantas y 14.000 metros cuadrados tiene la forma de cuatro proas, todas de la misma altura que tenía el auténtico Titanic desde la quilla hasta la cubierta. Son las entrañas del mismo astillero, donde se puede vivir en primera persona todo el proceso en un recorrido por los muelles, con imágenes en vídeo filmadas hace cien años, modelos de tamaño real, sonidos de la época y donde también se puede percibir hasta los olores de ese entorno industrial. La galería 6 es, quizá, la más dramática de todas. Efectos visuales y sonoros de última generación reviven las últimas horas del buque. En la 7, en tanto, se puede ver a través de pantallas táctiles la lista de fallecidos y las consecuencias de la tragedia. En la galería 8, la leyenda creada en torno al barco a través de los reportajes de la época, de las películas que lo inmortalizaron o de la literatura. Y la guinda es una inmersión a 4.000 metros de profundidad, al fondo del Atlántico Norte, donde se puede bucear junto a los restos del Titanic de la mano de unas imágenes que muestran el pecio tal y como lo descubrió Robert Ballard en 1985.

Belfast tiene dos universidades: la Universidad Queen's de Belfast, fundada en 1845 y que forma parte del Russel Group; una asociación de 20 universidades importantes del Reino Unido, además de ser una de las más grandes de este, con 25.231 estudiantes universitarios y de posgrado distribuidos en más de 250 edificios, 120 de los cuales están catalogados con el grado de mérito arquitectónico. La Universidad del Ulster, creada en su forma actual en 1984, es una universidad con un campus situado en el barrio de la Catedral de Belfast. El campus de Belfast está enfocado específicamente en el Arte y Diseño, y actualmente está experimentando una renovación mayor. El campus de Jordanstown, a sólo siete millas del centro de la ciudad de Belfast, concentra los estudios de ingeniería, salud y ciencias sociales. El servicio web de "Conflict Archive on the INternet" (CAIN) recibe fondos de ambas universidades y una rica fuente de información y material acerca del Conflicto de Irlanda del Norte así como de sociedad y política en Irlanda del Norte.

El Consejo Bibliotecario y de Educación de Belfast (en inglés "Belfast Education and Library Board") fue establecido en 1973 como la autoridad local responsable de la educación, la juventud y los servicios bibliotecarios dentro de la ciudad. Existen 184 escuelas primarias, secundarias y "grammar schools" (que pueden dar educación tanto primaria como secundaria) en la ciudad.





</doc>
<doc id="41085" url="https://es.wikipedia.org/wiki?curid=41085" title="Estado Libre Irlandés">
Estado Libre Irlandés

El Estado Libre Irlandés (en irlandés: "Saorstát Éireann" /sírstat éran/; ) fue el nombre del país independiente situado en la isla de Irlanda que se separó del Reino Unido en 1922, después de varios siglos de gobierno británico. El Estado era miembro de la Mancomunidad Británica de Naciones y, en una situación similar a Canadá, Australia o Nueva Zelanda, reconocía al como el jefe de Estado y soberano del pueblo irlandés.

En 1937, después de quince años con este sistema de gobierno, el país se separó de la Mancomunidad Británica de Naciones y se creó el cargo de . En 1949, después de algunos años de indefinición sobre su forma de gobierno, el país se convirtió formalmente en una república adoptando su nombre actual, República de Irlanda.

El 6 de diciembre de 1922 y durante varios días, Irlanda del Norte dejó de formar parte del Reino Unido y vino a formar parte del recién creado Estado Libre Irlandés. Este excepcional episodio constitucional sucedió debido al Tratado Anglo-Irlandés y a la legislación introducida para darle efecto legal al tratado.

El Tratado tuvo efecto en Reino Unido a través del Acta Constitucional 1922 del Estado Libre Irlandés. El acta establecía un nuevo dominio de la isla entera de Irlanda, pero también permitía a Irlanda del Norte no participar o no unirse al Estado Libre. Bajo el Artículo 12 del Tratado, Irlanda del Norte presentó una carta al rey solicitando no formar parte del Estado Libre Irlandés. Una vez el Tratado fue ratificado, el Parlamento de Irlanda del Norte tuvo un mes para ejercitar su "no unión" durante el cual el gobierno del Estado Libre Irlandés no legisló para Irlanda del Norte, dejando la jurisdicción efectiva del Estado Libre en desuso por un mes.

El primer ministro de Irlanda del Norte, James Craig, hablando al Parlamento en octubre de 1922, expresó que una vez pasara el 6 de diciembre comenzaba el mes para decidir si se unían o no al Estado Libre Irlandés. Para Craig era sumamente importante que la decisión se tomara lo antes posible tras el 6 de diciembre. El 7 de diciembre de 1922 (un día después del establecimiento del Estado Libre), el Parlamento demostró sin vacilación su posición de no unirse al Estado Libre Irlandés, haciendo la siguiente presentación al rey:

El 13 de diciembre de 1922, el primer ministro Craig se dirigió al Parlamento comunicándoles que el rey había respondido a su comunicación. De esta forma el Parlamento de Irlanda del Norte decide no unirse al nuevo Estado Libre Irlandés y permanecer junto al Reino Unido.

Las estructuras del antiguo Estado Libre Irlandés fueron señaladas en el Tratado y en el Acta de Constitución del Estado Libre Irlandés. Esta establecía para una monarquía constitucional, con un parlamento de tres niveles, llamado Oireachtas, formado por el rey y dos casas: "Dáil Éireann" y "Seanad Éireann" (el Senado irlandés). La autoridad ejecutiva era ejercida por el rey, y el ejercicio del poder por un gabinete llamado Consejo Ejecutivo, presidido por un primer ministro llamado "presidente del Consejo Ejecutivo".

El 8 de junio de 1949 el gobierno argentino sancionó la ley 13.516 estableciendo relaciones diplomáticas con el Estado Libre de Irlanda y creando una legación en la ciudad de Dublin


</doc>
<doc id="41086" url="https://es.wikipedia.org/wiki?curid=41086" title="Leucocitosis">
Leucocitosis

La leucocitosis es el aumento en el número de células de glóbulos blancos de la sangre (leucocitos). Se dice que hay leucocitosis cuando la cifra de glóbulos blancos es superior a 11 000 por mm³. 



La leucocitosis puede ser reflejo de un aumento de la población de neutrófilos (neutrofilia: la más común), linfocitos (linfocitosis), o monocitosis (monocitos). Rara vez, un aumento de eosinófilos y basófilos es tan grande como para ocasionar una leucocitosis. Es igualmente infrecuente que todas las líneas celulares estén aumentadas al mismo tiempo.

La distribución de los diversos tipos de leucocitos ayuda a orientar un diagnóstico en cuanto al posible origen de la leucocitosis, frecuentemente sobre la base de estos resultados, se indica un tratamiento temprano antes de que las pruebas complementarias (las cuales suelen durar muchas horas o días) arrojen el resultado específico de la patología.

Los neutrófilos son los leucocitos que se encuentran en mayor cantidad y son porcentualmente los más significativos. Estos se encargan de llevar a cabo la fagocitosis (absorción y digestión de elementos ajenos al organismo como: virus, cuerpos extraños, tejidos, etc.). Las formas jóvenes de neutrófilos se presentan cuando existe un importante estímulo medular para su producción, en esta etapa reciben el nombre de neutrófilos en banda o cayados dada la forma de su núcleo. Una alta presencia de estos indica que existe una actividad intensa de las defensas en contra de una infección de origen bacteriano.

Los eosinófilos suelen estar elevados en algunas enfermedades originadas bien sea por alergia o por infecciones parasitarias. Igual comportamiento siguen los basófilos.

La alta presencia de linfocitos o monocitos puede indicar que se trata de un cuadro de infección viral o bacteriana crónica.

Una larga lista de situaciones puede causar un aumento en el valor absoluto de los glóbulos blancos, por ejemplo:

Razones fisiológicas




</doc>
<doc id="41093" url="https://es.wikipedia.org/wiki?curid=41093" title="Donato d'Angelo Bramante">
Donato d'Angelo Bramante

Donato di Pascuccio d'Antonio o Donato di Angelo di Antonio, conocido como Bramante (Fermignano, c. 1443/1444-Roma, 1514), fue un pintor y arquitecto italiano, que introdujo el estilo del primer Renacimiento en Milán y el «Alto Renacimiento» en Roma, donde su obra más famosa fue el planeamiento de la Basílica de San Pedro.

Tuvo una formación quattrocentista pero su plenitud artística la alcanza en el siglo XVI. Su arquitectura está caracterizada por la severidad y el uso de planta central cubierta con cúpula.

Bramante nació en Monte Asdrualdo (hoy Fermignano), cerca de Urbino: aquí, en los años 1460, Luciano Laurana estaba añadiendo al Palacio Ducal un patio con arcos y otros elementos que parecen haber sido el verdadero toque de una antigüedad renacida para el Palacio ducal de Federico da Montefeltro. 

La arquitectura de Bramante ha eclipsado sus habilidades como pintor: conoció bien a los pintores Melozzo da Forlì y Piero della Francesca, quienes estaban interesados en las reglas de la perspectiva y las características ilusionistas de la pintura de Mantegna. Alrededor de 1474, Bramante se trasladó a Milán, una ciudad con una profunda tradición arquitectónica gótica, y erigió varias iglesias en el nuevo estilo de la Antigüedad. El duque, Ludovico Sforza, le hizo virtualmente su arquitecto de corte, a partir de 1476, con encargos que culminaron en el famoso coro en trampantojo de la iglesia de Santa Maria presso San Satiro (1482–1486). El espacio era limitado, así que Bramante hizo un ábside teatral en bajorrelieve, combinando las artes pictóricas de la perspectiva con detalles romanos. Hay una sacristía octogonal, coronada por una cúpula.

En Milán, Bramante también construyó Santa Maria delle Grazie (1492-1499); otras obras tempranas incluyen los claustros de Sant'Ambrogio, Milán (1497–1498), y algunas otras construcciones menores en Pavía y Legnano. Sin embargo, en 1499, su patrón Sforza fue expulsado de Milán por el ejército francés invasor, y Bramante decidió marchar a Roma, donde ya era conocido por el poderoso cardenal Raffaele Riario.

Sus obras más destacadas se encuentran en Roma. Allí fue pronto reconocido por el cardenal Della Rovere, que pronto se convertiría en el papa Julio II. 

En la Ciudad eterna su primera obra es fruto del encargo de los Reyes Católicos, que para conmemorar la Toma de Granada (1492) deciden levantar una iglesia en honor a san Pedro apóstol. En el lugar en que se cree fue martirizado se construyó en 1502 el Templete de San Pietro in Montorio o "tempietto". Este templete fue casi una especie de prueba por parte del papa Julio II. Está considerado uno de los edificios más armoniosos del Renacimiento. A pesar de su pequeño tamaño, la construcción tiene todas las proporciones rigurosas y la simetría de las estructuras clásicas, rodeado por finas columnas toscanas, con una cúpula por encima. Bramante planeó un patio con columnas que lo rodease, pero se pusieron en marcha planes más grandiosos: la Basílica de San Pedro. 
En noviembre de 1503, es nombrado arquitecto pontificio, llevando a cabo dos intervenciones: el llamado "Palacio de los Papas" y la nueva Basílica de San Pedro en el Vaticano, proyecto este último que solo llegó a comenzar y que sería más tarde continuado y modificado por Rafael, Antonio de Sangallo y Miguel Ángel, para ser concluido en el siglo XVII por Carlo Maderno.

En efecto, el papa Julio contrató a Bramante para la construcción de la obra arquitectónica europea más grande del siglo XVI: la construcción de una nueva basílica de San Pedro. La primera piedra del crucero se colocó con ceremonia el 18 de abril de 1506. Sobreviven muchos dibujos de Bramante, y muchos más de ayudantes suyos, lo que demuestra la extensión del equipo que había reunido. La visión de Bramante para San Pedro, una planta de cruz griega que simbolizaba la sublime perfección para él y su generación (compárese con Santa Maria della Consolazione, en Todi, que influyó en la obra de Bramante), fue fundamentalmente alterada por la extensión de la nave después de su muerte en 1514. El plan de Bramante preveía cuatro grandes capillas llenando los espacios de las esquinas entre los transeptos de igual tamaño, cada uno de ellos cubierto por una pequeña cúpula rodeando a la gran cúpula sobre el crucero. Así que el plan original de Bramante era más romano-bizantino en sus formas que la basílica que en realidad se construyó. (Véase Basílica de San Pedro para más detalles.)

Ocupado con San Pedro, Bramante tenía poco tiempo para otros encargos. Entre sus primeras obras en Roma, antes de emprender la construcción de la basílica, están los claustros (1504) de Santa María della Pace, cerca de Piazza Navona. Las bellas proporciones le dan un aire de gran simplicidad. Las columnas de la planta inferior están complementadas por las de la primera planta, que alternan con columnas más pequeñas colocadas centralmente sobre los arcos inferiores. Bramante es también famoso por su revolucionario diseño para el Palacio Caprini en Roma. Este palacio, erigido en el rione de Borgo, ya no existe. Fue más tarde propiedad del artista Rafael, y desde entonces se le conoce como la Casa de Rafael.



</doc>
<doc id="41095" url="https://es.wikipedia.org/wiki?curid=41095" title="Ley de Gauss">
Ley de Gauss

En física la ley de Gauss, relacionada con el Teorema de la divergencia o Teorema de Gauss, establece que el flujo de ciertos campos a través de una superficie cerrada es proporcional a la magnitud de las fuentes de dicho campo que hay en el interior de la misma superficie. Estos campos son aquellos cuya intensidad decrece como la distancia a la fuente al cuadrado. La constante de proporcionalidad depende del sistema de unidades empleado.

Se aplica al campo electrostático y al gravitatorio. Sus fuentes son la carga eléctrica y la masa, respectivamente. También puede aplicarse al campo magnetostático.

La ley fue formulada por Carl Friedrich Gauss en 1835, pero no fue publicado hasta 1867. Esta es una de las cuatro ecuaciones de Maxwell, que forman la base de electrodinámica clásica (las otras tres son la ley de Gauss para el magnetismo, la ley de Faraday de la inducción y la ley de Ampère con la corrección de Maxwell). La ley de Gauss puede ser utilizada para obtener la ley de Coulomb, y viceversa.

El flujo (denotado como formula_1) es una propiedad de cualquier campo vectorial referida a una superficie hipotética que puede ser cerrada o abierta. Para un campo eléctrico, el flujo (formula_2) se mide por el número de líneas de fuerza que atraviesan la superficie.

Para definir al flujo eléctrico con precisión considérese la figura, que muestra una superficie cerrada arbitraria ubicada dentro de un campo eléctrico.

La superficie se encuentra dividida en cuadrados elementales formula_3, cada uno de los cuales es lo suficientemente pequeño como para que pueda ser considerado como un plano. Estos elementos de área pueden ser representados como vectores formula_4, cuya magnitud es la propia área, la dirección es perpendicular a la superficie y hacia afuera.

En cada cuadrado elemental también es posible trazar un vector de campo eléctrico formula_5. Ya que los cuadrados son tan pequeños como se quiera, formula_6 puede considerarse constante en todos los puntos de un cuadrado dado.

formula_5 y formula_4 caracterizan a cada cuadrado y forman un ángulo formula_9 entre sí y la figura muestra una vista amplificada de dos cuadrados.

El flujo, entonces, se define como sigue:

O sea:

Supóngase una superficie cilíndrica colocada dentro de un campo uniforme formula_5 tal como muestra la figura:

El flujo formula_11 puede escribirse como la suma de tres términos, (a) una integral en la tapa izquierda del cilindro, (b) una integral en la superficie cilíndrica y (c) una integral en la tapa derecha:

Para la tapa izquierda, el ángulo formula_9, para todos los puntos, es de formula_13, formula_6 tiene un valor constante y los vectores formula_15 son todos paralelos.

Entonces:
siendo formula_16el área de la tapa. Análogamente, para la tapa derecha:
Finalmente, para la superficie cilíndrica:
Por consiguiente: da cero ya que las mismas líneas de fuerza que entran, después salen del cilindro.

Considérese una superficie esférica de radio r con una carga puntual q en su centro tal como muestra la figura.
El campo eléctrico formula_5 es paralelo al vector superficie formula_18, y el campo es constante en todos los puntos de la superficie esférica.

En consecuencia:
Este teorema aplicado al campo eléctrico creado por una carga puntual es equivalente a la ley de Coulomb de la interacción electrostática.

La ley de Gauss puede deducirse matemáticamente a través del uso del concepto de ángulo sólido, que es un concepto muy similar a los factores de vista conocidos en la transferencia de calor por radiación.

El ángulo sólido formula_20 que es subtendido por formula_21 sobre una superficie esférica, se define como:

formula_22

siendo formula_23 el radio de la esfera.

como el área total de la esfera es formula_24 el ángulo sólido para ‘’toda la esfera’’ es:

formula_25

la unidad de este ángulo es el estereorradián (sr)

Si el área formula_21 no es perpendicular a las líneas que salen del origen que subtiende a formula_20, se busca la proyección normal, que es:

formula_28

Si se tiene una carga "q" rodeada por una superficie cualquiera, para calcular el flujo que atraviesa esta superficie es necesario encontrar formula_29 para cada elemento de área de la superficie, para luego sumarlos. Como la superficie que puede estar rodeando a la carga puede ser tan compleja como quiera, es mejor encontrar una relación sencilla para esta operación:

formula_30

De esta manera formula_20 es el mismo ángulo sólido subentendido por una superficie esférica. como se mostró un poco más arriba formula_32 para cualquier esfera, de cualquier radio. de esta forma al sumar todos los flujos que atraviesan a la superficie queda:

formula_33

que es la forma integral de la ley de Gauss.
La ley de Coulomb también puede deducirse a través de Ley de Gauss.

Tomando la ley de Gauss en forma integral.

Aplicando al primer término el teorema de Gauss de la divergencia queda

Como ambos lados de la igualdad poseen diferenciales volumétricas, y esta expresión debe ser cierta para cualquier volumen, solo puede ser que:

Que es la forma diferencial de la Ley de Gauss (en el vacío).

Esta ley se puede generalizar cuando hay un dieléctrico presente, introduciendo el campo de desplazamiento eléctrico formula_37, de esta manera la Ley de Gauss se puede escribir en su forma más general como

Finalmente es de esta forma en que la ley de Gauss es realmente útil para resolver problemas complejos de maneras relativamente sencillas.

Su forma integral utilizada en el caso de una distribución extensa de carga puede escribirse de la manera siguiente:

donde formula_40 es el flujo eléctrico, formula_41 es el campo eléctrico, formula_42 es un elemento diferencial del área "A" sobre la cual se realiza la integral, formula_43 es la carga total encerrada dentro del área A, formula_44 es la densidad de carga en un punto de formula_45 y formula_46 es la permitividad eléctrica del vacío.

La ley de Gauss puede ser utilizada para demostrar que no existe campo eléctrico dentro de una jaula de Faraday. La ley de Gauss es la equivalente electrostática a la ley de Ampère, que es una ley de magnetismo. Ambas ecuaciones fueron posteriormente integradas en las ecuaciones de Maxwell.

Esta ley puede interpretarse, en electrostática, entendiendo el flujo como una medida del número de líneas de campo que atraviesan la superficie en cuestión. Para una carga puntual este número es constante si la carga está contenida por la superficie y es nulo si está fuera (ya que hay el mismo número de líneas que entran como que salen). Además, al ser la densidad de líneas proporcional a la magnitud de la carga, resulta que este flujo es proporcional a la carga, si está encerrada, o nulo, si no lo está.

Cuando tenemos una distribución de cargas, por el principio de superposición, sólo tendremos que considerar las cargas interiores, resultando la ley de Gauss.

Sin embargo, aunque esta ley se deduce de la ley de Coulomb, es más general que ella, ya que se trata de una ley universal, válida en situaciones no electrostáticas en las que la ley de Coulomb no es aplicable.

Sea una recta cargada a lo largo del eje z. Tomemos como superficie cerrada un cilindro de radio r y altura h con su eje coincidente al eje z. Expresando el campo en coordenadas cilíndricas tenemos que debido a la simetría de reflexión respecto a un plano z=cte el campo no tiene componente en el eje z y la integración a las bases del cilindro no contribuye, de modo que aplicando la ley de Gauss:
Debido a la simetría del problema el campo tendrá dirección radial y podemos sustituir el producto escalar por el producto de módulos (ya que la dirección de la superficie lateral también es radial).
Despejando el campo y añadiendo su condición radial obtenemos:

Considérese una esfera uniformemente cargada de radio R. La carga existente en el interior de una superficie esférica de radio r es una parte de la carga total, que se calcula multiplicando la densidad de carga por el volumen de la esfera de radio r:

formula_50

Si Q es la carga de la esfera de radio R, entonces, se tiene:

formula_51

Dividiendo miembro a miembro ambas expresiones y operando apropiadamente:

formula_52
Como se demostró en una sección anterior formula_53 y teniendo en cuenta que según la ley de Gauss formula_54, se obtiene:

formula_55

Por lo tanto, para puntos interiores de la esfera:

Y para puntos exteriores:

En el caso de que la carga se distribuyera en la superficie de la esfera, es decir, en el caso de que fuera conductora, para puntos exteriores a la misma la intensidad del campo estaría dada por la segunda expresión, pero para puntos interiores a la esfera, el valor del campo sería nulo ya que la superficie gaussiana que se considerara no encerraría carga alguna.

Al igual que para el campo eléctrico, existe una ley de Gauss para el magnetismo, que se expresa en sus formas integral y diferencial como

Esta ley expresa la inexistencia de cargas magnéticas o, como se conocen habitualmente, monopolos magnéticos. Las distribuciones de fuentes magnéticas son siempre neutras en el sentido de que posee un polo norte y un polo sur, por lo que su flujo a través de cualquier superficie cerrada es nulo.

En el hipotético caso de que se descubriera experimentalmente la existencia de monopolos, esta ley debería ser modificada para acomodar las correspondientes densidades de carga, resultando una ley en todo análoga a la ley de Gauss para el campo eléctrico. La Ley de Gauss para el campo magnético quedaría como

donde formula_59 densidad de corriente formula_60, la cual obliga a modificar la ley de Faraday

Dada la similitud entre la ley de Newton de la gravitación universal y la ley de Coulomb, puede deducirse una ley análoga para el campo gravitatorio, la cual se escribe
siendo G la constante de gravitación universal, y G vectorial el campo gravitatorio. El signo menos en esta ley y el hecho de que la masa siempre sea positiva significa que el campo gravitatorio siempre es atractivo y se dirige hacia las masas que lo crean.

Sin embargo, a diferencia de la ley de Gauss para el campo eléctrico, el caso gravitatorio es sólo aproximado y se aplica exclusivamente a masas pequeñas en reposo, para las cuales es válida la ley de Newton. Al modificarse la teoría de Newton mediante la Teoría de la Relatividad general, la ley de Gauss deja de ser cierta, ya que deben incluirse la gravitación causada por la energía y el efecto del campo gravitatorio en el propio espaciotiempo (lo que modifica la expresión de los operadores diferenciales e integrales).

- Es posible comparar ambas ya que podemos medir el flujo de propiedades que disminuyan con el cuadrado de la distancia , y esto lo tienen en común la fórmula del campo eléctrico con la del campo gravitatorio : Campo Eléctrico formula_61 y Campo Gravitatorio formula_62.




</doc>
<doc id="41096" url="https://es.wikipedia.org/wiki?curid=41096" title="Theotokos">
Theotokos

Theotokos (, o ) es una palabra griega que significa "Madre de Dios" (literalmente, 'la que dio a luz a Dios'). Su equivalente en español, vía latín, es "Deípara". "Theotokos" es el título que la Iglesia cristiana temprana le dio a María en referencia a su maternidad divina, título que se definió dogmáticamente en el Concilio de Éfeso de 431. 

El título le fue concedido solemnemente a María en el Concilio de Éfeso de 431 al ser proclamado el dogma cristológico. El significado teológico en ese momento fue enfatizar que el hijo de María, Jesús, era completamente Dios, y también completamente humano, tal y como había sido afirmado en el Concilio de Nicea I de 325, y que sus dos naturalezas (humana y divina) estaban unidas y eran inseparables en una sola persona de la Santísima Trinidad. 

La visión contraria en el concilio era que María debía ser llamada «Christotókos»,«Madre de Cristo». Esta posición, abogada por Nestorio, entonces Patriarca de Constantinopla, pretendía restringir el papel de María a ser solo la madre de la «humanidad de Cristo», y no de su naturaleza divina. 

Por su parte la versión de Cirilo de Alejandría, en contraposición a la de Nestorio de Constantinopla, era que no podía ser que solo fuese «Christotókos», ya que de ser así, Jesús habría nacido como cualquier ser humano normal y, llegado determinado tiempo, Dios Hijo lo «poseyera» de manera tal que una persona era divina y la otra mortal. 

En el Concilio se determinó que no podía ser de este modo: Jesús desde su concepción tenía las dos naturalezas, la divina y la humana, de tal forma que cuando Él nació, María «La Virgen» fue «Theotókos». Con la puntualización de que llamar a María «Madre de Dios» no intentaba sugerir que María sea coeterna con Dios, o que existió antes que Jesucristo o Dios Padre. La Iglesia acepta esto como un misterio en la letra de este antiguo himno: «Él a quien todo el universo no podía contener, fue contenido en tu matriz, oh Theotokos».

Muchos Padres de la Iglesia primitiva utilizaron el título de Madre de Dios para referirse a María por lo menos desde el siglo III.


La Solemnidad de Santa María, Madre de Dios (Theotokos) se inició en las Iglesias orientales alrededor del año 500. En el rito romano se celebra el 11 de octubre. Con la reforma de Pablo VI, Juan Pablo II lo trasladó al día de la octava de la Navidad, 1 de enero.

En el Ave María, la oración mariana más típica del cristianismo occidental, María es invocada con el título de Madre de Dios. En el rito bizantino se nombra «verdadera Madre de Dios, a Ti, te celebramos». El título "Theotókos" sigue siendo usado frecuentemente en himnos de la Iglesia Ortodoxa Oriental.

"Theotókos" es la denominación de un tipo iconográfico de la Virgen en el arte bizantino, en el que aparece sentada en un trono con el Niño Jesús en su regazo, mirando ambos al frente, en actitud hierática. En este modelo iconográfico se basa otro característico del arte románico: la "Maiestas Mariae" (majestad de María o suprema alteza –en los cielos), que a partir del gótico italiano se conoce como "Maestà".

La iconografía de la "Theotokos" incluye en el manto el adorno de tres estrellas, una en cada hombro y otra en el centro de su frente, para enfatizar su virginidad perpetua, indicando que María se mantuvo antes, durante y después del parto virgen. Probablemente también pueda entenderse como referencia a la Santísima Trinidad.

La imagen de María en el arte bizantino se representa con distintos modelos iconográficos, cuyas variaciones responden no tanto a la voluntad de estilo de los pintores sino a cuestiones teológicas. Entre los modelos iconográficos más distintivos están la "Odhigitria", la "Platytera", la "Eleusa", la "Galaktotrophousa", etc.

El compositor argentino Juan Francisco Giacobbe compuso la ""Sonata en Mi para Bandoneón solo op. 123"" bajo el nombre de «Theotòkos» en el año 1982.



</doc>
<doc id="41100" url="https://es.wikipedia.org/wiki?curid=41100" title="Recaredo I">
Recaredo I

Recaredo I (en latín: "Flavius Reccaredus", en gótico: "RekkareÞ") (559-Toledo, 21 de diciembre del año 601) fue rey de los visigodos desde el 586 hasta el 601, cuando murió en Toledo.

Hijo y sucesor de Leovigildo y de su primera mujer, combatió a los francos, a los bizantinos (aún presentes en el litoral andaluz) y a los vascones, y hubo de sofocar varias revueltas de los nobles visigodos.

El hecho más destacado de su reinado se produjo en 589, cuando convocó el III Concilio de Toledo en el que, junto con varios nobles y dignatarios eclesiásticos, abjuró del arrianismo y se convirtió al catolicismo, con lo que llevó a cabo la unificación religiosa entre visigodos e hispanorromanos, a la que aspiraba su padre de forma inversa y quien, al parecer y paradójicamente, le aconsejó esta vía, quedando así sellada la unidad espiritual y territorial del Reino Visigodo de Hispania.

Hermano de Hermenegildo, fue asociado al trono por su padre, lo que levantó las protestas de los nobles visigodos, que vieron en esta acción el intento de institucionalizar el hereditarismo en la monarquía visigoda, caracterizada precisamente por ser electiva.

En 584, en su deseo de emparentar y alcanzar una alianza con los francos, envió embajadores para desposar con Rigunda, hija de Chilperico I, rey de Neustria, y Fredegunda. Una vez acordado el matrimonio, Rigunda fue enviada junto con una espléndida dote, en agosto de 584, al Reino visigodo de Hispania para casarse con Recaredo. Tras un viaje muy azaroso, con multitud de robos que la dejaron sin nada, llegó a Toulouse, donde recibió la noticia del asesinato de su padre Chilperico, con lo que su matrimonio con el rey visigodo ya no tenía sentido para ser una alianza entre reinos. Poco tiempo más tarde, manteniendo el mismo deseo de emparentar con los francos, Recaredo envió una nueva delegación de embajadores para desposar a Clodosinda, hija de Sigeberto I, rey de Austrasia, y Brunegilda, pero las negociaciones fracasaron por razones que se desconocen.

Cuando murió su padre Leovigildo, Recaredo se encontraba en Septimania. Seguramente permaneció allí, pues proseguía la guerra contra Gontrán I de Borgoña, pese a la derrota de este el año anterior. Carcasona fue atacada de nuevo por Desiderio, noble neustrio que ostentaba el cargo de "dux" (Duque) de Aquitania, si bien fue rechazado.

Recaredo, aconsejado por su madrastra Gosuinda, envió mensajeros a Childeberto II de Austrasia pidiendo la paz. Había ya pasado mucho tiempo desde que Gosuinda maltratara a Ingundis y el tratado pudo concertarse con cierta facilidad. Como no existía ningún conflicto pendiente con Neustria, sólo uno de los tres reyes merovingios, Gontrán I de Borgoña, permanecía hostil a los visigodos.

Recaredo envió también mensajeros a Gontrán, pero este se negó a recibirlos y cerró la frontera con Septimania. Los visigodos realizaron diversos ataques en la región de la desembocadura del Ródano.

No mucho después de acceder al trono, el nuevo rey hizo ejecutar al godo Sisberto, responsable de la muerte de su hermano Hermenegildo, aunque probablemente por orden de Leovigildo, pues de no haber tenido la autorización del rey, no hubiera podido desobedecerle tan gravemente y seguir viviendo.

A principios del año 587 Recaredo, que ya debía de tener simpatías católicas, se hizo bautizar en secreto. Desde entonces intentó convencer a los obispos arrianos de que aceptaran la doctrina trinitaria, celebrando tres reuniones: una con los obispos arrianos, a los que animó a reunirse con obispos católicos para discutir los problemas teológicos y determinar cuál era la verdadera fe; una reunión conjunta de obispos católicos y arrianos, con fuertes polémicas entre ambos bandos, y con un Recaredo presionando a favor de los católicos; y finalmente, no habiendo logrado convencer a los arrianos, una reunión con los obispos católicos a los que comunicó que ya había realizado su opción por el catolicismo. Al comunicarles a los obispos católicos su fe, estaban presentes muchos nobles visigodos y al parecer lo siguieron, y hacia la primavera y el verano del 587 las iglesias arrianas fueron expropiadas y entregadas a los católicos.

Tras su conversión, Recaredo envió nuevas embajadas a Childeberto de Austrasia y Gontrán de Borgoña. Ofreció a Childeberto una fuerte suma (diez mil sueldos) y el rey austrasiano (aconsejado por su madre Brunegilda) reconoció que Recaredo no era culpable en absoluto de la muerte de Ingundis, concertándose un tratado de alianza. Incluso Recaredo negoció su enlace con Clodosinda, hermana de Childeberto, pero para concederla Brunegilda pidió el asentimiento de Gontrán. La embajada enviada a Borgoña solicitó este consentimiento pero Gontrán se negó a darlo. Unos meses después, Childeberto manifestó su aprobación del enlace, alegando que le constaba que los visigodos ya eran católicos, pero al parecer no llegó a celebrarse, pues en el 589 el rey ya estaba casado con Baddo, su concubina plebeya goda.

La reacción arriana no se hizo esperar. El obispo arriano de Mérida, Sunna, y los nobles godos Segga y Vagrila (probablemente condes) proyectaron asesinar al obispo local católico, Masona, y al "dux" de Lusitania, Claudio, y alzar a toda la provincia, seguramente proclamando rey a Segga. No sabemos el desarrollo de la conspiración, pero parece ser que algunos nobles godos —que habían accedido a volver al arrianismo— recuperaron su antigua fe y que muchos ciudadanos romanos (supuestamente católicos) se les unieron. Al fracasar el intento de asesinato de Masona, uno de los conjurados, el futuro rey Witerico, seguramente conde, reveló los detalles de la conjura. Claudio sofocó fácilmente el intento. A Segga se le cortaron las manos (castigo que parece haber estado reservado a los usurpadores), se confiscaron sus propiedades y fue desterrado a Galicia. Vagrila se refugió en la hoy Basílica de Santa Eulalia (Mérida), y el rey ordenó confiscar sus propiedades y entregarlas a dicha Iglesia, pero el obispo Masona le perdonó y se las devolvió. A Sunna le hicieron la oferta de recibir otro obispado si se convertía al catolicismo (el obispado arriano de Mérida debió quedar suprimido y el católico ya estaba cubierto, en todo caso el obispado ofrecido no sería metropolitano). Sunna se negó y fue desterrado, marchando a Mauritania, donde propagó el arrianismo hasta su muerte violenta, cuya fecha se desconoce (se supone que alrededor de 600).

Recaredo ordenó la quema de todos los libros y textos arrianos, excluyó a los arrianos de cualquier cargo público y suprimió la organización de la Iglesia arriana, que desapareció en pocos años. Algunos godos fueron obligados a convertirse al catolicismo.

Un segundo intento arriano tuvo como protagonistas al obispo Uldila, cuya sede se desconoce, suponiéndose que pudiera ser el obispo de Toledo, que, aunque nominalmente había abjurado, conservaba sus creencias arrianas, y a la reina Gosuinda, viuda de Atanagildo y Leovigildo. La conspiración fue abortada y Uldila enviado al exilio. Gosuinda murió poco después.

Una tercera conspiración se planeaba desde hacía unos meses: algunos nobles de Septimania preparaban una conjura para derrocar al rey. La encabezaban los condes Granista y Wildigerno y el obispo arriano de Narbona, Athaloc. Los conspiradores pidieron ayuda al rey de Borgoña Gontrán (que era católico).

Las hostilidades con Borgoña, suspendidas desde 586, se reanudaron súbitamente en 589. Las fuerzas borgoñonas al mando de Boso, que habían sido llamadas por los conspiradores, se acercaron a Carcasona, que al parecer fue ocupada, pero fueron derrotadas por fuerzas visigodas al mando de Claudio, "dux" de la provincia lusitana (aparentemente hispanorromano, aunque pudo haber adoptado un nombre romano al convertirse al catolicismo), en las cercanías del río Aude. Los francos dejaron sobre el terreno cinco mil cadáveres y dos mil prisioneros. La derrota fue completa y la seguridad de Septimania quedó asegurada. Parece ser que Granista y Wildigerno murieron en la lucha y que Athaloc falleció poco después de muerte natural.

Poco antes de celebrarse el Concilio de Toledo, Recaredo comunicó que dejaba sin efecto la prohibición para la Iglesia de celebrar sínodos provinciales de obispos.

El 8 de mayo de 589 se inició el III Concilio de Toledo. Recaredo hizo profesión de fe católica y anatematizó a Arrio y sus doctrinas, se atribuyó la conversión del pueblo godo y suevo al catolicismo. Varios obispos arrianos abjuraron públicamente de sus creencias, entre ellos cuatro probablemente suevos: Beccila de Lucus (Lugo), Gardingus de Tute (Tuy), Argiovittus de Portus Cale (Oporto) y Sunnila de Vaceum (Viseo, seguramente de la provincia Lusitana); y otros cuatro godos: Ugnus de Barcino (Barcelona), Fruisclus de Dertosa (Tortosa), Maurila de Palentia (Palencia) y Ubiligisclus de Valentia (Valencia). Sabemos que a la reunión asistió un obispo de Pamplona llamado Loliolo (de nombre godo), pero posteriormente la sede dejó de estar representada hasta el año 684. Las resoluciones del Sínodo arriano de Toledo de 580 fueron condenadas. Asistieron al Concilio setenta y dos obispos, personalmente o mediante delegados (además de los cinco metropolitanos), siendo las figuras principales Leandro de Sevilla (instigador de la conversión de Hermenegildo) y el abad de Servitanum, Eutropio.

Las decisiones del Concilio adquirieron fuerza de ley al publicar el rey un Edicto de confirmación del Concilio. La desobediencia era castigada con graves penas (la confiscación de la mitad de los bienes para los honestiores y el destierro y la pérdida de sus propiedades para los inferiores).

Después del concilio, en el año 590 se organizó una nueva conspiración encabezada por Argimundo, cubiculario del rey y "dux" de una provincia, y por personas influyentes del palacio. Aunque los conjurados pretendían asesinar al rey y proclamar en su lugar a Argimundo, se ignora si intentaban restablecer el arrianismo o actuaban movidos por la ambición de poder. Descubierta la conjura, Argimundo sufrió flagelación, decalvación, amputación de la mano derecha y escarnio público.

Sabemos que, coincidiendo con la conversión al catolicismo, se produjeron algunos cambios sociales entre los godos: su forma de vestir se adaptó a la de los romanos, desapareciendo los tradicionales broches y hebillas, y las propiedades de los difuntos ya no se enterraron con estos,sino que se incineraban.

Hubo negociaciones para casar a Recaredo con las princesas francas Rigunthis y Clodosinda, pero no consta que dichos enlaces llegaran a celebrarse. Poco antes del III Concilio de Toledo (589), Recaredo casó con la plebeya Baddo, Bado o Bada, con quien desde hacía ya algunos años estaba relacionado y había tenido a su hijo Liuva. Su matrimonio fue realizado para complacer a la Iglesia, cuando ya estaba previsto que en dicho Concilio el rey haría profesión pública y solemne de abrazar la fe católica y, por consiguiente, también por parte del reino. De la importancia del acto es prueba el hecho de que Baddo, su esposa, fuese la única reina visigoda que firmó las actas de un Concilio.

Aunque se ignora la fecha de nacimiento del rey, sí se sabe que Hermenegildo, su hermano mayor, había nacido hacia 564, por lo que él mismo hubo de nacer en 565 o después de esta fecha. Por tanto, en 589 contaba como máximo 24 años de edad. Su hermano Hermenegildo se casó en 579, contando, pues, 15 años de edad (la princesa Ingundis tendría unos 13 o 14 años). Las negociaciones para casarlo con Rigunthis se realizaron hacia 582 o 583 cuando contaría poco más de 15 años, y las nuevas negociaciones de las que tenemos noticias son de 587, cuando contaba con poco más de 20 años. El enlace ya debía tener cierta urgencia, no por el hecho de que ya era rey (pues la monarquía no era hereditaria), sino por la edad de Recaredo, que inmediatamente casó con Baddo, su antigua concubina.

Su hijo, Liuva, nació hacia 581 o 582 (en todo caso antes de 584) y era producto de su relación con Baddo antes del matrimonio canónico, extremo apoyado por el texto de la Crónica de San Isidoro, que dice: «"Ignobile quidem matre progenitus, sed virtutum indole in signitus"» (que podría traducirse por «Fue creado por una madre sin duda oscura, pero destacó su carácter virtuoso»).

Hacia 599 hubo una guerra contra los bizantinos, sin que sepamos las causas ni la evolución, aunque parece que la lucha fue favorable a Bizancio, que ocupó diversos territorios (no muy extensos en todo caso). Debió ser tras ello cuando Recaredo solicitó, por mediación del Papa, una copia del tratado concertado con los bizantinos, que fijaba los límites de la provincia de Spania (es posible que el ejemplar de los visigodos se habría perdido y el ejemplar imperial se supone destruido en un incendio seguramente en 564 o 565). El Papa le respondió que desistiera de ello, pues, caso de aparecer el tratado, aun con las presuntas conquistas bizantinas, el reino visigodo resultaría perjudicado, ya que la extensión de la provincia debía ser menor que en el momento del tratado (¿551?, ¿564?). Como sabemos que Leovigildo había recobrado toda o parte de la región del Estrecho (con Asidona), las regiones cercanas a Málaga y Baza (y tal vez la misma Baza) y probablemente el territorio entre Baza y Málaga, las regiones ocupadas por los bizantinos se situarían bien en la zona costera entre Málaga y Cartagena o bien en la zona del Estrecho.

Recaredo murió en Toledo de muerte natural, el 21 de diciembre del año 601, y le sucedió su todavía muy joven hijo Liuva II, del cual distintos autores discrepan sobre su legitimidad.




</doc>
<doc id="41108" url="https://es.wikipedia.org/wiki?curid=41108" title="Presidente de la Junta de Andalucía">
Presidente de la Junta de Andalucía

El presidente de la Junta de Andalucía, según su Estatuto de Autonomía, preside la Junta de Andalucía, cuya actividad dirige, coordina la Administración de la comunidad autónoma, designa y separa a los consejeros y ostenta la suprema representación de Andalucía y la ordinaria del Estado en la comunidad. Se elige por el Parlamento de Andalucía entre sus miembros y es nombrado por el Rey de España.

La Junta de Andalucía se define como un sistema parlamentario, por lo que la Presidencia de esta no es elegida por sufragio universal directo, sino que el Parlamento la elige al comienzo de cada legislatura.

Es la Presidencia del Parlamento quien, tras consultar a los Portavoces de los grupos parlamentarios, propone un candidato/a a jefe/a del Ejecutivo. El candidato o candidata, para ser elegido, debe presentar su programa, y seguidamente obtener mayoría absoluta en primera votación. Si no la consiguiese, se procedería a una segunda votación dos días después de la primera, en la que será suficiente para obtener la presidencia a través de mayoría simple. Si no se diese el caso, se procedería con las demás propuestas de manera similar. Si en dos meses ningún candidato hubiese obtenido la presidencia de la Junta, se disolverá el Parlamento y se convocarán nuevas elecciones.

Una vez elegido el presidente de la Junta por el Parlamento, el cargo se hará oficial por el Rey de España, quien procederá al nombramiento del Presidente. Tras esto, el Presidente procederá a nombrar a los Consejeros y a distribuir entre ellos las funciones ejecutivas.

El Estatuto de Autonomía de Andalucía define las funciones y responsabilidades ante el Parlamento del Presidente de la Junta en el artículo 117 del capítulo tercero del Título IV.

El Presidente es por un lado, Jefe del Ejecutivo andaluz, y por otro, máximo representante de Andalucía de cara tanto al resto de España como al extranjero. De la misma manera, es a la vez representante del Gobierno de la Nación en Andalucía. 

Esta función de representante de la Nación se distingue de la de Delegado del Gobierno, alto funcionario del Estado, que representa al gobierno central y dirige las administraciones y servicios descentralizados del Estado en Andalucía. El Delegado de Gobierno mantiene estrechas relaciones de cooperación y coordinación de la Administración General del Estado y sus Organismos públicos con Andalucía y con sus correspondientes entidades locales.

En tanto que Jefe del Ejecutivo, este dirige y coordina la acción de Gobierno del Consejo de Gobierno de Andalucía, del que nombra y separa a los consejeros, sobre los que puede delegar temporalmente funciones ejecutivas propias. Tiene la autoridad sobre el conjunto de la Administración propia de la Comunidad Autónoma de Andalucía.

Es responsable políticamente ante el Parlamento de Andalucía. Puede convocar consultas populares o referéndums, siempre con la aprobación de las Cortes Generales de España. En caso de infracción o delito en el ejercicio de sus funciones, debe comparecer ante la Sala de lo Penal del Tribunal Supremo. Ante este mismo se le podrá exigir la responsabilidad civil en que hubiera incurrido en Presidente de la Junta con ocasión del ejercicio de su cargo.

Su residencia oficial es el Palacio de San Telmo de Sevilla.

El primer titular fue Rafael Escuredo Rodríguez. Antes de 1982, los presidentes de la primera (1978-1979) y segunda (1979-1982) junta preautonómica fueron Plácido Fernández Viagas y el propio Rafael Escuredo, respectivamente, ambos del PSOE.



</doc>
<doc id="41117" url="https://es.wikipedia.org/wiki?curid=41117" title="Hutu">
Hutu

Hutu es el nombre dado a uno de los tres grupos étnicos que ocupan los países de Burundi, República Democrática del Congo y Ruanda. Los hutus son el grupo mayoritario, ya que el 90% de los ruandeses y el 85% de los burundeses son hutus. Culturalmente se trata de una división artificial, basada más en la clase social que en la etnicidad, dado que no hay diferencias lingüísticas o culturales entre los hutus y los demás grupos étnicos de la zona, principalmente los tutsis. Históricamente, sin embargo, había diferencias físicas, principalmente en la altura media. Los hutus y los tutsis comparten la mayoría la misma religión y lenguaje (la mayoría son católicos y de idioma bantú). Algunos estudiosos señalan también el importante papel que tienen los colonizadores belgas en crear la idea de una raza hutu y una raza tutsi.

Los hutus llegaron a la región de los Grandes Lagos de África alrededor del siglo I d. C., desplazando al grupo étnico de pigmeos llamados twa (en plural batwa). Los hutus eran agricultores y dominaron la zona con una serie de pequeños reinos hasta el siglo XV d. C.. Se cree que a partir de esa época entraron los tutsis en la zona desde Etiopía y conquistaron a los hutus. La monarquía tutsi sobrevivió hasta el fin de la era colonial en los años cincuenta, usando y codificando los gobernantes belgas la división étnica para apoyar su dominio. Tras la caída de la monarquía tutsi, la zona fue dividida en Ruanda y Burundi en el año de 1962. Los tutsis, no obstante, permanecieron dominantes en Burundi mientras que los hutus ganaron un cierto grado de control en Ruanda.

Los hutus, los tutsis y los batwa hablan el mismo idioma. Algunos estudiosos mantienen que los hutus y los tutsis realmente no son razas o pueblos diferentes, sino son diferentes castas. 

Si un tutsi y un hutu tienen descendencia común el descendiente es ascendido socialmente y es considerado tutsi.



</doc>
<doc id="41119" url="https://es.wikipedia.org/wiki?curid=41119" title="Twa">
Twa

Los twa (en plural: batwa) son un pueblo pigmeo, de África Central. Son los más antiguos habitantes registrados en el área del continente africano que ahora comprende los territorios de Ruanda y Burundi.

Cuando los hutus, un pueblo de origen bantú, llegaron a la región, dominaron a los twa y redujeron su población. Alrededor del siglo XV d. C., los tutsis, un pueblo nilótico, llegaron posiblemente de Etiopía y dominaron tanto a los twa como a los hutu.
Los batwa (plural de twa) viven principalmente en zonas rurales e inaccesibles y están marginados de las modernas sociedades africanas. Se dedican a la alfarería y a la agricultura de subsistencia. Viven en pequeños asentamientos dispersos en parajes apartados, en chozas de adobe y caña llamadas "poto-poto". Son de pequeña estatura como todos los pigmeos y solo se relacionan entre ellos.
Son miembros de la UNPO.
Según un documental sobre gorilas, está tribu ha sido expulsada de sus pequeños asentamientos para proteger a los gorilas en peligro de extinción. Esto puede implicar la extinción de su cultura y forma de vida ancestral.



</doc>
<doc id="41131" url="https://es.wikipedia.org/wiki?curid=41131" title="Ahuízotl (criatura)">
Ahuízotl (criatura)

El ahuízotl (náhuatl, "āhuitzotl") es una criatura legendaria de la mitología mexica.

La descripción del animal fue hecha por los informantes de Fray Bernardino de Sahagún y es la siguiente:

Disponía también de una cola larguísima rematada con una mano con la que atrapaba a todo aquel que se acercara a las charcas y cursos de agua donde habitaba y lo ahogaba.

Al ser un nombre poco común los cronistas pusieron poca atención en traducirlo, lo más general es encontrar su significado como "nutria" o "perro de aguas". El historiador Enrique Vela lo analiza desde un punto etimológico y propone la traducción como "el espinoso del agua"; que sería su sentido original pero en el uso diario debió referirse exclusivamente para nombrar al animal. Se ha propuesto que podría tratarse de un animal hoy extinto del Lago de Texcoco, emparentado con las nutrias, y por su rareza, mitificado tanto en hábitos como aspecto.

El ataque del ahuízotl, que estaba al servicio de las divinidades de la lluvia, suponía que los dioses habían elegido a la víctima y sus almas eran portadas al paraíso. Los cuerpos de los infortunados, que sólo podían ser tocados por sacerdotes debido al interés de los dioses por sus almas, siempre aparecían a los pocos días del ahogamiento y a todos ellos, la bestia les había arrancado los ojos, las uñas y los dientes en el interior de su gruta subacuática. Generalmente, el ahuízotl atraía a los humanos, especialmente a los pescadores, llorando como un bebé desde las orillas y a veces provocaba remolinos que expulsaban fuera del agua a peces y ranas.

Fue representado en la serie de televisión como el villano de un libro de aventuras.

En la segunda temporada de la serie mitológica mexicana El Diablero, el ahuízotl es un poderoso demonio de nivel 3 que asesina a sus víctimas para alimentar a otro ser mitológico y convertirlo en un ser malvado que cerrara la última puerta a los ángeles.




</doc>
<doc id="41136" url="https://es.wikipedia.org/wiki?curid=41136" title="Tutsi">
Tutsi

Tutsi se refiere a una clase social o pueblo de la región de los Grandes Lagos de África. Históricamente, a menudo se les llamaba watutsi, watusi, wahuma, wahima o wahinda. Los tutsis forman un subgrupo de los pueblos de Banyarwanda y Barundi, que residen principalmente en Ruanda y Burundi, pero con poblaciones significativas que también se encuentran en Uganda y Tanzania. 

Los tutsis son la segunda división de población más grande entre los tres grupos más grandes en Ruanda y Burundi; los otros dos son el hutu (el más grande) y el twa (el más pequeño). Un pequeño número de personas de Hema y Kiga también viven cerca de los tutsis en Ruanda. Los tutsis del norte que residen en Ruanda se llaman Ruguru (Banyaruguru), mientras que los tutsis del sur que viven en Burundi se conocen como Hima, los Banyamulenge no tienen un territorio propio.

Las definiciones de "Hutu" y "Tutsi" ha cambiado dependiendo del tiempo y el lugar. Las estructuras sociales no se mantuvieron estables en Ruanda, incluso durante la época colonial bajo el gobierno belga. La aristocracia o élite tutsi se distinguía de los plebeyos tutsis y los hutus ricos a menudo eran indistinguibles de los tutsis de clase alta.

Bajo la colonia de Ruanda-Urundi, los belgas intentaron aprovecharse de las estructuras políticas nativas mediante la introducción de una política de gobierno indirecto. Al hacerlo, la autoridad de lo que había sido el Reino de Ruanda se extendió a las áreas que previamente habían sido autónomas. Siguiendo lo que los belgas consideraban el orden consagrado de la sociedad, solo los tutsis tenían permitido asistir a escuelas secundarias o unirse a la administración colonial. Las autoridades belgas no usaron ningún método etnográfico real para determinar quien era tutsi, sino que simplemente realizaron un censo y expidieron documentos de identidad que definían como tutsi a quienes poseían 10 o más vacas y como hutu a los que tenían menos.

Se dice que los tutsis llegaron a la región de los Grandes Lagos desde el Cuerno de África.

Algunos investigadores consideran que los tutsis son de origen nilótico, aunque no hablan una lengua nilótica y han vivido en las áreas donde se encuentran durante al menos 400 años, lo que ha llevado a un considerable mestizaje con los hutus en el área. Debido a la historia de la mezcla entre hutus y tutsis, el consenso entre los etnógrafos e historiadores es que los hutus y los tutsis no pueden ser considerados como grupos étnicos distintos.

El pueblo tutsi es uno de los tres pueblos nativos de las naciones del África Central, Ruanda y Burundi.

En el idioma kinyarwanda el término "tutsi" es de número indeterminado: el singular es "batutsi" (un solo tutsi), mientras que el plural (más de un tutsi) es tutsis o "watutsi" (este último es el origen del baile "watusi").

Los tutsis son el último pueblo que llegó a asentarse en Ruanda y Burundi. Los primeros habitantes nativos de esta región era el pueblo twa o "watwa" (en plural "batwa"), un pueblo pigmeo. Después llegaron los hutus ("wahutu"), un pueblo bantú y dominaron a los batwa. Más tarde, los tutsis inmigraron y dominaron tanto a los hutus como a los batwa, estableciendo diversos reinos dominados por ellos. Los tutsis eran pastores, lo que les permitió tener éxito políticamente. 

Un aspecto interesante de estos tres grupos raciales es su estatura. Una persona twa es tradicionalmente baja, los hutus tienen una estatura media y los tutsis son altos; aunque en tiempos modernos el cruce entre estos grupos está reduciendo estas diferencias.

Las desigualdades entre los derechos de los grupos raciales no eran tan extremas, pero eran importantes. Para los tutsis, los hutus eran básicamente considerados como trabajadores. Si un tutsi asesinaba a un hutu, los del linaje del hutu podían matar al tutsi en venganza, pero si un hutu asesinaba a un tutsi, los del linaje del tutsi podían matar al hutu y a otro miembro de su familia en venganza.

En años recientes, tanto Ruanda como Burundi han sido, al menos en teoría, naciones democráticas con los mismos derechos pactados para todos. Sin embargo, los tutsis mantuvieron la mayoría del poder (dado por los belgas que los consideraban una raza superior), creando un gran resentimiento por parte de los hutus, que cuando obtuvieron el poder democráticamente se creó un clima de desconfianza y venganza que llevó al genocidio de la población tutsi en 1994, donde más de un 75 % (alrededor de 1 200 000 personas) de los tutsis ruandeses fueron exterminados (llamado genéricamente genocidio de Ruanda). 

Los hutus, los tutsis y los batwa hablan el mismo idioma. Algunos estudiosos mantienen que los hutus y los tutsis realmente no son razas o pueblos diferentes, sino diferentes castas. Parece ser que fueron los colonizadores belgas quienes crearon esta noción de dos razas diferentes.

Si un tutsi y un hutu tienen descendencia común el descendiente es considerado de la etnia paterna.



</doc>
<doc id="41140" url="https://es.wikipedia.org/wiki?curid=41140" title="Pigmeo">
Pigmeo

Pigmeo (del griego πυγμαῖος, "pygmaios", ‘del tamaño de un puño’) es el término usado para referirse a una serie de grupos humanos cazadores-recolectores que viven en selvas ecuatoriales africanas y que se caracterizan por su baja estatura: los hombres miden menos de 1,5 metros de media.

Los pigmeos se encuentran situados en el centro de África (región del Congo). A veces se llama también pigmeos a los aborígenes de menor talla del sureste de Asia y otras regiones. Los grupos más estudiados son los mbuti de la selva de Ituri en la República Democrática del Congo, que fueron el tema de un estudio de Colin Turnbull ("The Forest People", 1962). Entre los demás grupos africanos están los aka, baka, binga, efé, gok y twa.

Cazan con redes, flechas y jabalinas a antílopes, monos, cerdos, aves y otros animales, recolectan frutas, tubérculos y miel y además practican intercambios con los pueblos vecinos y algunos trabajan para esos vecinos, de quienes en la mayoría de los casos han adoptado el idioma. Existen algunas palabras comunes para las tribus pigmeas africanas, aún las más separadas, lo que indica que en el pasado podrían haber tenido una lengua común. Una de esas palabras es el nombre del espíritu de la selva, "Jengi".

Sus primeras referencias históricas las recoge Heródoto de Halicarnaso en su libro 2, "Euterpe", con la fábula de Etearco.

Tras pruebas genéticas, se estima que divergieron de los demás grupos africanos muy antiguamente: hace 60.000 años, adaptándose a la vida en la selva ecuatorial africana. Esta sería la divergencia humana más antigua luego de la de los khoisán. Así mismo la diferencia entre los pigmeos del Este con los del Oeste sería de unos 20.000 años.

En la República del Congo se estima que los pigmeos babongo y babinga constituyen un 10% (unos 300.000), aunque no hay datos oficiales que censen a la población indígena.

Los grupos más conocidos son los pueblos mbuti y twa hacia el Este y los babinga y bongo hacia el Oeste, pudiéndose agrupar del siguiente modo (acepciones en plural van en letra cursiva):

Si bien antropológicamente se usa el término "pigmeo" para referirse únicamente a los nativos cazadores-recolectores del África Central, el uso popular extiende ocasionalmente su significado a otras poblaciones de aspecto físico semejante por su baja estatura y piel oscura. Sin embargo no hay entre ellos mayor relación cultural, geográfica, lingüística ni cercanía genética. Estos pueblos serían:


Los pigmeos africanos son particularmente conocidos por su música vocal, habitualmente caracterizada por una improvisación comunal de denso contrapunto, polifonía y uso del yodel. Simha Arom dice que el nivel de complejidad polifónica de la música de los pigmeos fue alcanzada en Europa en el siglo XIV, aunque la cultura pigmea es no escrita y antigua, siendo algunos grupos pigmeos las primeras culturas conocidas en algunas zonas de África. La música penetra la vida diaria y hay canciones para el entretenimiento así como para eventos y actividades específicos.

Formalmente, la música consiste en, como mucho, sólo cuatro partes y puede ser descrita como un «ostinato» con variaciones o similar a un "passacaglia", en que es cíclica. De hecho, está basada en repetición de periodos de igual longitud, que cada cantor divide usando diferentes figuras rítmicas específicas de diferentes repertorios y canciones. Este interesante caso de etnomusicología y etnomatemáticas crea una superficie detallada de variaciones sin fin de no sólo el mismo periodo repetido, sino de la misma pieza de música. Como en algunos "gamelan" balineses, estos patrones están basados en un superpatrón que nunca es oído. Los pigmeos mismos no aprenden su música o piensan en ella en este marco teórico, sino que la aprenden al crecer.

Hay una relación directa entre el uso de polifonía y de yodel, con la asociación con otros pueblos africanos no pigmeos granjeros y agricultores; por lo que los pigmeos pueden clasificarse artísticamente en dos grupos:

En 2003, Sinafasi Makelo, un representante de los pigmeos mbuti, contó al Foro de Pueblos Indígenas de la ONU que durante la guerra civil en el Congo su pueblo había sido cazado y comido como si hubieran sido animales salvajes. En la provincia vecina de Kivu del Norte se dieron casos de canibalismo cometido por un grupo conocido como “Les effaceurs” (“los borradores”), que querían eliminar a toda la gente para abrir el territorio a la explotación minera. Ambos bandos en la guerra los consideraban “subhumanos” y algunos decían que su carne podía conferir poderes mágicos. Makelo pidió al Consejo de Seguridad de la ONU que reconociera el canibalismo como un crimen contra la humanidad y como un acto de genocidio. Según el Grupo Internacional de Derechos de Minorías hay pruebas extensas de matanzas masivas, canibalismo y violencia contra las mujeres pigmeas, y esta organización ha instado con insistencia a la Corte Penal Internacional a investigar una campaña de exterminación contra los pigmeos. Aunque han sido atacados prácticamente por todos los grupos armados, mucha de la violencia contra los pigmeos está atribuida al rebelde Movimiento para la Liberación del Congo, que es parte del gobierno de transición y que todavía controla muchas partes del norte, y sus aliados.

En la República del Congo, donde los pigmeos representan un 10 % de la población, muchos viven como esclavos de dueños bantúes. La nación está profundamente estratificada entre estos grupos étnicos, los mayores del país. Aunque los pigmeos son los principales responsables de la caza, pesca y del trabajo manual en las comunidades de la selva, tanto pigmeos como bantúes dicen que se les paga según el antojo del maestro: con cigarrillos, ropa usada o incluso nada. Como resultado de la presión de UNICEF y activistas de derechos humanos, una ley que garantice una protección especial a los pigmeos está ahora esperando el voto del parlamento de aquel país.

Raj James Sheshardi, de la Universidad Americana, realizó un estudio sobre los pigmeos de África y concluyó que la deforestación había afectado gravemente a su vida cotidiana. Hoy en día la cultura pigmea está amenazada por las fuerzas del cambio político y económico. Recientemente esto se ha hecho visible en el conflicto abierto por los recursos de la selva tropical, una batalla que los pigmeos están perdiendo.

Históricamente los pigmeos siempre han sido considerados inferiores por las autoridades coloniales y los pueblos bantúes que viven en las ciudades. Esto ha producido una discriminación atroz. Un ejemplo temprano se produjo cuando las autoridades coloniales belgas capturaron a niños pigmeos y los enviaron a parques zoológicos de toda Europa, e incluso a la exposición internacional de Estados Unidos en 1904. Muchas veces los pigmeos son expulsados y hacen los trabajos peor pagados. Muchos estados africanos no consideran a los pigmeos como ciudadanos y les niegan carnés de identidad, títulos de propiedad, asistencia sanitaria y educación adecuada. La política de los gobiernos y las corporaciones multinacionales involucradas en la deforestación masiva han agravado este problema, porque han expulsado a los pigmeos de su tierra ancestral y muchas veces los han trasladado a pueblos y ciudades donde muchas veces son marginalizados, empobrecidos y brutalizados. Allí trabajan en empleos ocasionales o en granjas comerciales. Una de las consecuencias más dramáticas de esta migración a las ciudades ha sido el incremento de la tasa de VIH/SIDA entre los pigmeos. Estudios realizados en Camerún y la República Democrática del Congo durante los años 1980 y 1990 mostraron una preponderancia más baja de HIV/SIDA entre poblaciones pigmeas que entre poblaciones vecinas, pero últimamente ha aumentado. Un estudio averiguó que la preponderancia de HIV entre los pigmeos baka en el este de Camerún ha aumentado de un 0,7 % en 1993 a un 4 % en 2003.

La explotación sexual de mujeres indígenas se ha convertido en un hecho común. La tala ha reforzado el sexo comercial, porque muchas veces viven grupos grandes de trabajadores en campamentos cerca de comunidades pigmeas. Hay una creencia bastante común en esta parte de África que dice que tener sexo con una mujer pigmea tiene el poder de limpiar al hombre de VIH/SIDA. Este mito expone a estas mujeres a un gran riesgo.

A pesar de estos riesgos, en general las poblaciones pigmeas tienen poco acceso a servicios sanitarios e información sobre el VIH/SIDA. Según fPcN-Global.org, en 2006 la revista médica británica "The Lancet" publicó un estudio que mostró que los twa tenían sistemáticamente menos acceso a la asistencia sanitaria que comunidades vecinas. Según este informe, incluso donde existen instalaciones sanitarias, muchos no acuden a ellas, porque no pueden pagar las consultas y medicinas, no tienen los documentos o carnés de identidad que necesitan para viajar o para obtener tratamiento en un hospital o son sometidos a un tratamiento humillante y discriminatorio.

Hoy en día viven todavía unos 500 000 pigmeos en la selva tropical de África Central. Esta población está disminuyendo rápidamente, porque la pobreza, el matrimonio con los bantúes, la occidentalización y la deforestación destruyen su forma de vida, cultura e identidad étnica.




</doc>
<doc id="41144" url="https://es.wikipedia.org/wiki?curid=41144" title="Estatura">
Estatura

La estatura o talla se considera la "altura humana", la distancia medida normalmente desde pies a cabeza, en (centímetros) o (metros) , (pies) o (pulgadas) en el sistema anglosajón, estando la persona erguida/parada, generalmente descalzo. La estatura de cada persona llega a variar de acuerdo con la (genética) y la (nutrición) aunque también se debe a factores medioambientales del individuos antes de la adultez (ejercicio físico, estado anímico, etc.). 

El ser humano adulto contemporáneo puede medir, como media, entre 1,5 a 1,9 metros. La especie humana posee un notorio dimorfismo sexual en el nivel anatómico, siendo los hombres adultos más altos y más pesados que las mujeres en promedio, aunque se ha notado una «tendencia secular» al aumento de las tallas en ambos sexos (especialmente durante el siglo XX). El varón adulto puede medir, como media global, entre 1,65 a 1,8 m.; y la mujer adulta, como media, entre 1,55 a 1,65 m.
Normalmente en los países del norte de Europa, como los Países Bajos o Letonia, se observan a los adultos tienen mayor estatura en mundo, con un promedio mayor al 1,80 en el hombre, y la mujer cerca del 1,70.

La estatura media, estándar o promedio, depende del sexo de la población en determinada región y/o raza, además de la edad en el caso de los individuos en edad de crecimiento. Cuando las poblaciones comparten antecedentes genéticos y factores ambientales, se puede determinar la estatura media del grupo poblacional examinado. Actualmente los habitantes de Europa y América del Norte son los más altos del mundo (considerados en su mayoría países de primer mundo), seguidos de los latinoamericanos, asiáticos y africanos.

Diversos factores como el tipo de alimentación, las enfermedades o problemas de salud como la obesidad, la intensidad o frecuencia de ejercicios físicos, exposición a la contaminación ambiental u otros contaminantes, el clima y hasta el estado emocional del individuo puede afectar en su crecimiento antes de la edad adulta. Se cree que la estatura está fuertemente influenciada por la nutrición materna durante el embarazo, y la nutrición del niño durante la infancia, aunque los grandes "estirones" de estatura se dan durante la infancia y la pubertad. La estatura de los padres generalmente determinan la estatura aproximada del hijo. Si ambos padres poseen una estatura promedio, probablemente el hijo tendrá una estatura promedio también, a menos que uno de ellos sea más alto del promedio, en este caso probablemente el hijo tendría una estatura levemente superior al promedio.

La altura promedio para cada sexo dentro de una población es significativamente diferente, con los varones adultos teniendo un promedio más alto que las mujeres adultas. Se calcula que el hombre es, en promedio, de 6 a 10 cm más alto que la mujer.
Esta diferencia puede atribuirse a diferencias de sexo cromosómico, XY (varón) en contraposición a XX (mujer). Las mujeres generalmente alcanzan su mayor altura a una edad más temprana que los hombres; alrededor de los 14-16 años, mientras que los varones alrededor de los 18-20 años. El crecimiento se detiene cuando los huesos largos dejan de prolongarse, lo que ocurre con el cierre de las placas epifisarias.

La estatura sigue una distribución que se modela por una campana de Gauss. Según criterios estadísticos se considera que un individuo es de estatura normal si se encuentra en un rango de ±2 desviaciones estándar (DE) respecto del promedio, de estatura alta si supera el promedio en más de 2 DE y de estatura baja si es inferior al promedio por más de 2 DE. Debido a esta definición, siempre habrá en torno a un 3% de la población de talla baja y otro 3% de talla alta. Cuando la estatura del individuo está más allá de 3 DE por encima o por debajo del promedio, se habla respectivamente de gigantismo y enanismo, que son condiciones médicas debido a genes específicos o de anormalidades endocrinas.

En las regiones de pobreza extrema o de prolongada guerra, los factores ambientales así como la desnutrición durante la infancia y la adolescencia pueden resultar en marcadas reducciones en la estatura ya como adultos, incluso sin la presencia de cualquier condición médica o enfermedad. También las malas costumbres de la actualidad, como el sedentarismo o la obesidad, pueden afectar la estatura final del niño en su adultez. 

Normalmente en la tercera edad, las personas ancianas sufren una leve reducción en su estatura, que en algunos individuos puede comenzar ya en la mediana edad. Esta disminución en la estatura se debe a factores tales como la disminución de la altura de los discos intervertebrales debido a la desecación, la atrofia de los tejidos blandos, enfermedades como la osteoporosis y los cambios de postura secundarios a la enfermedad degenerativa.

A lo largo del tiempo, en especial antes del siglo XIX, la estatura promedio era muy variable, en ocasiones aumentaba y al poco tiempo después se reducía, debido a los constantes problemas sociales y económicos de la época (hambruna, mala alimentación, mala atención médica, guerras, enfermedades, emigraciones, etc.). Según estudios a través de esqueletos antiguos, no mostraron diferencias significativas en la estatura desde la Edad de Piedra hasta principios del año 1800. Pero en los últimos siglos, el promedio de la estatura fue aumentando considerablemente debido a la mejor calidad de vida, entre otras cosas.

Entre los siglos XVIII y XIX, las personas de ascendencia europea que vivían en América del Norte eran mucho más altas que las que vivían en Europa y eran las más altas del mundo. La población indígena americana originaria de las llanuras también se encontraba entre las poblaciones más altas del mundo en aquel momento.

La estatura promedio de los adultos varones hace unos 100 años (1914) rondaban entre el 1,60 a 1,70 metros, mientras el de las mujeres alrededor de los 1,50 metros. Hoy día los adultos humanos miden unos 10 centímetros más en promedio que sus antecesores de hace cien años.

En muchos países a lo largo del siglo XX, aumentó la estatura media producida por una mejor alimentación, atención médica y por ende mejor calidad de vida. Por ejemplo, en los Países Bajos los varones en tiempos de Van Gogh (finales del siglo XIX) medían un promedio de 1,67 m, mientras que según estudios para comienzos de este siglo XXI, medían en promedio 1.82 m (15 cm. más). Sin embargo, algunos países se "estancaron", como es el caso de Estados Unidos, que a finales del siglo XIX los varones eran uno de los más altos del mundo, con 1,71 m. Hoy día los estadounidenses miden en promedio 1,77 m. (sólo 6 cm. más), menos que otros países desarrollados de Europa, que se cree por principalmente por la mala alimentación y el sedentarismo (muy común en los últimos años). Algunos países africanos como Uganda inclusive llegaron a reducir la estatura media de sus habitantes, debido a la extrema pobreza, colapso de servicios, aumento de población, escasez, etc. 

Aunque se cree que la alta estatura es un indicador de buena salud, en un modo general, la alta estatura no puede ser atribuida como mayor longevidad y mejor salud, ya que difiere de diversos factores, generalmente según el entorno.

En el extremo, ser excesivamente alto puede causar diversos problemas médicos, como problemas cardiovasculares, debido a la mayor carga en el corazón para irrigar al cuerpo, la mala postura y el aumento de riesgo de cáncer. Por otra parte, ser excesivamente bajo repercute en la baja autoestima, y en la incapacidad de realizar actividades destinadas a personas de estatura normal, entre otros problemas. Las mujeres de menos de 1.5 m. pueden tener una pelvis pequeña, lo que puede provocar complicaciones durante el parto.

La estatura puede ser, en algunos casos, un requisito físico para poder acceder a determinados deportes.
En la gimnasia es necesario tener una estatura más baja, pues se requiere mayor movilidad y musculatura, especialmente en las barras. Por otro lado, en el baloncesto los jugadores suelen tener una estatura superior a la media de la población general para poder alcanzar con mayor facilidad el aro de baloncesto.

Esta tabla publicada en 2014, indica la estatura media según el sexo en diversos países. Abarca a personas nacidas entre los años 1896 y 1996, según diversos estudios en conjunto, como el Imperial College London de Gran Bretaña. 

Según este estudio, la estatura promedio del ser humano en el mundo es de 1,65 metros aproximadamente (sin diferenciar el sexo masculino del femenino). Los hombres más altos viven en Países Bajos (1,82 metros), mientras que los más bajos viven en Timor Oriental (1,60 metros). Por otra parte, las mujeres más altas viven en Letonia (1,70 metros), y las más bajas en Guatemala (1,49 metros).



</doc>
<doc id="41147" url="https://es.wikipedia.org/wiki?curid=41147" title="Kiñaruanda">
Kiñaruanda

El kinyarwanda, kinyaruanda, ruanda o kiñaruanda es la principal lengua hablada en Ruanda, por cerca de nueve millones de personas. También se habla en las zonas cercanas de la República Democrática del Congo, Burundi, Uganda y Tanzania. Está emparentado con el idioma kirundi hablado en el vecino país de Burundi y el kiha o ha, hablado en el oeste de Tanzania. Por su parecido, ya que son lenguas mutuamente inteligibles es posible que entiendan el kinyaruanda unos 20 millones de personas. Está clasificada como un idioma bantú y tiene varios dialectos, entre ellos el ikireera, el aluciga, el ururashi y el ikinyanduga, en el que se basa el kinyaruanda normativo.

Ejemplos de traducciones




</doc>
<doc id="41151" url="https://es.wikipedia.org/wiki?curid=41151" title="Brigadas Internacionales">
Brigadas Internacionales

Las Brigadas Internacionales fueron unidades militares compuestas por voluntarios extranjeros de más de cincuenta países que participaron en la Guerra civil española junto al Ejército Republicano, enfrentándose al bando sublevado contra el gobierno de la Segunda República.

Según los datos manejados por estudios realizados en Estados Unidos por el Batallón Abraham Lincoln y por el historiador Andreu Castells, llegaron a participar un total de 59 380 brigadistas extranjeros; posteriormente, Hugh Thomas rebajaría la cifra de combatientes a 40 000, mientras que las más recientes investigaciones de Michael Lefebvre y Rémi Skoutelsky dan una cifra de casi 35 000. De estos, murieron al menos 15 000; al mismo tiempo los internacionales nunca sobrepasaron el número de 20 000 hombres presentes en los frentes en un momento determinado la guerra. La nacionalidad más numerosa fue siempre la francesa, con una cifra cercana a los 10 000 hombres, buena parte de ellos de la zona de París. La mayoría no eran soldados, sino trabajadores reclutados voluntariamente por los partidos comunistas (Comintern) o veteranos de la Primera Guerra Mundial.

Su base se encontraba en la base aérea de Los Llanos, en Albacete. Las Brigadas participaron en la defensa de Madrid en 1936, las batallas del Jarama, Guadalajara, Brunete, Belchite, Teruel, Aragón y el Ebro, siendo retiradas a partir del 23 de septiembre de 1938, a fin de modificar la posición ante la intervención extranjera del Comité de No Intervención.

Las Brigadas Internacionales no fueron, al contrario de lo que se suele creer, ni los primeros ni los únicos voluntarios extranjeros que partieron a luchar a España en favor de la República. Ya antes de su formación (en octubre de 1936) había en la Península un número, aunque no muy alto, de combatientes extranjeros, que prácticamente desde el día de la sublevación estaban participando en la contienda. Algunos de ellos ya residían en España antes del golpe del 18 de julio y procedían mayoritariamente de países con gobiernos fascistas (o pseudofascistas), de donde se habían visto obligados a exiliarse por su militancia progresista, socialista, comunista o anarquista. Por esta razón, los dos principales países de origen de estos primeros voluntarios extranjeros fueron Alemania e Italia. De este primer grupo de combatientes extranjeros que ya vivían en España al estallar la guerra se encontraban, como dos de los más conocidos, el novelista francés André Malraux y el socialista y antifascista italiano Fernando De Rosa Lenccini, que años antes había atentado contra Humberto II de Italia.

También hubo otro grupo de extranjeros que a partir del 18 de julio fue llegando a España por sus propios medios y se incorporó al bando republicano por simple simpatía política hacia el Frente Popular. Pero si es difícil dar cifras sobre los soldados que conformaron las Brigadas Internacionales, mucho más aún, por la inexistencia de documentos oficiales, lo es cifrar a los extranjeros que llegaron antes de octubre de 1936.

En tercer lugar, es destacable la incorporación a las filas del bando republicano de los participantes en las olimpiadas populares. Esta competición, organizada por grupos políticos de izquierda, se estaba celebrando en Barcelona en el verano de 1936 como contrapartida a las olimpiadas oficiales que se disputaban en Berlín bajo el gobierno de Adolf Hitler, y en ella tomaban parte deportistas de diversos países del mundo. Muchos de estos atletas se sumaron a las luchas callejeras de Barcelona, participaron en el levantamiento de barricadas y en la ocupación del Hotel Colón. La mayoría de los participantes, cuyo número oscilaba entre 174 y 300, regresó a sus respectivos países el día 24 de ese mismo mes de julio, tras haber sido protagonistas durante la primera semana de la guerra. Precisamente, el atleta austriaco Mechter, que murió durante el 19 de julio, es considerado el primer brigadista caído en combate.

Las unidades formadas por estos primeros voluntarios extranjeros se bautizaron con nombres de militares izquierdistas o progresistas del siglo anterior, como Walery Wroblewski, comandante en la Comuna de París, o de figuras políticas de mucho prestigio, como el socialista inglés Tom Mann. En agosto de 1936, entró en combate el batallón Comuna de París, compuesto principalmente por franceses y belgas al mando de Jules Dumont, en la batalla de Irún.

Muchos de los combatientes que conformaban estas unidades voluntarias espontáneas se integraron luego en las Brigadas Internacionales, pero otros muchos, por diversas circunstancias, permanecieron al margen de ellas y combatieron en otras unidades del Ejército Popular de la República. Numerosos extranjeros no se integraron en las brigadas debido, principalmente, a discrepancias políticas, ya que las Brigadas empezaron a ser organizadas y promovidas por el Partido Comunista Francés (de donde salieron los primeros oficiales brigadistas), lo cual causaba que extranjeros de filiación socialistas, anarquistas, o marxistas ajenos al comunismo, prefirieran enrolarse en otras unidades.

En algunos de los casos, algunos extranjeros lucharían integrándose en unidades del POUM o de otras organizaciones de izquierdas disidentes de la Internacional Comunista. Relacionado con esta cuestión, y tras las jornadas de mayo de 1937 en Barcelona, el gobierno republicano ordenó el 19 de junio de 1937, por un decreto implementado por Vicente Rojo Lluch siguiendo órdenes del entonces ministro de Defensa Indalecio Prieto ""que todos los extranjeros que prestan servicio al Ejército, quedaban encuadrados en las Brigadas Internacionales"." Esta orden no fue cumplida por muchos soldados extranjeros, que lucharon hasta el final de la guerra en unidades ajenas a las de los brigadistas.

Las Brigadas Internacionales no se formaron espontáneamente como sostuvo la Internacional Comunista, sino que fue ella quien las organizó (a partir de la decisión tomada por su Secretariado el 18 de septiembre de 1936 en Moscú, a instancias de Stalin), además del reclutamiento y de los aspectos organizativos se encargaron dirigentes del Partido Comunista Francés, encabezados por André Marty. Pero la inmensa mayoría de sus integrantes sí fueron verdaderamente "voluntarios de la libertad" (como decía la propaganda republicana) llegados desde países con gobiernos fascistas o autoritarios, como Alemania, Italia o Polonia, pero también de países democráticos como Francia (que aportó el mayor número de brigadistas, unos 10 000), Reino Unido o Estados Unidos (con el famoso batallón Abraham Lincoln que llegó a finales de 1936 y cuya entrada en combate se produjo en la batalla del Jarama en febrero de 1937). Así pues, las Brigadas Internacionales no eran el "Ejército de la Comintern", un instrumento de la política de Stalin, como aseguraba la propaganda del bando sublevado. Un trabajador inglés que se enroló en las Brigadas Internacionales le explicó así en una carta a su hija por qué había venido a combatir a España:
El Gobierno de la República, presidido por el socialista Francisco Largo Caballero desde el 4 de septiembre de 1936, en principio fue reacio a aceptar la propuesta, considerando que las Brigadas estaban siendo formadas y regidas por la Comintern y su partido afiliado en España, el PCE. De hecho, grupos anarquistas bajo la dirección de la FAI obstaculizaron la entrada de voluntarios antifascistas en la frontera, llegando a tener retenidos a más de mil brigadistas, como llegó a reconocer el dirigente faísta Diego Abad de Santillán en su libro de memorias "Por qué perdimos la guerra". La opinión de estos sectores reticentes dentro del bando republicano cambiaría en octubre, cuando el avance de los sublevados hacia Madrid evidenció la crítica situación militar de la República, lo cual hacía urgente reclutar la mayor cantidad posible de soldados.

Las movilizaciones en favor del reclutamiento para las Brigadas Internacionales se extendieron por toda Europa y luego por Estados Unidos, pero en países como Alemania e Italia se identificaron como el primer paso para combatir al fascismo y al nazismo, que ya habían establecido dictaduras en ambos Estados. Los primeros brigadistas llegaron a Albacete el 14 de octubre de 1936. Las primeras Brigadas formadas (XI, XII y XIII) estaban compuestas mayoritariamente por franceses, belgas, italianos y alemanes voluntarios. Dentro de cada brigada se constituyeron batallones, generalmente de miembros de la misma nacionalidad para facilitar las comunicaciones entre los integrantes.

El 22 de octubre el gobierno aprobó la constitución de las Brigadas Internacionales, siendo designado como organizador de las mismas el republicano Diego Martínez Barrio. Como presidente de la Junta Delegada del Gobierno para el abastecimiento de víveres y pertrechos, su labor de coordinación y logística fue de suma importancia, estableciendo el entonces presidente de las Cortes y vicepresidente de la República su residencia en Albacete durante un tiempo para desarrollar esta labor.

La sede internacional de reclutamiento se estableció en París bajo la dirección del Partido Comunista de la Unión Soviética y el Partido Comunista Francés. Desde el gobierno republicano se tramitaba la documentación necesaria para el recluta, se hacían llegar estos documentos a París, y desde allí se embarcaba a los voluntarios que llegaban vía ferrocarril a Barcelona desde toda Europa. Posteriormente, el gobierno los remitía a Albacete, donde la República había establecido el cuartel general y el centro de entrenamiento de las Brigadas Internacionales.

El 23 de octubre, Francisco Largo Caballero crea la "División Orgánica de Albacete" con un Comité de Organización encargado de asistir de manera centralizada a los voluntarios que llegaban del extranjero. El líder comunista francés André Marty, secretario general de la Comintern y hombre de la plena confianza de Stalin al parecer, es nombrado Jefe de la Base de Albacete. Los voluntarios que llegaban iban destinados luego a distintas poblaciones: La Roda, Tarazona de la Mancha, Villanueva de la Jara y Madrigueras eran los lugares de mayor concentración.

En el centro de entrenamiento de Albacete se organizaron las cinco brigadas numeradas de la XI a la XV. La XI, mandada por el general soviético Kléber, y la XII, mandada por el escritor húngaro Máté Zalka ""Lukács"", tuvieron un papel destacado en la batalla de Madrid. Los voluntarios canadienses formaron el Batallón Mackenzie-Papineau (los "Mac-Paps"). También hubo un pequeño grupo de pilotos estadounidenses que formaron el Escuadrón Yankee, liderado por Bert Acosta. Hubo brigadistas famosos, escritores y poetas como Ralph Fox, Charles Donnelly, John Cornford o Christopher Caudwell que describirían sus experiencias en el frente.

El historiador hispanista inglés Hugh Thomas, en su obra clásica sobre la Guerra Civil Española cifró el número de brigadistas que combatieron en España en unos 40 000, muy lejos de los 100 000 que daba la propaganda franquista para hinchar la influencia del Comunismo Internacional. Estudios más pormenorizados y recientes sitúan la cifra en algo menos de 35 000, no muy lejos por tanto de la cifra estimada por Thomas. Lo que también está demostrado es que nunca hubo más de 20 000 combatientes a la vez y que murieron en combate unos 10 000.

Las primeras operaciones de combate en las que participaron las brigadas (en concreto las números XI, XII y XIV) fueron en la batalla de Madrid a partir del 4 de noviembre de 1936 hasta febrero de 1937, durante la primera ofensiva del ejército sublevado, que ya ocupaba Getafe y Leganés.

Con 1550 hombres y mujeres (1628 según los archivos soviéticos), se instaló el cuartel general en la Facultad de Filosofía y Letras, siendo las unidades brigadistas muy activas en los alrededores de la Casa de Campo, donde se enfrentaron al general Varela en los accesos desde la carretera de Valencia, la defensa de la Ciudad Universitaria y los accesos a la sierra de Guadarrama, en un amplio despliegue que los llevaba en algunas ocasiones a combatir a las puertas de Getafe.

La XV Brigada, compuesta principalmente por unidades de rusos, norteamericanos y británicos, se enfrentó a las tropas sublevadas que pretendían conquistar Madrid desde el 6 de febrero de 1937 en la batalla del Jarama, donde los brigadistas británicos y estadounidenses tendrían un rol destacado. También participó en la contención de la ofensiva rebelde y capturó prisioneros, manteniendo enfrentamientos hasta el día 27 inclusive.

Durante la batalla de Guadalajara iniciada por tropas italianas del Corpo Truppe Volontarie el 9 de marzo de 1937 para tratar de penetrar desde el norte en Madrid, las tropas republicanas hicieron frente a un ejército de 30 000 hombres, 80 carros de combate y 200 piezas de artillería. En el escenario se encontraron combatiendo la XI y XII Brigadas Internacionales, que sufrieron gran cantidad de bajas.

En la batalla de Belchite tomaron parte las brigadas XI y XV desde el 26 de agosto hasta el 10 de septiembre de 1937. Los escasos resultados obtenidos por el bando republicano y la desconfianza del ministro socialista Indalecio Prieto hacia las Brigadas ocasionó que, poco después de acabada la lucha en Belchite, el gobierno republicano emitiera diversos decretos destinados a integrar a las Brigadas dentro del esquema organizativo del Ejército Popular Republicano, restando poder de decisión a la Comintern y al PCE, y tratando de encuadrar a los brigadistas bajo mando directo de militares profesionales españoles. Tales intentos chocaron con la oposición de la Comintern, quien con el apoyo del PCE y del gobierno de la Unión Soviética (casi único suministrador de armas a la República), logró mantener a las Brigadas bajo su control.

En la ofensiva republicana que se realizó en diciembre de 1937 en la batalla de Teruel, que tenía como fin desviar la presión de los Nacionales sobre el frente norte, participaron todas las Brigadas Internacionales (ya muy mermadas), excepto la XIV. De cara a las sesiones del Comité de No Intervención, el gobierno republicano mantuvo que serían sólo las tropas españolas las que lucharían, pero esto pronto se demostró como una falsedad cuando el 7 de diciembre llegó la orden a la base brigadista en Albacete de que los soldados en descanso partiesen hacia Aragón.

Los brigadistas tuvieron también un importante papel en los grupos de guerrilleros que se infiltraron tras las líneas antes de la batalla para sabotear las comunicaciones Nacionales. La reconquista de Teruel por parte de los franquistas en febrero del 38 costó un altísimo número de bajas, especialmente a la XI Brigada.

No obstante, la ofensiva de Aragón iniciada en marzo de 1938 significó una dura prueba para las Brigadas Internacionales, en tanto la severa derrota republicana en estos combates generó también un elevado número de bajas entre los brigadistas. Durante la batalla de Caspe, las brigadas tuvieron un destacado papel en la defensa de la localidad, donde se habían concentrado un importante número de unidades internacionales y republicanas. A partir de abril de 1938 y ante la extrema dificultad de cubrir las bajas de los combatientes extranjeros, las Brigadas se reorganizarían incorporando un gran número de reclutas españoles, con lo cual la proporción de extranjeros empezó a ser minoritaria en casi todos los batallones.

En la retaguardia de la zona Nacional. Por ejemplo, sólo entre marzo y abril de 1938 las tropas franquistas habían fusilado a 144 brigadistas, provocando protestas en Europa y Estados Unidos. También fueron internados en los campos de concentración abiertos por orden expresa de Franco; en su caso, se eligió para recluirlos el campo de San Pedro de Cardeña (Castrillo del Val, Burgos), ubicado en el monasterio del mismo nombre y que llegó a albergar a más de 4000 detenidos. Franco utilizó a algunos de estos prisioneros para canjearlos por militares alemanes e italianos en poder de las autoridades republicanas, mientras que otros eran directamente deportados a Alemania y entregados a la Gestapo: Al menos treinta brigadistas germanos y austriacos acabaron en campos de concentración nazis, donde murió la mayor parte de ellos.

Los "internacionales" eran sometidos en el campo de San Pedro a las mismas condiciones de hacinamiento y precariedad que se daban en el resto de centros de detención franquistas; el diplomático británico Robert MacLeod Hodgson, que visitó el recinto, denunció que los reclusos estaban encerrados las 24 horas del día en un local atestado de gente, con ratones, piojos, pulgas y sólo con tres retretes para trescientos hombres, que tampoco disponían de ropa interior, zapatos o medicamentos. Los internos de San Pedro también tuvieron que someterse a los experimentos de Antonio Vallejo-Nájera, jefe de los Servicios Psiquiátricos Militares de Franco y conocido como "el Mengele español", quien trataba de justificar sus peculiares teorías raciales y eugenésicas. Ayudado por dos asesores científicos alemanes, concluyó que estos prisioneros extranjeros eran individuos «degenerados» y «anormales», a causa de la democracia y el sufragio universal vigentes en «el medio ambiente cultural y social norteamericano» donde «el libertinaje sexual constituye la tónica». Los internos con rasgos asiáticos, mulatos o africanos eran fotografiados y ridiculizados en los diversos reportajes propagandísticos del fascismo que se filmaron allí.

Los últimos brigadistas en salir liberados de las cárceles y campos de concentración franquistas no lo harían hasta bien entrado 1943, cuatro años y medio después de finalizada la guerra en España.

Durante 1938 se suceden los intentos para poner fin a la Guerra Civil española desde los organismos internacionales, como la Sociedad de las Naciones, ante el evidente fracaso del Comité de No Intervención para detener el conflicto.

Tras la grave derrota sufrida en abril por la ofensiva de Aragón, la República era consciente de su debilidad, y el presidente del gobierno Juan Negrín juega la baza de apostar por un proceso de pacificación, emitiendo con ocasión del 1 de mayo de 1938 un posible acuerdo basado en trece puntos conocidos como los "Trece puntos de Negrín" ante la opinión pública internacional, entre los que se incluía la retirada de todas las fuerzas compuestas por extranjeros que estuvieran presentes en el conflicto español.

Esto se unía a una intensa labor diplomática encabezada por Manuel Azaña, en la que se mostraba a Francia y al Reino Unido la conveniencia de tener un fuerte aliado en el sur ante los acontecimientos que se precipitaban en Europa tras la amenaza dirigida contra Checoslovaquia por Hitler. La desfavorable situación bélica y estratégica de la República (desde el 15 de abril quedó cortada en dos la zona republicana) causó que Francia y Reino Unido no mostrasen entusiasmo por la propuesta de Negrín, e inclusive la prensa de la Unión Soviética, bajo control gubernamental, admitía seriamente la posibilidad de que Franco triunfase en España.

El gobierno republicano presidido por Juan Negrín dispuso que en la ofensiva republicana de la batalla del Ebro participasen las Brigadas Internacionales, y efectivamente ello sucedió a partir del 25 de julio, interviniendo las Brigadas como tropas de choque. No obstante, el estancamiento de la ofensiva republicana desde mediados del mes de agosto y la severidad de los contraataques sublevados causaron nuevas bajas entre los combatientes extranjeros de las Brigadas.

En 1938, el número de brigadistas se había reducido ostensiblemente (quedaba un tercio aproximadamente) y el 21 de septiembre de ese año, el presidente del gobierno republicano Juan Negrín anunció ante la Asamblea general de la Sociedad de las Naciones en Ginebra, la retirada inmediata y sin condiciones de todos los combatientes extranjeros que luchaban en el bando republicano con la esperanza de que el bando sublevado hiciera lo mismo. Un mes después, el 28 de octubre de 1938, las Brigadas Internacionales desfilaban por última vez por las calles de Barcelona en un acto encabezado por Azaña y Negrín al que asistieron unas 250 000 personas. Por esas mismas fechas, Mussolini retiró unos 10 000 soldados del Corpo Truppe Volontarie "como gesto de buena voluntad" hacia el Comité de No Intervención, pero unos 30 000 soldados italianos siguieron combatiendo en el bando sublevado hasta el final de la guerra.

El Gobierno de la República comunicó oficialmente a la Sociedad de las Naciones y al Comité de No Intervención su firme compromiso en la retirada de las Brigadas Internacionales cuando ya se había estancado mucho el avance de las tropas republicanas en la Batalla del Ebro y cuando había empezado una severa lucha de desgaste en ese frente de combate.

Para esta fecha se había tornado casi imposible el reclutamiento de soldados extranjeros para las Brigadas Internacionales, debido a los intermitentes cierres de la frontera realizados por Francia, que impedían el libre paso de voluntarios, considerando además que el gobierno socialista de Léon Blum (favorable a la República) había dejado el poder en Francia en junio de 1937 y sus sucesores derechistas procedieron a cierres intermitentes de la frontera hispano-francesa.

Asimismo, las pugnas internas entre el PCE y el POUM habían desalentado el reclutamiento de extranjeros en las Brigadas desde los sucesos de mayo de 1937 en Barcelona, pues después de estos hechos, muchos voluntarios extranjeros no comunistas optaban por acudir a España para unirse a otras unidades del Ejército Popular de la República y no a las Brigadas. Por su parte, los partidos comunistas afiliados a la Comintern carecían de más militantes en condiciones de ser enviados a España, lo cual impedía cubrir las bajas sufridas por las Brigadas.

Por todos estos factores, las Brigadas Internacionales habían reducido mucho su número tras la derrota en Aragón: los extranjeros de las Brigadas sumaban menos de 10 000 hombres en toda la España republicana al empezar la batalla del Ebro, sumando en dicha cifra inclusive a los servicios de no combatientes (médicos, técnicos, etc.). Para entonces en casi todos los batallones de las Brigadas, la mayoría de la tropa era española, reclutada para llenar los vacíos dejados por extranjeros.

La propuesta de retirar las Brigadas llegó al bando sublevado, si bien Franco comunicó ""oficiosamente"" que era tarde ya para cualquier acuerdo con el bando republicano, en tanto las tropas rebeldes contaban con una situación militar mucho más ventajosa tras su triunfo en Aragón. De todas formas, el Gobierno de la República consumó el proceso de desmovilización esperando que la buena voluntad sirviera para que las potencias europeas (neutrales o no) presionaran a Franco. Para esa fecha el valor bélico de las Brigadas se había reducido bastante, y su valor propagandístico tampoco resultaba relevante para la Comintern tras publicitarse las pugnas con el POUM y en menor medida con el PSOE. La Unión Soviética también apoyaba la retirada de las Brigadas, al desear que numerosos militantes comunistas (sobre todo los integrados en los mandos de las Brigadas) abandonaran España vivos al hacerse cada vez más posible un triunfo de Franco.

El 23 de septiembre de 1938, los brigadistas vivieron su último día de combate, pero no sería hasta el 27 de octubre que los internacionales del Ejército del Centro y de Levante, unos 1500 hombres, serían reagrupados en Valencia. Al día siguiente ocurrió igual con los brigadistas de Cataluña, que fueron reunidos en Barcelona.

El Ejército Popular les brindó en esa ciudad un gran homenaje bajo el lema: "Caballeros de la libertad del mundo: ¡buen camino!" El mayor de los homenajes que se les rindió, fue el desfile celebrado en Barcelona el 28 de octubre de 1938. Toda la ciudad amaneció con pancartas y carteles alusivos a las Brigadas Internacionales. Ante Companys, Azaña, Negrín, Vicente Rojo y más de 300 000 personas, los internacionales desfilaron por la "avenida del Catorce de Abril" (actual avenida Diagonal), en un ambiente altamente emotivo, con un histórico discurso de Dolores Ibárruri.

Hubo actos similares de homenaje en Valencia y Madrid. Tras un desfile en el que la gente los despidió con aplausos, llantos y cubriendo la calzada de rosas, después de un espectacular despliegue de cazas republicanos en los cielos de Barcelona, los brigadistas estaban listos para partir. Para esto fueron concentrados en diversas localidades catalanas, de acuerdo a su unidad de origen y nacionalidad.

La mayoría de los menos de diez mil brigadistas supervivientes a la guerra trataron de volver a sus países. Muchos de ellos no tendrían problemas (franceses, británicos, estadounidenses), pero otros muchos se verían con situaciones difíciles: los italianos, alemanes, austriacos, suizos, búlgaros y canadienses se vieron entre la espada y la pared. Formalmente eran expulsados de España, pero, o serían detenidos en sus países al regreso debido que en ellos gobernaban el fascismo y el nazismo, o bien se arriesgaban a la cárcel porque habían salido sin autorización para servir en un ejército extranjero, o porque sus respectivos gobiernos perseguían a los militantes comunistas, por lo cual muchos brigadistas debieron marchar como exiliados a terceros países.

Algunos brigadistas que no tenían un país al cual volver con seguridad, se refugiaron en casas particulares en Cataluña y otros pasaron la frontera de los Pirineos sólo para quedarse en Francia como exiliados, incluso de modo clandestino. La Unión Soviética acogió a algunos brigadistas, pero estos eran exclusivamente líderes comunistas de importancia, mientras que el gobierno soviético rehusaba admitir a militantes comunistas de menor jerarquía, ofreciéndoles a cambio "facilidades" para sobrevivir en el exilio.

Un caso paradigmático fue el de los brigadistas yugoslavos: cuatro de los voluntarios que combatieron en la guerra acabaron dirigiendo los cuatro grupos del Ejército Partisano de Liberación que combatió a los nazis en la Segunda Guerra Mundial: Peko Dapčević el I, Koča Popović el II, Kosta Nađ el III, y Petar Drapšin el IV.

Cuando las tropas del bando sublevado lanzaron su campaña en Cataluña el 23 de diciembre de 1938 aún quedaban unos pocos miles de exbrigadistas esperando salir de España; ante el avance franquista estos extranjeros reconstruyeron algunos batallones y ofrecieron de nuevo sus servicios al gobierno republicano. Inicialmente el primer ministro Negrín rechazó este apoyo, pero los antiguos mandos brigadistas (como André Marty) y los líderes del PCE instaron a que los exbrigadistas aún ubicados en España tomaran de nuevo las armas.

Así, en enero de 1939 se formaron improvisados batallones de antiguos brigadistas, mayormente eslavos, italianos, y latinoamericanos, que participaron en las últimas operaciones bélicas del bando republicano antes de la retirada de Cataluña; estos combatientes evacuaron el suelo español el 9 de febrero de 1939 junto con los restos del Ejército Popular y varios miles de refugiados civiles. Unos pocos exbrigadistas habían elegido quedarse en la región suroriental de España, aún en poder de la República, encuadrados en unidades militares afectas al PCE; en esa condición lucharon contra el golpe de estado del coronel Casado a inicios de marzo de 1939, algunos pudieron huir a último minuto junto con la jefatura del Partido Comunista de España, mientras otros acabaron capturados por los franquistas.

Hubo brigadistas de más de cincuenta países del mundo. El país que más voluntarios aportó fue Francia, con más de 10 000 según algunas fuentes (Andreu Castells la eleva hasta 15 000). El segundo contingente más importante era el de alemanes y austriacos con unos 5000, en su mayoría exiliados en París y Bruselas. También destacaron los contingentes de Italia (4000), los 2500 británicos, 2000 estadounidenses, 1700 yugoslavos, 1500 canadienses, 1200 cubanos y 600 argentinos. También se enrolaron en menores cantidades voluntarios de países como Perú, Bolivia, Abisinia, Polonia, Bélgica, Albania, Checoslovaquia, Hungría, Bulgaria, Suecia, Suiza, Holanda, Rumania, Colombia, China, Chile, Brasil, Uruguay, entre 450 y 500 de México, Argelia, Siria, Líbano, Irak, Egipto, Marruecos, Palestina y Nueva Zelanda.

Un importante número de brigadistas fue de origen judío, colectivo que mayoritariamente entendió la lucha contra el franquismo en el contexto de la lucha contra el ascenso del antisemitismo que se estaba dando en Europa. Según distintas estimaciones, hasta 8000 de estos voluntarios, un 15% del total de brigadistas internacionales, lucharon por el bando republicano. En general, estos voluntarios habían sido previamente militantes comunistas y anarquistas, con poca o nula conciencia hebrea, pero también se dieron casos de unidades específicamente judías, como la Unidad judía Botwin (anteriormente denominada 2.ª Compañía del Batallón Palafox). Esta participación judía en las brigadas internacionales fue silenciada sistemáticamente.

Los brigadistas procedían de muy diferentes estratos sociales, desde intelectuales a trabajadores manuales, pasando por militares retirados o soldados veteranos. Hubo en sus filas una gran variedad de procedencias: sindicalistas, mineros de Europa Central, estibadores y cargadores de los principales puertos europeos, algunos excombatientes de la Primera Guerra Mundial, médicos, afroamericanos y orientales naturales de suburbios neoyorquinos, también un numeroso grupo de universitarios británicos procedentes de las zonas de concentración industrial, algunos escritores, artistas, políticos y muchos militares desempleados de la Europa del Este. Como vemos, la procedencia tanto geográfica como social y profesional era de una heterogeneidad impresionante. El importante número de intelectuales, médicos, artistas y científicos que integraban las brigadas, ha hecho que en muchas ocasiones se les haya definido como “la unidad militar más intelectual de la historia”.

Hay que añadir en este apartado que hubo varios escritores, como Ernest Hemingway y George Orwell, que aunque sí fueron testigos directos de la guerra y escribieron algunas obras que se han hecho muy populares ("Por quién doblan las campanas" u "Homenaje a Cataluña", o que sirvió de inspiración para escribir "Rebelión en la granja"), no se encuadraron como combatientes dentro de las Brigadas Internacionales.

La filiación política mayoritaria era la comunista, ya que casi todos los brigadistas habían sido invariablemente reclutados por los partidos comunistas de diferentes naciones, afiliados a la Comintern, aunque unos pocos acudieron a España para enrolarse directamente sin adherirse previamente a un partido político. Sin embargo, la militancia política variaba según el país de origen; por ejemplo, entre los brigadistas estadounidenses los reclutas que eran militantes izquierdistas (socialistas, comunistas o anarquistas) no llegaban ni a la mitad, mientras que en el contingente alemán los soldados de filiación comunista estaban en torno al 80 %, siendo igual de elevada la proporción de comunistas en unidades francesas o italianas. Mientras tanto, los batallones británicos y de Europa Oriental mostraban presencia mayoritaria de obreros sindicalizados, con una minoría de militantes de algún partido.

La filiación de los brigadistas no comunistas era muy variada también: iba desde el socialismo hasta el anarquismo, pasando por todas las formas del progresismo antifascista o socialdemócratas. No obstante, en casi todos los batallones la Comintern insistió para que los puestos de jefatura quedaran en poder de militantes comunistas, lo cual se impuso desde las primeras semanas de existencia de las Brigadas. La única excepción a este control comunista ocurrió en el Batallón "Garibaldi", donde la Comintern permitió que los reclutas italianos fueron dirigidos por oficiales anarquistas.

Fueron muchos los brigadistas que posteriormente acabarían convirtiéndose en personajes de notable importancia histórica. Por dar algunos ejemplos se podrían citar los nombres del alemán Willy Brandt, que sería alcalde de Berlín y luego canciller de Alemania, el intelectual holandés Jef Last, el militar húngaro Kleber, el pintor mexicano David Alfaro Siqueiros, el general polaco Walter, el presidente yugoslavo Tito (la participación de este último ha sido bastante discutida), y otros muchos alemanes que llegarían a ocupar importantes cargos en la República Democrática Alemana. También participó en las Brigadas Internacionales el albanés Enver Hoxha, quien sería primer ministro de ese país desde 1946 hasta su muerte en 1985, durante la República Popular de Albania.

Los primeros voluntarios llegaron a Albacete el 12 de octubre de 1936, y a partir de ahí llegaron convoyes casi diariamente durante los días sucesivos. El día 15, Luigi Longo (luego se hará llamar "Luigi Gallo") empezó a organizar las primeras compañías. Otros que se suman al primer órgano de dirección son los militantes comunistas Allard, Wisniewski, Hans Kahle, Jean Marie François, Lalmanovic o Ribiere. Este comité organizador se vio superado ante la llegada de tantos voluntarios y pronto se transformó en un comité militar, en el que aparte de los ya mencionados entraron otros, como el comandante Vidal y André Marty, que se convertiría en el jefe de la base y de las Brigadas Internacionales.

El encuadramiento en los distintos grupos se efectuó en función de grupos idiomáticos y de origen. Los jefes en un principio fueron elegidos por los propios voluntarios, pero más tarde la elección pasó a hacerse en función de las necesidades, aunque la Comintern pronto logró imponer que todos los oficiales (y candidatos a serlo) fueran militantes comunistas. Al lado de cada jefe militar había un comisario político, cuyas tareas principales eran de carácter político (mantener la moral, arengar políticamente a las tropas, etc.) aunque en ocasiones también tenían que asumir labores puramente militares.

Se formaron siete brigadas, llamadas XI, XII, XIII, XIV, XV, 129.ª y 150.ª; Cada brigada se dividía a su vez en tres batallones (salvo en algunos casos en los que había cuatro) que en un principio rondaban los 650 hombres cada uno. Estos batallones recibían nombres con un claro contenido político, como Garibaldi o Commune de Paris.

Las Brigadas estuvieron organizadas de la siguiente forma:


La XI Brigada fue la primera en constituirse formalmente el 22 de octubre de 1936 con tres batallones: "Edgar André", "Commune de París" y "Garibaldi", apoyados por un batallón español. Jefe de la Brigada fue Manfred Stern primero y Jean Marie François después.


La XII Brigada se constituyó el 1 de noviembre de 1936 con los batallones "Ernst Thälmann", "André Marty" y, desde la XI Brigada, el "Garibaldi". El Jefe de la Brigada fue el general Máté Zalka.


La XIII Brigada se constituyó el 1 de diciembre de 1936 con los batallones "Chapaiev", "Henri Vuillemin" y "Louise Michel". El jefe de la Brigada fue Wilhelm Zaisser.


La XIV Brigada, a la que se conoció como "La Marsellaise" por estar conformada por mayoría de franceses, fue creada el 1 de diciembre de 1936 y reorganizada por completo el 27 de noviembre de 1938.


La XV Brigada se formó el 31 de enero de 1937 con los Batallones "Dimitrov", "6 de febrero", "Pierre Brachet" (que se trasladó pronto a la XIV Brigada), "Británico", "Lincoln" y "Washington". El jefe de la Brigada fue Janos Galicz.


La 129.ª Brigada se constituyó el 28 de abril de 1937 con restos de batallones de otras Brigadas y miembros del POUM. La distinta procedencia de sus miembros la llevó a ser conocida como "la Brigada de las cuarenta naciones". Las diferencias entre las fuerzas políticas y el conflicto en Cataluña con el POUM la hicieron poco efectiva, debiendo ser reorganizada en febrero de 1938. Entonces se nombró jefe de la Brigada a Wacek Komar (que provenía del "Batallón Dabrowski" de la XI Brigada).


Formada en junio de 1937 sobre la base del Batallón Dabrowski de la XI Brigada.

Tras la disolución de las Brigadas internacionales, y con el regreso a sus países de origen, sus miembros fueron acogidos de forma distinta. En un principio muchos fueron tachados de simples mercenarios, mientras otros fueron condecorados en su propia tierra. La llegada de la Segunda Guerra Mundial evidenció el papel que habían tenido estos combatientes en España al ser los primeros soldados de sus respectivos países que habían luchado contra el expansionismo fascista de Alemania e Italia.

El 26 de enero de 1996, el Congreso de los Diputados español concedió la nacionalidad española a los brigadistas si renunciaban a su nacionalidad propia, cumpliendo así la promesa realizada por Juan Negrín cuando estos abandonaron España cincuenta y siete años antes. Aun así, la mayoría de los veteranos optó por no renunciar.

Después, la Ley de la Memoria Histórica reconoció a los brigadistas la nacionalidad española por naturalización, sin tener que renunciar a la suya propia. En junio de 2009, la embajada española en Londres entregó a varios brigadistas sus pasaportes españoles.

Las Brigadas Internacionales contaron entre sus miembros con personalidades como el joven Willy Brandt, que sería luego canciller socialdemócrata de la República Federal de Alemania, Wilhelm Zaisser, Ministro de Seguridad del Estado en la República Democrática Alemana y jefe de la policía política Stasi desde 1950 hasta 1953, así como los literatos Ralph Fox, Charles Donnelly, John Cornford, Gustav Regler, Christopher Caudwell, Nick Gillain, George Orwell, científicos como Guido Nonveiller, pintores como Wifredo Lam y militares como el francés Alex Canitrot, entre otros. 

Quizá menos conocidas aunque más legendarias fueron las mujeres brigadistas, entre las que cabría recordar los nombres de Felicia Browne, Fanny Edelman, Mika Feldman, Elisaveta Párshina, Salaria Kea O'Reilly, Adelina Kondrátieva o Lise Ricol.


En algunos lugares, ya durante la guerra se construyeron monumentos en homenaje a los brigadistas. Por ejemplo en la zona de la batalla del Jarama, el 30 de junio de 1938 fue inaugurado un monumento en forma de puño. Volvió un grupo de brigadistas para un acto de despedida en noviembre. El monumento fue destruido después de la guerra.

El primer monumento a los brigadistas tras la guerra se inauguró el 28 de octubre de 1988, justo en el cincuentenario de la emotiva despedida que Barcelona brindó a las Brigadas Internacionales. Hablamos de la obra "David y Goliat", del escultor estadounidense Roy Schifrin, que puede verse en la boca norte del túnel de la Rovira, en el barrio del Carmel de la capital catalana, gracias también a la Spanish Civil War Historical Society, que con aportaciones entre otros de personalidades como Woody Allen, Leonard Bernstein o Gregory Peck, impulsó su creación. Acompaña al monumento una placa con un fragmento del discurso que ese 28 de octubre de 1938 pronunció Dolores Ibárruri, la Pasionaria, en el adiós de los brigadistas: "«Cuando los años pasen y las heridas de la guerra se vayan restañando, cuando el rechinar de los días dolorosos y sangrientos se esfumen en un presente de libertad (…) hablad a vuestros hijos, habladles de estos hombres de las Brigadas Internacionales (...) No os olvidaremos, y cuando el olivo de la paz florezca… volved»."

Otro monumento a los brigadistas en España puede verse desde 2012 en la Universidad Complutense de Madrid, aunque está en entredicho que se mantenga.



</doc>
<doc id="41153" url="https://es.wikipedia.org/wiki?curid=41153" title="Aka">
Aka

El término aka puede referirse a:



</doc>
<doc id="41154" url="https://es.wikipedia.org/wiki?curid=41154" title="Batak (Indonesia)">
Batak (Indonesia)

Los batak son uno de los pueblos de Indonesia. Su área central está en el norte de Sumatra con centro en el lago Toba.

Antes de su pacificación bajo el gobierno colonial holandés de las Indias orientales, los batak eran conocidos como fieros guerreros y caníbales. Después, el cristianismo fue ampliamente abrazado y la iglesia Batak es actualmente la mayor congregación cristiana de Indonesia.

La sociedada batak es patriarcal y existe un sistema de dote. La cultura batak destaca en la tejeduría, tallado de madera y especialmente en sus adornadas tumbas de piedra. Su cultura de enterramiento es muy rica y compleja e incluye una ceremonia en la cual los huesos de los propios ancestros son reenterrados varios años tras la muerte.

Los batak hablan una variedad de lenguajes muy relacionados, todos miembros de la familia de los lenguajes austronesios

Se cree que los ancestros de los batak navegaron a través del océano Índico y colonizaron Madagascar.

Hay cinco grupos de los bataks: 

Cada etnia tiene cultura propia y alfabeto propio también.



</doc>
<doc id="41155" url="https://es.wikipedia.org/wiki?curid=41155" title="Sumatra">
Sumatra

Sumatra o Sumatera es una gran isla del Sureste asiático localizada en aguas del océano Índico y perteneciente a Indonesia. Con una superficie de 473 605 km², es la y la mayor isla de Indonesia.

En el año 2010 tenía una población de 50 365 538 habitantes (el 22% de la población total de Indonesia) y la ciudad más grande era Medan con 2 109 330 de habitantes. El 87 % de la población de Sumatra se cree que son musulmanes.

Sumatra tiene una gran variedad de especies vegetales y animales, pero ha perdido casi el 50 % de su selva tropical en los últimos 35 años y tiene muchas
especies en peligro crítico de extinción, como el tigre de Sumatra, el rinoceronte de Sumatra y el orangután de Sumatra.

Hay evidencias de asentamientos de colonos en Sumatra del año 500 a. C. y en la isla florecieron varios reinos importantes. I Ching, un monje budista chino, estudió sánscrito y pasó cuatro años de su vida trabajando en Palembang. El viajero Marco Polo visitó la isla en 1292.

Sumatra era conocida en la antigüedad con los nombres en sánscrito de "Swarnadwīpa" («Isla de Oro») y "Swarnabhūmi" («Tierra de Oro»), debido probablemente a los depósitos de oro de las tierras altas de la isla. La primera obra que menciona el nombre de "Sumatra" fue el nombre srivijayano de "Haji" (rey) "Sumatrabhumi" («El rey de la tierra de Sumatra»), que envió un emisario a China, en 1017. Los geógrafos árabes, entre los siglos X-XIII, llamaban a la isla "Lamri" ("Lamuri", "Lambri" o "Ramni"), en referencia a un reino cerca de la actual Banda Aceh, que fue el primero en el que desembarcaron sus comerciantes.

A finales del siglo XIV el nombre de Sumatra se hizo popular, en referencia al Reino de Samudra Pasai, que era una potencia en ascenso, hasta que fue sustituido por el sultanato de Aceh. El sultán Alauddin Shah de Aceh, en cartas escritas en 1602 dirigidas a la reina Isabel I de Inglaterra, se refería a sí mismo como «rey de Aceh y Samudra». La palabra, también en sánscrito de "Samudra", (समुद्र), significa «reunión juntas de las aguas, mar u océano».

Después de la llegada del Islam al en el siglo XIII, la isla también fue llamada por los viajeros musulmanes como "Andalas", una voz derivada de Al-Andalus, para comparar los florecientes reinos islámicos de Sumatra en el extremo oriental del mundo musulmán como reflejo de la España musulmana en extremo oeste. Los escritores europeos en el siglo XIX descubrieron que los indígenas no tenían un nombre para su isla.

El eje mayor de la isla, de unos 1790 km de longitud, va aproximadamente de noroeste a sureste, cruzando el Ecuador cerca del centro. En su punto más ancho la isla tiene 435 km. El interior de la isla está dominado por dos regiones geográficas: las montañas Barisan, en la parte oeste, y las llanuras pantanosas, en la este.

La isla está en la parte noroccidental del archipiélago malayo y forma parte del grupo de islas mayores de la Sonda. La isla está en el océano Índico y tiene como límites

La espina dorsal de la isla es la cadena de las montañas Barisan, siendo el punto más alto, el volcán activo monte Kerinci (con 3805 m), que se encuentra aproximadamente en el punto medio de la cordillera. La actividad volcánica de esta región la dota de tierra fértil y bellos paisajes, por ejemplo, los alrededores del lago Toba. También contiene depósitos de carbón y de oro. La actividad volcánica es debido a que Sumatra está en el «anillo de fuego del Pacífico», siendo también la razón por la cual Sumatra ha tenido algunos de los terremotos más poderosos jamás registrados: en , , y .

Al este, varios grandes ríos acarrean limo de las montañas y forman la vastas tierras bajas, una región salpicada de charcas y áreas pantanosas. A pesar de ser en su mayoría inadecuada para el cultivo, en la actualidad la zona es de gran importancia económica para Indonesia, ya que produce aceite «por encima y por debajo del suelo»: el aceite de palma y el petróleo.

Sumatra es el mayor productor de café de Indonesia. Algunos agricultores pequeños cultivan café arábigo ("Coffea arabica") en las tierras altas, mientras que el Robusta ("Coffea canephora") se encuentra en las tierras bajas. El café arábigo de las regiones de Gayo, Lintong y Sidikilang es habitualmente procesado usando la técnica del Giling Basah (descortezado en húmedo), lo que le da un cuerpo pesado y baja acidez.

La mayor parte de Sumatra solía estar cubierta por selva tropical, hogar para especies como el orangután, el tapir, el rinoceronte de Sumatra y el tigre de Sumatra, y algunas plantas únicas, como la rafflesia. Desafortunadamente, el desarrollo económico junto con la corrupción y la tala ilegal han amenazado gravemente su existencia. Incluso ni las áreas protegidas se han salvado de la destrucción.

La isla, por altitud, es la quinta más elevada del mundo y la tercera en el archipiélago indonesio.

La isla de Sumatra pertenece a Indonesia y, administrativamente, está dividida en las siguientes provincias (algunas incluyen islas menores cercanas):

Las mayores áreas urbanas de Sumatra por población, tomando como referencia los cálculos de 2009 elaborados por "The World Gazetteer", son las siguientes:

Sumatra no está muy densamente poblada (45 millones de personas en un área mayor que Alemania). Las regiones más populosas incluyen la mayoría de Sumatra Utara y la tierra alta central en Sumatra Barat, mientras que los mayores centros urbanos son Medan y Palembang.

La población es de origen malayo compuesta de muchas tribus diferentes, que hablan 52 lenguajes diferentes. La mayoría de esos grupos, sin embargo, comparten tradiciones muy similares y las diferentes lenguas están muy relacionadas. La población malayoparlante domina la costa este, mientras que la población del sur y del interior central habla lenguajes relacionados con el malayo, tales como el Lampung y el Minangkabau. La tierra alta de Sumatra del norte está habitada por los bataks, mientras que la costa norte está dominada por los acehs. Minorías étnicas chinas están presentes también en los centros urbanos.

Una mayoría de la población en Sumatra son musulmanes. La mayoría de los bataks del centro son cristianos protestantes —la religión fue extendida por los holandeses. El resto sigue el hinduismo, budismo, catolicismo y creencias tradicionales chinas.

Un antiguo nombre para Sumatra fue "Swarna Dwipa", o "Isla de Oro", aparentemente basado en el hecho de que minas de las tierras altas de Sumatra exportaban oro desde épocas bastante tempranas.

Con su localización en la ruta comercial entre India y China, florecieron varias villas comerciales, especialmente en la costa este, y fueron influenciadas por las religiones indias. La más notable de ellas es la Srivijaya, una monarquía budista con centro en lo que ahora es Palembang. Dominando la región mediante el comercio y la conquista durante los siglos del VII al IX, el reino ayudó a extender la cultura malaya por todo Sumatra, la península Malaya y el oeste de Borneo. El imperio es talasocrático, sin embargo, significando que no extendía su influencia muy lejos de la zona costera.

La influencia de Srivijaya se desvaneció en el siglo XI. La isla fue sujeta a conquista desde los reinos javaneses, primero Singhasari y después Majapahit. Al mismo tiempo, el islam viajó hasta Sumatra, extendiéndose a través de contactos con comerciantes árabes e indios.

Al final del siglo XIII, el monarca del reino de Samudra (ahora en Aceh) se había convertido al islam. Ibn Battuta, que visitó el reino durante su viaje, pronunció el nombre del reino "Sumatra", de ahí el nombre de la isla. Samudra fue sucedido por el poderoso sultanato de Aceh, que sobrevivió hasta el siglo XX.

En el año 1509 llegaron a la isla los portugueses bajo las órdenes de Figueira. Y en 1511 después de la conquista de Malaca, los portugueses fundaron algunos establecimientos, pero los sultanes de Achim y Padang destruyeron dichas colonias en 1523.
El navegante holandés Hautman había intentado entablar relaciones en 1599 con Achim, pero este empeño le costó la vida.
En 1600 la Compañía Holandesa de las Indias Orientales se apoderó de algunos puntos de la isla, estableciendo en 1618 la factoría de Djambai, y dos años después otras en el reino de Palembang.
En 1662 la Compañía Holandesa impuso un tratado con la reina de Achim con el objetivo de formar un protectorado en aquella región. De esta manera la compañía se reservó el exclusivo comercio de la costa suroeste de la isla.
Más tarde, entre 1664 y 1669, se construyeron las factorías de Padang, Baros, Adjis y Lampong.
Mientras tanto los ingleses, que ya en 1685 se establecieron en Benkulen, tuvieron que soportar numerosos conflictos armados con los holandeses y nativos del lugar.
En el año 1811 fueron asesinados los empleados y soldados holandeses del fuerte de Palembang. Este atentado cometido por la gente del sultán de Palembang tuvo como consecuencia una sangrienta guerra. La lucha duró hasta 1821, perdiendo el sultán su libertad y todos sus estados.
En 1824 Inglaterra renunció a sus posesiones de Sumatra, a cambio del territorio que Holanda poseía en Malaca.
En 1835 volvió a turbarse la paz en la isla como consecuencia de las predicciones de tres peregrinos de La Meca. El gobierno holandés acabó con los insurgentes, y esta guerra arruinó definitivamente el ya mermado poder político de los sultanes de Menangkabo. En 1850 se sometió Palembang, en 1856 la provincia de Lampong, en 1857 los países de Djambi e Indraguiri, en 1861 Labong y de 1864 a 1868 los territorios del lago Rendau y Pasunrah.
Holanda sostuvo una guerra hasta 1874 con el objetivo de someter el reino de Achim, protegido por Inglaterra hasta 1872, y cedido a cambio de las posesiones de Guinea.

Durante la ocupación de este territorio por parte de la Compañía Holandesa de las Indias Orientales (Vereenigde Oostindische Compagnie o VOC) era común la utilización de diferentes monedas extranjeras. Para garantizar su circulación se estamparon diferentes contramarcas sobre piezas de 8 reales españoles, 5 francos franceses y talers de María Teresa I de Austria. La contramarca consistía en un punzón circular de 14 a 17 milímetros que llevaba las siglas «VOC».



</doc>
<doc id="41160" url="https://es.wikipedia.org/wiki?curid=41160" title="Notación científica">
Notación científica

La notación científica, también denominada patrón o notación en forma exponencial, es una forma de escribir los números que acomoda valores demasiado grandes (100 000 000 000) o pequeños como puede ser el siguiente (0.000 000 000 01)para ser escrito de manera convencional. El uso de esta notación se basa en potencias de 10 (los casos ejemplificados anteriormente en notación científica, quedarían 1 × 10 y 1 × 10, respectivamente). El módulo del exponente en el caso anterior es la cantidad de ceros que lleva el número delante, en caso de ser negativo (nótese que el cero delante de la coma también cuenta), o detrás, en caso de tratarse de un exponente positivo.

Siempre el exponente es igual al número de cifras decimales que deben correrse para convertir un número escrito en notación científica en el mismo escrito en notación decimal. Se desplazará a la derecha si el exponente es positivo y hacia la izquierda si es negativo. Cuando se trata de convertir un número a notación científica el proceso es a la inversa. 

Como ejemplo, en la química, al referirse a la cantidad de entidades elementales (átomos, moléculas, iones, etc.), hay una cantidad llamada cantidad de materia (mol).

Un número escrito en notación científica sigue el siguiente patrón:

El número "m" se denomina «mantisa» y "e" el «orden de magnitud». La mantisa, en módulo, debe ser mayor o igual a 1 y menor que 10, y el orden de magnitud, dado como exponente, es el número que más varía conforme al valor absoluto.

Observe los ejemplos de números grandes y pequeños: 


La representación de estos números, tal como se presenta, tiene poco significado práctico. Incluso se podría pensar que estos valores son poco relevantes y de uso casi inexistente en la vida cotidiana. Sin embargo, en áreas como la física y la química, estos valores son comunes. Por ejemplo, la mayor distancia observable del universo mide cerca de 740 000 000 000 000 000 000 000 000 m, y la masa de un protón es de unos 0.000 000 000 000 000 000 000 000 001 67 kg.

Para valores como estos, la notación científica es más adecuada porque presenta la ventaja de poder representar adecuadamente la cantidad de dígitos significativos. Por ejemplo, la distancia observable del universo, de modo que está escrito, sugiere una precisión de 27 dígitos significativos. Pero esto no puede ser verdad (es poco probable 25 ceros seguidos en una medición).

El primer intento de representar números demasiado grandes fue emprendido por el matemático y filósofo griego Arquímedes, y descrita en su obra "El contador de arena", en el siglo III a. C. Él desarrolló un sistema de representación numérica para estimar un límite superior para el número de granos de arena necesarios para llenar el universo. Para hacer esto tuvo que estimar el tamaño del universo según el modelo vigente en ese momento y, además, inventar una manera de expresar números muy grandes. El número estimado por él era de 10 granos.

Fue a través de la notación científica que se concibió el modelo de representación de los números reales mediante coma flotante. Esa idea fue propuesta por Leonardo Torres y Quevedo (1914), "Konrad Zuse" (1936) y "George Robert Stibitz" (1939). La codificación en punto flotante de los ordenadores actuales es básicamente una notación científica de base 2.

La programación con el uso de números en notación científica consagró una representación sin superíndices, en el cual la letra e (o E) a mantisa del exponente mantisa. Por lo tanto, 1.785 × 10 e 2.36 × 10 se representan, respectivamente, con 1.785E5 y 2.36E-14 (como la mayoría de los lenguajes de programación están basadas en inglés, las comas son sustituidas por puntos).

En la notación científica estándar, el exponente "e" es elegido de manera que el valor absoluto de "m" permanezca al menos uno pero menos de diez (1 ≤ | m | <10). Por ejemplo, "350" se escribe como "3.5 ⋅ 10²". Esta forma permite una comparación simple de dos números del mismo signo en "m", como el exponente e indica el número de la orden de grandeza. En notación estándar el exponente "e" es negativo para un número absoluto con valor entre 0 y 1 (por ejemplo, menos de la mitad es "-5 ⋅ 10"). El 10 y el exponente son generalmente omitidos cuando el exponente es 0.

En muchas áreas, la notación científica se normaliza de esta manera, a excepción de los cálculos intermedios, o cuando una forma no estándar, tales como la notación de ingeniería, se desea. La notación científica (normalizada) suele llamarse notación exponencial - aunque este último término es más general y también se aplica cuando "m" no está restringido al intervalo de 1 a 10 (como en la notación de ingeniería, por ejemplo) y para otras bases distintas de 10 (como en "315 ⋅ 2").

La mayoría de calculadoras y programas informáticos están programados para mostrar en notación científica los números excesivamente grandes o pequeños. Pese a esto, por lo general no son capaces de ilustrar "a la manera tradicional" los exponentes de potencias, como por ejemplo 10 (lo mismo ocurre con los subíndices matemáticos). En estos casos recurren a un formato alternativo de representación gráfica de potencias: la notación E, donde la letra E, seguida de un número, representa, literalmente, «multiplicado por diez elevado a» (es decir, "× 10n"). Dicho de otro modo, si tomamos dos números reales m y n, la representación "mEn" significaría exactamente m × 10n.

El carácter "e" no tiene nada que ver con la constante matemática "e" (la confusión no es posible cuando se utiliza la letra mayúscula "E"); y aunque represente un "exponente", la notación se refiere generalmente como "notación e (científica)" o "notación E (científica)", en vez de "notación exponencial (científica)" (aunque este última también puede ocurrir).


6.0221415e23 = 6.0221415E23
La notación de ingeniería difiere de la notación científica normalizada en el cual el exponente "e" está restringido a múltiplos de 3. Por consiguiente, el valor absoluto de m está en el intervalo 1 ≤ |"m"| <1000, en lugar de 1 ≤ |"m"| < 10. Aunque sea conceptualmente similar, la notación de ingeniería rara vez se la llama notación científica.

Los números de esta forma son fáciles de leer, utilizando los prefijos de magnitud como "mega" ("m" = 6), "kilo" ("m" = 3), "mili" ("m" = −3), "micro" ("m" = −6) o "nano" ("m" = −9). Por ejemplo, 12.5×10 m se puede leer como «doce punto cinco nanómetros» o escrito como 12.5 nm.

La notación científica es una forma muy conveniente para escribir números pequeños o grandes y hacer cálculos con ellos. También transmite rápidamente dos propiedades de una medida que son útiles para los científicos, las cifras significativas y orden de magnitud. Escribir en notación científica le permite a una persona eliminar ceros delante o detrás de las cifras significativas. Esto es muy útil para mediciones muy grandes o muy pequeñas en astronomía y en el estudio de moléculas. Los siguientes ejemplos pueden demostrarlo.


Una ventaja de la notación científica es que reduce la ambigüedad del número de dígitos significativos. Todos los dígitos en notación científica estándar son significativos por convención. Pero, en notación decimal cualquier cero o una serie de ceros al lado del punto decimal son ambiguos, y puede o no indicar números significativos (cuando ellos deben estar subrayados para hacer explícitos que ellos son ceros significativos). En una notación decimal, los ceros al lado del punto decimal no son, necesariamente, un número significativo. Es decir, pueden estar allí solo para mostrar dónde está el punto decimal. Sin embargo, en notación científica se resuelve esta ambigüedad, porque los ceros que se muestran son considerados significativos por convención. Por ejemplo, usando la notación científica, la velocidad de la luz en unidades del SI es 2.99792458×10 m/s y la eminencia es 2,54×10 m; ambos números son exactos, por definición, las unidades «pulgadas» por centímetro y "m" en términos de la velocidad de la luz. En estos casos, todas las cifras son significativas. Se puede adicionar un único cero o cualquier número de ceros al lado derecho para mostrar más dígitos significativos, o un único cero con una barra en la parte superior se puede agregar a mostrar infinitos dígitos significativos (así como en notación decimal).

Es habitual en mediciones científicas registrar todos los dígitos significativos de las mediciones, y asumir un dígito adicional, si hubiera cierta información a todos los disponibles para el observador a hacer una suposición. El número resultante es considerado más valioso del que sería sin ese dedo extra, y es considerado una cifra significativa, ya que contiene alguna información que conduce a una mayor precisión en las mediciones y en la agregación de las mediciones (agregarlas o multiplicarlas).

A través de anotaciones adicionales, se puede transmitir información adicional sobre la exactitud. En algunos casos, puede ser útil saber que es el último algoritmo significativo. Por ejemplo, el valor aceptado de la unidad de carga elemental puede ser válidamente expresado como 1.602176487(40)×10 C, y cuyas cifras aparecen entre paréntesis al final del valor, indican su incertidumbre, específicamente se expresa como 0.000000040×10 C, y es un acceso directo a la abreviatura de (1.602176487 ± 0.000000040)×10 C.

La notación científica permite una rápida comparación entre varias cantidades homogéneas. Por ejemplo:
Para compararlas con suficiente aproximación basta el cociente entre las potencias de diez:

Es decir, el protón es aproximadamente cuatro órdenes de magnitud (alrededor de 10 000 veces) más masivo que el electrón.

La notación científica también evita malentendidos, debido a las diferencias regionales en ciertos cuantificadores como «mil millones», lo que puede indicar tanto 10 como 10.

La definición básica de la notación científica permite una infinidad de representaciones para cada valor. Sin embargo, la notación científica estandarizada incluye una restricción: la mantisa (coeficiente) debe ser mayor que o igual a 1 y menor que 10. De ese modo es representado de una manera única.

Para transformar cualquier número a la notación científica estandarizada debemos mover la coma obedeciendo al principio de equilibrio.

Tomemos el ejemplo a continuación:

La notación científica normal requiere que la mantisa (coeficiente) es de entre 1 y 10 en valor absoluto. En esta situación, el valor apropiado sería 2,5375642 (observe que la secuencia de números es la misma, solamente cambia la posición de la coma). Para el exponente, pena el principio de equilibrio: «Cada decimal que disminuye el valor de mantisa aumenta el exponente en una unidad, y viceversa».

En este caso, el exponente es 5.

Observe la transformación paso a paso:

formula_15
formula_17
formula_18
formula_19
formula_20
formula_21

Otro ejemplo, con valores por debajo de 1:

0.00000004750.000000475 × 100.00000475 × 100.0000475 × 100.000475 × 100.00475 × 100.0475 × 100.475 × 104.75 × 10

En notación científica estándar, en notación "E" y la notación de ingeniería, el espacio (el que, en formato de texto, puede ser representado por un espacio normal de ancho o por un espacio delgado), solo se permite antes y después de "x", en frente de "E" o "e" puede ser omitido, aunque sea menos común que lo haga antes del carácter alfabético.

Para sumar o restar dos números en notación científica, es necesario que los exponentes sean los mismos. Es decir, uno de los valores debe ser transformado para que su exponente sea igual al del otro. La transformación sigue el mismo principio de equilibrio. El resultado probablemente no estará en forma estándar, siendo convertido posteriormente.

Ejemplos:

formula_22

formula_23 "(no estándar)" o formula_24 "(estandarizado)"

Multiplicar las mantisas y sumar los exponentes de cada valor. Probablemente, el resultado no será estándar, pero se puede convertir.

Ejemplo:

formula_25 "(no estandarizado)" formula_26 "(convertido a notación estándar)

formula_27"(ya estandarizado sin necesidad de conversión)"

Dividir las mantisas y restar los exponentes de cada valor. Probablemente, el resultado no será estándar, pero se puede convertir:

Ejemplos:

formula_28"(estandarizado)"

formula_29"(no estándar)" formula_30

La mantisa es elevada al exponente externo y el congruente de base diez se multiplica por el exponente externo.

formula_31"(estandarizado)"

Antes de realizar la radicación es necesario transformar un exponente a un múltiplo del índice. Después de que se hace esto, el resultado es la radicación de la mantisa multiplicada por diez elevado a la relación entre el exponente y el índice de radical.

formula_32

formula_33



</doc>
<doc id="41162" url="https://es.wikipedia.org/wiki?curid=41162" title="Gestalgar">
Gestalgar

Gestalgar es un municipio de la Comunidad Valenciana, España. Perteneciente a la provincia de Valencia, en la comarca de Los Serranos.

El término municipal de Gestalgar se encuentra atravesado por el río Turia, que pasa junto al casco urbano, el cual se sitúa en su margen izquierda. Gran parte del curso fluvial se halla encañonado, excepto algunos espacios que forman vegas, como la que se extiende entre el núcleo urbano y la parte oriental del término. Destaca la gran roca de la Peña María, a cuyos pies nace una fuente de agua que, junto con la Fuente Grande, abastece a la población. Muy cerca se encuentra la fuente del Morenillo, con una cascada.

La superficie del término es en general montañosa, con terreno muy quebrado por la sierra de Chiva que penetra por el sur en dos ramales, la Sierra de los Bosques y la Sierra de Santa María, cuya cumbre del Burgal, lindante con Chera, alcanza los 1107 metros sobre el nivel del mar. Además, los contrafuertes de los montes de Chulilla se extienden por el norte. Las partes llanas son las citadas vegas del Turia, a unos 200 m sobre el nivel del mar, y a mayor altitud, las planicies de El Olivar y Gabaldón; los Llanos del Higueral y el Campillo constituyen altiplanicies de cierta importancia, sobre todo este último, de considerable extensión y a unos 750 metros de altitud. Son muy numerosos los barrancos, como los del Regajo, Barco, Morenillo, Boquerillas y Escoba, así como las fuentes, entre las que destacan, aparte de las citadas, las del Alcaide, Pocino, Murté, Molinero, Antón Andrés y de la Peña Roya. Las tierras no cultivadas están cubiertas por pinos, romero, sabinas y esparto. 

Gestalgar forma, junto con Bugarra y Pedralba, una especie de subcomarca en la ribera del curso medio del Turia, que tradicionalmente ha pertenecido al área de influencia de Llíria; pero el carácter castellanohablante de estos municipios hace que se les incluya en la comarca de Los Serranos. 

Se accede a Gestalgar desde Valencia, a través de la CV-35, tomando después la CV-376 y la CV-377 (por Liria y Pedralba). Otra posibilidad es acceder por la A-3, tomando luego la CV-370 y finalmente la CV-379. 

Sot de Chera, Chulilla, Bugarra, Cheste, Chiva, Siete Aguas y Chera, todas ellas en la provincia de Valencia.

Existen pinturas rupestres neolíticas de Arte Esquemático en Las Clochas, al suroeste del término, que fueron descubiertas ya en el verano de 1979 por José Antonio del Valle, vecino de Dos Aguas, y han sido catalogadas y estudiadas por varios especialistas. (Martínez Valle y Guillem Calatayud 2006). También se han descubierto restos eneolíticos, del Bronce Valenciano y de la época ibérica (Aparicio Pérez 1979, 1983 y 1984; Martínez Perona 1975). Los restos de un poblado de la Edad de Bronce que existen en la Terrosa, al noreste del término, fueron descritos por Pla Ballester en 1973 y por Martínez Perona en 1975. Los demás vestigios de ocupación humana de este término municipal corresponden ya a tiempos de la romanización: una lápida con inscripción latina encontrada en una hondonada frente al molino inmediato a la localidad, los restos de una posible villa rústica cerca del cruce de la carretera de Pedralba con el río Turia, y cerámicas en la Loma y en la Pieza de Anastasio.

La primitiva alquería de Xest Algar es de origen islámico, pero carecemos de documentos que nos permitan una aproximación cronológica. En efecto, la primera mención escrita de Xestalgar corresponde a su incorporación a la Cristiandad, al producirse la conquista del territorio por Jaime I y su donación en 1238 al noble Rodrigo Ortiz. En 1255 fue vendida a Artal de Huerto y donada en 1277 a Martín Roig, el cual la vendió a la Corona en 1295. Al año siguiente, 1296, Jaime II la vendió a Bernardo Guillermo de Entenza. Buena parte de las transmisiones del señorío entre nobles puede seguirse en el Cartulari de Gestalgar, conjunto de valiosos documentos transcritos y publicados por Manuel Pastor (2004). 

Desde el punto de vista socioeconómico, los habitantes de Gestalgar y del núcleo de poblamiento anexo de La Andenia, todos mudéjares, quedaron feudalizados y sometidos al vasallaje de los distintos señores; el régimen de tenencia de la tierra era la enfiteusis.
Tras diversos traspasos entre nobles, a principios de la Edad Moderna pasó a Salelles de Montpalau (1484). El linaje de los Montpalau mantendría el señorío durante dos centurias. 

La primera noticia sobre el volumen demográfico del Gestalgar mudéjar corresponde al año 1488 y asigna a la villa 49 fuegos. Esa débil demografía está en consonancia con la tendencia regresiva de los mudéjares valencianos a lo largo de la Baja Edad Media. 

En efecto, la población de Gestalgar fue mudéjar hasta los bautismos forzosos practicados durante las Germanías, que se hicieron extensivos a todos los mudéjares del Reino de Valencia (1525). Poco después, la mezquita se transformó en iglesia dependiente de la parroquia de Chulilla, de la que se independizó en 1535. A pesar de ser oficialmente "cristianos nuevos", siguieron viviendo según sus costumbres islámicas, hablando árabe y practicando el islam de forma discreta (moriscos). Felipe III ordenó la expulsión de los moriscos de la Monarquía Hispánica en 1609; justo antes de su expulsión, el Censo de Caracena asignó a Gestalgar 270 fuegos, pero otros estudios estiman su población en 150 casas como máximo, ya que esa era la cifra que daba el propio señor de Gestalgar, Baltasar de Montpalau, en un memorial posterior en el que se quejaba de los perjuicios causados por la expulsión. Según los registros de embarque estudiados por Lomas Cortés, los expulsados de Gestalgar fueron un total de 472 individuos, que abandonaron la Península por el puerto de Denia el 25 de noviembre de 1609 en tres barcos franceses.

Fue Baltasar de Montpalau quien repobló la villa con cristianos viejos tras la expulsión de los moriscos, el mismo que más tarde sería investido conde por Felipe IV. Dicho noble otorgaba carta de población el 30 de mayo de 1611 a 53 familias, que ascendían a 62 en enero de 1612, fecha de los establecimientos oficiales de casas y tierras. En cuanto al linaje Montpalau, entroncó con los condes de la Alcudia (finales del siglo XVII) y de Carlet (siglo XVIII).

Una generación después de la expulsión de los moriscos, en 1646, solo contaba con 76 casas, que aumentaron a un centenar en 1681 según Vicente Marés, y a 133 según el impuesto del equivalente del año 1730. Los censos históricos posteriores ofrecen ya datos de habitantes, que ascienden a 739 en el Censo de Aranda (1768) y a 928 en el de Floridablanca (1787). Por su parte, Cavanilles dio 260 casas hacia 1792. 

Los problemas de lindes con Sot de Chera se produjeron de modo intermitente durante dos siglos, entre 1654 y 1853, pero las delimitaciones han sido más estables y menos conflictivas con Chulilla, prácticamente las mismas desde el siglo XIII. 

Durante la Guerra de Sucesión (1705-1707 en tierras valencianas), los vecinos de Gestalgar respaldaron al Archiduque Carlos de Austria y se negaron a pagar las prestaciones señoriales a la condesa, Francisca Felipa de Monsoriu Mompalau y Centelles, la cual recuperó el control del señorío tras la batalla de Almansa (1707) aunque un puñado de migueletes gestalguinos resistió frente a los botiflers hasta 1714.

Su última señora feudal fue Josefa Dominga Catalá de Valeriola, duquesa de Almodóvar, que fue condesa de Gestalgar entre 1800 y su muerte en 1814. Al publicarse su testamento, que había redactado en 1804, los habitantes de Gestalgar supieron que había testado en favor de su propia alma, dotando de fondos las escuelas de primeras letras de Gestalgar y otros señoríos. En 1811, además, se había decretado en España la primera abolición de los señoríos. Por todo ello, los gestalguinos no comprendieron que la "sucesión" del condado de Gestalgar recayese en favor del matrimonio Frígola-Mercader, y después en favor de su yerno, Antonio de Saavedra, según varias decisiones judiciales. Pero en 1837, la ley de 26 de agosto abolió definitivamente los señoríos y el título pasó a tener una consideración nada más que honorífica.

Están documentadas algunas incursiones carlistas en la villa entre 1835 y 1838. En julio de 1854 se produjo en la plaza de la Villa un enfrentamiento armado, que a pesar de la "derrota" progresista fue el preludio del Bienio Progresista en España (Azagra 1978). En 1888 el municipio ya estaba dotado de un Puesto de Guardia Civil. 

Desde el punto de vista demográfico, Gestalgar tenía un total de 1516 habitantes en el primer censo de la serie estadística española (1857), y alcanzó su máximo histórico en 1910, con sus 1863 habitantes "de hecho" y 1886 "de derecho". 

El proyecto franquista de Vilanova (1972) que trataba de urbanizar un territorio de 1300 hectáreas segregadas de los municipios de Ribarroja del Turia, Loriguilla y Gestalgar tropezó en este último municipio con la firme y unánime oposición de los vecinos, y fue el primero en descartarse.

Su población (1.755 habitantes en el año 1900) aún subió a 1886 habitantes en 1910, pero después se estancó y desde 1950 ha sufrido un acelerado descenso debido al éxodo rural. 

El municipio es esencialmente agrícola. La superficie no cultivada ocupa unas 4.800 hectáreas, tres cuartas partes de su término, con un claro predominio del matorral (3.500 hectáreas) sobre el área forestal (1.200 hectáreas). Los cultivos de secano ocupan 1.300 hectáreas, sobre todo de algarrobos, olivos y almendros, mientras que el regadío dispone de algo más de 200 hectáreas, situadas en las proximidades del río Turia, y en su mayor parte dedicadas a naranjos, frutales no cítricos y hortalizas. Hay, además, ganado ovino y cabrío.








 



</doc>
<doc id="41164" url="https://es.wikipedia.org/wiki?curid=41164" title="Manuel Blum">
Manuel Blum

Manuel Blum (Caracas, Venezuela 26 de abril de 1938) es un informático venezolano conocido por ser el único sudamericano que ha recibido Premio Turing en 1995 "En reconocimiento de sus contribuciones a los fundamentos de la teoría de la complejidad computacional y su aplicación a la criptografía y la verificación de programas".

Sus contribuciones incluyen el generador de números pseudoaleatorios Blum Blum Shub, el ""stream cypher"" de Blum-Goldwasser, y más recientemente Captchas.

Blum nació en una familia judía venezolana.  Blum se educó en el Instituto de Tecnología de Massachuset (MIT), donde recibió su licenciatura y su maestría en EECS en 1959 y 1961, respectivamente, y su Ph.D. en matemáticas en 1964 supervisado por Marvin Minsky.

Trabajó como profesor de ciencias de la computación en la Universidad de California, en Berkeley hasta el año 1999. Desde el 1999 al año 2018, fue profesor de ciencias de la computación en la Universidad Carnegie Mellon (CMU), donde su esposa, Lenore Blum,  también fue profesora de informática. En el año 2002 fue elegido miembro de la Academia Nacional de Ciencias de los Estados Unidos.

Él y su esposa renunciaron a CMU en 2018 para protestar contra el sexismo. 

Durante las décadas de 1960 desarrolló una teoría de la complejidad axiomática. La teoría se basa en la numeración de Gödel y los axiomas de Blum. Aunque la teoría no se basa en ningún modelo de máquina, produce resultados concretos como el teorema de compresión, el teorema de la brecha , el teorema de la honestidad y el teorema de aceleración de Blum.

Algunos de sus otros trabajos incluyen un protocolo para lanzar una moneda por teléfono, una mediana de medianas (un algoritmo de selección de tiempo lineal), el generador de números pseudoaleatorios Blum Blum Shub , el criptosistema Blum-Goldwasser y más recientemente CAPTCHA. 

Blum también es conocido como el asesor de muchos investigadores destacados. Entre los doctorados algunos de sus estudiantes son Leonard Adleman, Dana Angluin, Shafi Goldwasser, Mor Harchol-Balter, Russell Impagliazzo, Silvio Micali, Gary Miller, Moni Naor, Steven Rudich, Michael Sipser, Ronitt Rubinfeld, Umesh Vazirani, Vijay Vazirani, Luis von Ahn y Ryan Williams.


</doc>
<doc id="41166" url="https://es.wikipedia.org/wiki?curid=41166" title="Talagante">
Talagante

Talagante es una y comuna chilena, capital de la provincia homónima de la Región Metropolitana de Santiago.

Integra, junto con las comunas de Alhué, Curacaví, Isla de Maipo, María Pinto, Melipilla, El Monte, Padre Hurtado, Peñaflor y San Pedro, el Distrito Electoral N° 31 y pertenece a la Circunscripción Senatorial 7ª de la XIII región Metropolitana. Su actual alcalde es Carlos Álvarez.

Talagante su nombre del quechua "Tala"-"Canta"-"Ilabe", y significa «lazo de hechicero», el cual era el nombre propio del curaca o gobernante inca que administraba este valle del Chile Central a la llegada de los españoles. Después, en época del Virreinato, Talacanta pasó a ser Pueblo de indios.

Las coordenadas geográficas de Talagante son las siguientes:

La comuna se encuentra en el valle central de Chile, a 35 km al sudoeste de Santiago, entre los -33º37', -33º 47' latitud sur y los 70º 48', 71º 01' Oeste. Forma parte de la Provincia de Talagante, junto a las comunas de Peñaflor, con la que limita por el norte; Padre Hurtado; El Monte con la que limita por el oeste; Isla de Maipo por el Sur, y al este con Calera de Tango. Además de la ciudad de Talagante, la comuna tiene pueblos en el interior, como es el caso de Lonquén.

La comuna de Talagante está bañada por los ríos Mapocho y Maipo. La ciudad de Talagante se ha extendido, por autopista, hacia el occidente, en dirección al puerto de San Antonio y su configuración urbana mantiene la forma de tablero de ajedrez, destacando en el centro la Plaza de Armas, que es redonda.

Las primeras pistas de seres humanos en la zona, datan de 2000 años aproximadamente. Dichos habitantes practicaban la caza de animales como el guanaco, y el zorro, además de aves y roedores, así como la recolección de vegetales silvestres.

La primera comunidad que se ha encontrado, corresponde a la Tradición Bato, que se establece alrededor de los 300 A.C y 400 D.C, compartiendo pautas culturales con la Cultura Molle, que se ubicaba más al norte. Característico de dicha cultura fue el uso del tembetá; además se encontraron morteros, que son elementos de piedra usados en la molienda de vegetales y minerales. La evidencia del lugar de este grupo está en el ex fundo Trebulco y en La Manresa, ubicados en la localidad de Lonquén.

La segunda cultura de la cual hay hallazgos, tiene nombre de Complejo Cultural Llolleo, establecido entre los 200 y 800 D.C, coexistente con la Tradición Bato. Esta cultura destinaba gran dedicación y tiempo a la horticultura. También se ha identificado claramente el uso de ciertos elementos culturales, (de los cuales la cerámica es el más significativo), vasijas con forma humana, y de animales. Entre las costumbres funerarias, figura la utilización de urnas de greda, y arcilla. Esta cultura se evidencia en el sector central de Talagante, más específicamente en calle Balmaceda con O'Higgins, donde actualmente hay un supermercado.

Entre los años 900 y 1400 D.C se encuentra la Cultura Aconcagua, un nuevo grupo de agricultores, que también se dedicaban a la alfarería. Un elemento cultural importante lo constituye la forma externa de las tumbas. Para construirlas se creaba intencionalmente una acumulación de tierra, de forma circular, por sobre el nivel natural del terreno. Las formas de molienda fueron populares también. Este trabajo se realizaba en rocas grandes, en las cuales se practicaban numerosas horadaciones que servían para moler vegetales y minerales.

El Sapa Inca Pachacútec inició una campaña expansiva que sus herederos concluyeron fijando como límite el río Maule. El comandante inca Ilabe se estableció en el valle de Llollehue. Allí además se fundó una colonia y un pukará, que quedaron a cargo de Tala Canta Inca Ilabe, el hijo del inca. De allí derivó el nombre de Talagante.

Fundada la capital del El Reino de Chile, Bartolomé Blumenthal carpintero y constructor,(además de financista de Valdivia) lo comisionaron para buscar madera hacia esta tierra. Así fue como Blumenthal, llega a las tierras de los pukarás del Inca Tala Canta, tuvieron un gran entendimiento, no solo le dieron madera también le dio mano de obra para la construcción de Santiago, también se empezó a interesar en las vasijas de arcilla que lo impresionaron. La familia del inca fue convertida al cristianismo y la novia de Bartolomé Blumenthal fue bautizada como Elvira, pasando a ser la nueva cacique Elvira de Talagante.

Los servicios de Blumenthal fueron recompensados por Pedro de Valdivia, con la cesión de la encomienda de los caciques. En 1555, Blumenthal, castellaniza su nombre llamándose Bartolomé Flores, después tiene una hija con Elvira de Talagante, quien se llamó Águeda Flores, que luego sería abuela de Catalina de los Ríos y Lisperguer, apodada La Quintrala. Flores fallece en 1585, dejándole el poder a su esposa Elvira, que se destacó con su observancia católica, por los misioneros que se encontraban en San Francisco del Monte.

En mayo de 1604, Ginés de Lillo, en cumplimiento por ordenanza del reino, llegó a Talagante procediendo a medir y ratificar las dominaciones de Elvira de Talagante, que falleció a fines de ese año, pasando todas sus posesiones a Agüeda Flores, quien se casó con el capitán Pedro Lísperguer.

El 13 de mayo de 1647, Talagante fue sucumbido por un gran terremoto, quedando en el suelo gran parte de las construcciones y hubo crudos inviernos, en el cual nevó 3 días seguidos, lo cual es la situación más desastrosa de la ciudad.

Ya a mediados del siglo XVIII, era un paso de carreteras hacia Valparaíso.

Durante la Reconquista Española, Marcó del Pont, se nombró a la nueva cacica Martina de los Santos Toro, quien gobernó a 200 familias que vivían en torno a la posada. Después de la Batalla de Chacabuco, no se supo nada más de ella.

Asumió José de los Santos Toro quien, en el año 1822, fue visitado por María Graham, inglesa que recorrió la zona de Talagante, dejando un escrito llamado "Diario de mi residencia en Chile en 1822".

Talagante fue oficialmente fundada en diciembre de 1837, con las firmas del presidente de Chile, José Joaquín Prieto y Joaquín Tocornal Jiménez, con el nombre de "Villa Santa Maria de Talagante". 

Abundantes datos históricos de Talagante figuran en el libro "Historia de Talagante", del periodista Hernán Bustos Valdivia, publicado en 2008.

En los años 1950, por Talagante provenían desde San Antonio, un grupo de arrieros que se dirigían a Santiago a lomo de mulas con cochayuyo, y pasaban a descansar en la propiedad de Don Luis Gilberto Cobarrubias; un ciudadano ilustre de la comuna con una gran participación en el progreso de la ciudad; de allí estaban descansando 2 a tres días y luego continuaban a Santiago. La propiedad de la familia Cobarrubias en época de la colonia, también sirvió como estación de cambio de caballos para las "diligencias" que trasladaban pasajeros hacia San Antonio.

Talagante pertenece al Distrito Electoral Nº14 ("Provincias de Melipilla, Talagante y Maipo"). Es representada en la Cámara de Diputados del Congreso Nacional por los diputados Raúl Leiva Carvajal del PS, Marisela Santibáñez Novoa del PCCh, Juan Antonio Coloma Álamos de la UDI, Nora Cuevas Contreras de la UDI, Leonardo Soto Ferrada del PS y Renato Garín González de RD. A su vez, es representada en el Senado por los senadores Guido Girardi Lavín del PPD y 
Marcela Sabat Fernández de RN. 

La Ilustre Municipalidad de Talagante es dirigida por el alcalde Carlos Daniel Álvarez, el cual es asesorado por los concejales:

Las actividades económicas de Talagante, fueron en base de la agricultura, ya que en dicho territorio hubo muchas haciendas, en la época de la Colonia. También floreció la alfarería, y después, la empresa textil que ha ido declinando.

Con respecto a la artesanía destaca la Loza Policromada de Talagante, ésta surge a principios del siglo pasado de las manos de las hermanas María y Luisa Jorquera Díaz, quienes siguiendo la antigua técnica de las Monjas Claras, comenzaron a realizar pequeñas figuras que reproducen hechos, alegorías y personajes de la vida cotidiana de aquel entonces, como el Cuasimodo, el Pollero –vendedor de aves a caballo-, el Organillero, la Amasandera, la Lavandera, entre otras. Se trata de una artesanía muy particular, compuesta por pequeñas piezas que no superan los 20 centímetros, modeladas a mano, brillantes y muy coloridas que recrean imágenes costumbristas con bastante detalle.

Esta tradición heredada por la Familia Díaz Jorquera de Talagante prosigue hasta nuestros días y es así como esta hermosa expresión artesana de Chile ha sido obsequiado a jefes de estado y dignatarios del mundo. De hecho, un “Cuasimodo” en Loza Policromada recibió el Papa Juan Pablo II durante su visita a Chile en 1987, y en el mes de noviembre de 2007 la Presidenta Michelle Bachelet llevó una figura similar al Romano Pontífice, Benedicto XVI.

La principal actividad económica está dada por el área de servicios con desarrollo y presencia de 6 Bancos que son Banco Santander, Banco de Chile, Banco Desarrollo de Scotiabank, Banco Fallabella, Banco Estado y Bbva. Asimismo, entidades financieras como Coocretal y un desarrollo de empresas nacionales como son CMPC (papelera), Viña Undurraga, Montina (Ariztia), Nutrabien, entre otras.
Uno de los problemas que enfrenta la comuna es la creciente concentración económica en sectores como el transporte, el farmacéutico y el retail. La locomoción colectiva está controlada por la Flota Talagante, lo que ha dado paso a reclamos de los usuarios con acusaciones de monopolio, malos tratos a los estudiantes y fijación arbitraria de tarifas al llegar y mantener. En el retail existen dos grandes operadores de supermercados: supermercados Tottus (ex-San Francisco, con 2 locales: Plaza y Cordillera) y Líder (una plaza de ventas), Agregándose en 2011 la cadena de supermercados Econo y un local de Bigger en construcción. Se encuentran también tiendas como ABCDin, Dijón y Tricot. En tanto en el mercado farmacéutico se repite la pelea a nivel nacional entre Cruz Verde (2 sucursales), Farmacias Ahumada (3 locales) y Salco Brand, dejando en una posición minoritaria a los pequeños farmacéuticos como Farmacia del Sol, Farmacias San Juan, Dr. Simi, o Farmacias Serrano en Melipilla

En 2018, la cantidad de empresas registradas en Talagante fue de 1.696. El Índice de Complejidad Económica (ECI) en el mismo año fue de 1,03, mientras que las actividades económicas con mayor índice de Ventaja Comparativa Revelada (RCA) fueron Grandes Tiendas, Productos de Ferretería y Hogar (103,02), Elaboración de Bebidas Malteadas, Cervezas y Maltas (95,12) y Cultivo de Otros Cereales (86,83).

En el plano laboral, un alto porcentaje de la población trabaja fuera de la comuna. En primer lugar, un importante número de personas se desplazan al Gran Santiago, donde se concentran los servicios financieros y educacionales, entre otros. Por otro lado, una gran cantidad de personas realizan trabajos de temporada agrícola en las fundos y parcelas de otras comunas de la provincia como Isla de Maipo, El Monte, Padre Hurtado, Peñaflor y dentro de la misma comuna.

La comuna cuenta con cuatro radios. Dos de ellas AM (Progreso y Manantial) y otras dos FM (Manantial FM y Contacto.)
La actividada comercial está radicada en la calle Bernardo O"Higgins, donde se congregan en cuatro cuadras negocios minoristas.
En la comuna se encuentra el Complejo Químico del Ejército, en el que se elaboran una serie de substancias usadas para fabricar armas y con otros fines.

Desde el año 2006, producto de la publicación del Plan Regulador Metropolitano de Santiago, que fija una cuota importante de hectáreas de crecimiento urbano y que da inicio al desarrollo de Plan Regulador Comunal, han surgido organizaciones comunales como el Comité de Adelanto por un Talagante Sustentable, el cual busca informar a los ciudadanos los efectos del crecimiento no regulado si no se acompaña de las obras y servicios acorde a un crecimiento del más de 200%. Así mismo apoyar a los ciudadanos en que tomen conciencia de lo fácil que es caer en que poderes económicos de unos pocos afecten la vida de 60 000 habitantes.

Las Fuerzas de Orden y Seguridad de Chile están compuestas por Carabineros de Chile y la Policía de Investigaciones de Chile. La Unidad Policial territorial de la PDI en la comuna es la Brigada de Investigación Criminal Talagante o BICRIM Talagante, con área de competencia en las comunas de Talagante, El Monte e Isla de Maipo, cuya función principal es investigar delitos de distinta índole a nivel local encomendadas por los Tribunales de Justicia y el Ministerio Público, como también acoger denuncias, entre otras labores. Esta Unidad Policial, al igual que sus pares, cuenta con grupos internos, uno de ellos dedicado a la investigación del tráfico de drogas en pequeñas cantidades, es denominado Grupo Microtráfico Cero o MT-0, además de contar con una Oficina de Análisis Criminal.

La comuna cuenta con un Centro de Atención Primaria inaugurado recientemente el CESFAM (Dr. Alberto Allende Jones) dividido en dos partes, una radicada en el sector poniente de la comuna y otro en el sector centro, y para su atención se ha dividido a la comuna en sectores para su atención en su respectivo Centro de salud. También tiene el Centro de Salud mental COSAM de Talagante. Además cuenta con el Hospital de Talagante (Puertas Abiertas).
También la comuna tiene diversos centros médicos.

El Cuerpo de Bomberos de Talagante fue fundado el 13 de abril de 1945. Consta de tres compañías entrenadas y organizadas para proteger la comuna:


Su centro deportivo es el Estadio Municipal Lucas Pacheco Toro, en donde actúa el club deportivo de Tercera A Provincial Talagante; también se encuentra el gimnasio recreativo deportivo Roberto Torres Miranda donde se practican deportes tales como Taekwondo, gimnasia artística, básquetbol, baby fútbol, entre otros. Además, Talagante cuenta otro recinto municipal; la cual es piscina Tegualda donde se pueden practicar deportes como la natación y juegos interactivos en ella.

Cuenta con el gimnasio municipal Victor Soto Bastías.

También cuenta con un Skatepark en el Parque Octavio Leiva, donde se realizan deportes extremos como el Skateboarding, el Bmx, entre otros.



En Talagante se captan los principales medios de comunicación (tanto radios como televisión) provenientes del Gran Santiago.





</doc>
<doc id="41167" url="https://es.wikipedia.org/wiki?curid=41167" title="Idioma galés">
Idioma galés

El galés (autoglotónimo "Cymraeg") es un idioma perteneciente al grupo britónico de la familia de lenguas celtas. Es hablado en el país de Gales, donde aproximadamente 857 600 personas (el 28% de la población galesa) lo utilizan como su lengua principal, especialmente en la zona norte del país. El galés es el idioma oficial junto con el inglés. 

También se habla en diversas zonas del sur de Argentina, más específicamente en la provincia de Chubut, donde vive la mayor comunidad galesa fuera de las islas británicas (véase galés patagónico).

Hoy en día hay escuelas y universidades que enseñan tanto en galés como en inglés. El Gobierno galés y todos los servicios públicos son bilingües. Hay varios periódicos, revistas, y emisoras de radio disponibles en galés y también, desde 1982, un canal de televisión en este idioma, llamado Sianel Pedwar Cymru o S4C.

El galés era la lengua principal del país hasta que el rey Eduardo I de Inglaterra sometió el país a la Corona británica, durante el siglo XIII. Aunque el inglés es la lengua dominante en la actualidad, el galés todavía es importante, y no se observa riesgo de desaparición a corto plazo.

Cabe destacar que el galés fue uno de los idiomas predilectos del famoso escritor y filólogo J. R. R. Tolkien (quien usó algunos de sus sonidos para sus lenguas artísticas, especialmente el sindarin). En su ensayo titulado «Un vicio secreto» incluyó el galés entre los «idiomas que poseen una característica y, cada uno a su modo, bella formación de palabras». En otro ensayo, titulado «El inglés y el galés», analizó la palabra inglesa "Welsh" (‘galés’).

Como la mayoría de las lenguas, en la historia del galés existen períodos identificables, a pesar de que las fronteras entre ellas sean a menudo muy difusas.

Las fuentes más antiguas de una lengua identificable como galés se remontan hasta aproximadamente el siglo VI, y la lengua de este período se conoce como "Galés primitivo". Queda muy poco de este período. El siguiente período principal, algo mejor testimoniado, es el galés antiguo ("Hen Gymraeg") (siglos IX a XI); conservamos poesía tanto de Gales como de Escocia en esta forma de la lengua. Cuando la colonización germánica y gaélica de Gran Bretaña progresó, los hablantes britónicos en Gales se encontraron separados de los de Inglaterra septentrional, hablantes de cúmbrico, y de los del sudoeste, hablantes de la lengua que después se convirtió en córnico, y de esta manera las lenguas se separaron. A esta época pertenece tanto el "Canu Aneirin" como el "Canu Taliesin".

"Galés medio" (o "Cymraeg Canol") es la etiqueta puesta al galés de los siglos XII a XIV, período del que nos quedan más restos que del anterior. Esta es la lengua de casi todos los manuscritos antiguos supervivientes del "Mabinogion", a pesar de los cuentos mismos son mucho más viejos. Es también la lengua de los manuscritos existentes de la Ley galesa. El galés medio es razonablemente inteligible para un hablante de galés moderno con un poco de trabajo.

El galés moderno puede dividirse en dos períodos. El primero, llamado "galés moderno inicial" va desde el siglo XIV hasta aproximadamente el final del siglo XVI, y fue la lengua usada por Dafydd ap Gwilym. 

Esta etapa comienza con la publicación de la traducción de la Biblia de William Morgan en 1587. Como en el caso de la traducción al inglés, la versión de rey Jacobo, demostró tener un efecto de estabilización en la lengua. Por supuesto, ha habido mucho cambio menor en la lengua desde aquella.

La lengua tuvo un nuevo auge en el siglo XIX con la publicación de algunos de los primeros diccionarios completos del galés. El trabajo anterior de los pioneros lexicógrafos galeses, tales como Daniel Silva Evans, se aseguraron de la correcta documentación de la lengua, y los diccionarios modernos como el "Geiriadur Prifysgol Cymru" (o Diccionario de la Universidad de Gales), son descendientes directos de estos diccionarios.

Con todo, el influjo de los trabajadores ingleses durante la Revolución Industrial en Gales desde aproximadamente el 1800 llevó a una adulteración sustancial de la población de habla galesa de Gales. Los inmigrantes ingleses rara vez aprendían galés y sus colegas galeses tendían a hablar en inglés cuando había algún inglés, y el bilingüismo se hizo casi total. El estatus legal del galés era inferior al del inglés, y, de esa manera, el inglés poco a poco comenzó a prevalecer, excepto en las áreas más rurales, particularmente en el noroeste y en el centro de Gales. Una excepción importante, con todo, fueron las iglesias no conformistas, que estaban fuertemente asociadas con la lengua galesa.

En el siglo XX el número de hablantes de galés descendió a un punto que hacía prever la extinción de la lengua en pocas generaciones. La primera vez que el censo decenal comenzó a preguntar cuestiones lingüísticas fue en 1891, en esta época el 54 % de la población todavía hablaba galés. El porcentaje descendía con cada censo, hasta alcanzar la tasa más baja en 1981 (19 %):


En 1991 la posición era estable (19 % como en 1981) y en el censo más reciente, 2001, subía hasta un 21 % que podía hablar galés. El censo de 2001 también registra que el 20 % podía leer galés, el 18 % lo podía escribir y el 24 % lo podía comprender. Además, el porcentaje más elevado de hablantes de galés estaba entre la juventud, cosa que presagia algo bueno para el futuro del galés. En 2001, el 39% de los niños de entre 10 y 15 años sabían hablar, leer y escribir galés (muchos aprendiéndolo en la escuela), comparado con 25 % de los de 16 a 19 años. Con todo, el porcentaje de hablantes de galés en áreas donde es hablado por la mayoría está todavía en declive.

Al mismo tiempo que aumentó la influencia del nacionalismo galés, el idioma empezó a recibir apoyo y ayudas gubernamentales, todo ello añadido al establecimiento de la radiotelevisión en lengua galesa. Esta encontró una masa de audiencia que estaba preocupada por el estancamiento de la lengua.
Posiblemente, el acontecimiento reciente más importante es que a finales del siglo XX el estudio del galés se fijó como obligatorio para todos los alumnos de hasta 16 años, y esto reforzó la lengua de las áreas de habla galesa, reintroduciendo al menos un conocimiento elemental de galés en áreas que se habían convertido en casi completamente anglófonas. Se detuvo la caída del porcentaje de galeses que saben hablar galés y asimismo hay signos de una modesta recuperación. Con todo, a pesar de ser el galés la lengua cotidiana en algunas partes del país, el inglés es comprendido por todo el mundo.

El galés se escribe en una versión del alfabeto latino que consta de 28 letras, de las que ocho son dígrafos tratados como letras simples a efectos de contexto:

La letra "j", a pesar de no emplearse originariamente para escribir en galés, se tomó prestada del alfabeto inglés y es usada en algunos préstamos.

El diacrítico más usual es el circunflejo, que se usa en algunos casos para marcar una vocal larga.

El galés tiene los siguientes fonemas consonánticos:

Para las vocales se tiene el siguiente inventario vocálico:

Las vocales e solo aparecen en los dialectos del norte; en los del sur son sustituidas por e respectivamente. En los dialectos meridionales, el contraste entre vocales largas y breves solo se encuentra en sílaba tónica; en los dialectos septentrionales, el contraste solo se encuentra en sílabas finales acentuadas (incluyendo monosílabos).

La vocal no aparece en sílaba final de palabra (excepto en unos pocos monosílabos).

Los diptongos que contienen solo aparecen en los dialectos septentrionales; en los dialectos meridionales es sustituido por , convergen en , y convergen en .

El acento en polisílabos aparece normalmente en la penúltima sílaba, muy raramente en la última. La colocación del acento significa que palabras y conceptos relacionados (o mismamente plurales) pueden sonar bastante diferentes, cuando se le añaden sílabas al final de una palabra y el acento se mueve en correspondencia, e.g.:

(Es de destacar también que al añadir una sílaba a "ysgrifennydd" para formar "ysgrifenyddes" cambia la pronunciación de la segunda "y". Esto se debe a que la pronunciación de la "y" depende de si está en la sílaba final o no).

La morfología del galés tiene mucho en común con las dos otras lenguas británicas modernas, como el uso de las mutaciones consonánticas iniciales, y el uso de las llamadas "preposiciones conjugadas" (preposiciones fusionadas con pronombres personales). Los sustantivos pueden ser masculinos o femeninos y carecen de declinación. En galés existe toda una variedad de terminaciones que expresan el plural y dos para indicar el singular de algunos sustantivos. En el galés coloquial la conjugación verbal se indica principalmente a través del empleo de verbos auxiliares pero con la conjugación del propio verbo. En galés literario, por otra parte, es usual la conjugación del verbo propio.

En galés 'Me gusta Rhodri' es "Dw i'n hoffi Rhodri" ("Estoy a gustar [de] Rhodri"), pero "'Él" me gusta' es "Dw i'n ei hoffi fe" —literalmente, "Estoy en "su" gustar a él"; tú" me gustas' es "Dw i'n dy"' hoffi di" ("Estoy en "tu" gustar a ti"), etc.

El galés no literario tiende muy frecuentemente al empleo de verbos auxiliares. En el presente, todos los verbos se forman con el auxiliar "bod" 'ser'; así, "dw i'n mynd" es literalmente "estoy a ir", pero significa simplemente 'yo voy'. 

En pasado y futuro, hay formas conjugadas de todos los verbos (que son invariablemente usadas en la lengua escrita), pero hoy en el habla es mucho más común usar el sustantivo verbal ("berfenw") junto con la forma conjugada de "gwneud" 'hacer'; así, 'yo fui' puede ser "mi es i" o "mi wnes i fynd" y 'yo iré' puede ser "mi a' i" o "mi wna i fynd". Hay también una forma futura con el auxiliar "bod", dando "fydda i'n mynd" (traducido más correctamente como 'estaré yendo') y un imperfecto (un tiempo pasado continuo/habitual) que también usa "bod", con "roeddwn i'n mynd" significando 'yo solía ir/estaba yendo'.

"Mi" o "fe" se sitúan frecuentemente antes de los verbos conjugados para indicar que son enunciativos. En el presente e imperfecto del verbo "bod" 'ser', se emplea "yr". "Mi" está más restringido al galés septentrional coloquial, mientras que "fe" predomina en el sur y en el registro formal o literario. Tal rasgo de la enunciación es, en todo caso, mucho menos común en registros elevados.

El sistema de cómputo tradicional usado por la lengua galesa es el vigesimal, es decir, basado en las veintenas, como en los numerales franceses desde el 60 al 99, donde los números del 11 al 14 son ""x" sobre diez", del 16 al 19 son ""x" sobre quince" (a pesar de ser el 18 normalmente "dos nueves"); los números del 21 al 39 son "1–19 sobre veinte", 40 es "dos veintenas", 60 es "tres veintenas", etc.

Hay también un sistema de cómputo decimal, del gusto de la juventud, pero común en el sur de Gales, y que parece ser el más empleado en el galés de Patagonia, donde los números son ""x" diez "y"". Por ejemplo, 35 en este sistema es "tri deg pump" ('tres diez cinco') mientras que en vigesimal es "pymtheg ar hugain" (quince [–en realidad "cinco-diez"]– sobre veinte).

Otra fuente de complicación es que mientras que solo hay una palabra para "un" ("un"), existen formas diferentes para el masculino y el femenino en los números "dos" ("dau" y "dwy"), "tres" ("tri" y "tair") y "cuatro" ("pedwar" e "pedair"), que han de concordar en género con el sustantivo, aunque esta regla es observada menos estrictamente con el sistema de cómputo decimal.
"

Notas:





Evangelio según Juan capítulo I 1-8 


</doc>
<doc id="41169" url="https://es.wikipedia.org/wiki?curid=41169" title="Ibn Battuta">
Ibn Battuta

Shams ad-Din Abu Abd Allah Muhammad ibn Muhammad ibn Ibrahim al-Luwati at-Tanyi (), más conocido como Ibn Battûta (), fue un viajero y explorador de la época de la dinastía Meriní, nacido en Tánger (act. Marruecos) el 17 de rayab del año 703 de la Hégira, correspondiente al 25 de febrero de 1304, y muerto en 1377.

Es el más conocido de los grandes viajeros musulmanes; su "rihla" o periplo por el Oriente duró veinte años, que relató con detalle en una crónica dictada al estudioso granadino Ibn Yuzayy, a instancias del sultán marínida (o benimerín). Prácticamente todo lo que se sabe de su vida procede de este relato que, aun siendo fantasioso o exagerado en algunos puntos, es el retrato más fiel que existe de la parte del mundo que el viajero recorrió en esa época. En su viaje cubrió una distancia mayor que la de su contemporáneo Marco Polo, recorriendo en total el oeste, centro y norte de África, parte del sur y el este de Europa, Oriente medio, la India, Asia central, el sureste asiático y China.

En 1976 la Unión Astronómica Internacional llamó «Ibn Battuta» a un astroblema lunar en su honor. El aeropuerto de Tánger, su ciudad natal, también lleva su nombre.

Muhámmad ibn Battuta inició su viaje con intención de realizar el "hajj" o peregrinación a La Meca que constituye uno de los cinco pilares del islam, y de visitar la tumba de Mahoma en Medina. Partió de Tánger, según su crónica, el 2 de rayab del 725 de la Hégira, 13 de junio de 1325, «"solo, sin compañero con cuya amistad solazarme ni caravana a la que adherirme"». Tenía entonces 22 años. No volvería hasta 24 años más tarde, después de haber recorrido más de 120.000 kilómetros, de un extremo a otro del mundo musulmán y fuera de él. Una de las versiones traducidas al castellano se ha denominado "A través del Islam", publicada en 1981.

Siguió la costa norte de África, a la que no presta mucha atención en su relato, hasta llegar a Egipto. Desde allí había tres rutas comúnmente usadas para ir a La Meca e Ibn Battuta escogió la menos frecuentada: un viaje Nilo arriba (esto es, hacia el sur) y luego hacia el puerto de Aydab en el mar Rojo. Sin embargo, una rebelión local le impidió llegar a Aydab, debiendo regresar a la capital egipcia.

Desde la capital arranca un periplo por el País de Sham (Siria y Palestina), que entonces formaba parte de los dominios de la misma dinastía mameluca —la dinastía Bahrí— que gobernaba Egipto. Esto le permitió desplazarse con cierta seguridad, ya que las autoridades mamelucas hacían un especial esfuerzo en mantener segura para los peregrinos la ruta que pasaba por los lugares santos de Hebrón, Belén y Jerusalén.

Tras pasar el mes de ramadán en Damasco, Ibn Battuta siguió con una caravana un viaje de 800 millas que hay hasta Medina, en cuya mezquita principal está enterrado Mahoma. Luego siguió viaje a La Meca, donde cumplió con los ritos habituales de un peregrino musulmán, adquiriendo el apelativo de "hayi" («peregrino»). En teoría había cumplido los objetivos de su viaje, pero en lugar de volver a Marruecos decidió acompañar a una caravana de peregrinos procedentes de Irak e Irán de regreso a sus hogares.

Ibn Battuta conoce el Irak gobernado por los mongoles. En primer lugar visita Nayaf, el lugar de enterramiento del cuarto califa, Ali ibn Abi Talib. Desde allí viaja a Basora y luego pasa a Persia, visitando Isfahán, Shiraz y otros lugares. Vuelve a Irak y visita Kufa y Bagdad, la antigua capital de los abbasíes, ahora convertida en ciudad de segundo orden tras haber sido saqueada por las tropas mongolas de Hulagu Jan.

En Bagdad conoce al joven Abu Saíd Bahador Jan, «rey de los dos Irak» y último gobernante del Iljanato unificado, cuya muerte y posterior fragmentación de su reino cuenta también Ibn Battuta en su relato, escrito varias décadas después. Viaja con la caravana real y se desvía de ella acompañando a uno de los príncipes a la ciudad persa de Tabriz en la Ruta de la Seda, para regresar luego al campamento de Abu Saíd. Obtiene del rey el patrocinio para realizar una segunda peregrinación a La Meca, regresando a Bagdad para hacer los preparativos. Ibn Battuta aprovecha el tiempo que resta hasta la salida de la caravana de peregrinos para visitar el norte del país, atravesando poblaciones como Samarra, Tikrit y Mosul y llegando hasta el Kurdistán.

En sus viajes por Irak y Persia, Ibn Battuta tiene ocasión de conocer a los chiíes, rama del islam inexistente en el Magreb, de cuyas creencias abomina y a quienes no oculta su antipatía.

Tras cumplir por segunda vez con el rito del "hach", Ibn Battuta permaneció en La Meca durante un año, dedicándose por entero a la vida religiosa, lo que le permitió trabar conocimiento con numerosos peregrinos.

Hacia diciembre de 1330 Ibn Battuta emprende viaje hacia el sur. En Yida se embarca hacia la costa nubia, en el actual Sudán, para cruzar de nuevo el mar Rojo poco después hacia el Yemen, donde es alojado por el Nur ad-Din Ali. De Adén arranca un largo viaje por mar con el que recorrerá las costas de África, el sur de la península arábiga y el golfo Pérsico. Pasando alrededor de una semana en cada uno de sus destinos, visitó Etiopía, Mogadiscio, Mombasa, Zanzíbar y Kilwa Kisiwani, entre otros. Con el cambio del monzón, el barco en que iba embarcado volvió hacia el sur de Arabia. Habiendo completado su aventura, antes de establecerse, inmediatamente decidió ir a visitar Omán y el estrecho de Ormuz. Hecho esto, viajó a la Meca otra vez.

Al cabo de un año, decidió buscar ocupación con el Sultán de Delhi. Necesitando un guía y traductor para viajar allí, fue a Anatolia, entonces bajo el control de los turcos selyúcidas, para unirse a una de las caravanas que iban hasta la India. Un viaje por mar desde Damasco en un barco genovés lo llevó hasta Alanya en la costa sur de Anatolia. Desde allí viajó por tierra a Konya y después a Sinope en la costa del mar Negro.

Cruzando el mar Negro, Ibn Battuta tomó tierra en Kaffa, en Crimea, y entró en las tierras de la Horda de Oro. Allí compró un carro y de manera fortuita se unió a la caravana de Ozbeg, el Khan de la Horda de Oro, en un viaje hasta Astracán en el río Volga.

Tras alcanzar Astracán, el khan permitió a una de sus esposas embarazadas volver a dar a luz en su ciudad de origen, Constantinopla. No es quizá una sorpresa para el lector que Ibn Battuta persuadiera a alguien para poder viajar en esa expedición, la primera de las suyas fuera de los límites del mundo islámico.

Tras llegar allí hacia el final del 1332, encontró al emperador Andrónico III y vio el exterior de Santa Sofía. Después de un mes en la ciudad, volvió sobre su ruta hacia Astracán, continuó más allá del mar Caspio y el mar de Aral a Bujará y Samarcanda. Desde allí viajó hacia el sur hasta Afganistán, cuyos pasos de montaña cruzó para seguir a la India.

El Sultanato de Delhi era una adición relativamente nueva a "Dar al-Islam" (la tierra del Islam), y el sultán había decidido traer tantos estudiosos musulmanes como fuera posible para consolidar su dominio. Con la sabiduría adquirida en sus años de estudio mientras estaba en La Meca, Ibn Battuta fue nombrado "qadi" ("juez") por el Sultán Muhammad bin Tughluq.

Pero el Sultán era incluso más arbitrario que lo usual en su época e Ibn Battuta pasó de vivir la cómoda vida de un subordinado de confianza a estar bajo sospecha por muchas razones. Con el tiempo decidió irse, bajo pretexto de hacer otra peregrinación a La Meca, pero el Sultán le ofreció la posibilidad de ir como embajador a China. Ante la oportunidad, tanto de alejarse del sultán, como de visitar nuevas tierras, Ibn Battuta aceptó.

En ruta hacia la costa, él y su grupo fueron atacados por rebeldes hindúes y separado de los otros le robaron y casi pierde la vida. No obstante, logró alcanzar a la caravana en dos días y continuó su viaje a Cambay. Desde allí embarcaron hacia Calicut. Pero, mientras Ibn Battuta visitaba una mezquita en la costa, se desencadenó una tormenta y dos de los barcos de su expedición resultaron hundidos. El tercero, entonces, partió sin él y terminó requisado por un rey local en Sumatra unos meses más tarde.

Temeroso de volver a Delhi fracasado, permaneció un tiempo en el sur, bajo la protección de Jamal al-Din, pero cuando este hombre justo fue derrocado, Ibn Battuta debió abandonar completamente la India. Decidió continuar hacia China con un desvío a las Maldivas.

En las Maldivas pasó nueve meses, mucho más de lo que se proponía. Su saber como "qadi" era muy apreciado en las islas y fue medio sobornado medio secuestrado para quedarse. Nombrado juez en jefe y casado dentro de la familia real, se llegó a ver enredado en la política local, y terminó por marcharse de mala manera, al imponer Battuta juicios estrictos en el reino isleño, habituado al "laissez-faire". Desde allí, continuó a Ceilán para visitar el Pico de Adán.

Al poco de salir de Ceilán, su barco casi se hundió en medio de una tormenta, luego el barco que lo rescató fue atacado por piratas. Desembarcado en la costa, Ibn Battuta una vez más rehízo su camino de vuelta a Calicut, desde donde navegó a las Maldivas de nuevo antes de embarcar en un junco chino y tratar otra vez de alcanzar China.

Esta vez tuvo éxito, alcanzando en rápida sucesión Chittagong, Sumatra, Vietnam, y finalmente Quanzhou, provincia de Fujian, en China. Desde allí siguió al norte hasta Hangzhou, no lejos de la moderna Shanghái. También pretendió haber viajado incluso más al norte, por el Gran Canal a Janbalic (خاب باليق) (Pekín), pero se cree que es una de sus invenciones, no un hecho real.

De vuelta a Quanzhou, Ibn Battuta decidió volver a casa, aunque era un pequeño problema saber exactamente dónde fuera «su casa». Volviendo a Calicut una vez más, consideró acogerse a la piedad de Muhammad bin Tughluq, pero lo pensó mejor y decidió seguir a la Meca otra vez. Volviendo vía Ormuz y el Il-Khanato vio que el estado se deshacía en una guerra civil, habiendo muerto Abu Sa'id desde su anterior viaje allí.

Volviendo a Damasco, con la intención de seguir otra vez la ruta de su primer "hach", supo que su padre había muerto. La muerte estuvo presente durante el año siguiente porque la Peste negra había comenzado, e Ibn Battuta estaba a su alcance conforme se extendía por Siria, Palestina y Arabia. Tras llegar a la Meca, decidió volver a Marruecos, casi un cuarto de siglo después de salir de allí. Durante el viaje hizo un último desvío hasta Cerdeña y luego volvió a Tánger para descubrir que su madre también había muerto, pocos meses antes.

Habiéndose afincado en Tánger durante unos años, Ibn Battuta comienza un viaje a "al-Andalus" (España musulmana). Por entonces Alfonso XI de Castilla amenazaba con conquistar Gibraltar, e Ibn Battuta se unió a un grupo de musulmanes que salían de Tánger con la intención de defender el peñón. Cuando llegó, Alfonso había muerto de la peste negra y la amenaza había desaparecido, así que Ibn Battuta decidió seguir el viaje por placer. Viajó desde Gibraltar a Ronda, Marbella y Málaga (ciudad de la que hace grandes elogios), desde la que sube a Vélez, Alhama y Granada para, desandando el mismo camino, regresar a Gibraltar y cruzar a Ceuta ("cf. Voyages", vol. 4, pp. 354-374).

Al volver de España decidió viajar por una de las pocas partes del mundo musulmán que nunca había explorado: su propio país, Marruecos. En su vuelta a casa se detuvo un poco en Marrakesh, que era casi una ciudad fantasma tras la reciente epidemia y el cambio de la capital a Fez.

Una vez más retornó a Tánger y una vez más volvió a partir. Dos años antes de su primer viaje a El Cairo, el rey del Imperio de Malí, Mansa Musa, había pasado por esa ciudad en su propio "hach" y había causado sensación con sus extravagantes riquezas; algo así como la mitad del suministro mundial de oro en ese tiempo venía de África Occidental. Aunque Ibn Battuta nunca lo menciona abiertamente, esas noticias oídas durante su propio viaje debieron de incitar su curiosidad, porque decidió partir y visitar ese reino musulmán en el otro extremo del Desierto del Sahara.

Al finales de 1351, Ibn Battuta partió de Fez, alcanzando la última localidad de Siyilmasa poco más de una semana después. Cuando las caravanas de invierno comenzaron pocos meses más tarde, se unió a una de ellas, y en un mes estaba en la localidad de Taghaza, en el Sáhara Central, perteneciente al reino de Malí. Centro del comercio de la sal, Taghaza estaba inundada de sal y de oro de Malí, aunque Ibn Battuta no tuvo una favorable impresión del lugar. Otro viaje de 800 km a través de la peor parte del desierto lo llevó a Mali, y más exactamente a la localidad de Walata.

Desde allí viajó al suroeste a lo largo de un río que el creía ser el Nilo, pero que era realmente el río Níger, hasta que alcanzó la capital de Imperio de Malí. Allí encontró a Mansa Soulayman, rey desde 1341. Aunque dudoso por la escasa hospitalidad del rey, permaneció sin embargo durante ocho meses antes de volver hacia el Níger y hasta Tombuctú que, aunque en los siguientes dos siglos llegaría a ser la ciudad más importante de la región, en esa época era pequeña e insignificante, e Ibn Battuta pronto siguió adelante. En algún lugar de su viaje a través del desierto recibió un mensaje del sultán de Marruecos ordenándole volver a casa. Así lo hizo, y esta vez se quedó.

Se conoce poco de la vida de Ibn Battuta posterior a la fecha de publicación de la "Rihla". Podría haber sido nombrado "qadi" en Marruecos.

Ibn Battuta murió en Marruecos en algún momento entre 1368 y 1377. Durante siglos su libro fue desconocido, incluso dentro del mundo musulmán, pero en el siglo XIX fue redescubierto y traducido a varios idiomas europeos. Desde entonces la fama de Ibn Battuta ha ido creciendo y es ahora una figura bien conocida en el Oriente Medio.

En la medina de Tánger Ibn Battuta tiene un pequeño mausoleo familiar, que es lugar de oración.




</doc>
<doc id="41177" url="https://es.wikipedia.org/wiki?curid=41177" title="Pico Aneto">
Pico Aneto

El Aneto (en aragonés, y oficialmente, "Tuca d'Aneto") es el pico más elevado de los Pirineos, con una altitud de 3404 metros sobre el nivel del mar. Se encuentra situado en el Parque natural Posets-Maladeta, en el municipio de Benasque, provincia de Huesca, comunidad autónoma de Aragón, en España.

Forma parte del macizo de la Maladeta y, situado en el valle de Benasque, está constituido por terrenos paleozoicos de naturaleza granítica y materiales mesozoicos. En su cara norte, a partir de los 2810 m aproximadamente, se encuentra el mayor glaciar de los Pirineos, con unas 100 ha de superficie, que está, al igual que muchos en el mundo, en franca regresión como consecuencia del cambio climático (se calcula que en los últimos 100 años ha perdido más de la mitad de su superficie, y que en 30 o 40 años puede llegar a desaparecer).

Inicialmente, la gran aglomeración de granito estaría carente incluso de nombre. Existen indicios de que los pastores y cazadores que lo percibían lo designaban como Malheta o Malahita, o Punta desde los valles del sur. El primer viajero culto que lo avistó desde el puerto de Benasque, Louis Ramond de Carbonnières, se limitaría a describir en 1787 su aspecto de "aguja de hielo". Finalmente, la máxima cota del Pirineo acabaría heredando el nombre de un pequeño pueblo de su costado oriental: Aneto.

Los franceses, al oír pronunciar Aneto a los aragoneses, retuvieron las dos últimas sílabas fonéticas claramente acentuadas, "ne" y "tu", ignorando la primera sílaba "a". Al transcribirlo, se originó su nombre francés: "Netou”, a pesar de que cima y laderas se encuentran plenamente en territorio español. Varios mapas de cartógrafos galos posteriores asentaron el topónimo hasta referirse al pico como “Nethou”, nomenclatura utilizada en la actualidad. No es esta la única denominación existente en el país vecino. Nelto, Nettou, Anetthou, Annetton, Anelthou, Nethom o Aréthon son otras variantes históricas que aún persisten.

Al oeste del Aneto se encuentra la Maladeta, que sin estar entre los cinco picos más altos del entorno, se apropió del topónimo que aludía a todo el macizo, ya que desde la entrada natural al valle o al llegar desde Francia, su cima queda en primer plano, mientras que la cresta de los portillones oculta la verdadera dimensión del Aneto, más alto y con mayor glaciar. Solo una vez que Friedrich von Parrot alcanzara en 1817 la cima de la Maladeta, se supo que tanto el Aneto como sus vecinos el Pico del Medio, la Punta Astorg, el Pico Maldito y la Aguja Schmidt Endell eran de mayor altura que la Maladeta. Hasta entonces, el Monte Perdido había sido considerado el más alto de la península ibérica. Sin embargo, tampoco destaparse como el techo del Pirineo otorgó al monte la fama, pues varios desastres en los glaciares, algunos mortales, disiparon el interés por coronarlo. De hecho, la muerte de Luchon Barrau (considerado el decano y máximo experto de la zona) en una grieta del hielo de la Maladeta provocó una auténtica conmoción, y los naturales de la zona, ya muy temerosos de aventurarse por el glaciar, cogieron auténtico pánico a aquella montaña, que consideraban maldita. 

Finalmente, el 20 de julio de 1842, Platon de Tchihatcheff (Чихачёв, Chikhachev), militar ruso que veraneaba en Bagnères-de-Luchon, y Albert de Franqueville, botánico normando, ascendieron a la cima en una ruta que, con tres días de duración, esquivó deliberadamente todos los glaciares del camino. Lo acompañaban los guías Pierre Sanio de Luz, Bernard Arrazau, Pierre Redonnet y Jean Sors. Albert de Franqueville bautizó el paso final a la cumbre como "puente de Mahoma", conforme, según se cree, a la leyenda musulmana que dice que la entrada al paraíso es tan estrecha como el filo de una cimitarra sobre la que solo pasan los justos. Arriba, Tchihatcheff quiso abrir una ruta más directa de vuelta a través del glaciar, pero sus acompañantes se negaron en redondo, obligándole a ceder. Cuatro días más tarde realizó un segundo ascenso con otro grupo, persiguiendo el mismo objetivo que sus primeros compañeros le habían negado. Al atravesar el portillón, a la vista de las grietas que surcaban el glaciar, a punto estuvo de estallar un motín, pero finalmente, después de atarse todos a una gran maroma, atravesaron las simas y el paso de Mahoma fue derrotado por segunda vez. 
A partir de entonces el Aneto entraría en la dinámica de divulgación y popularización de las cumbres del Pirineo. En Francia, su ascensión se convirtió en una gran clásica y todo turista termal de Bagneres de Luchon tenía que intentarla. Reflejo de aquel momento es el libro de Henry Spont, titulado simplemente Le Néthou, donde describe la excursión, el horario y el material aconsejable.

En 1866 Henry Russell diseñó un recorrido innovador por el glaciar de Barrancs, al este, con la intención de evitar la cara norte. No consiguió llegar a la cima: el pico que hoy lleva su nombre le negó el ascenso por dos veces. Sería José Nariño, en 1879, quien consiguiera por primera vez descerrojar la cara sur del Aneto. Hacia 1935 ya se habían abierto todas las rutas de dificultad. 

A principios del siglo XX se inauguró el refugio de la renclusa, creación del barcelonés Juli Soler. Poco después, un rayo acabó con la vida del guía benasqués José Sayó y su cliente, sobre el paso de Mahoma, en 1916. 

La localización del Aneto en el área de transición lingüística entre las lenguas catalana y aragonesa ha creado cierta disputa en la simbología. Tras la cruz de Sayó de 1917, el Centre Excursionista de Catalunya alzó una gran cruz en 1951, correspondida con una Virgen del Pilar en 1956 y por un San Marcial en 1981. Ninguno de esos monumentos tiene una conservación fácil debido a las inclemencias del tiempo y la lucha simbólica de trasfondo. 

Debido a su particularidad orográfica como cúspide de los Pirineos, a la variedad de fauna y flora debida al enorme desnivel de sus valles, al impecable estado de conservación ecológica y, sobre todo, a la sensibilidad de los glaciares de sus cumbres (los más meridionales de Europa), fue declarado parque natural en 1994 junto a todo el macizo de la Maladeta y Posets y parte del Monumento Natural 'Glaciares pirenaicos'.

De cara al futuro, el Aneto está a la espera de la novedad más importante de su historia reciente, la desaparición de sus glaciares. Los más pesimistas señalan 2050 como fecha de caducidad de las 100 hectáreas que restan de las más de 250 de 1842. 

A mediados de octubre de 2018 la cruz del Aneto fue víctima de un acto de vandalismo, siendo pintada de amarillo, por lo visto para reclamar la independencia de Cataluña. La guardia civil se trasladó al lugar mediante helicóptero para investigar llevando un equipo para restaurar la cruz. Este acto de vandalismo suscitó el rechazo público de varias organizaciones y partidos políticos.

Se eleva hasta los 3404 metros sobre el nivel del mar en el centro de los Pirineos, cordillera cuyos territorios recorren casi por completo la frontera entre Francia y España. La cima se encuentra en el noreste de la provincia de Huesca y ocupa el extremo oriental de los Montes Malditos. La arista que lo une con la célebre Maladeta, más al oeste, sobrepasa los 3000 metros de altitud, y despunta en una hilera de picos denominada Coronas, que, junto a la cresta de los portillones, otorga al macizo su imagen tan característica. 

Aunque el valle supone el nacimiento del río Ésera, de vertiente sur, las nieves del Aneto y su glaciar se filtran por una gran sima en Aigualluts para desembocar en el valle de Arán y el río Garona, con destino a Francia. Las aguas de sus caras occidental y meridional, por el contrario, se reúnen en los ibones Superior, Medio e Inferior, para descender después hasta el río Ballibierna una vez superado el Ibonet de Coronas.

El macizo de la Maladeta, que supone la mayor concentración de tresmiles del Pirineo (ciento seis, más de la mitad de toda la cordillera), se encuentra rodeado por valles que ascienden hacia elevados pasos naturales, hoy casi en desuso. Un collado de más de 2500 metros, coronado por el característico Perdiguero, separa al pico de territorio francés y del valle de Arán. El lado español, más ancho y más compacto y, por lo tanto, de más difícil acceso, queda separado del piedemonte por los congostos y barrancos de los macizos de Posets y Maladeta. Tan solo dos valles más al sur, se levanta la estación de esquí alpino de Cerler.

 
Tal aglomeración de cumbres, todas ellas de carácter marcadamente alpino, es la cuna de los que fueron en su día los más grandes glaciares del Pirineo, que llegaron hasta la boca del Congosto de Ventamillo con grosores de hielo de varios centenares de metros. Hoy día, el calentamiento de la tierra ha reducido aquella masa portentosa a once heleros que sólo suman trescientas hectáreas de superficie. No se sabe con certeza el comienzo del proceso de deshielo, pero sí que en la actualidad se ha acelerado vertiginosamente, y se prevé que a partir de mediados del siglo XXI puedan desaparecer los hielos perpetuos del Aneto y de todo el Pirineo. 

En las laderas del monte moran tres glaciares: el mayor, llamado glaciar del Aneto, al norte; el de los Barrancos, junto al de las Tempestades, al noreste; y el de las Coronas o glaciar Coronado, al sur.

El resto no se pueden definir como glaciares sin entrar en polémicas, ya que han perdido toda movilidad y no se comportan como tales. Habría que citar aquí los heleros de Cregüella, Alba y Salenques, en importante estado de retroceso. No obstante, aun considerándolos como neveros, su pasado glaciar los ha mantenido hasta la fecha y está previsto que su corazón de hielo aguante décadas.

En la actualidad, el descenso de la innivación durante el invierno y el aumento de la temperatura en verano dificultan enormemente su supervivencia. En los años anteriores a 2006 tuvo lugar el mayor retroceso de los glaciares pirenaicos, a excepción de los orientados al sur, sobre los que quedó acumulada la nieve por los temporales de componente norte. En 2007 y 2008, sendas primaveras húmedas trajeron nieve abundante a los tresmiles del pirineo. Después, dos veranos no especialmente cálidos y algunas nieves tempranas en otoño de 2007 otorgaron un respiro a los glaciares del Aneto y del resto de los Pirineos.

La singularidad del macizo y su atractivo ha propiciado el abandono casi total de las actividades agrícolas y ganaderas, sustituidas por las turísticas. La flora del entorno, por lo tanto, goza de una impecable conservación, en especial en laderas y macizos, cuyos bosques permanecen en estado primario.

Esta capa, que alcanza los 3404 metros de altitud, es la que más dificultades presenta para el desarrollo de la vida. Las duras condiciones atmosféricas que han de soportar las plantas en lo alto de los picos, cimas y crestas requiere el desarrollo de una extraordinaria capacidad de adaptación. Existe una serie de factores a soportar como la fuerte insolación, bajas temperaturas y cortos ciclos vegetativos ante la presencia de nieve la mayor parte del año.

Carente totalmente de vegetación arbórea, se encuentra colonizado por no más de 100 especies vegetales, además de líquenes y algas microscópicas. El 20 % de estas especies son endémicas del Pirineo. A destacar la presencia de la "Androsace vandelli", que asciende hasta los 2800 metros, y la "Silene acaulis".

En las zonas inferiores y medias del piso alpino (desde los 2200 metros) el suelo es de hierba, constituyendo el tradicional pasto ganadero veraniego. El mundo de las flores que habitan aquí es amplio: nomeolvides, flor de las nieves, flor del viento, lirio pirenaico, borderea pirenaica, gencianas, orquídeas, saxifraga púrpura, regaliz de montaña, etc.

Desde los 1600 hasta las 2200 metros. Lo componen los bosques de pino negro, masa forestal de tipo taiga. Se encuentra en asociación con el rododendro y los arándanos, formando un bosque ombrófilo.

Se da en la parte baja del valle, hasta los 1600 metros de altitud, donde las nieblas son frecuentes. Consiste en hayedos (escasos), abetales y masas arbóreas mixtas de caducifolias junto a bosques de ribera, formados por fresnos, sauces y álamos principalmente.

Los alrededores del Aneto, con sus variados ecosistemas, encierran una biodiversidad animal elevada. Cada capa vegetal alberga una fauna singular y claramente diferenciada del resto. 

En alta montaña conviven la perdiz nival, el treparriscos, el pequeño acentor alpino, la marmota, la salamandra común y el topillo nival. En media montaña puede verse al sarrio o rebeco pirenaico, al águila real o a los blancos armiños. Los bosques densos son el hábitat de los picos picapinos, del azor, del cuco y de un sinfín de avecillas.

Algunas de las especies animales que en su día se fueron extinguiendo en gran parte de la península ibérica o de Europa siguen existiendo en los bosques, ríos, acantilados y rincones inaccesibles de los Pirineos. En muchos casos su presencia es señal del buen estado de conservación del entorno, aunque la mayoría se encuentra en situación crítica de supervivencia.
Hace décadas de la desaparición del oso pardo en el macizo y en la mayor parte de la cordillera. Tan solo de dos a tres osos quedan en la vertiente sur de los Pirineos, concretamente en los valles occidentales del alto Aragón. En los valles galos próximos de Aspe y Ossau hay una población máxima de once ejemplares. Los ataques al ganado o la presencia de huellas y rastros son, normalmente, los únicos indicios de su presencia, pues verlo es prácticamente imposible.

El lince boreal, similar al ibérico, sufrió una gran regresión en toda Europa, que lo llevó a la extinción en los macizos centrales, como el de la Maladeta. En los bosques de media montaña de las sierras exteriores pirenaicas es todavía probable su existencia. El bioparque del valle de Tena ha logrado su reproducción en cautividad recientemente.

De la musaraña alpina solo se tienen tres referencias en el macizo de la Maladeta, todas ellas a finales del siglo XIX, por encima de los 2000 metros de altitud. Su existencia es una incógnita para biólogos y naturalistas.

La cabra montesa del pirineo, o bucardo, tuvo hace siglos una extensa distribución. Sin embargo, la caza arrinconó a esta especie en la umbría del valle de Ordesa. No se tiene constancia de más de tres ejemplares, los únicos en todo el mundo.

El quebrantahuesos, mitad águila y mitad buitre, tiene en el pirineo aragonés las mayores poblaciones de todo el Paleártico occidental.

Los hayedos, abetales y masas de pino negro con abundante sotobosque de rododentros de Aneto-Maladeta, Posets y Cotiella conforman el hábitat idóneo del urogallo. 

Su pariente cercana, la perdiz nival, quedó arrinconada en los pisos más elevados y cumbres del macizo al retroceder los hielos de las glaciaciones cuaternarias.

La nutria todavía vive en las aguas del alto Ésera, aunque la contaminación fluvial, la destrucción de riberas y el barranquismo han llevado a su especie a una situación crítica.

A continuación se exponen los nombres de los pioneros en cada disciplina:



Espoleados por el sufrido estado de sus glaciares, por la literatura que arrastra o, sencillamente, por ser la cumbre del Pirineo, enseñarse en todas las escuelas y ofrecer una vista única, una multitud de personas se dirigen en cualquier época del año al valle de Benasque tratando de alcanzar la cumbre del Aneto.

Si bien la mayoría de las rutas son fáciles, se trata de una cima exigente a causa de factores como el desnivel acumulado a superar, la cota y la presencia del glaciar. La ascensión del Aneto excede la categoría de excursionismo o senderismo, y entra en el ámbito del alpinismo.
Por todas las rutas y en todas las épocas del año se requieren botas duras de montaña, crampones, piolet, ropa de abrigo e impermeable, guantes y gafas. En las rutas de dificultad o para personas con vértigo, además, cuerda y arnés o vaga con mosquetón.

Atención especial merece la travesía del glaciar, que siempre conlleva riesgos. Además, a causa de las frecuentes tormentas que se producen durante la tarde, es habitual que los que pretenden alcanzar la cumbre inicien la ascensión de madrugada para llegar pronto a la cima.

Esta cima es una de las más ascendidas de la cordillera, sobre todo en verano. Casi todos los años hay alguna víctima mortal. 

Desde Benasque, el curso del río Ésera lleva a la cola de la presa de Paso Nuevo, donde se encuentra el plan de Senarta. Desde allí se puede tomar la pista que sube por el valle de Vallibierna (unos 8 km) hasta el puente de Coronas (1950 m), junto a un refugio de pescadores no guardado.

Por el contrario, la carretera llega al plan del Hospital y luego al plan de la Besurta (1900 m). A partir de ahí, convertido en camino y luego en sendero, se accede, en unos 45 minutos, al refugio de La Renclusa (2160 m). 

Durante todo el verano están cerrados al tráfico particular tanto la pista de Vallibierna como la de la Besurta desde el vado del hospital. Existe un servicio de autobuses desde Benasque que permite acceder tanto al puente de Coronas como a la Besurta. En invierno, la nieve impide el acceso desde el hospital hacia el refugio.

La Besurta - La Renclusa - Portillón Superior - Glaciar del Aneto - Collado de Coronas - Paso de Mahoma - Cima (1504 m de desnivel)
Sale de La Besurta (1900 m) por el camino de La Renclusa, perfectamente indicado. Desde allí (2149 m) surge un camino pedregoso marcado por numerosos hitos. La ruta toma dirección SE, paralela a la cresta de los portillones, que asciende desde la base del pico de la Renclusa hasta el Pico de la Maladeta. 

Se puede atravesar la cresta por el portillón inferior (2738 m) o por el superior (2870 m). Los portillones son huecos en la cresta que comunican el glaciar de la Maladeta con el del Aneto. En verano es más recomendable pasar por el superior, para alcanzar el glaciar con más altura y acortar el paso entre los bloques, muy peligrosos con hielo. También se puede subir desde el inferior al superior por la propia cresta.

Una suave diagonal a través del glaciar asciende al collado de Coronas (3198 m).

Después espera una fuerte pendiente de nieve, hasta llegar a la antecima y el "Paso de Mahoma" (de unos 30 m), de poca dificultad (II) pero muy aéreo y expuesto. En fines de semana y festivos de verano hay tales aglomeraciones que su paso llega a ser más molesto que peligroso.

El descenso se puede hacer por la misma ruta o, si hay nieve abundante, por la izquierda del glaciar hasta el plan de Aigualluts. Esta es la mejor opción cuando se sube en invierno o primavera con esquís de travesía.
Por la derecha del glaciar se llega al valle de Barrancs, a través del cual también se llega al plan de Aigualluts.

Senarta - Vallibierna - Puente de Coronas - Ibones de Coronas - Glaciar de Coronas - Collado de Coronas - Paso de Mahoma - Cima (1454 m de desnivel)

La ruta comienza en el puente de Coronas (1950 m), junto al refugio de pescadores, a unos 8 km de pista desde el plan de Senarta.

Por el antiguo camino maderero (actual GR-11), a los 10 minutos hay un desvío a la izquierda en dirección al valle de Coronas. Un sendero bien marcado llega al ibonet de Coronas (2230 m).

Siguiendo los hitos o mojones de piedras se llega al segundo ibón de Coronas (2725 m). Por la derecha del mismo se alcanza la morrena del casi extinguido glaciar de Coronas, con nieve en invierno y primavera y piedras en verano y otoño. Al final de la ascensión, y tras una corta trepada, se alcanza el collado de Coronas (3198 m).

Una vez en el collado la ruta hasta la cima sigue el mismo camino que en la Normal, al igual que el descenso. 

Llanos de la Besurta - Plan de Aigualluts - Glaciar del Aneto - Paso de Mahoma - Cima (1504 m de desnivel)

Esta es la ruta más utilizada por los esquiadores de montaña para descender el Aneto, pues ofrece una baja ininterrumpida de más de mil doscientos metros, una de las mejores de toda la cordillera. Esta gran pendiente uniforme y constante es la principal causa de que no se utilice mucho para subir.

Parte de los Llanos de la Besurta camino del refugio, pero en breve hay que coger otro sendero bien marcado que se dirige hacia el Plan de Aigualluts. 

Allí existen dos alternativas: tomar un camino señalizado con hitos al lado de la cabaña metálica verde que hay en el extremo norte del Plan, o seguir hasta el fondo y remontar el río Barrancs hasta prácticamente el estrechamiento sobre el que está el lago de Barrancs. 

La nieve llega muy abajo hasta junio, y cuando se va deja al descubierto grandes pedreras y más arriba un lecho rocoso pulimentado por el glaciar en retroceso. Mucho más arriba aparecerá el hielo negro que no ha de abandonarse hasta el collado de Coronas. Aquí la ruta se une a la de los Portillones. Pero si se desea, no es necesario llegar hasta el collado pues la pendiente cimera puede ser atacada directamente. Cuando la nieve se ha retirado, esta larga subida contiene hitos que marcan varios posibles caminos. El problema que produce esta inflación de hitos y la falta de un camino bien definido no es muy grave, pues el Aneto marcará el rumbo sobre el escalador. 

Llanos de la Besurta - Lago de Barrancs - Glaciar de Barrancs - Cima (1500 m de desnivel) 

Es una ruta muy larga y de alguna manera comprometida, más que por su dificultad por lo remota que está y porque cuando la nieve se retira puede ser muy fatigoso subir por las pedreras del circo. Es mucho más cómodo atacarla cuando la nieve baja al menos hasta los 2600 metros de altitud.

El principal atractivo de esta ruta reside en que no la utiliza nadie, aun sin ser más difícil que la masificada de los Portillones. Está considerada por muchos la forma más emocionante de llegar a la cumbre sin recurrir a la escalada. Esta ruta es en realidad una variante de la ruta de Barrancs con la que comparte camino hasta muy cerca del lago de Barrancs.

Allí sigue por el valle, supera el fuerte escalón que embalsa el lago y una vez rebasada la arista Norte, que baja directamente del Aneto, gira noventa grados hacia el suroeste y comienza a subir por el impresionante circo este del Aneto hasta el glaciar de Barrancs.El glaciar de Barrancs se empina de forma considerable en su tramo final. Tras superarlo desembocaremos en la Espalda de Aneto, a 3350 metros de altitud. Desde allí solo hay que seguir la fácil cresta hasta la cumbre, sin pasar por el paso de Mahoma.






</doc>
<doc id="41180" url="https://es.wikipedia.org/wiki?curid=41180" title="Teoría de la complejidad computacional">
Teoría de la complejidad computacional

La teoría de la complejidad computacional o teoría de la complejidad informática es una rama de la teoría de la computación que se centra en la clasificación de los problemas computacionales de acuerdo con su dificultad inherente, y en la relación entre dichas clases de complejidad.

Un problema se cataloga como "inherentemente difícil" si su solución requiere de una cantidad significativa de recursos computacionales, sin importar el algoritmo utilizado. La teoría de la complejidad computacional formaliza dicha aseveración, introduciendo modelos de computación matemáticos para el estudio de estos problemas y la cuantificación de la cantidad de recursos necesarios para resolverlos, como tiempo y memoria.

Una de las metas de la teoría de la complejidad computacional es determinar los límites prácticos de qué es lo que se puede hacer en una computadora y qué no. Otros campos relacionados con la teoría de la complejidad computacional son el análisis de algoritmos y la teoría de la computabilidad. Una diferencia significativa entre el análisis de algoritmos y la teoría de la complejidad computacional, es que el primero se dedica a determinar la cantidad de recursos requeridos por un algoritmo en particular para resolver un problema, mientras que la segunda, analiza todos los posibles algoritmos que pudieran ser usados para resolver el mismo problema.

La teoría de la complejidad computacional trata de clasificar los problemas que pueden, o no pueden ser resueltos con una cantidad determinada de recursos. A su vez, la imposición de restricciones sobre estos recursos, es lo que la distingue de la teoría de la computabilidad, la cual se preocupa por qué tipo de problemas pueden ser resueltos de manera algorítmica.

Antes de que se realizaran investigaciones en torno a la complejidad de los algoritmos, se crearon los cimientos de esta teoría por varios investigadores. Uno de los aportes más influyentes fue la definición de las máquinas de Turing en 1936, las cuales resultaron ser una noción de computadora muy flexible y robusta. A medida que las computadoras se desarrollaban en los 40's y los 50's, la Máquina de Turing demostró ser el modelo teórico correcto de cómputo.

Sin embargo, rápidamente se descubrió que el modelo básico de la máquina de Turing fallaba al cuantificar el tiempo y la memoria requerida por una computadora, un problema crítico hoy en día, y aún más en aquellos tiempos. La idea de medir el tiempo y espacio como una función de la longitud de la entrada se originó a principios de los 60s por Hartmanis y Stearns, y así nació la teoría de la complejidad computacional.

En los inicios, los investigadores trataban de entender las nuevas medidas de complejidad, y cómo se relacionaban unas con otras. En 1965, Edmonds definió un "buen" algoritmo como uno con un tiempo de ejecución acotado por un polinomio, es decir, con un tiempo de ejecución polinómico. Esto condujo al surgimiento de uno de los conceptos más importantes de la teoría de la complejidad computacional: la NP-completitud y su pregunta fundamental, si P<nowiki>=</nowiki>NP.

El campo comenzó a florecer cuando el investigador estadounidense Stephen Cook y el soviético Leonid Levin, trabajando de manera independiente, probaron que existen problemas relevantes que son NP-completos. En 1972, Richard Karp llevó esta idea un paso más adelante, demostrando que 21 problemas combinatorios y de teoría de grafos, caracterizados por ser computacionalmente intratables, eran NP-completos. También en los 70's, se produjo un crecimiento de las clases de complejidad a medida que los investigadores trataban de comprender los distintos modelos de cómputo existentes.

En los 80's, se produjo un auge de los modelos finitos, que analizaban el proceso de cómputo de una manera inherentemente distinta. Surgió un nuevo acercamiento a problemas como P<nowiki>=</nowiki>NP, y aun cuando estos modelos tenían sus limitaciones separando las clases de complejidad, esta aproximación introdujo técnicas combinatorias que permitieron un mejor entendimiento de los límites de estos modelos.

Ya en los 90's, se estudiaron nuevos modelos de cómputo como las computadoras cuánticas, donde una misma tarea puede tener diferente complejidad en la computación clásica y en la computación cuántica. Sin embargo, existen varias limitantes, entre ellas, la de desarrollar un hardware para este modelo, y que se requieren grandes cantidades de espacio para realizar los cálculos.

Para poder referirnos a problemas como "inherentemente intratables" y problemas de dificultad "equivalente", es necesario comprender algunos términos más básicos.

Un problema computacional constituye una pregunta a ser respondida, teniendo generalmente varios parámetros, o variables libres, cuyos valores no se han especificado. Un problema se describe mediante:

Una instancia de un problema se obtiene cuando se especifican valores particulares para todos los parámetros del problema. Por ejemplo, consideremos el problema del test de primalidad. La instancia es un número (e.g. 15) y la solución es "sí" si el número es primo, y "no" en caso contrario. Visto de otra manera, la instancia es una entrada particular del problema, y la solución es la salida correspondiente para la entrada dada.

Un problema de decisión es un tipo especial de problema computacional cuya respuesta es solamente "sí" o "no" (o, de manera más formal, "1" o "0").

Un problema de decisión pudiera verse como un lenguaje formal, donde los elementos que pertenecen al lenguaje son las instancias del problema cuya respuesta es "sí", los que no pertenecen al lenguaje son aquellas instancias cuya respuesta es "no". El objetivo es decidir, con la ayuda de un algoritmo, si una determinada entrada es un elemento del lenguaje formal considerado. Si el algoritmo devuelve como respuesta "sí", se dice que el algoritmo "acepta" la entrada, de lo contrario se dice que la "rechaza".

Los problemas de decisión constituyen uno de los principales objetos de estudio de la teoría de la complejidad computacional, pues la NP-completitud se aplica directamente a estos tipos de problemas en vez de a problemas de optimización. Estos problemas tienen gran importancia porque casi todo problema puede transformarse en un problema de decisión.

Podemos decir informalmente, que los algoritmos son procedimientos paso-a-paso para resolver problemas. Se puede pensar en ellos como simples programas de computadora, escritos en un lenguaje artificial específico.

Se dice que un algoritmo resuelve un problema A, si dicho algoritmo se puede aplicar a cualquier instancia I de A, y se garantiza que siempre produce una solución para dicha instancia. De manera general, nos interesa encontrar el algoritmo más "eficiente" para resolver cierto problema. En su sentido más amplio, la noción de eficiencia involucra a todos los recursos computacionales necesarios para la ejecución de un algoritmo.

Por algoritmo "más eficiente" usualmente nos referimos al más rápido. Debido a que los requerimientos de tiempo son usualmente un factor dominante cuando se trata de determinar si un algoritmo es lo suficientemente eficiente para ser útil en la práctica, nos concentraremos en este recurso.

Los científicos de la computación realizan la distinción entre algoritmos de Tiempo polinómico y algoritmos de tiempo exponencial cuando se trata de caracterizar a los algoritmos como "suficientemente eficiente" y "muy ineficiente" respectivamente.

Un "algoritmo de tiempo polinomial" se define como aquel con función de complejidad temporal dentro de una cota superior asintótica (denominada a veces "orden") O("p"("n")) para alguna función polinómica "p", donde "n" denota el tamaño de la entrada. Los algoritmos de tiempo exponencial, formula_1 son los que el número de ciclos que tienen que realizarse con el algoritmo es proporcional a la función formula_2 de modo que el poder computacional necesario para correr el algoritmo crece de forma exponencial al tamaño formula_3 del problema. 

La mayoría de los algoritmos de tiempo exponencial son simples variaciones de una búsqueda exhaustiva, mientras que los algoritmos de tiempo polinomial, usualmente se obtienen mediante un análisis más profundo de la estructura del problema. En la teoría de la complejidad computacional, existe el consenso de que un problema no está "bien resuelto" hasta que se conozca un algoritmo de tiempo polinomial que lo resuelva. Por tanto, nos referiremos a un problema como "intratable", si es tan difícil que no existe algoritmo de tiempo polinomial capaz de resolverlo.

Una clase de complejidad es un conjunto de problemas que poseen la misma complejidad computacional.

Las clases de complejidad más sencillas se definen teniendo en cuenta factores como:

La clase P contiene a aquellos problemas que son solubles en tiempo polinómico por una máquina de Turing determinista.

Para la definición anterior se ha fijado el modelo de cómputo: la Máquina de Turing determinista. Existen distintas variantes de la Máquina de Turing y es conocido que la más débil de ellas puede simular a la más fuerte, adicionando a lo sumo un tiempo polinómico. En las décadas posteriores a la Tesis de Church-Turing surgieron otros modelos de cómputo, y se pudo mostrar que la Máquina de Turing también podía simularlos a lo sumo adicionando también un tiempo polinómico. Por tanto, la clase análoga a P para dichos modelos no es mayor que la clase P para el modelo de cómputo de la máquina de Turing.

La clase P juega un papel importante en la teoría de la complejidad computacional debido a que:

Muchas veces podemos evitar utilizar la fuerza bruta en los problemas para obtener soluciones en tiempo polinómico. Sin embargo, para algunos problemas esto no ha podido lograrse, es decir, no se conocen algoritmos que los resuelvan en tiempo polinómico. Quizás estos problemas tengan algoritmos en tiempo polinomial que se basan en principios por ahora desconocidos, o quizás estos problemas "no" pueden ser resueltos en tiempo polinómico, debido a que son "inherentemente difíciles".

La clase de complejidad NP consta de los problemas "verificables" en tiempo polinómico. Por verificable se entiende a un problema tal que dado un certificado de solución (candidato a solución), se puede verificar que dicho certificado es correcto en un tiempo polinómico en el tamaño de la entrada. A los problemas en la clase NP usualmente se les llama "problemas NP".

El término NP proviene de no determinista en tiempo polinómico y se deriva de un caracterización alternativa de esta clase, donde se utilizan Máquinas de Turing no deterministas. Informalmente, se puede definir la clase NP en términos de un "algoritmo no determinista" (recordar la equivalencia entre algoritmo y Máquina de Turing).

El algoritmo mencionado está compuesto por 2 etapas separadas. Dada una instancia del problema I, la primera etapa simplemente "adivina" un candidato a solución S. Entonces, la etapa de verificación recibe como entrada a I y a S, y procede a realizar el cómputo de una manera determinista, finalmente deteniéndose con la respuesta "sí", o con la respuesta "no", o sigue computando sin detenerse.

Al igual que la clase P, la clase NP es insensible a la elección del modelo de cómputo no determinista, debido a que dichos modelos son equivalentes polinómicamente.

Muchas clases de complejidad importantes pueden ser definidas acotando el tiempo o el espacio utilizado por el algoritmo. Algunas de estas clases de problemas de decisión son:

La relación entre las clases P y NP es fundamental para la teoría de la NP-completitud. Intuitivamente, creemos que P es un subconjunto de NP. Y, efectivamente, cada problema de decisión resuelto por un algoritmo de tiempo polinomial determinista, también puede ser resuelto por un algoritmo de tiempo polinomial no determinista. Simplemente se necesita observar que cualquier algoritmo determinista puede ser utilizado en la etapa de verificación de un algoritmo no determinista. Si B es un problema de P, y A es un algoritmo de tiempo polinomial para B, entonces se puede construir un algoritmo de tiempo polinomial no determinista para B, simplemente utilizando A en la etapa de verificación e ignorando la etapa de adivinación. Por tanto, si B pertenece a P, entonces B también pertenece a NP.

La pregunta P<nowiki>=</nowiki>NP es una de las más importantes en el campo de las ciencias de la computación, debido a las grandes repercusiones que habría, en caso de encontrarse una solución. Si P<nowiki>=</nowiki>NP, cualquier problema polinómicamente verificable sería polinómicamente decidible. La mayoría de los investigadores cree que estas clases no son iguales, porque se ha realizado bastantes esfuerzos, sin éxito, para encontrar algoritmos de tiempo polinomial para varios problemas en NP. Los investigadores también han tratado de probar que las clases son distintas, pero eso conllevaría a mostrar que no existe un algoritmo «eficiente» para reemplazar a la búsqueda por fuerza bruta.

Una reducción es una transformación de un problema en otro problema. Intuitivamente, un problema Q puede ser reducido a otro problema Q', si cualquier instancia del problema Q puede ser "fácilmente" expresada como una instancia del problema Q', y cuya solución proporcione una solución para la instancia de Q.

Existen muchos tipos de reducciones: basadas en el método de reducción, como las reducciones de Cook, las reducciones de Karp y las reducciones de Levin, y las basadas en la cota de la complejidad, como la reducción en tiempo polinomial o la reducción de espacio logarítmica. Una de las reducciones más utilizadas es la reducción en tiempo polinomial, lo cual significa que el proceso de reducción toma un tiempo polinomial.

Las reducciones en tiempo polinomial nos dotan de elementos para probar, de una manera formal, que un problema es al menos tan difícil que otro, con una diferencia de un factor polinomial. Estas son esenciales para definir a los problemas NP-completos, además de ayudar a comprender los mismos.

La clase de los problemas NP-completos contiene a los problemas más difíciles en NP, en el sentido de que son los que estén más lejos de estar en P. Debido a que el problema P<nowiki>=</nowiki>NP no ha sido resuelto, el hecho de reducir un problema B, a otro problema A, indicaría que no se conoce solución en tiempo polinomial para A. Esto es debido a que una solución en tiempo polinomial para A, tendría como consecuencia la existencia de una solución polinomial para B. De manera similar, debido a que todos los problemas NP pueden ser reducidos a este conjunto, encontrar un problema NP-completo que pueda ser resuelto en un tiempo polinomial significaría que P<nowiki>=</nowiki>NP.

Quizás la razón de mayor peso por la cual los científicos de la computación creen que P es distinto de NP, es la existencia de la clase de problemas "NP-completos". Esta clase tiene la curiosa propiedad de que si algún problema NP-completo puede ser resuelto en tiempo polinomial, entonces todo problema en NP tiene una solución en tiempo polinomial, es decir, P<nowiki>=</nowiki>NP. A pesar de años de estudio, ningún algoritmo de tiempo polinomial se ha descubierto para ningún problema NP-completo.

Desde el punto de vista teórico, un investigador intentando mostrar que la clase P es distinta de la clase NP, pudiera enfocarse en un problema NP-completo. Si algún problema en NP requiere más que un tiempo polinomial, entonces uno NP-completo también. Además, un investigador intentando demostrar que P<nowiki>=</nowiki>NP, solo necesita encontrar un algoritmo de tiempo polinomial para un problema NP-completo para lograrlo.

Desde el punto de vista práctico, el fenómeno de la NP-completitud puede prevenir la pérdida de tiempo cuando se busca un algoritmo de tiempo polinomial no existente para resolver un problema determinado. Aun cuando no se posean los elementos matemáticos para demostrar que cierto problema no se puede resolver en tiempo polinomial, creemos que P no es igual a NP, así que demostrar que el problema es NP-completo, es una fuerte evidencia de su no "polinomialidad".

Teniendo en cuenta la definición de problema intratable, si no se cumple que P<nowiki>=</nowiki>NP, entonces los problemas NP-completos son intratables.

Muchos problemas de la práctica son NP-completos, y son muy importantes como para desistir simplemente porque no sabemos cómo encontrar una solución óptima en tiempo polinomial. Aunque un problema sea NP-completo, puede haber esperanza. Existen tres estrategias fundamentales para lidiar con un problema NP-completo:






</doc>
<doc id="41181" url="https://es.wikipedia.org/wiki?curid=41181" title="NP">
NP

NP puede hacer referencia a:



</doc>
<doc id="41182" url="https://es.wikipedia.org/wiki?curid=41182" title="P (clase de complejidad)">
P (clase de complejidad)

En computación, cuando el tiempo de ejecución de un algoritmo (mediante el cual se obtiene una solución al problema) es menor que un cierto valor calculado a partir del número de variables implicadas (generalmente variables de entrada) usando una fórmula polinómica, se dice que dicho problema se puede resolver en un tiempo polinómico.

Por ejemplo, si determinar el camino óptimo que debe recorrer un cartero que pasa por formula_1 casas necesita menos de formula_2 segundos, entonces el problema es resoluble en un "tiempo polinómico".

De esa manera, tiempos de formula_3, formula_4 o formula_5 son polinómicos; pero formula_6 no lo es.

Dentro de los tiempos polinómicos, podemos distinguir los logarítmicos formula_7, los lineales formula_8, los cuadráticos formula_9, los cúbicos formula_10, etc.

En teoría de la complejidad, la clase de complejidad de los problemas de decisión que pueden ser resueltos en tiempo polinómico calculado a partir de la entrada por una máquina de Turing determinista es llamada P. Cuando se trata de una máquina de Turing no determinista, la clase es llamada NP. Una de las preguntas abiertas más importantes en la actualidad es descubrir si estas clases son diferentes o no. El Clay Mathematics Institute ofrece un millón de dólares a quien sea capaz de responder a esa pregunta.

Los problemas NP-completos pueden ser descritos como los problemas en NP que tienen menos posibilidades de estar en P (Ver NP-completo para una definición precisa). Actualmente los investigadores piensan que las clases cumplen con el diagrama mostrado por lo que P y NP-completo tendrían intersección vacía.

La importancia de la pregunta P = NP radica en que, de encontrarse un algoritmo en P para un problema NP-completo, todos los problemas NP-completos (y por ende, todos los problemas de NP) tendrían soluciones en tiempo polinómico.


</doc>
<doc id="41186" url="https://es.wikipedia.org/wiki?curid=41186" title="Lago Toba">
Lago Toba

El lago Toba () es un gran lago de origen volcánico, de 100 km de largo y 30 km de ancho, situado en el centro de la zona septentrional de la isla indonesia de Sumatra. Es el lago más grande de Indonesia y el lago de cráter más grande del mundo.

El lago Toba se formó por una erupción supervolcánica masiva con un Índice de Explosividad Volcánica VEI 8, que se produjo hace 69.000 a 77.000 años, y que provocó un cambio climático significativo. Fue la mayor erupción explosiva conocida en Tierra en los últimos 25 millones de años. De acuerdo con la teoría de la catástrofe de Toba, este evento volcánico tuvo consecuencias globales para las poblaciones humanas y podría haber causado la muerte de la mayoría de los seres humanos que vivieron en esta época, creando un cuello de botella poblacional en el centroeste de África e India, el cual podría haber afectado la composición genética de la población mundial humana hasta el presente. Sin embargo, esta hipótesis no es ampliamente aceptada porque no existe evidencia de que hubo una disminución o extinción de otros animales durante esta época, incluyendo especies que son sensibles a los cambios del entorno. Lo que es ampliamente aceptado es que la erupción de Toba condujo a un invierno volcánico tras una disminución de la temperatura mundial de 3 a 5 °C, y hasta 15 °C en latitudes más altas. Estudios adicionales, que se llevaron a cabo en el lago Malawi en África Oriental, muestran la existencia de depósitos notables de cenizas provenientes de la erupción de Toba, incluso a esa gran distancia, pero existen pocos indicios que apunten a un efecto climático significativo en el este de África.

El complejo de la caldera de Toba comprende cuatro cráteres volcánicos superpuestos que se unen al "eje volcánico" de Sumatra. El más reciente de los cuatro mide 100 por 30 km y es la mayor caldera del mundo del Cuaternario; forma la intersección de las tres calderas más antiguas. Se estima que se expulsaron 2800 km de material piroclástico equivalente de roca densa, conocido como Toba volcánica, durante una de las más grandes erupciones volcánicas explosivas de la historia geológica reciente. Después de la erupción, se formó un domo resurgente dentro de la nueva caldera, uniendo dos medio domos separados por un graben longitudinal.

Al menos cuatro estratovolcanes son visibles en el lago, así como cuatro conos, y tres cráteres. El cono Tandukbenua, que se encuentra en el extremo noroccidental de la caldera, tiene una vegetación escasa, lo que sugiere una edad temprana de apenas unos cientos de años. El volcán Pusubukit (1971 msnm), en el límite sur de la caldera, muestra una actividad solfatarica y ha sido declarado un santuario geológico.

El lago Toba se encuentra cerca de la falla de Sumatra, que corre a lo largo de Sumatra. Los volcanes de Sumatra y Java son parte del arco de Sonda, un arco volcánico que se formó como resultado del movimiento hacia el noreste de la placa Indoaustraliana, que se desliza bajo la placa Euroasiática la cual mueve en una dirección este. Esta zona de subducción es muy activa: en el fondo del mar cerca de la costa oeste de Sumatra se han producido varios terremotos muy fuertes desde 1995, incluyendo el terremoto del océano Índico de 2004 con una magnitud de 9,1 Mw y el terremoto de Sumatra de 2005 con una magnitud de 8,7 Mw, cuyos epicentros se localizaron a unos 300 km de Toba.

La erupción del Toba se produjo hace unos 69.500 a 77.500 años en el sitio que hoy es el lago Toba. Fue la última erupción de una serie de al menos tres erupciones que crearon calderas en este mismo lugar, de las cuales las calderas anteriores se formaron hace aproximadamente 700.000 y 840.000 años. Esta última erupción tuvo una magnitud estimada de VEI 8, y es posiblemente la erupción volcánica explosiva más grande en los últimos 25 millones de años.

Los especialistas Bill Rose y Craig Chesner, de la Universidad Tecnológica de Míchigan, estimaron la cantidad total de material erupcionado en unos 2800 km, de los cuales 2000 km correspondían a ignimbritas que fluyeron sobre la superficie, mientras 800 km corresponden a cenizas que cayeron en su mayor parte hacia el oeste, debido a la dirección de los vientos. Los flujos piroclásticos de la erupción destruyeron una superficie de 20.000 km, con depósitos de cenizas que llegaron a tener un espesor de 600 m en la cercanía de la chimenea principal.
Durante el evento se expulsó en la atmósfera un volumen de 10.000 toneladas de ácido sulfuroso o 6000 toneladas de dióxido de azufre.
El posterior colapso del volcán formó una caldera que, tras llenarse de agua, creó el lago Toba. La isla, Samosir, en el centro del lago se formó por un domo resurgente.

Aunque se desconoce el año exacto de la erupción, el patrón de depósitos de cenizas sugiere que se produjo durante el verano del hemisferio norte, ya que sólo el monzón de verano podría haber depositado ceniza de Toba en el mar de la China Meridional. La erupción puede haber durado dos semanas, y el consiguiente "invierno volcánico" dio lugar a una disminución de la temperatura global promedio de 3,0 a 3,5 °C durante varios años.
En los núcleos de hielo de Groenlandia se registró una fuerte reducción de los niveles de captura de carbono orgánico. En el sudeste de Asia muy pocas plantas o animales habrían sobrevivido el cambio del entorno, y es posible que la erupción pueda haber causada una mortandad global.

Existe evidencia de estudios de ADN mitocondrial que sugiere que los seres humanos pueden haber pasado por un cuello de botella genético en esta época, el cual redujo la diversidad genética por debajo de lo que se esperaría considerando la edad de la especie. De acuerdo con la teoría de la catástrofe de Toba propuesta por Stanley H. Ambrose de la Universidad de Illinois en Urbana-Champaign en 1998, los efectos de la erupción del Toba pueden haber resultado en una disminución del tamaño de las poblaciones humanas a unas pocas decenas de miles de individuos. Sin embargo, esta hipótesis no es ampliamente aceptada porque no se han observado efectos similares en otras especies animales.

Desde la gran erupción de hace ~70.000 años, han ocurrido varias erupciones de menor magnitud en la caldera de Toba. El pequeño cono de Pusukbukit se formó en el margen suroeste de la caldera, así como domos de lava. La erupción más reciente puede haber ocurrido en Tandukbenua en el extremo noroeste de la caldera, ya que la escasa vegetación podría ser un indicio de una erupción en los últimos siglos.

Algunas partes de la caldera muestran levantamiento debido al relleno parcial de la cámara magmática, el cual causó la emersión de la isla Samosir y la península Uluan por encima de la superficie del lago. Los sedimentos del lago en Samosir muestran que la isla creció con al menos 450 m desde la erupción cataclísmica. Este fenómeno de emersión es bastante frecuente en calderas de gran tamaño, aparentemente debido a la presión ascendente del magma subterráneo. Samosir es probablemente la mayor caldera resurgente de la Tierra.

Recientemente se produjeron fuertes terremotos en los alrededores del volcán, por ejemplo en 1987 a lo largo de la orilla sur del lago a una profundidad de 11 kilómetros. También se registraron terremotos similares en 1892, 1916, y 1920/22.

La mayoría de la población alrededor del lago Toba pertenece a la etnia batak. Las casas tradicionales de los batak se caracterizan por su decoración colorida y sus techos distintivos (que se curvan hacia arriba en cada extremo, como el casco de un barco).

La flora del lago incluye varios tipos de fitoplancton, y plantas acuáticas emergidas, flotantes y sumergidas, mientras que los alrededores del lago se compone de selva tropical, incluyendo bosques de pinos tropicales de Sumatra en las laderas de las montañas más altas.

La fauna del lago incluye varias especies de zooplancton y animales bentónicos. El lago es oligotrófico (pobre en nutrientes) y la ictiofauna nativa es relativamente escasa, y las únicas especies endémicas son "Rasbora tobana" (en rigor casi endémica, ya que también se encuentra en algunos afluentes que desembocan en el lago) y "Neolissochilus thienemanni", localmente conocido como el pez Batak. Esta última especie se ve amenazada por la deforestación (que causa sedimentación), la contaminación, cambios en el nivel del agua y las numerosas especies de peces que se han introducidas en el lago.
Otros peces nativos incluyen especies como "Aplocheilus panchax", "Nemacheilus pfeifferae", "Homaloptera gymnogaster", "Channa gachua", "Channa striata", "Clarias batrachus", "Barbonymus gonionotus", "Barbonymus schwanenfeldii", "Danio albolineatus", "Osteochilus vittatus", "Puntius binotatus", "Rasbora jacobsoni", "Tor tambra", "Betta imbellis", "Betta taeniata" y "Monopterus albus". Entre la multitúd de especies introducidas se encuentran "Anabas testudineus", "Oreochromis mossambicus", "Oreochromis niloticus", "Ctenopharyngodon idella", "Cyprinus carpio", "Osphronemus goramy", "Trichogaster pectoralis", "Trichopodus trichopterus", "Poecilia reticulata" y "Xiphophorus hellerii".




</doc>
<doc id="41189" url="https://es.wikipedia.org/wiki?curid=41189" title="Bandera del Reino Unido">
Bandera del Reino Unido

La bandera del Reino Unido, oficialmente denominada Union Flag (Bandera de la Unión) y más conocida como la Union Jack (torrotito de la Unión), es una combinación de las cruces de los santos patronos de Inglaterra, de Escocia y de Irlanda del Norte, tres de las cuatro regiones que, junto con Gales, forman el Reino Unido de Gran Bretaña e Irlanda del Norte.

La cruz de San Jorge es la bandera de Inglaterra, la cruz de San Andrés es la bandera de Escocia y la cruz de San Patricio fue la bandera de Irlanda. 

La versión final de la Bandera de la Unión apareció en 1801, al producirse la unión de Gran Bretaña con Irlanda, a raíz de lo cual se incluyó la cruz de San Patricio porque con anterioridad ya se habían combinado las cruces de los patronos de Inglaterra y Escocia. La cruz permanece en la bandera aunque en la actualidad únicamente Irlanda del Norte forma parte del Reino Unido. 

Se debe notar que en la versión definitiva de esta no oficial bandera del Reino Unido tiene una peculiaridad: Las dos cruces aspadas, es decir, la blanca sobre fondo azul o de san Andrés, que representa a Escocia (ver bandera de Escocia), y la roja aspada de san Patricio, que representa a Irlanda, se intercalan detrás de la cruz inglesa de San Jorge. Tal intercalación de las cruces de san Andrés y de san Patricio se hizo para evitar dar la idea de primacía de Escocia sobre Irlanda o viceversa.

Conviene advertir que, mientras que las cruces de San Jorge y San Andrés tienen una larga tradición, la cruz de San Patricio es de invención reciente, en paralelo con la independencia de la República de Irlanda.

Gales no está representada en la bandera de la Unión porque, cuando apareció la primera versión oficial de su bandera, Gales ya se había unido con Inglaterra, aunque los elementos de la bandera del País de Gales, un dragón rojo sobre un fondo blanco y verde, datan del siglo XV. El dragón es un símbolo que probablemente fue introducido en Gran Bretaña por las legiones romanas. 
La Bandera de la Unión se debe izar con la banda diagonal blanca más ancha hacia arriba cerca del asta, y la banda blanca diagonal más angosta (en la parte que ondea) más lejos del asta.

Por otra parte, el Reino Unido es de los países que tienen diferentes pabellones nacionales. Denominan Pabellón Rojo al pabellón civil, Pabellón Blanco al pabellón naval (excepto la Real Fuerza Aérea, que tiene un pabellón especial), y Pabellón Azul al pabellón institucional. Además, tienen infinidad de variantes de cada uno de ellos, con privilegios aprobados para diversos organismos y clubes náuticos, que pueden incluir sus escudos en el batiente del pabellón correspondiente.

La Enseña de la Union Jack aparece en gran cantidad de banderas de las excolonias y colonias británicas. Por ejemplo, en las de Australia, Nueva Zelanda, Tuvalu, Hawái, Fiyi, Santa Helena, Malvinas; en la antigua bandera de Canadá, pero esta última sigue siendo usada en las provincias de Ontario y Manitoba; la antigua bandera de Sudáfrica, en la bandera de las Trece Colonias que precedieron a los Estados Unidos, en la de Victoria (Australia), etc.




</doc>
<doc id="41190" url="https://es.wikipedia.org/wiki?curid=41190" title="Alfabeto batak">
Alfabeto batak

El alfabeto Batak es un tipo de alfabeto llamado un abugida que es usado para escribir las lenguas Batak del norte de Sumatra, un grupo de lenguas austronesias hablados por cerca de tres millones de personas en la isla indonesia de Bali. En la mayor parte de las comunidades Batak, sólo los sacerdotes o "datu" son capaces de usar el alfabeto Batak, y lo usan principalmente para textos mágicos y calendarios.

El alfabeto Batak fue derivado probablemente de los alfabetos Pallava y Antiguo Kawi, que en último término fueron derivados del alfabeto Brahmi, la raíz de todos los abugidas del Índico y del sudeste de Asia.

Como la mayoría de los abugidas, cada letra tiene una vocal /a/ inherente. Las otras vocales son indicadas usando marcas diacríticas que pueden aparecer encima, debajo, a la izquierda o a la derecha de la consonante.



</doc>
<doc id="41192" url="https://es.wikipedia.org/wiki?curid=41192" title="Lenguas austronesias">
Lenguas austronesias

Las lenguas austronesias constituyen una familia lingüística formada por más de 1250 lenguas que se distribuyen entre la isla de Madagascar, el archipiélago malayo y Oceanía. El nombre de esta familia deriva del término griego "austronesia", 'islas del sur'. 

Los pueblos que hablan estas lenguas suelen ser llamados pueblos austronesios. Se considera que la "Urheimat" de esta gran familia está en Taiwán, isla que fue invadida por grupos chinos que se impusieron a los pueblos nativos, de modo que la mayor parte de las lenguas formosanas se encuentran actualmente en grave peligro de extinción. Por el contrario, hay otras de estas lenguas que gozan de excelente salud y se encuentran entre las que tienen mayor número de hablantes en el mundo, tal es el caso del malayo, el indonesio, el javanés y el tagalo.

El descubrimiento de la familia es antiguo y precede al de las lenguas indoeuropeas (afirmada claramente sólo a finales del siglo XVIII y establecida científicamente a partir del siglo XIX). Desde 1706, el lingüista Hadrian Reland ya había subrayado el parecido entre la lengua hablada en Futuna, el "malayo" y el "malgache", a partir del glosario recogido por Jacob Le Maire en Futuna. La existencia de una familia de lenguas, que con sucesivas ampliaciones y clarificaciones se denomina actualmente austronesia, se reconoce definitivamente en "Catalogo delle Lingue" de Lorenzo Hervás y Panduro en 1784. En 1834, la familia, extendida hasta la isla de Pascua, es bautizada como "malayo-polynesia" por Wilhelm von Humboldt en "Über die Kawi-Sprache auf der Insel Java" (1836-1839). También se denominó "Lenguas oceánicas", reconociéndoles desde 1896 un origen común y una relación incluso con las lenguas formosanas, clasificándolas tradicionalmente en lenguas "indonesias, melanesias, polinesias y micronesias".

En otros trabajos, las "lenguas melanesias" fueron tratadas aparte durante largo tiempo, probablemente por prejuicios raciales, a pesar de los trabajos del lingüista Otto Dempwolff (1920).

La familia austronesia es una de las que posee mayor extensión geográfica abarcando tres continentes: Asia, Oceanía y África. Cuenta con más de 1000 lenguas la mayor parte de ellas en las . Los últimos territorios en ser alcanzados por la expansión austronesia probablemente fueron Hawái, Isla de Pascua en el siglo V y Nueva Zelanda hacia el siglo IX.

La lingüística comparativa, apoyada por hallazgos arqueológicos, localiza el origen de los ancestros lingüísticos de la familia en el sureste de la actual China desde donde emigraron hacia Taiwán.

El origen está relacionado con el temprano poblamiento de Taiwán durante la edad de hielo, el cual se encontraba unido al continente. Al subir el nivel del mar hace unos 10.000 años, emerge como isla produciéndose el aislamiento de la población de aborígenes de Taiwán. 

Las lenguas austronesias son la única familia cuya característica principal ha sido la expansión marítima. Desde hace unos 5.000 años sus hablantes se dispersan según el siguiente esquema simplificado:

La estructura interna de la familia austronesia es compleja, pues está constituida por un gran número de lenguas cercanamente relacionadas con un gran número de continuos dialectales, lo que dificulta el establecimiento de los límites entre cada grupo que conforma la familia. A pesar de ello es claro que la gran diversidad filogenética se encuentra entre las lenguas formosanas y es menor entre los idiomas hablados en las islas del Pacífico. Esta situación apoya la hipótesis de que el origen de esta familia se encuentra en la isla de Formosa o China. 

El trabajo seminal en la clasificación de las lenguas formosanas y la macroestructura de la familia austronesia es el de Blust (1999). Algunos especialistas en los idiomas formosanos toman este trabajo con algunas reservas en los detalles, pero se suele tener como referencia para el análisis lingüístico. Las lenguas malayo-polinesias son colocadas con frecuencia dentro del grupo formosano oriental en el trabajo de Blust, debido a la conservación de los fonemas protoaustronesios /*t/ y /*n/, el cambio de /*s/ a /h/, y algunas cuestiones léxicas, como el empleo de "*lima" 'cinco' que no se encuentra en otras lenguas formosanas. 

Es probable que hubiera dos grandes migraciones de pueblos de habla austronesia que cubrieron un áreas extensa en un tiempo relativamente corto, lo que resultó en una diversificación de múltiples grupos locales con una pequeña estructura de gran escala. La primera de estas migraciones correspondería a las lenguas malayo-polinesias, que se llevó a cabo sobre Filipinas, Indonesia y Polinesia. La otra correspondería a las lenguas oceánicas, dispersas sobre Melanesia y Micronesia .

Además del grupo malayo-polinesio, existe amplio consenso sobre la existencia de treinta familias formosanas. El debate académico está centrado sobre todo en las relaciones entre estos grupos. 

La clasificación de la familia lingüística austronesia, conformada por más de un millar de lenguas, es sumamente compleja. Abajo se presenta un panorama muy general, de las principales ramas, de la clasificación ofrecida en "Austronesian Basic Vocabulary Database" (Universidad de Auckland).

Lenguas autronesias

Algunos lingüistas creen que la familia tai-kadai debería colocarse dentro de una versión expandida de la familia austronesia, en particular las similitudes se dan con las lenguas kra. Otros se decantan a favor de una relación con la familia sino-tibetana. Y finalmente otros han propuesto una relación con las lenguas austroasiáticas, formando una superfamilia áustrica. Ninguna de estas propuestas se ha ganado la aceptación de la comunidad científica.

Las lenguas malayo-polinesias utilizan la reduplicación (procedimiento morfológico consistente en la repetición de todo o parte de una palabra) para expresar el plural y todas las lenguas austronesias tienen una entropía de primer orden baja, es decir, los textos son bastante repetitivos en cuanto a la frecuencia de los sonidos. La mayoría no posee grupos de consonantes (como [str] o [mpl]) y tiene un número de vocales pequeño, siendo cinco lo más común.

La primera reconstrucción del proto-malayo-polinesio fue intentada por Dempwolf en 1934 aunque su trabajo ignora las lenguas formosanas que parecen retener arcaísmos y distinciones fonológicas que se han perdido en el resto de la familia. El trabajo de Dyen (1965) considera las lenguas formosanas y añade algunas distinciones fonémicas introduciendo los fonemas /C, Z, D, T, L, R/ cuyo valor fonético exacto siguió difícil de reconstruir y ha sido fuente de no pocas revisiones. Más recientemente Malcom Ross examina los diversos intentos posteriores a Dyen y propone el siguiente inventario fonológico:
Los signos en mayúscula se justifican a partir de correspondencias fonéticas regulares entre cognados aunque su interpretación fonética es algo insegura. Ross propone como probables las siguientes interpretaciones para esos sonidos:

El inventario vocálico reconstruido es:
El fonema /ə/ aparece transcrito en muchas reconstrucciones simplemente como "e".

Los numerales reconstruidos para diferentes ramas de lenguas austronesias son:
En la tabla anterior se ha usado /s/-/ś/ para transcribir el par de sibilantes que otros autores transcriben como /s/-/S/.




</doc>
<doc id="41193" url="https://es.wikipedia.org/wiki?curid=41193" title="Páncreas">
Páncreas

El páncreas (del griego "πάνκρεας") es un órgano del aparato digestivo y del sistema endocrino de los vertebrados. En los seres humanos se localiza en la cavidad abdominal, justo detrás del estómago.<br>Es tanto una glándula exocrina como endocrina. Como endocrina tiene la función de secretar al torrente sanguíneo varias hormonas importantes, entre las que se encuentran insulina, glucagón, polipéptido pancreático y somatostatina. Como exocrina secreta jugo pancreático al duodeno a través del conducto pancreático. Este jugo contiene bicarbonato, que neutraliza los ácidos que entran en el duodeno procedentes del estómago; y enzimas digestivas, que descomponen los carbohidratos, proteínas y lípidos de los alimentos.

La inflamación del páncreas se conoce como pancreatitis, producida por causas como el consumo crónico de alcohol y los cálculos biliares. Debido a su papel en la regulación del azúcar en la sangre, el páncreas es también un órgano clave en la diabetes mellitus. El cáncer de páncreas puede surgir después de una pancreatitis crónica o por otras razones, y tiene un pronóstico muy malo, ya que a menudo se identifica cuando se ha extendido a otras áreas del cuerpo.

La palabra páncreas proviene del griego πᾶν (pân, "todo") y κρέας (kréas, "carne") en referencia a su color rojo parecido a la carne. La función del páncreas en la diabetes se conoce desde al menos 1889, y su papel en la producción de insulina se identificó en 1921.

El páncreas, en los seres humanos, se encuentra por detrás del estómago, entre el bazo y el duodeno, a nivel de la primera y segunda vértebras lumbares, junto a las glándulas suprarrenales. Forma parte del contenido del espacio retroperitoneal.

Tiene forma alargada y se divide en varias partes llamadas cabeza, cuello, cuerpo y cola. En la especie humana mide entre 15 a 20 cm de largo, 4 a 5 de grosor, con un peso que oscila entre 70 y 150  gr.


El canal común que lleva la bilis y las secreciones pancreáticas al duodeno está revestido por un complejo circular de fibras de músculo liso que se condensan en el esfínter de Oddi a medida que atraviesan la pared del duodeno.

El páncreas se desarrolla a partir de la 5° semana de vida embrionaria en la parte caudal del intestino anterior, a partir de brotes endodérmicos dorsal y ventral. El borde ventral forma el proceso unciforme y la cabeza pancreática. Gira hacia atrás y se fusiona con el brote dorsal que formará la parte restante de la glándula. Cuando esta fusión no ocurre dará origen a una anomalía que se llama "Páncreas divisum".

El páncreas recibe sangre del tronco celiaco y la arteria mesentérica superior, ambos son ramas de la aorta abdominal.

El páncreas tiene una parte exocrina cuya función es digestiva y una parte endocrina con funciones metabólicas, por lo tanto es una glándula mixta.

Su unidad histológica es el acino pancreático (acino = proviene del griego "uva"), por ser una estructura histológica esférica y uvoide hueca. La secreción exocrina del páncreas tiene un componente acuoso sintetizado por las células centroacinares (rico en bicarbonato) y un componente enzimático o proteico sintetizado por las células acinares (pequeño volumen del total de la secreción exocrina del páncreas que contiene enzimas digestivas para todos los constituyentes de las comidas: carbohidratos, lípidos y proteínas).



Su unidad histológica son los islotes de Langerhans (en honor al patólogo alemán que los describió), que consisten en cúmulos de células secretoras de hormonas. Existen diversos tipos de células en los islotes cada una de las cuales produce una hormona diferente.



El tamaño del páncreas varía considerablemente. Existen varias variaciones anatómicas, relacionadas con el desarrollo embriológico de los dos divertículos o brotes pancreáticos. El páncreas se desarrolla a partir de estos dos divertículos a cada lado del duodeno. El brote ventral gira para colocarse junto al brote dorsal, y finalmente se fusionan. Si los dos brotes no se fusionan —cada uno con su ducto—, puede existir un páncreas con dos ductos separados. Esta anomalía, llamada páncreas divisum, no tiene consecuencias físicas. Si el brote ventral no gira completamente, puede existir un páncreas anular. En ocasiones existe un conducto pancreático accesorio o secundario llamado conducto de Santorini.

Algunas de las más habituales son las siguientes:

El tejido pancreático está presente en todas las especies de vertebrados, pero su forma exacta y su disposición varían ampliamente. Puede haber hasta tres páncreas separados, dos de los cuales surgen a partir de yemas ventrales, y el otro de la yema dorsal. En la mayoría de las especies (incluidos los humanos), estos se fusionan en el adulto, pero hay varias excepciones. Incluso cuando un solo páncreas está presente, dos o tres conductos pancreáticos pueden persistir, para drenar por separado en el duodeno (o parte equivalente del intestino anterior). Las aves, por ejemplo, suelen tener tres de estos conductos.

En los peces teleósteos el tejido pancreático se distribuye de manera difusa a través del mesenterio e incluso dentro de otros órganos cercanos, como el hígado o el bazo. En unas pocas especies de teleósteos, el tejido endocrino se ha fusionado para formar una glándula distinta dentro de la cavidad abdominal, pero por lo demás está distribuido entre los componentes exocrinos. La disposición más primitiva, sin embargo, parece ser la de lampreas y pulmonados, en el que el tejido pancreático se encuentra como un número de nódulos discretos dentro de la pared del propio intestino, con las porciones exocrinas siendo poco diferente de otras estructuras glandulares del intestino.




</doc>
<doc id="41200" url="https://es.wikipedia.org/wiki?curid=41200" title="Estrecho de la Sonda">
Estrecho de la Sonda

El estrecho de la Sonda (en indonesio, "Selat Sunda") es un estrecho marino que separa las islas indonesas de Java y Sumatra. Conecta el mar de Java con el océano Índico.

El nombre del estrecho viene de "Sunda", que significa el país de los sondanés, el pueblo que habita la parte occidental de la isla de Java. "Sunda" también ha dado su nombre a las islas de la Sonda, un nombre que tradicionalmente se aplica a una parte del archipiélago indonesio. 

El estrecho se extiende a lo largo de un eje de orientación general suroeste/noreste. Su ancho mínimo es de 24 km entre el cabo Tua, en Sumatra, y el cabo Pujats, en Java. Tiene alrededor de 30 km de anchura en su tramo más estrecho, en el extremo nororiental, pero es una sección corta de alrededor de 30 km de largo, aunque luego se abre hasta los 100 km en un tramo de otros 100 km de largo. 

El estrecho está salpicado por una serie de pequeñas islas, incluyendo Sangiang, Sebesi, Sebuku, Panaitan y las islas de Krakatoa: Krakatoa, Lang (Panjang o Rakata Kecil), Verlaten (Sertung), y Anak Krakatoa. Muchas de ellas (incluyendo Sebesi y Panaitan) son de origen volcánico. Anak Krakatoa es producto de la famosa erupción de 1883. 

El estrecho es profundo en su extremo occidental, pero en su parte oriental, la profundidad mínima es de 20 metros. De hecho, no es un estrecho fácil para la navegación marítima, con numerosos bancos de arena, fuertes corrientes de marea y con muchas plataformas petroleras en las cercanías de Java. 

Según una hipótesis reciente, emitida por el arqueólogo Daid Keys y el geólogo Ken Wohletz, el estrecho conecta el mar de Java con el océano Índico desde el año 535, debido a una erupción del mismo Krakatoa. Esta erupción habría dejado una caldera de 50 km de diámetro, separando las islas de Java y Sumatra.
Sin embargo, esta hipótesis no tiene el favor de la mayoría de los geólogos e historiadores, que generalmente consideran que el estrecho de Sunda es mucho más antiguo, debiendo su existencia no a una caldera, sino al graben.

Fue durante siglos una importante vía marítima, sobre todo cuando la Compañía Holandesa de las Indias Orientales hacía pasar por sus aguas sus mercancías que provenían de las Molucas e iban hacia Europa o la India, como puerta de entrada a las islas de las Especias (1602-1799). Como uno de los principales pasos desde el mar de la China Meridional al océano Índico (siendo el otro el estrecho de Malaca), el estrecho de la Sonda, a pesar de los peligros debidos a la estrechez y las rocas, es mucho más corto que el estrecho de Malaca, y consecuentemente los barcos corrían menos riesgos del ataque de los piratas.

Las islas del estrecho y las regiones de las inmediaciones que lo rodean, en Java y Sumatra, fueron devastadas por la erupción del Krakatoa en 1883, debido principalmente a la intensa caída de cenizas y piedra pómez y a los enormes tsunamis causados por el colapso del volcán. La erupción alteró drásticamente la topografía del estrecho, con entre 18-21 km³ de ignimbrita que se depositaron en una superficie de 1,1 millones de km² alrededor del volcán. Algunas zonas no han sido nunca de nuevo reocupadas (como la región costera de Java ahora incorporada en el Parque Nacional de Ujung Kulon), pero la mayor parte de la costa está ahora muy densamente poblada. 

Hoy en día, la angostura del estrecho, su poca profundidad y la falta de cartas marinas lo hacen inadecuado para muchos grandes buques modernos y ha sido relegado como ruta marítima en favor del estrecho de Malaca, entre Sumatra y la península de Malaca.

El 1 de marzo de 1942 la batalla del Estrecho de la Sonda —parte de la gran batalla del Mar de Java— se libró en sus aguas, cuando los cruceros aliados HMAS Perth y USS Houston encontraron una fuerza japonesa de desembarco anfibio cerca de Bantam, al mando del almirante Kenzaburo Hara, que incluía portaaviones, tres cruceros y diez destructores. Los cruceros aliados fueron hundidos, pero un dragaminas y un buque de transporte japoneses también fueron hundidos por fuego amigo.

En la década de 1960 se hicieron propuestas para construir un puente sobre el estrecho de Sonda, y en el decenio de 1990 surgieron nuevas propuestas. Un nuevo plan se anunció en octubre de 2007, lo que implicaría utilizar las islas de Ular, Sangiang y Prajurit para crear un puente suspendido de cuatro partes, con una longitud de unos 26 km realizado a unos 70 metros sobre el nivel del mar y con un vano máximo de 3 kilómetros, casi un 50% más largo que el récord actual, el Gran Puente de Akashi Kaikyō.


</doc>
<doc id="41209" url="https://es.wikipedia.org/wiki?curid=41209" title="Estadística de Maxwell-Boltzmann">
Estadística de Maxwell-Boltzmann

En física, la estadística de Maxwell-Boltzmann es una función estadística desarrollada para modelar el comportamiento de sistemas físicos regidos por la mecánica clásica. Esta función estadística clásica, formulada originalmente por los físicos J.C. Maxwell y L. Boltzmann, rige la distribución de un conjunto de partículas en función de los posibles valores de energía de los estados que estas pueden ocupar. Para cada sistema termodinámico, la distribución de Maxwell-Boltzmann no es otra cosa que la aplicación del colectivo canónico de la mecánica estadística, bajo el supuesto no-cuántico de que los números de ocupación de cada estado disponible son pequeños comparados con el número máximo de ocupación.

Esta función es una densidad de probabilidad cuya expresión es:

O de forma más generalizada, puede expresarse como:

En donde:

La distribución de Maxwell-Boltzmann se ha aplicado especialmente a la teoría cinética de gases, y otros sistemas físicos, además de en econofísica para predecir la distribución de la renta. En realidad la distribución de Maxwell-Boltzmann es aplicable a cualquier sistema formado por "N" "partículas" o "individuos" que interacambian estacionariamente entre sí una cierta magnitud "M" y cada uno de ellos tiene una cantidad "m" de la magnitud "M" y a lo largo del tiempo se cumple que "M" := "m"+"m"+...+ "m".

Para un sistema de partículas cuánticas, la hipótesis de que formula_4 sea substancialmente menor que formula_6 para los estados diferentes del fundamental en general no se cumplirá y es necesario acudir a la estadística de Bose-Einstein si las partículas son bosónicas o a la estadística de Fermi-Dirac si las partículas son fermiónicas.

Las estadísticas de Fermi–Dirac (+) y Bose–Einstein (−) pueden ser expresadas como:

Asumiendo que el valor mínimo de formula_5 es bastante pequeño, se puede verificar que la condición en la cual la distribución de Maxwell-Boltzmann es válida es cuando se cumple que:

Para un gas ideal, podemos calcular los potenciales químicos utilizando el desarrollo de la ecuación Sackur–Tetrode para demostrar que :

dónde formula_18 es la energía interna total, formula_19 es la entropía, formula_20 es el volumen, y formula_21 es el longitud de onda térmica de De Broglie. La condición de aplicación para la distribución Maxwell-Boltzmann en un gas ideal resulta:



</doc>
<doc id="41211" url="https://es.wikipedia.org/wiki?curid=41211" title="Mercurio (mitología)">
Mercurio (mitología)

En la mitología romana, Mercurio (en latín, "Mercurius") era un importante dios del comercio, hijo de Júpiter y de Maia Maiestas. Su nombre está relacionado con la palabra latina "merx" (‘mercancía’). En sus formas más antiguas, parece haber estado relacionado con la deidad etrusca Turms, pero la mayoría de sus características y mitología se tomó prestada del dios griego análogo Hermes.

Mercurio ha inspirado el nombre de varias cosas en cierto número de campos científicos, como el planeta Mercurio, el elemento mercurio y la planta mercurial. La palabra «mercurial» se usa comúnmente para aludir a algo o alguien errático, volátil o inestable, y deriva de los rápidos vuelos de Mercurio de un lugar a otro.

Mercurio no aparecía entre los "numena di indigetes" de la primitiva religión romana. Más bien subsumió a los antiguos Dei Lucrii cuando la religión romana se sincretizó con la griega durante la época de la república romana, sobre principios del Desde el principio, Mercurio tuvo esencialmente los mismos aspectos que Hermes, vistiendo las talarias y el pétaso alados y llevando el caduceo, una vara de heraldo con dos serpientes entrelazadas que Apolo regaló a Hermes. A menudo iba acompañado de un gallo, el heraldo del nuevo día, una cabra o cordero que simbolizaba la fertilidad y una tortuga en alusión a la legendaria invención de Mercurio de la lira a partir de un caparazón.

Como Hermes, era también un mensajero de los dioses y un dios del comercio, particularmente del comercio de cereal. Mercurio también era considerado un dios de la abundancia y del éxito comercial, particularmente en la Galia. También fue, como Hermes, el psicopompo de los romanos, y llevaba las almas de los recién fallecidos al más allá. Además, Ovidio escribió que Mercurio llevaba los sueños de Morfeo desde el valle de Somnus a los humanos que dormían.

El templo de Mercurio en el Circo Máximo, entre el Aventino y el Palatino, se construyó en Este era un lugar adecuado para adorarle como un veloz dios del comercio y el viaje, debido a que era un importante centro de comercio además de una pista de carreras. Debido a que se erigía entre el baluarte plebeyo del Aventino y el centro patricio del Palatino, enfatizaba también el papel de Mercurio como mediador.

Debido a que Mercurio no fue una de las deidades primitivas que sobrevivieron a la monarquía romana, no tenía asignado un flamen (sacerdote), pero sí tenía una importante fiesta el 15 de mayo, la Mercuralia. Durante la misma, los mercaderes rociaban agua de su pozo sagrado cerca de la Porta Capena sobre sus cabezas.

Cuando describían a los dioses de las tribus celtas y germánicas, más que considerarlas como deidades separadas, los romanos los interpretaban como manifestaciones locales o aspectos de sus propios dioses, un rasgo cultural llamado "interpretatio romana". En particular, Mercurio se hizo extremadamente popular entre las naciones conquistadas por el Imperio romano: Julio César escribió que era el dios más popular en Bretaña y Galia, considerado el inventor de todas las artes. Esto probablemente se deba a que en el sincretismo romano se equiparó a Mercurio con el dios celta Lugus, y en este aspecto solía ir acompañado de la diosa celta Rosmerta. Aunque Lugus pudo haber sido originalmente una deidad de la luz o del sol (aunque esto es discutible), parecido al Apolo romano, su importancia como dios del comercio le hizo más comparable a Mercurio, y Apolo fue equiparado a su vez con la deidad celta Belenus.

Mercurio también estuvo fuertemente relacionado con el dios germánico Wodanaz: el escritor romano del siglo I Tácito identificaba a ambos como uno solo, a quien describía como el dios principal de los pueblos germánicos.

En las regiones celtas, Mercurio se representó a veces con tres cabezas o caras, y en Tongeren (Bélgica) se halló una estatuilla de Mercurio con tres falos, en la que sobresalen los dos adicionales de su cabeza en lugar de su nariz, lo que probablemente se deba a que el número tres se consideraba mágico, lo que hacía de tales estatuas hechizos de buena suerte y fertilidad. Los romanos también hicieron popular el uso de pequeñas estatuas de Mercurio, probablemente al adoptar la antigua tradición griega de las hermas.

Mercurio, conocido por los romanos como "Mercurius" y que aparece ocasionalmente en los escritos más antiguos como "Merqurius", "Mirqurios" o "Mircurios", tuvo cierto número de epítetos, que representaban diferentes aspectos o roles o sincretismos con deidades no romanas. Los más comunes e importantes son:

Ovidio: "Las metamorfosis", II, 679 – 701 (Mercurio y Bato).





</doc>
<doc id="41216" url="https://es.wikipedia.org/wiki?curid=41216" title="Eritrocito">
Eritrocito

Los eritrocitos (del griego ἐρυθρός ‘rojo’, y κύτος ‘bolsa’) también llamados glóbulos rojos o hematíes, son las células más numerosas de la sangre. La hemoglobina es uno de sus principales componentes, y su función es transportar el oxígeno hacia los diferentes tipos de tejidos del cuerpo. Los eritrocitos humanos, así como los del resto de mamíferos, carecen de núcleo y de mitocondrias, por lo que deben obtener su energía metabólica a través de la fermentación láctica. La cantidad considerada normal en la especie humana fluctúa entre 4 500 000 (en la mujer) y 5 400 000 (en el hombre) por milímetro cúbico (o microlitro) de sangre, es decir, aproximadamente 1000 veces más que los leucocitos. El exceso de glóbulos rojos se denomina policitemia y su deficiencia se llama anemia.Los eritrocitos se utilizan comúnmente en transfusiones en la práctica clínica y se han sugerido como transportadores de fármacos y nanopartículas.

El eritrocito es un disco bicóncavo de entre 5 y 7,5 μm de diámetro, de 1 μm de grosor y de 80 a 100 femtolitros de volumen. La célula ha perdido su ARN residual y sus mitocondrias, así como algunas enzimas importantes; por tanto, es incapaz de sintetizar nuevas proteínas o lípidos. Su citoplasma contiene en mayor parte el pigmento hemoglobina, que les concede su característico color rojo (que puede ser más oscuro dependiendo de su oxigenación) y es el responsable del transporte de oxígeno. 

Ahora bien, esta descripción se aplica a los eritrocitos de mamíferos, pues en el resto de vertebrados, salvo algunas excepciones, los eritrocitos carecen de la forma bicóncava y acostumbran ser más grandes que los descritos anteriormente. Esto se debe a que los glóbulos rojos del resto de vertebrados todavía poseen núcleo.

Los eritrocitos derivan de las células madre comprometidas denominadas hemocitoblasto. La eritropoyetina, una hormona de crecimiento producida en los tejidos renales, estimula la eritropoyesis (es decir, la formación de eritrocitos) y es responsable de mantener una masa eritrocitaria en un estado constante. Los eritrocitos, al igual que los leucocitos, tienen su origen en la médula ósea.

La concentración eritrocitaria varia según el sexo, la edad y la ubicación geográfica. Se encuentran concentraciones más altas de eritrocitos en zonas de gran altitud, en varones y en recién nacidos. Las disminuciones por debajo del rango de referencia generan un estado patológico denominado anemia. Esta alteración provoca hipoxia tisular. El aumento de la concentración de eritrocitos (policitemia) es menos común.

La hemólisis es la destrucción de los eritrocitos envejecidos y sucede en los macrófagos del bazo e hígado. Los elementos esenciales, globina y hierro, se conservan y vuelven a usarse. La fracción hemo de la molécula se cataboliza a bilirrubina y a biliverdina, y finalmente se excreta a través del tracto intestinal. La rotura del eritrocito a nivel intravascular libera hemoglobina directamente a la sangre, donde la molécula se disocia en dímeros α y β, los cuales se unen a la proteína de transporte, haptoglobina. Esta transporta los dímeros al hígado, donde posteriormente son catabolizados a bilirrubina y se excretan.

Los eritrocitos de los mamíferos no poseen núcleo cuando llegan a la madurez, es decir, pierden su núcleo celular y por lo tanto su ADN; los anfibios, reptiles y aves tienen eritrocitos con núcleo. Los eritrocitos también pierden sus mitocondrias y utilizan la glucosa para producir energía mediante el proceso de glucólisis seguido por la fermentación láctica.

Los eritrocitos son producidos continuamente en la médula ósea de los huesos largos, aunque en el embrión, el hígado es el principal productor de eritrocitos. El bazo actúa como reservorio de eritrocitos, pero su función es algo limitada en los humanos. Sin embargo, en otros mamíferos, como los perros y los caballos, el bazo libera grandes cantidades de eritrocitos en momentos de estrés. Algunos atletas han tratado de explotar esta función del bazo tratando de liberar sus reservas de eritrocitos mediante fármacos, pero esta práctica pone en riesgo al sistema cardiovascular, dado que este no está preparado para soportar sangre cuya viscosidad sea superior a la considerada normal.

Los eritrocitos tienen una forma oval, bicóncava, aplanada, con una depresión en el centro. Este diseño es el óptimo para el intercambio de oxígeno con el medio que lo rodea, pues les otorga flexibilidad para poder atravesar los capilares, donde liberan la carga de oxígeno. El diámetro de un eritrocito típico es de 6-8 µm. Los glóbulos rojos contienen hemoglobina, que se encarga del transporte de oxígeno y del dióxido de carbono. Asimismo, es el pigmento que le da el color rojo a la sangre.


Dada la necesidad constante de reponer los eritrocitos, las células eritropoyeticas de la médula ósea se cuentan entre las de crecimiento y reproducción más rápidas de todo el cuerpo. Por tanto, como cabria esperar, su maduración y producción resultan muy afectadas en casos de deficiencias nutricionales importantes.

Para la maduración final de los eritrocitos se necesitan en particular dos vitaminas: la vitamina B12 y el ácido fólico. Ambas son esenciales para la síntesis del ADN porque las dos, de forma diferente, resultan necesarias para la formación de trifosfato de timidina, uno de los componentes esenciales del ADN. Por lo tanto, la carencia de vitamina B12 o de ácido fólico originan una disminución de la producción de ADN y, en consecuencia, determina un fracaso de la maduración y división nuclear.

Asimismo, las células eritroblásticas de la médula ósea, además de no proliferar con rapidez, originan sobre todo eritrocitos de mayor tamaño que el normal denominados macrocitos, con una membrana muy delgada, irregular y oval, en lugar del disco bicóncavo habitual. Estas células mal formadas, tras entrar en la sangre circulante, transportan oxígeno con normalidad, pero debido a su fragilidad, su vida se acorta de la mitad a una tercera parte. Por eso, se dice que el déficit de vitamina B12 o de ácido fólico produce un fracaso de la maduración eritropoyetica.

Existen otras causas que alteran la maduración de los eritrocitos, como la deficiencia de hierro y otras anomalías genéticas que conducen a la producción de hemoglobinas anormales. Todos estos problemas conducirán a alteraciones de los eritrocitos, por alteración de la membrana, el citoesqueleto u otros.

Las etapas de desarrollo morfológico de la célula eritroide incluyen (en orden de madurez creciente) las siguientes etapas:

A medida que la célula madura, la producción de hemoglobina aumenta, lo que genera un cambio en el color del citoplasma en las muestras de sangre teñidas con la tinción de Wright, de azul oscuro a gris rojo y rosáceo. El núcleo paulatinamente se vuelve picnótico, y es expulsado fuera de la célula en la etapa ortocromática.

La membrana del eritrocito en un complejo bilipídico–proteínico, el cual es importante para mantener la deformabilidad celular y la permeabilidad selectiva. Al envejecer la célula, la membrana se hace rígida, permeable y el eritrocito es destruido en el bazo. La vida media promedio del eritrocito normal es de 100 a 120 días.

La membrana del eritrocito tiene varios roles que ayudan en la regulación superficial de la deformación, flexibilidad, adhesión a otras células y reconocimiento inmunológico. Estas funciones son altamente dependientes de su composición, lo cual define sus propiedades. La membrana del eritrocito está compuesta de tres capas: el glicocálix al exterior, que es rico en carbohidratos; la bicapa lipídica que contiene varias proteínas transmembranales además de sus constituyentes lipídicos principales; y el citoesqueleto membranal, una red estructural de proteínas localizado en la superficie interna de la bicapa lipídica. La mitad de la masa de la membrana del eritrocito en humanos y la mayoría de los mamíferos son proteínas, la otra mitad son lípidos, principalmente fosfolípidos y colesterol.

La membrana del eritrocito está compuesta por una bicapa lipídica, similar a la que se encuentra prácticamente en todas las células humanas. Esta bicapa lipídica está compuesta de colesterol y fosfolípidos en proporciones iguales en peso. La composición lipídica es importante debido a que define muchas propiedades físicas como la permeabilidad y la fluidez. Además, la actividad de varias proteínas de membrana es regulada por la interacción con los lípidos de la bicapa. A diferencia del colesterol que se encuentra distribuido de manera uniforme entre las monocapas interna y externa, los 5 fosfolípidos principales están dispuestos de forma asimétrica:

En la monocapa externa

En la monocapa interna

La distribución asimétrica de los fosfolípidos en la bicapa es el resultado de la función de algunas proteínas transportadoras de fosfolípidos tanto dependientes como independientes de energía. Las flipasas son proteínas que mueven fosfolípidos de la monocapa externa a la interna, mientras que las llamadas flopasas hacen la operación inversa, en contra del gradiente de concentración de manera dependiente de energía. Además, están las proteínas escramblasas que mueven fosfolípidos en ambas direcciones al mismo tiempo, por sus gradientes de concentración e independientes de energía. Todavía está en discusión la identidad de las proteínas de mantenimiento de membrana en los eritrocitos.

El mantenimiento de la distribución asimétrica de fosfolípidos en la bicapa es crítica para la integridad y funcionalidad de la célula debido a varias razones:


La presencia de estructuras especializadas llamadas balsas lipídicas en la membrana de los eritrocitos han sido descritas en estudios recientes. Estas estructuras ricas en colesterol y esfingolípidos están asociados a proteínas de membrana específicas, como la proteína G.

El metabolismo de los eritrocitos es limitado, debido a la ausencia de núcleo, mitocondria y otros orgánulos subcelulares. Aunque la unión, el transporte y la liberación de oxígeno y dióxido de carbono es un proceso pasivo que no requiere energía, existe una variedad de procesos metabólicos dependientes de energía que son esenciales para la viabilidad de la célula.

Las vías metabólicas más importantes para el eritrocito maduro necesitan glucosa como sustrato. Estas vías se refieren a:

Estas vías contribuyen con energía, al mantener:

Proporciona ATP para la regulación de la concentración intracelular de cationes (Na, K, Ca, Mg) a través de bombas de cationes. El eritrocito obtiene energía en forma de ATP del desdoblamiento de la glucosa por esta vía. Los eritrocitos normales no tienen depósitos de glucógeno, dependen por completo de la glucosa ambiental para la glucólisis. La glucosa penetra a la célula mediante difusión facilitada, un proceso que no consume energía. Es metabolizada a lactato, donde produce una ganancia neta de dos moles de ATP por un mol de glucosa.

Proporciona nicotinamida-adenina dinucleótido fosfato y glutatión reducido para reducir oxidantes celulares. Aproximadamente el 5 % de la glucosa celular ingresa a la vía oxidativa de las pentosas, un sistema auxiliar para producir coenzimas reducidas. El glutatión reducido protege a la célula contra muchas lesiones producidas por agentes oxidantes permanentes. Los oxidantes dentro de la célula oxidan los grupos sulfhidrilo (-SH) de la hemoglobina, a menos que los oxidantes sean reducidos por el glutatión reducido. Es por esto que es crucial en el eritrocito la función de esta vía.

Protege a la hemoglobina de la oxidación vía la NADH y metahemoglobina reductasa. Se trata de una vía alterna a la vía Embden–Meyerhof, esencial para mantener al hierro hemo en el estado reducido Fe. La hemoglobina con el hierro en estado férrico, Fe, es conocida como metahemoglobina. Esta forma de hemoglobina no logra combinarse con el oxígeno. La metahemoglobina reductasa, en unión con el NADH producido por la vía Embden–Meyerhof, protege al hierro hemo de la oxidación. Sin este sistema, el 2 % de la metahemoglobina formada todos los días se elevaría, con el tiempo, a un 20-40 %, con lo que se limitaría gravemente la capacidad transportadora de oxígeno en la sangre. Los medicamentos oxidantes pueden interferir con la metahemoglobina reductasa y producir valores aún más elevados de metahemoglobina. Esto provoca cianosis.

Este ciclo es parte de la vía Embden–Meyerhof, y tiene por finalidad evitar la formación de 3–fosfoglicerato y ATP. El BPG (2,3-bisfosfoglicerato) está presente en el eritrocito en una concentración de un mol BPG/mol de hemoglobina, y se une con fuerza a la desoxihemoglobina, con lo que la hemoglobina se mantiene en estado desoxigenado y se facilita la liberación de oxígeno. El incremento en la concentración de difosfoglicerato facilita la liberación de oxígeno a los tejidos mediante la disminución en la afinidad de la hemoglobina por el oxígeno. De esta manera, el eritrocito cuenta con un mecanismo interno para la regulación del aporte de oxígeno a los tejidos.

Es un pigmento especial que da a los eritrocitos su color rojo característico. Su molécula posee hierro, y su función es el transporte de oxígeno. Está presente en todos los animales, excepto en algunos grupos de animales inferiores. Participa en el proceso por el que la sangre lleva los nutrientes necesarios hasta las células del organismo y conduce sus productos de desecho hasta los órganos excretores. También transporta el oxígeno desde los pulmones (o desde las branquias, en los peces), donde la sangre lo capta, hasta los tejidos del cuerpo.

Cuando la hemoglobina se une al oxígeno para ser transportada hacia los órganos del cuerpo, se llama oxihemoglobina. Cuando la hemoglobina se une al CO para ser eliminada por la espiración, que ocurre en los pulmones, recibe el nombre de Carboaminohemoglobina (también se denomina desoxihemoglobina a la hemoglobina cuándo no está unida al oxígeno). Si la hemoglobina se une al monóxido de carbono (CO), se forma entonces un compuesto muy estable llamado carboxihemoglobina, que tiene un enlace muy fuerte con el grupo hemo de la hemoglobina e impide la captación del oxígeno, con lo que se genera fácilmente una anoxia que conduce a la muerte.

La hemoglobina también transporta productos residuales y el dióxido de carbono de vuelta a los tejidos. Menos del 2 % total del oxígeno, y la mayor parte del CO, son mantenidos en solución en el plasma sanguíneo. La hemoglobina representa el 35 % del peso del eritrocito. Un compuesto relacionado, la mioglobina, actúa como almacén de oxígeno en las células musculares.



</doc>
<doc id="41220" url="https://es.wikipedia.org/wiki?curid=41220" title="La metamorfosis">
La metamorfosis

La metamorfosis ("Die Verwandlung", en su título original en alemán) es un relato de Franz Kafka publicado en 1915 y que narra la historia de Gregorio Samsa, un comerciante de telas que mantiene a su familia con su sueldo, hasta que tras una noche que no recuerda, amanece convertido en un enorme insecto parecido a un escarabajo. En los últimos años, desde comienzos del siglo XXI, varias editoriales y traductores han preferido emplear la traducción literal del título, que es "La transformación". 

Como el conjunto de la obra de Kafka, "La metamorfosis" ha suscitado diversas interpretaciones, presentadas en numerosos libros y ensayos y no es fácil compendiarlas en un resumen o artículo breve. 

Entre las más obvias están las referidas al trato de una sociedad autoritaria y burocrática hacia el individuo diferente, donde este queda aislado e incomprendido ante una maquinaria institucional abrumadora y que ni él comprende ni tampoco es comprendido por ella. 

Una interpretación reconocida se refiere a la identidad desdoblada de Kafka, quien por un lado siente nostalgia por la identidad judía de sus abuelos y por otro siente que no logra hacer pie en el mundo "gentil" de Praga al que pertenece su padre.

Otra interpretación podría ser que la obra plasma el egoísmo humano ante el bienestar de los demás. Esto lo podemos identificar en la obra en la situación en la que se encontraba Gregorio, ya que sobre él recaía todo el peso de mantener económicamente a su familia. Sin embargo cuando la situación gira y ahora es la familia la que tiene que hacerse cargo de Gregorio, ésta rehúye responsabilidades y lo dejan morir. 

También se dice que Franz Kafka escribió La metamorfosis en forma de autobiografía, obviamente exagerada, de sus sensaciones anímicas y percibir físico. Precisamente el apellido del personaje, "Samsa", es a su vez similar al del propio Kafka con el cambio de consonantes correspondiente.

Gregorio Samsa es el protagonista de la historia, tiene unos 23 años. Trabaja como viajante de comercio para vender telas para mantener a su hermana y a sus padres. Se despierta una mañana como un monstruoso insecto. Tras la metamorfosis, Gregorio se encuentra incapacitado para trabajar, y esto obligará a su padre, a su madre y a su hermana, a trabajar para sustentarse. Pasa la mayor parte del tiempo en su habitación y es testigo del abandono y el desdén de parte de su familia, que crece poco a poco. A veces sale de su habitación para recorrer la casa en secreto.

Grete es la hija pequeña de la familia, hermana de Gregorio Samsa, tiene 17 años. Se convierte en la cuidadora de Gregorio desde que este se transforma en insecto. Al principio Gregorio y Grete tenían una relación muy íntima pero irá cambiando paulatinamente. Grete al principio se ofrece como voluntaria para alimentarle y limpiarle la habitación, pero cada día se despreocupa más por él. Ella toca el violín y parece tener cualidades como para ir al conservatorio musical, un sueño que secretamente Gregorio quería hacerle cumplir. Para aumentar los ingresos de la familia, Grete empieza a trabajar como dependienta en una tienda. Es quien propone al final, la idea de dejar morir a Gregorio, luego de que este hubiese, en teoría, ahuyentado a los inquilinos.

La señora Samsa es la madre de Gregorio. Al principio de la historia se encuentra conmocionada por su transformación aunque quiere entrar en su habitación. En ella se crea un conflicto interno, una fuerte lucha entre la repulsión que le produce el bicho y su instinto materno. Es asmática, lo que impide que pueda trabajar. En una ocasión se desmaya al encontrarse a Gregorio, lo que hace enfadar a Grete.
La madre no ve a su hijo como un insecto, al contrario, lo ve como un humano, es la única que no piensa mal de él.

El señor Samsa es el padre de Gregorio. Después de la metamorfosis, se ve obligado a volver a trabajar para soportar económicamente a la familia y pagar la deuda. Su actitud frente al hijo es dura; al transformarse, Gregorio le da asco y, posiblemente, miedo, y lo ataca en múltiples ocasiones. 

Debido a la necesidad de dinero de la familia tras la transformación de Gregorio, deciden alquilar un cuarto a tres inquilinos. Son los tres de un carácter serio e inquisitivo. Estos se van luego de la aparición de Gregorio, mientras Grete toca el violín.

El gerente 

Es otro personaje inquisitivo. Este se entera de que Gregorio es un insecto. Cuando comprueba que Gregorio no ha tomado el tren que le debería llevar a otra ciudad a trabajar, acude a casa de este, entrando casi hasta su habitación sin ningún tipo de respeto por su intimidad. Reprime a Gregorio llamándole irresponsable y vago por no haber salido a trabajar y por el poco rendimiento que, según él, está teniendo.
Cuando Gregorio sale de su habitación, el apoderado se asusta y de una manera muy cómica sale disparado de la casa por las escaleras.

Criadas

La primera no tiene mucha importancia. La segunda, en cambio, le tenía miedo y le pidió a los padres de Gregorio que la dejaran encerrada en la cocina. Es la tercera criada quien no le teme a Gregorio y lo visita constantemente.

1.-Tiempo Cronológico: La duración de los hechos sucede en aproximadamente en algunos meses, tomando como referencia desde la conversión en insecto de Gregorio Samsa, antes de Navidad, hasta su muerte, bien entrado el mes de marzo.
2.-Tiempo Psicológico El mundo onírico, el de los sueños, ocupaba un lugar axial en la configuración de la obra de Kafka. El tiempo psicológico son 11 años aproximadamente, tomando como referencia los cinco años del hecho que Gregorio no se enfermaba y la proyección de unos seis años más que no debía prescindir de su empleo como comerciante.
3.-Tiempo Histórico Los hechos de la obra históricamente nunca sucedieron.

Una mañana, después de un sueño intranquilo, Gregorio Samsa trata de levantarse para asistir a su trabajo, pero se da cuenta de que durante la noche se ha transformado en un insecto; al darse cuenta de lo tarde que es, intenta comenzar sus actividades diarias habituales, pero al estar acostado sobre su espalda, no logra levantarse de la cama.

Su familia (su madre, su padre y su joven hermana Grete) acaba de preguntar sobre su estado. Gregorio ha cerrado las tres puertas de su habitación e intenta tranquilizarlos, pero ninguno se da cuenta de la singularidad de su voz. 

El gerente de su trabajo llega a casa de Gregorio después de preguntar la razón del retraso tan inusual en Gregorio. Después de largos y penosos esfuerzos, Gregorio, cuya voz peculiar, «una voz bestial», trata de engañarlo y rechaza abrir la puerta y asomar la cabeza por el resquicio. El gerente se impacienta por la falta de explicaciones de Gregorio y comienza a agobiarlo con reproches por su falta de rendimiento, pero, al verlo convertido en un insecto, huye horrorizado. La familia de Gregorio se aleja de él y su madre lo evita en particular. Nadie comprende que Gregorio, pese a su apariencia, comprende y piensa todavía como un ser humano. Ciego de ira, el padre de Gregorio toma el bastón que dejó el gerente y lo conduce de nuevo a su habitación donde lo encierra.

La familia de Gregorio pasa duros momentos por el miedo a que se sepa que albergan a un monstruo como él en su casa. Su padre comienza a odiarlo. Su madre todavía le muestra cierta piedad ya que es su hijo, pero se desvanece después de verlo. Su hermana Grete supera su repulsión y todos los días lo alimenta y limpia su habitación. Gregorio se esconde para que ella no pueda verlo y para no hacerla sufrir. No obstante, Gregorio quisiera que ella lo viera para así recibir un poco de amor. Un día, Grete y su madre, al descubrir que la nueva afición de Gregorio es moverse por la habitación, tanto por las paredes como por el techo, deciden sacar sus muebles para facilitarle la tarea. Gregorio a pesar de notar la buena acción, se siente despojado de sus bienes materiales, y una vez despojado de la mayoría a excepción de su sillón y un cuadro que a él le gustaba, decide, como último recurso, posarse sobre la pintura; cuando la madre y Grete deciden volver a entrar a la habitación, observan a Gregorio y la madre se desmaya; Grete sale de esta a buscar algo para despertarla y Gregorio sale tras de ella, preocupado, intentando ayudar también. La hermana vuelve a entrar a la habitación y cierra la puerta, llega el padre, y su hija Grete le comenta lo que había sucedido. Su padre, pensando en que su hijo llevó a cabo una actitud violenta contra su familia, comienza a arrojarle manzanas para hacerlo retroceder; una le golpea en la espalda y queda incrustada en ella.

Nadie cuida a Gregorio y su herida se infecta. Como Gregorio ya no puede trabajar para ayudar a su familia, la familia alquila una parte de la vivienda a tres personas. Pese a su invalidez, su familia termina por aceptarlo. Pese a ello, una tarde Gregorio sale de su habitación atraído por la música interpretada al violín por su hermana. Por desgracia, los tres inquilinos lo ven y deciden marcharse de inmediato y sin pagar, no por su presencia, ya que este se les hacía curioso, sino por el mal trato que reciben de la familia al intentar que no lo vieran. Enfrentada a una situación sin remedio, su hermana propone entre lágrimas deshacerse de Gregorio. Todos están de acuerdo porque creen que han hecho todo lo que han podido, pero no saben qué hacer. Sin embargo, Gregorio, ya sin alimentarse desde hacía días, es encontrado muerto por la sirvienta y desechado a la basura. Ligeramente apenados, pero sobre todo aliviados, la familia se alegra de poder comenzar una nueva vida y salen para dar un paseo. Los padres se dan cuenta que Grete se ha convertido en una joven agraciada y comienzan a planear cómo casarla.

Desde sus primeras ediciones en español el título "Die Verwandlung" se ha presentado como "La metamorfosis". En los últimos años, desde comienzos del siglo XXI, varias editoriales y traductores han preferido traducir el título como "La transformación".

Esto se debe -según los valedores del nuevo título- a que en alemán la voz "Verwandlung" corresponde a 'cambio', 'transformación', 'conversión', 'reducción', 'mutación', y solo como 'metamorfosis' cuando apunta al lenguaje de la mitología clásica. De hecho, la palabra en alemán para denominar metamorfosis, es "Metamorphose", término que registra claramente su equivalencia y que le haría prescindir de la voz "Verwandlung" para su traslación idiomática. Esto supone además, la existencia de otro sustantivo con valor semántico independiente. Por ello, y además, optar por la palabra metamorfosis podría significar elegir un sustantivo muy concreto y atinente a cierto sector de la literatura, como es en este caso, la griega. De ahí en adelante «pueden cometerse errores hermenéuticos peculiares y sesgados, como valorar la obra por su carácter de 'fantástica transmutación' o 'suceso extraordinario', tan propios de las artes escritas en Grecia, pero impropias en la narrativa kafkiana».

Sin embargo, este argumento no convence a todos los lectores y traductores y una gran parte sigue prefiriendo mantener en español el título "La metamorfosis". Para los partidarios de conservar este título, las razones son diversas. Entre ellas pueden citarse las siguientes. La palabra metamorfosis es de uso común entre los hablantes; el DRAE la recoge con el significado, en su primera acepción, de "transformación de algo en otra cosa"; de hecho, ya se encuentra utilizada de esta manera en los clásicos de la lengua, incluido Cervantes. En todo caso, la palabra tal vez tiene el matiz para el hablante culto de "cambio completo, radical y definitivo" (que el DRAE no recoge). Muchos lectores no creen que la palabra metamorfosis en el título tenga connotaciones distorsionadoras de la biología, la mitología ni de la literatura romana; y otros perciben una referencia a la tradición literaria de "Las Metamorfosis" de Ovidio, pero la consideran incluso positiva o enriquecedora. Entienden que los primeros traductores del libro al español actuaron en base a estos criterios y que no es necesario ni conveniente enmendar su trabajo. Como argumento secundario, se puede aducir que esas traducciones iniciales han dejado una influencia profunda, porque eran acertadas, y hoy el libro de Kafka se identifica con el título "La metamorfosis", que está plenamente consolidado; el modificarlo produce una confusión innecesaria. Por otra parte, la propuesta de corregir el título solo afecta a algunos editores de la península ibérica (y no a todos); en la América hispanohablante no se ha visto la misma necesidad.


 en español
 (en alemán)


</doc>
<doc id="41221" url="https://es.wikipedia.org/wiki?curid=41221" title="Lenguas bantúes">
Lenguas bantúes

Las lenguas bantúes son un conjunto de lenguas habladas en África que constituyen una subfamilia de lenguas Níger-Congo. Las lenguas bantúes son habladas en el sur de Camerún, Gabón, República del Congo, República Democrática del Congo, Uganda, Kenia, Tanzania, Angola, Zambia, Malaui, Mozambique, Zimbabue, Namibia, Botsuana y Sudáfrica.

La palabra "bantú" fue usada en primer lugar por Wilhelm H. I. Bleek (1827-75) con el significado de "personas" ("*ba-ntu" es una forma de plural, el singular sería "*mu-ntu") como se refleja en muchos de los idiomas de este grupo (véase la tabla 1). A él se debe también la primera clasificación del grupo de lenguas siguiendo criterios científicos llevada a cabo entre 1862 y 1869. Él y más tarde Carl Meinhof hicieron estudios comparativos de las gramáticas de las lenguas bantúes.

La lengua bantú con mayor número de hablantes es el suajili (G 40). Los idiomas bantúes comprenden un abanico que abarca desde lenguas puramente tonales hasta las que prescinden totalmente del tono con funciones gramaticales y o semánticas.

Otros idiomas bantúes importantes son el lingala, el luganda, el kikongo (o kongo) y el chewa en África central y oriental y el shona, el ndebele (a menudo considerado una lengua aunque en realidad es un dialecto del zulú), el setsuana, el sesotho, el xhosa, el sepedi y el suazi en el sur de África.

Algunas de las lenguas son conocidas sin el prefijo de clase (chewa por chichewa, swahili en vez de kiswahili, zulú por isizulu, xhosa en lugar de isixhosa, etc.) mientras otras varían (setswana o tswana, sindebele o ndebele, etc.). Sin embargo, la forma radical sin el marcador normalmente no se da en estas lenguas: en Botsuana, por ejemplo, los habitantes son "batswana", una persona es un "motswana" y la lengua es "setswana".

Esta familia de lenguas tiene cientos de miembros. Fueron clasificadas por Guthrie en 1948 en grupos de acuerdo a zonas geográficas - A, B, C, D, E, F, G, H, J, K, L, M, N, P, R y S y después numeradas dentro del grupo. (Lista de nombres de lenguas bantúes con sinónimos ordenados por el número de Guthrie). Guthrie también reconstruyó el "Proto-bantú" como la proto-lengua de esta familia lingüística. Todo parece apuntar a que las lenguas bantúes tuvieron su origen hace 3.000 años en Nigeria oriental y Camerún, desde donde tuvieron una gran expansión hace 2.000 años hacia el sur y el este del continente africano. Los principales grupos según Guthrie (1948) son los siguientes (lenguas principales van en cursiva):


La clasificación de Guthrie sirvió para clasificaciones posteriores, que consistieron en reasignaciones de subgrupos y división de grupos, con el fin de asegurar que todos los subgrupos sean grupos filogenéticos válidos.

Las lenguas bantúes han sido extensivamente estudiadas desde el punto de vista fonológico y fonético y se conoce muy bien la fonología histórica de la familia. El proto-bantú ha sido reconstruido y existe un gran consenso entre los bantuistas en cuanto a las características básicas. A pesar de la enorme variedad que presentan las lenguas bantúes, el sistema fonológico del proto-bantú resulta sorprendentemente simple. El inventario consonántico reconstruido carece de aproximantes y viene dado por:
Las obstruyentes sordas parecen haber sido oclusivas, mientras que los sonidos designadas como podrían ser oclusivas o como sucede en muchos de sus modernos descendientes continuantes . Las "palatales" designadas como podrían haber sido genuinas oclusivas palatales o posiblemente africadas postalveolares (de hecho muchas lenguas bantúes presentan las evoluciones /*c/ > /s/ y /*ɟ/ > /z/ lo cual refuerza su interpretación como africadas.) Este sistema consonántico del proto-bantú da cuenta adecuadamente de los desarrollos históricos posteriores del bantú central y la aparición de innovaciones fonéticas compartidas es lo que permite establecer con seguridad las agrupaciones internas. Para algunos autores el sistema anterior reconstruido por Greenberg, Guthrie y Meeusen es sólo ancestral al bantú de la sabana o bantú central. Según Stewart (2002) el bantú noreste y el bantú central serían dos ramas derivadas de un proto-bantú ancestral con un sistema más complicado:
Según Stewart se habría producido una converegencia de la segunda y tercera series > y > . Por otra parte la última serie sería el origen de las nasales > .

El sistema vocálico parece claro que estaba formado por siete elementos agrupables en tres niveles de abertura distintivos que algunos autores reconstruyen como y otros como .

Las posibles estructuras silábicas en proto-bantú eran:

Donde C: cualquier consonante, V: cualquier vocal, VV: vocal larga, N: consonante nasal.

Las lenguas bantúes son lenguas aglutinantes. La característica morfológica más prominente de los idiomas bantúes es el uso extensivo de prefijos e infijos. Cada nombre pertenece a una clase y cada lengua puede tener alrededor de diez clases en conjunto, algo similar al género en las lenguas europeas. La clase se indica por un prefijo en el nombre, así como en los adjetivos y verbos que concuerdan con él. El plural se indica por un cambio de prefijo (véase la tabla 1).

El verbo se conjuga a base de prefijos. En suajili, por ejemplo:
"Mtoto", 'niño', gobierna al prefijo adjetival "m-" de "mdogo", 'pequeño', y el prefijo del sujeto verbal "a-". A continuación le sigue el tiempo en pretérito perfecto "-me-" y el marcador del objeto "-ki-" que concierta con el implícito vocablo "kitabu", 'libro'. Si pluralizamos el sujeto ('niños'), obtenemos:
y al pluralizar el objeto directo ('libros', "vitabu") la frase resultante es

La estructura típica de una forma verbal en muchas lenguas bantúes es:

Donde
Ejemplos:

La mayoría de las lenguas de este grupo forman la frase según el esquema básico de SVO (sujeto - verbo - objeto). Igualmente usan preposiciones y tipológicamente son lenguas de núcleo inicial.

Los numerales reconstruidos para diferentes grupos de lenguas bantúes son:

Los sudafricanos de raza negra a veces eran denominados oficialmente "bantúes" por el régimen del apartheid, de modo que ahora allí se prefiere el término "sintu" para referirse a este grupo de lenguas; "si-" es un prefijo usado, entre otros conceptos, para el nombre de muchas lenguas bantúes meridionales (derivado del proto-bantú "*ci-")




</doc>
<doc id="41223" url="https://es.wikipedia.org/wiki?curid=41223" title="Reloj atómico">
Reloj atómico

Un reloj atómico es un tipo de reloj que para alimentar su contador utiliza una frecuencia de resonancia atómica normal. Los primeros relojes atómicos tomaban su referencia de un máser. Las mejores referencias atómicas de frecuencia (o relojes) modernas se basan en físicas más avanzadas, que involucran átomos fríos y fuentes atómicas. Las agencias de normas nacionales mantienen una exactitud de 10 segundos por día y una precisión igual a la frecuencia del transmisor de la radio que bombea el máser.

Los relojes atómicos mantienen una escala de tiempo continua y estable, el Tiempo Atómico Internacional (TAI). Para uso cotidiano se difunde otra escala cronológica: el Tiempo Universal Coordinado (UTC). El UTC deriva del TAI, pero se sincroniza usando segundos de intercalación con el Tiempo Universal (UT1), el cual se basa en la transición día–noche según las observaciones astronómicas. 

El primero se construyó en el Willard Frank Libby, de los EE. UU., en 1949, basándose en ideas acerca de un fenómeno extremadamente regular: la resonancia magnética molecular y atómica, de Isidor Isaac Rabi, , aunque la precisión conseguida mediante amoníaco —molécula utilizada por el prototipo del "National Institute of Standards and Technology" (NIST)— no era muy superior a los estándares de la época, basados en osciladores de cuarzo.

Hoy los mejores patrones de frecuencia atómicos se basan en las propiedades físicas de las fuentes de emisión de cesio. El primer reloj atómico de cesio se construyó en 1955, en el National Physical Laboratory (NPL), en Inglaterra. Sus creadores fueron Louis Essen y John V.L Parry.

En el año 1967 los relojes atómicos basados en cesio habían conseguido fiabilidad suficiente como para que la Oficina Internacional de Pesas y Medidas eligiera la frecuencia de vibración atómica de los dispositivos creados y perfeccionados por Essen como nuevo patrón base para la definición de la unidad de tiempo físico. Según este patrón, un segundo se corresponde con 9 192 631 770 ciclos de la radiación asociada a la transición hiperfina desde el estado de reposo del isótopo de cesio 133: (Cs).

La precisión alcanzada con este tipo de reloj atómico es tan elevada que admite únicamente un error de un segundo en 30 000 000 años. El reloj más preciso del mundo se diseña en el Observatorio de París, donde los actuales relojes atómicos tardarían 52 millones de años para desfasarse un segundo. El nuevo objetivo de la investigación francesa es aumentar ese plazo a 32 mil millones de años. El estándar actual de los relojes atómicos en activo permite el atraso de un segundo cada 3700 millones de años (NIST).

Lord Kelvin sugirió por primera vez en 1879 la idea de utilizar la vibración atómica para medir el tiempo. 
El método práctico para realizarlo se convirtió en la resonancia magnética, desarrollada en el decenio de 1930 por Isidor Isaac Rabi. El primer reloj atómico fue un dispositivo de máser de amoníaco construido en 1949 en la Oficina Nacional de Normas de EE. UU. NBS, ahora NIST). Era menos exacto que los relojes de cuarzo existentes, pero sirvió para demostrar el concepto. El primer reloj atómico exacto fue un estándar de cesio sobre la base de una cierta transición del átomo de Cs, construido por Louis Essen en 1955 en el Laboratorio Nacional de Física (Reino Unido). La calibración del reloj atómico estándar de cesio se efectuó mediante la escala cronológica astronómica tiempo de efemérides (TE).

Esto condujo a la más reciente definición de "segundo" acordada internacionalmente, por el Sistema Internacional de Unidades (SI), basada en tiempo atómico. Se ha verificado que la igualdad del segundo ET con la del segundo SI (reloj atómico) es de una precisión de 1 parte en 10. El segundo SI hereda así el efecto de las decisiones de los diseñadores originales de la escala cronológica ET: tiempo de efemérides, la determinación de la duración del segundo ET.

Mayo de 2009. El reloj atómico óptico de estroncio JILA (siglas de "Joint Institute for Laboratory Astrophysics)" es ahora el reloj más exacto del mundo sobre la base de átomos neutros. Un luminoso láser azul en los átomos de estroncio ultrafríos en una trampa óptica que prueba sobre la eficacia de una explosión previa de luz de un láser de color rojo ha impulsado los átomos a un estado excitado. Solamente los átomos que permanecen en el estado de menor energía responden al láser azul y provocan la fluorescencia que se expresa aquí. Fotografía: Sebastián Blatt, JILA, Universidad de Colorado.

Desde el comienzo del desarrollo en el decenio de 1950, los relojes atómicos se han hecho sobre la base hiperfina (microondas) de las transiciones en H (hidrógeno 1), Cs y Rb (rubidio 87). El primer reloj atómico comercial fue el "Atomichron" fabricado por la "National Company". Se vendieron más de 50, entre 1956 y 1960. A esta máquina, voluminosa y cara, posteriormente la substituyeron dispositivos mucho más pequeños, de montaje en "rack," como el modelo 5060 de Hewlett-Packard estándar, de frecuencia de cesio, lanzado en 1964 [1]. 

A finales del decenio de 1990, cuatro factores han contribuido a importantes avances en este tipo de relojes:

En agosto de 2004, científicos del NIST demostraron un reloj atómico de chips. Según los investigadores, el tamaño del reloj sería de la centésima parte de cualquiera otro. También se proclamó que requería solo 75 milivatios (mW), lo que es idóneo para aplicaciones sustentadas en energía a base de pilas. Esta tecnología está disponible comercialmente desde 2011 (SA.45s CSAC Chip Scale Atomic Clock. 2011. 24 de mayo de 2012). 

En marzo de 2008, físicos del NIST demostraron un reloj basado en lógica cuántica sobre mercurio y sobre iones individuales de aluminio. Estos dos relojes son las más exactos que se han construido hasta la fecha. No se atrasan, ni se adelantan, a una velocidad que exceda en más de un segundo en mil millones de años.

A pesar de ello, los físicos continúan experimentando nuevas variaciones con másers, de: a) hidrógeno (Townes); b) bombeo óptico de rubidio (Kasler); c) los recientemente propuestos de mercurio, que permitirían alcanzar mayor precisión. También se mejora constantemente la precisión en los de cesio con láseres para enfriar los átomos, y la obtenida en el último reloj del NIST, el NIST-F1, puesto en marcha en 1999, que es del orden de un segundo en veinte millones de años.

En agosto de 2004, científicos del NIST hicieron la primera demostración de un reloj atómico del tamaño de un circuito integrado. Esto representa un reloj cien veces menor que cualquier otro construido hasta la fecha, cuyo consumo es de solo 0,079 vatios.

El reloj mecánico depende de un péndulo para funcionar. El atómico trabaja mediante la frecuencia de las transiciones energéticas hiperfinas (en los rangos de microondas) en los átomos.

En un extremo del reloj de cesio hay un horno con una placa de cesio, del cual se evaporan iones de este metal. Los iones se presentan en dos estados dependientes del espín o giro (spin) del último electrón del cesio. La diferencia de energía entre estos dos estados corresponde a una frecuencia de 9 192 631 770 hercios (Hz). En cada estado las propiedades magnéticas de los iones son diferentes. Tras la evaporación se utiliza un imán para separar los iones y descartar los de mayor energía. Los iones de menor energía se reubican en una cámara.

El verdadero reloj es un oscilador electrónico que genera pulsos de una frecuencia ajustable. Se ajusta a la correspondiente a la transición hiperfina del cesio por el proceso de realimentación siguiente. Un radioemisor de microondas llena de manera uniforme la cavidad de la cámara con ondas radioeléctricas de la frecuencia del oscilador electrónico. Cuando la frecuencia de la onda radiada se acopla con la frecuencia de la transición hiperfina del cesio, los iones de cesio absorben la radiación y emiten luz. Una celda fotoeléctrica es sensible a la luz emitida y está conectada al oscilador electrónico con instrumentación electrónica. 

Para realizar la medición mediante estas partículas es necesario crear un campo electromagnético que no existe naturalmente en el Universo. El proceso se realiza dentro de una «trampa magneto-óptica»: esfera del tamaño de un melón, en la cual se inyectan átomos de cesio que, confinados en un campo magnético, propagan seis rayos de luz láser. De igual modo que una persona disminuye su paso ante una ráfaga de viento, los átomos reducen su velocidad al ser bombardeados por los láseres emitidos en todas direcciones. Mediante este método los átomos pueden reducir su velocidad hasta hacerla 10 mil veces más lenta de lo normal. Cuando los átomos y los láseres chocan, se forma una nube de átomos muy lentos o ultrafríos.

Los usos más frecuentes de los relojes atómicos son:


La mayoría de las investigaciones se centran en los objetivos, a menudo contradictorios, de que los relojes sean más pequeños, más baratos, más precisos y más confiables.

Las nuevas tecnologías, tales como peines de frecuencia de femtosegundo, redes ópticas e información cuántica, han permitido crear prototipos de la próxima generación de relojes atómicos. Estos se basan en la óptica, en vez de en transiciones de microondas. Un obstáculo importante para el desarrollo de un reloj óptico es la dificultad de medir directamente las frecuencias ópticas. Este problema se ha resuelto mediante el desarrollo de la autorreferencia en modo bloqueado de láseres, comúnmente conocida como peines de frecuencia de femtosegundo.

Antes de la demostración del peine de frecuencias en el año 2000, eran necesarias técnicas de terahercio para salvar la distancia entre frecuencias de radio y ópticas. Los sistemas respectivos eran engorrosos y complicados. En virtud del perfeccionamiento del peine de frecuencias, estas mediciones se han vuelto mucho más accesibles, y en todo el mundo se están desarrollando numerosos sistemas de relojes ópticos. 

Tal como en el rango de la radio, la espectroscopia de absorción se utiliza para estabilizar un oscilador (en este caso un láser). Cuando la frecuencia óptica se divide hacia abajo en una frecuencia de radio contable usando un peine de femtosegundos, la anchura de banda de la fase de ruido se divide también entre ese factor. Aunque generalmente tal anchura de banda de la fase de ruido del láser es mayor que las fuentes de microondas estables, después de la división es menor. 

Los dos sistemas primarios en estudio para uso en los patrones de frecuencia óptica son iones aislados en una trampa de iones y átomos neutros atrapados en una red óptica. Estas dos técnicas permiten que en gran medida los átomos o iones se aíslen de perturbaciones externas, lo cual genera una referencia de frecuencia extremadamente estable.



Un radiorreloj es un reloj que automáticamente se ajusta a la hora atómica por medio de señales de radio oficiales recibidas por un receptor de radio. Muchos minoristas venden radiorrelojes erróneamente como «relojes atómicos». Aunque las señales de radio que reciben provienen de relojes atómicos, éstos no son relojes atómicos propiamente dichos. Proporcionan un medio de obtener la hora de alta precisión procedente de un reloj atómico, en una amplia zona, con un equipo barato.

Si bien las emisiones oficiales de la hora son en sí mismas extremadamente precisas, muchos radiorrelojes de consumo se sincronizan solo una vez al día, por lo cual solo consiguen una precisión de aproximadamente un segundo. Para obtener ventajas de la exactitud total de las señales horarias recibidas, deben utilizarse instrumentos receptores con capacidad de graduación de la hora. Por cada 300 kilómetros (186 millas) de distancia entre el transmisor y el receptor hay un retraso en la señal de aproximadamente 1 ms (un milisegundo).

Las señales horarias generadas en los relojes atómicos se difunden por transmisores de onda larga de radio gestionados por los gobiernos de muchos países, alrededor del mundo, como DCF77 (Alemania), HBG (Suiza), JJY (Japón), MSF (Reino Unido), TDF (Francia) y WWVB (Estados Unidos). Estas señales se pueden recibir desde muy lejos fuera de su país de origen. A veces, por la noche, la señal JJY se puede captar incluso en Australia Occidental y Tasmania. Así, hay muy pocas regiones del mundo donde la hora precisa procedente de relojes atómicos no esté disponible.

Los relojes atómicos se utilizan para generar las frecuencias estándar. Se instalan en los sitios de señales de tiempo, LORAN-C, y transmisores de navegación Alfa. También se han instalado en algunas estaciones de radiodifusión de ondas larga y media, para entregar frecuencias de transmisión muy precisas, que también pueden funcionar como frecuencias estándar. 

Además los relojes atómicos se utilizan en interferometría de línea de base larga en radioastronomía.

Los relojes atómicos constituyen la base del sistema de navegación GPS. La hora del reloj maestro GPS es una media ponderada de los relojes atómicos ubicados en las estaciones terrestres y de los colocados en los satélites GPS. Cada uno de ellos está dotado de varios relojes atómicos.

Físicos del "National Institute of Standards and Technology" (NIST) han construido una versión mejorada de reloj atómico experimental basado en un único átomo de aluminio. A febrero de 2009 es el reloj más preciso, ya que en 3.700 millones de años no gana, ni pierde, siquiera un segundo (el reloj atómico de fuente de cesio pierde un segundo cada 100 millones de años).

Como la definición internacional de segundo (Sistema Internacional de Unidades) está basada en el átomo de cesio, este elemento permanece como regulador del transcurso del tiempo oficial. Por lo tanto ningún otro reloj puede ser más preciso que el de cesio.

El sistema GPS proporciona señales muy exactas de hora y frecuencia. Un receptor GPS funciona midiendo el tiempo de retraso relativo de las señales de cuatro o más satélites GPS, cada uno con tres o cuatro relojes atómicos de cesio o de rubidio a bordo. Los cuatro tiempos relativos se transforman matemáticamente en tres coordenadas de distancia absoluta y en una coordenada de tiempo absoluto.

La precisión de la hora es de alrededor de 50 nanosegundos (ns). Sin embargo, receptores GPS poco costosos probablemente no asignen alta prioridad a la actualización de la pantalla. Por ello la hora mostrada puede diferir notablemente de la hora interna. Las referencias a la precisión de la hora que utilizan los GPS se comercializan para uso en redes informáticas, laboratorios y redes de comunicaciones celulares. Mantienen la exactitud dentro del margen de alrededor de 50 ns.


, sl<kcji, fjihj lnouhjb eygduxwhduwhih jha kjawkdwnkjsiwcjh evuh 0uedur4rjbkjb k khhh diesic



</doc>
<doc id="41225" url="https://es.wikipedia.org/wiki?curid=41225" title="Reloj de péndulo">
Reloj de péndulo

Los relojes de péndulo se caracterizan por utilizar un peso oscilante para medir el tiempo. La ventaja del péndulo para medir el tiempo con exactitud es que se trata de un oscilador armónico: sus ciclos de balanceo se producen en intervalos de tiempo iguales, dependiendo únicamente de su longitud (descontando los efectos de la resistencia al movimiento). Desde su invención en 1656 por Christiaan Huygens hasta la década de 1930, el reloj de péndulo fue el sistema de cronometraje disponible más preciso, por lo que su uso se hizo generalizado. A lo largo de los siglos XVIII y XIX, los relojes de péndulo, omnipresentes en hogares, fábricas, oficinas y estaciones de ferrocarril, sirvieron como referencia principal para la programación de la vida diaria, los turnos de trabajo, y el transporte público. Su precisión permitió adoptar el ritmo de vida más rápido propio de la Revolución Industrial.

Los relojes de péndulo deben permanecer en una posición fija para operar correctamente; cualquier desplazamiento o aceleración afectan al movimiento del péndulo, provocando imprecisiones en su funcionamiento, por lo que no se pueden utilizar como relojes portátiles. Desde la generalización de los relojes de cuarzo, los relojes de péndulo se mantienen en su mayoría por su valor decorativo y como antigüedades.

El reloj de péndulo fue inventado en 1656 por el científico holandés Christiaan Huygens, siendo patentado al año siguiente. Huygens encargó la construcción de sus diseños al relojero Salomon Coster, y se inspiró en las investigaciones de los péndulos iniciadas por Galileo Galilei alrededor de 1602. Galileo descubrió la propiedad clave que hace de los péndulos útiles para el cronometraje: el isocronismo, lo que significa que su periodo de oscilación solo depende de su longitud. Galileo tuvo la idea del reloj de péndulo en 1637. Su hijo inició su construcción en 1649, pero nunca lo terminó. La introducción del péndulo, el primer oscilador armónico descubierto, incrementó enormemente la precisión de los relojes, que pasó de unos 15 minutos diarios a unos 15 segundos diarios, propiciando con su rápida aceptación que los antiguos relojes del tipo 'foliot' se adaptasen para añadir un péndulo a sus primitivos mecanismos.

Estos antiguos relojes adaptados, debido al tipo de sus escapes, tuvieron péndulos con oscilaciones de hasta 100° de amplitud. En su análisis de 1673 de los péndulos, "Horologium Oscillatorium", Huygens demostró que las grandes oscilaciones hacían el péndulo inexacto, provocando irregularidades en su frecuencia, y por lo tanto en la velocidad del reloj. Llegó a la conclusión de que "solo péndulos con pequeñas oscilaciones de unos pocos grados son isócronos", lo que motivó la invención del escape de áncora alrededor de 1670, permitiendo reducir la oscilación del péndulo a valores comprendidos entre 4° y 6°. El áncora se convirtió en el escape estándar utilizado en los relojes de péndulo. Además de una mayor precisión, el reducido movimiento pendular requerido por el sistema de áncora obligó a adoptar péndulos más largos, que necesitan menos energía y que causaban menos desgaste en el movimiento. El péndulo de segundos (también llamado 'péndulo Real'), de 0.994 m de largo, en el que cada oscilación dura un segundo, llegó a ser ampliamente utilizado en los relojes de calidad. Los primeros relojes con sus características cajas largas y estrechas alrededor de estos péndulos, fueron construidos hacia 1680 por William Clement, se hicieron famosos, y eran conocidos como "longcase clock" o "reloj del abuelo". La mayor precisión resultante de estos avances provocó la aparición de la aguja de los minutos (previamente muy rara), que se añade a las esferas de reloj hacia 1690.

La ola de innovaciones relojeras en los siglos XVIII y XIX que siguió a la invención del péndulo trajo muchas mejoras en este tipo de relojes, como el escape sin retroceso inventado en 1675 por Richard Towneley y popularizado por George Graham alrededor de 1715 en sus relojes de precisión, con el nuevo sistema "regulador" que sustituyó gradualmente al escape de áncora y que se utiliza en la mayoría de los relojes de péndulo modernos. La observación de que los relojes de péndulo atrasaban en verano hizo ver que la dilatación y la contracción de la barra del péndulo con los cambios de temperatura era una fuente de error apreciable. Esto se resolvió mediante la invención de los péndulos con compensación de temperatura: el "péndulo de mercurio" de George Graham en 1721; y el "péndulo de parrilla" de John Harrison en 1726. Con estas mejoras, los relojes de péndulo de precisión de mediados del siglo XVIII alcanzaron precisiones de unos pocos segundos por semana.

Hasta el siglo XIX, los relojes se construían a mano por artesanos individuales y eran muy caros. La rica ornamentación de los relojes de péndulo de este período indica su valor como símbolos de estatus de las clases sociales altas. En Europa, los relojeros de cada país y región desarrollaron sus propios estilos distintivos. En el siglo XIX, la creación de fábricas de relojería hizo que los relojes de péndulo fueran gradualmente asequibles por las familias de clase media.

Durante la Revolución Industrial, la vida cotidiana de los hogares se organiza en torno al reloj de péndulo. Relojes de péndulo más exactos, llamados "reguladores", fueron instalados en centros de negocios y se utilizaban para programar el trabajo y establecer la hora de otros relojes. Los más precisos, conocidos como "reguladores astronómicos", fueron utilizados en los observatorios de astronomía, en topografía, y en la navegación astronómica. A principios del siglo XIX, los reguladores astronómicos de los observatorios navales sirven como estándares primarios para fijar la hora de cada país. Desde 1909, el "US National Bureau of Standards" (posteriormente denominado NIST) fija el estándar de tiempo en los Estados Unidos mediante relojes de péndulo dotados de escape Riefler, con precisiones cercanas a los 10 milisegundos por día. En 1929 se pasó a los relojes de péndulo libre del tipo Shortt-Synchronome, poco antes de la introducción gradual del reloj de cuarzo, que se impuso como estándar en la década de 1930.
Los relojes de péndulo han sido el estándar mundial para el cronometraje de precisión durante 270 años, hasta la invención del reloj de cuarzo en 1927, y fueron utilizados como estándares de tiempo a lo largo de la Primera Guerra Mundial. El Servicio de hora francesa usó relojes de péndulo como parte de su conjunto de relojes estándar hasta 1954. El reloj de péndulo empezó a ser reemplazado en los hogares durante los años 1930 y 1940 por el reloj eléctrico, que proporcionaba la hora con mayor exactitud porque estaba sincronizado con la oscilación de la red eléctrica. El reloj de péndulo más preciso hasta el año (2007), era el reloj experimental Littlemore, construido por Edward T. Hall en la década de 1990

Todos los relojes de péndulo mecánicos tienen al menos estas cinco partes:


En relojería, las funciones adicionales en los relojes (distintas de señalar la hora normal) se llaman "complicaciones". Relojes de péndulo más elaborados pueden incluir las complicaciones siguientes:

También existen "relojes de péndulo electromecánicos", que se utilizan en cronógrafos maestros mecánicos. La fuente de energía es un solenoide eléctrico que proporciona impulsos al péndulo mediante fuerza magnética. El escape se sustituye por un conmutador o un fotodetector que determina cuando el péndulo está en la posición correcta para recibir el impulso. No deben confundirse con los más recientes relojes de péndulo de cuarzo, en los que un módulo electrónico (reloj de cuarzo) hace oscilar un péndulo. Estos dispositivos no son verdaderos relojes de péndulo porque la indicación de la hora está controlada por un módulo de cristal de cuarzo, y el péndulo oscilante es meramente una simulación decorativa.

El péndulo oscila con un período que varía con la raíz cuadrada de su longitud efectiva. Con oscilaciones pequeñas, el período "(T)" es corto (del orden de segundos). Entonces, para el tiempo de un ciclo completo (dos oscilaciones de sentido contrario), se tiene que:
donde "L" es la longitud del péndulo en metros y "g" es la aceleración de la gravedad local expresada en metros por segundo al cuadrado. Todos los relojes de péndulo tienen un sistema para ajustar el péndulo a las condiciones de la gravedad local. Suele ser una tuerca de ajuste situada bajo el péndulo, que mueve la masa del péndulo hacia arriba o hacia abajo sobre un vástago roscado. Si se desplaza hacia arriba, se reduce la longitud efectiva del péndulo, se acorta el periodo de oscilación y el reloj va más deprisa. En algunos relojes de péndulo, el ajuste fino se realiza con un sistema auxiliar, que puede ser un pequeño peso que se mueve hacia arriba o hacia abajo sobre la barra de péndulo. En algunos relojes principales y relojes de torre, el ajuste se realiza mediante una pequeña bandeja montada en la varilla, donde se colocan o retiran pesos pequeños para cambiar la longitud efectiva, por lo que la tasa se puede ajustar sin detener el reloj.

Si la amplitud de la oscilación de un péndulo es considerable, su movimiento se hace más irregular, y su período fluctúa. En cambio, cuando se limita a pequeñas oscilaciones de unos pocos grados, el péndulo es prácticamente "isócrono"; es decir, su período es independiente de los cambios en la amplitud del movimiento. Por lo tanto, la oscilación del péndulo en los relojes se limita a valores comprendidos entre 2° y 4°.

Una fuente de error en estos relojes es que la varilla del péndulo varía de longitud ligeramente con los cambios de temperatura. Un aumento de la temperatura hace que la varilla se expanda, haciendo el péndulo más largo, por lo que su período se incrementa y el reloj tenderá a atrasar. La madera expande mucho menos que los metales, por lo que muchos relojes de gran calidad tenían las varillas de sus péndulos de madera. Para compensar este efecto, los primeros relojes de alta precisión usaban " péndulos de mercurio ", inventados por George Graham en 1721. Estos relojes tenían la pesa del péndulo consistente en un recipiente lleno de mercurio. Un aumento en la temperatura hace que la varilla del péndulo se expanda, pero el mercurio del recipiente también se expandiría, y su nivel se elevaría ligeramente en el recipiente, manteniendo el centro de gravedad del péndulo a la misma altura.

El péndulo con compensación de temperatura más utilizado fue el "péndulo de parrilla", inventado por John Harrison en 1726. Este sistema consiste en una "red" de barras paralelas de un metal de alta expansión térmica (como zinc o bronce) y otra de barras de un metal de baja dilatación térmica (como acero), que se montan en un marco en sentidos contrarios. Se construía de manera que las varillas de alta expansión compensaban el cambio de longitud de las barras de baja expansión, lográndose un cambio de longitud cero con las variaciones de temperatura. Este tipo de péndulo se hizo todo un símbolo de calidad, por lo que es frecuente ver relojes con péndulos de parrilla "falsos" (que no tienen una función real de compensación de la temperatura) por motivos simplemente decorativos.

Algunos de los relojes científicos de alta precisión, construidos alrededor de 1900, tenían elementos de "alta tecnología" en su época, utilizando materiales de baja expansión como la aleación de acero y níquel (invar) o el sílice fundido.

La viscosidad del aire a través del cual el péndulo oscila, varía con la presión atmosférica, con la humedad y con la temperatura. Este arrastre también requiere energía que de otro modo podría ser aplicada a extender el tiempo de marcha cada vez que se le da cuerda al reloj. Tradicionalmente, el péndulo se hace con una forma lenticular estrecha, optimizada para reducir la resistencia del aire, que es donde se pierde la mayor parte de la potencia de accionamiento en un reloj de calidad. A finales del siglo XIX y principios del siglo XX, los péndulos de los relojes maestros de precisión utilizados en observatorios astronómicos, a menudo se situaban en una cámara a baja presión de la que se había bombeado el aire, reducendo así la resistencia y haciendo el funcionamiento del péndulo aún más preciso.

Para mantener la hora con precisión, los relojes de péndulo deben estar perfectamente nivelados. Si no lo están, el péndulo oscila más a un lado que al otro, alterando el funcionamiento simétrico del escape. Esta condición a menudo se puede apreciar de forma audible en el sonido "tic-tac" del reloj. Los "latidos" deben estar situados en intervalos uniformemente espaciados, con la precisión necesaria para producir un sonido de "tic ... tac ... tic ... tac"; si no lo están, y tienen el sonido "tic-tac ... tic-tac ...", el reloj está "fuera de ritmo" y debe ser nivelado. Este problema puede causar fácilmente que el reloj deje de funcionar, y es una de las causas más comunes de avería. Con el uso de un nivel de burbuja o de una máquina de sincronización, se puede lograr un ajuste más preciso que confiando en el sonido de los "latidos". Los relojes de precisión a menudo tienen incorporado un nivel de burbuja para esta tarea. Algunos modelos tienen pies con tornillos ajustables para facilitar su nivelación; los más modernos tienen un ajuste de nivelación automático como parte del movimiento. Incluso determinados tipos de relojes de péndulo modernos tienen dispositivos de sincronización de ritmo autorregulados, y este ajuste no es necesario.

Dado que el peso del péndulo se incrementará con el aumento de la gravedad, y la gravedad local varía con la latitud y la elevación de la Tierra, los relojes de péndulo deben reajustarse para mantener la hora correcta cuando se trasladan de un lugar a otro. Por ejemplo, un reloj de péndulo que se mueva desde el nivel del mar hasta una altitud de , perderá unos 16 segundos diarios por este motivo. Incluso mover un reloj a la parte superior de un edificio alto hará que se retrase en una cantidad de tiempo apreciable debido a una gravedad menor.

También llamado péndulo de resorte de torsión, se trata de una masa de simetría circular (frecuentemente, cuatro esferas sobre unos brazos radiales) suspendida de un alambre de acero para muelles dispuesto verticalmente. Es utilizado como mecanismo de regulación en relojes de péndulo de torsión. La rotación del péndulo retuerce el resorte de suspensión en ambos sentidos alternativamente, aprovechando el impulso de la energía aplicada a la parte superior del alambre. Como el período de un ciclo es bastante lento en comparación con la velocidad de oscilación de un péndulo normal, es posible hacer que estos relojes solo necesitan que se les dé cuerda solo una vez cada 30 días, o incluso solo una vez al año o más. Los modelos con un año de autonomía de funcionamiento a veces se llaman ""reloj de 400 días"", ""reloj perpetuo"" o ""reloj de aniversario"", este último a veces se regala para conmemorar aniversarios de boda. Empresas como Schatz y Kundo, ambos alemanas, fueron los principales fabricantes de este tipo de relojes. El funcionamiento de este tipo de péndulo es independiente de la fuerza local de la gravedad, pero es más afectado por los cambios de temperatura que un péndulo oscilante no compensado.

El escape impulsa el péndulo, por lo general mediante un tren de engranajes, y es la parte que produce el "tic-tac" del reloj. La mayoría de los escapes tienen un estado de bloqueo y un estado de movimiento. En el estado de bloqueo, nada se mueve. En la fase de movimiento, el péndulo conduce la posición del escape, mientras que éste empuja al péndulo en algún momento del ciclo de oscilación. Una excepción notable pero rara a este principio es el escape saltamontes de Harrison. En los relojes de precisión, el escape es conducido a menudo directamente por un peso pequeño o un muelle que se vuelve a cargar a intervalos regulares mediante un mecanismo independiente llamado remontoire. Esto libera el escape de los efectos de las variaciones en el tren de engranajes. En el siglo XIX, se desarrollaron escapes electromecánicos. En estos, un interruptor mecánico (o una célula fotoeléctrica) en combinación con un electroimán permiten mantener la oscilación del péndulo. Estos sistemas de escape fueron utilizados en algunos de los relojes más precisos conocidos hasta entonces. En los relojes astronómicos de péndulo se suelen utilizar carcasas en las que se hace el vacío. El pulso de electricidad que acciona el péndulo, también puede controlar un émbolo para mover el tren de engranajes.
En el siglo XX, W.H. Shortt inventó un reloj de péndulo libre con una precisión de una centésima de segundo por día. En este sistema, el péndulo de cronometraje no hace ningún trabajo y se mantiene oscilante mediante el impulso de un brazo lastrado (brazo de gravedad) que se hace descender sobre el péndulo por otro reloj (esclavo) justo antes de que sea necesario. El brazo de gravedad empuja entonces el péndulo libre, evita que quede fuera de rango, y a la vez se sincroniza con el péndulo libre. Una vez que se suelta el brazo de gravedad, se dispara un mecanismo para restablecer el lanzamiento por el reloj esclavo si es necesario. Todo el ciclo se mantiene sincronizado por un pequeño muelle de diafragma situado en el péndulo del reloj esclavo. El reloj esclavo está configurado para ejecutarse con un ligero retardo, y el circuito de reposición del brazo de gravedad activa un brazo pivotante que solo se contacta con la punta del muelle de diafragma. Si el reloj esclavo ha perdido demasiado tiempo, el muelle de diafragma lo empuja contra el brazo y esto acelera el péndulo. La cantidad de esta ganancia es tal que el muelle de diafragma no se involucra en el ciclo inmediato, pero lo hace en el siguiente. Este tipo de reloj se convirtió en el estándar para el uso en los observatorios desde mediados de 1920 hasta que fue reemplazado por la tecnología de cuarzo.

El sistema indicador es casi siempre la tradicional "esfera del reloj" con manecillas de hora y minuto en movimiento. Muchos relojes tienen una pequeña tercera manecilla indicando los segundos en un dial subsidiario. Los relojes de péndulo se diseñan generalmente para ser puestos en hora mediante la apertura de una cubierta de vidrio que protege la esfera, y empujando manualmente la aguja de los minutos alrededor de su eje hasta señalar la hora correcta. El minutero está montado sobre un manguito deslizante de fricción que permite que sea girado sobre su eje. La aguja de las horas no se libera del tren de engranajes. Desde el eje del minutero, está dispuesto un pequeño conjunto de engranajes, que mueven sincronizadamente la aguja de las horas cuando se gira la aguja de los minutos de forma manual.

Los relojes de péndulo son algo más que simples instrumentos utilitarios para medir el tiempo; eran símbolos de clase social que expresaban la riqueza y la cultura de sus dueños. Evolucionaron en varios estilos tradicionales, específicos de cada país y época, y en función del uso que se les iba a dar. Su aspecto exterior en ocasiones refleja el estilo de muebles populares durante el período correspondiente. Los expertos a menudo pueden identificar la fecha de construcción de un reloj antiguo analizando sutiles detalles en cajas y esferas. Estos son algunos de los diferentes tipos de relojes de péndulo:



</doc>
<doc id="41233" url="https://es.wikipedia.org/wiki?curid=41233" title="Las metamorfosis">
Las metamorfosis

Las metamorfosis ("Metamorphoseis", en latín; del griego μεταμόρφωσις, 'transformación'), del poeta romano Ovidio, es un poema en quince libros que narra la historia del mundo desde su creación hasta la deificación de Julio César, combinando con libertad mitología e historia. Fue terminado en el año 8 d. C.

Esta obra literaria es considerada como una obra maestra de la edad de oro de la literatura latina. Una de las obras clásicas más leídas durante la Edad Media y el Renacimiento, "Las metamorfosis" inspiró a múltiples artistas, como Tiziano, Velázquez y Rubens, y continúa ejerciendo una profunda influencia en la cultura occidental.

Es una obra de difícil clasificación, entre la épica y la didáctica. Fue escrita en hexámetros y consta de más de 250 narraciones mitológicas que se suceden en el tiempo desde el origen del mundo hasta la transformación en estrella del alma de Julio César, describiendo los cambios físicos que hacen las distintas divinidades para conseguir fines distintos, griego y romano.

Se considera uno de los trabajos sobre mitología más populares, una joya de la literatura romana, que llegó a ser la obra más conocida por los escritores medievales y por lo tanto tuvo una gran influencia en la poesía medieval.


"Las metamorfosis" fue utilizada por el compositor inglés Benjamin Britten en una obra para oboe solo titulada "Seis metamorfosis de Ovidio", que evoca las imágenes de la obra.

Infinidad de ejemplos en la música barroca utilizaron episodios de "Las metamorfosis" para el argumento de cantatas, serenatas y óperas.

Durante el siglo XX se hicieron diversas adaptaciones de varios de los mitos de "Las metamorfosis" al cine, como puede ser My Fair Lady (película de 1964), protagonizada por Rex Harrison y Audrey Hepburn e inspirada en el mito de Pigmalión, presente en "Las metamorfosis". En el siglo XXI, el productor Pedro Alonso Pablos adaptó a dibujos animados varios de los mitos de "Las metamorfosis" en su mini-serie "Las metamorfosis de Ovidio".










</doc>
<doc id="41243" url="https://es.wikipedia.org/wiki?curid=41243" title="Itinerancia">
Itinerancia

La itinerancia (del inglés roaming) es un concepto utilizado en telecomunicaciones para referirse a la posibilidad de un dispositivo inalámbrico de utilizar una cobertura de red distinta de la principal. Esto le permite conectarse a redes secundarias utilizando su identificador en la red principal.

En telefonía móvil, el término se usa para indicar la posibilidad ofrecida a sus clientes por un operador de usar el servicio en una red móvil distinta de la suya, y normalmente fuera del territorio nacional. Esta identificación se hace a través de la tarjeta SIM, que permite conectar al cliente con su operador de otra red mediante acuerdos entre operadores.

En el caso de redes wifi, significa que el dispositivo wifi del cliente puede desplazarse e ir registrándose en diferentes redes inalámbricas. En este caso la identificación normalmente se hace a través de un usuario y contraseña personal compartido por distintas redes.

En el caso del arte, "itinerancia" hace referencia a las exposiciones temporales que rotan por diferentes instituciones. 

El servicio de itinerancia ha hecho posible que los usuarios de telefonía móvil adquieran una completa libertad de movimiento entre las áreas de cobertura de las diferentes empresas de telecomunicaciones.

Consiste en permitir que un usuario que se encuentre dentro de la zona de cobertura de una red móvil diferente a la que le presta el servicio pueda recibir las llamadas hechas hacia su número de móvil sin necesidad de realizar ningún tipo de procedimiento extra y, en muchos casos, también efectuar llamadas hacia la zona donde se contrató originalmente el servicio, sin necesidad de hacer una marcación especial. Para alcanzar este fin, ambas compañías (la prestadora original del servicio y la propietaria de la red en la que el cliente esté itinerando) deben tener suscrito un acuerdo de itinerancia, en el que definen qué clientes tienen acceso al servicio y cómo se efectuará la conexión entre sus sistemas para encaminar las llamadas.

Aunque el servicio permite una comunicación inmediata y, en muchos casos, sin necesidad de ninguna solicitud adicional, es de notar que habitualmente el costo de transferencia de cada llamada y los costos de interconexión se cargarán al receptor de la llamada, no a la persona que llama (que no tiene por qué saber dónde se encuentra el abonado llamado). Así, el servicio es transparente para el usuario que desea contactar un número que se desplaza a otra zona.

El concepto de itinerancia también se puede aplicar a los terminales móviles liberados, puesto que uno mismo puede reducir los costes de "roaming" tanto para el usuario emisor como para el receptor, usando una tarjeta SIM de alguno de los operadores móviles disponibles en la zona. Esta itinerancia es útil cuando se viaja al extranjero, lo que constituye una de las ventajas del sistema GSM.

En 2013, la Comisión Europea propuso acabar con los costes adicionales por itinerancia dentro de la Unión Europea a partir de diciembre de 2015, medida aprobada por el Parlamento Europeo en 2014. Sin embargo, el Consejo de la Unión Europea propuso su retraso para 2018. Finalmente se llegó a un acuerdo entre en Consejo de la Unión Europea y el Parlamento Europeo estableciéndose la fecha definitiva el 15 de junio de 2017.

Para que sea posible, tiene que haber una pequeña superposición en las coberturas de los puntos de acceso, de tal manera que los usuarios puedan desplazarse por las instalaciones y siempre tengan cobertura. Los puntos de acceso incorporan un algoritmo que decide cuándo una estación debe desconectarse de un punto de acceso y cuándo conectarse a otro.

Esto es muy frecuente en campus de facultades distintas que tienen diferentes puntos de acceso y nombres. Al caminar entre ellas se desconecta de una, pero se conecta a otra red.

Ello permite no sólo la conexión en distintos puntos distantes en los que el cliente tiene servicio, sino también que la llamada (en el caso de GSM) o la conexión (wifi) permanezca activa y no se interrumpa.



</doc>
<doc id="41248" url="https://es.wikipedia.org/wiki?curid=41248" title="Heroína">
Heroína

La heroína, diacetilmorfina o diamorfina en su Denominación Común Internacional, es un opioide con propiedades analgésicas que también se utiliza de forma menos común como supresor de la tos y antidiarreico. Por sus efectos eufóricos, la heroína se utiliza como droga recreativa semisintética. Derivada de la morfina y originada a partir de la adormidera, planta de la que se extrae el opio, su administración frecuente y regular está asociada a la tolerancia y a una fuerte dependencia física. En algunos países se emplea en terapias en usuarios crónicos como sustituto de opiáceos en combinación con labores de asistencia y asesoramiento al paciente.

Administrada por vía intravenosa mediante inyección, la heroína puede ser entre dos y cuatro veces más potente que la morfina y es más rápida en comenzar sus efectos. La heroína ilícita suele presentarse en un polvo blanco mate al que se añaden diversos adulterantes. Una fracción importante de los consumidores de opioides, más de treinta millones de personas al año en todo el mundo según la ONU (2014), consumen heroína, la cual está relacionada con un efecto narcótico pronunciado, se clasifica dentro de las drogas depresoras del sistema nervioso central y se caracteriza por producir una dependencia psicológica y física intensa a un ritmo muy acelerado, siendo considerada una de las drogas más adictivas y dañinas.

La heroína fue sintetizada por primera vez por Charles Romley Alder Wright a finales del siglo XIX, que consiguió aislarla gracias a la acetilación del clorhidrato de morfina, un producto obtenido de la adormidera. «Heroína» fue el nombre comercial que la empresa Bayer puso a la nueva sustancia, que la lanzó al mercado como sustituta de la morfina, creyéndola menos adictiva. A nivel internacional, la heroína está controlada por las Listas I y IV de la Convención Única sobre Estupefacientes y por lo general es ilegal su fabricación, posesión y venta sin licencia. Producida sobre todo en Afganistán y Birmania, está íntimamente unida al tráfico internacional de drogas y ha sido responsable de epidemias severas en varios países de Occidente durante el siglo XX. Afganistán produjo el 95 % del opio del mundo en 2012, y el 66 % en 2015, manteniéndose como el principal productor mundial de opio en las últimas dos décadas. Se ha registrado un aumento significativo de la oferta y la demanda a nivel mundial en los últimos años; en países como Estados Unidos el consumo de heroína se ha multiplicado en la segunda década del siglo XXI hasta convertirse en una verdadera epidemia.

En 1895, la compañía farmacéutica alemana Bayer comercializaba diacetilmorfina como uno más de sus productos bajo receta médica con el nombre comercial de heroína. El nombre fue registrado en junio de 1896 y deriva del alemán la palabra "heroisch" (que quiere decir, heroica), debido a sus efectos «heroicos» (efectos beneficiosos, y de alivio de la tos) y el sufijo medicinal "-in" (-ina) (como en "koffein" / cafeína), con lo que se creó a la vez la connotación muy vendible de la "Femme Héroïne" (Alemania en esa época era muy francófila). Se desarrolló principalmente como un sustituto de la morfina, supresor de la tos «que no crea adicción ni otros efectos secundarios». La morfina en ese momento era una droga recreativa popular, y Bayer deseaba encontrar una similar, pero que no creara tanta adicción. Aunque la publicidad de Bayer la presentaba como un "sustituto no adictivo de la morfina", la heroína pronto generaría una de las mayores tasas de dependencia entre sus usuarios, superando a la morfina.

En 1874, Charles Romley Alder Wright aisló un opiáceo nuevo gracias a la acetilación del clorhidrato de morfina, con lo cual obtuvo diacetilmorfina. El invento de Wright no se popularizó inmediatamente y la diamorfina no comenzaría a ser conocida hasta 23 años después, cuando fue re-sintetizada de forma independiente por otro químico, Felix Hoffmann. Hoffmann trabajaba para la compañía farmacéutica Bayer en Wuppertal (Alemania) y su supervisor, Heinrich Dreser, lo había instado a que acetilase morfina para producir codeína, un constituyente de la adormidera y farmacológicamente similar a la morfina, pero mucho menos potente y adictiva. Sin embargo, el experimento produjo una morfina acetilada entre un 50% y un 100% más potente que la morfina. Aunque los investigadores de Bayer no fueron los primeros en producir heroína, si fueron pioneros en su fabricación industrial y comercialización, que comenzó en 1898 bajo el nombre de «heroína», pocos días después de sacar a la venta la aspirina. Se cree que el nombre de heroína se deriva de la palabra «heroica».

El fármaco fue comercializado entre 1898 y 1910 como un sedante para la tos y como sustituto de la morfina pensando que era menos adictiva. Esto se vio facilitado por el hecho de que se creía que la heroína, producía algo menos de euforia con desviaciones mínimas en el comportamiento y la inteligencia, suponiendo un uso breve. En su 11ª edición de 1910, la Enciclopedia Británica, en su artículo sobre los estados de la morfina afirmaba:

Más tarde se descubrió que la heroína se convierte en gran medida en morfina al ser absorbida en el hígado. En poco tiempo se demostró que la adicción generada por utilizar este compuesto es mucho más intensa en comparación a la de la morfina. Durante muchos años, los médicos no se dieron cuenta de los peligros de usar clínicamente la heroína. Finalmente, se descubrió que algunos pacientes que habían estado usando grandes cantidades de heroína durante mucho tiempo comenzaban a presentar síntomas de adicción. En 1913, Bayer suspendió la producción de heroína y desde 1919, al igual que con la aspirina, Bayer perdió parte de sus derechos de marca sobre la heroína debido al Tratado de Versalles de 1919, consecuencia de la derrota alemana en la Primera Guerra Mundial. En los Estados Unidos se estableció, a través de la Ley de Impuesto sobre la Droga de 1914, un control exhaustivo sobre el uso de opiáceos, permitiendo el uso de la heroína únicamente con fines terapéuticos. Diez años después, en 1924, el Congreso de Estados Unidos estableció que no existía ningún uso legal de la heroína y prohibió su venta, importación o fabricación, y un año después el Comité de Salud de la Sociedad de Naciones prohibió la diacetilmorfina (1925), aunque se tardó más de tres años en hacer efectiva la restricción. Aun así, la producción de heroína fue grande y continua, ya que se calcula que en el mundo, entre 1925 y 1930, se vendieron 34 toneladas de esta droga.

Desde 1920 a 1930 la heroína fue utilizada en algunos países para la terapia de reemplazo en pacientes con adicción a la morfina y la cocaína. Además, en las farmacias alemanas se pudo adquirir heroína hasta 1971.

Con la firma de la Convención Única sobre Estupefacientes en 1961 y su posterior reforma de 1971, la heroína pasó a la Lista I y quedó ilegalizada prácticamente en todo el mundo. En la actualidad, casi ninguna empresa del mundo produce o vende heroína como droga legal : únicamente se sintetiza en algunos casos para realizar investigaciones o también para tratamientos paliativos (para aliviar el sufrimiento del paciente en situaciones extremas o terminales) y en muy pequeñas cantidades, como, por ejemplo, en corporaciones como Sigma-Aldrich, en particular, en el directorio «Fluka» (una empresa perteneciente a la mencionada anteriormente).

El tráfico de heroína fue prácticamente eliminado en los EE.UU. durante la Segunda Guerra Mundial, debido a las interrupciones temporales en el comercio causadas por la guerra. La guerra de Japón con China había cortado las rutas de distribución habituales de la heroína y la guerra en general había interrumpido la circulación de opio. Después de la Segunda Guerra Mundial, la mafia se aprovechó de la debilidad del gobierno italiano de posguerra y estableció laboratorios de heroína en Sicilia. La mafia se aprovechó de la ubicación de Sicilia, que atravesaba la ruta histórica del opio que se dirigía hacia el oeste en Europa y los Estados Unidos. Con la victoria del Partido Comunista de China en la guerra civil de aquel país a finales de la década de 1940 se eliminó casi por completo la producción de opio, un descenso paralelo que ocurría al mismo tiempo que aumentaba el peso de Sicilia en el comercio internacional.

Aunque se mantuvo legal en algunos países hasta después de la Segunda Guerra Mundial, los riesgos para la salud, la adicción y el uso recreativo generalizado llevaron a la mayoría de los países occidentales a declarar a la heroína una sustancia controlada en la segunda mitad del siglo XX.
Entre finales de 1960 y principios de 1970, la Agencia Central de Inteligencia de Estados Unidos (CIA) ayudó al Kuomintang (los nacionalistas chinos que tras la victoria comunista huyeron a Taiwán) a establecer centros en la frontera con la China continental y Laos; esto ayudó al desarrollo del Triángulo de Oro, una región productora de opio que en 1973, momento en que Estados Unidos se retiró de Vietnam, se estimaba que suministraba un tercio de toda la heroína que se consumía en Estados Unidos. El historiador estadounidense Alfred McCoy sostiene que la CIA fue un colaborador necesario, a través de la llamada «Conexión francesa», en la exportación de heroína desde el Triángulo de Oro e Italia hacia Estados Unidos.

A finales de la década de 1970 y la década de 1980, la guerra de Afganistán, en la que intervino la Unión Soviética, condujo a un aumento de la producción en las regiones fronterizas de Afganistán y Pakistán, ya que los rebeldes muyahidines que luchaban contra la URSS y el gobierno socialista afgano necesitaban financiación para la compra de armas; este hecho contribuyó en gran medida a la formación de la actual Media Luna de Oro. En 1980, el 60% de la heroína vendida en Estados Unidos, país que apoyaba a los muyahidines, provenía de Afganistán. Así, durante la década de 1980 se produjo un aumento en la producción mundial, lo que redujo los precios, por lo que desde ese momento las rutas comerciales se alejaron de Sicilia, ya que las organizaciones criminales se enfrentaron entre sí por el control, a lo que se sumó un mayor esfuerzo del gobierno italiano por imponer la ley en la isla.

En la década de 1990, el consumo de heroína en Occidente se redujo notablemente tras las epidemias de la década anterior (véase la sección posterior), mientras que su producción se estancó o decreció. En Afganistán, las cantidades recolectadas se mantuvieron estables durante toda la década, hasta que entre 2000 y 2001 el gobierno talibán, en colaboración con Naciones Unidas, inició una campaña que acabó con el 99% de los cultivos en las regiones que controlaba, que en aquel momento cubrían el 75% de la demanda mundial. Sin embargo, tras la invasión de la OTAN-ISAF encabezada por Estados Unidos de 2001 y el subsiguiente caos económico y social en el país, la producción volvió a dispararse hasta casi monopolizar el cultivo de adormidera a nivel mundial en la década de 2010. El 13 de marzo de 2012, fue condenado por la Corte de Distrito de Estados Unidos para el Distrito de Columbia por delitos de conspiración, tráfico de heroína para su importación a Estados Unidos y narcoterrorismo Hajji Bagcho Sherzai, un narcotraficante con vínculos con los talibanes y cuyas actividades, según la Oficina de Naciones Unidas contra la Droga y el Delito, fueron responsables del 20% de la producción mundial de heroína en el año 2006.

Desde principios de la década de 1970 y hasta mediados de la década de 1980 su consumo experimentó un verdadero boom mundial –solo en Europa el número de adictos se quintuplicó entre 1967 y 1977– que se dejó sentir hasta bien entrada la década de 1990 y que provocó la muerte de miles de personas, fundamentalmente jóvenes de países occidentales; en países de Europa como Alemania, España, Francia o Italia el fenómeno resultó en una verdadera epidemia, donde tuvo especial incidencia en las clases bajas de la población.

En Alemania Occidental (RFA) la epidemia fue descrita como la más grave de toda Europa, al menos en la década de 1970; según estimaciones federales, en 1978 había 60.000 heroinómanos, en la RFA se incautaba la mitad de la heroína de toda Europa y más de 700 personas morían por sobredosis cada año.Estos hechos fueron retratados en la simbólica novela, que se convirtió en lectura obligada en las escuelas, llamada "Los niños de la estación del Zoo" y que fue llevada al cine con el nombre de "Yo, cristina F." y que contó con la participación de David Bowie, quien admitió ser consumidor de esta sustancia.

En el caso de España su uso no empezó a generalizarse hasta después de 1975, tras la muerte de Francisco Franco y el comienzo de la Transición a la democracia, donde se vivía una atmósfera y anhelo de absoluta libertad donde prevalecía el «todo vale» tras la férrea dictadura. Unido a ello se produjo, sobre todo desde comienzos de la década de 1980, una fuerte reconversión industrial, que disparó el desempleo en las antiguas regiones industriales como Madrid, Cataluña y en especial el País Vasco, cuya economía dependía de la industria pesada, principal objetivo de la reconversión, que acabó prácticamente con todo el sector sin ofrecer alternativas. En estas regiones fue precisamente donde la epidemia de heroína más se cebó con la población; en 1979 se estimaba que en Barcelona había 30.000 heroinómanos, un 1% de la población y algunas estimaciones apuntaban a que en toda España su número podía rondar los 80.000 en 1984, concentrados la mayoría en Barcelona, Madrid (6000 jóvenes consumidores habituales) y el País Vasco. Solo entre 1982 y 1984, las muertes de adictos se duplicaron. En 1984 algunas estimaciones cifraban en 117.000 millones de pesetas (unos 700 millones de EUR) el dinero que este mercado movía al año.
En España la epidemia afectó a toda la sociedad y en las regiones más afectadas el tráfico y consumo de drogas estuvo entre las principales preocupaciones de la población hasta bien entrada la década de 1990. Su incidencia se dejó sentir en la criminalidad, que aumentó considerablemente y alcanzó sus máximos durante la epidemia; en 1985, el Ministerio del Interior estimaba que el 75% de los delitos comunes estaban asociados al tráfico o consumo de drogas, al respecto, el número de detenidos por tráfico o tenencia de drogas, que en 1970 fue de 1200, había aumentado hasta los 5200 en 1977 y escalado hasta unos 11.000 en 1984. Otro dato revelador eran los atracos a farmacias, que en 1977 fueron 718 solo en Madrid, cuando en toda Francia fueron 750 y 1500 en la RFA. Dicho masivo consumo duró hasta la primera mitad de la década de 1990 (a menudo se toma la referencia de 1992). Las películas de cine quinqui como "El pico" retratan a la perfección esta epidemia que se cebó en barrios obreros masificados y en los que la juventud no tenía ningún futuro por la crisis económica, y donde muchos de los protagonistas de estas películas murieron por su adicción a esta droga.

En 1984 el número de adictos en Francia se estimaba en unos 150.000 y de 240.000 a 360.000 en Italia según fuentes oficiales. El problema en Europa tuvo un alcance continental y se situó como una de las mayores problemáticas. Un informe del Parlamento Europeo de 1986 cifraba en 1,5 millones los heroinómanos de la Comunidad Europea (CE) y en 300.000 millones de dólares (USD) los beneficios generados por la venta de drogas y estupefacientes ilegales en todo el mundo, que a su vez motivaban el 50% de todas las detenciones en la CE. En algunos países, especialmente en Italia y España, se denunció en muchas ocasiones, desde una supuesta connivencia de la policía con la distribución local de drogas y la corrupción derivada del tráfico ilegal tanto a nivel empresarial como en el Estado, hasta la existencia de un plan preconcebido desde altas instancias para inundar de droga determinadas regiones o ciudades, especialmente en las que prevalecían sectores obreros o ligados a movimientos sociales.
Los problemas que atravesaban los drogadictos eran muy graves. La fortísima adicción física a la droga arrastraba a muchos jóvenes a la marginación, la delincuencia y la prostitución para poder pagarse la dosis necesaria. Los que sobrevivían quedaban marcados con un estigma social y a menudo con secuelas mentales y físicas (daños en riñones, hígado o arterias). Una de las primeras soluciones que se aplicó fue recluir a los drogadictos en sitios incomunicados, a menudo granjas, y dejar que se «limpiaran». Pero esa estancia era de unas pocas semanas o meses y cuando concluía el aislamiento una gran parte volvía a inyectarse. Posteriormente se crearon «narcosalas» en las cuales se inyectaba metadona, una droga mucho más blanda, como desintoxicación de la heroína. El problema es que era tratamiento de por vida e implicaba admitir que la heroína era un problema crónico sin solución.
La muerte podía deberse a múltiples motivos. Uno de ellos es que a menudo se cortaba, es decir, se introducían todo tipo de sustancias adulterantes (como el yeso) para reducir la proporción de droga y así vender más y obtener más beneficios, produciendo terribles efectos en los cuerpos de los consumidores sin que estos lo advirtieran. En otros casos ocurría que debido a esto, al estar acostumbrados a droga de «baja pureza», cuando venía un cargamento con una pureza mayor las sobredosis eran muy comunes. En ocasiones las mujeres embarazadas adictas transmitían su adicción a los recién nacidos y estos nacían con el síndrome de abstinencia.

El consumo continuó creciendo hasta mediados de la década de 1980, cuando se estancó y comenzó a descender fuertemente, sus motivos fueron varios. Las enfermedades de transmisión sexual (ETS) hacían estragos entre los consumidores, especialmente con la aparición del SIDA en los años 80, que entonces era una enfermedad muy dura e incurable y que se transmitía cuando los consumidores compartían las jeringuillas, lo que provocó que muchos jóvenes no se atrevieran a probar esta droga. Lo mismo sucedió con el miedo a contagiarse de otras enfermedades como la hepatitis. Paralelo al descenso de heroína se produjo el ascenso del consumo de cocaína en Europa y los Estados Unidos, que se convirtió en la droga de referencia. La cocaína se puso de moda entre famosos y las clases altas (como ejecutivos), y la sociedad acabó imitando el comportamiento de estas «élites». En Estados Unidos unas 22 millones de personas consumían cocaína en 1985 (casi un 10% de su población), consumo que se extendió hasta desatarse la epidemia de crack de los años 90, aunque esta afectó sobre todo a las clases bajas y minorías étnicas. De esta forma se acabó creando la imagen de la cocaína como la «droga del rico» y la heroína como la «droga del pobre», aunque el precio de la heroína siguió siendo mayor. A su descenso también pudo afectar la cada vez mayor conciencia social del problema, en el que se creaban asociaciones para combatir el problema y dejar de ver al consumidor como un delincuente y verlo como un enfermo que necesitaba ayuda; la evidente imagen de degradación física y psicológica que provocaba la adicción en los drogadictos y el daño a sus seres queridos provocó un fuerte impacto en la sociedad y «demonizó» la heroína para la siguiente generación.

A comienzos del siglo XXI su consumo es marginal, en comparación con otras drogas tradicionales como el cannabis o la cocaína, o incluso con drogas de diseño o sintéticas, de creación relativamente reciente. Desde los picos de producción del siglo anterior, esta se ha reducido y al respecto, Afganistán es el mayor productor mundial con diferencia y, se estima que en la primera década de siglo hasta 3,3 millones de afganos estaban involucrados en el cultivo y tráfico de opio; le sigue en su orden otro país asiático: Birmania o Myanmar. La producción asiática se exporta a través de las redes ilegales de contrabando fundamentalmente a Europa, aunque una parte significativa se queda en Asia o se transporta a África. La restante producción significativa de la droga está ubicada en Latinoamérica, concretamente en México (en el llamado Triángulo Dorado mexicano: Sinaloa, Durango y Chihuahua, además de 6 estados más) y Colombia (en este último, la producción de heroína es insignificante por la expansión de los cultivos de coca para producir cocaína), países que enfrentan conflictos y guerras contra grupos armados ilegales como guerrillas y paramilitares en el caso colombiano, además de carteles del narcotráfico y crimen organizado en los dos países. La heroína de los dos países termina casi toda en las calles de Estados Unidos.

En 2012 se estimaba que el 70% de la heroína se consumía en África y Asia y algunas estimaciones sostienen que entre 1990 y 2010 el precio de la sustancia, ajustado a la inflación, se redujo más de un 80% en el mercado negro, mientras que su consumo en ese periodo se incrementó un 74% en todo el mundo. La pureza media de la sustancia ofertada también se incrementó notablemente en el mismo periodo.

En la década de 2010, se observa un aumento en el tráfico de heroína hacia Europa, en el marco de lo que se ha señalado como una «oferta masiva» a nivel mundial. Sin embargo, las estadísticas no reflejan un aumento significativo en el número de consumidores europeos; situación muy distinta a la de Estados Unidos, donde el consumo de heroína se ha disparado, sobre todo desde la crisis económica de 2007 y potenciado por la gran oferta disponible y los bajos precios. Según datos de 2012, el número de drogodependientes de esta sustancia, 400.000 estadounidenses ese año, se había duplicado respecto al de 2002; y en 2014, el número de muertes por sobredosis de heroína se había cuadruplicado respecto al año 2002. Sin embargo, lejos de detenerse, el ascenso en Estados Unidos continúa a un ritmo alarmante, pues se estima (datos provisionales) que en 2016 murieron 35.000 personas por consumo de heroína (frente a las 8200 de 2013) y unas 591.000 personas eran dependientes. El elevado número de sobredosis y la alta mortalidad se explican por el creciente uso de otros opioides como adulterantes, en especial el fentanilo. En 2017 el presidente estadounidense Donald Trump declaró «emergencia nacional» la epidemia de los opiáceos, que provoca más de cien muertos al día.




Estos datos sobre solubilidad expresan la solubilidad de la heroína en forma de base libre, y no en su forma de sal clorhídrica. Cuando la heroína está en forma de sal (como la mayoría de los alcaloides) es fácilmente soluble en agua y otros solventes polares.

Se obtiene mediante un proceso de acetilación de la morfina
La materia prima para uso industrial o de laboratorio durante la síntesis de la heroína es la morfina. La acetilación con anhídrido acético o cloruro de acetilo se produce durante el calentamiento. No es necesario un exceso de cloruro de acetilo, ya que en este caso, el resultado, cloruro de hidrógeno, se une a la parte básica de nitrógeno núcleo morfinanovogo, y parcialmente retirado de la mezcla de gas que desplaza el equilibrio casi por completo hacia la formación de derivados diacetilados. El crudo de la acetilación se purifica por adición de carbón activo y filtrado para ser posteriormente recristalizado en etanol.

El rendimiento de la reacción es de hasta del 95,5%.

Los reactivos acetilantes están incluidos en la lista de precursores de estupefacientes y el tráfico en muchos países está limitado y controlado en conformidad con la ley y los tratados internacionales.
Además para la síntesis completa requiere de la limpieza adecuada de los productos resultantes, la heroína, a menudo es sintetizada por personas que no tienen el equipo necesario y utilizan ingredientes de dudosa calidad. Por ejemplo, mientras que la síntesis artesanal de heroína puede ser llevada a cabo sin morfina y opio, la paja de adormidera y similares, productos semi acabados causan que la sustancias adquiera un 50% extra de peso.

Como resultado del procesamiento de estos materiales se forma un compuesto masa resinosa marrón o negra con un bajo contenido de diacetilmorfina y una gran cantidad de impurezas formadas durante la reacción, con efectos secundarios poco predecibles.

La diacetilmorfina oral, una vez que está en el sistema circulatorio, se convierte rápidamente en el hígado en morfina. Sin embargo, cuando se inyectan heroína, que es más lipofílica que la morfina, penetra rápidamente en el cerebro, y entonces en este se convierte en un 6 monoacetilmorfina (6-MAM) y morfina.
El mecanismo de acción de la heroína es en gran parte determinado por el perfil de la morfina como típico (estándar) en un opioide, teniendo una alta afinidad a los receptores opiáceos-μ2 μ1.

El diacetilmorfina en sí tiene una afinidad relativamente baja para los receptores opiáceos μ. Sin embargo, cuando se administra por vía intravenosa, en contraste con la hidromorfona y oximorfona, la diacetilmorfina es una versión más fuerte de la histamina, que causa un pronunciado sentido más de «elevación», y en algunos casos también la sensación de picor.
Los receptores μ-opioide en los mamíferos están disponibles en el cerebro y la médula espinal, así como en el intestino. En el cerebro se concentran en la materia gris del cerebro, en el bulbo olfatorio y algunas capas de la corteza del encéfalo, así como en algunos núcleos de las neuronas y en la amígdala. Los receptores representan un mecanismo metabotrópico GPCR - los receptores asociados a proteínas G, que normalmente activan las endorfinas. Las endorfinas son parte del sistema de analgésicos diseñado para controlar el nivel de dolor. Los metabolitos de la heroína se unen a los receptores opioides. Pueden causar cambios en la excitabilidad de las neuronas, estimulando la liberación presináptica de ácido gamma-aminobutírico (GABA). Aunque el GABA es un neurotransmisor inhibidor, el efecto final depende del sistema nervioso y el estado de la neurona postsináptica. Además, en el caso de los receptores opioides μ-, depende específicamente del agonista.
Todos los opiáceos, incluyendo la heroína, tienen una cierta similitud estructural con las endorfinas endógenas (producidas por el cuerpo). La estructura molecular de los opiáceos interactúa precisamente con el receptor deseado. Las endorfinas, dependiendo del tipo, funcionan en un grupo específico de receptores, y los opiáceos, todos de manera simultánea, de manera muy similar con las endorfinas para lograr el mismo efecto.

La popularidad entre los adictos a las drogas, en comparación con otros opiáceos, se debe a que la heroína demostró tener efectos más pronunciados que el de otros estupefacientes y que los efectos de la morfina. Esto se debe a que el impacto de los metabolitos de la morfina en los receptores opioides μ produce una sensación de euforia acompañada de analgesia y acción anti-inflamatoria, así también una supresión de la ansiedad. La morfina también se une a los receptores δ-y y los κ. Existe alguna evidencia de que el 6-MAM se asocia con un subtipo de receptor opioide μ, que se une un metabolito de la morfina, morfina-glucurónido 6β. La contribución de estos receptores en los efectos farmacológicos generales de la heroína sigue siendo desconocido hasta el momento.
La administración crónica de opiáceos aumenta el número de receptores opioides en el cerebro, este es el principal mecanismo para la adicción y la dependencia a la heroína. Otros mecanismos de la adicción se puede aumentar por la producción de glutamato (excitación de un mediador) y la transmisión glutamatérgica en el cerebro, reduciendo la producción de endorfinas, y la regulación de la actividad de los receptores opioides. En este caso, la interrupción de la droga causa una serie de dolorosos síntomas (síndrome de abstinencia) caracterizados por dolor, ansiedad, calambres musculares, insomnio, etc. Dependiendo de la duración del consumo de la droga y de otros factores este se produce dentro de entre 4 y 24 horas después de la última dosis de diacetilmorfina.

Los efectos observados cuando se toma heroína, se pueden dividir en dos grupos - a nivel central y a nivel periférico.

Analgesia;
Inhibición del centro respiratorio;
Inhibición del centro del vómito;
Depresión del centro de la tos;
Disminución del tamaño de la pupila a través de los nervios craneales (miosis);
sedación, sentimiento de paz, euforia, posible aparición de alucinaciones agradables o terroríficas;
Inhibición de la actividad secretora del tracto gastrointestinal;
Estimulación de la liberación de la hormona antidiurética y una disminución en la micción;
Disminución de la temperatura corporal.
El efecto de la diacetilmorfina en el SNC se acompaña de un efecto sedante, disminución del nivel de conciencia, sensación de calor, somnolencia y euforia. Los efectos sedantes e hipnóticos del diacetilmorfina se vuelven más pronunciados que la de los agonistas μ meperedina (petidina), la morfina, la metadona, la codeína y el fentanilo. Este efecto es causado por la presencia de grupos acetil, lo que facilita la difusión al cerebro. En algunos casos, la sedación puede ser acompañada por picos de excitación de corto plazo e hiperactividad.
El diacetilmorfina es un potente analgésico, el efecto realizado es debido a la depresión directa de los metabolitos activos espinales.
Cabe señalar que el diacetilmorfina aumenta los efectos si es aplicado de forma concomitante con hipnóticos, sedantes, fármacos para anestesia general, ansiolíticos, o alcohol.

Posible desarrollo de náuseas y vómitos con dosis relativamente pequeñas, con un aumento del consumo manteniendo la misma dosis las náuseas y vómitos desaparecen. Fenómenos similares ocurren debido a la irritación de los intestinos y el sistema de quimiorreceptores de vértigo que ocurren durante la sedación.

Se eleva el funcionamiento de los esfínteres - esfínter urinario, del esfínter de Oddi y Lyutkensa, externo y esfínter interno y el recto.

Aumenta el funcionamiento de los músculos lisos. Aumenta la reactividad de los bronquios, como el asma, pudiendo producirse bronco-espasmos. Puede ocurrir un espasmo ureteral, lo que lleva a la dificultad en la micción volviéndose esta dolorosa.

Desde el sistema nervioso central y periférico ocurren acciones longitudinales que suprimen la peristalsis del intestino, y el peristaltismo transversal por lo generalmente aumenta, aumenta el funcionamiento de los distintos segmentos del tracto gastrointestinal, principalmente el antro gástrico, la secreciones basales se inhiben. Al disminuir el paso del contenido intestinal se produce un aumento en la absorción de agua en el intestino, un aumento de la viscosidad y la densidad de las heces y promueve el desarrollo del estreñimiento.

Se reduce la actividad secretora, que puede conducir a la sequedad de la boca, los ojos, la nariz y la garganta, y a dispépticos trastornos, visión borrosa, tinnitus, y reacciones alérgicas.

Se produce una disminucíon significativa de la temperatura corporal.

La heroína tiene un efecto pronunciado sobre el sistema nervioso periférico, la administración crónica conduce a muchos trastornos autonómicos - desarrolla bradicardia, disminución de la peristalsis del intestino, aumenta el tono de los esfínteres, disminución de la actividad secretora.

Uno de los factores principales que llevan a una variedad de complicaciones graves, es el efecto narcótico de la heroína. Las complicaciones surgen cuando se toma la heroína como una droga que puede dividirse en varias tomas diarias causando alteraciones fisiológicas por la acción de el diacetilmorfina en el cuerpo humano y debido a las impurezas del producto. Para los individuos con adicción a esta droga la más común y peligrosa complicación es una sobredosis. Según varios informes, el 50-60% de los consumidores de opiáceos al menos una vez sufrieron una sobredosis. También se puede desarrollar psicosis y estados epilépticos.
Además, al tomar la heroína, hay consecuencias a largo plazo que se manifiestan en una variedad de trastornos de la microcirculación, enfermedad en el hígado, y en los componentes que actúan durante la depresión del sistema nervioso central.
Además de los efectos tóxicos directos de heroína en el cuerpo, su consumo puede afectar seriamente la salud debido a una variedad de impurezas contenidas en el producto, debido a la falta de agentes de limpieza o productos intencionalmente añadidos de reventa para obtener mayores beneficios mediante mezclas con una disminución de su cantidad de narcóticos para así obtener más beneficios en la venta. También el mismo diacetilmorfina y las impurezas contenidas en la administración de la droga pueden desarrollar una reacción alérgica marcada por angioedema y anafilaxia, aunque estos efectos secundarios no ocurren con demasiada frecuencia, pero podría representar un grave peligro para la vida del usuario en el caso de producirse.

Cuando las inyecciones intravenosas son a menudo desarrolladas se genera flebitis, y la endocarditis con afectación de la válvula tricúspide del corazón. Si se usa jeringas o contenedores para solución o para la administración intravenosa, se corre el riesgo de desarrollar diversas infecciones (ETS) como el VIH o la hepatitis.

El primer uso de heroína fue de naturaleza puramente médica. Poco a poco, debido a la revalorización de las prestaciones profesionales y la evaluación de las relaciones riesgo-beneficio se produjo la eliminación gradual del uso generalizado de la heroína como medicamento. Al mismo tiempo, aumentó el creciente uso de medicamentos que contienen heroína como principio activo.

Desde 1971 el uso de la heroína en todo el mundo está permitido solo en pequeñas cantidades y en estudios científicos controlados estrictamente. Por eso, la producción de heroína está destinada prácticamente en su totalidad a la venta ilegal y el narcotráfico.
La diacetilmorfina podría ser utilizada como producto intermedio en la síntesis de derivados de la morfina, tales como el nalorfin.

A pesar de que la heroína es una droga de abuso conocida, algunos investigadores (médicos y farmacéuticos) están considerando la posibilidad de sustituir la morfina por heroína. Recientes estudios clínicos sugieren que puede ser menos peligroso que el tradicional clorhidrato de morfina.
En el Reino Unido la heroína purificada denominada diamorfina se utiliza como un potente analgésico para la práctica de los cuidados paliativos.
En otros países se prefiere el uso de la morfina. Actualmente se observa una tendencia a migrar a la morfina también en el Reino Unido, sobre todo después de los problemas por la escasez en el suministro de diamorfina.
Actualmente, en Alemania y Suiza durante la terapia de sustitución se considera la posibilidad de sustituir la metadona químicamente por heroína pura. En este sentido, en varias ciudades alemanas se están llevando a cabo estudios desde aproximadamente el año 2005, el denominado "proyecto de la heroína" ("él. Heroinprojekt" o "él. Heroinstudie"). Estos estudios intentan evaluar los beneficios de la heroína de calidad para un paciente externo bajo la supervisión de un médico con fines de investigación para así determinar la posibilidad del tratamiento de la adicción a los opioides con el uso de terapia de sustitución a base de heroína pura.

Se conoce a la heroína como una droga que se puede clasificar dentro de las drogas duras, caracterizándose por producir una alta tasa de dependencia (adicción psicológica y física); además produce un fuerte síndrome de abstinencia, generando un problema sanitario grave que dificulta el tratamiento en caso de adicción, es por eso que se utilizan drogas sustitutivas, para evitar los síntomas de la abstinencia a la droga. Sin embargo, el tratamiento de la heroína aun con métodos sustitutivos puede ser muy complicado debido a la fuerte dependencia psicológica que genera.

Debido a su solubilidad en disolventes orgánicos y agua, la heroína puede penetrar a través de las membranas mucosas del cuerpo. Puede ser inyectada en el cuerpo de varias maneras: a través de la mucosa nasofaríngea, el estómago, el intestino, el recto, la vagina, o también puede fumarse, inhalarse e ingerirse por vía oral. Desde el comienzo del siglo XX hasta la actualidad, el método más común de usarla era por vía intravenosa o inyectada, ya que dicho consumo permite un efecto rápido e intenso. Además, al necesitarse cantidades muy bajas el consumo por vía intravenosa, suele convertirse en un método económico mediante el que los heroinómanos pueden reducir la dosis y el costo de manera significativa. Para la administración a través de las membranas mucosas se requiere un especial refinado de la heroína, que es caro y requiere de más materiales.

Los sujetos que presentan adicción a la heroína utilizan diferentes métodos para administración de la sustancia, entre ellos:
La dosis media pura va de 5 a 10 miligramos de diacetilmorfina (heroína). Si una persona utilizó los opiáceos durante mucho tiempo, la dosis requerida de drogas puede aumentar hasta 4,2 veces o hasta entre 20 y 40 miligramos. En teoría, la dosis para la administración crónica puede aumentar indefinidamente hasta la ocurrencia de muerte por enfermedad o por complicaciones concomitantes.

Como todos los opiáceos de venta ilícita, la heroína puede adulterarse con quinina, lactosa, azúcar, y fármacos depresores del sistema nervioso central, tales como los barbitúricos y sedantes o contaminarse con bacterias, virus, hongos o partículas. Se han reportado algunos casos de sustitución total de heroína por pentazocina. La droga llamada "Speedball" no es más que cocaína mezclada con heroína.

Ya que los consumidores de heroína no saben la fuerza real de la droga o su verdadero contenido, están en riesgo de sufrir un envenenamiento por adulteración o una sobredosis, hechos que pueden causar un alto riesgo de muerte; en el caso de la sobredosis se utiliza la naloxona como antagonista de la heroína para salvar al sujeto.

El síndrome de abstinencia de la heroína, conocido comúnmente como "mono", es uno de los más fuertes entre las drogas de abuso.

Se localiza tanto a nivel físico como psicológico, y neurológico siendo el primero el que provoca el cuadro más "aparatoso".

Suele comenzar con moqueo, lagrimeo, rinorrea, calambres y dolores musculares, síntomas similares a una gripe, acompañado de una fuerte ansiedad, seguido de diarrea y vómitos. El cuadro se va agudizando según pasan las horas y puede acompañarse de convulsiones y alucinaciones.

Suele remitir a nivel físico entre el 4º y el 5º día. A nivel psicológico se extiende mucho más en el tiempo dependiendo del individuo.

A partir de su aparición, la heroína se utilizó principalmente para tratar la tuberculosis por su capacidad para suprimir el reflejo de la tos. Pronto se vio que su efecto anestésico no era mayor que el de la morfina, pero era más activa, por lo que podía utilizarse en dosis menores logrando el mismo efecto con las consiguientes ventajas a nivel de acumulación en los tejidos. Sin embargo, algo más la diferenciaba de la morfina: ciertos efectos estimulantes y no solo analgésicos, por lo que durante mucho tiempo se recomendó como cura para el hábito producido por la morfina.
Actualmente el clorhidrato de heroína se sigue utilizando como analgésico en países como el Reino Unido, con el nombre de diamorfina.
Además el efecto de la heroína es más potente que el de la morfina, pero menos duradero.




</doc>
<doc id="41249" url="https://es.wikipedia.org/wiki?curid=41249" title="Alucinógeno">
Alucinógeno

Se llama alucinógenos a cierto tipo de drogas que, en dosis no tóxicas, causan alteraciones profundas en la percepción de la realidad del consumidor. Bajo su influencia, las personas ven imágenes, escuchan cosas y experimentan sensaciones muy distintas a las propias de la vigilia. Algunos alucinógenos también producen oscilaciones emocionales rápidas e intensas. En su aspecto negativo, en muchas ocasiones producen confusión mental, pérdida de memoria o desorientación en la persona, de espacio y de tiempo.

Son sustancias que provocan estados alterados de conciencia que afectan a la percepción (alucinación) y varían la noción de la propia identidad. Sus efectos son muy variables, dependiendo tanto de la dosis como de las expectativas del sujeto y el ambiente que le rodea durante la experiencia. Cuando, por una razón u otra, el balance de la experiencia resulta desagradable para el sujeto suele hablarse coloquialmente de "mal viaje". 

Los alucinógenos producen sus efectos interrumpiendo la interacción de las células nerviosas y el neurotransmisor serotonina. Distribuido por el cerebro y la médula espinal, el sistema de serotonina está involucrado en el control de los sistemas de conducta, percepción y regulación, incluyendo el estado de ánimo, el hambre, la temperatura corporal, el comportamiento sexual, el control muscular y la percepción sensorial. Algunos alucinógenos antes de llegar al proceso anteriormente descrito pierden un radical en su molécula: tal es el caso de la psilocibina, contenida en los hongos del género psilocybe, que una vez dentro del cuerpo pierde un radical fósforo para de este modo convertirse en psilocina, que al parecer es la sustancia que libera los mecanismos en el sistema nervioso.

El LSD (acrónimo del término alemán para la dietilamida del ácido lisérgico) es la droga que se identifica más comúnmente con el término alucinógeno y la más ampliamente usada de este tipo de drogas. Se considera el alucinógeno típico y las características de sus acciones y efectos se aplican a los otros alucinógenos, incluyendo a la mescalina, la psilocibina y la ibogaína, aunque la experiencia con cada alucinógeno varía.

Entre los más utilizados están el LSD, los hongos psilocibios, la mescalina, presente en el peyote y los cactos de la familia Trichocereus, y otros más.

Existen muchas lagunas en el conocimiento científico de las drogas visionarias debido a las trabas que la legislación impone en casi todos los países a la investigación de este tipo de sustancias, sobre todo cuando en ella interviene el consumo humano .

La intoxicación aguda por fármacos alucinógenos no es muy habitual en la actualidad y resulta extraño que se presente sin estar asociada al consumo de alcohol. Normalmente los intoxicados precisan ayuda por causa de las crisis de pánico, derivadas del denominado "mal viaje" (experiencia negativa y desagradable), cuyos síntomas son la angustia y la depresión asociadas a confusión mental, alucinaciones visuales y auditivas, sensación de incapacidad, culpabilidad y riesgos de conductas agresivas con pérdida de autocontrol y peligro de suicidio.

En caso de «mal viaje» o efecto «el peti» (Como se le dice en Argentina y en Paraguay) se debe aislar al intoxicado en un lugar tranquilo y poco iluminado, evitando excesivos estímulos a su alrededor. Puede ser útil una música suave. Debe acompañarle una persona que le serene y tranquilice. Se le debe explicar serenamente que lo que ocurre es la reacción de algo que la persona tomó. Y que todo lo que siente, no es más que un efecto que en algún momento llegará a su fin; generando así tranquilidad en el individuo. También es recomendable decirle a la persona la hora exacta en la que el efecto, seguramente, habrá pasado. Muchos están especialmente preocupados por la idea de que han destruido su cerebro, de que son ellos mismos los que se han llevado a la locura y que serán incapaces de volver a su estado normal. Su traslado a un centro médico debe realizarse tomando en cuenta las premisas anteriores.

Existe una gran cantidad de nombres para hablar de este tipo de drogas. Alucinógenos, enteógenos, psicodélicos, drogas visionarias, drogas de poder, psicodislépticos, psicotomiméticos, eidéticos etc. Cada uno de los nombres está asociado a una cosmovisión concreta, y no siempre son adecuados en todos los contextos y ninguno describe por completo los efectos psicofisiológicos. En Europa tales efectos son llamados con frecuencia "phantastica". Se suele llamar alucinación a una "percepción sin objeto", o sea, percibir algo donde no está, sea un sonido, una imagen, etc. Ateniéndose a ese sentido, los "alucinógenos" más usados no lo serían, o lo serían sólo en dosis realmente altas o en contextos específicos -falta de luz, etc. A ese perfil responde bien sólo una de las familias de las drogas visionarias, que es la de los alcaloides tropanos (escopolamina, hyosciamina, atropina) que se encuentran en ciertas plantas solanáceas (estramonio, toloache, belladona, beleño, mandrágora, brugmansia, etc.).

Muchos autores (Ott, Escohotado) rechazan los términos psicodélico y psiquedélico por estar en exceso asociados con el uso de drogas visionarias en los años sesentas y setentas. Psicodisléptico se refiere a aquello que desata la psique, y es un término que no pretende asignar valores morales. Psicotomimético, en cambio, habla de la sustancia que es capaz de imitar la psicosis. No obstante, nuevos estudios sobre el funcionamiento cerebral han comprobado que las actividades cerebrales provocadas por alucinógenos difieren fundamentalmente de las que se presentan durante psicosis auténticas.

Una subcultura occidental muy grande asigna a las drogas visionarias un valor de tipo espiritual e incluso religioso, inspirados casi siempre por culturas primigenias donde el uso de este tipo de drogas estaba integrado en un contexto chamánico. Ellos son los que prefieren denominarlas plantas de poder, maestros vegetales, drogas visionarias o enteógenos. Este último es un neologismo propuesto por Gordon Wasson, Jonathan Ott y otros que sugieren que este tipo de sustancias revelan y generan la divinidad en el interior de quienes las consumen.




</doc>
<doc id="41253" url="https://es.wikipedia.org/wiki?curid=41253" title="Coordenadas cilíndricas">
Coordenadas cilíndricas

El sistema de coordenadas cilíndricas es muy conveniente en aquellos casos en que se tratan problemas que tienen simetría de tipo cilíndrico o "azimutal". Se trata de una versión en tres dimensiones de las coordenadas polares de la geometría analítica plana.

Un punto formula_1 en coordenadas cilíndricas se representa por (ρ,φ,formula_2), donde:

Los rangos de variación de las tres coordenadas son

La coordenada azimutal φ se hace variar en ocasiones desde -π a +π. La coordenada radial es siempre positiva. Si reduciendo el valor de ρ llega a alcanzarse el valor 0, a partir de ahí, ρ vuelve a aumentar, pero φ aumenta o disminuye en π radianes.

Teniendo en cuenta la definición del ángulo φ, obtenemos las siguientes relaciones entre las coordenadas cilíndricas y las cartesianas: 

Las líneas coordenadas son aquellas que se obtienen variando una de las coordenadas y manteniendo fijas las otras dos. Para las coordenadas cilíndricas, éstas son:


Las superficies coordenadas son aquellas que se obtienen fijado sucesivamente cada una de las coordenadas de un punto. Para este sistema son:


Las líneas y superficies coordenadas de este sistema son perpendiculares dos a dos en cada punto. Por ello, éste es un sistema ortogonal.

A partir del sistema de coordenadas cilíndricas se puede definir una base vectorial en cada punto del espacio, mediante los vectores tangentes a las líneas coordenadas. Esta nueva base puede relacionarse con la base fundamental de las coordenadas cartesianas mediante las relaciones

e inversamente

En el cálculo de esta base se obtienen los factores de escala

Disponiendo de la base de coordenadas cilíndricas se obtiene que la expresión del vector de posición en estas coordenadas es

Nótese que no aparece un término formula_23. La dependencia en esta coordenada está "oculta" en los vectores de la base.

Efectivamente:

Un desplazamiento infinitesimal, expresado en coordenadas cilíndricas, viene dado por

La expresión general de un diferencial de superficie en coordenadas curvilíneas es complicada.

Sin embargo, para el caso de que se trate de una superficie coordenada, formula_26 el resultado es
y expresiones análogas para las otras dos superficies coordenadas.

En el caso particular de las coordenadas cilíndricas, los diferenciales de superficie son

El volumen de un elemento en coordenadas curvilíneas equivale al producto del jacobiano de la transformación, multiplicado por los tres diferenciales. El jacobiano, a su vez, es igual al producto de los tres factores de escala, por lo que

que para coordenadas cilíndricas da

El gradiente, la divergencia, el rotacional y el laplaciano poseen expresiones particulares en coordenadas cilíndricas. Estas son:







</doc>
<doc id="41254" url="https://es.wikipedia.org/wiki?curid=41254" title="Crack (droga)">
Crack (droga)

El crack es una droga ilegal utilizada comúnmente con fines recreativos, creada a partir de la combinación de clorhidrato de cocaína y bicarbonato sódico. 

A diferencia de la cocaína, se consume fumándose en pequeños tubos de vidrio y tiene un efecto inmediato, pues empieza a actuar en aproximadamente 10 segundos. Además de estar considerada como la forma de cocaína más adictiva, es la droga que más fácilmente puede provocar adicción psicológica, incluso en aquellos usuarios que la consuman por primera vez. Sus efectos iniciales son más rápidos e intensos incluso que otras drogas inyectadas y estos se caracterizan por un breve estado de euforia, placer o aumento de la energía, aunque también estimula el sistema nervioso y circulatorio. Sin embargo, el crack es mucho más dañino que la cocaína y tiene unos graves efectos adversos potencialmente mortales, especialmente cardiovasculares, psicológicos, hepáticos y pulmonares.

Los orígenes del crack se encuentran en barrios pobres de grandes ciudades de Estados Unidos a mediados de la década de 1980, que tras una epidemia de esta droga en ese país, fue saltando al resto del mundo; está incluida en la Lista I de la Convención Única sobre Estupefacientes de 1961, por lo que su producción, comercialización, consumo o posesión son ilegales en casi todos los países del mundo.

El término «crack» es una onomatopeya que sugiere el ruido que hacen las piedras de esta droga al calentarse por la evaporación de la cocaína en base que contienen, al liberarse de la mezcla con el bicarbonato de sodio. También recibe nombres vulgares por parte de los usuarios de esta droga, como «guacamayo», «rocas», «chulas», «pops», «piedras», «rirris», «niñas», «duras», «merca», «hielos», «rock&roll», «rockstars», «chespi» o «chifle»,«chirulón», «pirula sucia»,«chichiflín», entre otros; a veces erróneamente se le confunde con la pasta básica de cocaína, llamada también «pasta», «paco» o «pitillo», que es la costra que queda en la olla donde preparan la cocaína y está compuesto por los alcaloides de la planta sin refinar ni purificar.

En sus formas más puras, las piedras de crack aparecen en forma de pepitas blanquecinas con bordes irregulares, con una densidad ligeramente superior a la cera de velas y semejantes a las de un plástico duro pero quebradizo (en forma cristalina). El crack puede utilizarse como anestésico local, al poder dormir la boca o la lengua si se coloca directamente, aunque dependiendo de su nivel de pureza puede llegar a deshacerse cuando está cerca de una fuente de calor, ya que su punto de sublimación es de unos 90º C. 

La cocaína en forma de crack se vende en las calles adulterada con sustancias que imitan su apariencia, con el fin de aumentar su volumen y por tanto el beneficio económico por su venta ilegal. En América del Norte está extensamente documentado el uso de adulterantes tóxicos, especialmente el levamisol. 

El crack se compra frecuentemente en forma de roca, aunque tampoco es raro que algunos consumidores la fabriquen con cocaína en polvo. Este proceso se realiza con bicarbonato de sodio y agua. Una vez mezclado en una parte de cocaína en forma de clorhidrato y dos partes de bicarbonato, se calienta y el bicarbonato reacciona con la cocaína en polvo, formándose pasta de cocaína y ácido carbónico. El calor acelera la conversión del ácido carbónico en dióxido de carbono y agua y el CO2 evita que la reacción vuelva a formar clorhidrato de cocaína, quedando los alcaloides en el bicarbonato de sodio, que no se evapora, y cuya función es la de aumentar el tamaño y la manejabilidad de la sustancia. El crack pasa a estado gaseoso a los 90º C, mientras que el punto de fusión del clorhidrato de cocaína es de unos 190º C. Esta diferencia en la temperatura permite que el crack se pueda fumar, mientras que el clorhidrato de cocaína no; igualmente el crack permite al fumarse una rápida absorción en el torrente sanguíneo que llega al cerebro a los 8 segundos. Aunque también puede inyectarse con los mismos efectos que la cocaína, el crack no puede disolverse en agua, por ellos los consumidores deben disolverlo en una solución ácida (zumo de limón, vinagre) para revertir la conversión cocaína-crack. 

Dado que se fuma, el "crack" ingresa rápidamente al torrente sanguíneo, generando en el individuo una sensación de euforia, aumento de la energía y disminución de la fatiga, confianza total en uno mismo y estado de alerta, aunque también pánico e insomnio. Esto también hace que el "comedown" sea más repentino, causando la necesidad de repetir la toma del mismo. Los intentos por mantener la sensación de euforia inicial con el consumo reiterado puede producir ansiedad, aunque la mecanización ritual de su preparación contribuye a sosegar la sensación de pánico y el delirio de persecución. Sus efectos secundarios son similares a los de la cocaína, aunque el riesgo de padecer alguna complicación es más alto, por la vía de consumo, propensa a producir accidentes cardio y cerebrovasculares. Su efecto a nivel biológico es la liberación inicial de gran cantidad de dopamina en el cerebro, responsable de los sentimientos de euforia. El cenit de sus efectos se produce entre los 5 y 10 minutos después de su consumo, aunque pasado ese pequeño espacio de tiempo los niveles de dopamina en el cerebro caen bruscamente, provocando en el sujeto un cuadro depresivo. Respecto a la cocaína en polvo, si se administra por vía sanguínea tiene un tiempo de respuesta similar a cuándo se fuma en forma de crack, produciendo unos niveles de euforia también similares.

Desde la década de 1980, el "crack" se fuma en pipa de vidrio, con ceniza de cigarro sobre una lata con orificios, en un gotero de cristal, en un cigarro como "primo" (nombre que se le da al cigarro de tabaco junto con el "crack"), entre otras. Otro instrumento utilizado para consumir "crack" es un tubo metálico similar a una antena de radio (en muchos casos lo es) a la que se le introduce una suerte de alambre y se utiliza para fumar "crack" simulando una pipa. Este método es utilizado principalmente por adictos de muy pocos recursos, aunque acaba resultando más caro que la cocaína debido a la corta duración de los efectos, además de representar un mayor riesgo en el desarrollo de enfermedades pulmonares.

Debido a que el crack es una droga ilícita, los usuarios pueden consumir una droga adulterada o falsa, lo que añade problemas adicionales para su salud. 

Los efectos fisiológicos a corto plazo incluyen vasos sanguíneos constreñidos, pupilas dilatadas y aumento de la temperatura corporal, frecuencia cardíaca y presión arterial. Algunos consumidores también desarrollan inquietud, irritabilidad y ansiedad. Las muertes relacionados con cocaína a menudo ocurren cuando el usuario sufre un paro cardíaco o convulsiones seguidas de un paro respiratorio, además en raras ocasiones se han dado casos de muerte súbita momentos después de la primera dosis. 

Al igual que con otras formas de cocaína, fumar crack aumenta la presión cardíaca y la presión arterial, lo que puede generar problemas cardiovasculares a largo plazo. Algunas investigaciones apuntan a que fumar crack o pasta de cocaína entraña riesgos adicionales para la salud en comparación a cuando se consume cocaína en forma de clorhidrato (el más habitual). Muchos de estos problemas se relacionan con la liberación de metilecgonina al fumarse la cocaína, que afecta a corazón, pulmones e hígado. La presencia de adulterantes en la droga para aumentar su peso y volumen provoca que en ocasiones se encuentren sustancias altamente tóxicas que añaden un factor de riesgo extra para la salud del consumidor. Algunos de los adulterantes más habituales detectados en la cocaína incluyen leche en polvo, azúcares, almidón, cafeína, lidocaína, benzocaína, paracetamol, anfetamina, escopolamina y estricnina.

Como se ha dicho anteriormente, fumar crack provoca efectos dañinos mayores que el consumo de cocaína por otras vías. Los usuarios de crack tienden a fumarlo debido a que posee una biodisponibilidad más alta que otras rutas de administración habituales. Existe el riesgo de sufrir sobredosis, dado que cada lote de crack contiene una pureza distinta, por lo tanto un usuario habituado a consumir grandes cantidades de crack de baja pureza podría sufrir una sobredosis si consumiese un lote de alta pureza; la sobredosis puede desencadenar fallos cardíacos y pérdida del conocimiento.

En los usuarios de crack se han reportado síndromes respiratorios agudos o neumonías, con síntomas que incluyen fiebre, tos con sangre y dificultades graves para respirar, lo que en las publicaciones estadounidenses se ha venido a denominar "crack lung" (pulmón de crack). En un estudio publicado en diciembre de 2013, se encontró que las personas que tenían los síntomas descritos, a las que se realizaron radiografías de tórax con rayos X, sufrían una amplia gama de complicaciones respiratorias, como edema pulmonar, enfermedad pulmonar intersticial, hemorragia pulmonar e infiltraciones de eosinófilos. El estudio indicaba que los daños alveolares en los pulmones podrían explicarse adicionalmente por la presencia de impurezas, la elevada temperatura de la cocaína crack en el momento de su consumo y la vasoconstricción local inducida por la cocaína. 

El abuso de drogas estimulantes, particularmente anfetaminas y cocaína, puede provocar un delirio de parasitosis (también conocido como síndrome de Ekbom) donde los pacientes creen que su piel está infestada de parásitos. En el caso de la cocaína, los consumidores que toman una dosis excesiva pueden llegar a pensar que tienen insectos que se arrastran bajo su piel. Delirios similares también están asociados a individuos con fiebre alta o que padezcan el síndrome de abstinencia del alcohol, que a veces también va acompañado de alucinaciones visuales de insectos. Las personas que experimentan estas alucinaciones pueden rascarse hasta sufrir graves daños en la piel y sangrar en abundancia, sobre todo cuando las alucinaciones son especialmente delirantes. 

La paranoia y la ansiedad se encuentran entre los principales síntomas psicológicos del consumo de crack. La psicosis está particularmente ligada al crack, ya que es mucho más probable padecerla por esta vía (fumada) que cuando se administra por vía nasal o intravenosa. 

Se puede desarrollar rápidamente tolerancia a la cocaína y muchos adictos han señalado que los efectos y placer alcanzados en la primera experiencia no han podido volver a repetirlos. Algunos usuarios aumentan la dosis para intensificar y prolongar los efectos eufóricos, que con el tiempo tienden a reducirse. Si bien puede producirse tolerancia a los efectos, los usuarios a dosis similares pueden volverse más sensibles a los efectos analgésicos y convulsivos de la droga. Esta mayor sensibilidad podría explicar las muertes repentinas en personas que habían consumido dosis aparentemente bajas. 

En las últimas décadas se ha pensado que la cocaína en forma de crack es la más adictiva de todas. Sin embargo, algunos estudios señalan que empíricamente no está demostrado que fumar cocaína aumente las probabilidades de dependencia; Morgan y Zimmer argumentan que los consumidores de cocaína son más propensos al abuso, ya que con el tiempo tienden a buscar modos más eficientes de ingestión. Aunque el deseo de recuperar los efectos iniciales es lo que provoca adicción en una mayoría de usuarios, algunos autores señalan que la adicción al crack depende del contexto social y del perfil psicológico de cada usuario, al darse casos de usuarios de crack que pueden estar días o semanas sin consumir droga. El uso del "crack" se ha vinculado con la violencia, pero no se puede asegurar que esto sea un efecto derivado del propio consumo de la droga, tanto como de los grupos sociales más pobres, con un alto índice de violencia y delincuencia en sí mismos.
Algunos especialistas han querido ver la adicción al "crack" como intratable, pero otros académicos consideran que esto se asevera por ser una droga consumida por gente pobre que no puede pagar un tratamiento en centros especializados.

El crack se considera una droga cuya aparición es un fenómeno relativamente reciente. A principios de la década de 1980, la mayor parte de la cocaína que llegaba a los Estados Unidos por vía marítima y que atracaba en Miami, lo hacía a través de las Bahamas.Muy pronto se produjo un enorme excedente de polvo de cocaína en estas islas, por lo que el precio de la misma bajó hasta un 80 %. Ante la bajada de los precios de esta sustancia ilegal, los traficantes de drogas tomaron la astuta decisión empresarial de convertir el polvo de cocaína en «crack», una forma sólida de cocaína que se fuma y que se podía vender a más gente en menores cantidades. Era una sustancia barata, sencilla de producir, lista para usar y de cuya elaboración los traficantes obtenían mayores beneficios. Ya en 1980 fueron apareciendo informes sobre el crack en algunas de las principales ciudades de Estados Unidos y el Caribe.

Al principio, el crack tenía mayor pureza que el polvo de cocaína que se vendía en la calle (al menos, hasta que el crack pasó a ser lo que se denominaba "blow-up" —una variedad adulterada con lidocaína con la que se aumentaba su volumen— y en el llamado "whip dope"). Hacia 1984, la cocaína tenía una pureza del 55 % y costaba 100 dólares el gramo, mientras que el crack se vendía por el mismo precio con unos niveles de pureza superiores al 80 %. En algunas ciudades, como Nueva York, Houston, Los Ángeles, Detroit, y Filadelfia, se podía obtener una dosis de crack por tan solo dos dólares y medio. Nunca antes ningún tipo de cocaína había estado disponible a un precio tan bajo y con tal nivel de pureza y, lo que es más importante desde un punto de vista comercial, el crack producía un efecto inmediato y sus consumidores se convertían en adictos en muy poco tiempo. 

El crack comenzó a consumirse a gran escala por primera vez en Los Ángeles en 1984. Se produjo un aumento masivo de la distribución y consumo de la droga ese mismo año y a finales de 1986 estaba disponible en 28 estados y en el Distrito de Columbia, incluyendo los barrios de las principales ciudades del país. 

En 1986, los casos de urgencias hospitalarias relacionadas con la cocaína se incrementaron en un 110 %, desde los 26.200 hasta los 55.200. Entre 1984 y 1987, los incidentes relacionados con la cocaína se cuadruplicaron en Estados Unidos. El Estado respondió a la epidemia con medidas disuasorias: se promulgó la «Anti-Drug Abuse Act», una nueva ley federal que estipulaba que cualquier detenido por posesión de cinco gramos de crack tendría una condena mínima sin libertad condicional de cinco años de cárcel; esta ley estableció una disparidad de 1 a 100, ya que era la misma condena que se estipulaba para detenidos por posesión de 500 gramos de cocaína. En 1987, podía encontrarse crack en el Distrito de Columbia y en todos los estados de los Estados Unidos, exceptuando tan solo cuatro de ellos. Sin embargo, algunos expertos citaron la «epidemia de crack» como un ejemplo de pánico moral y han apuntado que el boom producido en el uso y tráfico de la droga ocurrió realmente después de que la cobertura mediática de la droga la calificara como «epidemia». En 1996, Gary Webb y sus artículos en el "San Jose Mercury News" causaron una gran polémica en Estados Unidos cuando aseguró que las autoridades estadounidenses habían ayudado en la expansión de la epidemia con fines políticos, escribió: «durante la mayor parte de la década, dentro del anillo de droga del área de San Francisco, se vendieron toneladas de cocaína a bandas callejeras como los Crips y los Bloods, que reportaron millones de dólares en ganancias que fueron canalizados a un ejército guerrillero latinoamericano ["la Contra nicaragüense"] dirigido por la Agencia Central de Inteligencia de Estados Unidos (CIA). Esto abrió la primera línea de cooperación entre los cárteles de cocaína de Colombia y los barrios negros de Los Ángeles, lo que los inundó de cocaína y ayudó a propagar la epidemia de crack en la América urbana». Aunque encontraron el apoyo de otros autores, sus investigaciones fueron muy contestadas y desmentidas por distintos órganos gubernamentales.

A partir de entonces el fenómeno ha seguido extendiéndose. La mayoría de los consumidores de crack europeos se encuentran en tres ciudades: Hamburgo, Londres y París, además en otros países el consumo de esta droga ilegal es un problema de salud pública, como en Brasil, considerado el mayor consumidor del mundo, con 370.000 adictos solo en las capitales de las provincias del país en 2013 y estimaciones de un millón de adictos en todo el país en 2017.



</doc>
<doc id="41256" url="https://es.wikipedia.org/wiki?curid=41256" title="Metanfetamina">
Metanfetamina

La metanfetamina (desoxiefedrina) es un potente psicoestimulante. Es un agente agonista adrenérgico sintético, estructuralmente relacionado con el alcaloide efedrina y con la hormona adrenalina. El compuesto es un líquido aceitoso a temperatura ambiente, insoluble en agua. El hidrocloruro de metanfetamina se presenta como cristales blancos, muy solubles en agua o etanol.

Fue sintetizada en Japón, en 1919, tomando como modelo la molécula de anfetamina. Sin embargo, sólo comenzó a comercializarse en 1938 con el nombre de "Methedrina". Originalmente se utilizaba en descongestivos nasales e inhaladores bronquiales.

En la Alemania del Partido Nazi, se vendía la metanfetamina sin receta, bajo el nombre comercial "Pervitin". Durante la Segunda Guerra Mundial fue utilizada tanto por los Aliados como por el Eje para estimular a sus tropas.

En 1971, la Convención sobre sustancias psicotrópicas sometió a control la metanfetamina, ubicándola en la Lista II (Schedule II), por lo que su circulación se vio drásticamente reducida, pero continuó siendo legal.

En la actualidad, este estatus sigue siendo válido (aunque solo sea nominalmente) en la mayoría de los países. En el Reino Unido la forma oral está en "Lista II" ("Clase B", en su legislación).

Aunque la estructura química de la metanfetamina es similar a la de la anfetamina, sus efectos sobre el sistema nervioso central son más pronunciados. La molécula de metanfetamina tiene la habilidad de cruzar muy fácilmente la barrera hematoencefálica. Esta habilidad permite que los niveles de sustancia en el cerebro alcancen unas 10 veces los niveles en sangre, logrando ejercer su acción casi exclusivamente sobre el sistema nervioso central.

La metanfetamina está indicada en el tratamiento de la narcolepsia, del desorden caracterizado por déficit de atención y también en el control de la obesidad. El último uso, aunque vigente, es poco aceptado en la actualidad; las indicaciones para narcolepsia y TDAH son reconocidas como terapéutica de segunda línea.

Como ya se ha mencionado, la metanfetamina es un estimulante incluido por la "Convención Internacional de Psicotrópicos" en la "Lista II" ("Schedule II"), lo cual significa que la droga tiene un alto potencial de adicción y solo es accesible por medio de recetas médicas oficiales, que no se pueden renovar.

La metanfetamina es un estimulante conocido por su reputación de ser una droga altamente adictiva y dañina. Como la anfetamina, esta droga incrementa la actividad, reduce el apetito y produce una sensación general de bienestar. Excita receptores neuronales vinculados a las señales de recompensa y gratificación: produce euforia, alivia la fatiga y mejora el rendimiento en tareas simples.
Se fabrica en laboratorios clandestinos usando procedimientos sencillos y reactivos relativamente baratos, generalmente de fácil acceso. Por esta causa, sobre todo en Estados Unidos, se han establecido normas legales sobre una serie de sustancias químicas que pueden servir como precursores o reactivos en la síntesis de esta droga, por ejemplo la efedrina. Estos factores se combinan para hacer de la metanfetamina una droga de gran circulación, cuyo abuso está muy extendido en Estados Unidos y en varios países de Europa.

El producto vendido en la calle se conoce por muchos nombres como «anfetas», «meta» y «tiza» en español (o bien: "meth" y "crank", en inglés). El clorhidrato de metanfetamina consiste en pedazos de cristales transparentes parecidos al hielo, que al moler estos cristales se pueden inhalar o bien fumarlos mezclándolos con bromo y bario. En esta forma, se conoce como «hielo», «cristal», «crico» y «vidrio».

Los efectos de la metanfetamina pueden durar hasta 6 o 12 horas. Los adictos a esta sustancia, pueden permanecer despiertos durante varios días. Esto genera un creciente agotamiento físico, psicológico y cognitivo, que, a la larga, degenera en problemas cardiovasculares graves. La droga bloquea las señales somáticas (como fatiga, sueño, hambre) que advierten sobre el deterioro funcional progresivo. En estos casos, una vez que la droga abandona el organismo, estos sujetos pueden experimentar estados de gran agitación psicomotriz, a veces asociados con comportamientos violentos y delirios persecutorios, llegando a cuadros de disociación psíquica apenas distinguibles de los que caracterizan a una esquizofrenia de tipo paranoide. Estas manifestaciones psiquiátricas de toxicidad se producen por sobredosificación y en casos de adicción crónica a dosis altas (especialmente por vía parenteral); estos casos se denominan "psicosis anfetamínicas" en la práctica clínica.

Otro problema que acarrea el consumo de la metanfetamina es la llamada «boca metanfetamínica», nombre dado al deterioro de los dientes provocado por los largos periodos de sequedad bucal y pobre higiene oral durante los periodos de consumo intenso. A estas causas se añade que, debido a la supresión de apetito, los usuarios consumen bebidas carbonatadas y altamente endulzadas, lo cual deteriora aún más los dientes, llevando a los usuarios a describir sus dientes como «ennegrecidos», «podridos» o «cayéndose a pedazos».



En español:
En inglés:


</doc>
<doc id="41258" url="https://es.wikipedia.org/wiki?curid=41258" title="Droga disociativa">
Droga disociativa

Las drogas como el PCP (clorhidrato de fenciclidina, "polvo de ángel") y la ketamina, inicialmente desarrollados como anestésico general para cirugía, distorsionan las percepciones visuales y auditivas y producen sentimientos de aislamiento o disociación del medio y del propio individuo. Por esta razón, el PCP y la Ketamina se conocen como "anestésicos disociativos".

El dextrometorfano, un supresor de la tos ampliamente disponible, en dosis altas, puede producir efectos similares a aquellos del PCP y de la ketamina. Otro disociativo es el muscimol, presente en el hongo "Amanita muscaria".

Las drogas disociativas actúan alterando la distribución del neurotransmisor glutamato a través del cerebro. El glutamato está involucrado en la percepción del dolor, las respuestas al ambiente, y la memoria. El PCP se considera la droga disociativa típica, y la descripción de los efectos y acciones del PCP que aparecen aquí también se aplican en gran medida a la ketamina y al dextrometorfano.



</doc>
<doc id="41259" url="https://es.wikipedia.org/wiki?curid=41259" title="Inhalante">
Inhalante

Los inhalantes son sustancias volátiles que producen vapores químicos que pueden ser inhalados para provocar un efecto psicoactivo o un estado de alteración mental. 

A pesar de que otras sustancias pueden ser inhaladas, el término "inhalantes" se puede utilizar para describir una variedad de sustancias cuya característica común es que rara vez o nunca son usadas por otra ruta que no sea por la de inhalación. Esta definición abarca una amplia gama de químicos encontrados en cientos de productos diferentes que pueden tener diversos efectos farmacológicos. Como resultado, es difícil lograr una clasificación precisa de los inhalantes. Un sistema de clasificación nombra cuatro categorías generales de inhalantes, es como 
disolventes volátiles, aerosoles, gases y nitritos– basándose en la forma en que estos a menudo se encuentran en los productos domésticos, industriales y médicos. Las personas que consumen este tipo de drogas corren especialmente el riesgo de morir debido a ciertos riesgos que presenta el consumo de estas sustancias. Hay tres formas "básicas" de consumirlas (inhalándolas, calentándolas o poniendo directamente el producto en un recipiente).

Los disolventes volátiles son líquidos que se vaporizan a temperaturas ambientales. Se encuentran en una variedad de productos económicos y fácilmente obtenibles, de uso común doméstico e industrial. Estos incluyen los diluyentes y removedores de pinturas, líquidos para lavado en seco, quita-grasas, gasolinas, pegamentos, líquidos correctores y los líquidos de los rotuladores con punta de fieltro.
El pegamento de neopreno es un inhalante bien conocido, con efectos que van desde una intoxicación e intensa euforia a alucinaciones vívidas, según la sustancia y la dosis. Algunos usuarios de inhalantes se lesionan debido a los efectos nocivos de los disolventes o gases o debido a otros productos químicos utilizados en los productos que están inhalando. Al igual que con cualquier droga recreativa, los usuarios pueden sufrir lesiones debido a un comportamiento peligroso mientras están intoxicados, como conducir bajo los efectos. En algunos casos, los usuarios han muerto de hipoxia (falta de oxígeno), neumonía, insuficiencia cardíaca o paro, o aspiración de vómito. El daño cerebral generalmente se observa con el uso crónico a largo plazo de solventes en lugar de la exposición a corto plazo.
Aunque los adhesivos de contacto son legales, se han tomado acciones legales en algunas jurisdicciones para limitar el acceso de menores. Si bien el pegamento solvente es normalmente un producto legal, un tribunal escocés ha dictaminado que suministrar pegamento a los niños es ilegal si la tienda sabe que los niños tienen la intención de abusar del pegamento. En los EE. UU., Treinta y ocho de los 50 estados han promulgado leyes que hacen que varios inhalantes no estén disponibles para los menores de 18 años, o que hacen que el uso de inhalantes sea ilegal.

Los aerosoles son rociadores que contienen propulsores y disolventes. Estos incluyen las pinturas pulverizadas, atomizadores para desodorantes y fijadores de cabello, rociadores de aceite vegetal para cocinar y rociadores para proteger tejidos.

Entre los gases tenemos las anestesias médicas así como gases que se utilizan en productos domésticos o comerciales. Los gases de las anestesias médicas incluyen el éter, cloroformo, halotano y óxido nitroso, comúnmente conocido como gas hilarante. Entre estos, el óxido nitroso es el gas más abusado y puede ser encontrado en los dispensadores de crema batida y productos que incrementan los octanajes en vehículos de carreras. Entre los productos caseros y comerciales que contienen gases están los encendedores de butano, tanques de gas propano, dispensadores de crema batida y refrigerantes.

A menudo se considera a los nitritos como una clase especial de inhalantes. A diferencia de la mayoría de los demás inhalantes que actúan directamente sobre el sistema nervioso central (SNC), los nitritos esencialmente dilatan los vasos sanguíneos. Los nitritos incluyen el nitrito ciclohexílico, nitrito isoamílico (amílico) y nitrito isobutílico (butilo). El nitrito ciclohexílico se encuentra en los perfumes ambientales. El nitrito amílico se utiliza en ciertos procedimientos de diagnóstico y se les prescribe a algunos pacientes para dolores del corazón.

Asimismo, mientras que los otros inhalantes se utilizan para alterar el estado de ánimo, los nitritos se usan principalmente para intensificar el placer sexual. En la calle, se le da el nombre de "poppers" ("reventadores") o "snappers" ("crujidores") a las ampollas de nitrito de amilo cuyo uso se ha desviado ilegalmente en esa dirección. El nitrito de butilo es una sustancia ilegal que frecuentemente se empaca y se vende en pequeñas botellas que también se conocen como "poppers".

La inhalación de los denominados "poppers" conlleva un gran peligro en combinación con drogas estimulantes ("speed", cocaína), y puede afectar muy gravemente la salud, en caso de padecer anemia o en caso de embarazo.




</doc>
<doc id="41260" url="https://es.wikipedia.org/wiki?curid=41260" title="Opioide">
Opioide

Un opioide es cualquier agente endógeno o exógeno que se une a receptores opioides situados principalmente en el sistema nervioso central y en el tracto gastrointestinal. 

Aunque el término opiáceo es frecuentemente utilizado para referirse a todas las drogas similares al opio, es más apropiado limitar su alcance a los alcaloides naturales del opio y a sus derivados semi-sintéticos. Hay tres grandes clases de sustancias opiáceas: alcaloides del opio, tales como morfina (el opiáceo prototípico) y codeína; opioides semi-sintéticos, tales como heroína y oxicodona; y opioides completamente sintéticos, tales como petidina y metadona, que tienen una estructura no relacionada con los alcaloides del opio. El término opioide se refiere únicamente a las sustancias endógenas y exógenas con afinidad por estos receptores, como las endorfinas, las encefalinas o las dinorfinas.

Los opiáceos se recetan frecuentemente por sus propiedades efectivas analgésicas de aliviar el dolor.

Los opioides se unen a receptores opioides específicos en el sistema nervioso y otros tejidos. Existen tres clases principales de receptores opioides: μ, κ, y δ (mu, kappa y delta), aunque se han descrito más de diecisiete, incluyendo los receptores ε, ι, λ, y ζ (épsilon, iota, lambda y zeta). Por el contrario, los receptores σ (Sigma) actualmente no son considerados como opioides debido a que su activación no está reservada al agonista inverso del opioide naloxona, no muestran alta afinidad por los opioides clásicos, y son estereoselectivos para los isómeros dextro-rotatorios, mientras que los otros receptores opioides son estereoselectivos para isómeros levo-rotatorios.

Además, hay tres subtipos de receptores μ: μ y μ, y el recientemente descubierto μ. Otro receptor de importancia clínica es el receptor similar a receptores opioides 1 (ORL1), el cual está relacionado con las respuestas del dolor y el desarrollo de tolerancia a los agonistas opioides μ usados como analgésicos. Son todos ellos receptores ligados a proteína Gi/o los cuales inhiben la adenilatociclasa y disminuyen la producción de AMPc, además promueven la apertura de canales de Potasio y el cierre de canales de calcio presinapticos, todas estas acciones en conjunto disminuyen la excitabilidad neuronal.

Los medicamentos que pertenecen a esta clase (también conocidos como narcóticos) incluyen la morfina, la codeína ("metilmorfina") y la heroína ("diacetilmorfina"); la heroína es de estas tres la que tiene mayor afinidad por los receptores endorfínicos, por lo que es más potente que la morfina; no obstante, entró rápidamente en desuso en la práctica médica, por tener un perfil de seguridad muy desventajoso y por su mayor potencial de abuso. La morfina se utiliza a menudo como analgésico para aliviar el dolor intenso tras la cirugía o el dolor oncológico intenso. La codeína, por ser menos eficaz que la morfina, se utiliza para dolores menos agudos. Otros ejemplos de opiáceos que se recetan para aliviar el dolor incluyen buprenorfina, oxicodona ("OxyContin"), propoxifeno ("Darvon"), hidrocodona ("Vicodin") e hidromorfona ("Dilaudid"), así como la petidina ("Demerol") que se usa menos debido a sus efectos secundarios. Además de sus propiedades analgésicas, algunas de estas drogas, por ejemplo, la codeína y el difenoxilato ("Lomotil"), pueden ser utilizadas para aliviar la tos y la diarrea. 
Los derivados mórficos: Fentanilo, Alfentanilo, Sufentanilo son potentes analgésicos que se utilizan durante la cirugía. Actualmente existe el Remifentanilo, que es un potente opiáceo de vida media muy corta está siendo utilizado cada vez más durante los actos anestésicos. En veterinaria son utilizados la etorfina, el carfentanilo y el tiafentanilo, especialmente en especies de fauna silvestre y de zoológico, todos ellos reversibles con naltrexona, diprenorfina o naloxona; el uso de estos fármacos en este tipo de animales se justifica porque la reversión se logra en escasos minutos y con una gran seguridad para el animal y las personas que realizan el procedimiento.

Antiguamente los opiáceos recibieron otras denominaciones:



El conocimiento de los efectos del opio y su uso con finalidades terapéuticas, se remonta tiempo atrás, ya que los datos más claros tienen lugar a partir de los siglos III y IV antes de Cristo: Hipócrates (460-366 a. C.) se refiere a sus propiedades analgésicas con el lema ""Divinum opus est sedare dolores"".

Se lo consideró siempre como una medicación casi milagrosa, llegándose Paracelso a considerarlo la "piedra de la inmortalidad".

En 1660, Thomas Sydenham elaboró la tintura de opio que lleva su nombre (Láudano de Sydenham), acuñando la célebre frase : ""entre los remedios que Dios todopoderoso se ha dignado dar al hombre para aliviar sus sufrimientos, ninguno es tan universal y eficaz como el opio"".

Pero el desarrollo más significativo en la historia del uso del opio, aconteció cuando en 1803, F.W. Sertümer -- químico alemán -- logra aislar el alcaloide principal del opio, denominándolo morfina, en relación con Morfeo, el mitológico Dios de los sueños.

A partir de este descubrimiento, rápidamente acontecieron otros: la codeína en 1832 por Robiquet, la papaverina por Merck en 1848. Comienza entonces a partir de allí a difundirse en el mundo médico el uso de los alcaloides puros en reemplazo de los preparados del opio.




</doc>
<doc id="41261" url="https://es.wikipedia.org/wiki?curid=41261" title="Comunidad terapéutica">
Comunidad terapéutica

La comunidad terapéutica (CT) para el tratamiento del abuso y adicción a las drogas ha existido por alrededor de 40 años en los Estados Unidos. En general, las CT son ambientes residenciales libres de droga que usan un modelo jerárquico con etapas de tratamiento que reflejan niveles cada vez mayores de responsabilidad personal y social. Se utiliza la influencia entre compañeros, mediada a través de una variedad de procesos de grupo, para ayudar a cada persona a aprender y asimilar las normas sociales y desarrollar habilidades sociales más eficaces.
Las CT difieren de otros enfoques de tratamiento principalmente en su uso de la comunidad, compuesta por el personal de tratamiento y aquellos en recuperación, como agentes claves del cambio. Este enfoque a menudo se conoce como "la comunidad como método". Los miembros de la CT interactúan en maneras estructuradas y no estructuradas para influir en las actitudes, percepciones y comportamientos asociados con el uso de drogas.

Muchas de las personas admitidas a las CT tienen una historia de funcionamiento social, habilidades educativas/vocacionales, y lazos comunitarios y familiares positivos que han sido debilitados por su abuso de drogas. Para ellos, la recuperación involucra la rehabilitación, es decir, el volver a aprender o restablecer un funcionamiento, habilidades y valores saludables así como rescatar la salud física y emocional. Otros residentes de las CT nunca tuvieron estilos de vida funcionales. Para ellos, la CT generalmente constituye la primera vez que son expuestos a una vida ordenada. En su caso, la recuperación involucra la habilitación, es decir, aprender por primera vez las habilidades conductuales, las actitudes y valores asociados a convivir en una sociedad.

Además de la importancia de la comunidad como el agente primario del cambio, un segundo principio fundamental de las CT es la "auto-ayuda". La auto-ayuda implica que las personas en tratamiento son los principales contribuyentes al proceso de cambio. La "auto-ayuda mutua" significa que las personas también asumen una responsabilidad parcial en la recuperación de sus compañeros, un aspecto importante del propio tratamiento de la persona.


</doc>
<doc id="41262" url="https://es.wikipedia.org/wiki?curid=41262" title="Mezzosoprano">
Mezzosoprano

Mezzosoprano o mesosoprano es la voz media que se encuentra por debajo de la soprano y por encima de la contralto. 

El término se usa también para designar a la persona que canta con esta voz. Se trata de un término italiano, que significa medio-soprano o casi-soprano. Se considera que la voz de soprano se encuentra englobada dentro de la voz de mezzosoprano. Esta situación superalto, en lugar de ser un inconveniente, le permite acometer ornamentos vocales muy complicados. Es una voz de timbre rotundo y ligeramente más grave que la de la soprano.

Según el "Harvard Dictionary of Music", la tesitura de mezzosoprano se extiende desde un "la" a un "fa".

La "mezzosoprano ligera" es casi equivalente a la "soprano dramática", pero con más agilidad. Debe estar capacitada para resolver ornamentos auténticamente virtuosos.

La "mezzosoprano lírica" es una voz con los graves reforzados, equiparable a la "soprano lírica", con capacidad para vibrato rápido y perfectamente controlado y la agilidad en las escalas y arpegios. A las mezzosopranos líricas con un repertorio especializado en las óperas de Rossini, también se las denomina como mezzosopranos rossinianas, aunque interpreten papeles de otros compositores. Ejemplos de mezzosopranos líricas son: la letona Elīna Garanča (El barbero de Sevilla), la española Conchita Supervía (como Rosina en "El barbero de Sevilla" de Rossini), las también españolas Teresa Berganza (como Sesto en "La clemenza di Tito" de Mozart) y Maria Elena Iglesias (como Flora Bervoix en "La Traviata" de Verdi), la italiana Cecilia Bartoli (como la Cenicienta en "La Cenerentola" de Rossini), la estadounidense Frederica von Stade, Marilyn Horne que revivió las óperas de Rossini.

La "mezzosoprano dramática" es una voz mucho más potente, está muy cercana a la soprano Falcon francesa. Ejemplos de mezzosoprano dramática son Grace Bumbry como la "princesa Eboli" en "Don Carlos", de Verdi, Fiorenza Cossotto, Shirley Verrett, Yelena Obraztsova, Rita Gorr, Giulietta Simionato, Dolora Zajick, Olga Borodina, Waltraud Meier, Christa Ludwig y Stephanie Blythe.

En el repertorio de la mezzosoprano se encuentran los siguientes roles dramáticos: 





</doc>
<doc id="41269" url="https://es.wikipedia.org/wiki?curid=41269" title="Riñón">
Riñón

Los riñones son los órganos principales del sistema urinario humano. Se encargan de la excreción de sustancias de desecho a través de la orina y cuentan con otras funciones muy importantes, entre ellas la regulación del equilibrio del medio interno del organismo (homeostasis), controlando el volumen de los líquidos extracelulares, la osmolaridad del plasma sanguíneo, el balance de electrolitos y el pH del medio interno. Además el riñón fabrica hormonas como la eritropoyetina que regula la producción de glóbulos rojos de la sangre y la renina que regula la presión arterial.

Los riñones en el ser humano están situados en la parte posterior del abdomen. Hay dos, uno a cada lado de la columna vertebral. El riñón derecho descansa detrás del hígado y el izquierdo debajo del diafragma y adyacente al bazo, separados de estos órganos por el peritoneo parietal posterior. Sobre cada riñón hay una glándula suprarrenal. La asimetría dentro de la cavidad abdominal causada por el hígado, da lugar a que el riñón derecho esté ligeramente más bajo que el izquierdo. Los riñones están situados detrás del peritoneo, en el retroperitoneo, se ubican entre la última vértebra torácica, y las tres primeras vértebras lumbares (de T12 a L3). Los polos superiores de los riñones están protegidos, parcialmente, por las costillas 11 y 12. Cada riñón está rodeado por dos capas de grasa (perirrenal y pararrenal) que ayudan a protegerlos. 

El peso de los riñones equivale al 1 % del peso corporal total de una persona. Los riñones tienen un lado cóncavo y otro convexo. En la porción cóncava que mira hacia adentro hay una región central llamada hilio por la cual entra en el riñón la arteria renal y sale la vena renal y el uréter.

En el riñón humano pueden distinguirse dos áreas diferenciadas, una zona externa de color más claro que se llama corteza y otra interna que recibe el nombre de médula renal. La médula renal contiene entre 8 y 18 estructuras de forma cónica que se llaman pirámides renales. En el vértice de cada pirámide se encuentra la papila renal muy próxima al hilio. Del hilio renal parte el uréter por el cual la orina transita hasta la vejiga urinaria desde donde se vierte al exterior a través de la uretra.

Cada riñón recibe su flujo de sangre de una de las dos arterias renales que parten desde la aorta abdominal. La irrigación sanguínea de los dos riñones en condiciones normales corresponde aproximadamente al 22% del gasto cardíaco, el suministro de sangre a los riñones está íntimamente ligado a la presión arterial. 

Al entrar en el hilio del riñón, la arteria renal se divide en arterias segmentarias que se ramifican en arterias interlobulares más pequeñas situadas entre las papilas renales que dan lugar a las arterias arciformes, que transcurren a lo largo del límite entre la médula y la corteza renal. Las arterias arciformes emiten ramas más pequeñas llamadas arterias corticales radiales o arterias interlobulillares. Las ramificaciones de estas arterias corticales son las arteriolas aferentes que forman los capilares glomerulares que drenan en las arteriolas eferentes. Las arteriolas eferentes se dividen en los capilares peritubulares que proporcionan sangre a la corteza y los vasa recta que son capilares que aportan la sangre a la médula renal. El retorno venoso sigue un camino inverso al arterial a través de las venas interlobulillares, venas arciformes y venas interlobulares que finalmente drenan en la vena renal.

Es la parte externa del riñón y tiene aproximadamente 1 cm de grosor, de coloración rojo parduzca y fácilmente distinguible al corte de la parte interna o medular. Forma un arco de tejido situado inmediatamente bajo la cápsula renal. La corteza renal contiene el 75 % de los glomérulos y los túbulos proximales y distales. Recibe el 90 % del flujo sanguíneo renal y su principal función es la filtración, la reabsorción y la secreción.

La médula renal está compuesta por entre 8 y 18 formaciones cónicas que reciben el nombre de pirámides renales o pirámides de Malpighi. La amplia base de cada pirámide hace frente a la corteza renal, y su ápice, o papila, apunta internamente, descargando en el cáliz menor, el cual a modo de embudo confluye en la pelvis renal. Las pirámides parecen rayadas porque están formadas por segmentos paralelos rectos de túbulos renales. Entre una pirámide renal y otra se encuentran las columnas de Bertin, estructuras que están compuestas por el mismo tejido que la corteza renal, sin embargo por su situación se consideran parte de la médula.

A nivel microscópico, el riñón está formado por entre de unidades funcionales, que reciben el nombre de nefronas. Es en la nefrona donde se produce realmente la filtración del plasma sanguíneo y la formación de la orina; la nefrona es la unidad básica constituyente del órgano renal. En cada riñón existen 250 conductos colectores, cada uno de los cuales recoge la orina de 4000 nefronas.

La estructura de la nefrona es compleja, se compone de un corpúsculo renal en comunicación con un túbulo renal. El corpúsculo renal es una estructura esferoidal, constituida por la cápsula de Bowman y el ovillo capilar contenido en su interior o glomérulo. El túbulo donde se vierte el filtrado glomerular se divide en tres partes: túbulo contorneado proximal, asa de Henle y túbulo contorneado distal.

La función de la nefrona está dividida en tres pasos fundamentales:




El aparato yuxtaglomerular es una pequeña estructura que se encuentra situada en cada una de las nefronas entre la arteriola aferente y eferente, junto al túbulo contorneado distal. Está formado por las células yuxtaglomerulares que segregan renina, las células de la mácula densa y las células de Goormaghtigh o células mesangiales extraglomerulares.

El filtrado glomerular fluye desde el túbulo contorneado distal de la nefrona al sistema de conductos colectores del riñón. Cada tubo colector recibe como afluentes los túbulos contorneados distales de las nefronas próximas. Los tubos colectores se agrupan entre ellos dando origen a conductos cada vez más gruesos que finalmente desembocan en la papila renal, donde pasan a llamarse conductos de Bellini o conductos papilares. En los conductos colectores actúa la hormona antidiurética aumentando la permeabilidad al agua y facilitando su reabsorción, concentrando la orina cuando es necesario.

Los riñones filtran la sangre del aparato circulatorio y eliminan mediante la orina los residuos metabólicos del organismo, entre ellos urea, ácido úrico, creatinina, potasio y fósforo. La producción de orina tiene lugar a través de un complejo sistema que incluye mecanismos de filtración, reabsorción y secreción. Diariamente los riñones producen unos 180 litros de filtrado glomerular que se concentran en únicamente 1 o 2 litros de orina. La orina baja continuamente desde el riñón a través de los ureteres hasta la vejiga urinaria, donde se almacena hasta el momento de su expulsión al exterior a través de la uretra.


Casi todas las enfermedades del riñón actúan sobre las nefronas y les hacen perder su capacidad de filtración, proceso denominado insuficiencia renal. La insuficiencia renal puede suceder rápidamente, a menudo como resultado de un traumatismo de riñón o intoxicación, pero casi todas las patologías del riñón destruyen las nefronas lenta y silenciosamente, provocando insuficiencia renal crónica que se agrava progresivamente durante años o décadas. Las dos causas más comunes de insuficiencia renal crónica son la diabetes y la hipertensión. Las especialidades médicas que estudian los riñones y las enfermedades que le afectan son la nefrología y la urología.


Los invertebrados pueden poseer órganos excretores que se denominan a veces como "riñones", pero, incluso en Amphioxus, estos nunca son homólogos con los riñones de los vertebrados, y se conocen con mayor precisión por otros nombres, tales como nefridios.

En la mayoría de los vertebrados, el riñón primitivo (mesonefros) persiste en el adulto, aunque generalmente fusionado con el metanefros; en los amniotas sin embargo, el mesonefros solo existe en el embrión.

En los vertebrados más primitivos, el pez bruja y lampreas, el riñón es extraordinariamente sencillo: consiste en una fila de nefronas, cada una de ellas vacía directamente en el conducto de Wolff.

Los riñones de peces y anfibios son típicamente órganos estrechos, alargados, que ocupan una parte importante del tronco. Los conductos colectores de cada grupo de nefronas por lo general desembocan en el conducto de Wolff. Sin embargo, la situación no siempre es tan sencilla; en peces cartilaginosos y algunos anfibios, hay también un conducto más corto, similar al uréter amniote, que drena las partes posterior (metanéfrico) del riñón, y se une con el conducto de Wolff en la vejiga o la cloaca. De hecho, en muchos peces cartilaginosos, la porción anterior del riñón puede degenerar o dejar de funcionar por completo en el adulto.

Los riñones de reptiles consisten en un número de lóbulos dispuestos en un patrón ampliamente lineal. Cada lóbulo contiene una sola rama del uréter en su centro. Los reptiles tienen relativamente pocas nefronas en comparación con otros amniotas de un tamaño similar, posiblemente debido a su menor tasa metabólica.

Las aves tienen, riñones alargados relativamente grandes, cada una de las cuales se divide en tres o más lóbulos distintos. Los lóbulos se componen de varios lobulillos más pequeños irregularmente dispuestos, cada uno centrado en una rama del uréter. Las aves tienen glomérulos pequeños, pero aproximadamente el doble de nefronas que mamíferos de tamaño similar.

El riñón humano es bastante similar al de otros mamíferos. Las características distintivas del riñón de mamífero, en comparación con la de otros vertebrados, incluyen la presencia de pelvis renal, pirámides renales, y una corteza renal claramente distinguible de la médula. Esta última característica se debe a la presencia de asas alargadas de Henle; éstas son mucho más cortos en las aves, y no realmente presente en otros vertebrados. Solamente en los mamíferos el riñón adquiere su clásica forma de habichuela, aunque hay algunas excepciones, como los riñones multilobulados de pinnípedos y cetáceos.


</doc>
<doc id="41270" url="https://es.wikipedia.org/wiki?curid=41270" title="Huelga general">
Huelga general

Una huelga general o paro general es una huelga que afecta simultáneamente a todas las actividades laborales. 

La huelga general es convocada por el movimiento sindical -sindicatos y centrales obreras- y dirigida al conjunto de trabajadores. La convocatoria y participación en la huelga general puede dirigirse exclusivamente a la clase trabajadora o ser más amplia y afectar a otros sectores y organizaciones sociales como estudiantes, parados o desempleados, jubilados, pudiendo recibir apoyo de sectores no tradicionales del movimiento obrero cuando las reivindicaciones afectan a todo el conjunto social: reconversiones económicas, reconversión industrial, deslocalización de empresas, depresiones, crisis económicas y financieras.

El primero en teorizar sobre la huelga general como arma política (la llamó la «gran vacación nacional», "Gran National Holiday", o «gran día sagrado nacional», al descomponer la palabra "holi-day", 'día sagrado') fue el obrero radical británico William Benbow en una obra publicada en 1832 con el título "La gran vacación nacional y el congreso de las clases productoras", que pronto se convirtió en uno de los escritos más difundidos del primer socialismo inglés y en una obra de referencia para el movimiento cartista, en el que Benbow participó activamente.

A finales del siglo XIX, los movimientos obreros internacionales, de creciente influencia, defendieron la huelga general con fines industriales y políticos.

Por lo general en Europa, durante el siglo XIX, la huelga general se usó para demandar derechos políticos (sufragio universal) o sociales (legislación social y la reconocimiento legal de las organizaciones obreras). Dentro de la izquierda política la huelga general era también considerada como el elemento que iniciaría la revolución social, al paralizar la actividad del Estado e implementar el control obrero de la producción y la administración estatal. Georges Sorel fue el principal teórico de esta forma de acción. En "Reflexiones sobre la violencia" (1908), señalando que el mito de la huelga general sirve para reforzar la solidaridad, la conciencia de clase y el espíritu revolucionario en la clase trabajadora. 

Durante los dos primeros siglos de la Revolución industrial, sin embargo, la huelga laboral estuvo severamente penada, y no fue hasta la difusión de la socialdemocracia a comienzos del siglo XX cuando el derecho de huelga fue reconocido internacionalmente como un derecho esencial de los trabajadores constitutivo de la libertad sindical. Se trata de uno de los derechos de segunda generación, que se reconoce en la actualidad en la mayoría de los ordenamientos internos y en tratados internacionales de alcance universal como el Pacto Internacional de Derechos Económicos, Sociales y Culturales.
Salvo en algunos negocios informales, su ausencia fue notable en calles, escuelas, oficinas, transporte, bancos, medios de comunicación y otros espacios.

Este paro se realizó apenas un día después de la marcha por el Día Internacional de la Mujer que contó con la participación de miles de mujeres –80 mil la cifra oficial, más de 200 mil según las organizadoras-.
El movimiento en contra de la violencia de género #UnDíaSinMujeres o #UnDíaSinNosotras, en principio, fue rechazado por algunas empresas y negocios bajo el argumento de que habría pérdidas por más de 37 mil millones de pesos. Pero, al paso de los días, fue creciendo y se sumaron instituciones públicas y privadas.

El presidente de México, Andrés Manuel López Obrador, celebró este lunes la libre manifestación en la multitudinaria marcha de mujeres del domingo 8.
Ninguna mujer salió, algunas que estuvieron en desacuerdo con el paro nacional salieron a trabajar y ofendieron, expresaron sus opiniones a este paro nacional






</doc>
<doc id="41274" url="https://es.wikipedia.org/wiki?curid=41274" title="Cálculo renal">
Cálculo renal

Los términos cálculo renal, nefrolitiasis, litiasis renal, piedra en el riñón y la antigua denominación mal de piedra se refieren a la formación de un trozo de material sólido compuesto de sales de fosfato y carbonato cálcico o úricas, dentro del riñón a partir de sustancias que están en la orina. Una piedra pequeña puede pasar sin causar síntomas. Si un cálculo crece a más de 5 milímetros (0,2 pulgadas), puede causar un bloqueo del uréter, lo que provocará un dolor intenso en la parte inferior de la espalda o el abdomen. Un cálculo también puede producir sangre en la orina, vómitos o dolor al orinar. Alrededor de la mitad de las personas que sufrieron de un cálculo renal tendrán otro en los próximos diez años.

La mayoría de los cálculos se forman debido a una combinación de factores genéticos y ambientales. Los factores de riesgo incluyen niveles altos de calcio en la orina; obesidad; ciertos alimentos; algunos medicamentos como los suplementos de calcio; hiperparatiroidismo; gota y la ingesta insuficiente de líquidos.

Entre el 1% y el 15% de las personas a nivel mundial se ven afectadas por cálculos renales en algún momento de sus vidas. La frecuencia de nefrolitiasis por sexo es de un 13 % para el hombre y 7 % para la mujer. Estos suelen ser de calcio o niacina por lo cual se puede obtener un mayor riesgo.


Es el tipo de piedra más común. El calcio es un mineral que forma parte de nuestra dieta normal. El calcio que no se necesita para los huesos y los músculos pasa a los riñones. En la mayoría de las personas, los riñones eliminan ese calcio que sobra junto con el resto de la orina. Las personas que forman piedras de calcio retienen ese calcio en los riñones. El calcio que no se elimina se une a otros desperdicios para formar una piedra.

La nefrolitiasis por cálculos de sales de calcio representan entre el 75 % y el 85 % de todos los tipos, es más frecuente en varones; y los tipos de sales son las de oxalato de calcio y las de fosfato de calcio, esta última puede ser en forma de hidroxiapatita o en forma de brushita.

La edad de inicio de formación de estos cálculos está generalmente entre los 20 y los 39 años de edad.

Se puede formar cuando hay demasiado ácido en la orina (pH < 5,4), debido a un exceso de ácido úrico en la sangre.

Representan entre el 5 % y el 10 % de los casos de nefrolitiasis, y es más frecuente en varones. Las personas con cálculos de ácido úrico pueden tener o no gota, la frecuencia de gota en este grupo es de 50 %.

Son poco comunes. La cistina es una de las sustancias que forman los músculos, nervios y otras partes del cuerpo. La cistina se puede acumular en la orina hasta formar una piedra. La enfermedad que causa la formación de piedras de cistina es hereditaria.

Son muy poco comunes (1 % de las nefrolitiasis) y son el producto de un transporte defectuoso de aminoácidos dibásicos (cisteina → disulfuro de cisteía o cistina y la lisina ornitina, arginina) en el intestino y en los túbulos renales.

También conocida como triple fosfato, puede formarse después de una infección del sistema urinario o por presencia de cuerpos extraños en este sistema. Estas piedras contienen el mineral magnesio y el producto de desperdicio, amoníaco además de fosfato.

Este tipo de piedras es producto de la infección del tracto urinario por bacterias productoras de ureasa como Proteus. producen un cálculo míxto: carbonato de calcio (CaCO3) y estruvita (MgNH4PO4) el cual forma un cristal en forma de «Tapa de féretro» (prismas rectangulares).
Es frecuente en mujeres. Pueden producir una concreción en «asta de ciervo» en el interior de los riñones.

Son de xantinas, iatrogénicos, de silicato (inducido por fármacos como efedrina, o indinavir) y los espurios o falsos.

Los cálculos renales pueden ser tan diminutos como un granito de arena o tan grandes como una perla. Incluso algunas piedras pueden tener el tamaño de una pelota de golf. La superficie de la piedra puede ser lisa o con picos. Por lo general son de color amarillo o marrón.
Es posible que la ingestión de algunas pastillas como L-carnitina o populares preparados vitamínicos con calcio o magnesio ayude a la aparición de las piedras.

Algunos cálculos renales que ocupan el espacio conformado por la pelvis renal adquieren forma de coral o Litiasis coraliforme.





La nefrolitiasis surge al romperse el equilibrio que debe mantener la solubilidad y evitar la precipitación de las sales.
Para que se forme un cálculo se necesita de:

a. Sobresaturación

La sobresaturación se produce cuando la concentración de litogénicos sobrepasa el límite hasta el que la orina puede mantenerlos en solución. Este límite lo determinan muchos factores como el pH y la concentración y la presencia de otros compuestos. Por ejemplo, el calcio con el oxalato y el fosfato con el citrato forman muchas sustancias solubles entre sí, por lo tanto, si disminuyen las concentraciones de citrato en la orina, se produce más sobresaturación, al igual que si disminuye la cantidad de agua en la orina, lo que facilita la formación de cristales.

El pH también influye, porque al aumentar este, aumenta también la cantidad total de fosfato ionizado que se une al Ca+2 y hace que se precipiten cada vez más brushita y apatita. Por el contrario, cuando el pH < 5,5 disminuye la frecuencia de cristales de fosfato, pero se eleva la de los cristales de ácido úrico.

b. Cristalización

Comienza con la formación de núcleos de cristales que pueden ser restos celulares o hasta otros cristales (núcleos heterogéneos).
Estos núcleos se retienen en la pelvis renal; esto es posible a través de las excrecencias o proliferaciones sobre placas de apatita en papilas renales (Placas de Randall).
Las Placas de Randall, que surgen en la membrana basal de la porción fina del asa de Henle, pasan a través del intersticio hacia la membrana basal del endotelio papilar cuando estas células endoteliales son lesionadas. Esto deja expuesta las placas, haciéndolas bases para la cristalización de oxalato de calcio.

Inhibidores de la formación de cristales:

Si son muy pequeños o están en formación, suelen ser asintomáticos. Puede haber eliminación de cálculos generalmente cuando estos son de un diámetro menor que 0,5 cm y producir hematuria (orina con sangre) aisladas.

Los síntomas suelen surgir cuando hay oclusión o cierre de algún uréter o de la unión uretero-pélvica, lo que provoca sus síntomas clásicos:

Si la obstrucción se produce en la porción parietal del uréter en la vejiga, puede producir tenesmo, polaquiuria y disuria. También puede presentarse como un dolor abdominal de inicio agudo de menos de 12 horas de evolución.

Crónicamente favorecen las infecciones urinarias. Pueden dar un dolor silente que se irradia según el lugar donde quedó atrapado el cálculo dentro de la vía urinaria (riñón, uréter, vejiga).

Si se desplaza un cálculo, el espasmo de los músculos y la inflamación causada por el daño al tejido por donde pasa causan un dolor muy intenso tipo puntada, llamado cólico nefrítico.

Si se expulsa parte del cálculo, puede aparecer hematuria (sangre) y disuria.
También al sentir dolor, pueden presentarse náuseas y vómitos reiterados.

Para hacer el diagnóstico, se deberán tomar 2 muestras de orina en 24 horas, cada una con sus respectivas muestras de sangre aparejadas. Una muestra se tomara en un día hábil y otra el fin de semana.
En el análisis del suero sanguíneo interesan: calcio, ácido úrico, electrolitos, creatinina.
En el análisis de orina interesan: pH, volumen, oxalato, citrato.

Deben observarse también la dieta, la actividad y el entorno del paciente.

Debe determinarse la composición del cálculo.

A todo paciente con nefrolitiasis debe indicarse consumir cantidades copiosas de agua y evitar siempre la deshidratación.

Técnicas para la eliminación de cálculos:








</doc>
<doc id="41275" url="https://es.wikipedia.org/wiki?curid=41275" title="Rosalind Franklin">
Rosalind Franklin

Rosalind Elsie Franklin (; Londres, -ibídem, ) fue una química y cristalógrafa británica. Una de los cuatro investigadores descubridores de la estructura molecular del ADN en 1953. Fue responsable de contribuciones imprescindibles para la comprensión de la estructura del ADN (las imágenes por difracción de rayos X que revelaron la forma de doble hélice de esta molécula son de su autoría), del ARN, de los virus, del carbón y del grafito. Sus trabajos acerca del carbón y de los virus fueron apreciados en vida, mientras que su contribución personal a los estudios relacionados con el ADN, que tuvo un profundo impacto en los avances científicos de la genética, no se reconoció de la misma manera que los trabajos de James Dewey Watson, de Francis Crick y de Maurice Wilkins.

Nacida en una prominente familia judía inglesa, Franklin fue educada en una escuela privada en Norland Place, en el oeste de Londres, en la Escuela Lindores para Señoritas en Sussex, y en la Escuela St Paul's para niñas, donde fue sobresaliente en todos los deportes y materias. Fue aceptada en la universidad a los 18 años, y ganó una beca de estudios de 30 libras al año por tres años. Su padre le pidió que donara el dinero a estudiantes refugiados de la segunda guerra mundial. Después estudió Ciencias Naturales en el Newnham College en Cambridge, donde se graduó en 1941. Ganó una beca universitaria en la Universidad de Cambridge, en el laboratorio de fisicoquímica, bajo la supervisión de Ronald George Wreyford Norrish, quien la decepcionó por su falta de entusiasmo. Afortunadamente, la Asociación Británica para la Investigación del Uso del Carbón (BCURA, por sus siglas en inglés) le ofreció una plaza de investigadora en 1942, y fue así como inició su trabajo sobre el carbón. Esto la ayudó a obtener su doctorado en 1945. Fue a París en 1947, como "chercheuse" (investigadora postdoctoral) bajo la supervisión de Jacques Mering en el Laboratorio Central de Servicios Químicos del Estado, donde se convirtió en una consumada cristalógrafa de rayos X. Se unió al King's College de Londres en 1951, pero se vio obligada a mudarse al Birkbeck College pasados únicamente dos años, debido a desacuerdos con su director John Randall y, más aun, con su colega Maurice Wilkins. En Birkbeck, J. D. Bernal, director del Departamento de Física, le ofreció un equipo de investigación por separado. Rosalind Franklin murió de cáncer de ovario a los 37 años de edad.

Franklin tomó las imágenes de ADN por difracción de rayos X durante su estancia en el King's College, en Londres. Estas imágenes, que sugerían una estructura helicoidal y que permitieron generar inferencias sobre detalles claves acerca del ADN, fueron mostradas por Wilkins a Watson. Según Francis Crick, la investigación y datos obtenidos por ella fueron clave para la determinación del modelo de Watson y Crick de la doble hélice del ADN en 1953. Watson confirmó esta opinión a través de una afirmación propia en la inauguración del edificio Franklin-Wilkins en el 2000.

Su trabajo fue el cuarto en publicarse en una serie de tres artículos sobre el ADN en la revista "Nature", el primero de los cuales fue el de Watson y Crick. Watson, Crick y Wilkins compartieron el Premio Nobel de Fisiología y Medicina en 1962. Watson puntualizó que Franklin debió haber sido galardonada también con el Premio Nobel de Química, junto con Wilkins, lo cual era incompatible con las normas del prestigioso premio que no permite que se entregue premios a personas ya fallecidas.

Una vez concluido su trabajo en el ADN, con su propio equipo en Birkbeck College, Franklin dirigió investigaciones acerca de las estructuras moleculares de los virus, que llevó a descubrimientos nunca antes vistos. Dentro de los virus que estudió se incluyen el virus de la polio y el virus del mosaico del tabaco. Continuando su investigación, su compañero de equipo y posteriormente beneficiario Aaron Klug ganó el Premio Nobel de Química en 1982.

Franklin nació en 500 Chepstow Villas, en el barrio londinense de Notting Hill, en el seno de una acaudalada e influyente familia judía británica. Sus padres fueron Ellis Arthur Franklin (1894-1964), un banquero mercante con visión política liberal que daba cátedra en el Workings Men's College, y Muriel Frances Waley (1894-1976). Rosalind era la hija mayor y la segunda de una familia de cinco hijos: David (1919), el hermano mayor; Colin (1923), Roland (1926) y Jenifer (1929) eran sus hermanos menores. 

Herbert Louis Samuel, tío de su padre, fue un importante político, ejerciendo como Ministro del Interior en 1916 (siendo el primer judío practicante miembro del gabinete británico) y primer alto comisionado del Mandato Británico de Palestina. Su tía, Helen Caroline Franklin, conocida en la familia como "Mamie", estuvo casada con Norman de Mattos Bentwich, quien fue el procurador general en el Mandato Británico.

Rosalind era activa en organizaciones sindicales y en el movimiento del sufragio femenino, y posteriormente perteneció al . Su tío, Hugh Franklin, fue otra figura prominente del movimiento sufragista, aunque sus acciones en el mismo resultaran motivo de vergüenza para la familia Franklin. Rosalind recibió su segundo nombre, "Elsie", en memoria de la primera esposa de Hugh, quien murió en la pandemia de gripe de 1918. El Working Men's College era sede de actividades de la familia, donde su padre impartía materias como electricidad, magnetismo e historia de la Gran Guerra por las tardes, donde después ocupó el cargo de subdirector. Los padres de Franklin ayudaron al asentamiento de refugiados judíos de Europa, quienes habían escapado de los nazis, particularmente a los del "kindertransport". Los Franklin acogieron a dos niños judíos en su hogar, uno de los cuales, Evi Eisenstädter (quien tenía nueve años de edad y provenía de Austria), compartía habitación con Jenifer. El padre de Evi, Hans Mathias Eisenstädter estuvo encarcelado en Buchenwald, y después de su liberación, la familia adoptó el apellido "Ellis".

Desde su infancia, Franklin demostraba habilidades escolares excepcionales. A los seis años, ingresó a la Escuela Norland Place, donde su hermano ya estudiaba, la cual era privada y se encontraba en la Avenida Holland Park, en el Oeste de Londres. En ese tiempo su tía Mamie (Helen Bentwich) le dijo a su esposo: «Rosalind es inteligente de manera alarmante —pasa todo su tiempo estudiando aritmética por gusto e invariablemente obtiene los resultados correctos de las sumas—». Además, desarrolló interés por el críquet y el "hockey" desde muy joven. A los nueve años fue admitida en un internado, la Escuela Lindores para señoritas en Sussex. La escuela estaba cerca de la costa, pues la familia deseaba un ambiente apropiado para su delicada salud. A los once años la cambiaron a la Escuela St. Paul's para niñas, donde tuvo un desempeño sobresaliente en las ciencias, el latín y los deportes. Además, aprendió alemán y adquirió fluidez en francés, idioma que después le sería útil. Fue la primera en sus clases y ganó premios anuales. Sus únicos problemas académicos estaban relacionados con la música, por lo cual el director de música de la escuela, el compositor Gustav Holst, llamó a su madre en una ocasión, para averiguar si había padecido un problema auditivo o tonsilitis. Con seis distinciones, se matriculó en 1938 y ganó una beca para la universidad, la Beca de Fin de Estudios (School Leaving Exhibition), de 30 libras esterlinas al año durante tres años, cinco libras esterlinas de parte de su abuelo. Su padre le pidió que cediera la beca a un estudiante refugiado que lo mereciera.

Franklin asistió a Newnham College, Cambridge, en 1938 y estudió química dentro del Tripos de Ciencias Naturales. Uno de sus profesores fue el espectroscopista W. C. Price, quien después se convertiría en uno de sus colaboradores principales en el King's College. En 1941, se le otorgaron Honores de Segunda Clase por sus exámenes finales. Aceptó la distinción como un título de licenciatura en aptitudes para su empleo. Cambridge empezó a otorgar títulos de licenciatura y maestría a las mujeres en 1947, y las mujeres que se habían graduado antes los recibieron de manera retroactiva. En su último año en Cambridge, conoció a Adrienne Weill, una refugiada francesa que había sido alumna de Marie Curie; Adrienne fue una gran influencia en su carrera y en su vida. Con ella aprendió a hablar francés.

Franklin ganó una estancia de investigación, con la cual se unió al laboratorio de fisicoquímica de la Universidad de Cambridge para trabajar bajo la supervisión de Ronald Norrish (ganador del Premio Nobel de Química en 1967), donde se dice que «no tuvo éxito». Según su biógrafo, Norrish era «obstinado y casi perverso en las discusiones, prepotente y sensible ante las críticas». Norrish no podía decidir en qué trabajaría Franklin, y en esos momentos solía beber mucho. Franklin escribió que por esas razones lo despreciaba completamente. Renunció al laboratorio de Norrish y cumplió con los requisitos que estipulaba la ley del Servicio Militar Nacional, por lo que en 1942 comenzó a trabajar como oficial asistente de Investigación en la Asociación Británica para la Investigación del Uso del Carbón (BCURA), en Coombe Springs, cerca de Kingston upon Thames, al sudoeste de Londres. Norrish fungía como consejero militar en BCURA. John G. Bennett era el director. Marcello Pirani y Victor Goldschmidt, ambos judíos refugiados de los nazis, eran consultores y profesores en BCURA cuando Franklin asistía. Durante sus investigaciones en BCURA, vivió en la casa de huéspedes de Adrienne Weill, en Cambridge, hasta que su prima Irene Franklin le pidió que se mudara con ella a una casa desocupada perteneciente a su tío en Putney. Con Irene, fue voluntaria como guardiana de ataques aéreos y se encargó de organizar patrullas para salvaguardar el bienestar de las personas durante estos ataques.

Estudió la porosidad del carbón y comparó la densidad del helio. Descubrió la proporción entre las finas constricciones en los poros del carbón y la permeabilidad del espacio poroso. Al concluir que las sustancias eran expulsadas siguiendo un patrón de tamaño molecular, ayudó a clasificar carbones y a predecir con precisión su capacidad para ser utilizados como combustibles y para la producción de aparatos de guerra (por ejemplo, para máscaras de gas). Este trabajo fue la base de su tesis de doctorado (Ph.D.), titulada "La fisicoquímica de coloides orgánicos sólidos con referencia especial al carbón", por la cual recibió el grado en 1945. Su trabajo fue la base para varios artículos.

Con el final de la Segunda Guerra Mundial en 1945, Franklin pidió ayuda a Adrienne Weill para encontrar vacantes de trabajo para «una fisicoquímica que sabe muy poco de fisicoquímica y mucho sobre los hoyos en el carbón». En una conferencia en otoño de 1946, Weill la presentó a Marcel Mathiu, director del Centre national de la recherche scientifique (Centro Nacional para la Investigación Científica), la red de institutos que componen la mayor parte de los laboratorios de investigación respaldados por el gobierno francés. Esto conllevó a una entrevista con Jacques Mering, en el Laboratorio Central de Servicios Químicos del Estado en París. Se integró al equipo de Mering el 14 de febrero de 1947 como una de los 15 investigadores.

Mering fue un cristalógrafo de rayos X que aplicaba la difracción de los mismos al estudio del rayón y de otras sustancias amorfas, en contraste con todos los miles de cristales que se habían estado estudiando con este método durante muchos años. Él le enseñó los aspectos prácticos de la aplicación de cristalografía de rayos X a sustancias amorfas. Esto presentó nuevos retos en el desarrollo de experimentos y en la interpretación de resultados. Franklin los aplicó a problemas relacionados con el carbón, particularmente los cambios en la disposición de los átomos cuando se convierte en grafito. Publicó varios artículos más con respecto a este tema. Esta parte de su trabajo (que aparece descrito en una monografía de 1993, el anual y en otras publicaciones) se convirtió en la base del campo de la física y la química del carbón. Mering también continuó el estudio del carbón en varias formas, utilizando difracción con rayos X y otros métodos.

En 1950, Franklin recibió la beca Turner and Newall por tres años para trabajar en King's College, Londres. En enero de 1951, empezó a trabajar como asociada de investigación en la Unidad de Biofísica del Consejo de Investigación Médica (CIM), dirigida por John Randall. Originalmente, trabajaría en difracción de rayos X aplicada a proteínas y lípidos en solución, pero Randall redirigió su trabajo a fibras de ADN, gracias a los últimos desarrollos en el campo, pues ella era la única investigadora con experiencia en difracción experimental en King's College en ese momento. Randall realizó esta resignación, aun antes de que ella iniciara sus actividades en King's, debido al consiguiente trabajo pionero hecho por Maurice Wilkins y Raymond Gosling, estudiante de doctorado a quien asignaron como su ayudante.

Con un equipo muy poco avanzado, Wilkins y Gosling pudieron obtener una imagen de ADN sobresaliente a través de difracción, lo cual logró despertar aún más interés en la molécula. Ellos trabajaban análisis de ADN por difracción en la unidad desde mayo de 1950, pero Randall no informó que había solicitado a Franklin que se encargara del trabajo de difracción en ADN y el tutelaje de Gosling para su tesis. La falta de comunicación de Randall con respecto a esta asignación contribuyó de manera significativa a la bien documentada fricción que se desarrollaba entre Wilkins y Franklin.

Franklin, que trabajaba con Gosling, empezó a aplicar sus conocimientos en rayos X en la estructura del ADN. Utilizó una microcámara y un tubo nuevo de enfoque fino para rayos X, ambos ordenados por Wilkins, que ella refinó, ajustó y enfocó cuidadosamente. Utilizando su formación como físicoquímica, manipuló cuidadosamente la hidratación crítica de sus muestras. Cuando Wilkins indagó acerca de estas técnicas mejoradas, ella contestó en modos que ofendieron a Wilkins, pues Franklin actuaba "con aires de tranquila superioridad".

Franklin hablaba de manera concisa, directa e impaciente mientras miraba directamente a los ojos, lo cual ponía nerviosos a muchos de sus colegas. En cambio, Wilkins era muy tímido, premeditaba sus palabras y evitaba el contacto visual directo. A pesar de la atmósfera intensa, Franklin y Gosling descubrieron que existían dos formas de ADN: cuando la humedad era alta, la fibra de ADN adoptaba una figura larga y delgada, mientras que en estado seco adquiría una forma corta y ancha.

Estas formas se denominaron A y B, respectivamente. Debido al intenso conflicto de personalidades entre Franklin y Wilkins, Randall dividió el trabajo relativo al ADN. Franklin escogió la forma A, de la que poseía una base de datos basta, mientras que Wilkins seleccionó la forma B, pues sus foros preliminares habían sugerido que esta era helicoidal. Además, mostró gran agudeza en las evaluaciones de los datos preliminares. Las imágenes por difracción por rayos X tomadas por Franklin en esos días fueron, en palabras de J. D. Bernal, "algunas de las fotografías por rayos X más hermosas que se han tomado alguna vez de una sustancia".

Al final de 1951, se creía en King's College que la forma B del ADN era helicoidal, pero después de que Franklin documentó una imagen asimétrica en mayo de 1952, ella misma dejó de creer que la forma A tuviese una estructura helicoidal. En julio de 1952, a modo de broma pesada dirigida a Wilkins (quien frecuentemente expresaba que ambas formas del ADN eran helicoidales), Franklin y Gosling redactaron un aviso fúnebre donde se lamentaban por la «muerte» de la estructura cristalina helicoidal del ADN (A-ADN). Durante 1952, ellos aplicaron la función de Patterson a las imágenes de ADN que habían generado. Esto implicó un trabajo muy demandante, pero rindió frutos y acrecentó la comprensión de la estructura de la molécula.

En enero de 1953, Franklin había reconciliado sus datos en conflicto y concluyó que ambas formas de ADN estaban formadas por 2 hélices, y había comenzado a escribir una serie de tres manuscritos, dos de los cuales incluían un esqueleto ADN de doble cadena. Sus dos manuscritos acerca de la forma A se publicaron en la revista "Acta Crystallographica" en Copenhague el 6 de marzo de 1953, un día antes de que Watson y Crick completaran su modelo de ADN B. Ella debió de haberlos enviado mientras la pareja de Cambridge se encontraba construyendo su modelo, y sin duda los escribió antes de enterarse del contenido de su trabajo. El 8 de julio de 1953, modificó uno de esos artículos "en prueba", debido al trabajo reciente realizado por los equipos de trabajo de King's y Cambridge.

El tercer borrador hablaba acerca de la forma "B" del ADN, data del 17 de marzo de 1953 y lo descubrió años después su colega de Birkbeck, Aaron Klug, entre otros documentos suyos. Aaron publicó después una evaluación de la cercana correlación existente entre el borrador y el tercer artículo del trío original de "Nature" del 25 de abril de 1953. Klug diseñó este artículo para complementar el primero que había escrito, defendiendo la significativa contribución que Franklin aportó a la estructura del ADN. Había escrito el primer artículo en respuesta a la representación incompleta del trabajo de Franklin incluida en el libro de las memorias de Watson, "La doble hélice", publicada en 1968.

El 30 de enero de 1953, Watson viajó a King's College con un preliminar de la propuesta de la estructura de ADN incorrecta planteada por Linus Pauling. Puesto que Wilkins no se encontraba en su oficina, Watson fue al laboratorio de Franklin con el mensaje urgente de que todos deberían colaborar, antes de que Pauling se diera cuenta de su error. Franklin, poco impresionada, se veía enojada cuando Watson sugirió que ella no sabía interpretar sus datos correctamente. Watson se retractó apresuradamente y buscó apoyo en Wilkins, quien parecía atraído por la conmoción. Wilkins se conmiseró con su hostigado amigo, y cambiaron el curso de la historia del ADN: sin prudencia, Wilkins le mostró a Watson la imagen del ADN que Gosling obtuvo por medio de difracción de rayos X. Watson, por su parte, mostró a Wilkins la pre-publicación del manuscrito de Pauling y Corey. La foto 51 de Franklin y Gosling le dio información fundamental sobre la estructura del ADN al par de Cambridge, mientras que el artículo de Pauling y Corey describía una molécula notablemente similar a su primer modelo, que era incorrecto.

En febrero de 1953, Francis Crick y James D. Watson, del Laboratorio de Cavendish, en la Universidad de Cambridge, habían iniciado la construcción de un modelo de la forma B del ADN utilizando datos similares a los obtenidos en King's College. Una gran parte de sus datos se derivaba de la investigación realizada por Wilkins y Franklin. La investigación de Franklin terminó cerca de febrero de 1953, antes de mudarse a Birkbeck, y sus datos resultaron críticos. La creación de modelos había sido aplicada exitosamente por Linus Pauling en 1951 para el esclarecimiento de la estructura de la hélice alfa, pero Franklin se opuso a la creación prematura de modelos teóricos hasta que se hubiese recabado información suficiente para guiar correctamente la creación de modelos. Franklin también creía que la construcción de un modelo debía realizarse únicamente hasta que se contara con información estructural suficiente.

Siempre con cautela, buscó eliminar posibilidades que llevaran a conclusiones erróneas. Fotógrafos del equipo de trabajo de Birkberck muestran que ella utilizaba modelos moleculares pequeños rutinariamente, aunque ciertamente no empataran con los utilizados en gran escala en Cambridge para el ADN. A mediados de febrero de 1953, el tutor de tesis de Crick, Max Perutz, le proporcionó a Crick una copia del reporte escrito para una visita a King's por el comité de biofísica del consejo de investigación médica en diciembre de 1952, el cual contenía muchos cálculos cristalográficos hechos por Franklin.

Dado que Franklin había tomado la decisión de transferirse a Birkbeck College y Randall había decidido que todo el trabajo sobre el ADN debería de mantenerse en King's, Wilkins recibió copias de las fotografías de Franklin, a través de Gosling. Para el 28 de febrero de 1953, Watson y Crick sintieron que habían resuelto el problema, lo cual bastó para que Crick proclamara (en un bar local) que habían «encontrado el secreto de la vida». Sin embargo, ellos sabían que debían completar su modelo antes de que pudieran estar seguros.

Watson y Crick acabaron de construir su modelo el 7 de marzo de 1953, un día antes de recibir una carta de Wilkins, que afirmaba que Franklin finalmente se iría, y que podrían trabajar sin limitaciones. Esto también fue un día después de que dos artículos de Franklin alcanzaran el "Acta Crystallographica". Wilkins acudió a ver el modelo la siguiente semana, de acuerdo a la biógrafa de Franklin, Brenda Maddox, el 12 de marzo; y supuestamente a informar a Gosling de su regreso a King's.

No es seguro cuanto le tomó a Gosling informar a Franklin, quien se encontraba en Birkbeck, pero su manuscrito original del 17 de marzo no muestra ningún indicio de que sabía del modelo de Cambridge. Franklin modificó este borrador después, antes de publicarlo como el tercero del trío de los artículos de "Nature". En respuesta a la recepción de su manuscrito preliminar, el 18 de marzo, Wilkins escribió lo siguiente: «Me parece que son un par de viejos rebeldes pero, de cualquier manera, puede que se hayan hecho de algo».

Crick y Watson publicaron su modelo en "Nature" el de 25 de abril en 1953 en un artículo que describe la estructura de doble hélice del ADN, con una nota a pie reconociendo "haberse sentido estimulados por el conocimiento de las contribuciones «no publicadas» de «Franklin y Wilkins». Aunque solo fuera un mínimo elemental, tenían suficiente información específica obtenida por Franklin y Gosling en la cual basar su modelo. Como resultado de un trato realizado por los dos directores del laboratorio, los artículos de Franklin y Wilkins, que incluían sus datos de difracción rayos X, fueron modificados y publicados en segundo y tercer lugar en el mismo número de "Nature", lo cual aparentaba que eran únicamente un apoyo al papel teórico de Watson y Crick que proponía un modelo para la forma B del ADN.

Semanas más tarde, el 10 de abril, Franklin escribió a Wilkins, solicitando permiso para ver su modelo. Franklin mantuvo su escepticismo sobre la creación de modelos prematuramente aun después de haber visto el modelo de Watson y Crick y se mantuvo poco impresionada. Se encuentra reportado que ella comentó «Es muy bonito, pero ¿cómo van a comprobarlo?» Como científica experimental, Franklin parece haber estado interesada en producir evidencia mucho más relevante, antes de publicar un modelo propuesto en el momento de haber sido probado. Por ello, su respuesta al modelo de Watson y Crick fue para conservar su forma cautelosa de hacer ciencia. La mayor parte de la comunidad científica se mostró reticente en aceptar el modelo de la doble hélice. Al inicio, muchos genetistas aceptaron el modelo debido a sus obvias implicaciones genéticas.

Franklin dejó King's College, Londres a mediados de marzo en 1953, para ir a Birkbeck College, en una transferencia que había planeado por algún tiempo, la cual ella describió (en una carta a Adrienne Weill en París) como «mudarse de un palacio a los barrios bajos... pero más agradable al mismo tiempo». Fue reclutada por el director del departamento de física J. D. Bernal, un brillante cristalógrafo quien resultó ser un comunista irlandés, conocido por promover mujeres cristalógrafas. Franklin trabajó como científica sénior con su propio grupo de investigación, financiado por el Consejo de Investigación en Agricultura. A pesar de las últimas palabras de Bernal (al ser despedido) para detener su interés en los ácidos nucleicos, ayudó a Gosling a acabar su tesis, aunque ya no fuera su supervisora oficial. Juntos publicaron la primera evidencia de dobles hélices en la forma A del ADN en el ejemplar de julio de "Nature" de 1953. Además, continuó explorando otro de los ácidos nucleicos más importantes, el RNA, una molécula igual de crucial para la vida que el ADN. Volvió a utilizar cristalografía de rayos X para estudiar la estructura del virus del mosaico del tabaco (TMV, por sus siglas en inglés), un virus de ARN. Su reunión con Aaron Klug a principios de 1954 generó una larga y exitosa relación de trabajo. Klug apenas había recibido su doctorado por el Trinity College, Cambridge, y se había unido a Birkbeck a finales de 1953. En 1955 Franklin publicó el primero de sus trabajos más importantes acerca del TMV en "Nature", en el cual describió que todos las partículas del virus TMV tenían la misma longitud. Lo anterior contradecía las ideas del eminente virólogo Norman Pirie, aunque a final de cuentas, ella estaba en lo correcto.

Franklin asignó el estudio de la estructura del TMV completa a su estudiante de doctorado, Kenneth Holmes. Pronto descubrieron que la cobertura del TMV eran proteínas acomodadas en forma de hélice. Su colega Klug trabajó con virus esféricos con su estudiante John Finch, con Franklin coordinando y supervisando el trabajo. En equipo, desde 1956, empezaron a publicar estudios muy influyentes acerca del TMV, virus del pepino 4 y el virus del mosaico amarillo del nabo.

Franklin también tuvo un asistente de investigación, James Watt, subsidiado por la Junta Nacional de Carbón; en ese tiempo, también era la líder del grupo ARC de Birkbeck. Los miembros del equipo de Birkbeck continuaron con virus de ARN que afectan muchas plantas, dentro de las cuales se encuentran las papas, el nabo, el tomate y el chícharo. En 1955 se unió al equipo un estudiante postdoctoral estadounidense llamado Donald Caspar. Él se enfocó en la localización precisa de moléculas de ARN en el TMV. En 1956, él y Franklin publicaron artículos individuales, pero complementarios en una edición de marzo de "Nature," en la que mostraban que el ARN en el TMV se encuentra ceñido a la superficie interna del virus hueco. Caspar no era un escritor entusiasta, al punto en el que Franklin tuvo que escribir el manuscrito entero por él.

En 1957, su beca de investigación proporcionada por el ARC expiró; sin embargo, se le otorgó una extensión con vigencia de un año, de modo que finalizaría en marzo de 1958. Gracias a esto, soliticó una beca nueva al Instituto Nacional de Salud de los Estados Unidos, que fue aprobada proveyendo 10000 libras por tres años, el fondo más grande alguna vez recibido en Birkbeck.

El primer acontecimiento internacional después de la segunda guerra mundial, llamado denominado Expo 58, tomaría lugar en Bruselas en 1958. Se extendió una invitación a Franklin para realizar un modelo de TMV de 5 pies de alto, el cual comenzó en 1957. Sus materiales fueron bolas de ping pong y agarraderas de plástico de manubrios de bicicleta. La feria mundial de Bruselas, la cual contaba con una exhibición de su modelo del virus en el Pabellón Internacional de Ciencia, abrió el 17 de abril, justo el día después de su muerte.

Su equipo de investigación principal en Birkbck College, Londres, Klug, Finch y Holmes se trasladaron al Laboratorio de Biología Molecular en Cambridge en 1962.

Franklin se describía como agnóstica. Su falta de fe religiosa al parecer no provenía de ninguna influencia externa, sino de su propia mente inquisitiva. Desde pequeña desarrolló una actitud escéptica. Su madre recordó que, al oponerse a creer en la existencia de Dios, Rosalind dijo: «Bueno, pues de cualquier manera, ¿cómo sabes que Él no es Ella?». Posteriormente, ella puntualizó su opinión basándose en su experiencia científica, y le escribió a su padre en 1940:

Aunque, por otra parte, nunca abandonó las tradiciones judías. Dado que era la única estudiante judía en Lindores School, tomaba lecciones de hebreo por su cuenta mientras sus amigas iban a la iglesia. Se unió a la Sociedad Judía a los 27, por respeto a la petición que le hizo su abuelo. Franklin le confió a su hermana que ella «siempre fue judía a conciencia».

A Franklin le encantaba viajar fuera del país, y en particular, practicar el excursionismo. Ella «calificó por primera vez en Navidad de 1929» para unas vacaciones en Menton, Francia, donde su abuelo se refugiaba del invierno inglés. Su familia vacacionaba frecuentemente en Gales o Cornualles. Un viaje a Francia en 1938 generó en ella un amor duradero por el país y por su lenguaje. Consideraba el estilo de vida francés como «muy superior al estilo de vida inglés». En contraste, describió a los ingleses como personas que «poseían caras ausentes y estúpidas y una complacencia infantil». Su familia casi queda atrapada en Noruega en 1939, pues la segunda guerra mundial inició mientras iban camino a casa. En otra ocasión, en 1946, hizo una excursión a los Alpes franceses con Jean Kerslake que casi le cuesta la vida. Resbaló en una pendiente y apenas pudo ser rescatada. No obstante, escribió a su madre: «Estoy segura de que podría merodear felizmente en Francia por siempre. Amo la gente, el país y la comida».

Realizó varios viajes profesionales a Estados Unidos y se comportaba especialmente jovial con sus amigos estadounidenses, demostrando constantemente un buen sentido del humor. William Gonza, de la Universidad de California, Los Ángeles, comentó que ella era el perfecto opuesto de la descripción que Watson había hecho sobre ella, y Maddox comentó que los estadounidenses disfrutaban su «lado alegre».

Watson, en "La doble hélice", se refiere a Franklin como "Rosy" la mayor parte de las veces, el apodo que la gente del King's College utilizaba a sus espaldas. A ella no le gustaba que la llamaran de ese modo, pues tuvo una tía abuela Rosy. Dentro de su familia le decía "Ros". Para los demás, respondía a Rosalind. Esto lo dejó en claro a una amiga estadounidense que la visitaba, Dorothea Raacke, mientras estaban sentadas en la mesa de Crick, en el bar The Eagle. Raacke le preguntó cómo debería llamarla, a lo que ella contestó: «Me temo que Rosalind», y agregó: «Definitivamente no "Rosy"».

Frecuentemente expresaba sus opiniones políticas. Inicialmente culpaba a Winston Churchill por favorecer la posibilidad de la guerra, pero posteriormente lo admiró por sus discursos. Apoyaba activamente a John Alfred Ryle, Profesor Regente de Física en la Universidad de Cambridge, como un candidato independiente para miembro del parlamento en 1940, lo cual fue en vano.

No parecía tener una relación íntima con nadie y mantuvo sus sentimientos más profundos para sí misma. Desde su infancia evitó amistades cercanas con el sexo opuesto. Una vez en la que sus primos los visitaron, ella le pagó a Roland para acompañarlos. Años después, Evi Ellis, quien en ese entonces estaba casada con Ernst Wohlgemuth, se había mudado a Notting Hill desde Chicago e intentó que iniciara una relación con Ralph Miliband, pero falló. Franklin le dijo a Evi que su compañero de cuarto le quería invitar un trago, pero ella no entendió sus intenciones. Ella estaba perdidamente enamorada de su mentor francés Mering, quien tenía esposa y una amante. Mering también admitió que su «inteligencia y belleza» lo cautivaban. Según Sayre, ella confesó sus sentimientos por Mering mientras le hacían una cirugía, pero su familia lo negó. Mering lloró cuando la visitó posteriormente, y destruyó todas sus cartas.

Su relación personal más cercana probablemente fue con su estudiante de postdoctorado, Donald Caspar. En 1956, lo visitó en su hogar en Colorado, después de ir a un viaje por la Universidad de Berkeley, California, y se supo que Franklin comentó que Caspar «fue alguien a quien pudo haber amado, incluso casarse con él». En su carta a Sayre, lo describió como «un partido ideal».

A mediados de 1956, durante un viaje de trabajo en Estados Unidos, Franklin comenzó a sospechar que tenía un problema de salud. En Nueva York, no pudo negar el hecho de que su estómago estaba inflamado. Al regresar a Londres, consultó a Mair Livingstone, quien le dijo: «no estás embarazada», a lo que ella replicó: «desearía estarlo». Su diagnóstico reveló que no estaba embarazada, y su caso fue marcado como «urgente». Una operación el 4 de septiembre del mismo año reveló tumores en su abdomen. Después de este periodo de hospitalización, Franklin pasó tiempo convaleciendo con varios amigos y parientes, como Anne Sayre, Francis Crick y su esposa Odile, con quien Franklin tenía ya una gran amistad; y con la familia de Roland y Nina Franklin, siendo los sobrinos de Rosalind quiénes le ayudaron a sentirse mejor.

Franklin decidió no quedarse con sus padres, debido a que la aflicción y el llanto de su madre la trastornaban demasiado. Aun cuando estaba tomando tratamiento para el cáncer, Franklin y su grupo continuó trabajando y generando resultados: siete artículos en 1956 y seis más en 1957. En 1957, el grupo también trabajaba en el virus de la polio, y gracias a estas publicaciones obtuvo fondos del Servicio Público de Salud y de los Institutos Nacionales de Salud en los Estados Unidos.

A finales de 1957, Franklin enfermó de nuevo y fue internada en el Hospital Royal Marsden. El 2 de diciembre escribió su testamento. Designó a sus tres hermanos como albaceas y a Aaron Klug como el principal beneficiario, que recibiría 3000 libras y su auto Austin. Sus otros amigos obtendrían: Mair Livingstone, 2000 libras; Anne Piper, 1000 libras, y su enfermera, la Srta. Griffith, 250 libras. La cantidad restante se usaría para la caridad. Regresó al trabajo en enero de 1958, y recibió el nombramiento de Asociada de Investigación Biofísica el 25 de febrero. Recayó el 30 de marzo, y el 16 de abril de 1958 murió de bronconeumonía, carcinomatosis secundaria y cáncer de ovario en Chelsea, Londres. Es posible que la exposición a los rayos X haya sido uno de los factores de riesgo, además de la predisposición genética.

Otros miembros de su familia murieron de cáncer, y se sabe que la incidencia de cáncer ginecológico es particularmente alta entre los judíos askenazíes. Su acta de defunción dice: «Científica investigadora, soltera, hija de Ellis Arthur Franklin, banquero». Fue enterrada el 17 de abril de 1958 en una sección familiar en el Cementerio de la sinagoga de Willesden United, en el London Borough of Brent, con el epitafio siguiente:

EN MEMORIA DE <br> ROSALIND ELSIE FRANKLIN <br> מ' רחל בת ר' יהודה <Br> QUERIDA HIJA MAYOR DE <br> ELLIS Y MURIEL FRANKLIN <br> 25 DE JULIO DE 1920 - 16 DE ABRIL DE 1958 <br> CIENTÍFICA <br> SU INVESTIGACIÓN Y SUS DESCUBRIMIENTOS EN MATERIA DE <br> VIRUS QUEDAN COMO UN BENEFICIO <br> PARA LA HUMANIDAD <br> ת נ צ ב ה [Iniciales en hebreo que indican: "Su alma permanecerá guardada en el hacecillo de la vida".]

Han surgido diversas controversias después de la muerte de Franklin:

Sayre, una de las biógrafas de Franklin, afirmó: «En 1951 ... el King's College como institución no se distinguía por la bienvenida que daban a las mujeres... Rosalind... no estaba acostumbrada al "purdah" (una forma religiosa y social de exclusión femenina) ... había únicamente otra mujer científica en el personal del laboratorio». Andrzej Stasiak declara: "El libro de Sayre se cita continuamente en los círculos feministas, para exponer el fuerte sexismo en el ámbito de las ciencias". Farooq Hussain afirma: "había 7 mujeres en el departamento de biofísica... Jean Hanson llegó a ser una de ellas, la Dama de Honor B. Fell, directora del Laboratorio Strangeways, supervisaba a los biólogos". Maddox anota: «Randall... contaba con muchas mujeres dentro de su personal... ellas lo consideraban... empático y servicial».

Sayre sostiene: «mientras los empleados masculinos en Kings almorzaban en un comedor grande y cómodo con aires de club», los miembros femeninos de distintos rangos «almorzaban en el vestíbulo de estudiantes o apartadas de las inmediaciones del edificio». Elkin afirma que, generalmente, la mayor parte del grupo del CIM comían juntos (incluida Franklin) en el comedor mixto que se menciona en las líneas siguientes. Maddox declara de Randall: «Le gustaba ver a su gente, hombres y mujeres, reunirse para el café matutino y en el almuerzo en el comedor mixto, donde él comía casi todos los días». Francis Crick también comentó que «sus colegas trataban a hombres y mujeres científicos por igual».

Sayre también argumenta sobre la lucha de Franklin, respecto a seguir el camino de la ciencia y la preocupación que su padre tenía por el hecho de que las mujeres obtuvieran puestos académicos. Esta manifestación ha sido tomada como base para acusar a Ellis Franklin de sexismo contra su hija. Una cantidad de información importante declara explícitamente que él se oponía a que ella ingresara al Newnham College. La biografía del Servicio Público de Divulgación (Public Broadcasting Service (PBS) afirma incluso que él se negaba a pagar sus gastos, y que una tía tuvo que apoyarla. Su hermana Jenifer Glynn explica que estas historias son mitos y que los padres de Franklin pagaron su carrera completa.

Se dice que "La doble hélice", las memorias de James Watson publicadas 10 años después de la muerte de Franklin y de que Watson regresara de Cambridge a Harvard, se hallan impregnadas de sexismo. Su colega de Cambridge, Peter Pauling, escribió en una carta: «Se supone que Wilkins está haciendo este trabajo. La señorita Franklin es tonta, evidentemente». Crick reconoce después: «Me temo que tendíamos a adoptar, digamos, una actitud «condescendiente» con ella».

Glynn acusa a Sayre de transformar a su hermana en una heroína feminista, y a "La doble hélice" de Watson como la raíz de lo que él llama «la industria Rosalind». Ella conjetura que estas supuestas historias de sexismo «la habrían avergonzado casi tanto como le habría molestado el testimonio de Watson», y declaró que «ella nunca fue feminista» Klug y Crick concordaron también en que ella definitivamente no era feminista.

Una carta de Franklin a su familia en enero de 1939 se toma como una demostración de su propia actitud perjudicada y del hecho de que «ella no era inmune al terrible sexismo en esos círculos». En la carta, dijo que una catedrática era «muy buena, pero mujer». Pero Maddox explica que era más bien un comentario circunstancial que un prejuicio de género. De hecho, ella se reía de los hombres que se sentían avergonzados por el nombramiento de la primera profesora mujer, Dorothy Garrod.

La primera contribución importante al modelo de Watson y Crick fue su cátedra en el seminario en noviembre de 1951, donde presentó a los presentes, entre ellos Watson, las dos formas de la molécula, A y B, y el planteamiento de que las unidades de fosfato se ubican en la parte externa de la molécula. Además, especificó la cantidad de agua encontrada en la molécula de acuerdo a otras partes de la misma, datos que son de considerable importancia en términos de estabilidad molecular. Franklin fue la primera que describió y formuló estos hechos, que en realidad constituyeron la base para todos los demás intentos de creación de modelos de esta molécula. Sin embargo Watson, en el momento ignorante de la química pertinente, no comprendió la información crucial, lo que llevó a la construcción de un modelo erróneo.

La otra contribución incluye una fotografía de rayos X de B-ADN, (llamada fotografía 51), que Wilkins mostró brevemente a Watson en enero de 1953, y un reporte escrito para una visita del comité de biofísica del CIJ al King's College en diciembre de 1952. Perutz, supervisor de tesis de Crick y miembro del comité de visita al CIJ, entregó este reporte a Crick, quien en ese momento trabajaba en su tesis sobre la estructura de la hemoglobina.

La biografía de Franklin, escrita por Sayre, contiene una historia que declara que Wilkins mostró la fotografía 51 a Watson sin permiso de Franklin, y que esto es un ejemplo de ausencia de ética científica. Otros rechazan esta teoría, y aseguran que Watson había recibido esta fotografía a través de Gosling, el estudiante de doctorado de Franklin porque ella ya se iba de King's College para trabajar en Birkbeck, y que no había nada negativo en ello, pues el director Randall insistió en que todo el trabajo sobre ADN pertenecía exclusivamente al King's College y que inclusive había ordenado a Franklin, a través de una carta, que dejara de trabajar en la molécula y mandara su información. Horace Freeland Judson dejó implícito que Maurice Wilkins tomó la fotografía del cajón de Franklin, pero se dice que esto también es incorrecto.

De igual modo, Perutz «no consideró dañino» mostrar a Crick el reporte del CIJ que contenía las conclusiones de Franklin y Gosling sobre sus análisis de los datos de sus estudios con rayos X, debido a que no había sido marcado como confidencial, aunque este «no estuviera predestinado para ser visto por externos». Después de que la publicación de "La doble hélice" de Watson expusiera las acciones de Perutz, recibió tantas cartas juzgando su juicio que sintió la necesidad de contestarlas todas, y de revelar una afirmación general en "Science" excusándose por ser «inexperto en asuntos administrativos».

Perutz también declaró que la información del CIJ ya se encontraba disponible para el equipo de Cambridge, cuando Watson había asistido al seminario en noviembre de 1951. La versión preliminar de mucho del material contenido en el reporte del CIJ de diciembre de 1952 había sido presentada por Franklin en una plática que había impartido en noviembre de 1951, a la cual Watson asistió pero no comprendió.

La carta de Perutz era una de 3 cartas publicadas junto otras de Wilkins y Watson, que argumentaban sobre sus distintas contribuciones. Watson aclaró la importancia de los datos obtenidos del reporte del CIJ ya que él no había capturado esta información cuando atendió la cátedra de Franklin en 1951. La culminación de todo esto sucedió cuando Crick y Watson comenzaron a crear su modelo en febrero de 1953 y trabajaban con parámetros críticos que habían sido determinados por Franklin en 1951 y que ella y Gosling habían refinado significativamente en 1952, junto con sus datos publicados y otros muy similares a los disponibles en King's. Se creía, de modo general, que Franklin nunca estuvo consciente de que sus estudios habían sido utilizados durante la construcción del modelo, pero Gosling afirmó en una entrevista en 2013: «Sí. Ella sabía de ello».

Una vez completado el modelo, Crick y Watson invitaron a Wilkins a ser coautor del artículo en el que se describía la estructura. Wilkins rechazó la oferta, ya que no había participado en su construcción. Después expresó arrepentimiento de que no hubiera habido mayor discusión sobre la coautora, pues esto habría podido ayudar a esclarecer qué tanto contribuyó el King's College al descubrimiento. No cabe duda de que la información experimental de Franklin fue utilizada por Watson y Crick para construir su modelo de ADN en 1953. Algunos, incluido Maddox, que se cita en los párrafos siguientes, han explicado esta omisión en las citas como una cuestión de referencias, pues habría resultado muy difícil citar los resultados no publicados del reporte del CIJ que habían visto.

Habría sido difícil de manejar un reconocimiento puntual, debido a la manera en que se transfirieron los datos del King's College a Cambridge. No obstante, había métodos disponibles. Watson y Crick podrían haber citado el reporte del CIJ como comunicación personal y podrían haber citado los artículos con estatus de edición del "Acta" o, aún más fácil, el tercer artículo de "Nature" que también sabían que estaba en estatus de edición. Uno de los logros más importantes de la aclamada biografía de Maddox es que el autor presentó un caso bien recibido de reconocimiento inadecuado. El reconocimiento otorgado que le dieron fue muy apagado y siempre emparejado al nombre de Wilkins.

Veinticinco años después de lo ocurrido, las primeras citas claras a las contribuciones de Franklin aparecen en "La doble hélice", pues se perneó el testimonio de Watson, aunque estas estén enterradas bajo descripciones (que en varios casos son muy negativas) de Franklin durante su periodo de trabajo en el ADN. Esta actitud alcanza su clímax en la confrontación que tuvieron Watson y Franklin gracias a una impresión previa del manuscrito erróneo de Pauling sobre el ADN. Las palabras de Franklin motivaron a Sayte para escribir su refutación, en el capítulo 9 de la cual, titulado "Winner Take All", se halla la estructura de un sumario legal que describe y analiza el tema del reconocimiento.

Franklin nunca estuvo nominada para un Premio Nobel. Murió en 1958, y durante su tiempo en vida la estructura del ADN no se consideraba completamente probada. A Wilkins y sus colegas les tomó alrededor de siete años recabar suficiente información para comprobar y refinar la estructura propuesta del ADN. Aún más, su importancia biológica, propuesta por Watson y Crick, no se había determinado. La aceptación general para la doble hélice del ADN y su función no se determinó sino hasta los últimos años de la década de 1950, lo cual propició nominaciones para el Nobel de fisiología o medicina en 1960, 1961 y 1962, y en 1962 para el Premio Nobel de Química. El primer suceso notorio con respecto a lo anterior fue realizado por Matthew Meselson y Franklin Stahl en 1958, quienes mostraron de modo experimental la replicación de ADN de la bacteria "Escherichia coli". A través del experimento Meselson-Stahl, se mostró cómo el ADN se replica para formar dos hélices de dos cadenas cada una, y cada una de estas hélices porta una de las cadenas originales de ADN. Este concepto de replicación de ADN se estableció con firmeza alrededor de 1961 después de su demostración en otras especies y de la reacción química paso a paso. De acuerdo con la carta de Crick y Monod de 1961, esta prueba experimental y la iniciación del trabajo de difracción sobre el ADN iniciado por Wilkins fueron las razones por las cuales a Crick le pareció que Wilkins debió de haber sido incluido en el Premio Nobel referente al ADN.

En 1962, Crick, Watson y Wilkins recibieron el Premio Nobel. No está claro si Franklin debió haber sido incluida, en caso de que hubiera estado viva. El premio se otorgó por su trabajo completo y no específicamente por el descubrimiento de la doble hélice. Cuando el premio se otorgó, Wilkins había estado estudiando la estructura del ADN por más de 10 años y había contribuido de manera importante para confirmar el modelo de Watson y Crick. Crick había trabajado en el código genético en Cambridge, y Watson en el ARN durante algunos años. Watson ha sugerido que idealmente, Wilkins y Franklin debieron haber ganado el Premio Nobel de Química.

También es interesante que el colega de Franklin y principal beneficiario de su testamento, Klug, fue el único ganador del premio de Química en 1982, «por su desarrollo de la microscopía cristalográfica de electrones y su elucidación estructural de complejos ácido nucleico-proteína biológicamente importantes». Este trabajo fue exactamente lo que Franklin había iniciado y que presentó a Klug. Es altamente plausible que, si ella hubiera estado viva, habría compartido el Nobel con él.










Rosalind Franklin generó varias publicaciones, algunas de las cuales han sido citadas en múltiples ocasiones. Una lista representativa aparece líneas abajo. Las últimas dos fueron póstumas.





</doc>
<doc id="41279" url="https://es.wikipedia.org/wiki?curid=41279" title="Nefropatía diabética">
Nefropatía diabética

La diabetes es una enfermedad que impide que el cuerpo use glucosa (azúcar) de forma adecuada. Si la glucosa se queda en la sangre en lugar de ser utilizada por los tejidos (metabolizarse), puede provocar toxicidad. El daño que el exceso de glucosa en sangre causa a las nefronas 
se llama nefropatía diabética. Esta patología se puede diagnosticar gracias a la microalbuminuria, que es la pérdida en pequeñas cantidades de proteínas en la orina, en concreto, la albúmina. Si se mantienen las concentraciones de glucosa en la sangre, en su rango normal (60 - 110 mg/dL) se puede demorar o prevenir la nefropatía diabética casi en todas sus formas.

Además otra definición podría ser que la nefropatía diabética es un trastorno o patología del riñón, que incluye procesos inflamatorios, degenerativos y escleróticos relacionados con la hiperglucemia persistente asociado a otros factores (hipertensión, dislipemia, predisposición genética).

La nefropatia diabética es una de las principales causas de Insuficiencia Renal Crónica.

"Estadio I".: No provoca síntomas. Existe hiperfiltración glomerular y los análisis de orina y creatinina son normales. Tampoco hay alteraciones histológicas.

"Estadio II".: Aparece aproximadamente después de cinco años de evolución. Es silente. Mantiene función renal normal y no hay perdida de albúmina. Alteraciones mínimas en el glomérulo como inicio de engrosamiento de membranas basales o ligero aumento de la matriz mesangial. 

Estadio III: Presencia de microalbuminuria (más de 30 mg de albúmina en 24 horas o 20 mg/litro de orina). La creatinina en sangre es normal. La hipertensión arterial asociada puede empeorar la lesión renal. Expansión mesangial y de las membranas basales. 

Aparición después de 15 años del diagnóstico. 
Se asocia a retinopatía en más del 75%, coronariopatía en más del 45% y enfermedad cerebrovascular en más de 25% de los casos.

Estadio V: Proteinuria. Creatinina mayor de 200 µmol/litro o 2.2 mg/dl, hipertensión arterial. 
Glomerulosclerosis, lesiones nodulares, fibrosis intersticial, atrofia tubular. Aparición en general después de veinte años de evolución.

La presencia de microalbuminuria es un signo de nefropatía incipiente y se usa como screening para la detección precoz de la afectación renal.

Los principales síntomas son los siguientes:


La patogenia de la glomeruloesclerosis diabética está íntimamente relacionada con la microangiopatía diabética generalizada. Sus principales aspectos son los siguientes:

'¿Cómo prevenir y tratar la nefropatía diabética?'
En el estudio UKPDS se observó que el riesgo de aparición de complicaciones microvasculares (nefropatía, neuropatía y/o retinopatía) se reduce en un 37% en 10 años por cada punto de descenso de la Hemoglobina Glucosilada (HbA1c) e igualmente un 37% por cada 10 mm de Hg de descenso de presión arterial sistólica . Por lo tanto el correcto control de ambos factores es necesario para la prevención y ralentización en la evolución de las complicaciones microvasculares.

Diagnóstico precoz de nefropatía: se recomienda realizar una determinación anual de microalbuminuria por debajo de los 75 años. El despistaje se realizará mediante la determinación del índice albúmina/creatinina en una muestra de orina matutina. Ante la presencia de microalbuminuria , es preciso un control aún más estricto de los factores de progresión: hipertensión arterial , tabaco, dislipemias, prohibición de fármacos nefrotóxicos y tratamiento de las infecciones urinarias . 

Cuantificación de la función renal: se recomienda realizar una determinación anual para detectar precozmente su deterioro y posteriormente valorar su evolución. Para su cálculo en diabéticos es preferible utilizar la ecuación del MDRD (www.kidney.org/professionals/kdoqi/gfr_calculator.cfm) aunque también puede servir la de Cockcroft y Gault ; ambas nos permiten estimar su valor en función del sexo, la edad (años), la creatinina plasmática (mg/dl) o el peso (kg) . Los distintos grados de insuficiencia renal vienen determinados por el nivel del filtrado glomerular . 

Control de la HTA: su control estricto disminuye en un 29% el riesgo de progresión de la microalbuminuria. El tratamiento de elección de la hipertensión arterial en diabéticos con microalbuminuria o nefropatía son los IECA (enalapril) o ARA II (losartan). 

Control glucémico: en pacientes con nefropatía se recomienda un adecuado control glucémico (HbA1c ≤7%). En caso de insuficiencia renal severa pueden utilizarse insulina, glinidas y pioglitazona; no pudiendo utilizarse los restantes antidiabéticos .

Microalbuminuria sin HTA: es aconsejable la utilización de un IECA o ARAII, que demostraron disminuir su cuantía. 

En caso de insuficiencia renal moderada o grave es recomendable la restricción de proteínas por debajo de 0,8 gr/Kg de peso/día (ADA, 2011). 

Cuando se utilicen IECAS y/o ARA II en pacientes con nefropatía es preciso monitorizar los niveles séricos de potasio por el riesgo de hiperpotasemia.



</doc>
<doc id="41281" url="https://es.wikipedia.org/wiki?curid=41281" title="Glomerulonefritis">
Glomerulonefritis

La glomerulonefritis es una enfermedad que afecta la estructura y la función del glomérulo, aunque posteriormente pueden resultar afectadas las demás estructuras de la nefrona. Se trata de una enfermedad renal que puede tener varias causas y presentaciones clínicas y en la que se daña el sector de los riñones que ayuda a filtrar los desechos y los líquidos de la sangre. El término genérico glomerulonefritis (que implica una patogenia inmune o inflamatoria) designa varias enfermedades renales, por lo general de naturaleza bilateral. Muchas de esas enfermedades se caracterizan por la inflamación de los glomérulos o los pequeños vasos sanguíneos de los riñones, de ahí su nombre, pero no todas tienen un componente inflamatorio.
Como en términos estrictos no se trata de una única enfermedad, su presentación depende de la entidad patológica específica: puede presentarse con hematuria, proteinuria o ambas afecciones o como un síndrome nefrótico, un síndrome nefrítico, una lesión renal aguda o una enfermedad renal crónica. 

La glomerulonefritis puede ser "primaria" o "secundaria". Se habla de glomerulonefritis primaria cuando el compromiso renal no es consecuencia de una enfermedad más general y las manifestaciones clínicas se limitan al riñón y de glomerulonefritis secundaria cuando la afección es resultado de una enfermedad sistémica (p. ej., lupus eritematoso sistémico, diabetes, etc.) o de una infección. Entre las glomerulonefritis primarias figuran la nefropatía por IgA o por IgM, la glomerulonefritis proliferativa mesangial y la glomerulonefritis membranoproliferativa. En cuanto a las glomerulonefritis secundarias, pueden ser consecuencia de una infección bacteriana, viral o parasitaria o de enfermedades multisistémicas.

En síntesis, las causas primarias son intrínsecas, es decir intrarrenales, y las secundarias son extrínsecas y se asocian con infecciones (causadas por bacterias, virus o parásitos), con ciertas drogas o con trastornos sistémicos (p. ej., lupus, vasculitis o diabetes).

Algunos autoresdividen las glomerulonefritis según su patrón anatomopatológico y las agrupan en dos categorías amplias, a saber, de "tipo proliferativo" y de "tipo no proliferativo". Entre las de tipo proliferativo (es decir las caracterizadas por un aumento del número de algunas células glomerulares) se encuentran la glomerulonefritis mesangial por IgA y la glomerulonefritis mesangial por IgM, la glomerulonefritis membranoproliferativa o mesangiocapilar, la glomerulonefritis posestreptocócica o endocapilar difusa y la glomerulonefritis extracapilar. A su vez, las de tipo no proliferativo (o sea sin aumento del número de células de los glomérulos) incluyen la nefropatía por cambios mínimos, la glomeruloesclerosis segmentaria y focal y la glomerulonefritis membranosa o extramembranosa. La determinación del patrón histológico de la glomerulonefritis es importante porque el pronóstico y el tratamiento difieren según el tipo. 

Como las glomerulonefritis primarias son entidades muy heterogéneas tanto por su etiología como por su evolución no es posible establecer una clasificación única que permita diferenciarlas en grupos homogéneos. Sin embargo, si se consideran los datos evolutivos, histológicos y clínicos se las puede clasificar en diversos tipos. Por ejemplo, de acuerdo con su evolución la glomerulonefritis puede ser "aguda" (forma que comienza en un momento conocido, habitualmente con síntomas claros, y que suele cursar con hematuria, a veces proteinuria, edema, hipertensión arterial e insuficiencia renal), "subaguda" (de comienzo menos claro, con un deterioro de la función renal que progresa en un plazo de semanas o meses y no muestra tendencia a la mejoría) y "crónica" (forma que independientemente del comienzo tiende a la cronicidad, suele cursar con hematuria, proteinuria, hipertensión arterial e insuficiencia renal y evoluciona en forma variable a lo largo de los años, pero tiende a progresar una vez que se instaura el daño). 

También se las puede clasificar según la histología, que es la clasificación más utilizada y aporta información útil para el pronóstico. Las diferentes enfermedades glomerulares pueden compartir las manifestaciones clínicas, lo que dificulta el diagnóstico y explica el papel decisivo que desempeña la biopsia. La biopsia renal permite establecer el diagnóstico correcto para administrar un tratamiento específico y también posibilita la detección de lesiones agudas o crónicas cuya naturaleza puede no ser sugerida por la historia clínica. Esto es importante porque el descubrimiento de lesiones más crónicas y potencialmente irreversibles evitaría el tratamiento de las lesiones con pocas probabilidades de responder.

Por último, según el comportamiento del complemento las glomerulonefritis se pueden clasificar en las que cursan con complemento sérico normal y las que lo hacen con complemento reducido (sea en la fracción C3, en la fracción C4 o en ambas). Las que cursan con complemento normal son la enfermedad de cambios mínimos, la glomerulonefritis focal y segmentaria, la nefropatía por IgA, la glomerulonefritis membranosa primaria y la glomeruloesclerosis diabética. Las que se asocian con hipocomplementemia son la glomerulonefritis posestreptocócica (bajo nivel de C3), la glomerulonefritis lúpica (niveles bajos de C3 y C4), la glomerulonefritis membranoproliferativa de tipos I, II y III (bajo nivel de C3) y la glomerulonefritis asociada con crioglobulinemia(nivel bajo de C4).

Richard Bright, un médico inglés que hizo múltiples aportes a la medicina, entre ellos descripciones de enfermedades del sistema nervioso, el páncreas, el hígado y, especialmente, el riñón, publicó en 1827 su mayor contribución al campo de la patología renal, la descripción de la glomerulonefritis, término acuñado por Edwin Klebs en 1875 y utilizado como sinónimo de "enfermedad de Bright" desde que F. Volhard y T. Fahr lo introdujeron en su clasificación de las enfermedades renales en 1914.
Bright fue el primero en relacionar la presencia simultánea de albuminuria, hidropesía y lesión del parénquima renal y así identificó un nuevo tipo de enfermedad, en la que unía los signos clínicos con alteraciones químicas y cambios estructurales. Bright asociaba la observación clínica con pruebas de laboratorio en las que se analizaba la química de la orina y por último la necropsia permitía demostrar las alteraciones estructurales del riñón. Ese fue el criterio anatomoclínico que este investigador llevó a un nuevo escenario, el de la patología renal.

En su trabajo titulado "Reports of Medical Cases", ilustrado por él mismo, Bright describió las observaciones realizadas en pacientes que habían presentado edema y albuminuria tras padecer escarlatina.
Según el Registro Español de Glomerulonefritis, con datos obtenidos de 21.988 biopsias renales practicadas durante el período 1994-2013 (sin incluir biopsias de trasplantes), la nefropatía por IgA sigue siendo la patología más frecuente en las biopsias renales de ese país. La relación varones-mujeres es de 3:1. En los adultos la presentación más frecuente es como anomalías urinarias persistentes, pero en los mayores de 65 años se presenta más a menudo con disfunción renal aguda. El síndrome nefrótico se desarrolla en un trece por ciento de los casos, pero con más frecuencia en mayores de 65 años. 

Hay un aumento progresivo de la edad de los pacientes sometidos a biopsia renal y el síndrome nefrótico es la causa más común. Las patologías observadas con más frecuencia son nefropatía por IgA y lupus eritematoso sistémico en los adultos y vasculitis y nefropatía membranosa en los mayores de 65 años. La disfunción renal aguda está incrementando su frecuencia como causa de biopsia renal, en especial en mayores de 65 años, y se asocia principalmente con vasculitis y con nefritis tubulointersticial aguda. La frecuencia de esta última enfermedad está aumentando, sobre todo en mayores de 65 años.

Las glomerulonefritis primarias son enfermedades de base inmunitaria, aunque en la mayor parte de los casos se desconoce el antígeno o causa última de la afección. La inmunidad desempeña un papel fundamental en el desencadenamiento de muchos tipos de lesiones glomerulares. En algunos casos la activación inespecífica de la inflamación puede causar o agravar la lesión glomerular. Los microorganismos infecciosos también pueden desencadenar respuestas inmunitarias anómalas o contra antígenos microbianos. Por último, los factores genéticos pueden ser causa de nefropatía glomerular, pero también pueden influir sobre la predisposición al desarrollo de lesión glomerular, sobre la progresión de esa lesión o sobre la respuesta al tratamiento.

La glomerulonefritis es una enfermedad caracterizada por inflamación intraglomerular y proliferación celular asociada con hematuria en cuya patogenia desempeñan un papel importante tanto los mecanismos de inmunidad celular como los mecanismos humorales. El sistema del complemento también es importante. Su activación se asocia con patrones característicos de disminución de su concentración sérica, algunos de los cuales son prácticamente diagnósticos de ciertas nefritis. La patogenia, entonces, puede ser inmunitaria o inflamatoria, con la participación de células y mediadores del sistema inmunitario, incluida la vía del complemento. Las células glomerulares intrínsecas, en particular los podocitos, son importantes en la lesión glomerular y en la respuesta a ella.

Como ya se dijo, la glomerulonefritis puede tener una patogenia inmune o inflamatoria y aunque en algunas situaciones es posible establecer un diagnóstico específico sobre la base de la presentación clínica y las pruebas de laboratorio, en la mayor parte de los casos es útil realizar una biopsia renal tanto para efectuar la clasificación como para determinar el pronóstico. Además, lo ideal es que las muestras de biopsia se examinen con el microscopio óptico, mediante inmunofluorescencia y por microscopia electrónica porque ese enfoque permitirá diagnosticar el patrón histológico. En algunos casos ese patrón se puede comparar con los resultados de otras pruebas de laboratorio para identificar una etiología específica, pero en muchos otros la enfermedad es idiopática. Aun así, como los tratamientos suelen desarrollarse para patrones histológicos específicos, en el manejo actual de estos trastornos se prefiere este enfoque.
La evaluación histopatológica completa de las muestras obtenidas para la biopsia renal requiere el empleo de microscopia óptica y electrónica y el examen con las técnicas de inmunofluorescencia o inmunoperoxidasa para detectar depósitos de complemento e inmunoglobulina.
En la glomerulonefritis las lesiones histológicas dominantes en la microscopia óptica, aunque no las únicas, se localizan en los glomérulos. La enfermedad se describe como "focal" (solo afecta algunos glomérulos) o "difusa". En cualquier glomérulo individual la lesión puede ser "segmentaria" (afectar solo una parte del glomérulo) o "global". En síntesis, las lesiones glomerulares pueden ser focales (solo presentes en algunos glomérulos) o difusas (presentes en todos o casi todos los glomérulos) y segmentarias (comprometer solo parte del glomérulo) o globales (con compromiso de todo el glomérulo). Al obtener las muestras para la biopsia renal se pueden cometer errores. Por ejemplo, si la muestra es pequeña se puede juzgar erróneamente la extensión de una lesión focal y los cortes transversales pueden pasar por alto lesiones segmentarias. Las lesiones también pueden ser hipercelulares debido a un aumento de las células endoteliales o mesangiales endógenas (caso en el cual se las denomina proliferativas) o a la infiltración de leucocitos inflamatorios (en este caso se las llama exudativas). Cuando la inflamación es aguda e intensa puede provocar necrosis glomerular, la que a menudo es segmentaria. Además, es posible que se produzca un adelgazamiento de las paredes de los capilares glomerulares a causa de diversos procesos, entre ellos un aumento de los depósitos inmunes presentes en la membrana basal glomerular. También puede haber esclerosis y formación de cicatrices segmentarias, que se caracterizan por colapso capilar segmentario con acumulación de material hialino y de la matriz mesangial y muchas veces fijación de la pared capilar a la cápsula de Bowman (lo que determina la formación de sinequias o adherencias).

Las tinciones clásicas que se utilizan en la microscopia óptica son hematoxilina-eosina y la reacción del ácido periódico de Schiff, que es particularmente útil para evaluar la celularidad y la expansión de la matriz. Las tinciones más específicas incluyen la tinción argéntica, que tiñe de negro la membrana basal glomerular y que puede revelar, entre otras cosas, un doble contorno de la membrana debido a la interposición de material celular o un aumento de la matriz mesangial que no sería fácil detectar con otras técnicas. La tinción tricrómica también es útil para detectar áreas con formación de cicatrices (que tiñe de azul) mientras que los depósitos inmunes se tiñen de rojo. Las semilunas, que son colecciones inflamatorias de células presentes en el espacio de Bowman, se desarrollan cuando se produce una lesión glomerular grave que determina la ruptura local de la pared capilar o de la cápsula de Bowman, lo que posibilita el ingreso de proteínas plasmáticas y material inflamatorio en el espacio homónimo. Las semilunas están compuestas por células epiteliales y parietales proliferantes, fibroblastos infiltrativos y además linfocitos y monocitos-macrófagos, muchas veces con depósitos locales de fibrina. Se las denomina semilunas por el aspecto que presentan en el corte en un plano del glomérulo para estudiar su histología. Son destructivas y su rápido aumento de tamaño conduce a la oclusión de las redes glomerulares. Si la lesión aguda cesa las semilunas pueden resolverse con restitución de la morfología normal o curar con fibrosis y causar la pérdida irreversible de la función renal. Las semilunas son más frecuentes en casos de vasculitis, en la enfermedad de Goodpasture y en las formas agudas graves de glomerulonefritis de cualquier etiología. En la glomerulonefritis también puede haber lesión tubulointersticial y fibrosis, las que posiblemente desempeñen un papel importante en el pronóstico.
Para identificar fenómenos reactivos inmunitarios se utilizan inmunofluorescencia indirecta y tinción con inmunoperoxidasa. La tinción se usa para detectar IgG, IgA e IgM, componentes del sistema del complemento (habitualmente C3, C4 y Clq) y fibrina, que suele verse en las semilunas y en los capilares en los trastornos trombóticos (como el síndrome urémico hemolítico y el síndrome antifosfolípidos). Puede haber depósitos inmunes a lo largo de las asas capilares o en el mesangio y es posible que sean continuos (lineales) o discontinuos (granulares).

Los síntomas comunes en los pacientes con glomerulonefritis incluyen hematuria, proteinuria y edema facial, edema palpebral y edema de los tobillos, los pies, las piernas o el abdomen. Otros síntomas posibles son dolor abdominal, hematemesis, melena, tos, disnea, diarrea, poliuria, fiebre, malestar general, fatiga, anorexia, artralgia y epistaxis. 
Si la enfermedad es crónica el paciente puede desarrollar síntomas con el tiempo.

La glomerulonefritis es una causa importante de morbilidad y mortalidad y una causa potencialmente prevenible de enfermedad renal terminal de manera que es vital que se establezca el diagnóstico temprano para permitir la remisión oportuna de los pacientes a unidades especializadas en la biopsia renal.

El mejor método para el diagnóstico de las enfermedades renales de etiología inmunitaria consiste en realizar la biopsia renal y estudiar con microscopia óptica los tejidos teñidos porque de ese modo se podrá anticipar el pronóstico y seleccionar el tratamiento adecuado. Sin embargo, como hay varios mecanismos inmunitarios que pueden provocar cambios morfológicos similares, también resulta útil la microscopia de inmunofluorescencia con anticuerpos específicos marcados con fluoresceína para determinar el tipo y la localización de los compuestos inmunes en el riñón. Además, la biopsia renal es importante porque no solo permite saber dónde se encuentra la lesión histológica o qué mecanismos intervienen sino también el grado de importancia de dicha lesión, un factor fundamental para decidir qué tipo de manejo terapéutico se requiere y en qué momento iniciarlo.

Se pueden emplear criterios clínicos, pero el diagnóstico requiere confirmación histológica con una sola excepción, a saber, la enfermedad por cambios mínimos en el niño. En ese caso se considera diagnóstica la respuesta positiva al tratamiento con esteroides.

En la enfermedad renal mediada por anticuerpos (anticuerpos antimembrana basal glomerular, anticuerpos anti-HLA) los análisis serológicos pueden detectar anticuerpos citotóxicos en la circulación y en la granulomatosis de Wegener (una nefropatía mediada por anticuerpos anticitoplasma de neutrófilos o ANCA) se pueden encontrar ANCA circulantes.

Las anomalías en la concentración de las proteínas del complemento en general permiten distinguir los tipos de nefropatía mediada por procesos inmunitarios. Cuando predomina la activación por vía alternativa (como sucede en la glomerulonefritis membranoproliferativa y con frecuencia en la posestreptocócica), el consumo de complemento empieza con la activación de C3, por lo que los primeros elementos del complemento (C1q, C4 y C2) no disminuyen. Cuando se activa la vía clásica (como en el lupus eritematoso sistémico), el consumo empieza en los primeros componentes, que por ende estarán disminuidos. La presencia de un factor nefrítico C3 con niveles bajos de C3 y normales de C1q, C4 y C2 es prácticamente diagnóstica de glomerulonefritis membranoproliferativa por activación de la vía alternativa.

El diagnóstico diferencial de la glomerulonefritis sin enfermedad sistémica incluye glomerulonefritis posestreptocócica, nefropatía por IgA, glomerulonefritis rápidamente progresiva y glomerulonefritis membanoproliferativa. Es probable que la inflamación glomerular sea inducida directamente por una proteína estreptocócica nefritógena en la glomerulonefritis posestreptocócica y por el depósito mesangial de agregados inmunes con contenido de IgA1 de glicosilación anormal en la nefropatía por IgA. En la glomerulonefritis rápidamente progresiva con formación de semilunas cada vez está más claro que intervienen mecanismos inmunitarios celulares en lugar de humorales. En muchos pacientes con glomerulonefritis membanoproliferativa existe una infección crónica por el virus de la hepatitis C.

El tratamiento varía según la patogenia. Se han elaborado varias alternativas terapéuticas, pero muchas de estas enfermedades siguen siendo resistentes a todos los tratamientos. Por ejemplo, no existe una terapia específica eficaz para la glomerulonefritis posestreptocócica o la nefropatía por IgA. Habitualmente se aplican medidas generales y un tratamiento para aliviar los síntomas. Si hay infección activa se indica la antibioticoterapia correspondiente. Los pacientes con glomerulonefritis rápidamente progresiva se benefician con la administración de altas dosis de esteroides y terapia con drogas citotóxicas más el agregado de plasmaféresis en la enfermedad inducida por anticuerpos contra la membrana basal glomerular. Los tratamientos antivirales reducen la gravedad de la glomerulonefritis membranoproliferativa debida al virus de la hepatitis C. Para hallar una terapéutica eficaz se están desarrollando nuevas formas de tratamiento dirigidas contra citocinas específicas, factores de crecimiento, depósito de fibrina y otros mediadores de la lesión así como formas más específicas y menos tóxicas de inmunoterapia.

Los principios de los tratamientos nuevos incluyen la modulación de los mecanismos inmunitarios del huésped para eliminar el antígeno, el anticuerpo o los complejos inmunes, la inducción de inmunosupresión mediante fármacos inmunosupresores y la administración de agentes antiinflamatorios y, en algunos casos, de fármacos inhibidores de las plaquetas y anticoagulantes. Si no se logra la erradicación del antígeno habrá que reducir la carga antigénica y crear un exceso de anticuerpos para favorecer la eliminación de los complejos inmunes por el sistema fagocítico mononuclear normal. La plasmaféresis resulta beneficiosa en la enfermedad por anticuerpos antimembrana basal glomerular y el lupus eritematoso sistémico. Aparte del lupus y quizá también la glomerulonefritis membranosa pocas enfermedades responden a la administración de esteroides diarios o en dosis grandes. En la granulomatosis de Wegener y tal vez también en la glomerulonefritis membranosa y el lupus el fármaco de elección es la ciclofosfamida. Para la glomerulonefritis membranoproliferativa de tipo I el único tratamiento recomendado es la administración de inhibidores de las plaquetas (dipiridamol, aspirina y ticlopidina). Los niveles de anticuerpos citotóxicos son difíciles de reducir en la glomerulonefritis membranoproliferativa de tipo II a causa de la persistencia del antígeno estimulador.

Uno de los primeros objetivos del tratamiento es el control de la presión arterial, lo que puede resultar muy difícil si los riñones funcionan mal. Cuando hay hipertensión se prescriben inhibidores de la enzima convertidora de angiotensina (p. ej., captopril) o antagonistas de los receptores de esa enzima (p. ej., losartán). Para reducir la inflamación desencadenada por la respuesta inmunitaria se indican corticosteroides y si no dan resultado se puede recurrir a la plasmaféresis (con la que parte del plasma se elimina y se reemplaza por líquidos intravenosos o plasma de donante —sin anticuerpos—).

En la forma crónica de la enfermedad es preciso reducir la ingesta de proteínas, sal y potasio de la dieta. Es posible que se indiquen suplementos de calcio y que se requieran diuréticos para reducir el edema. 

Si de todos modos la enfermedad avanza y el paciente desarrolla insuficiencia renal habrá que recurrir a la diálisis.

La glomerulonefritis puede ser una enfermedad temporal y reversible o puede empeorar. Es posible que la glomerulonefritis progresiva conduzca a insuficiencia renal crónica, deterioro de la función renal o enfermedad renal terminal. Si existe síndrome nefrótico y se lo puede controlar es posible que también se puedan controlar otros síntomas. En cambio, si no se lo puede controlar el resultado posible es una enfermedad renal terminal.



</doc>
<doc id="41283" url="https://es.wikipedia.org/wiki?curid=41283" title="Enfermedades hereditarias o congénitas de los riñones">
Enfermedades hereditarias o congénitas de los riñones

Algunas enfermedades de los riñones son el resultado de factores hereditarios. Por ejemplo, la poliquistosis renal es un trastorno genético en que se forman muchos quistes en los riñones. Los quistes formados en esta enfermedad pueden reemplazar lentamente gran parte de la masa del tejido de los riñones, lo que reduce la función renal y conduce a insuficiencia renal.

Algunos problemas de los riñones pueden presentarse cuando el niño está todavía en el vientre de la madre. Son ejemplos de ellos la poliquistosis renal recesiva autosómica, una forma rara de poliquistosis renal, y otros problemas del desarrollo que obstaculizan la formación normal de las nefronas. Los signos de enfermedad de los riñones en los niños varían. Un niño puede tener un crecimiento anormalmente lento, vomitar a menudo o tener dolor de espalda o del costado. Algunas enfermedades de los riñones pueden ser "silenciosas" por meses o aún años.

Es posible que algunas enfermedades hereditarias de los riñones no se detecten sino hasta la edad adulta. La forma más común de poliquistosis renal se llamó alguna vez "poliquistosis renal del adulto" porque los síntomas de tensión arterial alta e insuficiencia renal no ocurren sino hasta que los pacientes pasan de 20 ó 30 años. Pero con los adelantos de la tecnología de diagnóstico por imágenes, los médicos han descubierto quistes en los niños y adolescentes antes de que se presenten los síntomas.



</doc>
<doc id="41286" url="https://es.wikipedia.org/wiki?curid=41286" title="Disfunción eréctil">
Disfunción eréctil

La disfunción eréctil (antes "impotencia sexual"; véase más abajo) es la incapacidad repetida de lograr o mantener una erección lo suficientemente firme como para tener una relación sexual satisfactoria.

La disfunción eréctil (o DE) puede ser, aunque no necesariamente, una incapacidad para alcanzar una erección satisfactoria, una capacidad inconsistente para hacerlo o bien la tendencia a tener únicamente erecciones breves. 

Estas variaciones hacen difícil definirla y calcular su incidencia.

Los cálculos varían desde 20 hasta 30 millones de casos, según la definición que se utilice. De acuerdo con la encuesta de Atención Médica Ambulatoria Nacional (NAMCS, según sus siglas en inglés), por cada 1.000 hombres en Estados Unidos, hubo un total de 7,7 visitas al consultorio médico por DE en 1985. En 1999, la frecuencia casi se había triplicado a 22,3. El aumento se produjo de modo gradual, presuntamente a medida que se pusieron a disposición más ampliamente tratamientos tales como los dispositivos de vacío y los medicamentos inyectables y comenzó a aceptarse la discusión de la disfunción eréctil. Es posible que el avance más publicitado haya sido la introducción del medicamento oral citrato de sildenafil (Viagra) en marzo de 1998. Los datos de NAMCS acerca de medicamentos nuevos muestran un cálculo de 2.6 millones de menciones de Viagra en visitas al consultorio médico en 1999, y un tercio de esas menciones tuvieron lugar durante visitas para un diagnóstico no relacionado con DE.

En los hombres mayores, la DE generalmente tiene una causa física, como una enfermedad, una lesión o efectos secundarios de medicamentos. Cualquier trastorno que cause una lesión en los nervios o que deteriore el flujo de sangre al pene puede causar DE. La incidencia aumenta con la edad: alrededor del 5 por ciento de los hombres de 40 años de edad y entre el 15 y el 25 por ciento de los hombres de 65 años de edad experimentan DE. Sin embargo, la disfunción eréctil no es necesariamente una parte inevitable del proceso de envejecimiento.

Debido a que una erección requiere una secuencia precisa de eventos, la DE puede presentarse cuando cualquiera de tales eventos se interrumpe. La secuencia completa incluye los impulsos de los nervios en el cerebro, en la columna vertebral y en el área alrededor del pene, así como las respuestas de los músculos, los tejidos fibrosos, las venas y las arterias en y cerca de los cuerpos cavernosos del pene.

La causa más común de DE es el daño a las arterias(La etiología vascular de la disfunción eréctil está presente en el 60% de los pacientes con DE. ), a los nervios, a los músculos lisos y a los tejidos fibrosos, a menudo como resultado de una enfermedad. Enfermedades tales como la diabetes, las afecciones del riñón, el alcoholismo crónico, la esclerosis múltiple, la arteriosclerosis, la psoriasis, las enfermedades vasculares y las enfermedades neurológicas son responsables de alrededor del 70 por ciento de los casos de DE. Entre el 35 y el 50 por ciento de los varones con diabetes padecen DE.

Una cirugía (especialmente la cirugía radical de próstata, debido a cáncer) puede lesionar también nervios y arterias cerca del pene y causar DE. Una lesión en el pene, en la columna vertebral, en la próstata, en la vejiga y en la pelvis puede llevar a DE y producir lesión en los nervios, en los músculos lisos, en las arterias y en los tejidos fibrosos de los cuerpos cavernosos.

Además, muchos medicamentos comunes —medicamentos para la presión arterial, antihistamínicos, antidepresivos, tranquilizantes, supresores del apetito y cimetidina (un medicamento para la úlcera)— pueden causar DE como efecto secundario.

Factores emocionales tales como el estrés, la ansiedad, la culpa, la depresión, una baja autoestima y el miedo a no funcionar bien en el coito como se espera causan del 10 al 20 por ciento de los casos de DE. Los hombres con una causa física de DE experimentan a menudo el mismo tipo de reacciones psicológicas (estrés, ansiedad, culpa, depresión).

Otras causas posibles son el tabaquismo y el consumo excesivo de bebidas alcohólicas y el consumo excesivo de la marihuana, que afectan el flujo sanguíneo en las venas y en las arterias, y anormalidades en las hormonas, como, por ejemplo, una cantidad insuficiente de testosterona. El incremento de prolactina que pueden producir algunos fármacos, como los ansiolíticos y antipsicóticos (risperidona, olanzapina, haloperidol), puede provocar también disfunción eréctil. Las causas hormonales suelen afectar también la libido.

La DE es tratable a cualquier edad, y el conocimiento de este hecho ha ido creciendo. Más hombres han buscado ayuda y regresado a la actividad sexual normal debido a tratamientos mejorados y exitosos de la DE. Tradicionalmente los urólogos, quienes se especializan en problemas de las vías urinarias, han tratado la DE; sin embargo, los urólogos solo son responsables del 25 por ciento de las menciones de sildenafilo en 1999.

En general, los especialistas en medicina familiar (médicos de cabecera especializados) son, junto a los urólogos, los cardiólogos y los psiquiatras, los mejor formados para la valoración, manejo y tratamiento de la disfunción eréctil. Las principales ventajas que aportan frente a los demás especialistas son la visión integral del paciente, la proximidad, la accesibilidad y la capacidad para la entrevista clínica.

En la actualidad estudiando la aplicación de la terapia con células madres en el tratamiento de la disfunción eréctil. La mayoría de estudios en animales modelo se han hecho a partir de células madre de la médula ósea, del tejido adiposo u obtenidas del cordón umbilical. Los resultados indican que la inyección de células madre beneficia la restauración de la función eréctil y la fisiología del pene. Estas mejoras parecen deberse a factores paracrinos secretados por las células inyectadas: crioprotectores, anti-fibróticos y moléculas anti-apoptóticas, más que por la diferenciación de estas células madre. El único estudio preclínico llevado en pacientes fue a partir de células del cordón umbilical que fueron inyectadas en pacientes con disfunción eréctil asociada a la diabetes. Los pacientes experimentaron una mejora en la erección y un aumento en la rigidez del pene, especialmente cuando se combinaban con las clásicos inhibidores de la fosfodiesterasa. 

Aunque el término "impotencia" (del latín "impotens", "no poder") se usa coloquialmente para describir los problemas que interfieren con la relación sexual y con la reproducción, tales como la falta de deseo sexual (véase libido) y los problemas con la eyaculación o con el orgasmo, los especialistas en sexología y educación sexual concuerdan, sin embargo, que el uso del término "disfunción eréctil" resulta mucho más adecuado, pues no implica una calificación ni un prejuicio de la persona que presenta esa dificultad.

Es la incapacidad del varón para obtener o mantener una erección suficiente y realizar un coito satisfactorio. La DE es una situación muy frecuente; se ha calculado que afecta en mayor o menor grado a la mitad de los hombres entre los 40 y los 70 años. Pero no es un tema que se trate abiertamente, pues forma parte de la vida íntima de los individuos y de las parejas. Mitos y expectativas culturales de la sexualidad masculina han impedido a muchos varones buscar ayuda para un trastorno que puede beneficiarse, en la mayoría de los casos, de un tratamiento relativamente sencillo.

Aunque puede decirse con seguridad que todo hombre experimenta de vez en cuando dificultades para mantener la erección, la disfunción eréctil se define como la incapacidad para mantener una erección suficiente para el coito al menos en el 25 por ciento de los intentos.

"Impotencia sexual" es el nombre con el que se sigue conociendo a la disfunción eréctil. Ya no se considera el nombre técnicamente correcto, sin embargo. Es la incapacidad constante de mantener la erección suficiente para el coito. Los hombres tensos, con ansiedad y sobreocupados en ocasiones no pueden lograr esa concentración necesaria, lo que genera dificultad para obtener y sostener la erección del pene. Existen otras causas, como los problemas vasculares. También sigue usándose el término latino "impotencia erigendi", es decir, la incapacidad para la erección del pene.

El término "impotencia" se aplica también, médicamente, en los siguientes casos:


Pueden aparecer combinadas:


La DE se puede presentar por alteración de uno o varios de los tres mecanismos responsables de la erección: bloqueo de las arterias; incapacidad de los vasos sanguíneos dentro del pene para almacenar la sangre, o daño en los nervios del pene o del área pelviana. También pueden ser responsables de una DE otras disfunciones fisiológicas, como bajos niveles de hormona masculina (testosterona).

Las situaciones que más frecuentemente producen DE son: enfermedades que afectan a los vasos sanguíneos y restringen el flujo sanguíneo hacia el pene, como la diabetes, la hipertensión (tensión arterial alta), el exceso de colesterol o las enfermedades cardíacas. Situaciones que interrumpen la conexión entre el sistema nervioso y el pene, como la cirugía de próstata o lesiones traumáticas en la zona. Muchos medicamentos (algunos de ellos empleados para tratar la hipertensión y las depresiones) causan DE entre los efectos secundarios no deseados. Depresión nerviosa.

Los hábitos de riesgo que pueden conducir a que se desarrolle DE son: el consumo de sustancias adictivas legales (tabaquismo, el consumo excesivo de alcohol) o ilegales, el estrés. Un indicador de la DE física, en contraposición con la psicológica, es la incapacidad de experimentar o mantener una erección al despertarse por la mañana. La DE que persista por más de tres meses y que no sea debida a un suceso estresante evidente, al consumo de sustancias adictivas, al consumo de alcohol o a afecciones médicas transitorias que causan DE señala la necesidad de recibir atención médica por parte de un urólogo.

Existen muchos malentendidos en este tema. Como resultado del proceso de envejecimiento, suele haber un periodo refractario mayor —tiempo necesario para una nueva erección después de un orgasmo. La edad también parece afectar el tiempo necesario para excitarse y para la erección y la eyaculación. Todos estos se consideran cambios no patológicos. Sin embargo, la sexualidad no tiene fecha de caducidad. Si la DE se da más en personas mayores, es solo porque es más probable que sufran enfermedades asociadas a la DE y que usen más medicamentos que alteren la función eréctil.

Cuando no hay estimulación sexual, el flujo de sangre dentro del pene es muy bajo, lo que lo mantiene en estado flácido o no erecto. Cuando se recibe estimulación sexual (a través de cualquiera de los órganos de los sentidos o incluso de la imaginación), las arterias del pene se relajan y se dilatan, y el flujo sanguíneo hacia el pene aumenta mucho. A medida que el pene se expande, las venas del pene —que tendrían que devolver la sangre del pene hacia la circulación de retorno— se comprimen, y la sangre no puede salir. Con un aumento en el flujo sanguíneo que entra y una reducción en el flujo que sale, el pene se vuelve cada vez más grande y se pone cada vez más duro (véase cuerpos cavernosos).

Al ser causada por diversas enfermedades, se impone un estudio multidisciplinario integrado en un mismo equipo de trabajo. Se realiza una exhaustiva historia clínica del caso, se realizan estudios bioquímicos y hormonales, un perfil psicológico, pruebas vasculares y estudios radiológicos. Todo esto, sumado a un examen físico uroandrológico, cardiocirculatorio y neurológico, conduce al diagnóstico.

Interesa recoger problemas médicos actuales y previos, medicamentos que se estén tomando y antecedentes de problemas psicológicos (estrés, ansiedad, depresión). El médico también requerirá antecedentes sexuales —inicio de la DE, frecuencia, calidad y duración de cualquier erección, etc.— e investigará la motivación para el tratamiento y las expectativas del paciente. La DE es lógicamente cosa de dos, y puede ser apropiado entrevistar a la pareja sexual (cualquiera que sea la preferencia sexual del paciente).

Examen físico. Incluye una exploración del área genital y un tacto rectal (examen del recto con un dedo enguantado). Deben buscarse evidencias de otras enfermedades —hipertensión, diabetes, ateroesclerosis, daño nervioso, etc.—.

Los más utilizados son el IIEF (International Index of Erectile Function, es decir, el Índice Internacional de la Función Eréctil) y su versión más sencilla: el test SHIM (Sexual Health Inventory for Men, es decir, el Inventario de Salud Sexual para Varones).

Se requieren análisis de sangre para medir los niveles de testosterona y, si es necesario, los de prolactina para determinar si hay problemas del sistema endocrino. Pueden ser necesarios diversos exámenes específicos para detectar la DE, como pruebas de respuesta eréctil tras inyección de medicamentos que dilatan los vasos sanguíneos del pene o detección de erecciones nocturnas mediante diversos dispositivos.

La cavernosometría y la cavernosografía de infusión dinámica (DICC) es una prueba en la que se induce una erección con medicamentos, se mide la capacidad de almacenamiento del pene, se hace una ecografía de las arterias del pene (para medir la presión arterial) y se realiza una radiografía del pene erecto para obtener datos anatómicos precisos. Solo es necesaria en algunos casos de DE.

Menos del 10 por ciento de los hombres que sufren DE buscan ayuda médica. Al enfrentarse con la DE, es frecuente que se desmoralicen, que se depriman o que busquen tratamientos milagrosos. Existen innumerables remedios populares que se deben considerar con toda cautela y escepticismo. Actualmente existen muchos tratamientos eficaces y muy seguros, aunque en ningún caso mágicos. 

La modalidad del tratamiento viene dictada por el problema específico que causa la disfunción eréctil. El primer paso es definir la causa, si es posible, y luego intentar la solución más sencilla y menos arriesgada. En síntesis, las distintas alternativas terapéuticas incluyen una o varias de las siguientes:


Cambiar los hábitos de vida que afectan a la salud de las arterias y venas: no fumar, moderar el consumo de alcohol y de grasas (particularmente grasas saturadas), hacer algo de ejercicio y aprender a relajarse.

Muchos especialistas opinan que una de las medidas preventivas más efectivas consiste en hacer el amor frecuentemente con una pareja afín, buscando el placer. Aunque no tiene que ser necesariamente con una pareja estable, recomendación que sí es necesaria para reducir las probabilidades de contagio de una infección de transmisión sexual, pero no un requisito absoluto para el buen desempeño en el coito.




</doc>
<doc id="41288" url="https://es.wikipedia.org/wiki?curid=41288" title="Erección">
Erección

La erección (del latín "erectio", acción de erguir o erigir) es el endurecimiento del pene, del clítoris, de los pezones, con agrandamiento y estado firme. Su consecución depende de complejas interacciones psicológicas y virtuales, neurales, vasculares y endocrinas. El término también se aplica al proceso que lleva a este estado. La erección del pene permite al varón el coito y la masturbación.

El pene contiene dos cámaras llamadas cuerpos cavernosos, las cuales ocupan el largo del órgano. Un tejido esponjoso llena las cámaras. Los cuerpos cavernosos están rodeados por una membrana, llamada túnica albugínea. El tejido esponjoso contiene músculos lisos, tejidos fibrosos. La albugínea ayuda a atrapar la sangre en los cuerpos cavernosos y con ello sostiene la erección. Cuando los músculos del pene se contraen para parar el flujo de entrada de la sangre y abrir el flujo de salida de los canales, la erección se revierte.

Un pene erecto puede tomar un número de diferentes formas y ángulos, desde un tubo recto en un ángulo de 45-90º, o con una curvatura a izquierda o derecha, o arriba o abajo. Una fuerte curvatura peneana, conocida como enfermedad de Peyronie, puede remediarse usualmente con cirugía. Generalmente el tamaño de un pene erecto se fija genéticamente, a través de la vida, y poco puede hacerse para incrementarlo sin modificar sus tejidos directamente a través de la "cirugía" peneana.

Mientras que los púberes experimentan y exploran sus erecciones privadas, sin causar ningún quebrantamiento social, una erección pública está severamente cuestionada y estigmatizada, aun en sociedades contemporáneas. Posiblemente se lo vincula a un desorden psicológico no deseado por la sociedad. Generalmente, la mayoría de los niños que están entrando a la pubertad son los máximos exponentes a experimentar una erección descontrolada y que les produce intensa turbación. Pero puede ocurrir en cualquier momento de la vida, en el peor momento en público, debido a una reacción involuntaria, posiblemente exacerbada por la ropa interior excesivamente ceñida que cause estimulación por rozamiento. Con el tiempo los niveles hormonales bajan y los adultos y jóvenes dejan de ser tan sensibles a erecciones en momentos socialmente inoportunos, como primeras citas de pareja sin acercamiento sexual, en baños públicos o en cambiadores de clubes masculinos.

Existe una prevención e imposibilitación física directa de la erección masculina, posible por el uso de ropa interior elástica apretada, shorts de compresión de atletas, suspensorios, y vaqueros apretados colocando el pene flácido en una posición descendente en la bolsa. Si ocurriera una erección, el tejido textil ajustado y elástico impide el aumento de la presión sanguínea interna, constriñendo su agrandamiento y alargamiento; así se previene que la erección se haga visible, sin causar daño al pene restringido.

El clítoris es el homólogo anatómico del pene, y los mecanismos fisiológicos y psicológicos de su erección son similares.

La erección del clítoris suele formar parte de la excitación sexual de la mujer, pero debido a que mucha de su anatomía permanece dentro de su capuchón, puede no ser tan obvio para la pareja.
El punto de Gräfenberg es una pequeña zona del área genital de las mujeres que se encuentra por dentro de la vagina, detrás del hueso púbico y alrededor de la uretra. Durante la excitación sexual, el área alrededor del punto G se hincha, haciéndolo más prominente y fácil de estimular. La estimulación del punto G (a través de la pared frontal de la vagina) puede propiciar en muchas mujeres un orgasmo más vigoroso y prolongado, y es posiblemente la causa de la eyaculación femenina.

Muchos sexólogos aconsejan a las mujeres incapaces de lograr un orgasmo el considerar la estimulación del punto G como técnica sexual. Esto se puede lograr de manera manual, por medio de vibradores o utilizando que facilitan la estimulación del pene a la pared frontal de la vagina. Por ejemplo, posturas de penetración desde atrás.

La erección de pezones, y frecuentemente de toda la mama: 

Ambos procesos son causados por la emisión sanguínea de oxitocina. Esta erección también la pueden causar las bajas temperaturas ambientales, en ambos sexos. Allí se debe a una respuesta táctil al frío, mucho más que nada vinculado a los preliminares sexuales. 

La erección de pezones no se debe a la erección de tejidos, sino a la contracción de músculos lisos, bajo el control del sistema nervioso autónomo.




</doc>
<doc id="41289" url="https://es.wikipedia.org/wiki?curid=41289" title="Chiismo">
Chiismo

El chiismo, islam chií o islam chiita (o chía, ) constituye una de las principales ramas del islam junto al sunismo. Es el nombre tradicional por el que se conoce a la escuela de jurisprudencia islámica Ya'farita. El chiismo es profesado por alrededor del 15 % de los 1600 millones de musulmanes existentes en el mundo.

Un seguidor del islam es conocido como “musulmán”, mientras que un musulmán que cree que Ali ibn Abi Tálib fue el sucesor y califa inmediato del profeta Mahoma es llamado "“chía”" —forma abreviada de "“chíat-u-Ali”", que significa “partidario de Alí”— término que ha sido castellanizado como "chiita".

"Chía", que significa literalmente ‘partidarios’ o ‘seguidores’, se refiere a aquellos que consideran que la sucesión del Profeta es un derecho especial de la familia de este, y a aquellos que en el campo de las ciencias y cultura islámicas siguen la escuela de la Casa del Profeta.

Etimológicamente, chía deriva del árabe shi‘a, que significa facción, partido, o seguidor. Se refiere históricamente a los seguidores de la shi'a del Imam Ali, partido, facción o seguidores de Alí, en las luchas por el poder que siguieron a la muerte de Mahoma. Los chiíes consideran que poco antes de su muerte, Mahoma, al regresar de la peregrinación a La Meca, reunió a más de 100 000 creyentes en Ghadir Jum y dijo ante ellos que quienes le considerasen su maestro hiciesen lo mismo con 'Ali Ibn Abu Tálib. 

En el Corán se menciona que en su regreso de la última peregrinación, el Profeta Mahoma recibió la siguiente orden de Dios: 

Mahoma se detuvo en Ghadir al-Jumm el 18 de Du l-Hiyya del décimo año de la Hégira para comunicar el mensaje a los peregrinos antes de que se dispersaran. Como hacía mucho calor, se construyó una tarima cubierta con ramas para él. Luego el Profeta dio un sermón muy extenso. En un punto le preguntó a sus fieles seguidores si él (Mahoma) tenía más autoridad ("awla") sobre los creyentes de la que ellos tenían sobre sí mismos. La multitud gritó: "Sí, es así Oh Apóstol de Alá". Entonces Mahoma tomó a Ali ibn Abi Tálib, su primo y yerno, de la mano y declaró: 

“Para quien yo sea su Maulá, este Alí también es su Maulá ("Man kuntu Maulahu fa hada Aliyun maulahu")”.

El 8 de "Du l-hiyya" de cada año se celebra en el mundo chiita el aniversario de la declaración de Ghadir al-Jumm.

Cuando murió Mahoma en el año 632, un grupo de sus compañeros decidieron ignorar la proclamación de Ghadir al-Jumm y nombraron de entre ellos al sucesor del Profeta. No obstante, parte de los creyentes tomaron partido por Ali ibn Abi Tálib, primo y yerno de Mahoma, ya que consideraban que este era su único sucesor legítimo dado que había sido la persona más cercana a Mahoma, y el Profeta lo había señalado como sucesor en varias ocasiones, la más notable en Ghadir al-Jumm. Este grupo de "partidarios de Alí (chíat-u-Ali)" se negaron a reconocer a los sucesivos califas o sucesores del Profeta: Abu Bakr, Ómar y Uthmán.

Tras la muerte de este último, Alí es finalmente elegido califa. Sin embargo, acusado de haber instigado la muerte de su predecesor, su poder será contestado por Mu'awiya, gobernador de Siria y miembro de la familia de los Omeyas, iniciándose así una guerra civil entre ambas facciones. En el campo de batalla de Siffín ambos líderes aceptaron someter sus diferencias al dictamen de un árbitro independiente. Sin embargo, de las filas de Alí surgirá una tercera facción, la de los jariyíes, que no aceptaron el arbitraje. Esta facción asesinó a Alí en el 661, y el mismo día trataron de acabar también con Mu'awiya y con el árbitro, sin lograrlo. 

Los partidarios de Alí pusieron entonces sus esperanzas en su hijo Hasan, que presionado y engañado por Mu'awiya renunció al poder. El segundo hijo de Alí, Husáyn ibn Ali, se negó a jurar lealtad a Mu'awiya, debido a su corrupción, y fue muerto junto a 72 seguidores en la Batalla de Karbalá (Irak) contra el ejército de Yazid, hijo de Mu'awiya, compuesto por más de treinta mil hombres. Su muerte en el campo, en 680, marcará el principio del cisma entre los chiíes y aquellos a quienes se llamará más tarde «suníes». Los chiíes conmemoran este suceso el día de Ashura, el décimo día del mes Muharram.

Tras el suceso de Ashura (el martirio de Husáyn ibn Ali) los chiíes nombraron a Ali ibn al-Husayn como el siguiente Imam. Sin embargo, una minoría, conocida como Kisaniyah, siguió a Muhámmad Ibn Hanafiyah como su Imam y lo consideró como el cuarto y último Imam.

Ali ibn al-Husayn muere martirizado el año 95 de la Hégira en Medina (el 712 en el calendario gregoriano). Los chiíes nombran entonces a Muhammad al-Baqir como siguiente Imam. De nuevo, una minoría, conocida como los Zaidíes, discrepó de esta sucesión y consideraron que el Imam debía ser Zaid Ibn Alí, otro hijo del Imam Sayyad.

Tras la muerte de Muhammad al-Baqir, los chiíes nombraron Imam a Ya`far as-Sadiq y luego a Musa ibn Ya'far (Musa al-Kazim). Este último nombramiento causó un nuevo cisma entre los chiíes, puesto que un grupo consideró que Ismael (otro hijo del Ya`far as-Sadiq) debía ser el siguiente Imam después de Sadiq. Son los llamados Ismailíes. Simultáneamente, otro grupo, conocido como los Fatahíes, siguió a Abdul·lah Aftah, hermano de Musa ibn Ya'far.

Musa ibn Ya'far muere el 25 de Rayab del año 183 de Hégira, y los chiíes nombran como siguiente Imam a Ali ibn Musa (Alí ibn Musa ar-Rida). Algunos chiíes conocidos como los Waqifiyah (aquellos que se detuvieron en el séptimo Imam) consideran que no hay ningún Imam tras la muerte de Musa ibn Ya'far.

Tras el martirio de Ali ibn Musa, los chiíes siguieron a su hijo Muhammad al-Yawad y, más tarde, a Ali al-Hadi. Después de su martirio los chiíes siguieron a Hasan al-Askari y luego también a Mahdi ibn Hasan.

Este último tiene una especial consideración para los chiíes. Según sus creencias, el Mahdi sigue con vida, oculto. También creen que es el salvador esperado por la humanidad.

Los imanes de los chiíes son doce:

La fe islámica chiita es vasta e incluye muchos grupos diferentes. Las creencias teológicas y prácticas religiosas chiíes, como sus oraciones, difieren ligeramente de las de los suníes. Si bien todos los musulmanes oran cinco veces al día, los chiíes tienen la opción de combinar el "Dhuhr" con el "Asr" y el "Magrib" con el "Isha'," en tanto hay tres distintas horas mencionadas en el Corán. Los suníes tienden a combinarlas sólo bajo ciertas circunstancias. El islam chií comprende un sistema completamente independiente de interpretación religiosa y autoridad política en el mundo musulmán. La identidad chií original se refería a los seguidores del Imán Alí y la teología chií se formuló en el siglo II A.H. (después de la Hégira, siglo VII d.C.). Los primeros gobiernos y sociedades chiíes se establecieron para finales del siglo II AH (siglo IX d.C.). Louis Massignon se ha referido al siglo IV AH (siglo X d.C) como "el siglo ismaelí chiíta en la historia del Islam."

Según la doctrina chií los principios de la religión son cinco:
Los chiíes creen en la existencia de un único Dios, creador y gobernante. La mayoría de los versículos del Corán sobre esta materia enfatizan la Unidad de Dios con respecto a la Creación, las órdenes (la dirección del mundo) y el culto. En él se indica que Dios es el único creador del mundo, que solamente Él tiene la autoridad soberana sobre el mismo, y por lo tanto, solamente Él merece ser adorado.
Todos los musulmanes (incluyendo a los chiíes) creen en la Justicia de Dios ya que la justicia debe formar parte de los atributos de la perfección que se le atribuyen. Basan esta creencia en las palabras del Corán que niega para Dios cualquier forma de opresión y se refiere a Él como “establecedor de la equidad”.

La imamah (Imamato o liderazgo) posee en el islam un sentido amplio, que abarca tanto el liderazgo intelectual como la autoridad política. Tras el fallecimiento del Profeta, se buscó en el Imam a alguien capaz de enseñar a la gente la cultura coránica, las verdades religiosas y las disposiciones sociales, alguien digno de ser seguido (e imitado) en todos los aspectos, métodos y dimensiones, de modo que se preservara el legado de Mahoma y sus objetivos, así como para dar continuidad a la conducción de sus creyentes.
"Yaum al-Qiyamah" (يوم القيامة; literalmente: "Escatología o Día de la Resurrección" (Corán 71:18), también conocida como "la Hora" (Corán 31,34, 74,47), "Día de la Cuenta" (Corán 72.130), "Día del Encuentro", "Día del Juicio", "Día de la angustia" (Corán 74,9), o el "Gran Anuncio") es el Juicio Final para los creyentes chiíes.

Los chiíes creen en Qiyamah como uno de los principios fundamentales del islam. Creen que después de la aniquilación de este mundo, Dios levantará la humanidad para el Juicio Final. En este juicio cada uno será responsable de lo que haya cometido (Corán 74,38), y cada ser humano tendrá que responder ante sus hechos.

Según la doctrina chií las ramificaciones de la religión, siguiendo la clasificación más utilizada, son:

Los chiíes creen que el estatus de Alí tiene soporte en numerosos hadices, incluyendo el Hadiz del Estanque de Khumm, el Hadiz de las dos cosas pesadas, el Hadiz de la pluma y el papel, el Hadiz de la invitación de las familias cercanas y el Hadiz de los Doce Sucesores. En particular, el Hadiz del Manto es citado con frecuencia para ilustrar los sentimientos de Mahoma hacia Alí y su familia por parte de escolares tanto suníes como chiíes. Los chiíes prefieren hádices atribuidos a los Ahlul Bayt y sus compañeros cercanos, y tienen su propia colección de hadices.

La versión chiita de la Shahada, el credo islámico, difiere de la de los suníes. La Shahada suní afirma que "No hay dios con excepción de Dios, Mahoma es el mensajero de Dios," pero a esto los chiíes añaden que "Alí es el Wali (custodio) de Dios" ( علي ولي الله). Esta frase ejemplifica el énfasis chií en la herencia de autoridad a través del linaje de Mahoma. Las tres cláusulas de la Shahada chií abordan por tanto el "tawhid" (la unidad de Dios), el "nubuwwah" (el profetismo de Mahoma), y el "imamah" (imanato, el liderazgo de la fe). 

La base de Alí como el "wali" es tomada de un verso específico del Corán, la Aleya de Wilayah.

"Ismah" es el concepto de infalibilidad o "libertad otorgada por Dios sobre el error y el pecado" en el Islam. Los musulmanes creen que Mahoma y otros profetas en el islam poseían "ismah". Los musulmanes chiíes imamíes (duodecimanos) e ismaelíes le atribuyen también esta cualidad a los Imánes así como a Fátima, la hija de Mahoma, en contraste con los zaidinos, que no le atribuyen "ismah" a los Imanes. Aunque empezó inicialmente como un movimiento político, la infalibilidad e impecabilidad de los imanes evolucionó después como una creencia distintiva del chiismo (no zaidino).

De acuerdo con los teólogos chiíes, la infalibilidad se considera una precondición racional necesaria para la guía espiritual y religiosa. Argumentan que puesto que Dios ha ordenado obediencia absoluta de estas personas, éstas deben por tanto sólo ordenar aquello que es correcto. El estado de infalibilidad se basa en la interpretación chií del verso de purificación (verso 33 del Al-Ahzab). De esta manera, ellos son los más puros, los únicos inmaculados preservados de, e inmunes a, toda suciedad. No significa que haya poderes sobrenaturales evitando que cometan un pecado, sino que gracias a su absoluta creencia en Dios, se abstienen de hacer cualquier cosa que sea pecado.

Tienen también un conocimiento pleno de la voluntad de Dios. Poseen todo el conocimiento traído por los ángeles a los profetas (nabi) y a los mensajeros (rasul). Su conocimiento abarca la totalidad de todos los tiempos. Actúan, por tanto, sin falla en asuntos religiosos. Los chiíes consideran a Alí como el sucesor de Mahoma, rigiendo no solo sobre la comunidad en justicia, sino también interpretando las prácticas islámicas y su significado esotérico. De allí que fuese considerado como libre de error y de pecado (infalible), y escogido por Dios por decreto divino (nass) para ser el primer Imán. Alí es conocido como "hombre perfecto" (al-insan al-kamil) similar a Mahoma, de acuerdo con el punto de vista chií.

El Ocultamiento ("al-Ghayba", o "ghaybat" en Persa) es la creencia en algunas formas del islam chií de que una figura mesiánica, un imán oculto conocido como el Mahdi, regresará un día y llenará el mundo de justicia. De acuerdo con los chiíes imamíes, el objetivo principal del Mahdi será establecer un estado islámico y aplicar las leyes islámicas que le fueron reveladas a Mahoma. El Corán no contiene versos sobre el Imanato, que es la doctrina básica del islam chií.

Algunos chiíes, como los Zaidinos y los Ismaelíes Nizaríes, no creen en la idea del Ocultamiento. Los grupos que sí creen en ello difieren en cuanto a cuál linaje del Imanato es válido, y por tanto en cuanto a qué individuo es el que ha entrado en ocultamiento. Creen que hay muchos signos que indicarán el momento de su retorno.

Los Imamíes creen que el Mahdi (el duodécimo imán, Hujjat-Allah al-Mahdi, de nombre Abu al-Qasim Muhammad, hijo de Hasan al-Askari) se encuentra ya en la tierra, está en ocultamiento (originalmente para escapar de sus perseguidores), y regresará al final de los tiempos. Los Fatimíes/Bohra/Dawoodi Bohra creen lo mismo pero hacia su 21o. Tayyib, At-Tayyib Abu'l-Qasim, en tanto que los suníes creen que el futuro Mahdi no ha llegado aún a la tierra.

Se cree que los armamentos y objetos sagrados de todos los Profetas, incluyendo a Mahoma, fueron dados en sucesión a los Imanes de la Ahlul Bayt. En el Kitab al-kafi, Yaʿfar as-Sadiq menciona que "conmigo se encuentran las armas del Mensajero de Alá. No está abierto a disputa."

Más aún, afirma que con él se encuentran la espada del Mensajero de Dios, su escudo de armas, su Lamam (gallardete) y su casco. Además, menciona que con él se encuentra la bandera del Mensajero de Dios, el victorioso. Con él están el Báculo de Moisés, el anillo de Salomón y la bandeja en la que Moisés solía dar sus ofrendas. Con él se encuentra el nombre que cuando fuese que el Mensajero de Dios lo coloque entre los musulmanes y paganos ninguna flecha de los paganos alcanzará a los musulmanes. Con él se encuentra el objeto similar que trajeron los ángeles. 

As-Sadiq narra también que la sucesión de armamentos es sinónima a recibir el Imanato (liderazgo), similar a cómo el Arca de la Alianza en la casa de los israelitas señalaba la facultad del profeta. 

El Imán Ali ibn Musa narra que "doquiera que los armamentos entre nosotros vayan, el conocimiento irá tras ellos y los amamentos nunca se separarán de aquellos con conocimiento (Imanato)".

Los libros generales de hadîz compilados que hoy se consideran el eje de referencia de la doctrina y las normas del Chiismo son:


Este conforma el segundo conjunto de los compendios del "hadîz" que elaboró y ordenó el "Chiita" a lo largo de la historia mediante sus raudos esfuerzos hasta los siglos cuarto y quinto de la hégira. Como ya hemos mencionado, fueron elaborados compendios de hadices durante la época de los Imames en los siglos segundo y tercero, que se denominan "“las primeras compilaciones”", eso sumado a los "“Usûl al-arba‘mî’ah”" (los cuatrocientos documentos elaborados directamente por los compañeros de los Imames Inmaculados) cuyo contenido fue trasladado al segundo conjunto de los compendios del hadîz.

Desde que la Ciencia del Hadîz fue siempre objeto de atención por parte de la Chiita, debido a ello, en los siglos XI y XII fueron elaboradas otras compilaciones del hadîz que no mencionamos para no extendernos. Las más famosas de estas compilaciones son "Bihâr al-anwâr" ("Los mares de luces") del ‘Allâmah Muhammad Bâqir Al-Maÿlisî, y "Wasâ’il ash-Shî‘ah" ("Los Medios de la Chía") de Muhammad Ibn Al-Hasan Al-Hurr Al-‘Âmilî.

Las principales (en orden de importancia) son el Corán, la Sunna (o tradición profética y de los Imames sus sucesores), el consenso de opinión (de los sabios de la comunidad) y la razón o intelecto. 


El chiismo considera que el Corán tiene un mensaje literal, interpretable por cualquier musulmán, que es válido. Sin embargo, ese mensaje literal o exotérico es a su vez un mensaje cifrado o esotérico que oculta conocimientos que solo son interpretables por ciertos iniciados. Dicho mensaje esotérico es a su vez metáfora de un tercer mensaje, más oculto aún, y así hasta siete niveles de esoterismo. El mensaje último en cualquier caso es conocido solo por Dios. El esoterismo (especialmente fuerte en el caso de los ismailíes) no tiene como tal repercusiones prácticas para la mayoría de los fieles, que se limitan a seguir el mensaje literal del Corán, pero está muy relacionado con la institución del imanato, marcando distancias con el sunnismo, que considera que cualquier creyente puede ser su propio intérprete del mensaje divino. Esto implica, entre otras cosas, que en el sunismo, (más del 80% de todos los musulmanes) no existe una estructura clerical como ocurre en otras religiones abrahámicas, como el cristianismo o el judaísmo.

El origen del esoterismo chií hay que buscarlo en la expansión inicial del chiismo, según los wahhabíes y los salafíes, por Irán, Siria, Líbano, Jordania y Palestina, donde habría adquirido características de las creencias preexistentes, en concreto de la filosofía neoplatónica y del mazdeísmo. así también, según esas dos sectas, los supuestos mensajes ocultos estudiados por los iniciados tienen muchas características comunes con aquellas escuelas filosóficas extrañas (en general el sunnismo, desde el siglo XII rechaza la filosofía y la teología). Según salafíes y wahhabíes, este sería un sincretismo religioso del chiismo contrastante con el anhelo del islam (según wahhabies y salafis) de mantenerse en su forma pura y original, sin mezclarse con otras ideologías y creencias.

En realidad, no existe un clero chií, sino expertos en religión, que sin embargo no pertenecen a un cuerpo colegiado. Esos expertos chiíes en las altas esferas de formación e intelectualidad, están muy relacionados con el esoterismo y el imanato. Dado que existe un mensaje invisible y dado que quien lo conoce sigue vivo pero está oculto, es necesario un cuerpo de intérpretes capaces de captar los signos enviados por el imán desde su ocultación. Podría decirse también que como el guía espiritual sigue vivo, la doctrina no está completamente cerrada. Los intérpretes son los ulemas, también llamados mulás.

Las diferencias en torno a la sucesión de ciertos imanes son en buena medida el origen de la formación de varios grupos dentro del chiismo. La mayoría de los chiíes se encuadran en cuatro grandes grupos: el de los imamíes o duodecimanos, mayoritario, el de los alauíes también duodecimanos, el de los zaydíes y los ismailíes. Estos últimos se dividieron a su vez por la sucesión del califa fatimí Al-Mustansir.

A ellos hay que añadir ciertos cultos situados en la periferia del islam, es decir, que surgieron del chiismo o de las ramas anteriores, o que mezclaron ideas musulmanas y de otras religiones, pero que no siempre son considerados musulmanes. Los más destacados son los drusos y los alevíes.

Desde el punto de vista del carácter de los imanes se dividirían en zaydíes (el imán es solo un líder); intermedios (el imán es hereditario y está guiado por Dios, creencia apoyada por la mayoría de los chiíes); y extremistas o "ghulat" (el imán es una manifestación de Dios, por lo que son considerados no-musulmanes —Alí-ollahíes o Ahl-e Haqq, drusos—).

Los chiíes constituyen hoy entre un 15% de los musulmanes. Son mayoritarios en Irán, Azerbaiyán, Irak, Baréin y el sur del Líbano, y existen minorías chiíes en otros lugares, especialmente en Siria, Afganistán y Pakistán. El chiismo septimano existe en la India, Pakistán, Siria y Yemen. Los drusos se encuentran sobre todo en la región situada entre el sur del Líbano, los altos del Golán y el norte de Israel. Los zaydíes se encuentran principalmente en Yemen. Los alauíes son bastante numerosos en Siria. La familia de Bashar al Assad, actual presidente del país, pertenece a esta confesión.
Los alevíes se encuentran en el centro y el este de Turquía.

Tanto los chiitas como los suníes comparten una cierta veneración y obligaciones religiosas hacia ciertos santuarios y lugares sagrados, como La Meca, Medina y Mezquita de Al-Aqsa de Jerusalén pero la mezquita del Imán Alí en Nayaf, Irak y la Mezquita Imam Husayn también son veneradas. Después de La Meca y Medina, Nayaf y Kerbala son las ciudades más sagradas para los chiitas.



</doc>
<doc id="41299" url="https://es.wikipedia.org/wiki?curid=41299" title="Vejiga (desambiguación)">
Vejiga (desambiguación)

Vejiga puede designar:


</doc>
<doc id="41309" url="https://es.wikipedia.org/wiki?curid=41309" title="Patricio Patrón Laviada">
Patricio Patrón Laviada

Patricio José Patrón Laviada (n. Mérida, Yucatán; 17 de diciembre de 1957) es un político mexicano, miembro del Partido Acción Nacional. Ha sido presidente municipal de Mérida, gobernador del estado de Yucatán y titular de la Procuraduría Federal de Protección al Ambiente.

Nació en la ciudad de Mérida el 17 de diciembre de 1957. Realizó estudios de primaria, secundaria y bachillerato en la ciudad de Mérida y ha tomado diversos cursos especializados, entre ellos de Calidad Total y Administración Pública Municipal.

Ha sido Secretario Ejecutivo del Pronasol Municipal en Mérida; diputado local, presidente municipal de Mérida, senador de la república y gobernador del estado de Yucatán para el período 2001 - 2007. Además es empresario, socio de tres empresas yucatecas, todas del sector pesquero. Fue el primer gobernador del estado de Yucatán emanado de la oposición, específicamente del Partido Acción Nacional (PAN), mediante una coalición con el Partido de la Revolución Democrática (PRD), el Partido del Trabajo (PT) y el Partido Verde Ecologista de México (PVEM), derrotando a su contrincante del Partido Revolucionario Institucional (PRI), el abogado Orlando Paredes Lara en la elección estatal que se llevó a cabo el año 2001.

El 18 de enero de 2008 fue nombrado como titular de la Procuraduría Federal de Protección al Ambiente por el presidente Felipe Calderón Hinojosa, cargo al que renunció el 26 de enero de 2011 por presuntas diferencias con el titular de la Secretaría de Medio Ambiente y Recursos Naturales.




</doc>
<doc id="41335" url="https://es.wikipedia.org/wiki?curid=41335" title="Calcuta">
Calcuta

Calcuta es la ciudad capital del estado indio de Bengala Occidental. Su nombre oficial es Kolkata (), aunque hasta el 1 de enero de 2001 era Calcutta, y su denominación original, que aún es utilizada en la literatura culta, fue Kolikata (en bengalí কলিকাতা). Es conocida como “la ciudad de la alegría” o “la ciudad de los palacios”; y localmente como Michhil Nagari (মিছিল ন).

En una época fue la ciudad más poblada de la India, por delante de Bombay. Según el último censo indio, del 1° de marzo de 2001, la ciudad “propiamente dicha” tenía 4 580 544 habitantes. El hecho de que el censo anterior (de 1991) ya hubiese arrojado 4 399 819 hab sugiere fuertemente una cierta saturación del casco urbano histórico de la ciudad. Debido a eso mismo, estimados posteriores calculan que el Bangalore “estrictamente definido” ya ha sobrepasado la población de Calcuta, la cual entonces pasaría a ubicarse cuarta entre las grandes ciudades indias (detrás de Bombay, Delhi y del propio Bangalore).

No obstante, según los mismos datos oficiales de 2001, la población de su área metropolitana ascendía a los 13 211 853 habitantes(11 021 918 de acuerdo al anterior, de 1991). Para enero de 2009, una estimación ya la ubicaba cerca de los 15 230 000. De esta manera, sólo los aglomeraciones urbanas de Bombay y Delhi la superan.

No se debe confundir con la antigua ciudad de Calicut (la actual Kozhikode, de un millón de habitantes, en el estado sureño de Kerala).

Los nombres Kolkata (nombre oficial en inglés desde 2001), Calcutta (antiguo nombre inglés) y Calcuta (en español) están probablemente basados en la palabra sánscrita "kalikata", que es el nombre de uno de los tres pueblos que existían en el área antes de la llegada de los británicos. Es posible también que el término "Kolikata" sea una variación de "Kalikkhetrô" [kalikʰːet̪rɔ] (bengalí: কালীক্ষেত্র), que significa "campo de [la diosa] Kali". Del mismo modo, puede ser una variación de "Kalikshetra" (sánscrito: कालीक्षेत्र, lit. "área de la Diosa Kali"). Otra teoría es que el nombre deriva de Kalighat.

La zona sobre la que actualmente se asienta la ciudad de Calcuta ha sido objeto de ocupación humana al menos desde hace más de 2.000 años, según atestiguan los yacimientos arqueológicos encontrados.

En 1690, la Compañía Británica de las Indias Orientales, que había establecido su primera sede de sus negocios en el Golfo de Bengala y en la propia Bengala desde 1608 en la localidad de Surat, optó por trasladar la sede de sus negocios a Calcuta, dando así inicio a la gran expansión de la ciudad, que administraba, al igual que al resto de sus posesiones, como si se tratase de un estado prácticamente soberano.

Tradicionalmente, pues, se considera la fecha de 1690 como la de la fundación de la ciudad, que se considera obra de Job Charnock, un administrador de dicha compañía, sobre la anterior aldea de Kalikata, aunque esta teoría es desautorizada por la moderna Historiografía.

Para 1699, Gran Bretaña completó la construcción de un fuerte, Fort William, cuya misión era la de servir de base militar para el establecimiento de las tropas del Ejército británico destinadas a la región.

Poco después, en 1756, motivados por los enfrentamientos con Francia por el control de la India, los británicos efectuaron la ampliación y modernización de las fortificaciones de la ciudad. El nawab de Bengala, Siraj-Ud-Daulah, protestó por dichas obras y, al no ser atendidas sus reclamaciones, atacó el fuerte, tomando pues Fort William. Durante la toma del mismo, fueron asesinados varios británicos en una de las habitaciones, lo que marcó el imaginario colectivo británico, que se refiere a los hechos como “La noche del agujero negro”.

Al año siguiente, 1757, Fort William y Calcuta fueron reconquistados por una fuerza mixta formada por cipayos al servicio de la Compañía Británica de las Indias Orientales y de soldados regulares del Ejército británico, puesta bajo el mando del general Robert Clive, un antiguo empleado (como escribiente) de la Compañía. La acción decisiva de la campaña fue la batalla de Plassey, que tuvo lugar el 23 de junio en la propia Bengala, en las cercanías de Calcuta, y que Robert Clive ganó más a base de sobornos y de promesas de ventajas comerciales que de combate militar.

En 1772, la ciudad fue nombrada capital de la India británica (el llamado Raj británico), rango que conservaría hasta 1911. Fue a partir de este momento cuando se emprendieron obras de saneamiento para la ciudad, consistentes en la desecación de las zonas de marismas que rodeaban a la ciudad, al igual que se construyó a orillas del río Hugli una zona residencial y de oficinas gubernamentales. Fue Richard Wellesley, quien entre 1797 y 1805 fuera gobernador, quien dio destacado impulso a las obras en la ciudad.

Hacia principios del siglo XIX tiene lugar la división interna de la ciudad en dos sectores diferenciados: un sector europeo y otro reservado para la población india, zona conocida como “ciudad negra”.

A partir de los años 1850, tiene lugar un proceso de industrialización en la ciudad, especialmente relativa al sector textil y a la industria del yute. Ello, a su vez, hace que el Gobierno británico haga inversiones en el sector de comunicaciones, especialmente en el ferrocarril y el telégrafo. Como resultado de la bonanza económica y del contacto entre la sociedad británica y la india, hace su aparición en la ciudad una nueva clase social, la de los "babu", grupo de oficinistas y burócratas de estirpe frecuentemente angloindia y relacionados en la mayoría de los casos con las castas superiores de la India.
Desde finales del siglo XIX, tiene lugar en la India un proceso gradual de toma de conciencia nacionalista, que acaba por cristalizar en las ansias de independencia de lo que ya es una colonia británica, asumiendo Calcuta en este proceso un lugar destacado. Así, ya en 1883 fue organizada en la ciudad una Conferencia Nacional por parte de Surendranath Banerjea, siendo la primera de sus características que tuvo lugar en la India.

En 1905, George Curzon, primer marqués Curzon de Kedleston, al que se suele conocer como “Lord Curzon”, y que a la sazón era Gobernador General de la India, decidió partir la región de Bengala en dos distritos diferentes, lo que actuó como detonante para una serie de disturbios que se sucedieron en la ciudad, que incluso incluyó el boicot indio a las mercancías de origen británico.

El clima de agitación hizo que los británicos tomasen en 1911 la decisión de que la ciudad de Calcuta dejase de ser la capital del Raj británico, asumiendo dicha función la ciudad de Nueva Delhi, ya que además se consideraba que esta ciudad ocupaba una mejor situación estratégica en la India.

Durante la Segunda Guerra Mundial, el puerto de Calcuta fue bombardeado en dos ocasiones por los japoneses. En 1943 se produjo en la ciudad una grave crisis de subsistencias, que degeneró en un hambre que provocó numerosas víctimas, y que los nacionalistas indios consideraron que se produjo como consecuencia del acaparamiento de suministros destinados a los ejércitos de los Aliados.

En 1946 se produjeron fuertes disturbios en la ciudad, con motivo de la petición de la creación de un estado separado para los indios de religión musulmana, que acabaron desembocando en una lucha abierta que provocó más de 2000 víctimas.

Fue una importante en el comercio y la exportación del yute, pero en 1947, cuando tuvo lugar la partición (línea divisoria entre musulmanes e hinduistas) se vio invadida por oleadas de emigrantes procedentes de áreas donde la lucha por la independencia había ocasionado gran violencia, a la vez que desde la propia Calcuta partían emigrantes de confesión musulmana hacia el recién creado Pakistán oriental (hoy independiente bajo el nombre de Bangladés). Por si ello fuera poco, las tierras en que se cultivaba el yute de que se abastecía la industria yutera de Calcuta quedaron del otro lado de la nueva frontera. Todo ello provocó un período de estancamiento económico.

En los años 1960 y 1970, una serie de graves averías en el sector eléctrico, seguidos por huelgas y por la actividad de una guerrilla de ideología maoísta, los "naxalitas", siguió generando inestabilidad económica en la ciudad.

En 1971 el conflicto entre la India y Pakistán, la guerra indo-pakistaní de 1971, que provocó la creación de Bangladés como estado independiente, originó nuevas oleadas de refugiados, que —unidos a los que habían ocasionado tres sequías sucesivas—, obligaron a la gente del campo a emigrar a la ciudad. El incremento de la población consecuente a la explosión demográfica tras la guerra, ha convertido a Calcuta en un hervidero humano donde las imágenes de hacinamiento, decrepitud, enfermedad y muerte, son tan habituales que la sola mención del nombre de la ciudad ya las evoca. Calcuta es la ciudad del mundo donde existe mayor número de población sin hogar que vive en la calle y el mayor número de leprosos.

Toda esta situación explica que hacia los años 1980 Bombay pasase a ser la ciudad más poblada de la India, en detrimento de Calcuta.

Desde 1977, la ciudad es gobernada por el Partido Comunista de la India (Marxista).

Calcuta se encuentra ubicada en el este de la India, en el delta del Ganges, a una altura de entre 1,5 y 9 metros sobre el nivel del mar. Se extiende a orillas del río Hugli en dirección norte-sur, a unos 154 km del golfo de Bengala hacia el interior del continente. La mayor parte del terreno sobre el que se asienta la ciudad fue originalmente un vasto humedal, ganado tras décadas de asentamiento de la población la ciudad. La zona húmeda restante, conocida como Humedales occidentales de Calcuta o "East Calcutta Wetlands" han sido designados como "zona húmeda de importancia internacional" por el Convenio de Ramsar el 19 de agosto de 2002.

Como en la mayoría de las llanuras del Indo-Ganges, el tipo de suelo predominante es el de aluviones. La ciudad se asienta sobre suelos cuaternarios consistentes en varias capas de sedimentos de arcilla, cieno y grava. Estos sedimentos se encuentran comprendidos entre dos lechos de arcilla, la inferior con una profundidad entre los 250 y 650 metros, y la superior con una grosor entre 10 y 40 metros. Según el "Bureau of Indian Standards", la población se asienta sobre una zona sísmica de grado III en una escala de I a V (según la propensión de la zona a sufrir un terremoto), mientras que la zona es considerada de un "muy alto riesgo de daños" por viento y ciclones según el PNUD.

El clima de Calcuta es de tipo tropical, húmedo y seco (Clasificación climática de Köppen). La temperatura media anual es de 26,8 °C, las temperaturas medias mensuales oscilan entre 19 °C y 30 °C. Los veranos son cálidos y húmedos. Durante la temporada seca (mayo y junio) las temperaturas máximas suelen superar los 40 °C. El invierno térmico suele durar solo unos dos meses, entre diciembre y enero, con temperaturas mínimas estacionales de 12 °C. La temperatura máxima registrada es de 43,9 °C y la más baja de 5 °C. A menudo, al comienzo del verano, períodos de fuertes lluvias y tormentas azotan la ciudad, con lo que se alivia el calor. Estas tormentas son conocidas localmente como "kal baisakhi" (কালবৈশাখী).

Las lluvias del monzón sudoccidental azotan el golfo de Bengala y la ciudad entre junio y septiembre y suministran a la ciudad la mayor parte de su precipitación anual de 1582 milímetros. La más alta precipitación ocurre durante las lluvias del monzón en agosto (306 milímetros).

La ciudad recibe 2528 horas de sol al año, el máximo de luz solar se producen en marzo. La contaminación es una preocupación importante en Calcuta, su nivel es alto en comparación con otras grandes ciudades de la India. Esta grave contaminación del aire en la ciudad ha causado un aumento de las enfermedades respiratorias como el cáncer de pulmón.

El 11 de octubre de 1737 se registró una violentísima tormenta (cayeron 380 mm de agua en 6 h) y
en la madrugada del 12 de octubre la ciudad recibió una marejada ciclónica de varios metros de altura, generada por un superciclón. Solo en Calcuta ―que en esa época contaba con menos de 20 000 habitantes― murieron 3000 personas. Posiblemente sea exagerado el número de 300 000 personas fallecidas, y la ola de «12 m de altura» (posiblemente bastante menor). Hasta 1994 se consideró que se trató de un maremoto.

En 2001 Calcuta tenía una población de 4 580 544, mientras que la aglomeración urbana contaba con una población de unos 15 000 000. El porcentaje de mujeres es de 828 por cada 1000 varones, inferior a la media nacional, debido a que muchos hombres trabajadores proceden de las zonas rurales, en las que dejan a sus familias. La tasa de alfabetización es de 80,86 %, superior a la media de toda la India que es de 64,8 %.

Los bengalíes constituyen la mayoría de la población de Calcuta, con otras grandes minorías de marwaris y biharis. la comunidad incluye chinos (tusán), tamiles, gujaratis, ingleses, armenios, tibetanos y parsis. Los principales idiomas que se hablan en Calcuta son el bengalí, el hindi, el urdu, el inglés, el oriya y el bhojpuri.

Según el censo de 2001, el 77,68 % de la población profesa la religión hindú, el 20,27 % son musulmanes, el 0,88 % cristianos y el 0,75 % profesan el jainismo. Existen otras minorías que constituyen el resto de la población como los sijs, budistas y zoroástrica.

La tasa de delincuencia en la ciudad fue 81,4 por 100 000 en contra de la tasa nacional de 168,8 en 2004. El barrio de Sonagachi, cuenta con más de 10 000 trabajadores del sexo, es uno de los distritos de zona roja más grandes de Asia.

En ella se encuentra el Kalighat (en la zona sur de la ciudad), un templo dedicado a la diosa patrona de la ciudad, Kali, que data del año 1809. También se denomina Kalighat a la vecindad donde se encuentra este templo. En esta zona se encuentra el barrio rojo con mujeres que vienen de diferentes partes de la ciudad o del país (incluso muchas mujeres de Bangladés) a ejercer la prostitución.

Cuenta también con Fort William, el fuerte que está en el origen de la propia ciudad, como arqueología militar.

En Calcuta se encuentra igualmente el Victoria Memorial, construido cuando la India era parte del Imperio Británico, es un Museo dedicado a la pintura y que está igualmente consagrado a la conservación de su patrimonio histórico documental; en él hay óleos de gran tamaño en la Galería Real, ilustrando episodios de la larga y agitada vida de la Reina Victoria y su reinado. Fue construido dotado de un revestimiento en mármol blanco entre los años 1840 y 1847.

Posee igualmente el Jardín botánico de Kokata, emplazado al sur de la ciudad, en la orilla oeste del río Hugli, que cuenta con uno de los mayores banianos ("Ficus benghalensis") del mundo. Aloja la Biblioteca Nacional de India, en la mansión Belvedere.

En la ciudad se ambienta La ciudad de la alegría, novela de gran éxito de Dominique Lapierre, así como la película oscarizada "Slumdog Millionaire". La documentalista israelí, Zana Briski, igualmente, filmó en la ciudad Los Niños del Barrio Rojo, que ganó el Óscar el 2005 al mejor documental. Dan Simmons ganó el prestigioso premio World Fantasy Award 1986 con su opera prima, la novela La Canción de Kali, en que la ciudad de Calcuta hace las veces de protagonista principal para mostrar su rostro más terrible.

El fútbol es el deporte más popular de Calcuta, siendo ésta el principal centro de este deporte en todo el país. Los principales equipos del país se encuentran en la ciudad y su federación local se fundó en 1893, incluso antes que la federación de la India, la All India Football Federation. La federación local recibe el nombre de Indian Football Federation y controla este deporte en todo el estado de Bengala Occidental. Los principales clubes de la ciudad son el Mohun Bagan AC, el Atlético de Kolkata y el East Bengal Club.

El críquet es también muy popular en la ciudad al igual que en el resto de la India y suele practicarse tanto en campos de juego como en las calles. Los clubes locales suelen organizar regularmente sus propios campeonatos, principalmente de críquet, fútbol, bádminton y carrom. En la zona de Maidan se ubican varios equipos menores de fútbol y críquet, y otras instituciones deportivas.

Calcuta cuenta con muchas instalaciones deportivas entre las que destacan sus grandes estadios. El Eden Gardens es uno de los únicos dos estadios de críquet del mundo con 100 000 asientos. El multiusos Saltlake Stadium es el segundo estadio de fútbol del mundo en cuanto a capacidad y en él disputan sus partidos los tres principales equipos de la ciudad. El Calcutta Cricket and Football Club es el segundo club de críquet más antiguo del mundo, fundado en 1792.

Calcuta tiene tres campos de golf de 18 hoyos, el Royal Calcutta Golf Club (el primer club de golf del mundo fuera del Reino Unido), el Tollygunge Club y Fort William. El Royal Calcutta Turf Club (RCTC) organiza carreras ecuestres de forma regular y partidos de polo. El Calcutta Polo Club es considerado el club de polo más antiguo del mundo. El Calcutta South Club organiza varios torneos de tenis tanto a nivel nacional como internacional. El Calcutta Rowing Club organiza competiciones y entrenamientos de remo.

Las escuelas primarias y secundarias de la ciudad de Calcuta son dirigidas bien por el Gobierno del estado de Bengala Occidental, bien por la iniciativa privada, a menudo relacionada con el mundo de la religión. La lengua vehicular de la enseñanza en dichas escuelas suele ser bien el bengalí bien el inglés, aunque también se utilizan otros idiomas, como el urdu o el hindi, en función de las diversas lenguas que se hablan en la ciudad.

Por lo que respecta a la enseñanza universitaria, Calcuta, en su condición de gran ciudad de la India, cuenta con un total de nueve centros de enseñanza universitaria, entre los que cabe destacar la Universidad de Tecnología y de la Ciencia de Bengala, o la Universidad de Jadavpur, por lo que respecta a los estudios de tipo técnico.

Calcuta es la principal zona de negocios, de comercio y financiero del este de la India y de los estados del noreste. Es la sede de la Bolsa de Valores de Calcuta, la segunda bolsa más grande de la India. También es un importante puerto comercial y militar, y la única ciudad de la región con un aeropuerto internacional. Al igual que otras ciudades metropolitanas de la India, Calcuta sigue luchando contra problemas como son la urbanización incontrolable, la pobreza o la contaminación.

La que una vez fue la principal ciudad y capital de la India, experimentó una estable disminución económica en los años posteriores a la independencia de la India debido a la constante inestabilidad política y al ascenso del sindicalismo apoyado por los partidos de izquierda.Entre los años 60 y 90 el despoblamiento de la capital fue inmenso cuando muchas de las grandes fábricas fueron cerradas o reajustadas y los negocios trasladados. La carencia de capital y recursos junto con una superabundancia mundial demandando las industrias tradicionales de la ciudad se sumó a la depresión económica de la ciudad.La liberalización de la economía de la India en los años 90 junto con la elección del primer ministro reformista Buddhadeb Bhattacharya provocó una mejora en las fortunas de la ciudad.

El principal medio de transporte público es proporcionado por el ferrocarril suburbano de Calcuta, el Metro de Calcuta, tranvías y autobuses. La red de ferrocarriles de cercanías es muy amplia y se extiende hasta los barrios más alejados de la ciudad. El Metro de Calcuta es el sistema de transporte subterráneo más antiguo de la India, circula paralelo al río Hugli y se extiende por el norte y el sur de la ciudad abarcando una distancia de 16,45 kilómetros. Los autobuses son el modo preferido de transporte y están a cargo de dos agencias gubernamentales, además de algunos operadores privados. Debido a las fuertes lluvias que caen durante la estación de los monzones, a veces se interrumpe el transporte público.

También son muy comunes los cochecillos autorickshaw y las bicitaxis, especialmente para los desplazamientos a corta distancia por el interior de la ciudad.
Los vehículos de propiedad privada son menos frecuentes en número y uso en comparación con otras grandes ciudades, debido a la abundancia y variedad de los vehículos de transporte público. Sin embargo, la ciudad fue testigo de un aumento constante en el número de vehículos matriculados, de modo que en 2002 los datos mostraron un aumento de un 44 % en los siete años anteriores. Debido al escaso espacio vial, es frecuente la aparición de importantes problemas de tráfico; por esta razón y para aliviar el tráfico en cierta medida se están construyendo nuevas vías y estaciones para la red Metro, así como toda una serie de nuevas carreteras.

Calcuta tiene principalmente dos estaciones de ferrocarril de larga distancia, la estación de Howrah y la de Sealdah. A principios de 2006 se ha empezando a construir la que debe ser la tercera estación de la ciudad, llamada Kolkata.

Por lo que respecta a medios de transporte aéreo, el único aeropuerto que posee Calcuta, el aeropuerto internacional Netaji Subhash Chandra Bose, se encuentra ubicado al norte de la ciudad, operando tanto en vuelos nacionales como en vuelos internacionales.

Calcuta constituye también un importante puerto comercial en el este de la India, acorde con su antiguo papel como centro de salida de las exportaciones durante el período del Raj británico, durante el cual que fue la capital de los dominios británicos en la India. Tiene igualmente servicio de pasajeros hacia Port Blair, en las islas Andamán y Nicobar. También hay el servicio de un ferry que conecta Calcuta con su ciudad gemela de Howrah o Haora.

Varios puentes atraviesan el río Hugli uniendo Calcuta con su vecina Howrah, el más importante de estos puentes y símbolo de Calcuta es el precisamente llamado puente de Howrah.




</doc>
<doc id="41336" url="https://es.wikipedia.org/wiki?curid=41336" title="Íñigo Arista">
Íñigo Arista

Íñigo Arista (Íñigo Íñiguez  o Íñigo Jímenez )  (m. 851) fue el fundador de la dinastía Arista-Íñiga, y conde de Bigorra. Aunque tradicionalmente ha sido considerado el primer rey de Pamplona —así como el quinto rey del reino de Sobrarbe—, hoy muchos historiadores prefieren hablar de «reino en estado latente» para el territorio y sus pobladores que Arista y sus descendientes García Íñiguez y Fortún Garcés acaudillaron entre 824 y 905. Así pues, según esta interpretación estos tres miembros de la dinastía Íñiga fueron más bien caudillos, y no reyes. En cualquier caso, Arista obtuvo el liderazgo con el apoyo de sus parientes, los Banu Qasi, e hizo frente a una expedición franca a la que derrotó en la segunda batalla de Roncesvalles.

Íñigo Arista fue hijo de Íñigo Jiménez y Oneca. Su madre se casó con Musa ibn Fortún tras la muerte de su padre y, por este matrimonio, fue medio hermano de Musa ibn Musa. Pudo estar casado con una hermana del conde aragonés Aznar I Galíndez, aunque no se descarta la posibilidad de que fuese polígamo.

En el año 799, el gobernador de Pamplona, Mutarrif ibn Musa, miembro de la dinastía Banu Qasi, fue asesinado en una revuelta ciudadana que puso en el poder a un miembro de la familia Velasco. En el año 806, tanto navarros como pamploneses se sometieron a la autoridad carolingia. Ludovico Pío envió una expedición en el año 812 contra Pamplona. A su regreso, los expedicionarios tomaron por rehenes a mujeres y niños para protegerse durante el paso del puerto de Roncesvalles.

Íñigo Arista llegó al caudillaje pamplonés con el apoyo de la familia Banu Qasi, en fecha indeterminada entre los años 810 y 820. Fue proclamado sobre la peña Oroel, en Jaca, por trescientos caballeros. Según Eulogio de Córdoba, se tituló "christicolae princeps". El parentesco con los Banu Qasi permitió que Íñigo controlara la región comprendida entre Pamplona y los valles pirenaicos de Irati y Hecho.

Alrededor del año 820, ayudó a García el Malo, su yerno, a hacerse con el condado de Aragón y sacudirse el control carolingio.

En el año 824, Ludovico Pío envió una segunda expedición contra Pamplona encabezada por los condes Eblo y Aznar Galíndez para tratar de restablecer el control franco. Los condes fueron derrotados en la segunda batalla de Roncesvalles por Íñigo Arista, quien recibió el apoyo de su pariente Musa ibn Musa y García el Malo. Mientras que Aznar, quizá en virtud de su parentesco con Íñigo, fue puesto en libertad, Eblo fue enviado como prisionero a Córdoba.

En el año 841 fue víctima de una enfermedad que lo dejó paralítico. Su hijo, García Íñiguez, se ocupó de la regencia hasta la muerte de Íñigo en el año 851. Durante la regencia de su hijo, el (futuro) reino de Pamplona colaboró con los Banu Qasi en la sublevación del año 843 contra el califato omeya, sofocada por Abderramán II, que implicó represalias andalusíes en tierras pamplonesas.

Por su matrimonio o matrimonios, Íñigo Arista fue padre de:




</doc>
<doc id="41338" url="https://es.wikipedia.org/wiki?curid=41338" title="Reino de Asturias">
Reino de Asturias

El Reino de los astures (en latín: "Regnum Asturorum") fue la primera entidad política cristiana establecida en la península ibérica después del colapso del reino visigodo de Toledo tras la desaparición del rey Rodrigo en la batalla de Guadalete y la subsiguiente conquista musulmana de la península ibérica. En sus primeras décadas, la extensión territorial del Reino de Asturias se limitó a los territorios de la cornisa cantábrica y sus comarcas adyacentes. Con posterioridad, los reyes asturianos iniciaron una vigorosa expansión que a principios del siglo X alcanzó el río Duero.

Se considera que la historia del reino se inició en el año 718, fecha probable de la elección de Don Pelayo como "princeps" o líder de los rebeldes. El final suele establecerse en el año 925, cuando Fruela II de Asturias sucedió a su hermano Ordoño II y unió sus territorios al Reino de León. El Reino de Asturias es el precedente histórico de la Corona de Castilla y del Reino de Portugal.

El reino asturiano tuvo como solar los territorios occidentales y centrales de la Cordillera Cantábrica, particularmente los Picos de Europa y el área central de la actual Asturias, zonas donde tuvieron lugar los principales acontecimientos político-militares durante las primeras décadas de existencia del reino. Según las descripciones de Estrabón, Dión Casio y otros geógrafos grecorromanos dichas zonas estaban habitadas en los albores de la era cristiana por diferentes pueblos, entre los cuales se pueden citar los siguientes: "vadinienses", que habitaban los Picos de Europa y cuya área de asentamiento fue desplazándose lentamente hacia el sur durante los primeros siglos de nuestra era, tal y como testimonian numerosas estelas; los "orgenomescos", que moraban en la costa oriental asturiana; los "selinos", que como su propio nombre indica se distribuían por todo el valle del río Sella ("Salia"); los "lugones", cuyo territorio se extendía entre los ríos Sella y Nalón y cuya capital se situaba en Lucus Asturum (Lugo de Llanera); los "astures" propiamente dichos que habitaban la zona interior de Asturias situada entre los concejos actuales de Piloña y Cangas del Narcea, la provincia actual de León (excepto la zona noreste donde habitaban los "Vadinienses"), parte de Zamora y noreste de Portugal, los "galaicos" se encontraban desde el Río Navia hasta el finisterre de la Costa da Morte, es decir, más o menos el território de Galicia, y los "pésicos", que moraban en la zona costera de Asturias occidental, entre la desembocadura del Navia y la actual ciudad de Gijón.

En cualquier caso, la conquista del norte peninsular fue finalizada por César Augusto Octavio después de la conquista de las Galias, que tuvo como aliados a los vascones que cortaban el territorio aquitano de donde provenían las provisiones para las legiones y cuyo tránsito era vital para su abastecimiento.
Las informaciones que nos dan los geógrafos clásicos acerca de la filiación étnica de estos pueblos son confusas: Ptolomeo señala que los "astures" habitaban la zona central de la actual Asturias, la que se extiende entre los ríos Navia y Sella, situándose al oriente de este río la frontera con el territorio de los "cántabros". Sin embargo, ya en el siglo IV la "Cosmographia" de Julio Honorio pone el nacimiento del Ebro en territorio de los astures ("sub asturibus"). En cualquier caso y dejando a un lado los detalles relativos a las fronteras entre las diferentes etnias cantábricas, el propio Estrabón señalaba en su "Geographia" que durante la época romana, todos los pueblos del norte de España, desde los galaicos hasta los vascones, tenían una cultura y unas formas de vida similares.

De otra parte, existen testimonios que manifiestan que ni los "lugones" ni los "pésicos" se identificaban originariamente con los "astures": así, en el Parroquial Suevo se distingue entre "astures" y "pésicos", como si fueran dos tribus diferenciadas, y en una lápida encontrada en el concejo de Piloña –la "piedra de los Ungones"– se señala la frontera entre los "lugones" y los "astures". Siendo todos ellos celtas romanizados.

Esta situación se afianzó en el Bajo Imperio y en tiempos de las invasiones germánicas: la lucha primero contra los romanos y luego contra los vándalos asdingos y los visigodos fue forjando una identidad común entre los pueblos de la futura Asturias. A este respecto, diversas excavaciones arqueológicas han encontrado restos de fortificaciones en los alrededores del Campamento romano de La Carisa (concejo de Lena). Los expertos consideran que dicha línea defensiva, ubicada estratégicamente en la cuenca alta del río Lena –vía de entrada natural a Asturias desde la Meseta–, prueba la existencia de una resistencia organizada en el seno de la cual forzosamente debieron cooperar todos los habitantes de Asturias central. En este sentido, dichos especialistas han descubierto en La Carisa dos niveles arqueológicos diferentes, uno de los cuales corresponde a las guerras cántabras y el segundo al periodo 675–725, en el que tuvieron lugar la expedición del rey visigodo Wamba contra los astures y la conquista de Asturias por Muza.

La identidad asturiana que progresivamente iba forjándose cristalizaría de una manera definitiva tras la coronación de Pelayo, la victoria en Covadonga y la subsiguiente consolidación del Reino de Asturias. En este sentido, la "Crónica Albeldense", al narrar patrióticamente los sucesos de Covadonga, afirma que tras esa batalla "Asturorum Regnum divina providentia exoritur", «nació por la divina providencia el Reino de los Astures».

En el transcurso de la conquista musulmana de la península ibérica, las principales ciudades y centros administrativos de la Península fueron cayendo en manos de las tropas del Emirato de Córdoba. El dominio de las regiones centrales y meridionales, como los valles del Guadalquivir o del Ebro presentó muy pocos problemas para los recién llegados, que se ayudaron de las estructuras administrativas visigodas existentes, de origen romano. Sin embargo, en las montañas del norte, los centros urbanos eran prácticamente inexistentes (como Gigia) y la sumisión del país había de realizarse valle a valle. A menudo los musulmanes recurrían a tomar rehenes para asegurarse la pacificación del terreno recién conquistado.

Tras la primera incursión de Tariq que en el año 711 llegó hasta Toledo, el virrey yemení de Ifriqiya, Musa ibn Nusair, cruzó el año siguiente el Estrecho de Gibraltar y llevó a cabo una masiva operación de conquista que le llevaría capturar, entre otras, las ciudades de Mérida, Toledo, Zaragoza y Lérida. En la última fase de su campaña militar llegó hasta el noroeste de la Península donde logró apoderarse de las poblaciones de Lugo y Gijón. En esta última ciudad situó a un pequeño destacamento bereber al mando de un gobernador, Munuza, cuya misión debía consistir en consolidar el dominio musulmán sobre Asturias. Como garantía de la sumisión de la región algunos nobles, entre ellos algunas teorías apuntan que Pelayo (aunque su origen resulta desconocido), fueron llevados como rehenes de Asturias a Córdoba.

Pero, según cuentan tanto la "Crónica Rotense" (crónica de Alfonso III donde se considera a Pelayo como sucesor de los reyes de Toledo, con claros fines de búsqueda de legitimidad política) como la de Al-Maqqari (historiador marroquí del siglo XVI que murió en El Cairo, Egipto, y que pudo haber tomado sus fuentes de la versión anterior, y reescribirlo ocho siglos después, con nula utilidad como documento histórico), Pelayo logró fugarse de dicha ciudad durante el gobierno del valí Al Hurr (717–718) y a su vuelta a Asturias instigó una revuelta contra las autoridades musulmanas de Gijón (la identidad de don Pelayo, sigue siendo un tema abierto, siendo esta solo una de las teorías). El caudillo de los astures —cuyo origen es discutido por los historiadores— tenía entonces su morada en Bres (concejo de Piloña) y a dicho lugar Munuza envió tropas al mando del general Al Qama. Tras recibir noticias de la llegada de los musulmanes, Pelayo y sus compañeros cruzaron apresuradamente el río Piloña y se dirigieron al monte Auseva, en una de cuyas cuevas, Covadonga, se refugiaron. Allí lograron emboscar al destacamento sarraceno, que fue aniquilado. La victoria —relativamente pequeña, pues en ella intervinieron apenas unos cuantos cientos, o decenas, de soldados bereberes— otorgó un gran prestigio a Pelayo y provocó una insurrección masiva de los astures. Munuza, viéndose entonces aislado en una región crecientemente hostil decidió abandonar Gijón y dirigirse a la Meseta a través del Camino de la Mesa. Sin embargo, siempre según la crónica citada, fue interceptado y muerto por los astures en Olalíes (actual concejo de Grado). La "Crónica Mozárabe", única crónica casi contemporánea y probablemente con menos intereses creados en los hechos, pasa por alto cualquier mención al incidente. 

Recientemente, en el Picu Homón —junto al puerto de la Mesa— y el Campamento romano de La Carisa (situada unos 15 kilómetros más al este, en el concejo de Lena, dominando los valles del Huerna y Pajares), se han llevado a cabo excavaciones por un equipo de arqueólogos, que han encontrado fortificaciones cuya datación, según los datos proporcionados por el Carbono 14, es de entre finales del siglo VII y principios del VIII: En estos lugares han sido halladas atalayas y fosos de casi dos metros, en cuya construcción y vigilancia tuvieron que participar miles de soldados, lo que requería de un alto grado de organización y de un liderazgo firme, probablemente el del propio Pelayo. Por tal motivo, los especialistas consideran que es muy probable que la construcción de dicha línea defensiva tuviera como objetivo impedir la entrada de los musulmanes en Asturias a través de los puertos de la Mesa y Pajares.

Tras la victoria de Don Pelayo en la batalla de Covadonga (722) sobre los musulmanes, se establece una pequeña entidad territorial en las montañas asturianas que dará lugar más tarde al Reino de Asturias. El liderazgo de Pelayo no era comparable al de los reyes visigodos: de hecho los primeros reyes de Asturias se autotitulaban alternativamente "princeps" ‘príncipe’ y "rex" ‘rey’ y no es hasta la época de Alfonso II cuando este último título se consolida definitivamente. En este sentido el título de "princeps" tenía una gran tradición en los pueblos indígenas del norte de España y su uso se constata en la epigrafía galaica y cantábrica, en la que aparecen expresiones como "princeps albionum" (en una inscripción hallada en el concejo de Coaña) y "princeps Cantabrorum" (sobre una lápida vadiniense del municipio de Cistierna, en León). En realidad, el reino de Asturias surgió como un caudillaje sobre los pueblos de la Cornisa Cantábrica que habían resistido tanto a los romanos como a los visigodos y que no estaban dispuestos a someterse a los dictados del Imperio Omeya. La influencia de los inmigrantes provenientes del sur, huidos de al-Ándalus, irá impregnando de goticismo al reino asturiano. Sin embargo, todavía a principios del siglo IX en el testamento de Alfonso II se renegaba de los visigodos culpándoles de la pérdida de Hispania. La crónicas en las que se basa el conocimiento de la época, escritas todas en tiempos de Alfonso III cuando la influencia ideológica goticista era ya importante, son la "Sebastianense", "Albeldense" y "Rotense".

Durante las primeras décadas el control asturiano sobre las diferentes regiones del reino era aún bastante laxo, y por ello debía ser fortalecido continuamente a través de alianzas matrimoniales con otras familias poderosas del norte de la península ibérica: De este modo, Ermesinda, la hija de Pelayo, contrajo matrimonio con Alfonso, hijo de Pedro de Cantabria. Y los hijos de Alfonso, Fruela y Adosinda hicieron respectivamente lo propio con Munia, una vasca originaria de Álava, y Silo, un jefe local pésico del área de Flavionavia (Pravia).

Tras la muerte de Pelayo en el año 737, su hijo Favila o Fáfila es elegido monarca. A Fáfila, según las crónicas, lo mata un oso en una de las pruebas de valor normalmente exigidas a la nobleza de la época.

A Favila le sucede Alfonso I, que heredó el trono de Asturias gracias a su matrimonio con la hija de Pelayo, Ermesinda. La crónica Albeldense narra como Alfonso llegó al reino en algún momento posterior a la batalla de Covadonga para contraer matrimonio con Ermesinda. La muerte de Favila posibilitó su acceso al trono así como la llegada al poder de la que llegaría a ser una de las familias más poderosas del Reino de Asturias: La Casa de Cantabria. Si bien en un principio únicamente Alfonso se desplazó a la corte de Cangas, lo cierto es que, tras la progresiva despoblación de la Meseta y del Valle Medio del Ebro, donde se situaban las principales plazas fuertes del Ducado de Cantabria como Amaya, Tricio o la Ciudad de Cantabria, los descendientes del duque Pedro de Cantabria se retiraron desde tierras riojanas hacia el área cantábrica y allí llegaron con el tiempo a hacerse con los destinos del Reino de Asturias.

Será Alfonso el que inicie la expansión territorial del pequeño reino cristiano desde su primer solar de los Picos de Europa avanzando hacia el oeste hasta Galicia y hacia el sur con continuas incursiones en el valle del Duero tomando ciudades y pueblos y llevando a sus habitantes hacia las zonas más seguras del norte. Esto provocará el despoblamiento estratégico de la meseta creando el "Desierto del Duero" como protección contra futuros ataques musulmanes.

Este despoblamiento, defendido por Claudio Sánchez-Albornoz, es puesto en duda hoy en día, por lo menos en lo que se refiere a su magnitud. Las principales ideas para refutarlo son por un lado la conservación de la toponimia menor en múltiples comarcas así como el hecho de que aún hoy en día existan grandes diferencias, tanto desde el punto de vista de la antropología biológica como desde la cultural, entre los habitantes de la zona cantábrica y los de la Meseta Central. Lo que sí es cierto es que en la primera mitad del siglo VIII tuvo lugar en el valle del Duero un proceso de ruralización que trajo consigo el abandono de la vida urbana y la organización de la población en pequeñas comunidades de pastores. Como causas de dicho proceso pueden citarse las siguientes: La quiebra definitiva del sistema de producción esclavista existente desde tiempos del Bajo Imperio, la propagación continuada de grandes epidemias en la zona, y por último el abandono de Al Ándalus por parte de las guarniciones bereberes tras la revuelta de los años 740 y 741. Todo ello posibilitó el surgimiento de un espacio poco poblado y sin organizar que aisló al reino asturiano de las acometidas musulmanas y le permitió afianzarse progresivamente.

Por lo demás, las "campañas" de los reyes Alfonso I y Fruela en valle del Duero no debían ser muy diferentes a las "razias" que los astures realizaban por la misma zona en época prerromana. Inicialmente la expansión asturiana se lleva a cabo fundamentalmente a través del territorio cantábrico (desde Galicia hasta Vizcaya) y será necesario esperar hasta los reinados de Ordoño I y Alfonso III para que el Reino de Asturias tome posesión efectiva de los territorios situados al sur de la Cordillera.

Fruela I, hijo de Alfonso I, consolida y amplía los dominios de su padre. Es asesinado por miembros de la nobleza vinculados a la casa de Cantabria.

Las fuentes escritas son muy concisas en lo referido a los reinados de Aurelio, Silo, Mauregato y Bermudo I. Generalmente este período, con una duración de veintitrés años (768–791), ha sido considerado como una larga etapa de oscuridad y repliegue del reino de Asturias. Esta visión sostenida por algunos historiadores, que incluso denominaron a esta fase de la historia del reino asturiano como la de los "Reyes holgazanes", ha sido debida a que en ese momento parece que no se dieron importantes acciones bélicas contra al-Ándalus. Sin embargo, esas mismas fuentes escritas permiten decir que durante esos años se produjeron relevantes y decisivas transformaciones en lo relativo a las cuestiones internas del reino asturiano. Todas ellas prepararon y dieron una base, en todos los órdenes y aspectos, para el posterior afianzamiento y expansión de Asturias.

En primer lugar, fue en esos años cuando se constata la primera rebelión interna astur protagonizada por el propio Mauregato, que expulsó del trono a Alfonso II de Asturias. Con ella, se inició en Asturias una serie de rebeliones protagonizadas por ascendentes grupos aristocráticos palaciegos y de grandes propietarios que, en base al creciente desarrollo económico de la zona, trataban de desplazar del poder a la familia reinante de Don Pelayo. Las importantes rebeliones de Nepociano, Aldroito y Piniolo, durante el posterior reinado de Ramiro I, forman parte de este proceso de transformación económico, social, político y cultural del reino asturiano, sucedido entre los siglos VIII y IX.

En segundo término, en esa época fracasaron las sublevaciones periféricas de galaicos y vascones, que fueron abortadas por los reyes asturianos. Dichas revueltas, a su vez, se aprovecharon de las rebeliones internas de la zona central y oriental de Asturias; y en ciertas ocasiones, dieron su ayuda a unos u otros contendientes de la aristocracia asturiana: refugio de Alfonso II en tierras alavesas, tras su huida; el apoyo a la sublevación de Nepociano en algunas zonas asturianas o la unión de los galaicos a la causa de Ramiro I.

Por último, otros datos hablan de importantes transformaciones internas del reino asturiano en ese momento. Son las sublevaciones de los libertos ("serbi", "servilis orico" y "libertini", según las Crónicas) acaecidas durante el reinado de Aurelio. Las relaciones de propiedad entre dueño y esclavo poco a poco se fueron rompiendo. Este hecho, unido al progresivo papel del individuo y de la familia restringida en detrimento del papel que hasta ese momento había jugado la familia amplia, es un indicio más de que una nueva sociedad estaba surgiendo en la Asturias de finales del siglo VIII y comienzos del siglo IX.

A Fruela I le sucede Aurelio de Asturias, nieto de Pedro de Cantabria, que instalará la corte en terrenos de lo que actualmente es el concejo de San Martín del Rey Aurelio, antes perteneciente a Langreo, entre los años 768 y 774. Al morir este, le sucede Silo, que traslada la corte a Pravia. Silo estaba casado con Adosinda, una hija de Alfonso I (y por lo tanto, nieta de Pelayo). 

Al morir el rey Silo es elegido rey el joven Alfonso II (que más adelante, en 791, volvería a recuperar el trono), pero Mauregato, hijo bastardo del rey Alfonso I, organiza una fuerte oposición y consigue que el nuevo rey se retire a tierras alavesas (la madre de Alfonso II, Munia era vascona) adjudicándose el trono asturiano. Este rey, pese a la mala fama que la historia le adjudica, mantuvo buenas relaciones con Beato de Liébana, quizás la figura cultural más importante del reino, y le apoyó en su lucha contra el adopcionismo. La leyenda dice que este rey era hijo bastardo de Alfonso I con una mora, y le atribuye el tributo de las cien doncellas. Le sucede Bermudo I, hermano de Aurelio. Se le llama "el diácono", aunque probablemente solo recibiera votos menores. Bermudo abdica tras una derrota militar, acabando su vida en un monasterio.

Tras la abdicación de Bermudo I, Alfonso II "el Casto" volvió a Asturias y se proclama rey, acabándose el período de relativa paz con los musulmanes de periodos anteriores. Durante su reinado realiza expediciones de castigo hacia el sur, llegando tan lejos como hasta Lisboa en 798, y en 825 vence también a los musulmanes en el Nalón. Fija la capital del reino en Oviedo y repuebla Galicia y zonas septentrionales de Castilla y León. Fue un reinado expuesto a ataques continuos de los musulmanes. Aun así, se expande, y aparece el prerrománico asturiano, dando lugar a joyas de la arquitectura medieval europea. Alfonso II instaura el culto jacobeo, y es la primera figura en el Camino de Santiago, que vincula a Asturias con Europa (especialmente con el reino de Carlomagno), teniendo como enemigo común a un Sur de cultura oriental. La madre de Alfonso II, Munia era alavesa, con lo que ya se ve la vocación de atraer al reino asturiano a los vecinos vascones. En la batalla de Lutos ("llodos" en asturiano, ciénagas en castellano), se inflige una dura derrota a los árabes y bereberes que querían acabar con la creciente amenaza que suponía el ya reino. En 808, manda forjar la Cruz de los Ángeles. Este rey encarga al arquitecto Tioda la construcciones de varios edificios de carácter regio y religioso para embellecer Oviedo, de los cuales por desgracia pocos han sobrevivido, al edificarse encima en reinados posteriores.

Los siguientes reyes, Ramiro I (hijo de Bermudo que se proclama rey tras una guerra civil) y Ordoño I, viven en un periodo de guerra continua contra los musulmanes. En tiempos de Ramiro I, se desarrolla el arte ramirense, el apogeo del prerrománico asturiano. Este rey libra la batalla de Clavijo, en la que, según la leyenda, el apóstol Santiago a lomos de un caballo blanco ayuda al ejército asturiano contra las tropas islámicas. En el año 844, una flota normanda aparecía frente a la costa de Gijón. No se sabe con certeza si desembarcaron allí, pero no fueron detenidos ya que prosiguieron hasta el lugar que las crónicas llamaban "Faro de Brigantio" (La Coruña), donde fueron rechazados, prosiguiendo la incursión según las crónicas hacia España (las crónicas asturianas llamaban España a al-Ándalus).

Ordoño repuebla Astorga, León, Tuy y Amaya. Establece relaciones estrechas con el Reino de Pamplona, ayudando posiblemente a la liberación del rey García Íñiguez secuestrado por los normandos. Dentro del proceso de vinculación con el valle del Ebro, establece alianzas con los Banu Qasi de Zaragoza, a los que también combate en ocasiones en sucesivas variaciones de alianzas. Ordoño también trata de ayudar, sin éxito, a los mozárabes toledanos en rebelión contra el emir cordobés. A su muerte, le sucede su hijo Alfonso III.

Alfonso III marca el momento cumbre de poderío del reino de Asturias. Establece relaciones muy estrechas con el Reino de Pamplona, lucha y se alía repetidas veces con los Banu Qasi de Zaragoza y lucha al lado de los mozárabes de Toledo en su lucha contra el poder emiral.

En el año 908, un siglo después de que Alfonso II lo hiciera con la cruz de los Ángeles, manda forjar la Cruz de la Victoria, símbolo desde entonces de Asturias. Alfonso se casa con Jimena, noble navarra, posiblemente hija de García Iñíguez. Con el apoyo de los nobles gallegos, como Hermenegildo Gutiérrez, conquista el norte del actual Portugal. También se avanza por el Duero, conquistándose Zamora y Burgos. En el momento de apogeo, el reino asturiano ocupa todo el noroeste peninsular, desde Oporto hasta Álava. 

García I, hijo de Alfonso III el Magno, después de su lucha contra su padre y sus hermanos Ordoño II y Fruela II, traslada la capital del reino a León, con lo que se crea un nuevo reino que aglutinará al asturiano, el Reino de León.

Las dos Asturias (Asturias de Oviedo y Asturias de Santillana) y la comarca cántabra de Liébana constituyeron el solar donde se forjó el primer estado cristiano de la Reconquista. En territorio asturiano se sitúan las cuatro capitales que sucesivamente tuvo el reino (Cangas de Onís, Pravia, San Martín del Rey Aurelio y Oviedo) así como las principales muestras del arte prerrománico asturiano.

La Crónica Rotense, al mencionar las campañas de Alfonso I, dice que «en este tiempo se poblaron las Asturias, Primorias, Liébana, Trasmiera, Sopuerta, Carranza, Bardulia, que ahora llaman Castilla y la parte marítima de Galicia». Se describen en esta cita las diferentes entidades regionales y comarcales existentes en territorio cantábrico.

En principio, el reino original de Pelayo comprendía, al menos, los territorios de la actual Asturias central y oriental, como se desprende de las narraciones de la crónica Albeldense, y de la Crónica Rotense, que sitúan el relato de los orígenes del reino entre la "ciuitate Gegione" y Covadonga, con Brece, en Piloña, de por medio. Este ámbito territorial es el denominado como "patria Asturiensium" en la Crónica Sebastianense.

Sin embargo, los sucesores de Pelayo fueron progresivamente extendiendo sus dominios, engullendo territorios como Trasmiera o El Bierzo que, no obstante, conservaron su autonomía bajo la forma de ducados o condados regidos por "comtes" vinculados a la aristocracia local, como Rodrigo de Castilla o Gatón del Bierzo.

Al este del río Miera se situaban las comarcas de Trasmiera, Sopuerta y Carranza. Estos dos últimos territorios fueron anexionados a Vizcaya (1285) y posteriormente al País Vasco (1979), pero aún hoy siguen conservando buena parte de su cultura montañesa original: El habla tradicional de Encartaciones presenta rasgos asturleoneses y la mitología tradicional encartada incluye referencias a criaturas como el Ojáncanu o el Trenti que tan familiares son en el folclore de La Montaña de Cantabria.

Tras la conquista islámica de España, el territorio de la Submeseta norte comenzó a experimentar un proceso de despoblamiento que se vio agudizado por la rebelión bereber de los años 740 y 741 y por la sequía que afectó a dicha área durante las décadas centrales del siglo VIII. El resultado es que la Cuenca del Duero se convirtió en un territorio de nadie.

Ha habido cierta discusión en la historiografía española en torno a la naturaleza e intensidad del despoblamiento del Valle del Duero. Algunos autores, como Sánchez Albornoz, afirmaban que dicha despoblación fue total, y más aún, fue buscada por los reyes asturianos para de esta manera aislarse estratégicamente del emirato de Córdoba y dificultar la entrada de las aceifas musulmanas en Asturias. Otros autores, como Abilio Barbero y Marcelo Vigil, consideraron que, antes que una despoblación, lo que se produjo fue una desorganización política y económica del territorio que, lejos de haber comenzado en el siglo VIII, hunde sus raíces en la crisis del latifundismo tardorromano y del sistema esclavista. Además, etnólogos como Julio Caro Baroja han llamado la atención sobre el hecho de que hay enormes diferencias entre las culturas cantábricas (gallega, asturiana...) y las de la Meseta (como la leonesa o la castellana).

La zona occidental de la Submeseta Norte, aquella que corresponde a los valles del Esla, el Órbigo y el Sil, estaba poblada en tiempos prerromanos por tribus de lengua céltica como los "astures" o los "vacceos". Con la conquista romana, dichos territorios fueron incorporados al "Conventus Asturiensis", que tras la división provincial de Caracalla fue adjudicado a la provincia de Gallaecia. En el periodo visigodo, el área pasó a formar parte del Ducado de Asturia (o Ducado Asturiense), cuyas principales ciudades eran Astorga ("Asturica Augusta", capital de los astures cismontanos) y León ("Legio VII", fundada por los romanos tras las guerras cántabras).

Desde la segunda mitad del siglo VIII estas regiones pasaron a ser progresivamente absorbidas por el Reino de Asturias. Sin embargo, dicha absorción se realizó de diferentes maneras, dependiendo del territorio. Así, de un lado, parece que las regiones de la montaña leonesa, el Bierzo y la Maragatería nunca llegaron a despoblarse del todo y conservaron toda su personalidad étnica: De este modo, es muy probable que los territorios de Valdeón, Laciana y Babia pertenecieran a la monarquía asturiana desde tiempos de Pelayo. Asimismo, se constata la existencia de un condado del Bierzo desde tiempos del rey Alfonso II, y es muy probable que sea bastante anterior al reinado de este monarca. Por otro lado, los estudios etnográficos que se han realizado sobre el pueblo maragato, revelan un posible origen astur, que fue expresado de una manera bastante poética por el folklorista asturiano Constantino Cabal. En todas estas comarcas, se han preservado hasta la actualidad modalidades lingüísticas asturleonesas y rasgos culturales que son muy próximos a los asturianos. Por el contrario, la colonización del Páramo Leonés, Coyanza y Tierra de Campos tuvo un fuerte componente mozárabe: Por todas estas comarcas abundan formas toponímicas correspondientes a dicha lengua, en las que predominan los sufijos "-el" y "-iel", en lugar del asturleonés "-iellu".

En cualquier caso, lo cierto es que la ciudad de León se convirtió en el principal bastión asturiano en la Meseta Central, llegando, ya en vida de Alfonso III, a convertirse en sede regia. Otro hito más en el avance cristiano hacia el Sur lo constituyó la fortificación y repoblación de Zamora, verdadera guardiana del río Duero y que por su importancia llegó a ser calificada por algunos historiadores árabes como la "capital de los gallegos". La expansión leonesa se articularía durante los siglos siguientes en torno a la antigua calzada romana que unía "Asturica" con "Emerita Augusta", que daría lugar con posterioridad a la Vía de la Plata.

La vinculación entre el norte de Galicia y Asturias se constata ya en el Parroquial Suevo, documento del siglo VI donde se habla de la sede obispal de Britonia, que se extendía por territorios de la provincia de Lugo y de Asturias.

En el transcurso de la conquista musulmana los musulmanes conquistaron Tuy, y establecieron allí un señorío que tenía por base el valle bajo del Río Miño. La rebelión bereber de los años 740 y 741 trajo como consecuencia el abandono por parte de las guarniciones bereberes de todas sus posiciones al norte de la Sierra de Gredos. De este modo el sur de Galicia se vio libre del dominio musulmán, aunque sufrió un proceso de despoblación similar al del Valle del Duero que llevó al abandono de todo tipo de vida urbana.

Por el contrario, el norte de Galicia fue incorporado al naciente reino asturiano por el rey Alfonso I, que instaló en la ciudad de Lugo al obispo Odoario. La débil posición asturiana tuvo que ser consolidada por su sucesor, Fruela I, que aplastó una insurrección de los gallegos y derrotó en Pontuvia una expedición de castigo enviada por el emir de Córdoba Abderramán I. Décadas después, otra insurrección de los gallegos fue derrotada por el rey Silo en la batalla de Montecubeiro, cerca de Castroverde.

En cualquier caso, el descubrimiento en tiempos del rey Alfonso II del sepulcro del apóstol Santiago y el surgimiento del Camino que lleva su nombre aseguraron la integración espiritual de Galicia en el Reino de Asturias y posteriormente en los de León y Castilla.

La expansión hacia el Sur fue iniciada por Ordoño I, que repobló Tuy. En décadas posteriores Vímara Pérez, vasallo de Alfonso III, llegó hasta Oporto (tomada en 868) sentando las bases del Condado Portucalense que más tarde daría lugar a Portugal.

Las zonas más orientales de la Submeseta norte estaban pobladas a finales del siglo VIII por pequeñas comunidades rurales de muy diversos orígenes étnicos. La población indígena era descendiente de las diferentes tribus que poblaban el lugar en tiempos prerromanos, como los várdulos, vacceos, los turmogos y los celtíberos, y se dedicaba fundamentalmente a labores de pastoreo. Sobre esta población originaria se fue asentando una oleada migratoria procedente del área cántabro-pirenaica, que venía integrada fundamentalmente por clanes pertenecientes a dos pueblos diferentes: Los cántabros y los vascones.

La expansión más temprana es la de los cántabros. La Cantabria descrita por los geógrafos romanos se extendía casi exclusivamente por territorios de la Cordillera, pero sin embargo ya a partir del siglo II y probablemente fruto de la sedentarización de este pueblo, comienza su expansión por tierras de la Meseta, testimoniada arqueológicamente por infinidad de lápidas vadinienses que registran un intenso movimiento migratorio de los habitantes de la zona de los Picos de Europa hacia la zona de Cistierna (León). Sin embargo, la colonización más intensa fue la que se llevó a cabo en el valle alto-medio del río Ebro, en las actuales provincias de Burgos y La Rioja.

De este modo, de la lectura de la Crónica del Biclarense (siglo VI), donde se describen las campañas del rey visigodo en tierras de los cántabros, se deduce que la Cantabria visigoda no coincidía con la descrita por los geógrafos romanos, sino que se extendía por las tierras de La Rioja y la Ribera Navarra. Se la describe como una región ubicada junto al territorio de los vascones, y cuya capital era una urbe que portaba el mismo nombre, la Ciudad de Cantabria, asentada un kilómetro al norte de la actual ciudad de Logroño y cuyas ruinas son aún visibles. Dicha ciudad recibió las admoniciones de San Millán, que exhortó a sus habitantes a la conversión, sino querían ser aniquilados por las fuerzas del mal. Una advertencia que no fue escuchada por los lugareños, que al año siguiente verían sus hogares destruidos por las tropas del rey arriano Leovigildo. Más tarde, este lugar fue sede del Ducado de Cantabria, creado por Ervigio a finales del siglo VI y que tenía como objetivo pacificar a los cántabros y contener la expansión vasca. Se conoce el nombre de uno de sus duques, Pedro, que fue padre del rey asturiano Alfonso I y también algunas de sus instituciones, como el "Senado de Cantabria", que tenía su sede en la ciudad homónima y que es citado por San Braulio en su obra "Vida de San Millán".

Todavía en el siglo XI el obispo de Astorga, Sampiro, llama a Sancho III el Mayor de Pamplona "Rex Cantabriensis", y ya en el reinado de García Sánchez III, a un noble navarro, Fortún Ochoa, aparece en la documentación como señor de Cameros, de la Val de Arnero y 'de Cantabria por ejercer la tenencia de estas plazas bajo el mandato del rey.

La expansión vasca tuvo lugar a principios de la Reconquista. La toponimia demuestra que la lengua éuskara fue hablada en buena parte de La Rioja y de Burgos y en las Glosas Emilianenses se conservan algunas frases en vasco que fueron anotadas probablemente por monjes hablantes nativos de esta lengua. De hecho, la lengua castellana ha heredado de la vasca su sistema fonológico y buena parte de su antroponimia (García, Sancho, Jimeno) e incluso en el poema del Mio Cid y en las obras de Gonzalo de Berceo algunos de sus personajes emplean expresiones vascuences.

En cualquier caso, la zona comenzó a caer bajo la órbita de los reyes de Asturias a partir de Ordoño I y Alfonso III, que con ayuda de sus vasallos Rodrigo y después su hijo Diego Rodríguez Porcelos repoblaron la Peña de Amaya y fundaron la ciudad de Burgos.

Los primeros avances significativos desde la Cordillera Cantábrica hacia la Meseta fueron protagonizados por los "foramontanos", nombre con el que se designa a los colonos que abandonaban los territorios montañosos del Norte y se dirigían hacia el Sur a colonizar el llano: Unas veces la colonización se llevaba a cabo por iniciativa de la pequeña nobleza y los monasterios, y en otras ocasiones eran amplios grupos de parentela los que migraban a la Meseta, en un movimiento no muy diferente al que los vadinienses realizaron en los primeros siglos de nuestra era. Durante el reinado de Alfonso II fueron ocupadas la zona de Campoo, el territorio de las fuentes del Ebro así como las zonas más septentrionales de la Cuenca del Duero. Era este un territorio difícil de colonizar, puesto que el flanco oriental del reino era con diferencia el más desprotegido: Las aceifas que se dirigían a Galicia y León habían de atravesar el Desierto del Duero, un lugar poco propicio para el aprovisionamiento de las tropas, y por ello sus bases se situaban en Toledo, Coria, Talamanca y Coímbra, poblaciones que se situaban a más de 400 kilómetros de sus objetivos. Sin embargo, la zona de la Rioja estaba relativamente poblada, se encontraba en manos de una poderosa familia de señores locales, los Banu Qasi, y estaba atravesada por una calzada romana que pasaba por Amaya y llegaba hasta Astorga. Esta misma carretera había sido utilizada por Leovigildo durante sus campañas contra los cántabros en el año 574 y por Muza, durante su extensa operación de conquista llevada a cabo en los años 712–714.

El rey Ramiro I realizó un intento de colonización y fortificación de la ciudad de León, aunque este intento fue desbaratado por una aceifa musulmana. Sin embargo, su sucesor, Ordoño, aprovechó el creciente poderío militar astur así como los problemas internos del Emirato para establecer y fortificar plazas estratégicas en la Cuenca del Duero. Rodrigo, primer conde de Castilla por Ordoño I repobló la Peña de Amaya, con lo que aseguró la presencia asturiana en la margen derecha del río Ebro.

Su sucesor, Diego Rodríguez Porcelos, procedió ya en tiempos de Alfonso III a una política aún más expansiva: Se fija la frontera oriental del condado en el río Arlanzón y los Montes de Oca. Se funda Burgos y se arrebatan a los musulmanes algunas de sus fortalezas fronterizas, como Pancorbo, que servían de base para las aceifas con las que los emires de Córdoba asolaban estas comarcas. Para proteger la frontera oriental del Reino de Asturias tuvieron que construirse multitud de castillos que pronto darían nombre a la región: Castilla.

En las décadas siguientes a la muerte de Diego Porcelos, otros nobles como Vela Jiménez, conde de Álava, o Munio Núñez, conde de Castilla, continuarán con el avance asturiano hacia el Sur, que alcanzará el valle del Duero a principios del siglo X. Se procederá a la ocupación de la ciudad de Osma y a la penetración hacia la zona de Sepúlveda. Todas estas tierras, pertenecientes al Valle alto del río Duero, estuvieron habitadas por los celtíberos y los arévacos, y en ellas se enclavaban poblaciones de abolengo como "Numantia" (destruida por las tropas de Escipión), y "Uxama" (Osma), que según todos los indicios siguió poblada aún después de la conquista islámica. La carta de Beato a Eterio, obispo de Osma, demuestra que a finales del siglo VIII dicha ciudad seguía conservando incluso su sede obispal. El filólogo español Rafael Lapesa, expone en su obra "Las lenguas circunvecinas del castellano", su tesis de que el castellano hablado en Soria así como en la zona de Montes de Oca, tenía un sustrato mozárabe, lo que parecería dar argumentos a los que afirman que hubo una continuidad demográfica y cultural en determinadas zonas de la Cuenca de Duero.

A principios de la era cristiana, los territorios de la depresión vasca estaban poblados fundamentalmente por tres pueblos diferentes: Los várdulos, los caristios y los autrigones. Algunos autores, como el lingüista Koldo Mitxelena, consideran que dichos pueblos hablaban una lengua antepasada del vasco actual.
En cualquier caso, lo cierto es que la lengua vasca nunca sobrepasó el límite del río Nervión en la época de la Monarquía Asturiana. En ese momento, los vascones de los territorios más occidentales, cayeron en la órbita asturiana durante los reinados de los reyes Alfonso I y Fruela. El segundo casó con una alavesa, Munia, que le daría un hijo, el futuro rey Alfonso II. Durante el reinado de Mauregato, el joven príncipe Alfonso hubo de refugiarse con sus parientes maternos en la zona de Álava hasta que al fin, tras la muerte de Bermudo I, pudo acceder definitivamente al trono asturiano. La constitución del Condado de Álava se remonta a la rebelión del conde Eglyón contra el rey Alfonso III. Tras sofocar la rebelión, el monarca encomendó el gobierno de Álava a un noble leal a su causa, Rodrigo de Castilla, aunque nunca se intituló conde de Álava y su gobierno fue efímero pues en el 882 aparece Vela Jiménez en la documentación como conde de Álava. Tuvo este magnate una importancia fundamental en la repoblación y la fortificación de Castilla, especialmente en la defensa de Cellorigo en el año 882 contra las tropas de Al-Mundir de Córdoba. El Condado de Álava se extendía por parte de las actuales provincias de Álava y Vizcaya, llegando hasta el río Deva ya en Guipúzcoa.

El cronista vizcaíno Lope García de Salazar sitúa en sus obras "Crónicas de Vizcaya" (del año 1454) y "Bienandanzas e fortunas" (1471) el nacimiento del señorío de Vizcaya en esta época. Se menciona en ellas la existencia de un héroe fundador, Jaun Zuria, de tez blanca y cabellos rubios que creó el señorío tras su victoria sobre las tropas asturianas en la legendaria Batalla de Arrigorriaga (año 840). Sin embargo, la falta de documentación al respecto hace que todas estas cuestiones queden en un terreno especulativo: Lo único que constatan las crónicas contemporáneas es que Alfonso III hizo frente exitosamente a una rebelión de los vascones.

El reino tenía una economía de subsistencia puramente agrícola y ganadera, eminentemente rural, con Oviedo como único núcleo urbano en la actual Asturias. Sin embargo, había una serie de ciudades importantes en las demás partes del reino, como Braga, Lugo, Astorga, León, Zamora. La sociedad, de tipo igualitario en un primer momento, se va feudalizando progresivamente, sobre todo con la llegada de población mozárabe de cultura visigoda. Paradójicamente, esta población va cristianizando el reino, que inicialmente se asentaba en una zona con muchos elementos culturales paganos (la iglesia de Santa Cruz, en Cangas de Onís, primer vestigio arquitectónico, se construye sobre un dolmen).

Pese a que tradicionalmente se consideró que la actividad cultural era muy escasa, el trabajo de Beato, el acróstico dedicado a Silo, las construcciones prerrománicas, etc., hacen que este punto de vista esté cambiando.

La organización territorial estaba ligada a "comtes", que estaban al mando de las partes más alejadas, estando el núcleo inicial astur bajo mandato directo del rey. La estructura de la corte, el "oficio palatino", era mucho más simple que el de los visigodos.

El reino de Asturias empleó la representación de la Cruz de la Victoria como símbolo protector en Iglesias y fundaciones públicas y también en construcciones militares, como la fortaleza de Alfonso III en Oviedo, constituyéndose así en emblema del reino.

Los monumentos de arte prerrománico en Asturias son exponentes de la pequeña civilización que estaba forjándose en el área cantábrica. En este sentido, el arte asturiano es, junto con el catalán, uno de los dos principales exponentes del prerrománico en España. Si bien en este último las influencias lombardas son evidentes, en el arte prerrománico asturiano se deja sentir sobre todo el influjo carolingio.

Sin embargo, a pesar de que tradicionalmente se han venido subrayando los vínculos entre el estilo asturiano y el visigótico, algunos autores no dejan de señalar el hecho de que probablemente buena parte de sus características deriven del arte romano y paleocristiano del que existen algunos exponentes en territorio asturiano. También hay ciertas influencias autóctonas, puramente "astures", y en este sentido en algunos monumentos prerrománicos, como San Miguel de Lillo, pueden observarse medallones en los que aparecen grabados motivos paganos como la "hexapétala" o la espiral solar, que aún hoy se siguen empleando para decorar los hórreos asturianos.

El arte prerrománico asturiano puede estructurarse en los siguientes periodos: "Prerramirense" (mediados del siglo VIII–842), en el que se insertan tanto las iglesias construidas por el rey Silo en Pravia como los monumentos que construyó Alfonso II alrededor de su corte en Oviedo, entre los que destacaban la catedral prerrománica de San Salvador, que fue sustituida por la actual gótica (construida en el siglo XIV), el Palacio Real, que también fue derruido con posterioridad y del que tan solo se conservan la capilla palatina (actual Cámara Santa) y algunas arquetas que hoy en día están integradas en la iglesia de San Tirso; "Ramirense", que recibe su nombre del rey Ramiro I, bajo cuyo reinado se construyeron los principales monumentos pertenecientes al arte asturiano, como Santa María del Naranco y San Miguel de Lillo; "Postrramirense", que abarca todas aquellas construcciones realizadas durante los reinados de Ordoño II y Alfonso III el Magno, como San Salvador de Valdediós.

Junto con todos estos logros en materia arquitectónica, en el Reino de Asturias se desarrolló una orfebrería refinada cuyos exponentes más renombrados lo constituyen la Cruz de los Ángeles, la Cruz de la Victoria y la Caja de las Ágatas.

Aunque los primeros testimonios cristianos de Asturias datan del siglo V la verdadera progresión del cristianismo en Asturias solo tuvo lugar a partir de mediados del siglo VI, cuando toda una serie de anacoretas, como Santo Toribio de Liébana y otros monjes pertenecientes a la orden de San Fructuoso de Braga, se fueron asentando en territorios de la cordillera Cantábrica e iniciaron la predicación de la doctrina cristiana entre los lugareños.

La cristianización de Asturias avanzó de una manera muy lenta y puede decirse que jamás llegó a significar el olvido de las antiguas divinidades. Como en muchos otros lugares (aunque quizá aquí en mayor medida), pervivieron en las creencias populares coexistiendo sincréticamente con la nueva religión. En este sentido, San Martín de Braga reprendía de este modo en su obra "De correctione rusticorum" a los campesinos de la Gallaecia por su apego a los cultos paganos: «Muchos demonios de los expulsados del cielo presiden en el mar, en los ríos, en las fuentes o en las selvas y se hacen adorar de los ignorantes como dioses. A ellos hacen sacrificios: en el mar invocan a Neptuno; en los ríos, a las Lamias; en las fuentes, a las Ninfas; "en las selvas, a las Dianas"».

El folclorista asturiano Constantino Cabal fue el que sostuvo por vez primera la existencia de parentesco etimológico, hoy generalmente aceptado por los filólogos, entre el vocablo latino "diana", que menciona la cita de San Martín de Braga, y el asturiano "xana", que designa a la conocida criatura de la mitología asturiana: ello podría indicar la existencia de una cierta continuidad entre la antigua religión astur y las creencias míticas presentes en la actualidad en las zonas rurales de Asturias. No en vano el arroyo que brota del santuario de Covadonga lleva aún hoy el nombre de la antigua diosa celta Deva, a cuyo culto estaba consagrado el lugar antes de su cristianización. Según otros autores, "deva" es una palabra céltica e indoeuropea que significa simplemente "diosa", por lo que sería posible que tras esta denominación se escondieran otras divinidades femeninas como Navia o Briga. En todo caso, "Deva" era una advocación que, según la opinión de renombrados historiadores, etnólogos y filólogos, gozaba de gran predicamento en época precristiana, tal y como testimonian topónimos como La Isla de Deva (en Castrillón) o el pozo del Güeyu la Deva (Gijón). De la primera se dice aún hoy que vienen las niñas que nacen en el territorio de dicho concejo. Del Güeyu la Deva, que sus aguas rojas no son más que la sangre de los moros derrotados en la batalla de Covadonga. 

En el valle medio del Sella, zona donde se asienta Cangas de Onís, existía un área dolménica que databa de época megalítica, probablemente del periodo 4000–2000 a. C. En ella, particularmente en el dolmen de Santa Cruz, se realizaban los enterramientos rituales de los jefes tribales de la comarca. Dicha práctica pervivió tras las conquistas romana y visigótica, y lo hizo hasta tal punto que todavía en el siglo VIII el rey Favila fue enterrado allí, en el mismo lugar donde reposaban los restos de caudillos ancestrales. Aunque la propia monarquía asturiana patrocinó la cristianización del lugar (ordenando la edificación de una iglesia), lo cierto es que aún hoy existen tradiciones paganizantes que afirman que el dolmen de Santa Cruz está poblado por "xanas" y que la tierra que se extrae de su suelo tiene propiedades curativas.

Según la lápida encontrada en la tumba de Favila, la iglesia fue consagrada en el año 738 por un personaje llamado Asterio, al que se califica de "vate", palabra latina que quiere decir 'adivino, profeta', y que tiene cognados en las lenguas célticas, como el gaélico irlandés "oaith", que designaba a aquellos bardos que realizaban profecías y adivinaciones (por ejemplo, el mago Suibhne, equivalente irlandés de Merlín). Esta terminología contrasta con la que encontramos en los textos cristianos más comunes, donde se suele designar a los sacerdotes con el término "presbyterus" (del griego Πρεσβυτερος, 'hermano mayor').

En tal sentido, no está de más recordar que la cristianización de Asturias se llevó a cabo por vías no demasiado ortodoxas: el Parroquial Suevo atribuía a la sede de los bretones las parroquias existentes en el territorio asturiano, por lo que es probable que las primitivas formas de cristianismo usuales en Asturias no difirieran demasiado de las existentes entre las iglesias celtas de las islas Británicas, entre ellas la tonsura de sus monjes, que por sus reminiscencias paganas fue condenada por el IV Concilio de Toledo. Quedan hoy en día en Galicia numerosas leyendas pías relativas a religiosos que viajaron por mar hasta las costas del Paraíso, como por ejemplo San Amaro, Trezenzonio o Ero de Armenteira: leyendas que guardan enormes paralelismos con las historias de San Brandán el Navegante, San Maclovio de Gales o los "imramma" irlandeses. Por otro lado, lo cierto es que el paganismo influyó incluso en las prácticas de la Iglesia Católica en Asturias: no era infrecuente que los sacerdotes participasen en los conjuros para impedir la llegada del Ñuberu a una determinada parroquia, y en la figura de los "freros" se conservan los últimos vestigios de la poesía mitológica en la Asturias tradicional.

El proceso de cristianización fue fomentado por los reyes de Asturias, que a diferencia de los monarcas de la Inglaterra pagana (como Penda de Mercia), de la Irlanda gaélica (Conn el de las Cien Batallas) o la Sajonia del siglo VIII (el duque Witikindo), no cimentaron su poder sobre las tradiciones religiosas indígenas sino que tomaron sus mitos fundacionales de los textos de las Sagradas Escrituras cristianas (particularmente del Apocalipsis, y de los libros proféticos de Ezequiel y Daniel) y de los textos de los Padres de la Iglesia, como veremos en la sección siguiente.

Durante los reinados de Silo y de Mauregato se sentaron las bases de la cultura del Reino de Asturias y de la España cristiana de la Alta Edad Media. En este periodo aparentemente anodino, en el que los reyes de Asturias se sometieron a los dictados de los emires cordobeses, vivió Beato de Liébana, que es probablemente la mayor figura intelectual del Reino de Asturias, y cuya obra dejó una huella imperecedera en la cultura cristiana de la Reconquista.

Beato se vio directamente involucrado en la querella adopcionista, en el seno de la cual combatió con fuerza a Elipando, obispo de Toledo. Los adopcionistas defendían que Jesucristo nació hombre y que solo tras su muerte y resurrección fue adoptado por el Padre y adquirió la cualidad divina. El adopcionismo tenía raíces en el arrianismo, que negaba la divinidad de Cristo, y en el paganismo grecorromano, donde existían algunos ejemplos de héroes como Hércules que después de su muerte alcanzaron la apoteosis. No han de descartarse asimismo influencias musulmanas en el surgimiento del adopcionismo, pues Elipando fue impuesto en su cargo por las autoridades musulmanas, cuya religión negaba la divinidad de Jesús, al que se consideraba profeta pero no Hijo de Dios. Sin embargo, la herejía adopcionista fue combatida por Beato desde su monasterio de Santo Toribio de Liébana, al par que defendió la independencia de la iglesia asturiana frente a la toledana y estrechó lazos con Roma y el Imperio Carolingio: En este sentido, Beato fue apoyado en su lucha contra la iglesia toledana por el Papa así como por Alcuino de York, estudioso anglosajón afincado en Aquisgrán con el cual cultivó una gran amistad.

La obra de mayor trascendencia creada por Beato fueron sus "Comentarios al Apocalipsis", que fueron copiados en manuscritos en los siglos posteriores (denominados usualmente Beatos) y de los que el escritor italiano Umberto Eco ha llegado a decir: «Sus fastuosas imágenes han dado lugar al mayor acontecimiento iconográfico de la historia de la humanidad». Beato expone en ellos una interpretación personal del relato apocalíptico, a la que añade citas procedentes del Antiguo Testamento y de los Padres de la Iglesia, y todo ello acompañado por magistrales ilustraciones.

En los "Comentarios" se da una nueva interpretación a los símbolos del Apocalipsis: Babilonia ya no representa a la ciudad de Roma, sino a Córdoba, sede de los emires de Al Ándalus; la Bestia, antiguo símbolo del Imperio Romano, encarna ahora al invasor islámico que amenazaba con destruir la cristiandad occidental y que en esa época atribulaba con sus frecuentes razzias a los territorios del Reino de Asturias.

En el prólogo al segundo libro de esta obra se encuentra uno de los "Mapa Mundi" más conocidos de la cultura altomedieval europea. El objetivo de este mapa no es la representación geográfica del mundo sino el de servir como ilustración de la diáspora evangelizadora de los Apóstoles durante las primeras décadas del cristianismo. Beato se basó para confeccionarlo en los datos proporcionados por San Isidoro de Sevilla, Ptolomeo y las Sagradas Escrituras. El mundo se representa como un disco de tierra rodeado por el Océano y que se divide en tres partes: Asia (semicírculo superior), Europa (cuadrante inferior izquierdo) y África (cuadrante inferior derecho). El Mar Mediterráneo (Europa–África), el Río Nilo (África–Asia) y el Mar Egeo y el Bósforo (Europa–Asia) separaban a las masas continentales.
El Mapa Mundi de Beato de Liébana es la primera obra cartográfica que muestra la existencia de la "Terra Australis". A pesar de que esta tierra hipotética ya había aparecido citada en las obras de Claudio Ptolomeo o San Agustín de Hipona, lo cierto es que el mapa contenido en los "Comentarios al Apocalipsis", es el primero que refleja la existencia de este continente austral, que a partir de este momento aparecerá repetidamente multitud de mapas y originará innumerables expediciones en su búsqueda, como las de Fernández de Quirós y Abel Tasman, que culminarán en el descubrimiento de Australia. Beato estaba convencido de la llegada inminente llegada del Fin de los Tiempos, que vendrían precedidos por el reinado del Anticristo, cuyo imperio duraría 1290 años. Basándose en el esquema expuesto por San Agustín en su obra la Ciudad de Dios, el creador de los "Comentarios" consideraba que la historia del mundo se estructuraba en seis edades: Las cinco primeras se extendían entre la creación de Adán y la crucifixión Jesucristo, mientras que la sexta, posterior a Cristo y contemporánea a nosotros, debía culminar con el desencadenamiento de los sucesos profetizados por el Apocalipsis.

Los movimientos de carácter milenarista eran comunes en la Europa de entonces: En el periodo 760–780 se producen en las Galias toda una serie de fenómenos astrales que provocan pánico entre la población; un monje visionario, Juan, predice la llegada del Fin del Mundo en el reinado de Carlomagno. Aparece en estas mismas fechas el Apocalipsis de Daniel, un texto escrito en lengua siríaca durante el reinado de la emperatriz Irene en Bizancio en el que se profetizaban toda una serie de guerras entre árabes, bizantinos y pueblos del Norte que finalizarían con la llegada del Anticristo.

Para Beato, los acontecimientos que estaban teniendo lugar en Hispania (el dominio islámico, la herejía adopcionista, la progresiva asimilación de los mozárabes...) eran señales que indicaban la proximidad del eón apocalíptico. Según cuenta Elipando en su "Carta de los obispos de Spania a sus hermanos de la Galia", el abad de Santo Toribio llegó a anunciar a sus paisanos de la Liébana la llegada del Fin del Mundo para la pascua del año 800: la víspera de ese día, cientos de aldeanos se agruparon en torno al Monasterio de Santo Toribio, esperando —aterrados— el prodigio. Durante casi día y medio permanecieron en aquel lugar sin probar bocado hasta que uno de ellos, de nombre Ordoño, exclamó: «¡Comamos y bebamos, de manera que si llega el fin del mundo estemos hartos!».

Las visiones proféticas y milenaristas de Beato de Liébana tuvieron una huella perdurable en el desarrollo del Reino de Asturias: La Crónica Profética, que fue redactada en torno al año 880, predice la caída final del Emirato de Córdoba y la conquista y redención de toda España por el rey Alfonso III. Asimismo, el icono de la Cruz de la Victoria, que terminó convirtiéndose el emblema del Reino de Asturias, tiene su origen en un pasaje del Apocalipsis en el que San Juan tiene la siguiente visión de la Parusía: Ve a Jesucristo sentado en majestad compañado de nubes y afirmando «Yo soy el Alfa y la Omega, el principio y el fin, el que Fue, el que Es y el que Será. El Todopoderoso». El uso del lábaro se remonta a tiempos de Constantino el Grande, que lo empleó durante la célebre batalla del Puente Milvio. Pero en Asturias, el uso de la Cruz de la Victoria adquirió tintes de veneración. En casi todas las iglesias prerrománicas aparece grabado dicho icono, a menudo acompañado de la expresión «"Hoc signo tuetur pius, in hoc signo vincitur inimicus"», que se convirtió en el lema de los monarcas asturianos.

Otro de los legados espirituales del Reino de Asturias lo constituye el surgimiento de una de las vías de transmisión cultural más fascinante de Europa: El Camino de Santiago. El primer texto que hace referencia a la predicación de Santiago el Mayor es el "Breviario de los Apóstoles", texto del siglo VI que cita a un lugar denominado "Aca Marmárica" como su lugar de descanso definitivo. San Isidoro de Sevilla insistió en esta idea en su tratado "De ortu et obitu patrium". Siglo y medio después, en tiempos del rey Mauregato fue compuesto el himno "O Dei Verbum" en el que se califica al apóstol de «áurea cabeza de España, nuestro protector y patrono nacional», y se hace referencia a su predicación en la Península durante las primeras décadas del cristianismo. Algunos atribuyen dicho himno a Beato, aunque esto es discutido por los historiadores.

Pero no fue hasta el reinado de Alfonso II cuando desde Galicia llegaron noticias de un acontecimiento prodigioso: En la diócesis de Iria Flavia un ermitaño llamado Pelayo había observado durante varias noches sucesivas resplandores misteriosos sobre el bosque de Libredón. Canciones de ángeles acompañaban el baile de luminarias. Impresionado por este fenómeno, Pelayo se presentó ante el obispo de Iria Flavia, Teodomiro, que acudió al lugar con su séquito. En la espesura del bosque se halló un sepulcro de piedra con tres cuerpos, que fueron identificados con los del apóstol Santiago el Mayor y sus dos discípulos, Teodoro y Atanasio. Según la leyenda, el rey Alfonso fue el primer peregrino en acudir a ver al Apóstol: Durante las noches que duró el trayecto fue guiado por el curso de la Vía Láctea, que a partir de ese momento tomaría el nombre popular de "Camino de Santiago".

El hallazgo de la tumba de Santiago supuso un éxito político de primer orden para el Reino de Asturias: Hispania podía reclamar para sí el honor de albergar los restos de uno de los apóstoles de Jesucristo, un galardón solo compartido con Asia (concretamente Éfeso) donde reposaba el cuerpo de San Juan, y con Roma, donde fueron enterrados los restos de San Pedro y San Pablo. A partir de este momento, Santiago de Compostela se convertiría junto con Roma y Jerusalén en una de las tres ciudades santas de la Cristiandad. Al abrigo del Camino de Santiago penetraron en la península ibérica multitud de influencias procedentes de Centroeuropa durante los siglos siguientes, desde los estilos gótico y románico hasta la trova provenzal.

Sin embargo, la historia del "descubrimiento" de los restos del Apóstol presenta ciertos trazos enigmáticos. La tumba fue encontrada en un lugar que venía siendo usado como necrópolis desde el Bajo Imperio, por lo que es posible que se tratara de los restos de un notable de la zona: El historiador británico Henry Chadwick lanzó la hipótesis que identificaba el sarcófago hallado en Compostela con las reliquias de Prisciliano. Otros autores, como Constantino Cabal, ponen de relieve que muchos lugares de Galicia como el Pico Sacro, la Pedra da Barca (Muxía) o San Andrés de Teixido eran objetivo de peregrinaciones de fieles paganos, que consideraban que aquellos lugares, identificados con el Fin del Mundo, eran puertas de entrada al Otro Mundo. Con el descubrimiento de la tumba de Santiago se inició la progresiva cristianización de estas rutas de peregrinación.

Puesto que las Crónicas del Reino de Asturias fueron redactadas siglo y medio después de la batalla de Covadonga, son muchas las facetas de los primeros reyes de Asturias que han quedado en la penumbra, abandonadas al nebuloso territorio del mito y de la leyenda.

Si bien la historicidad de Pelayo queda fuera de toda duda, en torno a su figura se han tejido multitud de tradiciones y relatos. Uno de ellos afirma que antes de la invasión islámica de España acudió de peregrino a Jerusalén, la ciudad santa de la Cristiandad.

Se afirma así mismo, que la Cruz de la Victoria fue formada por un rayo que al golpear un roble talló dicha figura en su tronco. Se entrelazan en este mito dos elementos de importancia fundamental en la tradición asturiana: Por un lado, el "rayo", que era el símbolo de del antiguo dios astur Taranis y que en la mitología asturiana es forjado por el Ñuberu, señor de las nubes, de la lluvia y de los vientos. Por otro lado, el "roble" es el símbolo de la realeza asturiana, tal y como testimonian grabados en piedra como los de la Iglesia de Abamia, en los que se reproducen hojas de dicha especie arbórea.

Además, la zona de Covadonga ha sido pródiga en relatos asombrosos, como el que afirma que sobre el lugar que hoy ocupan los lagos de Enol y de la Ercina se alzaba un poblado de pastores que fue visitado en su día por la Virgen, la cual disfrazada de peregrina pidió comida y habitación por las casas del poblado. En todas ellas fue rechazada bruscamente, y solo encontró acogida en el humilde refugio de un pastor, que cariñosamente compartió con ella todo lo que poseía. Como castigo ante la inhospitalidad de los moradores del lugar, el día siguiente un diluvio de origen divino arrasó con la población, que quedó anegada para siempre, con excepción de la choza del pastor. Ante él, la misteriosa huésped comenzó a llorar, y sus lágrimas al caer al suelo se convirtieron en deliciosas florecillas. Entonces el pastor se dio cuenta de que la divina peregrina era la Virgen.

Es este un mito pancéltico que se encuentra representado en numerosas historias de otros países del Arco Atlántico, como aquella que afirma que bajo la laguna de Antela (Galicia) se hallan los rastros de la antigua ciudad de Antioquía, borrada en su día del mapa por un diluvio nocturno en castigo por la vida pecaminosa de sus habitantes. Todavía hoy es posible oír durante la Noche de San Juan los tañidos de la iglesia de la ciudad así como el cantar de los gallos. Al otro lado del golfo de Vizcaya, en Bretaña, circulan tradiciones relativas a la ciudad de Ker-Ys, que se situaba en territorios de la bahía de Douarnenez ganados al mar y protegidos por un poderoso dique. La hija del rey de la ciudad, Dahud, entregó las llaves del dique a un demonio que se había disfrazado de un apuesto príncipe, acción que resultó en el anegamiento de la ciudad.

Mas también existen mitos en torno a la Monarquía Asturiana que enlazan con la más pura tradición judía y cristiana: la Crónica Sebastianense narra que cuando falleció el rey Alfonso I tuvo lugar en Cangas de Onís un suceso extraordinario. Mientras los notables velaban su cadáver en la corte, se oyeron cánticos celestiales de ángeles. Entonaban el siguiente texto de Isaías que por lo demás era el empleado por la liturgia hispánica durante la Vigilia del Sábado de Gloria:

Se trata del cántico que entonó el rey de Judá Ezequías tras su curación de una enfermedad mortal por Yahvé, gracias a la intercesión de Isaías: En dicho cántico, el rey, viéndose ante las puertas de la muerte, lamenta angustiado su partida hacia el sheol, el inframundo judío, un lugar oscuro y tenebroso donde no verá ya más a ni a Dios ni los hombres.

En Asturias se encuentran asimismo exponentes del mito del Rey Durmiente: Según la leyenda, es posible aún hoy en día ver vagar al rey Fruela por el Jardín de los Reyes Caudillos de la Catedral de Oviedo y se dice que su nieto, el renombrado caballero Bernardo del Carpio, duerme también en una cueva de los montes asturianos. La tradición relata que en una ocasión un campesino perdió una de sus vacas, y cuando se internó en una cueva para buscarla oyó una voz que afirmaba ser Bernardo del Carpio, vencedor sobre los francos en Roncesvalles. Tras contarle que había vivido solitariamente durante siglos en aquella cueva le dijo al campesino: «Dame tu mano, que quiero saber cómo son los hombres de ahora». El pastor, asustado, le alcanzó el cuerno de una vaca, que al ser agarrado por el gigante se deshizo al instante. El pastor se marchó despavorido, no sin antes oír a Bernardo decir: «Los hombres de ahora no son como los que me ayudaron a matar franceses en Roncesvalles».

Son evidentes los paralelismos entre estas leyendas y las que rodean las figuras de otros héroes medievales europeos como Barbarroja o el Rey Arturo. Del primero se afirma que no murió, sino que se retiró al interior del monte Kyffhäuser, desde donde retornará para restablecer la antigua gloria de Alemania cuando los cuervos dejen de volar. Del segundo se afirma que vive junto con sus caballeros en multitud de grutas y colinas de la isla de Gran Bretaña. Su morada más famosa es aquella que le atribuyó Sir Walter Scott: las colinas de Eildon, en Escocia, donde se refugió Arturo tras su última batalla, y donde dormirá hasta que el destino le otorgue de nuevo el gobierno de Britania.

Crónicas redactadas en territorio andalusí:


Crónicas redactadas durante el reinado de Alfonso III:


Crónicas del siglo XI:


Crónicas del siglo XII:


Crónicas redactadas durante el reinado de Fernando III del Santo:


Crónicas redactadas durante el reinado de Alfonso X el Sabio:



El Reino de Asturias se contempla tradicionalmente como el origen de la Reconquista. Si bien en los primeros momentos fue solo una lucha indígena contra pueblos extranjeros (como ástures y cántabros ya habían hecho contra romanos y visigodos), la espectacular expansión posterior y el hecho de haber contenido el germen de la conocida como Corona de Castilla (unión de los reinos de Castilla y León) supusieron una relevancia histórica que en la época no cabía vislumbrar.

Desde el reino de Asturias se crearon los condados de Castilla y de Portugal, que en tiempos del Reino de León cobrarían su independencia y se convertirían en reinos: tras el traslado de la corte a León por Fruela II, el centro de gravedad del Reino se desplazó hacia el Sur, y a partir de ese momento es cuando comienza a hablarse del Reino de León, cuyos monarcas se consideran herederos de la Monarquía asturiana. Si bien en sus primeras décadas de existencia, la autoridad de los reyes asturleoneses era bastante fuerte, a partir de mediados del siglo X, surgieron tendencias disgregadoras, particularmente en Castilla y en Portugal.

Los condados castellanos se aglutinaron a mediados del siglo IX en torno a la dinastía condal fundada por Fernán González. Si bien en sus comienzos el condado de Castilla no llegó a independizarse formalmente nunca del Reino de León, pronto entró en la órbita del rey Sancho Garcés III de Pamplona, "el Mayor" , que acabó definitivamente con la dependencia jurídica respecto de los reyes leoneses. Su hijo, Fernando I, heredó el condado de Castilla y tras derrotara Bermudo III de León anexionó su reino. Tras la muerte de Alfonso VII, los reinos de León y Castilla volvieron a separarse durante setenta años, hasta que fueron unificados definitivamente por Fernando el Santo. El recuerdo de la monarquía asturiana pervivió en las cortes de los reyes de Castilla y de España. Alfonso X el Sabio, en su Estoria de España, consideraba al Reino de Asturias como el lugar donde comenzó la reconquista y recristianización de España. Siglos después, el primer parque nacional de España, el de la "Montaña de Covadonga" (hoy en día, "Parque nacional de los Picos de Europa)", fue fundado por Alfonso XIII en 1918 para conmemorar el 1200 aniversario de la coronación Pelayo, y de la batalla de Covadonga. En Ultramar, la leyenda pía afirma que Santiago Matamoros, el protector del reino asturiano, se apareció en la batalla de Otumba, desequilibrando el combate a favor de los españoles. Muchas ciudades americanas, como Santiago de Cuba o Santiago de Chile, llevan el nombre de aquel apóstol cuyo cadáver se encontró en tiempos de Alfonso II, en un lugar situado en los confines de la monarquía asturiana.

Por lo que se refiere a Portugal, fue Alfonso III de Asturias el que ordenó en 868 a uno de sus vasallos, el conde gallego Vimara Pérez, tomar y repoblar la ciudad de Oporto y los territorios portucalenses entre el Miño y el Duero (fue el fundador de la ciudad de Guimarães. De este modo, al mismo tiempo que nacía en el centro hispánico el Condado de Castilla vasallo de los reyes asturleoneses y navarros, surgió en la frontera suroccidental asturiana el Condado Portucalense, que también se mantuvo vasallo de los reyes de Asturias y León durante los siglos IX a XII. Simultáneamente nacía en la punta suroriental peninsular el condado de Aragón, inicialmente vasallo de los reyes francos. Durante el siglo XI los condados de Castilla y de Aragón fueron elevados a reinos, lo mismo pasó en el siglo XII con el condado de Portugal. Desde su fundación por el noble Vimara Pérez y su repoblación por gallegos en el siglo IX, el condado de Portocale había sido un territorio autónomo dentro del Reino de Galicia. En 1071 el conde de Portucale Nuño Méndez (quien se había rebelado) fue derrotado en la batalla de Pedroso por el rey García de Galicia, que tomó el título de rey de Galícia y Portugal, uniendo efímeramente a todos los galáico-portugueses. Pero unos meses más tarde García I de Galicia y Portugal, hijo de Fernando I de León, quedó prisionero hasta el fin de sus días después de haber sido derrotado por sus dos hermanos, Sancho II de Castilla y Alfonso VI de León. Aunque a la muerte de Sancho de Castilla García recuperó su trono en 1072, siendo llamado a conversaciones por Alfonso de León (ya rey de Castilla también por la muerte de Sancho en 1073), fue traicionado por este y hecho prisionero definitivamente, en el castillo de Luna, hasta su muerte en 1090. 

Alfonso VI de León, Castilla y ahora también Galicia y Portugal, reunidas las cuatro coronas de sus cuatro abuelos, apartados sus dos hermanos del poder, se intitula entonces Imperator totius Hispaniae, al ser el mayor poder político cristiano en Hispania. Poco después separó de nuevo Galícia y Portugal al entregar el gobierno de ellos a sus dos yernos, Raimundo de Borgoña, y Enrique de Borgoña. Este último gobernó como regente de Portugal hasta su muerte, por minoría de edad de la condesa propietaria de Portugal, Teresa de León, que empezó a gobernar por sí misma solamente cuando quedó viuda. Teresa era descendiente por vía paterna de los antiguos condes portucalenses, ya que su bisabuela Elvira Menéndez era condesa de Portugal y mujer de Alfonso V de León. Tanto el conde Enrique como después la reina Teresa encaminarán el condado de Portugal a un nuevo proceso de independencia gradual que culminaría con la autoproclamación de su hijo el infante Alfonso I de Portugal como rey tras la batalla de Ourique en 1139, en la que legendariamente—por cierto—le apareció en el cielo la cruz, la sangre, y el rostro de Jesús Cristo, acompañadas de las palabras en oro «"in hoc signo vinces"». Esta leyenda está documentada solo desde el siglo XIV, época de la fundación de la Orden de Cristo, que tomó para sí misma estas palabras alrededor de su escudo rojo y cruciforme.

En el plano estrictamente asturiano, el Reino de Asturias es el lugar del nacimiento del asturiano, bable o asturleonés, lengua también hablada en el Reino de León. Ya en textos tan tempranos como la Pizarra de Carrio pueden distinguirse rasgos que van pergeñando un dialecto protorromance asturleonés, como por ejemplo la diptongación de la "e" breve latina ("vostras" -> "vuestras") o la palatalización del grupo "c'l" ("ovecula" -> "oveya"). Si bien los documentos de la época del Reino de Asturias están redactados en casi su totalidad en lengua latina, no cabe la menor duda de que en la corte se empleaba como idioma habitual una forma primigenia del asturiano. En este sentido, los primeros documentos oficiales escritos en asturleonés comienzan a aparecer en el siglo XI y entre ellos destacan el Forum Iudicium ("Fueru Xulgu") y diferentes derechos municipales. En el primer parlamento de la historia de Europa, las Cortes de León de 1188, la lengua empleada tanto por el rey como por los procuradores fue la asturleonesa. Este idioma gozaba entonces de un enorme prestigio que venía derivado de su uso por los reyes de León, sucesores de Pelayo. Es de destacar el hecho de que en Portugal para designar a sus propios monarcas se empleaba usualmente el título "El-Rei", que como puede apreciarse no es galaicoportugués (en cuyo caso correspondería una forma tipo "O-Rei") sino asturleonés.
Siglos después del reinado de los últimos monarcas asturianos, en 1388, se creó el Principado de Asturias y el título de Príncipe de Asturias que desde entonces ostentaría el heredero de los reinos de la Corona de Castilla y, posteriormente, de la de España.

El territorio del Principado quedó constituido por las Asturias de Oviedo. Las Asturias de Santillana, que mantenían ese nombre desde el siglo XII, pasaron a formar la merindad denominada a partir del siglo XV "Montaña de Burgos" y desde 1778 Provincia de Cantabria. Tras el paso de Ribadedeva, Peñamellera Alta y Peñamellera Baja en 1833 a la nueva provincia de Oviedo, a ésta se la denominó provincia de Santander y desde 1982 constituye la comunidad autónoma de Cantabria.

Tras mantenerse el principado como ente territorial durante todo el Antiguo Régimen, la división territorial de 1833 formó la Provincia de Oviedo, que incluía los concejos de las antiguas Asturias de Oviedo a los que se añadieron Ribadedeva, Peñamellera Alta y Peñamellera Baja de las antiguas Asturias de Santillana. En 1983, la provincia de Oviedo cambió su nombre a provincia de Asturias, siendo la única provincia de la comunidad autónoma del Principado de Asturias.

La bandera y el escudo del actual Principado de Asturias incluyen la imagen de la Cruz de la Victoria.


</doc>
<doc id="41339" url="https://es.wikipedia.org/wiki?curid=41339" title="Reino de León">
Reino de León

El reino de León (, asturleonés: "reinu de Llión", , ) fue un reino medieval independiente situado en la región noroeste de la península ibérica. Fue fundado en el año 910 cuando los príncipes cristianos del reino de Asturias, en la costa norte de la península, trasladaron su capital desde Oviedo a la ciudad de León. Tuvo un papel protagonista en la Reconquista y en la formación de los sucesivos reinos cristianos del occidente peninsular. El condado de Portugal se separó para convertirse en el independiente reino de Portugal en 1139 y el este, parte interior de León, se unió al reino de Castilla en 1230.

Desde 1296 a 1301, el reino de León volvió a ser independiente y después de la nueva unión con Castilla permaneció como parte de la Corona de Castilla hasta 1833. En el Real Decreto del 30 de noviembre de 1833, el reino de León fue considerado una de las regiones españolas —región de León—, dividida en las provincias de León, Zamora y Salamanca. En 1981, esas tres provincias se incluyeron junto con las seis provincias de la región histórica de Castilla la Vieja para crear la comunidad autónoma de Castilla y León. Sin embargo, importantes partes del antiguo reino integran hoy esas tres provincias y las comunidades autónomas de Extremadura, Galicia y Asturias.

El reino de León se enmarcaba en el noroeste de la península ibérica; en su máxima extensión abarcaba el norte de Portugal, las actuales comunidades autónomas de Galicia, Principado de Asturias, Cantabria, las provincias de León, Zamora y gran parte de la provincia de Salamanca, Castilla la vieja, la actual provincia de Cáceres, la de Badajoz y el norte de Huelva.

Los primeros años de existencia del territorio cristiano aparecen envueltos en la oscuridad, debido a la parquedad de las fuentes que apenas descubren alguno de los interrogantes que surgen de los primeros años del reino de Asturias y su lucha por la supervivencia. Tras la conquista de la península por los ejércitos ismaelitas en el 711, aparecen focos de resistencia localizados en la zona cantábrica y en la figura de Don Pelayo. Pelayo, refugiado en el monte de Auseba, acaudillará los hostigamientos a las tropas árabes que supondrán el comienzo de la resistencia cristiana. Pero realmente será Alfonso I de Asturias (737-757), yerno de Pelayo, quien en un intento de organizar los territorios, funde la monarquía como tal, extendiendo el reino hasta la Cordillera Cantábrica. En tiempos de Alfonso II (791-842) se instala la capital en Oviedo, y es en esta época cuando se descubre el Santo Sepulcro. Ordoño I, en el año 856, repuebla y reconstruye las murallas de ciudad de León y Astorga. Alfonso III "el Magno" (866-910) será quien traslade la frontera hasta el Duero, repoblando Zamora, siendo el suyo, uno de los grandes reinados de la dinastía astur.

La ciudad de León se convertiría en un punto estratégico en el reino debido a su historia, su potente fortifiación romana, así como un centro neurálgico del territorio astur, cuya capital se había encontrado veinte kilómetros al sur, en la ciudad de Lancia.

Tras la muerte de Alfonso III "el Magno", el reino de Asturias se divide y queda repartido entre sus hijos:


Al morir García I en 914 sin descendientes, Ordoño II se trasladó a León donde fue aclamado rey, lo que supone que Galicia y León compartan el mismo monarca, y el que trasladaría definitivamente la capital del reino de Asturias desde Oviedo a León. Con lo que se creará un nuevo reino, el de León, que aglutinará al asturiano, ya que Fruela II permaneció en Asturias, pero reconociendo la primacía del reino leonés.

En el marco de las luchas entre Alfonso IV y su hermano Sancho Ordóñez, el reino de Galicia y el de León dejan de compartir rey, ya que Sancho se refugia en Galicia huyendo de su hermano en 926, coronándose como rey de Galicia y manteniendo el reino independiente hasta su muerte en el año 929. A su muerte, el gobierno de ambos reinos recae en la persona de Alfonso IV.

Uno de esos levantamientos conduciría a la coronación en Galicia de Bermudo II de León (982). El nuevo rey derrotaría a Ramiro III de León y acabaría unificando de nuevo ambos territorios.

Con la formación del nuevo reino continuará la reconquista contra los musulmanes e incluso la lucha contra otros reinos cristianos como el de Navarra.

El reino de León se expande hacia el Duero y el sistema Central hasta la actual Extremadura y logra hitos como la dotación de fueros de Alfonso V, la creación de un arte de repoblación leonés y un gran desarrollo de los sistemas administrativos.

En el siglo XI, Sancho III "El Mayor" de Navarra adquiere el condado de Castilla como herencia. En 1035 deja dicho condado a su hijo Fernando. Fernando I estaba casado con Sancha, hermana, a su vez, de Bermudo III de León. Fernando provoca una guerra en la que muere el soberano leonés en la batalla de Tamarón contra la coalición castellano-navarra. Al no tener descendencia Bermudo III, su cuñado (Fernando I) se apropia de la corona leonesa esgrimiendo los derechos de su mujer, tomando el título de rey de León con gran oposición entre los leoneses, que no quieren ver convertido en monarca al hombre que ha matado a su rey. Así, Fernando vuelve a unir el condado de Castilla al reino de León.
A la muerte de Fernando I en 1065, su testamento sigue la tradición navarra de dividir los reinos entre los herederos:

Sancho II de Castilla, no conforme con el reparto, pues su hermano menor obtiene el reino más importante, comienza una guerra. Junto con Alfonso VI conquista Galicia. Sancho no contento con Castilla y media Galicia, ataca a su hermano y ocupa León con la ayuda de El Cid. Gracias a Urraca, en Zamora se refugia el grueso del ejército leonés, al que Sancho pone cerco; será el famoso cerco de Zamora, donde el rey castellano es muerto por el noble leonés Vellido Dolfos, retirándose las tropas castellanas. De este modo, Alfonso VI recupera todo el territorio, gobernando como rey de León, Castilla y Galicia.

En el reinado de Alfonso VI se consolida el poder del monarca leonés sobre Castilla, siendo reconocido «Emperador de los Reinos Hispanos» por el papa Gregorio VII. Además, con Alfonso VI se produce un acercamiento al resto de reino europeos, especialmente a Francia, pues casa a su hija Urraca con Raimundo de Borgoña (1090) y más tarde a Teresa con Enrique de Borgoña (1095). En el concilio celebrado en Burgos en el 1080 se sustituye el rito mozárabe, usado hasta entonces en León, por el romano.
En la época de Alfonso VII "El Emperador" (1126-1157), reyes de toda la península ibérica y sur de Francia se declaran sus vasallos. Pero tras una etapa de esplendor imperial la unidad se desvanece, desapareciendo también el título de emperador de León.

Ya bajo Alfonso VII, Portugal se independiza de León, creando un reino gobernado por la hija de Alfonso VI, Teresa, casada con Enrique de Borgoña, y se recrudecen las luchas fronterizas con Castilla, y a su muerte, el hijo de Alfonso, Fernando II, hereda el reino de León, y Sancho III, el de Castilla.

Su sucesor, Alfonso IX, se convierte en uno de los más afamados monarcas del reino de León. Bajo su mandato se convocan las Cortes Leonesas de 1188, primeras cortes europeas en las que participa el tercer estado. En ellas se reconoce la inviolabilidad del domicilio, del correo, la necesidad del rey de convocar Cortes para hacer la guerra o declarar la paz, y se garantizan numerosos derechos individuales y colectivos. A estas Cortes le seguirán las de Benavente (1202), en las que se fijarán los principios y derechos económicos de la Corona de León y sus habitantes, y otras nuevas en León un lustro después. En las Cortes de Benavente de 1202 se referencia que la Corona de León está compuesta por cuatro entidades territoriales: León, Galicia, Asturias y Extremadura.

Con Alfonso IX el reino se extiende por Extremadura, logrando una gran expansión territorial. El s. XIII va a ser un periodo en que los reinos peninsulares viven un auge de los sentimientos nacionalistas. La expansión territorial de los reinos de Portugal y Castilla, que amenazaban con cerrar la salida al sur del reino de León y la pretensión de los reyes de Castilla de anexionarse el reino provocó constantes conflictos bélicos entre los reinos de León, Portugal y Castilla. Estas guerras tenían como aliados ocasionales a los reinos de taifas, que participaban alternativamente del lado de cualquiera de los reinos cristianos. Consecuencia directa de ello será que el reino de León no participe en la batalla de Las Navas de Tolosa, llegando por ello a ser excomulgado el soberano leonés por el papa. A su muerte, el rey ordena mantener la independencia de León, declarando herederas a sus hijas, y garantes de la misma a las órdenes de caballería. Sin embargo, Fernando III de Castilla, contraviniendo el testamento de su padre, logra que las jóvenes herederas del reino de León le cedan su trono, por lo que el reino de León pasa a ser anexionado por Castilla para formar la Corona de Castilla en 1230. Como dato adicional, Alfonso IX también creó el Estudio General que en tiempos de Alfonso X de Castilla se convertiría en la actual Universidad de Salamanca.

Las ciudades comienzan a desarrollarse cerca de fortalezas, monasterios o en las antiguas "civitates" romanas. Algunas de estas ciudades son potenciadas por el camino de Santiago y comienzan a conocerse como burgos, diferenciándose de las aldeas rurales en la preponderancia de la actividad económica no ligada al cultivo de la tierra.

En la ruta del camino de Santiago surgen burgos desde Aragón hasta Galicia a partir del siglo XI. León también se beneficia del paso hacia el lugar santo. Pero otros burgos también se desarrollan al margen del camino francés, en las orilla del Duero, como Zamora o Valladolid, esta última alcanza un gran desarrollo tras la llegada del conde Pedro Ansúrez a finales del siglo XI.

Sobre León, el geógrafo y viajero árabe Al-Idrisi escribe en el siglo XII: 

Al sur del río Duero, en las entonces conocidas tierras Extremaduras, el nacimiento de ciudades era con un objetivo defensivo, pero con el paso del tiempo se comenzó también a desarrollar una actividad económica y comercial de importancia similar a las ciudades del norte del Duero.

Aparecen los burgueses, que son los habitantes de los burgos (no confundir con la acepción actual del término burgués), que se añaden a clérigos y nobles. Los burgueses se dedicaban principalmente al comercio y la producción de objetos manufacturados y su crecimiento se encontraba limitado en lo económico y social por la nobleza (principalmente dedicada a la tierra), por esta razón en el siglo XII hay revueltas burguesas contra las autoridades señoriales. De estas revueltas, los habitantes de los burgos consiguen ciertas reivindicaciones.

También merece acepción la llegada de comunidades judaicas durante los siglos XI y XII por la intransigencia almorávide en al-Ándalus, quienes comienzan como artesanos, mercaderes y agricultores principalmente.

En el siglo XII Europa contemplará un gran avance en el terreno intelectual gracias a León y a Castilla. A través del Islam, se recuperarán obras clásicas anteriormente olvidadas en Europa y se pondrá en contacto con la sabiduría de los científicos musulmanes.

El Camino de Santiago no hará sino potenciar el intercambio de saber entre los reinos de Castilla, León y Europa, en ambos sentidos.

En el siglo XII también aparecerán múltiples órdenes religiosas a semejanza de las europeas, como las de Calatrava, Alcántara y Santiago y se fundan multitud de abadías cistercienses.

La muerte de Fernando I de León, que rigió el imperio en nombre de su esposa Doña Sancha, hermana de Bermudo III, da nacimiento al reino de Castilla al cedérselo como tal a su primogénito Sancho. Tras la muerte del monarca en 1065 los reinos se dividen entre sus hijos. En una guerra civil contra sus hermanos Alfonso y García, este reúne dinásticamente por primera vez los reinos de León y de Castilla. Una segunda unión se producirá desde el 1072 con Alfonso VI hasta el 1157 a la muerte de Alfonso VII. Hacia el año 1230 con Fernando III el Santo, rey de Castilla desde 1217, los reinos de León y de Castilla quedan bajo un mismo soberano leonés que por circunstancias diversas ha sido primero Rey en Castilla.

En 1230 muere Alfonso IX de León, que había hecho donación de sus reinos a sus hijas,y tras muchas gestiones Fernando III firma un acuerdo (Concordia de Benavente) por el que sus hermanas (Sancha y Dulce) renuncian a los derechos sucesorios al reino de León, tardando más de dos años en hacerse con el control del territorio debido a la oposición del pueblo de León y de sus nobles, que cierra las puertas de las murallas de su capital al nuevo monarca. Los reyes de la Corona de Castilla (Juana I) poseían los títulos de rey de Castilla y rey de León.

Aunque los dos reinos compartiesen el mismo soberano, las Cortes de León continuaron durante mucho tiempo; incluso se legislaba por separado a cada uno de los dos reinos aunque hubiese una reunión conjunta. En 1349 Alfonso XI celebró en la ciudad de León las Cortes de este reino.

Durante mucho los reinos singulares y las ciudades conservaron sus derechos particulares (entre los cuales se hallaban el Fuero de León, el Fuero Viejo de Castilla o los diferentes fueros municipales de Castilla, Extremadura y Andalucía, los concejos de León, el fuero de Oteruelo otorgado en 1417), mientras se iba articulando un derecho territorial común en torno a las "Partidas" (h. 1265), el Ordenamiento de Alcalá (1348) que todavía mantiene al Pisuerga como raya tradicional entre León y Castilla, y las Leyes de Toro (1505).

La situación de inestabilidad creada tras la muerte en 1295 de Sancho IV y la subida al trono de su hijo Fernando IV, de nueve años de edad, sería aprovechada por distintos nobles para rebelarse contra el joven monarca. Entre ellos se encontraba el infante Juan, tío de Fernando, que reclamó sus derechos al trono y se proclamó rey de León, Galicia y Sevilla. Aunque llegó a ser coronado como tal en León en 1296, finalmente la situación interna comenzó a estabilizarse y acabó renunciando a sus derechos y jurando fidelidad a Fernando IV en 1300.

Existieron durante todo el siglo XIV varios intentos de independizar el reino de León, lográndolo de facto, aunque por un escaso tiempo, Juan de Gante a mediados del siglo XIV. Este es derrotado por Juan I y se vuelven a reunir los dos reinos en una misma corona.

El reino de León mantiene sus estructuras durante la Edad Moderna, conservando sus características de organización territorial, lo que se reflejará en la cartografía de los siglos XVI, XVII y XVIII e instituciones propias, como el Adelantamiento o Merino Mayor del reino de León, el Defensor del reino de León, etc.

La última aparición incidental del reino de León en la historia se produce entre el 1 de junio y el 25 de septiembre de 1808, cuando la Junta Patriótica de León asume la soberanía del reino de León en la Guerra de la Independencia hasta que la cede a la Junta Suprema Central en el acto de su constitución.

En 1833 se produce la definitiva (y actualmente vigente) división provincial promovida por Javier de Burgos, que elimina definitivamente anteriores divisiones territoriales. Con la creación de las provincias se incluye una adscripción de dichas provincias a regiones, sin ningún tipo de competencia administrativa o de otro tipo. Una de dichas regiones es la de León.

Este título fue adoptado desde el siglo X por los monarcas leoneses, como expresión de una idea hispánica unitaria, que implicaba la supremacía política de León frente a los demás reinos peninsulares que se estaban formando. Los reyes leoneses aspiraron a restaurar el estado hispanogodo, creyéndose herederos directos del último monarca visigodo, Don Rodrigo. Ya en la Asturias del siglo IX tuvo aceptación la idea imperial, especialmente bajo el reinado de Alfonso III, llamado "magnus imperator" o "imperator noster".

Ordoño II ("imperator legionense"), Ramiro II ("magnus basileus"), Ramiro III, Alfonso V, Bermudo III y quizá Sancho III "el Mayor" de Navarra tras heredar León y Castilla (aunque este título solo se documenta en una moneda de ejemplar único, hoy comúnmente atribuida al reinado de Alfonso VII de León), adoptaron el título de emperador.

Fernando I fue llamado "rex imperator", y Alfonso VI de León llegó a titularse "Imperator totius Hispaniae". En 1135, Alfonso VII fue coronado solemnemente emperador en León. Entre sus vasallos se contaban los reyes de Aragón, Navarra y Portugal, el conde de Barcelona y varios monarcas musulmanes, quienes a la muerte del Emperador, rechazaron la teórica supremacía política del título.

Como todo reino medieval, el poder supremo "por la gracia de Dios" recaía en el rey. Pero comienzan a surgir comunidades rurales y urbanas para tomar decisiones sobre problemas de la vida cotidiana.

Así comienzan los concejos, o "concilium", como una manera de autogobierno de núcleos de población en las que todos los vecinos tenían representación como atestigua el Concejo de Berbeja, San Zadornil y Barrio (955):
Estos concejos abiertos evolucionarán a concejos cerrados, en los que una parte de los vecinos representará al resto. Asimismo conseguirán un mayor poder como la elección de magistrados y oficiales, los alcaldes, pregoneros, escribanos...

Ante el creciente poder de los Concejos, surge la necesidad de la comunicación entre el rey y estos, y he aquí el nacimiento de las Cortes en el año 1188 en León. En las Cortes leonesas medievales, los habitantes de las ciudades eran un grupo reducido, conocidos como "laboratores" y no tenían facultades legislativas, pero era un punto de unión entre el rey y el reino, algo en lo que el reino de León había sido pionero en la Europa medieval. Las cortes estarían así constituidas por tres estamentos (clero, nobleza, representantes de las ciudades) y aparecen como un diálogo entre el rey y la curia, por un lado, y los representantes de las ciudades y villas por otro.

La UNESCO declaró en 2013 este sistema de Cortes cuna del sistema parlamentario europeo.

El reino de León produjo algunos de los textos con rasgos de una lengua protorromance más antiguos de la península ibérica: la "Nodicia de Kesos".




</doc>
<doc id="41341" url="https://es.wikipedia.org/wiki?curid=41341" title="Pico de Adán">
Pico de Adán

El Pico de Adán (en tamil, Sivanolipatha Malai - சிவனொளி பாதமலை; en idioma cingalés, Sri Pada; en árabe al-Rohun; y en inglés Adam's Peak) es una montaña cónica de 2243 metros de altitud situada en Sri Lanka, reverenciada como sitio sagrado por hinduistas, budistas y musulmanes.

Los peregrinos hindúes suben a la montaña siguiendo una variedad de rutas de miles de escalones, el ascenso dura aproximadamente entre 3 o 4 horas, y en general se realiza de noche para llegar a la cima al amanecer.

El momento cumbre de la época de peregrinación es en abril, y el objetivo es estar en la cima de la montaña al amanecer, cuando la peculiar forma de la montaña proyecta una sombra triangular sobre la planicie circundante.

En la cima de la montaña hay un santuario en honor a Buda, en el que los fieles dejan sus ofrendas, y tocan una campana según el número de veces que han subido al santuario. Además, se quema coco con el que se produce aceite, el que alimenta las velas siempre ardientes del lugar.

La reliquia sagrada del santuario es una roca con forma de huella, similar a un enorme pie (casi dos metros).
La leyenda musulmana afirma que es la huella del pie de Adán, quien fue situado en Sri Lanka (la isla de Ceilán) como el mejor sitio después del Jardín del Edén; de esto viene el nombre de Pico de Adán. Otros candidatos de otras leyendas para haber dejado esa gigantesca huella son: Shivá, Buda y santo Tomás (el apóstol).

Cerca de la huella se puede encontrar un sepulcro dedicado a Saman, una deidad budista encargada de proteger la cumbre de la montaña.

La leyenda budista dice que la huella del otro pie estaría en una ciudad que dista unos 159 kilómetros, o posiblemente en Phra Sat (Tailandia).

Ibn Battuta fue el primer autor que relató su ascensión (en el siglo XIV) y confirmó la presencia de cadenas de hierro instaladas como pasamanos y que ya habían sido descritas por el italiano Marco Polo.

Sin embargo, el punto más alto de la isla no es el Pico de Adán, sino el monte Pidurutalagala, de 2524 m.


</doc>
<doc id="41344" url="https://es.wikipedia.org/wiki?curid=41344" title="Capella">
Capella

Capella (Alfa Aurigae / α Aur / 13 Aurigae) es el nombre de la estrella más brillante de la constelación de Auriga, («El Cochero»), y la sexta más brillante del cielo.
Es la estrella de primera magnitud más cercana al Polo Norte Celeste.
Se encuentra a 42,2 años luz de distancia del Sol. 

Su nombre procede del latín "capella", «pequeña cabra», y es el origen del mito romano de la cabra Amaltea que amamantó a Zeus. También recibe los nombres árabes de Alhajoth, que igualmente significa «La Cabra», y Al Rakib, «El Conductor», porque en los atardeceres y en las luces crepusculares era la primera estrella que se veía entre todas las que la rodeaban. En el antiguo acadio recibía el nombre de "Dil-gan I-ku", la «Mensajera de la Luz», así como "Dil-gan Babill", la «Estrella honorífica de Babilonia». Se han descubierto algunos templos celtas que se encontraban orientados de tal forma que recibían el primer rayo de Capella al salir esta. Los antiguos observadores le atribuyeron una coloración rojiza, del todo inexplicable.

En la mitología hindú, Capella era "Brahma Ridaya", simbolizando el corazón de Brahmā.

Aunque Capella es una estrella cuádruple, primero se reconoció su condición de estrella doble a través de estudios espectroscópicos y luego (en 1919) con interferometría. La separación visual de estas componentes, A y B, no supera los 0,05 segundos de arco, correspondiendo a una separación real de 0,73 unidades astronómicas (ua). Se mueven a lo largo de una órbita prácticamente circular con un periodo orbital de 104 días.

A 12 minutos de arco de A+B hay dos compañeras más tenues, denominadas C y D, que se encuentran a 11 000 ua (0,17 años luz) del par principal, describiendo una órbita tan enorme que todavía no se ha podido completar por medio de las observaciones; un cálculo de primera aproximación para esta órbita arroja un periodo de unos 400 años. La separación media entre C y D es de unas 48,1 ua.

El modelo que ofrece Capella puede asimilarse a dos esferas de 35 y 20 cm de diámetro separadas 3 m entre sí; a 40 km de la pareja principal se situarían dos esferitas de 2 cm, separadas entre sí 120 m.

El sistema forma parte de la corriente de las Híades.

Los dos astros principales del sistema, Capella A y Capella B, son estrellas gigantes amarillas con temperaturas superficiales similares a la del Sol; sus tamaños, sin embargo, son mucho mayores que el de este. La luz combinada de este par es la que origina, cuando se la observa a simple vista en la noche, el intenso color amarillo de Capella.
Capella A, de tipo espectral G8IIIe, tiene un radio 12,2 veces mayor que el radio solar y una masa de 2,7 masas solares. Con una luminosidad 78,5 veces mayor que la del Sol, su edad se estima en unos 525 millones de años. La baja abundancia de litio en su superficie indica que en su núcleo ha comenzado la fusión nuclear de helio en carbono. Asimismo, es una estrella variable de tipo RS Canum Venaticorum.

Capella B, de tipo espectral G1III, tiene un radio de 9 radios solares, una masa de 2,6 masas solares y una luminosidad 77,6 veces mayor que la del Sol. Su velocidad de rotación es mucho mayor que la de Capella A, por lo que su actividad cromosférica es mayor. Se piensa que está menos evolucionada que su compañera y que en su núcleo no ha comenzado aún la transformación de helio en carbono. De todos modos, ambas estrellas están ahora en el proceso de expandirse y enfriarse en su camino de transformación a gigantes rojas, lo que les tomará algunos millones de años.

Capella C y Capella D son dos enanas rojas de magnitudes 10 y 12 respectivamente. Capella C tiene tipo espectral M1V y, con un radio del 58 % del radio solar, su luminosidad es tan solo el 1,3 % de la del Sol. Capella D, de tipo M4-5V, es aún más pequeña y tenue, con una luminosidad que apenas alcanza el 0,05 % de la del Sol.




</doc>
<doc id="41350" url="https://es.wikipedia.org/wiki?curid=41350" title="Pedro III de Aragón">
Pedro III de Aragón

Pedro III de Aragón (Valencia, 1240-Villafranca del Penedés, 11 de noviembre de 1285), llamado el Grande, fue hijo de Jaime I el Conquistador y su segunda esposa Violante de Hungría. Sucedió a su padre en 1276 en los títulos de rey de Aragón, rey de Valencia y conde de Barcelona. Además, llegó a ser también rey de Sicilia. 

Casado el 13 de junio de 1262 en la catedral de Montpellier con Constanza de Hohenstaufen, hija y heredera de Manfredo I de Sicilia, fueron coronados en Zaragoza, probablemente el 17 de noviembre de 1276, en una ceremonia en la que Pedro canceló el vasallaje que con el papado había concertado su abuelo Pedro II.

Todo su reinado se centró en la expansión de la Corona de Aragón por el Mediterráneo y para ello aprovechó su matrimonio con Constanza para reivindicar la corona siciliana. Sicilia se encontraba desde 1266 bajo la soberanía de Carlos de Anjou quien, con el apoyo del papa Clemente IV, que no deseaba a ningún Hohenstaufen en el sur de Italia, había sido investido rey tras derrotar en Benevento a Manfredo, quien falleció en la batalla.

El monarca angevino hizo cegar a los tres hijos varones de Manfredo y, en 1268, capturó e hizo decapitar a Conradino que –como nieto de Federico II– era el último heredero varón de la casa Hohenstaufen. La línea sucesoria pasó entonces a Constanza, quien ofreció refugio en Aragón a las familias partidarias de su padre, los Lanza, los Lauria y los Prócidas. Desde ahí, Juan de Procida, Roger de Lauria y el resto del antiguo partido Hohenstaufen organizaron la oposición a Carlos de Anjou con Pedro como candidato con el apoyo bizantino. 

Una flota de la corona aragonesa, al mando de Conrado Lanza, recorre en 1279 las costas africanas para restablecer la soberanía feudal de Aragón sobre Túnez, que la muerte del emir Muhammad I al-Mustansir había debilitado. Posteriormente, en 1281, Pedro III armó una flota para invadir Túnez y solicitó al recién elegido papa Martín IV una bula que declarara la operación militar como cruzada, pero el papa, de origen francés y partidario de Carlos de Anjou, se la negó. 

Cuando la flota se disponía a zarpar, tuvieron lugar en Sicilia los acontecimientos conocidos como las Vísperas sicilianas que provocaron la expulsión de la isla, tras una gran matanza, de los franceses. Los sicilianos enviaron entonces una embajada a Pedro III ofreciéndole la corona siciliana, a la que tenía derecho gracias a su matrimonio. El rey aragonés puso entonces su flota rumbo a Sicilia, donde arribó el 30 de agosto de 1282 y fue coronado rey en la ciudad de Palermo.

Inmediatamente envió una embajada a Carlos de Anjou, que se encontraba en Mesina, instándole a reconocerle como rey de Sicilia y a abandonar la isla. La derrota de la flota angevina en Nicoreta, a manos del almirante Roger de Lauria, obligó a Carlos a dejar Mesina y refugiarse en su reino de Nápoles.

El papa Martín IV respondió a la coronación siciliana de Pedro III con su excomunión (9 de noviembre de 1282) y su deposición como rey de Aragón (21 de diciembre de 1283), ofreciendo la corona al segundo hijo del rey de Francia, Carlos de Valois, a quien invistió el 27 de febrero de 1284, y declarando una cruzada contra Aragón, entre 1284 y 1286, por su intervención en los asuntos sicilianos en contra de la voluntad papal. La mayor parte del conflicto se desarrolló en tierras catalanas, aunque los primeros episodios se sucedieron en la frontera navarro-aragonesa. Como respuesta, los aragoneses atacaron a los franceses en Mallorca y Occitania.

La situación en la que se encontró Pedro III era totalmente inestable, ya que no solo tenía que enfrentarse a la invasión francesa que se preparaba al norte de los Pirineos, sino que tuvo que hacer frente a graves problemas en el interior de sus reinos surgidos ante las necesidades económicas que provocó la conquista de Sicilia.

Pedro III soluciona los problemas internos concediendo, en las Cortes de Tarazona (1283-84), la formación de la Unión aragonesa y prestando juramento al Privilegio General que defendía los privilegios de la nobleza; asimismo concedió al Condado de Barcelona la constitución “Una vegada l´any” en las cortes celebradas en Barcelona entre 1283 y 1284.

Solucionados los problemas interiores, pudo centrar su atención en la invasión francesa, que al mando del propio rey francés Felipe III tomó en 1285 la ciudad de Gerona, para inmediatamente tener que retirarse cuando la flota aragonesa retornó de Sicilia al mando de Roger de Lauria e infligió a la escuadra francesa una derrota total en las islas Formigues y a continuación una derrota en tierra en el barranco de las Panizas, cuando las tropas francesas se retiraban. 

Tras su gran victoria, Pedro III se dispuso a enfrentarse a su hermano Jaime II de Mallorca y a su sobrino el rey Sancho IV de Castilla, que no le habían prestado apoyo durante su conflicto con los franceses,pero su prematura muerte lo impidió. A finales de octubre de 1285, el rey enfermó cuando se disponía a emprender viaje a Barcelona y tuvo que detenerse en la localidad de San Climent donde los médicos, que viajaron desde la capital para atenderle, no pudieron hacer nada para salvarle. Falleció el 11 de noviembre de 1285 en la festividad de san Martín. Los estudios forenses de sus restos, exhumados en 2010, indican que probablemente su deceso se debió a una afección pulmonar.

En su testamento, Pedro III dispuso que su cadáver recibiera sepultura en el Monasterio de Santes Creus, de la orden cisterciense. Las exequias del monarca se celebraron con gran solemnidad y el cuerpo del rey fue colocado en una urna de pórfido rojo, que el almirante Roger de Lauria trajo desde Sicilia. Él fue el primer monarca aragonés en recibir sepultura en el Monasterio de Santes Creus.

El rey Jaime II de Aragón, ordenó la erección de las tumbas del rey Pedro III el Grande, su padre, al mismo tiempo que disponía la creación de su propia tumba y la de su segunda esposa, Blanca de Nápoles. Se dispuso que los sepulcros se hallaran cobijados, como así se hizo, bajo baldaquinos labrados en mármol blanco procedente de las canteras de San Felíu, cerca de Gerona. Cuando el rey Jaime II dispuso la creación de su propio sepulcro, tomó como modelo el sepulcro de su padre.

El sepulcro del rey Pedro III fue realizado entre los años 1291 y 1307 por Bartomeu de Gerona y es más rico que el de su hijo Jaime II y su esposa. Un gran templete de caladas tracerías alberga el sepulcro del rey, consistente en una urna de pórfido rojo, antes una pila de baño romana, traída a España por el almirante Roger de Lauria. La urna de pórfido se encuentra rodeada por imágenes de santos.

El epitafio del rey Pedro III, colocado enfrente del mausoleo, en el pilar que separa el presbiterio de la capilla lateral del crucero, reza la siguiente inscripción:

En diciembre de 1835, durante la Primera Guerra Carlista, tropas gubernamentales integradas por la Legión Extranjera Francesa (procedente de Argelia) y varias compañías de migueletes se alojaron en el edificio monacal, causando numerosos destrozos en el mismo. Las tumbas reales de Jaime II y su esposa fueron profanadas. Los restos de Jaime II, hijo de Pedro III, fueron quemados, aunque parece que algunos restos permanecieron en el sepulcro. La momia de la reina Blanca de Nápoles fue arrojada a un pozo, de donde fue sacada en 1854. El sepulcro de Pedro III, a causa de la solidez de la urna de pórfido utilizada para albergar los regios despojos, impidió que sus restos corrieran igual suerte.

En 2009 se hallaron los restos mortales del rey en su tumba de Santes Creus. Mediante una sofisticada técnica de endoscopia y una analítica de los gases contenidos en su interior, se ha podido comprobar que es la única tumba de un monarca de la Corona de Aragón que no ha sido nunca profanada.

De su matrimonio con Constanza en 1262 nacieron: 

Tuvo tres hijos naturales de su relación con María Nicolau, antes de contraer matrimonio con Constanza: 

De la relación que mantuvo alrededor de 1275-1280 con Inés Zapata, a quien le donó las villas de Llíria y Alzira en el Reino de Valencia, nacieron cuatro hijos ilegítimos: 





</doc>
<doc id="41354" url="https://es.wikipedia.org/wiki?curid=41354" title="Kut">
Kut

Kut (también conocida como Kut al-Imara y Kut El Amara) es una ciudad al este de Irak, en la ribera izquierda del río Tigris, a unos 160 km al sureste de Bagdad.

Sus coordenadas son: latitud 32º 30' N, longitud 45º 50' E.

En 2003, se estima que su población es de 400.000 personas. Es la capital de la provincia conocida desde hace mucho como "Al Kut", pero que en los años 1960 cambió de nombre a Wasit.



</doc>
<doc id="41356" url="https://es.wikipedia.org/wiki?curid=41356" title="Gobernación de Wasit">
Gobernación de Wasit

Wasit (en árabe, محافظة ديالى) es una de las dieciocho gobernaciones que conforman la república de Irak. Su capital es Kut. Ubicada al centro-este del país, limita al norte con Diala, al noreste con Irán, al sureste con Mesena, al sur con Di Car y al oeste con Cadisia y Babilonia. Hasta 1976 era conocida como la provincia de Kut. 
Su nombre proviene de la palabra árabe que significa "medio", ya que se encuentra a lo largo de la Tigris a mitad de camino entre Bagdad y Basora. Sus ciudades principales son la capital, Kut y Al-Hai. 




</doc>
<doc id="41357" url="https://es.wikipedia.org/wiki?curid=41357" title="Tigris">
Tigris

El río Tigris (; , "Diŷla") es un gran río de Asia Occidental, el más oriental de los dos grandes ríos que definen Mesopotamia, siendo el otro el río Éufrates. El río fluye hacia el sur desde las montañas del este de Turquía a través de Irak y desemboca en el Golfo Pérsico. De hecho, el nombre "Mesopotamia" quiere decir «tierra entre los ríos».

El primer nombre conocido del río en sumerio era "Idigna" o "Idigina", que puede ser interpretado como "el río rápido" o "el río que fluye", en contraste con su vecino el Éufrates, cuyo caudal más lento provocaba que se depositaran más sedimentos y construyera un lecho más alto que el Tigris. En pahlavi, "tigr" significa "flecha" (de la misma familia que el persa antiguo "tigra-", y el persa moderno "têz": "agudo"). Sin embargo, no parece que este fuera el nombre original del río, sino más bien parece que fue acuñado (de forma similar que en las lenguas semíticas) como imitación del nombre local sumerio. Es también posible que el nombre Tigris sea derivado del idioma kurdo, en el que "tij" significa "agudo", refiriéndose al Tigris como un río agudo y rápido. Dado que no existe un equivalente a la letra "j" en griego, se utilizó la letra "g", derivando posiblemente en "tig" a partir de "tij".

Otro nombre dado a este río, utilizado desde el tiempo del Imperio persa, es Arvand, que tiene el mismo significado. Actualmente, el nombre Arvand se refiere a la parte baja del Tigris en el idioma persa.

El río Tigris es conocido en la Biblia como Hidekel, que era uno de los cuatro ríos en los que se dividía la corriente de agua que procedía de Edén (Biblia Génesis 2:10-14).

El Tigris tiene una longitud de unos . Nace en los montes Tauro de Turquía oriental y fluye en general hacia el sureste. Recorre en Turquía, en la frontera con Siria y en territorio iraquí, hasta que se une al Éufrates cerca de Al Qurna en el sur de Irak. Los dos ríos forman el canal de Shatt al-Arab, que desemboca en el golfo Pérsico. A este río llegan muchos afluentes, como el río Diyala, el Gran Zab y el Pequeño Zab.

Bagdad, la capital de Irak, se halla en la orilla oeste del Tigris, mientras que la ciudad portuaria de Basora está junto al Shatt al-Arab. En la Antigüedad, muchas de las grandes ciudades de Mesopotamia se hallaban junto a alguno de los dos ríos, o al menos cerca de ellos, aprovechando sus aguas para irrigar la civilización sumeria. Entre las ciudades más importantes del Tigris se encontraban Nínive, Ctesifonte y Seleucia del Tigris, mientras que la ciudad de Lagash estaba irrigada por agua del Tigris a través de un canal construido hacia el año 2400 a. C. La ciudad natal de Sadam Husein, Tikrit, también se encuentra junto al río, y además su nombre está basado en el del propio río.

El Tigris ha sido una ruta de transporte importante durante mucho tiempo a través de un territorio mayormente desértico. Es navegable hasta Bagdad por botes de poco calado, pero se requiere de balsas para el transporte hasta Mosul. El comercio fluvial por el río ha decaído durante siglo XX debido a que las vías ferroviarias y carreteras entre Basora, Bagdad y Mosul han sustituido una gran parte del tráfico por la zona.

El Tigris es un río muy represado, tanto en Irak como en Turquía, para suministrar agua para el riego a regiones áridas o semidesérticas que bordean el río. Las presas han sido importantes para controlar las inundaciones en Irak, de las que el Tigris ha sido históricamente propenso después del deshielo en las montañas turcas en abril. Las últimas presas turcas en el río han estado sujetas a cierta controversia, tanto por los efectos medioambientales en Turquía como por su potencial para reducir el caudal aguas abajo.

Las fuerzas de la coalición dirigidas por Estados Unidos destruyeron las plantas de tratamiento de aguas durante la guerra del Golfo en 1990, afectando a la calidad de agua del Tigris.

Desde la invasión de Irak de 2003, la coalición de Estados Unidos declara que la calidad del agua del Tigris ha mejorado en Irak gracias a sus esfuerzos en la rehabilitación y expansión de las plantas de tratamiento de aguas. No existen verificaciones independientes debido a la falta de seguridad.








</doc>
<doc id="41361" url="https://es.wikipedia.org/wiki?curid=41361" title="Éufrates">
Éufrates

El río Éufrates (; , Al-Furat; ) es un gran río de Asia Occidental, el más occidental de los dos grandes ríos que definen Mesopotamia, junto con el río Tigris.

Nace en Turquía, fluye por las montañas de Anatolia hacia Siria y posteriormente a Irak. El río confluye con el Tigris para formar el Shatt al-Arab, que luego desemboca en el golfo Pérsico. Tiene una longitud de . En la Biblia es conocido como "el río"; es el río que atravesaba Babilonia y el cuarto río del Edén (Génesis 2ː10-14).

Su caudal no es abundante en relación al tamaño de su cuenca, ya que discurre por zonas áridas y desérticas donde se da un importante aprovechamiento hídrico, con multitud de presas en su curso, sobre todo en Turquía, y la irrigación en Mesopotamia que tiene más de 5000 años de historia. Esta escasez de agua en el Oriente Medio deja a Iraq con el temor permanente de que Siria y Turquía vayan a utilizar la mayor parte del agua antes de que llegue a ellos. El caudal medio es de cuando entra en Siria, pero varía entre los del periodo de estiaje y los en sus máximos fluviales que causan inundaciones.

Los nombres modernos del río Éufrates pueden haber derivado por etimología popular desde sus nombres sumerio y acadio, "Buranun" y "Pu-rat-tu" respectivamente. El primero aparece ya en una inscripción del asociado con el rey Gudea.

Etimológicamente, el nombre de «Éufrates» es la forma griega del nombre original, "Phrat", que significa «fertilización» o «fructífero». Por otra parte, la segunda mitad de la palabra «Éufrates» puede derivar también tanto del persa "Ferat" como del griego φέρω (pronunciado [fero]), significando ambos «llevar» o «presentar».

También el Avestan "hu-pərəθwa" «bueno para cruzar», ha sido propuesto como etimología del Éufrates. Deriva del proto-indoeuropeo (pIE) *"su-" «bueno» (un cognado del sánscrito "su-", griego "eu-") + *"per-" «pasar por encima» (un cognado del inglés "ferry" y "ford"). Sin embargo, esto puede a su vez haber sido derivado por etimología popular de los nombres sumerio y acadio.

El Éufrates proveyó el agua que dio lugar al primer florecimiento de la civilización en Sumeria, que data de alrededor del IVmilenio antes de Cristo. Muchas antiguas ciudades importantes se encontraban en, o cerca de la orilla del río, incluida Mari, Sippar, Nippur, Shuruppak, Uruk, Ur y Eridu.

El valle del río fue el corazón de imperios posteriores, como el de Babilonia y el de Asiria. Durante varios siglos, el río fue el límite oriental del control efectivo que realizaron tanto los egipcios como los romanos y que les separaba de las regiones occidentales del Imperio persa.

También la batalla de Kerbala se produjo en el año 680 a orillas del río Éufrates, donde el Imán Husain —junto con su familia y amigos— fue asesinado.

El río Éufrates surge de la confluencia del río Murat o "Murat Su" () y el Kara Su (). El Murat Su nace a unos al noreste del lago Van, a medio camino entre dicho lago y el monte Ararat, en tanto que el Kara Su nace a unos al noreste de Erzurum, en las montañas Kargapazari. Los cursos del Kara Su y del Murat Nehri corren bastante paralelos en dirección oeste hasta que se unen cerca de la ciudad de Keban. Ese punto de confluencia da lugar formalmente al nacimiento del río Éufrates.

La longitud del Éufrates desde la confluencia de ambos ríos hasta su desembocadura en el río Shatt al-Arab se estima en . El río fluye a través de tres países, Turquía, Siria e Irak. La longitud del Éufrates turco es de aproximadamente mientras que las partes siria e iraquí del río se estiman en y , respectivamente.

En su curso superior, el Éufrates discurre entre cañones empinados, desfiladeros y quebradas. El río entra en Siria por el antiguo lugar de Carquemis, que se encuentra exactamente en la frontera sirio-turca.

El Éufrates entra en Siria cerca de la antigua Carquemis en la frontera sirio-turca y deja el territorio sirio cerca de la moderna ciudad de Abu Kemal ( en 2008). El río fluye generalmente en dirección sureste. El Éufrates sirio tiene tres afluentes: el río Sajur, que le aborda al noreste de la moderna Manbij ( en 2009); el río Balij, cerca de la ciudad de Ar-Raqqah ( en 2008), la capital de la gobernatura homónima; y el río Khabur, de de longitud, aguas arriba de Deir ez-Zor ( en 2004), la capital de la gobernación de Dayr az-Zawr. El Éufrates ha creado un amplio y profundo valle, con excepción de la estrecha brecha cerca Halabiyeh.

Al norte de Basora, en el sur de Irak, el río se funde con el río Tigris para formar el Shatt al-Arab, que desemboca en el golfo Pérsico. Según Plinio y otros historiadores antiguos, el Éufrates originalmente tenía su desembocadura en el mar separada de la del Tigris. Algunos piensan que el limo depositado por los dos ríos habría desarrollado la región del delta en la cabeza del golfo Pérsico y que la costa original se extendería mucho más al norte, tal vez llegando hasta la antigua ciudad de Ur de los caldeos.

El río se divide en muchos canales en Basora, formando un extenso pantano, pero dichos pantanos fueron drenados en gran medida por el gobierno de Saddam Hussein en la década de 1990, como un medio para expulsar a los rebeldes árabes de los pantanos. Desde la invasión de Iraq de 2003, la política de drenaje se ha invertido, pero queda por ver si los pantanos se recuperarán.

El Éufrates es navegable solo por embarcaciones muy poco profundas, que pueden llegar hasta la ciudad iraquí de Hit, situada aguas arriba y tan solo 60msnm (metros sobre el nivel del mar). Por encima de Hit, sin embargo, los bajíos y los rápidos hacen innavegable el río comercialmente. Su inundación anual, causada por el derretimiento de la nieve en las montañas del noreste de Turquía, ha sido parcialmente controlada por la construcción de nuevas presas y embalses en las partes más altas. Un canal de enlaza el Éufrates con el Tigris sirviendo como ruta para barcazas fluviales.

El caudal del río Éufrates ha sido observado durante 43 años (entre 1924 y 1972) en Hit, una localidad iraquí situada a unos al oeste-noroeste de Bagdad. Es en Hit donde el caudal del río es mayor; de hecho aguas abajo, las muchas obras realizadas para la irrigación recogen grandes cantidades de agua de los ríos, lo que reduce su caudal gradualmente. Además, ningún afluente importante contribuye con su aportación aguas abajo.

En Hit, el caudal anual promedio o módulo observado en este período fue para una superficie drenada de .

La lámina de agua de escorrentía que fluye en esta parte de la cuenca, con mucho la más importante en términos de caudal (casi el 100% del caudal total del río), alcanzó la cifra de por año.
Al igual que con el río Tigris, existe una gran controversia sobre los derechos y el uso del río. El «Proyecto del Sudeste de Anatolia», en Turquía, implicaba la construcción de 22 presas y 19 centrales eléctricas para el año 2005, que se construirían enteramente en la región etnogeográfica, no oficial, del Kurdistán Turco, siendo el proyecto de desarrollo más grande jamás llevado a cabo por Turquía. La primera de las presas se completó en 1990, pero las protestas realizadas por distintos grupos opositores y residentes, además de los ataques del PKK, han frenado el proyecto y causado importantes retrasos . El Sudeste de Turquía aún está luchando económicamente, añadiendo leña al descontento expresado por parte de la minoría kurda de concentrarse en ella. Las autoridades turcas esperan que el proyecto impulsara económicamente la región, pero los críticos, nacionales y extranjeros, cuestionan sus beneficios, así como destacan los costos sociales y ambientales del proyecto, que ha sumergido aldeas pobladas, tierras de cultivo y sitios arqueológicos no excavados cuyo potencial cultural y significación histórica no ha sido determinada.

En Siria, la presa de Tabqa (terminada en 1973 y, a veces conocida simplemente como la presa del Éufrates) creó un embalse —el lago Assad, de — que se utiliza para regar tierras destinadas al cultivo del algodón. Siria ha represado sus dos afluentes y está en proceso de construcción de otra presa. Irak tiene siete embalses en funcionamiento, pero el control de agua perdió prioridad durante el régimen de Saddam Hussein. Desde el colapso del partido Ba'ath iraquí en 2003, el uso del agua ha adquirido de nuevo protagonismo. La escasez de agua en Oriente Medio deja a Irak con el temor constante de que Siria y Turquía utilizaran la mayor parte del agua antes de que llegue a Irak. Además, el riego en el sur de Irak deja poca agua para unirse al Tigris en el Shatt-al-Arab. El potencial para la guerra de estas aguas es tema de mucha diplomacia.

Turquía ha dispuesto numerosas presas en el río Éufrates y sus afluentes, siendo la principal la presa de Ataturk. Las principales obras hidráulicas, en dirección aguas abajo, son las siguientes:

Las principales obras hidráulicas, en dirección aguas abajo, son las siguientes:

Las principales obras hidráulicas, en dirección aguas abajo, son las siguientes:




</doc>
