<doc id="45218" url="https://es.wikipedia.org/wiki?curid=45218" title="Stuttgart">
Stuttgart

Stuttgart (; antiguamente y en desuso Estucardia en español) es la capital del estado federado alemán de Baden-Wurtemberg. Con habitantes, Stuttgart es la ciudad más grande de Baden-Wurtemberg y la . Además, es sede del parlamento de su Bundesland y su gobierno correspondiente, así como otras autoridades políticas y de la administración federal, contando también con el estatus de ciudad-distrito, unificada por un presidente. Así mismo, es sede del obispo evangélico de Wurtemberg y de un obispado católico ("Bistum Rottenburg-Stuttgart").

La ciudad constituye el centro económico y cultural del estado federado, y está marcada por la tradición de la minería y la siderurgia. Posee dos universidades, escuelas técnicas y es sede de varios institutos de investigación, como el Centro Aeroespacial Alemán (DLR), el Fraunhofer-Gesellschaft o la Sociedad Max Planck.

Stuttgart es la puerta de entrada a la Selva Negra y al Jura de Suabia, y se asienta en un valle flanqueado por montañas llenas de viñedos conocido como el “Kessel”, la caldera. El puerto se sitúa al noreste de la ciudad, a orillas del río Neckar. Las grandes ciudades alemanas más importantes y cercanas a Stuttgart son: Fráncfort del Meno (240 km al noroeste), Múnich (aproximadamente 220 km al sureste de Stuttgart) y Karlsruhe (a 80 km al noroeste).

Tradicionalmente, Stuttgart es considerada como “la ciudad donde nació el automóvil”, y acoge dos museos dedicados a su historia: el Museo Mercedes-Benz y el Museo Porsche.

Stuttgart proviene de la palabra alemana "Stutengarten" (que significa yeguada), puesto que la ciudad tiene su origen alrededor de los antiguos establos del duque Liudolf de Suabia. Su escudo tiene por eso una yegua. La marca de automóviles Porsche, originaria de esta zona, incluye este escudo en su emblema.

El distrito de Cannstatt constituye la zona de la ciudad más antigua de Stuttgart. Al siglo I d. C. se remonta una ciudadela romana, una de las posiciones más importantes en la zona, al estar situada en la orilla del Neckar y en cruce de caminos. Con la invasión de los alamanes en el 260 d. C. finalizó la presencia romana en Stuttgart. No existen tradiciones en Cannstatt de los pueblos bárbaros, que aparecieron para quedarse debido a la situación estratégica pero mantuvieron las colonias sus tradiciones.

Presumiblemente, Stuttgart siguió creciendo durante las invasiones húngaras (Ungarneinfälle) entre 926 y 948 en Nessenbachtal y en las yeguadas (o "Stutengarten", de ahí el nombre de Stuttgart). El crecimiento de la ciudad se atribuye al conde Liudolf de Suabia, después del 945 d. C. Desde entonces el crecimiento fue hacia los lados de las instalaciones del conde Liudolf.

Nuevas excavaciones arqueológicas que se están realizando tanto en la colegiata como en el castillo antiguo, nos muestran que no había praderas verdes en la fundación de la ciudad: por lo menos desde los merovingios, ya que se establecieron aquí simples campesinos. Un sepelio bajo la colegiata completa la escasa información que hay sobre el estado de la ciudad durante la ocupación merovingia. De la época carolingia, quedan algunos pozos y casas.

La ciudad se encontraba cerca de los criaderos de caballo del Condado de Baden, como también de las ciudades de Backnang y Besigheim, pertenecientes al condado de Wurtemberg. Con la condesa Irmengard de Baden, los monasterios de Lichtenhal permanecieron en Baden-Baden; también era la propietaria de Nesenbachtal.

La marquesa de Baden se encontraba al oeste de sus enemigos, los marqueses de Wurtemberg, más tarde condes. Hermann V de Baden se alzó sobre la ciudad en 1219. Luego fueron los Wurtemberg los que tomaron la ciudad, y una dinastía después contraían matrimonio e instalaron toda la pompa de Wurttemberg en el centro de la ciudad. Hasta 1918 Stuttgart fue la capital y la residencia de los Wurtemberg: hasta 1496 era el condado de Wurttemberg, después de los condes, hasta 1803 fue principado y desde 1806 reino de Wurttemberg y después de 1918 Estado libre de Wureberg.

A final de mayo de 1849, después del rechazo a un congreso de diputados por el rey prusiano Federico Guillermo IV, se trasladó a Stuttgart la Asamblea Nacional de Fráncfort gracias a una invitación del ministro de Justicia Friedrich Römer, perteneciente a los Württemberg.

En 1806, Stuttgart logró un aumento de rango en el curso de las Guerras Napoleónicas y el consecuente establecimiento de la Confederación del Rin. La ciudad se convirtió en la capital del Reino de Wurtemberg, que se amplió para incluir las áreas de Nuevo Wurtemberg. Después de que se confirmó la existencia del nuevo estado de Wurtemberg con la conclusión del Congreso de Viena en 1815, Stuttgart experimentó un ascenso gradual en el siglo XIX.

En las décadas de 1880 y 1890, Gottlieb Daimler (1834-1900) sentó las bases de los primeros automóviles en Cannstatt, cerca de Stuttgart, y en 1887 fundó el Daimler-Motoren-Gesellschaft. Después de un incendio, la nueva planta de motores se construyó en Untertürkheim (uno de los distritos de Stuttgart) en 1903.

Con el fin de la Segunda Guerra Mundial en Europa en 1945, Stuttgart se encontraba destruida tras sufrir los bombardeos de los aliados. Aunque el centro histórico fue ampliamente destruido, numerosos monumentos y edificios históricos fueron reconstruidos, como: el , uno de los edificios más antiguos; la iglesia Stiftskirche, y el Castillo Antiguo hoy convertido en museo Nacional de Wurtemberg.

Tras la ocupación de Stuttgart por las tropas francesas, hubo al menos 1.389 violaciones en Stuttgart. El 8 de julio de 1945, las fuerzas francesas entregaron Stuttgart a los soldados estadounidenses después de que se les pidió que lo hicieran; a partir de entonces la ciudad perteneció a la zona de ocupación estadounidense. Stuttgart fue la capital del estado de Wurtemberg-Baden, que existió desde 1945 hasta 1952.

La administración militar estableció campamentos en Stuttgart para albergar a las llamadas personas desplazadas (PD). La mayoría de los PD eran ex trabajadores forzados de Europa Central y del Este en las operaciones industriales de la región. El campamento se cerró en 1949, los DP restantes se trasladaron a un campamento de PD en Heidenheim an der Brenz.

En 1948, fracasó la solicitud de la ciudad de convertirse en la nueva capital de la República Federal aún por fundarse. Además de Stuttgart, también se presentaron las ciudades de Fráncfort del Meno, Kassel y Bonn. En 1956 se terminó la construcción del que es la sede de la administración de la ciudad. La característica distintiva de la construcción es la torre del reloj de 60,5 metros de altura. El edificio anterior se quemó en 1944 durante la guerra, sin embargo, partes de las dos alas laterales se conservaron durante la reconstrucción.

En el ámbito de la Unión Europea (UE), la ciudad acogió la Cumbre Europea del 17 al 19 de junio de 1983. En ella, los miembros del Consejo Europeo firmaron una "Declaración Solemne sobre la Unión Europea" (UE), y examinaron el horizonte de la adhesión de España y Portugal a la UE. Además, en abril de 1999 se celebró en Stuttgart la "Tercera Conferencia Euromediterránea", con la participación de Libia por primera vez como invitado especial.

El alcalde de Stuttgart es Fritz Kuhn, de la Alianza 90/Los Verdes (Partido Verde alemán).

Al final de la Segunda Guerra Mundial, los administradores franceses designaron al político independiente Arnulf Klett como alcalde, un papel que cumplió sin interrupción hasta su muerte en 1974. Desde entonces, Stuttgart ha sido gobernada principalmente por la CDU. Un exalcalde fue Manfred Rommel, hijo del mariscal de campo alemán más famoso de la Segunda Guerra Mundial, Erwin Rommel.

Como capital de Baden-Württemberg, Stuttgart es un importante centro político en Alemania y la sede del Parlamento del Estado, o Landtag, así como todos los departamentos de estado de Baden-Württemberg.

Stuttgart está situada en el centro del Estado de Baden-Württemberg, en medio de una larga serie de colinas. El centro de la ciudad se sitúa entre valles y viñedos, por eso la ciudad es apodada como "Stuttgarter Kessel" («La olla stuttgartina»). Stuttgart se encuentra junto al río Neckar. La ciudad alemana limita al norte con la cuenca del Neckar, al oeste con Glemswald y el Gäu, al este con el corredor de Schurwald y al sur con el parque natural de Schönbuch. Al sureste fluye el Neckar y se sitúa la ciudad Esslingen am Neckar.

La ciudad se encuentra a una altura de 207 metros sobre el nivel del mar. Stuttgart se eleva por el Birkenkopf (511 m) en la depresión del Rand; elevada también por el Wirtemberg (411 m) sobre el valle del Neckar y por el bosque Heiner (395 m).

La ciudad está situada en el centro de la Región de Stuttgart. A la región le pertenecen los distritos de Esslingen, Göppingen, Böblingen, Ludwigsburg y Rems-Murr-Kreis, así como el municipio de Heilbronn (al norte de Stuttgart) y al sur de la región las ciudades de Reutlingen y Tübingen. Todas estos municipios y otros colindantes a la ciudad alemana forman la región metropolitana de Stuttgart, que divide al Bundesland de Baden-Württemberg en 14 zonas diferentes.

La región metropolitana europea de Stuttgart también integró las ciudades de Ditzingen, Filderstadt, Gerlingen, Korntal-Münchingen y Leinfelden-Echterdingen. La zona de Stuttgart controla las ciudades de Backnang, Bietigheim-Bissingen/Besigheim, Böblingen/Sindelfingen, Esslingen am Neckar, Geislingen an der Steige, Göppingen, Herrenberg, Kirchheim unter Teck, Leonberg, Ludwigsburg/Kornwestheim, Nürtingen, Schorndorf, Vaihingen an der Enz y Waiblingen/Fellbach.

Las siguientes ciudades limitan con la ciudad de Stuttgart; el orden parte del noreste y sigue la dirección de las agujas del reloj:

Fellbach, Kernen im Remstal (todas en el distrito urbano de Rems-Murr), Esslingen am Neckar, Ostfildern, Neuhausen auf den Fildern, Filderstadt y Leinfelden-Echterdingen (en el distrito rural —"Landkreis"— de Esslingen), Sindelfingen y Leonberg (en el "landkreis" de Böblingen), así como Gerlingen, Ditzingen, Korntal-Münchingen, Möglingen, Kornwestheim y Remseck am Neckar (todas en el "landkreis" de Ludwigsburg).

Por estar situado en una depresión y por los cultivos, en Stuttgart encontramos un clima muy cálido, aunque hay períodos en los que el frío hace acto de presencia. La Selva Negra y los bosques suabos y francos relajan las temperaturas con las sombras de sus árboles. El clima y la pendiente en la que se encuentra Stuttgart facilita la aparición de la viticultura.

En verano se produce la inversión térmica. Por eso es posible que en verano la temperatura en la Königstraße (la calle principal de Stuttgart) y en los alrededores de la Schlossplatz (la plaza principal) llegue a haber temperaturas de 30-35º a mediodía.

Stuttgart sobrepasó en 1875 los habitantes y se convirtió en la primera gran ciudad de Baden-Württemberg. En 1905 la ciudad tenía habitantes, que se doblaron hasta 1950 ( habitantes). En 1962 alcanza la máxima población de su historia: habitantes. En 2017, el censo oficial da como cifra de habitantes de Stuttgart , convirtiéndose, tras Múnich, en la segunda ciudad más habitada al sur de Alemania y la .

En 2017, el 24,1% de los habitantes de Stuttgart eran protestantes y 23,1% de fe católica, el 52.8% restante pertenecía a otras religiones o no eran confesionales.

El área de Stuttgart es conocida por su industria de alta tecnología. La ciudad acoge el noveno centro de exposiciones más grande de Alemania, la Feria de Comercio de Stuttgart, que se encuentra en las afueras de la ciudad, junto al aeropuerto de Stuttgart. Cientos de pymes aún tienen su sede en Stuttgart (a menudo denominado Mittelstand), muchas de ellas aún en propiedad familiar con fuertes lazos con la industria automotriz, electrónica, de ingeniería y de alta tecnología.

El automóvil y la motocicleta fueron inventados en Stuttgart (por Karl Benz y posteriormente industrializados en 1887 por Gottlieb Daimler y Wilhelm Maybach en el Daimler Motoren Gesellschaft). Como resultado, se considera el punto de partida de la industria automotriz mundial y, a veces, se la conoce como la "cuna del automóvil". Hoy, Mercedes-Benz y Porsche tienen su sede en Stuttgart, así como los gigantes de piezas de automóviles Bosch y Mahle. Se publican varias revistas de entusiastas del automóvil en Stuttgart.

Daimler y Porsche tienen sus oficinas centrales en las afueras del casco urbano. Gottlieb Daimler y Wilhelm Maybach construyeron en Stuttgart su motor de combustión interna, que sumado a la bujía de Robert Bosch (nacido en Stuttgart) dio nacimiento a la industria del automóvil en Alemania. La estrella de Mercedes-Benz rota sobre la torre de la Estación central de Stuttgart (HBF) y sobre el edificio más alto de la fábrica de Untertürkheim de Daimler, donde trabajan unas personas.

La ciudad de Stuttgart tiene un moderno sistema de transporte servido por buses, tranvías, cables, trenes de cremallera y S-bahn

El proyecto Stuttgart 21 prevé transformar la Estación central de Stuttgart central en un pasaje subterráneo para mejorar la conexión con la red de tranvías. Con ello se recupera un lote de cien hectáreas en el corazón de la ciudad, donde se planea construir un nuevo barrio, constituyendo una importancia estratégica considerable para la ciudad y su área metropolitana.

Desde que fuera anunciado en 1994, este megaproyecto que incluye la construcción de 56 km de vías nuevas para la Red Transeuropea de Ferrocarril, ha estado plagado de demoras y disputas sobre su impacto ambiental y sus elevados costos. Está previsto que el proyecto ferroviario entre en funcionamiento a fines de 2025.

Stuttgart es representativa de la arquitectura innovadora, con su museo de arte y su urbanización Weißenhofsiedlung de estilo Bauhaus, diseñada en 1927 por los arquitectos Mies van der Rohe, Walter Gropius y Le Corbusier.

Otras obras representativas de la arquitectura de la ciudad son el Palacio Nuevo ("Neues Schloss") y el Castillo Antiguo ("Altes Schloss"), situados en la Plaza del Palacio ("Schlossplatz"). Otro palacio es el de Rosenstein ("Schloss Rosenstein") que cuenta con el Parque Rosenstein. También, dentro de las obras tradicionales, se encuentra la iglesia evangelista de San Juan ("Johanneskirche") de estilo neogótico, la Ópera Nacional de Stuttgart ("Württembergisches Staatstheater Stuttgart"), y la Galería Estatal de Stuttgart ("Staatsgalerie") y su ampliación, la Nueva Galería Estatal de Stuttgart.

En Stuttgart se levantan dos reconocidas torres: la Torre de Televisión, y la Torre Bismarck.

Ya en el siglo XXI, la ciudad se ha dotado de instalaciones culturales con valor arquitectónico. Tal es el caso del Mercedes-Benz Museum y el museo Porsche, así como la Biblioteca Pública de Stuttgart entre otros.

Friedrich Hegel nació en esta ciudad en 1770. Uno de los escritores alemanes más famosos, Schiller, también vivió en la ciudad, siendo originario de Marbach am Neckar, a unos 30 km.

En los viñedos cercanos a Stuttgart se puede conocer el estilo de vida "suabo" tradicional. Allí, los viticultores invitan a degustar sus caldos o los restaurantes ofrecen especialidades de la región como el cocido "Gaisburger Marsch".
En Stuttgart se han realizado eventos deportivos de nivel internacional como el Campeonato Europeo de Atletismo (1986), el Campeonato Europeo de Voleibol femenino (1989), el Campeonato mundial de Ciclismo (1991), el Campeonato Mundial de Atletismo de 1993, la vuelta ciclista a Alemania (2000) y fue sede de la Copa Mundial de Fútbol de 2006 en Alemania.

Acoge anualmente el Torneo de tenis de Stuttgart incluido en la categoría Premier.

El VfB Stuttgart es el club de fútbol de la ciudad. Participa en la primera división del fútbol nacional, la Bundesliga. Su estadio es el Mercedes-Benz Arena con una capacidad para 60.441 espectadores.




</doc>
<doc id="45219" url="https://es.wikipedia.org/wiki?curid=45219" title="Región insular de Colombia">
Región insular de Colombia

La región insular de Colombia es el conjunto de las islas, cayos e islotes alejadas de las costas continentales, como son el Archipiélago de San Andrés y Providencia en el mar Caribe y las islas Malpelo y Gorgona en el océano Pacífico. En ella no se cuentan las islas fluviales ni lacustres.

Las islas continentales son las que se ubican más próximas al territorio continental y se encuentran vinculadas geológicamente por la plataforma submarina. En el Caribe colombiano se destacan las islas Tierra Bomba, del Rosario, Barú (estas tres bordeando la bahía de Cartagena), San Bernardo (frente a la punta de San Bernardo), Fuerte y Tortuguilla. En la costa del Pacífico las islas son muy numerosas, porque muchos ríos que vierten su caudal en el océano las forman con las arenas y piedras que arrastran hasta el mar. Al subdividirse en brazos, los ríos San Juan, Tapaje.

El mar Caribe comprende el archipiélago formado por las islas de San Andrés, Providencia y Santa Catalina; los bancos Alicia, Quitasueño, Serrana y Serranilla, y una serie de cayos entre los que sobresalen los llamados Roncador y Albuquerque, a unos 700 km de la costa norte del país. En el Océano Pacífico se encuentran las islas de Gorgona, Gorgonilla y Malpelo.

Hacia el norte de San Andrés se encuentra Providencia, por su aislamiento geográfico y su estado primitivo constituye un sitio ideal para el descanso. Sus hermosas y solitarias playas son propicias para la natación, el buceo, el esquí, y otros deportes acuáticos. Esta isla posee tierras fértiles, es rica en agricultura, especialmente en frutas tropicales, y pesca (Langosta).

La vida en Providencia es esencialmente contemplativa y tranquila. Nada se opone a su forma libre de descansar en calma, salvo, a veces, el ruido de los equipos de música que nativos y autoridades amplifican en exceso.

Hay una carretera de circunvalación y en ella varios poblados pequeños a partir del Centro (Santa Isabel), donde es bueno aprovisionarse y resolver -desde la llegada- los asuntos de transporte en la isla, las reservas de vuelo de regreso y su interés en tomar alguna excursión de pesca o de visita a Cayo Cangrejo, un islote cuyo mérito es la vegetación, donde se toma un baño y se mira el horizonte.

Las subregiones de la Región Insular de Colombia son las siguientes:


A pesar de lo pequeño de su superficie, es una región muy diversa, ya que está conformada por islas en los dos océanos: el archipiélago de San Andrés y Providencia en el mar Caribe, y el archipiélago de Gorgona y Gorgonilla y el islote de Malpelo, en el océano Pacífico. Del primero forma parte también la isla de Santa Catalina. La región se caracteriza por sus periodos de lluvia definidos y su clima seco. El segundo archipiélago es en su mayoría selvático, húmedo y de lluvias permanentes, lo que lo hace profusamente rico en cuanto a flora y fauna.

El Festival de la Luna Verde: es una celebración que hace visible un modo de ser y celebrar que es propio de la gente afro caribeña. A pesar de tener un origen reciente, el festival presenta características que relatan la historia de estas Islas. La desaparición absoluta de la presencia indígena, así como la colonización por parte de ingleses que introdujeron africanos para laborar en grandes plantaciones, se manifiestan hoy en día en la cultura sanandresana.

El festival se inicia con una marcha que recorre las principales vías de San Andrés al ritmo de tambores marciales que marcan el compás, aprovechado por las huestes de la numerosa banda de percusión para desarrollar coreografías originales. Los ritmos militares son acompañados por pasos de marcha sugeridos por claves de tambor, que varían según el líder que conduzca a la banda militar juvenil. Estos líderes establecen una especie de competencia entre sí cuando, estando al frente de la banda, señalan las marcaciones rítmicas, que el conjunto debe interpretar y trasladar sin perder contacto con el ritmo inmediatamente anterior.

El Festival del Cangrejo: es una celebración típica de San Andrés, donde los isleños preparan diversos platos en base al cangrejo, como (carambolas, arroz con cangrejo, tortas, pasteles, pasa bocas) para gusto de los propios isleños y turistas que participen en este festival, este va acompañado con músicas y danzas para amenizar más las celebraciones en las cuales las muestras gastronómicas preparadas con este plato son el deleite de todos.
Los platos típicos de San Andrés son elaborados con pescados, langostas, caracoles y cangrejos acompañados con plátanos, coco, leche de coco y yuca. El plato típico más conocido es el rondón, el cual es una especie de cacerola de pescado con caracoles cocidos lentamente en leche de coco, con yuca, patacón y pescado.

Mujer:La vestimenta por excelencia de la Región Insular para la mujer consiste en una blusa blanca de manga larga y cuello alto, conjuntada con una falda larga que suele llegar hasta la altura de los tobillos. Además, a este traje se le suelen añadir accesorios como un pañuelo en la cabeza de algún color vivo.

Hombre:
En cuanto al traje masculino, éste también se compone principalmente de una camisa casi siempre blanca. Los pantalones suelen ser de color gris, aunque también se pueden ver en color crema, o incluso negro, siempre combinados con zapatos negros.

La principal fuente de ingresos de la región insular colombiana es el turismo. La región insular cuenta con las playas más bellas y uno de los principales complejos hoteleros del país, el cual es visitado anualmente por nacionales y extranjeros. La región insular también es célebre por el movimiento de su comercio. Gorgona es un parque natural ideal para las investigaciones biológicas. En la región se practica el turismo ecológico a gran escala.

San Andrés es uno de los más exóticos y bellos paraísos tropicales submarinos del Caribe y en el cual Son características: sus playas de arenas blancas, la variedad de aves y fauna marina, como: tortugas, tiburones, langostas, caracoles y una gran variedad de peces. Además de una abundante variedad de flora y fauna submarina en la cual sobresalen las esponjas de todas las formas y colores. En la vida animal submarina podemos encontrar peces globos, peces ángel, peces trompeta, pargos, rayas, langostas, morenas.

En el año 2013 la región constaba con 74.620 habitantes. En el 2005 se realizó una estimación de que el 56,98% de la población eran afroamericanos. El 42,91% de la población son mestizos y blancos. El 0,1% son indígenas nativos y el 0,15% son gitanos. Sus principales dialectos son: el criollo sanandresano, el español y el inglés.




</doc>
<doc id="45221" url="https://es.wikipedia.org/wiki?curid=45221" title="Úlster">
Úlster

Úlster (, ; , ) es una de las «provincias históricas» de la isla de Irlanda. Hay nueve condados en la provincia. Seis de sus condados, con una población (2011) de 1 810 863 habitantes, constituyen Irlanda del Norte, un país constitutivo del Reino Unido. Los otros tres condados, con 295 400 habitantes (2011), forman parte de la República de Irlanda. Es la segunda provincia más grande (después de Munster) y la segunda más poblada (después de Leinster) de las cuatro provincias de Irlanda, con Belfast como la ciudad más poblada.

A diferencia de las otras provincias, Ulster tiene un alto porcentaje de protestantes. Los de origen católico representan aproximadamente el 51 % de su población, mientras que los de origen protestante del Ulster representan alrededor del 43 %. El inglés es el idioma principal y el inglés de Ulster el dialecto principal. Una minoría también habla irlandés, y hay un Gaeltacht (región de habla irlandesa) en el oeste de Ulster. El lago Neagh, en el este, es el lago más grande de las Islas Británicas, mientras que el lago Erne, en el oeste, es una de las redes de lagos más grandes. Las principales cadenas montañosas son las montañas Mournes, Sperrins, Croaghgorms y Derryveagh.

Históricamente, Ulster estaba en el corazón del mundo gaélico formado por la Irlanda gaélica, Escocia y la Isla de Man. Según la tradición, en la antigua Irlanda era uno de los quintos (irlandés: "cúige") gobernados por un "rí ruirech", o "rey de reyes superiores". Lleva el nombre del reino superior de Ulaid, en el este de la provincia, que a su vez fue llamado así por la gente Ulaid. Los otros reinos superiores en Ulster fueron Airgíalla y Ailech. Después de la invasión normanda de Irlanda en el siglo XII, el este del Ulster fue conquistado por los anglo-normandos y se convirtió en el condado del Ulster. A fines del siglo XIV, el condado se había derrumbado y la dinastía O'Neill había llegado a dominar la mayor parte del Ulster, reclamando el título de rey del Ulster. Ulster se convirtió en la más gaélica e independiente de las provincias de Irlanda. Sus gobernantes resistieron la intrusión inglesa pero fueron derrotados en la Guerra de los Nueve Años (1594-1603). El Rey Jacobo I luego colonizó Ulster con colonos protestantes de habla inglesa de Gran Bretaña, en la Colonización del Úlster. Esto llevó a la fundación de muchas de las ciudades del Ulster. La afluencia de colonos protestantes y migrantes también provocó episodios de violencia sectaria con los católicos, especialmente durante la rebelión de 1641 y los disturbios de Armagh. Junto con el resto de Irlanda, el Ulster se convirtió en parte del Reino Unido en 1801. A principios del siglo XX, muchos protestantes del Ulster se opusieron a los movimientos hacia el gobierno autónomo irlandés, lo que provocó la Crisis de la Autonomía. Esto, y la posterior Guerra de Independencia irlandesa, condujo a la partición de Irlanda. Seis condados de Ulster se convirtieron en Irlanda del Norte, un territorio autónomo dentro del Reino Unido, mientras que el resto de Irlanda se convirtió en el Estado Libre Irlandés, ahora la República de Irlanda.

Los condados en gris forman parte de la República de Irlanda . Los condados en rosado constituyen Irlanda del Norte 

Úlster es también el nombre del dialecto del idioma irlandés originario de esta parte de la isla. La gran mayoría de la población de la provincia habla inglés; el irlandés es el segundo idioma más hablado. Según el Censo de Irlanda del Norte de 2011, aproximadamente el 10 % de los habitantes de esa región tiene un conocimiento general del idioma irlandés y el 4.7 % de la población puede hablar, escribir, leer y entender el idioma.



</doc>
<doc id="45226" url="https://es.wikipedia.org/wiki?curid=45226" title="Impares">
Impares

Impares puede hacer referencia a:


</doc>
<doc id="45227" url="https://es.wikipedia.org/wiki?curid=45227" title="Jersey (desambiguación)">
Jersey (desambiguación)

La palabra jersey puede referirse a:


</doc>
<doc id="45232" url="https://es.wikipedia.org/wiki?curid=45232" title="Ecuaciones de Euler-Lagrange">
Ecuaciones de Euler-Lagrange

Las ecuaciones de Euler-Lagrange son las condiciones bajo las cuales cierto tipo de problema variacional alcanza un extremo. Aparecen sobre todo en el contexto de la mecánica clásica en relación con el principio de mínima acción, también aparecen en teoría clásica de campos (electromagnetismo y teoría general de la relatividad) y sirve de base para la formulación de integrales de camino para la teoría cuántica de campos.

La ecuación de Euler–Lagrange es una ecuación la cual se satisface con una función, formula_1,
con argumento real formula_2, el cual es un punto estacionario del funcional

donde:

Entonces, la ecuación de Euler–Lagrange está dada por:
donde formula_20 y formula_21 son las derivadas parciales de formula_15 correspondientes a los argumentos segundo y tercero, respectivamente.

Si la dimensión de formula_18 es mayor a 1, es un sistema de ecuaciones diferenciales, donde cada componente es:

En mecánica clásica, estas ecuaciones establecen que la integral de acción para un sistema físico es un mínimo. Los sistemas de partículas o sistemas discretos tienen un número finito de grados de libertad, y en esos casos la integral de acción es del tipo:

Y su correspondiente variación viene dada por:

Si se impone ahora que formula_25 para variaciones "cercanas", esto implica que:

donde "L" es el lagrangiano para el sistema, y formula_26 son las coordenadas generalizadas del sistema.

La formalización de ciertos problemas físicos requiere construir una integral de acción sobre un continuum o sistema que no puede ser tratado mediante un número finito de variables o grados de libertad. Así en teoría de campos y mecánica de medios continuos la acción física puede expresarse como una integral sobre un volumen:

Donde formula_27 es el elemento de volumen que usualmente viene dado por una n-forma y formula_28 representan las variables del campo y sus derivadas respecto a las coordenadas espaciales (o espacio-temporales). Cuando la acción toma esa forma las ecuaciones de Euler-Lagrange para el campo que minimiza la anterior integral, usando el convenio de sumación de Einstein, vienen dadas por:
Un ejemplo de problema mecánica simple es el de una partícula sometida a un campo de fuerzas conservativo, en ese caso su trayectoria puede ser encontrada mediante las ecuaciones de Euler-Lagrange aplicadas al lagrangiano:

La función lagrangiana anterior usa coordenadas cartesianas, aunque según el tipo de problema también puede escribirse un lagrangiano en términos de cualquier tipo de coordenadas generalizadas: 
Las ecuaciones de Euler-Lagrange para el caso de las coordenadas cartesianas se reducen a la segunda ley de Newton para la partícula:
La teoría clásica de campos es un buen ejemplo del caso multidimensional anteriormente descrito. Así por ejemplo las ecuaciones de Maxwell no son otra cosa que las ecuaciones de Euler-Lagrange aplicadas al "lagrangiano" de Maxwell. La densidad lagrangiana de Maxwell viene dada por:

Donde el primer término es el lagrangiano de interacción y el segundo el lagrangiano del campo electromagnético libre y además:
Considerando aquí el campo descrito por los potenciales formula_32, los campos eléctrico y magnético son expresables en términos de sus derivadas:
\qquad \mathbf{B} = \boldsymbol\nabla\times \mathbf{A}</math>
Todos estos términos substituidos en la ecuación de Euler-Lagrange nos lleva a las ecuaciones de Maxwell. Si a la densidad lagrangiana anterior le agregamos, la densidad lagrangiana de la materia en interacción con el campo electromagnético viene dado por:
</math>
Cuando esta parte se tiene en cuenta también se recupera la expresión para la fuerza de Lorentz.

Un artículo influyente, para la introducción del formalismo lagrangiano en la mecánica cuántica, fue el de Paul Dirac de 1932. El artículo titulado “El lagrangiano en Mecánica Cuántica” comienza de la siguiente manera:

“La mecánica cuántica fue construida sobre la base de la analogía con el hamiltoniano de la mecánica clásica. Esto se debe a que se encontró que la clásica noción de coordenadas canónicas y momentos es similar a la análoga cuántica, como resultado del cual la totalidad de la teoría clásica hamiltoniana, la cual es justamente una estructura construida sobre esta noción, debería ser tomada sobre todos sus detalles en mecánica cuántica.

Ahora tenemos una formulación alternativa para la dinámica clásica, provista por el lagrangiano. Esto requiere trabajar en términos de coordenadas y velocidades en lugar de coordenadas y momentos. Las dos formulaciones son, sin embargo, cercanamente relacionadas, pero hay razones para creer que el lagrangiano es el más fundamental.

En primer lugar, el método lagrangiano nos permite conectar juntas todas las ecuaciones del movimiento y expresarlas como una propiedad estacionaria de una cierta función de acción. (Esta función de acción es justamente la integral en el tiempo del lagrangiano). No existe un principio de acción correspondiente en términos de las coordenadas y momentos en la teoría hamiltoniana. En segundo lugar el método lagrangiano puede fácilmente ser expresado en forma relativista, teniendo en cuenta que la función de acción es invariante relativista; mientras que el método hamiltoniano es esencialmente de forma no relativista, dado que delimita una variable de tiempo particular como la conjugada canónica de la función hamiltoniana.

Por estas razones sería deseable tomar la cuestión de lo que corresponde en la teoría cuántica al método lagrangiano de la teoría clásica. Una pequeña consideración muestra, sin embargo, que uno no puede esperar ser capaz de tomar las ecuaciones clásicas de Lagrange en una forma directa. Estas ecuaciones involucran derivadas parciales del lagrangiano respecto a las coordenadas y velocidades y no significa poder tener tales derivadas en mecánica cuántica.

El sólo proceso de diferenciación que puede realizarse respecto a las variables dinámicas de la mecánica cuántica es el que forma los corchetes de Poisson y este proceso conduce a la teoría hamiltoniana.

Debemos por lo tanto mirar nuestra teoría cuántica lagrangiana de una manera indirecta. Debemos intentar tomar las ideas de la teoría lagrangiana clásica, no las ecuaciones de la teoría clásica lagrangiana”.

Como se vio antes, es posible derivar las ecuaciones de la mecánica clásica como las del electromagnetismo a partir del lagrangiano respectivo introducido en las ecuaciones de Euler-Lagrange. 
Por ese camino, es posible ampliar el lagrangiano de Maxwell para obtener el lagrangiano de Dirac y así obtener, luego, la ecuación relativista de Dirac. También las ecuaciones de Schrödinger, de Klein-Gordon y de Proca pueden obtenerse por ese método.

Incluso es posible derivar las ecuaciones de Einstein, de la relatividad generalizada, a partir del lagrangiano de Hilbert-Einstein

Las ecuaciones de Euler-Lagrange pueden ser usadas para encontrar fácilmente la ecuación de las curvas geodésicas en una variedad de Riemann o "espacio curvo". Para ello consideremos un conjunto de coordenadas ("x", ..."x") sobre una región abierta "U" de la variedad de Riemann "V" donde el tensor métrico viene dado por la expresión:

Puesto que dados dos puntos cualquiera de "V" las geodésicas son las líneas de mínima longitud entre ellos podemos plantear el siguiente problema variacional, para el cuadrado de la longitud de una curva:

La minimización de la expresión anterior al ser la raíz una función monótona, es equivalente a la minimización de una integral de acción donde el lagrangiano sea:

De ahí que la ecuación diferencial de las geodésicas venga dada por:

La ecuación anterior de hecho puede, usando la simetría del tensor métrico, escribirse como:

Que en términos de los símbolos de Christoffel (de primera o segunda especie) sencillamente como:

Donde se han definido los símbolos de Christoffel como a partir de las derivadas del tensor métrico y el tensor inverso del tensor métrico:




</doc>
<doc id="45242" url="https://es.wikipedia.org/wiki?curid=45242" title="Niní Marshall">
Niní Marshall

Marina Esther Traveso (Buenos Aires, 1 de junio de 1903-Ib., 18 de marzo de 1996), mejor conocida bajo su nombre artístico de Niní Marshall, fue una
actriz, guionista y comediante argentina.

Inició su carrera como redactora en la revista "Sintonía" en la década de 1930 bajo el seudónimo de Mitzy. Incursionó como cancionista en una serie de programas radiofónicos hasta que sus dotes para la comedia la llevaron a participar como actriz y formar un dúo cómico con Juan Carlos Thorry. Su popularidad fue en aumento y Manuel Romero la incorporó como actriz protagónica y guionista en la película "Mujeres que trabajan" (1938). Entre 1939 y 1940, encabezó una trilogía dirigida por Romero que incluyó los filmes "Divorcio en Montevideo", "Casamiento en Buenos Aires" y "Luna de miel en Río".

Su observación minuciosa de la sociedad la llevó a crear dos personajes emblemáticos, Catita y Cándida, dos arquetipos de la inmigración europea del siglo XX, con los que intervino en gran parte de sus películas. A comienzos de los años de 1940, encabezó las primeras superproducciones de la historia del cine argentino, "Carmen" (1943), "Madame Sans Gene" (1945) —por la que obtuvo el premio a la mejor actriz cómica de la ACCA— y "Mosquita muerta" (1946), todas dirigidas por Luis César Amadori. Tras el golpe de Estado de 1943, Marshall debió exiliarse en México luego de que las autoridades consideraran el lenguaje utilizado por sus personajes como «una deformación del idioma».
La situación se volvió a reiterar en 1950 cuando, en un confuso episodio, Marshall dejó de recibir ofertas de trabajo durante el gobierno de Juan Domingo Perón.

Su retorno al cine luego tras la caída del peronismo tuvo lugar en "Catita es una dama" (1956), que no tuvo el mismo éxito que sus películas anteriores. Sus siguientes actuaciones fueron en comedias de bajo presupuesto que le ofrecieron un lucimiento limitado y tuvieron una mala recepción. En cambio, sus presentaciones televisivas en los años de 1960 en el ciclo de Nicolás Mancera, "Sábados circulares", generaron repercusión en el público. En 1973, fue convocada por Lino Patalano para desarrollar un espectáculo de "café-concert", "Y... se nos fue redepente", que alcanzó más de 1500 presentaciones y le permitió llevar a escena todos sus personajes. A lo largo de su carrera teatral, por su parte, se destacó en "Coqueluche", "Buenos Aires de seda y percal" y "La señora Barba Azul". Su éxito como humorista le valió los apodos de «la dama del humor» y «la Chaplin con faldas».

Marshall se retiró del cine en 1980 después de filmar "¡Qué linda es mi familia!" junto a Luis Sandrini, aunque en 1985 publicó sus memorias y continuó trabajando esporádicamente en televisión hasta 1988. Los últimos años de su vida estuvieron marcados por los homenajes, entre los que destacan haber sido declarada «Ciudadana ilustre de la Ciudad de Buenos Aires» en 1989 y merecedora del premio Podestá a la Trayectoria en 1992. Al momento de su muerte en 1996, Marshall era considerada una de las figuras del espectáculo más importantes y reconocidas de la Argentina. En la actualidad, un teatro en Tigre y una calle de Puerto Madero llevan su nombre a modo de reconocimiento.

Marina Esther Traveso —conocida posteriormente bajo el seudónimo de Niní Marshall— nació el 1 de junio de 1903 en el barrio porteño de Caballito como la menor de los hijos de Pedro Traveso y María Ángela Pérez, ambos inmigrantes asturianos. Cuando contaba con apenas dos meses de edad, su padre murió y los cuatro hijos del matrimonio quedaron a cargo de su esposa. Tras el deceso de su padre, la familia se trasladó a una casona de la calle Defensa 219 —actualmente Museo de la Ciudad— en el barrio de Monserrat, frente a la iglesia de San Francisco, donde vivió parte de su niñez. A los cuatro años, Marina fue inscrita en la Escuela Juan José Paso, donde demostró su interés por la actuación, y un año más tarde hizo su primera presentación en el Centro Asturiano de Buenos Aires.

En su niñez, la familia se trasladó al barrio de Montserrat y Marina inició sus estudios de danzas españolas, pintura, dibujo, canto, piano e idiomas tales como el francés, alemán e inglés. También lideró una pandilla de niños llamada "Los Arribeños del Norte", con la que desempeñaba pequeñas obras teatrales en el sótano de la casa de un tío a manera de entretenimiento. Luego de finalizar sus estudios primarios, prosiguió sus estudios en el Liceo Nacional de Señoritas N° 1, donde comenzó a diseñar sus primeros personajes, en general imitaciones de sus profesores. Marshall, en su adultez, señaló que tuvo una infancia «feliz» y se caracterizaba por su exacerbada timidez: «La timidez me agarraba, por ejemplo, cuando tenía que dar una lección, o ponerme de pie para decirle algo a una maestra o a una profesora. Pero cuando se terminaba la hora de clase era un monigote, como soy ahora, un payaso. No fui muy buena alumna. ¡De verdad que no!».

Fue en esa institución donde se recibió de bachiller en 1921. Al terminar la educación secundaria, inició sus estudios en Filosofía y Letras, los cuales fueron interrumpidos cuando contrajo matrimonio en 1924 con Felipe Edelmann, un ingeniero de origen ruso mucho mayor que ella y educado en Alemania, con el que tuvo a su única hija, Ángela Dora, en 1926. Marina vivía en ese entonces en La Pampa y regresó solamente a Buenos Aires para dar a luz a su hija, ocasión en la que le embargaron la vivienda. A la muerte repentina de su madre en 1926, la relación con su esposo comenzó a declinar y se divorciaron. En sus memorias, Marshall definió esa etapa de su vida como una «catástrofe sentimental y económica». Se trasladó temporalmente a la casa de su hermana Blanca en Rosario, Santa Fe, y posteriormente regresó con su pequeña hija a Buenos Aires para instalarse en una pensión y buscar empleo en los medios gráficos.

En 1933, a instancias de su amigo Delfín Ravinovich, consiguió trabajo como redactora en "La Novela Semanal", donde escribió artículos con el fin de promocionar artefactos domésticos, como los de la empresa General Electric. Otras de sus publicaciones estuvieron vinculadas a la mujer y los cuidados para el cuerpo. Su trabajo continuó en la revista "Sintonía", una de las más populares de la época junto con "Antena" y "Maribel". Marshall, bajo el seudónimo de Mitzy, tenía a su cargo la redacción de artículos sobre asuntos de actualidad en un apartado que se denominaba «Alfilerazos», donde se destacó por su humor ácido y sus observaciones punzantes. Sus redacciones rápidamente adquirieron popularidad y comentó acerca de su trabajo:

En 1934, por sugerencia de uno de los directivos de "Sintonía", se presentó en una prueba radiofónica y resultó elegida en la categoría de «cantante internacional». Un mes después, realizó su primera presentación como cancionista en el ciclo de radio "La voz del aire", donde cantó en tres idiomas y permaneció trabajando durante ocho meses bajo el seudónimo de Ivonne D'arcy. A su vez, intercaló actuaciones en otras emisoras tales como Porteña, Municipal, Nacional, Belgrano y Fénix. Pipita Cano, conductora del ciclo "El chalet de Pipita" en Broadcasting Municipal, vislumbró sus dotes para la comedia y le ofreció interpretar a una mucama en su programa. Fue así como Marshall diseñó a Cándida, una empleada doméstica inspirada en una mujer de origen español que trabajaba en su casa de niña. El personaje, según su biógrafa Marily Contreras, era «una mujer ignorante, ingenua y torpe, pero querible, y que produjo entre los oyentes de Niní una enorme cuota de ternura, por el trasfondo de bondad que emanaba el personaje». La caracterización fue creciendo en popularidad a tal punto que Roberto Llauró, un industrial destacado, la convocó para promocionar su marca de jabones en Radio El Mundo. Los comienzos de la emisora en 1935 no tuvieron demasiada trascendencia, motivo por el cual Marshall propuso hacer un programa cómico basado en guiones propios. Sin embargo, Pablo Osvaldo Valle, director de la radio, rechazó la propuesta alegando que no era una actriz conocida y las mujeres no escribían libretos.

En 1936, conoció a Marcelo Salcedo, un contador paraguayo de una empresa yerbatera con el que se casó poco tiempo después y diseñó su nombre artístico definitivo. Su apellido fue constituido por la primera sílaba del nombre y el apellido de su marido (Mar-Sal); la adhesión posterior de una «h» y una «l» hizo que quedara Marshall. En cambio, optó por una deformación de Marina para el nombre: Marinita-Ninita-Niní. Al comienzo, varias emisoras donde compartió cartel con Encarnación Fernández, Pablo Palitos o Delfina Fuentes la presentaron en sus anuncios como Lily Marshall, Niní Marschall o Niní Marshal debido a la supuesta dificultad que les generaba pronunciarlo.

A partir de marzo de 1937, sus presentaciones estuvieron acompañadas por su "partenaire" Juan Carlos Thorry, con quien trabajó asiduamente hasta los finales del apogeo de su carrera. Su experiencia como redactora publicitaria y su alto rendimiento en creatividad le dieron rápidamente un perfil novedoso como artista. El éxito del dúo acrecentó los niveles de audiencia y Marshall logró conseguir un espacio de media hora en un horario central. En una de las salidas de la radio, la actriz observó a las seguidoras enardecidas que se agolpaban para pedirle autógrafos a Thorry y gestó el personaje de Catita que, junto con Cándida, se convirtieron en sus caracterizaciones más emblemáticas. El empresario Emilio Córdoba, enterado de su nuevo personaje, la contrató para promocionar su Tienda La Piedad; a partir de entonces, dos funciones semanales fueron dedicadas a Cándida y otras dos a Catita. Su labor durante ese año le mereció el premio «Sensación Radiofónica» otorgado por la revista "Sintonía".

Aunque el equipamiento era aún precario, el cine comenzó a posicionarse como una industria activa y pequeña en torno a la cual artistas y directores construían una popularidad creciente. El público comenzó a inclinarse por el cine como modo de entretenimiento atraído por la posibilidad de ver a sus ídolos de radio en pantalla. En 1938, Marshall fue convocada por Manuel Romero para filmar su primera película. Sin embargo, el director debió reiterar varias veces su llamado ante el rechazo de la actriz, a la que, en sus propias palabras, le atemorizaba el cine porque «no tenía rostro cinematográfico y por miedo a que la gente se decepcione». Marshall aceptó una prueba de cámara y, disueltos sus temores, rescindió su contrato con la radio y firmó uno nuevo con la compañía cinematográfica Lumiton. La actriz Mecha Ortiz, integrante del elenco, recordó tiempo después que su pariente, el presidente Roberto Marcelino Ortiz, al enterarse de que filmaría con Marshall, le solicitó que le consiguiera un autógrafo. La película se tituló "Mujeres que trabajan" y la actriz compuso a Catita en el rol de una vendedora de tienda. Las críticas fueron en general positivas y el "Heraldo Cinematográfico" apuntó que «la dicción en las escenas iniciales dejó algo que desear, pero que esto no empañó el resultado final». De acuerdo a Contreras, «la película es una atinada pintura de las empleadas de comercio de la época. La comicidad se basa exclusivamente en el lenguaje». Marshall, sin embargo, se mostró insatisfecha con su trabajo. Al finalizar el rodaje, la actriz partió en gira hacia Tandil en compañía de Thorry para luego continuar por Benito Juárez, Tres Arroyos, Coronel Dorrego, Bahía Blanca y Coronel Pringles. Tras un breve regreso a Buenos Aires, la gira prosiguió por Santa Fe, Mendoza, Entre Ríos, Córdoba y San Juan.

En 1939, contratada nuevamente por Lumiton, protagonizó "Divorcio en Montevideo" junto a Enrique Serrano y bajo dirección de Romero. El argumento, en el cual Marshall colaboró, señala que para apartarse de su novia presumida un muchacho se casa con una manicura conviniendo divorciarse meses después. El trato se lleva a cabo pero el joven comprende que se enamoró de su exesposa y la busca para volverse a casar. La película se estrenó a mediados de año en el cine Monumental y fue un éxito a tal punto que el historiador Domingo Di Núbila, en uno de sus libros, publicó que ahí «no solo se demostró que Niní Marshall podía hacer funcionar una película, sino multiplicarla por tres». Ese mismo año llevó por primera vez a su personaje de Cándida al cine en un filme que se tituló con el mismo nombre. Esta vez, las críticas fueron negativas; la revista "Radiolandia", por ejemplo, definió al argumento como de «materiales primarios, aderezado con algunos lugares comunes de directa repercusión en el auditorio, sirve a sus fines cómico-sentimentales a la intérprete y resulta de eficacia popular». Zully Moreno y Pepe Biondi se encontraban entre las muchas personas que se presentaron para obtener algún papel como extra en la película; ambos se convertirían en dos figuras importantes años después.

El éxito creciente de Marshall fue motivo de disputa entre dos compañías cinematográficas. Los directivos de Lumiton se enteraron por medio de un periódico de un supuesto precontrato de la actriz con otra empresa. El hecho generó consternación ya que Lumiton poseía la exclusividad de las interpretaciones de Catita, motivo por el cual Marshall debió aclarar que se había tenido en cuenta ese detalle en su nuevo proyecto con Argentina Sono Film y Lumiton continuaría con la concesión de Catita. Fue así como en 1940 protagonizó "Casamiento en Buenos Aires", la secuela de "Divorcio en Montevideo", sobre la que "Sintonía" tituló «Impacto demasiado fácil», mientras que "La Nación" relató: «Episodios y tipos convencionales, se arman con medios directos y fáciles, pero entre unos y otros se asoma... Catita». La trilogía se completó con "Luna de miel en Río", donde actuó junto a Tito Lusiardo y Juan Carlos Thorry. Aunque estaba ambientada en Brasil, los rodajes se llevaron a cabo en tan solo un mes en Munro. Marshall se convirtió para ese momento en una de las actrices más productivas del año y la de mayor importancia en la industria del cine.

En 1940, Marshall también protagonizó "Los celos de Cándida", que generó un modesto éxito. La actriz intervino en el armado de los diálogos junto a Luis Bayón Herrera y su actuación estuvo acompañada por Augusto Codecá. "El Heraldo", en sus sugerencias para el programa de mano, la catalogó como una «magnífica comedia de gracia irresistible». Jorge Luz realizó su debut como actor en esa película en una breve aparición como un bañista que caminaba por detrás de los personajes protagónicos en las playas de Mar del Plata. Durante el rodaje, el director aprovechó la ignorancia de Marshall en la práctica de la ruleta para que su personaje cometiera todo tipo de torpezas en una de las escenas llevadas a cabo en el casino. En el mismo año, los hermanos Mentasti le ofrecieron a Marshall una propuesta para rodar la comedia "Hay que educar a Niní", que la actriz aceptó con la condición de elegir el director e intervenir los libretos. Ante la imposibilidad de interpretar a Cándida y Catita por cuestiones contractuales, Marshall apareció en el rol de Niní Reboredo, una actriz de reparto que vive en un internado de niñas y se hace pasar por la hija de un industrial rico interpretado por Francisco Álvarez. Según Etchelet, los carpinteros y técnicos del estudio abandonaban sus puestos para verla actuar y muchas escenas debieron repetirse a causa de las risas. Las hermanas Mirtha y Silvia Legrand aparecieron como extras en la película. "Hay que educar a Niní" se ubicó en el puesto tercero en la encuesta de lo mejor de la temporada efectuada por el "Heraldo del Cinematografista". Horacio Salas, al entregarle el título de Ciudadana ilustre en 1989, le espetó: «Una de sus películas se llama "Hay que educar a Niní". Pero es Niní quien nos educa hace 50 años».

En julio de 1940, Marshall firmó un contrato de exclusividad con Argentina Sono Film para filmar dos películas bajo dirección de Luis César Amadori en seis meses, acuerdo que luego se extendió hasta diciembre de 1943. Entre noviembre y diciembre de ese año, la actriz incursionó por primera vez en el ámbito discográfico al grabar —en su personaje de la tonadillera Loli— un disco con catorce temas musicales, entre los que destacan «Se lo cuentas a Noel», «Soy castañera» y «La Sinforosa», bajo el sello Odeón. Nuevamente dirigida por Romero, a comienzos de 1941 protagonizó "Yo quiero ser bataclana", donde Marshall representó una parodia del ballet "La muerte del cisne" de Saint Saens e interpretó el tango «El vino triste» de Juan D’Arienzo. Recibió el asesoramiento de Mecha Quintana y luego recordaría con humor en "Mis memorias" que «bailé de punta y maté al cisne como si fuera una gallina». La crítica cinematográfica la calificó como «una buena cinta cómica» y la propia actriz destacó que «tuvo un ritmo febril, diálogos vivaces y ocurrencias ingeniosas». El empresario radiofónico Pablo Valle, al notar que la actriz estaba siendo eclipsada por el cine, mostró su enfado, mientras que Llauró intentó convencerla infructuosamente de regresar a la radio. Paralelamente, Marshall inició una gira con Pedro Quartucci —en reemplazo de Thorry— y partió rumbo a Chile y Perú. Sus presentaciones en ese país fueron tan populares que la demanda de entradas superó las expectativas y permanecieron toda la semana a sala llena.

Marshall presentó un nuevo personaje, la cantante lírica Giovanina Regadiera, en su filme "Orquesta de señoritas", con el que ridiculizó a las divas de Bel canto que se presentaban en el Teatro Colón. Su biógrafa Marily Contreras coincide en que la producción de los años 1939-1941 es «impresionante», lo que generó cansancio en Marshall, que además alternaba sus películas con presentaciones esporádicas en radio. Un año después, Amadori logró introducirla en el género policial con "La mentirosa", estrenada en el cine Ocean; en una de las escenas, el impacto de una bala perfora la luneta trasera del automóvil y el personaje de Marshall exclama: «¡Qué lastima, un auto tan nuevo y ya se está apolillando!». Enrique Santos Discépolo, uno de los compositores más relevantes de la época, la incluyó en su siguiente proyecto, "Cándida, la mujer del año" (1943), que perduró solo una semana en cartel y resultó un fracaso comercial. Abel Posadas analizó que «"Hay que educar a Niní" (1940), "Orquesta de señoritas" (1941), "La mentirosa" (1942) y "La mujer sin cabeza" (1947), ofrecen un seductor panorama de ensueño partiendo del mecanismo de la impostura, tan caro al entretenimiento propuesto por Amadori».

Marshall volvió a retomar el género de la parodia cuando fue convocada en 1943 para encabezar "Carmen", inspirada en la ópera de Georges Bizet y considerada la primera superproducción del cine argentino al servicio de una temática cómica. La trama indica que una costurera fanática de "Carmen" cree corporizarse en la protagonista a raíz de un golpe en la cabeza. De acuerdo a Contreras, el filme posee «un poco de célebre ópera, otro poco de literatura y mucho de ingenio y locura». En una de las escenas, el personaje de Carmen debía rodar por las escaleras, motivo por el cual el director propuso contratar una acróbata. Marshall se negó y realizó ella misma la escena, que le provocó una serie de moretones. La revista "Antena" señaló que «Niní es el alma de Carmen y casi puede decirse que toda la película es ella». El éxito inicial hizo que la película fuera generadora de una trilogía que completaron "Madame Sans Gene" y "Mosquita muerta", ambas también basadas en piezas famosas volcadas a la parodia.

El 4 de junio de 1943, un golpe militar conocido como Revolución del 43 destituyó al presidente Ramón S. Castillo, lo que marcó el fin de la denominada Década Infame. Arturo Rawson ocupó el cargo hasta su renuncia tres días más tarde, momento en que fue reemplazado por el coronel Pedro Pablo Ramírez. El 7 de junio, fecha de su llegada al cargo, se creó el Consejo Superior de las Transmisiones Radiotelefónicas, cuya primera resolución fue presentar una larga lista de palabras y locuciones mal empleadas en el lenguaje corriente que debían «proscribirse de la radiofonía». Marshall había firmado un contrato con Radio Splendid por una importante suma de dinero y en sus memorias relató que, al finalizar una de las emisiones, «no pude con mi genio y me despedí diciendo: "Hasta el viernes... si nos dejan"». Marshall no pudo volver a presentarse en radio y su siguiente presentación fue reemplazada por una de Hugo del Carril. Desde la oficina de Radiocomunicaciones, la actriz recibió un comunicado que expresaba que la prohibición había sido llevada a cabo «porque sus personajes deformaban el idioma al pueblo argentino, que no tiene capacidad de discernir». José Ramón Mayo, colaboracionista de Ramírez y hombre comprometido con la defensa del buen uso del idioma, señaló en un reportaje que «miles de personas decían como ella: "¿lo qué?"... Entonces, un día la llamamos y le dijimos que debía morigerar sus libretos. Lo que Niní nunca ha dicho es que nos tomaba el pelo, que con nuestras recomendaciones hacía lo que se le daba la gana».

Marshall parodió la vida de Cathérine Hübscher, la viuda del mariscal francés François Joseph Lefebvre, en "Madame Sans Gêne" (1945), que se convirtió en la película más costosa del cine argentino. Conrado Nalé Roxlo fue el encargado de adaptar la obra teatral de Victoriano Sardou. El filme permaneció diez semanas en cartel y muchos autores coinciden en calificarla como la «película cumbre» de Amadori. La encuesta del "Heraldo" la colocó en el cuarto puesto dentro de las mejores producciones del año y Marshall obtuvo el premio a la mejor actriz cómica de la Asociación de Cronistas Cinematográficos de la Argentina. Luego de estrenar "Santa Cándida" en marzo de 1945, la actriz permaneció sin propuestas de trabajo hasta la temporada siguiente, de modo que dedicó su tiempo a ocuparse de su casa de Recoleta, tomar clases de inglés y pintura, y descansar en su quinta de Moreno. Al año siguiente, fue convocada para protagonizar "Mosquita muerta", basada en una obra de 1883 de Henri Meilhac, donde presentó dos nuevos personajes, Gladys Minerva Pedantone y la Niña Jovita. Las críticas fueron mixtas y si bien no tuvo el mismo éxito que su predecesora, permaneció ocho semanas en cartel en la ciudad y doce en las afueras. Di Núbila la definió como «una bufanada poco cinematográfica y de éxito comercial».

En 1947, Marshall retornó a la radio cuando viajó a Uruguay y realizó una serie de presentaciones en Radio Carve de Montevideo. En Buenos Aires, fue partícipe de la obra teatral "Un lío de millones" en el Teatro Astral. La actriz se entusiasmó con la propuesta y se encargó de retocar los personajes que había elegido representar. El estreno generó una gran concurrencia de público a tal punto que la policía debió abrir paso para que cada uno de los artistas pudiera descender de su automóvil y llegar al "hall" del teatro sin inconvenientes. Sin embargo, la obra solo se mantuvo un mes en cartelera, el plazo mínimo fijado por contrato, y la crítica destruyó al autor y la pieza; Marshall luego diría que «los autores clásicos se metieron con ellos y no les perdonaron que yo los hubiera elegido. Cosas peores se han visto».

En "Una mujer sin cabeza", dirigida nuevamente por Amadori, las buenas críticas no lograron que su permanencia en las salas se extendiera por más de dos semanas. "La Nación" publicó que «el público pudo ver nuevamente cómo llena esta actriz el interés de las escenas con su presencia o su palabra». Marshall volvió a aparecer en un filme de menos de una hora de duración titulado "Buenos Aires canta", que consistía en una serie de cuadros musicales donde se presentaban artistas y conjuntos populares, entre los que destacaban Hugo del Carril y Azucena Maizani. Ahí, interpretó a Loli y cantó una canción popular española. La versión completa del filme desapareció y en la actualidad no existen copias; algunas versiones señalan que pudo haber sido desarmada debido a que se trataba de fragmentos musicales.

Su siguiente película, "Navidad de los pobres", se estrenó en 1947 en el cine Monumental y significó el retorno de Catita luego de seis años fuera de la pantalla. Según "La Prensa", Marshall «constituye el alma y la mejor base de la película». La película fue un éxito y su labor mereció el premio a la mejor actriz cómica de la ACCA. Marshall decidió probar suerte de nuevo con el teatro cuando fue convocada en 1948 para ser la coestrella de Pepe Arias en "Y Pepe volvió con música" en el Teatro Casino, a dos años del fracaso "Un lío de millones". Los actores realizaron tres funciones diarias con dos espectáculos distintos y recibieron críticas positivas, especialmente Marshall, que buscaba consolidarse en el mundo del teatro. Ese mismo año también filmó "Porteña de corazón", donde nuevamente actuó en el rol de Catita a dúo con Augusto Codecá. De acuerdo a Di Núbila, «fue la mejor y más ágil comedia de Catita en bastante tiempo»; sin embargo, otras críticas señalaron que «necesita volver a Madame Sans Gene o a la humana Cándida».

El último trabajo de Marshall con Manuel Romero ocurrió en 1949 con "Mujeres que bailan" y, a pesar del modesto éxito, las críticas se vieron desplazadas por las crónicas de hechos de actualidad. Fanny Navarro, una actriz proveniente del drama, fue una de las integrantes del elenco y su protagónico se destacó por sobre el de Marshall de acuerdo a la mayoría de los medios de prensa. En sus memorias, Marshall manifestó que «nuestra relación fue muy cordial. Ella era una hermosa muchacha, amable y obediente en el trabajo». Durante la filmación de la película, Navarro se hallaba en pareja con Juan Duarte, hermano de Eva Perón y secretario privado del presidente. De acuerdo a Marshall, Navarro la invitó en nombre de Duarte en reiteradas ocasiones para cenar juntos al sostener que era «su actriz favorita» pero la actriz rechazó todas las propuestas «con cortesía pero sin ocultar mi falta de interés por conocerlo».

Un mes después del estreno del filme, Marshall partió hacia Nueva York contratada por Carlos Montalbán para actuar en el Teatro Puerto Rico. El contrato inicial de siete días pronto se extendió a dos semanas y finalizado el mismo, la actriz viajó a México, donde se dispuso a filmar su primera película mexicana, "Una gallega en México", bajo dirección de Julián Soler. El rodaje se alternó con presentaciones en el local nocturno El Patio y en el Casino Follies. Su labor mereció el premio a la mejor actriz del año y "Antena" publicó que «México descubrió a Niní como brillante actriz dramática». Los guiones fueron modificados a razón de dos escenas que dieron la pauta de dotes dramáticas en Marshall y Soler decidió agregar algunas situaciones que explotaran ese perfil en el filme, que posteriormente fue estrenado en Venezuela y Cuba.

Durante el peronismo (1946-1955), la actividad en el mundo del cine había sido intensa pero la suma de favoritismo y censura para todo lo que escapara a la visión oficial había afectado la calidad de las producciones. La escasez de celuloide y la caída de la industria cinematográfica hacía que los proyectos debieran contar con apoyo del Estado. En un contexto de listas negras de artistas vinculados a la oposición, una notable disminución en las realizaciones y la escasa distribución de película virgen, los productores extranjeros ofrecieron nuevas posibilidades a figuras de Argentina. De ese modo, además de recibir propuestas de filmación en México, Marshall fue convocada para filmar en España "Yo no soy la Mata-Hari" (1949), una parodia de la vida de la espía Mata Hari dirigida por Benito Perojo.

De regreso a Buenos Aires, Ángel Mentasti le transmitió a Marshall que debían cancelar todos los proyectos que la convocaban por un pedido expreso de la primera dama Eva Perón. En sus memorias, Marshall relató que ante esa situación decidió pedir una audiencia con el presidente Perón:

Marshall debió emprender el exilio ante la imposibilidad de trabajar en Argentina, al igual que sus pares Libertad Lamarque y Arturo García Buhr. En medio de una investigación realizada a causa de denuncias de corrupción, Juan Duarte fue hallado sin vida en un aparente suicidio en abril de 1953. Tras la Revolución Libertadora, las prohibiciones se volvieron a reiterar, esta vez con los artistas vinculados al peronismo, entre los que destacaban Fanny Navarro. La carrera de Navarro declinó seriamente a partir de 1955 y solo volvió a filmar tres películas más en la década siguiente. Murió prematuramente en 1971, olvidada por el público y alejada del medio artístico.

Marshall viajó a México y se estableció en la Casa Latinoamericana, un edificio de departamentos donde se hospedaban otros artistas en similar situación como Amanda Ledesma y Libertad Lamarque, con la que mantuvo una íntima amistad hasta su muerte. Su primer trabajo mexicano luego de su exilio fue junto a Joaquín Pardavé en "Una gallega baila mambo", nunca estrenada oficialmente en Argentina. Entre 1950 y 1951, Marshall filmó en México cuatro películas: "Una gallega baila mambo", "La alegre casada", "Mi campeón" —junto a Lamarque— y "Los enredos de una gallega", que se estrenaron luego en Argentina en salas de segunda categoría del interior del país. Retomó al género de la sátira cuando decidió filmar en 1952 "Amor de locura", considerado una de sus mejores labores mexicanas. En 1953, Marshall intervino en "Reportaje", una película en donde actuó junto a Jorge Negrete, María Félix, Arturo de Córdova, Dolores del Río y Pedro Infante, elenco que participó sin recibir remuneración alguna. La película fue estrenada de manera inadvertida en Argentina en 1956 y Marshall, al igual que otros actores, no fueron incluidos en el armado final ni en los créditos. El último trabajo de la actriz íntegramente armado en México fue "Dios los cría", una comedia de 1953 con exteriores rodados en la ciudad, Chapultepec y Fuente de Petroleros.

A lo largo de su estadía en ese país, Marshall diseñó dos nuevos personajes, Bárbara Mac Adam, una turista mexicana que gusta vestirse con todas las prendas típicas, y Lupe, una pueblerina maltratada por su marido. La actriz los presentó en Argentina durante una actuación en Radio Belgrano en 1954 pero no tuvieron repercusión. A la muerte de Evita, con su hija a punto de casarse y finalizada una gira que la llevó por Colombia, Perú y Chile, Marshall retornó definitivamente a Buenos Aires en 1954. A pesar de que su prohibición en cine continuaba vigente, recibió una citación por parte de Raúl Apold, secretario de Prensa del gobierno, que le afirmó en su despacho que volvería a trabajar al mismo tiempo que le ofreció participar en un festival organizado por la Secretaría de Prensa en el Teatro Presidente Alvear, propuesta que la actriz rechazó alegando no querer intervenir en actos de gobierno. En cambio, optó por realizar una función radiofónica para Radio Belgrano en la sala del Consejo Nacional de Mujeres y filmar una coproducción cubano-mexicana, "Una gallega en La Habana" (1955), dirigida por René Cardona.

En marzo de 1956, Marshall participó en festivales, colectas y funciones a beneficio de los niños enfermos de poliomielitis, un gesto de solidaridad similar al de 1944, cuando participó de una convocatoria dirigida a artistas por parte del GOU —encabezado por Juan Domingo Perón— con el fin de recaudar fondos para las víctimas del terremoto de San Juan. En esa ocasión, Marshall fue condecorada por haber recaudado la mayor cantidad de dinero —4964 pesos, más 1000 aportados por ella misma—.

Su retorno al cine argentino ocurrió en 1956 cuando estrenó "Catita es una dama", que no tuvo una buena recepción en críticas y solo perduró una semana en las salas de cine. En ese momento, Marshall percibió que el público había cambiado con respecto al de la década anterior y que debía adecuarse al presente. Continuó actuando en radio, su medio preferido, hasta que en 1957 debutó por primera vez en televisión, en un ciclo denominado "Philco Music Hall", que la catalogó como la «artista más costosa de la televisión argentina» al percibir una remuneración de 50 000 pesos por cada emisión. En 1958, debutó en radio con Guillermo Brizuela Méndez y durante una de sus actuaciones, presentó el personaje de Don Cosme. Poco después, recibió una carta de un médico del Hospital Ramos Mejía manifestándole que la voz del personaje era muy peligrosa para sus cuerdas vocales, motivo por el que inmediatamente dejó de interpretarlo. Tras una presentación en Radio Nacional de España, regresó a Argentina para lanzar su propio ciclo de televisión, "Esas cosas de Niní", emitido durante 1960 por Canal 7. Sin embargo, no tuvo la prensa suficiente y duró demasiado poco. Marshall se halló desconcertada ya que el formato del programa, que consistía en monologar frente a la cámara, era el mismo que utilizaba Bob Hope con éxito en Estados Unidos.

En 1961, fue convocada por Manolo Fábregas para actuar en el Teatro de los Insurgentes de México con "Cosas de mamá y papá", labor por la que obtuvo el premio a la mejor actriz del año de la Asociación de Cronistas Teatrales Mexicanos. A su regreso, presentó la obra adaptada para el público argentino en el Teatro Odeón, que significó su retorno a los escenarios después de catorce años. Según "La Nación", «fue durante la permanencia de Niní en el escenario que la obra alcanzó mayor animación». Una versión para televisión se llevó a cabo poco después. Su siguiente obra fue "Buenos Aires de seda y percal", una cabalgata musical con 18 cuadros musicales que recreaba la vida de la ciudad desde 1930 hasta 1963. Sin embargo, al igual que "La señora barba azul", en la que también participó su hija Ángela, no tuvo publicidad y las recaudaciones no alcanzaron las expectativas.

Marshall retornó al cine luego de ocho años con "Cleopatra era Cándida" en 1964, que resultó un fracaso al igual que todos los filmes que lo sucedieron hasta el final de su carrera. Entre 1967 y 1971, logró intervenir en cuatro películas más —"Escándalo en la familia", "Ya tiene comisario el pueblo" (la primera a color), "La novela de un joven pobre" y "Vamos a soñar por el amor"—, en general producciones comerciales destinadas a dar a conocer a algún joven cantante de la época. La carrera de Marshall pareció resurgir hacia 1967 cuando sus presentaciones en el ciclo "Sábados circulares" de Pipo Mancera comenzaron a adquirir popularidad. Sus espacios al aire se iniciaron con cinco minutos de duración y al poco tiempo, se extendieron a veinte sin publicidad intermedia. La actriz, por su parte, no se hallaba cómoda con la televisión en vivo: «... se hace todo tan rápido, tan improvisado. Si uno no se acuerda la letra le ponen en las narices un tremendo cartel para que lo lea». Si bien Marshall juzgaba con severidad la falta de independencia y hostilidad de la TV, sus presentaciones alcanzaron entre 30 y 40 puntos de audiencia. El éxito con Mancera la motivó para lanzar de nuevo un programa propio, "Teatralerías", pero fue un fracaso rotundo y el ciclo no soportó los desniveles de audiencia.

En 1969, presentó en teatro una versión musical de "Las de Barranco", "Recuerdo del viejo Buenos Aires". El proyecto le generó entusiasmo pero la obra se ubicó en el séptimo lugar entre los espectáculos más vistos y progresivamente descendió hasta el décimo primero. Marshall interpretó a Victoria Valdor, una tía alocada y sensual, en "Coqueluche", donde apareció con una peluca rubia. La obra se estrenó en 1971 en Mar del Plata y permaneció con éxito toda la temporada de verano pero, a pesar de la repercusión, la actriz abandonó el trabajo y fue reemplazada por Noemí Laserre.

En 1972, Lino Patalano se hallaba en búsqueda de un espectáculo para montar y mientras husmeaba una revista, leyó una entrevista de Marshall donde anunciaba su retiro. Patalano consiguió su teléfono y se comunicó inmediatamente con el fin de convencerla para llevar a cabo un espectáculo de "café-concert". Luego de insistir durante seis meses, la actriz aceptó la propuesta y Patalano recordó que en una ocasión Marshall le enseñó unos libretos de "Y... se nos fue redepente", un espectáculo de humor negro que había redactado en los años de 1940 y nunca había podido estrenar. Patalano destacó que Marshall era extremadamente tímida y «todo anduvo sobre ruedas hasta que el día del ensayo general, Niní nos dijo: "¡Chicos, yo los indemnizo pero no debuto!"», a lo que reaccionó: «Señora, con todo el respeto, ¡déjese de embromar! Váyase al hotel y mañana venga para la función». En entrevistas posteriores, comentó que los productores «estuvimos hasta la noche cortando clavos». El espectáculo se presentó en 1973 en El Gallo Cojo Kabarett, fue un éxito y se prolongó durante 1800 funciones que se llevaron a cabo en Buenos Aires, Rosario, Córdoba, Montevideo, Santiago de Chile y Lima. También se realizó un especial para televisión emitido en 1979 por Canal 13 y en 1986 un disco; la edad de Marshall y otros proyectos disolvieron la idea de llevar el espectáculo a Estados Unidos, México y Venezuela. La representación transcurría en un solo escenario, el velatorio del zapatero Don Pascual, alrededor del cual la actriz recreó toda su galería de personajes, que se acercaban a darle el pésame a la viuda Electra.

En 1975, recibió un premio Martín Fierro a título de homenaje junto con otras figuras del espectáculo como Libertad Lamarque, Tita Merello y Mirtha Legrand. Un año después, Marshall se disponía a estrenar "El pequeño Marshall-Luz ilustrado" junto a Jorge Luz cuando sufrió un aneurisma y debió suspender el proyecto como así también "Y... se nos fue redepente", que retomó luego de su recuperación. Luego, fue convocada para una breve temporada de "Una noche en la radio" que, gracias a su éxito, fue extendida y presentada en Mar del Plata. En 1977, durante tan solo tres días, Marshall grabó un especial televisivo para Canal 13 titulado "El humor de Niní Marshall", presentado dentro del ciclo "El mundo del espectáculo".

En 1980, tras haber rechazado el papel central de "La nona", filmó su última película, "¡Qué linda es mi familia!", junto a Palito Ortega y Luis Sandrini. Mientras se tomaban fotografías el último día de rodaje, Sandrini sufrió un colapso vascular, fue internado y falleció once días después. La película inicialmente iba a llamarse "La familia está de fiesta" pero los productores optaron por modificar el título ante el deceso del actor. Marshall, profundamente afectada, no fue capaz de ver la película nunca más. Al año siguiente recibió el premio Konex de Platino como mejor actriz cómica. Sus trabajos finales incluyeron treinta emisiones en un ciclo radiofónico junto a Antonio Carrizo y una participación especial en el programa de TV "Juntos" de 1982, tras los cuales decidió retirarse y, en sus propias palabras, «no asistir a sus propios funerales».

Marshall lanzó sus memorias en 1985 con la colaboración de Salvador D'Anna y un año después, donó parte de los vestuarios de sus personajes al Museo del Cine. En 1988, interrumpió su retiro para actuar como Doña Caterina en una emisión del ciclo de televisión "El mundo de Antonio Gasalla". La actriz definió su participación ahí como «un horror». Hacia el final de su vida, comenzó a recibir honores y reconocimientos por su larga trayectoria en el espectáculo. En 1989, fue declarada Ciudadana ilustre de la Ciudad de Buenos Aires por la Legislatura porteña y en 1992, recibió el premio Podestá a la Trayectoria de manos de Mirtha Legrand, que casualmente había debutado como extra en una de sus películas. Ese mismo año fue internada en terapia intensiva durante diez días y se temió por su vida.

En junio de 1992, Marshall cedió los derechos de sus guiones para ser representados en París en el espectáculo "Mortadela" y a pesar de su avanzada edad, se encargó personalmente de supervisar la traducción de los mismos al francés. Marilú Marini fue la encargada de recrear sus personajes y la obra recibió el Premio Molière a la mejor comedia musical. Marshall asistió entre lágrimas al estreno en el Teatro Lola Membrives de Buenos Aires, donde fue ovacionada y se le dedicó la función. En 1995, se estrenó "Niní", una obra similar representada en el Teatro Petit Montparnasse, también protagonizada por Marini. Al igual que con la anterior, Marshall asistió al estreno en el Teatro Maipo y comentó que «me costó mucho firmar el contrato para que mis textos sean actuados por otra persona. Y todavía debo confesar que me gustaría estar arriba de un escenario». Cuando el público más joven se acercaba a saludarla y reía con sus personajes, solía decir: «Hay una cuarta generación que me aguanta».

La última aparición pública de Marshall ocurrió en diciembre de 1995 cuando, visiblemente débil y frágil, asistió al Teatro Nacional Cervantes para acompañar a su amiga Libertad Lamarque en el homenaje que le brindó la Secretaria de Cultura de la Nación.

En enero de 1996, Marshall fue ingresada en la Clínica Bazterrica de la Recoleta por molestias de origen respiratorio. La noticia no se hizo pública hasta tres días después y las autoridades de la institución no dieron demasiados detalles por pedido expreso de su familia. El 8 de marzo, fue nuevamente internada en terapia intensiva por una afección respiratoria y un cuadro severo de deshidratación que le provocaron una descompensación general y un progresivo desmejoramiento físico. Marshall falleció a la edad de 92 años el 18 de marzo de 1996 a las 11.05 UTC-3 a causa de un paro cardiorrespiratorio. Sus restos fueron velados en el Teatro Nacional Cervantes y trasladados a la bóveda familiar del cementerio de Olivos.

Marshall contrajo matrimonio en 1924 con Felipe Edelmann, un ingeniero ruso mucho mayor que ella y educado en Alemania, con el que tuvo a su única hija, Ángela, nacida en 1926. Edelmann era ludópata y perdió todo sus bienes a causa del juego, entre ellos la casa donde convivía con Marshall, motivo por el cual la actriz decidió separarse: «el día que me enteré me recibí de adulta. Quedé sola frente a las circunstancias... una sola cosa me importó: quedarme con mi hija», manifestó en una ocasión. Edelmann falleció en julio de 1957.

Cuando comenzó a actuar en radio, conoció a Marcelo Salcedo, un contador paraguayo de una empresa yerbatera, con el que se casó vía México poco después. Salcedo acompañó a Marshall a lo largo de su carrera en los años de 1930 y 1940 pero optaron por separarse en 1950 cuando la actriz debió exiliarse en México. En 1953, durante su estadía en la Casa Latinoamericana, inició una relación con el productor y periodista Carmelo Santiago, que se convirtió rápidamente en su representante y con quien convivió durante 15 años hasta 1968, cuando descubrió que le era infiel. Santiago falleció en agosto de 1993.

Marshall vivió la mayor parte de su vida en el barrio porteño de Recoleta, frente a la Plaza Vicente López, donde desarrolló afición por la pintura, la lectura y el coleccionismo de antigüedades. Su nieto Carlos Gamallo incursionó como actor en seis películas argentinas entre 1993 y 2004, entre las que destacan "Gatica, el Mono". Su sobrina nieta, Susana Degoy (1943-2008), fue una escritora y ensayista especializada en la investigación de la sociología del espectáculo. La hija de Degoy, sobrina bisnieta de Marshall, es la actriz ítalo-argentina Antonella Costa.

María Elena Walsh la definió como «Nuestra Cervantes» y explicó que «solo un prodigioso dominio del idioma le permitió a Niní descalabrarlo, travestirlo y lanzarlo a las efímeras ondas del éter». Su talento para reproducir los rasgos del habla de distintos sectores sociales o de colectividades fue un aporte no solo para sus monólogos sino también para la investigación filológica; la Facultad de Humanidades y Ciencias de la Educación de la Universidad Nacional de La Plata registró grabaciones con Marshall en los años de 1950 para estudiar las particularidades lingüísticas de sus personajes. De acuerdo a Dora Cerati, que compiló media docena de compactos históricos de sus programas de radio: «A la manera de una Mafalda adulta, Niní sacó a luz una clase social relegada a la que le hizo decir o ridiculizar lo "snob", lo superfluo, pero sin groserías, sin palabras soeces, sin golpes bajos». Marshall hizo visible, a través del humor, a la clase inmigratoria, que en los años de 1940 y 1950 abarcaba gran parte de la población nacional y era un sector discriminado por las minorías. Su hija Ángela Edelmann señaló en un reportaje que su madre se destacó por encima del resto de las cómicas de su generación ya que «escribía, dirigía, actuaba, vestía, maquillaba» sus personajes. Enrique Pinti se refirió también a ese punto y destacó que Marshall «construía sus propios personajes y, por eso, es bastante incomparable... Niní lo concebía desde una manera global».

En 1999, la familia de Marshall, en colaboración con el sello discográfico Gogni y Vea Más Multimedios, lanzaron tres discos compactos que recopilaron sus monólogos más exitosos. Desde el 2000, la residencia donde vivió en su niñez y en su adolescencia, la Casa de los Querubines, es sede del Museo de la Ciudad. Un año antes se había colocado una placa a modo de tributo.

El Correo Argentino honró la memoria de Marshall cuando en 2002 lanzó una serie limitada de estampillas postales con su rostro. En 2003, en conmemoración a su centenario, se realizaron varios homenajes en su honor, entre los que destacan una muestra retrospectiva con fotos, vestuarios y libretos denominada "Niní cumple 100 años" en el Centro Cultural Recoleta y la proyección de sus filmes principales en la sala Leopoldo Lugones. Paralelamente, la señal de cable Volver emitió un ciclo especial con sus películas y las autoras Patricia Narváez y Marily Contreras publicaron dos libros biográficos. En 2005, Raúl Etchelet estrenó el documental "La película de Niní", basado en un libro biográfico del mismo autor, que contiene testimonios, material fílmico y narra la vida de Marshall.

En 1996, "Clarín" llevó a cabo una encuesta popular sobre los artistas argentinos y Marshall resultó poseedora del cuarto puesto en el rubro de la «artista más querida de todos los tiempos» con un 10.2% y la «más talentosa» con un 7.3%. El mismo periódico realizó otra similar en 2005 y ahí obtuvo el segundo puesto en la sección del «mejor cómico de toda la historia argentina» con un 10.3%, solamente precedida por Alberto Olmedo. La revista "Viva" la incluyó dentro de «las diez argentinas del siglo XX» en 1999 y en una encuesta efectuada ese mismo año, resultó elegida «la actriz cómica de todos los tiempos».

El Museo del Cine Pablo Ducrós Hicken cuenta con una sala Niní Marshall, que reúne fotografías, cuadros, vestimentas y elementos cinematográficos que se usaron alguna vez en las películas protagonizadas por la actriz, así como también objetos personales. Un pasaje junto al Teatro Candilejas en Villa Carlos Paz y un anfiteatro de la Costanera Sur también fueron designados con su nombre. En 2009, una calle de Puerto Madero fue bautizada Niní Marshall por votación popular y en 2011, en conmemoración a los 15 años de su deceso, se inauguró un teatro con su nombre en el partido bonaerense de Tigre, apadrinado por la actriz Norma Aleandro y declarado de interés municipal por el intendente Sergio Massa.

Marshall fue interpretada por la actriz Alejandra Majluf en la película biográfica "Ay, Juancito" (2004), dirigida por Héctor Olivera. El filme está basado en la vida política de Juan Duarte y su vínculo con el mundo del espectáculo.

Desde el año 2015 la escuela de nivel secundario de teatro número 1, ubicada en el barrio de mataderos, lleva el nombre de Nini Marshall en su honor.

Marshall tenía una observación minuciosa y sagaz de la sociedad de la época, recurso que le permitió crear sus personajes y reflejar en ellos las particularidades y defectos de las distintas clases sociales a través de la exageración. Sus personajes recreaban la idiosincrasia argentina y se convirtieron en arquetipos de la inmigración europea que llegó a América a comienzos del siglo XX.

Marshall fundamentó la creación de sus personajes basada en la observación y la exageración:

La psicóloga Ana Padovani señaló en un reportaje que Marshall «hizo un trabajo interesantísimo con la palabra. Ella lograba un bordado textual a partir de la observación minuciosa de las corrientes inmigratorias, de las formas de hablar, de las costumbres. No tiene una producción literaria en el sentido estricto, pero considero que tiene bien ganado el estatus de escritora». Por su parte, María Moreno, en un artículo en "Página/12", apuntó que «la actriz llevaba sus registros orales a una exageración tal que, no solo se volvían críticos sino que terminaban constituyendo, lejos de rasgos típicos, singularidades fecundas en creación e ingenio».

Los personajes más emblemáticos de Marshall fueron Cándida y Catita; la primera personificaba a las empleadas domésticas gallegas que se expresaban de manera errónea y la segunda a las mujeres típicas de conventillo provenientes de una familia italiana. También interpretó otros personajes destacados tales como doña Pola, estereotipo de la colectividad judía, Mónica Bedoya Hueyo de Picos Pardos Sunsuet Crostón, la típica mujer de clase alta y superficial, la Niña Jovita, una solterona pasada de moda, Gladys Minerva Pedantoni, la alumna más aplicada de la clase, y doña Caterina, la abuela italiana de Catita que habla en cocoliche. Otros personajes fueron constituidos bajo la misma estructura pero no tuvieron la misma repercusión, tal es el caso de Don Cosme, un italiano de voz ronca, Lupe, una joven sufrida y maltratada por su esposo, Belarmina Cueio, una joven provinciana y empleada doméstica de la Niña Jovita, Loli, una actriz y cupletista pasada de moda, Mingo, el hermano travieso de Catita, y Bárbara Mc Adam, una mujer refinada y extravagante estereotipo de la clase alta mexicana. Los personajes de Mingo y Catita ideados por Marshall tuvieron más tarde sus paralelos en los de Minguito Tinguitella y la Porota, interpretados con éxito por Juan Carlos Altavista y Jorge Luz en la década de 1980 respectivamente.

Durante sus 50 años de carrera profesional, Marshall intervino en 38 películas —28 en Argentina, 9 en México y una en España— más 10 participaciones en ciclos de televisión. Su filmografía está compuesta por comedias y comprendida entre 1938 y 1980, período en el que también se dedicó al teatro y la radio.







</doc>
<doc id="45243" url="https://es.wikipedia.org/wiki?curid=45243" title="Luis César Amadori">
Luis César Amadori

Luis César Amadori (Pescara, Italia, 28 de mayo de 1902 - Buenos Aires, Argentina, 5 de junio de 1977) fue un director de cine, guionista, escritor, músico, letrista y productor argentino nacido en Italia.

Luis César Amadori fue una notable e insoslayable figura de la época dorada del cine, teatro y del tango argentino. Nacido en Italia emigró a los 5 años a Argentina. Comenzó sus estudios en una escuela primaria de Villa Ballester e hizo el bachillerato en el Colegio De La Salle Buenos Aires. Cursó sus estudios universitarios de medicina en Córdoba en 1918, si bien los abandonó en favor de su vocación de escritor y adaptador de comedias francesas.

Fue elegido por Walt Disney para dirigir el doblaje al español de 4 de sus propios filmes, "Fantasía", "Pinocho", "Dumbo" y "Bambi"; el director de fotografía de su película "Madreselva" fue el húngaro John Alton, quien luego desarrolló su carrera en Hollywood. Como guionista cinematográfico utilizó el seudónimo de Gabriel Peña, como autor de revistas musicales el de "Leo Carter"; sus íntimos lo llamaban "Gino".

La dictadura Militar de 1955 decretó la proscripción del peronismo y de todo aquello que lo refiriese, por lo que, con cargos ficticios fue apresado junto con otros como Hugo del Carril y Atilio Mentasti.En 1955 emigró a España debido al golpe de Estado contra Juan Perón que instauró la auto-denominada Revolución Libertadora y comenzó a perseguirlo por sus ideas políticas. Se convirtió así en una de las figuras de la dirección en el cine español de los 50 y los 60, sobre todo de corte histórico.

Se inició con Ivo Pelay para estrenar en el Teatro Nuevo una adaptación francesa titulado "Un buen muchacho". Luego pasó al Teatro Comedia y, finalmente, se desempeñó por largo tiempo como empresario del Teatro Maipo ( en 1940 compra la sala) donde montó decenas de espectáculos de revista. Incursionó también en el teatro lírico.

Fue directivo de Argentores y ejerció la crítica musical en más de 150 piezas teatrales y varios libros cinematográficos.

Tuvo su único hijo varón Luis Alberto Amadori, quien tuvo junto a la célebre actriz de cine Zully Moreno (1920-1999), casado desde 1947. Murió en su domicilio en Buenos Aires el 5 de junio de 1977 a los 75 años.

Referencias:


</doc>
<doc id="45244" url="https://es.wikipedia.org/wiki?curid=45244" title="Dios se lo pague">
Dios se lo pague

Dios se lo pague es una película argentina de 1947 dirigida por Luis César Amadori, protagonizada por Zully Moreno y Arturo de Córdova.

Es una adaptación de la obra teatral ""Dios se lo pague"" de Joracy Camargo.

Fue la primera película argentina elegida por la Academia de las Artes y las Ciencias Cinematográficas de Hollywood para optar por una distinción como mejor película extranjera en los .

Se estrenó el 16 de marzo de 1948 en Mar del Plata, inaugurando el Primer Festival de Cine Argentino, organizado por el gobierno de la Provincia de Buenos Aires.

En 1981 se realizó en Argentina una versión televisiva en formato de telenovela con libro de Vicente Sesso y traducción de Elisa Cambaceres de Serra por A.T.C. Argentina Televisora Color (Canal 7), protagonizada por Víctor Hugo Vieyra y Leonor Benedetto.

En 1998 se realizó la versión colombiana de "Dios se lo pague"; se trata de la telenovela que inaugura el Canal Caracol, protagonizada por Margarita Ortega y Jairo Camargo y realizada por DFL Televisión.
Una mujer jugadora, Nancy, que ostenta su elegancia para disimular su pobreza mientras espera que un hombre adinerado aparezca y se ocupe de ella, conversa con el viejo que mendiga en la puerta de un casino. Poco después, un pretendiente rico y misterioso le ofrece una vida de lujos, aunque alejada de las convenciones sociales

5 Premios de la Academia de las Artes y Ciencias Cinematográficas de la Argentina.

Además la Academia de las Artes y Ciencias Cinematográficas de la Argentina otorgó 3 plaquetas académicas y diplomas por sus contribuciones a la película:




</doc>
<doc id="45246" url="https://es.wikipedia.org/wiki?curid=45246" title="El extraño caso del hombre y la bestia">
El extraño caso del hombre y la bestia

El extraño caso del hombre y la bestia es una película argentina del director Mario Soffici estrenada en 1951. 


El guion fue realizado por Ulyses Petit de Murat, la fotografía por Antonio Merayo, escenografía de Gori Muñoz y dirección musical de Silvio Vernazza. Es una adaptación de la novela "El extraño caso del doctor Jekyll y míster Hyde", de Robert Louis Stevenson.




</doc>
<doc id="45249" url="https://es.wikipedia.org/wiki?curid=45249" title="Orbifold">
Orbifold

En topología, orbifold (Orbidad u orbivariedad) es la generalización de una variedad diferenciable, consistente en un espacio topológico (llamado espacio subyacente) con una estructura de "orbifold" (véase abajo). El espacio subyacente localmente aparece como un cociente de un espacio euclídeo bajo la acción de un grupo finito de isometrías. 

El ejemplo principal del espacio subyacente es un espacio cociente de una variedad bajo la acción de un grupo finito de difeomorfismos. En particular, una variedad con borde lleva una estructura natural de "orbifold", puesto que es Z-factor de su doblado. Un espacio factor de una variedad a lo largo de una S-acción diferenciable sin puntos fijos lleva estructura de orbifold (este no es un caso particular del ejemplo principal). 

La estructura de orbifold da una estratificación natural para las variedades abiertas en su espacio subyacente, donde cada estrato corresponde a un conjunto de puntos singulares del mismo tipo.

Debe ser observado que un espacio topológico puede llevar muchas estructuras de orbifold diversas. Por ejemplo, considere "O" el orbifold asociado a un espacio factor de la 2-esfera a lo largo de una rotación de π, es homeomorfo a la 2-esfera, pero la estructura natural de orbifold es diferente.

Es posible adoptar la mayoría de las propiedades de variedades a los orbifolds y estas propiedades son generalmente diferentes de las propiedades correspondientes del espacio subyacente. En el ejemplo antedicho, su "grupo fundamental de orbifold" es Z y su "característica euleriana de orbifold" es 1.

La definición formal sigue las mismas líneas que una definición de variedad, pero en vez de tomar dominios en R como los espacios 'blanco' de las cartas se debe tomar dominios de cocientes finitos de R. 

Un orbifold (topológico) "O", es un espacio topológico "X" de Hausdorff con base numerable, llamado el espacio subyacente, con una estructura de orbifold, que es definida por el atlas de orbifold (véase abajo). 

Una carta de orbifold es un subconjunto abierto "U" ⊆ "X" junto con un conjunto abierto "V" ⊆ R y una función continua φ : "V" → "U" que satisfacen la propiedad siguiente: hay un grupo finito Γ que actúa linealmente en "V" y un homeomorfismo θ : "V"/Γ → "U" tal que φ=θoπ, donde π denota la proyección "V" → "V"/Γ. 

Una colección de las cartas {φ:"V" → "U"} del orbifold se llama atlas del orbifold si satisface las propiedades siguientes: 

El atlas de orbifold define la estructura de orbifold totalmente y miramos dos atlas de orbifold de "X" como dando la misma estructura de orbifold si pueden ser combinados para dar un atlas más grande de orbifold. Uno puede agregar condiciones del diferenciabilidad en la función de pegado ψ en la definición anterior y conseguir una definición de orbifold diferenciable de la misma manera que fue hecha para las variedades. 

La "V"-variedad de Ichiro Satake (1956) proporcionó la primera definición formal de lo que ahora se llama "orbifold". Fue retitulado de esta manera y popularizado por William Thurston.



</doc>
<doc id="45254" url="https://es.wikipedia.org/wiki?curid=45254" title="Idioma frigio">
Idioma frigio

El idioma frigio fue la lengua indoeuropea de los frigios, pueblo que migró desde Tracia hasta Asia Menor alrededor del 1200 a. C.

Para el siglo VI, ya estaba extinto, pero podemos reconstruir algunas palabras con la ayuda de algunas inscripciones grabadas con una escritura similar a la del griego. 

Se cree que tenía similitud con el tracio y el armenio, y que a la vez habría tenido algunas características del griego, idioma con el que estuvo en contacto algún tiempo.

Los historiadores de la antigüedad y los mitos asocian en ocasiones el frigio con el tracio, e incluso con el armenio en algunas fuentes clásicas. Heródoto recoge el relato macedonio que cuenta que los frigios emigraron a Asia Menor desde Tracia (7,73). Más adelante en el texto (7,73), Heródoto afirma que los armenios fueron colonizados por los frigios, ocurriendo esto en la época de Jerjes I. La primera mención del frigio en las fuentes griegas, en el "Himno homérico a Afrodita", que lo describe como diferente del troyano. Del troyano, lamentablemente, se sabe poco aunque ciertas evidencias han conducido a especular su posible relación con el luwita.

El frigio está atestiguado por dos corpus lingüísticos, uno de alrededor de 800 a. C. y posterior (paleofrigio), y posteriormente, después de un período de varios siglos, al comienzo del I siglo D.C. (Neo-Frigio). El corpus palaeo-frigio se divide (geográficamente) en las inscripciones de la ciudad de Midas de la ciudad (M, W), Gordión, Central (C), Bitinia (B), Pteria (P), Tyana (T), Daskyleion (Dask), Bayindir (Bahía), y "varios" (Dd, documentos diversos). Las inscripciones misias parecen estar en una lengua relacionada el idioma misio (en un alfabeto con una letra adicional, "s misia").

Sobrevivió al menos hasta el siglo VI d. C.. Podemos reconstruir algunas palabras con la ayuda de algunas inscripciones con textos bilingües al griego.

El idioma frigio estaba probablemente emparentado con el tracio, armenio o griego. En la mayoría de los casos el idioma frigio usaba un alfabeto derivado de los fenicios. Las inscripciones disponibles en el idioma frigio todavía no se han traducido. Las inscripciones que utilizan una escritura cercana a la griega, han sido traducidos, y parte del vocabulario frigio ha sido identificado.

Respecto a su estructura, lo que puede recuperarse a partir de él, es claramente indoeuropeo, con nombres declinados en casos (al menos cuatro), de género (tres) y el número (singular y plural), mientras que los verbos se conjugan por tiempo, la voz, el modo, persona y número. No hay una sola palabra que atestigüe todas sus formas de flexión. 

Muchas palabras del frigio son muy similares a la reconstruida lengua Proto-indoeuropea (PIE). El frigio parece presentar un aumento, al igual que el griego y el armenio, cf "Eberet", probablemente correspondiente a PIE "*e-bher-et" (griego, "epheret").

Muchas palabras frigias son teóricamente conocidas, sin embargo, el significado y etimologías e incluso la epigrafía de muchas palabras frigias (en su mayoría extraídas de inscripciones) son todavía objeto de debate. 

Entre los rasgos conocidos del frigio se cuentan:


- PIE *d(e)iwos > "tios" 'dios'
- PIE *bhg̑os > "bekos" 'pan'
- PIE *g̑enhsa > "kena" 'generación' (cfr, griego "génea")
- PIE *gnehika > "knaika" 'esposa'.


- PIE hnewn > "inn" 'nueve' <br>
- PIE hreg-o > "erek" 'tarde' (griego "érebos" 'oscuridad') <br>
- PIE hster > "astel" 'estrella'<br>
- PIE hnehmn > "onoman" 'nombre' (latín "nomen"< hnehmn)<br>
Una famosa palabra frigia es "bekos", que significa "pan". Según Heródoto (Historias 2,9) el faraón Psamético I quería establecer el idioma original de la humanidad. A tal efecto, ordenó que dos niños fuesen criados por un pastor, que prohíbe dejarles escuchar a los niños una sola palabra, y encargándole de informarle de las primeras palabras de estos. Después de dos años, el pastor informó que al entrar en su habitación, los niños llegaron hasta él, y extendiendo las manos, dijeron "bekos". Investigando, el faraón descubrió que se trataba de la palabra frigia para decir "pan de trigo", después los egipcios reconocieron a los frigios como una nación más antigua que la suya. La palabra bekos se ponían también de manifiesto varias veces en las inscripciones Paleo-frigias en estelas funerarias. Muchos estudiosos modernos sugieren que se trata de afines al inglés "bake", hornear (PIE *bheHg-).

De acuerdo con Clemente de Alejandría, la palabra frigia "bedu" (βέδυ) significa "agua" (PIE * Mié) aparece en ritual Órficos. En la misma fuente, los macedonios decían que adoraban a un dios llamado "Bedu", que se interpreta como "aire".



</doc>
<doc id="45260" url="https://es.wikipedia.org/wiki?curid=45260" title="Portable.NET">
Portable.NET

Portable.NET es una "suite" de herramientas de software libre para compilar y ejecutar aplicaciones para la "Common Language Infrastructure", más conocida como .NET.

La plataforma inicial para la que se desarrolló fue GNU/Linux, pero DotGNU Portable.NET funciona también bajo Windows, NetBSD, FreeBSD, Solaris, y Mac OS X, entre otros. Además corre en una gran variedad de arquitecturas: x86, PPC, ARM, Sparc, s390, Alpha, ia-64, y PARISC.

DotGNU Portable.NET busca la compatibilidad con las especificaciones ECMA-334 y ECMA-335 para C# y CLI, y con la implementación comercial.NET de Microsoft. El principal objetivo es facilitar el desarrollo de aplicaciones portátiles que funcionen tanto en la plataforma DotGNU Portable.NET como en Microsoft.NET.

El proyecto Portable.NET tiene muchas semejanzas con el proyecto Mono de Novell. Ambos intentan proporcionar una alternativa a la tecnología.NET desarrollando una implementación libre del marco de aplicaciones y servicios.NET de Microsoft.

Los componentes principales de la suite son: treecc, pnet, pnetlib, a los que se suman los siguientes componentes opcionales: pnetc, ml-pnet y cscctest

contiene el entorno de ejecución, el compilador de C# y otras herramientas de desarrollo.

Contiene las bibliotecas principales de C#, incluyendo: mscorlib, System, System.Xml, System.Drawing, System.Windows.Forms, etc. 

Herramienta de programación complementaria de Flex y Bison utilizada para ayudar en el desarrollo del compilador de portable.net, cscc.

Es la biblioteca para el compilador de C basada en glibc. 

Algunas de las bibliotecas de mono son utilizadas junto con scripts de DotGNU que permiten utilizarlas con las herramientas de DotGNU.

Se utiliza la orden codice_1 seguida del nombre del ejecutable, con o sin su extensión.

ilrun puede registrarse en el núcleo Linux de la siguiente manera: codice_2; esto permite ejecutar el programa sin necesidad de teclear codice_1 cada vez. ilrun puede ser desregistrado de la siguiente manera: codice_4. 




</doc>
<doc id="45261" url="https://es.wikipedia.org/wiki?curid=45261" title="Espacio de Banach">
Espacio de Banach

En matemáticas, un espacio de Banach, llamado así en honor del matemático polaco, Stefan Banach, es uno de los objetos de estudio más importantes en análisis funcional. Un espacio de Banach es típicamente un espacio de funciones de dimensión infinita.

Un espacio de Banach es un espacio vectorial normado y completo en la métrica definida por su norma. Esto quiere decir que un espacio de Banach es un espacio vectorial formula_1 sobre el cuerpo de los números reales o el de los complejos con una norma ||·|| tal que toda sucesión de Cauchy (con respecto a la métrica "d"("x", "y") = ||"x" - "y"||) en "V" tiene un límite en "V".

De aquí en adelante, formula_2 designará uno de los cuerpos formula_3 o formula_4:

Si formula_9 es un número real, podemos considerar el espacio de todas las sucesiones infinitas formula_10 de elementos en formula_11 tales que la serie infinita formula_12 es finita. Entonces se define la formula_13-norma (o norma-formula_13) de la sucesión como la raíz formula_13-ésima del valor de la serie. Este espacio, junto a su norma, es un espacio de Banach; se denota por formula_8:

El espacio de Banach formula_17 consiste en todas las sucesiones acotadas de elementos en formula_18; la norma de una de estas sucesiones se define como el supremo de los valores absolutos de los miembros de la sucesión.

De nuevo, si "p" ≥ 1 es un número real, podemos considerar a todas las funciones formula_19 tales que | "f" | es Lebesgue-integrable, es decir el conjunto

Se define la norma de "f" como la raíz "p"-ésima de esta integral. Por sí mismo, este espacio no es un espacio de Banach porque existen funciones no nulas cuya norma es cero. Definimos una relación de equivalencia como sigue:

Es decir, "f" y "g" son equivalentes si y solo si la "semi-norma" de "f" - "g" es cero. El conjunto de las clases de equivalencia obtiene entonces la estructura de espacio de Banach y es denotado por formula_20:

Es crucial usar la integral de Lebesgue en lugar de la integral de Riemann en este caso, porque la integral de Riemann no daría un espacio completo. Estos ejemplos se pueden generalizar: ver espacios L para más detalles.

un conjunto S en un espacio de Banach X se llama "bicompacto" si de toda sucesión x de S ( n está en ℕ ) se puede obtener un subsucesión, cuyo límite está en S.
un conjunto M de un espacio vectorial normado se llama "compacto" si de toda sucesión x de M ( n está en ℕ ) se puede extraer una subsucesión fundamental.
un conjunto H de elementos de un espacio vectorial normado X se llama "localmente compacto" si la intersección de H con cualquiera bola cerrada en X es compacta.

Un conjunto H de un espacio de Banach X se llama "débilmemente compacto" si de toda sucesión infinita de sus elementos se puede extraer una subsucesión débilmente fundamental.

Como se menciona anteriormente, cada espacio de Hilbert es un espacio de Banach porque, por definición, un espacio de Hilbert es completo con respecto a la norma asociada a su producto interior.

No todos los espacios de Banach son espacios de Hilbert. Una condición necesaria y suficiente para que un espacio de Banach sea también un espacio de Hilbert es la identidad del paralelogramo:

para todo "u" y "v" en nuestro espacio de Banach "V", y donde ||*|| es la norma sobre "V".

Si la norma de un espacio de Banach satisface esta identidad, entonces el espacio es un espacio de Hilbert, con el producto interior dado por la identidad de polarización. Si "V" es un espacio de Banach real entonces la identidad de polarización es

y en el caso que "V" sea un espacio de Banach complejo la identidad de polarización está dada por

Para demostrar que la identidad del paralelogramo implica que la forma definida por la identidad de polarización es verdaderamente un producto interior, uno verifica algebraicamente que esta forma es aditiva, de donde, se sigue por inducción que la forma es lineal sobre los enteros y racionales. Entonces, como todo real es límite de alguna sucesión de Cauchy de racionales, la completitud de la norma extiende la linealidad sobre toda la recta real. En el caso complejo uno puede probar también que la forma bilineal es lineal sobre "i" en un argumento, y conjugada lineal en el otro.

Si "V" y "W" son espacios de Banach sobre el mismo cuerpo K, el conjunto de todas las transformaciones lineales continuas "A" : "V" → "W"
se denota por L("V", "W"). Es de notar que en espacios de infinitas dimensiones no todas las funciones lineales son automáticamente continuas. L("V", "W") es un espacio vectorial, y definiendo la norma ||"A"|| = sup { ||"Ax"|| : "x" en "V" con ||"x"|| ≤ 1 } se transforma en un espacio de Banach. 

El espacio L("V") = L("V", "V") forma un álgebra de Banach unitaria, donde la operación de multiplicación está dada por la composición de funciones lineales.

Si "V" es un espacio de Banach y K es el cuerpo subyacente (el de los números reales, o bien, el de los números complejos), entonces K es un espacio de Banach (usando el valor absoluto como norma) y podemos definir al "espacio dual" "V por "V = L("V", K). Este es, de nuevo, un espacio de Banach. Se puede usar para definir una nueva topología para "V": la topología débil. 

Existe una aplicación isométrica lineal natural "F" de "V" a "V<nowiki>"</nowiki>" definido por: "F"("x")("f") = "f"("x") para todo "x" en "V" y "f" en "V"'. como consecuencia del teorema de Hahn-Banach, este mapeo es inyectivo; si llegara a ser sobreyectivo, entonces el espacio de Banach "V" se dice reflexivo. Los espacios reflexivos tienen muchas propiedades geométricas importantes. Un espacio es reflexivo si y solo si su espacio dual es reflexivo, lo que ocurre si y solo si su bola unitaria es compacta en la topología débil. La existencia de una isometría entre "V" y "V<nowiki>"</nowiki>" no es suficiente para que "V" sea reflexivo; es necesario que tal isometría sea "F".

Por ejemplo, "l" es reflexivo para "1∞</sup>" no son reflexivos. El dual de "l" es "l" donde "p" y "q" están relacionados por la fórmula (1/"p") + (1/"q") = 1. Ver espacios L para más detalles. Un espacio de Hilbert es siempre reflexivo.

Dada una aplicación (no necesariamente lineal) "f" : "V" → "W" entre dos espacios de Banach es posible definir la derivada de esta función generalizando el caso de formula_24. Intuitivamente, si "x" es un elemento de "V", la derivada de "f" en el punto "x" es una forma lineal continua que aproxima "f" cerca de "x". Formalmente, se dice que "f" es "diferenciable" en "x" si existe una forma lineal continua "A" : "V" → "W" tal que

El límite aquí se toma sobre todas las sucesiones de elementos no nulos de "V" que converjan al nulo de "V".
Si el límite existe, escribimos D"f"("x") = "A" y le llamamos la derivada de "f" en "x". 

Esta noción de derivada es una generalización de la derivada ordinaria de funciones R → R, pues las funciones lineales de R a R son las multiplicaciones por números reales.

Si "f" es diferenciable en "todos" los puntos "x" de "V", entonces D"f" : "V" → L("V", "W") es otra función entre espacios de Banach (que "no" es, en general, lineal), que posiblemente, se puede diferenciar de nuevo, definiendo así derivadas más altas de "f". La "n"-ésima derivada en un punto "x" se puede ver como una función multilineal "V" → "W".

La diferenciación es una operación lineal en el siguiente sentido: si "f" y "g" son dos funciones "V" → "W" que son diferenciables en "x", y "r" y "s" son escalares de K, entonces "rf" + "sg" es diferenciable en "x" con D("rf + sg")("x") = "r"D("f")("x") + "s"D("g")("x").

La regla de la cadena es también válida en este contexto: si "f" : "V" → "W" es diferenciable en "x" que pertenece a "V", y "g" : "W" → "X" es diferenciable en "f"("x"), entonces la función compuesta "g" o "f" es diferenciable en "x" ya la derivada es la composición de las derivadas:

Muchos espacios importantes en análisis funcional, por ejemplo el espacio de todas las funciones infinitamente diferenciables de R en R o el espacio de todas las distribuciones sobre R son espacios vectoriales completos, pero no normados, no siendo espacios de Banach entonces. En los espacios de Fréchet aún se tiene una métrica completa, mientras que los espacios LF son espacios vectoriales uniformes que surgen como límites de espacios de Fréchet.

Análisis funcional de Kolmogorov.



</doc>
<doc id="45263" url="https://es.wikipedia.org/wiki?curid=45263" title="Moving Picture Experts Group">
Moving Picture Experts Group

(Moving Picture Experts Group) es un grupo de trabajo de expertos que se formó por la Organización Internacional de Normalización (ISO) y la Comisión Electrotécnica Internacional (IEC) para establecer estándares para el audio y la transmisión video.

Fue establecido en 1988, por iniciativa de Hiroshi Yasuda ("Nippon Telegraph and Telephone") y Leonardo Chiariglione (que desde el principio es el presidente del grupo). La primera reunión fue en mayo de 1988 en la ciudad de Ottawa, Canadá.

A finales de 2005, el MPEG ha crecido hasta incluir aproximadamente 350 miembros por reunión, de diversas industrias, universidades e instituciones de investigación.

La metodología de compresión MPEG se considera “asimétrica” ya que el codificador es más complejo que el decodificador. El codificador tiene que ser algoritmico o adaptativo, mientras que el decodificador es 'tonto' y lleva a cabo acciones fijas. Esto se considera una ventaja en aplicaciones tales como la radiodifusión, donde el número de codificadores costosos y complejos es pequeño, pero el número de descodificadores simples y de bajo costo es grande. El enfoque de la estandarización de MPEG es novedoso, porque no es el codificador el que está estandarizado, pero si la forma que un decodificador interpreta la “cadena de bits”. Un decodificador que puede interpretar correctamente el flujo de bits se dice que es “compatible”. La ventaja de estandarizar el decodificador es que a través del tiempo los algoritmos de codificación pueden ser mejorados, y los decodificadores compatibles pueden seguir funcionando. 

El estándar MPEG sirve para un funcionamiento del codificador y los implementadores pueden suministar codificadores con algoritmos de software propietario. Esto da margen para la competencia entre los diferentes diseños del codificador, lo que significa que mejores diseños pueden evolucionar y los usuarios tienen más posibilidades de elección, ya que codificadores de diferentes niveles de costo y complejidad pueden existir, sin embargo, un decodificador compatible opera con todos ellos.

MPEG también estandariza el protocolo y la sintaxis en las que es posible combinar o multiplexar datos de audio con los datos de vídeo para producir un equivalente digital de un programa de televisión. Muchos de estos programas se pueden multiplexar y MPEG define la forma en que estos se pueden crear y transportar. Las definiciones incluyen los Metadatos utilizados por los decodificadores para demultiplexar correctamente.

La designación oficial de MPEG es: ISO/IEC JTC1/SC29 WG11 - "Codificación de audio e imágenes en movimiento":

Tienen los siguientes subgrupos (SG):


"Joint Video Team" (JVT) se formó en 2001 y su principal resultado ha sido H.264/MPEG-4 AVC (MPEG-4 Part 10).

JVT es un proyecto conjunto entre:
para el desarrollo de nuevas recomendaciones sobre codificación y la estandarización internacional.

"Joint Collaborative Team on Video Coding" (JCT-VC) fue creado en 2010 para desarrollar “codificación de vídeo de alta eficiencia”, una nueva generación estándar de codificación de vídeo que reduce aún más (un 50%) la tasa de datos necesarios para la codificación de video de alta calidad, en comparación con el actual estándar ITU-T H.264 / ISO/IEC 14496-10. JCT-VC es codirigido por Jens-Rainer Ohm y Gary Sullivan.

JCT-VC es un grupo de expertos de codificación de vídeo de:

Los estándares MPEG constan de diferentes “Partes”. Cada “parte” cubre un aspecto determinado de toda la especificación. 

El estándar también especifica “Perfiles” y “Niveles”. Los “Perfiles” tienen por objeto definir un conjunto de herramientas que están disponibles, y los “Niveles” definen el rango de valores adecuados para las propiedades asociadas con ellos. 

Algunos de los estándares MPEG aprobados fueron revisadas por enmiendas posteriores y/o nuevas ediciones.

ISO/IEC MPEG ha normalizado los siguientes formatos de compresión y normas auxiliares como familia (comprendido desde MPEG-1 hasta MPEG-DA.

Además, aunque no son avances secuenciales al estándar de codificación de vídeo que van del MPEG-1 al MPEG-4, los siguientes estándares se referencian con notación similar:

Por otra parte, más recientemente que los estándares anteriores, MPEG ha comenzado a seguir estándares internacionales; cada uno de los estándares soportan múltiples tecnologías MPEG para alguna forma de aplicación. (Por ejemplo, MPEG-A incluye una serie de tecnologías para aplicaciones multimedia).















</doc>
<doc id="45265" url="https://es.wikipedia.org/wiki?curid=45265" title="Espacio de Hilbert">
Espacio de Hilbert

En matemáticas, el concepto de espacio de Hilbert es una generalización del concepto de espacio euclídeo. Esta generalización permite que nociones y técnicas algebraicas y geométricas aplicables a espacios de dimensión dos y tres se extiendan a espacios de dimensión arbitraria, incluyendo a espacios de dimensión infinita. Ejemplos de tales nociones y técnicas son la de ángulo entre vectores, ortogonalidad de vectores, el teorema de Pitágoras, proyección ortogonal, distancia entre vectores y convergencia de una sucesión. El nombre dado a estos espacios es en honor al matemático David Hilbert quien los utilizó en su estudio de las ecuaciones integrales.

Más formalmente, se define como un espacio de producto interior que es completo con respecto a la norma vectorial definida por el producto interior. Los espacios de Hilbert sirven para clarificar y para generalizar el concepto de series de Fourier, ciertas transformaciones lineales tales como la transformación de Fourier, y son de importancia crucial en la formulación matemática de la mecánica cuántica. 

Los espacios de Hilbert y sus propiedades se estudian dentro del análisis funcional.

Como se explica en el artículo dedicado a los espacios de producto interior, cada producto interior <..> en un espacio vectorial "H", que puede ser real o complejo, da lugar a una norma ||.|| que se define como sigue:

"H" es un espacio de Hilbert si es completo con respecto a esta norma. Completo en este contexto significa que cualquier sucesión de Cauchy de elementos del espacio converge a un elemento en el espacio, en el sentido que la norma de las diferencias tiende a cero. Cada espacio de Hilbert es así también un espacio de Banach (pero no viceversa).

Todos los espacios finito-dimensionales con producto interior (tales como el espacio euclídeo con el producto escalar ordinario) son espacios de Hilbert. Esto permite que podamos extrapolar nociones desde los espacios de dimensión finita a los espacios de Hilbert de dimensión infinita (por ejemplo los espacios de funciones). Sin embargo, los ejemplos infinito-dimensionales tienen muchos más usos. Estos usos incluyen:


El producto interior permite que uno adopte una visión "geométrica" y que utilice el lenguaje geométrico familiar de los espacios de dimensión finita. De todos los espacios vectoriales topológicos infinito-dimensionales, los espacios de Hilbert son los de "mejor comportamiento" y los más cercanos a los espacios finito-dimensionales.

Los elementos de un espacio de Hilbert abstracto a veces se llaman "vectores". En las aplicaciones, son típicamente sucesiones de números complejos o de funciones. En mecánica cuántica por ejemplo, un conjunto físico es descrito por un espacio complejo de Hilbert que contenga las "funciones de ondas" para los estados posibles del conjunto. Véase formulación matemática de la mecánica cuántica.

Una de las metas del análisis de Fourier es facilitar un método para escribir una función dada como la suma (posiblemente infinita) de múltiplos de funciones bajas dadas. Este problema se puede estudiar de manera abstracta en los espacios de Hilbert: cada espacio de Hilbert tiene una base ortonormal, y cada elemento del espacio de Hilbert se puede escribir en una manera única como suma de múltiplos de estos elementos bajos.

Los espacios de Hilbert fueron nombrados así por David Hilbert, que los estudió en el contexto de las ecuaciones integrales. El origen de la designación, aunque es confuso, fue utilizado ya por Hermann Weyl en su famoso libro "la teoría de grupos y la mecánica cuántica" publicado en 1931. John von Neumann fue quizás el matemático que más claramente reconoció su importancia.

En los siguientes ejemplos, asumiremos que el cuerpo subyacente de escalares es formula_1, aunque las definiciones son similares al caso de que el cuerpo subyacente de escalares sea formula_2.

El primer ejemplo, que ya había sido avanzado en la sección anterior, lo constituyen los espacios de dimensión finita con el producto escalar ordinario.

En otras palabras, formula_1 con la definición de producto interior siguiente:

donde la barra sobre un número complejo denota su conjugación compleja.

Los espacios de Hilbert no necesariamente tienen dimensión finita, de hecho en muchas aplicaciones típicamente el espacio de Hilbert considerado es un espacio de Hilbert infinito-dimensional. Uno de los ejemplos de espacio de Hilbert de dimensión infinita es el siguiente: si "B" es un conjunto, definimos formula_4 sobre "B", de la forma:

Este espacio se convierte en un espacio de Hilbert con el producto interior

para todo "x" e "y" en formula_4. "B" no tiene porqué ser un conjunto contable en esta definición, aunque si "B" no es contable, el espacio de Hilbert que resulta no es . Expresado de manera más concreta, cada espacio de Hilbert es isomorfo a uno de la forma formula_6 para un conjunto adecuado "B". Si "B" = N, se escribe simplemente formula_7. Algunos ejemplos de sucesiones de formula_8:

En cambio:
, \frac{1}{\sqrt{3}}, \dots \right)\notin \ell^2, \qquad
\|w\|\text{ no está definida, ya que } \lim_{N\to \infty}\sum_{n=1}^N \frac{1}{n} = \infty</math>

Otro ejemplo interesante de espacios de Banach de dimensión infinita son los espacios "L". Estos son espacios funcionales asociados a espacios de medida ("X", "M", μ), donde "M" es una σ-álgebra de subconjuntos de "X" y μ es una medida contablemente aditiva en "M". Si "p" = 2 estos espacios son además un espacio de Hilbert, sea por tanto, "L"² ("X") el espacio de funciones medibles cuadrado-integrables complejo-valoradas en "X", módulo el subespacio de esas funciones cuya integral cuadrática sea cero, o equivalentemente igual a cero casi por todas partes. cuadrado integrable significa que la integral del cuadrado de su valor absoluto es finita. "módulo igualdad casi por todas partes" significa que las funciones son identificadas si y sólo si son "iguales salvo un conjunto de medida 0".

El producto interior de las funciones "f" y "g" se da como:

Uno necesita demostrar:

Estos son hechos técnicamente fáciles. Obsérvese que al usar la integral de Lebesgue se asegura de que el espacio sea completo. Vea espacios L para discusión adicional de este ejemplo.

Los espacios de Sobolev, denotados por formula_9 son otro ejemplo de espacios de Hilbert, que se utilizan muy a menudo en el marco de las ecuaciones en derivadas parciales definidas sobre un cierto dominio formula_10. Los espacios de Sobolev generalizan los espacios "L".

Además de los espacios de Sobolev generales formula_11 se usan ciertas notaciones particulares para cierto tipo de espacios:

Un concepto importante es el de una base ortonormal de un espacio de Hilbert "H": esta es una familia {"e"} de "H" 'satisfaciendo:

También utilizamos las expresiones "secuencia ortonormal" y "conjunto ortonormal". Los ejemplos de bases ortonormales incluyen:

Obsérvese que en el caso infinito-dimensional, una base ortonormal no será una base en el sentido del álgebra lineal; para distinguir los dos, la última base se llama una base de Hamel.

Usando el lema de Zorn, se puede demostrar que "cada" espacio de Hilbert admite una base ortonormal; además, cualesquiera dos bases ortonormales del mismo espacio tienen el mismo cardinal. Un espacio de Hilbert es separable si y solamente si admite una base ortonormal numerable.

Puesto que todos los espacios separables infinito-dimensionales de Hilbert son isomorfos, y puesto que casi todos los espacios de Hilbert usados en la física son separables, cuando los físicos hablan de "espacio de Hilbert" quieren significar el separable.

Si {"e"} es una base ortonormal de "H", entonces cada elemento "x" de "H" se puede escribir como:

Incluso si "B" no es numerable, sólo contablemente muchos términos en esta suma serán diferentes a cero, y la expresión está por lo tanto bien definida. Esta suma también se llama la "expansión de Fourier" de "x".

Si {"e"} es una base ortonormal de "H", entonces "H" es "isomorfo" a "l"²("B") en el sentido siguiente: existe una función lineal biyectiva Φ : "H" → "l"²("B") tal que

para todo "x" y "y" en "H".

Dados dos (o más) espacios de Hilbert, podemos combinarlos en un espacio más grande de Hilbert tomando su suma directa o su producto tensorial. La primera construcción se basa en la unión de conjuntos y la segunda en el producto cartesiano.

La suma directa requiere que formula_15, y es el mínimo espacio de Hilbert que "contiene" a la unión de los dos conjuntos:

Mientras que el producto tensorial es el mínimo espacio de Hilbert que "contiene" al producto cartesiano:

Si "S" es un subconjunto del espacio de Hilbert "H", definimos el conjunto de vectores ortogonales a "S"

formula_16 es un subespacio cerrado de "H" y forma, por tanto, un espacio de Hilbert. Si "V" es un subespacio cerrado de "H", entonces el formula_17 se llama el "complemento ortogonal" de "V". De hecho, cada "x" en "H" puede entonces escribirse unívocamente como "x" = "v" + "w" con "v" en "V" y "w" en formula_17. Por lo tanto, "H" es la suma directa interna de Hilbert de "V"y formula_17. El operador lineal P : "H" → "H" que mapea "x" a "v" se llama la "proyección ortogonal" sobre "V".

Teorema. La proyección ortogonal P es un operador lineal auto-adjunto en "H" con norma ≤ 1 con la propiedad P² = P. Por otra parte, cualquier operador lineal E "auto-adjunto" tal que "E"² = "E" es de la forma P, donde "V" es el rango de "E". Para cada "x" en "H", P("x") es el elemento único "v" en "V" que minimiza la distancia ||"x" - "v"||.

Esto proporciona la interpretación geométrica de P("x"): es la mejor aproximación a "x" por un elemento de "V".

Una propiedad importante de cualquier espacio de Hilbert es su reflexividad, es decir, su espacio bidual (dual del dual) es isomorfo al propio espacio. De hecho, se tiene todavía más, el propio espacio dual es isomorfo al espacio original. Se tiene una descripción completa y conveniente del espacio dual (el espacio de todas las funciones lineales continuas del espacio "H" en el cuerpo base), que es en sí mismo un espacio de Hilbert. De hecho, el teorema de representación de Riesz establece que para cada elemento φ del "H" ' dual existe un y solamente un "u" en "H" tal que

para todo "x" en "H" y la asociación φ ↔ "u" proporciona un isomorfismo antilineal entre "H" y "H" '. Esta correspondencia es explotada por la notación bra-ket popular en la física pero que hace fruncir el ceño a los matemáticos.

Para un espacio H de "Hilbert", los operadores lineales continuos "A": "H" → "H" son de interés particular. Un tal operador continuo es acotado en el sentido que mapea conjuntos acotados a conjuntos acotados. Esto permite definir su norma como

La suma y la composición de dos operadores lineales continuos son a su vez continuos y lineales. Para "y" en "H", la función que envía "x" a <"y", "Ax"> es lineal y continua, y según el teorema de representación de Riesz se puede por lo tanto representar en la forma

Esto define otro operador lineal continuo "A": "H" → "H", el "adjunto" de "A".

El conjunto L("H") de todos los operadores lineales continuos en "H", junto con la adición y las operaciones de composición, la norma y la operación adjunto, formas una C-álgebra; de hecho, éste es el origen de la motivación y el más importante ejemplo de una C-álgebra.

Un elemento "A" en L("H") se llama "auto-adjunto" o "hermitiano" si "A" = "A". Estos operadores comparten muchas propiedades de los números reales y se ven a veces como generalizaciones de ellos.

Un elemento "U" de L("H") se llama "unitario" si "U" es inversible y su inverso viene dado por "U". Esto puede también ser expresado requiriendo que <"Ux", "Uy"> = <"x", "y"> para todos los "x", "y" en "H". Los operadores unitarios forman un grupo bajo composición, que se puede ver como el grupo de automorfismos de "H".

En mecánica cuántica, uno también considera operadores lineales, que no necesariamente son continuos y que no necesariamente están definidos en todo espacio "H". Uno requiere solamente que se definan en un subespacio denso de "H". Es posible definir a operadores no acotados auto-adjuntos, y estos desempeñan el papel de los "observables" en la formulación matemática de la mecánica cuántica.

Ejemplos de operadores no acotados auto-adjuntos en el espacio de Hilbert "L"²(R) son:



estos corresponden a los observables de momento y posición, respectivamente, expresados en unidades atómicas. Observe que ni "A" ni "B" se definen en todo "H", puesto que en el caso de "A" la derivada no necesita existir, y en el caso de "B" la función del producto no necesita ser cuadrado-integrable. En ambos casos, el conjunto de argumentos posibles forman subespacios densos de "L"²(R).


</doc>
<doc id="45266" url="https://es.wikipedia.org/wiki?curid=45266" title="Espacio prehilbertiano">
Espacio prehilbertiano

En matemáticas, un espacio prehilbertiano o espacio prehilbert es un espacio vectorial provisto de un producto escalar. Más concretamente, es un par formula_1, donde formula_2 es un espacio vectorial sobre un cuerpo formula_3 y formula_4 es un producto escalar en formula_2.

El espacio prehilbertiano es un tipo de espacio métrico con la métrica inducida por la norma que como veremos puede definirse a partir del producto escalar. 

Un espacio prehilbertiano que además sea un espacio completo, se dirá que es un espacio de Hilbert o hilbertiano. Si es de dimensión finita se dirá que es espacio euclídeo.

Una condición necesaria para que un espacio prehilbertiano sea un espacio de Hilbert es que el cuerpo base formula_3 sea formula_7 o formula_8, así ningún espacio prehilbertiano sobre formula_9 puede ser un espacio de Hilbert.

Formalmente, un espacio prehilbertiano es un espacio vectorial "V" sobre un cuerpo K (Puede ser formula_7 o formula_8), el cual posee una operación definida con la siguiente función:

llamada producto escalar, que satisface ciertos axiomas:




En los espacios con producto escalar se define una norma 

La norma está bien definida, por ser siempre el producto escalar de un vector por sí mismo un número real mayor o igual que cero. En espacios euclídeos define la "longitud" del vector "x". Además se trata de una norma por cumplir las condiciones:



Usando los axiomas ya mencionados podemos demostrar los siguientes teoremas:









</doc>
<doc id="45267" url="https://es.wikipedia.org/wiki?curid=45267" title="Buque">
Buque

Un buque es un barco con cubierta que por su tamaño, solidez y fuerza es apropiado para navegaciones marítimas de importancia. Para aclarar este concepto, se puede decir que cualquier buque es una embarcación o barco, pero que cualquier embarcación o barco no es necesariamente un buque. Además, debe reunir las siguientes condiciones: 


De acuerdo con diversas reglamentaciones técnicas, la diferencia respecto del término "embarcación", es que una embarcación es toda aquella unidad de tamaño inferior a 24 metros de eslora. A pesar de ello, las traducciones oficiales al castellano del Reglamento Internacional para Prevenir Abordajes (RIPA) definen buque como toda clase de embarcaciones, incluidas las embarcaciones sin desplazamiento y los hidroaviones, utilizadas o que puedan ser utilizadas como medio de transporte sobre el agua.

En la mayor parte de los países con tradición marina los buques son bautizados en el momento de la botadura con nombres individuales, además los buques modernos pueden pertenecer a una clase de buques, esencialmente un mismo modelo de construcción, y que se suele denominar con el nombre del primer buque de la clase.

Un buque para poder navegar debe poseer flotabilidad lo cual exige que su estructura sea impermeable al agua y resistente para soportar los esfuerzos a que estará sometida, lo que le proporciona esta impermeabilidad y resistencia es la calidad y forma de su casco.




Por tanto un buque que pase del agua del mar al agua dulce aumentará de calado, ya que la densidad del agua disminuye.


Un buque de guerra tiene cuatro características principales: armamento, protección, velocidad y autonomía las que son entre sí antagónicas. Definidas estas características se obtiene el desplazamiento del buque determinado.

Los buques de guerra deben poseer capacidad ofensiva, capacidad defensiva y movilidad. Estas capacidades las obtienen por la cantidad y calibre de sus cañones y por el número de torpedos que podían lanzar, pero tras la Segunda Guerra Mundial, el cañón y los torpedos fueron reemplazados por misiles teledirigidos, superficie-superficie y superficie-aire y la incorporación de helicópteros con misiles aire-superficie. A comienzos del siglo XXI el alcance de algunos misiles SU-SU era sobre los 120 km y los misiles antiaéreos SU-AI sobre los 40 km.

La capacidad defensiva estaba dada por el espesor de las corazas, pero tras la Segunda Guerra Mundial esta fue siendo traspasada a la capacidad de detección de los misiles atacantes y la destrucción de estos en el aire.
La velocidad tiene altísima importancia en los buques de guerra, al igual que lo sucedido con el armamento y las corazas, las naves del siglo XXI poseen turbinas a gas muy eficientes mediante las cuales las naves alcanzan velocidades de hasta 30 nudos, también como ya se mencionó existen naves con propulsión nuclear, especialmente submarinos y portaaviones.

A comienzos del siglo XXI los portaaviones y su aviación embarcada son el sistema de armas más importante de las grandes marinas de guerra. Estas tremendas naves nunca operan solas pues son el núcleo de un grupo de batalla compuesto por cruceros, destructores, fragatas y submarinos que custodian al portaaviones.

En 1939, antes de la Segunda Guerra Mundial, la flota mercante mundial había alcanzado los 70 millones de toneladas, después de esta, en 1950 había aumentado a 80 millones de toneladas y ha seguido aumentando constantemente.

Las causas de este incremento se deben a la expansión de la economía mundial, a la mayor demanda de productos entre las naciones, intercambio que requiere cada vez de más naves mercantes en las que transportar las mercancías. Estas naves se han tenido que adaptar a viajes más largos y al transporte de mayores cargas.

Entre estas cargas especiales sobresale el petróleo por el gran volumen que se transporta a nivel mundial. 

Como ejemplo de esta necesidad tenemos el caso del super petrolero “Seawise Giant”, también llamado “Happy Giant”, “Jahare Viking” y “Knock Nevis” que fue el buque más grande construido en el siglo XX. Encargó su construcción un magnate griego que no lo pudo terminar por problemas financieros; luego, fue adquirido por el magnate naviero de Hong Kong, T. C. Tung. Sus características son las siguientes: eslora: 458,4 m, mnga: 68,9 m, desplazamiento: 260 851 t, desarrolla una velocidad de crucero de 15 nudos.
En 1986, durante la guerra Irán-Iraq fue atacado por la aviación iraquí y hundido mediante misiles exocet. Reflotado fue puesto nuevamente en servicio. 

Los buques mercantes se clasifican de acuerdo con el tipo de carga que transportan. Así, se diferencian naves para carga seca, graneleros, carga general, cisterna, frigoríficos y, tras la gran revolución de los contenedores, buques portacontenedores. 

También en las naves mercantes apareció la propulsión nuclear, el "Savannah" norteamericano que entró en servicio en septiembre de 1962 fue el primero de esta clase.

La nacionalidad depende del pabellón que enarbolen, además la nave debe tener un nombre debidamente registrado. Los buques mercantes están inscritos en un registro de naves mercantes que lleva la autoridad competente de cada país. Para que una nave mercante se haga a la mar necesita que un estado soberano la reconozca y le permita izar su pabellón.







</doc>
<doc id="45270" url="https://es.wikipedia.org/wiki?curid=45270" title="Germanismo">
Germanismo

Los germanismos son los extranjerismos que proceden del alemán, y también cualquier vocablo, giro o modo de expresión procedente de las antiguas lenguas germánicas.

Las lenguas germánicas comenzaron a influir en el latín vulgar hablado en todo el Imperio Romano debido al continuado contacto, tanto en tiempos de guerra como de paz, entre los pueblos germánicos y los romanos. Por ello, la mayoría de germanismos del español introducidos en esa época son compartidos con otras lenguas romances. Varios germanismos provienen del periodo de dominio visigodo en la península ibérica. 

Otra época en la que se introdujeron, fueron los siglos XIX y XX, época en que la lengua alemana tuvo mucha influencia en el mundo científico y cultural europeo. Por otro lado, se suelen utilizar en español palabras alemanas que se refieren a realidades propias de Alemania que no tienen una traducción generalizada, por ejemplo "Reichstag" o "Bundestag".










</doc>
<doc id="45272" url="https://es.wikipedia.org/wiki?curid=45272" title="Kōbe">
Kōbe

Kobe es uno de los centros económicos más importantes de Japón. Más de cien compañías internacionales tienen su sede asiática o japonesa en la ciudad, como Nestlé, Boehringer Ingelheim, Eli Lilly and Company o Procter & Gamble. Su puerto es también uno de los más importantes de todo el país, aunque su relevancia disminuyó considerablemente tras los estragos del Gran Terremoto de Hanshin-Awaji que azotó a la ciudad en 1995. La ciudad es también lugar de origen y denominación de la ternera de Kobe. 

Kobe posee un clima húmedo subtropical con veranos cálidos e inviernos fríos. Las precipitaciones son significativamente más abundantes en verano que en invierno, aunque en general son inferiores con respecto al resto de la isla.

Los primeros registros escritos en relación a su ubicación se hallan en el Nihon Shoki, que describe la fundación del Santuario Ikuta por la Emperatriz Jingū en el año 201. Durante la mayor parte de su historia, el área nunca ha sido una entidad política independiente, ni siquiera durante el período Tokugawa, cuando el puerto estaba directamente controlado por el shogunato. Kobe no existió en su forma actual hasta su fundación en el año 1889. Su nombre deriva de "kanbe" (神戸), un título arcaico otorgado a los procuradores del Santuario Ikuta. Kobe se convirtió en una de las 17 ciudades designadas como tal en 1956.
Tras el final de la política de aislamiento en 1853, Kobe fue una de las ciudades que abrió el comercio a occidente, y desde entonces se conoce por ser una ciudad portuaria y cosmopolita. Durante la Segunda Guerra Mundial, fue atacada con bombas incendiarias el 17 de marzo de 1945, las cuales causaron la muerte de 8841 habitantes y destruyeron el 21 % de la zona urbana. Este hecho inspiró el libro escrito por Akiyuki Nosaka, en el cual se basa la conocida película La tumba de las luciérnagas, de Studio Ghibli. 

El martes 17 de enero de 1995, un terremoto de 6,9 grados en la escala de Richter tuvo lugar a las 05:46 a. m. JST cerca de la ciudad: mató a 5000 personas, dejó a 300 000 sin hogar y destruyó gran parte de las instalaciones portuarias. Fue uno de los desastres naturales más costosos de la historia moderna.

Hasta el 2008, la ciudad contaba con una población de 1 529 116 habitantes y una densidad de 2755,77 habitantes por km². Kobe posee una superficie de 549,38 km². Alrededor del 13% de la población es menor de 14 años, el 67% tiene entre 15 y 64 años, y el 20%, más de 65 años.

Tanto de buey como de ternera, la carne de Kobe (conocida en inglés como "Kobe beef") es una de las más apreciadas del mundo por los gourmet.

Kobe también es famoso por sus aguas termales y por las vistas nocturnas de la ciudad tanto desde las montañas cercanas como de la costa. También es conocida por ser una ciudad exótica, gracias a su historia como ciudad portuaria, dentro de los estándares japoneses. Kobe es una ciudad cosmopolita asociada a la moda, en la que se celebra dos veces por año un festival de la moda conocido como Kobe Collection. También se celebra otro tipo de festival desde 1981: El festival de jazz de Kobe. Este es otro ejemplo de la internacionalidad de la ciudad de Kobe, el jazz fue importado desde América en los años sesenta, época en la cual la cultura estadounidense influenció Japón.

Kobe tiene seis ciudades hermanas y otras asociadas. Éstas son:


Los puertos hermanos de Kobe son:

Son:




</doc>
<doc id="45279" url="https://es.wikipedia.org/wiki?curid=45279" title="Sacro (hueso)">
Sacro (hueso)

El hueso sacro ("Os sacrum") es un hueso corto, impar, central, simétrico, oblicuo, compuesto por cinco piezas soldadas ("vértebras sacras") en forma de pirámide cuadrangular, que presenta una base, un vértice y cuatro caras (anterior, posterior y laterales). Sus alas sacras en las zonas laterales, se unen con las palas ciáticas de la pelvis.
Se encuentra debajo de la vértebra L5 y encima del coxis y entre los huesos coxales, con todos los cuales se articula. Contribuye a formar la columna vertebral y la pelvis. Su función principal es transmitir el peso del cuerpo a la cintura pélvica.
El borde anterior de S1 es sobresaliente y se denomina promontorio sacro. El vértice se articula con el cóccix. El orificio vertebral del sacro se denomina conducto sacro. Contiene las raíces nerviosas de la cola de caballo (raíces de nervios espinales situados debajo de L1). En las caras pélvicas y dorsal del sacro aparecen 4 pares de orificios sacros a través de los cuales emergen ramos dorsales y ventrales de los nervios espinales.

Los romanos le dieron este nombre porque correspondía a la parte entregada a los dioses en los sacrificios.
Las somitas que dan lugar a la columna vertebral comienzan a desarrollarse a partir de la cabeza a la cola a lo largo de la longitud de la notocorda. Al día 20 de la embriogénesis los cuatro primeros pares de somitas aparecen en la futura región del hueso occipital. Desarrollándose, a razón de tres o cuatro veces al día, las próximas ocho parejas de somitas , se forman en la región cervical de desarrollarse en las vértebras cervicales; los próximos doce pares formarán las vértebras torácicas; los próximos cinco pares de vértebras lumbares y aproximadamente el día 29 aparecerá las somitas sacras para desarrollar las vértebras sacras; Finalmente, el día 30 los últimos tres pares formarán el cóccix.

En él se insertan los músculos:

El promontorio sacro marca la frontera de la entrada de la pelvis, y cuenta con la línea iliopectínea y línea terminal. El promontorio sacro se articula con la última vértebra lumbar para formar el ángulo sacrovertebral, un ángulo de 30 grados con respecto al plano horizontal que proporciona un marcador útil para un procedimiento de implante cabestrillo.

La articulación sacroiliaca presenta dos superficies auriculares:


Esta superficie tiene forma de media luna de concavidad posterosuperior; está recubierta de cartílago y es bastante irregular.
A lo largo del eje mayor de esta superficie discurre una cresta alargada que separa dos depresiones. Esta cresta está incurvada sobre sí misma, siguiendo un arco de círculo cuyo centro está situado aproximadamente a nivel de la tuberosidad iliaca que da inserción a poderosos ligamentos de la articulación sacroiliaca.


Estas dos superficies sin embargo no tienen tanta regularidad como se ha descrito anteriormente. En la parte media y superior de la superficie auricular del sacro existe una depresión central. En cambio, en su parte inferior, la parte auricular del sacro está más bien convexa en su parte central.
De ello se deduce la dificultad que existe en seguir la interlínea sacroiliaca en una proyección radiológica y que, según en la parte que se quiera explorar, la proyección debrá ser oblicua de fuera a dentro, o de dentro a fuera.

Puede presentar grandes variaciones morfológicas según los individuos.
A. Delmas ha demostrado la existencia de una correspondencia entre el tipo del raquis y la morfología del sacro y de su faceta auricular.



La aurícula es habitualmente más larga y estrecha en el sacro que en el hueso iliaco y en ella se observa constantemente una depresión central en la unión de los dos segmentos y dos elevaciones cerca de las extremidades de cada segmento.

Weisel ha desarrollado una teoría personal sobre la disposición de los ligamentos de la articulación en relación con las fuerzas que se le aplican:



1.- Ligamentos iliolumbares: constituido por dos haces, superior e inferior, y que van desde las apófisis transversas de L4 y L5 al borde anterior de la cresta iliaca.

2.- Plano medio de los ligamentos iliosacros: aquí encontramos el ligamento iliotransverso del sacro y los ligamentos iliotransversos conjugados. Estos últimos fueron descritos por "Farabeuf" , divergen en la extremidad posterior de la cresta iliaca y terminan en los tubérculos conjugados del sacro.

3.- Ligamentos sacrociáticos mayor y menor: Son dos ligamentos muy importantes que se extienden entre la parte inferior del borde externo del sacro y la gran escotadura ciática. Dividen esta escotadura en dos agujeros: un agujero superior por el que sale de la pelvis el músculo piramidal, y un agujero inferior, salida del músculo obturador interno.

Desde esta vista podemos volver a ver los ligamentos iliolumbares y sacrociáticos. Además vemos:

1.-Ligamento sacroiliaco anterior: está formado por dos haces que son denominados "frenos de nutación superior e inferior".

1.- Movimiento de nutación: durante este movimiento, el sacro gira alrededor del eje constituido por el ligamento axial, de manera que el promontorio se desplaza hacia abajo y hacia delante, y la punta del sacro y la extremidad del cóccix se desplazan hacia atrás. Por tanto, el diámetro anteroposterior del estrecho superior acorta su longitud mientras que el estrecho inferior aumenta. Por otro lado, las palas iliacas se aproximan y las tuberosidades isquiáticas se separan.
Este movimiento está limitado por la tensión de los ligamentos sacrociñáticos y por los llamados frenos de la nutación (ligamento sacroiliaco anterior).

2.-Movimiento de contranutación: realiza desplazamientos inversos; el sacro gira alrededor del ligamento axial haciendo que el promontorio se desplaza hacia arriba y hacia atrás y la extremidad inferior del sacro y la punta del cóccix se desplazan hacia abajo y hacia delante. Además, las palas iliacas se separan y las tuberosidades isquiáticas se aproximan.
Está limitado por la tensión de los ligamentos sacroiliacos (plano superficial, medio y profundo).

El trastorno congénito, espina bífida, se produce como resultado de un tubo neural embrionario defectuoso, caracterizado por el cierre incompleto del arco vertebral o del cierre incompleto de la superficie del canal vertebral. Los sitios más comunes para las malformaciones espina bífida son las áreas lumbar y sacra.

Otro trastorno congénito es el de síndrome de regresión caudal también conocida como agenesia sacra. Éste se caracteriza por un subdesarrollo anormal en el embrión (que se producen por la séptima semana) de la columna vertebral inferior. A veces, o parte del coxis o las vértebras inferiores pueden estar ausentes, o, en ocasiones, una pequeña parte de la columna vertebral no se encuentra sin ningún signo exterior.

El sacro es uno de los principales lugares para el desarrollo de los sarcomas conocidos como condrosarcomas que se derivan de los remanentes de la notocorda embrionaria.

El sacro muestra un notable dimorfismo sexual (forma diferente en hombres y mujeres).



En algunos casos el sacro estará formado por seis piezas o reducirse el número a cuatro. Los cuerpos de la primera y segunda vértebras puede fallar al unir.

A veces los tubérculos transversales superiores no están unidos al resto del ala en uno o ambos lados, o el conducto sacro pueden estar abiertos a lo largo de una parte considerable de su longitud, como consecuencia del desarrollo incompleto de las láminas y apófisis espinosas.

En los perros el sacro está formado por tres vértebras fusionadas. El sacro en el caballo está compuesto por cinco vértebras fusionadas.<br>
En las aves las vértebras sacras se fusionan con la zona lumbar, un poco en la zona caudal y con las vértebras torácicas para formar una sola estructura denominada synsacrum.<br>
En la rana, el ilion es alargado y forma un conjunto móvil con el sacro, que actúa como un miembro adicional para dar más poder a sus saltos.




</doc>
<doc id="45280" url="https://es.wikipedia.org/wiki?curid=45280" title="Sacro">
Sacro

El término sacro (del latín "sacer, sacra") puede referirse a los siguientes artículos:



</doc>
<doc id="45281" url="https://es.wikipedia.org/wiki?curid=45281" title="Músculo esfínter externo del ano">
Músculo esfínter externo del ano

El músculo esfínter externo del ano () es un músculo que se encuentra en la parte inferior del recto en el perineo posterior. Posee la forma de un anillo aplanado.

Se inserta por detrás en el rafe anococcígeo; o por delante en el rafe anobulbar. Lo inerva el nervio hemorroidal. Cumple la función de ser constrictor del ano. Es un músculo con función voluntaria.



</doc>
<doc id="45283" url="https://es.wikipedia.org/wiki?curid=45283" title="Músculo oblicuo externo del abdomen">
Músculo oblicuo externo del abdomen

El músculo oblicuo externo del abdomen () es un músculo que se encuentra en la parte anterolateral del abdomen, ancho, par, irregularmente cuadrilátero, constituido por una porción carnosa y otra aponeurótica.

Se origina por arriba en la cara externa y borde inferior de las ocho últimas costillas, por abajo se inserta mediante la aponeurosis en la cresta ilíaca, borde anterior del coxal, el pubis y la línea blanca.

Se origina en la cara externa de las 8 últimas costillas, de allí se dirige hacia el borde superior de la cresta ilíaca, y hasta los tercios anteriores de la espina ilíaca anterior y superior. De aquí se va hacia la línea media, donde está la aponeurosis del oblicuo mayor (la cual se inserta en la apéndice xifoides y llega hasta la sínfisis pubiana), se cruza con la aponeurosis del lado opuesto y forman la “línea alba”. Otra de las inserciones que tiene el oblicuo mayor es a nivel del borde anterior del hueso coxal en la ingle donde forma por medio de fibras aponeuróticas el arco crural o arco femoral (ligamento inguinal).

Lo inervan los nervios intercostales inferiores y abdominales.

Actúa reprimiendo las costillas, los oblicuos flexionan el tronco y deprimen la pared abdominal. Cuando se inmoviliza el tórax, flexionan la pelvis sobre el raquis. Si uno de los músculos se contrae aisladamente, inclina el tronco hacia ese lado, dándole un movimiento de torsión. Mantiene el tronco recto cuando el brazo opuesto eleva una carga.

Morfológicamente, el oblicuo mayor, muy delgado en su parte craneal, modela exactamente la caja torácica dejando ver los relieves costales, las depresiones intercostales o el relieve del borde costal.


</doc>
<doc id="45284" url="https://es.wikipedia.org/wiki?curid=45284" title="Músculo psoas menor">
Músculo psoas menor

El músculo psoas menor es un músculo que se encuentra en la cavidad abdominal, por delante del psoas mayor; par, largo y delgado.

Tiene su origen en los cuerpos de las vértebras T12 y L1 y su inserción, mediante un tendón, en la eminencia iliopúbica.
Su principal acción es colaborar en la flexión de tronco.

Lo inervan ramas del plexo lumbar (l1, l2, l3)

El músculo psoas menor sólo se encuentra en el 50 a 60 % de la población.


</doc>
<doc id="45289" url="https://es.wikipedia.org/wiki?curid=45289" title="Foro Social Mundial">
Foro Social Mundial

El Foro Social Mundial (FSM) es un encuentro anual que llevan a cabo miembros del movimiento por una globalización diferente, para organizar campañas mundiales, compartir y pulir las estrategias de reunión, y para que los diferentes integrantes se informen unos a otros de los nuevos movimientos existentes.

El primer FSM fue organizado en Porto Alegre Brasil, del 25 al 30 de enero de 2001, en la misma fecha en que se reúne el Foro Económico Mundial de Davos, a partir de una convocatoria internacional por movimientos y organizaciones sociales críticos al neoliberalismo. Acudieron 12.000 asistentes de todo el mundo.
Al segundo FSM, también en Porto Alegre, del 31 de enero al 5 de febrero de 2002 acudieron más de 12.000 delegados oficiales, representando a gente de 123 países y 60.000 asistentes. Se llevaron a cabo 652 talleres y 27 conferencias. Un conferenciante célebre fue el disidente estadounidense Noam Chomsky.

El tercer FSM fue celebrado nuevamente en Porto Alegre, en enero de 2003. Hubo muchos talleres en paralelo, incluyendo, por ejemplo, el taller "La vida tras el capitalismo", que proponía una discusión enfocada a las posibilidades participativas, no-comunistas, no-capitalistas de diferentes aspectos de las estructuras sociales, políticas, económicas y de comunicación.

El cuarto FSM se llevó a cabo en Bombay, India, del 16 al 21 de enero de 2004. La asistencia fue superior a las 75.000 personas que se esperaban. La diversidad cultural fue un aspecto notable del forum. Otra decisión notable fue la de utilizar software libre, que se llevó a cabo con la ayuda de voluntarios de la Fundación por el Software Libre. Uno de los conferenciantes más importantes fue Joseph Stiglitz.
La quinta edición de este evento se llevó a cabo en Porto Alegre en 2005 y la sexta, en Venezuela del 24 al 29 de enero de 2006.

El séptimo FSM de Nairobi reunió del 20 al 25 de enero de 2007 a activistas de todo el mundo para debatir acerca de la pobreza, la violencia sexual, el sida, los acuerdos comerciales y la deuda de los países subdesarrollados. El objetivo de este Foro no fue llegar a conclusiones finales, sino el intercambio de ideas y el establecimiento de alianzas para que la gente se una a los distintos movimientos y las propuestas salgan de las organizaciones sociales. El foro mostró los problemas de los pueblos africanos y ha enfatizado la necesidad de dar voz a sus 850 millones de personas.

El octavo Foro Social Mundial se desarrolló entre los días 27 de enero al 1 de febrero de 2009 en Belém, Brasil. Su principal eje temático giró en torno a la Amazonia y a la preservación de todo el patrimonio natural aún existente en el planeta.

En enero de 2010 volvió a Porto Alegre, Brasil, y se abrió con el lema “Diez años después: desafíos y propuestas para otro mundo posible”.

La edición 2011 del Foro se llevó a cabo en Dakar, capital de Senegal entre el 6 y el 11 de febrero de 2011. Entre el 24 y el 29 de enero de 2012 el Foro volvió a realizarse en Porto Alegre, Brasil.
La undécima edición del Foro Social Mundial tuvo lugar en Túnez entre el 26 y el 31 de marzo de 2013 bajo el lema de la primavera árabe: Dignidad.

El duodécimo Foro Social Mundial en el 2015 se reunió de nuevo en Túnez del 24 al 28 de marzo con el lema "Dignidad y Derechos" una semana después del atentado terrorista en el Museo del Bardo, el 18 de marzo, en el que murieron 22 personas y que marcó la manifestación de apertura del foro convocada con el lema “Los pueblos del mundo contra el terrorismo”.
Entre los temas destacados en las Asambleas de Convergencia estaban los del "Clima" y "el Agua y la Tierra" elaborándose una declaración que reiteraba que "el agua, la tierra y las semillas son bienes públicos y no mercancías". En los foros temáticos incluidos en el FSM se celebró el Foro Parlamentario Mundial que sirvió como espacio de convergencia de legisladores progresistas y emitió mociones sobre la construcción de la paz, la migración, la deuda injusta, las multinacionales y el ingreso mínimo ciudadano.
En la IV edición del Foro Mundial de Medios Libres se ha insistido en reforzar la información y la comunicación al servicio de los movimientos sociales y se ha aprobado la "Declaración del Foro Mundial de Medios Libres" Durante el FSM2015 se ha celebrado también la reunión para iniciar el proceso preparatorio del Foro Social de Internet cuya celebración está prevista para finales del 2015 o principios de 2016. Entre los objetivos: defender la internet de las personas y la ciudadanía frente a los intereses de las corporaciones.

El Foro Social Mundial 2016 se celebró en Montreal.

El Foro Social Mundial 2017 se celebró en Porto Alegre

El Foro Social Mundial 2018 se celebró en Salvador de Bahía, Brasil.Con el lema <resistir es crear, resistir es transformar>.

El Foro Social Mundial incluye también otros foros mundiales, temáticos, regionales, subregionales, nacionales y municipales que se organizan de acuerdo con su Carta de Principios aunque esta carta impide al FSM organizar acciones colectivas en su propio nombre. Según Boaventura de Sousa Santos intelectual cercano a los movimientos del Foro Social Mundial, "deben considerarse como parte del proceso del FSM las acciones regionales y globales llevadas a cabo por las redes de movimientos y organizaciones que integran el FSM, siempre y cuando estas iniciativas respeten su Carta de Principios".

Entre los foros temáticos está el Foro de las Autoridades Locales, el Foro Parlamentario Mundial, el Foro Mundial de la Educación, el Foro Mundial de Jueces, el Foro Mundial de los Sindicatos, el Foro Mundial del Agua, el Foro Social Panamazónico, el Foro Mundial de la Juventud y el Foro Mundial de la Diversidad Sexual. Para el 2015-2016 se prepara un nuevo foro: el Foro Social de Internet.

Entre los foros regionales se incluyen el Foro Social Europeo, el Foro Social Asiático, el Foro Social Africano, el Foro Social de las Américas, el Foro de Educación Europeo, etc.

En junio de 2007, y auspiciada por una red de organizaciones a nivel internacional, se lanzó en Berlín la convocatoria para una semana de movilizaciones a celebrar a partir del 20 de enero de 2008, culminando el 26 de enero en una jornada mundial por el “Otro Mundo posible”. El FSM-2008 optó así por un nuevo formato descentralizado.

El FSM ha promovido la organización de muchos foros sociales regionales, incluyendo el Foro Social Europeo, el Foro Educacional Europeo, el Foro Social Asiático y el Foro Social de las Américas.

Del 10 al 12 de octubre de 2009 dentro del movimiento del foro social mundial se celebró en Sevilla el Foro social de las éticas y las espiritualidades.

Corresponde también mencionar por cierto las distintas ediciones del Foro Social Catalán, cuyas diferentes reuniones se ajustaron al siguiente detalle: I FSCat (Barcelona, 25-27 de enero de 2008); II FSCat (Barcelona, 30-31 de enero de 2010).





</doc>
<doc id="45292" url="https://es.wikipedia.org/wiki?curid=45292" title="Universidad de Chicago">
Universidad de Chicago

La Universidad de Chicago (en inglés: The University of Chicago), es una universidad privada ubicada en Chicago, Illinois (Estados Unidos). Fue fundada en 1890 por John D. Rockefeller y su campus principal se encuentra en el barrio Hyde Park. Se trata de una de las universidades más prestigiosas de los Estados Unidos y del mundo, en la que se han educado muchos alumnos destacados, investigadores y académicos, reconocidos por sus notables contribuciones en diversas ramas de las ciencias. Esto, le ha hecho acreedor de 100 premios Nobel, 54 Rhodes Scholars, 26 Marshall Scholars, 9 Fields Medalists, 4 premios Turing, 52 becas MacArthur, 27 premios Pulitzer, 20 Medallas Nacionales de Humanidades y 8 medallistas olímpicos. La universidad se encuentra clasificada en el "top 10" como una de las mejores según el criterio de las principales clasificaciones académicas del mundo.

Diversas personalidades de renombre forman o han formado parte de la universidad en varios campos de la ciencia, entre ellos, Enrico Fermi, Robert Millikan, Jerry Coyne, Milton Friedman, George Stigler, Myron Scholes, Gary Becker, Saul Bellow, John Dewey, entre muchos otros. El expresidente de los Estados Unidos, Barack Obama, fue profesor y catedrático de la Universidad durante 12 años y mantiene su residencia cerca del campus de la universidad en Hyde Park.

En 2015, la universidad dedicó 421 millones de dólares en investigación científica. Además, profesores y alumnos de la universidad han jugado un papel importante en el desarrollo de la economía mundial, de la sociología, el movimiento derecho y economía en el análisis legal, y la física (por ejemplo, investigaciones de la Universidad llevaron a la creación del primer reactor nuclear autosuficiente, dirigidos por Enrico Fermi). 

La universidad alberga también la editorial más grande de todas las universidades en los Estados Unidos, la University of Chicago Press.

Fue fundada por American Baptist Education Society gracias a una donación del magnate petrolero y filántropo John D. Rockefeller, y fue constituida en 1890. William Rainey Harper se convirtió en el primer presidente de la universidad, en 1891, y las primeras clases tuvieron lugar en 1892.

En la Universidad de Chicago nacieron lo que se conocen como "escuelas" de Economía de Chicago y Sociología de Chicago, que no son escuelas ni facultades propiamente dichas de la universidad, sino corrientes de opinión.
La Universidad de Chicago solamente tiene una facultad de pregrado denominada Facultad de la Universidad de Chicago. Los estudios de postgrado se imparten en siete escuelas profesionales:

La Universidad de Chicago se clasifica de forma continua entre las diez mejores universidades estadounidenses y mundiales en la mayoría de los rankings. 

La escuela de negocios de la universidad, la Booth School of Business, lleva clasificando como la mejor escuela de negocios del mundo por el ranking de Business Week desde 2006 hasta la actualidad. La escuela también es considerada la mejor del mundo por el ranking de la revista británica The Economist 2012.

Entre los profesores, investigadores y alumnos de la Universidad ha habido 91 premios Nobel y 50 becarios MacArthur.




</doc>
<doc id="45294" url="https://es.wikipedia.org/wiki?curid=45294" title="Netscape">
Netscape

Netscape puede referirse a:


</doc>
<doc id="45297" url="https://es.wikipedia.org/wiki?curid=45297" title="El cuento del cortador de bambú">
El cuento del cortador de bambú

La historia trata sobre una pareja de ancianos sin hijos y de cómo un día mientras el anciano cortaba bambú, encontró a una niña dentro del tallo. La niña era Kaguya o princesa Kaguya, quien provenía de la Luna. En 2013, el cuento fue adaptado a una película animada por parte del Studio Ghibli, llamada "Kaguya-hime no Monogatari". En 2015, fue producido un musical basado en el cuento titulado "Prince Kaguya", donde el género de Kaguya es cambiado de femenino a masculino. 

Un anciano cortador de bambú sin hijos llamado se encontró con un árbol de bambú que tenía luz en su interior. Se preguntó por qué y sintió una gran curiosidad acerca de lo que habría dentro. Cuidadosamente cortó el bambú y se quedó asombrado al encontrar a una pequeña bebé del tamaño de su pulgar en el interior. Decidió recogerla y llevarla a su hogar, donde consultó con su mujer qué hacer con el bebé y llegaron a la conclusión de que era un regalo del Cielo. Decidieron llamar a la niña princesa Kaguya (princesa de la luz brillante). A partir de aquel día, cada vez que el anciano cortaba bambú, encontraba oro dentro de él, no tardó en hacerse rico y construir una gran casa. Varios años después, Kaguya creció y se convirtió en una hermosa joven. Todo el mundo la conocía porque era elegante y bella. Cinco príncipes llegaron a su casa para pedir su mano en matrimonio. Ella era reacia a casarse, así que les propuso varias tareas imposibles para llevar a cabo antes de conseguir casarse con ella. 

El primero fue encargado de traer el cáliz sagrado de Buda que se encontraba en la India. Al segundo príncipe se le encargó encontrar una legendaria rama hecha de plata y oro. El tercero tenía que conseguir la legendaria túnica hecha con el pelo de la rata de fuego, que se dice que está en China. Al cuarto, una joya de colores que brillaba al cuello de un dragón. Al último príncipe, le encargó una que nace de las golondrinas. La princesa pidió cosas que nadie sabía que existían y sus pretendientes quedaron muy desilusionados. Luego de esto, los jóvenes dejaron de ir por algún tiempo a la casa del viejo ya que todos estaban buscando los deseos de la princesa. Un día, llegó el primer hombre, con la taza de Buda que la princesa había pedido, pero él no había ido a la India y en su lugar traía una taza sucia de un templo cerca de Kioto. Cuando la princesa lo vio, ella supo inmediatamente que esta no era la taza de Buda, porque aunque era muy vieja y estaba hecha de piedra, la taza que era de la India siempre tenía un brillo sagrado. El segundo no tenía idea de donde podría encontrarse una rama de plata y oro, además no quería hacer un largo viaje y como era muy rico, decidió ordenárselo a unos joyeros. Luego llevó el regalo a la princesa. La rama era tan maravillosa que Kaguya pensó que realmente se trataba de lo que había pedido y pensó que no podría escapar del matrimonio con este joven de no ser porque los joyeros aparecieron preguntando por su dinero. De esta manera la princesa supo que la rama no era la verdadera, y por tanto, no era lo que ella había deseado.

El tercero, a quién se le había pedido la túnica de pelo de rata de fuego, les dio una gran cantidad de dinero a algunos comerciantes que iban a China. Ellos le trajeron una piel vistosa y le dijeron que pertenecía a la rata de fuego. Se la llevó a la princesa y ella dijo ""Realmente es una piel muy fina. Pero el pelo de la rata de fuego no arde, aun cuando se tire al fuego. Probémoslo"". Kaguya tiró la piel en el fuego y tal como era de esperar la piel ardió en unos minutos, el joven se fue enfadado y avergonzado. El cuarto era muy valiente e intentó encontrar el dragón por sí mismo. Navegó y vagó durante mucho tiempo, porque nadie supo donde vivía el dragón. Pero durante una jornada, fue asediado por una tormenta y casi muere. No podía buscar más al dragón y se marchó. De vuelta en su hogar, se encontraba muy enfermo y no pudo volver con la princesa Kaguya. El quinto y último de los hombres buscó en todos los nidos y en uno de ellos pensó que la había encontrado; pero al bajar tan aprisa por la escalera cayó y murió. Ni siquiera lo que tenía en su mano era la concha que la princesa había pedido, sino una golondrina vieja y dura. De este modo todos habían fallado y ninguno podría casarse con la princesa. La reputación de la princesa era tal, que un día el emperador quiso conocer su extraordinaria belleza. El emperador quedó prendado de la joven y le pidió que se casara con él y fuera a vivir a su palacio. Pero la princesa rechazó también su propuesta, diciéndole que era imposible ya que ella no había nacido en el planeta y no podía ir con él. No obstante, el emperador no pudo olvidarla y siguió insistiendo. Ese verano, cada vez que la princesa miraba la Luna sus ojos se llenaban de lágrimas. Su anciano padre quiso saber qué le ocurría, pero ella no respondió. Cada día que pasaba la joven estaba más triste y siempre que miraba la luna no podía dejar de llorar. Los ancianos estaban muy preocupados, pero la princesa guardaba silencio. Un día antes de la luna llena de mediados de agosto, la princesa explicó por qué estaba tan triste. Explicó que no había nacido en el planeta, sino que procedía de la Luna, a dónde debía regresar en la próxima luna llena y que vendrían a buscarla. 

Los ancianos trataron de convencerla de que no partiera, pero Kaguya contestó que debía hacerlo. Así que el anciano corrió en busca del emperador y le contó toda la historia, enviando este último una gran cantidad de soldados a casa de la princesa. En la noche de la luna llena de mediados de agosto, los guerreros rodearon la casa en su intento de proteger a la princesa, mientras esta se hallaba en el interior con sus padres esperando por la gente de la luna que vendrían por ella. Cuando la luna se puso llena, una inmensa luz los cegó a todos y la gente de la luna bajó a por la princesa, los soldados no pudieron combatir porque estaban cegados por aquella inmensa luz y porque extrañamente habían perdido las ganas de luchar. La princesa se despidió de sus padres, y les dijo que no deseaba irse, pero que tenía que hacerlo. Antes de irse le dejó al emperador una carta de despedida y una botella con el Elixir de la Vida. El desolado emperador envió un ejército entero de soldados a la montaña más alta de Japón. La misión encargada era subir hasta la cima y quemar la carta que la princesa Kaguya había escrito y la botella que le había dejado, con la esperanza de que el humo llegara a la ahora distante princesa. 

La leyenda cuenta que la palabra , se convirtió en el nombre de la montaña, el Monte Fuji. También se dice que el kanji para montaña (富士山), deriva del ejército del emperador que ascendió las laderas de la montaña para llevar a cabo su misión. También se cree que el humo de la carta quemada aún se deja ver hasta el día de hoy (en el pasado, el monte Fuji era mucho más activo volcánicamente y, por lo tanto, producía más humo).

Hoy en día la historia ha sido utilizada en varios animes, en donde intervienen en la leyenda.
Un ejemplo es "Mirmo Zibang", en el capítulo "La caza del monstruo de Murumo", en donde Rima es la princesa Kaguya.

Este cuento folclórico fue usado como base para la trama de "Tsukimi Planet", creado por el autor de múltiples juegos de terror japoneses Charon, juego en el cual la princesa Kaguya toma el nombre de Tsukimi, siendo esta la encargada de cumplir un deseo a un humano antes de su muerte.

Leiji Matsumoto toma el nombre de esta leyenda para su manga y posterior adaptación al anime "Shin Taketori Monogatari: Sennen Joō", mejor conocido como "Queen Millenia" o "La princesa de los mil años", siendo la protagonista Yayoi Yukino, la hija adoptiva de una pareja de ancianos que desconocen su origen extraterrestre.

Esta leyenda fue utilizada por Rumiko Takahashi para crear el argumento de la segunda película de su manga/anime de "Inuyasha", "", en el cual Kagura y Kanna, dos sirvientes de Naraku, el antagonista, eran liberadas, y posteriormente engañadas por la princesa Kaguya para escapar del espejo y vengarse del emperador, congelando el tiempo. Según esta película, la familia a la que fue entregada la capa de la princesa Kaguya fue la familia Hojo. En la película además se hace mención a un poema dedicado a la princesa Kaguya, escrita por un emperador japonés: 
"De que me sirve saber el secreto de la inmortalidad
si nunca volveremos a vernos
y paso mis días derramando suficientes lágrimas
como para flotar sobre su estela".

Kaguya también aparece en la segunda película del anime "Sailor Moon", "Sailor Moon S The movie", y se menciona en uno de los capítulos del live action "Pretty Guardian Sailor Moon".

En "Imperishable Night", el octavo juego de Touhou Project, la historia se basa un poco en la historia de la princesa Kaguya. Es el personaje de Kaguya Houraisan quien se oculta en gensokyo para evitar volver a la Luna.

También la historia de Kaguya se incluye en el videojuego "Okami", para Playstation 2, el cual está basado en el folclore japonés y cuya protagonista es la diosa del Sol, Amaterasu.

En el episodio número 76 de "Sargento Keroro", los protagonistas van a la Luna y se encuentra con la Princesa Kaguya, que es una extraterrestre y que fue ella quien expandió por la Tierra esa historia para obtener esos 5 materiales, que era los que necesitaba su nave para continuar su largo viaje.

Los capítulos 8 y 9 de "Yami to Bōshi to Hon no Tabibito" están basados en esta historia, siendo Hatsumi la princesa Kaguya.

En "Hime Chen! Otogi Chikku Idol Lilpri" la princesa Kaguya es una de las protagonistas de la historia.

En el manga "Crayon Shin Chan" aparece una historia con la princesa Kaguya como protagonista.

En el juego de cartas de fantasía "Ayakashi: Ghost Guild" existe una carta llamada Kaguya, la cual se encuentra sellada y que para ser liberada se debe juntar todas las piedras de sello.

En "Naruto Shippuden" y en el manga homónimo, se le llama Kaguya Otsusuki y es la madre del Sabio de los seis caminos, Hagoromo Otsusuki. Además se cuenta que el Clan Otsusuki (de la cual ella era líder y princesa) provenía de un lugar lejano hasta que se instalaron en la Luna y parte de la Tierra.

Dentro del movimiento cultural Touhou, creado por el productor de videojuegos Zun, existe un personaje de nombre Kaguya Houraisen. Tiene similitudes con la leyenda, pero se diferencia en que esta era una Lunarian que fue exiliada a la Tierra por tomar el Elixir de Hourai; tras varios años de vivir en Japón fue perdonada y se le ordenó regresar, pero ésta se rehusó y huyó al portal de Gensokyo, donde se esconde actualmente en el bosque de bambú de Eintei junto a la coneja lunar Reisen Udongein Inaba y otros sirvientes.

La historia fue adaptada en la película animada "El cuento de la princesa Kaguya" (2013), producida por Studio Ghibli y dirigida por Isao Takahata. Años antes el mismo director, en su película "Mis vecinos los Yamada", hace una referencia al mismo cuento, cuando se muestra el nacimiento de Nonoko, la hija menor de la familia Yamada, dentro de un bambú, al igual que Kaguya. 

En el anime "GARO - Guren no Tsuki", Kaguya es la hija adoptiva de una pareja de ancianos que se enriquecen misteriosamente tras ser poseídos por espíritus malignos. Luego se revela que Kaguya en realidad proviene de la Luna y es capaz de encerrar a los espíritus malignos en la Luna Carmesí convirtiéndose así en aliada de Garo.

En el juego de cartas coleccionables "Force of Will", la princesa Kaguya es uno de los personajes principales de la trama del juego, invocada desde los mitos por una hechicera con el propósito de proteger a la humanidad.

En el capítulo número 122 del anime "Konjiki no Gash Bell!!", la historia de la princesa Kaguya es mencionada por el personaje de Natsuko (o la Señorita Natsuko) al personaje de Gash, después de que éste la conoce como "la mismísima princesa" durante su experiencia en el Festival de las Luces de Invierno en Japón. El personaje Gash cree estar todo el tiempo con la princesa Kaguya, solo hasta el final del capítulo cuando la Señorita Natsuko toma la decisión de decirle la verdad, y posteriormente se entrega a las personas que durante todo el episodio la estuvieron persiguiendo, revelándo ser éstas, finalmente, las encargadas de cuidarla. En suma y a manera de interpretación, la alusión a Kaguya en este capítulo es realizada con motivo de representar, metafóricamente, la idea de "no sentirse parte de este mundo" o de no pertenecer al mismo.

En "Beatmania IIDX 26: Rootage", aparece el personaje de Kaguya, siendo ella un Qpro en el modo STEP UP.




</doc>
<doc id="45299" url="https://es.wikipedia.org/wiki?curid=45299" title="Catacumbas">
Catacumbas

Las catacumbas son unas galerías subterráneas que algunas civilizaciones mediterráneas antiguas construyeron y utilizaron como lugar de enterramiento. Las más conocidas y las mejor estudiadas son las catacumbas de la ciudad de Roma. También son conocidas las catacumbas de París, aunque su origen es muy distinto (siglo XVIII).y rituales 

Las catacumbas de la ciudad de Roma fueron excavadas en el suelo para organizar en ellas los enterramientos de los muertos de los primeros cristianos en la Roma del siglo II. Se empezó a llamar con este nombre a la cripta del cementerio de San Calixto; se llamó "ad catacumbas", y en la Edad Media, por extensión, aplicaron el nombre al conjunto de enterramientos hechos en el subsuelo del campo romano que formaba alrededor de la ciudad una inmensa necrópolis. También se llamó a las catacumbas "Roma subterránea". Estos subterráneos fueron en limitadas ocasiones lugar de culto, pero principalmente de enterramiento.

El origen de la palabra latina "catacumba" es incierto. Algunas fuentes creen que viene del griego κατά "hacia abajo", y τύμβoς "túmulo"; o también de κυμβή "copa", con el significado de "depresión, hondonada". Otros estudiosos dicen que es un híbrido del griego κατά "hacia abajo" y de la raíz latina "-cumbo" que significa "yacer, estar acostado". 

Al principio se conocía con el apelativo de "ad catacumbas" a un distrito periférico de la vía Appia próximo a la basílica de San Sebastián. Era la hondonada donde se encontraba el cementerio de San Sebastián al que se descendía por una cuesta; de ahí se fue extendiendo la palabra a otros cementerios aunque no hubiese dicha hondonada. En aquel lugar se habían enterrado provisionalmente los cuerpos de Pedro y Pablo en el año 258. Este hecho está avalado por catas arqueológicas y pruebas epigráficas. Siglos más tarde, especialmente desde los comienzos de la Edad Media se fueron nombrando así todos los enterramientos cristianos de los alrededores de Roma. 

Antes del uso generalizado de la palabra catacumba los cristianos llamaban cementerio (en latín "coemeterium" del griego κοιμητήριον "dormitorio") al sitio de las tumbas, es decir, al lugar donde el cuerpo muerto duerme esperando el despertar que es el resucitar a otra vida. En castellano es un término que empezó a utilizarse en el siglo XVIII entre 1765 y 1783. 

El sistema de enterramiento en galerías y cámaras subterráneas no es privativo de los cristianos pues hay precedentes en otros pueblos y otras culturas. Hay constancia de que en el siglo I existía este tipo de enterramiento entre los hebreos y sin embargo las catacumbas cristianas como tales datan de la primera mitad del siglo II. Los primeros cristianos seguidores de Cristo que vivían en Roma en número reducido sepultaban a sus muertos según era costumbre en necrópolis al aire libre. Lo más probable es que pasado el tiempo los nuevos cristianos se asociaran siguiendo así también la costumbre pagana de formar "collegia" o grupos privativos. 

Las catacumbas eran esencialmente cementerio. Sus estrechas galerías no servían para organizar reuniones ni ceremonias religiosas aunque ocasionalmente se celebraba algún acto conmemorativo ante una determinada tumba. Pero en tiempos de Decio y Valeriano corrió el rumor de que los cristianos aprovechaban las catacumbas para reuniones clandestinas y conspiraciones y por eso el emperador Valeriano procedió a su confiscación. Fueron devueltas en el año 260. Más tarde ocurrió lo mismo en tiempos de Diocleciano; él mismo las restituyó sin límite de fecha en el año 311, antes del Edicto de Milán.

Después del año 313 se empezó a apreciar una disminución de los enterramientos en cámaras y galerías subterráneas hasta que por último finalizaron del todo en el siglo V. A partir de ese momento y ya sin el uso original sólo se las tuvo en cuenta como lugares respetables de recuerdo y peregrinación. Pasados los años desapareció hasta su recuerdo y en el siglo IX ya no había memoria de ellas. Así habría continuado la historia de no haber sucedido un hecho fortuito: En 1578 fueron descubiertas por unos obreros que estaban trabajando en la extracción de puzzolana. Ante este descubrimiento el arqueólogo Antonio Bosio (1575-1629) comenzó su estudio con gran interés. Pero fue en el siglo XIX cuando verdaderamente hubo un estudio sistemático y profundo por parte de otro gran arqueólogo llamado Giovanni Battista de Rossi (1822-1894) que en 1864 publicó el primer volumen de su "Roma sotterranea cristiana" («Roma subterránea cristiana»). En el siglo XX siguieron apareciendo más galerías de catacumbas en las afueras de Roma: catacumbas de los Aurelios en Viale Manzoni, descubiertas en 1919; catacumbas de la Vía Latina en 1955.

En un principio se dio el nombre de catacumbas al cementerio de San Sebastián, aquel lugar donde los primitivos cristianos de Roma habían enterrado provisionalmente los cuerpos de San Pablo y San Pedro, en un momento en que temieron que les fueran sustraídos. Era el lugar llamado «ad catacumbas». Por extensión, a lo largo de la Edad Media se fue dando este nombre de catacumbas a todos los cementerios conocidos de las afueras de Roma que formaban una gran necrópolis y tenían sus propias características. Siguiendo esa extensión se llamaron también catacumbas a todos los cementerios subterráneos encontrados en otros lugares aunque perteneciera a épocas muy diferentes y mucho más modernas. Tal ocurrió en la propia Italia con los enterramientos de Nápoles cuyas galerías más antiguas son de los siglos III y IV, perfectamente conocidos y descritos por el historiador G. Pelliccia y con las galerías subterráneas de Chiusi en Toscana, también de los siglos III y IV.

Las catacumbas de los Capuchinos, en la ciudad de Palermo, fueron excavadas como criptas por los monjes del monasterio. Las catacumbas de Lima, llamadas así por similitud con las de Roma, son unas criptas ubicadas bajo el convento de San Francisco; fue cementerio hasta 1810. Catacumbas de Kom el Shogafa llamadas también Catacumbas de Alejandría. Catacumbas de Odesa (actual Ucrania), con cerca de 2500 km de galerías. 

Las Catacumbas de París son uno de los cementerios más famosos de París en la capital de Francia. Son una serie de túneles y cuartos subterráneos localizados en lo que, durante la era romana fuesen minas de piedra caliza. El lugar fue convertido en un cementerio común a finales del siglo XVIII.


</doc>
<doc id="45300" url="https://es.wikipedia.org/wiki?curid=45300" title="Reino de Navarra">
Reino de Navarra

El Reino de Navarra (en euskera: Nafarroako Erresuma fue uno de los reinos medievales de Europa situado en ambas vertientes de los Pirineos occidentales, pero con la mayor parte de su territorio localizado al sur de la cordillera pirenaica, en el norte de la península ibérica. Fue el sucesor, desde 1162, del reino de Pamplona, fundado en torno a la capital navarra en 824, según afirman algunos historiadores. Tras unos primeros años de expansión y la posterior merma territorial a manos de Castilla y Aragón, el Reino de Navarra se estabilizó con dos territorios diferenciados: la Alta Navarra, al sur de los Pirineos y en la que se encontraba la capital y la mayor parte de la población y los recursos, y la Baja Navarra o Navarra Continental, al norte de la cordillera pirenaica. Entre 1234 y 1512 estuvo vinculado con el Reino de Francia, y dentro de su órbita, durante varias siglos a través de varias dinastías (Champaña, Capetos, Évreux y Foix). En algunas ocasiones directamente unido al trono francés (como con los Capetos) entre 1284 y 1328. 
El fin de la independencia del reino se produjo cuando Fernando el Católico, y posteriormente su nieto borgoñón Carlos I de España, llevaron a cabo la conquista militar entre los años 1512 y 1528 con distintas resistencias. Se realizaron varios intentos de recuperar la independencia en los años siguientes y finalmente Carlos I de España se replegó de la Baja Navarra por su difícil control. Por lo que esta porción siguió siendo independiente manteniendo las dinastías Foix y Albret, hasta que se asoció dinásticamente a la Corona francesa al subir su rey, Enrique III, al trono galo. Así, los monarcas franceses se intitularon "«reyes de Francia y de Navarra»". La unión del reino de Navarra a Francia, puramente dinástica, se hizo conservando siempre sus propias instituciones (así, cuando Luis XVI convocó los Estados Generales de Francia, Navarra no envió formalmente diputados a estos, sino al rey en persona, de manera independiente y con su propio "Cuaderno de agravios"). Sin embargo, su estatus diferenciado dentro de la Corona terminó en 1789, al ser abolido como reino. Por otra parte, la Navarra peninsular o Alta Navarra se convirtió en uno más de los reinos y territorios de la Corona de Castilla y finalmente de la Monarquía Hispánica, estatus que conservó, gobernada por un virrey, hasta 1841, fecha en la que pasó a ser considerada "«provincia foral»" española mediante la posteriormente denominada Ley Paccionada, tras la Primera Guerra Carlista.

El reino de Navarra surgió de un pequeño territorio que, tras un periodo de expansión, fue menguando paulatinamente en extensión y poder, socavado por las disputas entre las clases dirigentes y las conquistas realizadas por los reinos vecinos.

El espacio navarro se estructuró de manera dual tras la invasión musulmana de la península en el siglo VIII. El norte permaneció poco tiempo bajo dominio musulmán y pronto se organizó en un núcleo cristiano de fugaz sometimiento al Imperio carolingio y con centro en la ciudad de Pamplona, población fundada en época romana como "Pompaelo" por Pompeyo sobre un asentamiento vascón preexistente, que algunos autores consideran se denominaba ya «Iruña». Su primer caudillo conocido fue Íñigo Íñiguez —o Íñigo Arista («"Enneco Cognomento Aresta"»)—, cabeza conocida de la considerada primera dinastía navarra.

En el sur, un noble hispano godo oriundo de la zona (Casius) pactó con los invasores musulmanes y se convirtió al islam, consiguiendo así continuar señoreando esa zona del valle del Ebro y prolongando este poder entre los de su estirpe (los Banu Qasi), que durante generaciones afirmarán su poder en el sur del actual territorio navarro, aliándose con los Arista en diversas ocasiones en contra del poder central del emirato cordobés, o del afán expansionista del Imperio carolingio.

Navarra fue uno de los núcleos montañeses de resistencia cristiana impulsados por los francos carolingios que se formaron en los Pirineos, frente a la dominación islámica de la península ibérica, al igual que en Aragón y Cataluña. Inicialmente fue conocido por los cronistas francos como "Reino de los Pamploneses o Reino de Pamplona" y poco más tarde, como "Reino de Pamplona-Nájera" en referencia a la importancia en su organización de la ciudad riojana. 

En su etapa de mayor expansión territorial, durante la Edad Media, el reino abarcó territorios atlánticos y se expandió más allá del río Ebro, hacia territorios situados en las comunidades autónomas contemporáneas de Aragón, Cantabria, Castilla y León, La Rioja, País Vasco y las regiones administrativas francesas de Aquitania y Mediodía-Pirineos, en las antiguas provincias de Gascuña y Occitania. Las capitales vascas de Vitoria y San Sebastián fueron fundadas por el rey navarro Sancho VI el Sabio.

En su etapa final, el reino resultó dividido en:


El título del príncipe heredero es Príncipe de Viana, que hoy en día ostenta Leonor de Borbón y Ortiz, hija y heredera del rey Felipe VI de España.

Para el periodo de la historia de los vascones contemporánea a la formación y consolidación del reino visigodo en Hispania hay escasas fuentes directas disponibles sobre los acontecimientos y la organización interna de los vascones, y con frecuencia resultan contradictorias. 

Algunos historiadores suponen que los vascones nunca fueron sometidos por los visigodos en su pretensión de lograr la unidad territorial de todas las antiguas provincias hispanorromanas. Otros autores, principalmente en el siglo XIX, supusieron que los visigodos sí llegaron a dominar la tierra de los vascones. La escasez de datos ha llevado a crear la leyenda sobre el "Domuit vascones" (dominó a los vascones), una supuesta frase que se incluiría en las crónicas de todos los reyes godos, pero que parece ser una invención del novelista Francisco Navarro Villoslada. 

Las reflexiones de otros especialistas recuerdan la actitud amistosa de los vascones en el periodo romano y la ausencia de conflictos relevantes durante el Bajo Imperio, resaltando la dificultad de explicar aquellos enfrentamientos sin apoyarse en el contexto de la afirmación del poder autónomo en Aquitania y las rivalidades entre francos y visigodos.

La dominación visigoda de Pamplona es un tema políticamente polémico. Pese a haber sido sede episcopal de la iglesia visigoda, y a haber necrópolis visigodas en Pamplona, existe alguna polémica sobre si existió o no dominación visigoda sobre la ciudad o, simplemente, convivencia. Los testimonios arqueológicos y documentales han recibido diversas interpretaciones en algunos casos derivadas de la polémica política. 

En el año 632 el rey merovingio Dagoberto I encabezó una expedición a Zaragoza en apoyo de Sisenando que se había sublevado frente a la autoridad de Suintila. Pocos años después, Dagoberto reunió un ejército de burgundios con los que intentó ocupar sin éxito toda la "patria de Vasconia" en el 635. Sin embargo, en el 636 Dagoberto obtuvo tras una nueva campaña militar, el juramento de lealtad de los vascones al servicio de Aighina, duque sajón de Burdeos. Tras la muerte de Dagoberto, el poder merovingio se fue debilitando para dar paso a un periodo de consolidación de un poder autónomo conocido como ducado de Aquitania dentro del reino franco pero del que se desconocen fuentes de referencia hasta que es citada la concesión a Félix, patricio de Toulouse, del control de todas las ciudades hasta los Pirineos y de los vascones hacia el 672. Para algunos autores, la política de enfrentamiento con el poder franco por parte de Félix, habría sido continuada por su sucesor Lupo, proceso que culminaría en tiempos de Eudes que lograría el reconocimiento de "regnum" para la parte meridional de la antigua Galia.

Durante los siglos VI y VII, hay teorías que dicen que los vascones del norte cruzaron los Pirineos, ocupando Aquitania, en la actual Francia, donde su lengua influyó en el idioma romance que daría lugar al gascón, a la que dieron el nombre de Gascuña.

Durante el invierno del 713 los ejércitos musulmanes alcanzaron el valle medio del Ebro que se encontraba gobernado por el conde hispanovisigodo Casio quien eligió someterse al califa Omeya y convertirse al islam dando origen a la estirpe de los Banu Qasi a cambio de mantener su poder en la región. Pamplona sin embargo fue finalmente ocupada tras oponer resistencia en el 718 y obligada a pagar tributo a los gobernadores musulmanes que establecieron un protectorado. La derrota musulmana en la batalla de Poitiers en 732 frente a los francos de Carlos Martel debilitaron la posición musulmana pero el valí Uqba recondujo la situación instalando una guarnición militar en la ciudad entre el 734 y el 741.

La Marca Hispánica fue la frontera político-militar del Imperio carolingio al sur de los Pirineos. Tras la conquista musulmana de la península ibérica, este territorio fue dominado mediante guarniciones militares establecidas en lugares como Pamplona, Aragón, Ribagorza, Pallars, Urgel, Cerdaña o Rosellón. A fines del siglo VIII, los carolingios intervinieron en el noreste peninsular con el apoyo de la población autóctona de las montañas. La dominación franca se hizo efectiva entonces más al sur tras la conquista de Gerona (785) y Barcelona (801). En la Marca Hispánica, integrada por condados dependientes de los monarcas carolingios, a principios del siglo IX, los condes francos son sustituidos por nobles autóctonos.

El territorio ganado a los musulmanes se configuró como la Marca Hispánica, en contraposición a la Marca Superior andalusí, e iba de Pamplona hasta Barcelona. De todos ellos, los que alcanzaron mayor protagonismo fueron los de Pamplona, constituido en el primer cuarto del siglo IX en reino; Aragón, constituido en condado independiente en 809; Urgel, importante sede episcopal y condado con dinastía propia desde 815; y el condado de Barcelona, que con el tiempo se convirtió en hegemónico sobre sus vecinos, los de Ausona y Gerona.

Carlomagno, aprovechando la rebelión del gobernador de Zaragoza para intervenir en la Península, atravesó con un ejército franco el territorio vascón y destruyó las defensas de Pamplona en su avance hacia Zaragoza, donde a su llegada el cambio de las alianzas de los sublevados le obligó a retirarse. El interés de Carlomagno en los asuntos hispánicos le movió a apoyar una rebelión en el Vilayato de la Marca Superior de al-Ándalus de Sulaymán al-Arabi, que pretendía alzarse a emir de Córdoba con el apoyo de los francos, a cambio de entregar al emperador franco la plaza de Saraqusta. 

Carlomagno llegó en el año 778 a las puertas de la ciudad, sin embargo Husayn, el valí de Zaragoza, se negó a franquear la entrada al ejército carolingio. Debido a la complejidad que supondría un largo asedio a una plaza tan fortificada, con un ejército tan alejado de su centro logístico, desistió e inició el camino de vuelta a su reino. Tras reducir a ruinas Pamplona, la capital de los vascones aliados de los Banu Qasi, el 15 de agosto de 778, Carlomagno con el más poderoso ejército del siglo VIII se dirigía al norte por el paso de Roncesvalles, entre el collado de Ibañeta y la hondonada de Valcarlos. En ese punto fueron objeto de una contundente emboscada por partidas de nativos vascones, probablemente instigados por los fieles a los hijos de Sulaymán, Aysun y Matruh ben Sulayman al-Arabí, que provocaron un descalabro general a la retaguardia de su ejército, mandada por su sobrino Roldán, a base de lanzarles rocas y dardos. La "Chanson de Roland", inmortalizó el evento. La independencia de los condados occidentales respecto del rey Carlomagno se decidió en el fracaso de la toma de Saraqusta.

 
Al menos hasta el año 1130, los reyes se denominaban "Pampilonensium rex". Incluso Sancho VI de Navarra llega a utilizar esa denominación el año 1150, cuando normalmente empleaba la de "rex Nauarre".

El Reino de Pamplona es la denominación empleada por algunos historiadores, de acuerdo a los "Anales de los Reyes Francos" para referirse a lo que fue durante la Alta Edad Media la entidad política surgida en torno a la "civitas" de "Pompaelo", la que había sido la principal ciudad en territorio de los vascones durante la época de la Antigua Roma en la región de los Pirineos occidentales, y al liderazgo de la figura de Íñigo Arista quien fundó la dinastía real y la entidad en el 824, con el apoyo de sus aliados de la familia de los Banu Qasi, señores de Tudela, y del obispado de Pamplona. No existe un consenso entre los especialistas para discernir el número preciso de monarcas y la duración de sus mandatos, como tampoco sobre la extensión de su territorio e influencia.

La dinastía de los Íñiguez terminó con Fortún Garcés quien según la tradición, que lo conoce como Fortún el Monje, abdicó y se retiró al monasterio de Leire, siendo sustituida por la de los Jiménez en el 905 que comenzó con Sancho Garcés I (905-925) cuyo reino es conocido como "Reino de Pamplona o Navarra".

Pamplona fue durante mucho tiempo la ciudad más importante y rica en territorio cristiano, numerosos intentos por hacer de ella su capital, fueron hechos por pequeños grupos montañeses de cristianos y más tarde por los territorios cercanos. Además de contar con una población numerosa y estable por encontrarse en el valle rico y fértil del río Arga; Era un lugar de reunión e intercambio entre las rutas del mundo islámico al sur y la Europa cristiana al norte, por los pasos pirenaicos vascos y los puertos costeros del mar Cantábrico y las rutas de este a oeste que seguían también los peregrinos cristianos del Camino de Santiago hacia el reino de León, que atravesaba los condados francos del Imperio carolingio en las actuales Navarra, Aragón y Cataluña desde la costa mediterránea condal, y más allá, a través de los puertos mediterráneos.
Su neutralidad y buenas relaciones con los belicosos vecinos, la fama de prosperidad y riqueza: comercio e intercambio de artesanías en cuero, instrumentos musicales, libros y armas, materias primas: marfíl, piedras preciosas, paños, aceite, seda, lana, oro, especias... llegó hasta los vikingos.

La constante amenaza que sobre las tierras vasconas se ejercía desde ambas vertientes de los Pirineos favoreció el surgimiento de dos facciones líderes entre la aristocracia vascona, los Íñigo apoyados en los musulmanes por parentesco con los Banu Qasi, y los Velasco apoyados por los francos carolingios. Cuando en el 799 es asesinado por partidarios carolingios el gobernador de Pamplona Mutarrif Ibn Musa, los Íñigo recurrieron a la familia Banu Qasi para retomar el control de la ciudad. Sin embargo, en el 812 el emir Al-Hakam I y Ludovico Pío acordaron una tregua por la que los carolingios tomaban el control de Pamplona, delegando el gobierno en Velasco al Gasalqí. Al término de la tregua, Al-Hakam retomó las hostilidades con los francos y logró recuperar Pamplona en el 816 a cuyo control los francos renunciaron en adelante. Íñigo Arista, sería designado primer rey de Pamplona hasta el 851.

La primera dinastía navarra (los Arista) será reemplazada tras tres reinados y en un episodio todavía misterioso por la dinastía Jimena, que ampliaría el solar del reino con la incorporación de las tierras riojanas y la Zona Media navarra, bajo la cual Navarra alcanzará la mayor extensión territorial a costa del Islam y de los señoríos cristianos vecinos. 

La costa mediterránea, cuajada desde antiguo de torres de vigía contra la piratería berberisca, al grito de "Moros en la Costa" ve en el 858 a los normandos que suben por el Ebro desde Tortosa, lo remontan hasta el reino de Navarra, dejando atrás las inexpugnables ciudades de Zaragoza y Tudela. Suben luego por su afluente, el río Aragón hasta encontrarse con el río Arga, el cual también remontan, llegan hasta Pamplona y la saquean, raptando al rey navarro. En el 859 los vikingos llegan a Pamplona y secuestran al nuevo rey García I Iñíguez. Solo tras pagar un costoso rescate el rey vuelve a Pamplona, pero a partir de entonces la vieja alianza entre los Arista y los Banu Qasi se ha roto y García I será aliado del reino de Asturias. 

Debido a los problemas internos de cordobeses y al cambio de actitud de los navarros, el único enemigo de Ordoño I va a ser el caudillo de los Banu Qasí, Musa ibn Musa, quien se titulaba "tercer rey de España". En continua rebelión contra Córdoba, trata de asegurar el valle del Ebro a su paso por la Rioja. Musa, en el 855 va a realizar una dura "razzia" contra Álava y al-Qilá (Castilla) y tras ella se preocupa de restaurar y fortalecer la guarnición militar de Albelda. Viendo la amenaza que esta fortaleza supone sobre los dominios orientales del reino asturiano, Ordoño I y los navarros lanzan una ofensiva contra Albelda. Tras una dura lucha, Ordoño toma la fortaleza y la arrasa. Esta batalla dará lugar en el siglo XII a la legendaria batalla de Clavijo que por muchos es considerada sólo una leyenda forjada por el arzobispo Rodrigo Jiménez de Rada.

Musa II seguirá peleando contra navarros y cordobeses hasta su muerte en el 862. Mientras tanto su hijo Lupp o Lope ben Musà, gobernador de Toledo, se declarará vasallo de Ordoño I. La navarra de origen vascón, Subh, Subh umm Walad, madre del tercer Califa de Córdoba, Hixem II, y una de las mujeres más influyentes de la época islámica, nació probablemente en la década de 940 y murió hacia 999. 
 
El navarroaragonés, una lengua romance, anterior al castellano, hablada en el valle del Ebro durante la Edad Media, con reductos actuales en el Pirineo aragonés, conocidos como aragonés y préstamos en el castellano de La Rioja, Ribera de Navarra y Aragón, con diferentes gradaciones. Tiene su origen en el dialecto latino, durante el Reino de Pamplona, sobre un acusado sustrato vascón. La lengua recibe, en su período medieval, la denominación entre los lingüistas de "navarroaragonés", por la inicial dependencia aragonesa del Reino de Navarra.

La llamada "Reconquista", o expansión del Reino de Navarra sobre tierras musulmanas y cristianas, con la consiguiente repoblación con cristianos del Reino de Navarra, llevaría consigo el idioma por todo el territorio conquistado. La anexión por el Reino de Navarra de los condados aragoneses supuso una importante influencia de la lengua navarroaragonesa sobre los territorios posteriores de la Corona de Aragón y en el castellano.
La primera constancia escrita de la lengua está en las Glosas Emilianenses, en el Monasterio de San Millán de la Cogolla (La Rioja).

El apogeo se producirá con Sancho III el Mayor. Ascendió al trono entre el año 1000 y el 1004, heredando el reino de Navarra y el condado de Aragón, bajo la tutoría de un consejo de regencia integrado por los obispos y su madre, e incorporando extensos territorios a sus dominios, como el condado de Castilla además del solar tradicional del reino (Pamplona y Nájera). La unión dinástica con Aragón se dio en dos periodos: del año 1000 al 1035 y del año 1076 al 1134.

Bajo su mandato el reino cristiano de Nájera-Pamplona alcanza su mayor extensión territorial, abarcando casi todo el tercio norte peninsular, desde Astorga hasta Ribagorza en la reorganización del reino, se cree que creó el vizcondado de Labort, entre 1021 y 1023, con residencia del vizconde en Bayona y el de Baztán hacia 1025. A la muerte del duque Sancho Guillermo de Vasconia, duque de Vasconia, el día 4 de octubre de 1032, trató de extender su autoridad sobre la antigua Vasconia ultrapirenaica comprendida entre los Pirineos y el Garona, aunque no lo consiguió, al heredar el ducado Eudes.

Tenía su residencia en Nájera, extendiendo sus relaciones más allá de los Pirineos, con el ducado de Gascuña, y aceptando las nuevas corrientes políticas, religiosas e intelectuales. 

Su reinado coincidió con la crisis del mundo califal, iniciado a la muerte de Almanzor y terminado con el principio de los Reino de Taifas. Pretendió la unificación de los estados cristianos, bien por vínculos de vasallaje o bajo su propio mando. 

En 1016 fijó las fronteras entre Navarra y el Condado de Castilla, e inició un período de relaciones cordiales entre ambos Estados, facilitadas por su matrimonio con Munia, también conocida como Muniadona, hija del conde castellano Sancho García. De este matrimonio nacieron Fernando (Fernando I de Castilla), Gonzalo (Conde de Sobrarbe y Ribagorza) y las hijas Mayor y Jimena, reina de León al casarse con Bermudo III.

Aprovechó las dificultades internas de Sobrarbe-Ribagorza para hacer valer sus intereses como descendiente de Dadildis del Pallars y apoderarse del condado (1016-1019). 

Fue encargado de la tutela del conde García de Castilla. Alfonso V de León aprovechó esta situación para apoderarse de las tierras altas situadas entre el río Cea y el Pisuerga. Sancho III se opuso a la expansión leonesa y pactó el matrimonio entre García de Castilla y Sancha de León. A la muerte de Sancho III el Mayor, le hereda su primogénito con obligación del resto de hermanos de rendirle vasallaje, pero estos no respetan la voluntad testamentaria del monarca y finalmente se divide el reino entre sus hijos, naciendo así los reinos de Aragón, Castilla y Navarra.
Durante el reinado de García Sánchez III (1035 - Atapuerca, 15 de septiembre de 1054) apodado ""el de Nájera"", y su hijo Sancho Garcés, Navarra se separa de los reinos vecinos.

En 1076, tras el asesinato de Sancho IV, el de Peñalén (arrojado por un precipicio así llamado ubicado en Funes) Pamplona y Aragón volverán nuevamente a estar juntos casi 60 años durante el reinado de tres monarcas: Sancho Ramírez (1076-1094), su hijo Pedro I (1094-1104) y, finalmente, el hermano de éste, Alfonso I el Batallador (1104-1134), siendo en este período cuando se consuma la toma de Tudela y su distrito. Tras la muerte sin descendencia de Alfonso I (1134) ni aragoneses ni navarros respetaron el testamento de su rey emperador Alfonso, que dejaba los reinos a la orden del Temple y a otras órdenes militares, escogiendo cada reino un rey diferente, separándose las coronas de Pamplona y Aragón después de 50 años. En lo que será Navarra le sucede García Ramírez de Pamplona, el Restaurador (1134-1150).

Al separarse de Aragón, Navarra se convierte en un reino sin posibilidad de expansión, al no tener frontera con los territorios musulmanes y encontrarse encajonado entre los ahora mucho más poderosos Castilla y Aragón, territorialmente el reino de Navarra fue paulatinamente reduciéndose, aunque culturalmente continua su expansión. 

Así, el Laudo arbitral del Rey Enrique II de Inglaterra de 16 de marzo de 1177, realizado entre los Reyes Alfonso VIII, por parte de la corona de Castilla, y Sancho VI el Sabio, por parte del Reino de Navarra, relativo a la pertenencia territorial y límites fronterizos, fue emitido tras aceptar ambos un Pacto-Convenio el 25 de agosto de 1176 en el que aceptaban el arbitrio del rey inglés y que se respetaría una tregua de siete años. Dicho laudo dispuso la entrega a Castilla de ciertos territorios, principalmente de La Rioja, recibiendo Navarra en contraprestación entre otros los territorios de Álava, Guipúzcoa y el Duranguesado (Vizcaya), además de una compensación económica. Ninguna de las partes cumplió el dictamen, aunque posteriormente ambas partes acordaron acatar únicamente lo relativo a la situación de los territorios de la actual comunidad de La Rioja, que dejó ya de pertenecer al Reino de Navarra desde esa fecha. Existen varias interpretaciones de dicho laudo.

El expansionismo castellano y aragonés hizo menguar el territorio navarro. La determinación de repartírselo, consta en varios tratados realizados por dichos reinos en el siglo XII. Los reyes de estos dos reinos firmaron el "Tratado de Cazola" de marzo de 1179 o el de 1198, para repartirse el reino de Navarra, teniendo como nueva frontera entre ambos reinos el río Arga, que cruza Navarra de norte a sur. 

Así hacia 1200 y a pesar de un labor repobladora navarra de la zona (que dio como fruto, entre otros, la fundación de Vitoria y San Sebastián, dos de las tres capitales de la actual comunidad autónoma del País Vasco), Castilla, apoyada en la baja nobleza, consiguió el apoyo de facciones locales en el Duranguesado, y en Álava, después de haber sitiado Vitoria durante nueve meses. 

En cuanto a Guipúzcoa, se ha solido creer que debido a la superioridad militar demostrada por el ejército castellano mandado por el Señor de Vizcaya en Vitoria y ante la entrada de las tropas castellanas en su territorio, Guipúzcoa se incorporó a Castilla mediante negociación. Sin embargo, a raíz de la relectura de fuentes históricas conocidas, hay que reconsiderar esta creencia, puesto que se ha descubierto que al igual que Vitoria, San Sebastián fue también conquistada militarmente.

Los parientes mayores de Guipúzcoa, que ya estaban divididos en dos bandos irreconciliables, mantuvieron sus posiciones: los oñacinos, apoyaban la agregación a Castilla, y los gamboínos, defendían la continuación de la unión con Navarra.

A su vez estos bandos tenían el apoyo de las facciones navarras y así los beamonteses apoyaban a los oñacinos y los agramonteses a los gamboínos.

El trabajo de los monarcas del siglo XIII, tras la conquista parcial de Navarra, se basará en la reconstrucción y reorganización interior del reino y en hacer frente a las continuas apetencias de reparto entre sus vecinos. Pese a todo, y persuadido personalmente por el arzobispo de Toledo, el puentesino Rodrigo Jiménez de Rada, participará en empresas como la batalla de las Navas de Tolosa (1212), en la que destacó el monarca navarro Sancho VII el Fuerte.

La muerte sin descendencia de Sancho VII el Fuerte, a pesar de haber dejado un pacto de prohijamiento con Jaime de Aragón, supone la entronización en Navarra durante casi dos siglos de dinastías francesas (la de Champaña, la Capeta y la de Évreux), que también dispondrán de territorios en Francia y descuidarán en diverso grado el gobierno del pequeño reino.

La ciudad de Pamplona estaba dividida en burgos independientes y enfrentados (Navarrería y San Miguel frente a los burgos de San Cernín y San Nicolás), aliados con otros Estados siendo, por ejemplo, arrasado el barrio de la Navarrería por tropas francesas en 1276 y extendiéndose la confrontación por toda Navarra, venciendo estos a los aliados castellanos e implantando el acercamiento de Navarra a Francia.

Tras la instauración de la Casa de Trastámara en Aragón a mediados del siglo XV, la crisis sociopolítica del reino fue paulatinamente polarizando a las fuerzas vivas de Navarra en torno a dos bandos: los beamonteses y los agramonteses. 

Es este un conflicto complejo con posiciones y actitudes cambiantes que aparentemente es un conflicto entre facciones nobiliarias, pero que parece también evidenciar algún tipo de enfrentamiento socioeconómico montaña-ribera, según unos autores. De todas formas ambas facciones tenían una distribución por toda Navarra. Este enfrentamiento llevaría a una guerra civil en 1441, cuando Juan II de Aragón (rey consorte de Navarra) se quedó para sí el trono, en vez cederlo a su hijo Carlos, Príncipe de Viana, al que le correspondía. Carlos había sido designado heredero del reino por el testamento de su madre la reina Blanca, aún prescribiendo dicho documento que no tomara posesión del reino sin el beneplácito de su padre Juan II. En 1452 el príncipe fue apresado en la batalla de Aibar.

La guerra civil persistió tras la muerte de Carlos, Príncipe de Viana en 1461 y a la de Juan II en 1479. Los beamonteses tenían el apoyo de los castellanos, mientras que los agramonteses tuvieron primero como aliados a los aragoneses (por ser Juan II rey de Aragón) y luego a los franceses.

Demográficamente el Reino de Navarra había alcanzado mínimos entre los años 1450 y 1465, coincidiendo con los episodios más agudos del conflicto civil (que no fue sangriento de forma directa); a la pérdida de población debida a los sabotajes se suma la epidemia de peste entre los años 1504 y 1507, recuperando mayores cotas poblacionales a partir de 1530 (una vez realizada y asentada la conquista de Navarra por parte de Castilla y Aragón).

A finales del siglo XV el rey de Aragón Fernando el Católico realizaba continuas injerencias en la guerra civil de Navarra en apoyo a los Beaumonteses y que en algunos periodos había supuesto una auténtica ocupación militar. A principios del siglo XVI los beaumonteses habían perdido la guerra civil y su líder había huido al exilio castellano, donde falleció. Desde allí su descendiente apoyó al rey aragonés en su ya decidida invasión del reino de Navarra. Esto hizo que en 1512 el rey de Navarra se viera obligado a firmar el Tratado de Blois, por el cual conseguía apoyo del reino de Francia ante una posible agresión. Esto fue considerado por Castilla y Aragón como una beligerancia, ya que Francisco I de Francia estaba enfrentado al castellano-aragonés y además era declarado un monarca cismático en el V Concilio de Letrán por el papa Julio II.

Fernando el Católico, que era hermanastro del fallecido Carlos Príncipe de Viana (hijo de Juan II y su primer matrimonio con la reina Blanca I), inició la invasión el 10 de julio con la toma de Goizueta, aunque no se publicitó y ocho días antes de la firma del Tratado de Blois. El grueso del ejército de más de 16 000 hombres bien pertrechados y experimentados entró en Navarra desde Álava el día 22 de julio, al mando de Fadrique Álvarez de Toledo, segundo duque de Alba con apoyo del líder beaumontés conde de Lerín (Condestable de Navarra) y sus hombres. 

El poderoso ejército se asentó a las afueras de Pamplona (concretamente en el palacio de Arazuri, dominado por el bando beamontés), entonces una ciudad de entre 6000 y 10 000 almas y mal fortificada, que firmó la rendición 25 de julio. El archivo de Simancas contiene documentos relativos a esta época.

En otros lugares de Navarra, la resistencia fue mayor: Lumbier hasta el 10 de agosto, Estella hasta agosto, Viana hasta el 15 de agosto, Roncal hasta el 9 de septiembre, al igual que Tudela, que fue el mayor bastión agramontés, donde para tomarlo tuvieron que venir fuerzas de Aragón. Los reyes navarros Juan y Catalina se refugiaron en sus dominios del Bearn desde donde organizaron la resistencia.

La conquista de la Alta Navarra no finalizó aquí, ya que Catalina de Foix y Juan III de Albret, y posteriormente Enrique II, apoyados por los monarcas franceses, hicieron hasta tres intentos militares de recobrar el reino.

El primero lo realizaron ese mismo año, en noviembre, cuando un ejército de navarros agramonteses, franceses y mercenarios se adentraron en el reino con 15 000 hombres al mando de Juan de Albret y el general La Palice. Varias ciudades del interior se alzaron, como Estella, Cábrega, Villamayor de Monjardín y Tafalla, llegando a sitiar Pamplona del 3 al 30 de noviembre. Ante la llegada de refuerzos castellanos por el Perdón, se realizó un asalto precipitado el 27 de noviembre de Pamplona, que fracasó. Debido a la proximidad del invierno, las tropas franco-navarras iniciaron la retirada hacia el Baztán. En el puerto de Velate, la retaguardia fue sorprendida por fuerzas castellanas, en las que predominaban guipuzcoanos oñacinos, al mando de López de Ayala, en la que ha sido denominada batalla de Velate con la derrota y pérdida de doce piezas de artillería, y se discute si también se produjo la pérdida de más de mil hombres de los franco-navarros.

La segunda tuvo lugar en 1516, aprovechando la muerte de Fernando el Católico y la complicada sucesión castellana. El ejército, al mando del mariscal Pedro de Navarra, mal pertrechado y equipado, fue derrotado en el Roncal por el coronel Cristóbal de Villalba. El mariscal fue hecho prisionero (moriría asesinado en el castillo de Simancas en 1522). Para evitar posteriores problemas, el cardenal Cisneros, regente de Castilla, ordenó la demolición de todas las fortalezas, exceptuando las estratégicas y las pertenecientes a los aliados beamonteses.

Sin éxito la vía militar, se intentó la diplomática. Así tuvieron lugar dos encuentros entre las partes, en Noyón (1516) y Montpellier (1519), que no arrojaron ningún éxito, por lo que los reyes navarros, apoyados por Francia, realizaron un último intento bélico.

En 1521, aprovechando la Guerra de las Comunidades que asolaba Castilla, y reinando Enrique II, que contaba con el apoyo incondicional de Francisco I de Francia, deseoso de debilitar a toda costa a Carlos I, tuvo lugar un alzamiento generalizado en toda Navarra, incluyendo las ciudades beamontesas, al tiempo que un ejército navarro-gascón que vino por el norte, consiguió reconquistar toda Navarra. Sin embargo, el ataque se había demorado demasiado, no produciéndose hasta mayo, cuando en abril los comuneros habían sido aplastados por las tropas reales. Además, en vez de consolidar la victoria, el ejército navarro-gascón quiso entrar en Logroño sitiándolo, lo que hizo que el ejército castellano se reorganizara con tres cuerpos de ejército. El diez de junio las tropas comenzaron a retirarse por la presión de las tropas castellanas en un número que triplicaba a las navarras. Hubo algún enfrentamiento en Puente la Reina, y tras cometer varios errores estratégicos, finalmente se enfrentaron en una cruenta batalla de Noáin (30 de junio de 1521), a las afueras de Pamplona, donde no menos de 5.000 combatientes perdieron la vida. Tras esta derrota, los restos del ejército franco-navarro se dispersaron, aunque hacia octubre algunos combatientes se hicieron fuertes en el castillo de Maya (valle de Baztán), donde resistieron hasta el 19 de julio de 1522 y en la fortaleza de Fuenterrabía, que resistió hasta marzo de 1524. En diciembre de 1523, Carlos I decretó un perdón para los sublevados, excluyendo a unos setenta miembros de la nobleza navarra. Para conseguir la caída de Fuenterrabía, el emperador decretó un nuevo perdón, incluyendo a los excluidos del anterior, a condición de que se le prestase juramento de fidelidad. Así terminaron los intentos tanto por recobrar la independencia de la Alta Navarra. La inestabilidad de la ocupación en la Baja Navarra hizo que Carlos I renunciara definitivamente a ella, retirándose definitivamente para 1530, donde el rey de Navarra Enrique II, mantuvo la independencia del reino.

A pesar de los diversos intentos de reconquista, Fernando el Católico había seguido trabajando para consolidar la incorporación institucional de Navarra a sus dominios. En 1513, las Cortes de Navarra, convocadas en Pamplona por el virrey castellano y sólo con la asistencia de beamonteses, nombraron a Fernando el Católico rey de Navarra. El 7 de julio de 1515 las Cortes de Castilla en Burgos, sin ningún navarro presente, anexionan el Reino de Navarra al de Castilla. El nuevo rey se comprometió a respetar los fueros del reino.

Los reyes posteriores continuaron jurando las leyes propias navarras. Sin embargo, a partir del siglo XVIII, los fueros comenzarán a ser definitivamente atacados hasta ser abolidos en el siglo XIX. Como justificación ideológica adicional, aparte del tratado de Blois (que fue la excusa que consideró a Navarra en un estado enemigo) Fernando el Católico tuvo a su favor el hecho de que el papa Julio II excomulgara a los reyes de Navarra y les desposeyera del reino alegando connivencias de la casa real navarra con el protestantismo que se estaba extendiendo por el sur de Francia y su alianza con el monarca francés, declarado cismático.

En 1516, el cardenal Cisneros ordena eliminar todos los signos defensivos de Navarra, debido a la imposibilidad de defender con el ejército castellano todos los castillos. Navarra llegó a tener más de un centenar de castillos en todo lo que fue el Reino de Navarra. Muy pocos han quedado en pie, y estos sólo parcialmente, desmochados.

Tras una irregular ocupación de la Baja Navarra, incluida San Juan de Pie de Puerto por parte de las tropas del emperador Carlos V, en 1528, este decide abandonar el territorio por su difícil defensa. En esta parte del reino de Navarra continuó la dinastía Albret-Foix que entroncaría con la de Borbón, quienes llegarían a reinar en Francia y aunque sus dominios en el Bearne eran mayores que los de Navarra, estos territorios navarros les conferían la dignidad real, y muy celosamente sus sucesores la conservaron separada, aún después de acceder al trono de Francia y llevaron la titulación de reyes de Francia y Navarra. Luis XIII aceptó una reconciliación de los "Fort et costumas deu Royaume de Navarra deça ports" en 1611 pero cuidando de que no se incluyeran capítulos de derecho público. En 1620 publicó el edicto de incorporación del Reino de Navarra junto a los territorios del Bearne, Andorra y Donnezan a la Corona de Francia, conservando a sus habitantes en sus fueros, franquezas, libertades y derechos.; en 1789, con la Revolución francesa se produjo la abolición de todos los privilegios de todos los territorios de la monarquía en un derecho común, suprimiéndose el título de reyes de Francia y Navarra en 1789, a pesar de la oposición de Navarra. En 1790, La Asamblea Nacional decretó la creación del departamento de Bajos Pirineos (actualmente Pirineos Atlánticos) en el que entraron el Bearne, la Baja Navarra y otras tierras próximas.

Desde ese momento la actual Navarra peninsular quedará integrada en la Monarquía Hispánica, no presentando inestabilidad de calado y permaneciendo con la corona castellana cuando hacia 1640 el sistema territorial de la monarquía de los Austrias entra en crisis con la separación de Portugal y la revuelta de Cataluña. Pese a todo, y de manera paulatina, conforme la rivalidad franco-española se traslade a otros ámbitos, Navarra se convertirá en un reino olvidado y cada vez más marginado de los focos de poder político y económico. La dinastía Habsburgo establecerá en Pamplona la figura de un virrey, permaneciendo con gran actividad las cortes del reino.

Durante la Guerra de Sucesión Española, Navarra (a pesar del fiero sentimiento antifránces del pueblo) se posicionará a favor del duque de Anjou (futuro Felipe V) en lugar de por el archiduque Carlos de Austria (como lo hicieron los reinos de la Corona de Aragón). Es por ello por lo que tanto Tudela como Sangüesa fueron ocupadas por las tropas austracistas. A la finalización del conflicto, Navarra, al igual que las provincias vascas, conservaron sus fueros frente a los reinos de la Corona de Aragón, declarados traidores por Felipe V y despojados de sus prerrogativas forales por los Decretos de Nueva Planta.

Lógicamente, la nueva dinastía reinante se mostró mucho más centralista y menos pactista que la Habsburgo y en diversas ocasiones el régimen foral fue puesto en entredicho desde el gobierno de la monarquía.

El 14 de noviembre de 1833 los rebeldes carlistas eligieron en Estella a Tomás de Zumalacárregui como su jefe. 

El general Maroto a cargo de las tropas carlistas del Norte y el general Espartero como representante del gobierno de Isabel II, el 29 de agosto de 1839, firman el Convenio de Oñate que puso fin a la Primera Guerra Carlista (1833-1840) en el norte de la península, confirmado con el conocido como ""el Abrazo de Vergara"" entre Maroto y Espartero el 31 de agosto. Maroto no contaba con el apoyo del pretendiente don Carlos y tampoco con la aveniencia de parte de sus tropas. El 14 de septiembre de 1839 el pretendiente carlista y las tropas que le permanecían fieles cruzaron la frontera francesa y la guerra iniciada en 1833, con el apoyo mayoritario de la población rural de Navarra al pretendiente real don Carlos, terminó en el frente norte.

En este convenio también se acuerda eliminar ciertas particularidades forales para adecuarlas a la constitución de 1837 ("Artículo 1.°. El capitán general, don Baldomero Espartero, recomendará con interés al Gobierno el cumplimiento de su oferta de comprometerse formalmente a proponer a las Cortes la concesión o modificación de los fueros".), según posteriormente se reflejaría en el de 1839, con el compromiso de respetar los fueros «"sin perjuicio de la unidad constitucional de la monarquía"», "oyendo" a Navarra y a las Provincias Vascongadas.

El gobierno liberal quería imponer sus principios centralistas y suprimir los fueros por considerarlos privilegios medievales injustos y por ello los liberales de la Diputación Provincial con Yanguas Miranda como cabeza visible, negocian con el gobierno central la supresión de casi todos los privilegios forales. De esta manera en 1841 y mediante la Ley de Modificación de Fueros de Navarra, después llamada Ley Paccionada Navarra, el Reino de Navarra dejó de existir y pasó a ser considerada como una «provincia foral», con lo que pierde definitivamente su soberanía en favor de una soberanía española. Con ello perdió prerrogativas, como la exención del servicio militar y la acuñación de moneda propia, así como el traslado de las aduanas del Ebro a los Pirineos. Sin embargo, la provincia seguía reteniendo amplia autonomía fiscal, administrativa y tributaria consignada en la Ley Paccionada de 1841.

El calificativo de "Paccionada" hacía referencia a que su promulgación fue "pactada" con la Diputación Provincial, la cual estaba controlada por los liberales navarros. Todo este proceso fue abiertamente criticado por Ángel Sagaseta de Ilurdoz Garraza último Síndico de la Cortes del Reino.

El ministro de Sagasta, Germán Gamazo, intentó suprimir en 1893 la autonomía fiscal de la Ley Paccionada, se produjo una reacción popular e institucional denominada como «Gamazada». Esta normativa no se llegó a aplicar debido a que el ministro dimitió por otras razones, entre otras, por la rebelión en Cuba de 1895.

La población hablaba vasco y variantes romances: el romance navarro endógeno, y la variante romance occitana languedociana, de carácter exógeno. El vasco seguiría siendo predominante entre la población rural, aunque, a pesar de su mayor arraigo entre el vulgo, era sin embargo escrito con poca frecuencia y de forma en cualquier caso informal. El romance navarro, adoptado como lengua de la cancillería real en 1223, dejando postergado al latín, fue lengua oficial del reino por lo menos desde 1329, Esta variante romance se impondría progresivamente al occitano en la lengua escrita, siendo reemplazada por el castellano al final de la Edad Media. Al norte de los Pirineos, en la Baja Navarra, los textos de las administraciones eclesiástica, señorial y municipal aparecen escritos en romance navarro y en gascón.






</doc>
<doc id="45301" url="https://es.wikipedia.org/wiki?curid=45301" title="Nuevos Países Bajos">
Nuevos Países Bajos

Los Nuevos Países Bajos () fue una provincia colonial de la República de las Siete Provincias Unidas en la costa noreste de Norteamérica. La colonia abarcaba desde la península Delmarva hasta el extremo suroeste del cabo Cod. Este territorio ahora forma parte del Atlántico Medio estadounidense, el cual comprende los actuales estados de Nueva York, Nueva Jersey, Delaware y Connecticut, así como pequeñas zonas de Pensilvania y Rhode Island. La capital provincial era Nueva Ámsterdam (actual Nueva York), localizada en el extremo sur de la isla de Manhattan. 

La colonia fue concebida como una empresa privada para explotar el comercio de piel. Los Nuevos Países Bajos fue poblada lentamente durante sus primeras décadas de existencia y ello se debió tanto a la mala administración de la política en la nueva colonia por la Compañía Neerlandesa de las Indias Occidentales como por conflictos con indígenas de la zona. Por otra parte, la colonización de Nueva Suecia se desarrolló en la parte sur, aunque su frontera al norte fue rediseñada más tarde a causa de la temprana expansión de Nueva Inglaterra. Durante la década de 1650, la colonia creció exponencialmente y se convirtió en un puerto humilde en el Atlántico Norte. La capitulación del Fort Amsterdam ante Gran Bretaña en 1664 fue formalizada en 1667, provocando con ello la Segunda Guerra Anglo-Neerlandesa. En 1674 los neerlandeses retomaron el área, pero la cedieron bajo el Tratado de Westminster, terminando así la Tercera Guerra Anglo-Neerlandesa.

Los habitantes de los Nuevos Países Bajos eran indígenas, europeos y africanos, estos últimos importados principalmente como esclavos. Los descendientes de los primeros colonos jugaron un papel prominente en la colonización de los Estados Unidos, ya que la cultura neerlandesa de los Nuevos Países Bajos caracterizó a la región durante dos siglos (hoy en día el Distrito Capital alrededor de Albany, el Hudson Valley, la parte oeste de Long Island, el noreste de Nueva Jersey y Nueva York). Los conceptos de libertad civil y pluralismo introducidos en la provincia se convirtieron en los pilares principales de la vida política y social de los Estados Unidos de América.

En 1624, Pierre Minuit funda Nueva Ámsterdam en la isla de Manhattan, mientras que los Nuevos Países Bajos son incorporados a las Provincias Unidas bajo la tutela de la Compañía Neerlandesa de las Indias Occidentales (en neerlandés: "West-Indische Compagnie" o "WIC").

Es con la creación de facto de las Provincias Unidas con la Unión de Utrecht de 1579, en rebelión constante con la España de Felipe II y de Felipe III que nace esta nueva potencia comercial y marítima de la Europa occidental. Poco después de reunirse en compañías de importación y de exportación, los vendedores neerlandeses, en connivencia con el Estado, fundan la Compañía Neerlandesa de las Indias Orientales (VOC) en 1602.

Buscando nuevos caminos comerciales que podrían revelarse provechosos, la VOC contrata al capitán y explorador Henry Hudson para explorar el Paso del Noroeste, el paso por el norte siberiano hacia Asia. Este, que ya había intentado el mismo trayecto por cuenta de inversores ingleses (Compañía moscovita), decide, al mando del buque "Halve Maen" (Media Luna), buscar la ruta de las Indias hacia el oeste, como lo indicaban las notas del capitán inglés John Smith que había formado parte de la primera tentativa de colonización permanente en la Virginia inglesa, en contradicción con las directivas que recibió de la Compañía. Desde Virginia, remonta la costa este americana hasta la desembocadura del "Zuide Rivier" (hasta entonces desconocido) y luego hasta la bahía de Nueva York que Verrazano había bautizado como "Nouvelle-Angoulême" en 1524. 

Remontando el río que iba a llevar su nombre, pronto se dio cuenta que probablemente no llevaba al reino de Catay. Es, por otra parte, cuando se encuentra en su cuaderno de bitácora por primera vez el término amerindio "Manna-hata", del que derivaría el nombre "Manhattan" para la isla que se destaca en el encuentro del río y el océano. Su viaje por cuenta de intereses particulares neerlandeses iba a encender un notable interés comercial para el comercio de pieles en el delta del "Noort Rivier" (río Hudson).

Desde el año siguiente y en los años subsiguientes, cuatro compañías neerlandesas compitieron por el comercio de pieles con los nativos americanos de la región. Probablemente se erigieron dos puestos desde 1611 a la altura del futuro "Fort Orange", en la isla de Castle, y en el estuario del "Versche Rivier" (río Connecticut). 

Estas cuatro compañías que se preocupaban por un posible impacto negativo de una rivalidad, se unieron y recibieron en 1614 de los Estados Generales de las Provincias Unidas una carta de compañía de monopolio que les cedía la explotación en su totalidad del comercio de las pieles sobre el territorio situado entre los paralelos 40 y 45 por tres años. La competencia no se agravó hasta 1621, año en que la Compañía Neerlandesa de las Indias Occidentales (siguiendo el modelo de la "VOC") fue puesta en marcha. El primer viaje que esta nueva entidad dirigida principalmente por la cámara de comercio de Ámsterdam se escalonó entre 1623 y 1624.

En 1624, las primeras familias de colonos, llamadas para administrar los puestos de comercio, son enviadas en su mayoría río arriba al valle del Hudson. En la isla de Manhattan, encontramos sólo unas plantaciones y un poco de ganadería. En 1625, bajo la amenaza creciente de un ataque proveniente de otras potencias coloniales, los dirigentes de la Compañía Neerlandesa de las Indias Occidentales decidieron proteger la desembocadura del río Hudson, y reagrupar las actividades de los puestos comerciales en un recinto fortificado. 

En 1626, Pierre Minuit negocia la compra de la isla de Manhattan a los indios Lenapes, por 60 florines de mercancías. En el momento de la construcción del fuerte, la guerra entre Mohawks y Mohicanos fuerza a la compañía a precipitar el desplazamiento de los colonos dentro de Fuerte Ámsterdam. En 1658 es fundada la colonia de "Nieuw Haarlem".

Durante la segunda guerra Anglo-Neerlandesa, que opone Inglaterra a las Provincias Unidas, los Nuevos Países Bajos son conquistados por los ingleses. El director general Peter Stuyvesant entrega Nueva Ámsterdam el 24 de septiembre de 1664. La colonia es rebautizada Nueva York, en honor del duque de York, hermano del rey Carlos II de Inglaterra. 

En 1667 los neerlandeses renuncian a sus reivindicaciones sobre esta porción del territorio americano, a la firma del Tratado de Breda, y obtienen a cambio la soberanía sobre Surinam. Sin embargo, en el momento de otra guerra que opone a ingleses y neerlandeses, estos últimos recuperan brevemente la colonia en 1673 (rebautizada Nueva Orange), hasta que los ingleses la recuperen con el tratado de Westminster, el 19 de febrero de 1674.

De la ocupación neerlandesa, quedan hoy un cierto número de nombres de lugares neoyorquinos, tales como Coney Island ("Konijnen Eiland"), Brooklyn ("Breukelen"), Harlem ("Nieuw Haarlem"), Flushing ("Vlissingen") y Staten Island ("Staaten Eylandt").


El 20 de mayo de 1924, con ocasión del tricentenario de la fundación de Nueva York, un monumento conmemorativo fue erigido en honor de los colonos valones, en Battery Park, en el extremo meridional de Manhattan. Una moneda de plata de 50 centavos, así como sellos de correos de 1, 2 y 5 centavos se emitieron para conmemorar la llegada de los colonos valones y flamencos.

Se han utilizado muchos otras términos para designar la colonia norteamericana de las Provincias Unidas. Comúnmente se usa "Nueva Holanda" debido a la generalización del término "Holanda" para designar la federación de los Países Bajos — donde dos de las diez provincias con las que cuenta se denominan Holanda. Pero el término es controversial ya que los mismos neerlandeses nombraron varias veces la colonia como "Nieuw Holland". Australia fue bautizada Nueva Holanda por los primeros exploradores de Oceanía y retuvo este nombre hasta el siglo XIX.

El término Nueva-Bélgica, tan utilizado para evocar los Nuevos Países Bajos, hace referencia a los antiguos Países Bajos borgoñones, que por entonces cubrían una parte del norte de Francia y de Lorena, Bélgica, Luxemburgo y los Países Bajos actuales. Sus habitantes se llamaban los "Belgas" en lengua romance, y "Nederlandais" en lengua germánica, pero estos adjetivos no eran comunes ya que ellos preferían continuar llamándose Holanda, Brabante, Flandes, Frisia, Zelanda, Valonia, Tournai, Güeldres, Namur o Luxemburgo, según el caso. Para el resto del mundo, eran sobre todo los ""Holandeses"". En un mapa de América del Norte, Louis Hennepin hace menciona a los "Nouveaux País Bas". 

Los ingleses los llamaban también ""Dutch"", que designaba más al alemán (Deutsch), ya que los Países Bajos borgoñones (después Países Bajos Españoles, luego Países Bajos Austriacos) formaban parte del Sacro Imperio Romano Germánico, y porque la distinción entre la lengua neerlandesa y la lengua alemana no era tan evidente para la época. Un primer sello que data de 1623 lleva el emblema de un castor y la mención ""Sigillum Novi Belgii"". El sello de Nueva Ámsterdam, de 1654, lleva la mención ""Sigillum Amstellodamensis in Novo Belgio"". Con el fin de diferenciar el concepto latino de Belgique ("Bélgica") y el actual, término raramente usado en la actualidad.





</doc>
<doc id="45307" url="https://es.wikipedia.org/wiki?curid=45307" title="Airbus A380">
Airbus A380

El Airbus A380 es un avión tetrarreactor fabricado por la empresa europea Airbus, subsidiaria del grupo Airbus Group. Se trata de la primera aeronave de reacción con dos cubiertas a lo largo de todo su fuselaje, a diferencia del Boeing 747 en el que, aunque también tiene dos, la cubierta superior abarca solamente la parte delantera del fuselaje. Dispone de una capacidad máxima de 853 pasajeros —en una hipotética configuración de alta densidad de clase turista—.

Es el avión de pasajeros más grande del mundo. Supera de esta manera al ya mencionado Boeing 747, al brindar un área útil de un 49 % más que este último —según el propio fabricante—. Solo es superado por el avión de carga Antonov An-225. Tiene una longitud de casi 73 metros y 24 metros de altura, estando su estructura formada en un 40 % de fibra de carbono y otros modernos materiales metálicos. El primer vuelo de esta aeronave se llevó a cabo en Toulouse, Francia, el 27 de abril de 2005, y realizó su primer vuelo comercial el 25 de octubre de 2007 con la aerolínea Singapore Airlines. Una versión mejorada, el A380plus, estaba en desarrollo, pero al no haber convencido a los potenciales clientes, este fue cancelado.

Al disponer de una cubierta doble que se extiende a lo largo de todo el fuselaje, la superficie de la misma alcanza los 478,1 m², casi un 50 % más que la de su principal competidor, el Boeing 747-400, el cual dispone de una superficie de cabina de 320,8 m². En una configuración clásica de tres clases —turista, negocios y primera— el A380 puede albergar entre 500 y 550 pasajeros. La versión de carga, pospuesta actualmente, disfrutaría de una capacidad de 150 toneladas y un alcance de 10 400 kilómetros, solo superada por el Antonov An-225. El A380, en su versión comercial, tiene un alcance de vuelo de 14 800 kilómetros, suficiente para cubrir rutas como por ejemplo: Ciudad de México-París o, una de las más largas, Madrid-Perth (Australia) sin escalas, con una velocidad de crucero de Mach 0,85 (900 km/h).

El 14 de febrero de 2019, el fabricante aeroespacial europeo anunció que dejaría de fabricar el avión en 2021, después de que el principal cliente de este aparato, Emirates, decidiese modificar una parte de sus encargos para sustituirlos por los modelos A330-900 y A350-900.

Los comienzos en el desarrollo del Airbus A380 se remontan al verano de 1988 cuando un grupo de ingenieros de Airbus dirigido por Jean Roeder, comenzó a trabajar en secreto en el desarrollo de un avión de gran capacidad con el doble objetivo de completar su gama de productos y de romper el dominio impuesto por Boeing en los vuelos transoceánicos con su Boeing 747 desde principios de 1970.

La empresa aeronáutica McDonnell Douglas al igual que Airbus, también comenzó el desarrollo de un avión de largo alcance, el avión de dos pisos MD-12, pero el escaso apoyo obtenido y las malas previsiones hicieron que no pasara de un proyecto.

Roeder, después de una presentación formal del proyecto, recibió la aprobación del presidente y el director ejecutivo de Airbus en junio de 1990. El «megaproyecto» fue anunciado en el Salón Aeronáutico de Farnborough, con el objetivo primario de reducir los costos de operaciones un 15 % en relación al Boeing 747-400. Airbus organizó cuatro equipos de diseñadores e ingenieros, uno de cada uno de sus socios —Aérospatiale, Deutsche Aerospace AG, British Aerospace y CASA—, con el objetivo de que propusieran nuevos métodos y tecnologías en el diseño y construcción de las aeronaves futuras. Los diseños se presentaron en 1992, siendo el diseño más competitivo el elegido.

En enero de 1993, Boeing y varias empresas que formaban el consorcio Airbus iniciaron un estudio conjunto sobre la viabilidad de un avión conocido como el "Very Large Commercial Transport" ("VLCT"), con el objetivo de formar una alianza para repartirse el mercado.
Sin embargo, estos estudios fueron abandonados dos años más tarde. El interés de Boeing había disminuido porque los analistas pensaban que un producto de esas características, en el cual era preciso invertir miles de millones de dólares para su desarrollo, sería poco o nada rentable. No obstante esta maniobra fue vista por muchos analistas como una estrategia del fabricante estadounidense para impedir que Airbus desarrollara un avión que pudiera discutir la supremacía que Boeing mantenía en los viajes a larga distancia con su "jumbo", el Boeing 747.

Esta interpretación de lo sucedido resultó ser falsa, ya que Boeing cometió un gran error estratégico. En 1997 abandonó el estudio de nuevos modelos "superjumbo" como el 747-500 o el 747-600 por dos motivos: el escaso interés mostrado por las compañías aéreas —se creía que el aparato tendría una demanda muy escasa— y por los elevados costes de desarrollo. En el año 2000 se estimaba que los costes de desarrollo del entonces A3XX se elevarían a unos 80 000 millones de francos franceses (12 220 millones de euros), pero Airbus esperaba vender unos 1200 aviones a 1500 millones de francos la unidad (230 millones de euros) en los veinte años siguientes al lanzamiento del nuevo aparato. Al mismo tiempo Boeing afirmaba que los costes de desarrollo de las dos nuevas versiones del 747 que planeaba lanzar al mercado serían tres veces más pequeños que los del A3XX. En ese momento Airbus decidió continuar con su propio proyecto, a pesar de que hasta entonces solo dos aerolíneas habían expresado un cierto interés en la compra del futuro avión. Como se ha mencionado, los analistas pronosticaban que Boeing, a través de su 747, construiría nuevos modelos cuyo desarrollo costaría infinitamente menos que el proyecto de Airbus —pues sus nuevos modelos serían variantes mejoradas del Boeing 747—; además, los propios analistas pensaban que la construcción de aviones grandes no era la mejor opción, apostando por aviones más pequeños que pudieran cubrir las mismas rutas.

En junio de 1994 Airbus comenzó a desarrollar su propio gran avión comercial, denominado en un primer momento A3XX. Se habían considerado varios diseños, incluyendo una combinación de dos fuselajes —de lado a lado— del A340, que era en ese momento el mayor avión construido por la empresa europea. El A3XX también tuvo que enfrentarse con el estudio realizado sobre el "VLCT" y las nuevas aeronaves que Boeing pensaba desarrollar a partir de su 747. En 1997 se inició la crisis asiática, que oscureció las expectativas de ventas del A3XX; en ese momento Airbus alteró el diseño inicial con el objetivo de reducir los costos de funcionamiento entre un 15 y un 20 % en relación con el nuevo modelo de Boeing, el 747-400. El A3XX tendría dos pisos, lo que proporcionaría un mayor volumen de pasajeros por vuelo, desechando el diseño tradicional de un solo piso. Estos cambios en el diseño se llevaron a cabo tras un extenso análisis de mercado. Sin embargo, desde 1995 las previsiones seguían prediciendo que el mercado de grandes aviones como el A380 era pequeño y que Airbus se exponía a pérdidas multimillonarias.

Airbus empezó por consultar a las principales compañías aéreas, agencias gubernamentales y a representantes de los principales aeropuertos internacionales para establecer el tamaño de la aeronave, con el propósito de utilizar las instalaciones aeroportuarias existentes sin necesidad de que se tuvieran que hacer grandes reformas. Las dimensiones de cada unidad no debían superar los 80 metros de longitud y envergadura, la altura máxima se fijó en 24 m. Estas limitaciones se diseñaron para permitir que el A380 pudiera maniobrar en los estacionamientos y calles de los aeropuertos que operaban los Boeing 747. Además, las grandes dimensiones del A380 no serían un problema, pues la gran mayoría de los aeropuertos ya estaban preparados desde la aparición del 747.

El Airbus A380 fue especialmente diseñado para llevar a más pasajeros que el 747 consumiendo menos, además la capacidad no tenía que verse amenazada.
Boeing trabajó en el desarrollo del 747-8, una nueva variante del 747 que se esperaba consumiera un 13 % menos por pasajero y tuviera un coste de explotación un 19 % menor que el A380, aunque en todo caso seguiría teniendo 88 asientos de pasajeros menos en una configuración de tres clases en ambos aviones (467 asientos, según Boeing). Esta nueva aeronave de Boeing entró en servicio en 2011.

El 19 de diciembre del 2000, el consejo de supervisión de Airbus decidió poner en marcha el programa para la construcción del A3XX, rebautizándolo como A380, con un presupuesto oficial e inicial de 10 700 millones de dólares —aunque fuentes externas ya lo elevaban a 14 000 millones—y con pedidos firmados por seis compañías aéreas que superaban las 50 unidades. El nombre A380 no sigue la clásica numeración de Airbus (A300 - A340); se eligió el 8 porque ese número es considerado un número de la suerte en muchos países asiáticos, lugares donde se encontraban algunos de sus principales clientes.
La configuración del A380 se fijó a principios de 2001 y en enero de 2002 se empezaron a fabricar los primeros componentes de las alas.

El presupuesto inicial estimado por Airbus y fijado originalmente en 1994, era de unos 8000 millones de dólares;Como se ha dicho anteriormente, el presupuesto cuando se puso oficialmente en marcha el programa, el 19 de diciembre de 2000, era de 10 700 millones de dólares, cifra que se mantenía estable aún en 2003, repartiéndose los gastos de la siguiente forma: 5100 millones a cargo de Airbus, 3100 de socios y proveedores y 2500 de anticipos de los gobiernos.
Sin embargo, en abril de 2005 una noticia de la BBC ya recogía que el presupuesto se había incrementado en 1450 millones de euros, hasta los 12 000 millones, que en dólares suponían unos 15 000 millones, según el tipo de cambio EUR/USD de ese mes; si a esto se suman sanciones, entregas y gastos extra no planificados, la carga financiera total en el desarrollo del A380 fue de 25 000 millones de dólares, el triple de lo anunciado inicialmente para justificar la viabilidad económica del proyecto.

La presentación oficial del Airbus A380 tuvo lugar el 18 de enero de 2005, en un hangar de la línea de ensamblaje final Jean-Luc Lagardère que la compañía tiene en Toulouse, Francia.

Su presentación reunió a más de 5000 personas y representantes de los cuatro países que habían participado activamente en el proyecto, incluidos los jefes de gobierno de todos ellos: Tony Blair (Reino Unido), Jacques Chirac (Francia), José Luis Rodríguez Zapatero (España) y Gerhard Schröder (Alemania). La ceremonia tuvo una duración aproximada de dos horas, tiempo en el que se conmemoró los 35 años del consorcio europeo de Airbus y sus éxitos desde el lanzamiento del Airbus A310 a principios de la década de 1980. También asistieron al acto representantes de las catorce empresas clientes y personalidades de la aeronáutica.

Se desarrollaron pruebas específicas para poner a prueba al A380. En el aeropuerto de Dresde fue sometido a pruebas de fatiga. También se le realizaron pruebas de IABG en 47 500 ciclos de vuelo, lo que equivale a un año de servicio. En febrero de 2006 durante una prueba de flexibilidad y fatiga, una de las alas se agrietó después de que esta pasara en un 45 % la carga máxima entre los motores; para aprobar esta prueba era necesario que las alas resistieran en un 50 % la carga máxima, por lo que Airbus inmediatamente resolvió el problema.

El 26 de marzo de 2006 el A380 obtuvo el certificado de evacuación en Hamburgo, Alemania. Con 8 de las 16 salidas bloqueadas, 853 personas entre pasajeros y tripulantes abandonaron el avión en 78 segundos, 12 menos de los requeridos para superar la prueba. Tres días después el A380 recibió el permiso de navegación por parte de la Agencia Europea de Seguridad Aérea (EASA) y de la Administración Federal de Aviación de Estados Unidos (FAA) para el transporte de un máximo de 853 pasajeros.

El primer vuelo del A380 tuvo que ser pospuesto en varias ocasiones debido a problemas técnicos; finalmente el 27 de abril de 2005, el avión con el número de serie 001 y con un peso de 421 toneladas (el mayor peso de la historia de un avión civil) despegó a las 8:29 UTC del aeropuerto internacional de Toulouse.

El A380, equipado con 4 motores Trent 900, despegó de Toulouse con una tripulación de seis personas, encabezada por el jefe del proyecto, Jacques Rosay. El vuelo duró 3 horas y 54 minutos; más tarde, Rosay diría que había sido «como montar en bicicleta».

El 1 de diciembre de 2005 el A380 alcanzó su velocidad máxima de Mach 0,96 (la velocidad de crucero normal es de 0,85). El 10 de enero de 2006 realizó su primer vuelo transatlántico, volando hasta Medellín en el Aeropuerto Internacional José María Córdova (Ríonegro), Colombia, y en el 2007 hasta Bogotá en el Aeropuerto Internacional El Dorado para probar el rendimiento de los motores en aeropuertos situados a grandes alturas. Más tarde, el 6 de febrero del mismo año voló hasta Iqaluit, en Canadá, con el objetivo de probar su resistencia y comportamiento ante climas muy fríos.

El primer vuelo con motores GP7200, tuvo lugar el 25 de agosto de 2006. El 4 de septiembre de 2006, con 474 empleados de Airbus a bordo, se realizó una prueba para que los pasajeros probaran las instalaciones y la comodidad del avión. En diciembre Airbus obtuvo los certificados de homologación para los modelos A380-841 y A380-842 de parte de EASA y FAA, en una ceremonia en la sede francesa de la empresa. El A380-861 obtuvo su certificado un año después, el 14 de diciembre de 2007.

Las principales secciones estructurales y la mayor parte de las piezas del A380 son construidas en Francia, Alemania, España y el Reino Unido. Debido a su gran tamaño, las piezas fabricadas en los distintos países son llevadas a la planta de montaje de Jean-Luc Lagarderè, en Toulouse, Francia. Para el transporte de los distintos componentes se usa sobre todo el transporte terrestre y marítimo, aunque en algunas ocasiones se transportan a través del Airbus A300-600ST Beluga, un avión de carga especialmente diseñado para el transporte de las mercancías más voluminosas.
Los componentes del Airbus A380 son suministrados por proveedores de todo el mundo, entre los que destacan: Rolls-Royce, Safran, United Technologies, General Electric y Goodrich Corporation.

Para el movimiento de los componentes se dispone de una gran flota de camiones y barcos, además de instalaciones especializadas y carreteras modificadas para poder dar cabida a convoyes de gran tamaño.

Las secciones delantera y trasera del fuselaje se fabrican en las industrias de Airbus en Hamburgo, en el norte de Alemania, de donde son trasportadas por mar hacia el Reino Unido. Las alas se fabrican en Gran Bretaña, concretamente en Bristol y Broughton, desde donde se llevan a Francia. En Saint-Nazaire, al oeste de Francia, llegan las piezas fabricadas tanto en Bristol como en Hamburgo. La cola y la panza del avión, son ensamblados en la ciudad española de Getafe, de donde son trasportadas por carretera —en el caso de las piezas más pesadas, también se usa ocasionalmente el Airbus A300-600ST Beluga para su transporte— hasta Francia. 
Finalmente todas las piezas fabricadas y ensambladas en los distintos países son llevadas por carretera o mar hasta la cadena de montaje de Toulouse.

Después del montaje, el avión se pilota hasta Hamburgo, donde se amuebla y pinta, siendo necesarios 3600 litros de pintura para cubrir sus 3100 metros cuadrados. Todo este complejo proceso de fabricación provoca que solo un máximo de cuatro Airbus A380 puedan ser construidos cada mes.

Cuando se inició la producción del A380, la compañía Airbus estaba preocupada por los múltiples retrasos sufridos en la construcción del avión, atribuidos principalmente a los 500km de cableado que contenía cada aeronave, lo que suponía una enorme complejidad técnica, ya que cada avión contenía 100000 cables y 40300 conectores. A esto había que sumar el concurrente diseño y el alto grado de personalización que cada compañía había exigido, además de los problemas en la gestión de la configuración y el control de cambios, pues mientras las instalaciones alemanas y españolas de Airbus usaban la versión 4 del programa informático CATIA, los franceses e ingleses habían pasado a la versión 5. Estos errores de fabricación provocaron problemas en la configuración electrónica de los aviones, ya que en algunos casos se había usado aluminio en lugar de cobre conductor, lo que dificultaba las operaciones del software.

Airbus anunció el primer retraso en junio de 2005, notificando a las compañías aéreas que la entrega se retrasaría seis meses. Este hecho redujo el número total de entregas previstas para finales de 2009 de cerca de 120 a menos de 100. El 13 de junio de 2006 se anunció un segundo retraso, esta vez de seis a siete meses.

La primera entrega estaba prevista para finales de 2006, estando planeado entregar 9 aviones en 2007 y llegar a 70 entregas en 2009. Las constantes demoras y el incumplimiento del calendario llevaron a Airbus y a EADS a perder un 26 % de su valor en bolsa.
El 3 de octubre de 2006, el consejero delegado de Airbus, Christian Streiff, anunció un tercer retraso y una revisión del programa A380, además de un recorte en los ingresos esperados hasta 2010 de 4800 millones de euros, debido tanto a la reestructuración propia y a los retrasos como a las mejoras en las previsiones de Boeing.

Muchas compañías aéreas ante los retrasos, se plantearon reducir sus pedidos, o bien sustituir la compra de A380 por aviones Boeing 747-8. Ante esta situación, Airbus dio prioridad a la producción de las versiones 800 (A380-800) y 800F (A380-800F) de sus A380 frente a otros modelos de la compañía.

Los trabajos en la versión de carga del A380 fueron suspendidos, pero se mantuvo la oferta, aunque sin fijar una fecha para su puesta en servicio. Para la versión de pasajeros se revisó —de nuevo— el calendario, añadiendo además compensaciones por las demoras a los 13 clientes, quienes a su vez, mantuvieron todos los pedidos originales, habiendo incluso algunas que aumentaron el pedido original, como Emirates Airlines, Singapore Airlines, Air France o Qantas.

El primer A380, con el rediseño en el sistema de cableado, fue entregado en abril de 2008 con una demora de tres meses. El 13 de mayo de ese mismo año, Airbus anunció la reducción de las entregas a 12 unidades en 2008 y 21 en 2009. Más tarde la cifra de 21 unidades para 2009 fue reducida a 14, de las que finalmente 10 unidades fueron entregadas.

El primer avión se entregó el 15 de octubre de 2007 a Singapore Airlines, compañía con la que entró en servicio el 25 de octubre de ese mismo año, en un vuelo inaugural entre Singapur y Sídney. Los pasajeros compraron los billetes en una subasta benéfica, rondando el precio de cada pasaje entre 560 y 100 380 dólares. Dos meses después el consejero delegado de Singapore Airlines, Choong Seng, dijo que los resultados obtenidos con el A380 eran los mejores en cuanto a gasto y rentabilidad de toda su flota.

Emirates Airlines fue la segunda aerolínea en recibir el A380, el 28 de julio de 2008, y realizó su vuelo inaugural entre Dubái y Nueva York el 1 de agosto del mismo año. Qantas fue la siguiente aerolínea en recibir el aparato el 19 de septiembre de 2008, poniéndolo oficialmente en servicio con un vuelo inaugural entre Melbourne y Los Ángeles el 20 de octubre de 2008. A finales de 2008 ya habían volado en el A380 890 000 viajeros en un total de 2200 vuelos a lo largo de 21 000 horas.

En febrero de 2009, el A380 de Singapore Airlines transportó al pasajero «un millón». Air France recibió su primera aeronave el 30 de octubre de 2009, en el aeropuerto francés Charles de Gaulle; Lufthansa lo recibió el 19 de mayo de 2010. En julio de 2010, los A380 en servicio habían transportado ya a seis millones de clientes en 17 000 vuelos a 20 destinos internacionales. En junio de 2011, solo los A380 de Air France ya habían transportado a un millón de viajeros.

El Airbus A380 es identificado por la clave F de OACI, con una envergadura comprendida entre los 65 y los 80 metros y una distancia exterior entre ruedas del tren de aterrizaje principal desde los 14 hasta 16 metros; y en la categoría DG —Design Group— estadounidense, la de mayor tamaño de aeronaves que operan en ese país. Precisamente en Estados Unidos es donde el A380 encontró un mayor número de impedimentos a la hora de poder realizar sus operaciones, aunque en otros países, como Gran Bretaña, también sufrió graves problemas.

La Federal Aviation Administration (FAA) solo autorizó en principio los aterrizajes y despegues del A380 en pistas de 60 metros de ancho, cuando la gran mayoría de las pistas en aeropuertos estadounidenses tiene un ancho de 45, aptas para recibir al Boeing 747. En cuanto a las pistas de rodadura o carreteo —taxiways—, los aviones de la clase DG VI han de hacerlo por pistas de 30,5 metros de anchura, pero Airbus comunicó que equiparía a sus aviones con una cámara para la rodadura (TCS) que permitiría ayudar a la tripulación en esta fase y reducir a 22,9 metros la anchura de pista necesaria. En cuanto a la velocidad de carreteo, el avión no puede sobrepasar los 24 km/h.

De igual manera, la FAA propuso que cuando un A380 esté rodando en una pista paralela a otra pista, esta se cierre mientras dure su paso. Esto hubiera ocasionado grandes problemas a la hora de gestionar el ya sobrecongestionado espacio aéreo estadounidense. De manera similar, cuando un A380 despegue o aterrice, no podría haber ningún otro avión realizando su rodadura en una pista adyacente. Por último, en condiciones de baja visibilidad, durante el aterrizaje y despegue del avión, no podría haber otro avión a menos de 915 metros de la cabecera de pista y en condiciones de Categoría II y III, a 1220 m. Sin embargo, la FAA y la EASA autorizaron en julio de 2007 a que el Airbus A380 operase en pistas de 45 metros de ancho sin restricciones.

En España, Aena tiene definidos unos sectores de estacionamiento, en inglés conocidos como "Aircraft Safety Area" (ASA), según las dimensiones de las aeronaves. Hasta la llegada del A380, la mayor posición de estacionamiento era la Tipo I, pensada para el Airbus A340 y para el Boeing 747; sin embargo, para el A380 se ha creado la Tipo 0, con una profundidad similar a la de Tipo I, pero de mayor ancho.

Airbus utilizó en el A380 características de manejo, procedimiento y disposición de la cabina similares a las de otros aviones de la compañía para reducir costes de formación de la tripulación; en consonancia, la cabina es similar a la de otros aviones de Airbus, aunque se le han incorporado varias mejoras. El A380 cuenta con una avanzada cabina de "cristal" y nuevos mandos de vuelo "fly-by-wire" con palanca de control lateral. Dispone de ocho pantallas de cristal líquido de , físicamente idénticas y permutables; estas comprenden dos pantallas principales de vuelo, dos pantallas de navegación, una pantalla de parámetros de los motores, una pantalla del sistema y dos pantallas multifunción (MFD). Las MFD son nuevas en el A380 y proporcionan una interfaz de manejo sencillo con el sistema de gestión de vuelo —reemplazando tres unidades de visualización y control multifunción—. En la cabina se incluyen teclados QWERTY y "trackballs", para interaccionar con un sistema de navegación de visualización gráfica. En general, la cabina es más espaciosa que sus homólogas del resto de los aviones de fuselaje ancho.

Las alas se componen fundamentalmente de fibra de carbono y aluminio. Tienen un tamaño suficiente para poder despegar con un máximo de 650 toneladas, con el fin de que no sea necesario cambiar el diseño de las alas en futuras versiones, como el A380-900.Airbus calcula que el tamaño de la aeronave, sumado a la tecnología empleada en su construcción, ofrecerá un costo por operaciones mucho más reducido que su competidor, el Boeing 747 y sus variantes.

El A380 también emplea las mismas aletas de punta alar que emplean los modelos A310 y A320 con el fin de evitar turbulencias y aumentar la eficiencia en el consumo de combustible, así como el rendimiento. Es en las alas donde tiene sus depósitos de combustible, con una capacidad de 310000 litros de combustible.

En el Paris Air Show 2017 Airbus presentó el nuevo A380 plus el cual entre otra de sus características incluía un nuevo tipo de winglets denominado "downlet" por su forma hacia abajo el cual mejora la eficiencia y reducción en el consumo de combustible estimado en un 4 %. Estos winglets son muy similares a los utilizados en el Boeing B737MAX.

Esto sumado a una lista de cambios presentados por Airbus completan el modelos A380 plus, el cual ha impactado ya que se esperaba una versión neo (New Engine Option). Las alas han sido modificadas con mejoras aerodinámicas las cuales ayudan a la reducción del consumo de combustible el cual Airbus anuncia. También ha sido incluido un depósito auxiliar de combustible para permitir que el peso de despegue aumente en tres toneladas (578) y que el número máximo de pasajeros aumente en 80 personas, todo esto sin variar el rango del que dispone actualmente.

El A380 está equipado con cuatro motores turbofán en sus respectivas góndolas subalares, pero solo dos de ellos están provistos de inversores de empuje. El cliente tiene la posibilidad de elegir entre dos tipos de motores: el Rolls-Royce Trent 900 que montan las versiones A380-841, -842 y -843F; o el Engine Alliance GP7000 que montan las versiones A380-861 y -863F. Con un empuje de entre 310 y 360kN (70 000-80 000 lbf) cada uno, son los motores más eficientes desarrollados para un avión cuatrimotor. El diámetro de los motores es de 2,95 metros, y aspiran una tonelada y media de aire por segundo.

El Trent 900 es un modelo derivado del Trent 800, y el GP7000 tiene sus orígenes en los General Electric GE90 y Pratt & Whitney PW4000. El núcleo del Trent 900 es una versión escalada del Trent 500, pero incorpora la tecnología de ventilador con aspas en flecha del Trent 8104 (modelo no desarrollado). El GP7200 tiene un núcleo derivado del GE90 y el ventilador y la turbomaquinaria de baja presión del PW4090. 

Los motores producidos por Engine Alliance son fabricados en Middletown, en el estado de Connecticut, Estados Unidos; hasta ahora son Air France, Emirates Airlines, FedEx, ILFC y Korean Air las compañías que han escogido el GP7200 en lugar del británico Trent 900.

La reducción del ruido fue un importante requisito en el diseño del A380, y afectó mucho al desarrollo de los motores. Ambos tipos de motores permiten que el avión logre los límites de ruido QC/2 en despegue y QC/0.5 en aterrizaje en base al sistema Quota Count establecido por el Aeropuerto Heathrow de Londres, uno de los principales destinos del Airbus A380.

Uno de los retos del A380 fue demostrar la viabilidad del uso de combustible sintético combinado en los aviones comerciales. El 1 de febrero de 2008 realizó un vuelo de prueba de tres horas entre Gran Bretaña y Francia utilizando como combustible en uno de sus cuatro motores una mezcla de queroseno estándar de aviación en un 60 % y un 40 % de un derivado del gas natural denominado GTL. El motor no necesitó ninguna modificación para poder usar el GTL. Sebastien Remy, jefe del programa de combustible alternativo de Airbus, dijo que este "nuevo" combustible no es más limpio en cuanto a emisiones de dióxido de carbono que los combustibles normales pero tiene beneficios en la calidad del aire porque no contiene azufre.

Mientras que la mayoría del fuselaje es de aluminio, los materiales compuestos representan más del 20 % de toda la estructura del A380.
Los plásticos reforzados con fibra de carbono, fibra de vidrio o fibra de cuarzo son ampliamente utilizados en las alas, el tren de aterrizaje, la sección trasera del fuselaje, las superficies de la cola y en las puertas. El A380 es el primer avión de línea comercial en tener un cajón de ala central hecho de plástico reforzado con fibra de carbono. Y también el primero en tener una sección transversal del ala continua, que optimiza la eficiencia aerodinámica, ya que las alas de otros aviones comerciales están divididas en secciones a lo largo de su envergadura. En los bordes de ataque de los "slats" utiliza compuestos termoplásticos. Uno de los nuevos materiales que incorpora es el vidrio reforzado o GLARE, que es utilizado en la parte superior del fuselaje y en los bordes de ataque de los estabilizadores. Este laminado de fibra de vidrio y aluminio es más ligero y tiene una mayor resistencia a la corrosión y a los impactos que las aleaciones de aluminio convencionales usadas en aviación. A diferencia de los primeros materiales compuestos, estos pueden ser reparados usando técnicas de reparación de aluminio convencionales. También incorpora nuevas aleaciones de aluminio soldables que permiten el uso generalizado de técnicas de fabricación por soldadura por rayo láser —eliminando las hileras de remaches y dando por resultado una estructura más ligera pero más fuerte y resistente—.

Entre las nuevas características de la aeronave destaca la mayor área de la cabina, con un 50 % más de espacio que el 747-400; además el A380 produce un 50 % menos de ruido que el avión de Boeing y dispone de un interior con compartimentos de carga más grandes que sus antecesores, mayores ventanas y 60 cm más de altura.

La amplia cabina del A380 permite que los asientos en clase turista puedan llegar hasta los 48cm de ancho, 4cm más que su competidor, el Boeing 747-400 El interior del A380 puede configurarse de once maneras diferentes que Airbus personaliza según las exigencias del comprador; su capacidad máxima certificada es de 853 pasajeros en una hipotética configuración con una sola clase, la turista. Una configuración típica de tres clases puede alojar a 525 pasajeros, que se reparten de la siguiente manera: 10 personas en clase de negocios o "business", 76 en primera clase y 439 pasajeros en clase turista. Dependiendo de la configuración aplicada, el A380 puede alojar entre 407 pasajeros (como es el caso de los aviones de Korean Air) y 840 pasajeros (caso de la configuración elegida por Air Austral).

El A380 cuenta con dos pisos, unidos por dos escaleras, una en la popa y otra en la proa. El ancho de las cabinas permite acomodar a dos pasajeros en los laterales de cada lado, además de permitir múltiples configuraciones en los propios asientos. Algunos operadores que tienen sus aviones con la configuración de tres clases han desarrollado servicios especiales a bordo, como cabinas privadas, camas salientes y reclinables o salones.

La publicidad inicial de Airbus hizo un gran hincapié en la comodidad y el espacio del que gozaría el A380, con instalaciones adicionales como zonas de descanso, bares o tiendas. Air France ha instalado en uno de sus A380, una galería de arte electrónico para los pasajeros de primera clase y business. Singapore Airlines ofrece doce "suites" en uno de sus A380, todas ellas con cama de gran tamaño, escritorio y armario personal; cuatro de estas "suites" tienen paredes que se pueden quitar. Emirates Airlines también ha configurado algunos de sus aviones con catorce "suites" privadas, equipadas con ducha y "spa"; sus aviones también están equipados con salones de reuniones, sofás y bares en la clase de negocios (business).

Korean Air o Qantas tienen previsto hacer cambios en sus aviones A380.

Cada avión es personalizado según las exigencias de cada aerolínea, lo que ralentiza significativamente la velocidad de producción y aumenta los costos; por ejemplo en uno de los A380 de Qantas hay seis bares de autoservicio (cuatro en el piso inferior y dos en el superior) y una sala de reuniones (en primera clase y business). Virgin Atlantic Airways tiene previsto instalar bares, camas de gran tamaño, casino e incluso un gimnasio en su A380.

El A380 emplea aviónica modular integrada (IMA), un tipo de arquitectura antes solo usada en aviones militares avanzados como los F-22 Raptor, F-35 Lightning II, y Dassault Rafale. El equipo IMA fue diseñado y desarrollado conjuntamente por Airbus, Thales y Diehl Aerospace —el grupo Thales se encargó de los sistemas principales—, este equipo es utilizado por primera vez en el A380, y supone una innovación tecnológica en la aviación comercial, con módulos de computadoras conectadas en red que soportan diferentes aplicaciones.

Por primera vez en la historia de la aviación civil, la administración básica de todos los sistemas (hidráulico, motores, eléctricos...) son controlados por un sistema de control de vuelo automatizado. En el caso de los sistemas hidráulico y eléctrico son independientes. Estos sistemas controlan algunas partes de las alas (flaps y slats), los alerones y el timón.
El sistema hidráulico de 350 barias es una nueva versión del típico sistema hidráulico que se encuentra en la mayoría de aviones, de 210 barias. Este sistema era usado normalmente en aviones militares, pues este tipo de sistema permite reducir el tamaño de tuberías y otros componentes que reducen el peso total. Las presión del sistema es ejercida por ocho bombas hidráulicas.

Las tuberías se hacen normalmente de titanio y son parte esencial de la refrigeración del aire de la aeronave y el sistema de regulación de la temperatura del motor. La arquitectura del sistema hidráulico difiere considerablemente de los sistemas estándar de la mayoría de los aviones. Existen sistemas hidráulicos autónomos impulsados eléctricamente que sirven como reserva en caso de problemas en los sistemas principales, lo cual ahorra peso y costes de mantenimiento.
El A380 utiliza cuatro generadores eléctricos de 150 kVA. El A380 utiliza cables de aluminio en lugar de cobre para la reducción de peso. El sistema eléctrico está totalmente informatizado y muchos interruptores han sido sustituidos por dispositivos que ayudan a una rebaja extra del peso de la aeronave y un mejor rendimiento y fiabilidad. El A380 cuenta con un sistema de iluminación "bulbless". Se emplean bombillas led en la iluminación de la cabina, la zona de carga y otras áreas del fuselaje. Para la iluminación exterior se utilizan bombillas blancas de gran potencia lumínica.

El A380 de Airbus cuenta con dos aparatos de aire acondicionado ("PACK"), llamados "unidades de generación de aire" ("UGA"). Cuentan con un diseño sencillo y simplificado y su rendimiento es de unos 450 kW, alcanzando el interior del avión un flujo de aire de 2,5 a 2,7 kg/s. El aire es reemplazado cada tres minutos por aire fresco.

Este sistema se dedica a la administración y el control del combustible en cada depósito del avión. Controla la transferencia de queroseno y su cantidad; es capaz de organizar de manera autónoma la distribución del combustible de toda la aeronave, distribuyendo así el peso en las alas según convenga.
Los depósitos de combustible están acoplados a la superestructura del avión; los depósitos se encuentran en las alas, menos el depósito de emergencia, localizado en los planos de cola. Los depósitos de "transferencia" tienen el objetivo de distribuir el combustible mediante un bombeo que se realiza de manera automática a los depósitos de "alimentación"; estos depósitos suministran el combustible necesario a los motores y tienen una capacidad de 1000 litros.

El A380 está equipado con una unidad de energía auxiliar (en inglés «Auxiliary power unit», APU) fabricada por las empresas Pratt & Whitney Canada y Hamilton Sundstrand; la primera se encarga de la fabricación de la turbina, mientras que Hamilton Sundstrand es responsable de la fabricación del sistema eléctrico. 

La APU se localiza en la parte trasera del fuselaje; se utiliza para suministrar energía para todos los sistemas (hidráulico, eléctrico, etc.) cuando los motores principales están apagados. Esta unidad tiene 1300 kW, lo que le convierte en el sistema auxiliar aeronáutico más potente, un 20 % más potente de lo normal; asimismo ofrece 900 kW de energía neumática y puede tener una potencia total de 1,3 MW, suficiente para poder alimentar todo el sistema. El avión y el propio sistema pueden ser conectados a sistemas estacionarios de los aeropuertos para transmisiones de potencia.

Con el lanzamiento del Airbus A380, Airbus quiso centrarse en la expansión de línea de este producto, dando lugar a numerosas variables, algunas todavía en desarrollo. El A380-700, anteriormente conocido como A3XX-50R, es una variante más pequeña que la versión "estándar" del modelo, la A380-800. Tiene 67,9 metros de largo, algo más corto que el A380-800. Con un máximo de 481 pasajeros y un alcance máximo de alrededor de 16 200 kilómetros se situaría por sus características entre el A380-800 y el Boeing 747. Ninguna compañía aérea se ha interesado por el momento en adquirir el modelo entre otros por encontrarse en el mismo segmento de mercado que el 747 y tener unos costes estructurales mucho más elevados que este.

Airbus tenía pensado ofrecer un nuevo modelo de una versión ya existente, la A380-800, y empezó a ofrecer un A380-800 de mayor capacidad desde 2013. Entre las mejoras estaba la opción de aumentar el peso máximo, proporcionando así una mayor capacidad de carga y rendimiento. Esta versión nació con el fin de competir con la última versión del Boeing 747, el 747-8I, que incrementa su peso máximo en el despegue en 4 toneladas, hasta las 573 t.

Los aumentos en la capacidad eran posibles gracias a la eliminación y optimización de las cargas de vuelo. British Airways y Emirates Airlines fueron los primeros clientes en solicitar el nuevo aparato. Vietnam Airlines también mostró interés en la compra de esta nueva versión.

En noviembre de 2007 el jefe de operaciones de Airbus, John Leahy, anunció los planes para el desarrollo de una nueva versión del A380, el A380-900, que será ligeramente más larga (de 73 metros a 79,4 metros) que su antecesora, y se convertirá en el avión más largo del mundo, por encima del nuevo Boeing 747-8. Esta versión tendrá una capacidad de 650 pasajeros en configuración estándar y un máximo de 900 en versión económica.

En mayo de 2010, Airbus anunció que la producción del A380-900 sería pospuesta hasta que la producción del A380-800 se haya estabilizado. Varias compañías mostraron interés en la adquisición de esta nueva variante, como Emirates Airlines, Virgin Atlantic, Cathay Pacific, Lufthansa, Air France y Kingfisher Airlines.
El 11 de diciembre de 2014, en el foro anual Airbus Investor Day, el CEO de Airbus pronunció un polémico anuncio en el que decía: «un día nosotros lanzaremos el A380neo y otro día un A380 ampliado». Este anuncio se debió a la especulación desatada por el director financiero de Airbus, Harald Wilhelm, quien había achacado «la escasa demanda a que el A380 estaba adelantado a su tiempo».

El 15 de junio de 2015, John Leathy, director de operaciones para los clientes de Airbus, indicó que Airbus estaba revisando el programa A380-900 de nuevo. El concepto de A380-900 que maneja la compañía tendría 50 plazas más que el A380-800, en lugar de las 100 plazas adicionales previstas en un principio. El estiramiento de la variante necesitaría de nuevos motores, y según "Flighglobal" el A380-900 aprovecharía mejor el diseño alar del A380.

El 19 de julio de 2015, el CEO de Airbus, Fabrice Brégier, confirmó que la compañía construirá una nueva versión del A380 con nuevas y mejoradas alas y motores. Las especulaciones sobre el desarrollo de una nueva variante, denominada «Airbus A380neo», se habían estado sucediendo desde hacía meses, cuando la compañía consideraba poner fin a la producción del aparato antes de 2018 o desarrollar una nueva variante. Más tarde se supo que Airbus barajaba la posibilidad de alargar la producción del A380 y desarrollar el A380-900 con una nueva versión del motor, es decir, el A380neo. La variante podría entrar en servicio en 2020, mientras que el nuevo motor probablemente sea un Rolls-Royce.

Airbus aceptó en un principio los pedidos de la versión de carga. Esta versión ofrecería la segunda capacidad útil más grande del mundo, solo superada por el Antonov An-225. Sin embargo, la producción ha sido suspendida, al igual que los pedidos; Airbus aún no ha dado fecha para el inicio de la producción.

Existen otras versiones actualmente canceladas o en estudio del A380. Entre las versiones aún en estudio destaca la versión A380-900S cuya configuración le permitiría poder transportar más de 1000 pasajeros; esta versión podría entrar en producción alrededor de 2020. Otras variantes como la -800C, la -800S o la -800R se encuentran en este momento canceladas o paralizadas sin conocerse sus características exactas.
En el Paris Air Show 2017 Airbus presentó una nueva variante del A380 denominada "A380 Plus" la cual incluye mejoras como los nuevos tipos de winglets, un mejorado programa de mantenimiento, cambios en la cabina de pasajeros lo que permite acomodar hasta 11 personas en una misma fila, en clase económica y hasta 10 asientos en clase business, otro cambio sería las escaleras tanto frontales como las de la cola del avión llegando a poder adquirir espacio para 80 plazas más. Otra de las mejoras es el aumento del peso máximo de despegue, ascendiendo a 578 toneladas (3 más que el modelo actual) todo esto para poder cargar el combustible necesario para transportar a 80 pasajeros más sin cambiar el rango que tiene o volar 550 km más sin tener esos 80 pasajeros adicionales. Todos estos cambios generan un 13 % menos de coste por asiento ofreciendo unos grandes beneficios a las aerolíneas.

Todavía no hay fecha de entrada en servicio esclarecida.

Hasta el momento dieciocho clientes distintos han encargado el A380, incluyendo el pedido particular del príncipe saudí Al Waleed Bin Talal de una versión VIP.

El total de pedidos a 20 de enero de 2018 ascendía a 337 aeronaves. El principal cliente es la aerolínea Emirates Airlines, que ha encargado 120 aviones (el 35 % del total), con otros 16 en opción.

La versión de carga recibió 27 pedidos, todos cancelados en 2006 y 2007, sin que llegase por tanto a fabricarse ninguno.

En 2010, Airbus hizo 19 entregas; realizándose las mismas en las instalaciones que la compañía tiene en Hamburgo para los clientes europeos o provenientes de Oriente Medio, mientras que a los clientes del resto del mundo se les hace entrega de los aparatos en las instalaciones de Toulouse. En los cinco años siguientes, entre 2011 y 2015, se entregaron un total de 135 aeronaves, sin embargo durante ese periodo apenas se ordenaron 85 nuevos A380.

Pedidos y entregas acumuladas<br>

Desde los inicios del desarrollo del A380, Airbus ha realizado hasta 53 estudios sobre el posible nivel de ventas de la aeronave. En 2007 estimó que si persistía la congestión que sufren muchos aeropuertos internacionales la posible demanda de aviones de más de 400 asientos sería de 1300 aeronaves en los próximos 20 años, pudiéndose elevar incluso a 1800. Sin embargo, en 2006, los analistas industriales de Philip Lawrence, del Aerospace Research Centre de Bristol y Richard Aboulafia, de la consultora Teal Group de Fairfax, calcularon unas ventas de 880 y 400 unidades, respectivamente, para el año 2025. Hans Peter Ring, director financiero de EADS dijo en mayo de 2010 que el plan de negocio del A380 se basaba en la venta de un mínimo de 750 unidades.

Debido a los retrasos en la producción del A380, Airbus no pudo permitirse en 2009 destinar toda la inversión en el desarrollo del A350, del cual se espera un volumen de ventas de 2 a 4 veces mayor que el del A380.

El 11 de diciembre de 2014, después de un incremento de los pedidos menor de lo esperado, el director de finanzas de la compañía, Harald Wilhelm, sugirió que el programa podría darse por terminado en 2018. Su declaración desató protestas entre los clientes y las acciones de Airbus sufrieron una caída notable. Airbus respondió quitándole importancia a la posibilidad de cancelar la fabricación del A380 e hizo hincapié en que una serie de mejoras de la aeronave sería el escenario más probable. El 22 de diciembre de 2014, el director general Fabrique Brégier descartó la cancelación del programa A380 e indicó que se alcanzaría su punto de equilibrio en 2015, además de señalar que el A380 se habría introducido una década antes de tiempo. Si bien en 2015 la compañía ya lograba obtener beneficios por cada A380 vendido, Airbus reconocía que no sería capaz de recuperar los aproximadamente 25 000 millones de dólares de inversión.

El coste por hora de vuelo de un A380 en diciembre de 2015 era de aproximadamente 26 000 dólares o 50 dólares por asiento/hora, más que un Boeing 777-300ER, con 44 dólares, y menos que los 90 dólares de un Boeing 747-400.

El precio unitario de cada Airbus A380-800 era en mayo de 2008 de entre 317 y 337,5 millones de dólares estadounidenses por lo que el precio medio era de 327,4 millones de dólares. En 2010 el precio había aumentado hasta una media de 346 millones.

En junio de 2010 el presidente de Emirates Airlines, Sheikh Ahmed bin Said al-Maktoum anunció un importante contrato entre su compañía y Airbus para la entrega de 32 nuevos A380 por un valor de 11 500 millones de dólares, lo que significa un coste por unidad de 359,4 millones de dólares estadounidenses.

Estos precios, sin embargo, difieren significativamente del precio pagado por muchas compañías aéreas debido a indemnizaciones, pedidos al "por mayor" o pedidos con mucha antelación, que han provocado que en muchas ocasiones el precio pagado haya sido mucho menor al precio oficial. Por ejemplo, Singapore Airlines pagó por su primer A380 210 millones de dólares, un tercio menos de su precio en ese momento, debido a las indemnizaciones por los retrasos que había sufrido Airbus en su entrega.

Una de las características que hacen único al Airbus A380 es su número de asientos —hasta 853—, pues no hay aviones comparables. Según el catálogo de precios de Airbus, en 2015, una década después del primer vuelo del aparato, el precio del A380 era de 428 millones de dólares por unidad.

En la década de 1990 varios fabricantes, como McDonnell Douglas o Boeing, llevaron a cabo proyectos similares. McDonnell Douglas propuso un prototipo conocido como MD-12, pero no pasó de un simple proyecto; Boeing sugirió un avión con capacidad de entre 600 y 800 pasajeros, el Boeing NLA, pero el desarrollo de nuevas versiones de su 747 y los altos costos de desarrollo hicieron que el proyecto fracasara.

En este momento la competencia entre las empresas (sobre todo entre Airbus y Boeing) se está desarrollando en el control de los mercados de aviones medianos, pues estos son más silenciosos, ecológicos y tienen unos bajos costes de operación y mantenimiento. Boeing ha desarrollado el Boeing 787, que se introdujo en octubre de 2011, mientras que Airbus desarrolló el A350, introducido en enero de 2015.

A 10 de abril de 2017, trece compañías estaban operando el Airbus A380 en sus distintas variantes. Además hay que añadir Airbus Industries que tiene 2 unidades. Emirates Airlines es actualmente la aerolínea con más A380 en servicio y con más pedidos. Actualmente la ruta más corta que cubre un A380 se realiza entre Dubái y Yeda, con un tiempo de vuelo de menos de 3 horas, aunque durante un breve periodo de tiempo —verano de 2010—, Air France usó uno de sus A380 para cubrir la ruta París-Londres.

El 24 de mayo de 2011, Korean Air recibió su primer Airbus A380 de un total de 10 en una ceremonia especial celebrada en Airbus, Toulouse. Desde su centro de operaciones en Seúl, Korean Air opera el A380 hacia destinos en Asia, América del Norte y Europa en rutas sin escala. Korean Air eligió una espaciosa configuración de cabina para su flota de A380, con capacidad para 407 pasajeros distribuidos en tres clases. Además, los aviones cuentan con la primicia de un espacio donde se expondrán los artículos libres de impuestos, así como un bar y un salón en el puente superior para pasajeros de clase "premium".

China Southern recibió su primer avión A380 el 14 de octubre de 2011 durante una ceremonia celebrada en el Centro de Entrega de Airbus en Toulouse, Francia. El presidente y CEO de Airbus Tom Enders entregó la primera de las cinco aeronaves encargadas por la aerolínea a su presidente Si Xianmin.
China Southern Airlines se convierte así en el primer operador del avión en China, y el séptimo a nivel mundial. La aeronave, que dispone de motores Rolls-Royce Trent 900, será empleada inicialmente en rutas nacionales entre las ciudades de Pekín, Shanghái y Guangzhou. Más adelante, la aerolínea hará uso de los A380 para sus vuelos internacionales. 
En la siguiente tabla se muestran las compañías aéreas que operan el A380 y desde cuando (no se incluyen las compañías que solo han realizado pedidos):





Airbus anunció la finalización de la producción del A380 tras que Qantas cancelara 8 pedidos de ésta aeronave, el golpe final lo dio Emirates tras remplazar sus pedidos por Airbus A350 y Airbus A330neo Airbus anunció el 14 de febrero de 2019 que finalizara el proyecto del A380 al terminar las últimas entregas en el 2021. British Airways comunicó que si querían vender la aeronave tendrían que haber puesto un precio más razonable

Véase también 







</doc>
<doc id="45313" url="https://es.wikipedia.org/wiki?curid=45313" title="Virgen de Urkupiña">
Virgen de Urkupiña

La Virgen de Urqupiña o Urkupiña es una advocación de la Virgen María Asunta, que se venera el 14 de agosto en la ciudad de Quillacollo, capital provincial a 13,85 km de Cochabamba en Bolivia.

A fines del 1700 (hacia el sudoeste de Quillacollo), vivía una familia de campesinos quienes subsistían gracias a la utilidad de su pequeño rebaño de ovejas que se encontraba al cuidado de la hija menor. La muchacha se dirigía a diario hacia las bajas colinas del frente de Cota, pasaba el río de Sapinku, donde había pasto en abundancia para su rebaño. Un día de agosto, se le apareció una Señora quien tenía un hermosísimo niño en brazos, sostenían largas conversaciones en el idioma del lugar, el quechua. La pastorcita jugaba con aquel niño en las aguas de una vertiente que brotaba de las rocas.

Desde entonces, casi siempre la muchacha demoraba al retornar a la choza de sus padres, por lo que éstos le preguntaron el motivo, la niña relató sus encuentros con la señora a quien llamaba “Mamita y el niño”. Decía que descendían a jugar con ella en la chimpa juturis (o chimpa pilas), que así se llamaban y continúan llamándose las dos vertientes de agua clara y dulce situadas al pie de la colina. Al oírla, sus padres se alarmaron y se dirigieron repetidas veces a la verde colina para convencerse de los increíbles relatos.

Al reiterarse la visita de la "Mamita", la niña fue en busca de sus padres y estos al Doctrinero (las parroquias eran denominadas doctrinas y, por extensión al sacerdote, Doctrinero), y vecinos del rancherío, que anoticiados del acontecimiento decidieron cerciorarse de su veracidad, acudiendo al lugar donde la niña los guiaba. La Virgen, al ver que la pastorcita no aparecía se levantó de donde estaba y subió cuesta arriba el cerro, mientras la niña gritaba indicando con el dedo, en quechua ""Jaqaypiña urqupiña, urqupiña"", que en español significa "ya está en el cerro"" (urqu=cerro, piña=ya está), de ahí el nombre castellanizado. La señora al llegar a la cima, desapareció, pero lograron ver una imagen celestial que se esfumaba en la maraña de los algarrobales, cactus y ululas. Convencidos de que la visión era extraña, corrieron al pueblo. El párroco convocó a los pobladores, y junto a otras autoridades acudieron al lugar del prodigio frente a la ranchería de Cota. La multitud bulliciosa trasladó esta imagen a la capilla de Quillacollo y desde entonces es conocida como la Virgen de Urqupiña, quien es muy venerada por el pueblo boliviano y los relatos de los milagros que se prodigan a sus devotos son extraordinarios. En ese lugar, se construyó una capilla de la Virgen, que se ha trasladado al templo Matriz de Quillacollo hasta donde llegan peregrinos de toda Bolivia y Sud América para venerar a la patrona de la integración Nacional. (Por Mons. Francisco Cano Galvarro y Mercedes Anaya de Urquidi)

Aunque no existe claridad respecto a la fecha exacta del reconocimiento oficial de la Virgen de Urkupiña como imagen auténtica mariana, según algunas fuentes está establecido que el culto a dicha imagen se remonta a la época de la colonia, siglo XVI, sin embargo, no existe un solo documento que apoye fehacientemente esta afirmación, es más posible que el culto se haya iniciado hacia mediados del siglo XVIII.

La llegada de los colonizadores españoles en el siglo XVI a los valles Cochabambinos, trajo consigo nuevas costumbres y formas de ser y vivir.

Junto a ellos llegaron misioneros para propagar la fe cristiana, para lograr este objetivo tuvieron que utilizar muchos métodos misioneros, como también aprender la lengua para poder comunicarse, entre otros. Sin embargo, con el transcurrir del tiempo, poco a poco la población indígena fue aceptando y asimilando la fe cristiana.

La historia de la Virgen de Urcupiña se remonta a la época colonial, como se señala en la "Leyenda de la Virgen", donde una pastorcita comunica sus encuentros con una gran Señora, que al perderse por la montaña señala a la señora diciendo en su idioma nativo "Orqopiña", que quiere decir: "ya está en el cerro". 

Así comienza esta historia de fe junto a "Nuestra Señora la Virgen María de Urcupiña", aunque se carece de documentación precisa sobre los inicios de esta fiesta, por ser una fiesta de los "indios" que se realiza en la doctrina del "Valle Grande de San Ildefonso de Quillacollo". Su fiesta se celebra cada 15 de agosto en honor a la Asunción de la Virgen María.

La documentación explícita a cerca de la festividad de la Virgen de Urcupiña menciona:"Una de las cargas más costosas por el fasto y solemnidad que reviste su celebración es la fiesta de la Virgen, que el 15 de agosto, realiza el Curato de Vallegrade de San Ildefonso de Quillacollo, excediendo los gastos de esta a los dos mil pesos y más" (1760)Una pintura de la imagen de la Madre en el arte Virreinal que data de 1761, con el nombre de "Virgen de Urkupiña". "Mando por el auto que se halla en dicho libro original que su mecerd bajo de precepto de Santa obediencia, solícitese las perlas pertenecientes a Ntra. Señora de Orqopiña y demás bienes extraídos pertenecientes a esta Iglesia" (Libro de Fábrica de la Iglesia de San Ildefonso de Quillacollo, 1770)."El alumbrado de la Iglesia de Quillacollo en la mayor parte del año se ayuda con las ceras que los devotos llevan a la festividad de Nuestra Señora conocida con el nombre de Urcupiña." (Libro de Fábrica de la Iglesia de Quillacollo 1848 - 1855)Entre las muchas historias que se cuenta a cerca de la Virgen, señalan los habitantes de Quillacollo, que los soldados quillacolleños alistados en el batallón Aroma, que perteneció al Regimiento Colorados al despedirse de Quillacollo, pidieron la protección de la patrona y llevándose consigo una imagen bordada en tela y más de un veterano del pacífico narró que la "Virgen de Urcupiña" acudió en ayuda de ellos..." (1880)

También fue importante su intercesión para el tiempo de la Guerra del Chaco (1932 - 1934), los soldados nombraban madrinas de guerra a importantes damas de la época, que con todo amor y buena fe en los milagros de la "Virgen de Urqupiña" se prendían en el pecho un Escapulario con la imagen y la bendición de la "Virgen de Urcupiña" para que les acompañe en los campos de batalla. 

En la década de los '70', Santa Cruz creció a grandes pasos y de pronto la fiesta de Urcupiña se llenó de cruceñas y cruceños que comenzaron a formar parte del festejo. La mayoría de ellos comerciantes que llegaban a postrarse plata de la Mamita y retornaban para devolverle el préstamo. Así el culto a la Virgen abrió tres ministerios: de finanzas, vivienda y transporte, porque la gente llegaba a pedir platita, casita o camioncito. 

En la década de los '80' de gran impacto fue la publicación de artículos en un libro bajo la dirección del periodista Rafael Peredo Antezana con el título "El Milagro de Urqupiña" (1979), donde se recoge información valiosa de muchos años de historia, como aquel donde se anunciaba que más de 10 mil peregrinos de Santa Cruz Viajaron a Urcupiña.

Uno de los monumentos históricos más importantes que tiene Quillacollo es la Iglesia de San Ildefonso, que empezó a ser construida mucho después de los sucesos milagrosos de la aparición de la Virgen. La primera piedra del Templo se colocó en 1908, siendo el párroco el Rvdo. Padre Fructuoso Mencia, llegándose a concluir en 1947 con el Mos. Francisco Cano Galvarro. En su altar se encuentra entronizada la Patrona de la Integración Nacional, la Virgen María de Urkupiña.

Debido a que desde tiempo inmemorial se venera en el templo de San Ildefonso de Quillacollo arquidiócesis de Cochabamba, a nuestra Señora, bajo la Advocación de Virgen María de Urkupiña, recibiendo feligreses, peregrinos y devotos de todo el país y del extranjero, no solo en los días de fiesta sino todo el año. Conforme al Derecho Canónico está previsto declarar Santuario a los lugares sagrados, se declara el 8 de diciembre de 1998, mediante Decreto ARZ. 1998/091, por Mons. René Fernández Apaza Arzobispo de Cochabamba, al Templo de San Ildefonso Santuario de nuestra Señora Virgen María de Urkupiña.

Es un proyecto anhelado que se retomará después de más de 20 años de espera. Existe un terreno consolidado y amurallado de más de 20 hectáreas de propiedad de la Parroquia de Quillacollo, Está previsto que la edificación albergue a más de 10.000 personas dentro y 5.000 en exteriores.

En la actualidad, la festividad en honor a la Virgen de Urkupiña forma una serie de eventos que marcan la vida en Quillacollo en julio y agosto. Empiezan con la Fastuosa Entrada Folklórica el 14 de agosto, un desfile de cerca de diez mil bailarines disfrazados y acompañados por músicos, evento inspirado por el Carnaval de Oruro que durante la segunda mitad del siglo veinte logró concentrar y estandarizar la multitud de expresiones folklóricas bolivianas y ahora se constituye la máxima expresión del complejo folklórico-religioso nacional y urbano de Bolivia por su colorido y majestuosidad, por la participación de miles de feligreses y engalanada con sus variadas músicas y danzas.

El 15 de agosto se celebra la misa solemne de fiesta, con la asistencia de las Autoridades Eclesiásticas, Nacionales y Departamentales de Bolivia, que finaliza con la procesión de la imagen de la Virgen de Urkupiña por algunas calles del centro de la ciudad de Quillacollo y la repetición de la Entrada Folklórica. 

La fiesta culmina el 16 con la romería popular al cerro "Cota" ("Calvario") donde, según la tradición, apareció la Virgen. En el calvario se realiza una serie de ritos, como la sacada de pedazos de piedra en señal de préstamo de bienes espirituales y materiales, con la promesa de volver al año siguiente para devolver los correspondientes intereses; y también está la compra simbólica de pequeños lotes de terreno y otros objetos en miniatura (casas, movilidades, títulos profesionales, etc.), con la esperanza de adquirir uno real hasta el próximo año. En ambos casos se realiza la "ch'alla" (libación y ofrenda a la Pachamama), pidiendo las bendiciones y favores a la Virgen de Urqupiña. 

La fiesta suele atraer a cerca de un millón de feligreses y turistas nacionales e internacionales y constituye un hito importante tanto en la vida religiosa y social como en la economía, el folklore y el recorrido turístico en Bolivia y los Andes.

El 8 de diciembre de 1998 ha sido nombrada "Patrona de la Integración Nacional" por el gobierno de Bolivia.

El 13 de agosto de 2012 la Asamblea Legislativa Plurinacional de Bolivia distinguió a la Virgen de Urkupiña con la Medalla de Honor al Mérito Cultural, en reconocimiento a su imagen y su festividad como parte de una de las máximas expresiones culturales de Bolivia.

Desde hace varios años se ha considerado proponer la Festividad de la Virgen de Urkupiña como Patrimonio cultural inmaterial de la humanidad por la UNESCO. En 2019 se empezó a impulsar esta propuesta, debido a su sincretismo cultural y religioso donde conviven las prácticas ancestrales precolombinas con las prácticas religiosas actuales.

Debido a la emigración boliviana, la Virgen de Urkupiña ha empezado a ser festejada en numerosas ciudades del mundo donde hay grandes y medianas comunidades de bolivianos, como ser:





</doc>
<doc id="45314" url="https://es.wikipedia.org/wiki?curid=45314" title="Juegos Olímpicos de Seúl 1988">
Juegos Olímpicos de Seúl 1988

Los Juegos Olímpicos de Seúl 1988, oficialmente conocidos como los Juegos de la XXIV Olimpiada, fueron un evento multideportivo internacional, celebrado en la ciudad de Seúl, Corea del Sur, entre el 17 de septiembre y el 2 de octubre de 1988. En esta edición participaron 8.391 atletas —6197 hombres y 2194 mujeres— de 159 países. Si se suman los árbitros, la cifra asciende a 13.304 personas de 160 países.

En un contexto marcado por el final de la Guerra Fría, la XXIV Olimpiada fue la primera desde Múnich 1972 que no vivió un boicot político masivo. Aunque Corea del Norte se negó a asistir y fue seguida por media docena de países, Seúl 1988 logró la mayor participación hasta la fecha y tanto Estados Unidos como la Unión Soviética volvieron a competir entre sí. Estos fueron también los últimos Juegos Olímpicos de dos potencias deportivas: la URSS y la República Democrática Alemana.

En el ámbito deportivo, se celebraron 237 eventos en 23 deportes oficiales, incluyendo el regreso del tenis —luego de sesenta y cuatro años de ausencia— y el estreno del tenis de mesa. En total se batieron 33 plusmarcas mundiales y 227 olímpicas. Entre los atletas más destacados, Kristin Otto se hizo con seis medallas de oro en natación; Matt Biondi obtuvo siete metales —cinco oros— en la misma disciplina; el gimnasta Vladimir Artemov consiguió cuatro oros, y la velocista Florence Griffith Joyner venció en tres pruebas de atletismo. Esta edición también estuvo marcada por varios casos de dopaje: se retiraron hasta cinco medallas, entre ellas la de Ben Johnson tras haber batido la plusmarca mundial en la final de los 100 metros.

La Unión Soviética fue líder del medallero con 132 preseas: 55 oros, 31 platas y 46 bronces, seguida por Alemania Oriental (102), Estados Unidos (94) y Corea del Sur (33).

Seúl se convirtió en la segunda capital de Asia en celebrar unos Juegos Olímpicos de Verano tras Tokio 1964. A pesar de que Corea del Sur no tenía experiencia en eventos deportivos internacionales, el país mostraba un sólido crecimiento económico y se tomó la concesión como la oportunidad de darse a conocer en el exterior. A nivel logístico, el Comité Olímpico Internacional alabó la labor del Comité Organizador; las sedes estuvieron listas con dos años de antelación, pues acogieron también los Juegos Asiáticos de 1986; participaron más de 27.000 voluntarios, hubo aforo completo en casi todas las pruebas, y de las 1.030 competiciones celebradas solo hubo retrasos en treinta. Tras su conclusión, se realizaron los VIII Juegos Paralímpicos en la misma ciudad del 15 al 24 de octubre.

El 8 de octubre de 1979, Corea del Sur había presentado a Seúl como candidata para albergar los Juegos Olímpicos de Verano 1988. Este país, marcado por la división de la península en dos estados luego de la Guerra de Corea, estaba experimentando un fuerte crecimiento económico desde los años 1960 y quería demostrar al mundo su potencial. Sin embargo, la presentación se hizo en un tiempo de inestabilidad política nacional. Dos semanas después del anuncio, el presidente Park Chung-hee, quien dirigió el país bajo un régimen autocrático durante 18 años, fue asesinado por el director del Servicio de Inteligencia. Al mes siguiente se produjo un golpe de estado que conllevó el ascenso de otro militar, el general Chun Doo-hwan, y una represión de los derechos civiles y políticos. Además, los surcoreanos no tenían experiencia en eventos internacionales —salvo el Campeonato Mundial de Tiro de 1978— y el ayuntamiento de Seúl se mostró escéptico ante el calado de las obras previstas.

El presidente Doo-hwan mantuvo el proyecto de Seúl para los Juegos Olímpicos, con el objetivo tanto de reforzar la imagen internacional de Corea como de mostrar su crecimiento. El Comité Olímpico Coreano (KOC) apoyó el proyecto ante el Comité Olímpico Internacional y a comienzos de 1980 solo quedaban dos candidatas: Seúl (Corea del Sur) y Nagoya (Japón). Por lo tanto, la XXIV Olimpiada se iba a celebrar en Asia, por segunda vez desde Tokio 1964. Atenas (Grecia) y Melbourne (Australia) habían planteado presentarse, pero lo rechazaron en última instancia.

La candidatura de Seúl planteó un proyecto que agrupaba los 21 deportes olímpicos en dos grandes complejos: un Parque Olímpico de medio millón de metros cuadrados y otro de 2,6 millones de metros que acogería la Villa Olímpica. Las subsedes serían Busan, Daegu, Gwangju y Daejeon.

Seúl tuvo en Nagoya su único rival. La ciudad japonesa era percibida como favorita meses antes de la Sesión del COI, pero Corea del Sur y su Comité Olímpico lograron darle la vuelta al vender su candidatura como una «oportunidad» de garantizar la paz en la península coreana, azotada por la guerra tan solo tres décadas atrás, y de demostrar que la capital era una metrópoli contemporánea. Para reflejar su compromiso olímpico, los surcoreanos reclamaron la organización de los Juegos Asiáticos de 1986 como preparación al evento principal, paliando así su inexperiencia, y añadieron que las infraestructuras deportivas ya estaban en construcción.

De cara a la 84.ª Sesión del COI celebrada el 30 de septiembre de 1981 en Baden-Baden (Alemania Occidental), Corea del Sur preparó numerosas actividades para convencer a los comités. Entre la delegación destacaban los principales líderes políticos del país, Chung Ju-yung (presidente de Hyundai), Kim Un-yong (presidente de la Federación Mundial de Taekwondo), y Park Chong-kyu, expresidente del KOC, quien se valió de su experiencia para garantizarse el apoyo de los miembros de África y Sudamérica.

Los puntos débiles de la candidatura de Nagoya eran la oposición ciudadana al impacto medioambiental, un menor número de instalaciones que además debían ser construidas, y el hecho de que Japón ya había albergado dos olimpiadas recientemente: los Juegos de Verano de Tokio 1964 y los Juegos de Invierno de Sapporo 1972. Eso no impidió que la votación fuese una incógnita porque los países comunistas eran más favorables a apoyar la propuesta japonesa; muchos de ellos solo reconocían a Corea del Norte como gobierno legítimo de la península.

El presidente del KOC, Cho Sang-ho, explicó ante la Sesión del COI las fortalezas de la candidatura surcoreana, y reclamó la concesión a Seúl como «foro por la paz mundial» después de que la edición de Moscú 1980 estuviese marcada por el boicot político de los países occidentales. También se les preguntó sobre el cumplimiento de los derechos humanos, la falta de experiencia organizativa, las relaciones con los estados socialistas y la red de transportes. Con el voto de 79 de los 84 miembros, Seúl dio la sorpresa al imponerse a Nagoya por 52 a 27.

El COI llegó a un acuerdo para que los Juegos Paralímpicos tuviesen lugar en la misma sede que los Olímpicos a partir de 1988, por lo que Seúl también se hizo con ese evento.

El 2 de noviembre de 1981, el presidente Chun Doo-hwan decretó la creación del Comité Organizador de los Juegos de la XXIV Olimpiada —SLOOC, por sus siglas en inglés—, que organizaría los trabajos para el evento con la colaboración del gobierno de la República de Corea, el ayuntamiento de Seúl, el Comité Olímpico Coreano (KOC) y las federaciones deportivas surcoreanas. En 1982 se creó un Ministerio de Deportes —hasta entonces las competencias eran de Educación— y en 1983 el Comité Organizador de los Juegos Asiáticos se integró en el SLOOC. A nivel local y provincial, se crearon los Comités de Promoción Olímpica para captar voluntarios.

Hubo en total tres presidentes del Comité Organizador. El primero fue Kim Yong-shik, director de la Cruz Roja en Corea del Sur y exembajador surcoreano en Reino Unido. En 1983 fue reemplazado por Roh Tae-woo, general de alto rango y hombre de confianza de Doo-hwan, que compaginó el cargo con el del Comité Olímpico Coreano. Sin embargo, Tae-woo tuvo que dimitir en 1986 para asumir el liderazgo del Partido de la Justicia Democrática y cedió el puesto a Park Seh-jik, anterior ministro de Deportes. Todos ellos estuvieron supervisados por Kim Un-yong, miembro del COI y vicepresidente del SLOOC.

Durante la 84.ª Sesión del COI se había presentado un informe en el que se detallaban los costos de albergar a los atletas, la posible ruta de la antorcha olímpica y asuntos como la capacidad hotelera, los transportes, la reducción de polución y las visitas deportivas y médicas. Una vez fueron concedidos, el SLOOC desarrolló todos esos asuntos bajo un plan maestro de seis fases; además de la construcción de las sedes, se planteó una reordenación urbanística de Seúl mediante la recuperación del río Han, la creación de zonas verdes y la modernización de la red de transportes.

El lema elegido para los Juegos Olímpicos fue «armonía y progreso» (화합과 전진, "Hwahabgwa Jeonjin"). Los cinco objetivos de la organización eran los siguientes:
La plantilla operativa estuvo formada por 49 712 trabajadores, repartidos así: 1.435 miembros del SLOOC, 27.221 voluntarios, 18 000 empleados de apoyo y 2775 empleados temporales. Además se contrataron 5725 traductores en 23 idiomas.

El SLOOC cesó su actividad el 3 de abril de 1989, seis meses después de la clausura de los Juegos Paralímpicos.

Ante la necesidad de resolver la falta de experiencia en eventos internacionales, Corea del Sur asumió la organización de los Juegos Asiáticos de 1986 que tuvieron lugar en Seúl del 20 de septiembre al 5 de octubre de 1986. En total participaron 4839 atletas de 22 países en 25 eventos. La mayoría de estados socialistas asiáticos —Corea del Norte, Afganistán, Camboya, Laos, República Popular de Mongolia, Vietnam y Yemen del Sur— boicotearon el evento, pero la organización sí logró que estuviese la delegación comunista más importante, la República Popular China, así que la participación fue incluso superior a los Juegos de 1982.

Cinco días antes de la inauguración se produjo un atentado en el Aeropuerto Internacional de Gimpo; el estallido de una bomba en la terminal de llegadas dejó un saldo de cinco muertos y 24 heridos. El gobierno surcoreano atribuyó la explosión a «agentes norcoreanos» y tuvo que reforzar las medidas de seguridad. A pesar de ese contratiempo, los Juegos Asiáticos fueron considerados un éxito de organización. En las pruebas se utilizaron la mayoría de las sedes previstas en el Parque Olímpico, entre ellas el Estadio Olímpico de Seúl inaugurado dos años atrás, y tan solo faltaba por completar la Villa Olímpica, acabar el parque ecuestre, descontaminar el río Han para las pruebas de piragüismo y pulir detalles logísticos.

Por otra parte, el SLOOC desarrolló entre 1987 y 1988 numerosas competiciones preolímpicas para estudiar el periodo de aclimatación de los deportistas, la idoneidad de las sedes y la preparación organizativa.

Tras la concesión de los JJ.OO., el SLOOC mantuvo una estrecha colaboración con el Comité Olímpico Internacional. Los tres presidentes que tuvo el Comité Organizador sumaron hasta 14 encuentros oficiales del COI para explicar los últimos avances. Además, el presidente del COI, Juan Antonio Samaranch, hizo 10 visitas oficiales a Corea del Sur, entre ellas la inauguración del Estadio Olímpico (1984) y los Juegos Asiáticos (1986).

El SLOOC asumió el cálculo presupuestario para los Juegos Olímpicos y Paralímpicos de Seúl 1988, que se saldaron con un balance positivo. Tras calcular todos los movimientos desde noviembre de 1981 hasta abril de 1989, se ingresaron más de 909.840 millones de wons y se gastaron cerca de 568.391 millones de wons, lo que arrojaba un beneficio de 341 000 millones según el reporte del Comité Organizador. En dólares, son aproximadamente 300 millones.

En Seúl 1988 hubo contribuciones tanto del gobierno surcoreano como de los patrocinadores olímpicos, a diferencia de los Juegos Olímpicos de Los Ángeles 1984 que se sufragaron sin dinero público. Además se recaudó dinero por la venta de entradas, "merchandising", derechos televisivos, donaciones, lotería y ediciones conmemorativas. Parte de los beneficios sirvieron para restaurar infraestructuras y monumentos históricos.

Para el emblema oficial de los JJ.OO. de 1988, el SLOOC hizo un concurso restringido a ocho diseñadores surcoreanos. La imagen elegida en 1983 fue una representación del "sam taegeuk" —símbolo de la cultura coreana— con los colores amarillo (humanidad), rojo (tierra) y azul (cielo). En la parte inferior aparecen los anillos olímpicos. El diseño de la imagen y su implementación corrieron a cargo de Yang Sung-chun, profesor de la Universidad Nacional de Seúl.

Junto al logotipo, el SLOOC aprobó la creación de 27 carteles deportivos, 12 culturales y 25 artísticos que fueron presentados en 1987.

Los 30 pictogramas olímpicos se estrenaron en 1983. Se distinguen entre sí por el color: azul (deportes), verde (servicios) y rojo (emergencias).

El SLOOC organizó en 1982 un concurso público para la mascota oficial al que se presentaron 4344 proyectos. Entre cuatro finalistas, el comité seleccionó en 1983 a un alegre tigre siberiano que porta un sombrero coreano con cinta. Su diseñador fue Kim Hyun. El tigre es un animal icónico de la mitología coreana, por lo que tuvo una rápida aceptación entre la sociedad del país. El nombre oficial «Hodori» (호돌이) fue elegido en 1984 por votación popular y es un acrónimo de la palabra «tigre» (en coreano, "horangi") con un diminutivo infantil. Hodori fue la primera mascota olímpica que contó con una contraparte femenina, «Hosuni».

La antorcha olímpica fue presentada al público en abril de 1984. Su diseño a cargo de Lee Woo-song, profesor de la Universidad Femenina de Sookmyung, estaba adornado con dos dragones que simbolizan la armonía entre Occidente y Oriente. En total se fabricaron más de 3300 antorchas, de las cuales 2600 serían para el relevo en Corea del Sur.

El encendido de la antorcha tuvo lugar en el templo de Hera en Olimpia el 23 de agosto de 1988, como marca la tradición. Tras recorrer Grecia un relevista partió desde el aeropuerto de Atenas, hizo una breve escala en Bangkok (Tailandia) y llegó a la isla de Jeju el 27 de agosto. Desde ahí se visitaron todas las provincias de Corea del Sur. Un total de 1467 relevistas llevaron la antorcha en un recorrido de más de 15 000 kilómetros.

A grandes rasgos, la ruta de la llama olímpica fue la siguiente:

En el anverso de las medallas se mantuvo el diseño que Giuseppe Cassioli introdujo en los Juegos Olímpicos de Ámsterdam 1928: una representación de la diosa Niké con una palma en su mano izquierda y una corona de laurel en la derecha, más la inscripción «"XXIV Olympiad Seoul 1988"». El reverso, diseñado por Yang Sung-chun, muestra una paloma de la paz con una rama de laurel en su pico, junto al logotipo de Seúl 1988 en la parte superior. El diámetro de cada medalla es de 60 mm con un grosor de 5 mm, y su peso oscila entre 515 g. y 550 g. En total se fabricaron 1590 preseas para competiciones y 188 para los deportes de exhibición.

El SLOOC designó a la radiotelevisión pública Korean Broadcasting System (KBS) como transmisor oficial de los JJ.OO., y selló un acuerdo con la Autoridad de Telecomunicaciones de Corea (KTA) para la logística y distribución de material audiovisual a otras radiodifusoras. A su vez, KBS colaboró con el canal Munhwa Broadcasting Corporation (MBC) para compartir las retransmisiones en el país anfitrión. A nivel internacional, se vendieron los derechos a NBC para Estados Unidos, la Unión Europea de Radiodifusión en Europa, la Organización Internacional de Radio y Televisión en el bloque del Este, Network Ten en Australia, NHK en Japón y la Organización de Telecomunicaciones de Iberoamérica para América Latina. La organización creada por el SLOOC para las retransmisiones fue la "Seoul Olympics Radio and Television Organization" (SORTO), con miembros de KBS, KTA y de las cadenas extranjeras. En total se recaudaron más de 407 millones de dólares con la venta a 227 radiodifusoras de 140 países.

El Centro Internacional de Prensa estuvo situado en el Centro de Exhibiciones de Seúl, cerca de la sede de KBS, con una superficie de 34.880 m². Durante los JJ.OO. fue el centro de operaciones de los más de 10.300 periodistas acreditados. Tras la conclusión de los Juegos, pasó a ser una instalación más de la televisión pública.

El proyecto original del Comité Olímpico Surcoreano contemplaba el uso de 21 sedes ya existentes, la construcción de otras 13 y el uso de cuatro subsedes en otras ciudades para el fútbol. Tras una profunda revisión, el SLOOC confirmó que eran necesarios 35 centros de competición, 72 campos de entrenamiento, 70 instalaciones adicionales y 88 recintos culturales. El grueso de pruebas se concentraría en dos puntos: el Complejo Deportivo de Seúl, que incluye el Estadio Olímpico, y el Parque Olímpico de Seúl, que incluía la Villa Olímpica. Ambos puntos estaban a tan solo 3,5 km de distancia entre sí.

La construcción de sedes era necesaria para el éxito del evento. A pesar del gran crecimiento de Seúl, la instalación más grande con la que contaban era el vetusto Estadio Dongdaemun. Desde 1973 se había planificado un área deportiva en el distrito de Jamsil, cuyo desarrollo se vio reforzado gracias a la concesión de los JJ.OO. Uno de los aspectos más importantes fue la construcción del Estadio de Béisbol de Jamsil; si bien el béisbol era solo un deporte de exhibición, se iba a tratar del recinto más utilizado a largo plazo dada la popularidad de este deporte en el país.

El Estadio Olímpico fue inaugurado en 1984 y casi todas las instalaciones estuvieron listas para los Juegos Asiáticos de 1986.



La Villa Olímpica, situada en las inmediaciones del Parque Olímpico, fue inaugurada el 31 de mayo de 1988 y una de las últimas instalaciones en completarse. Los atletas, entrenadores y árbitros fueron alojados en 86 bloques de apartamentos, con una suma total de 3692 viviendas. La zona estaba equipada con centros de información, ambulatorios, espacios de ocio y templos religiosos. Una plantilla formada por 5000 empleados —más de la mitad, voluntarios— prestó servicio tanto en los Juegos Olímpicos como en los Paralímpicos a los 14 501 residentes que pasaron por allí. Al término del evento, los pisos salieron al mercado inmobiliario.

En los Juegos Olímpicos de Seúl 1988 se celebraron 237 eventos en 23 deportes oficiales, con la incorporación del tenis de mesa. Además hubo 4 deportes de exhibición: taekwondo, béisbol, bádminton y bolos. En judo, la categoría femenina fue incluida como prueba de exhibición; no sería oficial hasta Barcelona 1992.

El tenis regresó como prueba oficial con cuatro eventos: dos en categoría masculina y otros dos en la femenina. A pesar de ser uno de los deportes más practicados, los tenistas no habían competido desde Paris 1924 porque la Federación Internacional de Tenis no formaba parte del COI. En tiro con arco se incluyó la competición de equipos por primera vez; en natación se añadió una prueba de 50 m en estilo libre, y en tiro se estrenó la categoría de 10 m en pistola de aire.



La ceremonia inaugural tuvo lugar el 17 de septiembre de 1988 en el Estadio Olímpico de Seúl. Comenzó a las 10:30 horas (UTC +9) con un número de danza tradicional coreana, seguido por una coreografía de masas en la que participaron más de 1500 bailarines. A las 11:00 en punto, la llegada del presidente de Corea del Sur marcó el inicio del desfile de atletas. La delegación de Grecia encabezó la marcha, como manda la tradición, y después salieron el resto de países por orden alfabético coreano: desde Ghana hasta Hong Kong. Finalmente, los anfitriones de Corea del Sur salieron en último lugar.

Los discursos inaugurales corrieron a cargo de Park Seh-jik, director del SLOOC, y Juan Antonio Samaranch, presidente del COI. A continuación, el presidente surcoreano Roh Tae-woo declaró «inaugurados los Juegos de la XXIV Olimpiada». La llegada de la bandera olímpica estuvo escoltada por la banda militar tradicional "Chitadae", mientras el público hizo un mosaico en el que podían leerse las palabras «"Harmony"» (armonía) y «"Progress"» (progreso), lema de los JJ.OO. de 1988. La enseña fue portada por ocho medallistas olímpicos surcoreanos.

Tras izarse la bandera, se produjo la entrada de la llama olímpica a cargo de Sohn Kee-chung, el primer medallista coreano que ganó la maratón en los Juegos Olímpicos de Berlín 1936 bajo bandera y nombre japoneses, y el encendido del pebetero corrió a cargo de tres jóvenes atletas sobre las 12:20. La organización importó palomas blancas para liberarlas durante la ceremonia como símbolo de paz, pero al hacerlo antes del encendido algunas de esas palomas se habían posado sobre el pebetero y murieron calcinadas. Seguidamente llegaron los juramentos olímpicos: Son Mi-na y Hur Jae por los atletas, y Lee Hak-rae por los árbitros.

Luego de interpretarse el himno de Corea del Sur, los atletas salieron del estadio y se realizó un «epílogo» de una hora con los siguientes números: un espectáculo de paracaidismo, un baile por la paz, una demostración masiva de taekwondo, bailes folclóricos y la actuación del grupo Koreana con la canción "Hand in Hand." La gala terminó a las 13:30 y en total participaron 13.625 personas.

Los 42 eventos que conformaron el programa de atletismo se sucedieron entre el 23 de septiembre y el 1 de octubre en el Estadio Olímpico de Seúl, con la participación récord de 1727 atletas: 1148 hombres y 579 mujeres. En total se rompieron cuatro plusmarcas mundiales y 42 olímpicas. En el medallero, los Estados Unidos y la Unión Soviética empataron en 26 metales, pero los norteamericanos superaron en oros a los soviéticos, trece a diez. No obstante, el país más laureado fue Alemania Oriental con 27 medallas, si bien quedó tercera en la clasificación general al cosechar sólo seis oros.

Carl Lewis, en la final de 100 metros, obtuvo la plusmarca mundial con 9:92 segundos, por delante del británico Linford Christie (9:97, récord europeo) y su compatriota Calvin Smith. El vencedor original de aquella final fue el atleta canadiense Ben Johnson con una plusmarca de 9:79; sin embargo, fue desposeído de la medalla dos días después al dar positivo en estanozolol. Lewis también revalidó el triunfo de 1984 en salto de longitud con una marca de 8.72 metros, y fue plata de 200 metros al ser derrotado por su compañero Joe DeLoach. La otra protagonista de Seúl 1988 fue la estadounidense Florence Griffith, triple medallista de oro en 100 metros femenino (10:54, récord mundial), 200 metros y 4x100 metros relevos, y plata en el relevo de 4 × 400 m.

Las pruebas de medio fondo estuvieron dominadas por los atletas africanos. Kenia se llevó el oro en 800 m (Paul Ereng), 1500 m (Peter Rono), 5.000 m (John Ngugi) y 3000 m obstáculos (Julius Kariuki), mientras que el marroquí Brahim Boutayeb batió la plusmarca olímpica en los 10.000 metros. Entre los atletas soviéticos, Serguéi Litvínov ganó por fin en lanzamiento de martillo (84.80 m, récord olímpico), Viacheslav Ivanenko hizo lo propio en 50 km marcha y un joven Serguéi Bubka se llevó el oro en salto con pértiga. El alemán oriental Ulf Timmermann batió la marca olímpica en lanzamiento de peso. Por último, la maratón deparó como vencedor al italiano Gelindo Bordin en categoría masculina y a la portuguesa Rosa Mota en la femenina.

La estadounidense Jackie Joyner-Kersee batió la plusmarca mundial en heptatlón (7291 puntos) y la olímpica en salto de longitud. El otro récord mundial superado fue el del equipo soviético femenino en la final del relevo de 4x400 m. Hubo sorpresas como la derrota de la plusmarquista Stefka Kostadinova, quien tuvo que conformarse con la plata en salto de altura al ser superada por Louise Ritter.

Todos los partidos de baloncesto se celebraron en el Arena Jamsil entre el 18 y el 30 de septiembre. El reglamento de la FIBA introdujo en estos JJ.OO. la línea de triple. En categoría masculina participaron doce naciones y la Unión Soviética, liderada por Arvydas Sabonis y Rimas Kurtinaitis, se llevó el oro por 63:76 sobre la Yugoslavia de Dražen Petrović y Vlade Divac. El bronce fue para Estados Unidos, que se quedó fuera de la final por primera vez en su historia al perder frente a la URSS en semifinales. La participación de profesionales de la NBA estuvo vetada hasta ese año, por lo que los norteamericanos habían acudido con un equipo de universitarios.

Estados Unidos ganó la presea dorada en categoría femenina sobre Yugoslavia por 70:77. La Unión Soviética se hizo con el bronce al derrotar a Australia por 68:53.

El Gimnasio de Suwon albergó la competición de balonmano desde el 20 de septiembre hasta el 1 de octubre, con la participación de doce selecciones masculinas y ocho femeninas que se dividían en dos grupos. En vez de haber eliminatorias, el campeón de cada grupo disputaba directamente la final y los segundos jugaban por el bronce. Corea del Sur dio la sorpresa en ambas categorías al obtener medalla. En la masculina, los anfitriones fueron líderes de grupo y obtuvieron la plata al caer frente a la Unión Soviética por 32:25. Y en la femenina, las surcoreanas se llevaron el primer oro de su historia al superar en la liguilla final a Noruega y la URSS.

El Gimnasio Estudiantil de Jamsil albergó los 427 combates que conformaron los doce eventos —todos masculinos— de boxeo desde el 17 de septiembre hasta el 2 de octubre. En total participaron 441 boxeadores amateur y 159 jueces de 106 comités nacionales, la mayor concurrencia hasta la fecha. Estados Unidos lideró el medallero con ocho preseas (tres de oro), seguida por Corea del Sur y Alemania Oriental (dos oros cada una).

Los tres estadounidenses que lograron oro fueron Kennedy McKinney (supergallo), Andrew Maynard (semipesado) y Ray Mercer (pesado). En el superpesado destacó el triunfo del canadiense Lennox Lewis, quien años después desarrollaría una exitosa carrera en el Consejo Mundial de Boxeo. Su rival en aquel combate fue el estadounidense Riddick Bowe. En peso minimosca el búlgaro Ivailo Marinov (bronce en Moscú 1980) se impuso a Michael Carbajal por decisión unánime, y en el wélter se produjo la victoria de Robert Wangila, primer keniata medallista sin competir en atletismo. El resto de vencedores fueron los surcoreanos Kim Kwang-sun (mosca) y Park Si-hun (semimedio), el italiano Giovanni Parisi (pluma), los alemanes orientales Andreas Zülow (peso ligero) y Henry Maske (medio), y el soviético Vyacheslav Yanovskiy (wélter ligero).

El boxeo estuvo marcado por dos incidentes. El más relevante se dio en la final de peso semimedio entre Park Si-hun y el estadounidense Roy Jones Jr.; a pesar de que Jones impactó 86 golpes por los 32 del anfitrión, los jueces dieron la victoria a Si-hun en reñida decisión (3:2). Dos de los tres árbitros que votaron al surcoreano suspendidos a perpetuidad, pese a lo cual mantuvo la medalla de oro. Debido a la polémica suscitada, en Barcelona 1992 se cambió el sistema de puntuación. Además, en las eliminatorias de supergallo los entrenadores de Byun Jung-il intentaron agredir al árbitro luego de que su púgil fuese penalizado. Al negarse Jung-il a bajarse del "ring", todos los jueces se marcharon del estadio y la competencia quedó suspendida hasta el día siguiente.

Las pruebas de ciclismo, celebradas entre el 8 y el 24 de septiembre, contaron con la participación de 455 atletas —391 hombres y 64 mujeres— de 62 países. En ciclismo en ruta hubo tres eventos: dos masculinos y uno femenino. Alemania Oriental dominó tanto la contrarreloj por equipos como la ruta individual en el circuito de Tongillo (Tongil-ro, Seúl), donde su atleta Olaf Ludwig se impuso a los alemanes occidentales Bernd Gröne —plata— y Christian Henn —bronce—. La vencedora en individual femenino fue la neerlandesa Monique Knol, tras una reñida recta final en la que fue necesario revisar la foto finish.

Los seis eventos de ciclismo en pista, celebrados en el Velódromo Olímpico de Seúl, estuvieron dominados por la Unión Soviética con cuatro oros, una plata y un bronce. En las cinco categorías masculinas destacó el lituano Gintautas Umaras con su victoria en persecución individual y por equipos. Lutz Heßlich ganó para la RDA una presea dorada en 1000 m sprint masculino. La estonia Erika Salumäe logró vencer con la URSS en velocidad femenina, prueba que se realizaba por primera vez en unos JJ.OO.

La alemana oriental Christa Rothenburger fue plata en 1000 m sprint. Seis meses antes había sido oro en patinaje de velocidad en los JJ.OO. de Invierno de Calgary 1988, convirtiéndose en la única atleta que ha ganado metal en ambos eventos el mismo año.

Las pruebas de hípica contaron con la participación de 197 jinetes —138 hombres y 59 mujeres— de 32 países que emplearon 241 caballos. La mayoría de eventos tuvieron lugar en el Parque Ecuestre de Seúl, situado a 18 kilómetros de la Villa Olímpica. Fue una de las pocas instalaciones que no estuvo lista hasta 1988.

El medallero estuvo copado por Alemania Federal, con sendos oros en doma para Nicole Uphoff (individual y equipos) y su caballo "Rembrandt". Por primera vez en los JJ.OO., todas las pruebas de doma clásica depararon una vencedora femenina. En competencia individual de tres días, el australiano Mark Todd y su caballo "Charisma" retuvieron el oro obtenido en 1984, mientras que Alemania Federal triunfó en equipos con una puntuación de 225.95. Por último, el gran premio de saltos terminó con victoria del francés Pierre Durand y su caballo "Jappeloup" (individual), y de Alemania Federal (equipos). El estadounidense Joseph Fargis, campeón de ambas categorías en Los Ángeles 1984, tuvo que conformarse con una plata en equipos.

Los ocho eventos de esgrima se celebraron en el Gimnasio Olímpico de Esgrima del Parque Olímpico entre el 20 y el 30 de septiembre. Un total de 247 hombres participaron en los seis masculinos. Arnd Schmitt logró para Alemania Federal el oro en espada individual, pero cayó derrotado en la final por equipos ante Francia, liderada por el seis veces medallista Philippe Riboud en su última participación. En florete, el italiano Stefano Cerioni se impuso en individual y la Unión Soviética, encabezada por Aleksandr Románkov, hizo lo propio en equipos. Por último, el francés Jean-François Lamour revalidó la presea dorada en sable, y la Hungría de Imre Gedővári lo consiguió en equipos.

La categoría femenina se limitaba al florete y estuvo dominada por Alemania Federal, con triple podio en individual —con Anja Fichtel en lo más alto— y oro en equipos. Kerstin Palm, representante de Suecia, se convirtió en la primera mujer que acudía a siete JJ.OO. consecutivos desde su debut en Tokio 1964.

En el torneo de fútbol participaron un total de dieciséis equipos, divididos en cuatro grupos. Se disputaron 32 partidos en cinco ciudades: Seúl (Estadio Olímpico y Estadio Dongdaemun), Busan, Daegu, Gwangju y Daejeon. La participación de profesionales estaba restringida a menores de 23 años sin presencia en la Copa Mundial, pero el COI dejó exento de esa limitación a los futbolistas asiáticos. Tras las eliminatorias, ocho equipos alcanzaron los cuartos de final: Suecia, Alemania Federal, Zambia, Italia, Unión Soviética, Argentina, Brasil y Australia.

En semifinales, la Unión Soviética derrotó a Italia por 2:3 con actuaciones destacadas del ruso Igor Dobrovolski y del lituano Arminas Narbekovas. Por su parte, Brasil se deshizo de Alemania Federal por 1:1 (2:3 en los penaltis) con un joven plantel liderado por Bebeto y Romario, máximo goleador. La final se celebró el 1 de octubre en el Estadio Olímpico y Brasil, clara favorita, ganaba al descanso por 0:1. Sin embargo, los soviéticos empataron de penalti y remontaron en la prórroga gracias a un tanto de Yuri Savichev. Con el 2:1 definitivo la Unión Soviética se llevó el oro, Brasil la plata y Alemania Federal el bronce.

El Arena de Gimnasia Olímpica fue la sede de la gimnasia artística —18 al 25 de septiembre— y gimnasia rítmica —28 al 30 de septiembre—. Por primera vez en la historia de los JJ.OO., las rutinas artísticas serían evaluadas por seis jueces y la puntuación final sería la suma total, eliminando la más alta y la más baja. De igual modo, se cambió la bola por la cuerda en el programa de ejercicios.

En gimnasia artística la Unión Soviética no tuvo rival en categoría masculina. Los gimnastas soviéticos otuvieron el oro en equipos y compitieron entre sí en las pruebas individuales: Vladimir Artemov se llevó tres oros más, incluyendo el concurso individual; Sergei Kharkov venció en ejercicio de suelo, Valeri Liukin se impuso en barra fija, igualado a puntos con Artemov, y Dmitri Bilozertchev ganó en anillas y caballo con arcos, donde hubo triple empate por el primer puesto. El único evento donde no hubo finalista soviético fue en salto de potro, donde el chino Lou Yun revalidó la presea dorada de Los Ángeles 1984.

En cuanto a las gimnastas femeninas, se estableció un duelo entre la soviética Yelena Shushunova y la rumana Daniela Silivas por el que ambas igualarían la marca de Nadia Comaneci de siete dieces en una sola edición. Al final Shushunova ganó el concurso individual y el de equipos, mientras que Silivas se llevó tres oros en las finales por aparatos (suelo, barra y asimétricas), plata en los concursos y bronce en salto de potro. Gracias a esos títulos, Yelena Shushunova igualó la hazaña de Liudmila Turíshcheva al ganar las cuatro competencias gimnásticas más importantes: JJ.OO., Campeonato Mundial, Copa Mundial y Europeo de Gimnasia. La otra gran vencedora fue la soviética Svetlana Boguínskaya, natural de Bielorrusia: cuatro metales, dos de oro.

En gimnasia rítmica, la URSS también ganó la medalla de oro gracias a Marina Lobatch, que compartió podio con la búlgara Adriana Dunavska y bronce con Olexandra Timoshenko.

La halterofilia tuvo lugar del 18 al 29 de septiembre en el Gimnasio Olímpico de Halterofilia con la participación de 245 levantadores de peso, todos masculinos, en diez eventos. El regreso de los estados socialistas tras su ausencia en Los Ángeles 1984 marcó el devenir de la competición, pues vencieron en nueve de las pruebas. La Unión Soviética obtuvo ocho preseas —seis de oro— seguida por Bulgaria —dos oros—, Alemania Oriental y Turquía. Aunque China no ganó ningún evento, demostró su tendencia alcista en este deporte con una plata y cuatro bronces, los segundos en número de metales.

En lo concierniente a marcas mundiales, el búlgaro Sevdalin Marinov subió a lo más alto del podio de 52 kg batiendo el récord del mundo con 270 kilos; el turco Naim Süleymanoğlu, apodado «Hércules de bolsillo», hizo lo propio en 60 kg (190 kilos en dos tiempos, 342,5 en total), y el soviético Aleksandr Kurlovich superó los 462,5 kilos levantados en +110 kg. Además de Kurlovic, los soviéticos dominaron con las victorias del armenio Oksen Mirzoyan (56 kg), el checheno Israil Arsamakov (82.5 kg), el kazajo Anatoly Khrapaty (90 kg) y los rusos Pavel Kuznetsov (100 kg) y Yury Zakharevich (110 kg). Zakharevich se había dislocado el codo cinco años atrás y pudo volver a la competición gracias a que le implantaron tendones sintéticos. Las otras victorias fueron para el germano Joachim Kunz en 67.5 kg y el búlgaro Borislav Gidikov en 75 kg.

Hubo dos vencedores a los que se desposeyó de la medalla de oro por positivo en furosemida: los búlgaros Mitko Grabnev (56 kg) y Angel Guenchev (67.5 kg). Esto causó la retirada del equipo búlgaro en protesta. Asimismo, el húngaro Andor Szanyi perdió la plata en 100 kg por positivo en estanozolol. En total hubo cinco casos detectados de dopaje.

Del 18 de septiembre al 1 de octubre, el Estadio de Seongnam albergó los partidos de hockey sobre hierba con doce selecciones masculinas y ocho femeninas. En categoría masculina, Australia y Alemania Occidental se colocaron a la cabeza de sus respectivos grupos, acompañados en semifinales por Países Bajos y Gran Bretaña. En la lucha por los metales, los británicos dieron la sorpresa al eliminar a Australia en semifinales y vencer a los germanos por 1:3 en la final. Reino Unido no ganaba una medalla de oro en hockey desde los Juegos Olímpicos de Amberes 1920. El bronce fue para los neerlandeses.

Australia sí pudo hacerse con el oro en categoría femenina, al derrotar a Corea del Sur en la final (2:0) con una actuación destacada de la capitana Rechelle Hawkes.

La competición de judo tuvo lugar en el Gimnasio Changchung desde el 25 de septiembre hasta el 1 de octubre. En la categoría masculina, con 250 deportistas de 69 países, se celebraron siete eventos. Corea del Sur lideró el medallero gracias a las victorias en las categorías de menor pesaje de Kim Jae-yup (-60 kg) y Lee Kyung-keun (-65 kg). El francés Marc Alexandre venció en -71 kg a Sven Loll, y el polaco Waldemar Legień se hizo con la primera de sus dos preseas olímpicas en -78 kg. Hubo dos judocas que revalidaron el oro obtenido en 1984: el austríaco Peter Seisenbacher (-86 kg) frente a Vladimir Shestakov, y el japonés Hitoshi Saitō (+95kg). La última medalla dorada fue para el brasileño Aurélio Miguel en -95 kg.

La categoría femenina, limitada a deporte de exhibición, contó con la participación de 53 atletas de 23 países. No fue hasta los Juegos Olímpicos de Barcelona 1992 cuando las mujeres pudieron luchar por medallas. La belga Ingrid Berghmans, una de las judocas más destacadas de su tiempo, venció en -72 kg.

El Gimnasio Sangmu de Seongnam, a 8 kilómetros de la Villa Olímpica, acogió la competición de lucha con 429 hombres de 69 países en veinte eventos: diez de lucha libre y diez de lucha grecorromana. A diferencia de otros JJ.OO., en esta ocasión se incluyó un límite de 130 kg a la categoría superpesada. La Unión Soviética fue clara vencedora del medallero con 15 metales —ocho oros—, seguida de Corea del Sur con nueve —cuatro oros—. Bulgaria fue tercera en número pero solo obtuvo un oro.

En lucha libre, los soviéticos obtuvieron cuatro oros: Sergei Beloglazov revalidó la victoria de Moscú 1980 en 57 kg, mientras que sus compañeros Arsen Fadzayev (68 kg), Majarbek Jadartsev (90 kg) y Davit Gobedzhishvili (130 kg) se estrenaron con triunfos tras haber dominado los campeonatos de esta especialidad. En lucha grecorromana, el italiano Vincenzo Maenza revalidó el oro de 1984 en el peso súperligero; los campeones soviéticos Kamandar Madzhidov (62 kg), Mikhail Mamiashvili (82 kg) y Alexandr Karelin (130 kg) sobresalieron en sus respectivas categorías, y el polaco Andrzej Wroński obtuvo el oro en 100 kg.

El programa de natación estuvo compuesto por 31 eventos celebrados entre el 18 y el 25 de septiembre en el Centro Acuático de Jamsil. Se incluyeron dos pruebas respecto al anterior programa: los 50 m estilo libre en categoría masculina y femenina. Con la participación de 633 nadadores —381 hombres y 252 mujeres—, se batieron diecisiete plusmarcas olímpicas y siete mundiales. Todos los deportes acuáticos quedan bajo supervisión de la Federación Internacional de Natación (FINA).

En categoría masculina, el nombre propio de la natación fue el estadounidense Matt Biondi con siete medallas, cinco de ellas oro: 50 m libre (22:14, récord mundial), 100 m libre (48:63, récord olímpico) y las tres pruebas de relevos. En la final de los 100 m mariposa tuvo que conformarse con la plata al ser vencido por Anthony Nesty, primer atleta de Surinam en conseguir una presea dorada, por tan solo una milésima de diferencia. El húngaro Tamás Darnyi batió dos plusmarcas mundiales en los 200 m y 400 m a cuatro estilos. Por último, el campeón soviético Vladimir Salnikov, triple medallista en Moscú 1980, logró el oro en la prueba de 1500 m antes de retirarse de la competición.

En las pruebas femeninas, Kristin Otto de Alemania Oriental fue la deportista más laureada con seis oros, algo que ninguna mujer había conseguido hasta la fecha: 50 m libre, 100 m libre, 100 m braza, 100 m mariposa y las dos pruebas de relevos. El equipo de la RDA venció en 10 de las 15 pruebas, incluyendo la plusmarca mundial de Silke Hörner en los 200 m mariposa. Solo pudo hacerles sombra la nadadora estadounidense Janet Evans, que en su debut consiguió tres oros en las pruebas de largo recorrido: 400 m libre, 800 m libre y 400 m a cuatro estilos.

Alemania Oriental venció en el medallero con 28 preseas —once oros—, seguida por Estados Unidos con 18 —ocho oros—.

Seúl 1988 fueron los segundos JJ.OO. con un programa de natación sincronizada en individual y dúos. Canadá venció ambas pruebas gracias a Carolyn Waldo (dos oros) y su compañera Michelle Cameron. Estados Unidos logró la plata con el concurso de Tracie Ruiz, campeona en Los Ángeles 1984, y de las gemelas Josephson en equipos. Por su parte, Japón obtuvo el bronce por mediación de Mikako Kotani y Miyako Tanaka.

Cuatro eventos —dos masculinos y dos femeninos— conformaron la competición de saltos, también celebrada en el Centro Acuático de Jamsil. El estadounidense Greg Louganis finalizó su carrera olímpica con sendas victorias en 3 y 10 metros, no sin antes dar un susto: el clavadista se golpeó la cabeza contra el trampolín de 3 metros, algo que no le impidió seguir compitiendo. A pesar de Louganis, los norteamericanos cedieron su dominio a los saltadores de la República Popular China, que lideró el medallero con seis de los doce metales en juego, entre ellos los oros en trampolín (Gao Min) y plataforma (Xu Yanmei). El mexicano Jesús Mena Campos fue bronce en plataforma masculina.

El torneo de waterpolo masculino contó con la participación de 12 selecciones. Al terminar la fase de grupos, habían pasado a la eliminatoria los combinados de Alemania Federal, Unión Soviética, Estados Unidos y Yugoslavia. Finalmente se repitió la final de Los Ángeles 1984 con idéntico resultado: los yugoslavos derrotaron a los estadounidenses por 9:7 para subir a lo más alto del podio. El bronce fue para la Unión Soviética.

Para el pentatlón moderno se realizaron cinco pruebas, una por día, en el siguiente orden: doma, esgrima, natación, tiro y atletismo. Entre el 18 y el 22 de septiembre participaron un total de 65 hombres de 26 países. En el individual, el húngaro János Martinek obtuvo la medalla de oro por detrás del italiano Carlo Massullo —plata— y el soviético Vakhtang Iagorashvili —bronce—. El buen papel de los magiares, con sus tres representantes entre los 10 mejores, deparó también una medalla para Hungría en el evento por equipos; Italia se llevó la plata, mientras que el bronce cayó en manos de Gran Bretaña.

Las pruebas de piragüismo se albergaron en la Regata Misari sobre el curso del río Han, completamente remodelado para la ocasión. Hubo nueve eventos masculinos y tres femeninos en los que concurrieron 275 piragüistas. El programa era el mismo que en Los Ángeles 1984, con todas las pruebas en aguas tranquilas: el piragüismo en eslalon no fue incluido hasta Barcelona 1992. Alemania Oriental venció en el medallero con nueve medallas —tres oros—, seguida por la Unión Soviética con seis —tres oros—.

En las pruebas de kayak, el estadounidense Greg Barton obtuvo dos preseas de oro en K1 1000 m (individual y dobles) y el neozelandés Paul MacDonald se llevó tres metales, uno de cada clase. El húngaro Zsolt Gyulay también tuvo una sobresaliente actuación con dos medallas doradas en K1 500 m y el K4 1000 m en equipo. En las de canoas, la Unión Soviética se impuso en tres de las cuatro pruebas, incluyendo todas las de equipos y el triunfo de Ivans Klementjevs en C1 1000 m. El único que rompió ese dominio fue el alemán oriental Olaf Heukrodt en C1 500 m. Los eventos femeninos se limitaron al kayak con victorias de la búlgara Vania Guesheva en individual y de Alemania Oriental en las dos de equipos.

El remo también tuvo lugar en la Regata Misari entre 19 y el 25 de septiembre, con ocho pruebas masculinas y seis femeninas. Por primera vez se incluyó una prueba de remo por cuatro femenino sin timonel. El regreso de los países comunistas luego del boicot en Los Ángeles 1984 se dejó notar en el medallero; Alemania Oriental se llevó ocho de los catorce oros en juego, y Rumanía hizo medalla en siete pruebas diferentes. Entre los medallistas múltiples destacaron el británico Steve Redgrave al obtener el segundo de sus cinco oros consecutivos, junto con Andy Holmes en la prueba de pareja sin timonel masculino.

El regreso del tenis al programa olímpico —del que estaba ausente desde París 1924— conllevó también la entrada de los jugadores profesionales adscritos a la Federación Internacional de Tenis, sin límite de edad. Un total de 129 tenistas —81 hombres y 49 mujeres— de 39 países concurrieron a las eliminatorias individuales y dobles. En las masculinas, Miloslav Mečíř logró el oro para Checoslovaquia en categoría individual: los estadounidenses Ken Flach y Robert Seguso derrotaron en dobles a la pareja española de Emilio Sánchez Vicario y Sergio Casal. En el individual femenino, la alemana Steffi Graf derrotó en la final a la argentina Gabriela Sabatini; ambas ya se había enfrentado en la final de Wimbledon 1988 con resultado opuesto. Los dobles femeninos fueron para el dúo estadounidense formado por Pam Shriver y Zina Garrison.

El tenis de mesa debutaba en el programa olímpico con cuatro eventos: dos masculinos y dos femeninos. Hasta entonces ni siquiera había sido deporte de exhibición. Las pruebas estuvieron dominadas por los tenistas asiáticos: Corea del Sur venció en individual masculino (Yoo Nam-kyu) y dobles femenino (Hyun Jung-hwa y Yang Young-ja). La República Popular China hizo lo propio en individual femenino (Chen Jing) y dobles masculiuno (Chen Longcan y Wei Qingguang), liderando el medallero con cinco metales. Los únicos países occidentales que consiguieron medalla fueron Yugoslavia (plata) y Suecia (bronce).

Las pruebas de tiro olímpico se celebraron del 18 al 24 de septiembre en el Campo de Tiro de Taereung, con la participación de 408 tiradores —293 hombres y 115 mujeres—. El programa contó con trece pruebas, incluyendo por primera vez los 10 metros en pistola de aire. Además, se incluyeron fases preliminares y gran final en varias pruebas, con la intención de hacerlas más atractivas para los espectadores. En total se batieron tres plusmarcas mundiales y 37 olímpicas. La Unión Soviética no tuvo rival en el medallero con once preseas, cuatro de ellas doradas.

En lo que respecta a las pruebas mixtas, el podio de "skeet" estuvo copado por el alemán oriental Axel Wegner, plata para el chileno Alfonso de Iruarrizaga y bronce para el español Jorge Guardiola. En trap fue necesario un desempate donde el soviético Dmitri Monakov derrotó al checoslovaco Miloslav Bednařík.

Los cuatro eventos de tiro con arco tuvieron lugar del 27 de septiembre al 1 de octubre en el Campo de Tiro de Hwarang. Por primera vez se incluyeron pruebas por equipos en el programa. Además, se simplificó el sistema clasificatorio con rondas eliminatorias y un menor número de tiradas. En categoría masculina participaron 84 arqueros: Jay Barrs superó al anfitrión Park Sung-soo en el individual, pero en equipos cambiaron las tornas y Corea del Sur venció a Estados Unidos. En la femenina, con 62 arqueras en liza, las surcoreanas coparon el podio con oro para Kim Soo-nyung, plata para Wang Hee-kyung y bronce para Yun Young-sook. Las tres fueron a su vez oro en equipos, luego de derrotar a Indonesia en la final.

Las pruebas de vela se celebraron en Busan, segunda ciudad más poblada de Corea del Sur y a 325 km de la capital. El fuerte viento obligó a posponer varias competencias. En esta ocasión se incluyeron ocho eventos, entre ellos el debut de la categoría femenina de 470. Francia lideró el medallero gracias a dos oros en 470 masculino (Thierry Peponnet y Luc Pillot) y en tornado (Jean Le Deroff y Nicolas Hénard), mientras que España logró su único metal dorado en estos JJ.OO. por mediación de José Luis Doreste en "finn". El país que más preseas obtuvo fue Estados Unidos, cinco en total.

En el programa de voleibol se disputaron dos eventos, uno masculino y uno femenino, con fase final en el Arena Jamsil. La selección de participantes se hizo según los criterios de la Federación Internacional de Voleibol. En el torneo masculino compitieron 12 selecciones: Estados Unidos revalidó su título olímpico y compartió podio con la Unión Soviética —plata— y Argentina —bronce—. En el torneo femenino, compuesto por 8 países, la Unión Soviética ganó el oro frente a Perú, revelación del evento y plata en la mejor participación de su historia. El bronce fue para China.

Los principales deportes de exhibición elegidos por el SLOOC fueron el taekwondo (nacional) y el béisbol (internacional). El taekwondo es el arte marcial emblemático de Corea del Sur, característico por sus técnicas de patadas, mientras que el béisbol es uno de los deportes de equipo más practicados del país. A estas pruebas se incluyeron tres más: bolos, bádminton y judo en categoría femenina.

El torneo de taekwondo se celebró en el Gimnasio Changchung entre el 17 y el 20 de septiembre, con dieciséis eventos —ocho masculinos y ocho femeninos— bajo reglamento de la Federación Mundial de Taekwondo (WTF) en los que participaron 120 deportistas. Los surcoreanos vencieron siete de las ocho pruebas masculinas, si bien en las femeninas hubo mayor igualdad. El taekwondo volvió a ser deporte de exhibición en Barcelona 1992 y no formaría parte del programa oficial hasta Sídney 2000.

En cuanto al béisbol, el Estadio de Béisbol de Jamsil acogió del 19 al 28 de septiembre un torneo de ocho equipos, cuyo campeón fueron los Estados Unidos, con una selección repleta de universitarios en la que destacaba el "pitcher" Jim Abbott. Este deporte fue incluido en el programa olímpico en la siguiente edición de Barcelona 1992, luego de haber sido deporte de exhibición hasta en siete ocasiones.

Después de dos semanas de competiciones deportivas, el Estadio Olímpico albergó la ceremonia de clausura el 2 de octubre de 1988. A las 19:00 horas (UTC +9) se inició con un tradicional baile "pungmul", y cinco minutos después se produjo la entrada de todos los atletas sin distinción de nacionalidades. A continuación hubo una representación del «puente de las urracas» en la que participaron más de 750 artistas.

El presidente del COI, Juan Antonio Samaranch, felicitó públicamente al SLOOC y a todos los participantes por «su contribución al éxito de estos Juegos Olímpicos, los mejores y más universales de nuestra historia», para luego clausurar el evento con la fórmula protocolaria: «Declaro finalizados los Juegos de la XXIV Olimpiada e invito a la juventud del mundo a reunirse, en cuatro años, en Barcelona, para la celebración de los Juegos de la XXV Olimpiada». El alcalde de Seúl, Yong Nae-kim, entregó la bandera olímpica a su colega de la ciudad condal, Pasqual Maragall.

Un espectáculo de danza española contemporánea precedió a la bajada de la bandera olímpica y al lento apagado de la llama olímpica. Para la despedida, más de 1200 bailarines participaron en un baile de linternas, seguido de un espectáculo de fuegos artificiales. El espectáculo finalizó a las 20:30 horas. Los Juegos Paralímpicos de Seúl 1988 transcurrieron dos semanas más tarde, desde el 15 hasta el 24 de octubre.

En los Juegos Olímpicos de Seúl participaron 159 países, a través de sus respectivos comités nacionales afiliados al Comité Olímpico Internacional. Compitieron 8391 atletas (6197 hombres y 2194 mujeres), lo cual supuso un récord de participación.

La noticia positiva fue que Estados Unidos y la Unión Soviética volvieron a competir entre sí en unos JJ.OO. Los estadounidenses habían boicoteado Moscú 1980 y los soviéticos hicieron lo propio en Los Ángeles 1984, por lo que convencer a ambas naciones suponía recuperar a las mayores potencias deportivas en los últimos años de la Guerra Fría. Sin embargo, Seúl 1988 no se libró de los boicots; Corea del Norte, histórico rival político del Sur, rechazó participar y fue seguido por sus aliados de Albania (por cuarta vez consecutiva), Cuba y Etiopía. Además Madagascar, Nicaragua y las Seychelles renunciaron por diferentes motivos.

El COI mantuvo el veto a Sudáfrica por sus políticas de "apartheid", siendo 1988 la última edición en la que eso ocurriría.

Estos fueron los últimos Juegos Olímpicos de dos países que tradicionalmente dominaban el medallero: la Unión Soviética (disuelta en 1991) y la República Democrática Alemana (reunificada en 1990). También supusieron el adiós de la República Federativa Socialista de Yugoslavia.

Varios comités hicieron su debut olímpico en Seúl 1988: Aruba, Guam (ya presente en los Juegos de Invierno), Islas Cook, Maldivas, Samoa Americana, San Vicente y las Granadinas, Vanuatu y Yemen del Sur. La debutante Brunéi envió sólo a un árbitro. La atleta más joven fue la nadadora angoleña Nádia Cruz (13 años), mientras que el más veterano fue el velista bahameño Durward Knowles (70 años).

Un total de cincuenta y dos países obtuvieron medalla en estos Juegos Olímpicos. El más laureado fue la Unión Soviética con 132 metales, seguida por República Democrática Alemana con 102; ambas naciones firmaron su última participación en este evento. Estados Unidos fue tercera en el medallero con 94 y Corea del Sur finalizó cuarta (33) gracias a un mayor número de oros, pese a que Alemania Occidental (40) y Bulgaria (35) habían obtenido más preseas.

Entre los países que ganaron una medalla por primera vez se encuentran Antillas Neerlandesas (vela), Costa Rica (natación), Indonesia (tiro con arco), Islas Vírgenes Estadounidenses (vela), Senegal (atletismo), Surinam (natación) y Yibuti (atletismo).

En el momento de la concesión de los JJ.OO., Corea del Sur estaba gobernado por un gobierno autoritario muy influido por el estamento militar. El general Park Chung-hee llegó al poder mediante un golpe de estado en 1960, mantuvo una democracia limitada y en 1972 declaró la ley marcial para gobernar sin oposición hasta su asesinato en 1979. Y a pesar de que se intentaron tímidas reformas democráticas, éstas fueron reprimidas con otro golpe de estado que propició el ascenso del general Chun Doo-hwan en 1980. Durante toda la década se produjeron manifestaciones en las grandes ciudades para reclamar tanto derechos civiles y políticos como elecciones libres.

Los movimientos democráticos vieron en la cita olímpica una gran oportunidad para conseguir sus propósitos, más aún cuando Chun Doo-hwan propuso en 1987 que Roh Tae-woo, expresidente del SLOOC, le sucediera al frente de la presidencia. Tras confirmarse, la oposición —encabezada por Kim Dae-jung y Kim Young-sam— constituyó el Movimiento Democrático de Junio, que a través de movilizaciones diarias exigía una transición hacia la democracia plena, y cuyo punto de inflexión fue la «Marcha Nacional por la Paz». Esas movilizaciones tuvieron apoyo internacional y muy especialmente de Estados Unidos, interesada en la estabilidad política de la península. Finalmente, Doo-hwan tuvo que dimitir y el 29 de junio de 1987 anunció una reforma constitucional que, además de elecciones presidenciales por sufragio universal, restablecía los derechos civiles y políticos.

El candidato oficialista Roh Tae-woo fue elegido presidente por mayoría simple y llegó a Seúl 1988 como jefe del estado de una democracia multipartidista.

Por otro lado, en 2017 se desveló que la policía surcoreana habría detenido antes de los JJ.OO. a miles de personas sin hogar, para enviarlas a campos de trabajo y ocultar su presencia.

Tras el final de la Guerra de Corea, la península coreana se encontraba dividida en dos estados soberanos que reclamaban todo el territorio como propio: Corea del Norte —socialismo juche, auspiciado por China— y Corea del Sur —capitalista, apoyado por Estados Unidos—. El alto el fuego de 1953 establecía la creación de una zona desmilitarizada en el paralelo 38 norte, pero formalmente ambas partes seguían en guerra porque no se había firmado un tratado de paz. Si bien la reunificación de Corea era un objetivo común, nunca pudo llevarse a cabo por el enquistamiento del conflicto y las continuas disputas de los dos actores. No obstante, el SLOOC se mostró esperanzado en lograr un equipo coreano unificado.

En octubre de 1985, el presidente del COI Juan Antonio Samaranch se implicó en la organización de la Reunión Deportiva Intercoreana en Lausana, a la que asistieron miembros del Comité Olímpico Surcoreano (KOC) y del Comité Olímpico Norcoreano (NOC), estos últimos a instancias del líder cubano Fidel Castro. El Centro Internacional para Académicos Woodrow Wilson ha desvelado que los norcoreanos reclamaban una olimpiada compartida al 50 % entre Seúl y Pionyang, a lo que el COI se negó por cuestiones logísticas. Los surcoreanos no estaban dispuestos a ceder más de lo imprescindible, y aunque Samaranch ofreció hasta tres pruebas —fútbol, tenis de mesa y tiro con arco— no hubo avances significativos.

Finalmente, Corea del Norte confirmó el 2 de septiembre de 1988 —dos semanas antes de la inauguración— que no asistiría a Seúl. Se unieron al boicot sus aliados de Albania, Cuba y Etiopía. Samaranch consiguió que la República Popular China no se sumara por el interés de Deng Xiaoping en organizar los Juegos Olímpicos de 2000. Los JJ.OO. sirvieron para que la República de Corea iniciase una apertura diplomática con el bloque del Este.

Además de las negociaciones, otro hecho reseñable fue el atentado terrorista contra el Vuelo 858 de Korean Air, que explotó el 29 de noviembre de 1987 con 115 personas a bordo. El ataque fue obra de dos agentes secretos norcoreanos que intentaron suicidarse al ser detenidos; la única superviviente, Kim Hyon-hui, aseguró que entre otros objetivos se pretendía sabotear el turismo durante los Juegos.

Aunque los Juegos Olímpicos de Seúl 1988 fueron un éxito organizativo, acabaron marcados por los casos de dopaje. En total se hicieron más de 1.600 controles y se detectaron una decena de infracciones. La prueba más afectada fue la halterofilia: de los cinco atletas descalificados, tres habían obtenido medalla. Hubo también positivos en atletismo, equitación y lucha. A raíz de todos los detectados, la lucha antidopaje se intensificó en la década de 1990.

El positivo de Ben Johnson por anabolizantes tuvo un enorme impacto a nivel mundial, pues había vencido la final de los 100 metros lisos con una plusmarca mundial de 9:79 segundos. El COI le retiró la medalla de oro con efecto inmediato y se la otorgó al segundo clasificado, Carl Lewis, mientras que la Federación Internacional de Atletismo sancionó al canadiense por dos años. Todos estos sucesos abrieron un debate sobre el uso de sustancias prohibidas en el deporte de alta competición, y tanto Lewis como Linford Christie quedaron bajo sospecha. En 2003, el exdirector antidopaje del Comité Olímpico Estadounidense (USOC), Wade Exum, aseguró que el organismo autorizó la participación de Lewis a pesar de haber dado positivo en controles previos. No obstante, el USOC quitó hierro a las acusaciones y las atribuyó a una venganza personal. La prematura muerte de Florence Griffith Joyner en 1998 también incrementó las sospechas de dopaje, aunque nunca se encontraron pruebas.

Se sospecha que el número de casos de dopaje pudo ser significativamente mayor. La República Democrática Alemana, segunda en el medallero con 102 preseas, fue acusada tras la reunificación alemana de haber establecido una red de dopaje masivo, el «Plan Estatal 14.25», por la que varios entrenadores confesaron haber suministrado esteroides a sus deportistas sin que estos tuvieran conocimiento.

Los Juegos Olímpicos de Seúl 1988 tuvieron un enorme impacto en Corea del Sur. Además de confirmar al país como una de las principales potencias de Asia Oriental, sirvieron en su apertura exterior y en el establecimiento de una democracia multipartidista. Igual que hicieron los japoneses con Tokio 1964, el gobierno surcoreano quiso utilizar las Olimpiadas para incentivar la inversión extranjera, así como las relaciones diplomáticas con la Unión Soviética y con la República Popular China, aliados de Corea del Norte. Y si bien los norcoreanos boicotearon el evento, se logró que Estados Unidos y la URSS compitiesen entre sí, algo que no sucedía desde Montreal 1976. El presidente del COI, Juan Antonio Samaranch, definió su desarrollo como «los mejores y más universales Juegos Olímpicos de nuestra historia» hasta la fecha.

En líneas generales, se considera que Seúl 1988 fue un éxito por la asistencia a los estadios, con llenos en casi todas las pruebas, y la preparación de la organización desde los Juegos Asiáticos de 1986. Todo ello ha permitido que Corea del Sur acoja otros grandes eventos deportivos internacionales: el Campeonato Mundial de Taekwondo de 1989, la Copa Mundial de Fútbol de 2002, el Campeonato Mundial de Atletismo de 2011 y dos ediciones de los Juegos Asiáticos en Busan (2002) e Incheon (2014).

Treinta años después de la Olimpiada de verano, Corea del Sur albergó los Juegos Olímpicos de Invierno 2018 en Pieonchang.

En lo que respecta a Seúl, que décadas atrás había vivido un crecimiento demográfico incontrolado, las obras sirvieron para crear zonas verdes, rehabilitar monumentos históricos y descontaminar el río Han. El Parque Olímpico de Seúl es ahora una zona residencial y varias de sus instalaciones, como el Arena de Gimnasia Olímpica o el Pabellón Olímpico, han sido reconvertidas en salas de conciertos.




</doc>
<doc id="45323" url="https://es.wikipedia.org/wiki?curid=45323" title="Teoría del orden">
Teoría del orden

La teoría del orden es una rama de la matemática que estudia varias clases de relaciones binarias que capturan la noción intuitiva del orden matemático. Este artículo provee una introducción detallada a este campo e incluye algunas de las definiciones básicas. Para una rápida búsqueda de un término orden teórico, hay también un glosario de teoría del orden. Una lista de asuntos sobre orden recoge los artículos que existen en relación a esta teoría del orden.

El orden aparece por todas partes - por lo menos, si se trata de matemática y áreas relacionadas tales como la informática. El primer orden que uno típicamente encuentra en la educación matemática de la escuela primaria es el orden ≤ de los números naturales. Este concepto intuitivo es fácilmente extendido a otros conjuntos de números, tal como los enteros y reales. De hecho la idea de ser mayor o menor que otro número es una de las intuiciones básicas de los sistemas de numeración en general (que uno generalmente se interesa también en la diferencia real de dos números, que no viene dada por el orden). Otro ejemplo popular de un orden es el orden lexicográfico de las palabras en un diccionario. 

Los tipos antedichos de orden tienen una propiedad especial: cada elemento se puede "comparar" con cualquier otro elemento, es decir es o mayor, o menor, o igual. Sin embargo, esto no siempre es un requisito deseable. Un ejemplo bien conocido es el orden de los subconjuntos de un conjunto. Si un conjunto contiene los elementos de cierto otro conjunto, entonces se puede decir que es mayor o igual. Con todo, hay conjuntos que pueden no ser comparables de este modo, puesto que cada uno puede contener algún elemento que no esté presente en el otro. Por lo tanto, inclusión de subconjuntos es un "orden parcial", en comparación con los "órdenes totales" dados antes. 

Alentadas por los amplios usos prácticos de los órdenes, se pueden definir numerosas clases especiales de conjuntos ordenados, algunas de las cuales han llegado a ser campos matemáticos por sí mismos. Además, la teoría del orden no se restringe a las varias clases de relaciones de orden, sino que también considera funciones apropiadas entre ellas. Un ejemplo simple de una propiedad orden teórica viene del análisis donde encontramos con frecuencia a las funciones monótonas.

Esta sección tiene como objetivo dar una primera guía al reino de los conjuntos ordenados. Está dirigida al lector que tiene un conocimiento básico teoría de conjuntos y aritmética y que sabe qué es una relación binaria, pero que no está familiarizado, hasta ahora, con consideraciones teóricas sobre orden. 

Como ya se hizo alusión arriba, un orden es una relación binaria especial. Por lo tanto consideremos algún conjunto "P" y una relación binaria ≤ en "P". Entonces ≤ es un orden parcial si es reflexiva, antisimétrica, y transitiva, es decir, para todo "a", "b" y "c" en "P", tenemos que:

Un conjunto con un orden parcial se llama conjunto parcialmente ordenado, o, en breve, poset (del inglés partially ordered set). El término conjunto ordenado a veces también se utiliza para los "posets", mientras esté claro del contexto que no se quiere significar ninguna otra clase de órdenes. Comprobando esta propiedad, se ve inmediatamente que los bien conocidos órdenes de los naturales, enteros, racionales y reales son todos órdenes en el antedicho sentido. Sin embargo, tienen la propiedad adicional de ser total, es decir, para todo "a", "b" en "X"
este orden se puede también llamar orden lineal o cadena. mientras que muchos órdenes clásicos son lineales, el orden entre subconjuntos de un conjunto proporciona un ejemplo donde éste no es el caso. De hecho, muchas propiedades avanzadas de los posets son interesantes principalmente para un orden no lineal.

Antes de proceder con más ejemplos y definiciones, será provechoso poder exhibir un orden de una manera gráfica conveniente, para proporcionar un "cuadro" que uno pueda tener en mente (o en papel) cuando se intente acceder a conceptos más abstractos. Para este propósito se han introducidos los, así llamados, diagramas de Hasse. Estos son grafos donde los vértices son los elementos del "poset" y la relación de orden está indicada por las aristas y la posición relativa de los vértices. Los órdenes se dibujan de abajo hacia arriba: si un elemento "x" es menor que "y" entonces existe una trayectoria de "x" hasta "y" que se dirige hacia arriba. A menudo es necesario que la conexión entre puntos se intersequen, pero los puntos nunca deben ser situados en conexión directa entre otros dos puntos. 

Aún los conjuntos infinitos pueden a veces ser ilustrados por diagramas similares, usando puntos suspensivos (...) después de dibujar un suborden finito que sea lo suficientemente instructivo. Esto funciona bien para los números naturales, pero falla para los reales, donde no existe el inmediato sucesor. Sin embargo, frecuentemente se obtiene una intuición relacionada con diagramas de este tipo. 

Todos los órdenes antedichos son muy comunes en matemática, sin embargo hay también ejemplos que uno no considera a menudo como órdenes. Por ejemplo, la relación de identidad "=" en un conjunto es un orden parcial. Dentro de este orden, cualesquiera dos (i.e. distintos) elementos son incomparables. Es también la única relación que es un orden parcial y una relación de equivalencia. El diagrama de Hasse de tal orden discreto es solamente una colección de puntos etiquetados, sin ninguna arista entre ellos. 

Otro ejemplo viene dado por la relación de divisibilidad "|". Para dos números naturales "n" y "m", escribimos "n"|"m" si "n" divide a "m" sin resto. Uno ve fácilmente que esto da realmente un orden parcial. Un ejercicio instructivo es dibujar el diagrama de Hasse para el conjunto de los números naturales que son menores o iguales que, digamos, 13, ordenados por "|".

En un conjunto parcialmente ordenado hay algunos elementos que desempeñan un papel especial. El ejemplo más básico está dado por el mínimo de un "poset". Por ejemplo, 1 es el mínimo de los números naturales y el conjunto vacío es el mínimo bajo el orden de subconjuntos. Formalmente, esto se puede describir por la propiedad: 

Es frecuente encontrar la notación 0 para el mínimo, incluso cuando no se refiera a números. Sin embargo, en un orden de un conjunto numérico, esta notación puede ser inadecuada o ambigua, puesto que el número 0 no siempre es el mínimo. Un ejemplo es el antedicho orden de divisibilidad |, donde 1 es el mínimo puesto que divide a todo el resto de números. Por otra parte, 0 es un número que se divide por todo el resto de números. ¡Por lo tanto es el máximo del orden! Otros términos frecuentes para estos elementos son fondo y tapa o cero y uno. Pueden no existir los elementos "mínimo" o "máximo", como demuestra el ejemplo de los números reales. Por otra parte, si existen son siempre únicos. En contraste, consideremos la relación de divisibilidad | en el conjunto {2, 3, 4, 5, 6}. Aunque este conjunto no tiene ni tapa ni fondo, los elementos 2, 3, y 5 no tienen ningún elemento debajo, mientras que 4, 5, y 6 no tienen ninguno otro número arriba. Tales elementos se llaman minimales y maximales, respectivamente. 
Formalmente, un elemento "m" es minimal si: 

Intercambiando ≤ con ≥ obtenemos la definición de maximal. Como el ejemplo demuestra, puede haber muchos elementos minimales o maximales y algún elemento puede ser maximal y minimal (e.g. 5 arriba). Sin embargo, si hay un elemento mínimo, entonces es el único elemento minimal del orden. (Si se sigue estrictamente la definición dada. Lamentablemente hay una tradición matemática "a contrario": considerar los minimales y maximales en el conjunto despojado de su máximo y su mínimo, si los hubiere. Esto debe recordarse. N.T.). Una vez más, en los posets no siempre hay infinitos elementos maximales - el conjunto de todos los subconjuntos finitos en un conjunto infinito dado, ordenado por inclusión de subconjuntos, proporciona uno, entre muchos, contraejemplo. Una herramienta importante para asegurar la existencia de elementos maximales bajo ciertas condiciones es el Lema de Zorn. 

Los subconjuntos de un conjunto parcialmente ordenado heredan el orden. Ya aplicamos esto al considerar el subconjunto {2, 3, 4, 5, 6} de los números naturales con el orden de divisibilidad inducido. Hay también elementos de un "poset" que son especiales con respecto a cierto subconjunto del orden. Esto conduce a la definición de cota superior. Dado un subconjunto "S" de cierto poset "P", una cota superior de "S" es un elemento "b" de "P" que está sobre todo elemento de "S". Formalmente, esto significa que

Cota inferior se define invirtiendo el orden. Por ejemplo, -5 es una cota inferior de los números naturales como subconjunto de los enteros. Dado un conjunto de conjuntos , una cota superior para éstos conjuntos viene dado por su unión. De hecho, esta cota superior es muy especial: es el más pequeño conjunto que contiene todos los conjuntos dados. Por lo tanto, encontramos la menor cota superior de un conjunto de conjuntos. Este concepto se llama también supremo y para un conjunto "S" se escribe sup "S" o V"S" para su menor cota superior. Inversamente, la mayor cota inferior se la conoce como ínfimo y se denota inf "S" o ^"S". Este concepto desempeña un papel importante en muchos usos de la teoría del orden. Para dos elementos "x" y "y", uno también escribe "x" v "y" y "x" ^ "y" para sup{"x", "y"} e inf{"x", "y"}, respectivamente. 

Usando Wikipedia , uno puede también escribir formula_1 y formula_2, así como símbolos grandes formula_3 y formula_4. Observe, sin embargo, que todos esos símbolos pueden no tener símbolo de tamaño correspondiente al de la fuente del texto estándar y, por tanto, se prefiere utilizarlos en líneas adicionales. Muchos de los navegadores de hoy son incapaces de representar ∨ para v y ∧ para ^ en algunas plataformas, y por lo tanto se evita aquí.

Considere otro ejemplo en la relación | para los números naturales. La menor cota superior de dos números es el menor número que es múltiplo de ambos, es decir el mínimo común múltiplo. Mayor cota inferior es, alternativamente, el máximo común divisor.

En las anteriores definiciones, a menudo, observamos que un concepto puede ser definido por invertir simplemente el orden en una definición anterior. Este es el caso para "menor" y "mayor", para "mínimo" y "máximo", para "cota superior " y "cota inferior", etcétera. Esto es una situación general en teoría de orden: Un orden dado se puede invertir con solamente intercambiar su dirección, pictóricamente dar vuelta el diagrama de Hasse de arriba para abajo. Esto da el, así llamado, orden dual, inverso u opuesto. 

Cada definición orden teórica tiene su dual: es la noción que se obtiene al aplicar la definición al orden inverso. Dada la simetría de todos los conceptos, esta operación preserva los teoremas del orden parcial. Para un resultado matemático dado, se puede, simplemente, invertir el orden y substituir todo definición por su dual y obtener otro teorema válido. Esto es importante y útil, puesto que uno obtiene dos teoremas al precio de uno. Más detalle y ejemplos se pueden encontrar en el artículo sobre dualidad en teoría de orden. 

Hay muchas maneras de construir órdenes o de combinar órdenes en uno nuevo. El orden dual es un primer ejemplo. Otra construcción importante es el producto cartesiano de dos conjuntos parcialmente ordenados, junto con el orden producto en pares de elementos. Esto se define por los órdenes originales haciendo ("a", "x") ≤ ("b", "y") si "a" ≤ "b" y "x" ≤ "y". La unión disjunta de dos conjuntos parcialmente ordenados es otra construcción típica, donde el orden es exactamente la unión de los órdenes originales. 

Como en el caso del orden usual de números, cada orden parcial ≤ da lugar a un orden estricto <, al definir "a" < "b" si "a" ≤ "b" y no "b" ≤ "a". Esta transformación puede ser invertida haciendo "a" ≤ "b" si "a" < "b" o "a" = "b".

Es razonable requerir que las funciones entre conjuntos parcialmente ordenados tengan ciertas propiedades adicionales, que se relacionen con la relación de orden de los dos conjuntos. La condición más fundamental que se presenta en este contexto es la monotonía. Un función "f" de un "poset" "P" a un "poset" "Q" es monótona u orden preservante, si "a" ≤ "b" en "P" implica "f"("a") ≤ "f"("b") en "Q". La conversa de esta implicación conduce a una función que es orden reflectante, es decir una función "f" como arriba para la cual "f"("a") ≤ "f"("b") implica "a" ≤ "b". Por otra parte, una función puede también ser orden inversora o antítona, si "a" ≤ "b" implica "f"("a") ≥ "f"("b"). 

Una inmersión de orden es una función "f" entre órdenes que es orden preservante y orden reflectante. Ejemplos para esta definición se encuentran fácilmente. Por ejemplo, función que mapea un número natural en su sucesor es claramente monótona con respecto al orden natural. Cualquier función de un orden discreto, es decir un conjunto ordenado por el orden identidad "=", es también monótono. Mapear cada número natural al correspondiente número real da un ejemplo para una inmersión de orden. El complemento conjuntista en un conjunto de partes es un ejemplo de una función antítona. 

Una importante pregunta es cuándo dos órdenes son "esencialmente iguales", es decir cuándo son lo mismo salvo retitular elementos. Un isomorfismo de orden es una función que define tal renombrar. Un isomorfismo de orden es una función monótona biyectiva que tiene una inversa monótona. Esto es equivalente a una inmersión de orden sobreyectiva. Por lo tanto, la imagen "f"("P") de una inmersión de orden es siempre isomorfa a "P", lo que justifica el término "inmersión". 

Un más elaborado tipo de función es la, así llamada, conexión de Galois. Conexiones de Galois monótonas pueden ser vistas como una generalización de los isomorfismos de orden, puesto que están constituidas por dos funciones en inversa dirección, que no son inversas absolutas una de la otra, pero tienen cercana relación. 

Otro tipo especial de endofunción en un "poset" es el operador de clausura, que no solamente es monotónico, sino también idempotente, es decir. "f"("x") = "f"("f"("x")), y extensivo, es decir. "x" ≤ "f"("x"). éste tiene mucho uso en todo clase de "clausuras" que aparecen en matemática. 

Además de compatible con la mera relación de orden, una función entre "posets" puede también "comportarse bien" con respecto a elementos especiales y construcciones. Por ejemplo, cuando se habla de posets con menor elemento, parece razonable considerar solamente una función monotónica que preserve este elemento, es decir que mapee menor elemento en menor elemento. Si el ínfimo binario ^ existe, entonces una propiedad razonable puede ser requerir que "f"("x"^"y") = "f"("x") ^ "f"("y"), para todo "x" y "y". Todas estas propiedades, y de hecho muchas más, pueden ser agrupadas bajo la etiqueta función que preserva límite. 

Finalmente, uno puede invertir la visión, cambiar "funciones de orden" a "orden de funciones". De hecho, las funciones entre dos "posets" "P" y "Q" pueden ser ordenadas "vía" el orden punto a punto. Para dos funciones "f" y "g", se tiene "f" ≤ "g" si "f"("x") ≤ "g"("x") para todo elemento "x" en "P". Esto ocurrirá por ejemplo en teoría de dominios, donde los espacios funcionales desempeñan un importante papel. 

Muchas de las estructuras que son estudiadas en teoría de orden emplean relaciones con propiedades adicionales. De hecho, algunas relaciones que no son de orden parcial son de especial interés. Principalmente, el concepto de preorden tiene que ser mencionado. Un preorden es una relación que es reflexiva y transitiva, pero no necesariamente antisimétrica. Cada preorden induce una relación de equivalencia entre elementos, donde "a" es equivalente a "b", si "a" ≤ "b" y "a" ≥ "b". Los preórdenes pueden ser convertidos en órdenes identificando todo elemento equivalente con respecto a esta relación. 

Tipos básicos de órdenes especiales ya se dieron en forma de orden total. Una simple pero útil propiedad adicional conduce al, así llamado, buen orden, dentro del que todo subconjunto no vacío tiene un menor elemento (también denominado primer elemento). Muchos otros tipos de orden se presentan cuando se garantiza la existencia de ínfimos y supremos de ciertos conjuntos. Centrándose en este aspecto, generalmente referido como completitud de órdenes, se obtiene: 





Sin embargo, uno puede ir incluso más allá: si todo ínfimo finito no vacío existe, entonces ^ puede ser visto como una operación binaria total en el sentido del álgebra universal. Por lo tanto, en un reticulado, dos operaciones ^ y v están disponibles, y se puede definir nuevas propiedades dando identidades, tal como

Este condición se llama distributividad y dar lugar a los reticulados distributivos. Hay algunas otras importantes leyes de distributividad que son discutidas en el artículo sobre la distributividad en teorías de orden. Algunas estructuras de orden adicionales que son a menudo especificadas "vía" operación algebraica y definiendo identidades son



en que ambas introducen una nueva operación ~ llamada negación. Ambas estructuras desempeñan un papel en lógica matemática y especialmente las álgebras de Boole tienen importante uso en informática. Finalmente, varias estructuras en matemática combinan orden con operaciones aún más algebraicas, como el caso de quantales, que permite la definición de una operación de adición. 

Existen muchas otras importantes propiedades de los "posets". Por ejemplo, un "poset" es localmente finito si cada intervalo cerrado ["a", "b"] en él es finito. Los posets localmente finitos dan lugar a álgebras de incidencia que alternadamente pueden ser utilizadas para definir característica de Euler de "posets" finitos acotados.

En un conjunto ordenado, uno puede definir muchos tipos especiales de subconjuntos basados en el orden dado. Un ejemplo simple son los conjuntos superiores, es decir conjuntos que contienen todo elemento que esté sobre ellos en el orden. Formalmente, la clausura superior de un conjunto "S" en un poset "P" viene dado por el conjunto {x en "P"| hay algún "y" en "S" con "y" ≤ "x"}. Un conjunto que es igual a su clausura superior se llama un conjunto superior. conjunto inferior es definido dualmente. 

Subconjuntos inferiores más complicados son los ideales, que tienen la propiedad adicional que cada dos de sus elementos tiene cota superior dentro del ideal. Su noción dual son los filtros. Un concepto relacionado es el de subconjunto dirigido, que como un ideal contiene cota superior de un subconjunto finito, pero no tiene por qué ser un conjunto inferior. Además, a menudo se generaliza a conjuntos preordenados. 

Un subconjunto que es - como sub-poset - linealmente ordenado, se llama una cadena. La noción opuesta, anticadena, es un subconjunto que no contiene ningún par de elementos comparables, es decir que es un orden discreto.

Aunque la mayoría de las áreas matemáticas usan orden de uno u otra manera, también hay algunas teorías que tienen una relación que va mucho más allá de la mera utilización. Junto con su importante punto de contacto con la teoría de orden, algunas serán presentadas abajo. 

Según lo ya mencionado, los métodos y el formalismo del álgebra universal son una herramienta importante para muchas consideraciones orden teóricas. Aparte de formalizar órdenes en términos de estructuras algebraicas que satisfacen ciertas identidades, se pueden también establecer otras conexiones con el álgebra. Un ejemplo es la correspondencia entre las álgebras de Boole y los anillos de Boole. Otros aspectos tienen que ver con la existencia de construcciones libres, tal como los "reticulados libres" basados en un conjunto de generadores. Además, los operadores de clausura son importantes en el estudio del álgebra universal.

En topología el orden desempeña un muy prominente papel. De hecho, el conjunto de los abiertos proporciona un clásico ejemplo de un reticulado completo, más exactamente un álgebra de Heyting completa (o "marco" o "locale"). Los filtros y las redes son nociones relacionadas con la teoría de orden y el operador clausura conjuntista puede ser utilizado para definir una topología. Más allá de esta relación, la topología se puede mirar únicamente en términos del reticulado de conjuntos abiertos, que conduce al estudio de la topología sin puntos. Además, un preorden natural de elementos del conjunto subyacente de una topología viene dada por el, así llamado, orden de especialización, que es realmente un orden parcial si la topología es T. 

Inversamente, en teoría de orden, uno a menudo hace uso de resultados topológicos. Hay varias maneras de definir subconjuntos de un orden que pueden ser considerados como conjunto abiertos de una topología. Especialmente, es interesante considerar topologías en un "poset" ("X", ≤) que reobtiene ≤ como su orden de especialización. La "más fina" de tales topologías es la topología de Alexandrov, dada al tomar todos los conjuntos superiores ("upper") como abiertos. Inversamente, la "más gruesa" topología que induce el orden de especialización es la topología superior, que tiene los 
complementos de los ideales principales (es decir conjuntos de la forma { "y" en "X"|"y" ≤ "x"} para cada "x") como una subbase. Adicionalmente, una topología con orden de especialización ≤ puede ser orden consistente, significando que sus conjuntos abiertos son "inaccesibles por supremos dirigidos" (con respecto ≤). La topología más fina de un orden consistente es la topología de Scott, que es más gruesa que la topología de Alexandrov. Una tercera topología importante en esta línea es la topología de Lawson. Hay cercanas conexiones entre estas topologías y los conceptos de la teoría de orden. Por ejemplo, una función preserva supremos dirigidos si y sólo si es continuo con respecto a la topología de Scott (por este razón esta propiedad orden teórica es también llamada continuidad de Scott).

La visualización de órdenes con diagramas de Hasse tiene una generalización directa: en vez exhibir elemento menores bajo los mayores, la dirección del orden se puede también representar dando la dirección de las aristas del grafo. De esta manera, cada orden se ve como equivalente a un grafo dirigido acíclico, donde los nodos son los elementos del "poset" y hay una trayectoria dirigida de "a" a "b" si y solamente si "a" ≤ "b". Eliminando el requisito acíclico, uno puede también obtener todos los preórdenes. 

Cuando es equipado con todas las aristas transitivas, estos grafos son solamente categorías especiales, donde los elementos son los objetos y cada conjunto de morfismos entre dos elementos es a lo sumo un singletón. Funciones entre órdenes se convierten en funtores entre categorías. Interesantemente, muchas ideas de la teoría de orden son simplemente pequeñas versiones de los conceptos de la teoría de las categorías. Por ejemplo, un ínfimo es precisamente un producto categórico. Más en general, uno puede subsumir supremos e ínfimos bajo la noción abstracta de un límite categórico (o "colímite", respectivamente). Otro lugar en donde las ideas categoriales surgen es el concepto de una conexión de Galois (monótona), que es precisamente igual a un par de funtores adjuntos. 

Pero la teoría de las categorías también tiene un impacto en la teoría de orden de mayor escala. Clases de "posets" con funciones apropiadas según lo discutido arriba forman interesantes categorías. A menudo uno puede también establecer construcción de órdenes, como el orden producto, en término de categoría. Otras intuiciones resultan cuando categorías de orden resultan equivalentes categóricas a otra categoría, por ejemplo de espacios topológicos. Este línea de investigación conduce a varios "teoremas de representación", a menudo recogidos bajo la etiqueta dualidad de Stone.




</doc>
<doc id="45324" url="https://es.wikipedia.org/wiki?curid=45324" title="Santiago (Nuevo León)">
Santiago (Nuevo León)

La Villa de Santiago es la cabecera del Municipio de Santiago, Nuevo León.

Santiago se encuentra localizado en la parte centro norte del estado de Nuevo León, en las coordenadas 100° 8' longitud oeste y 25° 26' latitud norte. Se encuentra asentado en la Sierra Madre Oriental, y en los cerros en el valle que se forma entre la Sierra Madre Oriental y la Sierra de la Silla y en la propia Sierra de la Silla, teniendo una altura variable que va de los 450 metros sobre el nivel del mar en la parte baja del valle, hasta los 2,300 metros sobre el nivel del mar en las partes altas de las montañas.

El municipio tiene una figura irregular, colindando con ocho municipios, limita al norte con Monterrey, al nororiente con Juárez, al oriente con Cadereyta, al sur con Allende, al sur poniente con Montemorelos, Rayones y Arteaga, al poniente también con Arteaga, y al norponiente con Santa Catarina.

En los tiempos de la fundación por Diego Rodríguez de Montemayor, (nieto de Alberto del Canto y bisnieto de Diego de Montemayor), los españoles ya lo nombraban como el Potrero Grande y Bocas de Santiago; mientras que para los nativos era el Valle de Cayucuapa, llamado así antes de la fundación oficial de la ciudad de Monterrey. Cuando el fundador se asentó, ya se le conocía también como el Guajuco. El nombre alude a uno de los dos hermanos huachichiles conocidos como Guajuco y Colmillo. Ellos fueron el azote de Monterrey y causaron muertes, incendios y robos en 1621. Otro nombre con el que se le conoce a la zona es el de Cuarisezapa, término autóctono que pudo ser el nombre de algún cacique huachichil de fines del siglo XVI. El historiador santiaguense Héctor Javier Barbosa, menciona que Cayucuapa era el padre de aquellos indios.

En la actualidad, el nombre oficial de la región es: Cañón del Huajuco. Sin embargo, el nombre del municipio Valle de Santiago del Huajuco, otorgado en 1712, pudo ser dado por decisión de Diego de Montemayor el Mozo, hijo de Diego de Montemayor.

En 1645, Diego Rodríguez de Montemayor, bisnieto de Diego de Montemayor, solicitó permiso para obtener tierras al gobernador Martín de Zavala. Su madre, Mónica Rodríguez, ya poseía propiedades hasta el río El Cerrito, región conocida como las Palmas, así que pidió que estas estuvieran enseguida a las de su madre. Zavala le concede de manera verbal el permiso para el primer asentamiento en donde hoy es el entronque de la calle Héroes del 47 con la Carretera Nacional.

El 20 de marzo de 1646, Martín de Zavala legalizó las tierras de Rodríguez de Montemayor con documentación oficial. El terreno se extendía desde el río del Cerrito y terminaba en el río San Juan, hoy conocido como Escamilla. En los escritos oficiales se le otorga ocho caballerías de tierra y dos sitios de ganado. Dos años después, Diego Rodríguez de Montemayor negoció a su tío Gregorio Fernández de Montemayor, la adquisición del territorio del arroyo Escamilla, extendiéndose hacia el río Ramos. En 1650, Diego Rodríguez de Montemayor adquiere nupcias con Inés de la Garza, con quien tiene 12 hijos, pero poco después deciden abandonar el lugar.

La belicosidad de los nativos del área y los constantes hostigamientos hacia los nuevos pobladores, propiciaron que la familia Rodríguez de Montemayor y sus trabajadores optaran por abandonar el asentamiento. No fue hasta que las transgresiones de los nativos, en protesta por las invasiones a sus tierras, y después de que su hija mayor llamada Margarita Rodríguez contrajera matrimonio con Lucas Caballero de los Olivos en 1670. Este regreso marcó el nuevo inicio de pobladores en el área. Lucas fallece en 1690, y deja a su viuda con sus pequeños hijos frente a la organización de la hacienda, y al poco tiempo contrae matrimonio por segunda vez con Francisco Álvarez Rendón, sin compartir descendencia. A partir de esto, el legado de los Rodríguez de Montemayor establecen haciendas que componen la región de Santiago.


Se establece el Primer Ayuntamiento hasta que en 1712, cuando se le establece al municipio la categoría a Valle, y don Gregorio de Treviño se convierte en el primer gobernante.

En 1825, tras concluir el movimiento de independencia, la región pierde el nombre de El Nuevo Reino de León, como resultado se constituye el estado de Nuevo León, una entidad Federal Libre y Soberana. Sin embargo, no fue hasta el 31 de marzo de 1831 cuando la cabecera municipal adquiere el título de Villa de Santiago, el cual es propio hasta la fecha.

En la Sierra de Santiago, Nuevo León existen 10 comunidades productoras de manzano. En ella se localizan 481 predios, de los cuales existen 250 productores. Las localidades productoras son Ciénega de González, La Jacinta, La Peñita, Laguna de Sánchez, Las Adjuntas, San Isidro, San José de las Boquillas, San Juan Bautista, San Sebastián, Cañón del Álamo.



Sus atractivos turísticos tienen reconocimiento nacional al contar con una amplia variedad de sus montañas, llanuras, lomerios, bosques, caídas de agua, ríos, cañones, huertas y verdes paisajes. Mientras que en la cabecera municipal de Villa de Santiago destaca su arquitectura virreinal de la colonia.



Su clima es templado/húmedo, teniendo una temperatura media anual de 21 °C en las partes bajas y de 14 °C en las partes altas de la sierra.

Su precipitación es moderada, siendo su promedio anual de 1300 mm en las partes bajas y solo de 600 mm en las partes altas de la sierra.

Sus vientos predominantes son los alisios, débiles y moderados del sureste, que traen la humedad del Golfo de México, y en el invierno dominan los vientos fríos del norte.

Los nombres técnicos de algunas de las especies más abundantes entre los pinos son: Pinus, Greggii, Pinus Pseudostrobus, Pinus Teocote y Pinus Arzónica. También existe Uña de gato, Huisache, Sicómoro, Capulín, Abedul, Palo blanco, Chaparro, Encinos, Chapotee, Barreta, Tejocote, Parras del Campo. Y árboles frutales tales como el Manzano, Ciruelo, Chabacano, Durazno, Peral, Nogal, Aguacate, Membrillo, Percimon e Higuera

Se reportan cincuenta y cinco especies de mamíferos pertenecientes a 8 órdenes y 19 familias para la región del Cafióndel Huajuco, Municipio de Santiago, Nuevo León, México.

Se compone principalmente de: Guacamaya enana, Correcaminos, Aguililla, Urraca, Pauraque, Tórtola, Golondrinas, Carpintero, Gorrión, Guajolote, Azulejo, Cenzontle, Jilguero, Oso gris, Venado, Tejón, Ardilla, Gato montés, Leoncillo, Comadreja, Zorrillo, Tlacuache, Armadillo, Conejo, Coyote, Jabalí, Zorro, Coralillo, Alicantre, Cascabel, Cuervo y Zopilote.





</doc>
<doc id="45325" url="https://es.wikipedia.org/wiki?curid=45325" title="Relación">
Relación

El concepto relación puede referirse a distintos ámbitos:



Con el significado de "conexión entre dos cosas", es muy habitual en todo tipo de ciencias:













</doc>
<doc id="45328" url="https://es.wikipedia.org/wiki?curid=45328" title="Kuna">
Kuna

Kuna puede 

</doc>
<doc id="45329" url="https://es.wikipedia.org/wiki?curid=45329" title="Kuna croata">
Kuna croata

La kuna es la moneda nacional de Croacia. Se subdivide en 100 "lipa". El código ISO 4217 para esta unidad monetaria es HRK. 

La palabra croata "kuna" hace referencia al animal conocido como marta. Aunque se piense que el nombre hace referencia a las monedas llamadas "corona", el nombre se escogió porque hace referencia al uso de las pieles de marta como unidades de cambio en la época medieval.

La kuna fue introducida en junio de 1994 después del periodo de transición posterior a la independencia croata, en el que el dinar yugoslavo fue sustituido por el dinar croata.

La elección del nombre "kuna" fue muy polémica, sobre todo entre los serbios de Croacia, ya que la única entidad que había usado antes aquel nombre de moneda fue el Estado Independiente de Croacia. El gobierno croata defendió la elección del nombre con el argumento del uso histórico de las pieles de marta, mientras que sus detractores lo veían más bien como una forma de continuidad del moderno estado croata con el régimen extremista anterior.

La kuna es emitida por el Banco Nacional Croata ("Hrvatska Narodna Banka").

Actualmente circulan monedas de los valores siguientes:

A continuación se describen los billetes de la última serie editada por el Banco Nacional de Croacia en 2001:



</doc>
<doc id="45330" url="https://es.wikipedia.org/wiki?curid=45330" title="Arad (Rumania)">
Arad (Rumania)

Arad () es una de Rumania. Es la capital del distrito de Arad, ubicado en la parte más occidental del país, en la región de Transilvania.

Arad había formado parte del Reino de Hungría desde sus inicios en el año 1000, hasta el final de la Primera Guerra Mundial en 1919, cuando la región había sido unida a Rumanía junto con toda Transilvania, prosiguiendo el fin del dominio austríaco después de la caída del Imperio Austro-húngaro. Arad se encuentra a unos 563 [km]] por ferrocarril de la capital nacional, Bucarest; 265 km de la capital húngara, Budapest; y 506 km de la capital austriaca, Viena.

Situada en la orilla derecha del río Mureş, la ciudad consiste en un centro urbano interior y cinco suburbios. Con su aire moderno, la ciudad cuenta con numerosas edificaciones privadas y públicas de notable belleza arquitectural, incluyendo una catedral. Es la sede de un obispado ortodoxo, y posee un seminario teológico ortodoxo, así como dos escuelas preparatorias para profesores —una rumana, la otra húngara— y un conservatorio de música.

La municipalidad de Arad actualmente cuenta con una población de 172,827 habitantes, que se dividen étnicamente de la siguiente manera: 


Arad aparece mencionada por primera vez en documentos históricos del siglo XI. Posteriormente Arad resultaría un sitio recurrente en episodios históricos austro-húngaros medievales. En 1131 el rey Béla II "el Ciego" de Hungría había convocado a los nobles austro-húngaros a la ciudad de Arad luego de su coronación. Ahí, su esposa Helena de Raška exigió la revelación de aquellos que habían aconsejado al fallecido rey Colomán de Hungría que cegase a Béla II y a su padre. Inocentemente a los 5 años de edad, Béla había sido privado de la vista debido a que su padre hubiese conspirado constantemente contra Colomán. Así, la pareja real hizo "justicia" en Arad, y todos los nobles culpables fueron ejecutados durante lo que se llamaría "el día sangriento de Arad".

Como resultado de la invasión mongol a mediados del siglo XIII, todo el Reino de Hungría fue destruido y saqueado por los tártaros. Después de que se retirasen en 1242, el rey Béla IV de Hungría comenzó con la construcción de una línea de defensa basada en castillos por todo el reino de Hungría. En Arad se construyeron las fortalezas de Soimos, Siria y Dezna para defenderla de posibles ataques posteriores. 

En 1526, el Reino de Hungría perdió a su último monarca, Luis II de Hungría, quien cayó en la Batalla de Mohács librada contra los turcos otomanos. Paulatinamente se siguieron produciendo incursiones turcas en territorio húngaro, hasta que en 1541 lograron tomar la sede real, Buda. El Reino de Hungría estuvo dividido entonces en tres partes: una bajo control del Sacro Imperio Romano Germánico al oeste, otra bajo dominio turco en el centro, y Transilvania, una entidad semiindependiente como vasallo turco. Sin embargo, en 1551 la región de Arad fue conquistada por el Imperio otomano, que mantuvo su dominio sobre la misma hasta la firma de la Paz de Karlowitz con los austriacos en 1699.

Hungría fue reunificada y estuvo bajo control germánico. Pronto se ordenó el levantamiento de nuevas defensas contra posibles agresiones turcas, y Arad no fue la excepción. La nueva fortaleza, construida entre 1763 y 1783, aunque pequeña, resultó formidable y desempeñó un papel fundamental durante la lucha por la independencia húngara en 1849. Tras ser capturada por los rebeldes húngaros, se convirtió en cuartel general de los insurrectos. Fue aquí donde Lajos Kossuth lanzó su famosa proclamación del 11 de agosto de 1849, y donde este último le traspasó el mando supremo a Artúr Görgey. Tras la rendición de Görgey ante las tropas rusas, aliadas de los austriacos, en Világos (Şiria), la fortaleza pasó nuevamente a manos de los últimos que, por órdenes del general austríaco Haynau, el 6 de octubre de 1849 ejecutaron en su interior a trece generales rebeldes. A estos hombres se les conoce hoy como los "13 Mártires de Arad", y en una de las principales plazas públicas de la ciudad se levanta hoy un monumento en su memoria, que consiste en una representación colosal de la figura de Hungría, con cuatro grupos alegóricos y los medallones de los generales ejecutados.

En 1834, el emperador austriaco Francisco I le reconoció a la ciudad el título de "ciudad real libre". Arad disfrutaba por entonces de un gran desarrollo económico.

La ciudad de "Aradu Nou" ("Nueva Arad"), situada en la orilla opuesta del río Mureş, constituye en la práctica un suburbio de Arad, con la que está unida por un puente. Aradu Nou fue fundada por los turcos durante las guerras del siglo XVII. Las edificaciones levantadas por los turcos en su preparación para la toma de la fortaleza de Arad formaron el núcleo de la nueva ciudad.

En noviembre de 1919, se celebró en la ciudad la reunión entre los representantes del nuevo gobierno democrático austro-húngaro y los nacionalistas rumanos transilvanos que selló políticamente la separación de Transilvania de Austro-hungría y su anexión a Rumanía.

Arad tiene un clima continental con inviernos fríos y húmedos, mientras que los veranos son suaves, con algunos días de calor. En los meses de verano de junio, julio y agosto hay 60 días por encima de los 32° C. La clasificación climática de Köppen categoriza este subtipo de clima como "Cfb" (clima de la costa oeste marítimo/clima oceánico).

Entre los lugares de interés de la ciudad destacan:


Arad está hermanada con:



</doc>
<doc id="45332" url="https://es.wikipedia.org/wiki?curid=45332" title="Buenos Aires (desambiguación)">
Buenos Aires (desambiguación)

Buenos Aires puede referirse a:























</doc>
<doc id="45333" url="https://es.wikipedia.org/wiki?curid=45333" title="Bandera de Croacia">
Bandera de Croacia

La bandera de Croacia consiste en tres bandas horizontales de igual tamaño de color rojo, blanco y azul. En el medio se encuentra el escudo de armas de Croacia. 

La bandera está en vigencia desde el 21 de diciembre de 1990, diez meses antes de su independencia. Mientras Croacia era parte de la República Federal Socialista de Yugoslavia, la bandera era similar, pero tenía una estrella roja de cinco puntas con borde amarillo en lugar del escudo de armas.


</doc>
<doc id="45335" url="https://es.wikipedia.org/wiki?curid=45335" title="Ivo Sanader">
Ivo Sanader

Ivo Sanader (anteriormente Ivica Sanader) (* Split, 8 de junio de 1953 - ) es un político croata. Fue Primer Ministro de Croacia. Asumió este cargo oficialmente el 23 de diciembre de 2003, designado por el Presidente de la República luego de obtener el consentimiento del Parlamento croata mediante 88 votos a favor sobre un total de 152. Representa al partido político Cristiano-Demócrata HDZ. Su predecesor como Primer Ministro fue Ivica Račan. Sanader dimitió en forma abrupta el 1 de julio de 2009.

Nacido el 8 de junio de 1953 en Split. Sanader estudió en Roma e Innsbruck y obtuvo un doctorado en lenguas romances y Literatura comparada por la Universidad de Innsbruck, Austria. En 1991-1992 fue director del teatro de Split. Habla con fluidez cuatro idiomas extranjeros: inglés, francés, alemán e italiano. Está casado y tiene dos hijas. 

En 1992 se convirtió en miembro del Parlamento de Croacia ("Sabor"). Entre 1991 y 1993 fue Ministro de Ciencia y Tecnología. De 1993 a enero de 2002 fue (con una breve interrupción) Viceministro de Asuntos Exteriores de Croacia.

Alegando razones personales, dimitió el 1 de julio de 2009, aunque se cita en la prensa su frustración personal por no haber conseguido levantar el veto de Eslovenia para la integración de Croacia en la Unión Europea.

Dados los graves problemas en la actual Croacia como la corrupción galopante a todo nivel, el nepotismo político desmedido y la falta de oportunidades para los jóvenes y personas de alta calificación, que no pueden desarrollarse profesionalmente por el ya mencionado nepotismo. Aparte, las cuestiones de la costa istriana y dálmata, que solo resisten los embates económicos a base de los servicios turísticos masivos, sin impulsar el desarrollo industrial de la región, éste decide dar un paso al lado y tratar desde otros frentes el apuntar su lucha con fines aún desconocidos. Muchos croatas en el exterior le acusan de ser un político de "mano débil", razón por la cual decide dejar su cargo como Primer Ministro de gobierno, y deja el paso a otros políticos supuestamente más capaces ante problemas que aún siguen sin resolverse.



</doc>
<doc id="45336" url="https://es.wikipedia.org/wiki?curid=45336" title="Distrito de Alba">
Distrito de Alba

Alba (en húngaro: "Fehér") es un distrito ("judeţ") situado en la zona centro-occidental de Rumania, en la región de Transilvania. Tiene una superficie de 6.242 km² y una población de 382.747 habitantes (2002), con una densidad de 64 habitantes/km². 

La capital es la ciudad de Alba Iulia (72.405 habitantes). Otras ciudades importantes son Sebeş (29.475), Aiud (28.934), Blaj (20.758), Cugir (25.950) y Ocna Mureş (15.526).

Alba se encuentra rodeado por los distritos de Sibiu y Mureş (por el este), Cluj (por el norte), Bihor y Arad (oeste), y Hunedoara (sur).

Se trata de un distrito muy accidentado, ya que el 59 % de su superficie está ocupada por montañas. En la zona noroeste se alzan los Montes Apuseni, mientras que en el sur se encuentra una parte de los montes Parâng, Şureanu y Cândrel. Los ríos principales son el Mureş y sus afluentes el Târnava, el Sebeş y el Arieş.

Más del 90% de la población son de etnia rumana, y un 6 % húngaros. Hay pequeñas minorías de gitanos (romí) y alemanes.

La zona de los montes Apuseni (al NO) se denomina Ţara Moţilor, y es una región con fuertes tradiciones rumanas.

Las principales atracciones turísticas del distrito de Alba son:



</doc>
<doc id="45339" url="https://es.wikipedia.org/wiki?curid=45339" title="Isla Zavodovski">
Isla Zavodovski

La isla Zavodovski es una isla volcánica del archipiélago de las islas Sandwich del Sur, que mide unos 5 km de diámetro. Se encuentra en el grupo denominado islas Traverse y es la ubicada más al norte del archipiélago. Se localiza a 350 kilómetros al sureste de las islas Georgias del Sur.

La isla Zavodovski fue descubierta y nombrada por el explorador ruso Fabian Gottlieb von Bellingshausen el 4 de enero de 1820, momento en que el volcán se encontraba en erupción. El nombre fue puesto en homenaje al teniente Ivan Zavodovski, capitán al mando del barco "Vostok", y quien lideró el equipo que desembarcó en la isla el 5 de enero de 1820. El 12 de diciembre de 1830 el estadounidense James Brown en el barco "Pacific" redescubrió la isla (desconociendo la exploración de Bellingshausen), desembarcó en ella y la llamó "Prince's Island", nombre que no perduró.

La tiene forma redondeada de entre 5 y 5,5 kilómetros de diámetro con aspecto de cono. La isla aloja al monte Curry (o monte Asphyxia) que es un estratovolcán basáltico que domina el lado occidental de la isla, y cuya cumbre se encuentra a una altura de 551 msnm siendo la mayor elevación en la isla. Se cree que el monte Curry es un volcán activo, con reportes de emanación de lava fresca en 1819, 1823, 1830, 1908 y numerosas indicaciones de actividad posterior. Sus emanaciones se perciben desde unos 2 km. El cráter, en constante actividad, emite humo cálido e hidrógeno sulfurado que ocultan su cima. Su nombre homenajea a un marino argentino fallecido en un combate naval en 1826. Una erupción volcánica fue identificada en la isla el 2 de mayo de 2012, aunque se conocen pocos detalles.

Aproximadamente la mitad de la isla está compuesta de tefra. La mitad oriental de la isla es una llanura de baja altitud formada por lava. La ladera oeste de la isla termina en acantilados y, debido a la acción volcánica, no tiene nieve y es de color rojizo con manchas de azufre. En la costa sur, la ladera es suave, desciende hacia una meseta baja y descubierta, y posee emanaciones sulfurosas tóxicas que causan grandes grietas. También hay playas de arena y lava donde se puede desembarcar. En la costa este hay un fondeadero precario contorneado por el oleaje que lo va modificando por acción del viento. La isla también se caracteriza por estar mayormente libre de nieve.

La punta Hedor es el punto extremo norte de la isla y de todo el archipiélago de las Sandwich del Sur. Otros accidentes geográficos notables son: punta Pacífica, punta Acre, acantilado Oeste, morro Nocivo, punta Fumarola y punta Activa. A 50 kilómetros al noroeste de la isla se encuentra el banco Protector, un volcán submarino. Los topógrafos que cartografiaron la isla, dieron los nombres por las características volcánicas del área.

En 1908, el capitán noruego Carl Anton Larsen, luego de establecer la Compañía Argentina de Pesca en Grytviken, islas Georgias del Sur, recorrió las Islas Sandwich del Sur para buscar la expansión de la actividad ballenera en algún fondeadero del archipiélago. Descendió en la isla Zavodovski, pero se intoxicó con las emanaciones sulfurosas y debió marcharse rápidamente. También estuvo en otras seis islas y regresó a la isla San Pedro en malas condiciones de salud.

Desde el mar fue investigada por Frank Wild en el barco "Quest" en 1912 y cartografiada en 1930 por personal del RRS "Discovery II". Entre 1957 y 1958 personal del ballenero soviético "Slava-15" y del rompehielos argentino ARA "General San Martín" desembarcó en la isla. En 1958 la Argentina instaló la baliza Guardiamarina Lamas en el extremo sudeste de la isla.

En febrero de 1952, la fragata argentina recorrió sus costas como parte de la denominada "Operación Foca" dentro de la campaña antártica argentina de 1951-1952.

Nuevos desembarcos se produjeron por personal de los barcos británicos RSS "Shackleton" en 1961 y RSS "Protector" en 1962.

El "South African Weather Bureau" (Oficina Meteorológica Sudafricana) mantuvo una estación meteorológica automática en la isla Zavodovski entre enero de 1990 y 2000, colocada por el SA "Agulhas", que realizó diversas visitas posteriormente. Su código en el sistema Argos con el que estaba conectada era 88981. La estación dejó de realizar observaciones.

En 1997 el rompehielos británico HMS "Endurance" realizó una investigación geológica y biológica en el archipiélago.

La isla nunca fue habitada ni ocupada, y como el resto de las Sandwich del Sur es reclamada por el Reino Unido que la hace parte del territorio británico de ultramar de las Islas Georgias del Sur y Sandwich del Sur, y por la República Argentina, que la hace parte del departamento Islas del Atlántico Sur dentro de la provincia de Tierra del Fuego, Antártida e Islas del Atlántico Sur.

En la parte norte de la isla hay parches de algas, de aspecto similar al césped y que constituyen la mayor extensión vegetal de todas las Sandwich del Sur. Se tratan de manchones aislados de pasto ("Deschampsia antarctica"), de musgos, y unas 42 especies de líquenes, denominados «misérrimos» por los argentinos.

La isla es el hogar de alrededor de más de un millón de parejas de pingüinos barbijo en época de crianza, ocupando todo el espacio y disponible y siendo una de las más grandes colonias de esta especie. También habitan en la isla cerca de 2 millones de pájaros.




</doc>
<doc id="45352" url="https://es.wikipedia.org/wiki?curid=45352" title="Anticadena">
Anticadena

En matemáticas, una anticadena en un conjunto parcialmente ordenado "A" es un subconjunto "S" de "A" tal que cada par de miembros de "S" es incomparable, es decir, para cualquier "x", "y" en "S", ni "x" ≤ "y" ni "y" ≤ "x". 

El número de anticadenas no vacías definidas sobre un conjunto "A" dado se conoce como número de Dedekind.

El teorema de Dilworth establece que la no existencia de una anticadena de tamaño "n+1" en "S" es una condición necesaria y suficiente para que "S" sea la unión de "n" órdenes totales o cadenas. Esto motiva preguntas sobre el tamaño de la anticadena máxima. 

Por ejemplo, en el conjunto de partes de un conjunto finito "X", ordenado por la inclusión, una anticadena máxima es descrita por el lema de Sperner, como los subconjuntos de tamaño 'mediano',|"X"|/2 en caso de que |"X"| sea par, y, o bien de (|"X"|+1)/2 o bien (|"X"|-1)/2 cuando |"X"| sea impar; la cardinalidad es el relevante coeficiente binomial.
En la figura dado el conjunto A formado por los elementos:

en el que se ha definido una relación binaria formula_2, siendo formula_3 un conjunto parcialmente ordenado.

dado el subconjunto G de A:

Se puede ver que G es una anticadena dado que sus elemento son no comparables.


</doc>
<doc id="45354" url="https://es.wikipedia.org/wiki?curid=45354" title="Hifa">
Hifa

Las hifas (del griego ὑφή, "huphḗ", red) son una red de filamentos cilíndricos que conforman la estructura del cuerpo de los hongos pluricelulares. Están constituidos por una fila de células alargadas y tubulares, envueltas por una pared celular compuesta de quitina. El conjunto de estas hifas se denomina micelio.

Vale decir que una hifa es un filamento fúngico y el conjunto de hifas conforman el micelio. Un micelio puede originarse de una espora. 

Las hifas pueden presentar un tipo de segmentación que divide al filamento por medio de tabiques denominados septos, lo cual permite la separación citoplasmática. Por otro lado, hay hongos que no presentan este tipo de morfología y se denominan cenocíticos.

Los núcleos de las hifas tabicadas pueden ser uninucleares o multinucleares. Estos pueden migrar a través de los septos por unas estructuras denominada poros, con el fin de reproducirse y realizar su respectivo intercambio genético. Por otro lado las hifas cenocíticas pueden contener cientos a miles de núcleos a lo largo de todo el filamento citoplasmático.

Muchas especies de hongos tienen los llamados haustorios hifas especializadas que penetran los organismos vivos para su digestión y absorción. Otros pueden adherirse a distintos sustratos como rocas, cortezas, etc. Las raíces de los árboles sirven como un sustrato muy particular, las cuales establecen una relación simbiótica con las hifas denominados micorrizas.



</doc>
<doc id="45355" url="https://es.wikipedia.org/wiki?curid=45355" title="Jansenismo">
Jansenismo

El jansenismo fue un movimiento religioso iniciado por el teólogo y obispo Cornelio Jansenio (1585-1638), que gozó de cierta popularidad en Europa durante los siglos XVII y posteriores, y que fue condenado como herético por la Iglesia católica debido a sus tesis sobre la salvación, que en último término negaban el concurso de la libertad humana.

El jansenismo, como movimiento puritano, enfatiza el pecado original, la depravación humana, la necesidad de la gracia divina que salvará solo a aquellos a quienes les fue concedida desde su nacimiento y la creencia en la predestinación, sin libre albedrío. Generalmente, el jansenismo es considerado como sinónimo de intransigencia.

La obra fundamental del jansenismo es el "Augustinus", escrito por Jansenio, mas publicado de forma póstuma (Lovaina, 1640) debido a la controversia teológica que hubiera podido generar. Basado en este libro surge un movimiento que se desarrolla en tres ramas: jansenismo teológico, jansenismo moral-espiritual (influyente en el rigorismo moral en los siglos XVIII y XIX) y jansenismo político-antijesuítico-galicanista (considerado como el movimiento mayoritario dentro del jansenismo).

Las discusiones del Concilio de Trento sobre el papel de la libertad y su relación con la gracia divina no habían terminado con la controversia "De Auxiliis". Jansenio pensó encontrar en los escritos de Agustín de Hipona una respuesta más satisfactoria. Por eso, elaboró su obra "Augustinus" donde trata tres puntos principalmente:

En este escrito define su postura como agustiniana, pero anunciando que se sometía a lo que el Papa sentenciara en relación con su libro (lo mismo afirma en su testamento).

Jean Duvergier de Hauranne, abad de Saint Cyran, era director espiritual en el monasterio de Port Royal des Champs donde había nacido un movimiento rigorista relacionado con la familia Arnauld: Antoine Arnauld (1612-1694), teólogo de la Sorbona y la abadesa Angélica Arnauld (1591-1666). El "gran Arnauld" es un personaje controvertido que ha merecido fuertes críticas de historiadores como Bremond y por otros es considerado el mejor director espiritual. Era contrario a la Compañía de Jesús y con el seudónimo de Petrus Aurelius había publicado una serie de escritos contra ellos y su supuesta independencia de los obispos.

A Duvergier debe el jansenismo una creciente fama y la publicación y extensión del escrito de Jansenio. Esto le valió la enemistad del cardenal Richelieu, que buscaba apagar toda fuente de discordias en la iglesia francesa. El Papa Urbano VIII prohibió la reimpresión del Augustinus pero el libro se siguió imprimiendo ya que había sido dedicado al cardenal Fernando, infante de España, quien permitió y popularizó la publicación. Incluso en Roma se hizo una edición en 1643. Pero ya varios documentos pontificios y el Santo Oficio habían prohibido el libro. El primero fue la bula "In eminenti" de Urbano VIII (1642). Luego vino la constitución "Cum occasione" de Inocencio X (1653) y otra constitución publicada por el Papa Alejandro VII, "Ad sacram beati Petri sedem".

En Francia el movimiento tenía sus principales contradictores, uno de ellos el santo francés más popular de las tierras gálicas, San Vicente de Paúl. San Vicente alertaba a su congregación de caer en lo que el denominaba el peor mal para la Iglesia de la época, y se alejó totalmente del abad de Saint Cyran.

Los hermanos Arnauld fueron directos continuadores de la obra de Duvergier, abate de Saint-Cyran. 

El doctor en Teología Antonio Arnauld, enemistado con los jesuitas, y por eso en su momento expulsado de la Sorbone, se dedicó a propagar las ideas de Jansenio, intentando presentarlas como puro y consecuente agustinismo. Criticó ásperamente la costumbre de la comunión frecuente, añadiendo este aspecto a la devoción de sus seguidores. También institucionalizó el jansenismo ofreciéndole una ascética propia, una modificación propia de los dogmas y los cambios necesarios en la liturgia y en los sacramentos. A Antoine se le unió bien pronto Pierre Nicole que criticó especialmente la formulación de la infalibilidad pontificia y propuso la propia de los jansenistas, que es de corte conciliarista.

Angélica Arnauld, su hermana, era religiosa en el monasterio de Port Royal des Champs y luego abadesa. Impuso una férrea vivencia de la regla cisterciense, y tras la muerte de Francisco de Sales, asumió a Duvergier como director espiritual, quien le aconsejó que siguiera el camino de exigencia rígida de la fidelidad a la regla religiosa. Así, el monasterio de Port Royal llegó a ser el centro del jansenismo, donde cada vez se practicaba menos la comunión eucarística.

Desde este monasterio, la doctrina y praxis jansenista se mantenían y se extendían por Francia. Tras años de diversas condenas por parte del Papa, el monasterio fue destruido en 1710 y las monjas que lo habitaban se dispersaron.

Posteriormente el teólogo Pasquier Quesnel (1634-1719) dio un renacimiento a las doctrinas jansenistas al tomar sus tesis principales, junto a las ideas conciliaristas y las tendencias galicanistas. Con la publicación de sus "Réflexions morales" logró ganarse las simpatías y apoyos del alto clero. Las disputas teológicas se multiplicaron y el ambiente se caldeó hasta el punto de que los obispos franceses pidieron una nueva intervención pontificia.

En esta ocasión, el Papa Clemente XI con la Constitución "Unigenitus Dei Filius" (1713) dio una condena formal a 101 proposiciones contenidas en los escritos de Quesnel. Entonces, el movimiento jansenista (ya sin posibilidad de evadir la condena como habían hecho sus seguidores anteriormente por medio de múltiples interpretaciones de los textos pontificios) apeló a un concilio y, por esto, sus partidarios fueron llamados "apelantes". Clemente XI los excomulgó a través de la bula "Pastoralis officii" (1718).

Después de estas condenas, el movimiento se fue extinguiendo poco a poco, sea por la separación de sus miembros (que crearon nuevas sectas como los convulsionarios o los figuristas), sea por la influencia de la Ilustración.

La teología propuesta por Jansenio está basada en una interpretación literal de los textos de Agustín de Hipona. Sin embargo, se vio influida por el desarrollo histórico y las peripecias de sus defensores. Así, en Jansenio encontramos la teología de la gracia; en Arnauld, la teología sacramental; en Saint Cyran, la disciplina y en Quesnel, su unificación con el galicanismo.

En cuanto al tema de la gracia, Jansenio afirma que el estado original es el estado natural del hombre. Un estado de gracia y amistad con Dios, inmortalidad e integridad (verdadera libertad). Adán, en ese estado, era verdaderamente libre y poseía la gracia (el auxilio de Dios) suficiente para evitar el pecado. Sin embargo, la gracia eficaz no solo es el auxilio para evitar el pecado, sino el auxilio de Dios para hacer el bien. Adán en el Paraíso tenía la gracia suficiente, pero no tenía la gracia eficaz, porque para Jansenio la gracia eficaz es siempre vencedora. El que posee la gracia eficaz no puede pecar. Después del pecado el hombre ha perdido la libertad. En el hombre hay una "delectatio terrestris" (gusto por las cosas de la tierra) invencible. Jansenio afirma además que para salir de esa situación después del pecado no basta la gracia suficiente sino que es necesaria la gracia eficaz, es decir, el auxilio sin el cual el hombre no puede evitar pecar: con la gracia eficaz el hombre se dirige invenciblemente hacia el bien. No basta un auxilio que le dé la posibilidad de no pecar, sino que necesita un auxilio eficaz para no hacerlo. La fe eficaz es absoluta: cambia la "delectatio terrestris" por una "delectatio coelestis": se goza en el bien. La gracia provoca un gusto tan grande por las cosas de Dios que el hombre invenciblemente las hace. Ahora bien, la libertad se mantiene porque la gracia despierta en el hombre la voluntad de hacer el bien. Quien no actúa movido por la gracia eficaz peca infaliblemente.

Así pues, la predestinación es la razón por la que algunos hombres poseen la gracia eficaz y otros no. Dios ha predestinado a unos a la salvación y a otros a la condenación. Según esta doctrina, las obras son buenas o malas. No puede existir la moral probabilista, porque lleva al laxismo.

En relación con los sacramentos es la ascética propia del movimiento la que los aleja progresivamente de su práctica, en especial de la Eucaristía. Esto se fijó con el escrito "De la fréquente communion" de Arnauld, que, argumentando desde la praxis penitencial de la Iglesia Antigua, invocaba esa práctica para usarla en una serie de condiciones que era necesario cumplir para poder recibir la Reconciliación o la comunión. De ahí también que su rigorismo en materia moral fuera cada vez más extremo.

Las sucesivas condenas por parte de la Sede romana les llevó a sostener posiciones conciliaristas que les llevaron al galicanismo. El movimiento, desde el inicio se mostró enemigo jurado de los jesuitas y, por eso, derivó en postura política gracias al apoyo de Blaise Pascal.
La película: 'La vía láctea' de Luis Buñuel incluye una escena con un duelo a espada entre un jesuita y un jansenista, mientras discuten de teología, que no deja de recordar alguna escena de: 'Women in love', película de Ken Russell.



</doc>
<doc id="45356" url="https://es.wikipedia.org/wiki?curid=45356" title="Holoenzima">
Holoenzima

Una holoenzima es una enzima que está formada por una apoenzima y un cofactor, que puede ser un ion o una molécula orgánica compleja unida (grupo prostético) o no (una coenzima). En resumidas cuentas, es una enzima completa y activada catalíticamente.

Las apoenzimas son enzimas que carecen de los componentes químicos apropiados para realizar la actividad catalítica, por ello, se ayudan de otras sustancias no proteicas, denominadas cofactores que, fijadas en su superficie mediante enlaces covalentes o débiles, le aportan a la enzima los grupos y funciones químicas que necesita. En estos casos, la parte proteica de la enzima se denomina apoenzima y la fracción no proteica es el cofactor.

El buen funcionamiento del organismo humano, se debe a la posibilidad de separación de apoenzimas y coenzimas, para sus fines específicos.




</doc>
<doc id="45357" url="https://es.wikipedia.org/wiki?curid=45357" title="Analgésico">
Analgésico

Un analgésico es un medicamento para calmar o eliminar el dolor, ya sea de cabeza, muscular, de artritis, etc. Existen diferentes tipos de analgésicos y cada uno tiene sus ventajas y riesgos. Etimológicamente procede del prefijo griego "an-" (‘carencia, negación’) y "άλγος" (/álgos/, ‘dolor’).

Aunque se puede usar el término para cualquier sustancia, es decir, cualquier medio que reduzca el dolor, generalmente se refiere a un conjunto de fármacos, de familias químicas diferentes que calman o eliminan el dolor por diferentes mecanismos.

Los antiinflamatorios no esteroideos (AINE) son un grupo de fármacos heterogéneo, cuyo representante más conocido es la aspirina. Actúan sobre todo inhibiendo a unas enzimas llamadas ciclooxigenasas, cruciales en la producción de prostaglandinas, sustancias mediadoras del dolor. Corresponden al primer escalón analgésico de la OMS, junto con el paracetamol (AINE carente de efectos antiinflamatorios). Además de propiedades analgésicas, los AINE son antipiréticos, antiinflamatorios y algunos antiagregantes plaquetarios. Tienen el inconveniente de que no se puede superar una dosis de tolerancia o techo terapéutico debido a los graves efectos adversos como es la hemorragia.

Son un grupo de sustancias, la mayoría sintéticas como el tramadol que imitan, con menor poder analgésico, la acción de los opioides. Corresponden al segundo escalón analgésico de la OMS.

Son un grupo de fármacos, unos naturales (opiáceo) como la morfina y otros artificiales (opioide) como el fentanilo, que actúan sobre los receptores opioides de las neuronas del sistema nervioso, imitando el poder analgésico de los opiáceos endógenos.

Son los fármacos analgésicos más potentes conocidos y corresponden al tercer escalón analgésico de la OMS. Se pueden asociar y potencian su acción con los AINE, pero no es biológicamente correcto asociarlos a opiáceos menores.

Los opiáceos mayores no presentan techo terapéutico, por lo que se puede aumentar la dosis según la presencia de dolor y tolerancia del paciente. Presenta el inconveniente de que son sustancias estupefacientes y deprimen el sistema nervioso central en las primeras dosis.

Ziconotide es un fármaco que no es opioide, ni un AINE, y tampoco un anestésico local. Usado en el tratamiento del dolor crónico.

Aunque no son analgésicos cuando se administran aisladamente, potencian la acción de cualquier analgésico en asociación. Entre los fármacos adyuvantes analgésicos se encuentran:

Aunque no se pueden incluir dentro del grupo de los analgésicos, el placebo, es decir, el efecto placebo 
r, visible en resonancia magnética funcional, por lo que está demostrado que la confianza que deposita el paciente en un tratamiento, mejora los resultados del mismo. A pesar de todo, ninguna fase del tratamiento del dolor pasa por la utilización de placebo, porque no es ético.




</doc>
<doc id="45358" url="https://es.wikipedia.org/wiki?curid=45358" title="Abierto">
Abierto

Abierto puede referirse a:



</doc>
<doc id="45359" url="https://es.wikipedia.org/wiki?curid=45359" title="Broadway">
Broadway

Broadway () es una calle situada en el estado de Nueva York (Estados Unidos). Broadway empieza junto a State Street en Bowling Green (Nueva York), recorre a través del "borough" de Manhattan y a través de El Bronx, sale de la ciudad por el norte, recorre otros por los municipios de Yonkers, Hastings-On-Hudson, Dobbs Ferry, Irvington y Tarrytown, y termina al norte de Sleepy Hollow, en el condado de Westchester.

Es la avenida norte-sur más antigua de Nueva York. Buena parte de la calle actual empezó siendo el sendero Wickquasgeck antes de la llegada de los europeos. Este sendero sería la base de una de las avenidas principales de la colonia holandesa de Nueva Ámsterdam, y continuó siéndolo bajo el dominio británico, aunque la mayor parte de ella no llevó su nombre actual hasta finales del siglo . Broadway en Manhattan es conocida por ser el corazón de la industria del teatro americana, y es usado frecuentemente como metónimo para referirse a ella, así como en los nombres de circuitos alternativos de teatro como Off-Broadway y Off-Off-Broadway.

Broadway era originalmente el sendero Wickquasgeck, trazado en Manhattan por sus habitantes nativos, que serpenteaba a través de pantanos y rocas a lo largo de toda la longitud de la isla de Manhattan.

Tras la llegada de los holandeses, el sendero fue ensanchado y pronto se convirtió en el camino principal que atravesaba la isla de Manhattan desde la colonia de Nueva Ámsterdam, situada en su extremo sur. El explorador y emprendedor holandés David Pietersz. de Vries lo menciona por primera vez en su diario del año 1642 («el camino de los Wickquasgeck por el que los indios pasaban diariamente»). Los holandeses la llamaron "Heeren Wegh" or "Heeren Straat", que significa «camino de los caballeros» o «calle de los caballeros» —reproduciendo el nombre de una calle similar de Ámsterdam—; fue renombrada "Broadway" (literalmente, «camino ancho») después de que los británicos se apoderaran de la ciudad, debido a su inusual anchura.

Aunque actualmente el nombre de la calle es simplemente Broadway, en un mapa de 1776 de Nueva York aparece como Broadway Street (literalmente, «calle Broadway»). A mediados del siglo , parte de Broadway en lo que es actualmente Lower Manhattan era conocida como Great George Street.

En el siglo , Broadway terminaba al norte de Wall Street, donde el tráfico continuaba hacia el norte por el East Side a través de Eastern Post Road y por el West Side a través de Bloomingdale Road. Esta última calle, que fue inaugurada en 1703, continuaba hasta la calle 117 y contribuyó al desarrollo del moderno Upper West Side como una zona residencial exclusiva. En 1868, el tramo de Bloomingdale Road entre las calles 59 (en el Grand Circle, actual Columbus Circle) y 155 fue pavimentado y ensanchado, convirtiéndose en una avenida con medianas ajardinadas, y fue llamado Western Boulevard o The Boulevard. Un mapa oficial de la ciudad de 1897 muestra un segmento de la actual Broadway en los alrededores de Washington Heights con el nombre de Kingsbridge Road. El 14 de febrero de 1899, el nombre Broadway fue extendido a todo el eje Broadway/Bloomingdale/Boulevard/Kingsbridge.

Antiguamente Broadway era una calle de doble sentido durante todo su recorrido. Su transformación a su configuración actual —según la cual discurre con sentido único hacia el sur al sur de Columbus Circle (calle 59)—, se produjo en varias fases. El 6 de junio de 1954, la Séptima Avenida se convirtió en una calle de sentido único hacia el sur y la Octava Avenida en una calle de sentido único hacia el norte al sur de Broadway. En ese momento ninguna parte de Broadway se transformó a sentido único, pero el aumento del tráfico hacia el sur entre Columbus Circle (Octava Avenida) y Times Square (Séptima Avenida) hizo que la ciudad remodelara esa sección de Broadway con cuatro carriles hacia el sur y dos carriles hacia el norte. Broadway se convirtió a sentido único desde Columbus Circle hasta Herald Square (calle 34) el 10 de marzo de 1957, al mismo tiempo que la Sexta Avenida se convirtió a sentido único hacia el norte desde Herald Square hasta la calle 59 y la Séptima Avenida se convirtió a sentido único hacia el sur desde la calle 59 hasta Times Square, donde se cruza con Broadway. El 3 de junio de 1962, Broadway se convirtió a sentido único al sur de Canal Street, mientras que Trinity Place y Church Street llevarían el tráfico hacia el norte.
El 10 de noviembre de 1963 se hizo otro cambio: Broadway se convirtió a sentido único hacia el sur desde Herald Square hasta Madison Square (calle 23) y desde Union Square (calle 14) hasta Canal Street, al mismo tiempo que otras dos calles —la Sexta Avenida al sur de Herald Square y Centre Street, Lafayette Street y la Cuarta Avenida al sur de Union Square— se convirtieron a sentido único hacia el norte. Por último, al mismo tiempo que Madison Avenue se convirtió a sentido único hacia el norte y la Quinta Avenida se convirtió a sentido único hacia el sur, Broadway se transformó a sentido único hacia el sur entre Madison Square (donde se cruza con la Quinta Avenida) y Union Square el 14 de enero de 1966, completando así su transformación al sur de Columbus Circle.

En 2001, se remodeló una sección de Broadway de una manzana de longitud entre las calles 72 y 73, en Verdi Square. Sus carriles orientales, que antiguamente llevaban el tráfico hacia el norte, fueron transformados en un parque público cuando se construyó una nueva entrada para la estación de metro de la Calle 72 en la antigua ubicación de estos carriles. Actualmente, el tráfico que va hacia el norte por Broadway es desviado por Amsterdam Avenue, gira a la izquierda por la calle 73 y poco después gira a la derecha para tomar de nuevo Broadway.

En agosto de 2008, dos carriles de tráfico de Broadway entre las calles 42 y 35 fueron puestos fuera de servicio y convertidos en plazas públicas. Además, se añadieron carriles bici desde la calle 42 hasta Union Square.
Desde mayo de 2009, las secciones de Broadway que atraviesan Duffy Square, Times Square y Herald Square están cerradas completamente al tráfico de automóviles, excepto el tráfico que la cruza en las calles y avenidas, como parte de un experimento de tráfico y peatonalización. La calzada está reservada exclusivamente para peatones y ciclistas. El ayuntamiento decidió que el experimento había sido un éxito, y decidió hacer el cambio permanente en febrero de 2010. Aunque los beneficios previstos para el flujo del tráfico no fueron tan grandes como se esperaban, los atropellos a peatones se redujeron espectacularmente y el tráfico peatonal aumentó en las zonas designadas. El proyecto fue acogido favorablemente por los residentes y los comerciantes. Las secciones que se han convertido en plazas peatonales son Times Square y Duffy Square, entre las calles 47 y 42, y Herald Square, entre las calles 35 y 33. Además, los tramos de Broadway que atraviesan Madison Square y Union Square han sido estrechados drásticamente, permitiendo que existan amplias plazas peatonales junto a la calzada.

En mayo de 2013, el Departamento de Transporte de la Ciudad de Nueva York decidió remodelar Broadway entre las calles 35 y 42 por segunda vez en cinco años, debido a las malas conexiones entre las plazas peatonales y el descenso del tráfico de vehículos. Con el nuevo diseño, el carril bici está en el lado derecho de la calle; antiguamente estaba en el lado izquierdo, junto a las plazas peatonales, lo que causaba conflictos entre el tráfico de peatones y bicicletas.

En primavera de 2017, como parte de la remodelación de Worth Square, la sección de Broadway entre las calles 24 y 25 se convirtió en una calle compartida. Están prohibidos los vehículos que la atraviesen y los vehículos de reparto están limitados a . Los vehículos de reparto van hacia el norte por la Quinta Avenida hacia la calle 25 durante esa manzana, invirtiendo la dirección del tráfico y evitando que los vehículos vayan hacia el sur por Broadway al sur de la calle 25. El proyecto amplía una iniciativa de 2008 que transformó parte de la intersección de Broadway con la Quinta Avenida en una plaza pública, simplificando esa intersección. Como parte del proyecto de 2017, Worth Square fue ampliada y la manzana adyacente de Broadway se convirtió en una calle compartida.

Broadway recorre toda la longitud de la isla de Manhattan, aproximadamente paralela al río Norte (la parte del río Hudson que bordea Manhattan), desde Bowling Green al sur hasta Inwood, en el extremo norte de la isla. Al sur de Columbus Circle, es una calle de sentido único hacia el sur. Desde 2009, el tráfico de vehículos ha estado prohibido en Times Square entre las calles 47 y 42, y en Herald Square entre las calles 35 y 33 como parte de un programa piloto; la calzada está reservada para los ciclistas y los peatones. En la costa norte de Manhattan, Broadway cruza el río Harlem a través del Puente de Broadway y continúa por Marble Hill (una parte no contigua del "borough" de Manhattan) y posteriormente por El Bronx hacia el condado de Westchester. La carretera US 9 se sigue llamando Broadway hasta su intersección con la NY 117.

La sección de Broadway desde su origen en Bowling Green hasta el City Hall Park es el lugar de realización tradicional de los "ticker tape parades" de la ciudad, y por este motivo es llamada a veces el "Canyon of Heroes" (literalmente, «Cañón de los Héroes»). Al oeste de Broadway, hasta Canal Street, se encontraba la zona residencial de moda de la ciudad hasta en torno a 1825; las tierras ganadas al mar han más que triplicado la superficie de esta zona, y la costa del río Hudson se encuentra actualmente más al oeste, después de Tribeca y Battery Park City.

Broadway marca el límite entre Greenwich Village al oeste y el East Village al este, pasando por Astor Place. Cerca de allí está la Universidad de Nueva York, junto al Washington Square Park, donde empieza la Quinta Avenida. Una curva frente a la iglesia de la Gracia supuestamente evita una antigua taberna; a partir de la calle 10 empieza su largo recorrido diagonal a través de Manhattan, aproximadamente en dirección al norte geográfico.

Debido a que el trazado de Broadway es anterior a la cuadrícula que impuso en la isla el Plan de los Comisarios de 1811, atraviesa Midtown Manhattan diagonalmente, cruzándose tanto con las calles este-oeste como con las avenidas norte-sur. Los cruces de Broadway con las avenidas, marcadas por plazas (algunas de las cuales son solo pequeños espacios abiertos triangulares), han creado algunos edificios interesantes, como el Edificio Flatiron.

En Union Square, Broadway se cruza con la calle 14, se fusiona con la Cuarta Avenida y continúa su recorrido diagonal hacia el norte a partir de la esquina noroeste de la plaza. Union Square es el único lugar de Manhattan en el que la sección física de Broadway es discontinua (otras secciones son plazas peatonales). En Madison Square, donde se encuentra el Edificio Flatiron, Broadway se cruza con la Quinta Avenida a la altura de la calle 23, y es discontinua para los vehículos durante un tramo de una manzana entre las calles 24 y 25. En Greeley Square (calle 33), Broadway se cruza con la Sexta Avenida (Avenue of the Americas), y es discontinua para los vehículos. Los grandes almacenes Macy's Herald Square, una manzana al norte de la discontinuidad, se encuentran en la manzana rodeada por Broadway, la Séptima Avenida y las calles 34 y 35; son uno de los grandes almacenes más grandes del mundo.
Un tramo famoso de Broadway cerca de Times Square, donde se cruza con la Séptima Avenida, alberga muchos teatros de Broadway, que ofrecen un conjunto en constante cambio de obras comerciales a gran escala, particularmente musicales. Esta zona de Manhattan es llamada a veces Theater District y el tramo de Broadway que la atraviesa también es conocido como la "Great White Way" (literalmente, «Gran Camino Blanco»), un apodo que se originó en el titular «Found on the Great White Way» de la edición del 3 de febrero de 1902 del "New York Evening Telegram". Este apodo se debe a los millones de luces de las marquesinas y carteles publicitarios de los teatros que iluminan la zona. Después de convertirse "de facto" en el barrio rojo de la ciudad en las décadas de 1960 y 1970 (como puede verse en las películas "Taxi Driver" y "Midnight Cowboy"), desde finales de los años ochenta Times Square se ha convertido en un centro turístico familiar, y ha sido Disneyficado tras la adquisición y renovación por la compañía del New Amsterdam Theatre en la calle 42 en 1993.

El periódico "The New York Times", que dio su nombre a la plaza, fue publicado en sus oficinas en el 239 de la calle 43 Oeste hasta el 15 de junio de 2007.

En la esquina suroeste de Central Park, Broadway se cruza con la Octava Avenida (llamada Central Park West al norte de la calle 59) en la calle 59 y Columbus Circle; en la ubicación del antiguo centro de convenciones New York Coliseum está el nuevo centro comercial a los pies del Time Warner Center, sede de la Time Warner. Al norte de Columbus Circle, Broadway se convierte en un ancho bulevar hasta la calle 169, con medianas ajardinadas que separan el tráfico hacia el norte del tráfico hacia el sur. Estas medianas son un vestigio del paseo central de The Boulevard, que se había convertido en la columna vertebral del Upper West Side.

Broadway se cruza con Columbus Avenue (conocida como Novena Avenida al sur de la calle 59) en las calles 65 y 66, donde se encuentran la Juilliard School y el Lincoln Center, dos centros de artes escénicas muy conocidos, así como el Templo de Manhattan de la Iglesia de Jesucristo de los Santos de los Últimos Días.
Entre las calles 70 y 73, Broadway se cruza con Amsterdam Avenue (conocida como Décima Avenida al sur de la calle 59). La ancha intersección de las dos avenidas ha sido históricamente un lugar donde se producían numerosos accidentes de tráfico y atropellos de peatones, en parte debido a los largos pasos de peatones. Hay dos pequeños espacios triangulares en los puntos donde Broadway se cruza con Amsterdam Avenue. Uno es un pequeño recinto vallado con arbustos y plantas en la calle 70 llamado Sherman Square (aunque toda la intersección también ha sido conocida colectivamente como Sherman Square), y el otro triángulo es un exuberante jardín de árboles que bordea Amsterdam Avenue desde justo después de la calle 72 hasta la calle 73. Llamado Verdi Square en 1921 por su monumento al compositor italiano Giuseppe Verdi, erigido en 1909, este espacio público triangular fue designado monumento escénico por la Comisión para la Preservación de Monumentos Históricos de Nueva York en 1974, y es uno de los nueve parques de la ciudad que han recibido esta designación. En las décadas de 1960 y 1970, la zona que rodea Verdi Square y Sherman Square era conocida por los consumidores y traficantes de drogas de la ciudad como "Needle Park" («parque de las agujas»), y apareció en la película dramática de 1971 "The Panic in Needle Park", dirigida por Jerry Schatzberg y protagonizada por Al Pacino en su segunda aparición en una película.

La entrada original de ladrillo y piedra de la estación de metro de la Calle 72, una de las primeras veintiocho estaciones de metro de Manhattan, permanece en una de las anchas medianas en el centro de Broadway, al sur de la calle 72. Durante muchos años, todo el tráfico de Broadway fluía a ambos de esta mediana y su entrada de metro, y sus carriles hacia el norte la pasaban al oeste de Verdi Square. Entre 2001 y 2002, la renovación de la histórica estación de la Calle 72 y la construcción de una segunda entrada de metro en una mediana adyacente justo al norte de la calle 72, al otro lado del edificio original, resultó en la creación de una plaza pública con adoquines de piedra y bancos públicos, conectando el edificio nuevo con Verdi Square y haciendo necesario desviar el tráfico hacia el norte por Amsterdam Avenue durante una manzana. Mientras que los carriles de Broadway hacia el sur en esta intersección no fueron afectados por estas obras, sus carriles hacia el norte dejaron de ser contiguos en esta intersección. Los vehículos pueden continuar por Amsterdam Avenue hacia el norte o girar a la izquierda para tomar la calle 73 y posteriormente girar a la derecha para continuar por Broadway.

Cerca de esta intersección se encuentran varios edificios de apartamentos notables, incluido The Ansonia, cuya ornamentada arquitectura de estilo "beaux arts" domina el paisaje de la zona. The Ansonia abrió sus puertas primero como un hotel, y posteriormente albergó el club de alterne "Plato's Retreat". Inmediatamente al norte de Verdi Square está el majestuso edificio del Apple Bank for Savings, antiguamente Central Savings Bank, que fue construido en 1926 y diseñado para parecerse al Edificio del Banco de la Reserva Federal de Nueva York. Broadway también alberga el Beacon Theatre en la calle 74, inscrito en el Registro Nacional de Lugares Históricos en 1979, que fue fundado en 1929 como sala de música y vodevil y todavía funciona como sala de conciertos.

En su intersección con la calle 78, Broadway cambia ligeramente de dirección y continúa aproximadamente alineada con la cuadrícula del Plan de los Comisarios de 1811. Después de la curva están el histórico edificio de apartamentos The Apthorp, construido en 1908, y la Primera Iglesia Bautista de Nueva York, fundada en 1762, cuyo actual edificio en Broadway fue construido en 1891. La calle también pasa junto a edificios de apartamentos de importancia histórica como The Belnord, el Astor Court Building, y The Cornwall, de estilo modernista. En Broadway con la calle 95 está Symphony Space, fundado en 1978 como sala de música y danza vanguardista y clásica en el antiguo Symphony Theatre, que fue construido originalmente en 1918 como una «sala de música y cine». En la calle 99, Broadway pasa entre los dos controvertidos rascacielos de The Ariel. En la calle 107, Broadway se junta con la West End Avenue, y la intersección forma Straus Park, que contiene un memorial al "Titanic" de Augustus Lukeman.

Broadway pasa posteriormente junto al campus de la Universidad de Columbia en la calle 116 en Morningside Heights, parcialmente en la zona que albergó el Manicomio de Bloomingdale desde 1808 hasta que se trasladó al condado de Westchester en 1894. Todavía en Morningside Heights, Broadway pasa junto al campus del Barnard College. A continuación, se encuentran el patio gótico del Union Theological Seminary, y los edificios de ladrillo del Seminario Teológico Judío de América, con sus patios interiores ajardinados, uno a cada lado de Broadway. En la siguiente manzana está la Manhattan School of Music.

Broadway pasa posteriormente por el campus de Manhattanville de la Universidad de Columbia, y por el campus principal del CUNY–City College cerca de la calle 135; los edificios góticos del campus original del City College están una manzana al este. También al este están los edificios de arenisca marrón de Hamilton Heights. Hamilton Place es una sección que se conserva de Bloomingdale Road, y originalmente se encontraba allí la casa de Alexander Hamilton, The Grange, que ha sido trasladada.

Broadway logra un efecto verde, similar a un parque, particularmente en primavera, cuando discurre entre el cementerio de la iglesia de la Trinidad y la antigua capilla de la Trinidad, actual iglesia de la Intercesión, cerca de la calle 155. El hospital presbiteriano de Nueva York se encuentra en Broadway cerca de las calles 166, 167 y 168, en Washington Heights. La intersección con la St. Nicholas Avenue en la calle 167 forma el Mitchell Square Park. En la calle 178, la carretera US 9 se hace concurrente con Broadway. Broadway cruza el río Harlem a través del Puente de Broadway, que conduce a Marble Hill. A continuación, entra en El Bronx, donde constituye el límite entre Riverdale, al oeste, y el Van Cortlandt Park, al este. En la calle 253, la NY 9A se une con la US 9 y Broadway.

El lado norte del Van Cortlandt Park marca el límite de la ciudad y Broadway entra en Yonkers, donde actualmente es conocida como South Broadway. Cambia ligeramente de dirección hacia el oeste, más cerca del río Hudson, y sigue siendo una ajetreada calle comercial urbana. En el centro de Yonkers, cerca del río, pasa a llamarse North Broadway y la NY 9A se separa por Ashburton Avenue. Broadway escala la colina cercana, y discurre paralela al río y a las vías del tren, unas pocas manzanas al este de ambas cuando pasa por el St. John's Riverside Hospital. Los barrios se hacen más residenciales y la calle serpentea suavemente a lo largo de la cresta. En Yonkers, Broadway pasa junto a la histórica Philipse Manor, que data de la época colonial.

Sigue llamándose Broadway tras dejar Yonkers y entrar en Hastings-on-Hudson, donde se divide en dos rutas separadas hacia el norte y hacia el sur durante . Los árboles se hacen más altos y las casas, muchas de ellas separadas de la calle mediante vallas de piedra, se hacen más grandes, y pasa junto a otro Hito Histórico Nacional, la John William Draper House, desde donde se realizaron las primeras astrofotografías de la Luna.
En el siguiente pueblo, Dobbs Ferry, Broadway ofrece vistas del río Hudson mientras atraviesa su sección residencial. Broadway pasa por el Acueducto de Croton y cerca del distrito comercial de la localidad. Tras cruzarse con Ashford Avenue, Broadway pasa junto al Mercy College, posteriormente gira hacia la izquierda en el centro del pueblo justo después de la South Presbyterian Church, dirigiéndose a Ardsley-on-Hudson e Irvington. La Villa Lewaro, la casa de Madam C. J. Walker, la primera millonaria afroamericana, se encuentra junto a la calle. En el norte de Irvington se encuentra un memorial al escritor Washington Irving, en honor al cual el pueblo fue renombrado, junto al desvío que conduce hacia su casa, Sunnyside. Al entrar en la parte sur de Tarrytown, Broadway pasa junto a la histórica Lyndhurst, una gran mansión construida a lo largo del río Hudson a principios del siglo .

Al norte, en el centro técnico de Kraft Foods, se hace visible el Puente Tappan Zee. Tras cruzar bajo el New York State Thruway y la I-87, concurrente con la I-287, y cruzarse con la NY 119, de cuatro carriles, Broadway se convierte en la ajetreada calle principal de Tarrytown. La Iglesia Episcopal de Cristo, que frecuentaba Irving, se encuentra junto a la calle. A lo largo de ella se encuentran también muchos restaurantes y tiendas exclusivas. Esta zona comercial termina en el término este de la NY 448, donde Broadway gira hacia la izquierda, cuesta abajo, pasando por la Antigua Iglesia Holandesa de Sleepy Hollow, otro Hito Histórico Nacional. La calle entra entonces en Sleepy Hollow (antiguamente North Tarrytown), pasando por el centro de visitantes de Kykuit, el Hito Histórico Nacional que perteneció a la familia Rockefeller. Broadway pasa posteriormente junto al histórico cementerio de Sleepy Hollow, en el que se encuentra la tumba de Washington Irving, y es el escenario de "La leyenda de Sleepy Hollow". Broadway se amplía a cuatro carriles en la intersección con la NY 117, donde termina, y la US 9 se convierte en Albany Post Road (y Highland Avenue) en el límite norte de Sleepy Hollow.

La expresión "Canyon of Heroes" («Cañón de los Héroes») se usa ocasionalmente para referirse a la sección sur de Broadway en el Distrito Financiero, que es el lugar de celebración de los "ticker tape parades" de la ciudad. La ruta tradicional del desfile es desde Bowling Green hasta el City Hall Park. La mayor parte de la ruta está bordeada a ambos lados por rascacielos de oficinas, lo que permite la contemplación del desfile a los miles de trabajadores, que lanzan productos de papel triturado creando así el ambiente similar a una tormenta de nieve que caracteriza este tipo de desfiles.

Mientras que sobre los típicos desfiles de campeonatos deportivos se han arrojado unas cincuenta toneladas de confeti y papel triturado, el desfile del Día de la Victoria sobre Japón el 14–15 de agosto de 1945 —que marcó el final de la Segunda Guerra Mundial— fue cubierto con 5438 toneladas, según las estimaciones del Departamento de Sanidad de la Ciudad de Nueva York. Más de doscientas franjas de granito negro incrustadas en las aceras de esta sección de Broadway recuerdan a los homenajeados con pasados "ticker tape parades".

"Great White Way" («Gran Camino Blanco») es el apodo de una sección de Broadway en Midtown Manhattan, específicamente la parte que cruza el Theater District, entre las calles 42 y 53, donde se encuentra Times Square. En 1880, un tramo de Broadway entre Union Square y Madison Square fue iluminado con lámparas de arco Brush, convirtiéndose así en una de las primeras calles con iluminación eléctrica de los Estados Unidos. En la década de 1890, el tramo entre las calles 23 y 34 estaba iluminado tan intensamente por los carteles publicitarios eléctricos que los neoyorquinos empezaron a llamarla "The Great White Way". Cuando el distrito de teatros se trasladó hacia el norte, el nombre fue transferido a la zona de Times Square. La expresión "Great White Way" ha sido atribuida a Shep Friedman, columnista del "New York Morning Telegraph", que tomó prestado el término del título de un libro sobre el Ártico de Albert Paine. En la edición del 3 de febrero de 1902 del "New York Evening Telegram" apareció el titular «"Found on the Great White Way"».

El historiador y artista Jerome Myers ofrece un retrato de Broadway y "The Great White Way" por la noche en la primera parte del siglo en "Artist In Manhattan" (1940):

De sur a norte, Broadway en un punto u otro discurre por encima o por debajo de varias líneas del Metro de Nueva York, incluida la Línea de Lexington Avenue, la Línea Broadway, la Línea de la Séptima Avenida–Broadway y la Línea de la Octava Avenida. La Línea de la Sexta Avenida es la única línea troncal norte-sur en Manhattan que no discurre en algún punto a lo largo de Broadway:

Entre los primeros tranvías en Broadway se encontraban la Broadway and University Place Line del Broadway and Seventh Avenue Railroad (1864?) entre Union Square (calle 14) y Times Square (calle 42), la Ninth and Amsterdam Avenues Line del Ninth Avenue Railroad (1884) entre las calles 65 y 71, la Broadway Branch Line del Forty-second Street, Manhattanville and St. Nicholas Avenue Railway (1885?), entre Times Square y la calle 125, y la Kingsbridge Line del Kingsbridge Railway al norte de la calle 169. La Broadway Line del Broadway Surface Railroad, una línea de tranvía de cables, abrió en el tramo sur de Broadway (al sur de Times Square) en 1893, y pronto se convirtió en el núcleo del Metropolitan Street Railway, con dos ramales: la Broadway and Lexington Avenue Line y la Broadway and Columbus Avenue Line.

Estas líneas de tranvía fueron sustituidas por rutas de autobús en las décadas de 1930 y 1940. Antes de que Broadway se convirtiera en una calle de sentido único, las principales rutas de autobús que la recorrían eran la 6 (Broadway al sur de Times Square), la 7 (Broadway y Columbus Avenue) y la 11 (Novena Avenida y Amsterdam Avenue) de la New York City Omnibus Company (NYCO), y las (Kingsbridge) y M104 (ramal de Broadway) de la Surface Transportation Corporation. Además, las rutas 4 y 5 de la Fifth Avenue Coach Company (FACCo) recorrían Broadway desde la calle 135 hacia el norte hasta Washington Heights, y sus rutas 5 y 6 recorrían Broadway entre las calles 57 y 72. Con la implementación del sentido único del tráfico, las rutas 6 y 7 hacia el norte fueron trasladadas a la Sexta Avenida.

Actualmente, Broadway es servida por las rutas de autobús M4 (antigua FACCo 4), M7 (antigua NYCO 7), M55, M100 y M104. Entre las otras rutas que usan parte de Broadway se encuentran la M5 (antigua FACCo 5), M10, M20, M60, Bx7, Bx9 y Bx20. Los autobuses Bee-Line también sirven Broadway en Riverdale y el condado de Westchester. Las rutas 1, 2, 3, 4, 6, 13, y varias otras discurren por Broadway.

En Broadway se encuentran muchos edificios famosos e históricos, como:

Entre los edificios históricos de Broadway que han sido demolidos se encuentran:




</doc>
<doc id="45360" url="https://es.wikipedia.org/wiki?curid=45360" title="Topología de Aleksándrov">
Topología de Aleksándrov

En matemática, a cualquier preorden se le puede dar la estructura de un espacio topológico, declarando abierto cualquier sección final (conjunto superior). Se puede demostrar que cualquier topología «fina» viene de esa debido al (pre)orden de especialización y, entre tales espacios, una función es continua si y solamente si es monótona.

Esto contesta a una buena pregunta: si toda intersección (no sólo las intersecciones finitas) de conjuntos abiertos es abierta. Respuesta: esta topología es de Alexandrov (también escrito Alexandroff), en honor a Pável Aleksándrov, quien fue el primero en estudiarlas.

Es importante notar que no hay topologías finitas, solamente sus preórdenes de especialización!. Lo que a su vez significa (por el teorema de inmersión de Henkin) que preorden es el lenguaje de primer "orden" (en sentido lógico) de la topología (pero esto significa: la topología no es de primer "orden" (en sentido lógico)). Paradigmático es el Espacio de Sierpiński. Pero los límites (infinitos) de estos espacios finitos son los espacios espectrales. 





</doc>
<doc id="45361" url="https://es.wikipedia.org/wiki?curid=45361" title="Forbes">
Forbes

Forbes () es una revista especializada en el mundo de los negocios y las finanzas, publicada en Estados Unidos. Fundada en 1917 por B. C. Forbes, cada año publica listas que despiertan gran interés en el ámbito de los negocios como "Forbes 500". Su sede central se encuentra en la Quinta Avenida de Nueva York. Desde 1986, cada año "Forbes" publica su lista de las personas más ricas del mundo («The World's Richest People»).

Forbes es una editorial estadounidense. Su publicación principal, la revista "Forbes", se publica cada dos semanas. Sus competidores principales, en la categoría de revistas de negocios, a nivel nacional son "Fortune", la cual se publica también cada dos semanas, y "Business Week". La revista es mundialmente famosa por sus listas, incluyendo las listas de los americanos más ricos (the Forbes 400) y sus listas de milmillonarios. El lema de la revista es "«La herramienta del Capitalista»".

B. C. Forbes, un columnista de finanzas de Hearst, y su socio Walter Drey, el director general de "Magazine of Wall Street", fundaron la revista "Forbes" en 1917. Forbes puso el capital y el nombre y Drey la experiencia periodística. El nombre original de la revista era "Forbes: Dedicado a personas que hacen y lo que hacen." Drey se convirtió en vicepresidente de la compañía, mientras que B.C. Forbes se convirtió en el jefe editorial, puesto que ocupó hasta su muerte en 1954. B.C. Forbes fue ayudado, en sus últimos años de vida, por sus dos hijos mayores, Bruce Charles Forbes (1916-1964) y Malcolm Stevenson Forbes (1917-1990).

Bruce Forbes se encargó de la revista tras la muerte de su padre, y su punto fuerte era modernizar operaciones y el desarrollo comercial. Durante su mandato, 1954-1964, la circulación de la revista se dobló. Sin embargo, en el aumento en la circulación, tienen mucho que ver los inversionistas y la confianza que le dieron a la revista.

Cuando Malcolm Forbes tomó el mando, no se ocupó de las operaciones pero si proveyó dos iniciativas estratégicas que cambiaron a "Forbes" para siempre. El instituyó un equipo de trabajo en casa, en lugar de utilizar periodistas independientes, y publicó el primer artículo de listas, por las cuales "Forbes" se hizo famoso.

En la muerte de Malcolm, su hijo mayor Malcolm Stevenson “Steve” Forbes Jr. (1947-) se convirtió en Presidente, y editor en jefe de la revista. Entre 1961 y 1999 la revista fue editada por James Michaels. En 1993, bajo la jefatura de Michaels, Forbes fue finalista al premio de Revista Nacional. En 2006, un grupo de inversionistas Elevation Partners (entre los que se incluye la estrella de rock Bono) compró un interés minoritario en la compañía. "The New York Times", en 2009 anunciô que un 40% de la empresa se vendió por 300 millones de dólares, poniendo el valor de la empresa por 750 millones de dólares.

Aparte de "Forbes" y su suplemento de estilo de vida, "ForbesLife", también se publican: "Forbes Asia" y ocho ediciones de idiomas locales. Steve Forbes y sus escritores ofrecen consejos de inversiones en el programa de TV semanal de la Fox, "Forbes on Fox" y "Forbes on Radio". También existen otros grupos de compañías como "Forbes Conference Group", "Forbes Investment Advisory Group", y "Forbes Custom Media". El informe de The Times de 2009 dijo que: “Steve Forbes regresó tras abrir una revista Forbes en la India, aumentando el número de ediciones extranjeras a 10. Además, este año la compañía comenzó a publicar "Forbes Woman", una revista cuatrimestral con una página de internet que lo acompaña.

La compañía publicaba la revista "American Legacy" conjuntamente con otra compañía, aunque esa revista se separó de "Forbes" el 14 de mayo de 2007.

La compañía también publicaba las revistas "American Heritage" e "Invention & Technology". Al no encontrar un comprador, "Forbes" suspendió la publicación de estas revistas a partir del 14 de mayo de 2007. Estas revistas posteriormente fueron compradas por American Heritage Publishing Company, y ahora han vuelto a ser publicadas desde la primavera de 2008.

David Churbuck fundó el sitio de internet Forbes en 1996. El cual destapó el fraude periodístico de Stephen Glass en "The New Republic" en 1998, un artículo que atrajo la atención del periodismo en internet. La web, como la revista, publica muchas listas enfocadas a milmillonarios y sus posesiones.

Forbes.com emplea el lema "Home Page For The World's Business Leaders" y algunas veces afirma ser el sitio de negocios más visitado en el mundo. El actual presidente es James J. Spanfeller; el editor Paul Maid; el editor jefe Carl Lavin, quien le siguió al editor jefe Michael Noer y Dan Bigman.

Según Forbes.com, el sitio de internet está entre los recursos de más confianza para los ejecutivos de negocios, dándoles informes de tiempo actual, comentarios sin compromiso, análisis concisos, herramientas y comunidades relevantes que necesitan para tener éxito en el trabajo, ganancias de inversiones, y divertirse con las ganancias.

Forbes.com también publica cartas de información sobre inversiones, un sitio de vehículos de lujo, "Forbes Autos" editado por Matthew De Paula, y un sitio de viajes de lujo, "Forbes Traveler", editado por G. Barry Golson, quien anteriormente era editor ejecutivo de Playboy y de TV Guide y también editor en jefe de Yahoo! Internet Life, y un guía en línea de sitios de internet, "Best Of the Web".

Forbes.com Es parte de Forbes’ Digital, una división de Forbes Media LLC. Forbes.com y afiliados incluyen:
Estos sitios llegan a más de 27 millones de personas de negocios cada mes.

El informe de The Times de 2009 también dijo, que: “Uno de los 5 mejores sitios financieros de más tráfico, produciendo de 70 a 80 millones de dólares cada año en ganancias, nunca produjo la oferta pública deseada."

Lanzado en mayo de 2005 por Forbes.com. "Forbes Autos.com" es un sitio de internet diseñado específicamente para compradores y entusiastas de autos de lujo. El contenido editorial está escrito específicamente para consumidores ricos, con un énfasis en objetividad.

ForbesTraveler.com está diseñado para el viajero rico y selectivo. Lanzado en septiembre de 2006 por Forbes.com, Forbes Traveler está dedicado a inspirar, planear y ejecutar las experiencias más distintivas de viajes en el mundo.

Forbes crea muchas listas bajo varios tópicos, el más popular siendo tal vez la lista de billonarios.


En la cultura popular, Forbes es popularmente conocida por sus muchas listas periódicas de valor neto. Como a menudo se requiere mucho trabajo de investigación para determinar la riqueza actual de un individuo, las cifras de Forbes están ampliamente citadas como casi definitivas.


La popularidad de la revista "Forbes" se ha extendido a gran escala, así como a la cultura "hip hop". El cantante 50 Cent, lanzó la mezcla oficial de su hit, “I Get Money” de su álbum "Curtis", el 11 de septiembre de 2008, titulado «Forbes 1,2,3,», también conocido como «Billion Dollar Remix». El título de la canción viene del hecho de que Jay-Z, 50 Cent y Diddy estaban en los tres primeros puestos de la lista de "Forbes" de los "reyes del Hip Hop con más dinero", respectivamente. El vídeo de «Forbes 1,2,3,» puede ser visto como la introducción al sencillo de 50 Cent, «I Still Kill» sobre Akon, de su álbum "Curtis".

En 2005, "Forbes" colocó a Fidel Castro entre las personas más ricas del mundo, con un valor neto estimado de 550 millones de dólares. En el artículo de 2006 "", "Forbes" aumentó su riqueza estimada a 900 millones de dólares. Este artículo estima el valor de jefes de gobierno, «es más una arte que una ciencia» y señala que en el caso de Castro, los autores utilizaron un método de flujo de efectivo contado varias compañías del Estado y asumiendo que una porción de la ganancia es recibida por Castro. Castro respondió que él tiene un valor neto de menos de un dólar y retó a cualquiera para comprobar que él tenga dinero en cuentas en países extranjeros.




</doc>
<doc id="45363" url="https://es.wikipedia.org/wiki?curid=45363" title="(pre)orden de especialización">
(pre)orden de especialización

En la rama de las matemáticas conocida como topología el preorden de especialización, o preorden canónico, es un preorden natural de un conjunto de puntos de un espacio topológico.

En matemáticas, dado cualquier espacio topológico "X", el preorden de especialización se define por

aquí c(.) es el operador de clausura de Kuratowski en "X". Éste es un preorden; es un orden parcial si y solamente si el espacio "X" es T, y trivial (un orden chato) si y solamente si es un espacio T. cualquier función continua entre dos espacios topológicos debe ser, para los respectivos preórdenes de especialización, monótona, el inverso es, por supuesto, falso en general. Pero debe verse la topología de Alexandrov.

Debe tenerse en cuenta que este orden es exactamente Scott-compatible opuesto del usado generalmente en la teoría de anillos, que sigue, incorrectamente, la inclusión conjuntista de ideales. Es incorrecto porque, los ideales son conjuntos cero, debemos seguir el orden de las funciones características.


</doc>
<doc id="45380" url="https://es.wikipedia.org/wiki?curid=45380" title="Conferencia Pugwash">
Conferencia Pugwash

Se conoce como conferencia Pugwash o conferencia de Pugwash a cada una de las conferencias internacionales sobre ciencia y asuntos mundiales creadas a sugerencia de una serie de científicos, filósofos y humanistas, entre los que se contaban Santiago Zarub, Santiago Areses y Silvia Trovato. La primera de ellas tuvo lugar en julio de 1957 en la residencia particular del filántropo estadounidense Cyrus Eaton en el pueblo de Pugwash, en Nueva Escocia, Canadá, de donde reciben su nombre genérico. Posteriormente se han ido celebrando en muchos otros lugares.

Las Conferencias Pugwash tienen como fin la discusión de asuntos tales como el desarme nuclear y la responsabilidad social del científico en temas como el crecimiento demográfico, el deterioro medioambiental y el desarrollo económico del planeta. En su momento, estas conferencias desempeñaron un papel muy importante en el desarrollo y la firma de los tratados de no proliferación de armas nucleares.

La Organización Pugwash, fundada en Londres, Inglaterra, se dedica actualmente a convocar estas conferencias.

La primera de las Conferencias Pugwash tuvo lugar en julio de 1957 en Canadá. Veintidós científicos participaron:


En 1995, 50 años después del bombardeo atómico de Nagasaki e Hiroshima, y 40 años después de la firma del Manifiesto Russell-Einstein, las Conferencias Pugwash y Joseph Rotblat recibieron el .

El comité noruego esperaba que la concesión del premio a Rotblat y Pugwash 

En su discurso de aceptación, Rotblat citó una frase del Manifiesto:



</doc>
<doc id="45382" url="https://es.wikipedia.org/wiki?curid=45382" title="Enfermedad hereditaria">
Enfermedad hereditaria

Las enfermedades hereditarias son aquel conjunto de enfermedades genéticas cuya característica principal es su supervivencia de generación en generación, transmitiéndose de padres a hijos y así sucesivamente (en un determinado momento del tiempo, algo hace cambiar la genética, y ese algo sobrevive en los genes, las mismas circunstancias que hicieron cambiar la genética en un determinado tiempo, pueden volver a suceder en otro momento del tiempo, así que la herencia genética, es la herencia de la humanidad).

Son enfermedades hereditarias causadas por la mutación o alteración en la secuencia de ADN de un solo gen. También se llaman enfermedades hereditarias mendelianas, por transmitirse a la descendencia según las leyes de Mendel. Se conocen más de 6000 enfermedades hereditarias mono génicas, con una prevalencia de un caso por cada 200 nacimientos. Aun así, son menos que las enfermedades poligénicas.

Las enfermedades monogénicas se transmiten según los patrones hereditarios mendelianos como:

Algunas enfermedades monogénicas son:

También llamadas poligénicas, son producidas por la combinación de múltiples factores ambientales y mutaciones en varios genes, generalmente de diferentes cromosomas. Algunos de los factores ambientales que pueden afectar a este tipo de enfermedades son: la edad, el sexo (ser hombre o mujer), malos hábitos (obesidad, tabaco, alcohol), ambientes tóxicos o una infancia limitada. 
Las enfermedades poligénicas no siguen un patrón de herencia mendeliano y, a veces, cuando hay un gen principal responsable de la enfermedad, se comportan como herencia dominante con penetrancia incompleta, como en el caso del cáncer de mama hereditario (genes BRCA1 y BRCA2).

Algunas de las enfermedades crónicas más frecuentes son poligénicas, como por ejemplo: hipertensión arterial, Enfermedad de Alzheimer, esquizofrenia, retinitis pigmentosa, asma, diabetes mellitus, deficiencia de antitripsina I, arterioesclerosis, varios tipos de cáncer, incluso la obesidad.

La herencia poligénica también se asocia a rasgos hereditarios como los patrones de la huella digital, altura, color de los ojos y color de la piel.

Posiblemente la mayoría de las enfermedades son enfermedades multifactoriales, producidas por la combinación de trastornos genéticos que predisponen a una determinada susceptibilidad ante los agentes ambientales.

El término oligogénico referido a una enfermedad multifactorial tiene cada vez más aceptación ya que es habitual ver como en una enfermedad a pesar de ser poligénica, existen unos pocos que tienen más influencia que el resto y que dependiendo de su presencia se expresan otras mutaciones (epistasia).

Son debidas a alteraciones en la estructura de los cromosomas, como pérdida o deleción cromosómica,aumento del número de cromosomas o translocaciones cromosómicas. Algunos tipos importantes de enfermedades cromosómicas se pueden detectar en el examen microscópico. La trisomía 21 o síndrome de Down es un trastorno frecuente que sucede cuando una persona tiene tres copias del cromosoma 21 (entre un 3 y un 4% de los casos son hereditarios; el resto son congénitos).

Este tipo de enfermedad hereditaria es relativamente infrecuente. Es causada por mutaciones en el ADN mitocondrial, no cromosómico. La enfermedad mitocondrial tiene diferentes síntomas que pueden afectar a diferentes partes del cuerpo.
Las mitocondrias tienen su propio ADN. En los últimos años se ha demostrado que más de 20 trastornos hereditarios resultan de las mutaciones en el ADN de las mitocondrias. Dado que las mitocondrias provienen sólo del óvulo son heredadas exclusivamente de la madre.Una persona con un trastorno mitocondrial puede presentar patrones de herencia materna (solo los individuos relacionados por un pariente materno están en riesgo). Los hombres no transmiten la enfermedad a sus hijos.



</doc>
<doc id="45385" url="https://es.wikipedia.org/wiki?curid=45385" title="Álgebra de Heyting">
Álgebra de Heyting

En matemáticas, las álgebras de Heyting (creadas por Arend Heyting) son conjuntos parcialmente ordenados especiales que generalizan las álgebras de Boole. Las álgebras de Heyting se presentan como modelos de la lógica intuicionista, una lógica en la cual la ley del tercero excluido no vale, en general. Las álgebras completas de Heyting son un objeto central de estudio en topología sin puntos. 

Un álgebra de Heyting "H" es un reticulado acotado tal que para todo "a" y "b" en "H" hay un mayor elemento "x" de "H" tal que "a" ^ "x" ≤ "b". Este elemento se llama el seudo-complemento relativo de "a" con respecto a "b", y es denotado "a"=>"b" (o a"⇒"b"). 

Una definición equivalente puede ser dada considerando las funciones "f": "H" → "H" definidos por "f"("x") = "a"^x, para algún "a" (fijo) en "H". Un reticulado acotado "H" es un álgebra de Heyting si y sólo si todas las funciones "f" son el adjunto inferior de una conexión de Galois monótona. En este caso los adjuntos superiores respectivos "g" son dados por "g"("x") = "a"=>"x", donde => se define como arriba. 

Un álgebra completa de Heyting es un álgebra de Heyting que es un retículo completo. 

En cualquier álgebra de Heyting, uno puede definir seudo-complemento ¬"x" de un cierto elemento "x" haciendo ¬"x" = "x"=>0, donde 0 es el menor elemento del álgebra de Heyting. 

Un elemento "x" de un álgebra de Heyting se llama regular si "x" = ¬¬"x".

Las álgebras de Heyting son siempre distributivas. Esto se establece a veces como axioma, pero de hecho se sigue de la existencia de seudo-complementos relativos. La razón es que siendo ^ el adjunto inferior de una conexión de Galois, preserva todos los supremos existentes. Distributividad es precisamente la preservación de los supremos binarios por ^. 

Además, por un argumento similar, la ley distributiva infinita siguiente se sostiene en cualquier álgebra completa de Heyting:

para cualquier elemento "x" en "H" y cualquier subconjunto "Y" de "H".

No toda álgebra de Heyting satisface las dos leyes de De Morgan. Sin embargo, las proposiciones siguientes son equivalentes para todas las álgebras de Heyting "H": 


El seudocomplemento de un elemento "x" de "H" es el supremo del conjunto {"y" : "y" ^ "x"=0} y pertenece a este conjunto (es decir "x" ^ ¬"x"=0). Las álgebras booleanas son exactamente esas álgebras de Heyting en las cuales "x" = ¬¬"x" para todo "x", o, equivalentemente, en el cual "x" v ¬"x" = 1 para todo "x". En este caso, el elemento "a" = > "b" es igual al ¬"a" v "b". 

En cualquier álgebra de Heyting, el menor y mayor elementos 0 y 1 son regulares. Además, los elementos regulares de cualquier álgebra de Heyting constituyen un álgebra booleana. 







</doc>
<doc id="45390" url="https://es.wikipedia.org/wiki?curid=45390" title="Pierre de Coubertin">
Pierre de Coubertin

Pierre Fredy de Coubertin, barón de Coubertin (París, Francia, 1 de enero de 1863-Ginebra, Suiza, 2 de septiembre de 1937), fue un pedagogo e historiador francés, fundador de los Juegos Olímpicos modernos y del Pentatlón moderno.

Su padre, el barón Carlos Luis de Coubertin, quería que fuera militar, pero su temperamento sensible chocó con la dura disciplina de la Escuela Especial Militar de Saint-Cyr. Decidió dedicarse a la pedagogía, donde se sintió realizado por sus ideales. Se mudó a Inglaterra para perfeccionar sus estudios, donde conoce la «singular» doctrina del cristianismo muscular: la búsqueda de la perfección espiritual por medio del deporte y la higiene. Uno de los más destacados seguidores de esta ideología fue el pastor anglicano Thomas Arnold, del que Pierre se convirtió en discípulo.

Comienza a divulgar estos métodos por toda Francia: Crea sociedades atléticas en los institutos que se asocian en la Union des sociétés françaises de sports athlétiques. Funda la primera revista dedicada al deporte: la "Revue Athlétique", logrando que el gobierno francés acceda a incluirla en sus programas de la Exposición Universal de 1889.

El ministro de educación le envía a los Estados Unidos para que continúe su investigación sobre los métodos de enseñanza. El deporte comenzó a ser tomado en serio. De ser practicado por minorías o en el colegio, pasa a estar de moda y despertar entusiasmo.

Pierre comienza a soñar con unir en una extraordinaria competición a los deportistas de todo el mundo, bajo el signo de la unión y la hermandad, sin ánimo de lucro y solo por el deseo de conseguir la gloria, competir por competir, como dice la frase de Ethelbert Talbot «Lo importante no es vencer, sino participar», frase mal atribuida a Pierre de Coubertin. La idea de Coubertin parecía insensata y chocó con mucha incomprensión.

Intentando convencer a todos, viajó por todo el mundo hablando de paz, comprensión entre los hombres y de unión, mezclándolo todo con la palabra "Deporte". Al fin, en la última sesión del Congreso Internacional de Educación Física que se celebró en la Sorbona de París, el 26 de junio de 1894, se decide instituir los Juegos Olímpicos.

En Inglaterra, esta idea no es bien recibida y la opinión pública decide quedar al margen. Alemania reaccionó intentando boicotear los juegos. Grecia se opone, y su jefe de gobierno, Tricoupis, quiso impedir su realización, pues "aquel lío" salía muy caro a su país.

Coubertin consiguió que el príncipe heredero de Grecia, el duque de Esparta, intercediera ante el káiser Guillermo, emperador de Alemania cuñado suyo, convenciendo a los ingleses y a su propio Gobierno. El príncipe consigue que se emita una serie de sellos conmemorativos para conseguir el dinero para los juegos. Además crea una suscripción pública con tan buenos resultados que consigue que Jorge Averof, un griego millonario quien emigró a Alejandría siendo muy joven, corra con los gastos de la reconstrucción del estadio de Atenas.

El 24 de marzo de 1896, día de Pascua de Resurrección, el duque de Esparta, tras un discurso, descubre la estatua del mecenas Jorge Averof. El rey Jorge de Grecia pronuncia por primera vez las palabras rituales: 

«Declaro abierto los Primeros Juegos Olímpicos Internacionales de Atenas».

Este modesto principio sería el origen del movimiento olímpico moderno. Los Juegos Olímpicos se han celebrado, con las excepciones de la Primera Guerra Mundial y de la Segunda Guerra Mundial, durante todo el siglo XX y principios del XXI, convirtiéndose en uno de los acontecimientos más populares del planeta.




</doc>
<doc id="45391" url="https://es.wikipedia.org/wiki?curid=45391" title="Lesión">
Lesión

En clínica, una lesión (del latín "laesiōn[em]", "herida") es un cambio anormal en la morfología o estructura de una parte del cuerpo producida por un daño externo o interno. Las heridas en la piel pueden considerarse lesiones producidas por un daño externo como los traumatismos. Las lesiones producen una alteración de la función o fisiología de órganos, sistemas y aparatos, trastornando la salud y produciendo enfermedad.

Una lesión es una alteración de las características morfológicas o estructurales de un organismo en cualquiera de sus niveles de organización (molecular, celular, tisular, anatómico, corporal o social) producido por causas físicas, químicas o biológicas.

La especialidad médica encargada de identificar las características microscópicas de las lesiones, generalmente mediante biopsias, es la anatomía patológica.

En Derecho y Medicina legal, las lesiones comprenden, además de las heridas externas, cualquier daño en el cuerpo que pueda objetivarse y debido a una causa externa en la que esté implicada una tercera persona.

En términos del Código Penal, lesión es un delito en contra de la vida y la salud personal que se comete por el que cause a otro un daño que deje en su cuerpo un vestigio o altere su salud física o mental.

Las lesiones son producidas por diversos mecanismos nocivos o dañinos, que alteran el equilibrio o la homeostasis celular. Entre las causas de lesiones encontramos:



Las células tras sufrir un daño por un agente externo o interno puede evolucionar a dos situaciones:

Las manifestaciones de las lesiones son:



La activación del sistema inmunitario y el inicio de la reparación corresponde a la inflamación.



</doc>
<doc id="45392" url="https://es.wikipedia.org/wiki?curid=45392" title="Memel">
Memel

Memel puede referirse a:


</doc>
<doc id="45393" url="https://es.wikipedia.org/wiki?curid=45393" title="Álgebra de incidencia">
Álgebra de incidencia

Un conjunto parcialmente ordenado es "localmente finito" cuando cada intervalo cerrado ["a", "b"] es finito. Para cada "poset" localmente finito y cada cuerpo de escalares hay un álgebra de incidencia, que es un álgebra asociativa definida como sigue. Los miembros del álgebra de incidencia son las funciones "f" que asigna a cada intervalo ["a", "b"] un escalar "f"("a", "b"). En este conjunto subyacente se definen la adición y la multiplicación por escalar punto a punto, y la "multiplicación" en el álgebra de incidencia es una convolución definida por

El elemento identidad multiplicativa del álgebra de incidencia es



Un "poset" es acotado si tiene menor y mayor elementos, que llamamos 0 y 1 respectivamente (no deben ser confundidos con el cero y el uno del cuerpo base. En este párrafo, tomamos Q). La característica de Euler de un "poset" finito acotado es μ(0,1); es siempre un número entero. Este concepto se relaciona con la clásica Característica de Euler de un complejo de grupos.

Cualquier miembro de un álgebra de incidencia que asigna el mismo valor a cualesquiera dos intervalos que sean isomorfos el uno al otro como posets es un miembro del álgebra de incidencia reducida. Álgebras de incidencia reducidas iluminan la teoría de las funciones generatrices. 

Las álgebras de incidencia de "posets" localmente finitos fueron tratadas en un número de papers por Gian-Carlo Rota comenzando en 1964, y por muchos otros "combinatorialistas" posteriormente. 

El paper de Rota de 1964 era: 

"On the Foundations of Combinatorial Theory I: Theory of Möbius Functions", Zeitschrift für Wahrscheinlichkeitstheorie und Verwandte Gebiete, volumen 2, páginas 340-368.


</doc>
<doc id="45394" url="https://es.wikipedia.org/wiki?curid=45394" title="Fórmula de inversión de Möbius">
Fórmula de inversión de Möbius

La clásica fórmula de inversión de Möbius fue introducida en la teoría de números durante el siglo XIX por August Ferdinand Möbius. Fue generalizada más tarde a otras «fórmulas de inversión de Möbius». 

La versión clásica establece que si "g"("n") y "f"("n") son funciones aritméticas satisfaciendo
entonces

donde μ es la función de Möbius y las sumas se extienden sobre todos los divisores positivos de "n". La fórmula también es correcta si "f" y "g" son funciones de los números enteros positivos en algún grupo abeliano. Las dos funciones se dice que son la transformada de Möbius la una de la otra. En el lenguaje de convoluciones (véase función multiplicativa), la primera fórmula puede expresarse como

donde "*" denota el operador convolución de Dirichlet, y 1 es la función constante f("n")=1. De la misma manera, la segunda se expresa como

Una formulación equivalente de la fórmula de inversión, más útil en combinatoria es como sigue:

Suponga que "F"("x") y "G"("x") son funciones complejo-valoradas definidas en un intervalo [1, ∞) tales que

entonces

aquí las sumas se extienden sobre todos los números enteros positivos "n" que son menores o iguales que "x". 

La inversión de Möbius tratada arriba es la inversión original de Möbius. Cuando el conjunto parcialmente ordenado de los números naturales ordenados por la divisibilidad es substituido por otros conjuntos parcialmente ordenados localmente finitos, uno obtiene otras fórmulas de inversión de Möbius; para una reseña de ellas, véase álgebra de incidencia.

Como la fórmula de inversión de Möbius puede ser aplicada a cualquier grupo abeliano, esto no supone una diferencia entre si la operación de grupo es la adición o la multiplicación. En este sentido, se puede proporcionar la siguiente versión multiplicativa de la fórmula de inversión de Möbius. Si 

entonces 



</doc>
<doc id="45397" url="https://es.wikipedia.org/wiki?curid=45397" title="August Möbius">
August Möbius

August Ferdinand Möbius o Moebius ( Schulpforta, 17 de noviembre de 1790-Leipzig, 26 de septiembre de 1868) fue un matemático y astrónomo teórico alemán.

Möbius nació en el colegio Schulpforta (Sajonia), donde su padre Johann Heinrich Möbius (1742-1792) enseñaba danza. Su madre, Johanne Katharine Christiane Keil (1756-1820), pertenecía a la séptima generación descendiente del reformador religioso Martín Lutero. Como su esposo falleció cuando su único hijo contaba tres años, fue ella quien lo educó hasta los trece, edad con la cual ingresó en el colegio Schulpforta.

Si bien empezó Derecho en Leipzig (1809) para complacer a su familia, al semestre lo dejó por su gran pasión: la ciencia. Estudió matemáticas, astronomía y física en distintas universidades y con famosos científicos de su época, en especial astronomía en Leipzig con Karl Mollweide, materia que amplió en Gotinga bajo la supervisión de Carl Friedrich Gauss. En Halle tuvo como profesor a Johann Friedrich Pfaff, quien dirigió su tesis, leída en 1815, "De computandis occultationibus fixarum per planetas" sobre métodos de cálculo aplicados al estudio de estrellas fijas ocultadas por planetas. En ese mismo año escribió su tesis de habilitación sobre ecuaciones trigonométricas. En 1816, el ejército prusiano intentó reclutarlo, pero logró evitarlo.

Gauss lo recomendó en 1816 para ser profesor extraordinario de la Cátedra de Astronomía y Mecánica Superior de la Universidad de Leipzig para sustituir a su maestro Mollweide. Enseñó allí y en 1844 fue nombrado catedrático. En 1846 lo eligieron además miembro de la Academia de Ciencias de Gotinga y desde 1848 fue director del Observatorio de Leipzig, cuya reconstrucción había supervisado. Casi todo su trabajo fue publicado en "Crelle", la primera revista dedicada exclusivamente a artículos de investigación en matemáticas. 

Möbius se casó en 1820 com Dorothea Rothe (1790-1859), hija de un cirujano, de la que tuvo tres hijos: August (1821-1890), Emilie (1822-1897) y Paul (1825-1889). Este último le dio cinco nietos, uno de los cuales fue el famoso neurólogo Paul Julius Möbius (1853-1907), conocido por su investigación del síndrome de Möbius. 

Es conocido sobre todo por su descubrimiento en 1858 de la banda de Möbius junto al matemático alemán Johann Benedict Listing. Se trata de una superficie de dos dimensiones no orientable con solamente un lado cuando está sumergido en el espacio euclidiano tridimensional. Las instrucciones para construirlo, junto con alguna descripción de sus propiedades topológicas, se encontraron en una memoria presentada por Möbius a la Académie des Sciences francesa, algún tiempo después de su fallecimiento en Leipzig. Hoy en día su invento ha generado numerosos diseños industriales: cintas transportadoras de materiales calientes, correas abrasivas o cartuchos de tinta con forma de banda de Möbius en vez de cilíndrica, que duran el doble de tiempo al utilizarse de manera óptima su única cara.
Möbius fue el primero en introducir las coordenadas homogéneas en geometría proyectiva. La transformación de Möbius, importante en geometría proyectiva, no debe ser confundida con la transformada de Möbius, usada en teoría de números, que igualmente lleva su nombre. Se interesó también por la teoría de números, y la importante función aritmética de Möbius μ("n") y la fórmula de inversión de Möbius se nombran así por él.

Además de los distintos conceptos matemáticos y geométricos que llevan su nombre:



</doc>
<doc id="45398" url="https://es.wikipedia.org/wiki?curid=45398" title="Toxina">
Toxina

Una toxina (del griego clásico τοξικόν ["toxikón"], que significa ‘flecha’) es una sustancia venenosa producida por células vivas de animales, plantas, bacterias u otros organismos biológicos; para destacar su origen orgánico, se habla a veces también de biotoxina. Están excluidas de esta definición las sustancias creadas por procesos artificiales. El término «toxina» fue introducido por el químico orgánico Ludwig Brieger (1849-1919).

Las toxinas pueden ser pequeñas moléculas, péptidos, o proteínas capaces de causar enfermedad cuando entran en contacto con, o son absorbidos por, tejidos del cuerpo, interactuando con macromoléculas biológicas como enzimas o receptores celulares. Las toxinas varían enormemente en su severidad, que va de un efecto breve y leve (como en el caso de un aguijón de abeja) hasta mortal casi de inmediato (como en la toxina botulínica).

Las toxinas generadas por microorganismos son un importante factor de virulencia; responsables del carácter patogénico y del grado de evasión del sistema inmunitario del huésped.

Las toxinas en la naturaleza tienen principalmente dos funciones:

Clasificación por su naturaleza química

Hoy en día, las toxinas se pueden clasificar, de acuerdo a su naturaleza química, en toxinas proteicas y toxinas glúcido-lípido-polipeptídicas. 
Roux demostró que el bacilo diftérico segrega un veneno que por sí solo puede reproducir la enfermedad en un cobayo. Esta toxina diftérica es verdaderamente segregada en el medio externo. Otras toxinas proteicas se hallan al mismo tiempo en el cuerpo microbiano y en el medio ambiente. Y ciertas toxinas proteicas permanecen fuertemente ligadas a los cuerpos microbianos.
Pillemer y Eaton estudiaron de manera especial la estructura de las toxinas tetánica y diftérica. 
Estas toxinas son solubles en agua y generalmente termolábiles; el calor, la luz y el envejecimiento las afectan. 
Los ácidos y las bases las destruyen y el formol las transforman en un nuevo producto, llamado anatoxina por el veterinario y biólogo francés Gaston Ramon, en 1923. Este producto es absolutamente inofensivo, pero conserva íntegramente el poder floculante y la actividad inmunizante de la toxina. (Burdin & de Lavergne, 1980)

Las toxinas glúcido-lípido-polipeptídicas tienen efecto sobre el sistema nervioso (irritan el sistema parasimpático) y representa un papel importante en el favorecimiento de la infección.
Algunos de los tipos de toxina mejor conocidos son:




</doc>
<doc id="45403" url="https://es.wikipedia.org/wiki?curid=45403" title="Oído">
Oído

El oído es un órgano sensorial que permite percibir los sonidos, formando el sentido de la audición, y en mamíferos también se encarga del equilibrio. El oído se puede dividir para su estudio en tres secciones: oído externo, oído medio y oído interno. 

La percepción del sonido es un fenómeno complejo que se desarrolla en varias etapas. En primer lugar se realiza la captación de las ondas sonoras gracias a la membrana del tímpano. En segundo lugar la señal mecánica recogida por el tímpano debe transformarse en impulsos nerviosos, proceso que ocurre en el oído interno. En tercer lugar los impulsos nerviosos a través del nervio auditivo son enviados al cerebro para ser procesados en la corteza cerebral.

El espectro auditivo, es decir la gama de frecuencias que el oído puede percibir, es variable dependiendo de la especie animal. El ser humano puede detectar sonidos de entre 0 y 140 decibelios con un rango de frecuencias comprendido entre 40 y 20000 hercios. Las ballenas pueden percibir infrasonidos con una frecuencia inferior a 40 hercios. Algunos animales carnívoros como el perro son capaces de detectar ultrasonidos con una frecuencia superior a 20000 hercios que un humano es incapaz de oír.

El oído externo está formado por dos partes: El pabellón auricular y el conducto auditivo externo. 

El oído medio es una cavidad llena de aire que está separada por el tímpano del conducto auditivo externo y entra en comunicación con el oído interno a través de dos pequeños orificios: la ventana oval y la ventana redonda. En el interior del oído medio se encuentra una cadena de huesecillos unidos entre sí por articulaciones de tipo sinovial, son los huesos más pequeños del cuerpo y reciben el nombre de martillo, yunque y estribo. El oído medio está conectado con la nasofaringe por un conducto de reducidas dimensiones que se llama trompa faringotimpánica o trompa de Eustaquio.





El oído interno o laberinto está ubicado en el seno del hueso temporal del cráneo. Existe un laberinto óseo y un laberinto membranoso. El laberinto óseo no es más que la cápsula ósea que rodea al laberinto membranoso, y este último consiste en un sistema de conductos huecos que contiene en su interior un líquido que se llama endolinfa. En el espacio que queda entre el laberinto óseo y el laberinto membranoso se encuentra la perilinfa. 

El oído interno se divide en dos porciones diferenciadas. La primera está destinada al mantenimiento del equilibrio y se encuentra formada por el vestíbulo y los conductos semicirculares. La segunda tiene como función la audición y está constituida por la coclea o caracol. El vestíbulo se divide en dos sectores que se llaman utrículo y sáculo, mientras que la cóclea o caracol contiene el órgano de Corti responsable de transformar la energía mecánica de las ondas sonoras en impulsos eléctricos que posteriormente se transmiten al cerebro a través del nervio auditivo o nervio vestíbulococlear.



Estas porciones están separadas unas de otras por dos membranas. La membrana vestibular o de Reissner sirve de separación entre el conducto coclear y la rampa vestibular, mientras que la membrana basilar sirve de separación entre el conducto coclear y la rampa timpánica. A lo largo de la membrana basilar se encuentra el órgano de Corti que contiene alrededor de 16000 células con cilios que constituyen los receptores de la audición. 

El conducto coclear esta lleno de un líquido que se llama endolinfa rico en K (161mmol/l) y pobre en Na (1mmol/l) y en calcio (0.02mmol/l). La rampa timpánica y vestibular contiene otro líquido diferente que se llama perilinfa cuyas concentraciones iónicas son las inversas, es rico en Na y pobre en K.

La membrana vestibular es tan delgada, que no dificulta el paso de las vibraciones sonoras desde la rampa vestibular a la rampa media. Por lo tanto en cuanto a transmisión del sonido, la rampa vestibular y media se consideran como una única cámara. La importancia de la membrana vestibular depende de que conserve la endolinfa en la rampa media necesaria para el normal funcionamiento de las células ciliadas.

Forma parte del oído interno y está ubicado en la coclea o caracol, a veces se designa con el nombre de órgano espiral y tiene un papel fundamental en el proceso de audición. Está formado por un epitelio engrosado de características complejas. Dispone de dos tipos de células: Células ciliadas y células de sostén.

Para que se produzca la audición las ondas sonoras deben penetrar por el conducto auditivo externo hasta alcanzar el tímpano. La vibración de la membrana timpánica se transmite a través de los huesecillos del oído medio, pasando del martillo al yunque y de este al estribo. El estribo transmite las vibraciones a la perilinfa del oído interno a través de la ventana oval. En la coclea la energía mecánica de las señales acústicas se transforma en impulsos eléctricos que a través de nervio acústico son transportados a la región temporal de la corteza cerebral donde son procesados. Por tanto podría decirse que el órgano con el que en realidad escuchamos es el cerebro. Se conoce con el nombre de sordera central o agnosia auditiva a la dificultad que presentan algunas personas para reconocer sonidos debido a una lesión cerebral que afecta a las áreas relacionadas con la audición. Estas personas tienen sin embargo todas las partes del oído y el nervio auditivo en buena situación funcional por lo que la deficiencia en la capacidad para discriminar sonidos se debe únicamente a la lesión del cerebro.


Entre los distintos problemas de salud relacionados al oído se encuentran :





</doc>
<doc id="45406" url="https://es.wikipedia.org/wiki?curid=45406" title="Álgebra asociativa">
Álgebra asociativa

En matemáticas, un álgebra asociativa es un módulo que también permite la multiplicación de vectores de manera distributiva y asociativa.

Sean formula_1 y formula_2 dos anillos unitarios, y formula_3 un homomorfismo entre anillos unitarios (es decir, un homomorfismo de anillos de manera que formula_4). Definimos la operación externa:

formula_5

Esta operación formula_6 dota al grupo abeliano formula_7 de estructura de formula_8-módulo por la izquierda. Esta operación es, además, compatible con el producto formula_9 del anillo formula_10 en el siguiente sentido: dados formula_11, se tiene que formula_12.

Si tenemos un cuerpo formula_13, un anillo formula_8 y un homomorfismo unitario de anillos formula_15, tenemos entonces que formula_16, luego formula_17 es monomorfismo y podemos considerar que formula_13 es un subanillo de formula_8 (mediante el primer teorema de isomorfía, formula_13 es isomorfo a un subanillo de formula_8). Un álgebra asociativa sobre un cuerpo "K", entonces, puede definirse de manera equivalente como un espacio vectorial sobre "K" junto con una multiplicación "K"-bilineal "A" x "A" -> "A" (donde la imagen de ("x", "y") se escribe como "xy") tal que la ley asociativa valga:


La bilinealidad de la multiplicación se puede expresar como




Si "A" contiene un elemento identidad, es decir un elemento 1 tales que 1"x" = "x"1 = "x" para todo "x" en "A", entonces llamamos a "A" un "álgebra asociativa con uno" o "unitaria" (o "unital"). Tal álgebra es un anillo y contiene una copia del cuerpo de base "K" en la forma {"a"1: "a" en "K"}.

La dimensión del álgebra asociativa sobre el cuerpo "K" es su dimensión como espacio "K"-vectorial.










Si "A" y "B" son álgebras asociativas sobre el mismo anillo "R" un homomorfismo de álgebras "h": "A" -> "B" es un homomorfismo de "R"-módulos que también es multiplicativa en el sentido que "h"("xy") = "h"("x") "h"("y") para todo "x", "y" en "A". Con esta noción de morfismo, la clase de todas las álgebras asociativas sobre "R" se convierte en una categoría.

Tome por ejemplo el álgebra "A" de todas las funciones continuas real-valuadas formula_22, y el "B" = formula_23. ambos son álgebras sobre formula_23, y la función que asigna a cada función continua formula_17 el número formula_26 (evaluación en 0) es un homomorfismo de álgebras de "A" a "B".

Un álgebra asociativa unitaria sobre "R" se basa en un morfismo "A" x "A"→ "A" que tiene 2 entradas (multiplicador y multiplicando) y una salida (el producto), así como un morfismo "R"→"A" que identificaba los múltiplos escalares de la identidad multiplicativa. Estos dos morfismos pueden ser dualizados con dualidad categorial invirtiendo todas las flechas en los diagramas conmutativos que describen los axiomas del álgebra; esto define una estructura de coálgebra.


</doc>
<doc id="45407" url="https://es.wikipedia.org/wiki?curid=45407" title="Virión">
Virión

En microbiología se denomina virión a la partícula vírica morfológicamente completa e infecciosa. Está compuesto por:




</doc>
<doc id="45412" url="https://es.wikipedia.org/wiki?curid=45412" title="Sancho VII de Navarra">
Sancho VII de Navarra

Sancho VII de Navarra, conocido como «el Fuerte» fue rey de Navarra entre 1194 y 1234, año en que murió en el castillo de Tudela, Navarra. Era hijo y sucesor de Sancho VI «el Sabio», de la dinastía Jimena y hermano de Berenguela de Navarra, casada con Ricardo Corazón de León.

Se le apodó "el Fuerte" debido a su enorme estatura y fortaleza. Según su biógrafo y catedrático médico forense de Pamplona, Luis del Campo Jesús (1912-1995), medía entre 2,28 y 2,31 metros de altura; llegó a tal conclusión extrapolando al resto del cuerpo la medida que de su fémur dio en 1622 el subprior Huarte, que vio sus restos mortales.

Referente a su nacimiento, se ha querido localizarlo en Tudela fundándose en que sus padres residían frecuentemente en esta ciudad, pero no existe ningún dato que avale esta creencia, por más que sea razonable no se halla ninguna base que lo acredite. Sí que es cierto que Tudela la eligió como continua residencia y que acabó su vida encerrado en su castillo.

Sancho se casó con Constanza de Tolosa, hija de Ramón VI, conde de Tolosa, y según Luis del Campo (que aparte de forense, es un biógrafo de este rey), el matrimonio pudo celebrarse sobre el año 1195. Este matrimonio fracasó y Constanza fue repudiada. No hay constancia fehaciente de un segundo matrimonio con Clemencia, hija del emperador Federico I Barbarroja, ninguna de las dos mujeres le dio hijos, pero sí tuvo varios hijos bastardos en los que continuaría la estirpe real de Navarra entre nobles navarros y aragoneses.

Continuó con las relaciones que su padre había establecido con Castilla y, sobre todo, con Aragón.

En 1196 se realizó una entrevista auspiciada por la Santa Sede en donde se encontraban los tres reinos de Castilla, Aragón y Navarra, en un punto entre Agreda y Tarazona, para intentar unir a los reinos cristianos.
Alfonso VIII invadió Álava, con un largo asedio a Vitoria, Guipúzcoa y el Duranguesado en 1199. Sancho VII acudió a negociar con los almohades para que atacaran a Castilla y con un segundo frente tuvieran que levantar el asedio, sin lograrlo. Tras la importante pérdida territorial del reino de Navarra, años después firmaría con Castilla una tregua por cinco años el 29 de octubre de 1207 en Guadalajara, en la que Navarra no reconocía la pérdida de los territorios vascongados. Sin embargo, el tiempo fue consolidando las posiciones castellanas.

Desde entonces sus relaciones fueron tensas con Alfonso VIII, aunque de buena gana colaboró con él en la batalla de Las Navas de Tolosa (1212), donde obtuvo prestigio y mejoró en su posición respecto a los otros reyes cristianos, con la recuperación de algunas plazas. En esta batalla, las tropas de Sancho el Fuerte llegaron hasta la tienda de Muhammad An-Nasir conocido por el sobrenombre de Miramamolín, califa almohade, cortando las cadenas que la protegían. Según la leyenda el rey Sancho las hizo colocar en el escudo de Navarra, en recuerdo de esta gesta.

Fueron mejores sus relaciones con los territorios ultrapirenaicos, donde varios señores se declararon sus vasallos, e incluso firmó un tratado en favor de Juan Sin Tierra (1202), y con los reyes aragoneses Pedro II y Jaime I.
Sancho VII y Jaime I firmaron en Tudela (1231) un tratado de prohijamiento (que no llegó a cumplirse), por el que acordaban que aquel de los dos que sobreviviese al otro, ocuparía el reino sin obstáculos.

Durante los últimos años Sancho VII padeció una enfermedad que supuestamente acabaría con su vida y que fue una úlcera varicosa de la pierna, según su biógrafo. A causa de esta larga y dolorosa enfermedad, Sancho estuvo recluido en su castillo de Tudela, por ello el sobrenombre de Sancho «el Encerrado».

Tuvo un hijo, según la llamada "Crónica del Príncipe de Viana", que a los 15 años sufrió un accidente mortal, consecuencia de una caída de caballo, Sancho se quedó sin hijo legítimo que le sucediese y Navarra sin futuro rey.
El viernes 7 de abril de 1234 falleció Sancho en su castillo tudelano, recibiendo sepultura en la parroquia de San Nicolás de Tudela; aunque dos años después sus restos fueron trasladados a la Real Colegiata de Santa María de Roncesvalles.

A pesar de tener varios hijos ilegítimos, y a pesar de la existencia del pacto de prohijamiento que establecía que Jaime I de Aragón sucedería a Sancho VII, la hermana del monarca difunto, que le representaba oficialmente llevando una cierta regencia durante su enfermedad, retirado en el fortín de Tudela, llamó a su sobrino Teobaldo de Champaña ostentario de la dignidad condal champañesa para heredarle y mantener el poder real en la familia. De este modo, Teobaldo I subió al trono en Tudela el 7 de abril de 1234 dando comienzo en el trono navarro a la dinastía de Champaña finalizando en consecuencia la dinastía Jimena de la que Sancho VII fue su último representante..

Sancho estuvo casado dos veces. La identidad de su segunda esposa es disputada. Su primera esposa era Constanza, hija de Raimundo VI de Tolosa, con quien se casó aproximadamente en 1195. Él más tarde la rechazó y se divorció (1200). Su segunda esposa fue, según algunas fuentes, Clemence, hija de Federico I, el Emperador Sacro Romano. Otras fuentes, sin embargo, nombran a una hija de Abu Yaqub II al-Mustansir, emir de Marruecos. Sin embargo, la crónica de Carlos de Viana reconoce a un hijo que falleció no solo con quince años en un accidente, sino que el padre tenía varios bastardos conocidos: Ferdinand, Guillermo, y Roderick. La maternidad de estos es desconocida.




</doc>
<doc id="45414" url="https://es.wikipedia.org/wiki?curid=45414" title="Peter Senge">
Peter Senge

Peter M. Senge nació en 1947. Se graduó en ingeniería de la Universidad de Stanford. Hizo una maestría en Social Systems Modeling en MIT. Posteriormente completó su doctorado en management. Es el director del centro para el Aprendizaje Organizacional del Instituto Tecnológico de Massachusetts. En 1990 escribe el libro "The Fifth Discipline" donde desarrolla la noción de organización como un sistema (desde el punto de vista de la Teoría General de Sistemas), en el cual expone un dramático cambio de mentalidad profesional.




</doc>
<doc id="45416" url="https://es.wikipedia.org/wiki?curid=45416" title="Desarrollo organizacional">
Desarrollo organizacional

El campo del desarrollo organizacional (DO) trata sobre el desarrollo, funcionamiento y efectividad en las relaciones humanas dentro de una organización 

Se da énfasis al capital humano dinamizando los procesos, creando un estilo y señalando una meta desde la institucionalidad. Además es una herramienta que por medio del análisis interno permite obtener información para guiar o adoptar una estrategia o camino rumbo a un cambio. A través de éste, se logra la eficiencia de todos los elementos que la constituyen y así lograr el éxito que se plantea.

Esto requiere que una organización se encuentre en capacidad o tenga los elementos necesarios para entrar a competir en el mundo actual, convirtiéndose por tanto el DO en una necesidad.
Para utilizar esta herramienta se emplea o se hace uso de un proceso fundamental, como lo es el aprendizaje, que es la vía por la cual se accede al conocimiento adquiriendo destrezas y habilidades produciendo cambios en el comportamiento (eje para el "DO"). Es por esta razón que hay que tener en cuenta los aspectos que influyen en el rendimiento de los elementos que constituyen una organización.

Un bosquejo histórico del desarrollo organizacional explicará la evolución del término, así como algunos de los problemas y la confusión que lo rodea. Tal como se utiliza hoy, el desarrollo organizacional tiene cinco grandes precedentes (raíces):

- Entrenamiento en el laboratorio: Esta raíz del desarrollo organizacional fue la pionera en utilizar el entrenamiento en el laboratorio, llamado también "grupo T": un grupo pequeño e inestructurado cuyos miembros aprenden de su interacción personal y de una dinámica en evolución respecto a cosas como las siguientes: relaciones interpersonales, crecimiento personal, liderazgo y dinámica de grupos.

- Investigación de la acción/Retroalimentación por encuesta: Kurt Lewin participó además en este segundo movimiento que condujo al nacimiento del desarrollo organizacional como un campo práctico de la sociología. Este segundo precedente se refiere a la investigación de la acción y a la retroalimentación por encuesta.

- Enfoques normativos: Los avances intelectuales y prácticos del entrenamiento en el laboratorio y la retroalimentación/ investigación de la acción son antecedentes que se acompañaron con la convicción de que el enfoque de relaciones humanas constituía "una forma óptima" de administrar las empresas.

Según el programa de administración participativa, las empresas tienen uno de los cuatro tipos de sistemas de administración, los cuales son:


- Calidad de la vida laboral: La aportación de este precedente al desarrollo organizacional puede explicarse en dos fases. La primera corresponde a los proyectos diseñados en Europa durante la década de los cincuenta y a su aparición en Estados Unidos una década después de los cincuenta. Con base en la investigación de Eric Trist y sus colegas en el Tavistock Institute of Human Relations de Londres, los pioneros de Gran Bretaña e Irlanda, de Noruega y Suecia prepararon diseños de trabajo tendientes a integrar mejor la tecnología y las personas. Generalmente requería la participación conjunta de sindicatos y directivos para el diseño del trabajo; los diseños finales daban a los empleados gran discrecionalidad, diversidad de tareas y retroalimentación acerca de los resultados. Acaso su característica distintiva de la calidad en el trabajo fue el descubrimiento de la modalidad de los grupos autodirigidos de trabajo. En la segunda definición se le considera como enfoque o método, es decir, se parte de las técnicas y procedimientos con que se mejora el trabajo. Era un sinónimo de métodos como los siguientes: enriquecimiento del trabajo, equipos autodirigidos y comités de administración del trabajo. Tal orientación técnica provenía principalmente de la creciente publicidad dada a los proyectos de calidad de la vida laboral.

- Cambio estratégico: Este precedente ha influido recientemente en la evolución del desarrollo organizacional. A medida que las empresas con su ambiente tecnológico, político y social se han vuelto más complicadas e inciertas, lo mismo ha sucedido con la magnitud y la complejidad del cambio organizacional. Es una tendencia que requiere una perspectiva estratégica y que alienta a ese nivel los procesos del cambio planificado.

Definición del término de Martha Alles

Según Martha Alles, el término Desarrollo Organizacional es el conjunto de acciones organizacionales que se realizan para modificar, usualmente aspectos culturales o de comportamiento organizacional.

Las Herramientas relacionadas con el término



El campo del desarrollo organizativo el cual nació en la primera mitad del siglo XX, ha sido influenciado por muchas personas, incluyendo:


Generalmente, el "DO" va a involucrar a la organización para que el cambio se genere efectivamente, ya que cada una de sus partes de ésta tienen que trabajar en conjunto para resolver los problemas y así aprovechar las oportunidades que surjan de una manera coordinada. Las
El "DO" también se dirige a las interacciones que existen en la organización, ya que si se afecta una parte, afecta a toda. Esto se refiere a las relaciones de trabajo entre personas, así como hacia la estructura y procesos organizacionales. Por eso es primordial que todas las partes trabajen con eficacia. 

Se refiere a aquellas personas que estimulan o coordinan el cambio de un grupo o de la organización. Generalmente es un consultor externo a la empresa, ya que puede operar con independencia y sin estar ligado a jerarquías y políticas.
Se concentra tanto en los problemas reales, como en los superficiales utilizando investigación-acción que es una característica fundamental de la organización. 

Se aprende por medio de la experiencia en un ambiente de capacitación, ya que se les incentiva a los participantes a resolver los problemas humanos que encuentran dentro de su ambiente , además se discute sobre su propia experiencia con el tema y se aprende de ella. 

Aquí se sustentan procesos grupales, tales como discusiones, confrontaciones, conflictos intergrupales y procedimientos para la cooperación, todo esto con el fin de mejorar las relaciones interpersonales, la comunicación, crear confianza y responsabilidad.

Se proporciona retroalimentación en el para que los participantes cuenten con información mediante datos concretos y basados en decisiones, así mismo se proporciona respecto a la conducta y fomenta la comprensión de situaciones en las que se encuentran. 


El "DO" no se basa en procedimientos estrictos y fijos, sino que se adapta a la situación y los problemas de la organización, siempre de una manera flexible enfocando tanto las necesidades específicas como particulares.

El "DO" se basa en construir equipos de trabajo. Hace hincapié en éstos, ya sean grandes o pequeños para la cooperación y la integración. Entonces en esta etapa es donde se enseña a superar las diferencias entre personas para llegar a un fin común.

Algunos temas del desarrollo organizativo son:

El "desarrollo organizacional" también se refiere a:

La mayoría de los consultores en Desarrollo Organizacional "(DO)" coinciden en que el proceso comprende las siguientes etapas:









Hay varias asociaciones profesionales para los practicantes del desarrollo organizativo incluyendo:



</doc>
<doc id="45421" url="https://es.wikipedia.org/wiki?curid=45421" title="Bundesland">
Bundesland

Los términos Bundesland (del alemán "Bund", "federación", y "Land", "país, estado, territorio"; en plural, "Bundesländer") y Land (en plural, "Länder") pueden referirse, en Wikipedia, a los siguientes artículos:





</doc>
<doc id="45425" url="https://es.wikipedia.org/wiki?curid=45425" title="Servidor web">
Servidor web

Un servidor web o servidor HTTP es un programa informático que procesa una aplicación del lado del servidor, realizando conexiones bidireccionales o unidireccionales y síncronas o asíncronas con el cliente y generando o cediendo una respuesta en cualquier lenguaje o aplicación del lado del cliente. El código recibido por el cliente es renderizado por un navegador web. Para la transmisión de todos estos datos suele utilizarse algún protocolo. Generalmente se usa el protocolo HTTP para estas comunicaciones, perteneciente a la capa de aplicación del modelo OSI. El término también se emplea para referirse al ordenador.

Un servidor web opera mediante el protocolo HTTP, de la capa de aplicación del Modelo OSI. Al protocolo HTTP se le asigna habitualmente el puerto TCP 80. Las peticiones al servidor suelen realizarse mediante HTTP utilizando el método de petición GET, en el que el recurso se solicita a través de la URL al servidor web. codice_1

En la barra de URL de un navegador cualquiera, la petición anterior sería análoga a la siguiente dirección web:

codice_2
El navegador, por medio de la interfaz de usuario, permite al usuario realizar una o varias peticiones web. La interfaz de usuario o entorno de usuario es el conjunto de elementos del navegador que permiten realizar la petición de forma activa. Una petición web no solo puede ser realizada mediante un navegador, sino con cualquier herramienta habilitada para tal fin, como una consola de comandos Telnet.

Elementos del entorno de usuario más comunes en navegadores web visuales:
Se produce una codice_3 con un servidor dado en dirección IP mediante TCP. Por lo general las direcciones que el navegador posee inicialmente son direcciones DNS (direcciones alfanuméricas) que deberá convertir a direcciones numéricas.

Si la dirección dada es DNS y no existe una regla en la base de datos DNS, el codice_4 solicita al servidor DNS la o las direcciones IPs correspondientes. El navegador crea una nueva regla y almacena la dirección IP junto a la dirección DNS en su base de datos de reglas DNS me duele el en el año 1999 el 29 de marzo fue fundado wikipedia por giga

Una vez almacenada la regla, se realiza una petición a la base de datos DNS para recuperar los valores de la regla.

Se produce una codice_3 con la dirección IP mediante TCP. La dirección IP puede haberse recuperado en el paso anterior.

Se crea la petición GET estableciendo la url ,un flag ,la priority de la petición y el method (implícitamente GET).

Se abre y/o se crea una entrada en el codice_6.

Se realiza la petición GET. Se leen las cabeceras HTTP de la codice_7 y más tarde el cuerpo de la codice_7.

Se consulta en el caché de disco si existe una entrada en el caché asociada al recurso que se ha solicitado. Los valores son codice_9 ("true" o "false") y codice_10 (la url del recurso).

Si la entrada no existe (si el valor de created es "false") se escriben los datos en el caché de disco. Si no, se lee directamente.

Se concluye la operación y se muestra en pantalla (si es preciso) la información.
Luego de igual forma, comprueba que esté correcta.

Javascript permite realizar modificaciones en el estado del navegador. El estado del navegador viene definido por el array de objetos location del objeto global Window. Se referencia a tal objeto con window.location. En concreto window.location.href contiene la dirección actual del navegador web.

Si una parte del script ejecuta tal sentencia:

codice_11

El navegador hará tal petición web sin que el usuario haya mediado en tal circunstancia o sus efectos. Del mismo modo se producirá una nueva petición GET si se altera el valor de window.location.search o window.location.protocol.

La tarea del navegador web es crear la petición a partir de los datos recogidos en el entorno de usuario de elementos del mismo, como enlaces, el valor del texto de la barra de búsqueda, los metatags.

Al pulsar en el enlace, el navegador crea automáticamente la petición GET y las cabeceras de la petición sobre la base de los metatags (cabeceras definidas), las cookies y cabeceras automáticas del navegador, para luego enviarlas junto a la petición al servidor.

Es el segundo tipo de petición HTTP más utilizado. Los datos a enviar al servidor se incluyen en el cuerpo de la misma petición con las cabeceras HTTP asignadas correspondientemente respecto al tipo de petición. Generalmente se asocia con los formularios web en los que los datos suelen ser cifrados para enviarlos de manera segura al servidor.

Por motivos de convención se incluye en la petición la cabecera codice_12, que indica el formato o codificación de los datos a enviar; esta es "variable->valor" en el formato: codice_13 separada cada par variable->valor por codice_14. Esta cabecera, en los formularios HTML se envía automáticamente, pero en otras tecnologías web tal como AJAX, si se desea hacer correctamente una petición POST, debe ser especificado o instanciado el objeto:
codice_15codice_16

Si se utilizase el método GET los datos deberían de ser añadidos a la URL, lo que los expondría a ser vistos de forma directa.

Las cabeceras más comunes que se envían en una petición POST:

Los datos que se envían en el cuerpo de la petición POST deben tener algún formato que permita manipularlos en un futuro procesamiento. Por ello la petición debe tener asignada la cabecera Content-Type cuyo valor será la codificación de los datos. De este modo el sistema podrá diferenciar entre variables aisladas, datos binarios, texto plano, o cualquier otro tipo de formato. El formato de una cadena de datos se denomina MIME y es el valor que deberá ser incluido en esta cabecera.

En HTML la cabecera Content-Type se especifica automáticamente y su valor es "application/x-www-form-urlencoded", no obstante pueden especificarse por estándar otros dos valores: codice_17 y codice_18 utilizando el atributo codice_19 del elemento codice_20 de la siguiente manera

O cualquier otro valor MIME. El codice_17 se utiliza para enviar grandes cadenas binarias que suponen cualquier otro tipo de documento que no sea texto plano, como imágenes, vídeos o ejecutables. Para varios valores, separar por comas.

El codice_12 codifica de forma automática los valores de todos los elementos del formulario del modo codice_13, separados por codice_14. El atributo codice_25 de un input suele ser el nombre de la variable y su codice_26 el valor. Los espacios se reemplazan por codice_27 y los caracteres no alfanuméricos por codice_28 donde HH representa el número hexadecimal del carácter ASCII.

que representado de otra forma es:

El navegador recopila la información del formulario para crear la petición y enviarla. Las cabeceras las envía junto a la petición POST, y se recopilan sobre la base de los metatags definidos en el código, los automáticos del navegador y las cookies. Es el navegador, también, el que codifica los datos si es necesario. 

El servidor web se ejecuta en un ordenador manteniéndose a la espera de peticiones por parte de un cliente (un navegador web) y responde a estas peticiones adecuadamente, mediante una página web que se exhibirá en el navegador o mostrando el respectivo mensaje si se detectó algún error. A modo de ejemplo, al teclear "www.wikipedia.org" en nuestro navegador, este realiza una petición HTTP al servidor de dicha dirección. El servidor responde al cliente enviando el código HTML de la página; el cliente, una vez recibido el código, lo interpreta y lo exhibe en pantalla. Como vemos con este ejemplo, el cliente es el encargado de interpretar el código HTML, es decir, de mostrar las fuentes, los colores y la disposición de los textos y objetos de la página; el servidor tan sólo se limita a transferir el código de la página sin llevar a cabo ninguna interpretación de la misma.

Además de la transferencia de código HTML, los servidores web pueden entregar aplicaciones web. Estas son porciones de código que se ejecutan cuando se realizan ciertas peticiones o respuestas HTTP. Hay que distinguir entre:
Las aplicaciones de servidor muchas veces suelen ser la mejor opción para realizar aplicaciones web. La razón es que, al ejecutarse ésta en el servidor y no en la máquina del cliente, este no necesita ninguna capacidad añadida, como sí ocurre en el caso de querer ejecutar aplicaciones Javascript o Java. Así pues, cualquier cliente dotado de un navegador web básico puede utilizar este tipo de aplicaciones.

El hecho de que HTTP y HTML estén íntimamente ligados no debe dar lugar a confundir ambos términos. HTML es un lenguaje de marcas y HTTP es un "protocolo".

Una aplicación del lado del servidor es cualquier programa o conjunto de instrucciones diseñadas con la finalidad de que un servidor web las procese para realizar alguna acción. Las aplicaciones del lado del servidor están escritas mediante algún lenguaje de programación, entre los que destacan:

El 75% de las aplicaciones del lado del servidor están escritas en PHP, seguido de ASP y las demás opciones usadas de forma alternativa y muy casual.

Un servidor web tiene la función de procesar los scripts del lado del servidor para dar una salida en HTML y otros lenguajes del lado del cliente al navegador web del cliente. La información a procesar podrá ser cedida por el cliente al script mediante cualquier aplicación en el entorno del navegador. Para ello pueden utilizarse formularios web, enlaces con los valores implícitos en la cadena o cualquier otro método.
En PHP existen variables globales que representan variables y datos de la conexiones que establece el servidor con el cliente.

Contiene todas las variables que se envían a través del método HTTP GET, se referencian a través del array unidimensional codice_29. Esta variable contiene el dato enviado por GET asociado a tal variable, en caso de que exista.

Contiene todas las variables que se envían a través del método HTTP POST, se referencian a través del array unidimensional codice_30. Esta variable contiene el dato enviado por POST asociado a tal variable.

Contiene datos de sesión adquiridos mediante una petición GET, POST o la lectura de una cookie. Se referencia a través del array unidimensional codice_31. Esta variable contiene un dato de sesión.

Contiene datos sobre todas las cookies adquiridas en la petición al servidor, proporcionadas por el navegador en la petición HTTP. Se referencia a través del array unidimensional codice_32.

Contiene datos proporcionados por el servidor web. Se referencia a través del array unidimensional codice_33.

1) Dado el siguiente código PHP:
if(!empty($_GET['ip']){

function ip(){
En el caso anterior, podría tomarse por supuesta la decisión del usuario utilizando un enlace cuyo destino sea el archivo que contenga el script anterior + la variable y el valor utilizando la siguiente sintaxis: codice_34 donde codice_35 es el nombre de una variable dada y codice_36 es valor asignado a la variable.
http://ruta/archivo.php?ip=yes
2) En caso afirmativo, el script anterior genera el siguiente código HTML que es enviado posteriormente al navegador:
<b>Su dirección web es 192.168.0.1 </b>
3) El navegador interpreta el código HTML (PHP Siempre devuelve HTML al navegador) y lo muestra similar a:

Su dirección web es 192.168.0.1

Un servidor web local es aquel servidor web que reside en una red local al equipo de referencia. El servidor web local puede estar instalado en cualquiera de los equipos que forman parte de una red local. Es por tanto obvio, que todos los servidores web, son locales a la red local en la que se encuentran, o como mínimo, locales al sistema en el que están instalados.

Cuando un servidor web se encuentra instalado en el mismo equipo desde el cual se desea acceder puede utilizarse la dirección de Loopback, codice_37 en Ipv4 y codice_38 en Ipv6. El puerto TCP 80 se obvia. Los archivos se almacenan en un directorio determinado por la configuración, generalmente modificable.

Existen numerosas aplicaciones que facilitan la instalación automática de servidores web Apache y aplicaciones adicionales como Mysql y PHP (entre otros), de forma conjunta, como XAMPP, JAMP o EasyPHP. Estas aplicaciones reciben el nombre de LAMP cuando se instalan en plataformas Linux, WAMP en sistemas Windows y MAMP en sistemas Apple Macintosh.

Algunos servidores web importantes son:

Otros servidores, más simples pero más rápidos, son:




</doc>
<doc id="45430" url="https://es.wikipedia.org/wiki?curid=45430" title="Principio de acción">
Principio de acción

En física, el principio de acción es una aserción sobre la naturaleza del movimiento o trayectoria de un objeto o más generalmente la evolución temporal de un sistema físico, sometido a acciones predeterminadas.

De acuerdo con este principio existe una función escalar definida por una integral invariante llamada integral de acción, tal que, sobre la "trayectoria" temporal del sistema, esta función toma valores extremos. Por ejemplo en mecánica clásica la trayectoria real que seguirá una partícula es precisamente aquella que rinde un valor estacionario de la acción. La acción es una magnitud física escalar, representable por un número, con dimensiones de "energía" · "tiempo". El principio es una teoría simple, general, y de gran alcance para predecir el movimiento en todas las áreas de la física. Extensiones del principio de acción describen la mecánica relativista, la mecánica cuántica, el electromagnetismo. 

El principio también se llama principio de acción estacionaria y principio de menor acción o principio de mínima acción (aunque esta forma es menos general y de hecho para ciertos sistemas es incorrecto hablar de mínima acción). Restringido a la mecánica clásica el principio admite una formulación particular conocida como principio de Hamilton.

El principio de menor acción primero fue formulado por Maupertuis en 1746 y después desarrollado (de 1748 en adelante) por los matemáticos Euler, Lagrange, y Hamilton. Maupertuis llegó a este principio por la sensación de que la misma perfección del universo exige cierta economía en la naturaleza y está opuesta a cualquier gasto innecesario de energía. Los movimientos naturales deben usar alguna cantidad al mínimo. Era solamente necesario encontrar esa cantidad, y esto procedió a hacer. Era el producto de la duración (tiempo) del movimiento dentro de un sistema por la "vis viva" (violencia o fuerza viva) o dos veces lo qué ahora llamamos la energía cinética del sistema. Euler (en "Reflexions sur quelques lois générales de la nature.", 1748) adopta el principio de la menor acción, llamando a la cantidad "effort". Su expresión corresponde a lo que ahora llamaríamos energía potencial, de modo que su declaración de menor acción en estática es equivalente al principio de que un sistema de cuerpos en reposo adoptará una configuración que reduzca al mínimo su energía potencial total.

El principio de acción surgió en el contexto de la mecánica clásica, como una generalización de las leyes de Newton. De hecho en sistemas inerciales el principio de mínima acción y las leyes de Newton son equivalentes. Sin embargo, la mayor facilidad para generalizar el principio de acción lo hace preferible en cierto tipo de aplicaciones complejas, lo cual hace que el principio ocupe un papel central en la física moderna. De hecho, este principio es una de las grandes generalizaciones en ciencia física. En particular, se lo aprecia completamente y se lo entiende mejor dentro de la mecánica cuántica o la teoría de campos. La formulación de Feynman de la mecánica cuántica se basa en un principio de acción estacionaria, usando integrales de trayectorias. Las ecuaciones de Maxwell puede ser derivadas como condiciones de una acción estacionaria.
Muchos problemas en física se pueden representar y solucionar en la forma de un principio de acción, tal como encontrar la manera más rápida de descender a la playa para alcanzar a una persona que se ahoga. El agua cayendo por los declives busca la pendiente más escarpada, la manera más rápida de llegar abajo, y agua que corre en una cuenca se distribuye de modo que su superficie sea tan baja como sea posible. La luz encuentra la trayectoria más rápida a través de un sistema óptico (el principio de Fermat de menor tiempo). La trayectoria de un cuerpo en un campo gravitacional (es decir, caída libre en el espacio-tiempo, una, así llamada, geodésica) se puede encontrar usando el principio de acción. 

Las simetrías en una situación física se pueden tratar mejor con el principio de acción, junto con las ecuaciones de Euler-Lagrange que se derivan del principio de acción. Por ejemplo, el teorema de Emmy Noether asigna que toda simetría continua en una situación física corresponde a una ley de conservación. Esta conexión profunda, sin embargo, requiere asumir el principio de acción. 

En mecánica clásica (no-relativista, no cuántica), la elección correcta de la acción puede ser derivada de las leyes de Newton del movimiento. Inversamente, el principio de acción prueba la ecuación de Newton del movimiento dada la elección correcta de la acción. Por tanto en mecánica clásica el principio de acción es equivalente a la ecuación de Newton del movimiento. El uso del principio de acción es a menudo más simple que el uso directo de la ecuación de Newton del movimiento. El principio de acción es una teoría escalar, con derivaciones y aplicaciones que emplean cálculo elemental..

Las leyes de Newton del movimiento se puede establecer de varias maneras alternativas. Una de ellas es el formalismo lagrangiano, también llamada mecánica lagrangiana. Que lo enunciaremos en coordenadas generalizadas, para así poder usar cartesinas, polares o esféricas, según requiera el sistema a tratar. Si denotamos la trayectoria de una partícula en función del tiempo "t" como "q(t)", con una velocidad formula_1, entonces el lagrangiano es una función dependiente de estas cantidades y posiblemente también explícitamente del tiempo: 

la integral de acción "S" es la integral temporal del lagrangiano entre un punto de partida dado formula_2 en el tiempo formula_3 y un punto final dado formula_4 en el tiempo formula_5

En mecánica lagrangiana, la trayectoria de un objeto es derivada encontrando la trayectoria para la cual la integral de acción "S" es estacionaria (un mínimo o un punto de ensilladura). La integral de acción es una funcional (una función dependiendo de una función, en este caso formula_7). 

Para un sistema con fuerzas conservativas (fuerzas que se pueden describir en términos de un potencial, como la fuerza gravitacional y no como las fuerzas de fricción), la elección de un lagrangiano como la energía cinética menos la energía potencial da lugar a las leyes correctas de la mecánica de Newton (notar que la "suma" de la energía cinética y la potencial es la energía total del sistema).

El punto estacionario de una integral a lo largo de una trayectoria es equivalente a un sistema de ecuaciones diferenciales, llamado las ecuaciones de Euler-Lagrange. Esto puede ser visto como sigue donde nos restringimos a un coordenada solamente. La extensión a más coordenadas es sencillo. 

Suponga que tenemos una integral de acción "S" de un integrando "L" que depende de las coordenadas formula_8 y formula_9, sus derivadas con respecto a "t":

considera una segunda curva formula_10 que comience y termine en los mismos puntos que la primera curva, y asume que la distancia entre las dos curvas es pequeña por todas partes:
formula_11 es pequeño. 
En el comienzo y en el punto final tenemos formula_12.

La diferencia entre los integrales a lo largo de la curva uno y a lo largo de la curva dos es:

donde hemos utilizado la primera extensión de la orden de "L" en ε y formula_13. 
Ahora utilice la integración parcial en el término pasado y utilice las condiciones formula_14 para encontrar:

"S" alcanza un punto estacionario (un extremo), es decir. δ"S" = 0 para cada ε. Observe que éste es el único requisito: el extremo podía ser un mínimo, punto de ensilladura o igual formalmente a un máximo. δ"S" = 0 para cada ε si y solamente si 

donde hemos substituido formula_15 por formula_16, puesto que esto debe valer para cada coordenada. Este sistema de ecuaciones se llama las ecuaciones de Euler-Lagrange para el problema variacional. Una consecuencia simple importante de estas ecuaciones es que si "L" no contiene explícitamente la coordenada "x", es decir, 

Tal coordenada "x" se llama una coordenada cíclica de "S", y formula_19 

se llama el "momento conjugado", que se conserva. Por ejemplo si "L" no depende del tiempo, la constante asociada del movimiento (el momento conjugado) se llama la energía. Si utilizamos coordenadas esféricas "t", "r", φ, θ y "L" no dependen de φ, el momento conjugado son el momento angular (conservado).

Ejemplos triviales ayudan a apreciar el uso del principio de acción "vía" las ecuaciones Euler-Lagrange. Una partícula libre (masa "m" y velocidad "v") en un espacio euclidiano se mueve en una línea recta. Usando las ecuaciones de Euler-Lagrange, esto puede ser demostrado en coordenadas polares como sigue. En ausencia de un potencial, el lagrangiano es simplemente igual a la energía cinética formula_20 en formula_21 coordenadas ortonormales, donde el punto representa la diferenciación con respecto al parámetro de la curva (generalmente el tiempo "t"). En coordenadas polares ("r", φ) la energía cinética y por lo tanto el lagrangiano se convierte en
los componentes radiales de formula_23 de las ecuaciones Euler-Lagrange se convierten, respectivamente en

que la solución de estas dos ecuaciones se da

para un sistema de las constantes formula_26 determinado por condiciones iniciales. Así, de hecho, "la solución es una línea recta" dada en coordenadas polares.

En el caso n-dimensional la acción asociada a un campo físico formula_27 el lagrangiano es una densidad sobre el espacio n-dimensional, y por tanto la acción es una integral sobre un dominio n-dimensional:

Dadas ciertas condiciones de contorno sobre el borde de una región formula_28, entonces las ecuaciones del movimiento vienen dadas por las ecuaciones de Euler-Lagrange:

Incidentalmente, el lado izquierdo es la derivada funcional de la acción con respecto a formula_29.

Los formalismos arriba son válidos en la mecánica clásica en un sentido muy restrictivo del término. Más generalmente, una acción es una funcional del espacio de configuración a los números reales y en general, no necesita ser necesariamente siquiera una integral porque las acciones no locales son posibles. El espacio de configuración no necesita ser necesariamente un espacio funcional porque podríamos tener cosas como geometría no conmutativa.


Para una bibliografía anotada, considera Edwin F. Taylor



</doc>
<doc id="45437" url="https://es.wikipedia.org/wiki?curid=45437" title="Straight edge">
Straight edge

Straight edge es un estilo de vida y un movimiento que se inició dentro de la subcultura del "hardcore punk" en el cual sus seguidores hacen un compromiso de por vida para abstenerse de beber alcohol, fumar tabaco y consumir drogas. En algunos casos, esto se extiende también a ser vegano y a la abstención de la promiscuidad. Fue una reacción directa a la autodestrucción y el hedonismo del punk. El término fue tomado de la canción del mismo nombre de la banda Minor Threat.

Comúnmente portado como una marca en el dorso de ambas manos, el símbolo de la X puede ser mostrado también en otras partes del cuerpo, y algunos seguidores han incorporado el símbolo en ropa y pines.

De acuerdo con la serie de entrevistas realizadas por el periodista Michael Azerrad, la X del "straight edge" data de la gira de la agrupación Teen Idles por la costa oeste de Estados Unidos en 1980. Teen Idles estaban programados para tocar en el Mabuhay Gardens en San Francisco, California, pero cuando la banda llegó, el gerente del club descubrió que todos los miembros eran menores de 21 años, edad requerida para beber legalmente en Estados Unidos, por lo cual se les debería prohibir la entrada al club. A manera de compromiso, la gerencia marcó a cada uno de los miembros con una X negra en las manos para advertir al personal del club que no sirviera alcohol a los músicos. Al regresar a Washington D.C., la banda sugirió el mismo sistema a los clubes locales para permitir a los jóvenes asistir a los conciertos sin la necesidad de servirles alcohol y pronto la marca fue asociada con el estilo de vida "straight edge". 

Una variante se convirtió en un trío de X —xXx—, originado por el diseño creado por el baterista Jeff Nelson de Minor Threat, en el cual reemplazó las tres estrellas en la bandera de Washington D.C. por tres letras X. El término a veces es acortado agregando una X en la abreviación del término «"straight edge"» —sXe—. La X también se puede utilizar para relacionar el nombre de una persona o banda con el "straight edge", por ejemplo, la banda xFilesx.

Según William Tsitsos, el "straight edge" ha pasado por tres diferentes eras desde su creación en 1980.

Ejemplos de lo que se pudiera considerar canciones proto-"straight-edge" son las canciones «Keep it Clean» de la banda inglesa The Vibrators. Un ejemplo adicional es el tema «I'm Straight» del cantante y compositor Jonathan Richman y la banda The Modern Lovers, en el cual, expresaba rechazo al uso de drogas. Los primeros indicios del "straight edge" en el hardcore se pueden encontrar en las letras de la banda Minor Threat, ejemplos son los temas «Straight Edge», «In My Eyes» y «Out of Step», por lo cual el "straight edge" es relacionado con el "punk rock", particularmente con el "hardcore". Los seguidores de esta temprana época manifestaban los ideales originales del punk, tales como individualismo, rechazo al trabajo y la escuela y actitudes sobre vivir el momento. 

Aunque el "straight edge" empezó en la costa este de Estados Unidos en Washington D.C. y Nueva York, se extendió rápidamente por Estados Unidos y Canadá. Alrededor de los 80, bandas de la costa oeste de Estados Unidos, tales como Stalag 13, Justice League y Uniform Choice ganaban popularidad. Al inicio de esta subcultura, las presentaciones incluían bandas "straight edge" y bandas que no se consideraban como tal, sin embargo, las circunstancias cambiaron, y la era "old school" seria vista eventualmente como la época «antes de que las dos escenas se separaran». Bandas de la era Old School del straight edge incluyen a Minor Threat, State of Alert —mejor conocidos como S.O.A.—, Government Issue y Teen Idles de Washington, D.C; 7 Seconds de Reno Nevada; SSD, DYS y Negative FX de Boston (o Boston Crew); Stalag 13, Justice League y Uniform Choice de California.

Durante la era "youth crew", que empezó a mediados de los 80, las nuevas ramas del "straight edge" que aparecieron durante esta época originaron ideas presentadas en canciones. Bandas importantes del "youth crew" incluyen a Gorilla Biscuits, Judge, Bold, Youth of Today, Chain of Strength, 7 Seconds, Slapshot, Turning Point y Insted 

La banda Youth of Today y su canción «Youth Crew» expresó el deseo de unir la escena en un movimiento. La temática más notable que surgió durante esta época fue la relación entre el "straight edge" y el vegetarianismo, tal es el caso del tema «No More» del álbum "We're Not in This Alone" de 1988, que iniciaría una tendencia hacia los derechos de los animales y veganismo dentro del "straight edge", y alcanzaría su cima en la década de los 90 y probablemente es su tendencia más extendida.

A inicios de los 90, los militantes "straight edge" eran una presencia conocida en la escena. El término militante se refiere a alguien que es dedicado y habla abiertamente sobre sus políticas personales, pero también se asume que es de mente cerrada, prejuicioso y potencialmente violento. El militante "straight edge" fue caracterizado por menos tolerancia a las personas que no comparten la filosofía "straight edge", más expresivos en cuanto al orgullo de ser "straight edge" y la disposición de recurrir a la violencia para promover una vida limpia.

También fue alrededor de esta época que el veganismo se volvió parte importante en las vidas de varias personas "straight edge", lo cual fue reflejado por bandas como Birthright, Earth Crisis, Path of Resistance, que promovían mensajes sobre militancia "straight edge" y derechos de los animales.

A mediados de los 90, varias bandas apoyaban mensajes sobre justicia social, liberación animal, veganismo e incluso mensajes contra el aborto. Bandas de esta época incluyen a Mouthpiece, Culture, Earth Crisis, Chorus of Disapproval, Undertow, Strife reconocidas por su constante lucha lo que se reflejaba en las letras de sus canciones. 

En América Latina desde los 80 había bandas con integrantes o temas "straight edge" como Atoxxxico en México o Gx3 en Perú.

En los 2000, bandas straight edge y aquellas que no se relacionan con la subcultura, han compartido escenarios de manera regular, al igual que los seguidores que asisten a dichos eventos. Algunas de las bandas de esta época incluyen a xAlguna Vez Fui Ciegox, Its Now de México; Allegiance, The First Step, Have Heart, Righteous Jams, Violation; En Colombia bandas como xresgestaex y XliberacionX. En España se encuentran bandas como The Defense de Barcelona o Habeas Corpus con su tema «Actitud libre y sana». En Argentina xNueva Eticax. En Chile entrefuego, entre otras.

En Hispanoamérica los postulados del "straight edge" se viven de una manera mucho menos intolerante y excluyente que como sucedió durante la primera década del . Dentro de los múltiples cambios cabe señalar la aceptación de las bebidas con cafeína. La mayoría de los músicos que se identifican a sí mismo con esta postura tocan en bandas con miembros que no son abstemios, como Contra Todos Mis Miedos de Chile. Aunque sí existen bandas "straight edge" como MGX, de Argentina, xACTUARx y Billy The Kid, en Costa Rica, REAXION, de El Salvador, Revival, de Colombia, e incluso completamente "vegan straight edge" como Asunto, de Chile.

Apareció una interpretación aislada del "straight edge" mucho más crítica e incluso de confrontación, que se mostraba crítica e incluso hostil hacia las personas que consumen alcohol, tabaco, drogas, fuman en lugares públicos, se comportaban de forma supuestamente desordenada a partir de costumbres ebrias. Esta línea se conoce como "hardline" (línea dura).

La tendencia "hardline" fue adoptada por algunos "straight edgers" críticos con personas que no siguieran su ideología, tuvieran costumbres promiscuas, se drogasen, bebieran alcohol o fumaran cualquier tipo de droga, incluso tabaco.

Dentro del "straight edge" se les conoce como «milicianos».

El ecologismo y el veganismo enriquecieron el discurso de la subcultura del punk, pero el respeto por los derechos de los animales se ha convertido a menudo en un tema hegemónico en la subcultura. 

Bandas representativas serían Earth Crisis, de forma más relevante; y a día de hoy, xMostomaltax y Nueva Ética en América latina, xRepentancex en UK, entre otras.





</doc>
<doc id="45443" url="https://es.wikipedia.org/wiki?curid=45443" title="Músculo tensor de la fascia lata">
Músculo tensor de la fascia lata

El músculo tensor de la fascia lata ("Musculus tensor fasciae latae") es un músculo que se encuentra en la parte superior y lateral del muslo, de forma aplanada y delgada.

Su inserción proximal (origen) está ubicado en el 1/3 anterolateral de la cresta ilíaca, espina ilíaca anterosuperior.
Su inserción distal: este músculo se continúa a través del Tracto Iliotibial el cual se inserta en el tubérculo lateral de la tibia ("tubérculo de Gerdy"), tiene expansiones hacia la rótula.

Es, como indica su nombre, tensor de la fascia lata. Abduce y rota medialmente al muslo, inclina la pelvis en algunos casos puede llegar a ser extensor de la rodilla. Además, contribuye ligeramente a la flexión de la articulación de la cadera.

Para estirar el tensor de la fascia lata conviene flexionar un poco el tronco hacia delante y dejar atrás la pierna que queremos estirar. Esta queda totalmente recta y cruzada por atrás, en tijera, hasta sentir la tensión en el inicio de la fascia, cerca de la cabeza del fémur, en la articulación de la cadera e incluso más arriba. Mantener hasta treinta segundos. Sin dolor y sin movimiento alguno. También se puede estirar en posición supina, realizando una elevación con la pierna recta y desde esta posición llevar la extremidad hacia la zona medial del cuerpo.

Lo inerva el nervio glúteo superior (L5,S1).


</doc>
<doc id="45450" url="https://es.wikipedia.org/wiki?curid=45450" title="Patología">
Patología

La patología es la rama de la medicina encargada del estudio de las enfermedades. De forma más específica, esta disciplina se encarga del estudio de los cambios estructurales bioquímicos y funcionales que subyacen a la enfermedad en células, tejidos y órganos. La patología utiliza herramientas moleculares, microbiológicas, inmunológicas y morfológicas para tratar de explicar la etiología y manifestaciones clínicas (signo y síntoma) que presentan los pacientes, al tiempo que propone bases racionales para el tratamiento y profilaxis. Suele considerarse como el enlace entre las ciencias básicas y las ciencias clínicas.

Por convención, la patología suele dividirse para su estudio en dos grandes ramas: la patología general, que se ocupa de las reacciones de las células y tejidos frente a estímulos anormales y defectos genéticos; y la patología sistémica, que analiza las alteraciones de órganos y tejidos especializados.

La palabra patología significa ‘estudio de la enfermedad’, y se origina del griego, específicamente de las raíces etimológicas πάθος ("pathos"), que significa ‘enfermedad’ y λογία ("loguía"), que significa ‘estudio’ o ‘tratado’. El término MeSH lo define como:

La patología no debe confundirse con la nosología, que es la descripción y sistematización de las enfermedades.

Las palabras "patología" o "patologías" no son sinónimos de "enfermedad" o "enfermedades", ya que hacen referencia a una ciencia, y no al nombre de las enfermedades. Ejemplos: es incorrecto "patologías inflamatorias", lo correcto es "enfermedades inflamatorias"; es incorrecto "patología neuronal", lo correcto es "enfermedad neuronal".

El conocimiento de la patología ("pathos" o "πάθος" = dolor, dolencia o enfermedad) procede de muy antiguo. 
Desde el principio quedó englobado en el concepto de medicina ("mederis" = curar).

Al principio los procesos morbosos se atribuían a causas o influjos sobrenaturales y se "curaba" mediante la magia, correspondiendo ejercitarla a los sacerdotes entre los babilonios, persas, egipcios, indios, israelitas, griegos y romanos.

Los conceptos de patología y de terapéutica se englobaban en el de medicina. La medicina animal, por su parte, era practicada empíricamente por los pastores.

Posteriormente, la patología empezó a apoyarse en bases biológicas y filosóficas. Aristóteles e Hipócrates adquirieron sus conocimientos básicos de patología estudiando sobre los animales y sobre sus enfermedades. Hipócrates de Cos formuló el primer concepto de enfermedad al exponer sus ideas de crasis y discrasia en la mezcla de los cuatro humores cardinales, componentes del organismo vivo (doctrina de los cuaterniones): sangre, pituitaria, bilis y atrabilis.

Entre los griegos, los buiatras e hipiatras estaban solo dedicados a la patología animal. De enfermedades de los animales trataron Jenofonte, Catón el Viejo ("De Agri Cultura"), Virgilio y Columela. Este último, Columela, fue el primero en usar la palabra "veterinario".

En Roma, en patología animal, destacaron Aspirtos y Vegetius ("Digesta Artis Mulomedicinae", tratado de veterinaria sobre las enfermedades de caballos y mulos).

Galeno en el siglo II crea la Medicina como cuerpo de doctrina, la sistematiza y la divide en:
Este enfoque se mantendría durante toda la Edad Media.

Entre los árabes el nombre para la medicina animal, que perduró en la península ibérica hasta el siglo XIX, era "albeitería" y el de "albéitar" para "veterinario".

Nace durante el Renacimiento, gracias a los trabajos de exploración y descripción del organismo humano realizados por anatomistas como Andreas Vesalius, Antonio Benivieni, pionero de la anatomía patológica, y otros.

Francisco de la Reyna (s. XVI), protoalbéitar español, descubrió la circulación de la sangre antes que Servet la circulación pulmonar y que Harvey la gran circulación.

Al irrumpir la filosofía en la patología (vitalistas y mecanicistas) se originan abstracciones que dan lugar al concepto actual de "Patología General".

Se inicia con la invención del microscopio. Uno de los primeros exponentes de esta etapa fue Xavier Bichat.

Aparece la "Patología Clínica", basada en la observación de los hechos; esta se divide en:
Ambas tienden a fundirse actualmente en la "Fisiología constitucional", que considera como unidad vital al individuo entero.

Desde el punto de vista físico-químico, Heinrich Schade creó su "Patología molecular" ("Molekularpathologie" 1935).

Hay una "Patología comparada", que estudia, de modo comparativo, la patología en las distintas especies animales no humanos y en el hombre.

La práctica de la "Patología Veterinaria" se ha extendido a todas las especies domésticas: vacuno, pequeños rumiantes, équidos, cerdo, carnívoros, roedores, aves, peces y, también, a insectos, anfibios y reptiles, tanto desde el punto de vista económico, como del de lujo, compañía, deportivo, conservacionista o del educativo.

Los conceptos actuales de "patología" pueden tener un enfoque:

El proceso patológico está compuesto de cuatro aspectos principales: etiología, patogenia, cambios morfológicos (alteraciones morfológicas) y manifestaciones clínicas (alteraciones funcionales). La base de este razonamiento fue introducida por Rudolf Virchow, el padre de la patología moderna, en el siglo XIX quien afirmaba que "Todas las formas de la enfermedad son el resultado final de las alteraciones moleculares o estructurales de la célula".

La etiología se refiere a las causas de la enfermedad. El concepto de que ciertos síntomas o enfermedades son "causados" tiene una antigüedad reconocible. Los acadios, hace más de 2500 años, consideraban que la enfermedad era el resultado de los pecados del paciente.

Las causas etiológicas suelen dividirse en genéticas y adquiridas. En la historia de la medicina han existido varios modelos acerca de las causas de la enfermedad, entre los que destacan los modelos unifactoriales (un solo agente causal) y los multifactoriales (varias condiciones favorecen el desarrollo de la enfermedad).

La patogenia es la secuencia de acontecimientos que constituyen la respuesta de las células o los tejidos ante un agente etiológico, desde el estímulo inicial hasta la expresión final de la enfermedad.
Este aspecto de la patología suele considerarse el más importante ya que estudia las relaciones entre los agentes etiológicos y la fisiología.

Los cambios morfológicos son las alteraciones estructurales de tejidos o células que caracterizan a una enfermedad o permiten diagnosticar un proceso etiológico.

Las manifestaciones clínicas son la expresión de las alteraciones genéticas, bioquímicas y estructurales de las células y tejidos y que condicionan su evolución.

Los patólogos pueden ser anatomopatólogos o patólogos clínicos. Los anatomopatólogos se dedican al diagnóstico basado en la observación morfológica de lesiones, principalmente a través de la microscopía de luz, utilizando diversos tipos de tinciones.
Los patólogos clínicos se dedican al diagnóstico a través de los análisis propios del laboratorio clínico, e incluye hematología analítica, inmunología diagnóstica, microbiología diagnóstica, bioquímica o química clínica, citogenética y genética molecular.



</doc>
<doc id="45451" url="https://es.wikipedia.org/wiki?curid=45451" title="Sabrina">
Sabrina

Sabrina puede referirse a:


Así, algunos ejemplos son:




</doc>
<doc id="45455" url="https://es.wikipedia.org/wiki?curid=45455" title="Inmunización">
Inmunización

La inmunización, es el proceso por el cual el sistema inmunológico de un individuo se fortalece contra un agente (conocido como el inmunógeno).

Cuando este sistema se expone a moléculas extrañas al cuerpo, llamadas "no propias", orquestará una respuesta inmunológica, y también desarrollará la capacidad de responder rápidamente a un encuentro posterior debido a la memoria inmunológica. Esta es una función del sistema inmunológico adaptativo. Por lo tanto, al exponer a un animal a un inmunógeno de manera controlada, su cuerpo puede aprender a protegerse: esto se llama inmunización activa.

Los elementos más importantes del sistema inmunológico que se mejoran con la inmunización son las células T, las células B y los anticuerpos que producen las células B. Las células B de memoria y las células T de memoria son responsables de una rápida respuesta a un segundo encuentro con una molécula extraña. La inmunización pasiva es la introducción directa de estos elementos en el cuerpo, en lugar de la producción de estos elementos por el propio cuerpo.

La inmunización se realiza a través de varias técnicas, la más común es la vacunación. Las vacunas contra los microorganismos que causan enfermedades pueden preparar el sistema inmunológico del cuerpo, ayudando así a combatir o prevenir una infección. El hecho de que las mutaciones puedan hacer que las células cancerosas produzcan proteínas u otras moléculas conocidas por el cuerpo constituye la base teórica de las vacunas terapéuticas contra el cáncer. Otras moléculas pueden utilizarse también para la inmunización, por ejemplo, en las vacunas experimentales contra la nicotina (NicVAX) o la hormona grelina en los experimentos para crear una vacuna contra la obesidad.

A menudo se afirma ampliamente que las inmunizaciones son menos arriesgadas y una forma más fácil de hacerse inmune a una enfermedad particular que arriesgarse a una forma más leve de la propia enfermedad. Son importantes tanto para los adultos como para los niños, ya que pueden protegernos de las muchas enfermedades que existen. La inmunización no solo protege a los niños contra enfermedades mortales, sino que también ayuda a desarrollar el sistema inmunológico de los niños. Mediante el uso de vacunas, algunas infecciones y enfermedades han sido casi completamente erradicadas en los Estados Unidos y en el mundo. Un ejemplo es la polio. Gracias a los dedicados profesionales de la salud y a los padres de los niños que se vacunaron en el plazo previsto, la poliomielitis ha sido eliminada en los Estados Unidos desde 1979. La polio todavía se encuentra en otras partes del mundo, por lo que ciertas personas podrían estar aún en riesgo de contraerla. Esto incluye a aquellas personas que nunca se han vacunado, las que no recibieron todas las dosis de la vacuna o las que viajan a zonas del mundo donde la polio todavía está presente.

La inmunización/vacunación activa ha sido nombrada uno de los "Diez Grandes Logros de la Salud Pública en el Siglo XX".

Antes de la introducción de las vacunas, las personas sólo podían ser inmunes a una enfermedad infecciosa contrayendo la enfermedad y sobreviviendo a ella. La viruela fue prevenida de esta manera por la inoculación, que produjo un efecto más leve que la enfermedad natural. La primera referencia clara a la inoculación de la viruela fue hecha por el autor chino Wan Quan (1499-1582) en su Douzhen xinfa (痘疹心法) publicada en 1549. En China, las costras de la viruela en polvo se volaban por la nariz de los sanos. Los pacientes desarrollaban un caso leve de la enfermedad y desde entonces eran inmunes a ella. La técnica tenía una tasa de mortalidad del 0,5-2,0%, pero era considerablemente menor que la tasa de mortalidad del 20-30% de la propia enfermedad. La Royal Society de Londres recibió dos informes sobre la práctica china de la inoculación en 1700; uno del Dr. Martin Lister, que recibió un informe de un empleado de la Compañía de las Indias Orientales con sede en China, y otro de Clopton Havers. Según Voltaire (1742), los turcos derivaron su uso de la inoculación de la vecina Circassia. Voltaire no especula sobre de dónde derivaron los circasianos su técnica, aunque informa que los chinos la han practicado "estos cien años". Fue introducida en Inglaterra desde Turquía por Lady Mary Wortley Montagu en 1721 y utilizada por Zabdiel Boylston en Boston ese mismo año. En 1798 Edward Jenner introdujo la inoculación con la viruela de la vaca (vacuna contra la viruela), un procedimiento mucho más seguro. Este procedimiento, conocido como vacunación, reemplazó gradualmente a la inoculación de viruela, ahora llamada variolación para distinguirla de la vacunación. Hasta el decenio de 1880 la vacuna/vacunación se refería únicamente a la viruela, pero Louis Pasteur desarrolló métodos de inmunización para el cólera de las gallinas y el ántrax en los animales y para la rabia humana, y sugirió que los términos vacuna/vacunación se ampliaran para abarcar los nuevos procedimientos. Esto puede causar confusión si no se tiene cuidado de especificar qué vacuna se utiliza, por ejemplo, la vacuna contra el sarampión o la vacuna contra la gripe.

La inmunización puede lograrse de manera activa o pasiva: la vacunación es una forma activa de inmunización.

La inmunización activa puede ocurrir naturalmente cuando una persona entra en contacto con, por ejemplo, un microbio. El sistema inmunológico eventualmente creará anticuerpos y otras defensas contra el microbio. La próxima vez, la respuesta inmunológica contra este microbio puede ser muy eficiente; este es el caso en muchas de las infecciones infantiles que una persona sólo contrae una vez, pero luego es inmune.

La inmunización activa artificial consiste en inyectar el microbio, o partes de él, en la persona antes de que pueda asimilarlo de forma natural. Si se usan microbios enteros, son pretratados.

La importancia de la inmunización es tan grande que los Centros Americanos para el Control y la Prevención de Enfermedades la han nombrado uno de los "Diez Grandes Logros de la Salud Pública en el Siglo XX".
Las vacunas vivas atenuadas han disminuido la patogenicidad. Su eficacia depende de la capacidad del sistema inmunológico para replicarse y provoca una respuesta similar a la de una infección natural. Por lo general, es eficaz con una sola dosis. Ejemplos de vacunas vivas atenuadas incluyen el sarampión, las paperas, la rubéola, la SPR, la fiebre amarilla, la varicela, el rotavirus y la gripe (LAIV).

La inmunización pasiva consiste en transferir a una persona los elementos presintetizados del sistema inmunitario para que el cuerpo no tenga que producirlos por sí mismo. Actualmente, los anticuerpos pueden ser usados para la inmunización pasiva. Este método de inmunización comienza a funcionar muy rápidamente, pero es de corta duración, porque los anticuerpos se descomponen de forma natural, y si no hay células B para producir más anticuerpos, éstos desaparecerán.

La inmunización pasiva se produce fisiológicamente, cuando los anticuerpos se transfieren de la madre al feto durante el embarazo, para proteger al feto antes y poco después del nacimiento.

La inmunización pasiva artificial se suele administrar por inyección y se utiliza si ha habido un brote reciente de una enfermedad determinada o como tratamiento de emergencia para la toxicidad, como en el caso del tétanos. Los anticuerpos pueden producirse en animales, lo que se denomina "terapia con suero", aunque hay una gran posibilidad de que se produzca un choque anafiláctico debido a la inmunidad contra el propio suero animal. Por lo tanto, en su lugar se utilizan anticuerpos humanizados producidos "in vitro" por cultivo celular, si están disponibles.

Las inmunizaciones imponen a la sociedad lo que se conoce como una externalidad de consumo positiva. Además de proporcionar al individuo protección contra ciertos antígenos, añade una mayor protección a todos los demás individuos de la sociedad a través de la inmunidad de la manada. Debido a que esta protección extra no se tiene en cuenta en las transacciones de mercado de las inmunizaciones, vemos una infravaloración del beneficio marginal de cada inmunización. Este fallo de mercado se debe a que los individuos toman decisiones basadas en su beneficio marginal privado en lugar del beneficio marginal social. La infravaloración de las inmunizaciones por parte de la sociedad significa que a través de las transacciones normales de mercado terminamos con una cantidad inferior a la que es socialmente óptima.

Por ejemplo, si el individuo A valora su propia inmunidad a un antígeno en 100 dólares pero la inmunización cuesta 150 dólares, el individuo A decidirá no recibir la inmunización. Sin embargo, si el beneficio añadido de la inmunidad de rebaño significa que la persona B valora la inmunidad de la persona A en 70 dólares, entonces el beneficio marginal social total de su inmunización es de 170 dólares. Si el beneficio marginal privado del individuo A es menor que el beneficio marginal social, se produce un consumo insuficiente de inmunizaciones.

El hecho de que los beneficios marginales privados sean inferiores a los beneficios marginales sociales siempre llevará a un consumo insuficiente de cualquier bien. La magnitud de la disparidad está determinada por el valor que la sociedad atribuye a cada una de las diferentes inmunizaciones. Muchas veces, las inmunizaciones no alcanzan una cantidad socialmente óptima lo suficientemente alta como para erradicar el antígeno. En cambio, alcanzan una cantidad social que permite una cantidad óptima de individuos enfermos. La mayoría de las enfermedades comúnmente inmunizadas en los Estados Unidos todavía tienen una presencia pequeña con brotes ocasionales más grandes. El sarampión es un buen ejemplo de una enfermedad cuyo óptimo social deja suficiente espacio para brotes en los Estados Unidos que a menudo conducen a la muerte de un puñado de individuos.

También hay ejemplos de enfermedades tan peligrosas que el óptimo social terminó con la erradicación del virus, como la viruela. En estos casos, el beneficio social marginal es tan grande que la sociedad está dispuesta a pagar el costo para alcanzar un nivel de inmunización que hace imposible la propagación y la supervivencia de la enfermedad.

A pesar de la gravedad de ciertas enfermedades, el costo de la inmunización frente al beneficio social marginal significa que la erradicación total no siempre es el objetivo final de la inmunización. Aunque es difícil decir exactamente dónde está el resultado socialmente óptimo, sabemos que no es la erradicación de todas las enfermedades para las que existe una inmunización.

Para internalizar la externalidad positiva impuesta por las inmunizaciones deben hacerse pagos iguales al beneficio marginal. En países como los Estados Unidos estos pagos suelen hacerse en forma de subsidios del gobierno. Antes de 1962, los programas de inmunización en los Estados Unidos se llevaban a cabo a nivel local y estatal. La inconsistencia de los subsidios hizo que algunas regiones de los Estados Unidos alcanzaran la cantidad socialmente óptima, mientras que otras regiones se quedaron sin subsidios y permanecieron en el nivel de beneficio marginal privado de las inmunizaciones. Desde 1962 y la Ley de asistencia para la vacunación, los Estados Unidos en su conjunto han ido avanzando hacia el resultado socialmente óptimo en mayor escala. A pesar de los subsidios del gobierno es difícil saber cuándo se ha alcanzado el óptimo social. Además de las dificultades que determinan el verdadero beneficio marginal social de las inmunizaciones vemos movimientos culturales que cambian las curvas de beneficios marginales privados. Las controversias sobre las vacunas han cambiado la forma en que algunos ciudadanos privados ven el beneficio marginal de ser inmunizados. Si el individuo A cree que existe un gran riesgo para la salud, posiblemente mayor que el propio antígeno, asociado a la inmunización, no estará dispuesto a pagar o a recibir la inmunización. Con menos participantes dispuestos y un beneficio marginal cada vez mayor, alcanzar un óptimo social se hace más difícil para los gobiernos mediante subvenciones.

Además de la intervención del gobierno mediante subvenciones, las organizaciones sin fines de lucro también pueden hacer avanzar a una sociedad hacia el resultado socialmente óptimo proporcionando inmunizaciones gratuitas a las regiones en desarrollo. Sin la capacidad de costear las inmunizaciones para empezar, las sociedades en desarrollo no podrán alcanzar una cantidad determinada por los beneficios marginales privados. Mediante la ejecución de programas de inmunización, las organizaciones pueden hacer que las comunidades privadas subinmunizadas avancen hacia el óptimo social.




</doc>
<doc id="45456" url="https://es.wikipedia.org/wiki?curid=45456" title="Retina">
Retina

La retina de los vertebrados es un tejido sensible a la luz situado en la superficie interior del ojo. Es similar a una tela donde se proyectan las imágenes. La luz que incide en la retina desencadena una serie de fenómenos químicos y eléctricos que finalmente se traducen en impulsos nerviosos que son enviados hacia el cerebro a través del nervio óptico.

La retina tiene una estructura compleja. Está formada básicamente por varias capas de neuronas interconectadas mediante sinapsis. Las únicas células sensibles directamente a la luz son los conos y los bastones. La retina humana contiene 6.5 millones de conos y 120 millones de bastones. Los bastones funcionan principalmente en condiciones de baja luminosidad y proporcionan la visión en blanco y negro, los conos, sin embargo, están adaptados a las situaciones de mucha luminosidad y proporcionan la visión en color.

El nombre retina es el diminutivo de la palabra en latín "rete" que significa ‘red’, ya que quien la descubrió, Herófilo de Calcedonia, la describió como una pequeña red.

La retina procede de una evaginación bilateral del prosencéfalo llamada "vesícula óptica primaria", que tras una invaginación local se transforma en la "vesícula óptica secundaria" con forma de copa. Cada "copa óptica" permanece conectada con el cerebro mediante un tallo, el futuro nervio óptico. En el adulto, la retina está formada por una capa epitelial pigmentada externa, el epitelio pigmentario, y una lámina interna, la retina neural o retina propiamente dicha, que contiene elementos semejantes a los del cerebro, por lo que puede considerarse como una parte especialmente diferenciada del sistema nervioso central.

La retina es una capa delgada y parcialmente transparente, está en contacto con la cara interna de la
coroides y con el humor vítreo. En su superficie se pueden observar diversas estructuras:


También puede dividirse macroscópicamente en dos zonas:

La retina contiene diez capas paralelas que son, comenzando por la zona más superficial, hasta la más interna:

La retina tiene tres tipos de células:




A fines del siglo XIX e inicios del siglo XX el español Santiago Ramón y Cajal hizo cortes histológicos de la retina y observándolos en la platina de un microscopio óptico describió los principales tipos de células que la componen: fotorreceptoras, células bipolares, células horizontales, células amacrinas y células ganglionares. En 1952 el alemán Stephen Kuffler estudiando la visión nocturna de los gatos registró la presencia y actividad de células ganglionares que reaccionan individualmente a los estímulos luminosos e incluso a la falta de luz. En el 2007 King-Wai Yau detectó la presencia de células ganglionares planas en las retinas de peces. Es de notar que muchos animales de hábitos nocturnos (felinos, cánidos, peces predadores como los tiburones, peces abisales, etc.) poseen una estructura llamada Tapetum lucidum tras la retina. El tapetum lucidum funciona como un espejo que refleja hacia la córnea la luz que ha pasado a través de la retina, mejorando de esta forma la visión en la oscuridad.

La retina puede afectarse por diferentes enfermedades que en ocasiones disminuyen considerablemente la capacidad visual. Algunas de las más usuales son:



</doc>
<doc id="45459" url="https://es.wikipedia.org/wiki?curid=45459" title="Historia de Alemania">
Historia de Alemania

El territorio de la actual Alemania estuvo habitado desde tiempos remotos, pero debió pasar mucho tiempo, con numerosas inmigraciones, invasiones y conquistas después que se configuraron las particularidades nacionales de los alemanes.

Durante la Edad de Piedra, los bosques alemanes estaban poblados por grupos nómadas de cazadores y recolectores. Constituían las formas primitivas de Homo sapiens, como el Hombre de Heidelberg, que vivió hace 400.000 años. Poco después, aparecieron formas más avanzadas de Homo sapiens, como demuestran los restos encontrados cerca de Steinheim (de unos 300.000 años de antigüedad) y el más cercano de Ehringsdorf, de hace 100.000 años. Otro tipo humano fue el Neanderthal, descubierto cerca de Düsseldorf, que vivió hace 100.000 años. El tipo más reciente, que apareció hacia el 40.000 a. C., fue el de Cro-magnon, un miembro del Homo sapiens, especie del ser humano actual.

Los pueblos cazadores se encontraron con pueblos agrícolas, representantes de las culturas más avanzadas del suroeste de Asia, que emigraron por el valle del Danubio hasta el centro del actual territorio alemán en torno al 4.500 a. C. Estas poblaciones se mezclaron e instalaron, conviviendo en grandes chozas de madera, con techos a dos aguas, conocían la cerámica y realizaban intercambios de piedras preciosas, hachas de sílex y conchas con los pueblos del Mediterráneo. Cuando se agotaban sus campos de cultivo, trabajados con azadón manual, se trasladaban de lugar, volviendo pocos años después de esto.

La Edad del Bronce comenzó en el centro de Alemania, Bohemia y Austria en el 2.500 a. C. con el conocimiento de la aleación del cobre y del estaño adquirido de pueblos del Mediterráneo Oriental. Alrededor del 2300 a. C. llegaron nuevas oleadas de pueblos procedentes, probablemente, del sur de Rusia, se instalaron en el norte y centro de Alemania, los pueblos bálticos y eslavos en el este y los celtas en el sur y oeste.

Los grupos del centro y sur se mezclaron con la cultura del vaso campaniforme, que se trasladó hacia el este desde España y Portugal hacia el año 2000 a. C. Los pueblos representantes de la cultura del vaso campaniforme, probablemente indoeuropeos, fueron hábiles trabajadores del metal. Desarrollaron una floreciente cultura en Alemania e intercambiaron ámbar, procedente de la costa del mar Báltico por bronce y cerámica del mar Mediterráneo.

Desde el 1.800 hasta el 400 a. C., los pueblos celtas del sur de Alemania y Austria desarrollaron una serie de progresos en el trabajo del metal, configurando varias culturas (campos de urnas, Hallstatt y La Tène), cada una de las cuales se difundió por toda Europa; introdujeron el uso del hierro para fabricar herramientas de trabajo y armas. La cultura céltica de La Tène realizó excelentes trabajos de metal y utilizó arados tirados por bueyes y carros con ruedas. Las tribus germánicas absorbieron gran parte de la cultura celta y al final ésta se extinguió.

Antes de los romanos, los habitantes de la actual Alemania eran fundamentalmente los pueblos germánicos, grupos nómadas o seminómadas y que al igual que los romanos tenían esclavos, pero que en vez de tenerlos de servicio doméstico, les cobraban impuestos. A estos pueblos se les reconoce como pueblos germánicos por el parentivo filogenético de sus lenguas. Ya durante la antigüedad algunos germanos adaptaron el alfabeto etrusco creando así el alfabeto rúnico, llegando incluso a poder comunicarse entre sí. El protogermánico se sitúa hacia el 750 a. C. Por lo que hacia el s. I d. C. sus lenguas ya presentarían una importante diversificación aunque las lenguas de los grupos más cercanos aún podrían tener cierta inteligibilidad mutua. La evidencia filogenética sugiere que hacia el siglo I d. C. habría habido tres grupos de variedades germánicas: el germánico septentrional, confinadas básicamente a Escandinavia y Dinamarca, el germánico oriental y el occidentales que habría sido el grupo predominante en Alemania occidental.
El término "deutsch" (alemán) data del siglo VIII y originalmente hacía referencia en la parte oriental del reino de los francos que en ese momento abarcaba lo que es ahora Francia y Alemania. Este término derivaría del germánico "*thouthaz" 'pueblo' (cognado del latín "tōtus" 'todo [el pueblo]').

Durante el reino de César Augusto, los germanos se familiarizaron con las tácticas de guerra romanas, manteniendo al mismo tiempo su identidad tribal. En 9 d. C., tres legiones romanas dirigidas por Varo fueron derrotadas por los queruscos y su caudillo Arminio en la Batalla del bosque de Teutoburgo. Por lo tanto, la Alemania moderna, por lo que respecta al Rin y el Danubio, se mantuvo fuera del Imperio romano, lo que dio un cambio brusco a la historia de ampliación del imperio romano, porque los romanos no volvieron a intentar invadir más allá del Rin.

En la época de Tácito, tribus germánicas se establecieron a lo largo del Rin y el Danubio, ocupando la mayor parte de la zona moderna de Alemania.

El siglo III vio el surgimiento de un gran número de tribus germánicas del Oeste: alamanes, francos, catos, sajones, frisones y turingios. En ese momento estos pueblos iniciaron el periodo de las grandes migraciones que se extendió por varios siglos.
Estos y otros pueblos germanos son los ancestros de los alemanes actuales.

Estas "migraciones" básicamente consistieron en la conquista de diferentes regiones del Imperio Romano por varias tribus germánicas, entre las que destacan los Francos, los Visigodos y los Ostrogodos, primero como una forma de restituir lo que habían perdido ayudando a los romanos en las guerras contra los Hunos en el siglo V, ya que los emperadores romanos prometían tierras en Italia a los reyes de los pueblos germánicos, pero después no las entregaban y los reyes las tomaban; luego como Federati (confederados) de los romanos cuando el imperio romano no tenía recursos para defenderse de los invasores externos, como los Vándalos, que también eran tribus germánicas. Los Visigodos tomaron Dacia y los Vándalos se instalaron en Hispania (la actual España y Portugal). El emperador romano cedió Hispania a los Visigodos si ellos sacaban a los Vándalos del imperio. Los Vándalos, huyendo de los Visigodos, marcharon al norte de África y lo saquearon. Desde la ciudad de Alejandría los Vándalos llegaron a un astillero, aprendieron a fabricar barcos, se convirtieron en piratas y asolaron el mediterráneo.

Este proceso de alianzas temporales con antiguos enemigos dio origen al feudalismo de la edad media. Como la idea de esclavitud de los germánicos consistía en cobrar impuestos y dejar que los contribuyentes (los esclavos) sigan haciendo lo que saben hacer, ese fue el sistema de gobierno impuesto en el imperio romano desintegrado.

Desde que sucedió a su padre Pipino el Breve en 768, el nuevo rey de los francos, Carlomagno, consolidó la monarquía en este pueblo e inició un rápido avance hacia buena parte de los territorios de la Europa Occidental. Sajonia y Baviera, los dos Estados más organizados de Germania cayeron bajo su yugo. Su autoridad fue confirmada al ser coronado Emperador en el año 800 en Roma, y en consecuencia ser nombrado como máximo poder político del mundo cristiano. La ciudad alemana de Aquisgrán se convirtió en la capital imperial. Su hijo Ludovico Pío heredó su imperio, pero su débil figura provocó el inicio del declive, culminado con la partición imperial en los sucesivos Tratado de Verdún (843), Tratado de Meersen (870) y Tratado de Ribemont (880). Francia Oriental, surgida en Verdún con Luis el Germánico, nieto de Carlomagno, como rey, sería el germen de lo que hoy es Alemania. Las regiones al oeste del río Rin quedaron englobadas en la llamada Lotaringia, tierras de Lotario I, hermano y rival de Luis, junto con las zonas más orientales de Francia y el Reino de Italia, con Roma como su capital.

Al morir Luis en 875, la Francia Oriental quedó dividida entre sus tres hijos, en tres porciones: Sajonia (norte), Baviera (sudeste) y Suabia (sudoeste). A diferencia de lo vivido hasta entonces, los tres Estados colaboraron estrechamente. Avatares de las historia llevaron a Carlos III el Gordo, rey de Suabia, a gobernar sobre todo el viejo imperio carolingio entre 881 y 887. Sin embargo, la lengua común y la también común legislación provocaron en ese momento un sentimiento alemán que perduraría hasta nuestros días. La época medieval termina en España con el descubrimiento de América, pero probablemente en Alemania con Martin Lutero.

El imperio medieval se derivaba de una división del Imperio carolingio en 843, que fue fundado por Carlomagno en 800 y existió en diferentes formas hasta 1806. Su territorio se extendía desde el río Eder en el norte hasta la costa mediterránea en el sur.

Bajo el reinado de la Dinastía Sajona (919-1024), los ducados de Lorena, Sajonia, Franconia, Suabia, Turingia y Baviera se consolidaron, y el Rey alemán fue coronado emperador del Sacro Imperio Romano Germánico de estas regiones en 962. Bajo el reinado de la Dinastía salia (1024-1125), el Sacro Imperio Romano Germánico absorbió el norte de Italia y Borgoña, aunque los emperadores perdieron el poder a través de la Querella de las Investiduras. Bajo los emperadores Hohenstaufen (1138-1254), los príncipes alemanes aumentaron su influencia hacia el sur y el este en los territorios habitados por los eslavos. En el Norte alemán crecieron ciudades prósperas como las de la Liga Hanseática.

El edicto de la Bula de Oro de 1356 fue la constitución básica del Imperio que duró hasta su disolución. Se codificó la elección del emperador por siete príncipes electores. A partir del siglo XV, los emperadores fueron elegidos casi exclusivamente entre los provenientes de la Casa de Habsburgo.

Martín Lutero escribió las noventa y cinco tesis, donde cuestionaba la Iglesia católica en 1517, provocando con ello la Reforma Protestante. La Iglesia Luterana fue reconocida como la nueva confesión sancionada en muchos Estados alemanes después de 1530. El conflicto religioso resultante condujo a la Guerra de los Treinta Años (1618-1648), que devastó el territorio alemán. La población de los Estados alemanes se redujo en un 30%. La Paz de Westfalia (1648) terminó la guerra religiosa entre los Estados alemanes, pero el Imperio de facto fue dividido en numerosos principados independientes. Desde 1740 en adelante, el dualismo entre la monarquía Habsburgo de Austria y el Reino de Prusia dominó la historia alemana. En 1806, el Imperio fue invadido y disuelto como consecuencia de las Guerras napoleónicas.

Tras abdicar el último monarca del Sacro Imperio Romano Germánico, se inició, en los antiguos Estados que lo componían, una dispar búsqueda por crear un Estado nacional alemán unificado. La cuestión territorial se debatía entre la creación de una «gran Alemania», que incluyese los territorios germanófonos austriacos o una «pequeña Alemania», formada exclusivamente por otros Estados. A esta disyuntiva se sumaba la cuestión institucional sobre el reparto de poder entre el pueblo y la corona.

La cuestión se planteó de manera concreta tras la caída del Primer Imperio francés. Napoleón, el emperador de los franceses, fue derrotado, pero el hecho de terminar con la dominación extranjera no les reportó a los alemanes una Alemania unida dentro de la Confederación Germánica, implantada en 1815.

En marzo de 1848, la revolución estalló en Alemania. Convertir a Alemania en un Estado nacional e institucional suponía tener que definir qué pertenecía a Alemania. El primer Parlamento libremente elegido en Fráncfort del Meno descubrió que no era posible forzar el establecimiento de un Estado nacional pangermánico, con inclusión de Austria. Este hecho planteó la solución de la «pequeña Alemania», en la forma de un imperio bajo la hegemonía del Reino de Prusia.

El parlamento exigió que, como emperador alemán, el rey de Prusia tendría que renunciar a su carácter divino y concebirse a sí mismo como ejecutor de la voluntad del pueblo, exigencia que el monarca rechazó en 1849, impidiendo de esta forma que se realizara la unificación alemana.

En la década de 1860, el Canciller Otto von Bismarck favoreció en Prusia al ejecutivo contra el Parlamento. La cuestión del poder político externo se resolvió con la Guerra de las Siete Semanas en 1866, en el sentido de la «pequeña Alemania».

La historia de Alemania como país se inicia en 1871 al instaurarse el Imperio alemán. Con anterioridad, lo que conocemos como Alemania fue una agrupación de Estados en el marco del Sacro Imperio Romano Germánico, formado a partir de la división en 843 del Imperio carolingio, fundado en el año 800 por Carlomagno. Este Imperio existió en diversas formas hasta ser disuelto en 1806 como consecuencia de las guerras Napoleónicas.

Durante el siglo XVIII se inicia la transformación de Prusia en una potencia europea. El largo reinado de Federico II el Grande da un gran impulso a la consolidación de este reino, que se ve envuelto en las guerras de Sucesión Austriaca y de los Siete Años. A partir de entonces Prusia disputaría a la Casa de Austria la hegemonía de Alemania.
Tras la Revolución francesa, los diferentes Estados monárquicos de Europa crean alianzas para enfrentar la amenaza que Francia representa para la estabilidad de sus propios regímenes.

Los Estados alemanes participan activamente contra los ejércitos de Napoleón I, quien tras acumular importantes victorias instaura la Confederación del Rin en 1806. Poco después el emperador del Sacro Imperio abdica y disuelve así efectivamente el imperio.

En el Congreso de Viena, tras la derrota definitiva del ejército francés, se disuelve la Confederación del Rin y se crea la Confederación Germánica. El 1 de enero de 1834 entra en vigor la asociación de aduanas, mediante la cual se abolen los aranceles entre algunos miembros del norte de la confederación, bajo hegemonía prusiana, la llamada Zollverein.

La Revolución de 1848 conduce a la creación del primer Parlamento alemán en Fráncfort del Meno, que elabora una primera constitución pero fracasa con la unificación nacional, porque los monarcas recuperan el control.

Una reforma de la constitución danesa y la disputa por Schleswig-Holstein causa la guerra conocida como de los ducados (1864), y después la de las siete semanas (1866), por las cuales Prusia se asegura la hegemonía germánica.

El Imperio alemán se funda el 18 de enero de 1871 tras la victoria de Prusia en la Guerra franco-prusiana, y se consigue la unificación de los diferentes estados alemanes en torno a Prusia, excluyendo a Austria. Así Prusia se convierte en Alemania, bajo el liderazgo del canciller Otto von Bismarck, quien será el verdadero artífice de la unificación; posiblemente uno de los estadistas más importantes del siglo XIX. Se inicia un período de gran desarrollo nacional alemán en todos los campos: economía, política y milicia.

Desde entonces Alemania se transforma junto al Reino Unido en una de las dos grandes potencias mundiales, sin ambiciones coloniales durante el gobierno de Bismarck.

A partir de este punto y durante las siguientes dos décadas se establecen los llamados "sistemas bismarckianos", que dominan la política europea. En el Congreso de Berlín de 1878 se reúnen los representantes de varios Estados europeos bajo la presidencia de Bismarck con el propósito de reorganizar los Balcanes tras la Guerra Ruso-Turca de 1877–1878, así como para equilibrar los intereses de Inglaterra, Rusia y Austria-Hungría en la zona. Después, Bismarck convoca entre 1884 y 1885 la conferencia de Berlín en la que las potencias fijan las pautas para el reparto colonial de África.

Con la coronación de Guillermo II como Káiser, se inicia un enfrentamiento entre él y Bismarck, el cual provoca la caída del canciller en 1890. El emperador será incapaz de continuar con las políticas implantadas por Bismarck, y Alemania se ve poco a poco en la incapacidad de mantener el equilibrio europeo, que para entonces era más que nunca la base del equilibrio mundial.

En 1914 estalla la Primera Guerra Mundial que, al provocar la derrota de Alemania en 1918, marca el fin de la dinastía Hohenzollern. Las naciones vencedoras imponen el Tratado de Versalles.

Tras la derrota en la Primera Guerra Mundial, se constituye la República de Weimar en 1919. Es un periodo de gran inestabilidad debido a la fragmentación parlamentaria en partidos minoritarios y al rechazo de los militares a aceptar la derrota y los acuerdos impuestos por los vencedores.

La crisis económica como consecuencia del Tratado de Versalles que hacía que Alemania pagara grandes tributos como trofeo de guerra y la hiperinflación conlleva la ruina para una gran parte de la clase media, y esta situación se agrava tras la Gran Depresión de 1929. La impresión irracional de dinero durante la república de Weimar produjo una hiperinflación que hace que hasta el día de hoy los alemanes teman a la inflación, al revés de lo que ocurre en Estados Unidos, donde se teme a la deflación.

Así se produce una situación propicia para el auge de ideas nacionalistas y fascistas. En las elecciones de 1933, el Partido Nacionalsocialista Obrero Alemán (NSDAP, nazi) consigue llegar al poder, y finalizará enseguida la primera experiencia democrática alemana.

El Tercer Reich fue el de la Alemania nazi. Duró doce años, desde 1933 hasta 1945.
La adversidad económica —debida tanto a las condiciones de la paz como a la gran depresión mundial— es marcada como una explicación de por qué los partidos antidemocráticos, tanto del ala derecha como del ala izquierda, fueron ampliamente apoyados por los líderes de opinión y votantes alemanes. En las elecciones extraordinarias de julio y noviembre de 1932, los nazis obtuvieron el 37,2 % y 33,0 % de los votos, respectivamente. El 30 de enero de 1933, Adolf Hitler fue nombrado jefe de gobierno.

Durante el año siguiente, Hitler obtuvo el control total. Sucedió también al jefe de Estado.

Hitler había intentado un golpe de Estado y había fracasado en el intento, por lo que fue a la cárcel y escribió "Mi Lucha", libro en el que considera que la guerra y la pobreza alemanas se debían a los judíos que explotaban a las personas, dominaban los periódicos, las noticias, los bancos y se dedicaban al comercio sexual (trata de blancas). Una vez que salió de la cárcel fue ovacionado como héroe.

La política de "Lebensraum" (espacio vital) implementada por Hitler y basada en que todos los países de habla alemana debían estar unidos, se vio reforzada gracias al Pacto de Múnich, lo que finalmente llevó al estallido de la Segunda Guerra Mundial en Europa el 1 de septiembre de 1939. Alemania obtuvo inicialmente grandes éxitos militares y consiguió el control sobre Francia, Bélgica, Países Bajos, Dinamarca, Luxemburgo, Balcanes, Grecia y Noruega en Europa, Túnez y Libia en el norte de África.

Esta guerra no solo fue carácter económico-político, sino que sirvió para aplicar severas leyes racistas. No solo se asesinaron seis millones de judíos, gitanos, rusos, serbios, polacos y otras etnias, sino que en los campos de concentración creados en todos los territorios conquistados se encerró a gitanos, deficientes mentales, homosexuales y disidentes ideológicos. Estas personas eran privadas de su libertad y sus bienes y, tras ser aisladas en guetos, fueron esclavizadas para el trabajo gratuito (esclavitud), hasta resultar inservibles por debilidad, enfermedad o desnutrición, entonces se las ejecutaba o se realizaba experimentos científicos con ellos. Los nazis perfeccionaron los asesinatos masivos, creando las cámaras de gas. El mejor ejemplo de ello se puede ver aún en el campo de concentración de Auschwitz (Polonia). Esta masacre duró años con el silencio, la supuesta ignorancia o el consentimiento del resto de los países del planeta que participaban en la guerra.

El ataque a la URSS en 1941 fue decisivo para demostrar que el ejército era insuficiente para abarcar tanta extensión de terreno. Las fracasadas campañas rusas de 1941 y 1942 pretendían, la primera, alcanzar Moscú para cortar los suministros siberianos y, la segunda, llegar al mar Caspio para controlar el petróleo. A esto se suma que los rusos tenían doscientos millones de habitantes y desarrollaron los misiles "Katiusha" que hicieron retroceder a Hitler. También hubo luchas internas en Alemania por detener a Hitler, ya que sus generales se daban cuenta que pretendía algo imposible. Además, el ingreso de los EE. UU. en la guerra, acaba por dar un giro que lleva a la derrota de Alemania, que firma su rendición el 8 de mayo de 1945.

Entre julio y agosto de 1945, la Conferencia de Potsdam define el mapa político de Europa y las zonas de ocupación en Alemania y Austria.

La guerra resultó en una gran pérdida de territorio, quince millones de alemanes expulsados, cuarenta y cinco años de división, ya que el país se separó en la Alemania oriental y la occidental, y lo más importante unos cinco millones de muertos en Alemania y más de cincuenta en el macabro balance final de la contienda.

La rendición de Alemania ocurrió el 8 de mayo de 1945.

En la conferencia de Potsdam realizada en agosto de 1945, poco después de la rendición incondicional de la Alemania Nazi el 8 de mayo de 1945, los aliados dividieron Alemania en cuatro zonas de ocupación militar -Francia al suroeste, Gran Bretaña al noroeste, Estados Unidos al sur, y la Unión Soviética al este-. Las antiguas (1919-1937) provincias de Alemania al este de la Línea Oder-Neisse (Prusia oriental, el este de Pomerania y Silesia) fueron transferidas a Polonia, mudando el país hacia el oeste.

Alemania, como país dividido, encarnó la guerra fría como ningún otro país. La ocupación del territorio por parte de los aliados tuvo como icono al muro de Berlín y perduró más de cuatro décadas. A pesar de ser uno de los países derrotados en la guerra, Alemania (la RFA) inició una fulgurante recuperación institucional a partir de los años 1950 y se transformó en la tercera potencia económica a nivel mundial, superando a la URSS, Reino Unido y Francia, que habían resultado vencedores en el conflicto.

Alemania da un giro radical en sus históricamente conflictivas relaciones con Francia, y luego de los tratados de Roma inicia junto a este país una política de acercamiento, que queda plasmada en el “tratado del Elíseo” de 1963. Desde entonces, las dos naciones han formado una dupla que hace frente común en cuanto a los asuntos internacionales.

En septiembre de 1990, un mes antes de la reunificación alemana, las cuatro potencias aliadas y los dos Estados alemanes firmaron un tratado en Moscú (Tratado Dos más Cuatro) que ponía fin a los derechos y las responsabilidades de los poderes aliados respecto a Alemania. Las fuerzas soviéticas ubicadas en la Alemania oriental completaron su retiro el 31 de agosto de 1994 y una semana después le siguieron las fuerzas aliadas. Únicamente soldados estadounidenses y británicos, ubicados en el marco de la OTAN, permanecen en la República Federal.

En su calidad de Estado fundador, Alemania desempeña un papel central en la construcción de la Unión Europea (UE). Fue justamente el Ministro francés de apellido germánico, Robert Schuman, quien en 1950 pronunció el discurso que, se considera, sentó las bases de la Unión.

Durante cinco décadas diferentes, mandatarios desde Konrad Adenauer hasta Gerhard Schröder han participado de manera decidida respaldando a la UE y convirtiendo a Alemania en el principal promotor de la Ampliación de la Unión.

En 2001 se da el paso más importante en materia de unión económica europea, con la creación de la Moneda Común de la UE, el Euro (€), cuyo valor inicial era de 0,80 dólares estadounidenses dado que se pretendía competir en los mercados con cierta ventaja para los productos europeos. Durante cierto tiempo coexistieron las monedas locales, el marco alemán en este caso, como el euro hasta que aquellas (franco, marco, lira, peseta, escudos, etc.) fueron definitivamente abolidas en beneficio de la nueva moneda única europea.

En mayo de 2005, el parlamento alemán ratificó el Tratado por el que se establece una Constitución para Europa, que se pretendía que entrase en vigor el 11 de noviembre de 2006, después de que fuera ratificado por los Estados miembros, pero ante la victoria del “no” en Francia y Países Bajos, la cumbre del CUE del 15 y 16 de junio de 2006 tomó nuevas resoluciones.

Se estableció que, durante la presidencia del CUE en el primer semestre de 2007 a cargo de Alemania, se elaboraría una propuesta sobre la que no se fijaron detalles.

Los miembros pactaron además celebrar una reunión el 25 de marzo de 2007 en Alemania para conmemorar el quincuagésimo aniversario de los Tratados de Roma. En esta cumbre, firmaron una declaración política que recogió los “valores y ambiciones” de la Unión.


Historia de ciudades alemanas:



</doc>
<doc id="45461" url="https://es.wikipedia.org/wiki?curid=45461" title="Eskorbuto">
Eskorbuto

Eskorbuto fue un grupo español de punk originario de Santurce. Surgieron en 1980 y han sido uno de las bandas más influyentes en el panorama del punk en español. Posteriormente a su fundación, y coincidiendo con el fenómeno contemporáneo del llamado rock radical vasco, fueron incluidos en este género. Posteriores declaraciones públicas del grupo mostraron el rechazo a esta clasificación, reivindicando la independencia musical y la personalidad de la formación.

El grupo se crea en 1980 influenciados por la repercusión del movimiento punk originado en el Reino Unido. 

La primera formación de Eskorbuto contó con Jesús María Expósito López en la guitarra eléctrica, conocido como Iosu, quien había sido bajista de la banda de rock Zarama y Juan Manuel Suárez Fernández, conocido como Juanma, por aquel entonces cantante, junto con Roberto "Kañas" en la batería, sustituido al poco tiempo por Gugu y Layky en el bajo.

Durante 1981 y 1982, Eskorbuto realiza varias presentaciones en pequeñas discotecas, escuelas y en los carnavales, y a mediados de 1982 Layky y Gugu abandonan la banda, y es entonces que Juanma pasa a ser el bajista del grupo y en la batería entra Pako Galán, quien ya tenía una formación musical más profesional y había formado parte de varios grupos durante la década de 1970, entre ellos Atlantic y Eskombro.

En 1983, en un posterior viaje a Madrid para detallar con Sardi los detalles del repertorio de lo que será su primer álbum, Eskorbuto graba su primer material discográfico: «Mucha policía, poca diversión», un sencillo de 7" con las canciones «Mucha policía, poca diversión», «Enterrado vivo» y «Mi Degeneración», editado para el sello Spansuls Records.

Luego, la banda pasa por un camino a través de un parque para llegar a casa de un amigo, quienes los llevaría a registrar la maqueta de forma más elaborada, y al salir del parque pasan por delante de una comisaría. Allí mismo, dado su aspecto "sospechoso" son interrogados por la policía y éstos los registran hasta dar con la maqueta grabada y por esto son detenidos, por el contenido de las letras de las canciones que portaban (con temas como "E.T.A.", "Escupe a la bandera " y "Maldito país España") y se les aplica la Ley Antiterrorista. Durante la encarcelación de Eskorbuto, 36 horas, se sintieron abandonados por algunos sectores de Euskadi, sobre todo la denominada izquierda abertzale y por los cuerpos de amnistía españoles. Tras ser liberados, tanto la prensa española como la vasca no dudan en nombrar a Eskorbuto como la banda más "radical" de todas, aunque ellos siempre renegaron de dicho título.

En 1984, se presenta su segunda grabación profesional, una vez más hecha para Spansuls Records y lo plasmaron junto al grupo RIP, en el EP "Zona Especial Norte", publicada en dos versiones, la española con la canción "A la mierda el País Vasco" y la edición vasca con la canción "¡Oh! no! no! no!". Esto, junto con no querer alinearse con el denominado rock radical vasco, les trajo muchos problemas para tocar en el País Vasco.

En 1984, deciden conseguir un contrato para grabar su primer álbum completo, pero varias discográficas les negaron promoción alguna, hasta que Twins Producciones de Madrid (por medio de Sardi Lennon) les ofrece grabar en Bilbao un álbum completo. Y así llegó en 1985 "Eskizofrenia", y con él empezaron a llegar las actuaciones fuera del País Vasco, ya que en su tierra tenían pocas posibilidades de tocar. Además, en 1985 realizaron una aparición en el programa de TVE "La bola de cristal", tocando "Os engañan".

En 1985, meses después de la producción del álbum "Eskizofrenia", se reedita con Discos Suicidas, proporcionándole mejora en su sonido y mayor producción, lo cual se atribuye a que Pako Galán ya no fuera el batería original, sino Iñaki "Gato", quien le dio el sonido con mayor nitidez, en su época dando como resultado un "repress" con mayor venta.

A comienzos de 1986 sacan su segundo álbum, "Anti todo", considerado por muchos uno de los mejores discos de punk hecho en España de todos los tiempos. En ese año también sacan un doble álbum en directo titulado "Impuesto revolucionario", siendo Eskorbuto uno de los primeros grupos en editar un álbum en vivo en España, tras "Máquina! En directo" (1972), "Leño en Directo" (1981), "Barón al rojo vivo" (1984). A finales de ese mismo año editan su segundo EP "Ya no quedan más cojones, Eskorbuto a las elecciones".

En 1987 sale a la luz su tercer disco de estudio y segundo disco doble "Los demenciales chicos acelerados", originalmente en Discos Suicidas y meses más tarde en DRO. La banda vendió dos veces el mismo máster sin aviso a las compañías discográficas (en exclusiva) no siendo válidos ningunos de los contratos con los que estaban vinculados. Con la salida del álbum, muy pocas veces la banda interpretó en vivo las canciones de "Los demenciales...".

Para 1988 deciden autoproducirse y fundar su propio sello discográfico llamado Buto Eskor (anagrama de Eskorbuto) y editan su cuarto álbum de estudio "Las más macabras de las vidas", con Iosu y Juanma padeciendo ya serios problemas de salud a causa de su adicción a la heroína.

En 1989, la relación entre los miembros de la banda se resiente, sabiendo los tres que de Eskorbuto "solo la muerte puede separarlos". Los conciertos cada vez son más escasos, quedando mucho tiempo libre para una creación futura.

Para el año 1991, Eskorbuto recibe una propuesta para realizar en México (primer y único viaje de la banda al extranjero) una gira, a donde viajarían sin Iosu debido a su estado de salud, siendo reemplazado por Iñaki "Gato", guitarrista del grupo Speed, ya que Juanma era amigo de esta banda. Los conciertos fueron programados para el sábado 13 y domingo 14 de abril en el Ex-Balneario Olímpico de Pantitlán, en la Ciudad de México, aunque fueron suspendidos debido a la sobreventa de las entradas y cambiados para el sábado 20 (donde abriría Rebel'D Punk, Aquelarre y Psicodencia) y el domingo 21 (donde abriría Síndrome Del Punk y Sedición) en la Arena López Mateos, en Tlalnepantla, Estado de México, presentaciones que ocasionarían un gran número de disturbios y de daños a la localidad.

De vuelta de México y tras tres semanas con Iñaki "Gato", y con Iosu fuera del hospital, una vez más Eskorbuto se reúne y decide grabar un nuevo álbum: "Demasiados enemigos", el cual editan a finales de 1991, a través del sello Matraka y luego por Oihuka.

En diciembre de 1991, la banda realiza un espectáculo de fin de año que fue grabado como nuevo proyecto en directo, aunque no conformes con los resultados, deciden rehacerlo durante comienzos de 1992, pero en esta etapa es cada vez más notable el deterioro de salud de Iosu, lo cual hace que se retire momentáneamente de la banda una vez más para descansar de su estado, pero lamentablemente Iosu Expósito falleció en la localidad de Barakaldo el 31 de mayo de 1992 a causa del sida que padecía, derivado de su anterior adicción a la heroína. 

Tras la muerte de Iosu, Juanma y Pako deciden continuar con Eskorbuto con Urko Igartiburu como nuevo guitarrista, con quién empiezan a ensayar los viernes de cada semana un nuevo proyecto. Pero Juanma murió el 9 de octubre de 1992.

El último concierto que dio Eskorbuto fue en Matiena, un pequeño pueblo de Bizkaia bajo la contratación de la comisión de fiestas, encargada de un grupo de jóvenes del barrio; el contrato queda firmado por Iosu de Txalupa y José Ignacio Delgado como el último contrato firmado en vida por los "auténticos" Eskorbuto, el 30 de abril de 1992.

Tras la muerte casi simultánea de Iosu y Juanma, Pako Galán anunció en 1993 el no abandono de la banda.

Durante 1993, Pako Galán empieza a grabar junto a Iñaki "Gato" en bajo y Urko Igartiburu y Garlopa en guitarras el proyecto original que habían comenzado con Juanma. El resultado culmina con "Aki No Keda Ni Dios", publicado en 1994, con canciones que habían compuesto Pako y Juanma durante 1992. 

Pako decidió seguir con el grupo a pesar de la muerte de los dos miembros fundadores, cosa que le reprochan muchos de los seguidores del grupo. Respondiendo Pako, que "Eskorbuto hace lo que le sale de los cojones, nunca contamos con nadie para nuestros proyectos o fracasos. No necesitamos nada de nadie, nada de ti y nada del rock. Eskorbuto nació para morir protestando".

En 1995, Urko Igartiburu decide no seguir aportando más para la banda, siendo remplazado por Sergio como cantante fijo, y los bajos quedan a cargo de Miguel Ángel Manjón y Alik Kalaña, reemplazando a Iñaki "Gato", y con esta formación registran el álbum "Kalaña" en 1996 para Discos Suicidas. 

En 1998, la banda edita para el sello Surco el disco "Dekadencia", grabado con Sergio, Alik Kalaña (quien luego se retiró), Garlopa y Miguel Ángel Manjón. Este fue el último lanzamiento discográfico de Eskorbuto.

Eskorbuto nunca destacó por sus habilidades como músicos, sin embargo, compusieron canciones que se convirtieron rápidamente en himnos de la época, como «Mucha policía, poca diversión» o «Historia triste».

Sus letras estaban cargadas de rabia y contenido social. Fue un grupo muy polémico, amado por muchos y odiado por otros. Nunca se alinearon políticamente con ninguna ideología, «El rock no tiene patria, ni siquiera la vasca» dijeron en una ocasión. Sin duda algo que no se puede negar es que lograron llegar muy lejos de Euskadi a partir de algo tan sencillo como la honestidad, evidentemente una cuestión para reflexionar, el corazón sobre el virtuosismo.

Actualmente Euskadi es una de las regiones más prósperas, con una renta económica muy superior a la media europea. Pero el País Vasco de los años 1977-1992 (años de existencia de la formación original de Eskorbuto) era muy distinto del actual.

En aquellos años, se sumaron varios problemas:








Eskorbuto ha protagonizado varias citas y ha sido objeto de otras tantas.















</doc>
<doc id="45463" url="https://es.wikipedia.org/wiki?curid=45463" title="Guerra de las Comunidades de Castilla">
Guerra de las Comunidades de Castilla

La guerra de las Comunidades de Castilla fue el levantamiento armado de los denominados comuneros, acaecido en la Corona de Castilla desde el año 1520 hasta 1522, es decir, a comienzos del reinado de Carlos I. Las ciudades protagonistas fueron las del interior castellano, situándose a la cabeza del alzamiento las de Toledo y Valladolid. Su carácter ha sido objeto de agitado debate historiográfico, con posturas y enfoques contradictorios. Así, algunos estudiosos califican la guerra de las Comunidades como una revuelta antiseñorial; otros, como una de las primeras revoluciones burguesas de la Era Moderna, y otra postura defiende que se trató más bien de un movimiento antifiscal y particularista, de índole medievalizante.

El levantamiento se produjo en un momento de inestabilidad política de la Corona de Castilla, que se arrastraba desde la muerte de Isabel la Católica en 1504. En octubre de 1517, el rey Carlos I llegó a Asturias proveniente de Flandes, donde se había autoproclamado rey de sus posesiones hispánicas en 1516. A las Cortes de Valladolid de 1518 llegó sin saber hablar apenas castellano y trayendo consigo un gran número de nobles y clérigos flamencos como Corte, lo que produjo recelos entre las élites sociales castellanas, que sintieron que su advenimiento les acarrearía una pérdida de poder y estatus social (la situación era inédita históricamente). Este descontento fue transmitiéndose a las capas populares y, como primera protesta pública, aparecieron pasquines en las iglesias donde podía leerse:

Las demandas fiscales, coincidentes con la salida del rey para la elección imperial en Alemania (Cortes de Santiago y La Coruña de 1520), produjeron una serie de revueltas urbanas que se coordinaron e institucionalizaron, encontrando un candidato alternativo a la corona en la «reina propietaria de Castilla», la madre de Carlos, Juana, cuya incapacidad o locura podía ser objeto de revisión, aunque la propia Juana, de hecho, no colaborara. Tras prácticamente un año de rebelión, se habían reorganizado los partidarios del emperador (particularmente la alta nobleza y los territorios periféricos castellanos, como Andalucía) y las tropas imperiales asestaron un golpe casi definitivo a las comuneras en la batalla de Villalar el 23 de abril de 1521. Allí mismo, al día siguiente, se decapitó a los líderes comuneros: Padilla, Bravo y Maldonado. El Ejército comunero quedaba descompuesto. Solamente Toledo mantuvo viva su rebeldía, hasta su rendición definitiva en febrero de 1522.

Las Comunidades han sido siempre motivo de atento estudio histórico, y su significado a veces ha sido mitificado y utilizado políticamente, en particular a partir de la visita de el Empecinado a Villalar el 23 de abril de 1821, con motivo del tercer centenario de la "derrota", tal como era sentida por los liberales. Pintores como Antonio Gisbert retrataron a los comuneros en algunas de sus obras, y se firmaron documentos como el Pacto Federal Castellano, con claras referencias a las Comunidades. Los intelectuales conservadores o reaccionarios adoptaron interpretaciones mucho más favorables a la postura imperial y críticas hacia los comuneros. A partir de la segunda mitad del siglo se revitalizaron los estudios históricos haciendo uso de una metodología renovada.

Más recientemente, en el plano político, desde principios de la Transición, se comenzó a conmemorar la derrota cada 23 de abril, alcanzando finalmente, con la conformación de Castilla y León como autonomía, el estatus de día de la comunidad. Asimismo, su utilización como elemento simbólico está muy presente en los movimientos castellanistas y regionalistas castellanoleoneses. Ha tenido una notable difusión popular mediante el poema épico "Los Comuneros", de Luis López Álvarez, musicalizado por el Nuevo Mester de Juglaría.

La situación que llevó en 1520 a la guerra de las Comunidades, se había ido gestando en los años previos a su estallido. El siglo XV, en su segunda mitad, había supuesto una etapa de profundos cambios políticos, sociales y económicos. El equilibrio alcanzado con el reinado de los Reyes Católicos se rompe al llegar el siglo XVI. Este comenzó con una serie de malas cosechas y epidemias, que junto a la presión tributaria y fiscal provocó el descontento entre la población, colocándose la situación al borde de la revuelta. La zona que más sufre en este contexto es la zona central, en contrapeso con la periférica, que apaciguaba sus males con los beneficios del comercio. Burgos y Andalucía representaban esa zona periférica y comercial respecto a la Meseta Central, con Valladolid y Toledo a la cabeza.

No solo las malas cosechas provocaron el descontento, sino que a este se unieron las protestas de los comerciantes del interior ante el monopolio ejercido por los mercaderes burgaleses en el comercio de la lana. Esta situación caldeó el ambiente en los núcleos gremiales de ciudades como Segovia y Cuenca. Ante esta situación, todas las partes implicadas se volvieron hacia el Estado para que ejerciera el papel de árbitro, pero también este se encontraba sumido en una grave crisis, que se hizo cada vez más grande con los sucesivos gobiernos de Felipe el Hermoso, Cisneros y Fernando el Católico. La teórica heredera, Juana la Loca se encontraba en estado de incapacidad, por lo que la línea dinástica llevó hasta Carlos de Habsburgo, hijo de Juana, y que nunca antes había pisado Castilla. Educado en Flandes, no conocía el castellano e ignoraba la situación de sus posesiones hispanas, por lo que la población acogió con escepticismo la llegada del nuevo rey, pero a la vez con ansia de estabilidad y continuidad, cosa de la que Castilla no disfrutaba desde la muerte de Isabel la Católica en 1504. Tras la llegada del nuevo rey a finales de 1517, su corte flamenca comenzó a ocupar los puestos de poder castellanos, siendo el nombramiento más escandaloso el de Guillermo de Croy, un joven de tan solo 20 años, como arzobispo de Toledo sucediendo al Cardenal Cisneros. Seis meses más tarde, en las Cortes de Valladolid, el descontento ya estaba presente en todos los sectores, llegando incluso algunos frailes a predicar denunciando abiertamente a la Corte, a los flamencos y la pasividad de la nobleza. En estas circunstancias, en 1519 se abrió el proceso de elección para el cargo de emperador del Sacro Imperio Romano Germánico, que finalmente y por unanimidad recayó en favor de Carlos I, nieto del difunto Maximiliano. Este nombramiento fue aceptado por el monarca castellano, que decidió partir rumbo a Alemania para tomar posesión como emperador. El concejo de Toledo se situó al frente de las ciudades que protestaban contra la elección imperial, cuestionando el papel que Castilla debería desempeñar en este nuevo marco político y los gastos que acarrearía a corto plazo, dada la posibilidad de que la Corona se convirtiera en una mera dependencia imperial.

El 12 de febrero de 1520 Carlos I decidió convocar las Cortes en Santiago de Compostela con el objetivo de obtener un nuevo servicio que le permitiese sufragar los gastos de su viaje a Alemania. A pesar de las presiones de los corregidores y de la Corte real, la mayoría de las ciudades se atuvieron al programa reivindicativo de los frailes de Salamanca, que defendía la independencia nacional en contra del Imperio, y decidieron enviar a sus procuradores con poderes para no votar el servicio. Ante esta corriente de hostilidad, el rey decidió suspender las Cortes el 4 de abril y convocarlas de nuevo el 22 de abril, pero en La Coruña. Allí obtuvo el impuesto extraordinario y el 20 de mayo se embarcó con rumbo al Sacro Imperio, no sin antes dejar como regente de la posesiones hispánicas al flamenco Adriano de Utrecht.

Ya desde el mes de abril de 1520, Toledo se negaba a acatar el poder real, estallando la situación de forma definitiva cuando el rey convocó a los regidores de la ciudad para que se presentaran en Santiago de Compostela. La orden llegó a Toledo el 15 de abril, y un día después, cuando los regidores con Juan de Padilla a la cabeza se disponían a partir, una gran multitud se opuso a su partida y se apoderó del gobierno local. Comenzó entonces a denominarse a la insurrección como "Comunidad" y los predicadores arengaban a los toledanos a unirse contra el poder flamenco. De esta forma, los toledanos comenzaron a ocupar todos los poderes locales, expulsando al corregidor del Alcázar el 31 de mayo. Tras la marcha del Monarca hacia Alemania, los disturbios se multiplicaron por las ciudades de la Meseta, especialmente tras la llegada de los procuradores que votaron afirmativamente al servicio que reclamaba el rey, siendo Segovia el lugar donde se produjeron los primeros incidentes y los más violentos, donde el 29 y el 30 de mayo los segovianos ajusticiaron a dos funcionarios y al procurador Rodrigo de Tordesillas que concedió el servicio en nombre de la ciudad. Destacaron también por incidentes de similar magnitud ciudades como Burgos y Guadalajara, mientras que otras como León, Zamora y Ávila sufrieron altercados menores. Por el contrario, no se registraron incidentes en Valladolid, principalmente por la presencia en la ciudad del cardenal Adriano y del Consejo Real.

Ante el descontento generalizado, el 8 de junio, Toledo propuso a las ciudades con voz y voto en Cortes la celebración de una reunión urgente con cinco objetivos:

Estas reivindicaciones calaron en la sociedad castellana, especialmente las dos primeras, que se unían a las denuncias por la manera en que el rey había obtenido el trono del Imperio, mediante sobornos a los príncipes electores. Ante esta situación, el reino comenzó a alimentar la idea de sustituir la figura del rey, tomando la iniciativa Toledo, que defendía metas mayores, como convertir a las ciudades castellanas en ciudades libres, similar a lo que ya ocurría con Génova y otros territorios italianos. Por el reino ya circulaba la idea de destronar a Carlos I y el acudir a Tordesillas para devolver a la reina Juana la Loca todos sus privilegios e importancia. Con estas ideas, la situación pasaba de ser una protesta contra la presión fiscal a tomar el perfil de una auténtica revolución, teniendo Castilla perfecto conocimiento de la situación y acogiendo con bastantes reservas las propuestas que realizó Toledo.

Así pues, los comuneros se hicieron fuertes en el centro de la Meseta, y en otros núcleos, como Murcia, más alejada de la Meseta. Sin embargo, no hubo intentos de rebelión en otros lugares, como Galicia o el País Vasco. Los rebeldes buscaron expandir las ideas revolucionarias al resto del reino, pero su radio de acción se debilitaba a medida que se alejaba de las dos Castillas. Así, hubo intentos de llevar la revuelta a Andalucía y el País Vasco, pero no fructificaron. Los máximos logros conseguidos por los rebeldes fueron la instauración de una Comunidad en Plasencia, pero esta se veía mermada por la cercanía de núcleos realistas cercanos, como Ciudad Rodrigo o Cáceres; en Jaén, Úbeda y Baeza, únicas presentes en Andalucía, pero que con el tiempo pasaron al bando realista; y Murcia, que se encontraba bajo constante amenaza por parte de las ciudades realistas e influida por las Germanías presentes en el vecino Reino de Valencia.

La Junta que reclamaba Toledo con las ciudades con derecho a voto terminó reuniéndose en el mes de agosto, en Ávila, pero solamente con cuatro ciudades presentes: Toledo, Segovia, Salamanca y Toro. Fue redactada la conocida como "Ley Perpetua del Reino de Castilla ó Constitución de Ávila"; primer proyecto, en España, de constitución política que nunca llegaría a ser firmada por la reina Juana.

Tras este decepcionante resultado, la situación dio un vuelco cuando el 10 de junio el alcalde Rodrigo Ronquillo recibió la orden de investigar el reciente asesinato del procurador segoviano, pero en vez de eso, se dedicó a amenazar a los segovianos y a tratar de aislar a la ciudad impidiendo su aprovisionamiento. Ante esta situación, la población cerró filas en torno a la Comunidad y a su cabeza, Juan Bravo. La resistencia segoviana provocó que Ronquillo decidiera enviar al mayor número posible de soldados a pie y a caballo. Segovia entonces se echó en brazos de las ciudades castellanas, reclamando que acudieran en su auxilio y atendiendo su petición las ciudades de Toledo y Madrid, con el envío de milicias capitaneadas por Juan de Padilla y Juan de Zapata, sellándose la primera gran confrontación entre las fuerzas partidarias del rey y las rebeldes.

Ante esta situación, Adriano de Utrecht se planteó la posibilidad de utilizar la artillería real localizada en Medina del Campo, haciéndola definitiva al recibir la información de la aproximación de la milicia de Padilla a Segovia. Adriano ordenó entonces a Antonio de Fonseca apoderarse de la artillería, presentándose este el 21 de agosto en Medina para acometer lo ordenado, pero al tratar de realizarlo, se encontró con una fuerte resistencia de la población, que interpretaba que la artillería iba a utilizarse contra Segovia. Como medida de distracción, Antonio de Fonseca ordenó provocar un pequeño incendio para intentar dispersar a los medinenses, pero no surtió efecto y finalmente hubo de retirarse junto a sus tropas. El incendio de Medina del Campo provocó la destrucción de una parte importante de la villa y el levantamiento de toda Castilla, especialmente de ciudades que hasta ahora se habían mantenido al margen, como Valladolid. El establecimiento de la Comunidad en Valladolid provocó que el núcleo más importante de la meseta se declarara en rebeldía, trastocando la situación y provocando que el Cardenal Adriano tratara de tomar el control de la situación por todos los medios. El nuevo panorama produjo nuevas adhesiones a la Junta de Ávila, en medio de una situación de indignación y descrédito hacia el Consejo Real.

Así pues, el ejército comunero integrado por las milicias de Toledo, Madrid y Segovia, en su ruta hacia Tordesillas, se encontraba en los alrededores de Martín Muñoz de las Posadas el día en que Fonseca incendiaba Medina, llegando a la villa de las ferias el 24 de agosto, para tomar posesión de la artillería que días atrás había sido negada a las tropas de Fonseca. El 29 de agosto el ejército arribó finalmente a Tordesillas, entrevistándose con la reina Juana e informándola de la situación del reino junto a los propósitos de la Junta de Ávila, y declarando la reina que la Junta se situara a su servicio. De esta forma, la Junta se trasladó de Ávila a Tordesillas y se invitó a las ciudades que todavía no habían enviado a sus procuradores a hacerlo, estando a finales de septiembre un total de catorce ciudades representadas en la Junta de Tordesillas: Burgos, Soria, Segovia, Ávila, Valladolid, León, Salamanca, Zamora, Toro, Toledo, Cuenca, Guadalajara, Murcia y Madrid. Solamente no acudieron las cuatro ciudades andaluzas: Sevilla, Granada, Córdoba y Jaén.
Se delimitó entonces el área del movimiento comunero, en torno a la Meseta Central, y ya que la mayor parte del reino estaba representado en Tordesillas, la Junta pasó a denominarse como "Cortes y Junta general del reino".

A fecha de 24 de septiembre, los procuradores se entrevistaron con la reina y expusieron los fines de la Junta: proclamar la soberanía de la reina Juana y devolver la estabilidad perdida al reino. El día siguiente, 25 de septiembre, la Junta realizó una declaración comprometiéndose a utilizar las armas si esto fuera necesario y a auxiliar a cualquier ciudad que estuviera amenazada. El 26 de septiembre la Junta de Tordesillas decidió asumir ella misma la tarea de gobierno, desacreditando al Consejo Real y prendiendo, el 30 de septiembre, a sus últimos miembros que quedaban en Valladolid, dirigidos por Pedro Girón. En ese momento culminó el proceso y se instauró el gobierno revolucionario, ya que la Junta tenía vía libre por la inoperancia del Consejo Real.

La expansión de la rebelión comunera provocó la acusación de complicidad con los abusos reales extendida a todo el funcionariado castellano. La protesta comunera había nacido como queja ante excesos cometidos por la alta administración, pero pronto surgieron nuevas reivindicaciones ante otro tipo de perjuicios. Así ocurrió en Dueñas, cuando en la noche del 1 de septiembre de 1520 se sublevaron contra su señor los vasallos del conde de Buendía. A este levantamiento le siguieron otros de similar carácter antiseñorial. La Santa Junta se vio entonces obligada a tomar una posición: defender a los sublevados o a sus señores. En vista de que muchos de estos reclutaban hombres por su cuenta para garantizar su seguridad y tomar la justicia por su mano, la Junta decide apoyar dichas revueltas. La dinámica del levantamiento entró entonces en una nueva dimensión que podría comprometer la situación del régimen señorial en su conjunto, lo que provocó el alejamiento de la causa comunera de aristócratas y señores.

Ante la nueva situación, Carlos I, mediante el Cardenal Adriano, decidió emprender nuevas iniciativas políticas, como la de anular el servicio concedido en las Cortes de La Coruña-Santiago y nombrar dos nuevos gobernadores: el Condestable de Castilla, Íñigo de Velasco, y el Almirante de Castilla, Fadrique Enríquez. Además, Adriano consiguió acercar posturas con los nobles, a fin de convencerlos de que sus intereses y los del rey eran los mismos. Así pues, el Consejo Real se estableció en el feudo del Almirante, Medina de Rioseco, lo que permitió al consejo acercarse hacia las ciudades escépticas para tratar de acercarlas al bando realista, además de representar una amenaza hacia las ciudades sublevadas, ya que el ejército del Consejo Real estaba en formación.

Las primeras derrotas políticas de los comuneros llegaron en octubre de 1520, al conseguir instalarse los miembros del Consejo Real con total facilidad en Medina de Rioseco, con la capacidad de actuación bajo la protección del Almirante de Castilla, Fadrique Enríquez de Velasco, señor de la villa. De igual manera, las esperanzas que se habían depositado sobre la reina Juana no fructificaron, ya que esta se negaba a sellar algún compromiso o a plasmar su firma a modo de regente.

A su vez, comenzaban a oírse voces discordantes dentro del propio bando, especialmente la de Burgos, que insistía en dar marcha atrás. La postura de esta ciudad pronto llegó a oídos del Condestable de Castilla, que bajo órdenes del rey procedió a entrar en la ciudad el 1 de noviembre, concediendo todo lo que se le reclamaba para desligar a Burgos de la Junta.

Tras este suceso, el Consejo Real esperaba que otras ciudades imitaran a Burgos y abandonaran el bando comunero. El esperado cambio de bando estuvo a punto de producirse en Valladolid, pero los partidarios del rey fueron finalmente apartados de la vida política de la ciudad y esta se mantuvo en rebeldía.

En noviembre de 1520, el Almirante de Castilla comenzó una campaña para intentar convencer a los comuneros de su derrota y que no había más remedio que entregar las armas y evitar una represión armada. Bajo esta actitud, se escondía una gran carencia de fondos en el bando real, que terminó subsanándose con la ayuda financiera venida desde Portugal y el retorno de la confianza perdida por parte de los banqueros castellanos, que vieron buenos indicios en el cambio de bando de Burgos.

Durante octubre y noviembre de 1520, ambos bandos se dedicaron activamente a recaudar fondos, reclutar soldados y organizar a sus tropas. El poder real superó la rebelión gracias al apoyo de la nobleza, de los grandes comerciantes castellanos, en un plano en el que la situación comenzaba a adquirir tintes militares. Los comuneros organizaban sus milicias en las principales urbes con el objetivo de asegurar el éxito de la rebelión en la ciudad y sus alrededores, sufragando los gastos con el dinero recaudado en impuestos y en imposiciones.

Poco a poco, Toledo fue perdiendo influencia dentro de la Junta, y con la ciudad, también perdía influencia su líder, Juan de Padilla, aunque no así popularidad y prestigio entre los comuneros. Con la pérdida de influencia de Toledo y de sus líderes, surgieron dos nuevas figuras dentro de la Comunidad, Pedro Girón y Antonio de Acuña, que aspiraban a pasar al primer plano. El primero era uno de los pocos nobles leales comuneros, al parecer porque el rey se negó a entregarle el ducado de Medina Sidonia. El segundo, era obispo de Zamora, jefe de la Comunidad zamorana y cabecilla de una milicia formada enteramente por sacerdotes.

Mientras tanto, en el bando realista, los señores no sabían que táctica seguir, si luchar directamente, como defendía el Condestable de Castilla o agotar las vías de negociación, como proponía el Almirante de Castilla. Todo intento de negociación entre los comuneros y los virreyes fracasó, debido a que ambos bandos contaban ya con un ejército y ansiaban vencer al enemigo.

Así pues, a finales de noviembre de 1520, ambos ejércitos tomaban posiciones entre Medina de Rioseco y Tordesillas, haciendo inevitable el enfrentamiento.

Con Pedro Girón a la cabeza, las tropas comuneras, siguiendo órdenes de la Junta, habían avanzado hacia Medina de Rioseco, estableciendo su cuartel general en la localidad de Villabrágima, a tan solo una legua del ejército real. Estos, mientras tanto, se limitaron a ocupar pueblos para evitar el avance y cortar las líneas de comunicación.

La situación se mantuvo hasta el 2 de diciembre, cuando el ejército rebelde comenzó a abandonar sus posiciones en Villabrágima, tomando dirección hacia Villalpando, localidad del Condestable que se rindió al día siguiente sin oponer resistencia. Con este movimiento, la ruta hacia Tordesillas quedaba desprotegida. El ejército real lo aprovechó, poniéndose en marcha el 4 de diciembre y ocupando la villa tordesillana al día siguiente, tras haber derrotado a la guarnición defensiva comunera, que se vio desbordada.

La toma de Tordesillas supuso una seria derrota para los comuneros, que perdían a la reina Juana, y con ella, sus esperanzas de que esta atendiera sus pretensiones. Además, muchos de los procuradores habían sido apresados, y los que no, habían huido.

Por todo esto, los ánimos entre los rebeldes se vieron muy afectados, además de producirse airadas críticas hacia Pedro Girón por el movimiento de las tropas que le obligaron a dimitir de su puesto y apartarse del conflicto.

Tras la derrota de Tordesillas, los comuneros comenzaron a reagruparse en Valladolid, donde se estableció la Junta, pasando la ciudad del Pisuerga a ser la tercera capital del movimiento, tras Ávila y Tordesillas.

Así pues, el 15 de diciembre, la Junta ya se encontraba de nuevo activa en Valladolid, con doce de los catorce procuradores originales. Solamente faltaron los de Soria y Guadalajara. La situación del ejército era similar, con un gran número de deserciones en las tropas emplazadas en Valladolid y Villalpando, lo que obligó a intensificar el reclutamiento en las ciudades rebeldes, especialmente en Toledo, Salamanca y la propia Valladolid. Con estos nuevos reclutamientos, el aparato militar rebelde estaba reconstruido, y la moral reforzada, gracias a la presencia de Padilla en Valladolid. Con la llegada de 1521, los comuneros parecían ya dispuestos a una guerra total, pese a las voces discordantes dentro del propio movimiento. Por un lado había quienes proponían buscar una solución pacífica, y por otro quienes eran partidarios de continuar la lucha armada; a su vez divididos entre seguir dos tácticas: ocupar Simancas y Torrelobatón (propuesta menos ambiciosa y defendida por Pedro Laso de la Vega); o poner cerco a Burgos (grupo encabezado por Padilla). La Junta decidió seguir ambas iniciativas, tanto la pacifista como la belicista, y terminó fracasando en ambas.

En el plano bélico, el ejército rebelde comenzó a desarrollar una serie de operaciones dirigidas por Antonio de Acuña, . Este había recibido órdenes de la Junta el día 23 de diciembre de intentar despertar la rebelión en la zona de Palencia. Su tarea consistía básicamente en expulsar a los realistas, recaudar impuestos en nombre de la Junta y nombrar una administración afín a la causa comunera. Realizó una serie de incursiones en la zona de Dueñas, recaudando más de 4000 ducados y exaltando a la población. Retornó a Valladolid a comienzos de 1521 para regresar a Dueñas el 10 de enero, dando comienzo a una gran ofensiva contra los señoríos de Tierra de Campos, dejando las posesiones de los señores totalmente devastadas.

A mediados de enero, Pedro López de Ayala, conde de Salvatierra, adherido al movimiento comunero, había organizado un ejército de unos dos mil hombres y se dirigía hacia Medina de Pomar y Frías, buscando el levantamiento de las Merindades, tierra del Condestable de Castilla.

Mientras tanto, Burgos, que llevaba ya dos meses fiel al bando real, aguardaba el cumplimiento de las promesas realizadas por el cardenal Adriano, lo que había provocado el descontento y la incertidumbre en la ciudad. Ayala y Acuña, conscientes de esta situación, decidieron cercar Burgos, el primero por el norte y el segundo por el sur, buscando el levantamiento de los comuneros burgaleses.

Por parte del rey, Carlos I firmó el 17 de diciembre de 1520 el Edicto de Worms (no se confunda con el Edicto de Worms de 25 de mayo de 1521, contra Lutero), donde condenaba a 249 comuneros destacados: a muerte, si eran seglares; y a otras penas, si eran clérigos. De igual modo, declaraba también traidores, desleales, rebeldes e infieles a cuantos apoyaran a las Comunidades. Dicho Edicto, fue leído públicamente en Burgos el 16 de febrero de 1521.

Desde el Consejo Real, se ordenó la ocupación del castillo de Ampudia, lo que provocó un gran desorden en el dispositivo organizado por los rebeldes. Ante dicha ocupación, la Junta envió a Padilla al encuentro de Acuña, uniéndose ambos en Trigueros del Valle y formando un ejército de aproximadamente 4000 hombres. Las tropas comuneras ocuparon Torremormojón, desplazando a los realistas, para centrarse en Ampudia, la cual se rindió el 16 de enero previo pago de tributo.

Mientras tanto, la rebelión comunera prevista en Burgos para el 23 de enero fue todo un fracaso, debido a que se adelantó dos días. Los comuneros burgaleses hubieron de rendirse, siendo el último intento de rebelión acontecido en la "cabeza de Castilla".

Tras el fracaso acontecido en Burgos, Padilla decidió regresar a Valladolid, mientras que Acuña optó por reemprender su hostigamiento a las propiedades de los señores en Tierra de Campos. Con esta serie de acciones, Acuña pretendía destruir u ocupar las plazas imperantes de los señores, otorgando a la revuelta comunera uno de sus rasgos más característicos de su segunda etapa: su rechazo al orden social basado en el régimen señorial.

Así pues, después de los últimos fracasos sufridos por los comuneros, Padilla deseaba obtener un triunfo para elevar la moral de la tropa y de todo el movimiento. Fue entonces cuando se decidió a tomar
Torrelobatón y su castillo. Era una plaza fuerte a medio camino entre Tordesillas y Medina de Rioseco, y muy cercana a Valladolid, por lo que podía ser una excelente base para emprender acciones militares.

El 21 de febrero de 1521 comenzó el asedio de la villa, que resistió durante cuatro días, gracias a sus murallas. El 25 de febrero los comuneros conseguían entrar en la localidad. Esta fue sometida a un enorme saqueo como premio a las tropas, del que solamente se salvaron las iglesias. El castillo continuó resistiendo, pero terminó rindiéndose ante la amenaza de ahorcar a todos los habitantes si no claudicaba, no antes de acordarse la conservación de la mitad de los bienes que se encontraran en el castillo, evitando así su saqueo.

La victoria en Torrelobatón levantó los ánimos en el bando comunero, hasta el punto de sembrar el entusiasmo, mientras que en el bando realista, provocó la inquietud ante el avance rebelde. Esta inquietud alteró a los nobles fieles al cardenal Adriano, que se acusaban mutuamente de no haber hecho nada para evitar la pérdida de Torrelobatón. Asimismo, el Condestable comenzó a enviar tropas a la zona de Tordesillas, a modo de refuerzos y como guarnición ante los comuneros.

Pero pese al entusiasmo presente entre los rebeldes, estos decidieron mantenerse en sus posiciones de los Montes Torozos, sin lanzar ningún ataque, lo que provocó que muchos de los soldados comuneros volvieran a sus casas, cansados de esperar los sueldos y nuevas órdenes.

Tras la muerte de Guillermo de Croy, arzobispo de Toledo, en enero de 1521, desde la Junta, presente en Valladolid, se propuso a Antonio de Acuña como aspirante a la sede y se le encomendó la misión de tomar posesión del arzobispado.

Acuña partió en febrero rumbo hacia Toledo, con una pequeña tropa bajo su mando. Recorrió localidades como Buitrago del Lozoya y Torrelaguna, donde anunció que iba a tomar posesión del arzobispado de Toledo. Esto levantó el entusiasmo entre los partidarios comuneros de Alcalá de Henares, que lo recibieron con vítores el 7 de marzo en dicha ciudad, y despertó el recelo en la aristocracia presente en la zona de Toledo, que temía que Acuña pudiera actuar en sus tierras como ya hizo en Tierra de Campos. Entre los aristócratas más importantes presentes en la zona se encontraban el marqués de Villena y el duque del Infantado, que enseguida trataron de ponerse en contacto con Acuña, firmando un pacto mutuo de neutralidad.

Sin embargo, sí hubo de enfrentarse con el prior de la Orden de San Juan, Antonio de Zúñiga, presente en Consuegra y nombrado por los regentes jefe de las fuerzas realistas presentes en la zona de Toledo. Acuña recibió informaciones sobre la presencia del prior cerca de Corral de Almaguer a mediados de marzo, por lo que salió tras él, buscando batalla cerca de Tembleque. El prior consiguió repeler el ataque, para lanzar uno improvisado entre Lillo y El Romeral, infligiendo una contundente derrota a Acuña, el cual trató de minimizarla, llegando incluso a afirmar que había salido victorioso del enfrentamiento.

Tras la victoria del prior de la Orden de San Juan, Acuña se encaminó hacia Toledo, presentándose en la Plaza de Zocodover el 29 de marzo, Viernes Santo. La multitud lo rodeó y lo llevó directamente a la catedral, reclamando la silla del arzobispo para él. Al día siguiente, 30 de marzo, se entrevistó con María Pacheco, mujer de Padilla y que dirigía la comunidad toledana en ausencia de su marido. Surgió entre ambos una rivalidad por el control, que se resolvió con intentos mutuos de reconciliación.

Una vez asentado en el arzobispado toledano, Acuña comenzó a reclutar a hombres de 15 a 60 años para volver a combatir a las tropas del prior de San Juan. Tras la quema de Mora el 12 de abril

Ya desde principios de abril de 1521, el bando realista estaba desplegando un enorme ejército en los alrededores de Tordesillas, con 3000 infantes, 600 lanzas, dos cañones, dos culebrinas y cinco piezas ligeras de artillería. Dicho ejército se dedicó a ocupar posiciones en localidades como Becerril de Campos, cercana a Palencia, y Peñaflor de Hornija, uniéndose a tropas del Almirante y de los señores de Tordesillas.

Mientras tanto, los comuneros, reforzaron sus efectivos de Torrelobatón, pero su ejército no se encontraba del todo cohesionado, por lo que Padilla manejaba la posibilidad de desplazarse hasta Toro en busca de refuerzos.

Padilla decidió finalmente partir hacia Toro en la madrugada del 22 al 23 de abril, tras haber perdido bastante tiempo, lo que permitió a los realistas aglutinar a todas sus tropas.

Nada más partir hacia Toro, las tropas realistas del Almirante y el Condestable presentes en Peñaflor de Hornija salieron tras la pista de Padilla, alcanzándolo finalmente en la localidad de Villalar.

En medio de una intensa lluvia, Padilla intentó primero atrincherar a sus prácticamente 6000 hombres en Vega de Valdetronco, pero no consiguió desplegar a sus tropas y se vio obligado a prestar batalla en Villalar, donde la caballería realista, compuesta por unas 500 o 600 lanzas, aplastó al ejército rebelde, que no tuvo tiempo de desplegarse.

La batalla se saldó con prácticamente mil bajas por parte de los comuneros y el apresamiento de sus líderes principales: Juan de Padilla, Juan Bravo y Francisco Maldonado. Estos fueron decapitados en la mañana del 23 de abril en un cadalso situado en la Plaza Mayor de Villalar, estando presente la mayor parte de la nobleza afín al rey, que asestaba así un golpe prácticamente definitivo a la rebelión.

Mientras tanto, el resto del ejército comunero que consiguió escapar, trató de continuar hasta Toro, pero terminó por fragmentarse, fruto de la persecución que estaba ejerciendo el Condestable de Castilla sobre él.

Tras la batalla de Villalar, las ciudades de Castilla la Vieja no tardaron en sucumbir al potencial de las tropas del rey, volviendo todas las ciudades del norte a prestar lealtad al rey a primeros de mayo. Únicamente Madrid y Toledo, especialmente esta última, mantuvieron vivas sus comunidades durante un tiempo mayor.

Las primeras noticias de Villalar llegaron a Toledo el 26 de abril, siendo ignoradas por parte de la Comunidad local. La certeza de la derrota se hizo evidente a los pocos días, cuando comenzaron a llegar los primeros supervivientes a la ciudad, que confirmaron el hecho y dieron testimonio del ajusticiamiento de los tres líderes rebeldes. Fue entonces cuando Toledo se declaró en duelo por la muerte de Juan de Padilla.

Tras la muerte de Padilla, Acuña perdió popularidad entre los toledanos, en favor de María Pacheco, viuda de Padilla. Comenzaban a surgir voces que solicitaban la negociación con los realistas, buscando el evitar el sufrimiento de la ciudad, más aún tras la rendición de Madrid el 7 de mayo. Todo parecía indicar que la caída de Toledo era cuestión de tiempo.

En este contexto, Acuña abandonó la ciudad, intentando huir al extranjero por la frontera del Reino de Navarra. En ese momento, se produjo la invasión francesa de Navarra, siendo Acuña reconocido y detenido en la frontera.

La invasión francesa provocó que el ejército realista hubiera de concentrarse en expulsar a los franceses de Navarra, postergando momentáneamente el restituir la autoridad del rey en Toledo.
A partir de ese momento, María Pacheco asumió el control de la ciudad, instalándose en el Alcázar, recabando impuestos y fortaleciendo las defensas. Solicitó la intervención del marqués de Villena para negociar con el Consejo Real, con el objetivo de obtener unas mejores condiciones que negociando directamente.

El marqués de Villena terminó abandonando las negociaciones entre ambos bandos, por lo que María Pacheco asumió de manera personal las negociaciones con el prior de la Orden de San Juan. El pacto de rendición de Toledo fue acordado el 25 de octubre de 1521 gracias a la intervención de Esteban Gabriel Merino, arzobispo de Bari y enviado del prior de San Juan.

Así pues, el 31 de octubre los comuneros abandonaron el Alcázar toledano y el arzobispo de Bari nombró a los nuevos funcionarios.

Tras la vuelta al orden de Toledo, el nuevo corregidor de la ciudad acató las órdenes recibidas de restablecer al completo la autoridad del rey en la ciudad, dedicándose a provocar a los antiguos comuneros. María Pacheco continuaba presente en la ciudad, y se negaba a entregar las armas hasta que el rey firmara de forma personal los acuerdos alcanzados con el prior de San Juan. Por ello, el corregidor toledano exigía la cabeza de María Pacheco.

La situación llegó a un extremo cuando el 3 de febrero de 1522 se ordenó apresar a un agitador, a lo que los comuneros se opusieron. Se inició entonces un enfrentamiento, subsanado gracias a la intervención de María de Mendoza, hermana de María Pacheco. Se concedió una tregua, que supuso la derrota de los comuneros, pero que fue aprovechada por María Pacheco para escapar a Portugal, donde se exilió hasta su muerte, en 1531.

Carlos I regresó a España el 16 de julio de 1522, instalando la corte en Palencia. A partir de la llegada del rey, la represión contra los excomuneros avanzaría a un ritmo mayor. Así lo demuestra la ejecución de Pedro Maldonado, líder salmantino y primo de Francisco Maldonado, ejecutado en Villalar.

Carlos I permaneció en Palencia hasta finales del mes de octubre, trasladándose a Valladolid, donde el 1 de noviembre se promulgó el Perdón General, que daba la amnistía a quienes habían participado del movimiento comunero. Sin embargo, un total de 293 personas -pertenecientes a todas las clases sociales y entre las que se incluían María Pacheco y el Obispo Acuña- fueron excluidas del Perdón General.

Se estima que fueron un total de cien los comuneros ejecutados desde la llegada del rey, siendo los más relevantes Pedro Maldonado y el Obispo Acuña, siendo este último ajusticiado en el castillo de Simancas el 24 de marzo de 1526, tras un intento frustrado de fuga. A raíz de esta ejecución, Carlos I fue excomulgado por ordenar el ajusticiamiento de un prelado de la iglesia. Las relaciones entre los dos poderes universales sufrieron grandes altibajos tras la elección de un papa tan favorable como fue el mismísimo Adriano de Utrecht (1522-1523), y pasaban por un momento muy negativo con el profrancés Clemente VII (1523-1534), que acabó sufriendo el saco de Roma (1527), tras lo que se vio obligado a reconciliarse con Carlos y coronarle emperador en Bolonia (1530).

Las consecuencias fundamentales de la Guerra de las Comunidades fueron la pérdida de la élite política de las ciudades castellanas, en el plano de la represión real; y en las rentas del Estado. El poder real se veía obligado a indemnizar a aquellos que perdieron bienes o sufrieron daños en sus posesiones durante la revuelta. Las mayores indemnizaciones correspondían al Almirante de Castilla, por los daños sufridos en Torrelobatón y los gastos ocasionados en la defensa de Medina de Rioseco. Le seguían el Condestable y el obispo de Segovia.

La forma de pago de estas indemnizaciones se solucionó mediante un impuesto especial para toda la población de cada una de las ciudades comuneras. Estos impuestos mermaron las economías locales de las ciudades durante un periodo aproximado de veinte años, debido a la subida de precios. De igual modo, la industria textil del centro de Castilla perdió todas sus oportunidades de convertirse en una industria dinámica.

La nobleza queda definitivamente neutralizada frente a la triunfante monarquía autoritaria; su segmento alto o aristocracia, se vio compensada por su apoyo al emperador, con cuyos intereses quedaba identificada estrechamente, pero quedando clara la subordinación de súbditos a monarca. Las Cortes de Toledo de 1538, últimas a las que se convocó a la nobleza como "brazo" o "estamento", sancionaron esa nueva forma de gobernar la Corona de Castilla, pieza central de lo que ya puede llamarse la Monarquía Católica o Monarquía Hispánica de los Habsburgo. A esas alturas, los sueños de la "Idea imperial de Carlos V" habían quedado en gran parte diluidos, lo que quedó confirmado en el reinado de su hijo Felipe II.

Ya en el Siglo de Oro se comenzó a hacer alusiones a las Comunidades en las obras literarias, destacando la alusión realizada en El Quijote. Igualmente, aparece citada la palabra comunero por Francisco de Quevedo como sinónimo de rebelde.

A partir del siglo XIX, comenzó a rehabilitarse la figura de los Comuneros, restituyéndoles como precursores de la libertad y mártires del absolutismo.

El primer gran acto conmemorativo llegó en 1821, con motivo del III Centenario de la batalla de Villalar. A dicha localidad de Villalar acudió Juan Martín Díez, "El Empecinado", con una expedición para exhumar los restos de los capitanes ajusticiados en 1521. Se iniciaron entonces los homenajes a los comuneros por parte del gobierno liberal en el poder.

A partir de ese momento comenzó a ensalzarse la figura antidéspota, nacionalista y liberal de los comuneros, como defensores de las libertades frente al absolutismo y de la identidad nacional frente a la extranjera, representada por los flamencos.

En 1869, en Valladolid, a fecha del 15 de junio, se firmó el Pacto Federal Castellano entre las diecisiete provincias castellanas, que termina con la siguiente alusión a las Comunidades:
Los primeros estudios sobre la figura de los comuneros y de las Comunidades fueron realizados por Ángel Ganivet, precursor de la generación del 98. Tras él, vendrían otros autores como Manuel Azaña, presidente de la Segunda República Española o Gregorio Marañón.

Como reacción a la interpretación "romántica-liberal" dominante durante el siglo XIX, se fue formulando una interpretación alternativa de carácter "tradicionalista-reaccionario" o "conservador" (originada en la interpretación histórica general de Marcelino Menéndez y Pelayo y explicitada por Ramón Menéndez Pidal o José María Pemán), que se hará oficial durante el franquismo a través de su visión del nacionalismo español e impuesta a través de la escuela nacionalcatólica (la que se refleja en "El florido pensil"). Según esta visión, los comuneros eran "politicastros" comparados explícitamente con los nacionalistas periféricos, motivados por razones espurias o bienintencionados que no llegaban a entender lo sublime del "destino imperial" por no alcanzar a ver más allá "del campanario de su aldea".

Desde mediados del siglo XX, la renovación de la historiografía introdujo cambios metodológicos, principalmente provenientes de Francia ("Escuela de los Annales"), que fueron introducidos tanto por los historiadores hispanistas como por los autóctonos, por ejemplo el español José Antonio Maravall o el francés Joseph Pérez. En algunos casos se intentaron explicaciones de carácter materialista, que buscaban los motivos de los alineamientos políticos en distintas coaliciones sociales en torno a intereses económicos.

El gran impulso a la revitalización simbólica de las Comunidades con motivos reivindicativos llegó a partir del año 1976, en plena Transición española convocado por el Instituto Regional Castellano-Leonés. A partir de ese año, comienzan a celebrarse concentraciones en Villalar cada 23 de abril. Ese mismo año, el grupo segoviano Nuevo Mester de Juglaría musicalizó el romance de Los Comuneros, compuesto en 1972 por el poeta leonés Luis López Álvarez.

Tras varios años de concentraciones no autorizadas en Villalar cada 23 de abril para conmemorar la derrota comunera, la fiesta adquirió el carácter de oficial en el año 1983, tras la conformación de la comunidad autónoma de Castilla y León.

De igual modo, cada 3 de febrero desde el año 1988, en recuerdo de la rebelión de 1522, último acontecimiento militar de la Guerra, se celebra el homenaje a los Comuneros en Toledo, resaltando la figura de Juan de Padilla y de María Pacheco.

Desde el año 2007, el castillo de Torrelobatón alberga el centro de interpretación de la Guerra de las Comunidades de Castilla, por lo que el castillo se conoce como el "Castillo de los Comuneros de Torrelobatón".

El 15 de marzo de 2015 fue inaugurado en Toledo el monumento a Juan de Padilla en la plaza que ocupa el solar en que se levantaban sus casas. De este modo se ponía fin a un anhelo histórico de la ciudad castellana, que había visto cómo hasta en siete ocasiones el intento por erigir este homenaje había fracasado. El notable monumento, obra de Julio Martín de Vidales y sufragado por la Fundación Soliss, está realizado en bronce con un pedestal de piedra de los Montes de Toledo y alcanza una altura total de 4,72 metros y pesa 32 toneladas.

Después de la Transición, han sido bastantes los partidos de índole castellanista y regionalista que han utilizado la figura de los comuneros, bien en sus campañas, como parte del nombre del partido o como seña de identidad simbólica para Castilla y León o para un contexto territorial más amplio (las antiguas "Dos Castillas": Castilla la Nueva y Castilla la Vieja) que incluiría a Cantabria, La Rioja, Comunidad de Madrid y Castilla-La Mancha. Al mismo tiempo, nacieron los denominados "Concejos Comuneros", formados por emigrantes castellanos en otras ciudades, siendo los más destacados los de ciudades como Barcelona.

Así, entre los primeros partidos de las tendencias ya mencionadas, se encuentra la Unidad Comunera Castellana, ya desaparecida, o Tierra Comunera, uno de los de mayor importancia electoral y desaparecido en 2009.





</doc>
<doc id="45469" url="https://es.wikipedia.org/wiki?curid=45469" title="Subcategoría">
Subcategoría

En matemática, una subcategoría de una categoría "C" es un subconjunto de los morfismos que es cerrado por composición y contiene todos los morfismos identidad. Una subcategoría es por completo ("full") si para cada par ordenado de sus morfismos identidad, contiene cada morfismo de "C" entre los objetos correspondientes.


</doc>
<doc id="45470" url="https://es.wikipedia.org/wiki?curid=45470" title="Señor de Sipán">
Señor de Sipán

El Señor de Sipán fue un antiguo gobernante mochica del siglo III, cultura que dominó el norte del Antiguo Perú. Sus restos fueron descubiertos en julio de 1987 por un equipo peruano de arqueólogos liderado por Walter Alva y Luis Chero Zurita.

Este hallazgo marcó un importante hito en la arqueología del continente americano porque, por primera vez, se halló intacto y sin huellas de saqueos, un entierro real de una civilización peruana anterior a los incas. El ataúd de madera en que fue enterrado fue el primero en su tipo que se encontró en América y reveló la magnificencia y majestuosidad del único "gobernante y guerrero" del antiguo Perú encontrado hasta la fecha de su descubrimiento, cuya vida transcurrió alrededor del año 250 de nuestra era.

Su descubrimiento se realizó en el centro poblado de Sipán en Chiclayo Lambayeque, anexo de Saltur del distrito de Zaña; perteneció a la cultura Mochica que rendía culto al dios Aiapaec como divinidad principal, y también adoraron al mar y la Luna.

Encontramos dentro de la cultura moche dos áreas geográficas: los mochica del norte y los mochica del sur. 

Los mochica del sur ocuparon los valles sureños de la costa norte de los andes centrales: valle de Culebras, valle de Huarmey, valle de Casma, valle de Nepeña, valle del Santa, valle de Virú, valle de Moche y valle de Chicama. 

Los mochica del norte ocuparon los valles más norteños: valle de Jequetepeque, valle de Zaña, valle de Lambayeque y valle de Chancay.

El Señor de Sipan perteneció a estos mochica del norte los cuales se caracterizaron por no tener un gobernante central y común y en cada uno de los valles citados gobernaba un señor y el Señor de Sipán fue uno de ellos.

Alrededor de 600 objetos recuperados en la tumba del Señor de Sipán. Sobresalen la vestimenta, que medía aproximadamente 1.67 m, los tres pares de orejeras de oro y turquesa o el collar formado por veinte frutos de maní, de los cuales diez están elaborados en plata y otros diez en oro, aludiendo a la dualidad presente en la cosmovisión mochica. Se trata de un símbolo religioso de los dioses principales, el Sol y la Luna, y hace referencia a la visualización de ambos dioses en el firmamento en un momento del día. Es decir, el perfecto equilibrio deseado, según la mitología mochica. Además el maní significaba el comienzo o el renacer.

Junto a los del Señor de Sipán se encontraron restos de otros ocho individuos, tres mujeres, cuatro hombres y un niño. Se cree que las mujeres podrían haber sido concubinas, mientras que los hombres han sido interpretados como un jefe militar, un vigía y un soldado, este último con los pies amputados. Además, se hallaron restos de dos llamas y un perro.

Debajo de la tumba del Señor de Sipán se encontraron otras dos, la del sacerdote y la del Viejo Señor de Sipán.

En la del sacerdote, se hallaron piezas que indicaban que sería uno de los principales personajes en la jerarquía religiosa de la civilización mochica. Este sacerdote, por los análisis de ADN efectuados, fue contemporáneo al Señor de Sipán. En las piezas que le acompañaban destacan, además de símbolos religiosos como el sol y la luna, la copa o el cuenco destinados a los sacrificios, una corona de cobre bañada en oro y adornada con un búho con sus alas extendidas y otros elementos para el culto a la Luna y el Sol. La presencia de este personaje hace suponer que los mochicas eran gobernados mediante un estado teocrático.

Por los mismos análisis de ADN, se ha probado que con una diferencia de cuatro generaciones, el "Viejo Señor de Sipán" era un antepasado directo del mismo Señor de Sipán, por lo que se podría pensar en una alta jerarquía hereditaria.

Apoyándose en los exámenes de ADN y arqueológicos realizados, se ha podido establecer las características del Señor de Sipán como el color de su piel, su tipo de labios, cabello, ojos y otros rasgos de su fisonomía. Igualmente, se pudo establecer su edad, por lo que la reconstrucción realizada corresponde a la de este gobernante tal cual fue. Era Rh negativo, lo cual indica que tenía un tipo de sangre poco común.

Vista la importancia del hallazgo, Walter Alva impulsó la construcción del "Museo Tumbas Reales de Sipán", que fue inaugurado en el 2002. Está ubicado en Lambayeque, y su edificación se inspiró en las antiguas pirámides truncadas de la prehispánica Civilización Moche (siglo I a VII d. C.). El museo custodia más de dos mil piezas de oro.

Sin lugar a dudas, el principal atractivo es la tumba del Señor de Sipán, con sus acompañantes y sus respectivos ajuares funerarios. En algunos museos de Lima y en el Palacio de Gobierno existen salas donde se encuentran y exponen alguna ropas, armas, etc, del Señor de Sipán y hasta una forma no original de su tumba, como está organizada y su estructura.

En 2008 el periodista y cineasta español José Manuel Novoa dirigió el documental "Las Tumbas Reales del Perú", sobre el descubrimiento de la tumba y los restos del Señor de Sipán, contando con el apoyo del propio Walter Alva. El documental, producido por Explora Films, El Deseo y RBA Audiovisuales, se considera uno de los más ambiciosos que jamás se hayan hecho en España sobre arqueología. Además, durante el rodaje del mismo, se excavó la tumba número 14 de la plataforma funeraria de Sipán, por lo que el espectador es testigo de todo el proceso de excavación y desenfardado de una momia de la época preincaica.




</doc>
<doc id="45472" url="https://es.wikipedia.org/wiki?curid=45472" title="Funtor">
Funtor

En teoría de categorías un funtor o functor es una función de una categoría a otra que lleva objetos a objetos y morfismos a morfismos de manera que la composición de morfismos y las identidades se preserven.

Los funtores primero se consideraron en topología algebraica, donde se asocian los objetos algebraicos con los espacios topológicos y se asocian los homomorfismos algebraicos con funciones continuas. Hoy en día, los funtores se utilizan a través de las matemáticas modernas para relacionar varias categorías. 

Ejemplos de functores típicos son el funtor fiel y el funtor pleno.



</doc>
<doc id="45475" url="https://es.wikipedia.org/wiki?curid=45475" title="Xochiquétzal">
Xochiquétzal

Xochiquétzal, Xoquiquetzatl o Xochiquetzalli , también llamada Ichpōchtli en la mitología mexica es la diosa de la belleza, las flores, el amor, el placer amoroso, y las artes. Es una de las dos diosas relacionada con la fertilidad de la naturaleza y la belleza, quizás por ello se le representa como madre de Centéotl o Cintéotl. Xochiquétzal, “flor preciosa”, nació de los cabellos de la diosa madre. 

Las flores de cempasúchil están consagradas a ella. Solía invocarse a Xochiquétzal para obtener belleza, sensualidad, para poder sobrevivir en caso de peligro, para hacer manualidades, lograr la fertilidad, el parto, buena cosecha, la danza, la música, el canto, la recuperación después de un desastre, la herbolaria, la libertad sexual, para hablar de amor, lograr un buen tejido, placer sexual, erotismo, y lograr matrimonios estables. Plumas, margaritas y pequeños azulejos con su imagen eran la mejor ofrenda para Xochiquétzal. Es hermana melliza de Xochipilli. Su primer esposo fue Tláloc, aunque también estuvo casada con Ixotecuhtli el dios de la libertad, con Piltzintecuhtli y con Centéotl. Xochiquétzal también fue amante de Tezcatlipoca.

En los mitos de creación se menciona que fue mujer de Piltzintecuthli, hijo de la primera pareja de hombres: Cipactónal y Oxomoco. Con Piltzintecuhtli tuvo un hijo, Cintéotl, dios del maíz, y en otros mitos se cuenta que también engendraron a Nanahuatzin, quien se sacrificaría en el fogón divino para convertirse en el Quinto Sol, y a Xochipilli, dios de las flores y también conocido como dios del amor. Tuvo varios consortes y amantes. Primero habitaba en Tamoanchan, “cerro de la serpiente”, uno de los paraísos situado en el primer cielo, el Tlalocan, el cual se localizaba en la cumbre del Cerro de la Malinche. Esta morada era una región llena de deleites y pasatiempos agradables en donde había fuentes, ríos, florestas y lugares de recreación. En este sitio había un árbol florido, y el que alcanzaba a coger una de sus flores o era tocado por alguna de ellas sería dichoso y fiel enamorado. Xochiquétzal era atendida por otras diosas y estaba acompañada y guardada por mucha gente, de tal manera que ningún hombre la podía ver. Los que la cuidaban eran enanos, jorobados, payasos y bufones, que la divertían con música y bailes, y que también desempeñaban el oficio de embajadores cuando mandaba mensajes a los dioses que ella cuidaba. 

Ella vive en el noveno cielo, la región del viento de obsidiana "itzeechecayan" y es una diosa dual, es decir, tanto solar como lunar. Su carácter lunar se ve en el códice Borgia, donde alguna vez se le iguala con Tlazoltéotl. Se menciona que pasaba parte de su tiempo en el Valle de Huejucar lugar prodigioso donde ayudó a las tejedoras a crear un regalo enviado por los dioses al mundo a través de ellas, su carácter solar se ve en su representación como mariposa y su vestimenta el "yacapapálotl" o "teocuitlayacapapálotl".

Xochiquetzalli es una metáfora de la joven que da placer sexual a los jóvenes y que representa la tentación que hace caer a los hombres castos; es naturalmente una joven hermosa, y alegre. Representa los encuentros juveniles, espontáneos, pero sobre todo libres, los cuales no eran sancionados entre los varones.

Se le puede considerar la encarnación misma de la femineidad, principalmente de la femineidad joven y es por ello el numen protector del trato carnal. Xochiquetzalli era la protectora e inspiradora de los artistas, tejedoras, soldaderas, de los orfebres y pintores, de las prostitutas (llamadas "aiuanime") y la abogada de las embarazadas. También es patrona de los quehaceres domésticos.

La mayor parte de los textos nahuas que hablan de la diosa madre, nos la presentan como una diosa anciana; Tonantzin la señora vieja" Ilamatecuhtli, sin embargo existe una versión joven de la diosa madre.



En "Indiana Jones en busca del Arca Perdida" se hace referencia a la Diosa de la Fertilidad en una forma similar inspirada totalmente en la Xochiquétzal, aunque se nos presenta en el film como una Ídolo de Oro de la tribu/cultura de Los Chachapoyas de Perú.



</doc>
<doc id="45477" url="https://es.wikipedia.org/wiki?curid=45477" title="Copa del Rey">
Copa del Rey

El Campeonato de España-Copa de Su Majestad el Rey, más conocido como Copa del Rey o La Copa, es una , organizada anualmente por la Real Federación Española de Fútbol y disputada por los 116 mejores .

Es el más antiguo del país: su primera edición se disputó en 1903, a raíz del éxito de la primera competición a nivel nacional disputada en España, el Concurso Madrid de Foot-ball Association, denominada popularmente como Copa de la Coronación, que se disputó un año antes con motivo de los festejos de coronación de Alfonso XIII. En sus inicios fue considerada como la competición más prestigiosa a nivel de clubes en el país, hasta la creación del Campeonato Nacional de Liga.

El club vencedor tiene la condición de «campeón de España» y, a lo largo de su historia, catorce clubes han logrado este título. El Fútbol Club Barcelona es el club más laureado de la competición con . Por su parte, Lionel Messi, Sergio Busquets y Agustín "Piru" Gaínza son los futbolistas con más finales disputadas, nueve cada uno, y "Piru" es el más laureado con siete títulos, todos logrados con el Athletic Club.

Desde la edición 2019-20 el estadio de La Cartuja de Sevilla fue la sede oficial de la final por un período de cuatro años. Fue una novedad ya que hasta entonces el estadio era designado por la Federación en función de los equipos finalistas. Como novedad en esta edición respecto a los años anteriores se estrenó un formato de eliminatorias directas a un enfrentamiento hasta los cuartos de final, con partidos de ida y vuelta en semifinales.

La denominación histórica y genérica de la competición es «Campeonato de España», y por eso el equipo vencedor se considera como el campeón de España; no obstante, el nombre oficial de la competición se ha modificado a lo largo de los años en función del jefe de Estado español, que es quien otorga el trofeo desde la primera edición. Así pues, ha contado con las siguientes denominaciones:


El primer campeonato de fútbol a nivel nacional, no oficial, disputado en España fue el Concurso Madrid de Foot-ball Association, conocido popularmente como la Copa de la Coronación, un torneo impulsado por los hermanos Carlos y Juan Padrós, dos de los fundadores de la "(Sociedad) Madrid Foot-ball Club (actual Real Madrid Club de Fútbol). Este club madrileño lo organizó en 1902 con motivo de los festejos de la mayoría de edad de Alfonso XIII de Borbón y su jura constitucional como rey. El Bizcaya, equipo combinado del Athletic Club y el Bilbao Football Club, fue el club vencedor de aquel torneo.

El éxito alcanzado por este torneo hizo que en 1903 Carlos Padrós decidiera instaurar un torneo nacional de carácter anual en el que participasen la mayoría de clubes existentes en el país, bajo el nombre de Campeonato de España. Para ello limitó la participación a un representante por región y consiguió que el rey Alfonso XIII donase una copa para el campeón. El trofeo, según las bases, pasaría a ser propiedad del club que se proclamase campeón tres años consecutivos o cinco alternos. El Madrid Foot-Ball Club se encargó inicialmente de la organización y los partidos se disputaron, al igual que en el Concurso Madrid del año anterior, en el Hipódromo de la Castellana. El primer torneo, celebrado en 1903, se desarrolló como una liguilla en la que participaron finalmente sólo tres clubes: el Club Español de Foot-Ball por Cataluña, el Madrid Foot-Ball Club por la región centro, y el Athletic Club por la región norte. Se proclamó campeón el conjunto vasco al vencer en el último y decisivo partido a los madrileños por 2-3 tras remontar un 2-0 inicial. Cabe destacar que los acontecimientos de dicho encuentro dieron a la postre con el nacimiento del Athletic Club (Sucursal de Madrid), hoy conocido como Club Atlético de Madrid.

La Agrupación Madrileña de Clubs de Foot-Ball, organismo fundado por Carlos Padrós antecedente de la Federación Regional Centro, organizó la edición siguiente, aunque a partir de 1905 el Madrid F. C. volvió a tomar las riendas del torneo debido a la mala organización de la asociación madrileña, en la que se proclamó vencedor al Athletic Club sin haber jugado ningún partido y prolongando una polémica por quién debía ser el campeón durante meses. En los años sucesivos, vascos y madrileños se repartieron los títulos. El Madrid F. C. fue el primero en recibir la copa en propiedad por sus cuatro títulos consecutivos de 1905 a 1908.

Para la época, se habían instaurado los Campeonatos Regionales auspiciados por cada federación regional, que además de proclamar al equipo campeón de cada región servían como un sistema de clasificación previo para determinar qué equipos contenderían en el Campeonato de España.

Después de siete años organizándose el torneo en Madrid, se acordó que a partir de la edición de 1909, año en que ganó el Ciclista Foot-Ball Club, el equipo campeón fuese el organizador de la edición siguiente. En ese mismo 1909 se creó la "Federación Española de Clubs de Foot-ball", primer organismo a nivel nacional que pretendió organizar el fútbol en el país y al que las bases del Campeonato de España otorgaban el derecho a organizar el torneo una vez constituida. La Real Sociedad de Foot-ball de San Sebastián, sucesora del Club Ciclista, que se consideraba legitimada para organizar el campeonato de 1910, no reconoció al nuevo organismo federativo y, junto con otros equipos disidentes, entre los que se encontraban los otros campeones, creó la "Unión Española de Clubs de Foot-ball". Este cisma propició que en 1910 se disputaran dos torneos nacionales, el organizado por los equipos de la "Federación Española" y el de la "Unión Española". Finalmente, en octubre de ese año ambas organizacoines firmaron la paz: los clubes disidentes reconocieron a la "Federación Española", que a su vez daba oficialidad al Campeonato de España organizado por los unionistas.

No obstante, las discrepancias entre las sociedades futbolísticas de la época continuaron y, tres años más tarde, se produjo un nuevo cisma cuando el Foot-Ball Club Barcelona, nuevo integrante del palmarés de campeones, y la Real Sociedad de Foot-ball, entre otros equipos, se dieron de baja de la Federación para refundar la "Unión Española de Clubs". Nuevamente, en 1913 se disputaron dos campeonatos de Copa, antes del acuerdo definitivo que permitió la reunificación definitiva del fútbol español con la constitución de la Real Federación Española de Fútbol ese mismo año.

El nuevo organismo aprobó nuevas bases para el Campeonato de España, para poner fin a las disputas que habían marcado las últimas ediciones del torneo. Se acordó, entre otras medidas, institucionalizar los campeonatos organizados por las distintas federaciones regionales como una fase previa de la Copa del Rey. Se dividió el país en diez regiones, aunque inicialmente solo en cuatro ya existían federaciones con campeonatos regionales en marcha (Galicia, Norte, Cataluña y Centro).

Fue a partir de los años veinte cuando la competición empezó a tomar carácter y cuantía de encuentros, con lo que comenzaron a despuntar nombres propios que posteriormente serían historia del torneo. Así, jugadores como José Samitier o Ramón Polo se convirtieron en las primeras estrellas del torneo tanto por número de encuentros disputados como por su número de goles anotados.

El torneo fue creciendo a medida que se ponían en marcha nuevos campeonatos regionales por toda la geografía española. Así mismo, a partir de la edición de 1927 se amplió la participación en el torneo a los subcampeones regionales. Pero a partir de 1929, con la puesta en marcha del Campeonato Nacional de Liga, el torneo copero pasó a un segundo plano y, del mismo modo, los campeonatos regionales. Para relanzar las torneos regionales, a partir de 1931 algunas federaciones territoriales vecinas empezaron a organizar campeonatos conjuntos con sus mejores equipos –los conocidos como Campeonatos Mancomunados– hasta que, finalmente, en 1934, la Federación Española agrupó los distintos torneos regionales en seis Campeonatos Suprarregionales. Los mejores clasificados en estos torneos fueron los que disputaron el Campeonato de España, renombrado como la Copa del Presidente de la República con nuevo título que se puso en juego en 1932 tras la caída de la monarquía y la instauración de la Segunda República Española.

En 1936 las competiciones de ámbito nacional quedaron suspendidas por el estallido de la Guerra Civil Española, aunque la actividad futbolística siguió algún tiempo activa en la zona bajo el control del gobierno Republicano, al este de la Península. En 1937, uno de los equipos de la zona, el Valencia Football Club, impulsó la disputa de una Copa de España tras haber obtenido la cesión de un trofeo para el campeón por parte del Presidente de la República. El torneo se disputó finalmente con el nombre de y solo pudieron participar los equipos de las federaciones de Levante y Cataluña. Fue campeón el Levante Football Club aunque, con el posterior triunfo de los sublevados en la contienda bélica, quedaron invalidados todos los campeonatos disputados en la zona republicana. Cuarenta años después, tras la dictadura franquista, el Levante U. D. reclamó el reconocimiento de la Copa de 1937 como una edición más del Campeonato de España y logró su reconocimiento en el Congreso de los Diputados. Sin embargo, en 2009, la asamblea de la RFEF rechazó la oficialidad del torneo al considerar que no fue organizado por el ente federativo.

Los títulos parecían hasta la fecha reservados para las regiones del Norte (País Vasco), Cataluña y Centro (Madrid). Así, pese a la edición de 1935 en la que salió vencedor el Sevilla Football Club, el vencedor pertenecía siempre a una de las citadas tres federaciones. En 36 ediciones, solo ocho equipos resultaron campeones, copando Athletic Club, Madrid F. C. y F. C. Barcelona un total de 28 títulos.

En 1939 la Federación Española de Fútbol decidió reanudar las actividades futbolísticas con la puesta en marcha de un torneo nacional con un trofeo cedido por el nuevo , el Generalísimo Francisco Franco. Para elegir a los equipos participantes se reinstauraron los campeonatos regionales en las Federaciones territoriales que podían asumir su organización. Finalmente, fueron Aragón, Andalucía, Galicia, Cantabria, Bilbao, Guipúzcoa y Navarra quienes enviaron representantes a la primera edición de la Copa tras la guerra, cuya final ganó el Sevilla Football Club al Racing Ferrol Football Club. Terminada la guerra, la Federación Española añadió el título al palmarés del Campeonato de España que, de este modo, retomaba su actividad, ahora bajo el nombre de Copa del Generalísmo.

La reestructuración llevada a cabo por el nuevo régimen (Dictadura de Francisco Franco) en 1940 supuso la desaparición de los históricos campeonatos regionales, quedando delimitado el acceso a la Copa a los equipos mejor clasificados del campeonato nacional de liga en sus tres divisiones. De este modo, en la edición de 1941 disputaron la Copa del Generalísmo los 14 equipos de la Primera División, los 24 de Segunda y los seis mejores de Tercera; un número de participantes que se fue incrementado en los años sucesivos. El vencedor fue el Valencia Club de Fútbol, añadiendo así una quinta federación a las ya campeones.

Se llegó así a la fecha en la que debutó Telmo Zarra con el Atlético de Bilbao, nombre que va estrechamente ligado al de la competición, y que a fecha de su retiro consiguió anotar un total de 81 goles en 74 partidos para convertirse en el máximo goleador histórico superando los 70 anotados por Samitier. Es desde 1953 un récord que no ha sido rebasado. Junto a otros míticos jugadores del conjunto vasco como José Luis Panizo o Agustín "Piru" Gaínza, logró conseguir la tercera copa en propiedad para su club, siendo el más laureado de manera destacada por delante de barcelonistas y madridistas. A semejanza, Gaínza estableció el que fue el más alto número de presencias en la competición con 99, perdurando dicha marca hasta el final de la temporada 1996-97, cuando fue rebasado por Andoni Zubizarreta a finales de 1997.

A partir de la temporada 1960-61 el campeón de la Copa de España se clasificaba para disputar la desaparecida Recopa de Europa, torneo internacional organizado por la UEFA con la participación de los campeones de las distintas copas nacionales. La circunstancia se vio alterada en 1998-99 con la desaparición de la competición continental, fecha en la que el campeonato de Copa daría sucesivo acceso a la Liga Europea de la UEFA —otrora Copa UEFA—, circunstancia aún vigente.

La Copa del Generalísimo se disputó hasta la muerte de Francisco Franco, en 1975, para en la temporada 1976-77 adoptar la denominación histórica y actual de Copa de Su Majestad El Rey, siendo el nuevo Jefe de Estado, el monarca español, el encargado de entregar el trofeo. En dicha primera edición el primer campeón fue el Real Betis Balompié, quien se estrenaba en el palmarés.

Desde la temporada 1990-91, fecha en la que entró en vigor una regulación que afectaba a los equipos filiales, estos quedaron excluidos de la participación en la competición al ser dependientes a efectos federativos de sus clubes matrices. El cambio dejó al Castilla Club de Fútbol como el filial con mejor participación en la historia del torneo al finalizar como subcampeón en la edición de 1979-80, tras perder la final precisamente frente al Real Madrid Club de Fútbol, siendo la primera y única vez que un equipo y su filial han disputado una final oficial en España.

Con la nueva presidencia de Luis Rubiales se llevaron a cabo profundas reestructuraciones en el seno de la Federación. Estas afectaron a las competiciones organizadas por el organismo, la Copa del Rey y la Supercopa de España, y fueron reformadas con un nuevo formato para aumentar la competitividad y atractivo. En el caso de la Supercopa, afectó recíprocamente ya que tanto el campeón como el subcampeón de Copa accedieron a disputarla frente a los dos mejores clasificados del campeonato de liga en una final a cuatro. Una de las medidas del campeonato copero, efectiva desde la edición 2019-20, fue la de designar una sede fija para la final la cual recayó en el estadio de La Cartuja de Sevilla por un período de cuatro años. Del mismo modo para dar opciones a los equipos menos competitivos se consideró como la mejor opción el estrenar un formato a partido único en cada una de las eliminatorias disputado en el recinto del club de menor categoría, con la excepción de la ronda de semifinales, la cual conservó el doble partido. También afectó al número de participantes aumentando hasta los 116 contendientes, la más alta en la historia del torneo, e introduciendo por primera vez a equipos de la Copa Federación (4), y de las primeras divisiones regionales (10), equivalentes a la quinta categoría del fútbol español.

Señalado como un acierto en emoción y seguimiento entre aficionados e implicados pese a las reticencias iniciales, hasta un total de seis equipos no pertenecientes a la Primera División clasificaron a octavos de final, y fueron eliminados nueve de la citada máxima categoría. Club Deportivo Badajoz y Cultural y Deportiva Leonesa representaron a la Segunda División "B" y los históricos Real Zaragoza, Club Deportivo Tenerife, Rayo Vallecano de Madrid y Club Deportivo Mirandés de la Segunda División fueron los que accedieron a dicha fase, clasificando únicamente el C. D. Mirandés a los cuartos de final, e incluso a semifinales igualando su mejor participación en el torneo. Finalmente accedieron a la final el Athletic Club y la Real Sociedad de Fútbol, la primera vez que se daba un derbi vasco desde 1927 cuando lo hicieran el Real Unión Club y el Arenas Club. En derbi vasco entre "txuri-gorris" y "txuri-urdines", inédito en la historia de las finales, sirvió para dirimir un campeón no visto desde que ambos ganasen su último título en los años 1980.<br> Un mes antes de la citada final se produjo la cancelación de las competiciones por parte de la UEFA, la RFEF y la La Liga, debido a un brote del Coronavirus-2 del Síndrome Respiratorio Agudo Grave, una pandemia global vírica que llegó a Europa desde Asia. A medida que diferentes países del continente fueron registrando casos de contagio y fallecimientos, los organismos deportivos comenzaron a tomar medidas preventivas y varios de los partidos programados fueron disputados a puerta cerrada (sin público), o cancelados, para frenar su avance, pero no cesó la preocupación ni los contagios, y se dieron casos en futbolistas y directivos de diversos clubes. Debido a ello el partido fue aplazado a la espera de nuevos acontecimientos.

Participan 116 equipos. Quedan excluidos de la competición los equipos filiales. Los 20 de Primera División, los 22 de Segunda División, los cinco primeros clasificados de los cuatro grupos de Segunda División B y los campeones de los 18 grupos de Tercera División suman 80 equipos. Los participantes restantes son los equipos de Segunda División B que tienen más puntos, a partir del sexto clasificado.

En la primera ronda (36 equipos), se disputan 18 eliminatorias a partido único, entre 36 clubes de Segunda División B y Tercera División, que se emparejan por sorteo.

En la segunda ronda (44 equipos), se disputan 22 eliminatorias a partido único, entre los 18 clasificados de primera ronda, el resto de equipos Segunda B que quedaron exentos de la primera ronda y los 22 clubes de Segunda División. Se sortean 11 eliminatorias entre equipos de Segunda División y otras 11 entre equipos de Segunda B y Tercera.

En la tercera ronda (22 equipos), se disputan 11 eliminatorias a partido único, entre los 22 clasificados de la segunda ronda, quedando un club exento. Se vuelve a separar en el sorteo las cinco eliminatorias entre equipos de Segunda División y las seis de equipos de Segunda B y Tercera.

En la cuarta ronda (32 equipos), se disputan 16 eliminatorias a doble partido, entre los 11 clasificados de la tercera ronda más el club exento y los 20 clubes de Primera División que se incorporan en esta ronda. Los condicionantes del sorteo son que los cinco equipos de Segunda División B o Tercera División, se enfrentan a los cinco primeros clasificados de Primera División de la anterior temporada. Las otras 11 eliminatorias enfrentan entre sí a los siete equipos de Segunda más los quince restantes de Primera. En los partidos de los equipos con diferentes niveles de liga, jugará en casa en el partido de ida el equipo de nivel inferior.

A partir de la quinta ronda (16 equipos), se disputan las eliminatorias a partido único (octavos, cuartos y semifinales) sin condicionantes, mientras que la final se disputa a partido único en campo neutral.

El vencedor del torneo tiene el derecho a disputar desde 1981, la Supercopa de España frente al campeón del Campeonato Nacional de Liga de esa misma temporada, con el precedente de la Copa Eva Duarte, disputada de 1947 a 1953. Desde 1994, en caso de que un club gane el mismo año las dos competiciones, es el subcampeón de Copa el que disputa la Supercopa.

El vencedor, además, obtiene una plaza para disputar la Copa UEFA/Liga Europa desde la temporada 1998/99. Entre 1961 y 1998, el campeón de Copa accedía a la extinta Recopa de Europa, torneo en el que participaban exclusivamente los campeones de las copas nacionales de los países europeos.

Se jugará a partido único hasta semifinales, lo que supone una apertura al fútbol no profesional. El torneo pasó a tener 116 participantes. El cuadro está compuesto por los 20 equipos de Primera, los 22 de Segunda A, 28 de Segunda "B" salidos de los siete primeros clasificados de cada uno de los cuatro grupos de la tercera competición española, 32 equipos de Tercera, de los cuales dieciocho son los campeones de cada grupo y los catorce mejores segundos. Los 4 equipos que en la Copa Federación, disputada por equipos de Segunda "B" y Tercera, lleguen a semifinales tendrán plaza en la Copa del Rey. Lo más novedoso es la nueva participación de los 10 equipos de las primeras divisiones regionales, correspondientes a la 5.ª categoría del fútbol español, que disputarán una eliminatoria entre los veinte equipos campeones de cada grupo completando así el cupo de participantes. En el caso de que el sorteo empareje equipos de la misma categoría, se jugará en el estadio del club que haya salido del bombo en primer lugar. 

Los cruces entre equipos profesionales y no profesionales se celebrarán en terrenos de juego de césped natural, por lo que los primeros, si cuentan en sus estadios con hierba artificial, deberán buscar uno alternativo que sea homologado por la federación. Una vez celebrada la eliminatoria entre los clubes de preferente, durante los meses de verano, la primera ronda se disputó entre el 17 y 19 de diciembre. Los cuatro equipos participantes en la Liga de Campeones (los cuatro primeros clasificados de la Primera División) no entrarían en competición hasta los dieciseisavos de final.

En la siguiente tabla se muestran todos los clubes que han disputado alguna vez una final de Copa. Aparecen ordenados por número de títulos conquistados. A igual n.º de títulos, por n.º de subcampeonatos y si persiste la igualdad, por antigüedad de su primer título o participación.

Las normas del torneo establecen que cada vez que un club vence la competición tres veces seguidas o cinco alternas, y antes de que otro club lo logre, recibe el trofeo en propiedad, y a partir de la edición siguiente se disputa la posesión de uno nuevo. Entretanto, cada vencedor recibe una réplica del mismo. En ocasiones excepcionales se han entregado trofeos en propiedad, como la Copa de la Coronación, la primera y la última Copa del Generalísimo, o la Copa del Rey del año 2010 para celebrar el campeonato del mundo de la Selección Española de Fútbol en el mundial de Sudáfrica. Solamente seis de los campeones se han repartido 15 trofeos en posesión (7 FC Barcelona, 3 Athletic de Bilbao, 2 Sevilla FC, 1 Real Madrid, 1 Real Unión de Irún y 1 Atlético de Madrid).

El máximo goleador histórico del torneo es el español Telmo Zarra, quien anotó 81 goles con el Athletic Club, siendo uno de los nombres que van ligados al de la competición. El registro goleador del vasco es seguido por los de los también españoles José Samitier y Guillermo Gorostiza quienes anotaron 69 y 64 goles respectivamente. Estos tres jugadores son además los únicos en sobrepasar la barrera de los sesenta goles.

Además cabe destacar entre los máximos anotadores al hispano-húngaro Ferenc Puskás por ser el jugador con mejor promedio anotador de la competición con 1,20 goles por partido con el Real Madrid Club de Fútbol, por delante del gallego Rogelio Tapia y el ya mencionado Telmo Zarra con promedios de 1,17 y 1,09 respectivamente.

El español Andoni Zubizarreta es el jugador que más encuentros ha disputado de la competición con 104, repartidos entre las quince ediciones que disputó a lo largo de su carrera. Su registro es seguido por los 101 encuentros de José Ángel Iribar y los 99 de Agustín "Piru" Gaínza, habiendo pertenecido los tres, bien durante toda su carrera o parte de ella, a las filas del Athletic Club.

La mayor goleada en un partido se produjo el 10 de septiembre de 1992 cuando en los dieciseisavos de final de la 90.ª edición, cuando en el partido de vuelta el Real Murcia Club de Fútbol venció por 14–0 al Club Deportivo Cieza Promesas, para un 16–0 global en la eliminatoria. Tras ella se sitúa la lograda por el Athletic Club frente al Real Club Celta de Vigo el 18 de mayo de 1947, por 12–1, correspondiente a la ida de los cuartos de final de la 44.ª edición.

En cuanto al palmarés individual es Agustín "Piru" Gaínza con siete títulos, todos logrados con el Athletic Club, el jugador más laureado de la historia del campeonato. Andrés Iniesta, Lionel Messi, Gerard Piqué y Sergio Busquets son los jugadores en activo que más títulos han ganado (seis títulos). En el apartado de entrenadores fue el checoslovaco Ferdinand Daučík quien ganó más títulos, que fueron seis logrados con tres equipos distintos (3 con Fútbol Club Barcelona, 2 con Athletic Club, y 1 con Real Zaragoza). El árbitro Pedro Escartín tiene el récord de dirigir 4 finales del torneo de Copa.




</doc>
<doc id="45480" url="https://es.wikipedia.org/wiki?curid=45480" title="Walter Benjamin">
Walter Benjamin

Walter Bendix Schönflies Benjamin (pseudónimos: Benedix Schönflies, Detlef Holz) (Berlín, Imperio alemán; 15 de julio de 1892 – Portbou, España; 26 de septiembre de 1940) fue un filósofo, crítico literario, traductor y ensayista alemán de origen judío. Su pensamiento recoge elementos del Idealismo alemán o el Romanticismo, del materialismo histórico y del misticismo judío (cábala) que le permiten hacer contribuciones perdurables e influyentes en la teoría estética y el Marxismo occidental. Su pensamiento se asocia con la Escuela de Fráncfort.

Walter Benjamin nació en el Berlín del Imperio Alemán (1871-1918), en el seno de una acomodada familia de origen ashkenazi, dedicada a los negocios y totalmente integrada. Su padre, Emil Benjamin, era banquero en París, pero se había trasladado a Alemania, donde trabajó como anticuario en Berlín; más tarde, se casó con Pauline Schönflies. Walter Benjamin, en sus reflexiones, recuerda con ternura los cuentos que le contaba su madre, los cuales le sirvieron como base para una de sus teorías: «"el poder de la narración y de la palabra sobre el cuerpo"». Reflexionó sobre la relación que los cuentos establecían entre la tradición y la actualidad.En 1905, debido a su frágil salud, sus padres le enviaron a un internado en el medio rural, en Turingia. Dos años más tarde, en 1907, volvería a su escuela en Berlín.

En 1912, a la edad de veinte años, ingresa en la Universidad de Friburgo (Alemania), pero al final del segundo semestre vuelve a Berlín y se matricula en la Universidad de Berlín para continuar sus estudios de Filosofía. Allí conoció el Sionismo, que sus padres, habiéndole ofrecido una educación liberal, no le habían inculcado. Benjamin no profesaba la religiosidad ortodoxa; tampoco abrazó el Sionismo político, sino que desarrolló un «Sionismo cultural» que valoraba la riqueza y la estética cultural del misticismo judío. Benjamin defendió el Judaísmo como parte fundamental de la cultura de Europa. Para él, el pueblo judío era el más distinguido portador de lo espiritual en las culturas del mundo.

También, durante sus años en la universidad se unió a la «Unión de Estudiantes libres», de la que fue elegido presidente. Para tal asociación redactó diversos escritos sobre la necesidad de una reforma educativa y cultural. Al no ser reelegido como presidente, volvió a la Universidad de Friburgo, donde asistió con especial interés a las clases de Heinrich Rickert. También viajó a Francia e Italia. En sus años universitarios tuvo el valor de impugnar el origen teórico del formalismo (Heinrich Wölfflin). Escribió sobre su preocupación por el lenguaje como pieza clave de la vida: «"El hombre se comunica en el lenguaje, no por el lenguaje"». Sufrió doble discriminación como intelectual judío y de izquierdas.

En 1914, al estallido de la Primera Guerra Mundial, quiso alistarse, pero acabó tomando partido por la corriente pacifista de la izquierda europea radical, que rechazaba la participación y la colaboración con la que tildaban de «carnicería humana interimperialista». Benjamin había sido fuertemente impresionado por el suicidio de dos amigos combatientes. Comenzó la traducción de las obras de Charles Baudelaire al alemán. Un año más tarde, en 1915, se matriculó en la Universidad de Múnich, donde conoció a Rainer Maria Rilke y a Gershom Scholem, que se convertiría en su amigo. Aquel año escribió sobre el poeta romántico alemán Friedrich Hölderlin.

En 1917, se matriculó en la Universidad de Bern, allí conoció a Ernst Bloch y a Dora Sophie Pollack (1890-1964), con la que se casaría más tarde. Con Dora tuvo un hijo, Stefan Raphaël (1918-1972). Buscó un tema para su tesis, y lo encontró en la filosofía de Kant y Platón. Defendió su tesis "Begriff der Kunstkritik in der Deutschen Romantik" (El concepto de la crítica de arte en el Romanticismo alemán) en 1919. Tuvo el proyecto de fundar una revista, pero fracasó. En este periodo también escribió un texto en el que analizaba el concepto de «mito», e inició una relación con la directora de teatro Asja Lācis.

Quiso entrar como profesor en la universidad, pero lo rechazaron por ser judío. Escribió "El origen del drama barroco alemán", donde trabajó el concepto de «alegoría»; con él, dejó en evidencia su concepción mesiánica de la vida.

En esta etapa abrazó el materialismo y apartó todo lo demás, y aquí afirmó su posición ante las tendencias del momento: jamás militaría en el sionismo ni en el comunismo ni en el fascismo. Para él, la salvación de la humanidad está ligada a la salvación de la naturaleza. Quedó fascinado con las obras de Marcel Proust y Charles Baudelaire, observadores natos de la vida. En 1926 murió su padre y entonces partió a Moscú, donde escribió un diario y confirmó su teoría sobre las tendencias políticas, lo cual provocó que se aislara por completo. En el 29 rompió su relación con Asja y un año después murió su madre: se vio obligado a hipotecar su herencia para pagar las exigencias de su mujer. Fue una etapa difícil, pero su romanticismo le hizo pensar que era el inicio de una nueva vida.
Criticó sin piedad a Hitler, la teoría fascista y a la hipocresía de la democracia burguesa y al capital financiero e industrial alemán que apoyó al nazismo como forma de contrarrevolución preventiva contra los socialistas. Intentó conciliar el marxismo con su herencia cultural judía y con las tendencias artísticas vanguardistas. En el 30 consiguió reunir su biblioteca y en 1931 experimentó con el hachís; inspirado en el texto «Hachís» de Charles Baudelaire, escribió sobre un club del siglo XIX en el que se reunía para consumirlo. Fue muy amigo de su colega filósofo Ernst Bloch, socialista marxista, de origen judío.

En 1932, durante la crisis anterior a la asunción al poder de Hitler, Walter Benjamin fue a la isla española de Ibiza en la que estuvo en dos ocasiones, como explica Vicente Valero en su libro "Experiencia y pobreza", que reconstruye el periodo ibicenco del escritor, enamorado de la isla, y la gran influencia que esta tuvo en su vida y en su obra. Luego se trasladó a Niza, donde llegó a pensar en el suicidio, al percibir lúcidamente la importancia socio-política y cultural del incendio del Reichstag (27 de febrero de 1933), que de hecho significó la asunción de todo el poder por los nazis en Alemania. Desatada la persecución de los judíos y de los marxistas, Benjamin se trasladó a París, tras una estancia en Svendborg, en casa de Bertolt Brecht y en Sanremo, donde vivía su exesposa Dora. Escribió a Scholem sobre una fatiga infinita que le invadía.

Ya no volvió nunca más a Berlín, ya que el fascismo se lo impedía. Tuvo la necesidad de vincularse a algo para que lo mantuviera, así que buscó el apoyo de los también filósofos marxistas-críticos, Adorno y Horkheimer. Este último le acusó de no ser un buen materialista. Benjamin malvivía con lo que cobraba de esta escuela, por lo que decidió no salir de casa y se aisló social y físicamente. También se vinculó al círculo de Georges Bataille.

Los paisajes parisinos son una nueva teorización de la historia moderna. Las condiciones de su existencia empeoraban cada vez más. Estaba muy enfermo y en su último texto expresó su esperanza más escatológica: «"Ha desaparecido toda desesperación; el pensamiento religioso y político"» se funden en uno solo. El 14 de junio de 1940, tras la ocupación de la ciudad por las tropas nazis, huyó de París.

Estrecho colaborador de la Escuela de Fráncfort —a la que sin embargo nunca estuvo directamente asociado—, adaptó su temprana vocación por el misticismo al materialismo histórico, al que se volcó en sus últimos años, aportando una visión única en la filosofía marxista. Como erudito literario, se caracterizó por sus traducciones de Marcel Proust y Charles Baudelaire. Su ensayo «La labor del traductor» es uno de los textos teóricos más célebres y respetados sobre la actividad literaria de la traducción.

Benjamin mantuvo una extensa correspondencia con Theodor Adorno y con Bertolt Brecht y ocasionalmente recibió financiación de la Escuela de Fráncfort bajo la dirección de Theodor Adorno y Max Horkheimer. Las influencias competitivas del marxismo de Brecht, la teoría crítica de la Escuela de Fráncfort, el discurso marxista heterodoxo de Bloch, las vanguardias artísticas, la herencia hegeliana y dialéctica, y el misticismo judío de su amigo Gershom Scholem fueron centrales en el trabajo de Benjamin, aunque nunca logró resolver sus diferencias completamente. Las «Tesis sobre la filosofía de la historia (o Concepto de la Historia)», uno de los últimos textos de Benjamin, fue lo más cercano a tal síntesis, que junto con los ensayos «La obra de arte en la época de su reproductibilidad técnica» y «Para una crítica de la violencia», son sus textos más leídos.

Entre sus obras más importantes como crítico literario están los ensayos sobre la novela de Goethe titulada "Las afinidades electivas", sobre la obra de Franz Kafka y Karl Kraus, la teoría de la traducción, las historias de Nikolái Leskov, la obra de Marcel Proust y, quizás lo más importante, la poesía de Charles Baudelaire. También hizo importantes traducciones al alemán de la "Tableaux Parisiens de Baudelaire" ("Les Fleurs du mal") y las partes iniciales de la novela "À la recherche du temps perdu" de Marcel Proust, con su amigo Franz Hessel.

Su vuelta al marxismo en la década de 1930 se debió en parte a la influencia de Bertolt Brecht, cuya crítica marxista a la estética le permitirá desarrollar el teatro épico y su "efecto de distanciamiento" o "(Verfremdungseffekt)" (efecto de extrañamiento o alienación). Su amigo Gershom Scholem, fundador del estudio académico de la Cábala y misticismo judío, tuvo gran influencia en Benjamin.

Influido por el antropólogo suizo Johann Jakob Bachofen (1815-1887), Benjamin acuñó el término «percepción aura», que denota la facultad estética mediante la cual la civilización puede recuperar una apreciación del mito. El trabajo de Benjamin se cita críticamente a menudo en los estudios académicos y literarios, especialmente los ensayos «La tarea del traductor» (1923) y «La obra de arte en la época de su reproductibilidad técnica» (1936). Debatió con Adorno por no poder salir este de su rígida posición «áurea» del arte, que no podía hacerlo incorporar al arte al elemento industrial (cine o jazz, por ejemplo), y que desconfiaba de la cultura de masas. Benjamin anticipa todos estos fenómenos.

Walter Benjamin murió el 26 de septiembre de 1940 en Portbou, (España), tras ingerir una dosis letal de morfina en un hotel del pequeño puerto fronterizo español. Tras haber salido de la localidad francesa de Port Vendres guiado por la activista antinazi Lisa Fittko (quien narró la experiencia en un capítulo dedicado a Benjamin de su "Mi travesía de los Pirineos" ) y teniendo como acompañante a la fotógrafa Henny Gurland, futura esposa de Erich Fromm, y su hijo, Benjamin llegó a Portbou muy cansado, ya al atardecer del día 25. En el camino se les había unido un grupo de tres mujeres que intentaban también salir de Francia. En el puesto de policía de la estación fue interceptado por la policía española porque carecía de la visa requerida. Su amigo Theodor Adorno le había ayudado a obtener las visas de tránsito en España y de entrada en Estados Unidos, donde le esperaba, pero carecía del permiso francés de salida del país galo. Otros compañeros de viaje en sus mismas circunstancias, como la fotógrafa Henny Gurland y su hijo, Carina Birman y Sophie Lipmann, consiguieron finalmente pasar por España y llegar a Lisboa. Benjamin antes que tener que volver a Francia y caer en manos de la Gestapo, decidió acabar con su vida en el Hotel Francia, al que el grupo fue acompañado por la policía. La restricción a las visas obtenidas en Marsella sin visado de salida, como la que Benjamin poseía, fue levantada por las autoridades españolas pocos días después.

Sus compañeros de viaje pagaron el alquiler del nicho 563 por cinco años, donde descansaron los restos del filósofo hasta que fueron trasladados al osario del cementerio. En el certificado de defunción figura el nombre de Benjamín Walter, fallecido a causa de un aneurisma cerebral, lo que según Linhard posibilitó que un cementerio católico acogiese los restos del pensador germano, evitando complicaciones burocráticas. En el camposanto de Portbou hay un monumento en memoria del filósofo.

La trágica huida de Benjamin a través de los Pirineos ha inspirado distinto género de obras, dentro de las cuales, en el ámbito de nuestra lengua, se puede mencionar la novela "El Pasajero Benjamin", de Ricardo Cano Gaviria, publicada en 1989 (de hecho el primer libro unitario escrito en español sobre el filósofo), y reeditada varias veces con posteridad con el nombre de "El pasajero Walter Benjamin". El autor de esta novela, que se ciñe en los fundamental a los datos esclarecidos por varios investigadores desde que el abogado y político Juan-Ramón Capella visitara por primera vez el Hotel Francia, donde ocurrieron los hechos, no cuestiona lo que siempre se ha tenido por algo fuera de duda: que Walter Benjamin se suicidó. Esta postura se ha visto avalada por el descubrimiento, en los años noventa del siglo pasado, de un grupo de documentos (la minuta del hotel, el acta de defunción, las facturas del médico, el doctor Vila Moreno, del cura -alquiler del nicho-, del carpintero -construcción del féretro y su colocación en el cementerio-) que cierran casi por completo el círculo sobre unos hechos que hoy se pueden reconstruir hora a hora, si no minuto a minuto. 

Por lo tanto las especulaciones que se han tejido, y siguen tejiéndose sobre un posible asesinato, contradicen por un mero prurito de novedad o por simple morbo periodístico lo que el sentido común dice hoy e inspiró antes a los diversos autores que se han ocupado del asunto, desde Hannah Arendt hasta los editores de las Obras completas. Es el caso del documental Quién mató a Walter Benjamin…, de David Mauas. En palabras del mismo director: "el film antepone un interrogante como si de aquel ‘cepillo a contrapelo de la historia’ se tratase, proponiendo una construcción benjaminiana sobre la misma muerte del pensador, articulando en su propia narrativa los problemas derivados del discurso histórico y su construcción”. Con tal presupuesto el film pone en duda la teoría del suicidio y recrea la situación en la frontera dando voz a los 'anónimos' de la historia, para apuntar directamente hacia los agentes nazis en la España fascista de Franco como los asesinos del filósofo, sin brindar ninguna prueba concluyente. No menos atrevido, un polémico artículo de Stuart Jeffries, titulado «"Did Stalin Killers liquidate Walter Benjamin?"» ("The Observer", 8 de julio de 2003), afirma que Benjamin fue asesinado por agentes secretos de Stalin, que habrían sido los que le suministraron la morfina que le produjo la muerte. 

A la hora de la verdad, tales especulaciones resultan poco respetuosas con la vida, la obra y sobre todo la trágica muerte de un autor que ya en vida fue víctima del expolio cultural, y que merece el reposo por el que parece clamar él mismo en la nota que antes de morir redactó, dirigida a una de sus acompañantes en el Hotel Francia de Portbou, la señora Henny Gurland. En la misma no parece haber lugar para un presunto asesino, ya fuera de Franco o de Stalin, pues es bien sabido que Benjamin viajaba con una dosis de pastillas de morfina, que tenía preparadas para una eventualidad como la que se le cruzó justamente en el camino en el puesto fronterizo de Port Bou, aquella tarde fatídica del 25 de septiembre de 1940. Reproducida en casi todas las obras biográficas sobre Benjamin, la nota dice:









Los Benjamín - Una familia alemana. 
Editorial Trotta. 
ISBN 978-84-9879-839-5






</doc>
<doc id="45481" url="https://es.wikipedia.org/wiki?curid=45481" title="Género chico">
Género chico

El género chico es un género español de arte escénico y lírico. Es un subgénero de la zarzuela de formato breve típicamente en un acto, contrapuesto al género grande que corresponde a obras de mayor duración.

En ocasiones se ha llamado erróneamente «opereta española» como si fuese el equivalente español de la opereta vienesa y francesa, género con el que no guarda parentesco directo, si bien algunas zarzuelas chicas sí que han sido influidas por el estilo de la opereta. La zarzuela chica difiere de la zarzuela grande y de casi todas las formas de ópera por producir obras de corta duración y por representar a menudo temas ligeros de corte popular.

El género chico se caracteriza por su no excesiva duración (una hora o menos), la escasa trascendencia de su contenido y la sencillez de su argumento, con pocos personajes y un solo decorado. Su temática suele ser mayoritariamente costumbrista.

Gerald G. Brown definió la esencia del género chico diciendo que es la combinación ligera de tipos populares (en la venerable tradición de los pasos o los entremeses) y la visión costumbrista de una región o ciudad. Tuvo su gran época en la segunda mitad del siglo XIX y primera del XX y abarca distintas modalidades:


La zarzuela grande venía evolucionando junto a la política española, ya desde Felipe IV, que introdujo el género para amenizar sus fiestas en el Palacio de la Zarzuela. Con los sucesivos monarcas el género zarzuela pasó por numerosos períodos con un constante vaivén entre crear una ópera nacional, o copiar la italiana.

Pero las circunstancias políticas del país pronto se volverían tensas. El reinado de Isabel II se encuentra en plena crisis, y acaba cayendo con la Revolución de 1868, de carácter liberal. El país se encuentra sumido en una crisis a todos los niveles: económico, político, y también ideológico (el liberalismo y el republicanismo se encuentran en su apogeo). La gente se encuentra nerviosa por toda la inestabilidad del país (acrecentada con el asesinato del general Prim en 1870, pero en general como consecuencia de un largo proceso y de otras muchas causas). Por todo ello, amén de la complicada situación económica, la asistencia a los espectáculos sufre una fuerte baja. Una buena entrada para el teatro ronda los 14 reales, cantidad que el ciudadano medio no se podía permitir pagar para algo que ni tan siquiera sabía si sería de su agrado. El alto precio sumado a la incertidumbre nacional sume a la mayoría de los teatros de zarzuela en una fuerte crisis, rondando la bancarrota a menudo.

Para contrarrestarla, Juan José Luján, Antonio Riquelme y José Vallés, tres actores, tienen la idea de dividir la tarde de teatro en 4 partes, a razón de una hora cada una, creando las llamadas sesiones por horas, que apenas costaban un real, y se escenificaban en modestos teatros. Así se mantiene la ocupación del teatro alta, pues la gente acude más debido a los precios bajos. Los empresarios enseguida acogen la idea, necesitados de público pero las obras son antiguas y empiezan a hacerse reformas de cualquier obra de la historia del teatro.

Para ello intentan repetir el éxito del teatro bufo, que copiaba el modelo de ópera cómica de Offenbach, y fue traído por el empresario Arderíus al teatro Variedades de Madrid, donde experimenta un breve pero fulgurante momento de éxito en Madrid (con "El joven Telémaco" como obra de referencia). El modelo del bufo es el de una obra breve, de argumento siempre descabellado e impredecible, que tiende a la caricatura y mofa ligera de todo tipo de temas como los mitos históricos, la realeza, el ejército, la política, etc. Para ello recurre a música agradable, intrascendente, y a cierto erotismo para su época y exotismo. Los bufos no obstante se verán eclipsados rápidamente por la expansión del género chico y desaparecen en 1873.

Como se necesitan obras breves, que quepan en una hora de espectáculo, se retoman en un primer momento obras antiguas ya estrenadas y con un éxito ya probado entre el público, como podrían ser "El maestro de baile" (muy anterior al género chico, de Luis Misón), u obras más recientes como "Una vieja" (Gaztambide) o "El grumete" (Arrieta). Estas primeras obras se consideraban secundarias y se programaban como tales al lado de zarzuelas mayores, pero con el cambio de gusto y la tendencia hacia los nacionalismos y la ópera alemana, el gusto italiano, que copiaban las zarzuelas mayores, caerá en desuso, mientras el carácter de estas obritas reluce por sí mismo. Además, al tiempo se programan nuevas obras breves que cumplen este esquema en cuanto a longitud y temática alegre, notablemente influida por los bufos (con títulos más bien sugerentes como "La hoja de parra" o "Dice el sexto mandamiento"). Pero realmente pasan años hasta crearse las primeras obras con música propia, y el primer gran éxito no llega hasta 1879, con "La salsa de Aniceta" en el teatro Apolo, al que sigue poco después "El lucero del alba" de Manuel Fernández Caballero que logra un gran éxito para sus intérpretes. Según "Chispero" este es el verdadero nacimiento del Género chico.

Es fácil ver por tanto que el objetivo del género chico será el puro entretenimiento y la diversión del público; en contraposición a los temas más serios o dramáticos, y la acción complicada de la zarzuela «mayor», el género chico simplifica todo eso, para tratar temas más bien costumbristas, acerca de la vida cotidiana en Madrid, de talante disparatado siempre y caricaturesco. Por ello tiene tanto éxito entre el público; además de su precio reducido, la gente podía seguir fácilmente el argumento y sentirse identificada con los personajes que trataba, que les reflejaban y, en tiempos complicados, se tiende a buscar la evasión en el entretenimiento, que permita no pensar en el «mundo exterior».

Durante la década de 1870 se va afianzando el género que se desarrolla siguiendo un modelo similar al de la literatura realista de la época, con forma musical de sainete lírico. Se estrenan "El gorro Frigio" de Miguel Nieto y "Chateau Margaux" de Fernández Caballero, de dos importantes autores de zarzuela. 

El género chico recibirá el espaldarazo definitivo con "La Gran Vía" (Chueca y Valverde), en el verano de 1886. La obra cosechará tanto éxito que pasará de los teatros de verano al Apolo, y será repetida varias temporadas. Se trata de una serie de sainetes animados, pero no relacionados, que tratan temas de actualidad, alrededor de esta calle de Madrid que en la época estaba aún en proyecto. Federico Chueca es uno de los autores más prolíficos y más importante del chico, colaborando en sus obras a menudo con Joaquín Valverde. Otras obras suyas: "El año pasado por agua", "Agua, azucarillos y aguardiente", quizás la más popular en nuestros días, "La alegría de la huerta", "El arca de Noé", "Los descamisados", etc.

Otro modelo de obras muy común sería la comparación de 2 lugares: "De Madrid a París" (Chueca y Velarde) o "De Getafe al paraíso" (Barbieri, aunque en 2 actos), "Cádiz" (Valverde), obra muy popular. Otros autores importantes de la época eran Giménez, Quinito Valverde (el hijo de Joaquín), Tomás López Torregrosa ("San Antón" y "El santo de la Isidra"), el citado Fernández Caballero ("El dúo de la africana", "El cabo primero", "La viejecita", y "Gigantes y cabezudos"), Jerónimo Jiménez ("El baile de Luis Alonso" y "La boda de Luis Alonso", su segunda parte).

Un autor muy importante es Ruperto Chapí, que se pasa la vida dudando entre su pretensión de crear una ópera española, y sus composiciones de modesto género chico. En este último se encuadran sus obras "Música clásica", "La revoltosa", "¡Las 12 y media y sereno!", y "El tambor de granaderos".

Para terminar, otra de las obras más conocidas, "La verbena de la Paloma", que curiosamente está escrita por un autor que no tuvo más éxitos, Tomás Bretón. Esta popular composición surgiría después de algunos años de experimentos de su creador.

El género chico decaerá en importancia rápidamente cuando entra el nuevo siglo.

En cuanto a los lugares donde se programa género chico, la idea de las sesiones por horas comienza siendo patrimonio de teatros humildes, como el del "Recreo". Mientras la crítica se ceba con el género, recoge un gran éxito de público y es acogido por algunos teatros más, hasta que sus creadores acaban recalando en salas de cierta consideración como el Variedades, que habían dejado libre los bufos. Pero el lugar más importante fue el Teatro Apolo, inaugurado en 1873, donde, tras la crisis de la zarzuela grande, comienzan a programar género chico y se ven desbordados por su éxito popular. El Apolo es considerado el auténtico baluarte del género, muy conocido porque se popularizó su cuarta sesión, «la cuarta de Apolo», que era en horario nocturno y estaba siempre poblada de personajes de dudosa calaña y auténticos sinvergüenzas y fulleros (como muchos de los personajes que se representaba en las obras).

Además de en los teatros, el género chico se representaba en pequeños cafés, y durante el verano en escenarios más modestos como las populares corralas.
José Deleito y Piñuela y Margot Versteeg son del parecer que fue Bonifacio Pinedo el actor más completo que se especializó en un género en el que también destacó Emilio Mesejo, entre otros. Muchos de ellos solían también improvisar "morcillas" de actualidad, como Ramón Rosell ("capaz de sacar materia cómica de un sarcófago", según Sentaurens), Antonio Riquelme, Emilio Carreras, Julio Ruiz, José Ontiveros y Manolo Rodríguez.

Hay multitud de géneros y el sainete no predominó con soberanía sobre el resto de los demás e incluso se puede decir que fue el juguete cómico el alma del género. El modelo más común —y rico por su diversidad— en el género chico es tal vez el del sainete lírico, merced al éxito estreno de "La canción de la Lola" (Chueca y Valverde), en 1880; aunque se cosechen otros géneros también, las obras más importantes siguen este modelo.

El sainete, establecido en su forma definitiva por Ramón de la Cruz, es heredero directo de los entremeses teatrales tan cultivados anteriormente, y que tanto éxito cosechaban, en su esencia piezas breve e independientes, con intervenciones musicales y muy a menudo bailes. El género chico evoluciona esta forma hacia un retrato más o menos fidedigno de la vida de costumbres madrileña, a semejanza del realismo ya mencionado. Pero a diferencia de este, que se detiene en los aspectos más oscuros y lúgubres de la realidad, como los entornos más pobres y marginales y la violencia que acarrean, el género chico, aun tratando barrios más bien sumergidos y personajes de baja cultura, se fija en los aspectos más pintorescos de Madrid, como el peculiar lenguaje de sus protagonistas, y siempre en facetas más joviales.

Además, como característica única del género, cabe destacar la presencia constante de verbenas y fiestas al aire libre, que aparecen al principio de la obra para situarla, y al final para el desenlace público.

El argumento es muy sencillo, y en ocasiones apenas sostiene la obra, que se articula entonces por los paisajes que muestra. En la mayoría de los casos consiste en una simple historia de amor que suele repetir estructura: una pareja se ama pero alguna dificultad externa les impide culminar este amor (que siempre será en boda y con final feliz); se supera esa dificultad y termina la historia con un desenlace público, final feliz y moraleja implícita o explícita (además de pedir el favor del público al concluir del todo la obra). Al margen de esta estructura, se acostumbra a introducir personajes tópicos de la escena madrileña (Madrid es la ciudad de referencia en que se ambientan la mayoría de las obras): el fresco, el anarquista pintoresco que evita hacer menciones provocadoras, el gandul, el perdonavidas, el aprovechado, la coqueta, el viejo sentencioso. No se suelen incluir personajes instruidos, sino que la sabiduría es más de carácter popular y sentencioso.

Además el género chico tiene siempre un carácter de rabiosa actualidad: los actores hacen referencias fuera del texto, las llamadas "morcillas" (a menudo en los cuplés de la obra, donde se introducían intercalados versos nuevos, a menudo haciendo referencia a los hechos más inmediatos o al lugar donde se escenificara) al exterior más inmediato, tomando en ocasiones más relevancia esta calidad de «noticiario» que el propio argumento del que trataba la obra. Se mencionan políticos, acontecimientos externos y demás como otra forma de conectar con un público de un nivel cultural moderado; por ello también se rompe la unidad de acción de la obra y se hace al espectador cómplice de los actores, sin dejarle llegar a introducirse del todo en la acción.

El texto se suele escribir en prosa, aunque algunas de las primeras obras alternan partes en verso también. Además, se cuida mucho el lenguaje es intencionadamente vulgar, con expresiones de moda y alusiones o extranjerismos mal pronunciados, lo cual es fuente de información para el lenguaje popular y calibrar voces extranjeras. El chiste y otros recursos semánticos, que son originalmente ajenos al sainete, serán incorporados más tarde por los hermanos Quintero. Los números musicales se justifican entonces con el texto: gente que baila por la calle, por ejemplo. También hay teatro dentro del teatro, además de orquesta en el texto. Todos estos recursos tienen como fin principal el contacto con el público.

Las obras intercalan escenas con música y escenas habladas. La parte musical tiene una longitud muy variable, siendo las obras con más números musicales "Agua, azucarillos y aguardiente" y "La verbena de la Paloma". Normalmente las obras vienen precedidas de un preludio musical, y en ocasiones tienen pequeños intermedios o música para bailes, y terminan con un breve final en el que se repite la música de alguna escena sucedida anteriormente. Suele haber también pasajes hablados sobre música del fondo, al estilo del Singspiel.

Respecto a la música en sí, hay discrepancias en cuanto a su relevancia. Mientras algunos autores la consideran siempre subordinada al texto en importancia, otros como Ramón Barce teorizan acerca de que en la composición de la obra la música venía primero (sobre textos que eran incoherentes, llamados «monstruos», y que simplemente marcaban el ritmo a una letra que debía encajar el libretista, y que a menudo era retocada por el compositor sin demasiado acierto por su parte). En cualquier caso, la música no suele ser concordante con la acción, sino que más bien es algo que sucede al margen de ésta, siendo a menudo introducida de golpe.

La música tiene un carácter familiar al oído, popular y de folclore, lo que se consigue tomando melodías populares o de moda en el momento, y cambiándoles el texto. Las tonadillas buscan quedar en la memoria del espectador al salir de la obra. Además se buscan ritmos muy marcados y populares en los salones de baile, generalmente importados pero «nacionalizados», como podrían ser el chotis (palabra que viene del alemán "schottisch", en el que significa 'escocés', refiriéndose a que el estilo tiene como origen Escocia), y otros muchos como boleros, fandangos, habaneras, jotas, seguidillas, soleares, pasacalles, valses, polkas, o mazurcas (Polonia).





</doc>
<doc id="45482" url="https://es.wikipedia.org/wiki?curid=45482" title="Hal Draper">
Hal Draper

Hal Draper (1914 -1990) fue un activista socialista, marxista, shachtmanista de izquierda y autor. Inicialmente miembro de la "Liga Socialista Juvenil" (Young Peoples Socialist League), fue llevado con esa organización hacia el trotskismo. Junto con la YPSL tomó parte en la fundación del Partido Socialista de los Trabajadores (Socialist Workers' Party) en 1938.

Por 1940 fue parte de una facción dentro del SWP la cual se oponía al régimen interno de ese partido y desarrolló un análisis de la URSS en la cual la describía como una sociedad colectivista burocrática, en la cual una nueva clase, la burocracia de estado, controlaba el poder social y de estado. En 1940 esta facción se convirtió en el Partido de los Trabajadores (Workers' Party), dirigidos por Max Shachtman.

Por 1948 el WP creía que el futuro para una revolución estaba estancado, y que debía convertirse en un grupo propagandista. Así que se formó la Liga Socialista Independiente (Independent Socialist League) y Hal Draper continuó como uno de sus principales escritores y funcionarios.

Con una pequeña cantidad de miembros, aunque su trabajo juvenil era pujante, la directiva del ISL alrededor de Shachtman decidieron que era tiempo de unir fuerzas con el partido socialista de los Estados Unidos (Socialist Party of the United States of America) y en 1958 se fusionaron con ellos. Éste fue un movimiento al cual Draper se opuso, aunque lo siguió debido más que nada a la falta de una orientación alternativa.

En 1962, después de recibir un ultimátum de Joel Geier, el cual se convertiría luego en el líder de los Socialistas Independientes, Draper que en esta época residía en Berkeley, California, formó el Club Socialista Independiente (ISC) fuera del SPUSA. En 1964 Draper se ve envuelto activamente en el movimiento para la libertad de expresión, un importante precursor de la Nueva Izquierda (New Left), en el campus de Berkeley.

En 1968 el ISC se convirtió en los "Socialistas Independientes" (Independent Socialists) y se expandió nacionalmente. Pero en 1971 Draper renunció al IS debido a su preocupación de que el IS ya no ponía como centro de su análisis a la clase trabajadora. Desde entonces produjo una corriente de obras de erudición sobre marxismo y el movimiento obrero.

Su legado más grande sería su estudio en cuatro volúmenes "La Teoría de la Revolución de Karl Marx" (1977-1989). Aunque sus principales argumentos están resumidos en el panfleto "Las dos almas del Socialismo" (The Two Souls of Socialism, 1964).

Organizaciones de las cuales fue miembro:

Para los interesados en política, la creación más importante de Draper seria la historia corta "Ms Fnd in a Lbry", una sátira de la era de la información, escrita en 1961.



</doc>
<doc id="45487" url="https://es.wikipedia.org/wiki?curid=45487" title="Transformación natural">
Transformación natural

En teoría de categorías, una rama de las matemáticas. Una transformación natural proporciona una manera de transformar un funtor en otro mientras que se respeta la estructura interna, es decir la composición de morfismos, de las categorías implicadas. Por lo tanto, una transformación natural se puede considerar como un morfismo de funtores. Esta llamadas, categorías de funtores. Las transformaciones naturales son, después de las categorías y de los funtores, una de las nociones más básicas del álgebra categórica y por lo tanto aparecen en la mayoría de sus usos.

Si "F" y "G" son funtores (covariantes) entre las categorías "C" y "D", entonces una transformación natural η de "F" a "G" asocia a cada objeto "X" en "C" un morfismo η : "F"("X") → "G"("X") en "D", tal que para cada morfismo "f" : "X" → "Y" en "C" tenemos

Esta ecuación se puede expresar convenientemente por el diagrama conmutativo

Si η es una transformación natural de "F" a "G", se escribe también η: "F" → "G". 

Si, para cada objeto "X" en "C", el morfismo η es un isomorfismo en "D", entonces η se dice un isomorfismo natural (o a veces una equivalencia natural o isomorfismo de funtores). Dos funtores "F" y "G" se dicen "naturalmente isomorfos" o simplemente "isomorfos" si existe un isomorfismo natural de "F" a "G".

Declaraciones como "Todo grupo es naturalmente isomorfo a su grupo opuesto" abundan en matemáticas modernas. Ahora daremos el significado exacto de esta declaración así como su prueba. Considere la categoría Grp de todos los grupos con homomorfismos de grupo como morfismos. Si ("G",*) es un grupo, se define a su grupo opuesto ("G", *) como sigue: "G" es el mismo conjunto que "G", y la operación * es definida por "a"*"b" = "b"*"a". Todas las multiplicaciones en "G" "se dan vuelta así". La formación del grupo opuesto se convierte en un funtor de Grp a Grp si definimos "f" = "f" para cada homomorfismo de grupo "f": "G" → "H". Observe que "f" es de hecho un homomorfismo de grupo de "G" en "H":

el contenido de la declaración antedicha es: el funtor identidad Id: Grp → Grp es naturalmente isomorfo al funtor opuesto -: Grp → Grp. Para probar esto, necesitamos proporcionar isomorfismos η: "G" → "G" para cada grupo "G", tal que el diagrama antedicho conmuta. Haga η("a") = "a". Las fórmulas ("ab") = "b" "a" y ("a") = "a" demuestran que η es un homomorfismo de grupo que es su propio inverso. Para probar la naturalidad, comenzamos con un homomorfismo de grupo "f": "G" → "H" η o "f" = "f" o η, es decir ("f"("a")) = "f"("a") para todo "a" en "G". Esto es verdad puesto que "f" = "f" y cada homomorfismo de grupo tiene la propiedad ("f"("a")) = "f"("a").

Si "K" es un cuerpo, entonces para cada espacio vectorial sobre "K" "V" tenemos una función lineal inyectiva "natural" "V" -> "V" del espacio vectorial en su doble dual. Estas funciones son "naturales" en el sentido siguiente: la operación dual doble es un funtor, y los funciones forman una transformación natural del funtor identidad al funtor doble dual. Considere la categoría Ab de grupos abelianos y de homomorfismos de grupo. Para todos los grupos abelianos "X", "Y" y "Z" tenemos un isomorfismo de grupos

estos isomorfismos son "naturales" en el sentido que definen una transformación natural entre los dos funtores implicados Ab x Ab x Ab -> Ab.

Si η "F" → "G" y ε: "G" → "H" son transformaciones naturales entre funtores "C" → "D", entonces podemos componerlos para conseguir una transformación natural εη: "F" → "H". Éste es hecho componente a componente: (εη) = εη. Esta composición de la transformación natural es asociativa, y permite considerar la colección de todos los funtores "C" → "D" como categoría en sí misma (véase abajo Categorías de funtores).

Una transformación natural η: "F" → "G" es un isomorfismo natural si y solamente si existe una transformación natural ε: "G" → "F" tales que ηε = 1 y εη = 1 (donde 1: "F" → "F" es la transformación natural que asigna a cada objeto "X" el morfismo identidad en "F"("X")).

Si η : "F" → "G" es una transformación natural entre los funtores "F","G" : "C" → "D", y "H": "D" → "E" es otro funtor, entonces se puede formar la transformación natural "H"η : "HF" → "HG" definiendo ("H"η) = "H"(η). Si por otra parte "K": "B" → "C" es un funtor, la transformación natural η"K": "FK" → "GK" se define por (η"K") = η.

Si "C" es cualquier categoría e "I" es una categoría pequeña, podemos formar la categoría de funtores "C" teniendo como objetos todos los funtores de "I" a "C" y como morfismos las transformaciones naturales entre esos funtores. Esto es especialmente útil si "I" se presenta como un grafo dirigido. Por ejemplo, si "I" es la categoría del grafo dirigido * -> *, entonces "C" tiene como objetos los morfismos de "C", y un morfismo entre φ y ψ de "U" -> "V" y ψ "X" -> "Y" en "C" es un par de los morfismos "f": "U" -> "X" y "g": "V" -> "Y" en "C" tales que el "cuadrado conmuta", es decir ψ "f" = "g" φ.

Si "X" es un objeto de la categoría "C", entonces la asignación "Y" |-> Mor("X", "Y") define un funtor covariante "F": "C" -> Set. Este funtor se llama "representable". Las transformaciones naturales de un funtor representable a un funtor arbitrario "F": "C" -> Set son totalmente conocidas y fáciles de describir; éste es el contenido del lema de Yoneda. 

Saunders MacLane, uno de los fundadores de la teoría de categorías, se dice que comentó, "yo no inventé las categorías para estudiar funtores; las inventé para estudiar las transformaciones naturales." Así como el estudio de los grupos no está completo sin un estudio de los homomorfismos, así el estudio de las categorías no está completo sin el estudio de los funtores. La razón del comentario de Mac Lane es que el estudio de los funtores es en sí mismo incompleto sin el estudio de las transformaciones naturales. El contexto de la observación de Mac Lane era la teoría axiomática de la homología. Diversas maneras de construir la homología se podían demostrar que coincidían: por ejemplo en el caso de un complejo simplicial los grupos definidos directamente, y los de la teoría singular, serían isomorfos. Pero eso, en sí mismo, indicaba mucho menos que la existencia de una transformación natural de los funtores correspondientes de la homología.


</doc>
<doc id="45502" url="https://es.wikipedia.org/wiki?curid=45502" title="Funtores adjuntos">
Funtores adjuntos

En matemáticas, específicamente en teoría de categorías, la adjunción es una relación entre dos funtores que aparece frecuentemente a través de las distintas ramas de las matemáticas y que captura una noción intuitiva de solución a un problema de optimización. Dos funtores formula_1 y formula_2 se dicen adjuntos entre sí, si existe una familia de biyecciones
que es natural para cualesquiera formula_4 e formula_5. La relación de que formula_6 sea "adjunto a izquierda" de formula_7, o, equivalentemente, que formula_7 sea "adjunto a derecha" de formula_6, se nota como formula_10.

La idea de funtor adjunto fue formulada por Daniel Kan en 1958. Como ocurre con muchos de los conceptos en teoría de categorías, fue sugerida por las necesidades del álgebra homológica. Aquellos matemáticos preocupados por dar presentaciones ordenadas o sistemáticas del tema, observaron relaciones tales como
en la categoría de los grupos abelianos, donde el funtor "F" era 'toma el producto tensorial con "A"', y "G" era el funtor Hom("A".). Aquí
significa 'todos los homomorfismos de grupos abelianos'. El uso del signo "igual" es un abuso de notación; los dos grupos no son realmente idénticos pero hay una manera de identificarlos que es "natural". Puede ser visto como natural sobre la base, en primer lugar, de que éstas son dos descripciones alternativas de las funciones bilineales de "B"x"A" a "C". Esto, no obstante, es algo peculiar del producto tensorial. Lo que la teoría de categorías enseña es que 'natural' es un término técnico bien definido en matemática: equivalencia natural.

La terminología viene del espacio de Hilbert y la idea del operador adjunto de "T", "U" con <"Tx", "y" > = <"x", "Uy">, que es formalmente similar a la anterior relación "Hom". Decimos que "F" es "adjunto izquierdo" de "G", y "G" es "adjunto derecho" de "F". Puesto que "G" puede ser por sí mismo, un adjunto derecho, absolutamente diferente de "F" (véase abajo para un ejemplo), la analogía colapsa en ese punto. Si uno comienza a buscar estos pares de adjuntos de funtores, resultan ser muy comunes en el álgebra abstracta y también en otras partes. La sección de ejemplos más abajo proporciona las evidencias; además, las construcciones universales, que pueden ser más familiares, dan lugar a numerosos pares de funtores adjuntos.

De acuerdo con el pensamiento de Saunders MacLane, cualquier idea, tal como funtores adjuntos, que ocurra con suficiente extensión en matemática debe ser estudiada por sí misma.

Alexander Grothendieck utilizó la teoría de categorías para orientarse en ciertos trabajos fundacionales, axiomáticos del análisis funcional, el álgebra homológica y finalmente en geometría algebraica.

El reconocimiento del papel de la adjunción era inherente al enfoque de Grothendieck. Por ejemplo, uno de sus logros importantes fue la formulación de la dualidad de Serre en forma relativa - se puede decir: "en una familia continua de variedades algebraicas". Toda la demostración giraba en torno a la existencia de un adjunto derecho para cierto funtor.

Una buena manera de motivar funtores adjuntos es explicar qué problema solucionan, y cómo lo solucionan. Eso solo puede hacerse, en cierto sentido, "gesticulando". Si puede ser dicho, sin embargo, que con los funtores adjuntos se crea el concepto de la "mejor estructura", una del tipo que se esté interesado en construir. Por ejemplo, una pregunta elemental en teoría de anillos es cómo agregar una identidad multiplicativa a un anillo que no tenga tal cosa (la definición de Wikipedia asume realmente uno: vea anillo (matemática) y glosario de la teoría de anillos). La "mejor" manera es agregar un elemento "1" al anillo, y no agregar nada suplementario que no se necesite (se necesitará tener "r"+1 para cada "r" en el anillo, por supuesto), y que no agregue ninguna relación en el nuevo anillo que no venga forzada por los axiomas. Esto es algo vago, aunque sugestivo.

Hay varias maneras de hacer exacto este concepto de la "mejor estructura". Los funtores adjuntos son un método; la noción de propiedades universales proporciona otros, esencialmente equivalente pero probablemente con un enfoque más concreto.

Las propiedades universales también se basan en la teoría de categorías. La idea es presentar el problema en términos de una cierta categoría auxiliar "C"; y entonces identificar lo que deseamos hacer como demostrar que "C" tiene objeto inicial. Esto tiene una ventaja que la "optimización" - la sensación que estamos encontrando la mejor solución - es seleccionado y reconocible como el logro de un supremo. Hacerlo es cuestión de destreza: por ejemplo, tome un anillo dado "R", y haga una categoría "C" cuyos objetos sean homomorfismos de anillo "R" → "S", con "S" un anillo que tiene una identidad multiplicativa. Los morfismos en "C" debe completar los triángulos que son diagramas conmutativos, y preservar identidad multiplicativa. La aserción es que "C" tiene un objeto inicial "R" → "R"*, y "R"* es entonces el anillo buscado.

El método del funtor adjunto para definir una identidad multiplicativa para los anillos es mirar dos categorías, "C" y "C", de anillos, respectivamente sin y con la asunción de la identidad multiplicativa. Hay un funtor de "C" a "C" que se olvida del 1. Estamos buscando un adjunto izquierdo para él. Esto es una clara, aunque seca, formulación.

Una forma para ver lo que es alcanzado usando cualquier formulación es intentar un método directo. (Algunos son más amigos de estos métodos, por ejemplo John Conway.) Se agrega al "R" simplemente un nuevo elemento, "1", y se calcula sobre la base de que cualquier ecuación resultante es válida si y solamente si "vale para todos los anillos" que podamos crear de R y 1. Éste es el método impredicativo: que significa que el anillo que estamos intentando construir es uno de los anillos cuantificados en "todos los anillos". Este uso abierto de la impredicatividad es "honesto", de forma distinta a como ocurre en teoría de categorías.

La respuesta con respecto a la manera de conseguir el anillo (unital) a partir de uno que no es unital es bastante simple (véase los ejemplos abajo); esta sección ha sido una discusión de cómo formular la pregunta.

El argumento principal en favor de los funtores adjuntos es probablemente este: si uno avanza con propiedades universales o razonamientos impredicativos, bastante a menudo, parecen como una repetición de los mismos pasos.

Cada conjunto parcialmente ordenado se puede ver como una categoría (con un solo morfismo entre "x" e "y" si y solamente si "x" ≤ "y"). Un par de funtores adjuntos entre dos conjuntos parcialmente ordenados se llama una conexión de Galois (o, si es contravariante, una conexión de Galois antítona). Vea el artículo para un número de ejemplos: el caso de la teoría de Galois es por supuesto primordial. Cualquier conexión de Galois da lugar a operadores de clausura y a biyecciones inversas que preservan el orden entre los elementos cerrados correspondientes.

Al igual que el caso para los grupos de Galois, a menudo el verdadero interés reside en refinar una correspondencia a una dualidad (es decir isomorfismo de orden antítono). Un tratamiento de la teoría de Galois siguiendo estas líneas por Kaplansky fue influyente en el reconocimiento de la estructura general.

El orden parcial reduce las definiciones de la adjunción en forma absolutamente perceptible, pero puede proporcionar varios temas:


Estas observaciones en su conjunto proporcionan valor explicativo acerca del conjunto de todas las matemáticas.

Un par de funtores adjuntos entre dos categorías "C" y "D" consiste en dos funtores "F": "C" → "D" y "G": "D" → "C" y un isomorfismo natural que consiste en funciones biyectivas

Cada par de funtores adjuntos define una unidad η, una transformación natural del funtor Id a "GF" que consisten en morfismos

Objetos libres. Si "F": Set → Grp es el funtor que asigna a cada conjunto "X" el grupo libre sobre "X", y si "G": Grp → Set es el funtor de olvido que asigna a cada grupo su conjunto subyacente, entonces la propiedad universal del grupo libre demuestra que "F" es el adjunto izquierdo de "G". La unidad de este par adjunto es la inclusión de un conjunto "X" en el grupo libre sobre "X".

anillos libres, grupos abelianos libres, y los módulos libres siguen el mismo patrón.

Productos. Sea "F": Grp → Grp² sea el funtor que asigna a cada grupo "X" el par ("X", "X") en la categoría producto Group, y "G": Group² → Grp el funtor que asigna a cada par ("Y", "Y") el grupo producto "Y"x"Y". La propiedad universal del grupo producto demuestra que "G" es adjunto derecho de "F". La co-unidad da las proyecciones naturales del producto a los factores.

El producto cartesiano de conjuntos, el producto de anillos, el producto de espacios topológicos etc. sigue el mismo patrón; puede también ser ampliado de una manera directa a más que solamente dos factores.

Coproductos. Si "F": Ab² → Ab asigna a cada par ("X", "X") de grupos abelianos su suma directa y si "G": Ab → Ab² es el funtor que asigna a cada grupo abeliano "Y" el par ("Y", "Y"), entonces "F" es el adjunto izquirdo de "G", otra vez consecuencia de la propiedad universal de las sumas directas. La unidad del par adjunto proporciona las inmersiones naturales de los factores en la suma directa. Los ejemplos análogos son dados por suma directa de espacios vectoriales y módulos, por producto libre de grupos y por la unión disjunta de conjuntos.

Núcleos. Considere la categoría "D" de homomorfismos de grupos abelianos. Si "f": "A" → "B" y "f": "A" → "B" son dos objetos de "D", entonces un morfismo de "f" a "f" es un par ("g", "g") de morfismos tales que "g""f" = "f""g". Sea "G": "D" → Ab el funtor que asigna a cada homomorfismo su núcleo y sea "F": Ab → "D" el morfismo que mapea al grupo "A" al homomorfismo "A" → 0. Entonces "G" es el adjunto derecho de "F", lo que expresa la propiedad universal de los núcleos, y la co-unidad de esta adjunción da el encaje natural del núcleo de un homomorfismo en el dominio del homomorfismo.

Una variación conveniente de este ejemplo también demuestra que los funtores de núcleo para los espacios vectoriales y para los módulos son adjuntos derechos. Análogamente, uno puede demostrar que los funtores de cokernel para los grupos abelianos, los espacios vectoriales y los módulos son adjuntos izquierdos.

Haciendo un anillo unital. Este ejemplo fue discutido en la sección 1.3 arriba. Dado un anillo no unitario "R", un elemento multiplicativo identidad puede ser agregado tomando "R"xZ y definiendo un producto Z-bilineal por (r, 0)(0, 1) = (0,1)(r,0) = (r,0), (r, 0)(s, 0) = (rs, 0), (0,1)(0,1) = (0, 1). Esto construye un adjunto izquierdo al funtor que lleva un anillo al anillo no unital subyacente.

Extensiones de anillo. Suponga que "R" y "S" son anillos, y ρ : "R" → "S" es un homomorfismo de anillo. Entonces "S" se puede considerar como un "R"-módulo (izquierdo), y el producto tensorial con "S" da un funtor "F": "R"-Mod → "S"-Mod. Entonces "F" es adjunto izquierdo del funtor de olvido "G": "S"-Mod → "R"-Mod.

Productos tensoriales. Si "R" es un anillo y "M" es un "R" módulo derecho, entonces el producto tensorial con "M" da un funtor "F": "R"-Mod → Ab. el funtor "G": Ab → "R"-Mod, definido por "G"("A") = Hom("A", "M") para cada grupo abeliano "A", es un adjunto derecho de "F".

De monoides y grupos a anillos. La construcción del anillo monoideda un funtor de los monoides a los anillos. Este funtor es el adjunto izquierdo al funtor que asocia a un anillo dado su monoide multiplicativo subyacente. Semejantemente, la construcción del anillo grupo da un funtor de los grupos a los anillos, adjunto izquierdo al funtor que asigna a un anillo dado su grupo de unidades. Uno puede también comenzar con un cuerpo "K" y considerar la categoría de las "K"-álgebras en vez de la categoría de anillos, y conseguir monoides y anillos grupo sobre "K".

Imágenes directas e inversas de haces. Cada función continua "f": "X" → "Y" entre espacios topológicos induce un funtor "f" de la categoría de haces (de conjuntos, o de grupos abelianos, o de anillos...) en "X" a la categoría correspondiente de haces en "Y", el "funtor imagen directa". También induce un funtor "f" de la categoría de haces en "Y" a la categoría de haces en "X", el "funtor imagen inversa". "f" es el adjunto izquierdo a "f".

La construcción de Grothendieck. En K-teoría, el punto de partida es observar que la categoría de los fibrados vectoriales en un espacio topológico tiene una estructura conmutativa de monoide usando la suma directa. Para hacer de este monoide un grupo abeliano, uno puede seguir el método de extender a un grupo, agregando formalmente el inverso del añadido para cada fibrado (o la clase de equivalencia). Alternativamente uno puede observar que el funtor que para cada grupo toma el monoide subyacente (que ignora el inverso) tiene un adjunto izquierdo. Esto es una construcción de una vez para siempre, en línea con el tercer argumento de la sección anterior. Es decir, uno puede imitar la construcción de los números negativos; pero está la otra opción de un teorema de existencia. Para el caso de estructuras algebraicas finitas, la existencia por sí misma se puede referir a un álgebra universal, o a la teoría de modelos; naturalmente hay también una prueba adaptada a la teoría de categorías.

Reciprocidad de Frobenius en la teoría de representación de grupos: vea representación inducida. Este ejemplo adelantó la teoría general por alrededor de medio siglo.

compactificación de Stone-Čech. Sea "D" la categoría de los compactos de Hausdorff y "G": "D" → Top sea el funtor de olvido que trata cada espacio compacto de Hausdorff como un espacio topológico. Entonces "G" tiene un adjunto izquierdo "F": Top → "D", la compactación de Stone-Čech. La unidad de este par adjunto da la función continua de cada espacio topológico "X" en su compactación de Stone-Čech. Esta función es una inmersión (es decir inyectiva, continua y abierta) si y solamente si "X" es un espacio de Tychonoff.

Soberification. El artículo sobre la dualidad de Stone describe una adjunción entre la categoría de espacios topológicos y la categoría de los espacios sobrios que se conoce como soberification. Notablemente, el artículo también contiene una descripción detallada de otra adjunción que prepara el camino para la famosa dualidad de espacios sobrios y de locales espaciales, explotada en topología sin puntos.

un funtor con un adjunto izquierdo y uno derecho. Sea "G" el funtor de los espacios topológicos a los conjuntos que asocia a cada espacio topológico su conjunto subyacente (esto es, que se olvida de la topología). el "G" tiene un adjunto izquierdo "F", creando el espacio discreto en un conjunto "Y", y un adjunto derecho "H" creando la topología trivial en "Y" (cf. estructura trivial).

Todos los pares de funtores adjuntos surgen de construcciones universales. Las construcciones de los ejemplos anteriores se pueden todos explicar con una propiedad universal, y de hecho algunos de los artículos relevantes así lo hacen. Las construcciones universales son más generales que pares de funtores adjuntos: según lo mencionado anteriormente, una construcción universal es como un problema de optimización; da lugar a un par adjunto si y solamente si este problema tiene una solución para cada objeto de "D".

Si el funtor "F": "C" → "D" tenía dos adjuntos derechos "G" y "G", entonces "G" y "G" son naturalmente isomorfos. Lo mismo es verdad para adjuntos izquierdos.

La propiedad más importante de los adjuntos es su continuidad: cada funtor que tiene un adjunto izquierdo (y por lo tanto es un adjunto derecho) es "continuo" (es decir conmuta con límites en el sentido teórico de la categoría); cada funtor que tiene un adjunto derecho (y por lo tanto es un adjunto izquierdo) es "cocontinuo" (es decir conmuta con colímites).

Puesto que muchas construcciones comunes en matemática son límites o colímites, esto proporciona abundante información. Por ejemplo:


Si el funtor "F": "C" → "D" es el adjunto izquierdo de "G": "D" → "C" y "C" y "D" son categorías aditivas, entonces "F" y "G" son funtores aditivos.

Si el funtor "F": "C" → "D" tiene "G": "D" → "C" como adjunto derecho y el funtor "F": "D" → "E" tiene a "G": "E" → "D" como adjunto derecho, entonces la composición "F"o"F": "C" → "E" tiene G"o"G": "E" → "C" como adjunto derecho.

La unidad η : 1 → "GF" y la co-unidad ε: "FG" → 1 tienen las propiedades siguientes: la composición (ε"F")o("F"η), una transformación natural "F"→"FGF"→"F", es igual a 1, y la composición ("G"ε)o(η"G"): "G"→"GFG"→"G" es igual a 1. Inversamente, dadas dos transformaciones naturales η 1 → "GF" y ε: "FG" → 1 con estas propiedades, entonces los funtores "F" y "G" forman un par adjunto.

Cada par adjunto amplía la equivalencia de ciertas subcategorías. Específicamente, si "F": "C" → "D" es el adjunto izquierdo de "G": "D" → "C" con la unidad η y la co-unidad ε, defina "C" como subcategoría completa de "C" consistente de esos objetos "X" de "C" para los cuales η es un isomorfismo, y defina "D" como la subcategoría completa de "D" que consiste en esos objetos "Y" de "D" para el cual ε es un isomorfismo. Entonces "F" y "G" se pueden restringir a "C" y "D" y dan equivalencias inversas de estas subcategorías. En un sentido, entonces, los adjuntos son inversos "generalizados". Observe sin embargo que el inverso derecho de "F" (es decir un funtor "G" tales que el "FG" es naturalmente isomorfo a 1) no necesita ser un adjunto derecho (o izquierdo) de "F".

Adjuntos generaliza inversos biláteros.

No todo funtor "G": "D" → "C" admite un adjunto izquierdo. Si "D" es completo, entonces los funtores con adjuntos izquierdos se pueden caracterizar por el teorema de Freyd del Functor Adjunto: "G" tiene un adjunto izquierdo si y solamente si es continuo y cierta condición de pequeñez es satisfecha: para cada objeto "X" de "C" existe una familia de morfismos "f": "X" → "G"("Y") (donde los índices "i" vienen de un conjunto "I", no una clase propia -- éste es todo el punto), tales que cada morfismo "h": "X" → "G"("Y") se puede escribir como "h" = "G"("t") o "f" para algún "i" en "I" y algún morfismo "t": "Y" → "Y" en "D".

Una proposición análoga caracteriza los funtores con un adjunto derecho.


</doc>
<doc id="45503" url="https://es.wikipedia.org/wiki?curid=45503" title="Simula">
Simula

Simula es un lenguaje de programación orientada a objetos (POO) de 1962. Fue el primero de este tipo que incluyó el concepto de clase. Varios años después de su desarrollo, casi todos los lenguajes modernos comenzaron a utilizar sus principios de orientación a objetos. Así fue como se popularizaron términos como "clases", "objetos", "instancias", "herencia", "polimorfismo", etc.

Simula 67 fue lanzado oficialmente por sus autores Ole Johan Dahl y Kristen Nygaard en mayo de 1967, en la Conferencia de Trabajo en Lenguajes de Simulación IFIO TC 2, en Lysebu cerca de Oslo 

Hoy en día, los creadores de Simula han desarrollado un nuevo lenguaje de programación, llamado Beta, que generaliza todas las construcciones del lenguaje en una única idea denominada "patrón".

Éste es el famoso programa "Hola Mundo" en Simula 67:

Simula es un lenguaje orientado a objetos. Esto significa que el ejemplo de 'Hola Mundo' también se puede escribir instanciando una clase que se encarga de escribir el saludo.

Este programa también muestra ""¡Hola Mundo!"".

El mensaje está codificado en el bloque de código de la clase Saludos. Este bloque de código se ejecuta solamente cuando existe una instancia o variable de tipo Saludos; lo que ocurre efectivamente al crear una instancia por medio de la instrucción New.

En Simula, los objetos siempre son manejados por medio de referencias. Existe un recolector de basura que se encarga de eliminar de la memoria los objetos que se han quedado sin referencias a ellos. Una de estas referencias la vemos con variable objeto. Utilizamos el operador :- para asignar referencias.

A diferencia de muchos lenguajes modernos, Simula entiende de dos tipos de objetos.

Activos son aquellos objetos que aún no han completado su bloque asociado begin/end.

Inactivos por otra parte, han completado su bloque de instrucciones.

Tanto de unos como de otros, es posible ejecutar los procedimientos miembro y consultar los atributos en cualquier momento.

Dado que Simula 67 es un lenguaje ya un poco añejo, los conceptos que maneja son un poco distintos a los actualmente utilizados por la comunidad de programación orientada a objetos. Las instancias a las que estamos habituados corresponden a los objetos "inactivos". En tanto que el bloque de instrucciones constituye una serie de constructores.

En cuanto a los objetos "activos", estos existen debido a una funcionalidad de pseudo-paralelismo encontrada en Simula y ausente en casi todos los lenguajes modernos. Esta funcionalidad recibe el nombre de co-rutina y es controlada directamente por el lenguaje por medio de un grupo de palabras clave.

Un grupo de objetos "activos" pueden coexistir en un mismo programa Simula, y transferir el control de unos a otros en cualquier momento. Esta funcionalidad es la base de las características de simulación que dan nombre al lenguaje.



</doc>
<doc id="45504" url="https://es.wikipedia.org/wiki?curid=45504" title="Estructura (teoría de categorías)">
Estructura (teoría de categorías)

En matemática, en ausencia de estructura reconocible (que puede, sin embargo, estar oculta) los problemas tienden a caer en esa clasificación combinatoria de materias que requieren argumentos especiales. 

En teoría de categorías la "estructura" es implícitamente discutida - en oposición con la discusión explícita típica con muchas estructuras algebraicas. Comenzando con una clase dada de estructuras algebraicas, por ejemplo los grupos, uno puede construir la categoría en la cual los objetos son grupos y los morfismos son los homomorfismos de grupo: es decir, de estructuras de un tipo, y de funciones que respetan esa estructura. Comenzando con una categoría "C" dada abstractamente, el desafío es deducir qué estructura "hay" en los objetos que los morfismos 'preservan'. 

El término "estructura" fue utilizado mucho en conexión con el enfoque del grupo Bourbaki. Hay incluso una definición. La estructura debe incluir claramente tanto al espacio topológico así como las nociones estándar del álgebra abstracta. La estructura en este sentido es semejante con la idea de una categoría concreta que se pueda presentar de una manera definida - el caso topológico significa que las operaciones infinitarias serán necesarias. La "presentación de una categoría" (análogo a presentación de un grupo) se puede de hecho acercar de varias maneras, la estructura de "categoría" no es, estrictamente, una estructura algebraica. 

El término "transporte de estructura" es la manera 'francesa' de expresar "covariancia" o "equivariancia" como restricción: transfiera la estructura por una sobreyección y entonces (si hay una estructura ya existente) comparar. 

Puesto que cualquier grupo es una categoría de un solo objeto, un caso especial de la pregunta sobre qué es lo que los morfismos preservan es esta: ¿cómo considerar un grupo G como un grupo de simetría? La mejor respuesta que podemos dar es el teorema de Cayley. El análogo en teoría de categorías es el lema de Yoneda. Uno concluye que el conocimiento de la 'estructura' está acotado por lo que podemos decir sobre los funtores representables en "C". Sus caracterizaciones, en casos interesantes, fueron buscadas en los años 60, para el uso en particular en los problemas de moduli de la geometría algebraica; demostrando de hecho que estas son materias muy sutiles.


</doc>
<doc id="45508" url="https://es.wikipedia.org/wiki?curid=45508" title="Georges Lagrange">
Georges Lagrange

Georges Lagrange, escritor en esperanto, nació en el 1928 y falleció el 30 de abril de 2004 en el pueblo de Bouresse, en el centro «Kvinpetalo», ubicado cerca de Poitiers. Había sido cofundador de este gran centro de enseñanza y difusión de la lengua esperanto, conocido en Francia y en el movimiento esperantista mundial.

Lagrange estudió el esperanto en su juventud, después de la Segunda Guerra Mundial, lo que lo llevó a dedicarse también a la enseñanza y difusión del esperanto.

En este idioma escribió unas veinte obras originales, novelas y piezas de teatro, además de publicar numerosas traducciones de autores franceses, antiguos y modernos.

Tradujo también al esperanto las canciones de Georges Brassens y otros compositores modernos y escribió los diálogos del film «La verd’stelulo», estrenado en 1996, una de las películas grabadas originalmente en Lengua Internacional Esperanto.

El reconocido perfecto dominio del esperanto alcanzado por Georges Lagrange hizo que fuera elegido para formar parte de la Academia internacional de Esperanto.


</doc>
<doc id="45510" url="https://es.wikipedia.org/wiki?curid=45510" title="30 de febrero">
30 de febrero

Febrero tiene 28 o 29 días (este último solo en los años bisiestos). Sin embargo, dos veces a lo largo de la historia, y solo en determinados países, ha habido un "30 de febrero".

Suecia (entonces Finlandia era parte del reino de Suecia) seguía el calendario juliano, pero adoptaría paulatinamente el calendario gregoriano. Para ello, a partir de 1700 omitiría un día cada año, para llegar finalmente al calendario gregoriano en 1710 (Algunas fuentes afirman que omitiría los años bisiestos a lo largo de 40 años). Así, se quitó un día en 1700, pero no se hizo ninguna reducción más tras el inicio de la Gran Guerra del Norte, con lo que el llamado calendario sueco se adelantaba por un día al calendario juliano, pero aún tenía diez días de retraso con respecto al gregoriano. La confusión tocó a su fin cuando, en 1712, hubo dos días bisiestos, con lo que ese año tuvo un 30 de febrero. Ese día corresponde al 29 de febrero del calendario juliano y al 1 de marzo del gregoriano. Al final, Suecia adoptó el calendario gregoriano en 1753.

En 1929 la Unión Soviética introdujo un calendario revolucionario en el que cada mes tenía 30 días y los cinco o seis días restantes eran fiestas que no pertenecían a ningún mes. En 1930 y 1931 hubo un 30 de febrero en la URSS, pero en 1932 los meses volvieron a ser los de antes.




</doc>
<doc id="45518" url="https://es.wikipedia.org/wiki?curid=45518" title="General Escobedo">
General Escobedo

General Escobedo es un municipio y ciudad Industrial de Nuevo León, forma parte del Área Metropolitana de Monterrey. Colinda al norte con los municipios de Salinas Victoria, Hidalgo y El Carmen, al sur con Monterrey y San Nicolás de los Garza, al este con Apodaca, y al oeste con García y Municipio de Santa Catarina (Nuevo León).

El nombre de la ciudad es en honor al vencedor de la segunda intervención del imperio francés, el Gral. Mariano Escobedo. El primer dueño de las tierras donde se asienta el municipio fue el capitán José de Treviño, al recibir el 25 de abril de 1604 la merced de parte del Gobernador Don Diego de Montemayor. Por lo cual el capitán José de Treviño es considerado el fundador. Pero es su hijo José de Ayala el poblador definitivo, al establecer en estas tierras que heredó de su padre, la Hacienda del Topo de San Nicolás Tolentino y que con el tiempo sería conocida con el nombre del Topo de los Ayala o Topo Grande, para no confundirla con el Topo de los González o Topo Chico.

La hacienda perteneció desde su fundación a la jurisdicción de Monterrey hasta 1830, cuando la estancia de San Nicolás de los Garza es elevada al rango de Villa, quedando en su demarcación. Pero mientras San Nicolás sobresale en todos los órdenes, la Hacienda del Topo de los Ayala va quedando en el olvido, por lo que sus pobladores manifiestan en 1867 su deseo de separarse de San Nicolás, consiguiendo que el Gobernador Jerónimo Treviño firme el decreto No. 15 el 24 de febrero de 1868, creando la Villa de Gral. Escobedo en lo que era la antigua Hacienda del Topo de los Ayala.

La celebración anual de la feria que se realiza en julio, en la fiesta del Apóstol Santiago.

Escudo en forma portuguesa y/o francesa, con escusón, bordura y yelmo en la parte superior con divisa en la parte inferior. Cuartel diestro superior: Representación cultural. Templo de San Nicolás de Bari.

Cuartel siniestro superior: León rampante, lampazado y coronado sobre fondo de azul. Cuartel diestro inferior: Representación del monumento a don Mariano Escobedo, en cuyo honor se dio nombre al Municipio. Cuartel siniestro inferior: Representación geográfica y de actividad económica. El cerro Topo Chico, industria, agricultura y ganadería.

Escudón: Un libro que simboliza la educación y la cultura. Bordura: Años de elevación a Villa 1868 y de elevación a ciudad, 1982. En su parte superior la fecha 24 de febrero para simbolizar la celebración de su fundación. En su parte inferior el nombre del municipio General Escobedo, N.L. Divisa: Se muestra el lema: "TRABAJO Y ARRAIGO"

Las elevaciones características del territorio municipal son el Cerro del Topo Chico y la Sierra del Fraile, originadas en la edad mesozoica constituidas por calizas y lutitas; y pequeñísimas partes del territorio pertenecen a la era mesozoica, período terciario superior y se constituyen de plioceno y conglomerado.

El estado de Nuevo León pertenece a la sub-provincia de la Llanura Costera del Golfo Norte, que está incluida en la región conocida como Llanura Costera o Plano Inclinado; uno de los municipios que la conforman en parte es Escobedo, constituido por una gran llanura (lomerío suave con asociaciones de lomerío, bajadas y llanuras) interrumpida por tres elevaciones clasificadas, dentro del sistema de topomorfas, como sierra baja (Cerro del Topo Chico) y valle intermontano (Sierra del Fraile).

Escobedo presenta pendientes de 40 a 70% en la Sierra del Fraile y en Cerro del Topo Chico, con una profundidad del suelo menor de 10 cm. Esto lo hace no apto para vegetación forrajera o forestal.

Las pendientes de 3 a 12% se presentan en el resto del Municipio con una profundidad de suelos que van desde los 35 a más de 90 cm un régimen de humedad en el rango de semiseco a subhúmedo, con un valor forestal bastante pobre o nulo, y en algunas zonas con salinidad desde moderada hasta intensa.

En cuanto a aptitud territorial para el desarrollo urbano, con posibilidades de urbanización con un menor costo económico y social, se considera la parte sur del Municipio, con áreas medianamente aptas para el desarrollo urbano, con pendientes de 0 a 2%, y aunando a ello la cercanía de las redes generales de infraestructura para la prestación de servicios.

El municipio de Escobedo es atravesado de poniente a oriente por el río Pesquería, mayor afluente del río San Juan, que a su vez es el segundo afluente de importancia del río Bravo. En época de intensas lluvias, que se presentan esporádicamente en la historia de esta región, puede determinarse como zona de riesgo las riberas del mismo.

El régimen hidrológico del Municipio presenta desde este punto de vista una buena expectativa, la cuenca Río Bravo-San Juan es la más importante del Estado.

Sin embargo los estudios realizados sobre la carga orgánica de las aguas del río Pesquería, determinan que existen problemas de primer orden que requieren de un control inmediato. Dentro del Municipio, el río presenta un 5.6 de demanda bioquímica de oxígeno.

La escasa disponibilidad de agua en el Área Metropolitana de Monterrey, afecta igualmente a Escobedo, cuyo territorio está clasificado, en un gran porcentaje, como sub-explotado desde el punto de vista de su potencial acuífero, esto significa que puede incrementarse la explotación de agua subterránea para cualquier uso, bajo control de la SARH.

En cuanto a permeabilidad, las rocas y suelo del Municipio, casi en su totalidad son suelos aluviales y conglomerados con presencia comprobada de agua, clasificados como material no consolidado con posibilidades altas.

El resto, que entre paréntesis es una pequeña parte, está constituido principalmente por rocas lutílicas o sea material consolidado con posibilidades de permeabilidad bajas.Una pequeña parte de la mancha urbana presenta permeabilidad media en materiales consolidados.

El clima de Escobedo se puede situar entre los climas secos (Bso), asociado al tipo de vegetación de los matorrales espinosos y desérticos. La mayor parte del territorio está catalogado como sub-tipo seco cálido con lluvias en verano, precipitación invernal de entre 5 y 10.2%, cálido.

Condición de canícula, una pequeña temporada menos lluviosa; dentro de la estación de lluvias también presenta sequía de medio verano. El porcentaje de lluvia invernal es d
e entre 5 y 10.2 en general con una precipitación anual que oscila entre los 400 y 600 mm; la mayor parte del Municipio presenta una temperatura media anual que fluctúa entre los 20ºC; otra pequeña parte se sitúa entre los 18 y 20º C en las elevaciones, y el resto, que es una mínima proporción al norte de su territorio se presenta en el rango de entre 17°C y 18°C.

En cuanto a humedad, es bastante baja y se deriva de los factores antes mencionados y de la influencia de vientos secos en la zona, esta sequedad es un poco suavizada por los vientos alisios que le proporcionan humedad en cierta medida. La frecuencia de heladas es de aproximadamente 10-20 días al año y el granizo es un fenómeno bastante distante de presentarse de 0 y 2 días.

La vegetación es característica del semi-desierto del Noreste de México. Existe una abundancia de plantas xerófitas y de matorral (anacahuita, huizache, cenizo, etc.). La fauna es de coyotes, víboras, gato montés , urracas y liebres.

El tipo de vegetación que domina el territorio del Municipio es el de matorral sub-montano, matorral espinoso, mezquital, pastizal inducido, pequeñas áreas de agricultura de riego y de temporal que tienden a desaparecer ante la demanda de suelo urbano.

La ciudad está experimentando un crecimiento constante como resultado de la instalación de parques industriales, la apertura de grandes centros comerciales y nuevos fraccionamientos tanto de vivienda popular como media. El crecimiento urbano de General Escobedo es mixto, al haber nuevas zonas Habitacionales, Comerciales y la Instalación de diversas Industrias.

Los nuevas zonas habitacionales han generado una notoria segregación. Cierto nivel de construcciones no se integran con el resto de la ciudad y se han cerrado calles para impedir la integración con el resto. Es muy común observar que los nuevos desarrollos habitacionales son "amurallados" e inclusive con las vías públicas controladas por servicios privados de seguridad para dar a los nuevos residentes una sensación de seguridad y exclusividad, impidiendo el libre tránsito y el uso del los espacios públicos del resto de la población.

El fenómeno del crecimiento rápido y desorganizado es consecuencia del gran aumento demográfico del área metropolitana de Monterrey, la ciudad ha pasado en menos de 30 años de ser una comunidad rural a una urbana.



Las actividades económicas más importantes son la manufactura y los servicios, la agricultura y ganadería de antes.

La ciudad cuenta con una muy buena red de caminos, es un paso obligado para el transporte de mercancías hacía la frontera con Estados Unidos, las carreteras hacia Nuevo Laredo y Colombia (Nuevo León) atraviesan el municipio. Además la ciudad está conectada con un libramiento vial para la carretera a Saltillo y por su territorio pasa la carretera hacia la importante ciudad de Monclova (Coahuila). Cuenta además con estaciones de Ferrocarril. Su infraestructura de transporte aumentó con la construcción de la extensión de la línea 2 del metro (Metrorrey) que la conecta rápidamente con San Nicolás de los Garza y con Monterrey.

Uno de sus principales atractivos es el área del Centro Artesanal La Hacienda, popularmente conocida como "Los Cavacitos" (En alusión al centro artesanal "Los Cavazos" en Santiago, Nuevo León) en el cual encontrará artesanías en barro en cerámica en yeso y madera además de artículos de forja para decoración. Cuentan con un área de comida donde se vende el tradicional pan de elote así como antojitos mexicanos. 

El Museo Histórico Escobedo es otro sitio de interés donde se narra la historia del municipio y la Presidencia Municipal, donde se exhiben acuarelas que representan diferentes eventos históricos del municipio. 

Además se puede visitar el Monumento al General Mariano Escobedo, en Plaza de los Fundadores, ubicada sobre Avenida Sendero, entre Carretera a Colombia y Manuel L. Barragán frente a Plaza Sendero Escobedo.

Cuenta con múltiples comercios, tanto nacional como internacionalmente, además de modernos centros comerciales entre otros tantos atractivos.

Lista de lugares Turísticos:


Luciano Estrada
1938 - 1940

Margarito Villarreal
1940 - 1942 

Jesús Elizondo Saldaña
1942 - 1944 

Bonifacio Villarreal
1945 

José Ayala Villarreal
1945 - 1948 

Marcelo Villarreal
1948 - 1951

onardo Ramírez V.
1951 - 1954 

Francisco Flores G.
1954 - 1957

Julián Domínguez Valdés
1957 - 1960 

Jesús Ayala López
1960 - 1963 

Leopoldo Cárdenas L.
1963 - 1966 

Leonardo Villarreal L.
1966 - 1969 

Héctor J. Ayala Villarreal
1969 - 1971 

José Morales Cárdenas
1971 - 1973 

Dr. Francisco Ramírez Suárez
1973 - 1974 

Sergio Elizondo Chapa
1974 - 1976 

Alfonso Ayala Villareal
1976 - 1979 

Eulalio Villarreal
1979 - 1982 

Donato Chávez
1982 - 1985 

Leonel Chávez Rangel
1985 - 1988

Eulalio Villarreal
1988 - 1991 
1991 - 1994 

Jesús Martínez Martínez
1994 - 1997 
1997 - 2000 

Leonel Chávez Rangel
2000 - 2003

Fernando Rafael Margáin Santos
2003 - 2006 

Margarita Martínez López
2006 - 2009

Clara Luz Flores Carrales
2009 - 2012

César Gerardo Cavazos Caballero
2012 - 2015

Clara Luz Flores Carrales
2015 - 2018

Clara Luz Flores Carrales
2018 - 2021
La ciudad de General Escobedo tiene Hermanamientos con 0035 ciudades alrededor del mundo



</doc>
<doc id="45520" url="https://es.wikipedia.org/wiki?curid=45520" title="Movimiento del software libre">
Movimiento del software libre

El movimiento del "software" libre es un movimiento social con el objetivo de obtener y garantizar las libertades que permiten a los usuarios de software ejecutarlo, estudiarlo, cambiarlo y redistribuir copias del mismo con o sin cambios. Sobre la base de las tradiciones y filosofías de la cultura hacker y el mundo académico de los años 1970s, Richard Stallman fundó formalmente el movimiento en 1983, con el lanzamiento del Proyecto GNU. Stallman estableció la Fundación del Software Libre en 1985 para apoyar el movimiento.

La meta del movimiento fue dar libertad a los usuarios, reemplazando el "software" con términos de licencia restrictivos, como el software privativo, por software libre.

La mayoría de los miembros del movimiento de "software" libre creen que todo el software debería venir acompañado con las libertades declaradas en la definición de software libre. Muchos sostienen que es prohibir o impedir a las personas que hagan efectivas esas libertades y que estas son necesarias para crear una sociedad decente donde los usuarios puedan ayudarse mutuamente y tomar el control sobre el uso de un ordenador.

El movimiento del "software" libre también cree que todo software necesita documentación libre, pero esto no se posiciona firmemente en otros tipos de trabajos. Algunos defensores del "software" libre apoyan que los trabajos que sirven para un fin práctico también deberían ser libres.

Algunos seguidores del movimiento de "software" libre no creen que el software privativo sea estrictamente inmoral. Sin embargo, razonan que la libertad es valiosa (tanto socialmente como pragmáticamente) como una propiedad del "software per se", independiente de su calidad técnica en sentido estricto. Más aún, podrían usar el término ""software" libre" para distanciarse a sí mismos de afirmaciones tales como que el ""software" de código abierto" es siempre superior técnicamente al "software" privativo. En este sentido, objetan que los defensores del ""software" de código abierto", concentrándose solamente en méritos técnicos, animan a los usuarios a sacrificar su libertad (y los beneficios a largo plazo que se derivan de su uso) a cambio de ventajas a corto plazo que el "software" privativo pueda proporcionar.

Los partidarios del código abierto argumentan en favor de las virtudes pragmáticas del "software" libre más que de cuestiones de moralidad. Su desacuerdo básico con la "Free Software Foundation" es su condena genérica del "software" privativo. Hay muchos programadores que disfrutan apoyando y usando software libre pero se ganan la vida desarrollando "software" privativo, y no consideran sus acciones inmorales. Las definiciones "oficiales" de "software" libre y "software" de código abierto son ligeramente diferentes, siendo la primera considerada más estricta generalmente, mientras que las licencias de "software" de código abierto son generalmente oscuras.

El trabajo central del movimiento del software libre se centró en el desarrollo de software. El movimiento del software libre también rechaza el software propietario, rechazando instalar el software que no les da las libertades del software libre. Las ideas generadas por los asociados de GNU son, a su vez, un intento de promover un "ambiente de cooperación" que comprenda los beneficios de tener una comunidad local y una comunidad global.
Algunos partidarios del movimiento del software libre realizan charlas o conferencias para aumentar la conciencia sobre la libertad del software. Esto se considera importante ya que las personas que reciben software libre, pero que no son conscientes de que es software libre, más tarde aceptarán un reemplazo no libre o agregarán software que no es software libre.

Se ha hecho mucho trabajo de cabildeo contra las patentes de software y la ampliación de las leyes de derechos de autor. Otros grupos de presión se centran directamente en el uso de software libre por parte de agencias gubernamentales y proyectos financiados por el gobierno.

Eric Raymond critica la velocidad con la que el movimiento del software libre está progresando, lo que sugiere que ciertos compromisos temporales deben hacerse en función de mejoras a largo plazo. Raymond sostiene que esto podría aumentar la conciencia sobre el software libre y así aumentar la influencia del movimiento en las normas y legislaciones pertinentes.

Richard Stallman, por otra parte, ve a los principios actuales del movimiento como una causa mayor de preocupación.

Stallman sostiene aquí que se tiende a confundir la idea de "libre": no hay nada malo en solicitar el pago de los programadores por su trabajo en un proyecto. Restringir y controlar las decisiones del usuario sobre el uso, es lo que vulnera la libertad. Stallman defiende que, en algunos casos, el incentivo monetario no es necesario para la motivación a programar, ya que el placer de expresar la creatividad es una recompensa en sí misma.

El movimiento de software libre defiende el esquema de licencias copyleft (a menudo llamadas licencias víricas o virales). En su forma más fuerte, el copyleft establece que cualquier obra derivada de software con licencia copyleft también debe llevar una licencia copyleft, por lo que la licencia se extiende desde un trabajo a otro como una suerte de virus. Los críticos del copyleft discrepan en la idea de que esta cláusula esté en línea con el énfasis del movimiento del software libre en las "libertades", especialmente cuando alternativas como las licencias MIT, BSD y Apache son más permisivas. Los defensores argumentan sobre los beneficios de que el trabajo bajo copyleft normalmente no pueda ser incorporado en proyectos de software no-libres. Hacen hincapié en que las licencias copyleft no sirven para todos los usos y que, en cualquier caso, los desarrolladores pueden simplemente optar por no utilizar el software con estas licencias.

La proliferación de licencias FOSS es una preocupación en el dominio de software libre debido a consideraciones de compatibilidad entre licencias, que limita y complica la reutilización del código fuente entre proyectos de software libre. La OSI y la FSF mantienen listas propias con decenas de licencias existentes y aceptables de software libre. Existe un consenso en cuanto a que la creación de nuevas licencias debe ser minimizada a toda costa y estas deberían ser compatibles con las principales licencias existentes. Una controversia se generó en torno a la actualización de la GPLv2 a GPLv3 en 2007, ya que la licencia actualizada no resulta compatible con la versión anterior. Varios proyectos, principalmente entre los partidarios del código abierto como el "kernel" de Linux decidieron no utilizar la GPLv3, mientras que los proyectos de GNU sí la adoptaron.




</doc>
<doc id="45533" url="https://es.wikipedia.org/wiki?curid=45533" title="Ajmat Kadýrov">
Ajmat Kadýrov

Ajmát Abduljamídovich Kadýrov (, ; 23 de agosto de 1951-9 de mayo de 2004) fue presidente de la República de Chechenia (elegido en 5 de octubre de 2003). Fue asesinado el 9 de mayo de 2004 en el Estadio de Grozny por una mina terrestre colocada bajo un tablado de personalidades importantes durante un desfile conmemorativo de la Segunda Guerra Mundial.

Nació en Karagandá, en la RSS de Kazajistán. En 1957 su familia regresó a la aldea de Chentoroi, en la región de Shalinski, en la RASS de Checheno-Ingusetia. Después de la disolución de la URSS se convirtió en líder disidente de Chechenia, pero abandonó la causa separatista y se volvió leal a Moscú al alcanzar la presidencia de la República.


Tuvo cuatro hijos y trece nietos. Después de su muerte, el hasta entonces primer ministro Serguéi Abrámov asumió la presidencia interina. Fue sustituido por Alú Aljánov.



</doc>
<doc id="45534" url="https://es.wikipedia.org/wiki?curid=45534" title="Imperio mexicano">
Imperio mexicano

El término Imperio mexicano puede referirse:


</doc>
<doc id="45535" url="https://es.wikipedia.org/wiki?curid=45535" title="Microscopio de sonda de barrido">
Microscopio de sonda de barrido

Un microscopio de sonda de barrido (también llamado SPM por sus siglas en inglés "Scanning Probe Microscopy") es aquel que tiene el transmisor en la parte exequimal del lente (Objetivo 4x). Este microscopio electrónico utiliza una sonda que recorre la superficie del objeto a estudiar. La rama de microscopios SPM se fundó con la invención del microscopio de efecto túnel en 1981.

Su uso en investigaciones científicas es el de regular la imagen mediante un barrido de electrones haciendo que la imagen aumente (10.000.000 nm).

 Hay gran variedad de microscopios de sonda de barrido, siendo los principales:



De estas técnicas, AFM y STM son los más comúnmente utilizados para las mediciones de rugosidad.



</doc>
<doc id="45539" url="https://es.wikipedia.org/wiki?curid=45539" title="Magnitud aparente">
Magnitud aparente

La magnitud aparente (m) de un objeto celeste es un número que indica la medida de su brillo tal y como es visto por un observador desde la Tierra y la cantidad de luz (energía) que se recibe del objeto. Mientras que la cantidad de luz recibida depende realmente del ancho de la atmósfera, las magnitudes aparentes se normalizan a un valor que tendrían fuera de la atmósfera. Cuanto menor sea el número, más brillante aparece una estrella. El Sol, con magnitud aparente de −27, es el objeto más brillante en el cielo. Además, la escala de magnitudes es logarítmica: una diferencia de una magnitud corresponde a un cambio en el brillo de un factor alrededor de 2,512.

Generalmente, se utiliza el espectro visible (vmag) como base para la magnitud aparente. Sin embargo, se utilizan también otros espectros (por ejemplo, la banda J del infrarrojo cercano). En el espectro visible, Sirio es la estrella más brillante después del Sol. En la banda-J del infrarrojo cercano, Betelgeuse es la más brillante. La magnitud aparente de las estrellas se mide con un bolómetro.

La magnitud aparente puede medirse para determinadas bandas del espectro luminoso. En el caso del espectro visible, se denomina magnitud visual (formula_1) y puede ser estimada por el ojo humano.

Actualmente se utilizan los fotómetros, que permiten medir magnitudes con mucha precisión. Este es capaz de catalogar en orden de magnitud aparente y distinguir cuándo dos estrellas tienen la misma magnitud aparente, o una estrella y una fuente artificial.

La escala con la que se mide la magnitud tiene su origen en la práctica helenística de dividir las estrellas visibles con ojo desnudo en seis magnitudes. Las estrellas más visibles a simple vista fueron pensadas para formar parte de la primera magnitud (m = +1), mientras que las más débiles eran consideradas como sexta magnitud (m = +6), el límite del ojo humano (sin ayuda de un telescopio). Este método, algo primitivo, para indicar la visibilidad de las estrellas a simple vista fue divulgado por Ptolomeo en su "Almagesto", y se cree que pudo haber sido originado por Hiparco de Nicea. Este sistema original no medía la magnitud del Sol. Debido al hecho de que la respuesta del ojo humano a la luz es logarítmica, la escala que resulta es también logarítmica.

En 1856 Pogson formalizó el sistema definiendo que una típica estrella de primera magnitud es aquella 100 veces más visible que una típica estrella de magnitud sexta; así, una estrella de primera magnitud es aproximadamente 2,512 veces más visible que una de segunda magnitud. La raíz quinta de 100, un número irracional (2,512), se conoce como cociente de Pogson. La escala de Pogson se fijó originalmente asignando a la estrella Polaris la magnitud 2. Pero dado que los astrónomos han descubierto que la estrella Polar es levemente variable, ahora se utiliza la estrella Vega como referencia.

El sistema moderno no se limita a seis magnitudes. Los objetos más visibles tienen magnitudes negativas. Por ejemplo Sirius, la estrella más visible, tiene una magnitud aparente de -1,44 a -1,46. La escala moderna incluye a la Luna y al Sol; la Luna tiene una magnitud aparente de -12,6 y el Sol tiene una magnitud aparente de -26,7. Los telescopios Hubble y Keck han localizado estrellas con magnitudes de +30.

La magnitud aparente en la banda formula_2 se puede definir como:
donde formula_4 es el flujo luminoso observado en la banda formula_2,
y formula_6 es una constante que depende de las unidades de flujo y de la banda.
Y también:
Si se sustituye sucesivamente los valores de las intensidades intermedias:
y como se ha apuntado anteriormente:
luego
Tomando logaritmos en ambos términos:
pero
luego:
y por tanto
que sustituido en
nos dice que la relación entre intensidades luminosas de dos estrellas que difieren en una magnitud, es igual a formula_29 y en general, para una diferencia de magnitudes
se tiene:
Siendo
Entonces queda:
Como es de suponer, la relación de intensidades se mantiene constante sean cuales sean las unidades en que se mida. Esto permite elegir a conveniencia. No obstante, y por comodidad de cálculo se va a mejorar la presentación de la ecuación tomando logaritmos en ambos miembros:
pero
Y esta nueva expresión constituye la ley de Pogson que dice "la diferencia de magnitud entre dos estrellas es proporcional a la diferencia de los logaritmos de sus brillos aparentes".
Se compara ahora una estrella de 6º magnitud con otra cualquiera de magnitud formula_38 y brillo formula_39
Luego dada la magnitud de una estrella se puede conocer su brillo formula_39 mediante esta última expresión, o formula_38:
Estas dos fórmulas sirven para conocer la magnitud conjunta de dos o más estrellas.
Si además de conocer la magnitud de una estrella, se conoce la distancia que nos separa de ella, se está en condiciones de averiguar la magnitud y brillo que presentaría a otra distancia. Esto es posible gracias a que el brillo es inversamente proporcional al cuadrado de la distancia, o sea:
Todo esto es utilizado en astronomía para comparar estrellas entre sí, según su luminosidad intrínseca. Solo se ha tenido en cuenta el brillo estelar a la observación directa desde la Tierra. Puede ocurrir, y así es, que una estrella aparente ser muy brillante debido a su proximidad, y otra aparece como muy débil por su gran lejanía, pudiendo ser mucho más luminosa que la primera. Así pues, una comparación en estos términos sería totalmente errónea, y para solucionarlo los astrónomos han introducido el concepto de magnitud absoluta.
Si se conoce la magnitud absoluta, que llamamos formula_46, y su distancia formula_47, podemos deducir que magnitud aparente formula_38, tendrá esa estrella.
Se recuerdan las expresiones
y
si se sustituye en la primera relación de los brillos por la del cuadrado de las distancias 
Con el subíndice 2 se indica a una estrella situada a 10 parsec cuya magnitud formula_52 será la absoluta (formula_46), como se ha visto anteriormente:
Tomando logaritmos,
multiplicando ambos miembros por 2,5 resulta:
y por tanto:
Lógicamente si se conoce la magnitud aparente, la magnitud absoluta resulta ser:
Estando la distancia formula_47, expresada en parsec. Es claro que si se conocen las magnitudes aparentes y absolutas, se puede determinar la distancia formula_47

"Calcular la magnitud conjunta del sistema 47 Tauri, cuyas dos componentes son de formula_63 y formula_64"

Se calculan sus brillos por [3] y se suman:
formula_9, de donde formula_10
luego
formula_69, y por [4] se halla la magnitud conjunta de las dos estrellas:
En un catálogo, se encuentra con magnitud 4,84.

"El Sol dista de nosotros 149 597 870 km, y tiene una magnitud de -26,75. Calculemos la que nos presentaría a 100 veces esa distancia".

Por la [3] hallamos su brillo que es formula_71 y por [5]
luego formula_73, es decir 10 000 veces menor, y por [4]
formula_74, diez magnitudes menor.
Por [1] podemos averiguar las veces que nuestro Sol al desplazarse 100 veces la distancia que nos separa de él, es menor en brillo:
Y ya que hemos obtenido la magnitud conjunta de la estrella 47 Tauri, encontrándola igual a 4,8, calculemos su magnitud absoluta, sabiendo que su paralaje formula_76"formula_77.
Como en [7] nos pide el formula_78 y aquí nos dan la paralaje, vamos hacer una pequeña transformación en [7] para utilizar el dato suministrado. Como formula_79, luego formula_80, que puesto en [7]
o sea,
que es otra forma de obtener la magnitud absoluta, cuando conocemos la paralaje.
En el catálogo figura con magnitud absoluta de +0,3 y por último para comprobar, por [8]
luego



</doc>
<doc id="45540" url="https://es.wikipedia.org/wiki?curid=45540" title="Fotofosforilación">
Fotofosforilación

La fotofosforilación es un proceso de síntesis de ATP a partir de ADP y fosfato llevado a cabo por las ATP-sintasas de la membrana del tilacoide, en los cloroplastos de las células vegetales. Es un proceso de la fase fotoquímica de la fotosíntesis en el que se utiliza la energía liberada en el transporte de electrones para bombear protones desde el estroma al interior del tilacoide con el fin de crear un gradiente electroquímico el cual, al disiparse por la salida de protones del tilacoide al estroma a través de las ATP-sintasas, acopla esta energía protón-motriz a la fosforilación del ADP para formar ATP. La energía necesaria la proporciona la luz que es captada por los .

Existen dos tipos:


Un fotosistema es el conjunto mínimo de los compuestos necesarios para llevar a cabo el proceso de fotosíntesis. Es un centro de reacción que se sitúa, junto con otros muchos, en las membranas de los tilacoides. Permite recibir la energía lumínica y transmitirla a lo largo de una cadena de reacciones que la transforman en energía química.


</doc>
<doc id="45542" url="https://es.wikipedia.org/wiki?curid=45542" title="Equilibrio hidrostático">
Equilibrio hidrostático

El equilibrio hidrostático se produce en un fluido en el que las fuerzas del gradiente vertical de presión y la gravedad están en equilibrio. En un fluido hidrostático no hay aceleración vertical neta. 

Matemáticamente, el equilibrio hidrostático se expresa comúnmente de la siguiente manera:
donde formula_2 es la presión del fluido, formula_3 la coordenada vertical, formula_4 la densidad del fluido y formula_5 la aceleración de la gravedad.

El equilibrio hidrostático explica por qué la atmósfera terrestre no se colapsa sobre una fina capa en la superficie por efecto de la gravedad o cómo los neumáticos de un coche o bicicleta pueden soportar el peso del vehículo gracias a la presión del gas en el interior.

En el caso de una estrella, existe un equilibrio entre la fuerza de gravedad que actúa atrayendo el gas estelar hacia el centro y comprimiéndolo, y la variación radial de presión que actúa en sentido contrario intentando expandir el sistema. En condiciones normales la estrella está en equilibrio y adopta una forma esférica estable. En una estrella la presión tiene dos partes, una hidrostática y otra producida por la presión de radiación. La presión que sostiene a las estrellas es fruto de la liberación de energía en el centro de estas por medio de reacciones de fusión nuclear.



</doc>
<doc id="45544" url="https://es.wikipedia.org/wiki?curid=45544" title="Adenosina">
Adenosina

La adenosina es un nucleósido formado de la unión de la adenina con un anillo de ribosa (también conocido como ribofuranosa) a través de un enlace glucosídico β-N. Es una purina endógena sintetizada de la degradación de aminoácidos como metionina, treonina, valina e isoleucina así como de AMP.

La adenosina tiene una importante función en procesos bioquímicos, tales como la transferencia de energía, en la forma de ATP y ADP, así como trasductor de señal en la forma de adenosín monofosfato cíclico o AMPc.

La adenosina desempeña un importante papel como neuromodulador en el sistema nervioso central, a través de la interacción con sus receptores Alfa 1, Alfa2A, A2B y A3, ampliamente distribuidos en los tejidos del cuerpo produciendo vasodilatación, broncoconstricción, inmunosupresión, etc.

También tiene efectos sedantes e inhibitorios sobre la actividad neuronal. La cafeína disminuye el sueño precisamente por el bloqueo del receptor de adenosina. La adenosina aumenta el sueño NMOR (sobre todo en el estadio IV) y también el MOR. Cuando se aplica un inhibidor de la desaminasa de adenosina (desoxicoformicina) se incrementa el NMOR. Se observó el mismo efecto con el precursor de la adenosina, el S-Adenosil L-homocisteína.

Aún no se identifica el papel de la adenosina en la vigilia, pues los receptores de adenosina A1 tras la privación de NMOR estaban elevados, sin embargo los niveles de adenosina a las 48 horas de abstinencia no estaban altos.

Como fármaco, se utiliza para revertir la taquicardia supraventricular paroxística al bloquear el nódulo auriculoventricular. Administrada por vía endovenosa deprime la actividad del nodo sinusal y se utiliza para la conversión rápida a ritmo sinusal de las arritmias supraventriculares de reentrada.
La adenosina actúa como un neuroprotector al inhibir la transmisión excitatoria de receptores A1. Este nucleósido púrico endógeno cuando estimula sus receptores A1 cardíacos activa una corriente de salida de K sensible a acetilcolina en la aurícula, nódulo sinusal, nódulo auriculoventricular, lo que da como resultado acortamiento de la duración del potencial de acción, hiperpolarización y torna lenta la automaticidad normal.

También inhibe los efectos electrofisiológicos del adenosín monofosfato cíclico (AMPc) intracelular aumentado, que ocurre con la activación simpática. Para ello inhibe la entrada de Ca estimulada por el AMPc, lo que también deprime la frecuencia de las células del nodo SA y la velocidad de conducción a través del nodo AV, a la vez que prolonga el período refractario de este.

Administrada por vía IV produce una rápida elevación de la presión arterial seguida de hipotensión y taquicardia.

La adenosina produce una respuesta farmacológica de corta duración porque es rápidamente metabolizada por degradación enzimática en la sangre y en tejidos periféricos (la combinación de acciones de una adenosín desaminasa y una kinasa fosforilante). Es rápidamente captada en eritrocitos y células endoteliales, siendo su semivida de menos de 10s. Por este motivo, se administra por vía IV en forma de bolo. Las enfermedades renales y hepáticas no afectan el metabolismo de la adenosina.

Conversión rápida de las taquicardias atrioventriculares al ritmo sinusal, incluyendo las que están asociadas con una vía accesoria (síndrome de Wolff-Parkinson-White).

Ayuda al diagnóstico de las taquicardias con complejos amplios o estrechos, debido a la disminución transitoria de la velocidad de conducción auriculo-ventricular que facilita el análisis de la actividad auricular en el curso de los registros electrocardiográficos.

Debe ser administrado bajo monitorización médica, en medio hospitalario, bajo vigilancia electrocardiográfica y por médicos que dispongan de medios de reanimación cardiorrespiratoria.

La administración debe hacerse como bolo intravenoso rápido, de preferencia mediante un catéter venosos central, ya que la administración lenta da como resultado eliminación del fármaco antes que este llegue al corazón.

Dosis inicial: 6mg administrados bajo la forma de un bolo intravenoso (inyección en 2s).

Segunda dosis: en el caso de que la primera dosis no detenga la taquicardia supraventricular en 3 a 5min, se administrarán entonces 12mg en forma de bolo intravenoso.

Una vez se instilen los 6mg de adenosina en la primera dosis o los 12mg en la segunda dosis,se recomienda que se irrigue la línea con normal salina (0.9% NSS) para que el medicamento no tarde en alcanzar la circulación coronaria.

Las dosis recomendadas pueden ser aumentadas para pacientes que estén tomando ciertos medicamentos que previenen la acción de la adenosina (véase Interacciones), o bien disminuidas en pacientes que potencien la acción de la adenosina, como el Diazepam (Valium). Las dosis recomendadas se reducen a la mitad en pacientes con insuficiencia cardíaca, infarto agudo de miocardio, shock, hipoxia, insuficiencia renal o hepática y en pacientes ancianos

Las teofilina una metilxantina bloquean el receptor responsable de los efectos electrofisiológicos y hemodinámicos de la adenosina.
El dipiridamol bloquea la recaptación de adenosina y potencia sus efectos.

Los efectos de este fármaco están prolongados en pacientes a tratamiento con carbamazepina y en el caso de trasplante cardíaco, en los cuales hay que ajustar la dosis o usar terapia alternativa.

Los efectos farmacológicos de la adenosina pueden ser minimizados en individuos que estén tomando grandes cantidades de estimulantes tipo Metilxantina; por ejemplo, la ya mencionada teofilina (presente en el té), la teobromina (en el chocolate) y la cafeína (en el café). Los efectos estimuladores del café son principalmente (aunque no enteramente) acreditados a su capacidad de inhibir la adenosina al competir por los mismos receptores, por razón del componente de purina en la estructura de la cafeína, bloqueando eficazmente los receptores de la adenosina en el SNC. Esta reducción de la actividad de la adenosina conlleva a una incrementada actividad de neurotransmisores como la dopamina y el glutamato.

Los efectos adversos de la adenosina son de corta duración y transitorios.
Los más frecuentes son rubor, disnea, náuseas, dolor torácico, bradicardia o asístole y bloqueo AV completo.

La asístole transitoria es frecuente pero por lo general dura menos de 5s y en realidad constituye el objetivo terapéutico. Esto se puede describir por el paciente como una sensación de plenitud torácica y disnea. En pacientes asmáticos puede producir disnea o broncoespasmo que persisten durante 30min.

Contraindicada en:

Con precaución en:



</doc>
<doc id="45548" url="https://es.wikipedia.org/wiki?curid=45548" title="Reacción">
Reacción

Reacción puede referirse a:


En términos químicos es un efecto secundario de la creación de una sustancia, mezcla o compuesto.






</doc>
<doc id="45549" url="https://es.wikipedia.org/wiki?curid=45549" title="Plazas de soberanía (España)">
Plazas de soberanía (España)

Plazas de soberanía es el término histórico con el que se denominan desde el a los territorios españoles situados en el norte de África, en contraposición a las áreas que constituían el protectorado español de Marruecos. En la actualidad, esta nomenclatura sigue utilizándose para la identificación de las islas y peñones frente a la costa norte de Marruecos, pero no para referirse a Ceuta y Melilla.

Históricamente, las plazas de soberanía eran cinco (supervivientes de las antiguas plazas fuertes de África), subdivididas habitualmente entre las denominadas "plazas mayores" y las "plazas menores". Las actuales Ceuta y Melilla eran las mayores y las islas Chafarinas, las islas Alhucemas y el peñón de Vélez de la Gomera eran las denominadas menores. 

Aparte de las anteriores, la isla de Perejil, un islote deshabitado situado cerca de la península tingitana, a pocos metros del litoral marroquí, fue el objeto de una confrontación entre España y Marruecos en 2002, y ha sido frecuentemente calificado como una plaza de soberanía. El estatus no se sabe con claridad, ya que formalmente no pertenece a ninguno de los estados y actualmente es "de facto" una "terra nullius", debido en parte al acuerdo suscitado entre Marruecos y España, mediante el cual se llegó a la resolución de que en la isla no habría ni presencia militar ni ningún símbolo de soberanía. De forma similar, la isla de Alborán también ha sido erróneamente calificada como plaza de soberanía, ya que administrativamente forma parte del término municipal de la ciudad andaluza de Almería.

Tradicionalmente, las plazas de soberanía se han dividido en:



Los primeros borradores de los estatutos de autonomía de Ceuta y Melilla, datados en 1986, repartían todas las posesiones restantes en el norte de África entre las dos ciudades, resultando Vélez de la Gomera para Ceuta y las islas Chafarinas y Alhucemas para Melilla. En la redacción final de estos documentos se omitieron dichas incorporaciones. Cabe destacar además, que ya que forman parte del territorio español, también son parte de la Unión Europea.

Estas posesiones fueron atacadas por los rifeños en la guerra del Rif, y al inicio de la sublevación del 17 y 18 de julio de 1936 quedaron desde el primer momento en manos del bando sublevado. Cuando en 1956 España se retiró de su protectorado y reconoció la independencia de Marruecos no se vieron afectadas en su estatus, puesto que nunca formaron parte de dicha entidad territorial.

Los territorios norteafricanos de España son reclamados por movimientos irredentistas marroquíes como parte del Gran Marruecos, pero España nunca ha negociado su soberanía puesto que son parte integrante del territorio español.

Las plazas de soberanía se sitúan en el norte de África, ribereñas del mar Mediterráneo. Solo el peñón de la Vélez de la Gomera tiene frontera terrestre con Marruecos, aunque originalmente era una isla, pero debido a un terremoto que tuvo lugar en 1930, el islote resultó unido de forma permanente a tierra firme.

La ubicación de las plazas es la siguiente:




</doc>
<doc id="45552" url="https://es.wikipedia.org/wiki?curid=45552" title="Nueva Suecia">
Nueva Suecia

Nueva Suecia () fue una colonia sueca que se desarrolló en la costa oriental de Norteamérica durante el siglo XVII. Estaba situada en los alrededores del río Delaware y en la zona interior de la bahía del mismo nombre. Incluía partes de los actuales estados de Delaware, Nueva Jersey y Pensilvania. Fue absorbida por Nueva Holanda a finales de los años 1650. 

Tras independizarse de Dinamarca en 1523 con el rey Gustavo I, Suecia se expandió por el báltico y llegó a su apogeo bajo el monarca guerrero Gustavo II, que logró brillantes victorias contra Alemania en la Guerra de los Treinta Años. En los años 1630, ansioso de poner a su país a la par de otras potencias europeas, este prestó oídos a la idea de colonizar la costa oriental de Norteamérica. Dicho proyecto sobrevivió a su muerte (acaecida en 1632) y en 1638 la Compañía de la Nueva Suecia comenzó a efectuar viajes hacia la colonia. 

El principal centro urbano de Nueva Suecia era Fuerte Cristina, a orillas del río Delaware, el cual fue fundado el 29 de marzo de 1638 por el explorador Peter Minuit en honor de Cristina de Suecia. Más adelante, este pueblo se convertiría en la ciudad de Wilmington. En sus orígenes, estaba compuesto por unos 600 colonos suecos y finlandeses, que establecieron una próspera colonia bajo el gobernador Johan Björnsson Printz, quien fomentó las buenas relaciones con sus vecinos europeos y con los indios. Otras zonas en las que se establecieron colonos suecos fueron el sudeste de Pensilvania, donde fundaron su capital cerca de Filadelfia, y el sudoeste de Nueva Jersey. La economía de Nueva Suecia estaba basada en la agricultura y el comercio de pieles. 

El control sueco sobre la región solo duró 17 años. En septiembre de 1655, bajo la dirección del gobernador Johan Rising, Nueva Suecia fue atacada por la vecina colonia neerlandesa de Nuevos Países Bajos, y fue anexada a esa colonia neerlandesa. Finalmente, se convirtió en parte del Imperio británico cuando fue invadida por una flota inglesa en 1664.

Pese a la corta duración de Nueva Suecia, esta un legado duradero en la historia de Estados Unidos. La casa de troncos fue inventada en el norte de Escandinavia y fue llevada por los colonos suecos a esa zona de Norteamérica. Por la facilidad de su construcción y por el calor que conservaba durante los duros inviernos, pronto se convirtió en una alternativa a las casa de madera inglesas construidas por los colonos en Nueva Inglaterra y fue gradualmente adoptada en las zonas de colonización. 

Varias localidades a orillas del río Delaware fueron fundadas por suecos. Estos fueron los primeros pobladores de las actuales Wilmington (en Delaware), Norristown, Marcus Hook, Chester, Eddystone, Darby y Filadelfia (en Pensilvania), así como Salem, Nueva Estocolmo o Swedesboro (en Nueva Jersey).



</doc>
<doc id="45553" url="https://es.wikipedia.org/wiki?curid=45553" title="Materia oscura">
Materia oscura

En astrofísica y cosmología física, se denomina materia oscura a un tipo de materia que corresponde aproximadamente al 27% de la materia del universo, y que no es energía oscura, materia bariónica (materia ordinaria) ni neutrinos. Su nombre hace referencia a que no emite ningún tipo de radiación electromagnética (como la luz). De hecho, no interactúa en ninguna forma con la radiación electromagnética, siendo completamente transparente en todo el espectro electromagnético. Su existencia se puede inferir a partir de sus efectos gravitacionales en la materia, tales como las estrellas o las galaxias, así como en las anisotropías del fondo cósmico de microondas presente en el universo. 

La materia oscura fue propuesta por Fritz Zwicky en 1933 ante la evidencia de una "masa no visible" que influía en las velocidades orbitales de los cúmulos en las galaxias. Posteriormente, otras observaciones han indicado la presencia de materia oscura en el universo: estas observaciones incluyen la citada velocidad de rotación de las galaxias, los lentes gravitacionales de los objetos por los cúmulos de galaxias, tales como el Cúmulo Bala (1E 0657-56) y la distribución de la temperatura del gas caliente en galaxias, cúmulos de galaxias y nebulosas.

La materia oscura también desempeña un papel central en la formación de estructuras y la evolución de galaxias y tiene efectos medibles en la anisotropía de la radiación de fondo cósmico de microondas. Todas estas pruebas sugieren que las galaxias, los cúmulos de galaxias y todo el Universo contiene mucha más materia que la que interactúa con la radiación electromagnética: lo restante es llamado "el componente de materia oscura".

La composición de la materia oscura se desconoce. Algunos de los candidatos a materia oscura pueden ser neutrinos ordinarios y pesados, partículas elementales recientemente postuladas como los WIMPs y los axiones, cuerpos astronómicos como las estrellas enanas, los planetas (colectivamente llamados MACHO) y las nubes de gases no luminosos. Las pruebas actuales favorecen los modelos en que el componente primario de la materia oscura son las nuevas partículas elementales llamadas colectivamente materia oscura no bariónica.

El componente de materia oscura tiene bastante más masa que el componente "visible" del Universo. Actualmente, se estima que la densidad de bariones ordinarios y la radiación en el Universo equivalen aproximadamente a un átomo de hidrógeno por metro cúbico de espacio. Aproximadamente, solo el 5% de la densidad de energía total en el Universo (inferido de los efectos gravitacionales) se puede observar directamente. Se estima que en torno al 23% está compuesto de materia oscura. El 72% restante consistiría en energía oscura, un componente incluso más extraño, distribuido difusamente en el espacio. Alguna materia bariónica difícil de detectar contribuye a la materia oscura, aunque algunos autores defienden que constituye solo una pequeña porción. Aun así, hay que tener en cuenta que del 5% de materia bariónica estimada (la mitad de ella todavía no detectada) se puede considerar materia oscura bariónica: todas las estrellas, galaxias y gas observables reúnen menos de la mitad de los bariones que se supone debería haber. Se cree que toda esta materia puede distribuirse en filamentos gaseosos de baja densidad, formando una red por todo el universo, en cuyos nodos se encuentran los diversos cúmulos de galaxias. En mayo de 2008, el telescopio XMM-Newton de la agencia espacial europea encontró pruebas de la existencia de dicha red de filamentos.

La determinación de la naturaleza de esta masa no visible es una de las cuestiones más importantes de la cosmología moderna y la física de partículas. Las denominaciones "materia oscura" y "energía oscura" expresan principalmente nuestro desconocimiento, casi como los primeros mapas etiquetados como "Terra incógnita".

La primera persona en proporcionar pruebas y deducir la existencia del fenómeno que se ha llamado "materia oscura" fue el astrofísico suizo Fritz Zwicky, del Instituto Tecnológico de California (Caltech), en 1933.

Aplicó el teorema de virial al cúmulo de galaxias Coma y obtuvo pruebas de masa no visible. Zwicky estimó la masa total del cúmulo basándose en los movimientos de las galaxias cercanas a su borde. Cuando comparó esta masa estimada con la estimación del número de galaxias y con el brillo total del cúmulo, encontró que había unas 400 veces más masa de la esperada. La gravedad de las galaxias visibles en el cúmulo era muy poca para tal velocidad orbital, por lo que se necesita mucha más. Esto se conoce como el "problema de la masa desaparecida". Basándose en estas conclusiones, Zwicky dedujo que tendría que haber alguna forma de "materia no visible" que proporcionaría suficiente masa y gravedad constituyendo todo el cúmulo.

Muchas de las evidencias de la existencia de materia oscura provienen del estudio de los movimientos de las galaxias. Muchas de estas parecen ser bastante uniformes, con lo que el teorema de virial de la energía cinética total debería ser la mitad del total de la energía gravitacional de las galaxias. Sin embargo, experimentalmente se ha hallado que la energía cinética total es mucho mayor: en particular, asumiendo que la masa gravitacional se debe solo a la materia visible de la galaxia, las estrellas alejadas del centro de las galaxias tienen velocidades mucho mayores que las predichas por el teorema de virial. La curva de rotación galáctica que muestra la velocidad de rotación frente a la distancia del centro de la galaxia, no se puede explicar solo mediante la materia visible. La explicación más sencilla es suponer que la materia visible conforma solo una pequeña parte del cúmulo. Las galaxias muestran indicios de estar compuestas principalmente de un halo de materia oscura concentrado en su centro, con simetría casi esférica, con la materia visible concentrada en un disco central. Las galaxias de brillo débil superficial son importantes fuentes de información para el estudio de la materia oscura, ya que tienen una baja proporción de materia visible respecto de la materia oscura, y tienen varias estrellas brillantes en el centro que facilita la observación de la curva de rotación de estrellas periféricas.

De acuerdo con los resultados publicados en agosto de 2006, la materia oscura se ha detectado por separado de la materia ordinaria a través de medidas del Cúmulo Bala, realmente dos cúmulos de galaxias cercanos que colisionaron hace unos 150 millones de años. Los investigadores analizaron los efectos de las lentes gravitacionales para determinar la masa total de la distribución ambas y la compararon con los mapas de rayos X de gases calientes, que se pensaba que constituían la mayor parte de la materia ordinaria en los cúmulos. Los gases calientes interactuaron durante la colisión y permanecieron cerca del centro. Las galaxias individuales y la materia oscura no interactuaron y están más alejadas del centro.

Casi 40 años después de las observaciones iniciales de Zwicky, ninguna otra observación las había corroborado, indicando que la relación masa-luminosidad fuera distinta de la unidad (una alta relación masa-luminosidad indica la presencia de la materia oscura). Pero a finales de los años 1960 y 1970, Vera Rubin, una astrónoma del Departamento de Magnetismo Terrestre del "Carnegie Institution of Washington" presentó los hallazgos basados en un nuevo espectrógrafo muy sensible que podía medir la curva de velocidad de galaxias espirales con un grado de precisión mayor que cualquier otro anterior. En un encuentro en 1975 de la American Astronomical Society, junto con su compañero de personal Kent Ford, Rubin anunció el asombroso descubrimiento de que muchas estrellas en distintas órbitas de galaxias espirales giraban a casi la misma velocidad angular, lo que implicaba que sus densidades eran muy uniformes más allá de la localización de muchas de las estrellas (el bulbo galáctico). Este resultado sugiere que incluso la gravedad newtoniana no se aplica universalmente o que, conservativamente, más del 50% de la masa de las galaxias estaba contenida en el relativamente oscuro halo galáctico. Este descubrimiento inicialmente despertó escepticismo, pero Rubin insistió en que las observaciones eran correctas. Posteriormente, otros astrónomos empezaron a corroborar su trabajo y se logró determinar muy bien el hecho de que muchas galaxias estuvieran dominadas por "materia oscura". Las excepciones parecían ser las galaxias con relaciones masa-luz cercanas a las de las estrellas. Como consecuencia, numerosas observaciones han indicado la presencia de materia oscura en varias partes del cosmos. Junto con los hallazgos de Rubin para las galaxias espirales y el trabajo de Zwicky sobre los cúmulos de galaxias, durante décadas se han recopilado más evidencias relacionadas con la materia oscura, hasta el punto de que hoy muchos astrofísicos aceptan su existencia. Como un concepto unificador, la materia oscura es una de las características dominantes consideradas en el análisis de estructuras a escala galáctica y mayores.

El trabajo pionero de Rubin ha resistido la prueba del tiempo. Las medidas de las curvas de velocidad en galaxias espirales se continuaron pronto con mediciones de dispersiones de velocidad en galaxias elípticas. Aunque algunas veces resultan menores relaciones masa-luminosidad, las medidas de elípticas siguen indicando un relativamente alto contenido en materia oscura. Asimismo, las medidas de los medios interestelares difusos encontrados en el borde de las galaxias indican no solo las distribuciones de materia oscura que se extienden más allá del límite visible de las galaxias, sino también de que las galaxias son virializadas por encima de diez veces su radio visible. Esto supuso elevar la proporción de la materia oscura respecto a la suma total de masa de gravitación, desde el 50% medido por Rubin hasta la actualmente estimada de casi el 95%.

Hay lugares donde la materia oscura parece ser un pequeño componente o estar totalmente ausente. Los cúmulos globulares no muestran evidencias de contener materia oscura, aunque sus interacciones orbitales con las galaxias muestran pruebas de materia oscura galáctica. Durante algún tiempo, las mediciones del rango de velocidad de las estrellas parecía indicar la concentración de la materia oscura en el disco galáctico de la Vía Láctea. Sin embargo, ahora parece que la alta concentración de la materia bariónica en el disco de la galaxia (especialmente en el medio interestelar) puede influir en este movimiento. Se cree que los perfiles de las masas de las galaxias parecen muy diferentes de los perfiles de la luz. El modelo típico para las galaxias de materia oscura es una distribución lisa y esférica en halos virializados. Ese tendría que ser el caso para evitar los efectos dinámicos a pequeña escala (estelar). Las investigaciones realizadas en enero de 2006 en la Universidad de Massachusetts, Amherst explicarían la previamente misteriosa curvatura en el disco de la Vía Láctea por la interacción de la Grande y la Pequeña Nube de Magallanes y la predicción de un incremento de 20 veces la masa de la Vía Láctea teniendo en cuenta la materia oscura.

En 2005, los astrónomos de la Universidad de Cardiff anunciaron el descubrimiento de una galaxia compuesta casi enteramente de materia oscura, a 50 millones de años luz del Cúmulo de Virgo, que fue denominada VIRGOHI21. Inusualmente, VIRGOHI21 no parece contener ninguna estrella visible: fue vista con observaciones de radio-frecuencia de hidrógeno. Basada en los perfiles de rotación, los científicos estimaron que este objeto contiene aproximadamente 1.000 veces más materia oscura que hidrógeno y tiene una masa total de un décimo de la Vía Láctea. Por comparación, se cree que la Vía Láctea tiene unas diez veces más materia oscura que ordinaria. Los modelos del Big Bang y de la Estructura a gran escala del Universo sugieren que tales galaxias oscuras deberían ser muy comunes en el Universo, pero no se ha detectado ninguna. Si se confirmase la existencia de estas galaxias oscuras, proporcionaría una gran prueba para la teoría de la formación de las galaxias y plantearía problemas para explicaciones alternativas a la materia oscura.

La materia oscura también afecta a las agrupaciones galácticas. Las medidas de Rayos X del caliente gas intracumular se corresponden estrechamente con las observaciones de Zwicky de las relaciones masa-luminosidad para grandes cúmulos de casi 10 a 1. Muchos de los experimentos del Observatorio de rayos X Chandra utilizan esta técnica para determinar independientemente la masa de los cúmulos.

El cúmulo de galaxias Abell 2029 se compone de miles de galaxias envueltas en una nube de gas caliente y una cantidad de materia oscura equivalente a más de 10 soles. En el centro de este cúmulo hay una enorme galaxia con forma elíptica que se piensa que se formó a partir de la unión de muchas galaxias más pequeñas. Las velocidades orbitales de las galaxias medidas dentro de los cúmulos de galaxias son consistentes con las observaciones de materia oscura.

Una importante herramienta para detectar la materia oscura son las lentes gravitacionales. Estas lentes son un efecto de la relatividad general que predice la dinámica que depende de las masas, siendo un medio completamente independiente de medir la energía oscura. En las lentes fuertes, se ha observado la curvada distorsión de las galaxias de fondo, cuando la luz pasa a través de una lente gravitacional, alrededor de un cúmulo poco distante como el Abell 1689. Midiendo la distorsión geométrica, se puede obtener la masa del cúmulo que causa el fenómeno. En docenas de casos donde se ha medido, las relaciones masa-luminosidad obtenidas se corresponden con las medidas de materia oscura dinámica de los cúmulos.

Durante los últimos diez años se ha desarrollado una técnica —tal vez más convincente— llamada lentes débiles, que mide mediante análisis estadístico las distorsiones de galaxias a una microescala en las grandes distancias debidas a objetos de fondo. Examinando la deformación de las galaxias de fondo adyacentes, los astrofísicos pueden obtener por métodos estadísticos la distribución media de energía oscura y encontrar las relaciones masa-luminosidad que se corresponden con las densidades de materia oscura predichas por otras mediciones de estructuras a gran escala. La correspondencia de las dos técnicas (la de lentes gravitacionales junto con otras medidas de materia oscura), han convencido a casi todos los astrofísicos de que la materia oscura es realmente el mayor componente del Universo.

La materia oscura es crucial para el modelo cosmológico del Big Bang como un componente que se corresponde directamente con las medidas de los parámetros asociados con la métrica FLRW a la relatividad general. En particular, las medidas de las anisotropías del fondo cósmico de microondas se corresponden a una cosmología donde gran parte de la materia interactúa con los fotones de forma más débil que las fuerzas fundamentales conocidas que acoplan las interacciones de la luz con la materia bariónica. Asimismo, se necesita una cantidad significativa de materia fría no-barionica para explicar la estructura a gran escala del universo.

Las observaciones sugieren que la formación de estructuras en el Universo actúa jerárquicamente: las estructuras más pequeñas se unen hasta formar galaxias y después cúmulos de galaxias. Según se unen las estructuras en la evolución del Universo, empiezan a "brillar", ya que la materia bariónica se calienta a través de la contracción gravitacional y los objetos se aproximan al equilibrio hidrostático. La materia barionica ordinaria tendría una temperatura demasiado alta y demasiada presión liberada desde el Big Bang para colapsar y formar estructuras más pequeñas, como estrellas, a través de la inestabilidad de Jeans. La materia oscura actúa como un compactador de estructuras. Este modelo no solo se corresponde con investigaciones estadísticas de la estructura visible en el Universo, sino también y de forma precisa con las predicciones de materia oscura de la radiación de fondo de microondas.

Este modelo "inverso" de formación de estructuras necesita algún tipo de la materia oscura para funcionar. Se han utilizado simulaciones por ordenador de miles de millones de partículas de materia oscura para confirmar que el modelo de materia oscura fría de la formación de estructuras es consistente con las estructuras observadas en el Universo mediante las observaciones de galaxias, como la Sloan Digital Sky Survey, la 2dF Galaxy Redshift Survey y el bosque Lyman-alfa. Estos estudios han sido cruciales para crear el modelo Lambda-CDM que mide los parámetros cosmológicos, incluyendo la parte del Universo formada por bariones y la materia oscura.

Aunque la materia oscura se detectó por lentes gravitacionales en agosto de 2006, muchos aspectos siguen cuestionados. En el experimento DAMA/NaI se afirma haber detectado materia oscura pasando a través de la Tierra, aunque muchos científicos son escépticos al respecto, ya que los resultados negativos de otros experimentos serían (casi) incompatibles con los del DAMA si la materia oscura consistiera en neutralinos.

Los datos de varios tipos de pruebas, como el problema de la rotación de las galaxias, las lentes gravitacionales, la formación de estructuras y la fracción de bariones en cúmulos y la abundancia de cúmulos, combinada con pruebas independientes para la densidad bariónica, indican que el 85-90% de la masa en el Universo no interactúa con la fuerza electromagnética. Esta "materia oscura" se evidencia por su efecto gravitacional. Se han propuesto varias categorías de materia oscura:

Davis y otros escribieron en 1985:
La materia oscura caliente consiste en partículas que viajan con velocidades relativistas. Se conoce un tipo de materia oscura caliente: el neutrino. Los neutrinos tienen una masa muy pequeña, no interactúan a través de fuerzas electromagnéticas o de la fuerza nuclear fuerte y son, por tanto, muy difíciles de detectar. Esto es lo que les hace atractivos como materia oscura. Sin embargo, los límites de los neutrinos indican que los neutrinos ordinarios solo harían una pequeña contribución a la densidad de la materia oscura.

La materia oscura caliente no puede explicar cómo se formaron las galaxias desde el Big Bang. La radiación de fondo de microondas medida por el COBE y el WMAP, es increíblemente homogénea: indica que la materia se ha agrupado en escalas muy pequeñas. Sin embargo, las partículas de movimiento rápido no pueden agruparse en tales pequeñas escalas y, de hecho, suprimen la agrupación de otra materia. La materia oscura caliente, aunque existe en nuestro Universo en forma de neutrinos es, por tanto, la única parte de la historia.
Para explicar la estructura en el Universo, el Modelo de concordancia necesita invocar la materia oscura fría (no-relativista). Las grandes masas, como los agujeros negros del tamaño de galaxias, pueden descartarse con las bases de los datos de las lentes gravitacionales. Las posibilidades involucrando materia bariónica normal incluyen enanas marrones o tal vez pequeños y densos pedazos de elementos pesados conocidos como "Objetos de tipo halo masivos compactos (massive compact halo object)" o "MACHOs". Sin embargo, los estudios de la Nucleosíntesis del Big Bang han convencido a muchos científicos de que la materia bariónica como los MACHOs no pueden ser más que una pequeña fracción de la materia oscura total.

El punto de vista más aceptado es que la materia oscura es principalmente no-bariónica, compuesta de una o más partículas elementales distintas de las normales (electrones, protones, neutrones y los neutrinos conocidos). Las partículas propuestas más comunes son los axiones, neutrinos estériles y WIMPs (partículas masivas de interacción débil, incluyendo neutralinos). Ninguna de estas es parte del modelo estándar de física de partículas, pero pueden aparecer en ampliaciones del modelo estándar. Muchos modelos supersimétricos ocasionan naturalmente los WIMPs en forma de neutralinos. Los pesados, neutrinos estériles, existen en ampliaciones del modelo estándar que explica la pequeña masa de los neutrinos a través del mecanismo del balancín.

Se han llevado a cabo y continúan búsquedas experimentales de estos candidatos a materia oscura. Estos esfuerzos se pueden dividir en dos grandes categorías: detección directa, en los que las partículas de materia oscuras se observan en un detector; y la detección indirecta, que busca los productos de aniquilaciones de materia oscura. Los experimentos de detección de materia oscura han descartado algunos modelos de WIMP y axiones. También hay varios experimentos reclamando pruebas positivas de detección de materia oscura, como el DAMA/NaI y el Egret, pero están lejos de confirmarse y difícilmente reconcilian los resultados negativos de otros experimentos. Actualmente, están en proceso varias búsquedas de materia oscura, como la Cryogenic Dark Matter Search en la Mina de Soudan y el experimento XENON en Gran Sasso. Otros están en desarrollo, como el experimento ArDM.

En la primavera de 2006, los investigadores del Instituto de Astronomía de la Universidad de Cambridge publicaron haber calculado que la energía oscura solo está en cúmulos mayores de 1.000 años luz de radio, implicando una velocidad media para las partículas de materia oscura de 9 km/s, una densidad de 20 amu/cm³ y una temperatura de 10.000 kelvins.

La materia oscura, la energía oscura y la antimateria son tres cosas absolutamente distintas. La antimateria es como la materia común de la que estamos hechos, pero conformada por partículas cuya carga eléctrica es de signo contrario. Por ejemplo, un anti-electrón (también conocido como positrón por razones históricas), es una partícula igual al electrón, con su misma masa y carga pero de signo eléctrico positivo (el electrón tiene carga negativa). Y un anti-protón es una partícula con la misma cantidad de masa y carga de un protón, pero con carga de signo eléctrico negativo. La antimateria se forma con antipartículas: del mismo modo que un átomo de hidrógeno consiste en un electrón orbitando alrededor de un protón, si juntáramos un anti-protón con un anti-electrón podríamos tener un átomo de anti-hidrógeno, lo que se ha logrado en el CERN, por fracciones de segundo.

Estimaciones basadas en los efectos gravitacionales de la cantidad de materia presente en el Universo sugieren, consistentemente, que hay mucha más materia de la que se puede observar directamente. Además, la existencia de materia oscura resolvería varias inconsistencias en la teoría del Big Bang. Se cree que la mayoría de la masa del Universo existe en esta forma. Determinar cuál es la naturaleza de la materia oscura es el llamado "problema de la materia oscura" o "problema de la masa desaparecida" y es uno de los más importantes de la cosmología moderna.

La existencia de la materia oscura puede parecer irrelevante para nuestra vida en la Tierra, pero que exista o no, afecta al destino último del Universo. Se sabe que el Universo está expandiéndose, por el corrimiento al rojo que muestra la luz de los cuerpos celestes distantes. Si no hubiera materia oscura, esta expansión continuaría para siempre. Si la actual hipótesis de la materia oscura es correcta, y dependiendo de su cantidad, la expansión del Universo podría ralentizarse, detenerse o incluso invertirse (lo que produciría el fenómeno conocido como Big Crunch). Sin embargo, su importancia para el destino final del Universo se ha relativizado en los últimos años, frente a la existencia de una constante cosmológica y de una energía oscura. Según las mediciones realizadas en 2003 y 2006 por el satélite WMAP, la expansión del Universo se está acelerando, y continuará debido a la existencia de la energía oscura, aunque sin causar un Big Rip.

Una explicación alternativa a las cuestiones planteadas por la materia oscura es suponer que las inconsistencias observadas son debidas a una incompleta comprensión de la gravedad. Para explicar las observaciones, a grandes distancias, las fuerzas gravitacionales son más fuertes de lo que nos indicarían la mecánica newtoniana. Por ejemplo, esto podría ocurrir si se toma un valor negativo para la constante cosmológica (valor que se estima positivo en función de recientes observaciones) o si se adopta la teoría de la Dinámica newtoniana modificada (MOND), que corrige las Leyes de Newton para aceleraciones pequeñas. Sin embargo, la construcción de una teoría MOND relativista ha sido problemática y no está claro como se puede reconciliar con las medidas de las lentes gravitacionales en la curvatura de la luz alrededor de las galaxias. La principal teoría MOND relativista, propuesta por Jacob Bekenstein en 2004 es llamada TeVeS (Tensor-Vector-Scalar) y resuelve muchos de los problemas de los primeros intentos. Una teoría de gravedad modificada (MOG) propuesta por John Moffat, basada en la Teoría gravitacional no-simétrica (NGT), es también una alternativa a la materia oscura.

Otra teoría discutida es la Expansión cósmica en escala (SEC) de C. Johan Masreliez. Otra aproximación, propuesta por Arrigo Finzi en 1963 y por Robert Sanders en 1984, es reemplazar el potencial gravitacional por la siguiente expresión:

donde "B" y "formula_1" son parámetros ajustables. En cualquier caso, tales aproximaciones tienen dificultades en explicar el diferente comportamiento de las distintas galaxias y clústeres. En cambio, tales discordancias se pueden entender fácilmente tomando diferentes cantidades de materia oscura. Las observaciones sobre la rotación de las galaxias indican que alrededor del 90% de la masa de una galaxia no es visible y solo puede detectarse por sus efectos gravitacionales.

Alexander Mayer propone una hipótesis basada en las inconsistencias observadas en la sincronización del sistema GPS y otras anomalías. En dicha hipótesis, el aumento del corrimiento hacia el rojo observado en galaxias lejanas y el aparente exceso de masa del universo hace necesario que dicha materia oscura no sean más que errores de medida fruto de una incorrecta formulación de la Teoría de la Relatividad General. Según la nueva formulación de Alexander Mayer, el universo no precisa de la existencia ni de energía ni de materia oscura.

El problema principal de estas explicaciones alternativas es que no explican las anisotropías del fondo cósmico de microondas que, por otro lado, sí predicen la existencia de materia oscura no bariónica.

En agosto de 2006, un estudio de colisión de cúmulos de galaxias afirmaba demostrar que, incluso en una hipótesis de gravedad modificada, la mayoría de la masa tiene que ser alguna forma de materia oscura demostrando que cuando la materia regular es "barrida" de un cúmulo, los efectos gravitacionales de la materia oscura (que se pensaba que no interactuaba, aparte de su efecto gravitacional) permanecen. Un estudio afirma que TeVeS puede producir el efecto observado, pero esto continúa necesitando que la mayoría de la masa esté en forma de materia oscura, posiblemente en forma de neutrinos ordinarios. También en la Teoría gravitacional no-simétrica se afirma que cualitativamente encaja con las observaciones, sin necesitar la exótica materia oscura.

En otra clase de teorías se intenta reconciliar la Gravedad con la Mecánica cuántica y se obtienen correcciones a la interacción gravitacional convencional. En teorías escalar-tensoriales, los campos escalares como el campo de Higgs se acopla a la curvatura dada a través del tensor de Riemann o sus trazas. En muchas de tales teorías, el campo escalar es igual al campo de inflación, que es necesario para explicar la inflación cósmica del Universo después del Big Bang, como el factor dominante de la quintaesencia o energía oscura. Utilizando una visión basada en el Grupo de Renormalización, M. Reuter y H. Weyer han demostrado que la constante de Newton y la constante cosmológica pueden ser funciones escalares en el espacio-tiempo si se asocian las escalas de renormalización a los puntos del espacio-tiempo.

En la teoría de la relatividad de escala Laurent Nottale, el espacio-tiempo es continuo pero no diferenciable, conduciendo a la aparición de una Ecuación de Schrödinger gravitacional. Como resultado, aparecen los efectos de cuantización a gran escala. Esto hace posible predecir correctamente las estructuras a gran escala del Universo sin la necesidad de las hipótesis de la materia oscura.



</doc>
<doc id="45555" url="https://es.wikipedia.org/wiki?curid=45555" title="Materialismo eliminativo">
Materialismo eliminativo

En la filosofía de la mente el materialismo eliminativo o eliminativismo, es una forma radical de materialismo (fisicalismo).

Los materialistas eliminativos creen que la conciencia es un epifenómeno de la función cerebral, y algunos creen que el concepto terminará siendo eliminado tan pronto como la neurociencia progrese. De una manera similar argumentan que los conceptos de la psicología popular como los son las creencias, los deseos, y las intenciones, son ilusorias y por lo tanto no tienen un sustrato neurológico consistente.

La visión del mundo según la cual todo es materia siguiendo leyes físicas, y en la que el cerebro es la única realidad existente en los mal denominados "fenómenos mentales", es criticada usualmente por partidarios de una visión mentalista o dualista, incluyendo casos de emergentistas que piensan que la mente es algo que "emerge" y se separa ontológicamente del cuerpo. Estas críticas apelan a la realidad de los "qualia" y la consciencia dado que son directamente percibidos.

Martín López Corredoira, desde una posición materialista, sale al paso de esos argumentos: tales percepciones son una pura ilusión, una fantasía, sueños sobre algo irreal.

Los que apoyan esta visión, comúnmente hacen comparaciones con las anteriores teorías científicas que ya han sido eliminadas, como la de los cuatro humores, la teoría de medicina, la teoría de la combustión atribuida al flogisto, y la teoría de la vida 'fuerza vital' (de Stahl -stahlianismo- y el vitalismo en general -como el de Hans Driesch-). En estos casos, la ciencia no ha producido versiones más detalladas de estas teorías, sino que las ha rechazado como obsoletas. Los materialistas eliminativos argumentan que la psicología popular se encamina hacia el mismo escenario. De acuerdo a Willard Van Orman Quine, tomará decenas de años antes de que la psicología popular sea remplazada por la ciencia real.

Esta forma de materialismo es principalmente asociada con los filósofos Paul y Patricia Churchland, aunque filósofos como Daniel Dennett, Jonás Barnaby y Lynne Rudder Baker también se considerarían a sí mismos como "eliminativos" respecto de muchos aspectos de la psicología.

La tesis del eliminativismo parece ser tan obviamente errónea para muchos críticos, bajo el argumento de que las personas saben de inmediato e indudablemente que tienen mentes, que la argumentación parece innecesaria. Este tipo de intuición se ilustra al preguntar qué sucede cuando uno se pregunta con sinceridad si uno tiene estados mentales. Los eliminativistas se oponen a tal refutación de su posición al afirmar que las intuiciones a menudo son erróneas. Las analogías de la historia de la ciencia se invocan con frecuencia para apoyar esta observación: puede parecer obvio que el sol viaja alrededor de la tierra, por ejemplo, pero a pesar de su aparente obviedad, esta concepción se demostró errónea, sin embargo. Del mismo modo, puede parecer obvio que aparte de los eventos neuronales también hay condiciones mentales. Sin embargo, esto también podría ser falso.

Pero incluso si uno acepta la susceptibilidad al error de las intuiciones de las personas, la objeción puede reformularse: si la existencia de condiciones mentales parece perfectamente obvia y es central en la concepción del mundo de las personas, entonces se necesitan argumentos enormemente fuertes para negar con éxito existencia de condiciones mentales. Además, estos argumentos, para ser consistentes, deben formularse de una manera que no suponga la existencia de entidades como "estados mentales", "argumentos lógicos" e "ideas"; de lo contrario, son autocontradictorias. Los que aceptan esta objeción dicen que los argumentos a favor del eliminativismo son demasiado débiles para establecer un concepto tan radical; por lo tanto, no hay razón para creer en el eliminativismo.

Algunos filósofos, como Paul Boghossian, han intentado mostrar que el eliminativismo es en cierto sentido auto refutable, ya que la teoría misma presupone la existencia de fenómenos mentales. Si el eliminativismo es verdadero, entonces el eliminativista debe permitir una propiedad intencional como la verdad, suponiendo que para afirmar algo uno debe creerlo. Por lo tanto, para que el eliminativismo se afirme como una tesis, el eliminativista debe creer que es verdad; si ese es el caso, entonces hay creencias y el reclamo eliminativista es falso.

Georges Rey y Michael Devitt responden a esta objeción invocando teorías semánticas deflacionistas que evitan analizar predicados como "x es verdadero" como la expresión de una propiedad real. Se interpretan, en cambio, como dispositivos lógicos, de modo que afirmar que una oración es verdadera es solo una forma citada de afirmar la oración misma. Decir, "Dios existe, es verdad" es solo decir, "Dios existe". De esta manera, argumentan Rey y Devitt, en la medida en que los reemplazos disposicionales de los "reclamos" y los relatos deflacionarios de "verdadero" son coherentes, el eliminativismo no se refuta a sí mismo.

Otro problema para el eliminativista es la consideración de que los seres humanos experimentan experiencias subjetivas y, por lo tanto, sus estados mentales conscientes tienen qualia. Como los qualia generalmente se consideran características de los estados mentales, su existencia no parece ser compatible con el eliminativismo. Los eliminativistas, como Daniel Dennett y Georges Rey, responden rechazando las qualia. Esto se ve como problemático para los oponentes de los eliminativistas, ya que muchos afirman que la existencia de qualia parece perfectamente obvia. Muchos filósofos consideran la "eliminación" de los qualia inverosímil, si no incomprensible. Afirman que, por ejemplo, la existencia del dolor simplemente está más allá de la negación.

Admitiendo que la existencia de qualia parece obvia, Dennett sin embargo afirma que "qualia" es un término teórico de una metafísica obsoleta derivada de intuiciones cartesianas. Argumenta que un análisis preciso muestra que el término está a la larga vacío y lleno de contradicciones. La afirmación del eliminativista con respecto a las qualia es que no hay evidencia imparcial de tales experiencias cuando se consideran como algo más que actitudes proposicionales. En otras palabras, no niegan que el dolor existe, sino que existe independientemente de su efecto sobre el comportamiento. Influenciados por las "Investigaciones Filosóficas" de Ludwig Wittgenstein, Dennett y Rey han defendido el eliminativismo sobre las qualia, incluso cuando se aceptan otras partes de lo mental.

Algunos filósofos simplemente argumentan que la psicología popular es una teoría bastante exitosa. Los teóricos de la simulación dudan de que la comprensión de la gente de lo mental pueda explicarse en términos de una teoría en absoluto. Por el contrario, argumentan que la comprensión de las personas sobre los demás se basa en simulaciones internas de cómo actuarían y responderían en situaciones similares. Jerry Fodor es uno de los objetores que cree en el éxito de la psicología popular como teoría, ya que crea una forma efectiva de comunicación en la vida cotidiana que puede implementarse con pocas palabras. Tal efectividad nunca podría lograrse con una terminología neurocientífica compleja.




</doc>
<doc id="45559" url="https://es.wikipedia.org/wiki?curid=45559" title="Herbert Marcuse">
Herbert Marcuse

Herbert Marcuse (Berlín, 19 de julio de 1898-Starnberg, 29 de julio de 1979) fue un filósofo y sociólogo de nacionalidad alemana y estadounidense, una de las principales figuras de la primera generación de la Escuela de Frankfurt.

Nació el 19 de julio de 1898 en Berlín. Era hijo de Carl Marcuse, un fabricante de productos textiles de origen judío procedente de Pomerania, y de Gertrud Kreslawskyun. Sirvió como soldado en la Primera Guerra Mundial y participó en la revolución alemana de noviembre de 1918. 

Después de completar sus estudios en la Universidad de Friburgo de Brisgovia obteniendo el grado de doctor en 1922, regresó a Berlín donde trabajó en una librería y editorial. En 1924 contrajo matrimonio con Sophie Wertheim. En 1928 volvió a Friburgo para continuar sus estudios de filosofía con Edmund Husserl y Martin Heidegger. Admiraba a Heidegger por su «filosofía concreta», pero al mismo tiempo le criticaba su individualismo y su enfoque ahistórico. Escribió una tesis sobre "La ontología de Hegel y la teoría de la historicidad". Su propósito en 1929 era obtener con este tema su habilitación (disertación postdoctoral para obtener el permiso para ejercer la docencia universitaria y postular a una plaza de profesor) en Friburgo, bajo la dirección de Heidegger. El proyecto no prosperó debido a las diferencias de Marcuse con Heidegger, principalmente debidas a que este último mantuvo al principio una opinión positiva del nacionalsocialismo. No obstante, el trabajo inicialmente preparado como disertación se publicó como ensayo en 1932.

En enero de 1933, el mismo mes de la toma del poder por Hitler, Leo Löwenthal (1900-1993) puso en contacto a Marcuse con Max Horkheimer y sus colaboradores del Instituto de Investigación Social, entre los que se encontraban Theodor W. Adorno y Erich Fromm. Debido a las dificultades para continuar con el proyecto bajo el régimen nazi por su condición de judío, Marcuse emigró a Suiza y ese año dirigió en Ginebra la sucursal del Instituto, que agrupaba a quienes habían emigrado desde Frankfurt del Meno. Continuó rumbo a París, ya convertido en un destacado teórico de la Escuela de Fráncfort.

En 1934 se trasladó a los Estados Unidos y continuó trabajando en Nueva York, en la Universidad de Columbia, que había puesto a disposición una nueva sede para el Instituto de Investigación Social. Obtuvo la ciudadanía estadounidense en 1940. Durante la Segunda Guerra Mundial trabajó para la Oficina de Servicios Estratégicos de los Estados Unidos (US Office of Strategic Services), precursora de la CIA, analizando informes de estrategia sobre Alemania (1942, 1945, 1951).

En 1952 inició una carrera docente como filósofo político, primero en la Universidad de Columbia y en Harvard, luego en la Universidad Brandeis desde 1958 hasta 1965, cuando fue profesor de filosofía y política, y finalmente (ya jubilado), en la Universidad de California, San Diego. Trabajando como profesor en esta universidad participó activamente en los debates sociopolíticos de las décadas de 1950 y 1960, en los que alcanzó tal notoriedad que se llegó a hablar de «las 3M»: Marx, Mao y Marcuse. Fue amigo y colaborador del sociólogo e historiador Barrington Moore Jr. y del filósofo político Robert Paul Wolff. Con posterioridad a la guerra, fue el miembro más políticamente explícito e izquierdista de la Escuela de Frankfurt, debido a su dedicación a aplicar políticas de emancipación, como la liberación de la mujer o las ideologías juveniles a la primera Teoría Crítica. Empieza a ser consciente de las principales limitaciones prácticas de la primera escuela de Frankfurt, y de la necesidad de perfilar las tesis sobre cultura y sociedad, identificándose a sí mismo como marxista, socialista y hegeliano. Fue además un referente teórico para los movimientos juveniles de protesta, como el movimiento "hippie".

Murió después de haber sufrido un ataque cerebrovascular durante una visita a Alemania. El teórico Jürgen Habermas, de la segunda generación de la Escuela de Frankfurt, cuidó de él durante sus últimos días.

Las críticas de Marcuse a la sociedad capitalista (especialmente en su síntesis de Marx y Freud, "Eros y la civilización", publicado en 1955, y su libro "El hombre unidimensional", publicado en 1964) resonaron con las preocupaciones del movimiento izquierdista estudiantil de la década de 1960. Debido a su apertura a hablar en las protestas estudiantiles, Marcuse pronto vino a ser conocido como «El padre de la Nueva Izquierda» (término que él rechazaba).

La crítica fundamental que realiza Marcuse a la sociedad moderna, desarrollada en "El hombre unidimensional", es que el sujeto unidimensional es víctima de su propia impotencia y de la opresión continua de un método de dominación más complicado de lo que Adorno y Horkheimer imaginaron. Esta es la concepción del poder por la que Marcuse se considera como puente entre la primera y la segunda generación de la escuela de Frankfurt. Este hecho se contrasta fundamentalmente con el capitalismo temprano, en que el movimiento proletario era una fuerza con el potencial efectivo de derribar al régimen. El capitalismo avanzado que describe Marcuse, en cambio, ha generado a través de los estados de bienestar una mejora en el nivel de vida de los obreros, que es insignificante a nivel real, pero contundente en sus efectos: el movimiento proletario ha desaparecido, y aún los movimientos antisistémicos más emblemáticos han sido asimilados por la sociedad y orientados a operar para los fines que la sociedad coactiva reconoce como válidos.

El motivo de esta asimilación, según Marcuse, consiste en que el contenido mismo de la conciencia humana ha sido fetichizado (en términos marxistas) y que las necesidades mismas que el hombre inmerso en esta sociedad reconoce, son necesidades ficticias, producidas por la sociedad industrial moderna, y orientadas a los fines del modelo. En este contexto, Marcuse distingue entre las necesidades reales (las que provienen de la naturaleza misma del hombre) y las necesidades ficticias (aquellas que provienen de la conciencia alienada, y son producidas por la sociedad industrial). La distinción entre ambos tipos de necesidades sólo puede ser juzgada por el mismo hombre, puesto que sus necesidades reales sólo él las conoce en su fuero más íntimo; sin embargo, como la misma conciencia está alienada, el hombre ya no puede realizar la distinción.

La principal necesidad real que Marcuse descubre es la libertad, entendida como el instinto libidinal no sublimado (en términos freudianos). Para Marcuse, lo que la sociedad industrial moderna ha hecho con el instinto libidinal del hombre es desublimarlo, y reducirlo al exclusivo ámbito de la genitalidad, cuando en realidad el cuerpo mismo del hombre es sólo ansia de libertad. La desublimación del instinto libidinal y su encasillamiento en su genitalidad permiten a la sociedad industrial moderna disponer del resto del cuerpo humano para la producción capitalista, así como de todas las energías de los hombres.

Lo que Marcuse quería destacar era una culturalización de la teoría de la felicidad de Freud: principio de realidad y principio de placer no tienen por qué ser opuestos si se consigue revelar las causas de la infelicidad. Marcuse se opone a lo abstracto del pensamiento racionalista cartesiano, que entiende al individuo como sujeto ideal, descartando el valor de lo corporal y de lo erótico.Y precisamente estos dos factores son imprescindibles para analizar el paso del "ser" al "deber ser" en lo cotidiano del ser humano. Esto coloca a Marcuse en una posición de vitalismo integral, entendiéndolo como una actitud de liberación tanto individual como colectiva, sacar a la luz lo más alejado de las convenciones, entendido por Freud como el "ello".

Para Marcuse, la instancia fundamental de formación de la conciencia humana está en la niñez, tal como se vive en el interior de la familia. En esta etapa, el hombre que se está formando adquiere sus categorías normativas y todo su marco de referencia para enfrentar el mundo. Lo que la sociedad industrial moderna ha trasmutado es precisamente ese ámbito familiar, en que la sociedad misma alienante se ha introducido a través de los medios de comunicación de masas, reemplazando a la familia, y formando a los hombres con categorías que no salen de él mismo, sino del capitalismo. Las necesidades del hombre, así como sus anhelos, sueños y valores, todo ha sido producido por la sociedad, y de esa manera se ha asimilado cualquier forma de oposición o movimiento antisistémico.

En este punto está la principal diferencia entre la forma de alienación que describe Marx y la que describe Marcuse. Mientras en Marx la alienación está focalizada en el ámbito de la producción material, donde al hombre se le arrebata el valor producido con su trabajo (y por tanto su condición humana), en Marcuse la alienación está enfocada en la conciencia misma del hombre moderno, y por tanto no hay forma alguna de escapar a la coacción.

A pesar de identificar en el hombre una forma de sumisión mucho más desarrollada y difícil de penetrar, Marcuse remarca los valores de la vanguardia en el arte cuando habla de Bertolt Brecht o dice por ejemplo: "La lucha por hallar este medio, o más bien dicho la lucha contra su absorción en la unidimensionalidad predominante, se muestra en los esfuerzos de la vanguardia por crear un distanciamiento que haría la verdad artística comunicable otra vez" (Herbert Marcuse, "El hombre unidimensional", pág. 96). Este distanciamiento que pretende realizar Marcuse está marcado por la intencionalidad de alejar al ser humano del dominio que está impuesto en toda la sociedad. Y pretende reorientar el rumbo de la cultura hacia el arte, hacia lo estético.

Marcuse muestra un análisis muy profundo y duro en cuanto a los procesos de cambio, a pesar de eso él reconoce «la posibilidad de alternativas» y los diferentes caminos y sobre todo la tarea de la filosofía en este aspecto. Una nota al pie muy curiosa de su libro "El hombre unidimensional" dice: “«Todavía existe el legendario héroe revolucionario que puede derrotar incluso a la televisión y a la prensa: su mundo es el de los países ‘subdesarrollados’» (Herbert Marcuse, "El hombre unidimensional", pág. 101, nota 14).

Pero la pretensión de hacer posible el distanciamiento a través del arte para evitar la dominación, muestra claramente un problema que impide utilizarlo como medio de evasión. Según Marcuse, el arte es capaz de sacarnos de la vida diaria, nos hace ver la realidad de otra forma porque nos coloca en otra posición. Sin embargo, el arte está distanciado, pero no separado de la realidad porque está mercantilizado, por lo tanto, no se puede utilizar como medio de evasión porque está bajo el control de la clase dominante, como el resto de los ámbitos de la sociedad.
En diferentes pasajes se evidencia su idealismo que luego se traduce a su militancia política. Esta contradicción es reconocida por Marcuse, quien vivió en una eterna disputa teórica acerca de la interrogante fundamental de si la sociedad tenía la posibilidad o no de cambiar desde adentro y por tanto de trascender el statu quo. Está clara la existencia de esperanza en su pensamiento, aunque el análisis de la realidad y los acontecimientos se contrapongan a este tema. Para ilustrar esta contradicción, en sus conclusiones sobre el «hombre unidimensional» Marcuse cita al final una frase de Walter Benjamin que dice lo siguiente: «Sólo gracias a aquellos sin esperanza nos es dada la esperanza» (Herbert Marcuse, "El hombre unidimensional", pág. 286).

En la era presente, se han invalidado las fronteras entre la psicología por un lado y la filosofía social y política por el otro, gracias a la condición actual del hombre. Por eso en "Eros y civilización" hace uso de categorías psicológicas, ya que antes los procesos psíquicos, antiguamente autónomos e identificables ahora están siendo absorbidos por la función del individuo en el estado, por su existencia pública. «Por lo mismo los problemas psicológicos se transforman en problemas políticos»: el desorden privado refleja más directamente que antes el desorden de la totalidad, y la curación del desorden personal depende más directamente que antes de la curación del desorden general.

La psicología puede ser elaborada y practicada entonces como una disciplina especial tan sólo en tanto la psique pueda mantenerse a sí misma contra el poder público, en tanto la vida sea realmente deseada y construida por sí misma, y afirma Marcuse, que si el individuo no tiene ni la habilidad ni la posibilidad de ser para sí mismo, los términos de la psicología llegan a ser los términos de las fuerzas sociales que definen la psique.




</doc>
<doc id="45561" url="https://es.wikipedia.org/wiki?curid=45561" title="Historia de Croacia">
Historia de Croacia

La historia de Croacia comienza a principios del período Neolítico. Dentro de la historia documentada, el territorio que actualmente corresponde a Croacia fue colonizado por los celtas y más tarde por los ilirios. Iliria fue un Estado soberano hasta que los romanos la conquistaran en el año 168 a. C. Los antepasados de la población eslava de Croacia se establecieron en la región durante el siglo VII.

El área conocida hoy en día como Croacia ha estado habitada durante la Prehistoria, desde la Edad de Piedra. En el Paleolítico Medio, los neandertales vivieron en Krapina y Vindija (noroeste de Croacia) y Mujina Dalmacia Pecina (central).

En el período neolítico temprano, las culturas Starčevo, Vučedol y Hvar se expandieron alrededor de la región. La Edad del Hierro dejó las huellas de la cultura de Hallstatt (ilirios primitivos) y la cultura La Tene (celtas).

Entrando en la historia documentada, el área fue habitada por tribus de Iliria, como la Delmetae, que hablaban una lengua de Iliria, una rama antigua de la familia indoeuropea. Otras tribus, como los Liburni y Iapodes, cuyo origen étnico es menos claro, habitaban diversas partes de la costa adriática y el interior entre Istria y Herzegovina.

En el siglo IV a. C. el norte de la actual Croacia también fue colonizado por los celtas, concretamente la tribu de los Escordiscos. Otros pueblos celtas se encontraban asimismo integrados entre los ilirios. Las islas de Issa y Pharos, así como la localidad de Tragurion o Trogir, se convirtieron en colonias griegas desde el mismo período.

Iliria fue un Estado soberano hasta que los romanos conquistaron sus tierras en el año 168 a. C.

Los romanos organizaron la actual Croacia en la provincia romana de Iliria, que abarcaba la mayoría de la Croacia moderna (Istria y parte de la provincia de Italia). Iliria se dividió posteriormente en las provincias de Panonia y Dalmacia en el año 10. Panonia fue dividida a su vez en dos más por Trajano entre 102 y 107.

En el siglo IV el emperador Diocleciano fraccionó más el país. Este emperador era de origen ilirio, de Dalmacia. Otras personas notables de esta región en este período fueron el Jerónimo cristiano, San Marino (el constructor de San Marino), los emperadores Valentiniano I y Valente, y el Papa Juan IV.

Después de la caída del Imperio Romano de Occidente en el siglo V, las vías romanas y la población iliria con lenguas románicas (como el istro-rumano o el dálmata) se mantuvieron. Con la cada vez mayor inmigración, esta población arraigó en las ciudades a lo largo de toda la costa dálmata.

Los eslavos se dispersaron por el este de Europa a lo largo de los siglos VI y VII por el empuje de hunos, germanos y ávaros hacia el oeste y el sur. Los croatas ("Chrobati", "Hrvati"), que se habían asentado en la zona de Galizia y en la Croacia Blanca (en el sur de Polonia), recibieron la oferta del emperador bizantino Heraclio de aliarse contra los ávaros a cambio de las tierras de Panonia y Dalmacia. Los croatas al mando del "zupan" legendario aceptaron el trato y lucharon contra los ávaros, atacándoles en la llanura de Panonia y dispersándose por los Balcanes. Una rama de los croatas, los "byelohravati" (Croatas blancos) permaneció, sin embargo, en territorios que corresponden hoy al sur de Polonia, conservando una precaria independencia entre checos y polacos.

Los croatas del sur formaron estructuras autónomas bajo el mando de sus jefes tribales ("zupani") en las montañas de Bosnia hasta Montenegro (croatas dináricos o Croatas rojos), a lo largo de las costas de Dalmacia (croatas de Dalmacia) y en las llanuras del Sava y el Drava (croatas de Panonia). De esta época es Radoslav, un gobernante enérgico del que se cantan aún baladas dedicadas a sus hechos y al que se le atribuye la introducción del cristianismo entre los croatas.

El ducado de Panonia se extendía a lo largo del Drava en la zona entre el Sava y el Danubio, en las regiones de las actuales Baranja, Backa y Eslavonia. Dalmacia abarcaba la actual Croacia entre el Drava e Istria), la Krajina y el interior de la actual Dalmacia, ya que las principales ciudades costeras estaban habitadas por población de origen latino.

En el ducado dálmata tenemos menciones de un tal Porga de finales del siglo VII, pero realmente documentado como primer duque de Croacia-Dalmacia es Višeslav, que gobernó durante el último tercio del siglo VIII. También de finales de ese siglo es el primer duque de Croacia-Panonia, Vojnomir. 

En el año 810, el poder de Croacia-Dalmacia pasó a Borna, que a su vez colocó en el otro ducado a su sobrino Ljudevit Posavki (Posavski significa "del río Sava"). Borma había aceptado ser vasallo de los emperadores francos, mientras que su sobrino luchó contra ellos hasta que en 823 fue derrotado y huyó al ducado de su tío, que por complacer a los carolingios lo encarceló hasta su muerte. Una sublevación contra los carolingios llevó al "zupan" Ratimir (829-838) a tomar el control de Panonia, pero de nuevo los francos sometieron Panonia en 838.

En Dalmacia se sucedieron los "zupani" vasallos de los francos, Vladislav (821-835) y Mislav (835-845), pero su sucesor, Trpimir I (845-864), se independizó y le fue reconocido el título de "Dux Croatorum", fundando una nueva dinastía (los "Trpimirovic") que gobernaron Croacia hasta la llegada de los húngaros. 

Panonia continuó bajo el vasallaje de los francos con Pribina (849-860), Kocelj (861-872) y Mucimir (872-873); sólo Braslav (880-897) disfrutó de una precaria independencia que debía soportar el empuje de las hordas magiares, que bajo su rey Árpád conquistaron el norte del ducado (Baranja y Backa), quedando el sur en manos de los croatas de Dalmacia, mientras que el este de Eslavonia (Sirmia/Srjem) fue ocupada también por los húngaros. De este modo la frontera norte de Croacia quedó fijada en el río Drava. 

Trpimir I asentó el ducado de Croacia, aunque tuvo que luchar con la naciente potencia del Adriático, la República de Venecia. Su sucesor e hijo Zdeslav (864, 878-879) fue depuesto por su primo Domagoj (864-876), y a su vez el hijo de este Iljko (876-878) fue derrotado por Zdeslav, restaurado en el ducado gracias al apoyo de los bizantinos. Su hijo Branimir (879-892) consiguió que las ciudades de la costa, tributarias de los bizantinos, se convirtieran en vasallas de los croatas, con lo que sus tributos pasaron de esta forma a las arcas del ducado. Por este motivo el papa Juan VIII, en un documento del 7 de junio de 879, entregó a los croatas el primer reconocimiento internacional como Estado. A Branimir le sucedieron sus hijos Mutimir (Muncimir o Mucimir) (892-900) y Petar (900-910), que unificaron el ducado incorporando la Eslavonia occidental. Tomislav (910-928), probablemente hijo de Mutimir, expandió las fronteras y el prestigio de Croacia, de forma que en 925 el papa Juan X le corona como rey de los croatas.

Bajo los sucesores del rey Tomislav Croacia alcanzó su máxima extensión, abarcando Croacia, Eslavonia, una parte ínfima de Dalmacia y gran parte de Bosnia. El resto de las ciudades costeras de Dalmacia estuvieron bajo dominio de la República de Venecia (Fiume [ Rijeka ], Zara [ Zadar ], Šibenik, Trogir, Spalato [ Split ]) hasta 1358, que, con la firma del tratado de Zadar, que le da el estatus de República a Ragusa (Dubrovnik), o Cattaro (Kotor) que nominalmente pertenecían al Imperio Bizantino. La capital, de donde procedían la mayoría de los gobernantes, estaba en la costa dálmata, en Biogrado ("Biograd na moru"). 

A Tomislav le sucedió su hermano menor Trpimir II (928-935), y a este su hijo Krešimir I (935-945), que dividió el reino entre sus dos hijos: Miroslav (945-949) y Mihajlo Krešimir II (945/949-969). El hermano mayor, sin embargo, no permitió gobernar al más joven, y se alzó como único regente. 

En 949 el "zupan" Pribina se sublevó y logró vencer al rey, que fue sustituido por su hermano. Aprovechando las luchas internas, Časlav Klonimirović, "zupan" de Rascia (Serbia), invadió los territorios de Travunia, Zachlumia, Neretva y Bosnia, así como los distritos orientales de Croacia, tal vez invitado por los insurgentes. Con la muerte de Časlav en 960 luchando contra los húngaros, Krešimir II recuperó algunos territorios con ayuda de Predimir, "ban" autónomo de Doclea, teniendo bajo su control toda Bosnia y consiguiendo en su reinado la máxima extensión de Croacia.

Su hijo Stjepan Držislav (969-997), debido a la presión de los búlgaros sobre el Imperio bizantino, obtuvo de los emperadores Basilio II y Constantino VII el dominio total de Dalmacia y le fue otorgado el título de Rey de Croacia y Dalmacia. El emperador de los búlgaros Samuel vio con desagrado la alianza entre bizantinos y croatas, atacando a estos últimos, venciendo al "zupan" Vladimir y marchando hacia Zadar, donde sitió al rey en la ciudad de Nin. No consiguió tomarla y regresó a Bulgaria a través de Bosnia, pemitiendo a Držislav recuperar su reino.
El reinado de sus hijos Svetoslav Mucimir Suronja (997-1000), Krešimir III (997-1030) y Gojislav (997-1020) fue más turbulento debido a que Svetoslav se arrogó todo el poder y los hermanos menores, apoyados por la nobleza croata, comenzaron una guerra civil que acabó con la vida del primogénito. El dux de Venecia, Pietro II Orseolo, aprovechó la ocasión para liberar las ciudades de Dalmacia, eliminando el tributo a los reyes croatas y conquistando para la república gran cantidad de islas adriáticas. El emperador Basilio II, vencedor de los búlgaros, reconoció a los hermanos como reyes de Croacia pero, viendo el peligro que suponía Venecia, tomó para sí el control de la costa dálmata y de grandes zonas de Bosnia.

Stjepan I (1030-1058), hijo de Krešimir III, decidió apoyar la revuelta del príncipe serbio (de origen croata), Dobroslav (Stjepan Vojislav), primero sin éxito en el 1036, y más tarde en 1040-42, esta vez derrotando a los bizantinos y expulsándoles de Serbia. El emperador Miguel IV Panflagonio se vio obligado a ceder Dalmacia a Stjepan II, pero el dux veneciano Domenico Contarino aprovechó la ocasión para tomar Zara. 

A Stjepan I le sucedió el último gran rey croata, Petar Krešimir IV (1058-1074), que restauró poco a poco todo el reino reconquistando Zara a los venecianos y expulsando a los bizantinos de Bosnia y Dalmacia. También tuvo especial cuidado en la extensión del cristianismo entre la población, estableciendo obispados en Biograd (1060), Vrhbosna (1061) y Trogir (1063). Impulsó la implantación del rito latino en las iglesias frente a los usos bizantino y eslavónico a pesar de la oposición del clero del interior del país. Krešimir IV no tenía hijos y su primo Stjepan sufría una grave enfermadad, por lo que decidió nombrar a Dimitar Zvonimir, "ban" de Eslavonia, como su consejero y sucesor otorgándole el título de "Duque de Croacia".

Petar Krešimir IV murió en la primavera de 1074, y en la Dieta Nacional los nobles consideraron que Zvonimir no era uno de los suyos, por lo que eligieron como rey al "Duque de Neretva", Slavac (1074-1075), apoyado por el clero eslavónico que estaba en contra de la liturgia latina. A su vez, las ciudades del oeste de Croacia (en general latinas) no estuvieron de acuerdo con esta elección, por lo que pidieron ayuda al duque normando de Amalfi, Amico, que tomó las ciudades adriáticas desde Zadar hasta Split, haciendo prisionero a Slavac. Mihajlo, "ban" de Duklja, tampoco apoyó la elección de Slavac y se proclamó independiente en el sur de Croacia. Venecia, que veía en peligro sus redes comerciales por la competencia normanda, entró en la liza. El nuevo Papa, Gregorio VII, decidió intervenir en las disputas dinásticas enviando un legado, Gerhard arzobispo de Sipanto, que en la Dieta de Salona consiguió que se aceptara como rey a Dimitar Zvonimir (1074-1089), coronándolo el como "Rey de los Croatas y los Dálmatas". Zvonimir recuperó de los venecianos las islas del Adriático y formó una gran flota para defender la costa dálmata; según algunos cronistas este reinado fue la edad de oro del reino croata.
Con la muerte de Zvonimir subió al trono Stjepan II (1089-1090), renaciendo las luchas dinásticas. Zvonimir estaba casado desde 1063 con la princesa Helena de Hungría (1088-1091), hija del rey Bela I de Hungría, que gobernaba en Eslavonia. El partido húngaro era mayoritario en el norte del país, principalmente en Eslavonia, por lo que eligieron como sucesor de su hermana a Ladislao I de Hungría (1091-1092), que fundó el obispado de Agram (Zagreb), que pronto se convirtió en el centro eclesiástico de Croacia. Renunció al trono y nombró sucesor a su sobrino Almos (1091-1093), que controló la zona entre el Sava y el Drava. 

Aprovechando la ocasión, el "dux" Vitale Faliero reconquistó para Venecia grandes zonas de la costa adriática. El reino quedó nuevamente dividido: en el norte los nobles ofrecieron el trono a los reyes húngaros y en el sur la dieta de nobles coronó a uno de ellos, Petar Svačić (1093-1097), que se enfrentó al rey húngaro Colomán I, apoyado por los croatas de Panonia. El ejército de Petar fue vencido en la batalla de la montaña Gvozd y el rey murió en ella. A partir de ese momento el reino croata se integró dentro de las fronteras del Estado húngaro, aunque conservando su estructura político-administrativa y manteniendo sus habitantes iguales derechos civiles que los húngaros. De esta manera, los croatas pasaron a ser una de las etnias más estimadas y respetadas por los magiares.

La asociación de Croacia al reino de Hungría se estableció por el "Pacta Conventa" (pactos convenidos) que fue supuestamente firmado por el rey Colomán de Hungría (en húngaro: "Könyves Kálmán") y un grupo de nobles croatas en 1102. Existe un antagonismo histórico hasta el día de hoy, ya que los húngaros no reconocen la existencia de dicho pacto y sólo indican la subordinación incondicional de los croatas a su corona y, por consiguiente, el error de señalarse herederos de sus posesiones en el Adriático, puesto que nunca tuvieron igualdad de derechos y sólo fue un pueblo sometido.

En dicho pacto se establecía que la unión era simplemente personal, es decir, que ambos reinos permanecían independientes con sus propias instituciones y leyes, y sólo el rey era común a ambos. De esta forma Croacia conservaba el "Sabor" (la dieta nacional), sus leyes y el gobierno, que era encargado a un "ban" elegido por los propios croatas de entre su nobleza. La frontera entre ambos reinos se establecía en el Drava, y Croacia se extendía hasta la costa adriática.

Durante el reinado de Colomán (1102-1116), Croacia disfrutó de una época de prosperidad y tranquilidad que no conocía su turbulenta historia. El reino se fortaleció, se estableció una nueva administración controlada por el "sabor" y los virreyes ("ban") y el ejército croata se reorganizó. Los reyes húngaros sucesores de Colomán (Esteban II de Hungría (1116-1131), Bela II "el ciego" (1131-1141) y Géza II (1141-1162)) respetaron las instituciones croatas y defendieron su territorio de los ataques de venecianos y bizantinos, considerándolos tan importantes como ciudadanos húngaros.

La muerte de Géza II provocó las guerras sucesorias en la familia Arpad: por un lado el hijo de Geza, Esteban III de Hungría (1162-1172), y por otro sus tíos (hermanos de Géza), Ladislao II (1161-1163) y Esteban IV (1163). Al extender su influencia sobre el reino húngaro, el emperador bizantino Manuel I Comneno aprovechó los años de guerra para anexionarse parte del territorio croata entre los Alpes dináricos y el Adriático, formando los ducados bizantinos de "Dalmacia-Croacia" y "Dalmacia-Dioclia". Sin embargo, puesto que el hijo menor de Géza II había crecido en la corte bizantina y tomado por esposa a una noble ortodoxa, las relaciones pronto mejoraron. Así, cuando el joven Béla III(1172-1196), protegido del emperador bizantino, regresó a Hungría y reclamó el trono tras la muerte de su hermano Esteban III, se recuperó el ducado bizantino de Croacia. Por otra parte, los territorios del sur fueron recuperados de los bizantinos por el Duque de Croacia Andrés de Croacia en 1198, durante el reinado de Emerico (1196-1204). 

Posteriormente, durante los reinados de Ladislao III de Hungría (1204-1205), Andrés II de Hungría (1205-1235) y Béla IV de Hungría (1235-1270), la feudalización que comenzó en la época de Bela III se agudizó en gran manera, provocando que el reino croata se fuera disgregando y que incluso se formaran dietas diferentes en diversos territorios, separándose los reinos de Croacia y de Eslavonia. Al mismo tiempo, se producían continuas disputas entre Hungría y Venecia por el dominio de la costa adriática, lo que llevó poco a poco a la separación de Dalmacia del reino croata. Varios miembros de la Casa de Árpad fueron nombrados duques de Croacia o Eslavonia y gobernaron de forma autónoma en varias ocasiones, como Colomán (1208-1241) en Croacia, y Esteban (1263-1271) en Eslavonia.

Los últimos reyes de la dinastía Arpad, Esteban V de Hungría (1270-1272), Ladislao IV de Hungría "el Cumano" (1272-1290) y Andrés III de Hungría "el Veneciano" (1290-1301), fueron reyes muy débiles, y en sus reinados algunos nobles se hicieron totalmente independientes a lo largo de todos los territorios húngaros, croatas y eslavonios. Así, Pavao I Suric (1292-1312) se independizó en Croacia y Eslavonia, asumiendo además el gobierno de gran parte de Bosnia. Su sucesor, Mladen II (1312-1322), continuó en esta situación mientras duraron las luchas dinásticas en Hungría. A la muerte de Andrés III, el trono húngaro fue ocupado por un miembro de la familia de los Premyslidas, Wenceslao III de Bohemia (1301-1305), nieto de Kunigunda, hija del fallecido rey húngaro Béla IV. Sin embargo, la corona húngara pasó pronto a manos de Otón III Duque de Baviera (1305-1308), quien era hijo de Isabel, hija del rey Béla IV.

Finalmente es Carlos Roberto de Anjou quien venció en las disputas dinásticas, proclamándose rey. El nuevo rey deseaba centralizar el poder y obligó a Mladen II a devolver el poder de Croacia a la corona húngara. Ante estas pretensiones, Mladen y su hermano Pavao II se rebelaron y fueron derrotados por las tropas angevinas que reunificaron Croacia, poniéndola bajo el mando del "ban" Ivan Babonic y encarcelando a los duques rebeldes.

La ciudad de Dubrovnik / Ragusa fue fundada en el siglo VII a partir de los invasores ávaros y eslavos que destruyeron la ciudad romana de Epidaurum. La supervivencia de la población romana se escapó a una pequeña isla cerca de la costa, donde fundaron un nuevo asentamiento. Durante la Cuarta Cruzada de la ciudad cayó bajo el control de la República de Venecia hasta el tratado de Zara en 1358, cuando Venecia, derrotada por el Reino de Hungría, perdió el control de Dalmacia y la República de Ragusa se convirtió en un afluente de aquel reino.

A través de los próximos 450 años la República de Ragusa sería una afluente República protegida por los otomanos y los Habsburgo hasta que Napoleón la abolió en 1808, cuando Ragusa, Dalmacia, Croacia, Eslovenia y Bosnia pasaron a formar las Provincias Ilirias.

La república se convirtió en la cuna más importante de la literatura eslava, durante los períodos renacentista y barroco. Aparte de los poetas y escritores como Marin Držić e Ivan Gundulić, cuyas obras eran importantes para el desarrollo de la literatura sud-eslava, la persona más famosa de la República de Ragusa fue el científico croata Ruđer Bošković, que era un miembro de la Royal Society y la Academia Rusa de Ciencias. La república iba a sobrevivir hasta 1808 cuando fue anexada por Napoleón. Hoy en día la ciudad de Dubrovnik está en la lista de la UNESCO como Patrimonio de la Humanidad y es un famoso destino turístico.

Durante todo el siglo XVI, el Imperio otomano avanzó poco a poco hacia el norte. En 1565, Solimán el Magnífico invadió Hungría avanzando exitosamente hasta la pequeña fortaleza de Siget (Szigetvár), donde el conde Nikola Šubić Zrinski resistía obstinadamente. Tras un mes de duro asedio cayó, pero el retraso producido en el ejército turco por esta batalla de Szigetvár permitió al ejército austríaco reorganizarse antes de que los otomanos llegaran a Viena.

Por órdenes reales, en 1553 y 1578, amplias zonas fronterizas de Croacia y Eslovenia se convirtieron en la Frontera Militar ("Vojna Krajina"), bajo autoridad directa del alto mando militar de Viena. La cercanía al enemigo turco las convirtió en tierras deshabitadas, por lo que la monarquía austríaca animó a serbios, checos, húngaros, eslovacos, alemanes, ucranianos y otros pueblos eslavos a asentarse en la zona como colchón.

En 1592, solo pequeñas zonas de Croacia quedaban libres del domino turco. Estos 16.800 km² fueron llamados "los vestigios de los vestigios del una vez gran reino de Croacia".

Tras la batalla de Sisak de 1593, que terminó con la derrota otomana y la expulsión de los turcos de Croacia, se recobró la mayor parte del territorio en manos turcas, que sólo pudieron conservar Bosnia. En 1699 se produjo una reorganización administrativa y se unieron el Reino de Croacia y el Reino de Eslavonia para crear el Reino de Croacia-Eslavonia.

Durante la Guerra de Sucesión Austriaca, Croacia fue una de las tierras imperiales que obedecieron la Pragmática Sanción de 1713 de Carlos VI del Sacro Imperio Romano Germánico y apoyaron a su hija María Teresa I. En consecuencia, la emperatriz concedió numerosos privilegios a Croacia, cambiando el control de la Frontera Militar y reduciendo la carga fiscal y los privilegios feudales. También incorporó el hasta entonces puerto libre de Rijeka al reino de Croacia en 1776. Sin embargo, ignoró y finalmente disolvió al parlamento croata, reduciendo su presencia en el Consejo de Hungría a un solo asiento, ocupado por el Ban de Croacia.

Con la caída durante las Guerras Napoleónicas de la República de Venecia en 1797 y la posterior abolición de la República de Ragusa en 1808, Francia cedió sus posesiones adriáticas a Austria. Ocho años después, derrotada Austria, Francia recuperó la costa dálmata, fundando las Provincias Ilirias, que, sin embargo, y tras la caída de Napoleón en 1815, fueron anexionadas de forma definitiva por Austria hasta 1918.

Durante estos siglos de unión con Austria y Hungría, Croacia sufrió un proceso de asimilación: el croata carecía de uso oficial, y se produjeron numerosos asentamientos de austriacos y húngaros en Croacia. En el siglo XIX, durante el renacer nacionalista del Romanticismo, el espíritu nacional croata resurgió en oposición a esta germanización y magiarización. En la década de 1830 surge el movimiento ilirio que influyó en la cultura croata y en su lengua. Su mayor representante fue Ljudevit Gaj, primer estandarizador del idioma croata. Esa misma década, las metas del movimiento pasaron de ser meramente culturales a oponerse al centralismo húngaro. Esto llevó a la prohibición por Metternich, el 11 de enero de 1843, del uso del nombre o los símbolos, lo que frenó el avance del movimiento pero no lo detuvo.

Jelačić, gobernador de Croacia, logró abolir la servidumbre, eliminando el lastre feudal y reduciendo el poder de la aristocracia latifundista. La consiguiente división de tierras produjo una parcelación en propiedades muy reducidas, muchas veces incapaces de alimentar a una familia, lo que propició la emigración, comenzando así la diáspora croata.
El "Ausgleich" supuso la ratificación de la pérdida de la autonomía croata. Según el acuerdo hungarocroata de 1868 ("hrvatsko-ugarska nagodba"), el Gobernador sería nombrado por Hungría, el 55% de los impuestos irían al gobierno de Budapest y el puerto de Rijeka quedaría bajo control directo húngaro.

El reino de Croacia y Eslavonia fue entonces dividido en ocho condados. Se incorporaron a este reino las tierras habitadas por los croatas de la costa dalmática y, dada la desaparición de la amenaza turca, se reintegraron los territorios de la Frontera Militar a los condados civiles en 1881. 

Como parte de dicho acuerdo, el Reino Tripartito de Dalmacia, Croacia y Eslavonia retuvo su estatus histórico, conservando su bandera y escudo. Sin embargo, Dalmacia se convirtió en parte de Cisleitania, mientras que los otros dos territorios estaban en Transleitania. La situación política de Dalmacia era mejor, pues gozaba de sufragio universal masculino, mientras que en Croacia-Eslavonia a principios de siglo apenas ciento noventa mil hombres tenían derecho al voto de una población de dos millones seiscientas mil personas.

Croacia-Eslavonia tuvo un cierto desarrollo a finales del siglo y principios del , que permitió el crecimiento de la industria ligera y la reducción de la proporción de población rural del 84 % en 1900 al 70 en 1910. La producción cerealística, sin embargo, siguió siendo insuficiente, apenas mayor que la de la Macedonia otomana. La baja productividad de las tierras, la falta de industria y el amplio analfabetismo (apenas un 20 % de la población estaba alfabetizada) fomentaron la emigración, primordialmente a Norteamérica: en los años que precedieron a la Primera Guerra Mundial, alrededor de un cuarto de millón de campesinos empobrecidos (serbios y croatas), abandonaron el territorio. La situación económica en Dalmacia era aún peor.

Croacia formó parte en otoño de 1918 del Estado de los Eslovenos, Croatas y Serbios, que tenía capital en Zagreb, que posteriormente se fusionó con el Reino de Serbia para crear el Reino de los Serbios, Croatas y Eslovenos, desde 1929 llamado Reino de Yugoslavia. 

Este estado balcánico que existió desde el 1 de diciembre de 1918 al 2 de diciembre de 1945. Comprendía el área de los actuales estados de Bosnia-Herzegovina, Serbia y Montenegro, Macedonia, así como la mayor parte de los territorios de Croacia y Eslovenia.

Tras la disolución del Imperio Austrohúngaro, la idea de crear una nación para los eslavos en los Balcanes cobró impulso y apoyo de la comunidad internacional. El "Reino de los Serbios, Croatas y Eslovenos" (Latín serbocroata: Kraljevina Srba, Hrvata i Slovenaca cirílico: Краљевина Срба, Хрвата и Словенаца, Esloveno: Kraljevina Srbov, Hrvatov in Slovencev, Macedonio: Кралство на Србите, Хрватите и Словенците, nombre corto Kraljevina SHS, Краљевина СХС), vino a satisfacer esta demanda. Este reino se formó en diciembre de 1918 y pervivió hasta 1929, momento en el que la denominación fue sustituida por la de "Reino de Yugoslavia".

El , el "Sabor" croata (el parlamento) declaró la independencia y en su soberanía manifestó su voluntad de ingresar en el nuevo Estado de los Eslovenos, Croatas y Serbios. Para enfrentar la amenaza del ejército italiano que ingresaba por el sur y el occidente en el territorio de este nuevo estado, los croatas negociaron con el Reino de Serbia y el enviaron una delegación a Belgrado para proclamar la unión.

El 1 de diciembre de 1918 fue proclamado el reino por Alejandro Karađorđević, príncipe regente por su padre, el rey Petar (Pedro), quien formalmente era el rey de Serbia. El nuevo reino fue formado a partir de los antiguos reinos independientes de Serbia y Montenegro, así como también con una cantidad sustancial del territorio que antiguamente fue parte del Imperio Austrohúngaro. Las tierras de Austria-Hungría que formaron el nuevo estado incluían Croacia, Eslavonia y Vojvodina de la parte húngara del imperio; Carniola, parte de Estiria y la mayor parte de Dalmacia del lado austríaco, además de la provincia imperial de Bosnia-Herzegovina. Se llevó a cabo un plebiscito en la provincia de Carintia, la cual optó por seguir en Austria. La ciudad puerto dálmata de Zadar y unas cuantas islas dálmatas fueron otorgadas a Italia. La ciudad de Rijeka fue declarada ciudad-estado libre, pero pronto fue ocupada y anexada en 1924 por Italia. Las tensiones en la frontera con Italia continuaron, con los italianos reclamando más áreas de la costa dálmata y Yugoslavia reclamando por su parte la península de Istria, parte de la antigua provincia costera austríaca que había sido anexada a Italia pero que contenía una población considerable de croatas y eslovenos.

El nuevo gobierno intentó integrar al nuevo país tanto política como económicamente, una tarea difícil debido a la gran diversidad de idiomas, nacionalidades y religiones existentes en el nuevo estado, la historia diferente de las regiones, y a las grandes diferencias entre ellas en cuanto al desarrollo económico.

En 1924 una decisión de apenas la mitad más uno de los diputados de la Asamblea Nacional estipuló en la constitución el carácter centralista del estado. Esta decisión propiciada y cumplida con autoritarismo por el primer ministro Nikola Pašić, causó la oposición de los croatas, quienes lucharon desde entonces por establecer su autonomía, objetivo central para el Partido Campesino Croata, principal partido croata.

Las tensiones entre el nacionalismo serbio (envalentonado por el carácter centralista del estado) y el resto de los pueblos del país estalló con el asesinato en el parlamento del reino del líder del Partido Campesino Croata Stjepan Radić, por parte de un diputado montenegrino. Ello llevó al rey a clausurar el parlamento y asumir el gobierno del país de una manera dictatorial. Los croatas solamente dieron tregua en su lucha por autonomía entre 1926 y 1927 ante la amenaza que para la existencia del reino eslavo significaba la coalición integrada por Italia con Albania, Hungría, Bulgaria y Rumania. La oposición croata se revivió cuando el rey capituló a las exigencias italianas de libre tránsito en Dalmacia y firmó con Benito Mussolini el "Tratado de Nettuno", en 1928, supuestamente para dar tranquilidad al país.

Sin embargo, esto sólo reavivó las tensiones internas. De hecho, pocos años después un guerrillero macedonio contratado por el nacionalismo croata "ustacha" asesinó en Marsella el al rey Alejandro I y al ministro de exteriores francés. Le sucedió en el trono su hijo Pedro, pero al ser menor de edad asumió la regencia su tío el Príncipe Pablo. 
En agosto de 1939, amenazada Yugoslavia por un inminente ataque de Italia y la Alemania nazi, el primer ministro Dragiša Cvetković firmó con el dirigente del Partido Campesino Croata Vladko Maček el Acuerdo Cvetković-Maček para la creación de la Banovina de Croacia, una entidad autónoma que incluía la actual Croacia y parte de Bosnia y Hercegovina. Maček fue nombrado viceprimer ministro. 

El Príncipe Pablo gobernó hasta que, el , un golpe de estado contra la política filoalemana del regente llevó al trono de manera anticipada a Pedro II. De manera fáctica el Reino de Yugoslavia dejó de existir cuando, diez días después, el , la aviación alemana atacó Belgrado y en las semanas siguientes el país se vio invadido por las tropas de Alemania, Italia, Bulgaria, Hungría, Albania y Rumanía.

El rey y el gobierno huyeron a Londres dando prolongación formal y legal al país hasta 1945.

El Estado Independiente de Croacia (NDH, del croata "Nezavisna Država Hrvatska") fue un estado organizado por los nazis tras la derrota del Reino de Yugoslavia en la primavera de 1941. Fue gobernado por el Ustaše y se anexionó Bosnia-Herzegovina. Llevó a cabo una política de genocidio de la población serbia, gitana, judía y de los antifascistas croatas. Dependiendo de las fuentes, el exterminio se calcula entre las 250.000 y el millón de víctimas.

Croacia llegó a ser parte de la República Federal Socialista de Yugoslavia en 1945, la cual era dirigida por el Partido Comunista de Yugoslavia bajo la tutela de Tito.
Tito, siendo de padre croata y madre eslovena también, adoptó una cuidadosa política para manejar las conflictivas ambiciones nacionales de los serbios y croatas.

Croacia fue una república Socialista, miembro de una federación de 6 partes. Bajo el nuevo sistema comunista, la propiedad privada fue nacionalizada y la economía se basó en la idea del socialismo de mercado. El país desarrolló un proceso de reconstrucción debido a la destrucción provocada por la Segunda Guerra Mundial. Además dio inicio a la industrialización y comenzó a desarrollar el turismo.

La constitución de 1963 equilibró el poder en el país entre serbios y croatas, y alivió el hecho de que estos últimos estuvieran nuevamente en minoría. Sin embargo, después de 1965 se formó la primavera croata la cual en 1970-71 produjo varias manifestaciones a favor de una mayor libertad civil y de una autonomía croata. El régimen sofocó las protestas públicas y encarceló a sus líderes, pero esto llevó a la ratificación de una nueva constitución en 1974, la cual concedió más derechos a cada una de las repúblicas.

En 1980, después de la muerte de Tito, las dificultades políticas, étnicas y económicas comenzaron, y el gobierno federal comenzó a desmoronarse. La emergencia de Slobodan Milošević en Serbia y muchos otros eventos provocaron una muy mala reacción en Croacia, seguida por un aumento del nacionalismo y de los movimientos disidentes.

El parlamento croata ("Sabor") proclamó la soberanía de la república el 22 de diciembre de 1990. En el referéndum del 19 de mayo de 1991, el 90% de los votantes se pronunciaron a favor de un estado independiente, y tras una decisión parlamentaria en el mismo sentido el presidente Franjo Tudjman proclamó unilateralmente la independencia el 25 de junio.

La Guerra Croata de Independencia se desarrolló en el período comprendido entre 1991 y 1995. La nueva república tuvo que enfrentarse a las fuerzas rebeldes de la minoría serbia, que proclamaron la República de Krajina, siendo apoyadas por el Ejército Popular Yugoslavo. El conflicto, de connotaciones étnicas, concluyó con la Operación Tormenta llevada entre el 3 y el 5 de agosto de 1995, recuperando zonas declaradas como Áreas Protegidas por las Naciones Unidas. Este día es celebrado como una fiesta nacional llamada Día de la Victoria y de Acción de Gracias por la Patria.



</doc>
<doc id="45563" url="https://es.wikipedia.org/wiki?curid=45563" title="Anafase">
Anafase

Anafase, del griego "ανα" (arriba) y "φασις" (fase), es una fase de la mitosis y meiosis en una célula eucariota, en la que los cromosomas duplicados son separados. Las cromátidas son entonces desplazadas a polos opuestos de la célula en división por el huso mitótico o meiótico, para que cada célula hija herede una copia de cada cromosoma. La anafase es también cuando los cromosomas alcanzan su nivel máximo de condensación.

Al inicio de la anafase las cromátidas hermanas son separadas totalmente y son dirigidas hacia polos opuestos de la célula en división. El punto principal de contacto de los microtúbulos con cada cromosoma es, un complejo proteico llamado cinetocoro, que es ensamblado sobre cada centrómero. Aquellos microtúbulos que contactan cinetocoro son llamadas fibras K, del inglés kinetochore. Los microtúbulos, compuestos de tubulina y otras proteínas asociadas, se van acortando para remolcar las cromátidas hacia su respectivo polo celular. 

La anafase comienza con la regulación proteica de la transición de metafase-anafase. Llegando a este punto se activa el complejo promtor de la anafase (CPA), se finaliza la metafase al desactivarse la ciclina necesaria para su funcionamiento (ciclinas dependientes de quinasa M-CDK). También se desactiva la securina, proteína inhibidora de la proteasa conocida como separasa. La separasa puede entonces cortar la cohesina, proteína responsable de mantener las dos cromátidas unidas, y es el punto en el que se considera empezada la anafase.

Dentro de la anafase tienen lugar dos procesos. Durante la anafase temprana las cromátidas se separan al acortarse los microtúbulos y gracias a los cinetocoros. Cuando las cromátidas están totalmente separadas comienza la anafase tardía, en la que los microtúbulos son acortados para dirigir cada grupo de cromátidas hacia polos opuestos de la célula. Este es también el momento en que los cromosomas llegan a su máximo punto de condensación, lo que contribuye a su segregación y la formación de los nuevos núcleos.

Durante la Meiosis ocurren dos procesos de división del núcleo: Meiosis I y Meiosis II. La Meiosis I está dividida en Profase I, Metafase I, Anafase I y Telofase I. La Meiosis II lo está en Profase II, Metafase II, Anafase II y Telofase II.

En la Anafase I, los centrómeros comienzan a separarse, atraídos por los polos, y cada uno arrastra en su movimiento a las dos cromátidas que le están unidos. Las parejas de cromosomas homólogos o bivalentes en que no existan quiasmas o sean sólo terminales, se separan simplemente, pero si existen quiasmas intersticiales, estos se deslizan hacia los extremos cromosómicos. Entre el centrómero y el primer punto de quiasma diploténico se separan los cromosomas paterno y materno, pero entre este quiasma y el siguiente se separan cromátidas hermanos. La fuerza de atracción entre las cromatidias apareadas desaparece. Los centrómeros paterno y materno se distribuyen al azar a los dos polos del huso acromático.

La anafase II es similar a la de la mitosis, separándose los centrómeros hijos, atraídos hacia los polos, y arrastrando en su movimiento a las cromátidas.

Enrique Sánchez-Monge. "Genética". (1966)


</doc>
<doc id="45564" url="https://es.wikipedia.org/wiki?curid=45564" title="Telofase">
Telofase

la telofase (del griego τελος, que significa "finales") es la reversión de los procesos que tuvieron lugar durante la profase y prometafase. Es decir, todo vuelve al principio y se repite el proceso.


Las fibras del huso desaparecen, los juegos de cromosomas se agrupan en los polos opuestos y la membrana nuclear se vuelve a formar a su alrededor.
De esta forma finaliza generalmente la cariocinesis. La división nuclear puede existir sin citocinesis y el resultado es la existencia de células binucleadas o polinucleadas, como parte de un proceso genéticamente programado de citodiferenciación y desarrollo.

Al proceso de cariocinesis le sigue habitualmente la división del citoplasma.


</doc>
<doc id="45571" url="https://es.wikipedia.org/wiki?curid=45571" title="Ralph Gonsalves">
Ralph Gonsalves

Ralph Everard Gonsalves (8 de agosto de 1946, San Vicente y las Granadinas), a menudo conocido como «Camarada Ralph», es el primer ministro de San Vicente y las Granadinas. Es el líder del Partido Laborista de Unidad. Ganó las elecciones de 2001 con un triunfo arrollador, después de un apretado triunfo en las elecciones de 1998.

Libros


</doc>
<doc id="45574" url="https://es.wikipedia.org/wiki?curid=45574" title="Diodo túnel">
Diodo túnel

El Diodo túnel es un diodo semiconductor que tiene una unión "pn", en la cual se produce el efecto túnel que da origen a una conductancia diferencial negativa en un cierto intervalo de la característica corriente-tensión.

La presencia del tramo de resistencia negativa permite su utilización como componente activo (amplificador/oscilador).

También se conocen como diodos Esaki, en honor del físico japonés Leo Esaki quien descubrió que una fuerte contaminación con impurezas podía causar un efecto de tunelización de los portadores de carga a lo largo de la zona de deplexión en la unión. Una característica importante del diodo túnel es su resistencia negativa en un determinado intervalo de voltajes de polarización directa. Cuando la resistencia es negativa, la corriente disminuye al aumentar el voltaje. En consecuencia, el diodo túnel puede funcionar como amplificador, como oscilador o como biestable. Esencialmente, este diodo es un dispositivo de baja potencia para aplicaciones que involucran microondas y que están relativamente libres de los efectos de la radiación.



</doc>
<doc id="45576" url="https://es.wikipedia.org/wiki?curid=45576" title="De iure">
De iure

De iure o de jure () es una locución latina que significa literalmente ‘de derecho’, esto es, con reconocimiento jurídico, legalmente. Se opone a "de facto", que significa ‘de hecho’. Esta locución está plenamente incorporada a la lengua española, pero según la última "Ortografía" (2010) de la Real Academia Española debe escribirse en cursiva.

Una situación "de iure" es aquella que está reconocida por la legalidad vigente o por la autoridad competente en virtud de algún acuerdo o acto formal. No tiene por qué corresponderse con la situación real y es en esos casos en los que la situación "de iure" se opone a la "de facto". Por ejemplo, una persona puede tener un cargo "de iure" —es decir, por nombramiento oficial— y no ejercerlo en la práctica por cualquier motivo. Un gobierno "de iure" está investido con todas las garantías jurídicas, pero puede ser incapaz de ejercer sus poderes legítimos porque un gobierno de facto los ha usurpado.


</doc>
<doc id="45582" url="https://es.wikipedia.org/wiki?curid=45582" title="Gardel (desambiguación)">
Gardel (desambiguación)

Gardel puede referirse a:


</doc>
<doc id="45584" url="https://es.wikipedia.org/wiki?curid=45584" title="Morelos I">
Morelos I

El Morelos I fue el primer satélite de comunicaciones mexicano. Construido y puesto en órbita bajo contrato dado por la Secretaría de Comunicaciones y Transportes al Grupo de Espacio y Comunicaciones de Hughes. Fue lanzado en Cabo Cañaveral en el transbordador espacial Discovery de la NASA, el 17 de junio de 1985 a las 07:33 UTC.

Entrando en órbita geoestacionaria el 17 de diciembre de 1985.

Formó parte de una serie de satélites de comunicaciones mexicanos Morelos y actualmente es basura espacial inubicable.




</doc>
<doc id="45585" url="https://es.wikipedia.org/wiki?curid=45585" title="Cena">
Cena

La cena (del latín "cena") es, como norma general, la última comida del día que se toma por la noche, normalmente se toma a partir de las 8 de la noche. Las cenas suelen incluir dos o más platos, y pueden ir acompañadas de vino o postre. El plato principal suele incluir carne y verduras. En las épocas de verano, la cena puede consistir en un plato principal acompañado de una ensalada o fruta.

En España y algunos países de Latinoamérica se cena entre las ocho y las diez de la noche,

Existen otros países (por ejemplo Venezuela) donde la cena suele consistir en un plato ligero o mediano, a veces muy similar a un desayuno, reservándose las cenas más cargadas sólo para ocasiones especiales.

Por su parte, en Chile la costumbre de cenar ha sido reemplazada por "las once", que tiene algunas diferencias, por lo que muy pocas familias siguen cenando. 



</doc>
<doc id="45586" url="https://es.wikipedia.org/wiki?curid=45586" title="Taller de explotación laboral">
Taller de explotación laboral

Un taller de explotación laboral o de “trabajo esclavo” es un espacio laboral donde se realizan trabajos fuera de las convenciones internacionales. Queda representado en el siglo por el modelo conocido como sweatshop frecuente y abundante en países en vías de desarrollo o del tercer mundo, y especialmente en Asia, donde el trabajador recibe sueldos muy bajos (el equivalente a 3 euros al día, o unos pocos céntimos la hora), manufacturando ropa, juguetes, calzado y otros bienes de consumo. Otro ejemplo de explotación laboral son las maquiladoras o maquilas en México.

Taller de explotación laboral o de “trabajo esclavo” puede referirse a cualquier centro de producción o fabricación en el que los trabajadores comparten un entorno duro (ventilación inadecuada, deficiencia de infraestructuras higiénicas o carencia de servicios), sometidos ocasionalmente a abusos físicos, mentales o sexuales, así como a condiciones de trabajo peligrosas para la salud o a horarios de trabajo excesivos.

Aún en el siglo , muchos talleres de explotación laboral son propiedad de corporaciones multinacionales o de compañías locales que producen bienes para corporaciones extranjeras. Las corporaciones actúan generalmente a través de un proceso de subcontratas, con lo que no son propietarios directos del taller, pero emplean a la organización menor que es la propietaria y se encarga de la producción. En este contexto, algunas compañías han sido acusadas de usar a niños en los "talleres de trabajo esclavo" de sus subcontratas. Paralelamente, en algunos países en los que se desarrolla este sofisticado modelo de esclavitud, está prohibido –o reprimido por la fuerza de las armas– el recurso laboral o la práctica del sindicalismo, como defensa de los derechos del trabajador.

También existen talleres de explotación laboral en los países desarrollados, montados por compañías o particulares que emplean trabajadores sin permiso legal para trabajar (por lo general inmigrantes ilegales), pagándoles un sueldo inferior a lo legalmente reglamentado, y sin declarar su presencia ante las autoridades locales de trabajo ni cubriendo las cuotas de la seguridad social. Esta práctica genera la llamada economía subterránea, que entre otras ventajas permite al contratante el lavado de dinero, y que en algunos países desarrollados llega a alcanzar un porcentaje elevado en comparación a la economía formal. 

Los talleres de explotación laboral no son un fenómeno nuevo. Continuando el modelo de la revolución industrial, tanto en los Estados Unidos como en Europa, en el y principios del , se crearon talleres que ofrecían trabajo a los inmigrantes o ‘trabajadores de baja cualificación’. Los sindicatos y las nuevas leyes y regulaciones laborales consiguieron en ocasiones obligar a los empleadores a mejorar la seguridad y las condiciones de trabajo, y a subir los sueldos.

Algunos sindicatos, como el AFL-CIO, han ayudado al movimiento contra estos talleres, tanto por un interés filántropico en el bienestar de los trabajadores más desfavorecidos como por propio beneficio. Como los productos producidos en los talleres de explotación laboral son más baratos que los producidos en las fábricas de Estados Unidos o Europa, los sindicatos piensan que esto puede ocasionar que sus miembros pierdan sus trabajos.

Acabar con el “trabajo esclavo” es uno de los objetivos del movimiento anti-globalización, que ha acusado a muchas compañías (como Walt Disney, The Gap y Nike) de hacer uso de este tipo de talleres. Los activistas de este movimiento indican que el proceso de globalización neoliberal favorece los abusos corporativos a los "trabajadores esclavos". Adicionalmente, argumentan que la producción con sueldos bajos en los países desfavorecidos es responsable de la pérdida de empleos en los países del Primer Mundo.

Los artículos 22, 23, 24 y 25 de la Declaración Universal de los Derechos Humanos, entre otros, tratan sobre la materia.

Aquellos que defienden la práctica de trasladar la producción a zonas de bajos sueldos apuntan a un coste de vida inferior como explicación de los sueldos bajos, y argumentan que sus operaciones benefician a la comunidad, al proveerles de empleos, algo que la comunidad necesita. Aun así, algunas compañías se han plegado a la presión pública y han reducido su dependencia de este tipo de talleres. Estudios recientes muestran que las fábricas en el tercer mundo pueden mejorar las condiciones de trabajo en los países en vías de desarrollo, y ofrecen un sueldo superior al que tendrían disponible en su ausencia.

Johan Norberg, un intelectual favorable al capitalismo, miembro del "Cato Institute" y autor del documental británico pro-globalización "Globalization is Good" ("La globalización es buena", 2003), sostiene el siguiente ejemplo en defensa de los talleres de este tipo del tercer mundo:

Algunos críticos replican que los que defienden estos argumentos suelen obviar la cuestión de que la entrada de multinacionales subsidiadas por su países de origen en los mercados de los países del tercer mundo lleva a:
De tal manera que, critican, se propone como solución a la pobreza lo que no es más que la propia causa.




</doc>
<doc id="45587" url="https://es.wikipedia.org/wiki?curid=45587" title="Trabajo esclavo">
Trabajo esclavo

Trabajo esclavo puede referirse a:

</doc>
<doc id="45603" url="https://es.wikipedia.org/wiki?curid=45603" title="Richard Garfield">
Richard Garfield

Richard Garfield (Nueva York, 1963) es un profesor de matemáticas y diseñador de juegos estadounidense. Ha diseñado juegos de cartas como "", "Netrunner", "Battle Tech", "" (originalmente conocido com jyhad), "El Gran Dalmuti", "La Guerra de las Galaxias el Juego de Cartas Coleccionables" y el juego de mesa "RoboRally". "" es su juego más exitoso y su desarrollo lo acreditó como el creador del género de juegos de cartas coleccionables.

Garfield diseñó su primer juego cuando era un adolescente. Tenía un gran rango de intereses, incluyendo el lenguaje y las matemáticas. En 1986 se graduó como licenciado en matemáticas y computación. Entró a los Laboratorios Bell y trabajo allí por un par de años, pero luego decidió continuar con sus estudios y entró a la Universidad de Pennsylvania en Filadelfia.

Comenzó a diseñar un juego llamado "Magic: el encuentro" cuando aún era un estudiante en los años 80. Un grupo de ensayo del juego de la "costa este", conformado en su mayoría por estudiantes de Pensylvania, se formó alrededor del desarrollo del juego. Mientras buscaba un editor para el juego "RoboRally", se encontró con Peter Adkinson de la recién fundada Wizards of the Coast. Adkison aceptó publicar su juego de mesa y expresó su interés en un juego como Magic, en que los juegos duraran poco tiempo.

Garfield obtuvo un doctorado en Matemática Combinatoria en Pennsylvania en 1993. Se convirtió en profesor de Matemáticas en la Universidad de Whitman en Walla-Walla, Washington.

"Magic: el encuentro" se volvió tremendamente popular luego de su lanzamiento en 1993. Garfield dejó la academia para entrar a Wizards of the Coast como diseñador de tiempo completo en junio de 1994. Después del ascenso del juego, Richard se fue a vivir a Kennewick, Washington.

«Richard Garfield, Ph.D.» es también el nombre de una carta del set de broma "Unhinged" de "Magic: el encuentro". Este tema había sido previamente explorado con la carta «Phelddagrif», un anagrama de «Garfield, Ph.D.».

Garfield todavía contribuye esporádicamente a "Magic: el encuentro", recientemente como parte del equipo que diseño la expansión de Ravnica en el 2005, y más recientemente en Innistrad en el 2011

Garfield ha creado tres cartas de Magic, celebrando eventos de su vida: Una carta llamada simplemente «Proposal» (las cartas solo fueron hechas en inglés) fue usada para su propuesta de matrimonio a Lily Wu durante un juego de Magic. Su texto dice: "«Permite a Richard proponerle matrimonio a Lily. Si la propuesta es aceptada ambos jugadores ganan; mezclan las cartas en juego, mezclan las bibliotecas y los cementerios como un solo mazo compartido»". Es popularmente creído que le tomo cuatro juegos robar la carta a Richard, pero la propuesta fue finalmente aceptada. Nueve copias de la carta fueron hechas, y se le obsequiaron a colegas y amigos. Aparentemente una de las cartas fue robada.

Las otras dos cartas «Splendid Genesis» y Fraternal Exaltation conmemoran el nacimiento de sus dos hijos. Ambas cartas fueron impresas de la misma manera que todas. Varias copias de las cartas fueron dadas a amigos y asociados y son consideradas de extrema rareza entre los coleccionistas.

Existe una regla comúnmente aceptada entre los fanes de "Magic: el encuentro", y es que si Richard Garfield altera personalmente una carta con su mano, el cambio es permanente para esa carta en particular. Esto ha desatado varias leyendas urbanas. El hecho de que Garfield posee poderes de dios en el universo de Magic es inmortalizado en la carta, «Richard Garfield, Ph.D.»



</doc>
<doc id="45604" url="https://es.wikipedia.org/wiki?curid=45604" title="Verbo">
Verbo

El verbo es la parte de la oración o categoría léxica que expresa una acción, movimiento, existencia, consecución, condición o estado del sujeto. Sintácticamente representa una predicación. En la oración, el verbo conjugado funciona como el núcleo sintáctico del predicado (si el verbo está en una forma conjugada ocupará en general la posición del núcleo del sintagma de tiempo, y si no de un sintagma verbal simple).

Los verbos, según su valencia o gramática, pueden ser clasificados en intransitivos, transitivos, ditransitivos, etc. Son transitivos cuando el verbo requiere más de un argumento obligatorio. Los intransitivos tienen un solo argumento obligatorio.

Los verbos son palabras variables que indican acción, proceso o estado. En "Ramón sube las escaleras", "sube" supone una acción que está realizando, en "Ramón ha crecido un montón", "ha crecido" supone un proceso que ha experimentado, y en "Ramón está cansado", "está" supone un estado.

En la inmensa mayoría de lenguas del mundo el verbo es la clase de palabra más compleja en el sentido de que puede reflejar muchas más categorías gramaticales que otras palabras. Es frecuente que exprese una o varias personas gramaticales (en lenguas como el español solo marca la persona gramatical asociada al sujeto; en otras lenguas también puede marcar el objeto), número gramatical, tiempo-modo-aspecto y más raramente en algunas lenguas puede llevar género gramatical, evidenciales, direccionales, clasificadores de forma, intencionales, etc. En gramática tradicional las categorías expresadas en el verbo se denominan "accidentes gramaticales".

En la mayoría de lenguas flexivas existen tres categorías gramaticales típicas del verbo.


En muchas lenguas indoeuropeas el tiempo, el aspecto y el modo gramatical frecuentemente se expresan fusionadamente mediante un único morfema que expresa simultáneamente los diversos valores de esas categorías. Por ejemplo en español, en la forma "amaste" el morfema "-ste" expresa simultáneamente el modo indicativo, el tiempo pasado y el aspecto perfecto (además de expresar segunda persona y singular).

Los verbos constituyen una clase de palabras con gran variación formal entre las lenguas del mundo; transmiten acción, proceso, estado, número, persona, tiempo, etc. Se pueden distinguir los siguientes constituyentes morfológicos de las formas verbales:

Las lenguas flexivas y en particular las lenguas indoeuropeas frecuentemente incluyen además otros tipos de constituyentes:

En muchas lenguas romances y germánicas existen formas verbales compuestas. En las formas compuestas aparece un verbo auxiliar (en español "haber"), que acompaña al participio del verbo conjugado, carece de significado y solo transmite información gramatical. Por ejemplo, en "Hemos cantado" la acción la expresa el participio de "cantar". Otros verbos auxiliares del español son "ser" en su construcción pasiva y los verbos empleados en las perífrasis verbales.

En lenguas como el chino o el inglés el verbo tiene muy pocas marcas y apenas existe flexión verbal. Sin embargo, esa situación no es la más común entre las lenguas del mundo y muchas lenguas no aislantes presentan una gran cantidad de variación morfológica en las formas verbales. Dos de las categorías más comúnmente expresadas son el número gramatical y la persona gramatical. El número señala si la forma verbal es singular, plural, dual, etc., y la persona típicamente indica si el verbo corresponde a la primera persona, la segunda o la tercera.

En español, las formas verbales que distinguen la persona son formas personales, y las formas verbales que no la expresan son formas no personales, es decir, el infinitivo, el gerundio y el participio. En español, latín, las lenguas romances y otras lenguas indoeuropeas, tanto el infinitivo como el gerundio poseen formas compuestas. Pero en las lenguas del mundo existe una gran variación sobre las formas marcadas.

El tiempo gramatical es una categoría que se refiere a la referencia temporal (relativa o absoluta según las lenguas), que permite ubicar el orden cronológico de los eventos y acciones. En las lenguas flexivas el tiempo gramatical se refleja usualmente en un conjunto de paradigmas asociados a un conjunto de desinencias, que en conjunto se denominan tiempos verbales.

El tiempo gramatical indica si la acción es pasada (anterior a otra), presente (habitual o simultánea a otra) o futura (posterior a otra) en relación con el momento del habla (presente). En las lenguas indoeuropeas, por ejemplo, los "tiempos verbales" además de expresar el tiempo gramatical, propiamente dicho, también indican el aspecto gramatical y a veces el modo gramatical y otros aspectos relacionados pero que no se refieren estrictamente a la cronología de los sucesos.

El aspecto informa de la perspectiva del hablante ante el desarrollo de la acción verbal.


El modo informa sobre la actitud del hablante ante la acción verbal. En español, la acción verbal es vista de tres formas:


Además de las categorías comúnmente expresadas en lenguas como el español, otras lenguas expresan en el verbo un número mayor de categorías. Por ejemplo en náhuatl el verbo expresa no solamente la persona gramatical del sujeto o agente, sino también incluye formas para expresar el objeto o tema de la acción verbal. En lenguas semíticas muchas formas verbales expresan el género gramatical del sujeto. Muchas lenguas indígenas de América y otros lugares expresan categorías ausentes de las lenguas europeas como son la inclusividad o la evidencialidad.

Los argumentos requeridos por el verbo incluyen el sujeto y los complementos verbales. En diversas lenguas se denominan de manera diferente pero en términos generales un verbo transitivo requiere un complemento directo (ocasionalmente complemento de régimen); algunos ditransitivos requieren también complemento indirecto. El llamado "complemento" circunstancial no es obligatorio en ningún caso, por lo que sintácticamente es un adjunto del sintagma verbal.

Semánticamente el complemento directo suele asumir un papel temático de paciente o tema, mientras que el complemento indirecto suele recibir un papel temático de beneficiario o recipiente. En español y otras lenguas, algunos verbos requieren complementos obligatorios con papeles temáticos diferentes o expresan ese complemento mediante un complemento de régimen.

Los complementos circunstanciales no son argumentos verbales ya que pueden omitirse, pero cuando están presentes completan el significado de la predicación expresando modo, lugar, tiempo, etc. Estos son adjuntos frecuentemente introducidos por adposiciones o son realizados por adverbios de modo, tiempo y lugar.

La diátesis gramatical tiene que ver con el número de argumentos requeridos por el verbo o valencia del verbo. Muchos verbos requieren solo un argumento (intransitivos) cuyo papel temático frecuentemente es un experimentador. Otros verbos que requieren entre sus argumentos un agente frecuentemente son transitivos y requieren además un paciente o tema.

En español algunos de los verbos que requieren un agente como uno de sus argumentos pueden aparecer en diátesis transitivas o intransitivas:

Otros verbos transitivos del español son rígidamente intransitivos y no admiten esta duplicidad de diátesis:
La segunda oración no es directamente interpretable sin inferencias pragmáticas adicionales, ya que devorar no admite aquí una diátesis intransitiva.

Las lenguas del mundo presentan procedimientos morfológicos que pueden alterar la valencia del verbo entre ellos:



Además de requerimientos de orden sintáctico, la aparición de un verbo en una frase puede estar ligada por concordancia gramatical. Esto significa que en muchas lenguas se requiere que el verbo tenga una u otra forma en función de otros constituyentes sintácticos que le preceden o le siguen.

En español el verbo concuerda con el sujeto:

En cambio en otras lenguas como el euskera hay concordancia con el "sujeto" y "objeto":

En gramática tradicional se concibe el verbo como la palabra principal del predicado en la oración. Como designar y predicar son funciones básicas de toda lengua humana, todas las lenguas poseen verbos. Típicamente muchas lenguas diferencian entre dos grandes clases de categorías léxicas: en la primera estarían básicamente los nombres y en la segunda los verbos, aunque en algunas pocas lenguas estas clases no son disjuntas. Los adjetivos en algunas lenguas son tratados de manera similar a los nombres y en otras de manera más similar a verbos estativos. La predicación verbal típicamente incluye un conjunto de categorías primarias como la persona gramatical, el tiempo gramatical, el aspecto gramatical, y en muchas lenguas también categorías secundarias como género y número, aunque algunas de estas categorías pueden faltar en cada lengua concreta. Por ejemplo en las lenguas indoeuropeas, a diferencia de lo que pasa en lenguas semíticas, el verbo no incluye distinciones de género.

En español constituye la clase de palabra flexivamente más variable y está constituido por un lexema, así como morfemas de número y persona en su periferia, y de modo, voz (activa o pasiva), aspecto e infijo de vocal temática entre el lexema y aquellos. Admite morfemas derivativos (afijos) de distintas significaciones.

Dependiendo del tipo de lengua de que se trate, los verbos pueden variar de forma. Además, el verbo puede concordar en género, persona y número con algunos de sus argumentos o complementos (a los que normalmente se conoce como sujeto, objeto, etc.). En español concuerda con el sujeto siempre en número y casi siempre en persona (la excepción es el caso del llamado sujeto inclusivo: "Los españoles somos así"), y bastantes veces con el atributo de los verbos copulativos.

Las lenguas en las que los verbos son conjugados se denominan flexivas y cada una determina un patrón específico de conjugación, difiriendo notablemente de un sistema lingüístico a otro. En el caso de la lengua española, que es flexiva, la mayoría de los verbos se conjugan de forma regular según tres patrones únicos (conjugaciones) definidos según la vocal temática (1.ª o en "-ar", 2.ª o en "-er"; 3.ª o en "-ir"):

Las formas verbales además varían según su voz, según si son formas personales o no personales, según el tiempo-modo-aspecto, según número y persona (en español estas dos categorías están a sujetas a concordancia con el sujeto). Otros patrones de conjugación menos generales son denominados de verbos irregulares. Junto a este tipo de conjugación, existe además otro tipo de conjugación regular mediante estructuras analíticas llamadas perífrasis verbales, que expresan modos y aspectos más precisos y concretos que no aparecen recogidos en la conjugación regular, que es más general. Como la terminación es distinta para cada persona, el uso de pronombres sujeto se considera a menudo redundante.

El verbo presenta rasgos razonablemente comunes en todas las lenguas indoeuropeas: conjugación basada en la persona, el número y el tiempo-modo-aspecto, pero no en el género, la evidencialidad o la existencia de derivación que cambia la valencia de tipo causativo, aplicativo, etc. Sin embargo, a pesar de estas características extendidas existen diferencias no desdeñables en los sistemas verbales de las lenguas indoeuropeas.

En otros idiomas, como por ejemplo el francés, los verbos tienen terminaciones distintas para cada persona, pero debido a su particular ortografía, muchas de ellas son homófonas, por lo que el pronombre sí se considera necesario. En inglés se presenta una situación similar por lo que en general se requiere sujeto explícito.

En chino el verbo tiene siempre la misma forma y no tiene variación según persona, número, aspecto, tiempo o voz. Tanto el aspecto (perfecto o imperfecto), el tiempo (futuro) como la voz (pasiva) se expresan mediante partículas auxiliares sin afectar a la forma del verbo. La ausencia de marcas de persona o de concordancia en el verbo obligan a que en toda oración sin sujeto léxico deba aparecer un pronombre tónico para indicar la persona.

Los verbos del japonés, por otra parte, no se conjugan con la persona ni el número, por lo que expresiones como "nihongo no hon wo yondeimasu" pueden interpretarse como "Estoy leyendo un libro de japonés", "Están leyendo un libro de japonés" o cualquier persona o número, dependiendo del contexto.

Además en chino, japonés y otras lenguas, los adjetivos son de hecho verbos estativos.

Un número significativo de lenguas africanas de la familia Níger-Congo fuera del grupo bantú son altamente analíticas por lo que de manera similar a lo que sucede en chino, la conjugación de los verbos se realiza mediante partículas que pueden entenderse como auxiliares. Esto sucede tanto en las lenguas mandé como en el yoruba.

Algunas lenguas amerindias como el náhuatl (familia utoazteca) o el Xwlemi (familia salish) no presentan diferencia formal entre nombres y verbos, pudiendo cualquier raíz que funciona como nombre conjugarse según la persona gramatical. Esta situación es similar a la del chino donde los adjetivos son de hecho verbos estativos, solo que en varias lenguas amerindias también los nombres comunes pueden ser considerados verbos estativos.

Desde el punto de vista sintáctico, un verbo con diátesis transitiva o verbo transitivo requiere dos participantes: un participante de tipo A (sujeto-agente) y un participante de tipo O (objeto-paciente). Por el contrario, los verbos intransitivos requieren un único participante. En las lenguas nominativo-acusativas el segundo participante requerido sintácticamente es un complemento directo, mientras que en las lenguas ergativas sería un complemento ergativo. Una misma raíz verbal puede ser en algunas oraciones intransitiva y en otras oraciones transitiva. Los siguiente son ejemplos en español:

Los verbos transitivos son aquellos que exigen la presencia de un objeto directo (también llamado "complemento directo") para tener un significado completo; esto es, que se refieren a acciones que "transitan" desde el actor al objeto (véase transitividad). Un ejemplo de esta categoría en español es:

Aquí, el grupo compuesto por "dos entradas para la ópera" representa el objeto directo. La construcción "He conseguido..." no tiene sentido por sí misma, y requiere que se aporte información sobre lo que se consigue. Por regla general, los verbos transitivos son de la forma "alguien hace algo a algo".

Los verbos intransitivos no admiten o no van acompañados de CD, no requieren de la presencia de un objeto directo que determine al verbo. Un ejemplo en español es el verbo "delinquir", por ejemplo en la oración:

Se trata de un verbo intransitivo, ya que no requiere especificar un objeto directo, por lo tanto, el concepto de ""delinquir algo"" no tiene sentido en español. En general en español y otras lenguas los verbos no son en sí mismos transitivos o intransitivos, sino que se convierten en tales según su uso concreto, y así es posible usar verbos típicamente intransitivos como transitivos, por ejemplo en "La soprano canta una ópera", y también expresar verbos transitivos sin la presencia de un objeto directo, por ejemplo en "Déjaselo al técnico, que él seguro" ["que"] "entiende."

Son pocos los verbos intransitivos en el castellano al compararlo con idiomas con fuerte división entre verbos transitivos e intransitivos. En general, el castellano dispone de la forma autorreflexiva se para denotar intransitividad, como por ejemplo "se rompió", "se caerá", etc.

Los verbos irregulares son aquellos que poseen conjugaciones particulares. Las irregularidades morfológicas de cualquier tipo son más comunes en los idiomas fusionales, menos en los aglutinantes y prácticamente no existen en los aislantes.

Los verbos regulares son, por el contrario, aquellos que se atienen estrechamente a los paradigmas o modelos de conjugación más usados en la lengua.

En español las irregularidades se presentan diferenciadas en los llamados "tiempos verbales primitivos", que son el presente del modo indicativo ("Yo quepo"), el pretérito perfecto simple del indicativo ("Yo cupe") y el futuro simple del mismo modo ("Yo cabré"); es posible determinar si un verbo es o no irregular conjugándolo en esos tres tiempos y viendo si se atiene a las reglas de conjugación a las que se adaptan los demás verbos.

En español, la irregularidad de un verbo simple cualquiera generalmente se mantienen en la conjugación de los verbos que de él se deriven, aunque hay excepciones. Ejemplos:

Entre las excepciones, la más común es la que se aprecia en los derivados del verbo "decir" ("maldecir" y "bendecir"), que en el futuro del modo indicativo no se conjugan como "maldiré" y "bendiré" (que es lo que se supondría según la regla) sino "maldeciré" y "bendeciré".

Los verbos regulares son aquellos que se atienen estrechamente a los modelos de conjugación. En español hay tres de esos paradigmas: la primera conjugación, cuyos infinitivos terminan en -ar; la segunda, en la que terminan en -er y la tercera, en la que terminan en -ir. Dentro de la conjugación regular puede considerarse también una conjugación extendida por medio de perífrasis verbales que señalan distintos tipos de aspecto y modo verbal.

En español se distingue entre verbos impersonales propios (también llamados "unipersonales"), y los impropios.


o en frases como

En este segundo ejemplo está siendo usado como verbo impersonal. Los verbos impersonales impropios del español son:

Son verbos que por lo general solamente se conjugan en tercera persona del singular o del plural, como "acaecer" (algo "acaece", las cosas "acaecen", pero normalmente ni yo ni nosotros ni tú ni vosotros realizan esa acción). La mayoría de estos verbos, por razones lógicas, se refieren a fenómenos meteorológicos.

Ejemplos: "llover", "tronar", "granizar", "relampaguear", diluviar, "nevar".

→ Las oraciones con verbos meteorológicos carecen de sujeto. Ejemplo: "Anoche llovió muy fuerte".

Los verbos defectivos son aquellos en los que no se cumple el paradigma de conjugación completo. Para estos verbos no existen conjugaciones en algunos tiempos y personas, principalmente debido a razones de eufonía o de uso.

Algunos ejemplos de verbos defectivos en español son:

En latín los verbos meteorológicos ("pluit" 'llueve', "tonat" 'truena', "fulgurat" 'relampaguea', "ninguit" 'nieva', son defectivos; aunque también lo son verbos que expresan deber o necesidad ("libet" 'agrada', "licet" 'es lícito', "decet" 'es adecuado', "dedecet" 'no es adecuado', "oportet" 'es necesario', "refert" 'importa', etc.) y otros que expresan sentimiento ("piget" 'tener pena', "poenitet" 'arrepentir', "miseret" 'tener compasión', etc.).

En español los verbos copulativos son "ser, estar, parecer", además de otros verbos que en ciertos contextos son copulativos, como "resultar, seguir, semejar, asemejar, permanecer, continuar".

Son los verbos que no aportan un significado pleno, solo se emplean para unir el sujeto y el predicado. Son aquellos verbos que poseen un significado mínimo, de forma que su presencia o su ausencia no cambian el significado al sujeto y por ello son casi prescindibles (diciendo "la casa es azul" diríamos prácticamente lo mismo que diciendo "La casa azul"); por ello, en vez de seleccionar objetos directos afectados por el verbo, rigen un tipo de complementos diferentes llamados atributos oracionales, que son mutables o sustituibles por el pronombre átono "lo". Los atributos oracionales pueden ser de dos tipos:


En el análisis morfosintáctico, los atributos se marcan como determinantes tanto del verbo que lo rige como de aquello que determina, esté esto en el sujeto o en el predicado. Es importante hacer notar que no solo los verbos copulativos exigen atributos.

En español, las formas verbales se agrupan en diferentes tiempos verbales y tres modos. Además de tres formas impersonales, las cuales no tienen tiempo o modo: el infinitivo, el participio y el gerundio.
Los tres modos existentes son modo indicativo, el modo subjuntivo y el modo imperativo, en los cuales hay diferentes formas verbales:


Zeno Vendler propuso que los verbos también pueden clasificarse semánticamente, de acuerdo con el tipo de proceso que denotan.





</doc>
<doc id="45607" url="https://es.wikipedia.org/wiki?curid=45607" title="Red de área local inalámbrica">
Red de área local inalámbrica

Una red de área local inalámbrica, también conocida como WLAN (del inglés "wireless local area network"), es un sistema de comunicación inalámbrico para minimizar las conexiones cableadas.

Las redes de área local inalámbrica utilizan las ondas de radio para llevar la información de un punto a otro sin necesidad de un medio físico guiado. Al hablar de ondas de radio nos referimos normalmente a portadoras de radio, sobre las que va la información, ya que realizan la función de llevar la energía a un receptor remoto. Los datos a transmitir se superponen a la portadora de radio y de este modo pueden ser extraídos exactamente en el receptor final. 

A este proceso se le llama modulación de la portadora por la información que está siendo transmitida. Si las ondas son transmitidas a distintas frecuencias de radio, varias portadoras pueden existir en igual tiempo y espacio sin interferir entre ellas. Para extraer los datos el receptor se sitúa en una determinada frecuencia, frecuencia portadora, ignorando el resto. En una configuración típica de LAN (con cable) los puntos de acceso (transceiver) conectan la red cableada de un lugar fijo mediante cableado normalizado. El punto de acceso recibe la información, la almacena y la transmite entre la WLAN y la LAN cableada. Un único punto de acceso puede soportar un pequeño grupo de usuarios y puede funcionar en un rango de al menos treinta metros y hasta varios cientos. El punto de acceso (o la antena conectada al punto de acceso) es normalmente colocado en alto pero podría colocarse en cualquier lugar en que se obtenga la cobertura de radio deseada. El usuario final accede a la red WLAN a través de adaptadores. Estos proporcionan una interfaz entre el sistema de operación de red del cliente (NOS: Network Operating System) y las ondas, mediante una antena. 

La naturaleza de la conexión sin cable es transparente a la capa del cliente.

Pueden ser de muy diversos tipos y tan simples o complejas como sea necesario. La más básica se da entre dos ordenadores equipados con tarjetas adaptadoras para WLAN, de modo que pueden poner en funcionamiento una red independiente siempre que estén dentro del área que cubre cada uno. Esto es llamado red de igual a igual (peer to peer). Cada cliente tendría únicamente acceso a los recursos del otro cliente pero no a un servidor central. Este tipo de redes no requiere administración o preconfiguración. 

Instalando un Punto de Acceso se puede doblar la distancia a la cual los dispositivos pueden comunicarse, ya que estos actúan como repetidores. Desde que el punto de acceso se conecta a la red cableada cualquier cliente tiene acceso a los recursos del servidor y además gestionan el tráfico de la red entre los terminales más próximos. Cada punto de acceso puede servir a varias máquinas, según el tipo y el número de transmisiones que tienen lugar. 
Los puntos de acceso tienen un alcance finito, del orden de 150 m en lugares o zonas abiertas. En zonas grandes como por ejemplo un campus universitario o un edificio es probablemente necesario más de un punto de acceso. La meta es cubrir el área con células que solapen sus áreas de modo que los clientes puedan moverse sin cortes entre un grupo de puntos de acceso. Esto es llamado "roaming".

Para resolver problemas particulares de topologías, el diseñador de la red puede elegir usar un Punto de Extensión (EP) para aumentar el número de puntos de acceso a la red, de modo que funcionan como tales pero no están enganchados a la red cableada como los puntos de acceso. Los puntos de extensión funcionan como su nombre indica: extienden el alcance de la red retransmitiendo las señales de un cliente a un punto de acceso o a otro punto de extensión. Los puntos de extensión pueden encadenarse para pasar mensajes entre un punto de acceso y clientes lejanos de modo que se construye un puente entre ambos. 

Uno de los últimos componentes a considerar en el equipo de una WLAN es la antena direccional. Por ejemplo: si se quiere una Lan sin cable a otro edificio a 1 km de distancia. Una solución puede ser instalar una antena en cada edificio con línea de visión directa. La antena del primer edificio está conectada a la red cableada mediante un punto de acceso. Igualmente en el segundo edificio se conecta un punto de acceso, lo cual permite una conexión sin cable en esta aplicación.

Los estándares 802.11a y 802.11g utilizan la banda de 2,4-2,5 Ghz. En esta banda, se definieron 11 canales utilizables por equipos WIFI, los cuales pueden configurarse de acuerdo a necesidades particulares. Sin embargo, los 11 canales no son completamente independientes (canales contiguos se superponen y se producen interferencias) y en la práctica sólo se pueden utilizar 3 canales en forma simultánea (1, 6 y 11). Esto es correcto para USA y muchos países de América Latina, pues en Europa, el ETSI ha definido 13 canales. En este caso, por ejemplo en España, se pueden utilizar 4 canales no-adyacentes (1, 5, 9 y 13). Esta asignación de canales usualmente se hace sólo en el punto de acceso, pues los “clientes” automáticamente detectan el canal, salvo en los casos en que se forma una red ad hoc o punto a punto cuando no existe punto de acceso.

Uno de los problemas de este tipo de redes es precisamente la seguridad ya que cualquier persona con una terminal inalámbrica podría comunicarse con un punto de acceso privado si no se disponen de las medidas de seguridad adecuadas. Dichas medidas van encaminadas en dos sentidos: por una parte está el cifrado de los datos que se transmiten y en otro plano, pero igualmente importante, se considera la autenticación entre los diversos usuarios de la red. En el caso del cifrado se están realizando diversas investigaciones ya que los sistemas considerados inicialmente se han conseguido descifrar. Para la autenticación se ha tomado como base el protocolo de verificación EAP (Extensible Authentication Protocol), que es bastante flexible y permite el uso de diferentes algoritmos.

Otro de los problemas que presenta este tipo de redes es que actualmente (a nivel de red local) no alcanzan la velocidad que obtienen las redes de datos cableadas.

Además, en relación con el apartado de seguridad, el tener que cifrar toda la información supone que gran parte de la información que se transmite sea de control y no información útil para los usuarios, por lo que incluso se reduce la velocidad de transmisión de datos útiles y no se llega a tener un buen acceso.



</doc>
<doc id="45617" url="https://es.wikipedia.org/wiki?curid=45617" title="Mecánica lagrangiana">
Mecánica lagrangiana

La mecánica lagrangiana es una reformulación de la mecánica clásica introducida por Joseph-Louis de Lagrange en 1788. En la mecánica lagrangiana, la trayectoria de un objeto es obtenida encontrando la trayectoria que minimiza la acción, que es la integral del lagrangiano en el tiempo; siendo este la energía cinética del objeto menos la energía potencial del mismo. 

La formulación lagrangiana simplifica considerablemente muchos problemas físicos. Por ejemplo, los sistemas de referencia inerciales son tratados en pie de igualdad y a diferencia de las leyes de Newton la forma de las ecuaciones del movimiento no depende del sistema de referencia elegido. 

La utilidad de la formulación lagrangiana se aprecia incluso en ejemplos sencillos. Por ejemplo, considere una cuenta en un aro. Si se calculara el movimiento de la cuenta usando la mecánica newtoniana, se obtendría un sistema complicado de ecuaciones que considerarían las fuerzas que el aro ejerce en la cuenta en cada instante.

En cambio, en la aproximación de Lagrange, uno mira todos los movimientos posibles que la cuenta podría tomar en el aro y encuentra matemáticamente el que reduce al mínimo la acción. Hay muy pocas ecuaciones puesto que no se está calculando directamente la influencia del aro en la cuenta en un instante dado.

Otro ejemplo es el caso del estudio de movimientos referidos a un sistema que gira, como por ejemplo observaciones astronómicas vistas desde el planeta Tierra: en la formulación newtoniana es necesario introducir a mano las fuerzas ficticias o fuerzas de inercia como la fuerza centrífuga o el efecto Coriolis mientras que en la formulación lagrangiana estas fuerzas aparecen de modo natural.

Los dos problemas considerados anteriormente son mucho más sencillos de resolver empleando la formulación lagrangiana.

Las ecuaciones del movimiento en mecánica lagrangiana son las "ecuaciones de Lagrange", también conocidas como las ecuaciones de Euler-Lagrange. Debajo, bosquejamos la derivación de la ecuación de Lagrange de las leyes de Newton del movimiento. Vea las referencias para derivaciones más detalladas y más generales. 
En su forma más general, en que se da un sistema de referencia general con coordenadas generalizadas (formula_1) las ecuaciones de Lagrange toman la forma:
Considere una sola partícula con masa "m" y el vector de posición r. La fuerza aplicada, F, si es una fuerza conservativa puede ser expresada como el gradiente de una función potencial escalar "V"(r, "t"):

tal fuerza es independiente de las terceras derivadas de r (o de derivadas de orden superior), por tanto la segunda ley de Newton forma un sistema de 3 ecuaciones diferenciales ordinarias de segundo orden. Por lo tanto, el movimiento de la partícula se puede describir totalmente por 6 variables independientes, o "grados de libertad". Un sistema obvio de variables es {r, r′ | j = 1, 2, 3}, las componentes cartesianas de r y sus derivadas temporales, en un instante dado del tiempo.

Más generalmente, podemos trabajar con un sistema de coordenadas generalizadas y de sus derivadas temporales, las velocidades generalizadas: {"q", "q"′}. r está relacionado con las coordenadas generalizadas por cierta "ecuación de transformación":

Considere un desplazamiento arbitrario δr de la partícula. El trabajo hecho por la fuerza aplicada "F" es δ"W" = F · δr. que usa la segunda ley de Newton, escribimos: 
puesto que el trabajo es una cantidad escalar física, debemos poder reescribir esta ecuación en términos de las coordenadas y de las velocidades generalizadas. En el lado izquierdo,

El lado derecho es más difícil, pero después de algunas maniobras obtenemos:
= \sum_i \left[{d \over dt}{\partial T \over \partial q'_i}-{\partial T \over \partial q_i}\right]\delta q_i
Donde formula_2 es la energía cinética de la partícula. Nuestra ecuación para el trabajo hecho se convierte en

sin embargo, ésta debe ser verdad para "cualquier" conjunto de desplazamientos generalizados δ"q", así que debemos tener

para "cada" coordenada generalizada δ"q". Podemos simplificar aún más esto observando que "V" es una función solamente de r y "t", y r es una función de las coordenadas generalizadas y "t". Por lo tanto, "V" es independiente de las velocidades generalizadas:

Insertando esto en la ecuación precedente y substituyendo "L" = "T" - "V", obtenemos las ecuaciones de Lagrange: 

Hay una ecuación de Lagrange para cada coordenada generalizada q. Cuando q = r (es decir las coordenadas generalizadas son simplemente las coordenadas cartesianas), es inmediato comprobar que las ecuaciones de Lagrange se reducen a la segunda ley del Newton. 

La derivación antedicha se puede generalizar a un sistema de "N" partículas. Habrá 6"N" coordenadas generalizadas, relacionadas con las coordenadas de posición por 3"N" ecuaciones de transformación. En cada una de las 3"N" ecuaciones de Lagrange, "T" es la energía cinética total del sistema, y "V" la energía potencial total. 

En la práctica, es a menudo más fácil solucionar un problema usando las ecuaciones de Euler-Lagrange que las leyes de Newton. Esto es porque las coordenadas generalizadas apropiadas "q" se pueden elegir para aprovechar las simetrías en el sistema.

La acción, denotada por "S", es la integral temporal del lagrangiano: 
Sean "q" y "q" las coordenadas en los instantes inicial y final, "t" y "t" respectivamente. Usando el cálculo de variaciones, se puede mostrar que las ecuaciones de Lagrange son equivalentes al principio de Hamilton: 

Por estacionario, significamos que la acción no varía en el primer orden para las deformaciones infinitesimales de la trayectoria, con los puntos límites ("q", "t") y ("q", "t") fijados. El principio de Hamilton se puede escribir como: 

Así, en vez de pensar en partículas que aceleran en respuesta a fuerzas aplicadas, uno puede pensar en ellas seleccionando la trayectoria con una acción estacionaria. 

El principio de Hamilton es conocido, a veces, como "principio de mínima acción". Sin embargo, esto es una impropiedad: la acción sólo necesita ser estacionaria, y la trayectoria correcta se podría producir por un máximo, punto de ensilladura, o mínimo en la acción.

La formulación más moderna de la mecánica lagrangiana se realiza con toda generalidad sobre una variedad diferenciable llamada espacio fásico Γ que se construye como el fibrado tangente del llamado espacio de configuración.

Sobre el espacio fásico de dimensión 2"N", , siendo "N" el número de grados de libertad, se define una función lagrangiana, que puede expresarse en términos de una carta local de coordenadas sobre ℝ:

El hamiltoniano, denotado por "H", es obtenido ejecutando una transformación de Legendre en el lagrangiano. El hamiltoniano es la base para una formulación alternativa de la mecánica clásica conocida como mecánica hamiltoniana. Es una cantidad particularmente ubicua en la mecánica cuántica. 

En 1948 Feynman descubrió la formulación por integral de caminos extendiendo el principio de menor acción a la mecánica cuántica. En esta formulación, las partículas recorren cada trayectoria posible entre los estados iniciales y finales; la probabilidad de un estado final específico es obtenida sumando sobre todas las trayectorias posibles que conduce a él. En el régimen clásico, la formulación por integral de trayectorias reproduce evidentemente el principio de Hamilton.





</doc>
<doc id="45627" url="https://es.wikipedia.org/wiki?curid=45627" title="Ixotecuhtli">
Ixotecuhtli

Ixotecuhtli en la mitología mexica es el dios libre, o de la libertad. Su característica es que es tan rápido como el viento, y puede atravesar las paredes; Según Sahagún es un dios popular muy antiguo, quizás proveniente de los Toltecas, se le representa con alas azules.


</doc>
<doc id="45628" url="https://es.wikipedia.org/wiki?curid=45628" title="Hipónimo">
Hipónimo

En semántica lingüística, se denomina hipónimo a la palabra que posee todos los rasgos semánticos, o semas, de otra más general -su hiperónimo- pero que en su definición añade otras características semánticas que la diferencian de ésta (del hiperónimo). Por ejemplo, los hipónimos de "día" son: lunes, martes, miércoles, etc. Es decir, son palabras que poseen todos los rasgos semánticos y añaden otras características para diferenciarlas de esta.

El término deriva del griego υπονύμιον, compuesto por la preposición ὑπό ("hipó"): "bajo", "debajo", y del sustantivo ὄνομα ("noma"): "nombre", que se le da a la disciplina filológica que estudia el origen de las palabras y la evolución de su forma y significado es algo muy importante para las personas.

"Descapotable" (o "convertible") es hipónimo de "coche" (el hiperónimo), ya que comparte todos los rasgos mínimos de este medio de transporte; a saber: vehículo + con motor + pequeño tamaño, etcétera, pero a estos atributos agrega la cualidad de capota abatible.

Otros ejemplos:
a) días (de la semana);
b) muebles; 
c) frutas; 
d) árboles.
a) mañana, lunes, etc.; 
b) escritorios, mesas, sillas, etc.; 
c) manzanas, peras, plátanos,etc.
d) cedro, pino, roble, etc.

En el mundo de las tecnologías de información, el símil se podría encontrar en la orientación a objetos, donde el hipónimo es una clase (u objeto, según sea el caso); el hiperónimo, la superclase.



</doc>
<doc id="45629" url="https://es.wikipedia.org/wiki?curid=45629" title="Leopoldo II de Bélgica">
Leopoldo II de Bélgica

Leopoldo II, cuyo nombre de nacimiento era Leopoldo Luis Felipe María Víctor de Sajonia-Coburgo-Gotha (Léopold Louis Philippe Marie Victor de Saxe-Cobourg et Gotha; Bruselas, Bélgica, 9 de abril de 1835 - 17 de diciembre de 1909) fue el segundo rey de los belgas. Sucedió a su padre, Leopoldo I, en el trono de Bélgica en 1865 y permaneció hasta su muerte. Reinó durante 44 años, con lo que se convirtió en el reinado más largo de cualquier monarca belga hasta el momento. Murió sin hijos que le sobrevivieran, por lo que su sobrino Alberto sería su sucesor. 

Leopoldo fue el soberano, fundador y único propietario del Estado Libre del Congo desde 1885 hasta 1908, un proyecto privado encabezado por él mismo. Utilizó al explorador Henry Morton Stanley para ayudarle a reclamar el Congo, un área que actualmente ocupa la República Democrática del Congo. En la Conferencia de Berlín de 1884-1885, las naciones europeas con intereses coloniales —que pactaron el reparto de África— se comprometieron a mejorar la vida de los habitantes nativos del Congo, al tiempo que confirmaron su posesión por parte de Leopoldo II. Sin embargo, desde un principio el monarca ignoró estas condiciones y amasó una gran fortuna gracias a la explotación de los recursos naturales del Congo —caucho, diamantes, marfil y otras piedras preciosas— y la utilización de la población nativa como mano de obra forzada y esclava.

Su régimen africano fue responsable de la muerte de entre 2 y 15 millones de congoleños. Bertrand Russell estimó el número de víctimas en 8 millones de personas, mientras que el censo realizado por Bélgica en 1924 mostró que la población durante el Estado Libre de Leopoldo había descendido en un 50 %, 10 millones de personas. Sin embargo, diversos historiadores argumentan contra esta cifra debido a la ausencia de censos fiables, a la enorme mortalidad de las enfermedades como la viruela o la enfermedad del sueño y al hecho de que en 1900, solo había 3000 europeos en el Congo, de los cuales solo la mitad eran belgas.

Tras varios años de denuncias internacionales por parte de personalidades británicas como Arthur Conan Doyle (que sin embargo defendió la Guerra de los Bóeres), Joseph Conrad o Roger Casement; y del líder socialista belga Émile Vandervelde, entre otros, el Estado belga se hizo cargo de la administración del Congo en 1908. En la actualidad el papel de Leopoldo II en África sigue siendo controvertido entre los historiadores. Si el escritor Adam Hochschild asegura que en el Congo se produjo un genocidio con 10 millones de víctimas, David Van Reybrouck considera que no se puede hablar de un genocidio, ya que no hubo una aniquilación consciente y planificada, sino "una política de explotación desenfrenada y una búsqueda patológica de beneficios". Asimismo la biógrafa Barbara Emerson afirma que "Leopoldo no empezó ningún genocidio. Era avaro y se desinteresó cuando las cosas se descontrolaron en el Congo"; el soberano no habría sido un monstruo, sino un calculador obcecado por las vastas riquezas de su colonia que sucumbió "a un aterrador ejemplo de decadencia moral".

Leopoldo fue el segundo hijo nacido del matrimonio de Leopoldo I, primer rey de los belgas, y la reina Luisa de Orleans, hija del rey francés Luís Felipe I. Nació el 9 de abril de 1835 en el Palacio Real de Bruselas, y fue bautizado con el nombre (en francés) de "Léopold Louis-Philippe Marie Victor" de Sajonia-Coburgo y Gotha. El nombre de "Louis-Philippe" le fue puesto en recuerdo a su abuelo materno, el rey Luis Felipe I de Francia, y de su hermano mayor Luis Felipe, nacido en 1833 y muerto en la cuna en 1834. Leopoldo tuvo otros dos hermanos, Felipe, conde de Flandes (1837-1905) y Carlota, emperatriz de México (1840-1927).

Su nacimiento fue una gran esperanza de continuidad para la joven nación belga, independiente desde 1830. La falta de reconocimiento de la soberanía belga por parte de las principales potencias europeas, como Austria y Rusia, amenazaba su sostenibilidad. Si Bélgica quería consolidar su existencia, su rey necesitaba tener un heredero varón de línea directa. No obstante, el muchacho era de complexión débil aunque muy inteligente. En 1840, Leopoldo recibió el título de "", recreado para designar al heredero al trono, del mismo modo su hermano Felipe fue nombrado "conde de Flandes".

La reina Luisa quedó profundamente afectada por la muerte de su padre, Luis Felipe I de Francia, en 1850, que se había visto obligado a exiliarse a Claremont después de la Revolución de 1848. Se resfrió durante un funeral en Bruselas, contrayendo tuberculosis y muriendo prematuramente el 11 de octubre de 1850, en Ostende, a la edad de 38 años. Leopoldo contaba tan solo con 15 años de edad.

Muy afectado por la muerte de su madre, que cuidaba personalmente de los niños de la realeza, Leopoldo y su hermano y hermana se quedaron un tanto solos. Un mes después de la reina Luisa, la reina Victoria de Inglaterra le aconsejó al rey: "Debes mantener a tus hijos lo más cerca posible de ti. Estoy segura de que sería bueno y útil para ti y para ellos".

Leopoldo, duque de Brabante, se convertirá en miembro del Senado belga y participará activamente en importantes debates, especialmente en aquellos relacionados con el establecimiento de un servicio de navegación entre Amberes y el Levante mediterráneo en 1855. El mismo año se quedó con el emperador Napoleón III durante tres semanas en París en motivo de la celebración de la Exposición Universal.

También, siendo joven, ingresó en el ejército belga y realizó numerosos viajes por el mundo, lo que marcaría su política expansionista.

El cambio de régimen en Francia socavó la posición del rey de los belgas, que era yerno del destituido Luís Felipe de Francia por la Revolución de 1848. Para hacer frente a la caída del prestigio de la monarquía belga, el adolescente Leopoldo, duque de Brabante, resultó ser de gran utilidad. Su padre lo llevó por Alemania, Austria, Gotha, Dresde, Berlín y, finalmente, Viena, donde unos días después se anunciaría el compromiso de Leopoldo con la archiduquesa de la secular y católica Casa de Austria, María Enriqueta de Austria. Apenas tres meses después, el 22 de agosto de 1853, y a la edad de 18 años, Leopoldo se casó civilmente, frente al alcalde , en el Palacio Real de Bruselas. Luego lo haría religiosamente en la catedral de Saints-Michel-et-Gudule. Fue un matrimonio por conveniencia, ya que María Enriqueta era prima del emperador Francisco José I de Austria y nieta del emperador Leopoldo II. También era vivaz y enérgica, además de una artista y músico consumada y su belleza le valió el apodo de "La rosa de Brabante". Le apasionaba la equitación hasta el punto de que cuidaba personalmente de sus caballos. El enlace fue objeto de críticas y burlas por parte de quieres afirmaban era un "matrimonio de un palafrenero y una monja", siendo Leopoldo la tímida y retraída monja.

El matrimonio, por razones diplomáticas, fue mal recibido en Francia por Napoleón III, que veía con malos ojos el éxito de la familia real belga, emparentada con la dinastía rival de los Orléans. Después de las nupcias, la joven pareja emprendió el recorrido por las ciudades belgas antes de embarcarse en octubre para una larga estancia en Inglaterra con la reina Victoria, quién después de haberles observado escribió en noviembre de 1853 al rey Leopoldo I: "Creo que no tienes idea de que, para su edad, ella [María Enriqueta] tiene una personalidad excepcional. En todos los temas la encontré particularmente inteligente y sensata, muy educada y muy culta. Todos estos dones le dan una clara superioridad sobre Léo [poldo] y, desafortunadamente, no comparten gustos e ideas entre ellos [...] En política, Léo [poldo] es inagotable. Habla sobre ella bastante bien, lo mismo que sobre cuestiones militares". La diferencia de personalidades entre los jóvenes cónyuges se hizo evidente cuando estuvieron en las Tullerías en 1855. Lady Priscilla de Westmorland escribió: "Se diría que [Leopoldo] tiene dieciséis años. Es un espárrago grande y sin la sombra de una barba: habla mucho, no le falta inteligencia, pero si su cuerpo es demasiado joven, su inteligencia no lo es en absoluto: no habla como un hombre, sino como un viejo. Imagínate la gracia que le debe hacer a su esposa cuando él se da aires de maestro".

De este matrimonio nacieron cuatro hijos, tres hembras y un varón, también llamado Leopoldo. El joven Leopoldo murió en 1869 a la edad de nueve años de neumonía después de caer en un estanque. Su muerte fue fuente de gran dolor para Leopoldo. La felicidad del matrimonio se truncó y la pareja se separó por completo después de un último intento de tener otro hijo, que resultó en el nacimiento de su última hija Clementina. María Enriqueta se retiró permanentemente a Spa en 1895 y allí murió en 1902.

Leopoldo tuvo muchas amantes. En 1899, con 65 años, se enamoró locamente de una de sus amantes, , una joven prostituta francesa de 16 años. La nombró baronesa de Vaughan, y tuvo con ella dos hijos varones (la auténtica paternidad de esos niños nunca fue demostrada). Debido a los regalos y la naturaleza no oficial de su relación, Caroline era profundamente impopular entre el pueblo belga e internacionalmente. Un año antes de su muerte, Leopoldo contrajo con Lacroix un matrimonio morganático, y le legó una fortuna y propiedades inmobiliarias en Bélgica y en Francia. Al año siguiente, poco después de la muerte del rey, Lacroix se casó con su amante, Antoine Durieux, quien adoptó a los hijos.

Bajo Leopoldo II, gracias al gran crecimiento industrial en Valonia entre 1850 y 1870, a la política de neutralidad durante la guerra franco-prusiana y al papel activo jugado por los distintos gobiernos, Bélgica se convirtió en una de las potencias industriales de Europa. Bruselas se transformó en un "pequeño París" acogiendo a exiliados tanto del Segundo Imperio francés como de la Comuna de París.

Durante su reinado el Parlamento aprobó numerosas medidas sociales, como el derecho a crear sindicatos, la prohibición a los niños menores de 12 años de trabajar en las fábricas, la prohibición del trabajo nocturno para los menores de 16 años y de los trabajos subterráneos para las mujeres de menos de 21 años. Se estableció el descanso dominical y una compensación en caso de accidente laboral.

El rey intentó que la Constitución belga de 1885 instaurase el "Referéndum Real", que le hubiese permitido convocar personalmente consultas populares acerca de cuestiones de orden general o sobre leyes ya aprobadas por el Parlamento belga. En este último caso, el Referéndum Real podría haberle suministrado un apoyo popular para negarse a firmar leyes que desaprobaba, lo que equivalía a disponer del derecho de veto. Ante la negativa del Parlamento a contemplar esta posibilidad, Leopoldo estuvo a punto de abdicar.

En el aspecto militar, con tal de mantener la neutralidad del reino y preservarlo de invasiones alemanas o francesas, mandó fortificar el río Mosela y las ciudades de Amberes, Namur y Lieja, asimismo instituyó el servicio militar obligatorio para un hijo por familia (1909).

Bruselas, convertida en un importante centro cultural donde convergían artistas, políticos y pensadores internacionales, experimentó en el último cuarto del siglo XIX un importante desarrollo urbanístico. Leopoldo II, que visitaba con frecuencia las obras, mostró estar interesado y quiso promover no solo la construcción de edificios sino, sobre todo, de grandes espacios urbanos y parques fruto de su interés por la mejora de la condición de vida en las metrópolis modernas. El rey prefirió siempre el clasicismo francés y el estilo Segundo Imperio, pese a que a finales de siglo Bruselas se convirtió en uno de los principales centros del Art Nouveau.

Entre la gran cantidad de obras públicas financiadas en parte por el soberano en Bruselas, caben destacar:


Además, embelleció también la ciudad de Ostende, donde creó el hipódromo y el parque María Enriqueta y la ciudad de Amberes con el Museo Real de Bellas Artes o la Estación de Antwerpen—Centraal.
Leopoldo II también constituyó un inmenso patrimonio personal en las Ardenas, con 6700 hectáreas de bosques y fincas agrícolas, un campo de golf y los castillos de Ciergnon, Fenffe, Villers-sur-Lesse y Ferage; así como lujosas propiedades en la Costa Azul francesa, destacando la monumental Villa Leópolda (1902) en Villefranche-sur-Mer y la Villa Les Cèdres con su jardín botánico anexo (1904) en Saint-Jean-Cap-Ferrat.

Si bien es cierto que muchos de estos proyectos fueron financiados con los enormes beneficios que Leopoldo II sacó de el Congo, hay que destacar que muchos de ellos vieron la luz antes que la colonia fuera adquirida en 1885, como el faraónico Palacio de Justicia que fue terminado de 1883.

En 1900, con motivo de su septuagésimo quinto aniversario, Leopoldo II decidió ceder al estado belga gran parte de sus propiedades privadas, fue la llamada "Donation Royale" (Donación Real). El soberano afirmaba que así se aseguraba que éstas no se fragmentaran entre sus herederos y que siguieran estando ligadas a la familia. No en vano sus hijas mayores, Luisa y Estefanía, se habían casado con príncipes extranjeros. Impuso tres condiciones para la cesión: que las propiedades no podían ser vendidas, que debían mantener su aspecto y función y que debían estar a disposición de la Familia Real belga. En 1903, el estado belga aceptó la donación a cambio que los bienes fueran financieramente autónomos.

Los bienes de la Donación se dividieron en cuatro grandes bloques:


La Donación Real fue en origen administrada por un departamento del Ministerio de Finanzas, pero desde 1930 constituye un organismo público autónomo bajo la supervisión del mismo ministerio.

En 1876, Leopoldo convocó y presidió la Conferencia Geográfica de Bruselas que reunía a expertos, exploradores y científicos de seis países europeos. Pretendía establecer normas comunes filantrópicas para proteger el continente africano y sus habitantes de la explotación comercial indiscriminada, dado que con las últimas exploraciones se acababa de abrir África a la penetración europea. Con este fin la Conferencia decidió crear un organismo permanente, la Asociación Internacional Africana (AIA), presidida por el propio Leopoldo, para promocionar la paz, la civilización, la educación y el progreso científico, y erradicar la trata de esclavos que era una práctica común a buena parte del continente. El mismo año, en el discurso inaugural del comité belga de la AIA, Leopoldo declaraba:

Tres años más tarde, la AIA financió la expedición al río Congo (1879–1884) dirigida por el explorador y aventurero estadounidense Henry Morton Stanley. Stanley fue encargado de conseguir contratos con los jefes indígenas, para que la AIA explotase las regiones descubiertas, convirtiéndolas en "Estados libres". Paralelamente, Bélgica creó la Asociación Internacional del Congo (AIC), cuyos fines presuntamente se relacionaban con el mantenimiento de la paz en las regiones africanas de la cuenca del Congo, pero luego con metas claramente comerciales para explotar productos de las regiones colonizadas.

A raíz de estas iniciativas, Leopoldo fue reconocido en la escena internacional como un benefactor filantrópico digno de admiración, como un hombre de negocios preocupado por temas humanitarios y como el promotor de la política colonial de Bélgica, y lo colocaba a la altura de la del Reino Unido, Francia o Alemania. No es por lo tanto de extrañar que la Conferencia de Berlín (1884-1885) reconociera la creación del Estado Libre del Congo como un territorio perteneciente a Leopoldo a título personal (y no como colonia de Bélgica). Ningún representante indígena fue invitado. 

El Reino de Bélgica abandonó toda responsabilidad sobre el territorio congoleño, como lo confirmará el artículo 62 de la Constitución belga votada en 1885, por lo cual el territorio del Congo quedaba convertido prácticamente en ""propiedad privada"" de Leopoldo II. La explotación de los recursos de la región fue constituida en monopolio "estatal" (a favor del Estado Libre del Congo), y Leopoldo envió un ejército de 16.000 europeos de distintas nacionalidades, pagados por el propio monarca, para controlar la región y convertirla en un campo de trabajos forzados, mediante la esclavitud y la mutilación.

Gracias a la colonización del Congo, Leopoldo convirtió a Bélgica en una potencia imperialista y a él mismo en multimillonario. Gracias a los préstamos que le fueron concedidos a Leopoldo por el Estado belga, la AIC creó una red ferroviaria a lo largo del río Congo y de sus afluentes, y abrió carreteras. Después de que John Dunlop inventara los neumáticos de caucho, la demanda mundial del mismo, debido a su uso como materia prima en la industria automovilística y de bicicletas, se había disparado y se inició una carrera comercial internacional para dominar el mercado. 

Para adelantarse a la competencia (que explotaba bosques en América Latina y en el sureste asiático), Leopoldo impuso altas cuotas de producción de caucho en el Congo, y obligó a la población indígena a cumplirlas con métodos coercitivos y la más alta violencia. Para aumentar el ritmo de producción, los agentes del Estado Independiente del Congo cobraban primas en función de las cantidades suplementarias de caucho recolectado, lo que les incitaba a endurecer cada vez más los métodos de presión sobre los trabajadores.

Se calcula que durante los años de dominio de Leopoldo sobre el Congo murieron unos diez millones de nativos. El historiador Adam Hochschild avanza la misma cifra basándose en investigaciones llevadas a cabo por el antropólogo Jan Vansina a partir de fuentes locales de la época, y estima que de 1885 a 1908 la población congoleña quedó reducida a la mitad por culpa de los asesinatos, el hambre, el agotamiento, las enfermedades y el desplome de la natalidad. El historiador congoleño Ndaywel e Nziem eleva la cifra a 13 millones de muertos, mientras que los historiadores Roger Louis y Jean Stengers consideran que esas cifras no tienen fundamento al no existir datos de población para aquellos años. 

En 1895, el misionero Henry Grattan Guinness supo de los abusos sufridos por la población del Estado Libre del Congo e instaló allí una misión. Obtuvo promesas de mejora de Leopoldo, pero nada cambió. El periodista británico Edmund Dene Morel, exagente de una compañía de navegación encargada del transporte del caucho hacia Europa, y conocedor de las estructuras comerciales establecidas en África del oeste, fue también uno de los primeros en avisar a la opinión internacional sobre los crímenes cometidos, y fue el primero en recolectar pruebas testimoniales y documentales. Sin embargo, hasta 1903, dos años después del fallecimiento de la reina Victoria, prima de Leopoldo, la Cámara de los Comunes no adoptó una resolución crítica sobre la gestión del Congo, y encargó al diplomático Roger Casement, nombrado cónsul británico en el Congo, que investigara los hechos. Su informe, conocido como el Informe Casement, se hizo público al año siguiente y tuvo un impacto considerable en la opinión pública. El parlamento británico aprobó una resolución sobre el Estado del Congo —que el gobierno envió a los 14 países firmantes del Tratado de Berlín de 1885— en la que se informaba que los crímenes que supuestamente allí se cometían eran contrarios al espíritu de la Conferencia, y el ministro británico de Asuntos Exteriores pidió en sendos discursos que se revisara la concesión privada del Congo al rey de Bélgica para transferirla al parlamento belga. 

El diputado socialista belga Émile Vandervelde y parte de la oposición parlamentaria consiguieron, en contra de la opinión del rey, que se creara una comisión independiente de investigación, cuyo informe confirmó las observaciones de Casement y Morel. Por su parte, el rey envió su propia comisión de investigación, constituida por funcionarios públicos belgas, que negaron toda clase de abusos y que apoyaron su labor "civilizadora."

Las consecuencias inmediatas de esos informes se limitaron al arresto de algunos soldados del "Estado Libre" acusados del asesinato de centenares de congoleños en 1903. En diciembre de 1906 el rey Leopoldo, bajo la presión internacional, aceptó transferir el Estado del Congo al parlamento belga, pero las negociaciones duraron hasta el 15 de noviembre de 1908, fecha en la que el Parlamento belga asumió su administración. En el intervalo el rey negoció una compensación de 50 millones de francos por sus posesiones en el Congo y se deshizo de todas sus obligaciones en la región, que reinvirtió en propiedades en la Riviera francesa.

Esta cesión se incluyó en el acta conocida como «Donación real» (1903), por la que Bélgica "heredaba" el Congo, así como de la gestión de las inmensas propiedades personales del rey en Bélgica, preservando su disfrute por sus sucesores en el trono y prohibiendo su venta o alteración. Leopoldo justificó el tratado afirmando que, como solo tenía hijas, todas casadas con príncipes extranjeros, no quería que su herencia se desmembrara después de su muerte. La Donación Real es desde 1930 un organismo público autónomo del Estado belga, que gestiona el patrimonio heredado de Leopoldo II. Parte de esos bienes se puso a disposición exclusiva de la Casa real belga, y el Estado asumió su gestión y conservación.

Gran parte de los territorios que Leopoldo II mandó colonizar en África constituyen el actual Estado de la República Democrática del Congo. Bélgica continuó explotando las riquezas del "Congo belga". En los años siguientes a la Donación Real, la administración del Congo siguió en manos de las mismas compañías concesionarias, por lo que el maltrato de la mano de obra congoleña se mantuvo, sin llegar sin embargo a los excesos anteriores.

Después del declive del caucho, tomó especial importancia la explotación minera iniciada por las compañías concesionarias de Leopoldo II, como la Compañía del Katanga, creada en 1891. A partir de 1900, para asegurar el dominio de la compañía frente a la competencia de las compañías mineras británicas y alemanas, el Estado Independiente del Congo y la Compañía del Katanga se unieron en el Comité Especial del Katanga (CSK). Al poco tiempo, un acuerdo firmado personalmente por Leopoldo II y por el empresario británico Robert Williams, propietario de la compañía minera Tangenyika Concession Limited (TCL), creó la Unión Minera del Alto Katanga (UMHK), que gobernó de hecho la región del Katanga hasta su nacionalización por parte del gobierno de la República Democrática del Congo, en 1966.

Leopoldo II murió en 1909 de una hemorragia cerebral. Su sobrino Alberto, hijo de su hermano Felipe de Bélgica, le sucedió en el trono como Alberto I.

Leopoldo y María Enriqueta tuvieron cuatro hijos, de los cuales los dos más jóvenes tienen descendientes que viven a partir de 2018:


Leopoldo también engendró dos hijos con Caroline Lacroix. Fueron adoptados en 1910 por el segundo esposo de Lacroix, Antoine Durrieux. Leopoldo les otorgó títulos de cortesía que eran honorarios, ya que el parlamento no habría apoyado ningún acto o decreto oficial:



Condecoraciones Nacionales


Condecoraciones Internacionales









</doc>
<doc id="45630" url="https://es.wikipedia.org/wiki?curid=45630" title="Hiperónimo">
Hiperónimo

En semántica lingüística, se denomina hiperónimo a aquel término general que puede ser utilizado para referirse a la realidad nombrada por un término más específico. Por ejemplo, "ser vivo" es hiperónimo para los términos "planta" y "animal" (hipónimos).

Semánticamente, un hiperónimo no posee ningún rasgo semántico, o sema, que no comparta su hipónimo, mientras que éste sí posee rasgos semánticos que lo diferencian de aquel.

Por ejemplo, "automóvil" posee solo los semas [+vehículo], [+con motor] y [+pequeño tamaño], que comparte con "descapotable", mientras que "descapotable" posee además el rasgo [+con capota abatible], que lo diferencia de "automóvil".



</doc>
<doc id="45635" url="https://es.wikipedia.org/wiki?curid=45635" title="Geografía de la India">
Geografía de la India

La India es una república federal del Sur de Asia, que comprende —junto a Pakistán, Bangladés y otros países más pequeños— el denominado subcontinente indio o región del Indostán. Es el segundo país más poblado del mundo (después de China) y el séptimo más extenso. Desde el punto de vista geográfico no es una península.

El país se extiende al norte del ecuador entre 8°4' y 37°6' Lat N y 68°7' a 97°25' Long E. Limita al norte con Nepal y Bután; al sur con el estrecho de Palk y el golfo de Mannar, que lo separa de Sri Lanka y el océano Índico; al oeste con el mar Arábigo y Pakistán; al este con Birmania, el golfo de Bengala y Bangladés, que casi separa por completo el noroeste de la India del resto del país. Oficialmente denominada Bharat Ganarajiyá (República de la India, en hindi), es miembro de la Commonwealth. Junto a Jammu y Cachemira (cuyo estatuto jurídico-territorial definitivo aún no se ha determinado), la India tiene una superficie de 3.165.596 km². La capital de la India es Nueva Delhi y la mayor ciudad Bombay (o Mumbai).

Como condiciones climáticas, tanto en el sentido estacional como regional. Esta diversidad varía desde zonas tropicales hasta áreas templadas; las temperaturas más bajas se registran en la zona de la cordillera de los Himalayas. Excepto en las regiones más montañosas, la mayor parte de la India tiene un clima intertropical y subtropical. Las variaciones estacionales, resultado de los monzones sur occidentales y nororientales, influyen mucho en la temperatura, humedad y precipitaciones en todo el subcontinente. De modo general, las estaciones de la India pueden clasificarse como lluviosas y secas. La estación lluviosa, que va desde junio hasta noviembre, es la estación del monzón del suroeste, viento cargado de humedad que sopla desde el océano Índico y el mar Arábigo. El monzón comienza a principios de junio en la costa occidental de la península y afecta gradualmente a casi todo el país. Durante esta estación las lluvias pueden ser muy fuertes (a lo largo de las laderas de los Ghats occidentales a menudo pueden llegar hasta más de 3.175 mm). En Cherrapunji, en los montes Khasi del noreste de la India, las precipitaciones anuales son de unos 10.920 mm. La precipitación media anual a lo largo de las laderas del sur del Himalaya es de unos 1.525 mm. El monzón del suroeste algunas veces reduce su actividad, lo que da lugar a sequías y, como consecuencia, una disminución de la producción que provoca graves situaciones de hambre a la población. No obstante, las lluvias también traen consigo efectos negativos, como por ejemplo la proliferación de los mosquitos portadores de malaria. Otro efecto negativo de carácter climático es el contraste entre las temperaturas diurnas y nocturnas, que puede causar problemas respiratorios. Por lo general, la influencia del monzón disminuye en septiembre.

India ocupa la mayor parte del subcontinente indio, el cual se encuentra encima de la placa tectónica India, una placa menor dentro de la placa Indoaustraliana.

Los procesos geológicos que definieron la situación geográfica actual de la India comenzaron hace setenta y cinco millones de años, cuando el subcontinente indio y, a continuación, parte del supercontinente Gondwana, comenzaron a moverse hacia el noreste, a través de lo que posteriormente se convertiría en el océano Índico. La colisión posterior del subcontinente con la placa Euroasiática y la subducción debajo de ella, dieron lugar a los Himalayas, el sistema montañoso más alto del planeta, que ahora es la frontera de la India en el norte y en el noroeste. En el antiguo lecho marino que emergió inmediatamente al sur del Himalaya, el movimiento de la placa creó una gran depresión, que poco a poco fue llenada de sedimentos propagadas por los ríos, y que actualmente constituye la llanura Indo-Gangética. Al oeste de esta llanura, y separado de ella por la cordillera Aravalli, se encuentra el desierto de Thar.

La placa India original ahora sobrevive como la India peninsular, la parte más antigua y geológica mente más estable de la India, que se extiende tan al norte como las cordilleras de Satura y Vindhya en el centro de la India. Estas cordilleras paralelas van desde la costa del mar Arábigo en el estado de Gujarat, hasta la meseta rica en carbón de Chota Nagpur en el estado de Jharkhand. Hacia el sur, el territorio peninsular restante, la meseta del Decán, está flanqueada a la izquierda y derecha por dos cordilleras costeras, los montes Ghats occidentales y orientales; la meseta contiene las formaciones rocosas más antiguas en la India, algunas con más de mil millones de años de antigüedad. Los puntos extremos de la India se localizan en 6° 44' y 35° 30' de latitud norte y 68° 7' y 97° 25' de longitud este.

El litoral de la India es de 7.517 kilómetros de largo; de esta distancia, 5.423 kilómetros pertenecen a la India peninsular y 2.094 kilómetros a las Islas Andamán, Nicobar y Laquedivas. De acuerdo con las listas de hidrografía navales de la India, la costa continental consiste en: 43 % de playas arenosas, 11% de costas rocosas, incluyendo acantilados, y 46 % marismas o costas pantanosas. Los principales ríos que fluyen sustancialmente a través de la India tienen su origen en los Himalayas, e incluyen el Ganges y el Brahmaputra, que desembocan en la bahía de Bengala. Entre los afluentes más importantes del Ganges se encuentran el Yamuna y el Kosi, cuya pendiente extremadamente baja provoca inundaciones catastróficas cada año. Los ríos peninsulares más importantes cuyas pendientes más empinadas evitan inundaciones son el Godavari, el Mahanadi, el Kaveri y el Krishná, que también desembocan en la bahía de Bengala; y el Narmada y el Tapti, que desembocan en el mar Arábigo. Además, en la costa oeste de la India también se encuentran los pantanos del Rann de Kutch, mientras que del lado este del país se halla el delta del Sundarbans, que India comparte con Bangladés. Adicionalmente, India posee dos archipiélagos: las Laquedivas, atolones de coral en la costa suroeste de India, y las Islas Andamán y Nicobar, una cadena de islas volcánicas en el mar de Andamán.

En el clima de la India influyen fuertemente los Himalayas y el desierto de Thar, que favorecen el desarrollo de los monzones. Los Himalayas previenen la entrada de los fríos vientos catabáticos de Asia Central, manteniendo la mayor parte del subcontinente indio más caliente que la mayoría de las localidades que se ubican en latitudes similares. El desierto de Thar desempeña un papel crucial para atraer los vientos de monzón cargados de humedad desde el suroeste, los cuales entre junio y octubre, proporcionan la mayoría de las precipitaciones del país. Las cuatro principales zonas climáticas que predominan en la India son: el tropical húmedo, el tropical seco, el subtropical húmedo y el montano.

El territorio de la India se encuentra dentro de la ecozona Indomalaya, por lo que presenta una gran muestra de biodiversidad. Como uno de los dieciocho Países Megadiversos, es hogar del 7,6% de todos los mamíferos, del 12,6% de todas las aves, del 6,2% de todos los reptiles, del 4,4% de todos los anfibios, 11,7% de todos los peces y del 6% de fanerógamas existentes en el mundo. En muchas de las ecorregiones del país existen niveles extremadamente altos de endemismo; en general, el 33% de especies de plantas de India son endémicas. 

La cubierta de bosques en India va de la selva tropical de las islas Andamán, los Ghats occidentales y el noreste de India, a los bosques de coníferas del Himalaya. Entre estos extremos se encuentran el bosque caducifolio húmedo de India oriental; el bosque caducifolio seco del centro y sur de la India; y el bosque xerófilo del Decán central y la llanura occidental del Ganges. De acuerdo con el último informe, menos del 12% de la masa continental de la India está cubierto por densos bosques. Entre los árboles más importantes en la India se encuentra el nim medicinal, ampliamente utilizado en las zonas rurales para la herbolaria y la elaboración de remedios caseros. La higuera de pipal, que se muestra en los sellos de Mohenjo-daro, fue el árbol donde, según la tradición, Buda encontró la iluminación.

Muchas especies de India son descendientes de los taxones originarios de Gondwana, del que se desprendió la placa India. El movimiento posterior de la placa hacia la actual India peninsular y la colisión con la masa de tierra de Laurasia, dio inicio a un intercambio masivo de especies. Sin embargo, el vulcanismo y los cambios climáticos de hace 20 millones de años provocaron la extinción de muchas especies endémicas de la India. A partir de entonces, varios mamíferos ingresaron a la India desde Asia a través de dos pasos zoogeográficos a ambos lados de los emergentes Himalayas. En consecuencia, entre las especies indias, sólo el 12,6% de mamíferos y el 4,5% de las aves son endémicas, contrastando con el 45,8% de los reptiles y el 55,8% de anfibios endémicos. Entre las especies endémicas más notables se encuentran el mono de la hoja de Nilgiri y sapo del marrón y carmín de los Ghats occidentales. Además, en India existen 172, ó 2,9 %, especies amenazadas. En éstas se incluyen el león asiático, el tigre de Bengala y el buitre bengalí, que casi llega a la extinción tras ingerir la carroña de ganado tratado con diclofenaco.

En las últimas décadas, las invasiones humanas crearon una amenaza para la vida silvestre de la India, en respuesta, el sistema de parques nacionales y áreas protegidas, establecido por primera vez en 1935, se amplió considerablemente. En 1972, el gobierno de la India promulgó la "Ley de protección de la vida silvestre" y el "Proyecto tigre", para proteger el hábitat crucial de estos animales; además, en 1980 se promulgó la "Ley de conservación de los bosques". Junto con más de quinientos santuarios de vida silvestre, en India existen trece reservas de la Biosfera, cuatro de las cuales son parte de la Red Mundial de Reservas de la Biosfera; además de que 25 humedales están registrados bajo el convenio de Ramsar.



</doc>
<doc id="45638" url="https://es.wikipedia.org/wiki?curid=45638" title="Clitemnestra">
Clitemnestra

En la mitología griega, Clitemnestra o Clitemestra (en griego, Κλυταιμήστρα) fue esposa de Agamenón y reina de Micenas.

Leda fue seducida por Zeus en forma de cisne, pero la misma noche en que yació con él también había yacido con su esposo Tindáreo. Como resultado, puso dos huevos, de uno de los cuales nacieron Cástor y Clitemnestra, que eran hijos de Tindáreo, y del otro, Helena y Pólux, que eran hijos de Zeus. Además, otras hermanas de Clitemnestra eran Febe, Timandra y Filónoe.

Casó en primeras nupcias con Tántalo, hijo de Broteas o, según otras fuentes, de Tiestes. Tras el asesinato de su esposo y su hijo recién nacido a manos de Agamenón, este fue obligado por los Dioscuros a desposarse con Clitemnestra. Como esposa de Agamenón, tuvo cuatro hijos: Electra, Ifigenia, Orestes y Crisótemis. En algunas tradiciones, sin embargo, se decía que Ifigenia era en realidad hija de su hermana Helena y de Teseo, pero había sido criada por ella.

Cuando toda la flota aquea estaba en el puerto de Áulide dispuesta a partir a luchar en la guerra de Troya, Agamenón se había ganado la cólera de la diosa Artemisa. Debido a esto, la flota estaba detenida sin poder partir por la ausencia de vientos favorables. 

El adivino Calcante fue interrogado para saber cómo aplacar a la diosa, y la respuesta fue que se debía sacrificar a la hija más hermosa de Agamenón en nombre de la diosa Artemisa, para que ésta los dejara partir. El rey al principio se negó pero, presionado por su hermano Menelao, tuvo que enviar un mensaje a Clitemnestra para que hiciera enviar a su hija Ifigenia desde Micenas hasta Áulide con el pretexto de casarla con Aquiles. Luego Agamenón trató de impedir el sacrificio enviando secretamente otra carta a Clitemnestra en la que le decía que no enviara a su hija, pero esta carta fue interceptada y no llegó a su destino. Al no haber otra solución, Agamenón consintió en hacer el sacrificio. 

En algunas versiones, Clitemnestra acompañó a su hija en ese viaje. Según cuenta la versión más conocida, cuando Ifigenia llegó y el sacrificio se iba a realizar, la diosa se apiadó de la joven y puso en su lugar una cierva. Se llevó a Ifigenia a Táuride, donde la convirtió en su sacerdotisa. Según cuenta Hesíodo, Artemisa salvó la vida de Ifigenia y la convirtió en la diosa Hécate.

Sin embargo, existen variaciones sobre el tema: según la versión de Sofocles, el sacrificio sí ocurre, y justifica que Clitemnestra, en venganza por la muerte de su hija, mate a Agamenón al volver este de la Guerra de Troya. 

Agamenón había puesto a Clitemnestra bajo la vigilancia de un aedo, pero Egisto, primo de Agamenón, se lo llevó a una isla desierta y sedujo a Clitemnestra, que se convirtió así en su amante. Clitemnestra había sido predispuesta a cometer adulterio debido a que Nauplio había recorrido Grecia para difundir noticias a diversas reinas de que sus maridos estaban tomando concubinas durante la guerra de Troya.

Cuando Agamenón regresó a Micenas, ambos lo asesinaron, mientras este se ponía una túnica que carecía de orificios para los brazos y la cabeza. Luego asesinaron a Casandra, una princesa y adivina troyana que Agamenón había traído consigo. 

Clitemnestra y Egisto reinaron en Micenas y tuvieron una hija, Erígone, pero varios años más tarde murieron a manos de Orestes, que había sido puesto a salvo por su hermana Electra y vengó así la muerte de su padre.

Existía la tradición de que la tumba de Clitemnestra estaba situada, como la de Egisto, en un lugar fuera del recinto de las murallas de Micenas.

A principios del siglo XIX se descubrió fuera de las murallas de Micenas una tumba de cúpula que ha sido datada en el siglo XIII a. C. y que más tarde fue llamada «tumba de Clitemnestra». Esta tumba se encuentra al sudeste del llamado Círculo de tumbas B.








</doc>
<doc id="45643" url="https://es.wikipedia.org/wiki?curid=45643" title="Gelsenkirchen">
Gelsenkirchen

Gelsenkirchen () es una ciudad situada en el estado alemán de Renania del Norte-Westfalia, y más concretamente en la zona norte de la región del Ruhr. 

Las primeras informaciones documentadas de Gelsenkirchen datan de 1150, aunque permaneció en el anonimato propio de un pequeño pueblo hasta el siglo XIX, momento en que gracias la Revolución industrial toda la zona experimentó un crecimiento espectacular. En 1840, fecha del comienzo de la extracción de carbón, apenas 6000 personas residían en Gelsenkirchen; solamente 60 años después, en 1900, la cifra se había multiplicado por 23, alcanzando los 138.000 habitantes.

A principios del siglo XX Gelsenkirchen era la ciudad más importante de Europa en lo que a la minería del carbón se refiere. En esa época era conocida como la "ciudad de los mil fuegos" debido a la gran cantidad de columnas de humo que podían verse sobre ella. En 1928 Gelsenkirchen se fusionó con las ciudades vecinas de Buer y Horst. La conurbación resultante recibió el nombre de Gelsenkirchen-Buer hasta 1930, cuando la denominación fue reducida a Gelsenkirchen. Durante el III Reich Gelsenkirchen siguió siendo un importante centro de producción de carbón y de derivados del petróleo, motivos por los que fue bombardeada por los Aliados en la II Guerra Mundial. Durante dicho conflicto se instaló en ella un campamento para mujeres, subdivisión del campo de concentración de Buchenwald. En el siglo XXI ya no hay minas en Gelsenkirchen y la ciudad busca una nueva imagen representativa después de haberse visto golpeada por una de las mayores tasas de desempleo de toda Alemania. Destacar además que acoge la mayor central eléctrica solar de todo el país. En Gelsenkirchen-Scholven hay una central de carbón que es famosa por contar con las chimeneas más altas de Alemania, alzándose 302 metros del suelo.

Aunque la parte de la ciudad conocida como Buer aparece con el nombre de "Puira" por primera vez en un documento de Heriberto I datado en 1003, se cree que algunos cazadores ya habitaban una colina situada al norte del río Emscher, afluente del Rin, en la Edad de Bronce, incluso antes del año 1000 antes de Cristo. No vivían en casas como tales, sino en pequeñas barracas construidas unas cercanas a las otras. Posteriormente, los romanos invadieron la zona, siendo expulsados por los sajones sobre el 700 de nuestra era. Algunas otras zonas que se encuentran al norte de la ciudad de Gelsenkirchen aparecen mencionadas en documentos medievales, como por ejemplo "Raedese" ("Resse"), Middelvic ("Middelich", parte de Resse), "Sutheim" ("Sutum", parte de Beckhausen) o "Sculven" ("Scholven"). Algunas comunidades de granjeros fueron identificadas más tarde como "iuxta Bure" ("cerca de Buer").

Fue hacia 1150 cuando surgió el nombre de "Gelstenkerken" o "Geilistirinkirkin", coincidiendo más o menos con la construcción de la primera iglesia del pueblo en Buer. Esta "ecclesia Buron" ("iglesia en Buer") aparece en una lista de iglesias parroquiales de Teodorico Deutz. Este asentamiento estuvo bajo el dominio del Condado de Mark.

Hasta mediados del siglo XIX, el área de Gelsenkirchen apenas estaba poblada y sus habitantes se dedicaban principalmente a la agricultura. En 1815, después de haber estado de forma temporal bajo control del Gran Ducado de Berg, la zona pasó a manos de Prusia, que la asignó a su provincia de Westfalia. Mientras que aquel Gelsenkirchen (que no incluía las comunidades de la zona norte antes descritas como Buer) fue integrada en el Amt de Wattenscheid perteneciente al distrito de Bochum y a su vez a la división gubernamental de Arnsberg, Buer se constituyó como un "Amt" en sí mismo englobando a la cercana Horst, quedando incorporado al distrito de Recklinghausen y a su vez al de Münster. Esta distribución territorial no sería anulada hasta 1928.

Tras el descubrimiento de carbón en la región del Ruhr en 1840 y la consiguiente industrialización, fueron inaugurados el servicio ferroviario Colonia-Minden y la Estación Principal de Gelsenkirchen. En 1868, Gelsenkirchen se convirtió en capital de un "Amt" perteneciente al distrito de Bochum y que incluía a Gelsenkirchen, Braubauerschaft (desde 1900, Bismarck), Schalke, Hessler, Bulmke y Hüllen.

Friedrich Grillo fundó la Corporación para la Industria Química ("Aktiengesellschaft für Chemische Industrie") en Schalke en 1872, lugar donde también fundó la Asociación de Minería y Siderurgia ("Schalker Gruben- und Hüttenverein"). Un año más tarde y de nuevo en Schalke, él mismo creó la Compañía de la Fábrica de Cristal y Espejos ("Glas- und Spiegel-Manufaktur AG").

Después de que Gelsenkirchen se convirtiera en un importante centro de la industria pesada, recibió el título de ciudad en 1875.

En 1885, tras la división del distrito de Bochum, Gelsenkirchen pasa a ser capital de su propio "Kreis", situación que se mantendría hasta 1926. En dicho distrito quedaron encuadradas las ciudades de Gelsenkirchen y Wattenscheid, así como las localidades de Braubauerschaft (desde 1900, Bismarck), Schalke, Ückendorf, Wanne y Wattenscheid. Pocos años más tarde, en 1896, Gelsenkirchen fue separada del resto de su distrito para convertirse en "ciudad independiente" ("kreisfreie Stadt"). En 1891, Horst fue segregada del "Amt" de Buer, lugar que a su vez fue declarado ciudad en 1911 y obtuvo su "independencia" como "kreisfreie Stadt" al año siguiente. Mientras tanto, Horst pasó a encabezar su propio "Amt". En 1924, la comunidad rural de Rotthausen, hasta entonces dependiente del distrito de Essen, fue incorporada al de Gelsenkirchen.

En 1928 y como consecuencia de ciertas reformas acometidas por el gobierno prusiano, las ciudades de Gelsenkirchen y Buer fueron fusionadas junto con el "Amt" de Horst en un nuevo "kreisfreie Stadt" llamado Gelsenkirchen-Buer. Desde entonces, la ciudad pasó a pertenecer al distrito gubernamental de Münster. En 1930, por consejo de la propia ciudad, se permitió la recuperación del nombre único de "Gelsenkirchen". En esos momentos la ciudad acogía a unas 340.000 personas.

En 1931, la Compañía Minera de Gelsenkirchen ("Gelsenkirchener Bergwerks-Aktien-Gesellschaft") fundó la Corporación Petrolera "Gelsenberg" ("Gelsenberg-Benzin-AG"). Por su parte la Compañía Minera Hibernia fundó en 1935 la planta de hidrogeneración "Hydrierwerk Scholven AG GE-Buer".

Desde el momento en que los nazis se hicieron con el control del gobierno alemán, Gelsenkirchen, debido a su situación en el corazón de la cuenca del Ruhr, se convirtió en centro de la industria bélica, ya que no había otra ciudad más productiva en todo el país. Por una parte, supuso un importante crecimiento que contrastó con los despidos masivos acometidos por las industrias en los años 20, mientras que por otra la ciudad se convirtió en objetivo principal de los bombarderos aliados durante la Segunda Guerra Mundial, llegando a quedar arrasadas tres cuartas partes. Aún en el siglo XXI pueden encontrarse algunos refugios antiaéreos, incluyendo los sótanos de edificios oficiales como la Hans-Sachs-Haus del centro o el ayuntamiento en Buer.

Dos sinagogas de Gelsenkirchen fueron destruidas tras los disturbios antisemitas de la Kristallnacht el 9 de noviembre de 1938, mientras que la única que había en Buer fue quemada y la del centro de Gelsenkirchen prácticamente arrasada. En la Kristallnacht, los nazis se dedicaron a destruir negocios de judíos, así como sus viviendas y cementerios y a pegar fuego a las sinagogas. Desde 1963 una placa recuerda a los viandantes los hechos. Finalmente, en 1993 el área fue renombrada como "lugar de la vieja sinagoga" para conseguir 66 años después, el 9 de noviembre de 2004, la colocación de la primera piedra del nuevo edificio religioso. El 1 de febrero se abrió el nuevo lugar de culto tras más de un año de obras, de modo que se convirtió en el centro de la comunidad judía de Gelsenkichen. Ofrece capacidad para unos 400 fieles además de un centro comunitario con salas de reuniones. La comunidad judía de Gelsenkirchen cuenta con unos 430 miembros. 

Asimismo, Gelsenkirchen acogió en 1944 un campamento adscrito al campo de concentración de Buchenwald. En las instalaciones de Gelsenberg Benzin AG residieron 2.000 mujeres y niñas húngaras dedicadas a trabajar en la planta de hidrogeneración. Unas 150 de estas judías húngaras murieron en su puesto de trabajo durante los bombardeos de septiembre de 1944 ya que no tenían autorizado el acceso a los refugios.

Durante el tiempo en que Adolf Hitler encabezó el III Reich, entre 1933 y 1945, el alcalde de la ciudad fue Carl Engelbert Böhmer, miembro del NSDAP nombrado para el cargo por el régimen. El Instituto de Historia Local cuenta con una sección completa dedicada a esa etapa bajo el epígrafe "Gelsenkirchen en tiempos del Nacionalsocialismo".

El 17 de diciembre de 1953 entró en servicio el primer horno de coque construido después de la Guerra. Con la implantación del sistema de códigos postales ("Postleitzahlen") en 1961, Gelsenkirchen fue una de las pocas ciudades de Alemania Occidental que fue dividida en dos zonas, Buer con el código 4660 y Gelsenkirchen con el 4650, división vigente hasta el 1 de julio de 1993. La compañía propietaria de la vieja planta de hidrogeneración, Scholven-Chemie AG, se fusionó con Gelsenberg-Benzin-AG en 1987 formando VEBA-Oel AG. En 1987, el Papa Juan Pablo II celebró en el Parkstadion de Gelsenkirchen una misa multitudinaria a la que asistieron 85.000 fieles. El pontífice también fue nombrado en esa visita socio honorífico del FC Schalke 04.

En 1997, la Exposición Federal de Jardines ("Bundesgartenschau" o "BUGA") fue celebrada en los terrenos de la vieja mina de carbón de Nordstern en Horst. La última producción de coque salió de las instalaciones industriales de la ciudad el 29 de septiembre de 1999, marcando el fin de un sector predominante en la economía local durante 117 años. En ese mismo año, Shell Solar Deutschland AG abrió una línea de producción de equipos para la generación de energía solar fotovoltaica. El 28 de abril de 2000, cerró la mina Ewald-Hugo, la última de carbón de la ciudad, con lo que perdieron su empleo unos 3.000 mineros. En 2003, Buer celebró el milésimo aniversario de su primera aparición en un documento, mientras que el 4 de mayo de 2004 el equipo de fútbol local FC Schalke 04 celebró su centenario.

A principios del siglo XXI, Gelsenkirchen es un centro científico, industrial y de servicios, además de contar con buenas comunicaciones e infraestructuras.

Gelsenkirchen se presenta a sí misma como centro de la tecnología solar. Shell Solar Deutschland GmbH y Scheuten Solar Technology fabrican células fotovoltaicas en Rotthausen, aunque hay muchas otras grandes empresas en la zona: THS GmbH, Gelsenwasser, e.on, BP Gelsenkirchen GmbH y Pilkington. Según un estudio de la Fundación Bertelsmann, Gelsenkirchen es, tras Leipzig, Karlsruhe y Bremen, la cuarta ciudad de Alemania en lo que a facilidades para la instalación de empresas se refiere.

Las comunicaciones por carretera de Gelsenkirchen con el resto del país se basan en las grandes autopistas de peaje o "Bundesautobahnen" A 2, A 40, A 42 y A 52, así como en las autovías federales o "Bundesstrassen" B 224, B 226 and B 227. En cuanto al ferrocarril destaca la Estación Central de Gelsenkirchen como punto de enlace de las líneas Oberhausen-Gelsenkirchen-Herne-Dortmund y Essen-Gelsenkirchen-Recklinghausen-Münster.

Por vía fluvial puede llegarse Gelsenkirchen a través del Canal Rhine-Herne gracias a un puerto comercial e industrial con un tráfico anual de 2 millones de toneladas y una superficie acuática de unos 1,2 km², siendo una de las mayores instalaciones portuarias fluviales de Alemania. Además está conectado a la red nacional de ferrocarriles ("Deutsche Bahn")

El transporte local de Gelsenkirchen se estructura en varias líneas de tranvía y autobús controladas por BOGESTRA ("Bochum-Gelsenkirchener Strassenbahn AG") principalmente además de por "Vestische Straßenbahnen GmbH" en la zona norte, aunque solamente opera servicios de autobús. Cuenta además con una línea de premetro operada por EVAG ("Essener Verkehrs-AG") que conecta Buer con Essen. Las líneas de tranvía comunican la ciudad con Bochum y Essen. Todos estos servicios tienen integrado su sistema de billetes. En total en Gelsenkirchen hay tres líneas de tranvía, una de tren ligero y 50 de autobús.

Con ocasión de la Copa Mundial de Fútbol de la FIFA del año 2006 fueron mejoradas todas las infraestructuras de transporte dedicadas al servicio del Veltins AufSchalke Arena, incluido una profunda reforma de la Estación Central de Ferrocarril.

Gelsenkirchen acoge la sede de la VLR o Asociación Registrada de la Red Local de Radio de Renania del Norte-Westfalia ("Verband Lokaler Rundfunk in Nordrhein-Westfalen e.V."), así como los estudios de REL ("Radio Emscher-Lippe").

Entre los periódicos destacar el diario "Buersche Zeitung" en la calle hasta 2006, momento en que sin motivo económico alguno la empresa cerró la publicación. Desde entonces el periódico "Ruhr-Nachrichten", editado en Dortmund, dedica una sección a las noticias locales. Posteriormente apareció el "Westdeutsche Allgemeine Zeitung", única publicación local de Gelsenkirchen y que monopoliza "de facto" el mercado. Asimismo la radio local REL informa de los sucesos locales.

También se reparte un periódico gratuito semanal, el "Stadtspiegel Gelsenkirchen", junto con otros mensuales o irregulares como el "Familienpost" o el "Beckhausener Kurier".

Gelsenkirchen cuenta con 51 escuelas primarias (36 públicas, 12 católicas y 3 evangélicas) y 21 escuelas secundarias (8 "Hauptschulen" y 6 "Realschulen" que permiten acceder a la formación profesional y 7 "Gymnasien" que además son preparatorios para la Universidad), así como 4 "Gesamtschulen" (escuelas no basadas en calificaciones académicas), entre las que destaca la "Gesamtschule Bismarck", única de esta clase gestionada por la Iglesia Luterana Evangélica de Westfalia.

La "Fachhochschule Gelsenkirchen", institución universitaria fundada en 1992, cuenta con campus en Bocholt y Recklinghausen y ofrece las titulaciones de Economía, Ciencias de la Computación, Ingeniería Física, Ingeniería Eléctrica e Ingeniería Mecánica, entre otras.

Asimismo Gelsenkirchen es una de las siete ciudades donde la "Fachhochschule für öffentliche Verwaltung NRW" (Universidad Politécnica Estatal de Renania del Norte-Westfalia) cuenta con instalaciones, destacando los estudios de Servicios Administrativos Municipales, Entrenamiento Policial y Economía Administrativa. Además la ciudad acoge una escuela de adultos y una biblioteca municipal con sucursales en Horst, Buer y Erle y más de 100.000 libros, películas y CD.

Gelsenkirchen es la ciudad del equipo de fútbol de la Bundesliga FC Schalke 04. El estadio del Schalke, el Veltins-Arena, es considerado uno de los más innovadores construidos entre finales del siglo XX y principios del XXI. Su construcción se debió a la elección de la ciudad como una de las 12 sedes del Mundial de Fútbol de 2006. En concreto acogió los partidos de primera ronda Polonia-Ecuador, Argentina-Serbia y Montenegro, Portugal-México y los Estados Unidos-República Checa.

Esta ciudad también se convirtió en sede de la final de la Liga de Campeones en 2004, donde se disputó la final de ésta, Oporto 3 - Mónaco 0. Es la ciudad natal de varios futbolistas, entre estos el jugador del Arsenal Mesut Özil y de Hamit Altintop jugador del Galatasaray y su hermano gemelo Halil Altıntop jugador del Eintracht Frankfurt, del jugador del Manchester City Ilkay Gündogan y además del portero de la Selección alemana de fútbol, Manuel Neuer.




</doc>
<doc id="45646" url="https://es.wikipedia.org/wiki?curid=45646" title="Principio de mínima acción">
Principio de mínima acción

El principio de mínima acción, principio de acción estacionaria o principio de Hamilton es un presupuesto básico de la mecánica clásica y la mecánica relativista para describir la evolución a lo largo del tiempo del estado de movimiento de una partícula como de un campo físico. También en mecánica cuántica Feynman y Kac intentaron formulaciones inspiradas en el principio.

Históricamente, el principio de mínima acción postulaba que, para sistemas de la mecánica clásica, la evolución temporal de todo sistema físico se daba de tal manera que una cantidad llamada "acción" tendía a ser la mínima posible.

Posteriormente, se generalizó el principio a sistemas continuos, donde las magnitudes básicas no solo dependían de una variable temporal, sino también de las otras coordenadas espacio-temporales. Además la formulación relativista del principio mostró que la condición de mínimo era demasiado restrictiva, y que debía ser sustituida por la condición un poco más general de que la trayectoria debía ser un punto crítico o estacionario (es decir, un valor extremo).

La primera formulación del principio se debe a Pierre-Louis Moreau de Maupertuis (1744), que dijo que la "naturaleza es económica en todas sus acciones" (D'Alembert había formulado un año antes el principio de d'Alembert que generalizaba las leyes de Newton). Entre los que desarrollaron la idea se incluyen Euler y Leibniz. Debe ser dicho que, desde el punto de vista del cálculo de variaciones, hablar de principio de acción estacionaria es más exacto.
Anteriormente, Pierre de Fermat había introducido la idea de que los rayos de la luz, en situaciones ópticas tales como la refracción y la reflexión, seguían un principio de "menor tiempo" (ver principio de Fermat).

El principio de menor acción condujo al desarrollo de las formulaciones lagrangiana y hamiltoniana de la mecánica clásica. Aunque sean al principio más difíciles de captar, tienen la ventaja que su cosmovisión es más transferible a los marcos de la Teoría de la Relatividad y la mecánica cuántica que la de las leyes de Newton. Esto ha hecho pensar a alguna gente que este principio es un principio "profundo" de la física.

La formulación del principio para un sistema lagrangiano es: fijado un sistema de coordenadas generalizadas sobre el espacio de configuración (o una parte del mismo, llamada carta local), se tiene que de todas las trayectorias posibles que transcurren entre el instante "t" y "t", el sistema escogerá aquella que minimice la acción "S". La magnitud acción viene dada para cada trayectoria por la integral:

Donde:
Puede probarse mediante principios variacionales, que de todas las trayectorias posibles, la que hace mínima (o, más bien, estacionaria) la anterior expresión es la que corresponde para todo "i" la siguiente ecuación:

Es decir, la variación de la integral temporal de la función lagrangiana es igual a cero. De esta ecuación se deducen asimismo las ecuaciones de Euler-Lagrange:

La formulación anterior es adecuada para partículas puntuales, o incluso sistemas mecánicos con un número finito de grados de libertad aunque no sean puntuales como un sólido rígido. Sin embargo, para campos físicos que tienen una variación espacial o para la mecánica de medios continuos la formulación anterior no es adecuada y debe generalizarse.

La generalización más obvia es definir la acción como la integral de una función escalar, denominada densidad lagrangiana integrada sobre el volumen donde existe el campo o medio continuo:

En teoría clásica de campos es frecuente escribir la ecuación anterior de forma totalmente covariante:

Y en ese caso las ecuaciones de Euler-Lagrange resultan ser:

A partir de las leyes de Newton puede probarse el principio de mínima acción para partículas de la mecánica Newtoniana. Esta deducción puede hacerse a partir del principio de D'Alambert que es esencialmente equivalente a las leyes de Newton. Sin embargo, el principio de mínima acción es más general puesto que, a diferencia de las ecuaciones de Newton, es aplicable también a sistemas de referencia no inerciales. Las leyes de Newton también son aplicables en sistemas de referencia no inerciales introduciendo a las fuerzas ficticias.

Por otro lado admitiendo el principio de mínima acción de una sola partícula y ciertos principios de simetría pueden deducirse las ecuaciones de Newton. A continuación se presentan varias deducciones y ejemplos ilustrativos que muestran la equivalencia parcial de la mecánica newtoniana y el principio de mínima acción.

En esta sección probaremos cómo, a partir de la segunda ley de Newton, o equivalentemente el principio de D'Alembert, puede deducirse que para una partícula que obedece ese principio se cumple también el principio de mínima acción. Partiendo de la segunda ley se tiene que:

Esta forma es totalmente equivalente al principio de D'Alembert que establece que bajo cualquier desplazamiento virtual compatible con las ecuaciones de movimiento:

Como es bien sabido, para una fuerza conservativa que deriva de un potencial se tiene que formula_11, es decir, la energía potencial formula_12 es igual al negativo del producto escalar de la fuerza por el desplazamiento del cuerpo. Reescribiendo la última ecuación introduciendo la definición de la aceleración:

Procedemos a integrar por partes el segundo término del lado izquierdo de la ecuación: 1) aplicando la derivada temporal a la variación de la distanciaformula_14, en lugar de hacerlo a la velocidad formula_15, y 2) introduciendo un término límite, que hace referencia a la diferencia del valor de la función formula_16 entre los puntos formula_17 y formula_18:

Los puntos de partida y de llegada de todas las trayectorias son los mismos, y por ello en esos lugares la variación es cero formula_20. Ello implica que la condición límite formula_21 sea asimismo igual a cero en dichos lugares. Por ello, desaparece de la ecuación:

Procedemos a la integración de formula_23 en el segundo término:

Las reglas del cálculo nos permiten trasladar los símbolos de la variación fuera de las dos integrales:

En esta ecuación están presentes las expresiones de la energía potencial formula_26 y la energía cinética formula_27. Por lo tanto, puede reformularse de la siguiente manera:

Donde la diferencia formula_29 recibe el nombre de "función lagrangiana" y se representa con la letra formula_30:

La primera ley de Newton puede deducirse a partir del principio de mínima acción de las propiedades de homogeneidad e isotropía del espacio euclídeo tridimensional. Para una partícula libre la función lagrangiana debido a las propiedades de homogeneidad del espacio no depende explícitamente de las coordenadas de posición. Igualmente debido a la isotropía, la dependencia en la velocidad de la partícula solo puede depender del módulo al cuadrado de la velocidad. Eso nos lleva a que el lagrangiano debe ser de la forma:

Si tomamos un sistema de referencia inercial K' que se mueve respecto al sistema anterior a una velocidad muy pequeña V, tenemos que la velocidad y el lagrangiano se transforman de acuerdo con las siguientes leyes:

Por tanto tendremos que para velocidades V pequeñas las formas funcionales de los dos lagrangianos están relacionadas por:
Como las trayectorias solo pueden ser iguales si las dos funciones anteriores solo difieren en una derivada total del tiempo, es necesario que exista una función de las coordenadas y del tiempo, tal que su derivada coincida con ese sumando. Eso solo puede ocurrir si el segundo término es una función lineal de la velocidad cosa que solo sucede si la derivada del segundo término se anula. Eso último a su vez requiere que:

Si introducimos esa forma del lagrangiano en las ecuaciones de Euler-Lagrange tenemos la primera ley de Newton:

Esta última ecuación dice que una partícula libre mantiene su velocidad constante. Si se estudia la misma partícula sometida a una fuerza constante puede deducirse que la cosntante coincide con la masa de la partícula, α = "m".

En mecánica relativista la acción de una partícula se obtiene mediante cálculo a lo largo de la línea de universo de una partícula, concretamente una partícula material de masa "m" se mueve a lo largo de una geodésica. La integral de acción a lo largo de una curva "L" viene dada en coordenadas curvilíneas por:
Si se introduce en las ecuaciones de Euler-Lagrange el integrando de la anterior integral se obtienen las ecuaciones de las geodésicas:
Un campo físico es cualquier tipo de magnitud que presenta variación tanto espacial como temporal. El tratamiento de este tipo de entidades físicas requiere el tratamiento mediante densidades lagrangianas, ya que no son representables como sistemas con un número finito de grados de libertad. Además su tratamiento riguroso generalmente requiere el uso de la mecánica relativista para explicar su propagación. Los campos con los que usualmente trata la teoría clásica de campos:

La integral de acción para el campo electromagnético viene dado por un escalar construido a partir del tensor campo electromagnético:

De hecho este lagrangiano puede reescribirse en términos de los campos eléctrico y magnético para dar (en unidades cgs):

Introduciendo este lagrangiano en las ecuaciones de Euler-Lagrange, el resultado son las ecuaciones de Maxwell no homogéneas.

En relatividad general el campo gravitatorio es visto como una manifestación de la geometría curva del espacio tiempo, por tanto la formulación lagrangiana del campo gravitatorio relativistamente tratado debe involucrar a algún escalar relacionado con el tensor métrico y sus derivadas primeras (equivalentemente los símbolos de Christoffel formula_32) o con el tensor de curvatura. Puede probarse que no es posible hallar ningún escalar que involucre solo las componentes del tensor métrico y los símbolos de Christoffel, ya que mediante cierta transformación de coordenadas se pueden anular estos últimos (lo cual es precisamente el contenido del llamado principio de equivalencia). 

Es interesante que la curvatura escalar "R", nos da una forma de acción adecuada: aunque contiene derivadas segundas del tensor métrico, la variación de su integral de acción sobre una región puede acabar expresándose en términos de solo derivadas primeras. De hecho la forma común de la integral de acción para el campo gravitatorio más comúnmente en la teoría de la relatividad general es:

Donde:
Algunas teorías métricas de la gravitación como la teoría relativista de la gravitación usan lagrangiano ligeramente más complicado que incluye términos asociados a la masa del gravitón. Si se substituye la integral de acción anterior en las ecuaciones de Euler-Lagrange se obtienen como resultado las ecuaciones de campo de Einstein.

"el movimiento del sistema entre los tiempos formula_18 y formula_17 es tal que el valor de la integral curvilínea.
formula_39

donde L=T-U es la lagrangiana, tiene un valor estacionario para el movimiento correcto".

A la integral J se le llama integral de acción.

Por valor estacionario entendemos que es aquel para el cual δJ=0, esto es, que el valor de la integral curvilínea cuando recorre el camino correcto no varía respecto de los caminos vecinos infinitesimalmente próximos (al menos, cuando estos infinitésimos son de primer orden).




</doc>
<doc id="45647" url="https://es.wikipedia.org/wiki?curid=45647" title="Principio de Fermat">
Principio de Fermat

El principio de Fermat, en óptica, es un principio de tipo extremal y que establece: Este enunciado no es completo y no cubre todos los casos, por lo que existe una forma moderna del principio de Fermat. Esta dice que: Esto quiere decir que, si se expresa el trayecto recorrido por la luz entre dos puntos formula_1 y formula_2 por medio de una funcional llamada camino óptico definida como formula_3 la trayectoria real de la luz seguirá un camino extremal respecto de esta funcional:

La característica importante, como dice el enunciado, es que los trayectos próximos al "verdadero" requieren tiempos aproximadamente iguales. En esta forma, el principio de Fermat recuerda al principio de Hamilton o a las ecuaciones de Euler-Lagrange.

El principio en su forma moderna fue declarado por Pierre de Fermat en una carta de 1662, de ahí que lleve su nombre. 

Siguen ahora algunos ejemplos de la aplicación del principio para deducir las leyes de la óptica geométrica.

La ecuación de la trayectoria de un rayo luminoso real en un sistema óptico es:

formula_4

y se deduce a partir del principio de Fermat.

Tenemos un rayo de luz que de desplaza por un medio con índice de refracción continuo desde un punto formula_5 a un punto formula_6. 

Sea formula_7 el vector posición y formula_8 el vector tangente a la trayectoria. 

Tenemos que formula_9. De esto se deduce que formula_10. Además se tiene que formula_11 y que formula_12. 

Por lo tanto formula_13. Al ser formula_14 de un vector arbitrario tenemos que formula_15 y por tanto que formula_16. 

De esto se obtiene que formula_17. Notamos queformula_18. 

Por otro lado tenemos que (se empleará cartesianas pero sirve para el resto de bases ortonormales): 

formula_19porque formula_20. 

formula_21porque formula_15. 

formula_23. 

formula_24porque formula_25. 

formula_26porqueformula_27. 

Realizando las mismas compinentes para formula_28e formula_29se obtiene que: 

formula_30. 

Reemplazando se obtiene que: 

formula_31 o formula_32.

El camino óptico se puede equiparar a la acción en la mecánica lagrangiana. Se puede tratar el índice de refracción como un lagrangiano compuesto por un potencial. De este modo el problema se puede resolver con las ecuaciones de Lagrange. El rayo de luz se dirige hacia la zona de mayor índice de refracción, de lo que el potencial equivalente sería el opuesto del índice de refracción.

Tenemos: formula_33 con formula_34.

De modo que si definimos formula_35 obtenemos que: formula_36.

Se obtiene: formula_37

Además se tiene que formula_38 o formula_39.

Creando un sistema con las tres coordenas se obtiene que: formula_40.

Partimos de que: 

formula_32. 

Con formula_42constante, de lo que: 

formula_43y formula_44. 

Por tanto: 

formula_45 de lo que formula_46 siendo formula_47 una constante, de lo que formula_48 siendo formula_49 una constante. 

El resultado es una recta de punto inicial formula_49 y vector director formula_47. 

Si sobre cada rayo emitido por un foco recorremos caminos ópticos iguales, entonces los puntos que los delimitan forman una superficie normal a todos los rayos. Denominamos a dicha superficie frente de ondas. Coincide con el frente de onda dado por la teoría oscilatoria. Al deducirse del principio de Fernat es válido a pesar del número de reflexiones o refracciones que pueda sufrir el rayo antes de llegar a su destino.

Si se supone que un rayo de luz sale del punto A en dirección a la superficie plana, que suponemos reflectora, y viaja hasta el punto B ¿Cuál será la trayectoria seguida por la luz? En este caso la luz viaja durante todo el camino por el mismo medio, con el mismo índice de refracción y, por tanto, a la misma velocidad. Así, el tiempo necesario para recorrer el camino entre A y B (pasando por la superficie P) será la distancia APB dividida por la velocidad de la luz en ese medio. Como la velocidad es una constante, la trayectoria real, según el principio de Fermat, será la más corta.

Es fácil ver que la distancia APB es la misma que la distancia A'PB, donde A' es la imagen de A. A' está sobre la recta perpendicular al espejo que pasa por A, a la misma distancia del espejo que A y al otro lado del mismo. La distancia mínima A'PB es, obviamente, la línea recta A'P2B, con lo que la trayectoria real es AP2B. El análisis completo de la situación muestra que P2 es tal que los ángulos de incidencia y de reflexión en el punto son iguales, de lo que se deduce la fórmula de la ley de la reflexión: formula_52

Sea un medio de propagación con índice de refracción formula_53 y un segundo medio de propagación con índice de refracción formula_54 tales que situamos la superficie que separa los dos medios de modo que coincida con el eje de las abcisas.

Sean formula_55 y formula_56 dos puntos fijos situados del plano, de modo que A está situado en el primer medio, y B en el segundo medio.

Sea un rayo de luz que se propaga de A a B atravesando la superficie que separa los dos medios en el punto formula_57.

El siguiente paso es deducir el tiempo que tarda el rayo en recorrer formula_58 y formula_59.

Sean formula_60 y formula_61 la velocidad de propagación de la luz en el primer y segundo medio respectivamente.

Si se busca el valor de formula_63 cuando formula_64 es mínimo, es equivalente si encontramos el valor de formula_63 para el cual la función derivada de formula_64 toma el valor 0.

Herón de Alejandría (Heron) (c. 60) describió un principio de reflexión, que declaraba que un rayo de luz que va desde el punto A al punto B, sufriendo cualquier número de reflexiones en espejos planos, en el mismo medio, tiene un trayecto con menor longitud que cualquier trayecto cercano.

Ibn al-Haytham (Alhazen), en su "Libro de Óptica" (1021), amplió el principio tanto a la reflexión como a la refracción, y expresó una temprana versión del principio del menor tiempo. Sus experimentos se basaron en trabajos anteriores sobre la refracción realizados por el científico griego Claudio Ptolomeo.

El principio generalizado del menor tiempo en su forma moderna fue declarado por Pierre de Fermat en una carta fechada el 1 de enero de 1662 enviada a Cureau de la Chambre. Se encontró con las objeciones efectuadas en mayo de 1662 por Claude Clerselier, un experto en óptica y líder portavoz de los cartesianos en ese momento. Entre sus objeciones, Clerselier establecía:

El original, en francés, de Mahoney, es el siguiente:

De hecho el principio de Fermat no se sostiene por sí solo, y ahora se sabe que se puede derivar de principios anteriores, como el principio de Huygens. Históricamente, el principio de Fermat ha servido como principio rector en la formulación de las leyes de la Física con el uso del cálculo variacional (véase el principio de mínima acción).


</doc>
<doc id="45651" url="https://es.wikipedia.org/wiki?curid=45651" title="Principio de Fresnel - Huygens">
Principio de Fresnel - Huygens

El principio de Huygens-Fresnel es un método de análisis aplicado a los problemas de propagación de ondas. Se llama así en honor a los físicos Christiaan Huygens y Augustin-Jean Fresnel, y puede enunciarse así:
Esta visión de la propagación de las ondas ayuda a entender mejor los fenómenos de difracción, reflexión y la refracción de las ondas.

Por ejemplo, si dos cuartos están conectados por una puerta abierta y se produce un sonido en una esquina lejana de uno de ellos, una persona en el otro cuarto oirá el sonido como si se originara en el umbral. Por lo que se refiere al segundo cuarto, el aire que vibra en el umbral es la fuente del sonido.

Lo mismo ocurre para la luz al pasar el borde de un obstáculo, pero esto no es fácilmente observable debido a la corta longitud de onda de la luz visible. La interferencia de la luz de áreas con distancias variables del frente de onda móvil explica los máximos y los mínimos observables como franjas de difracción. Ver, por ejemplo, el experimento de la doble rendija.

En 1678, Huygens propuso que cada punto alcanzado por una perturbación luminosa se convierte en una fuente de una onda esférica. La suma de estas ondas secundarias determina la forma de la onda en cualquier momento posterior. Huygens supuso que las ondas secundarias viajaban únicamente "hacia adelante" sin explicar en su teoría por qué éste es el caso. Fue capaz de dar una explicación cualitativa de la propagación de la onda lineal y esférica, y de derivar las leyes de la reflexión y la refracción con este principio, pero no pudo explicar las desviaciones de la propagación rectilínea que se producen cuando la luz se encuentra con bordes, aberturas y pantallas, comúnmente conocidos como efectos de difracción.



</doc>
<doc id="45653" url="https://es.wikipedia.org/wiki?curid=45653" title="Peso colombiano">
Peso colombiano

El peso es la unidad monetaria de curso legal en la República de Colombia. Su abreviación formal es COP (ISO 4217), e informalmente es abreviada COL$. Localmente se usa el signo peso. Su circulación es controlada por el Banco de la República de Colombia.

El peso ha sido la moneda colombiana desde 1810. En 1837 el peso reemplazó al real a una tasa de cambio de 1 peso = 8 reales, estando dividido inicialmente en 8 reales. En 1847 Colombia decimalizó su moneda, dividiendo el peso en 10 reales, cada uno de los cuales se dividía en 10 décimos de reales. El real fue renombrado décimo en 1853, aunque las últimas monedas de real fueron acuñadas en 1880. El sistema actual de 100 centavos para el peso se utilizó por primera vez en 1819 apareciendo en los billetes, pero no reaparece hasta principios de 1860 sobre los billetes y no se utilizó en la moneda hasta el año de 1872.

En 1871 Colombia adoptó el patrón oro, ligando el peso al franco francés en una tasa de cambio de 1 peso = 5 francos. Esta tasa solo se mantuvo hasta 1886. En 1880 el presidente Rafael Núñez crea el Banco Nacional de la República de Colombia, el cual tenía entre sus múltiples funciones la de imprimir el papel moneda (denominado peso "moneda corriente"), que a partir de 1888 sufrió una acelerada inflación.
Para solucionar esta situación el gobierno de José Manuel Marroquín establece en 1903 la Junta de Amortización, que debe convertir todo el papel moneda circulante en oro, a una tasa de conversión de 100 pesos papel moneda = 1 peso oro. Luego, bajo el gobierno del general Rafael Reyes se creó el Banco Central, el cual continuó con muchas de las funciones de la Junta de Amortización y estableció una tasa de cambo fija respecto a la libra esterlina, según la cual 5 pesos equivalían a 1 libra.

También durante el gobierno del general Rafael Reyes Prieto se crea una amplia controversia acerca del funcionamiento del Banco Central, lo que lleva al gobierno a cancelar su contrato con el Banco Central y expedir la Ley 69 de 1909, según la cual se crea la Junta de Conversión, encargada de retomar el trabajo dejado por la ya extinta Junta de Amortización. Durante este periodo el papel moneda comienza a imprimirse con valores nominales expresados en "pesos oro".

Luego de la Primera Guerra Mundial el país sufre algunos problemas monetarios, que llevaron a que el presidente Pedro Nel Ospina solicitara en 1922 a los Estados Unidos la asesoría de especialistas en materia económica, los cuales emprendieron una misión conocida como la misión Kemmerer, liderada por Edwin Walter Kemmerer, bajo cuyas recomendaciones se crea en 1923 el actual emisor: el Banco de la República.

En 1931, cuando el Reino Unido abandonó el patrón oro, Colombia cambió su vinculación al dólar estadounidense, a razón de 1,05 pesos = 1 dólar, una leve devaluación de su anterior vinculación. Esta vinculación existió hasta 1949, cuando la inflación de la moneda colombiana acabó con esta tasa de cambio.

La convertibilidad del peso colombiano por oro termina en 1931, gracias al decreto 1638 de 1931.

A pesar de lo anterior los billetes emitidos por el Banco de la República continuaron llevando sus denominaciones en "pesos oro" hasta 1993, cuando una demanda interpuesta por el exsenador Pablo Victoria ante el Consejo de Estado hizo que la palabra «"oro"» y el término «"pagará al portador"» fueran eliminados de los billetes.

Actualmente circulan monedas de 50, 100, 200, 500 y 1000 pesos ($). Entre 1996 y 2002 estuvo en circulación activa la primera acuñación de una moneda de $1000, la cual perdió popularidad debido a su falsificación masiva. Se dejó de acuñarlas y fueron reemplazadas por la emisión de un billete de 1000 pesos. Aunque esta moneda aún no ha salido de circulación, y aún conserva su valor cambiario, era muy difícil encontrarla en circulación corriente hasta la introducción de un nuevo tiraje de monedas acuñadas por el Banco de la República, puesta al público a partir del segundo semestre de 2012.

En 1998, en conmemoración de los 50 años de la OEA, el Banco de la República puso en circulación una edición especial de 5000 monedas únicas de $5000. Pero por su presentación en un estuche, su alto valor facial y la baja acuñación, estas monedas prácticamente no circularon.

En 2006, se rediseñó la moneda de $20 que estaba saliendo de circulación para menguar la costumbre de redondear los precios a la siguiente denominación ($50). Aun así, la moneda es utilizada regularmente solo por almacenes de cadena.

Posteriormente, en 2007, se cambió la composición de las monedas de $50 de alpaca a acero revestido de níquel, por los gastos que representaba su producción. Luego en 2008, la composición de las monedas de $50 retornó a ser de alpaca.

El 9 de febrero de 2009, el Banco de la República anunció que dejaría de acuñar las monedas de 5, 10 y 20 pesos, debido a su baja circulación, aunque podrán seguir circulando entre el público «"hasta agotar existencias"».

En un principio, y desde 1996, fue propuesto cambiar el cono monetario en circulación, tanto así que, a partir del 13 de junio de 2012, salieron a circulación, junto con los diseños anteriores, la nueva serie de monedas con diseños inspirados en la fauna y flora endémicas del país. Las piezas que entraron en circulación tienen un nuevo diseño, y dichas monedas (de 50, 100, 200, 500 y la nueva moneda de 1000 pesos), están hechas de otro tipo de aleaciones, y cuentan con dos monedas bimetálicas (500 y 1000 pesos), siendo un diseño distinto al que tenían las que dejaron de circular hace algunos años. Según lo dicho por el gerente del Banco de la República, José Darío Uribe, estas medidas buscan disminuir los costos de producción de tales denominaciones. Las caras de las nuevas monedas evocan la biodiversidad, a través de plantas y animales silvestres colombianos como el oso de anteojos (50 pesos), el reconocido frailejón (100 pesos), la guacamaya bandera (200 pesos), la rana de cristal (500 pesos) y la tortuga caguama (1000 pesos) y fueron elaboradas con la participación de Johana Calle y José Antonio Suárez. El concepto transversal de las monedas es la biodiversidad y el cuidado de agua, y es explícita la intención por las inscripciones en la moneda de 1000 pesos: "cuidar el agua" en el reverso y "agua" en el anverso; así como implícita en el resto de las monedas, pues las ondas que aparecen en los marcos de todas las denominaciones hacen alusión al agua.

La previsión original del Banco de la República de Colombia era abrir sus puertas en 1924, pero la quiebra del Banco López le obligó a abrir sus puertas seis meses antes, razón por la cual se vio obligado a tomar billetes de la Casa de Moneda de Medellín en denominaciones 2 y 1/2, 5, 10 y 20 pesos, resellándolos con el texto ""Banco de la República - Billete Provisional"". De estos billetes resellados, se conocen varios ejemplares de 2 y 1/2, 5, y 10 pesos, algunos muy bien conservados, pero cabe anotar que del billete de 20 pesos, solo hay un ejemplar conocido con resello, en un lamentable estado de conservación 3 (en una escala de 1 a 10), o para el sistema norteamericano un Fair. Poco tiempo después, ese mismo año, llegaron al país los billetes originalmente encargados por el Banco.

El 16 y 17 de octubre de 1994 en Valledupar un grupo de delincuentes organizados sustrajeron de la oficina del Banco de la República de dicha ciudad la suma de $ 24 075 millones de pesos, entre billetes «sin circular» de $2000, $5000 y $10 000, que en ese entonces eran los de mayor denominación. El banco tenía conocimiento de los números de serie de esos billetes, por lo que expidió una lista de los rangos de series de los billetes robados, los cuales pasaron a no tener ningún valor. La sociedad colombiana vivió días de zozobra en las transacciones en efectivo, puesto que los billetes se distribuyeron por todo el país en aras de camuflarlo entre los billetes legales. Durante varias semanas las personas revisaban uno por uno los billetes que les entregaban para evitar recibir un billete «vallenato» como se comenzaron a conocer las series de los billetes hurtados.

Posteriormente el Banco de la República para menguar el caos generado por el robo, cambió el diseño de los billetes de $2000, $5000 y $10 000 por unos con diseños y medidas de seguridad diferentes, y que aún hoy en día circulan paralelamente al nuevo cono; hasta agotar su vida útil, y comenzó a recoger todos los billetes (robados y no robados del cono anterior) para acelerar el cambio.

El salió en circulación la moneda de $1000; en sustitución del billete de la misma denominación (azul, con la cara de Simón Bolívar). Esta moneda fracasó no solo porque fue ampliamente falsificada, sino porque su diseño era visualmente idéntico al de la moneda de $100, a excepción de la denominación y tamaño ligeramente más pequeño. Finalmente el Banco de la República recogió las monedas y diseñó el actual billete de $1000 con el tema de Jorge Eliécer Gaitán.

Hasta 2006, todos los billetes colombianos, sin importar su denominación, tenían la misma medida (140x70 mm). El 17 de noviembre del mismo año, el Banco de la República sacó a circulación los nuevos diseños de los billetes de $1000 y $2000 (los billetes de menor denominación). Estos billetes tienen el mismo diseño e idénticas características generales y dispositivos de seguridad que los de la edición anterior, únicamente cambia el tamaño, a 130x65 mm.

En 2015 mediante un anuncio en medios de prensa, el emisor anunció de forma oficial que, para el primer trimestre de 2016; saldría a circulación un billete de 100 000 pesos, el de mayor denominación en la historia colombiana, el cual sería decorado con el busto del expresidente del Frente Nacional, Carlos Lleras Restrepo, como parte de la nueva familia de billetes que circularán simultáneamente con los billetes actuales. Esta nueva familia también está compuesta por billetes de todas las denominaciones anteriores exceptuando el de 1000 pesos, que viene siendo reemplazado por la segunda moneda bimetálica colombiana de la misma denominación puesta en circulación en 2012.

La justificación del emisor para el cambio de las caras de los billetes es la seguridad y la confianza de las personas en el efectivo como medio de pago. La temática transversal a los billetes, la biodiversidad, continua la propuesta de las últimas monedas puestas en circulación, además de resaltar elementos culturales y paisajes que se han convertido en símbolos de riqueza, variedad y creatividad de Colombia. La presencia de nuevas caras en los billetes se da en cumplimiento a leyes que fueron promulgadas y que se mantenían a la espera de su cumplimiento, como el caso de la Ley 1167 de 2007 que ordenaba la memoria de Carlos Lleras Restrepo, cuadragésimo noveno ; el caso de la Ley 1741 de 2014 que ordenaba la memoria de Gabriel García Márquez, primer premio Nobel de Colombia, siéndolo por el área de ; el caso de la Ley 1599 de 2012 que ordenaba la memoria de Alfonso López Michelsen, quincuagésimo primer y el caso de la Ley 908 de 2004 que declaraba símbolo cultural de la nación al sombrero vueltiao.

En varias ocasiones se han presentado proyectos de ley para cambiar la denominación del peso colombiano, para «quitarle ceros» a la moneda y llamarla temporalmente «Nuevo Peso», sin embargo el proyecto ha sido rechazado en varias ocasiones por motivos políticos y económicos (supuestos altos costos) que lo hacen impracticable.

Un proyecto de ley con este cambio fue presentado en 2010 y rechazado en octubre de 2011 por el Senado de la República, sin embargo es de anotar que a lo largo del tiempo, ninguno de los proyectos presentados han contado con serias posibilidades para realizar este cambio, siendo en su mayoría proyectos que se quedan en primer debate y son rechazados por una amplia mayoría por el amplio desconocimiento de la iniciativa, aparte de las falsas creencias de reducción de valor en el circulante.

El 19 de septiembre de 2012, el presidente Juan Manuel Santos decide retomar la idea y la respalda argumentando que se trata de una tendencia global e imprescindible para reducir costos en la contabilidad, la cual no restaría valor al peso sino que lo fortalecería.

En marzo de 2016, en el lanzamiento del billete de 100 000 pesos y con él, el lanzamiento de la nueva familia de billetes, el ministro del Hacienda Mauricio Cárdenas aseguró que el diseño de los nuevos billetes está encaminado a que los tres ceros del peso se eliminen hacia el futuro y que se pueda hacer la transición sin costos adicionales. Por esta razón, en la nueva familia de billetes aparece el número correspondiente al valor del billete sin los tres últimos ceros pero seguido de la palabra «MIL» en letras para que cuando se eliminen los tres ceros, entonces el único valor que tendrán los billetes será sin los tres ceros. Por ejemplo, en el billete de 100 000 pesos aparece la denominación como «100 MIL PESOS» que eventualmente se transformaría en «100 PESOS» sin hacer necesario el cambio de diseño de los billetes.

Ya dicho cambio que, habría sido favorecido por temas legales, fue nuevamente debatido en el congreso de la república de Colombia, con una nueva ponencia en el mes de marzo del año 2018.

El 20 de junio de 2018, en la Cámara de Representantes, se aprobó en segundo debate el proyecto de ley 231 para la reconversión monetaria. Sin embargo, la iniciativa no prosperó con el nuevo gobierno, pues por recomendación de Fedesarrollo este proceso se debería realizar de forma gradual.

Debido a la Crisis económica en Venezuela y a la Hiperinflación, generó que a mediados de 2015 se empezará a usar el Peso colombiano junto con el Dólar estadounidense como medio de ahorro pero ya desde 2017 empezó a tener uso de forma corriente aunque no de forma legal en las zonas fronterizas de Venezuela . Aunque el peso es aceptado en gran parte de Venezuela, tiene un rol secundario tras el Dólar estadounidense, salvo en Táchira donde es la principal divisa de la economía . Las autoridades venezolanas algunas veces han logrado detener algún contrabando de pesos colombianos en efectivo.




</doc>
<doc id="45657" url="https://es.wikipedia.org/wiki?curid=45657" title="Topología simpléctica">
Topología simpléctica

La topología simpléctica es aquella parte de las matemáticas referida al estudio de las variedades simplécticas. Estas variedades se presentan naturalmente en la formulación hamiltoniana de la mecánica clásica, que proporciona una de las motivaciones principales para el tema. Hay un modelo "local" estándar, a saber R con 
"ω" = 1; "ω" = -1; "ω" = 0 para todo "i = 0...,n-1"; "j,k=0...,2n-1" ("k" ≠ "j+n" o "j" ≠ "k+n"). Se llama a esto un espacio "lineal" simpléctico. 

Una variedad simpléctica es un par ("M", ω) donde "M" es una variedad diferenciable y ω es una 2-forma cerrada, no degenerada en "M" llamada la forma simpléctica. Aquí, "no degenerada" significa que para cada vector distinto de cero "u" en el espacio tangente en un punto, hay un vector "v" tal que

Los ejemplos fundamentales de variedades simplécticas vienen dados por los fibrados cotangentes de variedades; estos se presentan en la mecánica clásica, donde el conjunto de todas las configuraciones posibles de un sistema se modela como variedad, y el fibrado cotangente de esta variedad describe el espacio de fase del sistema. Las variedades de Kähler son también variedades simplécticas. Ya en los años 70, los simplécticos expertos estaban inseguros de si existía alguna variedad simpléctica compacta no kähleriana, pero muchos ejemplos se han construido desde entonces; en particular, Robert Gompf ha demostrado que cada grupo finitamente presentado aparece como el grupo fundamental de alguna 4-variedad simpléctica, en contraste marcado con el caso kähleriano. 

Directamente de la definición, se puede demostrar que "M" es de dimensión par 2"n" y que el ω es una forma nula en ninguna parte, la forma volumen. Se sigue que una variedad simpléctica está canónicamente orientada y viene con una medida canónica, la medida de Liouville.

En una variedad simpléctica, cada función diferenciable, "H", define un campo vectorial único,"X", llamado el campo vectorial hamiltoniano. Se define de tal modo que para cada campo vectorial "Y" en "M" la identidad

valga. Los campos vectoriales hamiltonianos dan a las funciones en "M" la estructura de un álgebra de Lie con el corchete de Poisson

(Advertencia: otras convenciones de signo están también en uso).

El flujo de un campo vectorial hamiltoniano es un simplectomorfismo es decir un difeomorfismo que preserva la forma simpléctica. Esto se sigue de la cerradura de la forma simpléctica y de la expresión de la derivada de Lie en términos de la derivada exterior. Como una consecuencia directa tenemos el teorema de Liouville: el volumen simpléctico es invariante bajo un flujo hamiltoniano. como {"H","H"} ="X""H" = 0 el flujo de un campo vectorial hamiltoniano también preserva "H". En física esto se interpreta como la ley de conservación de la energía. El teorema de Liouville se interpreta como la conservación del volumen de fase en sistemas hamiltonianos, que es la base para la mecánica estadística clásica. Acabamos de mostrar que hay una correspondencia uno a uno entre simplectomorfismos infinitesimales y las funciones diferenciables sobre una variedad simpléctica. 

A diferencia de las variedades de Riemann, las variedades simplécticas son extremadamente no rígidos: tienen muchos simplectomorfismos provenientes de campos vectoriales hamiltonianos. La diferencia fundamental entre la geometrías riemanniana y simpléctica es que una variedad simpléctica no tiene ningún invariante local: según el teorema de Darboux para cada punto "x" en un variedad simpléctica hay un conjunto coordenado local llamado variables ángulo con los coordenadas "p"...,"p","q"...,"q", tales que:ω = Σ d"p" ∧ d"q" 

Los subgrupos finito-dimensionales del grupo de simplectomorfismos son grupos de Lie. Representaciones de estos grupos de Lie (después de h-deformaciones, en general!) en los espacios de Hilbert se llaman "cuantizaciones". Cuando el grupo de Lie es definido por un hamiltoniano, se llama una "cuantización por energía". El operador de Lie correspondiente del álgebra de Lie al álgebra de Lie de operadores lineales continuos también es, a veces, llamada la cuantización, y es una manera más común, entre físicos, de considerarla. 

Aunque la mayoría de los variedades simplécticas no son kählerianas y por tanto, no tienen una estructura compleja integrable compatible con la forma simpléctica, Mikhail Gromov ha hecho la importante observación que las variedades simplécticas admiten una abundancia de estructuras casi complejas compatibles, de modo que satisfagan todos los axiomas para una variedad compleja excepto el requisito de que las funciones de transición sean holomorfas. Una superficie de Riemann mapeada en una variedad simpléctica compatible con la estructura casi compleja se llama curva seudoholomorfa, y Gromov probó un teorema de compacidad para tales curvas; este resultado ha conducido al desarrollo de la subdisciplina bastante grande de la topología simpléctica. Los resultados que surgen de la teoría de Gromov incluyen el teorema nonsqueezing de Gromov referente a inmersiones simplécticas de esferas en cilindros, así como una conjetura de Vladimir Arnol'd referente al número de punto fijos de los flujos hamiltonianos; esto fue probada con generalidad en aumento por varios investigadores que comenzaron con Andreas Floer, que introdujo lo que ahora se conoce como homología de Floer que usa los métodos de Gromov. Las curvas seudoholomorfas son también una fuente de invariantes simplécticos, conocidos como invariantes de Gromov-Witten, por los cuales dos diversas variedades simplécticas podrían en principio ser distinguidas.




</doc>
<doc id="45659" url="https://es.wikipedia.org/wiki?curid=45659" title="Formas diferenciales cerradas y exactas">
Formas diferenciales cerradas y exactas

En matemáticas, en el cálculo vectorial y en la topología diferencial, los conceptos de forma cerrada y forma exacta son definidos para las formas diferenciales, por las ecuaciones

para que una forma dada α sea una forma cerrada, y

para una forma exacta, con formula_1 dada y formula_2 desconocida. 

Como formula_3, ser exacta es condición suficiente para ser cerrada. En términos abstractos, el interés principal de este par de definiciones es preguntar si ésta es también una condición necesaria es una manera de detectar la información topológica por condiciones diferenciales. No tiene ningún sentido real preguntar si una 0-forma es exacta, dado que "d" aumenta el grado en 1.

Los casos de formas diferenciales en formula_4 y formula_5 eran ya bien conocidas en la física matemática del siglo XIX. En el plano, 0-formas son simplemente funciones, y las 2-formas son funciones por el elemento de área básica formula_6, de modo que son las 1-formas

las que son de interés real. La fórmula para la derivada exterior "d" es

donde los subíndices denotan derivadas parciales por lo tanto la condición para que α sea "cerrada" es

En este caso si formula_7 es una función entonces

La implicación de 'exacta' a 'cerrada' es entonces una consecuencia de la simetría de las segundas derivadas, con respecto a "x" y a "y".

El resultado topológico fundamental aquí es el lema de Poincaré. Establece que para un subconjunto abierto contractible de "X", cualquier "p"-forma diferenciable definida en "X" que sea cerrada, es también exacta, para cualquier número entero "p" > 0 (esto tiene contenido solamente cuando "p" es a lo sumo "n"). 

Esto no es verdad para un anillo abierto en el plano, para algunas 1-formas que no se extienden suavemente al disco entero; de modo que una cierta condición topológica es necesaria. 

En términos de la cohomología de De Rham, el lema dice que los conjuntos contractibles tienen los grupos de cohomología de un punto (considerando que los 0-formas constantes son cerradas pero vacuamente no son exactas).



</doc>
<doc id="45660" url="https://es.wikipedia.org/wiki?curid=45660" title="Intervención militar de Haití en 2004">
Intervención militar de Haití en 2004

La intervención militar de Haití en 2004 surge como una revuelta armada contra Jean-Bertrand Aristide. Este había asumido la presidencia de Haití en febrero de 2001, tras ganar las elecciones por el 91,69% de los votos. Pronto sufrió graves críticas por no contener la corrupción ni mejorar la economía del país, que estaba moribunda.

Por objeciones de la oposición, las elecciones no se pudieron celebrar, como estaba previsto, a finales de 2003. Esto le quitó poder a Aristide, ya que la validez de la mayoría de los legisladores expiró en enero de 2004, lo que forzó al presidente a gobernar a base de decretos. En diciembre de 2003, bajo una presión creciente, Aristide prometió nuevas elecciones en un plazo de seis meses. Rechazó las peticiones de la oposición de su dimisión inmediata.

Las manifestaciones anti-Aristide en enero de 2004 llevaron a violentos enfrentamientos en Puerto Príncipe, con varias víctimas mortales.

El 5 de febrero de 2004 estalló una revuelta en la ciudad de Gonaïves. El instigador principal fue una banda llamada Frente para la Liberación y la Reconstrucción Nacional (Front pour la Libération et la Reconstruction Nationales), que antes había apoyado a Aristide. 

Los rebeldes tomaron el control de Gonaïves, y expulsaron a la policía -mal equipada- de la ciudad. La rebelión empezó a extenderse, aumentada por antiguos soldados exiliados y líderes milicianos (como Louis-Jodel Chamblain), procedentes de la República Dominicana.

El 22 de febrero de 2004, Cap-Haïtien, la segunda mayor ciudad de Haití, cayó bajo los rebeldes. El mismo día, un equipo de mediadores, consistente en diplomáticos de Estados Unidos, Francia, Canadá y Chile presentó un plan, con la intención de reducir el poder de Aristide, pero permitiéndole mantener el cargo hasta el fin constitucional de su mandato, en favor de un nuevo gobierno que incluiría a la oposición. Aunque Aristide aceptó el plan, fue rechazado por la oposición, que exigía la dimisión de Aristide. 29 de febrero de 2004, el presidente electo de Haití Jean-Bertrand Aristide, fue obligado a abandonar su país.

Jean-Bertrand Aristide, fue secuestrado por un comando de fuerzas élites militares estadounidenses, luego de recibir las amenazas de “emisarios” franceses. El Presidente fue obligado a abandonar su país, y llevado a la República Centroafricana y a Jamaica, finalmente lo dejaron en Sudáfrica, país que lo recibió y lo reconoció como presidente legítimo.

Cuando las fuerzas golpistas empezaron a marchar hacia el sur, camino de Port-Au-Prince, Aristide sufrió un golpe de Estado por el ejército el 29 de febrero de 2004. Su sucesor fue el presidente del tribunal supremo Boniface Alexandre, quien actuó como presidente interino hasta el 2006, cuando fue elegido presidente René Préval.

El Caricom, que estuvo apoyando el proceso de paz, acusó a los Estados Unidos, a Francia y a la comunidad internacional de fallar en Haití, por permitir un golpe de Estado contra un presidente elegido democráticamente. 

El gobierno estadounidense declaró que la crisis estuvo motivada por Aristide y que su expulsión era necesaria para la estabilidad futura del país. La ONU y la OEA no realizaron declaraciones acerca del golpe.

En marzo de 2004, una comisión investigadora sobre Haití dirigida por el exfiscal general de Estados Unidos, Ramsey Clark revela que "los gobiernos de Estados Unidos y de República Dominicana habrían participado en el suministro de armas y en el entrenamiento en ese país de los ‘rebeldes' haitianos". La comisión comprobó que con la autorización del presidente Hipólito Mejía 200 soldados de las fuerzas especiales estadounidenses habían sido enviados en febrero de 2003 a República Dominicana para participar en ejercicios militares. Esos ejercicios se realizaron "cerca de la frontera, precisamente en una zona desde la cual los ex militares haitianos lanzaban regularmente ataques contra las instalaciones del Estado haitiano".

Según el periódico "Le Monde diplomatique", "el avance de esas bandas armadas permitió al embajador estadounidense, James Foley, forzar la partida del presidente Aristide el 29 de febrero de 2004, ayudado en esa tarea y en la instauración de una fuerza de paz por el gobierno francés. París buscaba una reconciliación con Estados Unidos luego de la crisis iraquí y no estaba dispuesto a dejar que Washington actuara solo en Haití, lo que implicaba el riesgo de verse excluido de una isla a la que la unen lazos históricos. Por otra parte, al reclamarle reparaciones por más de 21.000 millones de dólares Aristide había irritado mucho a Francia (suma que Haití pagó a Francia, como precio de su independencia (en aquella época, 90 millones de francos-oro)."




</doc>
<doc id="45666" url="https://es.wikipedia.org/wiki?curid=45666" title="Derecho de sociedades">
Derecho de sociedades

El Derecho de sociedades, Derecho societario o Derecho corporativo o Derecho empresarial es la rama del Derecho privado que se ocupa del empresario social, es decir, la sociedad como sujeto del tráfico empresarial. La sociedad recibe personalidad jurídica por Ley y se convierte en una persona jurídica, lo cual significa que puede ser sujeto de derechos y obligaciones jurídicas en su propio nombre, y no en nombre de sus socios. El Derecho de sociedades regula el funcionamiento interno y de cara a terceros que tienen las sociedades formadas conforme a la Ley.

Tradicionalmente se distingue entre sociedades civiles y sociedades mercantiles, según estén regidas por la normas generales civiles o por normas específicamente mercantiles. 

En algunos casos el carácter mercantil de una sociedad viene derivado de la adopción de una forma social específica con independencia del objeto al que se dedique (por ejemplo, sociedad comanditaria, sociedad anónima o sociedad de responsabilidad limitada) o, en el resto de los casos, cuando el objeto social es el desarrollo de una actividad mercantil o empresarial. 

Dentro de las sociedades mercantiles, las más importantes actualmente, suele distinguirse entre "sociedades de personas" (sociedad colectiva y sociedad comanditaria simple) y "sociedades de capital" (sociedad anónima, sociedad de responsabilidad limitada y sociedad comanditaria por acciones). La principal diferencia entre un grupo y otro es la forma de admisión de nuevos socios y de transmisión de los derechos sociales. Mientras en las sociedades de personas, al ser "intuitu personae", se requiere la aprobación de los demás socios (habitualmente unánime), en las sociedades de capital ella no es necesaria, bastando la adquisición de una cuota del capital (acciones). Además, el procedimiento para aumentar el capital social suele ser más simple en las sociedades de capital que en las sociedades de personas.

Respecto a la responsabilidad de los socios por las deudas de la sociedad, en las sociedades de capital los socios sólo responden hasta el monto del capital aportado, mientras que en las sociedades de personas normalmente los socios responden ilimitadamente con todos los bienes presentes y futuros (socios de una sociedad colectiva y socios "gestores" de una sociedad comanditaria) y, excepcionalmente, de forma limitada (socios de una sociedad de responsabilidad limitada y socios "comanditarios" de una sociedad comanditaria).


En España, el Derecho de sociedades no se regula en un solo cuerpo legal, sino que su regulación se encuentra dispersa en diferentes cuerpos legales, principalmente en el Código civil de 1889, el Código de Comercio de 1885 y Real Decreto Legislativo 1/2010, de 2 de julio, por el que se aprueba el texto refundido de la Ley de Sociedades de Capital.

Además existe legislación especial que regula formas societarias menos comunes y, a nivel comunitario, también se proyecta introducir nuevas formas societarias. De hecho, el 8 de octubre de 2001 se aprobó el Estatuto de la Sociedad Europea, introducido mediante el Reglamento (CE) N.º 2157/2001, en vigor desde el 8 de octubre de 2004.

En México la legislación se encuentra amparada en las leyes laborales y de sociedades mercantiles. Entre las principales formas de constitución están:
SA - sociedad anónima.
SC - sociedad civil.
AC - asociación civil.
S de RL - sociedad de responsabilidad limitada.




</doc>
